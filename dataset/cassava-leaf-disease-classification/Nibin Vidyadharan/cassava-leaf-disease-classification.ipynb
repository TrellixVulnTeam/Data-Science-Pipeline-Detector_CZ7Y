{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#base imports \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \n\n#display image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n#deep learing \nimport tensorflow as tf\n\n#splitting the data\n#splitting the data \nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_height=500\nimg_width=600\nimg = mpimg.imread(\"../input/cassava-leaf-disease-classification/train_images/1000015157.jpg\")\nimgplot = plt.imshow(img[:img_width,:img_height])\nplt.show()\nimg.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading json file \nimport json\n\nwith open(\"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\") as f:\n  data = json.load(f)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\ndata_augmentation = tf.keras.Sequential(\n    [\n     layers.experimental.preprocessing.RandomRotation(0.05),\n     layers.experimental.preprocessing.RandomCrop(28, 28)\n    ]\n)\n\nmodel = tf.keras.Sequential([\n    data_augmentation,\n\n    layers.Flatten(input_shape=(28, 28, 1)),\n    layers.Dense(4096, activation='relu'),\n    layers.Dense(10)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimage_path= glob.glob(\"../input/cassava-leaf-disease-classification/train_images/*.jpg\")\nlabels= pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\nlabels[\"label\"]\nd = {'path': image_path, 'label': labels[\"label\"]}\ndf = pd.DataFrame(data=d)\ndf=df.iloc[:5000]\nlabels.label\n\nX_train, X_test, y_train, y_test = train_test_split(df.path, df.label, test_size=0.33, random_state=42)\n\nX_train=X_train.tolist()\nX_test=X_test.tolist()\ny_train=y_train.tolist()\ny_test=y_test.tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# directory=\"../input/cassava-leaf-disease-classification/train_images\"\n# data=tf.keras.preprocessing.image_dataset_from_directory(\n#     directory,\n#     label_mode=\"int\",\n#     class_names=None,\n#     color_mode=\"rgb\",\n#     batch_size=32,\n#     image_size=(256, 256),\n#     shuffle=True,\n#     seed=None,\n#     validation_split=None,\n#     subset=None,\n#     interpolation=\"bilinear\",\n#     follow_links=False,\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_files=\"../input/cassava-leaf-disease-classification/train_images\"\ntrain_data = tf.data.Dataset.from_tensor_slices((X_train,y_train))\ntest_data = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n\ndef process_img(file_path,label):\n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, size=(img_height, img_width))\n    return (img,label)\n\ntrain_data = train_data.map(process_img).batch(10)\ntest_data = test_data.map(process_img).batch(10)\n\n\nimg,target = next(iter(train_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting function \nfrom sklearn.metrics import confusion_matrix\n\n''' the idea of this function to make the prediction accouding to the input.'''\ndef prediction_matrix(dataframe,model,size):\n    #sorting the value wrt to the label \n    df=dataframe.sort_values(by=['label'])\n    #picking the 10\n    df=df.iloc[:size]\n    #getting the image path\n    x_train=df.path\n    x_train=x_train.tolist()\n    #getting the image label\n    y_train=df.label\n    y_train=X_train.tolist()\n    #creating the dataset object\n    train_data = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n    train_data = train_data.map(process_img).batch(size)\n    \n    #passing the matrix to model \n    predictions=model.predict(train_data)\n    predicted_class_list=[]\n    for x in predictions:\n        score = tf.nn.softmax(x)\n        predicted_class=np.argmax(score)\n        predicted_class.append(predicted_class)\n        \n    return predicted_class_list\n#     confusion_matrix(train_data, predicted_class_list)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = tf.data.Dataset.range(10)\ndataset=dataset.batch(5)\niterator = iter(dataset)\nprint(iterator.get_next())\n\nprint(iterator.get_next())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.layers.experimental\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten,experimental\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\n\nmodel_vgg_lite = Sequential()\nnum_classes=5\n# First CONV-ReLU Layer\nmodel_vgg_lite.add(Conv2D(64, (3, 3), padding = 'same', input_shape=(img_height, img_width, 3)))\nmodel_vgg_lite.add(Activation('relu'))\nmodel_vgg_lite.add(BatchNormalization())\n\n# Second CONV-ReLU Layer\nmodel_vgg_lite.add(Conv2D(64, (3, 3), padding = \"same\", input_shape=(img_height, img_width, 3)))\nmodel_vgg_lite.add(Activation('relu'))\nmodel_vgg_lite.add(BatchNormalization())\n\n# Max Pooling with Dropout \nmodel_vgg_lite.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_vgg_lite.add(Dropout(0.2))\n\n# 3rd set of CONV-ReLU Layers\nmodel_vgg_lite.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel_vgg_lite.add(Activation('relu'))\nmodel_vgg_lite.add(BatchNormalization())\n\n# 4th Set of CONV-ReLU Layers\nmodel_vgg_lite.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel_vgg_lite.add(Activation('relu'))\nmodel_vgg_lite.add(BatchNormalization())\n\n# Max Pooling with Dropout \nmodel_vgg_lite.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_vgg_lite.add(Dropout(0.2))\n\n# 5th Set of CONV-ReLU Layers\nmodel_vgg_lite.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel_vgg_lite.add(Activation('relu'))\nmodel_vgg_lite.add(BatchNormalization())\n\n# 6th Set of CONV-ReLU Layers\nmodel_vgg_lite.add(Conv2D(256, (3, 3), padding=\"same\"))\nmodel_vgg_lite.add(Activation('relu'))\nmodel_vgg_lite.add(BatchNormalization())\n\n# Max Pooling with Dropout \nmodel_vgg_lite.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_vgg_lite.add(Dropout(0.2))\n\n# First set of FC or Dense Layers\nmodel_vgg_lite.add(Flatten())\nmodel_vgg_lite.add(Dense(256))\nmodel_vgg_lite.add(Activation('relu'))\nmodel_vgg_lite.add(BatchNormalization())\nmodel_vgg_lite.add(Dropout(0.5))\n\n# Second set of FC or Dense Layers\nmodel_vgg_lite.add(Dense(256))\nmodel_vgg_lite.add(Activation('relu'))\nmodel_vgg_lite.add(BatchNormalization())\nmodel_vgg_lite.add(Dropout(0.5))\n\n# Final Dense Layer\nmodel_vgg_lite.add(Dense(num_classes))\nmodel_vgg_lite.add(Activation(\"softmax\"))\nmodel_vgg_lite.add(Dense(num_classes)) \n##units are 1 because we are using binary activation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\nmodel_checkpoint = ModelCheckpoint(\"keras.model\", save_best_only=True, verbose=1)\ncallbacks_list = [model_checkpoint]\nmodel_vgg_lite.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_vgg_lite.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"epochs=50\nhistory = model_vgg_lite.fit(\n  train_data,validation_data=test_data,\n  epochs=epochs,callbacks=callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = mpimg.imread(\"../input/cassava-leaf-disease-classification/train_images/1000015157.jpg\")\nimg_array=tf.convert_to_tensor(\n    img,)\nimg_array = tf.expand_dims(img[:img_width,:img_height], 0) # Create a batch\n\npredictions=model_vgg_lite.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n# score\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(np.argmax(score), 100 * np.max(score))\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data.take(5)\n# list(train_data.take(1).as_numpy_iterator())\n\npredictions=model_vgg_lite.predict(train_data.take(1))\n# prediction =train_data.take(3).map(displayimage)\n# predictions.shape\nscore = tf.nn.softmax(predictions[0])\npredictions\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in train_data.unbatch().take(1).as_numpy_iterator():\n    print(x)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}