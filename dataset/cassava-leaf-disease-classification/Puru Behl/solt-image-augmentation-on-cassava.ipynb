{"cells":[{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install solt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Augmentation Using SOLT"},{"metadata":{},"cell_type":"markdown","source":"![](https://github.com/MIPT-Oulu/solt/raw/master/doc/source/_static/logo.png)"},{"metadata":{},"cell_type":"markdown","source":"### Data augmentation libarary for Deep Learning, which supports images, segmentation masks, labels and keypoints.\n### Features:\n* Support of Images, masks and keypoints for all the transforms (including multiple items at the time)\n* Fast and PyTorch-integrated\n* Convenient and flexible serialization API\n* Excellent documentation\n* Easy to extend\n* 100% Code coverage"},{"metadata":{},"cell_type":"markdown","source":"# Importing The Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport os, cv2, json\nfrom PIL import Image\nimport solt\nimport solt.transforms as slt\nimport random\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysing The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"WORK_DIR = '../input/cassava-leaf-disease-classification'\nos.listdir(WORK_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train images: %d' %len(os.listdir(\n    os.path.join(WORK_DIR, \"train_images\"))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(os.path.join(WORK_DIR, \"label_num_to_disease_map.json\")) as file:\n    print(json.dumps(json.loads(file.read()), indent=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing The DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\ntrain_labels.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Distribution In The Csv File"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_labels['label'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examples Of Label 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=train_labels[train_labels['label']==0]\nx=sample['image_id'].head(4).values\nplt.figure(figsize=(18,8))\nfor i,n in enumerate(x):\n    plt.subplot(1,4,i+1)\n    im=Image.open('../input/cassava-leaf-disease-classification/train_images/'+n)\n    plt.imshow(im)\n    plt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examples Of Label 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=train_labels[train_labels['label']==1]\nx=sample['image_id'].head(4).values\nplt.figure(figsize=(18,8))\nfor i,n in enumerate(x):\n    plt.subplot(1,4,i+1)\n    im=Image.open('../input/cassava-leaf-disease-classification/train_images/'+n)\n    plt.imshow(im)\n    plt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examples Of Label 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=train_labels[train_labels['label']==2]\nx=sample['image_id'].head(4).values\nplt.figure(figsize=(18,8))\nfor i,n in enumerate(x):\n    plt.subplot(1,4,i+1)\n    im=Image.open('../input/cassava-leaf-disease-classification/train_images/'+n)\n    plt.imshow(im)\n    plt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examples Of Label 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=train_labels[train_labels['label']==3]\nx=sample['image_id'].head(4).values\nplt.figure(figsize=(18,8))\nfor i,n in enumerate(x):\n    plt.subplot(1,4,i+1)\n    im=Image.open('../input/cassava-leaf-disease-classification/train_images/'+n)\n    plt.imshow(im)\n    plt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examples Of Label 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=train_labels[train_labels['label']==4]\nx=sample['image_id'].head(4).values\nplt.figure(figsize=(18,8))\nfor i,n in enumerate(x):\n    plt.subplot(1,4,i+1)\n    im=Image.open('../input/cassava-leaf-disease-classification/train_images/'+n)\n    plt.imshow(im)\n    plt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augmentation Using SOLT"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since we have low data on label 0 let's start with it :)\nsample=train_labels[train_labels['label']==0]\nx=sample['image_id'].head(2).values\nimg=Image.open('../input/cassava-leaf-disease-classification/train_images/'+x[1])\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Stream to Flip the images"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  \n    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rotate ( To rotate the image ) "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r')\n    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Shear \nShear tool is used to shift one part of an image, a layer, a selection or a path to a direction and the other part to the opposite direction"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r')\n    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see shear effect in the 4th image :)"},{"metadata":{},"cell_type":"markdown","source":"# Scaling\nScaling is used to change the visual appearance of an image, to alter the quantity of information stored in a scene representation, or as a low-level preprocessor in multi-stage image processing chain which operates on features of a particular scale"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r'),\n    slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5)\n    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cropping The Image\nCropping is the removal of unwanted outer areas from a photographic or illustrated image"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"h,w,c=img.shape","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nstream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r'),\n    slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n    slt.Pad((h,w),'r'),\n    slt.Crop((w,w),'r')\n    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see the cropping in image1 :)"},{"metadata":{},"cell_type":"markdown","source":"# HSV ( hue, saturation ,value )\nIn color image processing, there are various models one of which is the hue, saturation, value (HSV) model. Using this model, an object with a certain color can be detected and to reduce the influence of light intensity from the outside."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nstream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r'),\n    slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n    slt.Pad((h,w),'r'),\n    slt.Crop((w,w),'r'),\n    slt.HSV((0, 10), (0, 10), (0, 10))\n    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Blur\nBlurring is an example of applying a low-pass filter to an image. In computer vision, the term “low-pass filter” applies to removing noise from an image while leaving the majority of the image intact. A blur is a very common operation we need to perform before other tasks such as edge detection."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nstream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r'),\n    slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n    slt.Pad((h,w),'r'),\n    slt.Crop((w,w),'r'),\n    slt.HSV((0, 10), (0, 10), (0, 10)),\n    slt.Blur(k_size=7, blur_type='m')\n    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cutout\nCutting out a specific part of the image :)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nstream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r'),\n    slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n    slt.Pad((h,w),'r'),\n    slt.Crop((w,w),'r'),\n    slt.HSV((0, 10), (0, 10), (0, 10)),\n    slt.Blur(k_size=7, blur_type='m'),\n    slt.CutOut(40, p=1),\n    slt.CutOut(50, p=1),\n    slt.CutOut(60, p=1),\n    slt.CutOut(70, p=1),\n\n    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SelectiveStreaming\nStream that uniformly selects n out of k given transforms."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nstream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r'),\n    slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n    slt.Pad((h,w),'r'),\n    slt.Crop((w,w),'r'),\n    slt.HSV((0, 10), (0, 10), (0, 10)),\n    slt.Blur(k_size=7, blur_type='m'),\n    solt.SelectiveStream([\n        slt.CutOut(40, p=1),\n        slt.CutOut(80,p=4),\n        slt.Crop((w,w),'r'),\n        slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n        solt.Stream(),\n        solt.Stream(),\n    ], n=3)    ])\n\nfig = plt.figure(figsize=(16,16))\nn_augs = 4\n\n\nrandom.seed(42)\nfor i in range(n_augs):\n    img=np.array(img)\n    img_aug = stream({'image': img}, return_torch=False, ).data[0].squeeze()\n\n    ax = fig.add_subplot(1,n_augs,i+1)\n    if i == 0:\n        ax.imshow(img)\n    else:\n        ax.imshow(img_aug)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making DataContainer ( To Contain Images)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample=train_labels[train_labels['label']==0]\nx=sample['image_id'].head(4).values\nims=[]\nplt.figure(figsize=(18,8))\nfor i,n in enumerate(x):\n    plt.subplot(1,4,i+1)\n    im=Image.open('../input/cassava-leaf-disease-classification/train_images/'+n)    \n    ims.append(np.array(im, dtype=np.uint8))\n    plt.imshow(im)\n    plt.axis(\"off\")\nplt.show()\ntt=tuple(ims)\ndc = solt.DataContainer(tt, 'IIII')\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Creating The Stream\nstream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r'),\n    slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n    slt.Pad((h,w),'r'),\n    slt.Crop((w,w),'r'),\n    slt.HSV((0, 10), (0, 10), (0, 10)),\n    slt.Blur(k_size=7, blur_type='m'),\n    solt.SelectiveStream([\n        slt.CutOut(40, p=1),\n        slt.CutOut(80,p=4),\n        slt.Crop((w,w),'r'),\n        slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n        solt.Stream(),\n        solt.Stream(),\n    ], n=3)    ])\ndc_res = stream(dc, return_torch=False)\nimg_res= dc_res.data\n# Getting the format of the data\ndc_res.data_format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 4, figsize=(16, 8))\nfor i in range(2):\n    for j in range(4):\n        if i==0:\n            \n            ax[i, j].set_title('Original image')\n            ax[i, j].imshow(tt[j].squeeze())\n\n        else:\n            ax[i, j].set_title('Transformed image')\n            ax[i, j].imshow(img_res[j].squeeze())\n        ax[i, j].set_axis_off()\n\n\nplt.axis(\"off\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Augmentation On Cats And Dogs :P"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nx=os.listdir('../input/cat-and-dog/training_set/training_set/dogs')\nx=x[1:5]\nims=[]\nplt.figure(figsize=(18,8))\nfor i,n in enumerate(x):\n    plt.subplot(1,4,i+1)\n    im=Image.open('../input/cat-and-dog/training_set/training_set/dogs/'+n)    \n    im=im.resize((128,128))\n    ims.append(np.array(im, dtype=np.uint8))\n    plt.imshow(im)\n    plt.axis(\"off\")\nplt.show()\ntt=tuple(ims)\ndc = solt.DataContainer(tt, 'IIII')\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Creating The Stream\nstream = solt.Stream([\n    slt.Flip(axis=1, p=0.5)  ,\n    slt.Rotate(angle_range=(-90, 90), p=1, padding='r'),\n    slt.Shear(range_x=0.3, range_y=0.8, p=0.5, padding='r'),\n    slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n    slt.Pad((128,128),'r'),\n    slt.Crop((128,128),'r'),\n    slt.HSV((0, 10), (0, 10), (0, 10)),\n    slt.Blur(k_size=7, blur_type='m'),\n    solt.SelectiveStream([\n        slt.CutOut(40, p=1),\n        slt.Scale(range_x=(0.8, 1.3), padding='r', range_y=(0.8, 1.3), same=False, p=0.5),\n        solt.Stream(),\n        solt.Stream(),\n    ], n=3)    ])\ndc_res = stream(dc, return_torch=False)\nimg_res= dc_res.data\n# Getting the format of the data\ndc_res.data_format","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 4, figsize=(16, 8))\nfor i in range(2):\n    for j in range(4):\n        if i==0:\n            \n            ax[i, j].set_title('Original image')\n            ax[i, j].imshow(tt[j].squeeze())\n\n        else:\n            ax[i, j].set_title('Transformed image')\n            ax[i, j].imshow(img_res[j].squeeze())\n        ax[i, j].set_axis_off()\n\n\nplt.axis(\"off\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cool Right :)\n# Drop a vote if you liked it :)"},{"metadata":{},"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/e2/d7/c7/e2d7c71b09ae9041c310cb6b2e2918da.gif)"},{"metadata":{},"cell_type":"markdown","source":"## You can see the implementation of SOLT with keras in : https://www.kaggle.com/accountstatus/solt-augmentation-and-keras-model :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}