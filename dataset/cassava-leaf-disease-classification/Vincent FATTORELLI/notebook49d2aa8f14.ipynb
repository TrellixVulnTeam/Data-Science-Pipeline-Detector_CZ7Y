{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n#from PIL import Image\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport random\n\nimport re\nimport json\n\n#!pip install tensorflow-gpu\n#!pip install -q --upgrade tensorflow\nimport tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T20:12:34.718551Z","iopub.execute_input":"2021-11-15T20:12:34.718866Z","iopub.status.idle":"2021-11-15T20:12:34.732258Z","shell.execute_reply.started":"2021-11-15T20:12:34.718821Z","shell.execute_reply":"2021-11-15T20:12:34.731256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def allocate_data(frac_total=0.4):\n    \"\"\"\n    \"\"\"\n    # Creating the base dir\n    base_dir = 'base_dir'\n    if os.path.isdir(base_dir):\n        shutil.rmtree(base_dir)\n        os.mkdir(base_dir)\n    else:\n        os.mkdir(base_dir)\n        \n    # Creating train and validation dir\n    train_dir = os.path.join(base_dir, \"train_dir\")\n    if not os.path.isdir(train_dir):\n        os.mkdir(train_dir)\n        \n    val_dir = os.path.join(base_dir, \"val_dir\")\n    if not os.path.isdir(val_dir):\n        os.mkdir(val_dir)\n    \n    \n    # Getting the different labels\n    json_labels = '/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json'\n    with open(json_labels) as json_file:\n        labels = json.load(json_file)\n        #data_keys = data.keys()\n        labels = {key : labels[key].replace(\" \", \"_\") for key in labels.keys()} \n        #print(labels)\n    \n    # Creating the labels' directories\n    for d in [train_dir, val_dir]:\n        for label in labels.values():\n            t_dir = os.path.join(d, label)\n            if not os.path.isdir(t_dir):\n                os.mkdir(t_dir)\n                \n    print(f\"Directories for training: {os.listdir(train_dir)}\")\n    print(f\"Directories for validation: {os.listdir(val_dir)}\")\n    \n    # Load labels dataframe and sample it for train and validation\n    labels_df = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n    #print(labels_df.head())\n    labels_df = labels_df.groupby('label').apply(lambda x: x.sample(frac=frac_total))\n    train_sample = labels_df.sample(frac = 0.70, replace=False, random_state=1998)\n    val_sample = labels_df.drop(train_sample.index)    \n    train_sample_dict = train_sample.to_dict() \n    val_sample_dict = val_sample.to_dict() \n    \n    #print(train_sample_dict['image_id'].values())\n    #print(f\"Train : {len(train_images_id)}, Validation : {len(val_images_id)}\")\n    print(f\"Train : {len(train_sample_dict['image_id'])}, Validation : {len(val_sample_dict['image_id'])}\")\n    \n    # Transfer the images\n    train_images_dir = \"../input/cassava-leaf-disease-classification/train_images\"\n    ## Train dir\n    #test = []\n    for image_key, image_value in train_sample_dict['image_id'].items():\n        label_ = train_sample_dict['label'][image_key]\n        label = labels[str(label_)]\n        image = str(image_value)\n        #test.append(image)\n        src = os.path.join(train_images_dir, image)\n        dst = os.path.join(train_dir, label, image)\n        shutil.copyfile(src, dst)\n    #print(test)\n        \n    ## Validation dir\n    for image_key, image_value in val_sample_dict['image_id'].items():\n        label_ = val_sample_dict['label'][image_key]\n        label = labels[str(label_)]\n        image = str(image_value)\n        #test.append(image)\n        src = os.path.join(train_images_dir, image)\n        dst = os.path.join(val_dir, label, image)\n        shutil.copyfile(src, dst)\n    \n    print(\"\\nTrain set:\\n\")\n    total = 0\n    for label in labels.values():\n        t = os.path.join(train_dir, label)\n        total += len(os.listdir(t))\n        print(f\"Length of {label} in {train_dir} is: {len(os.listdir(t))}\")\n    print(f\"\\nTotal: {total}\")\n    print(\"\\nVal set:\\n\")\n    \n    total = 0\n    for label in labels.values():\n        t = os.path.join(val_dir, label)\n        total += len(os.listdir(t))\n        print(f\"Length of {label} in {val_dir} is: {len(os.listdir(t))}\")\n    print(f\"\\nTotal: {total}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:12:34.734279Z","iopub.execute_input":"2021-11-15T20:12:34.734567Z","iopub.status.idle":"2021-11-15T20:12:34.751044Z","shell.execute_reply.started":"2021-11-15T20:12:34.73453Z","shell.execute_reply":"2021-11-15T20:12:34.750445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allocate_data()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:12:34.752119Z","iopub.execute_input":"2021-11-15T20:12:34.752417Z","iopub.status.idle":"2021-11-15T20:13:29.57571Z","shell.execute_reply.started":"2021-11-15T20:12:34.752392Z","shell.execute_reply":"2021-11-15T20:13:29.574488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def import_images_paths(n=5, is_random=False):\n    train_path = './base_dir/train_dir'\n    train_directories = os.listdir(train_path)\n    \n    paths_dict = {}\n    for x in train_directories:\n        t_join = os.path.join(train_path, x)\n        t_listdir = os.listdir(t_join)\n        t_len_listdir = len(t_listdir)\n        if is_random:\n            t_listdir = [t_listdir[i] for i in random.sample(range(0, t_len_listdir + 1), n)]\n        else:\n            t_listdir = os.listdir(t_join)[:n]\n        paths_dict[x] = [os.path.join(t_join, y) for y in t_listdir]\n        #print(os.listdir(os.path.join(train_path, x))[:5])\n    return paths_dict","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:29.577863Z","iopub.execute_input":"2021-11-15T20:13:29.578686Z","iopub.status.idle":"2021-11-15T20:13:29.586815Z","shell.execute_reply.started":"2021-11-15T20:13:29.578622Z","shell.execute_reply":"2021-11-15T20:13:29.585972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def import_images(n=5, is_random=False):\n    paths_dict = import_images_paths(n, is_random)\n    \n    images_dict = {}\n    for key, values in paths_dict.items():\n        t_list_images = []\n        for value in values:\n            t_list_images.append(mpimg.imread(value))\n        images_dict[key] = t_list_images\n    \n    return images_dict","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:29.589856Z","iopub.execute_input":"2021-11-15T20:13:29.590118Z","iopub.status.idle":"2021-11-15T20:13:29.604927Z","shell.execute_reply.started":"2021-11-15T20:13:29.59009Z","shell.execute_reply":"2021-11-15T20:13:29.60412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import_images_paths()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:29.60599Z","iopub.execute_input":"2021-11-15T20:13:29.606214Z","iopub.status.idle":"2021-11-15T20:13:29.615847Z","shell.execute_reply.started":"2021-11-15T20:13:29.606178Z","shell.execute_reply":"2021-11-15T20:13:29.614874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(n=5, is_random=False):\n    images_dict = import_images(n, is_random)\n    \n    #plt.figure(figsize=(20,10))\n    \n    columns = n#5\n    lines = len(images_dict.keys())#1\n    fig, ax = plt.subplots(lines, columns, figsize=(8 * 2.5, 6 * 2.5))\n    \n    i = 0\n    for key, values in images_dict.items():\n        for j, image in enumerate(values):\n            #plt.subplot(lines, columns, j + 1) #(len(images) / columns + 1, columns, i + 1)\n            ax[i, j].imshow(image, aspect='auto')\n            ax[i, j].set_title(key)\n        i += 1\n    #plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:29.617438Z","iopub.execute_input":"2021-11-15T20:13:29.617632Z","iopub.status.idle":"2021-11-15T20:13:29.627998Z","shell.execute_reply.started":"2021-11-15T20:13:29.617608Z","shell.execute_reply":"2021-11-15T20:13:29.627011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(is_random=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:29.629042Z","iopub.execute_input":"2021-11-15T20:13:29.629625Z","iopub.status.idle":"2021-11-15T20:13:34.708999Z","shell.execute_reply.started":"2021-11-15T20:13:29.629585Z","shell.execute_reply":"2021-11-15T20:13:34.708225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(is_random=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:34.710235Z","iopub.execute_input":"2021-11-15T20:13:34.710447Z","iopub.status.idle":"2021-11-15T20:13:39.861156Z","shell.execute_reply.started":"2021-11-15T20:13:34.710422Z","shell.execute_reply":"2021-11-15T20:13:39.860121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_diseases_repartition(is_train=True):\n    if is_train:\n        path = './base_dir/train_dir'\n    else:\n        path = './base_dir/val_dir'\n    directories = os.listdir(path)\n    \n    total = 0\n    count_dict = {}\n    for x in directories:\n        t_join = os.path.join(path, x)\n        t_listdir = os.listdir(t_join)\n        t_len_listdir = len(t_listdir)\n        total += t_len_listdir\n        count_dict[x] = t_len_listdir\n    \n    count_prop = {}\n    for key, value in count_dict.items():\n        count_prop[key] = round((value / total), 2)\n        \n    return(count_prop)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:39.86301Z","iopub.execute_input":"2021-11-15T20:13:39.863246Z","iopub.status.idle":"2021-11-15T20:13:39.869136Z","shell.execute_reply.started":"2021-11-15T20:13:39.863218Z","shell.execute_reply":"2021-11-15T20:13:39.868096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_diseases_repartition()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:39.870233Z","iopub.execute_input":"2021-11-15T20:13:39.87045Z","iopub.status.idle":"2021-11-15T20:13:39.893886Z","shell.execute_reply.started":"2021-11-15T20:13:39.870422Z","shell.execute_reply":"2021-11-15T20:13:39.893077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rgb2gray(image):\n    return np.dot(image[...,:3], [0.2989, 0.5870, 0.1140])","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:39.89545Z","iopub.execute_input":"2021-11-15T20:13:39.896286Z","iopub.status.idle":"2021-11-15T20:13:39.901453Z","shell.execute_reply.started":"2021-11-15T20:13:39.896198Z","shell.execute_reply":"2021-11-15T20:13:39.900567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images_hist(n=5, is_random=False, is_rgb=True):\n    \"\"\"\n    \"\"\"\n    images_dict = import_images(n, is_random)\n    \n    #plt.figure(figsize=(20,10))\n    \n    columns = n#5\n    lines = len(images_dict.keys())#1\n    coef = 3\n    fig, ax = plt.subplots(lines, columns, figsize=(8 * coef, 6 * coef))\n    \n    if is_rgb:\n        colors = (\"R\", \"G\", \"B\")\n        channels = (0, 1, 2)\n    \n    i = 0\n    for key, values in images_dict.items():\n        for j, image in enumerate(values):\n            if is_rgb:\n                for channel, color in zip(channels, colors):\n                    #subfigs = fig.subfigures(1, 3)\n                    ax[i, j].hist(image[:, :, channel].ravel(), bins=256, range=(0, 256), color=color.lower())\n                    ax[i, j].set_title(key)\n                    ax[i, j].set_xlabel(\"Color Value\")\n                    ax[i, j].set_ylabel(\"Pixels\")\n            else:\n                rgb2gray(image)\n                ax[i, j].hist(image.ravel(), bins=256, range=(0.0, 1.0))\n                ax[i, j].set_xlabel(\"Color Value\")\n                ax[i, j].set_ylabel(\"Pixels\")\n                ax[i, j].set_title(key)        \n        i += 1\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:39.902657Z","iopub.execute_input":"2021-11-15T20:13:39.903554Z","iopub.status.idle":"2021-11-15T20:13:39.912141Z","shell.execute_reply.started":"2021-11-15T20:13:39.903524Z","shell.execute_reply":"2021-11-15T20:13:39.911533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images_hist(n=5, is_random=False, is_rgb=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:13:39.914791Z","iopub.execute_input":"2021-11-15T20:13:39.915031Z","iopub.status.idle":"2021-11-15T20:14:21.569209Z","shell.execute_reply.started":"2021-11-15T20:13:39.915005Z","shell.execute_reply":"2021-11-15T20:14:21.568429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images_hist(n=5, is_random=False, is_rgb=False)\n# true values ?","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:14:21.570689Z","iopub.execute_input":"2021-11-15T20:14:21.571009Z","iopub.status.idle":"2021-11-15T20:14:38.665133Z","shell.execute_reply.started":"2021-11-15T20:14:21.570969Z","shell.execute_reply":"2021-11-15T20:14:38.66457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_stats(n=5, is_random=False):\n    \"\"\"\n    \"\"\"\n    images_dict = import_images(n, is_random)\n    \n    colors = (\"R\", \"G\", \"B\")\n    channels = (0, 1, 2)\n    \n    mean_col_dict = {}\n    \n    for key, values in images_dict.items():\n        R_list = []\n        G_list = []\n        B_list = []\n        for i, value in enumerate(values):\n            for channel, color in zip(channels, colors):\n                if color == \"R\":\n                    R_list.append(np.mean(value[:, :, channel]))\n                elif color == \"G\":\n                    G_list.append(np.mean(value[:, :, channel]))\n                else:\n                    B_list.append(np.mean(value[:, :, channel]))\n        mean_col_dict[key] = (np.mean(R_list), np.mean(G_list), np.mean(B_list))\n    \n    return mean_col_dict","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:14:38.666203Z","iopub.execute_input":"2021-11-15T20:14:38.66653Z","iopub.status.idle":"2021-11-15T20:14:38.673401Z","shell.execute_reply.started":"2021-11-15T20:14:38.666492Z","shell.execute_reply":"2021-11-15T20:14:38.67264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_image_stats(n = 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:14:38.674713Z","iopub.execute_input":"2021-11-15T20:14:38.675528Z","iopub.status.idle":"2021-11-15T20:14:44.426948Z","shell.execute_reply.started":"2021-11-15T20:14:38.675499Z","shell.execute_reply":"2021-11-15T20:14:44.426275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_generators(color_mode=\"rgb\", batch_size=64):\n    \"\"\"\n    \"\"\"\n    train_path = './base_dir/train_dir'\n    val_path = './base_dir/val_dir'\n    #test_path =\n    \n    train_directories = os.listdir(train_path)\n    val_directories = os.listdir(val_path)\n    \n    num_train_samples = sum([len(os.listdir(os.path.join(train_path, x))) for x in train_directories])\n    num_val_samples = sum([len(os.listdir(os.path.join(val_path, x))) for x in val_directories])\n    print(num_train_samples)\n    print(num_val_samples)\n    \n    train_batch_size = batch_size\n    val_batch_size = batch_size\n    \n    train_steps = np.ceil(num_train_samples / train_batch_size)\n    val_steps = np.ceil(num_val_samples / val_batch_size)\n    \n    datagen = ImageDataGenerator(rescale=1.0/255)\n\n    train_gen = datagen.flow_from_directory(train_path,\n                                            target_size=(256,256),\n                                            color_mode=color_mode,#\"grayscale\", #\"rgb\"\n                                            batch_size=train_batch_size,\n                                            class_mode='categorical')\n\n    val_gen = datagen.flow_from_directory(val_path,\n                                            target_size=(256,256),\n                                            color_mode=color_mode,#\"grayscale\", #\"rgb\"\n                                            batch_size=val_batch_size,\n                                            class_mode='categorical')\n    \n    return train_gen, val_gen, train_steps, val_steps\n\ndef plot_history(history, metric=\"loss\"):\n    nb_epochs = range(1, history.params[\"epochs\"] + 1)\n    plt.plot(nb_epochs, history.history[metric], label = metric)\n    plt.plot(nb_epochs, history.history[\"val_\" + metric], label = \"val_\" + metric)\n    plt.legend()\n    \ndef create_model(classification_type = 'softmax', color_mode=\"rgb\", n_blocks=1):\n    \"\"\"\n    \"\"\"\n    #input_shape = (600, 800, 3)\n    #input_shape = (60, 80, 1)\n    if color_mode == \"rgb\":\n        input_shape = (256, 256, 3)\n    else:\n        input_shape = (256, 256, 1)\n    \n    with tf.device('/gpu:0'):\n        model = models.Sequential()\n        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n        model.add(layers.MaxPooling2D((2, 2)))\n        model.add(layers.Dropout(0.5))\n        for i in range(0, n_blocks + 1):\n            model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n            model.add(layers.MaxPooling2D((2, 2)))\n            model.add(layers.Dropout(0.5))\n        model.add(layers.Flatten())\n        model.add(layers.Dropout(0.5))\n        model.add(layers.Dense(32, activation='relu'))\n        model.add(layers.Dense(5, activation=classification_type))\n    \n    model.summary()\n    \n    return model\n\ndef compile_and_fit(model, batch_size=64, epochs=10):\n    \"\"\"\n    \"\"\"\n    #with tf.device('/GPU:0'):\n    train_gen, val_gen, train_steps, val_steps = create_generators(batch_size=batch_size)\n\n    model.compile(\n    loss='categorical_crossentropy',\n    optimizer=optimizers.RMSprop(lr=1e-4),\n    metrics=['acc'])\n\n    #BATCH_SIZE = 16\n    epochs = epochs\n    #creuser ça \n    filepath = \"model.h5\"\n    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                             save_best_only=True, mode='max')\n    reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n    callbacks_list = [checkpoint, reduce_lr]\n    \n    with tf.device('/GPU:0'):\n        history = model.fit(\n            train_gen,\n            steps_per_epoch=train_steps,\n            validation_data=val_gen,\n            validation_steps=val_steps,\n            epochs = epochs,\n            callbacks=callbacks_list)\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:14:44.428331Z","iopub.execute_input":"2021-11-15T20:14:44.428758Z","iopub.status.idle":"2021-11-15T20:14:44.445548Z","shell.execute_reply.started":"2021-11-15T20:14:44.428699Z","shell.execute_reply":"2021-11-15T20:14:44.44478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allocate_data(frac_total=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:14:44.446573Z","iopub.execute_input":"2021-11-15T20:14:44.447168Z","iopub.status.idle":"2021-11-15T20:14:54.272328Z","shell.execute_reply.started":"2021-11-15T20:14:44.447135Z","shell.execute_reply":"2021-11-15T20:14:54.271619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nhistory = compile_and_fit(model)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:14:54.273449Z","iopub.execute_input":"2021-11-15T20:14:54.273863Z","iopub.status.idle":"2021-11-15T20:28:09.635803Z","shell.execute_reply.started":"2021-11-15T20:14:54.273831Z","shell.execute_reply":"2021-11-15T20:28:09.634885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allocate_data(frac_total=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:28:09.637451Z","iopub.execute_input":"2021-11-15T20:28:09.637842Z","iopub.status.idle":"2021-11-15T20:28:59.031593Z","shell.execute_reply.started":"2021-11-15T20:28:09.6378Z","shell.execute_reply":"2021-11-15T20:28:59.030786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nhistory = compile_and_fit(model, batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:28:59.03315Z","iopub.execute_input":"2021-11-15T20:28:59.033855Z","iopub.status.idle":"2021-11-15T21:27:58.846001Z","shell.execute_reply.started":"2021-11-15T20:28:59.03381Z","shell.execute_reply":"2021-11-15T21:27:58.845153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T21:27:58.847595Z","iopub.execute_input":"2021-11-15T21:27:58.848936Z","iopub.status.idle":"2021-11-15T21:27:59.060095Z","shell.execute_reply.started":"2021-11-15T21:27:58.848894Z","shell.execute_reply":"2021-11-15T21:27:59.059474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history, 'acc')","metadata":{"execution":{"iopub.status.busy":"2021-11-15T21:27:59.061342Z","iopub.execute_input":"2021-11-15T21:27:59.061669Z","iopub.status.idle":"2021-11-15T21:27:59.251959Z","shell.execute_reply.started":"2021-11-15T21:27:59.061642Z","shell.execute_reply":"2021-11-15T21:27:59.251129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allocate_data(frac_total=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T21:27:59.253635Z","iopub.execute_input":"2021-11-15T21:27:59.254224Z","iopub.status.idle":"2021-11-15T21:28:15.387439Z","shell.execute_reply.started":"2021-11-15T21:27:59.254177Z","shell.execute_reply":"2021-11-15T21:28:15.386444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(n_blocks=3)\nhistory = compile_and_fit(model, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T21:28:15.389053Z","iopub.execute_input":"2021-11-15T21:28:15.389313Z","iopub.status.idle":"2021-11-15T21:40:17.338097Z","shell.execute_reply.started":"2021-11-15T21:28:15.389281Z","shell.execute_reply":"2021-11-15T21:40:17.337426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T21:40:17.339524Z","iopub.execute_input":"2021-11-15T21:40:17.33989Z","iopub.status.idle":"2021-11-15T21:40:17.506311Z","shell.execute_reply.started":"2021-11-15T21:40:17.339855Z","shell.execute_reply":"2021-11-15T21:40:17.505467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history, \"acc\")","metadata":{"execution":{"iopub.status.busy":"2021-11-15T21:40:17.507781Z","iopub.execute_input":"2021-11-15T21:40:17.508703Z","iopub.status.idle":"2021-11-15T21:40:17.665395Z","shell.execute_reply.started":"2021-11-15T21:40:17.50866Z","shell.execute_reply":"2021-11-15T21:40:17.664815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model(n_blocks=1)\nhistory = compile_and_fit(model, batch_size=128, epochs=30)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T21:40:17.667237Z","iopub.execute_input":"2021-11-15T21:40:17.667806Z","iopub.status.idle":"2021-11-15T22:15:09.362Z","shell.execute_reply.started":"2021-11-15T21:40:17.667761Z","shell.execute_reply":"2021-11-15T22:15:09.361062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T22:15:09.363302Z","iopub.execute_input":"2021-11-15T22:15:09.363516Z","iopub.status.idle":"2021-11-15T22:15:09.544352Z","shell.execute_reply.started":"2021-11-15T22:15:09.36349Z","shell.execute_reply":"2021-11-15T22:15:09.543654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history, \"acc\")","metadata":{"execution":{"iopub.status.busy":"2021-11-15T22:15:09.545824Z","iopub.execute_input":"2021-11-15T22:15:09.5463Z","iopub.status.idle":"2021-11-15T22:15:09.724551Z","shell.execute_reply.started":"2021-11-15T22:15:09.546247Z","shell.execute_reply":"2021-11-15T22:15:09.723754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(classification_type = 'softmax'):\n    \"\"\"\n    \"\"\"\n    \n    base_model = keras.applications.Xception(\n        weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n        input_shape=(256, 256, 3),\n        include_top=False,\n    )\n    base_model.trainable = False # freeze base_model\n    \n    input_shape = (256, 256, 3)\n    inputs = keras.Input(shape=input_shape)\n    layers.Rescaling\n    scale_layer = keras.layers.Rescaling(scale=1./127.5, offset=-1) # [-1, 1]\n    x = scale_layer(inputs)\n    \n    x = base_model(x, training=False)\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    x = keras.layers.Dropout(0.5)(x)  # Regularize with dropout\n    outputs = keras.layers.Dense(5, activation=classification_type)(x)\n    model = keras.Model(inputs, outputs)    \n    model.summary()\n    \n    return model\n\ndef compile_and_fit(model):\n    \"\"\"\n    \"\"\"\n    with tf.device('/GPU:0'):\n        train_gen, val_gen, train_steps, val_steps = create_generators(\"rgb\")\n\n        model.compile(\n        loss='categorical_crossentropy',\n        optimizer=optimizers.RMSprop(lr=1e-4),\n        metrics=['acc'])\n\n        #BATCH_SIZE = 16\n        epochs = 10\n        #creuser ça \n        filepath = \"model.h5\"\n        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n                                 save_best_only=True, mode='max')\n        reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n                                       verbose=1, mode='max', min_lr=0.00001)\n        callbacks_list = [checkpoint, reduce_lr]\n    \n        history = model.fit(\n            train_gen,\n            steps_per_epoch=train_steps,\n            validation_data=val_gen,\n            validation_steps=val_steps,\n            epochs = epochs,\n            callbacks=callbacks_list)\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2021-11-15T22:15:09.725802Z","iopub.execute_input":"2021-11-15T22:15:09.726023Z","iopub.status.idle":"2021-11-15T22:15:09.736667Z","shell.execute_reply.started":"2021-11-15T22:15:09.725995Z","shell.execute_reply":"2021-11-15T22:15:09.73614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nhistory = compile_and_fit(model)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T22:15:09.73762Z","iopub.execute_input":"2021-11-15T22:15:09.738182Z","iopub.status.idle":"2021-11-15T22:47:36.972312Z","shell.execute_reply.started":"2021-11-15T22:15:09.738142Z","shell.execute_reply":"2021-11-15T22:47:36.971371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}