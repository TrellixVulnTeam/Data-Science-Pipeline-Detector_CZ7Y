{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The shortest way to baseline."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport tensorflow as tf\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Version history:\n* Ver. 7 Accuracy 0.748. Time 4559 s. Limit (32400)\n* Ver. 10 Change photo resolution to 224x224 from 150x300. And EfficientNetB3 from EfficientNetB0. Accuracy 0.787. Time 4559 s.\n* Ver. 11 Change photo resolution to 380x380 from 224x224. And EfficientNetB4 from EfficientNetB3. Accuracy 0.786. Time 16816 s.\n* Ver. 12 Change photo resolution to 260x260 from 380x380. And EfficientNetB2 from EfficientNetB4. And add EarlyStopping. Also change learning_rate to 0.0005 from 0.001. Not improving.\n* Ver. 13(14) Add photo rotaiting and change learning_rate to 0.001 from 0.0005. Not improving.\n* Ver. 18 Add class_weight. Quality got worse.\n* Ver. 22. Back to 260x260 and 20 epoch, remove EarlyStopping. Accuracy 0.817. Time 6239 s. New baseline.\n* Ver. 23. Add 2 Dense layer to model. Not improving.\n* Continue working...\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"general_path = '../input/cassava-leaf-disease-classification/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read train data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(general_path + 'train.csv')\ntrain['label'] = train['label'].astype('string')\ntrain.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names_of_disease = pd.read_json(general_path + 'label_num_to_disease_map.json', typ='series')\nnames_of_disease","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pictures"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 12))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    image = Image.open(general_path + 'train_images/' + train.iloc[i]['image_id'])\n    array = np.array(image)\n    plt.imshow(array)\n    label=train.iloc[i]['label']\n    plt.title(f'{names_of_disease[int(label)]}')\nplt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sizes = []\nfor i in range(1, len(train), 250):\n    image = Image.open(general_path + 'train_images/' + train.iloc[i]['image_id'])\n    array = np.array(image)\n    sizes.append(array.shape)\nprint('Picture size', set(sizes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 380, 380","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(validation_split=0.2,\n                             vertical_flip=True,\n                             horizontal_flip=True)\ntrain_datagen_flow = datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=general_path + 'train_images',\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_width, img_height),\n    batch_size=20,\n    subset='training',\n    seed=12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_datagen_flow = datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=general_path + 'train_images',\n    x_col='image_id',\n    y_col='label',\n    target_size=(img_width, img_height),\n    batch_size=20,\n    subset='validation',\n    seed=12345)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adjust class balance."},{"metadata":{"trusted":true},"cell_type":"code","source":"current_balance = train['label'].value_counts(normalize=True)\ncurrent_balance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = {0: (1 - current_balance['0']) / (1 - current_balance.min()),\n                1: (1 - current_balance['1']) / (1 - current_balance.min()),\n                2: (1 - current_balance['2']) / (1 - current_balance.min()),\n                3: (1 - current_balance['3']) / (1 - current_balance.min()),\n                4: (1 - current_balance['4']) / (1 - current_balance.min())}\n\nclass_weight","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implement EarlyStopping "},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\noptimizer = Adam(lr=0.00105)\nbackbone = EfficientNetB4(include_top=False, \n                          weights=None, \n                          pooling='avg')\nmodel.add(backbone)\nmodel.add(Dense(5, activation='softmax'))\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizer, \n              metrics=[\"accuracy\"])\nmodel.fit_generator(train_datagen_flow,\n                    validation_data=valid_datagen_flow, \n                    epochs=50,\n                    class_weight=class_weight,\n                    callbacks=[early_stopping, mc],\n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load best saved after EarlyStopping model"},{"metadata":{"trusted":true},"cell_type":"code","source":"saved_model = load_model('best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=['image_id','label'])\nfor image_name in os.listdir(general_path + 'test_images'):\n    image_path = os.path.join(general_path + 'test_images', image_name)\n    image = tf.keras.preprocessing.image.load_img(image_path)\n    resized_image = image.resize((img_width, img_height))\n    numpied_image = np.expand_dims(resized_image, 0)\n    tensored_image = tf.cast(numpied_image, tf.float32)\n    submission = submission.append(pd.DataFrame({'image_id': image_name,\n                                                 'label': saved_model.predict_classes(tensored_image)}))\n\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}