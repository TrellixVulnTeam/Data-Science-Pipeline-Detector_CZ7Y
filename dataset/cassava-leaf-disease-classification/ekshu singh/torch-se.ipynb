{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install ../input/timm-0-3-2/timm-0.3.2-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn as optim\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics.functional import accuracy\nfrom pytorch_lightning.callbacks import ModelCheckpoint ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset,DataLoader\nfrom torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import timm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn import preprocessing\n# lb = preprocessing.LabelBinarizer()\n# train[[0,1,2,3,4]]= lb.fit_transform(train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class configure:\n\n  epochs=6\n\n#   model_name='resnext50_32x4d'\n\n  model_name = 'seresnext50_32x4d'\n\n  size=500\n\n  batch_size=8\n\n  target_columns = [0,1,2,3,4]\n\n  Train_path = '../input/cassava-leaf-disease-classification/train_images'\n\n  target_size=5\n\n  device=torch.device('cuda')\n\n  num_workers = 4 \n    \n  Test_path =  '../input/cassava-leaf-disease-classification/test_images' \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class datasets(Dataset):\n\n#   def __init__(self,df, mode='Train'):\n#     super(datasets,self).__init__()\n#     self.df = df \n#     self.image_name = df['image_id'].values\n\n#     self.labels = df[configure.target_columns].values\n\n#     self.mode=mode\n\n#     self.train_transformer = transforms.Compose([\n#             transforms.Resize((configure.size,configure.size)),\n#             transforms.RandomHorizontalFlip(0.5),\n#             transforms.RandomVerticalFlip(0.5),\n#             transforms.RandomAffine(0.5),\n#             transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.5),\n#             transforms.ToTensor(),\n#             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n#         ])\n#     self.val_transformer = transforms.Compose([\n#             transforms.Resize((configure.size,configure.size)),\n#             transforms.ToTensor(),\n#             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n#         ])\n    \n#   def __len__(self):\n\n#     return len(self.df)\n\n#   def set_use_cache(self, use_cache):\n#         self.use_cache = use_cache\n\n#   def __getitem__(self,idx):\n#     image_name= self.image_name[idx]\n\n#     image_path= f'{configure.Train_path}/{image_name}'\n\n#     image = cv2.imread(image_path)\n\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n#     image = Image.fromarray(image.astype('uint8'))\n\n#     if self.mode =='Train':\n\n#       image = self.train_transformer(image)\n    \n#     else:\n#       image = self.val_transformer(image)\n\n\n#     label = torch.tensor(self.labels[idx]).float()\n\n#     return image,label    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = timm.create_model(configure.model_name,pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_features = model.fc.in_features\n# model.fc = nn.Linear(n_features, configure.target_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_datset=datasets(train,mode='Train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_loader = torch.utils.data.DataLoader(train_datset,batch_size=20,shuffle=True,num_workers=configure.num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# criterion = nn.BCEWithLogitsLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.001)\n# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tqdm.notebook import tqdm\n# model.train()\n# for epoch in tqdm(range(configure.epochs)):\n\n#   for images,labels in tqdm(train_loader):\n#     images = Variable(images)\n#     labels = Variable(labels)\n#     if torch.cuda.is_available():\n#       images = images.cuda()\n#       labels = labels.cuda()\n#     output = model(images)\n#     labels = labels.type_as(output)\n#     optimizer.zero_grad()\n    \n#     loss = criterion(output,labels)\n    \n#     loss.backward()\n\n#     optimizer.step()\n#   exp_lr_scheduler.step()\n#   print ('Epoch [{}/{}], Loss: {:.4f}'\n#             .format(epoch+1, configure.epochs, loss.item()))\n#   if epoch == 0:\n#     train_loader.dataset.set_use_cache(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.save(model, 'model_pytorch_cassava_starting_to_learn_more.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=torch.load('../input/torch-model/model_pytorch_cassava_starting_to_learn_more.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class testdatasets1(Dataset):\n\n  def __init__(self,df, mode='Train'):\n    super(testdatasets1,self).__init__()\n    self.df = df \n    self.image_name = df['image_id'].values\n\n\n    self.mode=mode\n\n    self.train_transformer = transforms.Compose([\n            transforms.Resize((configure.size,configure.size)),\n            transforms.RandomHorizontalFlip(0.5),\n            transforms.RandomVerticalFlip(0.5),\n            transforms.RandomAffine(0.5),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    self.val_transformer = transforms.Compose([\n            transforms.Resize((configure.size,configure.size)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    \n  def __len__(self):\n\n    return len(self.df)\n\n  def set_use_cache(self, use_cache):\n        self.use_cache = use_cache\n\n  def __getitem__(self,idx):\n    image_name= self.image_name[idx]\n\n    image_path= f'{configure.Test_path}/{image_name}'\n\n    image = cv2.imread(image_path)\n\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    image = Image.fromarray(image.astype('uint8'))\n\n    if self.mode =='Train':\n\n      image = self.train_transformer(image)\n    \n    else:\n      image = self.val_transformer(image)\n\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class testdatasets2(Dataset):\n\n  def __init__(self,df, mode='Train'):\n    super(testdatasets2,self).__init__()\n    self.df = df \n    self.image_name = df['image_id'].values\n\n\n    self.mode=mode\n\n    self.train_transformer = transforms.Compose([\n            transforms.Resize((configure.size,configure.size)),\n            transforms.RandomHorizontalFlip(0.5),\n            transforms.RandomVerticalFlip(0.5),\n            transforms.RandomAffine(0.5),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    self.val_transformer = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(100),\n        transforms.RandomVerticalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n])\n    \n  def __len__(self):\n\n    return len(self.df)\n\n  def set_use_cache(self, use_cache):\n        self.use_cache = use_cache\n\n  def __getitem__(self,idx):\n    image_name= self.image_name[idx]\n\n    image_path= f'{configure.Test_path}/{image_name}'\n\n    image = cv2.imread(image_path)\n\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    image = Image.fromarray(image.astype('uint8'))\n\n    if self.mode =='Train':\n\n      image = self.train_transformer(image)\n    \n    else:\n      image = self.val_transformer(image)\n\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class testdatasets3(Dataset):\n\n  def __init__(self,df, mode='Train'):\n    super(testdatasets3,self).__init__()\n    self.df = df \n    self.image_name = df['image_id'].values\n\n\n    self.mode=mode\n\n    self.train_transformer = transforms.Compose([\n            transforms.Resize((configure.size,configure.size)),\n            transforms.RandomHorizontalFlip(0.5),\n            transforms.RandomVerticalFlip(0.5),\n            transforms.RandomAffine(0.5),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    self.val_transformer = transforms.Compose([\n        transforms.RandomChoice([\n            transforms.RandomRotation((0,0)),\n            transforms.RandomHorizontalFlip(p=1),\n            transforms.RandomVerticalFlip(p=1),\n            transforms.RandomRotation((90,90)),\n            transforms.RandomRotation((180,180)),\n            transforms.RandomRotation((270,270)),\n        ]),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n])\n    \n  def __len__(self):\n\n    return len(self.df)\n\n  def set_use_cache(self, use_cache):\n        self.use_cache = use_cache\n\n  def __getitem__(self,idx):\n    image_name= self.image_name[idx]\n\n    image_path= f'{configure.Test_path}/{image_name}'\n\n    image = cv2.imread(image_path)\n\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    image = Image.fromarray(image.astype('uint8'))\n\n    if self.mode =='Train':\n\n      image = self.train_transformer(image)\n    \n    else:\n      image = self.val_transformer(image)\n\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset1=testdatasets1(test,mode='Val')\ntest_dataset2=testdatasets2(test,mode='Val')\ntest_dataset3=testdatasets3(test,mode='Val')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader1=torch.utils.data.DataLoader(test_dataset1)\ntest_loader2=torch.utils.data.DataLoader(test_dataset2)\ntest_loader3=torch.utils.data.DataLoader(test_dataset3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm \nmodel.eval()\npreds1=[]\nwith torch.no_grad():\n    for images in tqdm(test_loader1):\n        images = Variable(images)\n        if torch.cuda.is_available():\n            images = images.cuda()\n\n        outputs = model(images)\n        out = outputs.sigmoid()\n        preds1.append(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm \nmodel.eval()\npreds2=[]\nwith torch.no_grad():\n    for images in tqdm(test_loader2):\n        images = Variable(images)\n        if torch.cuda.is_available():\n            images = images.cuda()\n\n        outputs = model(images)\n        out = outputs.sigmoid()\n        preds2.append(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm \nmodel.eval()\npreds3=[]\nwith torch.no_grad():\n    for images in tqdm(test_loader3):\n        images = Variable(images)\n        if torch.cuda.is_available():\n            images = images.cuda()\n\n        outputs = model(images)\n        out = outputs.sigmoid()\n        preds3.append(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=[]\nfor i,j,k in zip(preds1,preds2,preds3):\n    a = (i+j+k)/3\n    pred.append(np.argmax(a.cpu().detach().numpy()).item())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['label']=pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}