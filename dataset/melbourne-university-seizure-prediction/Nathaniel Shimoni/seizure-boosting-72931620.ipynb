{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"eabb7760-1050-4117-17c8-46733edd7797"},"source":"Version of ZFTurbo's excellent Seizure Boost script that:  \na) Can actually run on the full data in less than 10% of the time (by virtue of being a notebook)   \nb) Has some experimental additional features added by anokas\nc) Has some experimental additional features added by me :-)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38c95abc-f17b-9a13-5eef-8ac787db25b7"},"outputs":[],"source":"# coding: utf-8\n__author__ = 'ZFTurbo & anokas :)'\n\nimport datetime\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.cross_validation import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom scipy.io import loadmat\nfrom operator import itemgetter\nimport random\nimport os\nimport time\nimport glob\n\nrandom.seed(2016)\nnp.random.seed(2016)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3996800f-0713-428a-509b-6184b7be784d"},"outputs":[],"source":"def create_feature_map(features):\n    outfile = open('xgb.fmap', 'w')\n    for i, feat in enumerate(features):\n        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n    outfile.close()\n\ndef get_importance(gbm, features):\n    create_feature_map(features)\n    importance = gbm.get_fscore(fmap='xgb.fmap')\n    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n    return importance\n\ndef intersect(a, b):\n    return list(set(a) & set(b))\n\n\ndef print_features_importance(imp):\n    for i in range(len(imp)):\n        print(\"# \" + str(imp[i][1]))\n        print('output.remove(\\'' + imp[i][0] + '\\')')\n\ndef create_submission(score, test, prediction):\n    # Make Submission\n    now = datetime.datetime.now()\n    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n    print('Writing submission: ', sub_file)\n    f = open(sub_file, 'w')\n    f.write('File,Class\\n')\n    total = 0\n    for id in test['Id']:\n        patient = id // 100000\n        fid = id % 100000\n        str1 = str(patient) + '_' + str(fid) + '.mat' + ',' + str(prediction[total])\n        str1 += '\\n'\n        total += 1\n        f.write(str1)\n    f.close()\n\ndef get_features(train, test):\n    trainval = list(train.columns.values)\n    testval = list(test.columns.values)\n    output = intersect(trainval, testval)\n    output.remove('Id')\n    # output.remove('file_size')\n    return sorted(output)\n\ndef read_test_train():\n    print(\"Load train.csv...\")\n    train = pd.read_csv(\"simple_train.csv\")\n    print(\"Load test.csv...\")\n    test = pd.read_csv(\"simple_test.csv\")\n    print(\"Process tables...\")\n    features = get_features(train, test)\n    return train, test, features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18dc44ad-5748-92c0-f8fd-61e1c4ddc444"},"outputs":[],"source":"def mat_to_pandas(path):\n    mat = loadmat(path)\n    names = mat['dataStruct'].dtype.names\n    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n    return pd.DataFrame(ndata['data'], columns=ndata['channelIndices'][0])\n\ndef create_training_data():\n    print('Create train.csv...')\n    files = sorted(glob.glob(\"../input/train_*/*.mat\"))\n    out = open(\"simple_train.csv\", \"w\")\n    out.write(\"Id,patient_id\")\n    for i in range(16):\n        out.write(\",avg_\" + str(i))\n        out.write(\",median_\" + str(i))\n        out.write(\",absavg_\" + str(i))\n        out.write(\",stdev_\" + str(i))\n        out.write(\",nonzero_\" + str(i))\n        out.write(\",max_\" + str(i))\n        out.write(\",min_\" + str(i))\n        out.write(\",spread_\" + str(i))\n    out.write(\",file_size,result\\n\")\n    len_files = len(files)\n    i = 0\n    for fl in files:\n        i += 1\n        if i % 100 == 0:\n            print('Read', i, 'of', len_files, '(' + str(round((i / len_files) * 100, 2)) + '%)')\n        id_str = os.path.basename(fl)[:-4]\n        arr = id_str.split(\"_\")\n        patient = int(arr[0])\n        id = int(arr[1])\n        result = int(arr[2])\n        new_id = patient*100000 + id\n        try:\n            tables = mat_to_pandas(fl)\n        except:\n            continue\n        out.write(str(new_id))\n        out.write(\",\" + str(patient))\n        for f in sorted(list(tables.columns.values)):\n            mean1 = tables[f].mean()\n            median1 = np.median(tables[f])\n            absmea1 = np.mean(np.abs(tables[f]))\n            stdev1 = np.std(tables[f])\n            count_nonzero1 = np.count_nonzero(tables[f])\n            max1 = np.max(tables[f])\n            min1 = np.min(tables[f])\n            spread1 = max1-min1\n            out.write(\",\" + str(mean1))\n            out.write(\",\" + str(median1))\n            out.write(\",\" + str(absmean1))\n            out.write(\",\" + str(stdev1))\n            out.write(\",\" + str(count_nonzero1))\n            out.write(\",\" + str(max1))\n            out.write(\",\" + str(min1))\n            out.write(\",\" + str(spread1))\n        out.write(\",\" + str(os.path.getsize(fl)))\n        out.write(\",\" + str(result) + \"\\n\")\n        # break\n    out.close()\n    \ndef create_testing_data():\n    print('Create test.csv...')\n    files = sorted(glob.glob(\"../input/test_*/*.mat\"))\n    out = open(\"simple_test.csv\", \"w\")\n    out.write(\"Id,patient_id\")\n    for i in range(16):\n        out.write(\",avg_\" + str(i))\n        out.write(\",median_\" + str(i))\n        out.write(\",absavg_\" + str(i))\n        out.write(\",stdev_\" + str(i))\n        out.write(\",nonzero_\" + str(i))\n        out.write(\",max_\" + str(i))\n        out.write(\",min_\" + str(i))\n        out.write(\",spread_\" + str(i))\n    out.write(\",file_size\\n\")\n    len_files = len(files)\n    i = 0\n    for fl in files:\n        i += 1\n        if i % 100 == 0:\n            print('Read', i, 'of', len_files, '(' + str(round((i / len_files) * 100, 2)) + '%)')\n        id_str = os.path.basename(fl)[:-4]\n        arr = id_str.split(\"_\")\n        patient = int(arr[0])\n        id = int(arr[1])\n        new_id = patient*100000 + id\n        try:\n            tables = mat_to_pandas(fl)\n        except:\n            continue\n        out.write(str(new_id))\n        out.write(\",\" + str(patient))\n        for f in sorted(list(tables.columns.values)):\n            mean1 = tables[f].mean()\n            median1 = np.median(tables[f])\n            absmea1 = np.mean(np.abs(tables[f]))\n            stdev1 = np.std(tables[f])\n            count_nonzero1 = np.count_nonzero(tables[f])\n            max1 = np.max(tables[f])\n            min1 = np.min(tables[f])\n            spread1 = max1-min1\n            out.write(\",\" + str(mean1))\n            out.write(\",\" + str(median1))\n            out.write(\",\" + str(absmean1))\n            out.write(\",\" + str(stdev1))\n            out.write(\",\" + str(count_nonzero1))\n            out.write(\",\" + str(max1))\n            out.write(\",\" + str(min1))\n            out.write(\",\" + str(spread1))\n            out.write(\",\" + str(os.path.getsize(fl)))\n        out.write(\"\\n\")\n        # break\n    out.close()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91efd1ea-882f-9eb5-cf90-6bb804660985"},"outputs":[],"source":"create_training_data()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9ccc3aa-b947-6762-ae78-9b1be34a7b8c"},"outputs":[],"source":"create_testing_data()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"147846fa-eb34-5185-0cc1-8280d13061e7"},"outputs":[],"source":"def run_single(train, test, features, target, random_state=1):\n    eta = 0.02\n    max_depth = 5\n    subsample = 0.9\n    colsample_bytree = 0.9\n    start_time = time.time()\n\n    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n    params = {\n        \"objective\": \"binary:logistic\",\n        \"booster\" : \"gbtree\",\n        \"eval_metric\": \"auc\",\n        \"eta\": eta,\n        \"tree_method\": 'exact',\n        \"max_depth\": max_depth,\n        \"subsample\": subsample,\n        \"colsample_bytree\": colsample_bytree,\n        \"silent\": 1,\n        \"seed\": random_state,\n    }\n    num_boost_round = 1000\n    early_stopping_rounds = 50\n    test_size = 0.2\n\n    kf = KFold(len(train.index), n_folds=int(round(1/test_size, 0)), shuffle=True, random_state=random_state)\n    train_index, test_index = list(kf)[0]\n    print('Length of train: {}'.format(len(train_index)))\n    print('Length of valid: {}'.format(len(test_index)))\n\n    X_train, X_valid = train[features].as_matrix()[train_index], train[features].as_matrix()[test_index]\n    y_train, y_valid = train[target].as_matrix()[train_index], train[target].as_matrix()[test_index]\n\n    print('Length train:', len(X_train))\n    print('Length valid:', len(X_valid))\n\n    dtrain = xgb.DMatrix(X_train, y_train)\n    dvalid = xgb.DMatrix(X_valid, y_valid)\n\n    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist,\n                    early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n\n    print(\"Validating...\")\n    check = gbm.predict(xgb.DMatrix(X_valid), ntree_limit=gbm.best_iteration+1)\n    score = roc_auc_score(y_valid, check)\n    print('Check error value: {:.6f}'.format(score))\n\n    imp = get_importance(gbm, features)\n    print('Importance array: ', imp)\n\n    print(\"Predict test set...\")\n    test_prediction = gbm.predict(xgb.DMatrix(test[features].as_matrix()), ntree_limit=gbm.best_iteration+1)\n\n    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n    return test_prediction.tolist(), score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a2c3369-dd59-f662-2ef0-879d4b99f7e5"},"outputs":[],"source":"train, test, features = read_test_train()\nprint('Length of train: ', len(train))\nprint('Length of test: ', len(test))\nprint('Features [{}]: {}'.format(len(features), sorted(features)))\ntest_prediction, score = run_single(train, test, features, 'result')\ncreate_submission(score, test, test_prediction)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31e55d86-a3ff-f328-621f-2763942eea76"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}