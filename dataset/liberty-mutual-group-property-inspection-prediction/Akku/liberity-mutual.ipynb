{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport\nfrom sklearn import preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/liberty-mutual-group-property-inspection-prediction/train.csv.zip\")\n#categorical cols\ncols = df.columns\nnum_cols = df._get_numeric_data().columns\ncate = list(set(cols) - set(num_cols) - set([\"T1_V17\",\"T2_V3\",\"T2_V11\",\"T2_V12\"]))\n\n#striping the values\ncate_cols=[]\nfor X in cate:\n    cate_cols.append(X.strip(\"''\"))\ncate_cols\n\ntemp_df =df\n\n#encoding boolean cols\nfor X in [\"T1_V17\",\"T2_V3\",\"T2_V11\",\"T2_V12\"]:\n    le = preprocessing.LabelEncoder()\n    temp_df[X] = le.fit_transform(temp_df[X])\ntemp_df\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\ncorr = temp_df.drop(\"Hazard\",axis=1).corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values , annot=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(y=temp_df[\"Hazard\"] , x =temp_df[\"T1_V2\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(80,60))\nsns.barplot(y=temp_df[\"Hazard\"] , x =temp_df[\"T2_V1\"] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df = temp_df.drop([\"T1_V17\"],axis=1)\ntemp_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dummyfying the categorical cols\nfor X in cate_cols:\n    temp_df= pd.concat([temp_df,pd.get_dummies(df[X],prefix=[X], drop_first = True  )], axis = 1)\n    temp_df = temp_df.drop([X] , axis =1 )\ntemp_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(80,60))\ncorr = temp_df.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values , annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = temp_df[\"Hazard\"]\ntemp_df = temp_df.drop([\"Id\"],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(temp_df, y, test_size=0.25, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train ,y_train)\nimportance = lr.coef_\np_out = lr.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nprint('Mean squared error: %.2f'\n      % mean_squared_error(y_test, p_out,squared = False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize feature importance\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train ,y_train)\np_out = lr.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nprint('Mean squared error: %.2f'\n      % mean_squared_error(y_test, p_out,squared = False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_le = VotingRegressor(estimators = [('lin_r',lin_r_le),('xgb',xgb_le)])\nensemble_le.fit(X_train,y_train)\npred_ensemble_le = ensemble_le.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/submission/Submission.csv\")\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"./SubFile.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Analysis**\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport\nfrom sklearn import preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Label encoding done on \"T1_V17\",\"T2_V3\",\"T2_V11\",\"T2_V12\" and dropped T1_V17\ndf = pd.read_csv(\"../input/liberty-mutual-group-property-inspection-prediction/train.csv.zip\")\n#categorical cols\ncols = df.columns\nnum_cols = df._get_numeric_data().columns\ncate = list(set(cols) - set(num_cols) - set([\"T1_V17\",\"T2_V3\",\"T2_V11\",\"T2_V12\"]))\n\n#striping the values\ncate_cols=[]\nfor X in cate:\n    cate_cols.append(X.strip(\"''\"))\ncate_cols\n\ntemp_df =df\n\n#encoding boolean cols\nfor X in [\"T1_V17\",\"T2_V3\",\"T2_V11\",\"T2_V12\"]:\n    le = preprocessing.LabelEncoder()\n    temp_df[X] = le.fit_transform(temp_df[X])\ntemp_df = temp_df.drop([\"T1_V17\"] , axis =1)\ntemp_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols = list(num_cols)\nnum_cols.remove('Id')\nnum_cols.remove('Hazard')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(data=temp_df , x =\"T1_V1\",y=\"Hazard\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(data=temp_df , x =\"T1_V2\",y=\"Hazard\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nsns.lineplot(data=temp_df , x =\"T1_V2\",y=\"T1_V1\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nsns.lineplot(data=temp_df , x =\"T1_V1\",y=\"Hazard\",hue=\"T1_V4\" , sort= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fig, axs = plt.subplots(ncols=2)\nsns.lineplot(data=temp_df , x =\"T1_V3\",y=\"Hazard\" )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for X in cate_cols:\n    print(temp_df[X].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for X in cate_cols:\n    sns.catplot(data=temp_df , x = X , y =\"Hazard\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **hazard is <=25**\n# 1. T1v11 --> M,A,F,N(mostly),D,K(mostly)\n# 2. T1v4  --> H,E(mostly),C,S,G\n# 3. T2v5  --> D,E,F(very less data points)\n# 4. T2v13 --> B\n# 5. t1v15 --> D,H,N,S,W,F\n# 6. t1v16 --> D,C,F,H,A,Q,G,L,P\n# 7. t1v5  --> D,J,  (E,L) have low density\n","metadata":{}},{"cell_type":"code","source":"print((cate_cols))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lot of outliers\nfor X in cate_cols:\n    sns.catplot(data=temp_df , x = X , y =\"Hazard\" , kind = \"box\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for X in num_cols:\n    sns.catplot(data=temp_df , x = X , y=\"Hazard\" , kind= \"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Hazard increase +ve or decreases -ve**\n# 1. t1v1 +ve\n# 2. t1v2 +ve\n# 3. t1v3 , t2v14 ,t2v15 +ve\n# 4. t1v14,t2v1 , t2v9-ve","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,5))\nfor X in num_cols:\n    sns.displot(temp_df[X] ,kde = True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df.hist(figsize=(15,30),layout=(6,4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# T1V5 to T1V9 Analysis","metadata":{}},{"cell_type":"code","source":"import plotly.express as px","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(df, x=\"T1_V1\", y=\"Hazard\", color=\"T1_V12\", barmode = 'stack')\n \nfig.show()#","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(df, x=\"T1_V2\", y=\"Hazard\", color=\"T1_V5\", barmode = 'stack')#why is hazard showing in thousands\n \nfig.show()#","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*When T1v12 is B then 90% of times Hazard =1*","metadata":{}},{"cell_type":"code","source":"fig = px.bar(df, x=\"T1_V10\", y=\"Hazard\", color=\"T1_V5\", barmode = 'stack')\n \nfig.show()#","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some Observations","metadata":{}},{"cell_type":"markdown","source":"T1v5 is L (5 values/59000) –haz(1,3,7,8)\n1.\tt1v7,t1v8,t1v12 are B\n2.\tt1v15,t2_v5 is A\n3.\tt1v17  , t2_v3 ,t2_v12 is N\n4.\tt1v9 D\n5.\tt2_v3 is E\n6.\tt2v8 1\n\n\nt1v5 is E (5 values/59000)—haz(2,4,7,14)\n1.\tt1v7 ,t1v8 , t1v12 are B\n2.\tt1v15    is A\n3.\tt1v9 is D\n4.\tt1v17,t2v12 Is N\n5.\tt2v11 is Y\n6.\tt2v8 is 1\n\n\nt1v5 is D (149)—haz(1-20)\n1.\tt1v7 is 98% ,t1v8 ,t1v12 is 80% B\n2.\tt1v9 is 80+% D\n3.\tt1v15 is 75% A\n4.\tt1v17 , t2v12 is 80% N\n5.\tt2v8 is 99% 1\n6.\tt2v11 is 80% Y\n\n\nt1v5 is J (188)—haz(1-20)\n1.\tt1v7 is 98% ,t1v8 ,t1v12 is 80% B\n2.\tt1v9 is 87+%  E\n3.\tt1v15 is 90% , t2v5 100% A\n4.\tt1v17 is 98%  , t2v12 is 80% N\n5.\tt2v8 is 99% 1\n6.\tt2v11 is 77% Y\n\n\nt1v5 is B (3335)—99% haz(1-25)\n1.\tt1v7 is 98% ,t1v8 ,t1v12 is 90% B\n2.\tt1v9 is 90% D\n3.\tt1v15 is 75% A\n4.\tt1v17 , t2v12 is 80% N\n5.\tt2v8 is 98% 1\n6.\tt2v11 is 66% Y\n\n\nt1v5 is I (4297)—99% haz(1-25)\n1.\tt1v7 is 95% ,t1v8 ,t1v12 is 90% B\n2.\tt1v9 is 90% E\n3.\tt1v15 is 92% , t2v5 100%  A\n4.\tt1v17  is 76, t2v12 is 80% N\n5.\tt2v8 is 98% 1\n6.\tt2v11 is 78% Y\n\n\nt1v5 is C (7845)—99% haz(1-25)\n1.\tt1v7 is 95% ,t1v8 ,t1v12 is 90% B\n2.\tt1v9 is 90% D\n3.\tt1v15 is 92% , t2v5 61%  A\n4.\tt1v17  is 80%, t2v12 is 80% N\n5.\tt2v8 is 98% 1\n6.\tt2v11 is 75% Y\n\n\nt1v5 is H(10137)—99%-->haz(1-25)\n1.\tt1v7 is 94% ,t1v8 ,t1v12 is 90% B\n2.\tt1v9 is  D 39% and E is 48%\n3.\tt1v15 is 90% A\n4.\tt1v17  is 90%, t2v12 is 91% N\n5.\tt2v8 is 98% 1\n6.\tt2v11 is 57% Y\n\n\nt1v5 is A(10900)—99%-->haz(1-25)\n1.\tt1v7 is 94% ,t1v8 ,t1v12 ,t1v11(85) is 90% B\n2.\tt1v9 is  D 86% and E is 48%\n3.\tt1v15 is 86 % , t2v5 68% A\n4.\tt1v17  is 80%, t2v12 is 80% N\n5.\tt2v8 is 98% 1\n6.\tt2v11 is 76% Y\n\n\nt1v5 is K(14138)—99%-->haz(1-25)\n1.\tt1v7 is 94% ,t1v8 ,t1v12 is 90% B\n2.\tt1v9 is  E 90% \n3.\tt1v15 is 90 % , t2v5 90% A\n4.\tt1v17  is 74%, t2v12 is 75% N\n5.\tt2v8 is 98% 1\n6.\tt2v11 is 76% Y\n","metadata":{}},{"cell_type":"markdown","source":"# Common Trend for Hazard (1-25)\n\n* T1v7\tT1v8\tT1v12 - B\n* T1v15 - A\n* T1v17\tT2v12 –  N\n* T2v8 - 1\n* T1v9 – D,E\n* T2v11 - Y\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}