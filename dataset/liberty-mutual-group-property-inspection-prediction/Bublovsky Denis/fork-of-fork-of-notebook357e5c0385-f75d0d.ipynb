{"cells":[{"outputs":[],"source":"import pandas as pd\nimport numpy as np \nfrom sklearn import preprocessing\nimport xgboost as xgb\nfrom sklearn.feature_extraction import DictVectorizer\n\ndef xgboost_prediction(train,labels,test):\n    params = {}\n    params[\"objective\"] = \"reg:linear\"\n    params[\"eta\"] = 0.01\n    params[\"min_child_weight\"] = 100\n    params[\"subsample\"] = 0.6\n    params[\"colsample_bytree\"] = 0.7\n    params[\"scale_pos_weight\"] = 1.0\n    params[\"silent\"] = 1\n    params[\"max_depth\"] = 9\n    \n    paramslist = list(params.items())\n    \n    offset = 4000\n\n    num_rounds = 10000\n    xgb_test = xgb.DMatrix(test)\n \n    xgb_train = xgb.DMatrix(train[offset:,:], label=labels[offset:])\n    xgb_value = xgb.DMatrix(train[:offset,:], label=labels[:offset])\n    \n    listforprint = [(xgb_train, 'train'),(xgb_value, 'value')]\n    model = xgb.train(paramslist, xgb_train, num_rounds, listforprint, early_stopping_rounds=120)\n    prediction1 = model.predict(xgb_test,ntree_limit=model.best_iteration)\n\n    train = train[::-1,:]\n    labels = np.log(labels[::-1])\n\n    xgb_train = xgb.DMatrix(train[offset:,:], label=labels[offset:])\n    xgb_value = xgb.DMatrix(train[:offset,:], label=labels[:offset])\n\n    listforprint = [(xgb_train, 'train'),(xgb_value, 'value')]\n    model = xgb.train(paramslist, xgb_train, num_rounds, listforprint, early_stopping_rounds=120)\n    prediction2 = model.predict(xgb_test,ntree_limit=model.best_iteration)\n\n    prediction = (prediction1)*1.4 + (prediction2)*8.6\n    return prediction\n\ntrain  = pd.read_csv('../input/train.csv', index_col=0)\ntest  = pd.read_csv('../input/test.csv', index_col=0)\n\nlabels = train.Hazard\ntrain.drop('Hazard', axis=1, inplace=True)\n\ntrain_temp = train\ntest_temp = test\n\ntrain_temp.drop('T2_V10', axis=1, inplace=True)\ntrain_temp.drop('T2_V7', axis=1, inplace=True)\ntrain_temp.drop('T1_V13', axis=1, inplace=True)\ntrain_temp.drop('T1_V10', axis=1, inplace=True)\n\ntest_temp.drop('T2_V10', axis=1, inplace=True)\ntest_temp.drop('T2_V7', axis=1, inplace=True)\ntest_temp.drop('T1_V13', axis=1, inplace=True)\ntest_temp.drop('T1_V10', axis=1, inplace=True)\n\ncolumns = train.columns\ntest_index = test.index\n\ntrain_temp = np.array(train_temp)\ntest_temp = np.array(test_temp)\n\nfor i in range(train_temp.shape[1]):\n    le = preprocessing.LabelEncoder()\n    le.fit(list(train_temp[:,i]) + list(test_temp[:,i]))\n    train_temp[:,i] = le.transform(train_temp[:,i])\n    test_temp[:,i] = le.transform(test_temp[:,i])\n\ntrain_temp = train_temp.astype(float)\ntest_temp = test_temp.astype(float)\n\nprediction1 = xgboost_prediction(train_temp,labels,test_temp)\n\n#model_2 building\n\ntrain = train.T.to_dict().values()\ntest = test.T.to_dict().values()\n\nvec = DictVectorizer()\ntrain = vec.fit_transform(train)\ntest = vec.transform(test)\n\nprediction2 = xgboost_prediction(train,labels,test)\n\nprediction = prediction1 + prediction2\n\nprediction = pd.DataFrame({\"Id\": test_index, \"Hazard\": prediction})\nprediction = prediction.set_index('Id')\nprediction.to_csv('result.csv')","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"ee1e1e12-6a3b-44cb-92f3-4f6ef71bed64","_uuid":"18a3323d09a75c73c299eaecb50f44b82285ec77"}}],"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","file_extension":".py","version":"3.6.4","mimetype":"text/x-python","pygments_lexer":"ipython3","nbconvert_exporter":"python"}},"nbformat_minor":1}