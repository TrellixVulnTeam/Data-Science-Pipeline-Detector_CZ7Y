{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install torch-geometric\n!pip install networkx\n!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nfrom torch_geometric.data import Data, DataLoader\nimport torch_geometric.nn as gnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file = open(\"/kaggle/input/stanford-covid-vaccine/train.json\", \"r\")\ntrain_data_raw = train_file.read()\ntrain_data = list(map(lambda l: json.loads(l), list(filter(lambda l: len(l) > 0, train_data_raw.split(\"\\n\")))))\ntrain_file.close()\n\ntest_file = open(\"/kaggle/input/stanford-covid-vaccine/test.json\", \"r\")\ntest_data_raw = test_file.read()\ntest_data = list(map(lambda l: json.loads(l), list(filter(lambda l: len(l) > 0, test_data_raw.split(\"\\n\")))))\ntest_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[0].keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[0][\"sequence\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[0][\"structure\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[0][\"predicted_loop_type\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[0][\"id\"], len(train_data[0][\"sequence\"]), len(train_data[0][\"structure\"]), len(train_data[0][\"predicted_loop_type\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_sequence = list(zip(train_data[0][\"sequence\"], train_data[0][\"structure\"], train_data[0][\"predicted_loop_type\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(input_sequence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_sequence[0], input_sequence[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[0][\"reactivity\"][0], train_data[0][\"deg_Mg_pH10\"][0], train_data[0][\"deg_pH10\"][0], train_data[0][\"deg_Mg_50C\"][0], train_data[0][\"deg_50C\"][0] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_sequence = list(zip(train_data[0][\"reactivity\"], train_data[0][\"deg_Mg_pH10\"], train_data[0][\"deg_pH10\"], train_data[0][\"deg_Mg_50C\"], train_data[0][\"deg_50C\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation_length = train_data[0][\"seq_scored\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_sequence[0], output_sequence[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_categorical_encoder(input_attribute_index_or_key, categories, total_dimensions, start_index, end_index):\n    if not (end_index - start_index + 1 == len(categories)):\n        raise Exception(\"Mismatch between number of categories and dimensions assigned.\")\n    def encoder(data_row, data_vector):\n        if len(data_vector) != total_dimensions:\n            raise Exception(f\"Data vector is of size {len(data_vector)}, but should be of size {total_dimensions}.\")\n        \n        category_index = categories.index(data_row[input_attribute_index_or_key])\n        encoding_index = start_index + category_index\n        data_vector[encoding_index] = 1\n    \n    return encoder\n\ndef build_continuous_encoder(input_attribute_index_or_key, total_dimensions, attribute_index):\n    def encoder(data_row, data_vector):\n        if len(data_vector) != total_dimensions:\n            raise Exception(f\"Data vector is of size {len(data_vector)}, but should be of size {total_dimensions}.\")\n        data_vector[attribute_index] = float(data_row[input_attribute_index_or_key])\n    \n    return encoder\n\ndef encode_data(rows, encoders, total_dimensions):\n    encoded_rows = []\n    for row in rows:\n        encoded_row = [0] * total_dimensions\n        for encoder in encoders:\n            encoder(row, encoded_row)\n        encoded_rows.append(encoded_row)\n    \n    return encoded_rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_dim_input = 11\ntotal_dim_output = 5\nsequence_classes = [\"A\", \"G\", \"U\", \"C\"]\nstructure_classes = [\"(\", \".\", \")\"]\npredicted_loop_type_classes = [\"S\", \"M\", \"I\", \"B\", \"H\", \"E\", \"X\"]\n\nsequence_encoder = build_categorical_encoder(0, sequence_classes, total_dim_input, 0, 3)\npredicted_loop_encoder = build_categorical_encoder(2, predicted_loop_type_classes, total_dim_input, 4, 10)\n\n\ndata_encoders = [\n    sequence_encoder,\n    predicted_loop_encoder\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_input_sequence = encode_data(input_sequence, data_encoders, total_dim_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_sequence[5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_input_sequence[5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_rna_graph_structure(input_sequence, target=None, target_errors=None):\n    encoded_input_sequence = torch.tensor(\n        encode_data(input_sequence, data_encoders, total_dim_input),\n        dtype=torch.float32)\n    edges = []\n    node_features = []\n    G = nx.Graph()\n    stack = []\n    prev_id = None\n    for (node_id, (base, structure_class, predicted_loop_type)) in enumerate(input_sequence):\n        G.add_node(node_id, base=base, predicted_loop_type=predicted_loop_type)\n        if structure_class == \"(\":\n            stack.append(node_id)\n        elif structure_class == \")\":\n            neighbour_id = stack.pop()\n            G.add_edge(node_id, neighbour_id)\n            edges.append([node_id, neighbour_id])\n            edges.append([neighbour_id, node_id])\n        \n        if prev_id is not None:\n            G.add_edge(node_id, prev_id)\n            edges.append([node_id, prev_id])\n            edges.append([prev_id, node_id])\n\n        prev_id = node_id\n    \n    edge_index = torch.transpose(torch.tensor(edges, dtype=torch.long), 0, 1)\n    \n    if target is not None and target_errors is not None:\n        weights = []\n        for error_row in target_errors:\n            weights_row = []\n            for error in error_row:\n                weights_row.append(1/(error + 1))\n            weights.append(weights_row)\n        target = torch.tensor(target, dtype=torch.float32)\n        weights = torch.tensor(weights, dtype=torch.float32)\n        graph_data = Data(x=encoded_input_sequence, edge_index=edge_index, y=target, weights=weights)\n    elif target is not None:\n        target = torch.tensor(target, dtype=torch.float32)\n        graph_data = Data(x=encoded_input_sequence, edge_index=edge_index, y=target)\n    else:\n        graph_data = Data(x=encoded_input_sequence, edge_index=edge_index)\n    \n    return G, graph_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G, graph_data = build_rna_graph_structure(input_sequence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nx.draw(G, node_size=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G.nodes[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_train_data = list(filter(lambda d: d[\"SN_filter\"] == 1, train_data))\nsn = list(map(lambda r: r[\"SN_filter\"], train_data))\n\ngraphs_train = []\ndataset = []\nfor row in filtered_train_data:\n    input_sequence = list(zip(row[\"sequence\"], row[\"structure\"], row[\"predicted_loop_type\"]))\n    target_sequence = list(zip(row[\"reactivity\"], row[\"deg_Mg_pH10\"], row[\"deg_pH10\"], row[\"deg_Mg_50C\"], row[\"deg_50C\"]))\n    target_sequence_errors = list(zip(row[\"reactivity_error\"], row[\"deg_error_Mg_pH10\"], row[\"deg_error_pH10\"], row[\"deg_error_Mg_50C\"], row[\"deg_error_50C\"]))\n    # target_sequence = list(zip(row[\"reactivity\"], row[\"deg_Mg_pH10\"], row[\"deg_Mg_50C\"]))\n    # target_sequence_errors = list(zip(row[\"reactivity_error\"], row[\"deg_error_Mg_pH10\"], row[\"deg_error_Mg_50C\"]))\n    G, graph_data = build_rna_graph_structure(input_sequence, target=target_sequence, target_errors=target_sequence_errors)\n    dataset.append(graph_data)\n    graphs_train.append(G)\n\n\ngraphs_test = []\ntesting_set = []\ntesting_sequence_id_to_dataset_map = dict()\nfor row in test_data:\n    input_sequence = list(zip(row[\"sequence\"], row[\"structure\"], row[\"predicted_loop_type\"]))\n    G, graph_data = build_rna_graph_structure(input_sequence)\n    testing_set.append(graph_data)\n    graphs_test.append(G)\n    testing_sequence_id_to_dataset_map[row[\"id\"]] = graph_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.shuffle(dataset)\n\ntraining = dataset[:int(len(dataset) * 0.8)]\nevaluation = dataset[int(len(dataset) * 0.8):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(training), len(evaluation), len(testing_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size_train = 31\nbatch_size_test = 318\nbatch_size_submission = 158\nnumber_of_epochs = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(training, batch_size=batch_size_train)\ntest_loader = DataLoader(evaluation, batch_size=batch_size_test)\nsubmission_loader = DataLoader(testing_set, batch_size=batch_size_submission)\ntest_batches = list(test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_batch = test_batches[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RNAGenConv(nn.Module):\n    \n    def __init__(self, node_features_dim=None, node_embedding_dim=None, node_output_features_dim=None):\n        super(RNAGenConv, self).__init__()\n        \n        self.conv_layer = gnn.GENConv(in_channels=node_features_dim, out_channels=node_embedding_dim)\n        self.dropout = nn.Dropout(p=0.1)\n        self.linear1 = nn.Linear(node_embedding_dim, node_embedding_dim + 5)\n        self.linear2 = nn.Linear(node_embedding_dim + 5, node_output_features_dim)\n    \n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv_layer(x, edge_index)\n        x = self.dropout(x)\n        x = F.relu(x)\n        x = self.linear1(x)\n        x = F.relu(x)\n        x = self.linear2(x)\n        x = F.relu(x)\n        \n        return x\n\n\nclass DeepRNAGenConv(nn.Module):\n    \n    def __init__(self, node_features_dim=None, node_embedding_dim=None, num_layers=None, node_output_features_dim=None, convolution_dropout=0.1, dense_dropout=0.0):\n        super(DeepRNAGenConv, self).__init__()\n        \n        self.node_encoder = nn.Linear(node_features_dim, node_embedding_dim)\n        \n        self.gcn_layers = nn.ModuleList()\n        for i in range(num_layers):\n            convolution = gnn.GENConv(in_channels=node_embedding_dim, out_channels=node_embedding_dim)\n            norm = nn.LayerNorm(node_embedding_dim)\n            activation = nn.ReLU()\n            layer = gnn.DeepGCNLayer(conv=convolution, norm=norm, act=activation, dropout=convolution_dropout)\n            self.gcn_layers.append(layer)\n\n        self.dropout = nn.Dropout(p=dense_dropout)\n        self.decoder = nn.Linear(node_embedding_dim, node_output_features_dim)\n    \n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = self.node_encoder(x)\n        for layer in self.gcn_layers:\n            x = layer(x, edge_index)\n        \n        x = self.dropout(x)\n        x = self.decoder(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weighted_mse_loss(output, target, weights=None):\n    if weights is not None:\n        weighted_sum_errors = weights * ((output - target)**2)\n        mean_weighted_sum_errors = weighted_sum_errors.mean()\n        return mean_weighted_sum_errors\n    else:\n        return F.mse_loss(output, target)\n\ndef unweighted_mse_loss(output, target, **kwargs):\n    return F.mse_loss(output, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_loss(batch_input, batch_output, batch_size, loss_function=None, eval_length=None):\n    total_loss = torch.tensor(0.0).to(\"cuda\")\n    for i in range(batch_size):\n        graph_output = batch_output[batch_input.batch == i]\n        target = batch_input.y[(i * eval_length):((i + 1) * eval_length), :].to(\"cuda\")\n        weights = batch_input.weights[(i * eval_length):((i + 1) * eval_length), :].to(\"cuda\")\n        evaluation_nodes = target.size(0)\n        graph_output_evaluation = graph_output[:evaluation_nodes, :]\n        total_loss += loss_function(graph_output_evaluation, target, weights=weights)\n    \n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rna_gcnn = DeepRNAGenConv(\n    node_features_dim=total_dim_input,\n    node_embedding_dim=90,\n    num_layers=10,\n    node_output_features_dim=5,\n    convolution_dropout=0.2,\n    dense_dropout=0.0).cuda()\n\noptimizer = optim.Adam(rna_gcnn.parameters(), lr=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_counter = list(range(len(train_loader) * number_of_epochs))\ntrain_losses = []\ntest_losses = []\ntest_counter = [i * len(train_loader) for i in range(number_of_epochs)]\nfor n in range(number_of_epochs):\n    for batch_input in train_loader:\n        rna_gcnn.zero_grad()\n        batch_output = rna_gcnn(batch_input.to(\"cuda\"))\n        loss = batch_loss(batch_input, batch_output, batch_size_train, loss_function=unweighted_mse_loss, eval_length=evaluation_length) / batch_size_train\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        rna_gcnn.zero_grad()\n        train_losses.append(torch.sqrt(loss).item())\n    with torch.no_grad():\n        batch_output_test = rna_gcnn(test_batch.to(\"cuda\"))\n        test_loss = batch_loss(test_batch, batch_output_test, batch_size_test, loss_function=unweighted_mse_loss, eval_length=evaluation_length) / batch_size_test\n        test_losses.append(torch.sqrt(test_loss).item())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(train_counter, train_losses, color=\"b\", label=\"Train Loss\")\nax.scatter(test_counter, test_losses, color=\"red\", label=\"Test Loss\")\nleg = ax.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min(train_losses), min(test_losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rna_gcnn.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_file = open(\"/kaggle/input/stanford-covid-vaccine/sample_submission.csv\", \"r\")\nsample_submission_data = sample_submission_file.read()\nsample_submission_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_lines = list(filter(lambda l: len(l) > 0, map(lambda ll: ll.strip(), sample_submission_data.split(\"\\n\"))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_lines[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_lines[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_sequence_id_to_dataset_map[\"id_00073f8be\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_header = 'id_seqpos,reactivity,deg_Mg_pH10,deg_pH10,deg_Mg_50C,deg_50C'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_lines = [output_header]\nfor sequence_id, graph_dataset in testing_sequence_id_to_dataset_map.items():\n    output = rna_gcnn(graph_dataset.to(\"cuda\"))\n    output = output.to(\"cpu\")\n    seq_length = output.size(0)\n    for i in range(seq_length):\n        seq_id_pos = f\"{sequence_id}_{i}\"\n        seq_id_pos_entry = list(map(lambda num: str(num), output[i,:].tolist()))\n        submission_line_entries = [seq_id_pos] + seq_id_pos_entry\n        submission_line = \",\".join(submission_line_entries)\n        output_lines.append(submission_line)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data = \"\\n\".join(output_lines)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_lines[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_lines[107]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file = open(\"submission.csv\", \"w\")\nsubmission_file.write(submission_data)\nsubmission_file.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}