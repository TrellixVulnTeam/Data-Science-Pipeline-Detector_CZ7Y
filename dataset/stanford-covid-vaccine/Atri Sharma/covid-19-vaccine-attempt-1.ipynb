{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nimport json\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing the competition data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1 = train.loc[train['SN_filter'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tokenizing the structure, sequence and loop type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(train):\n    token2int = {x:i for i,x in enumerate('AUCG().EISHXMB')}\n    cols = ['sequence','structure','predicted_loop_type']\n    train[cols] = train[cols].applymap(lambda seq: [token2int[x] for x in seq])\n    return np.transpose(np.array(train[cols].values.tolist()),(0,2,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = preprocess_inputs(train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importing the Bpps unpaired probability np array**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef read_bpps(df,seq_length):\n    \n    unpaired_probability = np.empty([len(df),seq_length])\n    \n    for i in range(len(df)):\n        unpaired_probability[i,:] = np.sum(np.load('../input/stanford-covid-vaccine/bpps/'+\n                                                   df['id'].iloc[i] + '.npy'), axis = 1)\n        \n    return unpaired_probability ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_train = read_bpps(train1,107)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Retrieving the labels**"},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols = ['reactivity','deg_pH10','deg_Mg_pH10','deg_Mg_50C','deg_50C']\ntrain_labels = np.transpose(np.array(train1[label_cols].values.tolist()),(0,2,1))\ntrain_labels.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install git+git://github.com/stared/livelossplot.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.layers as L ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from livelossplot import PlotLossesKeras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model 1: Seq to Seq using GRUs, with return_sequences = True**"},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i,x in enumerate('AUCG().EISHXMB')}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_gru_model(seq_length, scored_length):\n\n    inputs = L.Input(shape = (seq_length,3))\n    embed = L.Embedding(len(token2int),200,input_length = seq_length)(inputs)\n\n    reshape = tf.reshape(embed,shape = (-1,embed.shape[1],embed.shape[2]*embed.shape[3]))\n    \n    input_prob = L.Input(shape = (seq_length,1))\n    \n    \n    concat = L.Concatenate()([reshape, input_prob])\n                    \n    gru1 = L.Bidirectional(L.GRU(128, dropout=0.2, return_sequences=True, kernel_initializer='orthogonal'))(concat)\n    gru2 = L.Bidirectional(L.GRU(256, dropout=0.2, return_sequences=True, kernel_initializer='orthogonal'))(gru1)\n    gru3 = L.Bidirectional(L.GRU(128, dropout=0.2, return_sequences=True, kernel_initializer='orthogonal'))(gru2)\n    \n    \n    \n    dense = L.Dense(64, activation = 'relu')(gru3)\n    dense = L.Dense(32, activation = 'relu')(dense)\n    trunc = dense[:,:scored_length]\n    out = L.Dense(5)(trunc)\n\n\n    model = tf.keras.Model(inputs = [inputs,input_prob], outputs = out)\n\n    model.compile(tf.optimizers.Adam(), loss = MCRMSE)\n    \n    return model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model 2: Simple Seq to Seq model with an encoder decoder**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_seq2seq(seq_length,scored_length):\n    inputs = L.Input(shape = (seq_length,3))\n    embed = L.Embedding(len(token2int),200,input_length = seq_length)(inputs)\n\n    reshape = tf.reshape(embed,shape = (-1,embed.shape[1],embed.shape[2]*embed.shape[3]))\n    \n    input_prob = L.Input(shape = (seq_length,1))\n    \n    \n    concat = L.Concatenate()([reshape, input_prob])\n\n\n    encoder_last_h1, encoder_last_h2, encoder_last_c = L.LSTM(\n        128, activation='elu', dropout=0.2, recurrent_dropout=0.2, \n        return_sequences=False, return_state=True)(concat)\n    \n    encoder_last_h1 = L.BatchNormalization(momentum=0.6)(encoder_last_h1)\n    encoder_last_c = L.BatchNormalization(momentum=0.6)(encoder_last_c)\n\n    decoder = L.RepeatVector(seq_length)(encoder_last_h1)\n    decoder = L.LSTM(128, activation='elu', dropout=0.2, recurrent_dropout=0.2, return_state=False, return_sequences=True)(\n        decoder, initial_state=[encoder_last_h1, encoder_last_c])\n    \n    out = L.TimeDistributed(L.Dense(5))(decoder)\n    out = out[:,:scored_length]\n    \n    model = tf.keras.Model(inputs = [inputs,input_prob], outputs = out)\n\n    model.compile(tf.optimizers.Adam(), loss = MCRMSE)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model 3: Seq2Seq with attention**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_seq2seq_attention(seq_length,scored_length):\n    inputs = L.Input(shape = (seq_length,3))\n    embed = L.Embedding(len(token2int),200,input_length = seq_length)(inputs)\n\n    reshape = tf.reshape(embed,shape = (-1,embed.shape[1],embed.shape[2]*embed.shape[3]))\n    \n    input_prob = L.Input(shape = (seq_length,1))\n    \n    \n    concat = L.Concatenate()([reshape, input_prob])\n    \n    \n    encoder_stack_h, encoder_last_h, encoder_last_c = L.LSTM(\n    512, activation='elu', dropout=0.2, recurrent_dropout=0.2, \n    return_state=True, return_sequences=True)(concat)\n    \n    \n    encoder_last_h = L.BatchNormalization(momentum=0.6)(encoder_last_h)\n    encoder_last_c = L.BatchNormalization(momentum=0.6)(encoder_last_c)\n\n    \n    decoder_input = L.RepeatVector(seq_length)(encoder_last_h)\n    \n    \n    decoder_stack_h = L.LSTM(512, activation='elu', dropout=0.2, recurrent_dropout=0.2,\n         return_state=False, return_sequences=True)(\n         decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n\n    \n    attention = L.dot([decoder_stack_h, encoder_stack_h], axes=[2, 2])\n    attention = L.Activation('softmax')(attention)\n    \n    context = L.dot([attention, encoder_stack_h], axes=[2,1])\n    context = L.BatchNormalization(momentum=0.6)(context)\n    \n    decoder_combined_context = L.concatenate([context, decoder_stack_h])\n    \n    out = L.TimeDistributed(L.Dense(5))(decoder_combined_context)\n    \n    out = out[:,:scored_length]\n    \n    model = tf.keras.Model(inputs = [inputs,input_prob], outputs = out)\n\n    model.compile(tf.optimizers.Adam(), loss = MCRMSE)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model 4: 1D Convolutional Net**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_1Dconv(seq_length, scored_length):\n    inputs = L.Input(shape = (seq_length,3))\n    embed = L.Embedding(len(token2int),200,input_length = seq_length)(inputs)\n\n    reshape = tf.reshape(embed,shape = (-1,embed.shape[1],embed.shape[2]*embed.shape[3]))\n    \n    input_prob = L.Input(shape = (seq_length,1))\n    \n    concat = L.Concatenate()([reshape, input_prob])\n    \n    conv1 = L.Conv1D(32,16,activation = 'relu',padding = 'same')(concat)\n    conv2 = L.Conv1D(64,8, activation = 'relu',padding = 'same')(conv1)\n\n    conv3 = L.Conv1D(128,4, activation = 'relu', padding = 'same')(conv2)\n\n    out = L.Dense(5)(conv3)\n    \n    out = out[:,:scored_length]\n    \n    model = tf.keras.Model(inputs = [inputs,input_prob], outputs = out)\n\n    model.compile(tf.optimizers.Adam(), loss = MCRMSE)\n    \n    return model\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length = 107\ninputs = L.Input(shape = (seq_length,3))\nembed = L.Embedding(len(token2int),200,input_length = seq_length)(inputs)\n\nreshape = tf.reshape(embed,shape = (-1,embed.shape[1],embed.shape[2]*embed.shape[3]))\n    \ninput_prob = L.Input(shape = (seq_length,1))\n    \nconcat = L.Concatenate()([reshape, input_prob])\n    \nconv1 = L.Conv1D(32,16,activation = 'relu',padding = 'same')(concat)\nconv2 = L.Conv1D(64,8, activation = 'relu',padding = 'same')(conv1)\n\nconv3 = L.Conv1D(128,4, activation = 'relu', padding = 'same')(conv2)\n\nout = L.Dense(5)(conv3)\n\nprint(out)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preparing the training data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train_inputs, train_labels, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_train_actual, prob_train_val = train_test_split(prob_train, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training model 1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_gru_model(107,68)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    [x_train,prob_train_actual], y_train,\n    validation_data=([x_val,prob_train_val], y_val),\n    batch_size=64,\n    epochs=25,\n    verbose=1,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only = True),\n        PlotLossesKeras()\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training Model 2**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model = build_seq2seq(107,68)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"history = model.fit(\n    [x_train,prob_train_actual], y_train,\n    validation_data=([x_val,prob_train_val], y_val),\n    batch_size=64,\n    epochs=25,\n    verbose=1,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only = True),\n        PlotLossesKeras()\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training model 3**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_seq2seq_attention(107,68)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    [x_train,prob_train_actual], y_train,\n    validation_data=([x_val,prob_train_val], y_val),\n    batch_size=64,\n    epochs=25,\n    verbose=1,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only = True),\n        PlotLossesKeras()\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training Model 4**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model = build_1Dconv(107,68)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    [x_train,prob_train_actual], y_train,\n    validation_data=([x_val,prob_train_val], y_val),\n    batch_size=64,\n    epochs=25,\n    verbose=1,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only = True),\n        PlotLossesKeras()\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Making the predictions for the test set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_test = test.loc[test['seq_length'] == 107]\nprivate_test = test.loc[test['seq_length'] == 130]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_public_test = read_bpps(public_test, 107)\nprob_private_test = read_bpps(private_test,130)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"private_test_input = preprocess_inputs(private_test)\npublic_test_input = preprocess_inputs(public_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_gru = build_1Dconv(107,107)\nprivate_gru = build_1Dconv(130,130)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_gru.load_weights('model.h5')\nprivate_gru.load_weights('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_preds_gru = public_gru.predict([public_test_input,prob_public_test])\nprivate_preds_gru = private_gru.predict([private_test_input,prob_private_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_preds = public_preds_gru\nprivate_preds = private_preds_gru","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_ls = []\n\nfor df, preds in [(public_test, public_preds), (private_test, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=label_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission11.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}