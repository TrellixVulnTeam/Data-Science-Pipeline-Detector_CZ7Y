{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pytorch model based on GCN (GraphSAGE) and GRU\n\nThanks to:  \n* https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model/  \n* https://www.kaggle.com/theoviel/generating-graph-matrices-from-the-structures\n\nIn this notebook, we use an inductive version of GCN called [GraphSAGE](https://arxiv.org/abs/1706.02216). GraphSAGE improves traditional GCN by using different aggregator functions instead of only convolutional function.  \nWe implement GraphSAGE with following aggregator function: mean function, pooling function, convolutional function and LSTM. This model can be improved by implementing more efficient aggregator functions.\n\n**Structure of GraphSAGE:**\n![GraphSAGE](http://snap.stanford.edu/graphsage/sample_and_agg.png \"GraphSAGE\")\n  \n  \n  \n  \n**Overall structure of our model is**: Embedding -> GCN -> GRU -> Linear\n","metadata":{}},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport json\nimport seaborn as sns\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport plotly.express as px\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\nfrom torch.nn import functional as F\nfrom torch.optim import lr_scheduler","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:13:17.5318Z","iopub.execute_input":"2022-05-17T04:13:17.532132Z","iopub.status.idle":"2022-05-17T04:13:20.324838Z","shell.execute_reply.started":"2022-05-17T04:13:17.532103Z","shell.execute_reply":"2022-05-17T04:13:20.323938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Settings","metadata":{}},{"cell_type":"code","source":"class config:\n    train_file = '../input/stanford-covid-vaccine/train.json'\n    test_file = '../input/stanford-covid-vaccine/test.json'\n    pretrain_dir = './'\n    sample_submission = '../input/stanford-covid-vaccine/sample_submission.csv'\n    learning_rate = 0.001\n    batch_size = 64\n    n_epoch = 100\n    n_split = 5\n    K = 1 # number of GCN layers\n    gcn_agg = 'mean' # aggregator function: mean, conv, lstm, pooling\n    filter_noise = True\n    seed = 1234","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:27:18.956558Z","iopub.execute_input":"2022-05-17T04:27:18.956915Z","iopub.status.idle":"2022-05-17T04:27:18.963783Z","shell.execute_reply.started":"2022-05-17T04:27:18.956882Z","shell.execute_reply":"2022-05-17T04:27:18.962636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"class AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:13:39.936084Z","iopub.execute_input":"2022-05-17T04:13:39.936518Z","iopub.status.idle":"2022-05-17T04:13:39.943874Z","shell.execute_reply.started":"2022-05-17T04:13:39.936471Z","shell.execute_reply":"2022-05-17T04:13:39.942929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(config.seed)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:13:42.851952Z","iopub.execute_input":"2022-05-17T04:13:42.852292Z","iopub.status.idle":"2022-05-17T04:13:42.862089Z","shell.execute_reply.started":"2022-05-17T04:13:42.852262Z","shell.execute_reply":"2022-05-17T04:13:42.861116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define model","metadata":{}},{"cell_type":"code","source":"class GCN(nn.Module):\n    '''\n    Implementation of one layer of GraphSAGE\n    '''\n    def __init__(self, input_dim, output_dim, aggregator='mean'):\n        super(GCN, self).__init__()\n        self.aggregator = aggregator\n        \n        if aggregator == 'mean':\n            linear_input_dim = input_dim * 2\n        elif aggregator == 'conv':\n            linear_input_dim = input_dim\n        elif aggregator == 'pooling':\n            linear_input_dim = input_dim * 2\n            self.linear_pooling = nn.Linear(input_dim, input_dim)\n        elif aggregator == 'lstm':\n            self.lstm_hidden = 128\n            linear_input_dim = input_dim + self.lstm_hidden\n            self.lstm_agg = nn.LSTM(input_dim, self.lstm_hidden, num_layers=1, batch_first=True)\n        \n        self.linear_gcn = nn.Linear(in_features=linear_input_dim, out_features=output_dim)\n        \n    def forward(self, input_, adj_matrix):\n        if self.aggregator == 'conv':\n            # set elements in diagonal of adj matrix to 1 with conv aggregator\n            idx = torch.arange(0, adj_matrix.shape[-1], out=torch.LongTensor())\n            adj_matrix[:, idx, idx] = 1\n            \n        adj_matrix = adj_matrix.type(torch.float32)\n        sum_adj = torch.sum(adj_matrix, axis=2)\n        sum_adj[sum_adj==0] = 1\n        \n        if self.aggregator == 'mean' or self.aggregator == 'conv':\n            feature_agg = torch.bmm(adj_matrix, input_)\n            feature_agg = feature_agg / sum_adj.unsqueeze(dim=2)\n            \n        elif self.aggregator == 'pooling':\n            feature_pooling = self.linear_pooling(input_)\n            feature_agg = torch.sigmoid(feature_pooling)\n            feature_agg = torch.bmm(adj_matrix, feature_agg)\n            feature_agg = feature_agg / sum_adj.unsqueeze(dim=2)\n\n        elif self.aggregator == 'lstm':\n            feature_agg = torch.zeros(input_.shape[0], input_.shape[1], self.lstm_hidden).cuda()\n            for i in range(adj_matrix.shape[1]):\n                neighbors = adj_matrix[:, i, :].unsqueeze(2) * input_\n                _, hn = self.lstm_agg(neighbors)\n                feature_agg[:, i, :] = torch.squeeze(hn[0], 0)\n                \n        if self.aggregator != 'conv':\n            feature_cat = torch.cat((input_, feature_agg), axis=2)\n        else:\n            feature_cat = feature_agg\n                \n        feature = torch.sigmoid(self.linear_gcn(feature_cat))\n        feature = feature / torch.norm(feature, p=2, dim=2).unsqueeze(dim=2)\n        \n        return feature\n        \n    \nclass Net(nn.Module):\n    def __init__(self, num_embedding=14, seq_len=107, pred_len=68, dropout=0.5, \n                 embed_dim=100, hidden_dim=128, K=1, aggregator='mean'):\n        '''\n        K: number of GCN layers\n        aggregator: type of aggregator function\n        '''\n        super(Net, self).__init__()\n        \n        self.pred_len = pred_len\n        self.embedding_layer = nn.Embedding(num_embeddings=num_embedding, \n                                      embedding_dim=embed_dim)\n        \n        self.gcn = nn.ModuleList([GCN(3 * embed_dim, 3 * embed_dim, aggregator=aggregator) for i in range(K)])\n        \n        self.gru_layer = nn.GRU(input_size=3 * embed_dim, \n                          hidden_size=hidden_dim, \n                          num_layers=3, \n                          batch_first=True, \n                          dropout=dropout, \n                          bidirectional=True)\n        \n        self.linear_layer = nn.Linear(in_features=2 * hidden_dim, \n                                out_features=5)\n        \n        self.used = False\n        \n    def forward(self, input_, adj_matrix):\n        if not self.used: print(\"Input:\",input_.shape)\n        #embedding\n        embedding = self.embedding_layer(input_)\n        if not self.used: print(\"Embedding:\",embedding.shape)\n\n        embedding = torch.reshape(embedding, (-1, embedding.shape[1], embedding.shape[2] * embedding.shape[3]))\n        if not self.used: print(\"Embedding reshaped:\",embedding.shape)\n        \n        #gcn\n        gcn_feature = embedding\n        for i, gcn_layer in enumerate(self.gcn):\n            gcn_feature = gcn_layer(gcn_feature, adj_matrix)\n            if not self.used: print(i, \"gcn_feature:\",gcn_feature.shape)\n        \n        #gru\n        gru_output, gru_hidden = self.gru_layer(gcn_feature)\n        if not self.used: print(\"gru_output:\",gru_output.shape)\n        if not self.used: print(\"gru_hidden:\",gru_hidden.shape)\n\n        truncated = gru_output[:, :self.pred_len]\n        if not self.used: print(\"truncated:\",truncated.shape)\n\n        output = self.linear_layer(truncated)\n        if not self.used: print(\"output:\",output.shape)\n\n        if not self.used: self.used = True\n            \n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:26:47.795718Z","iopub.execute_input":"2022-05-17T04:26:47.79615Z","iopub.status.idle":"2022-05-17T04:26:47.832482Z","shell.execute_reply.started":"2022-05-17T04:26:47.796111Z","shell.execute_reply":"2022-05-17T04:26:47.831256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:16:23.841646Z","iopub.execute_input":"2022-05-17T04:16:23.842113Z","iopub.status.idle":"2022-05-17T04:16:23.846671Z","shell.execute_reply.started":"2022-05-17T04:16:23.84207Z","shell.execute_reply":"2022-05-17T04:16:23.84571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n\ndef get_couples(structure):\n    \"\"\"\n    For each closing parenthesis, I find the matching opening one and store their index in the couples list.\n    The assigned list is used to keep track of the assigned opening parenthesis\n    \"\"\"\n    opened = [idx for idx, i in enumerate(structure) if i == '(']\n    closed = [idx for idx, i in enumerate(structure) if i == ')']\n\n    assert len(opened) == len(closed)\n    assigned = []\n    couples = []\n\n    for close_idx in closed:\n        for open_idx in opened:\n            if open_idx < close_idx:\n                if open_idx not in assigned:\n                    candidate = open_idx\n            else:\n                break\n        assigned.append(candidate)\n        couples.append([candidate, close_idx])\n        \n    assert len(couples) == len(opened)\n    \n    return couples\n\ndef build_matrix(couples, size):\n    mat = np.zeros((size, size))\n    \n    for i in range(size):  # neigbouring bases are linked as well\n        if i < size - 1:\n            mat[i, i + 1] = 1\n        if i > 0:\n            mat[i, i - 1] = 1\n    \n    for i, j in couples:\n        mat[i, j] = 1\n        mat[j, i] = 1\n        \n    return mat\n\ndef convert_to_adj(structure):\n    couples = get_couples(structure)\n    mat = build_matrix(couples, len(structure))\n    return mat\n\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    inputs = np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\n    \n    adj_matrix = np.array(df['structure'].apply(convert_to_adj).values.tolist())\n    \n    return inputs, adj_matrix","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:17:05.805953Z","iopub.execute_input":"2022-05-17T04:17:05.806295Z","iopub.status.idle":"2022-05-17T04:17:05.823311Z","shell.execute_reply.started":"2022-05-17T04:17:05.806263Z","shell.execute_reply":"2022-05-17T04:17:05.822349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_json(config.train_file, lines=True)\n\nif config.filter_noise:\n    train = train[train.signal_to_noise > 1]\n    \ntest = pd.read_json(config.test_file, lines=True)\nsample_df = pd.read_csv(config.sample_submission)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:17:17.196608Z","iopub.execute_input":"2022-05-17T04:17:17.196977Z","iopub.status.idle":"2022-05-17T04:17:18.987394Z","shell.execute_reply.started":"2022-05-17T04:17:17.196946Z","shell.execute_reply":"2022-05-17T04:17:18.98655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inputs, train_adj = preprocess_inputs(train)\ntrain_labels = np.array(train[pred_cols].values.tolist()).transpose((0, 2, 1))\n\ntrain_inputs = torch.tensor(train_inputs, dtype=torch.long)\ntrain_adj = torch.tensor(train_adj, dtype=torch.long)\ntrain_labels = torch.tensor(train_labels, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:17:26.211412Z","iopub.execute_input":"2022-05-17T04:17:26.211857Z","iopub.status.idle":"2022-05-17T04:17:27.180093Z","shell.execute_reply.started":"2022-05-17T04:17:26.211818Z","shell.execute_reply":"2022-05-17T04:17:27.1793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train KFold","metadata":{}},{"cell_type":"code","source":"def train_fn(epoch, model, train_loader, criterion, optimizer):\n    model.train()\n    model.zero_grad()\n    train_loss = AverageMeter()\n    \n    for index, (input_, adj, label) in enumerate(train_loader):\n        input_ = input_.cuda()\n        adj = adj.cuda()\n        label = label.cuda()\n        preds = model(input_, adj)\n        \n        loss = criterion(preds, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss.update(loss.item())\n    \n    print(f\"Train loss {train_loss.avg}\")\n    return train_loss.avg\n    \ndef eval_fn(epoch, model, valid_loader, criterion):\n    model.eval()\n    eval_loss = AverageMeter()\n    \n    for index, (input_, adj, label) in enumerate(valid_loader):\n        input_ = input_.cuda()\n        adj = adj.cuda()\n        label = label.cuda()\n        preds = model(input_, adj)\n        \n        loss = criterion(preds, label)\n        eval_loss.update(loss.item())\n    \n    print(f\"Valid loss {eval_loss.avg}\")\n    return eval_loss.avg","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:21:07.384209Z","iopub.execute_input":"2022-05-17T04:21:07.384537Z","iopub.status.idle":"2022-05-17T04:21:07.395346Z","shell.execute_reply.started":"2022-05-17T04:21:07.384506Z","shell.execute_reply":"2022-05-17T04:21:07.394446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(fold, train_loader, valid_loader):\n    model = Net(K=config.K, aggregator=config.gcn_agg)\n    model.cuda()\n    criterion = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(params=model.parameters(), lr=config.learning_rate, weight_decay=0.0)\n    \n    train_losses = []\n    eval_losses = []\n    for epoch in range(config.n_epoch):\n        print('#################')\n        print('###Epoch:', epoch)\n        \n        train_loss = train_fn(epoch, model, train_loader, criterion, optimizer)\n        eval_loss = eval_fn(epoch, model, valid_loader, criterion)\n        train_losses.append(train_loss)\n        eval_losses.append(eval_loss)\n        \n    torch.save(model.state_dict(), f'{config.pretrain_dir}/gcn_gru_{fold}.pt')\n    return train_losses, eval_losses","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:21:15.79286Z","iopub.execute_input":"2022-05-17T04:21:15.793181Z","iopub.status.idle":"2022-05-17T04:21:15.801577Z","shell.execute_reply.started":"2022-05-17T04:21:15.79315Z","shell.execute_reply":"2022-05-17T04:21:15.800774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = KFold(n_splits=config.n_split, shuffle=True, random_state=config.seed).split(train_inputs)\n\nfor fold, (train_idx, val_idx) in enumerate(splits):\n    train_dataset = TensorDataset(train_inputs[train_idx], train_adj[train_idx], train_labels[train_idx])\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=8)\n    \n    valid_dataset = TensorDataset(train_inputs[val_idx], train_adj[val_idx], train_labels[val_idx])\n    valid_loader = DataLoader(valid_dataset, batch_size=config.batch_size, shuffle=False, num_workers=8)\n    \n    train_losses, eval_losses = run(fold, train_loader, valid_loader)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:27:35.023689Z","iopub.execute_input":"2022-05-17T04:27:35.024056Z","iopub.status.idle":"2022-05-17T04:48:33.766826Z","shell.execute_reply.started":"2022-05-17T04:27:35.024025Z","shell.execute_reply":"2022-05-17T04:48:33.765027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize losses","metadata":{}},{"cell_type":"code","source":"fig = px.line(\n    pd.DataFrame([train_losses, eval_losses], index=['loss', 'val_loss']).T, \n    y=['loss', 'val_loss'], \n    labels={'index': 'epoch', 'value': 'Mean Squared Error'}, \n    title='Training History')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:48:33.771221Z","iopub.execute_input":"2022-05-17T04:48:33.77154Z","iopub.status.idle":"2022-05-17T04:48:34.705585Z","shell.execute_reply.started":"2022-05-17T04:48:33.771508Z","shell.execute_reply":"2022-05-17T04:48:34.703877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict on test set","metadata":{}},{"cell_type":"code","source":"public_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\n\npublic_inputs, public_adj = preprocess_inputs(public_df)\nprivate_inputs, private_adj = preprocess_inputs(private_df)\n\npublic_inputs = torch.tensor(public_inputs, dtype=torch.long)\nprivate_inputs = torch.tensor(private_inputs, dtype=torch.long)\npublic_adj = torch.tensor(public_adj, dtype=torch.long)\nprivate_adj = torch.tensor(private_adj, dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:48:34.706893Z","iopub.execute_input":"2022-05-17T04:48:34.707221Z","iopub.status.idle":"2022-05-17T04:48:36.945787Z","shell.execute_reply.started":"2022-05-17T04:48:34.707186Z","shell.execute_reply":"2022-05-17T04:48:36.944955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_short = Net(seq_len=107, pred_len=107, K=config.K, aggregator=config.gcn_agg)\nmodel_long = Net(seq_len=130, pred_len=130, K=config.K, aggregator=config.gcn_agg)\n\nlist_public_preds = []\nlist_private_preds = []\nfor fold in range(config.n_split):\n    model_short.load_state_dict(torch.load(f'{config.pretrain_dir}/gcn_gru_{fold}.pt'))\n    model_long.load_state_dict(torch.load(f'{config.pretrain_dir}/gcn_gru_{fold}.pt'))\n    model_short.cuda()\n    model_long.cuda()\n    model_short.eval()\n    model_long.eval()\n\n    public_preds = model_short(public_inputs.cuda(), public_adj.cuda())\n    private_preds = model_long(private_inputs.cuda(), private_adj.cuda())\n    public_preds = public_preds.cpu().detach().numpy()\n    private_preds = private_preds.cpu().detach().numpy()\n    \n    list_public_preds.append(public_preds)\n    list_private_preds.append(private_preds)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:48:36.947109Z","iopub.execute_input":"2022-05-17T04:48:36.947461Z","iopub.status.idle":"2022-05-17T04:48:38.57854Z","shell.execute_reply.started":"2022-05-17T04:48:36.947426Z","shell.execute_reply":"2022-05-17T04:48:38.577168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get predict results by averaging results in 5-folds","metadata":{}},{"cell_type":"code","source":"public_preds = np.mean(list_public_preds, axis=0)\nprivate_preds = np.mean(list_private_preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:48:38.586275Z","iopub.execute_input":"2022-05-17T04:48:38.587074Z","iopub.status.idle":"2022-05-17T04:48:38.623515Z","shell.execute_reply.started":"2022-05-17T04:48:38.587033Z","shell.execute_reply":"2022-05-17T04:48:38.62231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_ls = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:48:38.625287Z","iopub.execute_input":"2022-05-17T04:48:38.625877Z","iopub.status.idle":"2022-05-17T04:48:41.984062Z","shell.execute_reply.started":"2022-05-17T04:48:38.625838Z","shell.execute_reply":"2022-05-17T04:48:41.983303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:48:41.985227Z","iopub.execute_input":"2022-05-17T04:48:41.985565Z","iopub.status.idle":"2022-05-17T04:48:46.702737Z","shell.execute_reply.started":"2022-05-17T04:48:41.985532Z","shell.execute_reply":"2022-05-17T04:48:46.701893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T04:48:46.70398Z","iopub.execute_input":"2022-05-17T04:48:46.704341Z","iopub.status.idle":"2022-05-17T04:48:46.722382Z","shell.execute_reply.started":"2022-05-17T04:48:46.704306Z","shell.execute_reply":"2022-05-17T04:48:46.721208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}