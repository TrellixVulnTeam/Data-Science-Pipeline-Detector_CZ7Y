{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Notebook by [Tucker arrants ](https://www.kaggle.com/tuckerarrants/competitions)with biological features from structure, loops, pairs_rate as new features of the model\n"},{"metadata":{},"cell_type":"markdown","source":"# 2. SN_filter = 1 for data from the train and test due to the fact that the test data are all SN_filter = 1"},{"metadata":{},"cell_type":"markdown","source":"# 3. theory : can we use the data from SN_filter != 1 ? "},{"metadata":{},"cell_type":"markdown","source":"# 4. LSTM work less so I delete it and keep the Gru RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd, numpy as np, seaborn as sns\nimport math, json, os, random\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport keras.backend as K\n\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed = 34):\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nseed_everything()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get comp data\ntrain = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsample_sub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"fig, ax = plt.subplots(1, 2, figsize=(15, 5))\nsns.kdeplot(train['signal_to_noise'], shade=True, ax=ax[0])\nsns.countplot(train['SN_filter'], ax=ax[1])\n\nax[0].set_title('Signal/Noise Distribution')\nax[1].set_title('Signal/Noise Filter Distribution');\n"},{"metadata":{},"cell_type":"markdown","source":"print(f\"Samples with signal_to_noise greater than 1: {len(train.loc[(train['signal_to_noise'] > 1 )])}\")\nprint(f\"Samples with SN_filter = 1: {len(train.loc[(train['SN_filter'] == 1 )])}\")\nprint(f\"Samples with signal_to_noise greater than 1, but SN_filter == 0: {len(train.loc[(train['signal_to_noise'] > 1) & (train['SN_filter'] == 0)])}\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_bpps_sum(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").sum(axis=1))\n    return bpps_arr\n\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ndef read_bpps_nb(df):\n    #mean and std from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n    bpps_nb_mean = 0.077522\n    bpps_nb_std = 0.08914\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\")\n        bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n        bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n        bpps_arr.append(bpps_nb)\n    return bpps_arr \n\ntrain['bpps_sum'] = read_bpps_sum(train)\ntest['bpps_sum'] = read_bpps_sum(test)\ntrain['bpps_max'] = read_bpps_max(train)\ntest['bpps_max'] = read_bpps_max(test)\ntrain['bpps_nb'] = read_bpps_nb(train)\ntest['bpps_nb'] = read_bpps_nb(test)\n\n#sanity check\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter as count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nfig, ax = plt.subplots(3, figsize=(15, 10))\nsns.kdeplot(np.array(train['bpps_max'].to_list()).reshape(-1),\n            color=\"Blue\", ax=ax[0], label='Train')\nsns.kdeplot(np.array(test[test['seq_length'] == 107]['bpps_max'].to_list()).reshape(-1),\n            color=\"Red\", ax=ax[0], label='Public test')\nsns.kdeplot(np.array(test[test['seq_length'] == 130]['bpps_max'].to_list()).reshape(-1),\n            color=\"Green\", ax=ax[0], label='Private test')\nsns.kdeplot(np.array(train['bpps_sum'].to_list()).reshape(-1),\n            color=\"Blue\", ax=ax[1], label='Train')\nsns.kdeplot(np.array(test[test['seq_length'] == 107]['bpps_sum'].to_list()).reshape(-1),\n            color=\"Red\", ax=ax[1], label='Public test')\nsns.kdeplot(np.array(test[test['seq_length'] == 130]['bpps_sum'].to_list()).reshape(-1),\n            color=\"Green\", ax=ax[1], label='Private test')\nsns.kdeplot(np.array(train['bpps_nb'].to_list()).reshape(-1),\n            color=\"Blue\", ax=ax[2], label='Train')\nsns.kdeplot(np.array(test[test['seq_length'] == 107]['bpps_nb'].to_list()).reshape(-1),\n            color=\"Red\", ax=ax[2], label='Public test')\nsns.kdeplot(np.array(test[test['seq_length'] == 130]['bpps_nb'].to_list()).reshape(-1),\n            color=\"Green\", ax=ax[2], label='Private test')\n\nax[0].set_title('Distribution of bpps_max')\nax[1].set_title('Distribution of bpps_sum')\nax[2].set_title('Distribution of bpps_nb')\nplt.tight_layout();\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENT=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aug_df = pd.read_csv('../input/augmented-data-for-stanford-covid-vaccine/43k_augment.csv')\nprint(aug_df.shape)\naug_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def aug_data(df):\n    target_df = df.copy()\n    new_df = aug_df[aug_df['id'].isin(target_df['id'])]\n                         \n    del target_df['structure']\n    del target_df['predicted_loop_type']\n    new_df = new_df.merge(target_df, on=['id','sequence'], how='left')\n\n    df['cnt'] = df['id'].map(new_df[['id','cnt']].set_index('id').to_dict()['cnt'])\n    df['log_gamma'] = 100\n    df['score'] = 1.0\n    df = df.append(new_df[df.columns])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Samples in train before augmentation: {len(train)}\")\nprint(f\"Samples in test before augmentation: {len(test)}\")\n\nif AUGMENT:\n    train = aug_data(train)\n    test = aug_data(test)\n\nprint(f\"Samples in train after augmentation: {len(train)}\")\nprint(f\"Samples in test after augmentation: {len(test)}\")\n\nprint(f\"Unique sequences in train: {len(train['sequence'].unique())}\")\nprint(f\"Unique sequences in test: {len(test['sequence'].unique())}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DENOISE = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    base_fea = np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\n    bpps_sum_fea = np.array(df['bpps_sum'].to_list())[:,:,np.newaxis]\n    bpps_max_fea = np.array(df['bpps_max'].to_list())[:,:,np.newaxis]\n    return np.concatenate([base_fea,bpps_sum_fea,bpps_max_fea], 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DENOISE:\n    train = train[train['signal_to_noise'] > .25]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(token2int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/c/stanford-covid-vaccine/discussion/183211\ndef rmse(y_actual, y_pred):\n    mse = tf.keras.losses.mean_squared_error(y_actual, y_pred)\n    return K.sqrt(mse)\n\ndef mcrmse(y_actual, y_pred, num_scored=len(target_cols)):\n    score = 0\n    for i in range(num_scored):\n        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / num_scored\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.GRU(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer='orthogonal'))\n\ndef lstm_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.LSTM(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer='orthogonal'))\n\ndef build_model(rnn='gru', convolve=False, conv_dim=512, \n                dropout=.4, sp_dropout=.2, embed_dim=200,\n                hidden_dim=256, layers=3,\n                seq_len=107, pred_len=68):\n    \n###############################################\n#### Inputs\n###############################################\n\n    inputs = tf.keras.layers.Input(shape=(seq_len, 5))\n    categorical_feats = inputs[:, :, :3]\n    numerical_feats = inputs[:, :, 3:]\n\n    embed = tf.keras.layers.Embedding(input_dim=len(token2int),\n                                      output_dim=embed_dim)(categorical_feats)\n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    \n    reshaped = tf.keras.layers.concatenate([reshaped, numerical_feats], axis=2)\n    hidden = tf.keras.layers.SpatialDropout1D(sp_dropout)(reshaped)\n    \n    if convolve:\n        hidden = tf.keras.layers.Conv1D(conv_dim, 5, padding='same', activation=tf.keras.activations.swish)(hidden)\n\n###############################################\n#### RNN Layers\n###############################################\n\n    if rnn is 'gru':\n        for _ in range(layers):\n            hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n    elif rnn is 'lstm':\n        for _ in range(layers):\n            hidden = lstm_layer(hidden_dim, dropout)(hidden)\n\n###############################################\n#### Output\n###############################################\n\n    out = hidden[:, :pred_len]\n    out = tf.keras.layers.Dense(5, activation='linear')(out)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    adam = tf.optimizers.Adam()\n    model.compile(optimizer=adam, loss=mcrmse)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_model = build_model(rnn='gru')\ntest_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_and_infer(rnn, STRATIFY=True, FOLDS=4, EPOCHS=50, BATCH_SIZE=64,\n                    REPEATS=3, SEED=34, VERBOSE=2):\n\n    #get test now for OOF \n    public_df = test.query(\"seq_length == 107\").copy()\n    private_df = test.query(\"seq_length == 130\").copy()\n    private_preds = np.zeros((private_df.shape[0], 130, 5))\n    public_preds = np.zeros((public_df.shape[0], 107, 5))\n    public_inputs = preprocess_inputs(public_df)\n    private_inputs = preprocess_inputs(private_df)\n\n    #to evaluate TTA effects/post processing\n    holdouts = []\n    holdout_preds = []\n    \n    #to view learning curves\n    histories = []\n    \n    #put similar RNA in the same fold\n    gkf = GroupKFold(n_splits=FOLDS)\n    kf=KFold(n_splits=FOLDS, random_state=SEED)\n    kmeans_model = KMeans(n_clusters=200, random_state=SEED).fit(preprocess_inputs(train)[:,:,0])\n    train['cluster_id'] = kmeans_model.labels_\n\n    for _ in range(REPEATS):\n        \n        for f, (train_index, val_index) in enumerate((gkf if STRATIFY else kf).split(train,\n                train['reactivity'], train['cluster_id'] if STRATIFY else None)):\n\n            #define training callbacks\n            lr_callback = tf.keras.callbacks.ReduceLROnPlateau(patience=8, \n                                                               factor=.1,\n                                                               #min_lr=1e-5,\n                                                               verbose=VERBOSE)\n            save = tf.keras.callbacks.ModelCheckpoint(f'model-{f}.h5')\n\n            #define sample weight function\n            epsilon = .1\n            sample_weighting = np.log1p(train.iloc[train_index]['signal_to_noise'] + epsilon) / 2\n\n            #get train data\n            trn = train.iloc[train_index]\n            trn_ = preprocess_inputs(trn)\n            trn_labs = np.array(trn[target_cols].values.tolist()).transpose((0, 2, 1))\n\n            #get validation data\n            val = train.iloc[val_index]\n            val_all = preprocess_inputs(val)\n            val = val[val.SN_filter == 1]\n            val_ = preprocess_inputs(val)\n            val_labs = np.array(val[target_cols].values.tolist()).transpose((0, 2, 1))\n\n            #pre-build models for different sequence lengths\n            model = build_model(rnn=rnn)\n            model_short = build_model(rnn=rnn,seq_len=107, pred_len=107)\n            model_long = build_model(rnn=rnn,seq_len=130, pred_len=130)\n\n            #train model\n            history = model.fit(\n                trn_, trn_labs,\n                validation_data = (val_, val_labs),\n                batch_size=BATCH_SIZE,\n                epochs=EPOCHS,\n                sample_weight=sample_weighting,\n                callbacks=[save, lr_callback],\n                verbose=VERBOSE\n            )\n\n            histories.append(history)\n\n            #load best models\n            model.load_weights(f'model-{f}.h5')\n            model_short.load_weights(f'model-{f}.h5')\n            model_long.load_weights(f'model-{f}.h5')\n\n            holdouts.append(train.iloc[val_index])\n            holdout_preds.append(model.predict(val_all))\n\n            public_preds += model_short.predict(public_inputs) / (FOLDS * REPEATS)\n            private_preds += model_long.predict(private_inputs) / (FOLDS * REPEATS)\n        \n        del model, model_short, model_long\n        \n    return holdouts, holdout_preds, public_df, public_preds, private_df, private_preds, histories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_holdouts, gru_holdout_preds, public_df, gru_public_preds, private_df, gru_private_preds, gru_histories = train_and_infer(rnn='gru')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_holdouts, lstm_holdout_preds, public_df, lstm_public_preds, private_df, lstm_private_preds, lstm_histories = train_and_infer(rnn='lstm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curves(results):\n\n    fig, ax = plt.subplots(1, len(results['histories']), figsize = (20, 10))\n    \n    for i, result in enumerate(results['histories']):\n        for history in result:\n            ax[i].plot(history.history['loss'], color='C0')\n            ax[i].plot(history.history['val_loss'], color='C1')\n            ax[i].set_title(f\"{results['models'][i]}\")\n            ax[i].set_ylabel('MCRMSE')\n            ax[i].set_xlabel('Epoch')\n            ax[i].legend(['train', 'validation'], loc = 'upper right')\n            \nresults = {\n            \"models\" : ['GRU', 'LSTM'],    \n            \"histories\" : [gru_histories, lstm_histories],\n            }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model\ndef format_predictions(test_df, test_preds, val=False):\n    preds = []\n    \n    for df, preds_ in zip(test_df, test_preds):\n        for i, uid in enumerate(df['id']):\n            single_pred = preds_[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n            if val: single_df['SN_filter'] = df[df['id'] == uid].SN_filter.values[0]\n\n            preds.append(single_df)\n    return pd.concat(preds).groupby('id_seqpos').mean().reset_index() if AUGMENT else pd.concat(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_error(preds):\n    val = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\n\n    val_data = []\n    for mol_id in val['id'].unique():\n        sample_data = val.loc[val['id'] == mol_id]\n        sample_seq_length = sample_data.seq_length.values[0]\n        for i in range(68):\n            sample_dict = {\n                           'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                           'reactivity_gt' : sample_data['reactivity'].values[0][i],\n                           'deg_Mg_pH10_gt' : sample_data['deg_Mg_pH10'].values[0][i],\n                           'deg_Mg_50C_gt' : sample_data['deg_Mg_50C'].values[0][i],\n                           }\n            \n            val_data.append(sample_dict)\n            \n    val_data = pd.DataFrame(val_data)\n    val_data = val_data.merge(preds, on='id_seqpos')\n\n    rmses = []\n    mses = []\n    \n    for col in ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']:\n        rmse = ((val_data[col] - val_data[col+'_gt']) ** 2).mean() ** .5\n        mse = ((val_data[col] - val_data[col+'_gt']) ** 2).mean()\n        rmses.append(rmse)\n        mses.append(mse)\n        print(col, rmse, mse)\n    print(np.mean(rmses), np.mean(mses))\n    print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curves(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_val_preds = format_predictions(gru_holdouts, gru_holdout_preds, val=True)\n\nprint('-'*25); print('Unfiltered training results'); print('-'*25)\nprint('GRU training results'); print('')\nget_error(gru_val_preds)\nprint('-'*25); print('SN_filter == 1 training results'); print('-'*25)\nprint('GRU training results'); print('')\nget_error(gru_val_preds[gru_val_preds['SN_filter'] == 1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_preds = [gru_public_preds, gru_private_preds]\ntest_df = [public_df, private_df]\ngru_preds = format_predictions(test_df, gru_preds)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_weight = .51\nlstm_weight = .5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blended_preds = pd.DataFrame()\nblended_preds['id_seqpos'] = gru_preds['id_seqpos']\nblended_preds['reactivity'] = gru_weight*gru_preds['reactivity'] + lstm_weight*lstm_preds['reactivity']\nblended_preds['deg_Mg_pH10'] = gru_weight*gru_preds['deg_Mg_pH10'] + lstm_weight*lstm_preds['deg_Mg_pH10']\nblended_preds['deg_pH10'] = gru_weight*gru_preds['deg_pH10'] + lstm_weight*lstm_preds['deg_pH10']\nblended_preds['deg_Mg_50C'] = gru_weight*gru_preds['deg_Mg_50C'] + lstm_weight*lstm_preds['deg_Mg_50C']\nblended_preds['deg_50C'] = gru_weight*gru_preds['deg_50C'] + lstm_weight*lstm_preds['deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_sub[['id_seqpos']].merge(blended_preds, on=['id_seqpos'])\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(f'submission_new.csv', index=False)\nprint('Submission saved')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}