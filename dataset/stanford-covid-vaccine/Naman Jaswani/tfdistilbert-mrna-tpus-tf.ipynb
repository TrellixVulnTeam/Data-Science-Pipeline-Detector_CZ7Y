{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://camo.githubusercontent.com/c1c57556008de61f649ae26939be7236e5a02d85/68747470733a2f2f68756767696e67666163652e636f2f66726f6e742f7468756d626e61696c732f64697374696c626172745f6c617267652e706e67)\n\n\n\nreference : [https://www.kaggle.com/eladwar/openvaccine-bert-model](https://www.kaggle.com/eladwar/openvaccine-bert-model)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# pip install --upgrade transformers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport copy\nimport tensorflow.keras.layers as L\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import regularizers\n\nfrom sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold, StratifiedKFold\nfrom transformers import BertTokenizer, TFBertModel, BertConfig, BertModel, TFDistilBertModel, DistilBertConfig\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def seed_everything(seed = 34):\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nseed_everything()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n\n#target columns\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE(y_true, y_pred):\n    columnwise_mse = tf.reduce_mean(tf.square(y_true-y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(columnwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = DistilBertConfig() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config.vocab_size = 10\nconfig.dim = 128\nconfig.hidden_dim = 128\nconfig.max_position_embeddings = 128\nconfig.n_layers = 2\nconfig.n_heads = 128\n# config.sinusoidal_pos_embds = True\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(transformer, seq_len=107, pred_len=68, dropout=0.5, embed_dim=100, hidden_dim=128):\n    ids = L.Input(shape=(seq_len,3),  dtype=tf.int32, name=\"input_word_ids\")\n    flat = L.Flatten()(ids)\n    sequence_output = transformer(flat)[0]\n    truncated = sequence_output[:,:pred_len, :]\n    \n    out = L.Dense(5, activation='linear')(truncated)\n    model = tf.keras.Model(inputs=ids, outputs=out)\n\n    model.compile(tf.keras.optimizers.Adam(), loss=MCRMSE)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    transformer_layer = (\n        TFDistilBertModel(config=config)\n    )\n    model = build_model(transformer_layer)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokentoint = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [tokentoint[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\npreprocess_inputs(train).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = preprocess_inputs(train[train['signal_to_noise'] >= 1])\ntrain_labels = np.array(train[train['signal_to_noise'] >= 1][target_cols].values.tolist()).transpose(0, 2, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_inputs.shape)\nprint(train_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test[test['seq_length']==107].copy()\nprivate_df = test[test['seq_length']==130].copy()\n\npublic_inputs = preprocess_inputs(public_df)\nprivate_inputs = preprocess_inputs(private_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#basic training configuration\nFOLDS = 5\nEPOCHS = 100\nREPEATS = 1\nBATCH_SIZE = 64\nVERBOSE = 2\nSEED = 34","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pip install livelossplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nlr_callback = tf.keras.callbacks.ReduceLROnPlateau()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_histories = []\nbert_private_preds = np.zeros((private_df.shape[0], 130, 5))\nbert_public_preds = np.zeros((public_df.shape[0], 107, 5))\n\nkf = KFold(n_splits=FOLDS,shuffle=True,random_state=42)\n\n\nwith strategy.scope():\n   \n    \n    for fold, (train_index, val_index) in enumerate(kf.split(train_inputs, train_labels)):\n        print(f\"FOLD {fold}\")\n        \n        model = build_model(transformer_layer)\n        \n        history = model.fit(\n            train_inputs[train_index,:,:], train_labels[train_index,:,:], \n            batch_size=BATCH_SIZE,\n            epochs=EPOCHS,\n            validation_split=0.1,\n                callbacks=[\n                            lr_callback,\n                            tf.keras.callbacks.ModelCheckpoint('model'+str(fold)+'.h5',save_weights_only=True,save_best_only=True)\n                            ])\n\n        model_short = build_model(transformer_layer,seq_len=107, pred_len=107)\n        model_long = build_model(transformer_layer,seq_len=130, pred_len=130)\n\n        model_short.load_weights('model'+str(fold)+'.h5')\n        model_long.load_weights('model'+str(fold)+'.h5')\n        \n        bert_histories.append(history)\n\n        bert_public_pred = model_short.predict(public_inputs) / FOLDS\n\n        bert_private_pred = model_long.predict(private_inputs) / FOLDS\n\n        bert_public_preds += bert_public_pred\n        bert_private_preds += bert_private_pred\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_bert = []\n\nfor df, preds in [(public_df, bert_public_preds), (private_df, bert_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_bert.append(single_df)\n\npreds_bert_df = pd.concat(preds_bert)\npreds_bert_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sub[['id_seqpos']].merge(preds_bert_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}