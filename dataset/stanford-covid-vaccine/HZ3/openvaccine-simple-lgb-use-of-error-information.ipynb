{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Reference\nI referred to the notebook below. Thank you for sharing.  \n- https://www.kaggle.com/t88take/openvaccine-simple-lgb-baseline\n- https://www.kaggle.com/mightyrains/a-study-in-errors\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport random\n\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport itertools\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\nfrom sklearn.cluster import KMeans\n\nsns.set(style='darkgrid')\nSEEDS = 19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse(y_true, y_pred):\n    return (mean_squared_error(y_true, y_pred))** .5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# treemodel_wrapper\nclass TreeModel:\n    def __init__(self, model_type):\n        self.model_type = model_type\n        self.tr_data = None\n        self.vl_data = None\n        self.model = None\n    \n    def train(self, params, train_x, train_y, valid_x=None, valid_y=None, num_round=None, early_stopping=None, verbose=None):\n        if self.model_type == 'lgb':\n            self.tr_data = lgb.Dataset(train_x, label=train_y)\n            self.vl_data = lgb.Dataset(valid_x, label=valid_y)\n            self.model = lgb.train(params, self.tr_data, valid_sets=[self.tr_data, self.vl_data],\n                                   num_boost_round=num_round, early_stopping_rounds=early_stopping,verbose_eval=verbose)\n            \n        if self.model_type == 'rf_reg':\n            self.train_x = train_x\n            self.train_y = train_y\n            self.model = RandomForestRegressor(**params).fit(self.train_x, self.train_y)\n            \n        if self.model_type == 'xgb':\n            self.tr_data = xgb.DMatrix(train_x, train_y)\n            self.vl_data = xgb.DMatrix(valid_x, valid_y)\n            self.model = xgb.train(params, self.tr_data, num_boost_round=num_round,\n                                   evals=[(self.tr_data, 'train'), (self.vl_data, 'val')], \n                                   verbose_eval=verbose, early_stopping_rounds=early_stopping)\n            \n        if self.model_type == 'cat':\n            params['num_boost_round'] = num_round\n            self.cat_cols = list(train_x.select_dtypes(include='object').columns)\n            self.tr_data = Pool(train_x, train_y, cat_features=self.cat_cols)\n            self.vl_data = Pool(valid_x, valid_y, cat_features=self.cat_cols)\n            self.model = CatBoost(params).fit(self.tr_data, eval_set=self.vl_data,\n                                                early_stopping_rounds=early_stopping, verbose=verbose, use_best_model=True)\n            \n            return self.model\n            \n    \n    def predict(self,X):\n        if self.model_type == 'lgb':\n            return self.model.predict(X, num_iteration=self.model.best_iteration)\n        \n        if self.model_type == 'rf_reg':\n            return self.model.predict(X)\n        \n        if self.model_type == 'xgb':\n            X_DM = xgb.DMatrix(X)\n            return self.model.predict(X_DM)\n        \n        if self.model_type == 'cat':\n            X_pool = Pool(X, cat_features=self.cat_cols)\n            return self.model.predict(X_pool)\n    \n    @property\n    def feature_names_(self):\n        if self.model_type == 'lgb':\n            return self.model.feature_name()\n        \n        if self.model_type == 'rf_reg':\n            return self.train_x.columns\n        \n        if self.model_type == 'xgb':\n            return list(self.model.get_score(importance_type='gain').keys())\n        \n        if self.model_type == 'cat':\n            return self.model.feature_names_\n    \n    @property\n    def feature_importances_(self):\n        if self.model_type == 'lgb':\n            return self.model.feature_importance(importance_type='gain')\n        \n        if self.model_type == 'rf_reg':\n            return self.model.feature_importances_\n        \n        if self.model_type == 'xgb':\n            return list(self.model.get_score(importance_type='gain').values())\n        \n        if self.model_type == 'cat':\n            return self.model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json',lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsubmission = pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SN_filter == 1 split Extraction \ntrain2 = train[train.SN_filter < 1]\ntrain = train[train.SN_filter == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sorting by SN == 1 results in 66% of all data."},{"metadata":{},"cell_type":"markdown","source":"# preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = []\nfor mol_id in train['id'].unique():\n    sample_data = train.loc[train['id'] == mol_id]\n    sample_seq_length = sample_data.seq_length.values[0]\n    \n    for i in range(68):\n        sample_dict = {'id' : sample_data['id'].values[0],\n                       'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                       'sequence' : sample_data['sequence'].values[0][i],\n                       'structure' : sample_data['structure'].values[0][i],\n                       'predicted_loop_type' : sample_data['predicted_loop_type'].values[0][i],\n                       'reactivity' : sample_data['reactivity'].values[0][i],\n                       'reactivity_error' : sample_data['reactivity_error'].values[0][i],\n                       'deg_Mg_pH10' : sample_data['deg_Mg_pH10'].values[0][i],\n                       'deg_error_Mg_pH10' : sample_data['deg_error_Mg_pH10'].values[0][i],\n                       'deg_pH10' : sample_data['deg_pH10'].values[0][i],\n                       'deg_error_pH10' : sample_data['deg_error_pH10'].values[0][i],\n                       'deg_Mg_50C' : sample_data['deg_Mg_50C'].values[0][i],\n                       'deg_error_Mg_50C' : sample_data['deg_error_Mg_50C'].values[0][i],\n                       'deg_50C' : sample_data['deg_50C'].values[0][i],\n                       'deg_error_50C' : sample_data['deg_error_50C'].values[0][i]}\n        \n        \n        shifts = [1,2,3,4,5]\n        shift_cols = ['sequence', 'structure', 'predicted_loop_type']\n        for shift,col in itertools.product(shifts, shift_cols):\n            if i - shift >= 0:\n                sample_dict['b'+str(shift)+'_'+col] = sample_data[col].values[0][i-shift]\n            else:\n                sample_dict['b'+str(shift)+'_'+col] = -1\n            \n            if i + shift <= sample_seq_length - 1:\n                sample_dict['a'+str(shift)+'_'+col] = sample_data[col].values[0][i+shift]\n            else:\n                sample_dict['a'+str(shift)+'_'+col] = -1\n        \n        \n        train_data.append(sample_dict)\ntrain_data = pd.DataFrame(train_data)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The error value is small due to SN_filter processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"#maximum error value\nmax_reactivity_error = train_data['reactivity_error'].max()\nmax_deg_error_Mg_pH10 = train_data['deg_error_Mg_pH10'].max()\nmax_deg_error_pH10 = train_data['deg_error_pH10'].max()\nmax_deg_error_Mg_50C = train_data['deg_error_Mg_50C'].max()\nmax_deg_error_50C = train_data['deg_error_50C'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check Train_data2 (SN_filter <1) in the same way.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data2 = []\nfor mol_id in train2['id'].unique():\n    sample_data = train2.loc[train2['id'] == mol_id]\n    sample_seq_length = sample_data.seq_length.values[0]\n    \n    for i in range(68):\n        sample_dict = {'id' : sample_data['id'].values[0],\n                       'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                       'sequence' : sample_data['sequence'].values[0][i],\n                       'structure' : sample_data['structure'].values[0][i],\n                       'predicted_loop_type' : sample_data['predicted_loop_type'].values[0][i],\n                       'reactivity' : sample_data['reactivity'].values[0][i],\n                       'reactivity_error' : sample_data['reactivity_error'].values[0][i],\n                       'deg_Mg_pH10' : sample_data['deg_Mg_pH10'].values[0][i],\n                       'deg_error_Mg_pH10' : sample_data['deg_error_Mg_pH10'].values[0][i],\n                       'deg_pH10' : sample_data['deg_pH10'].values[0][i],\n                       'deg_error_pH10' : sample_data['deg_error_pH10'].values[0][i],\n                       'deg_Mg_50C' : sample_data['deg_Mg_50C'].values[0][i],\n                       'deg_error_Mg_50C' : sample_data['deg_error_Mg_50C'].values[0][i],\n                       'deg_50C' : sample_data['deg_50C'].values[0][i],\n                       'deg_error_50C' : sample_data['deg_error_50C'].values[0][i]}\n        \n        \n        shifts = [1,2,3,4,5]\n        shift_cols = ['sequence', 'structure', 'predicted_loop_type']\n        for shift,col in itertools.product(shifts, shift_cols):\n            if i - shift >= 0:\n                sample_dict['b'+str(shift)+'_'+col] = sample_data[col].values[0][i-shift]\n            else:\n                sample_dict['b'+str(shift)+'_'+col] = -1\n            \n            if i + shift <= sample_seq_length - 1:\n                sample_dict['a'+str(shift)+'_'+col] = sample_data[col].values[0][i+shift]\n            else:\n                sample_dict['a'+str(shift)+'_'+col] = -1\n        \n        \n        train_data2.append(sample_dict)\ntrain_data2 = pd.DataFrame(train_data2)\ntrain_data2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data2.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train_data2 has a very large error value. On the other hand, the error value of most data is small.  \nExclude large error values and extract data that may be useful for prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data2 = train_data2.query('reactivity_error <= @max_reactivity_error')\ntrain_data2 = train_data2.query('deg_error_Mg_pH10 <= @max_deg_error_Mg_pH10')\ntrain_data2 = train_data2.query('deg_error_pH10 <= @max_deg_error_pH10')\ntrain_data2 = train_data2.query('deg_error_Mg_50C <= @max_deg_error_Mg_50C')\ntrain_data2 = train_data2.query('deg_error_50C <= @max_deg_error_50C')\ntrain_data2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Combine to train_data.\ntrain_data = pd.concat([train_data, train_data2], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = []\nfor mol_id in test['id'].unique():\n    sample_data = test.loc[test['id'] == mol_id]\n    sample_seq_length = sample_data.seq_length.values[0]\n    for i in range(sample_seq_length):\n        sample_dict = {'id' : sample_data['id'].values[0],\n                       'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                       'sequence' : sample_data['sequence'].values[0][i],\n                       'structure' : sample_data['structure'].values[0][i],\n                       'predicted_loop_type' : sample_data['predicted_loop_type'].values[0][i]}\n        \n        shifts = [1,2,3,4,5]\n        shift_cols = ['sequence', 'structure', 'predicted_loop_type']\n        for shift,col in itertools.product(shifts, shift_cols):\n            if i - shift >= 0:\n                sample_dict['b'+str(shift)+'_'+col] = sample_data[col].values[0][i-shift]\n            else:\n                sample_dict['b'+str(shift)+'_'+col] = -1\n            \n            if i + shift <= sample_seq_length - 1:\n                sample_dict['a'+str(shift)+'_'+col] = sample_data[col].values[0][i+shift]\n            else:\n                sample_dict['a'+str(shift)+'_'+col] = -1\n        \n        test_data.append(sample_dict)\ntest_data = pd.DataFrame(test_data)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label_encoding\nsequence_encmap = {'A': 0, 'G' : 1, 'C' : 2, 'U' : 3}\nstructure_encmap = {'.' : 0, '(' : 1, ')' : 2}\nlooptype_encmap = {'S':0, 'E':1, 'H':2, 'I':3, 'X':4, 'M':5, 'B':6}\n\nenc_targets = ['sequence', 'structure', 'predicted_loop_type']\nenc_maps = [sequence_encmap, structure_encmap, looptype_encmap]\n\nfor t,m in zip(enc_targets, enc_maps):\n    for c in [c for c in train_data.columns if t in c]:\n        train_data[c] = train_data[c].replace(m)\n        test_data[c] = test_data[c].replace(m)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train & predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"not_use_cols = ['id', 'id_seqpos']\nfeatures = [c for c in test_data.columns if c not in not_use_cols]\ntargets = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLD_N = 5\ngkf = GroupKFold(n_splits=FOLD_N)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'objective': 'regression',\n          'boosting': 'gbdt',\n          'metric': 'rmse',\n          'learning_rate': 0.1,\n          'seed' : SEEDS}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances = pd.DataFrame()\nresult = {}\noof_df = pd.DataFrame(train_data.id_seqpos)\n\nfor target in targets:\n    oof = pd.DataFrame()\n    preds = np.zeros(len(test_data))\n    scores = 0.0\n    \n    for n, (tr_idx, vl_idx) in enumerate(gkf.split(train_data[features], train_data['reactivity'], train_data['id'])):\n        tr_x, tr_y = train_data[features].iloc[tr_idx], train_data[target].iloc[tr_idx]\n        vl_x, vl_y = train_data[features].iloc[vl_idx], train_data[target].iloc[vl_idx]\n        vl_id = train_data['id_seqpos'].iloc[vl_idx]\n\n        model = TreeModel(model_type='lgb')\n        model.train(params, tr_x, tr_y, vl_x, vl_y,\n                    num_round=20000, early_stopping=100,verbose=1000)\n\n        fi_tmp = pd.DataFrame()\n        fi_tmp['feature'] = model.feature_names_\n        fi_tmp['importance'] = model.feature_importances_\n        fi_tmp['fold'] = n\n        fi_tmp['target'] = target\n        feature_importances = feature_importances.append(fi_tmp)\n\n        vl_pred = model.predict(vl_x)\n        score = rmse(vl_y, vl_pred)\n        scores += score / FOLD_N\n        print(f'score : {score}')\n\n        oof = oof.append(pd.DataFrame({'id_seqpos':vl_id, target:vl_pred}))\n\n        pred = model.predict(test_data[features])\n        preds += pred / FOLD_N\n    \n    oof_df = oof_df.merge(oof, on='id_seqpos', how='inner')\n    submission[target] = preds\n    \n    print(f'{target}_rmse : {scores}')\n    result[target] = scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(result)\ndisplay(f'total : {np.mean(list(result.values()))}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature_importances\nfor target in targets:\n    tmp = feature_importances[feature_importances.target==target]\n    order = list(tmp.groupby('feature').mean().sort_values('importance', ascending=False).index)\n\n    plt.figure(figsize=(10, 5))\n    sns.barplot(x=\"importance\", y=\"feature\", data=tmp, order=order)\n    plt.title(target)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(oof_df.shape)\ndisplay(submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_df.to_csv('oof_df.csv', index=False)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}