{"cells":[{"metadata":{},"cell_type":"markdown","source":"This Notebook is Machine_Learning Project that develop a model to predict the degradation rates of RNA molecules on current mRNAvaccines against COVID-19.\n* We will first pre-process train data. \n* Then, we will use all train data to train a model. \n* Finally, we run our model on the public test set and get the error rate of our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **File Path**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"root_dir = '../input/stanford-covid-vaccine/'\naug_data_dir = '../input/how-to-generate-augmentation-data/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Parameter**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sequence_length = 107\npredicted_length = 68\nembed_dim = 100\nhidden_dim = 256\nn_layers = 2\n# tf.random.set_seed(2020)\n# np.random.seed(2020)\n# y_true = tf.random.normal((32, 68, 3))\n# y_pred = tf.random.normal((32, 68, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_columns = ['reactivity', 'deg_Mg_50C', 'deg_Mg_pH10', 'deg_pH10', 'deg_50C']\ninput_columns = ['sequence', 'structure', 'predicted_loop_type']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Several function for process data and build model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def aug_data(df, aug_df):\n    target_df = df.copy()\n    new_df = aug_df[aug_df['id'].isin(target_df['id'])]\n    \n    del target_df['structure']\n    del target_df['predicted_loop_type']\n    \n    new_df = new_df.merge(target_df, on=['id','sequence'], how='left')\n\n    df['cnt'] = df['id'].map(new_df[['id','cnt']].set_index('id').to_dict()['cnt'])\n    df['log_gamma'] = 100\n    df['score'] = 1.0\n    df = df.append(new_df[df.columns])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pandas_list_to_array(df):\n    \"\"\"\n    Input: dataframe of shape (x, y), containing list of length l\n    Return: np.array of shape (x, l, y)\n    \"\"\"\n    \n    return np.transpose(\n        np.array(df.values.tolist()),\n        (0, 2, 1)\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, token2int, cols):\n    return pandas_list_to_array(\n        df[cols].applymap(lambda seq: [token2int[x] for x in seq])\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Post_process(name, submission_df, public_df, public_preds, private_df, private_preds):\n    pred_list = []\n    def process(df, predictions):\n        for index, value in enumerate(df.id):\n            pred = predictions[index]\n            pre_df = pd.DataFrame(pred, columns=predict_columns)\n            pre_df['id_seqpos'] = [f'{value}_{number}' for number in range(pre_df.shape[0])]\n            pred_list.append(pre_df)\n    for df, predictions in [(public_df, public_preds), (private_df, private_preds)]:\n        process(df, predictions)\n    preds_df = pd.concat(pred_list).groupby('id_seqpos').mean().reset_index()\n    submission = submission_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n    submission.to_csv(name, index=False)\n    print('done')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE_func(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE_numpy(y_true, y_pred):\n    colwise_mse = np.mean(np.square(y_true - y_pred), axis=1)\n    return np.mean(np.sqrt(colwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Single_GRU(embed_size, sequence_length, predicted_length, embed_dim, hidden_dim, n_layers, dropout=0.5, sp_dropout=0.2,):\n    inputs = keras.layers.Input(shape=(sequence_length, 3))\n    embed = keras.layers.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    \n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n    )\n    hidden = keras.layers.SpatialDropout1D(sp_dropout)(reshaped)\n    \n#     for x in range(n_layers):\n#         hidden = keras.layers.TimeDistributed(keras.layers.Bidirectional(keras.layers.GRU(\n#             hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal')))(hidden)\n    for x in range(n_layers):\n        hidden = keras.layers.Bidirectional(keras.layers.GRU(\n            hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :predicted_length]\n    out = keras.layers.Dense(5, activation='linear')(truncated)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(tf.optimizers.Adam(), loss=MCRMSE_func)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Single_LSTM(embed_size, sequence_length, predicted_length, embed_dim, hidden_dim, n_layers, dropout=0.5, sp_dropout=0.2,):\n    inputs = keras.layers.Input(shape=(sequence_length, 3))\n    embed = keras.layers.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    \n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n    )\n    hidden = keras.layers.SpatialDropout1D(sp_dropout)(reshaped)\n    \n    for x in range(n_layers):\n        hidden = keras.layers.Bidirectional(keras.layers.LSTM(\n            hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :predicted_length]\n    out = keras.layers.Dense(5, activation='linear')(truncated)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(tf.optimizers.Adam(), loss=MCRMSE_func)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Conv_Lstm(embed_size, sequence_length, predicted_length, \n              embed_dim, hidden_dim, n_layers, dropout=0.5, sp_dropout=0.2):\n    inputs = keras.layers.Input(shape=(sequence_length, 3))\n    embed = keras.layers.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    \n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n    )\n    hidden = keras.layers.SpatialDropout1D(sp_dropout)(reshaped)\n    \n    for x in range(n_layers - 1):\n        hidden = keras.layers.Conv1D(\n            2 ** x * hidden_dim, kernel_size=3,padding='same',activation='relu', kernel_initializer='glorot_uniform')(hidden)\n        hidden = keras.layers.BatchNormalization()(hidden)\n#         hidden = keras.layers.MaxPool1D(2)(hidden)\n    for y in range(n_layers - 1):\n        hidden = keras.layers.Bidirectional(keras.layers.LSTM(\n            hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :predicted_length]\n    out = keras.layers.Dense(5, activation='linear')(truncated)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(tf.optimizers.Adam(), loss=MCRMSE_func)\n    \n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def GRU_Lstm(embed_size, sequence_length, predicted_length, \n              embed_dim, hidden_dim, n_layers, dropout=0.5, sp_dropout=0.2):\n    inputs = keras.layers.Input(shape=(sequence_length, 3))\n    embed = keras.layers.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    \n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n    )\n    hidden = keras.layers.SpatialDropout1D(sp_dropout)(reshaped)\n    \n    for x in range(n_layers - 1):\n        hidden = keras.layers.Bidirectional(keras.layers.GRU(\n            hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))(hidden)\n#         hidden = keras.layers.MaxPool1D(2)(hidden)\n    for y in range(n_layers - 1):\n        hidden = keras.layers.Bidirectional(keras.layers.LSTM(\n            hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :predicted_length]\n    out = keras.layers.Dense(5, activation='linear')(truncated)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(tf.optimizers.Adam(), loss=MCRMSE_func)\n    \n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgboost(estimator_number, learning_rate):\n    model = XGBRegressor(\n    max_depth=8,\n    n_estimators=estimator_number,\n    min_child_weight=300,\n    learning_rate=learning_rate,\n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def light_lgb(estimator_number, learning_rate):\n    model = lgb.LGBMRegressor(n_estimators=estimator_number,\n                            learning_rate=learning_rate,\n                            feature_fraction=0.8)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_fuc(model, X_train, y_train, X_val, y_val, func_type):\n    if func_type == 0:\n        model.fit(X_train, y_train,\n                  eval_set=(X_val, y_val),\n                  early_stopping_rounds=100,\n                  verbose=1000)\n    elif func_type == 1:\n        model.fit(\n        X_train, \n        y_train, \n        eval_metric=\"rmse\", \n        eval_set=[(X_train, y_train), (X_val, y_val)], \n        verbose=True, \n        early_stopping_rounds = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_process(model, name, columns, fit_func, func_type=0):\n    train = pd.read_json('../input/stanford-covid-vaccine/train.json',lines=True)\n    test = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\n    sample_df = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n    train['mean_reactivity'] = train['reactivity'].apply(lambda x: np.mean(x))\n    train['mean_deg_Mg_pH10'] = train['deg_Mg_pH10'].apply(lambda x: np.mean(x))\n    train['mean_deg_Mg_50C'] = train['deg_Mg_50C'].apply(lambda x: np.mean(x))\n    train['mean_deg_pH10'] = train['deg_pH10'].apply(lambda x: np.mean(x))\n    train['mean_deg_50C'] = train['deg_50C'].apply(lambda x: np.mean(x))\n    if func_type == 1:\n        for info in input_columns:\n            train[f'{name}_{info}'] = train[input_columns].applymap(lambda seq: [token2int[x] for x in seq])[info]\n            test[f'{name}_{info}'] = test[input_columns].applymap(lambda seq: [token2int[x] for x in seq])[info]\n\n        for n in range(107):\n            train[f'{name}_structure_{n}'] = train[f'{name}_structure'].apply(lambda x: x[n]).astype('int')\n            test[f'{name}_structure_{n}'] = test[f'{name}_structure'].apply(lambda x: x[n]).astype('int')\n            train[f'{name}_predicted_loop_type_{n}'] = train[f'{name}_predicted_loop_type'].apply(lambda x: x[n]).astype('int')\n            test[f'{name}_predicted_loop_type_{n}'] = test[f'{name}_predicted_loop_type'].apply(lambda x: x[n]).astype('int')\n            train[f'{name}_sequence_{n}'] = train[f'{name}_sequence'].apply(lambda x: x[n]).astype('int')\n            test[f'{name}_sequence_{n}'] = test[f'{name}_sequence'].apply(lambda x: x[n]).astype('int')\n    elif func_type == 0:\n        for n in range(107):\n            train[f'{name}_structure_{n}'] = train[f'structure'].apply(lambda x: x[n]).astype('category')\n            test[f'{name}_structure_{n}'] = test[f'structure'].apply(lambda x: x[n]).astype('category')\n            train[f'{name}_predicted_loop_type_{n}'] = train[f'predicted_loop_type'].apply(lambda x: x[n]).astype('category')\n            test[f'{name}_predicted_loop_type_{n}'] = test[f'predicted_loop_type'].apply(lambda x: x[n]).astype('category')\n            train[f'{name}_sequence_{n}'] = train[f'sequence'].apply(lambda x: x[n]).astype('category')\n            test[f'{name}_sequence_{n}'] = test[f'sequence'].apply(lambda x: x[n]).astype('category')\n\n    SEQUENCE_COLS = [c for c in train.columns if f'{name}_sequence_' in c]\n    STRUCTURE_COLS = [c for c in train.columns if f'{name}_structure_' in c]\n    PLT_COLS = [c for c in train.columns if f'{name}_predicted_loop_type_' in c]\n    \n    for target in predict_columns:\n        X = train[SEQUENCE_COLS + STRUCTURE_COLS + PLT_COLS]\n        y = train[f'mean_{target}']\n\n        X_test = test[SEQUENCE_COLS + STRUCTURE_COLS + PLT_COLS]\n\n        X_train, X_val, y_train, y_val = train_test_split(X, y)\n        fit_func(model, X_train, y_train, X_val, y_val, func_type)\n        test[f'mean_{target}_pred'] = model.predict(X_test)\n    sample_df['id'] = 'id_' + sample_df['id_seqpos'].str.split('_', expand=True)[1]\n\n            # Merge my predicted average values\n    ss_new = sample_df. \\\n            drop(predict_columns, axis=1) \\\n            .merge(test[['id',\n                        'mean_reactivity_pred',\n                        'mean_deg_Mg_pH10_pred',\n                        'mean_deg_Mg_50C_pred',\n                        'mean_deg_50C_pred',\n                        'mean_deg_pH10_pred']] \\\n                        .rename(columns={'mean_reactivity_pred' : 'reactivity',\n                                        'mean_deg_Mg_pH10_pred': 'deg_Mg_pH10',\n                                        'mean_deg_Mg_50C_pred' : 'deg_Mg_50C',\n                                        'mean_deg_50C_pred' : 'deg_50C',\n                                        'mean_deg_pH10_pred': 'deg_pH10'}\n                                ),\n                    on='id',\n                validate='m:1')\n    sample_df = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n    ss_new[sample_df.columns].to_csv(f'{name}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Read Original_data and augmental_data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"aug_df = pd.read_csv(aug_data_dir + 'aug_data.csv')\naug_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test  = pd.read_json(root_dir + \"test.json\", lines=True)\ntrain  = pd.read_json(root_dir + \"train.json\", lines=True)\ntrain = train.query(\"signal_to_noise >= 1\")\nsample_df = pd.read_csv(root_dir + 'sample_submission.csv')\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = aug_data(train, aug_df)\ntest = aug_data(test, aug_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\nlen(token2int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Several Inputs and labels**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train inputs and labels\ntrain_inputs = preprocess_inputs(train, token2int, input_columns)\ntrain_targets = pandas_list_to_array(train[predict_columns])\n\n#public test inputs and private test inputs\npublic_df = test.query(\"seq_length == 107\")\nprivate_df = test.query(\"seq_length == 130\")\n\npublic_inputs = preprocess_inputs(public_df, token2int, input_columns)\nprivate_inputs = preprocess_inputs(private_df, token2int, input_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Process training data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(train_inputs, train_targets, test_size=.1, random_state=7,\n                                                    stratify=train.SN_filter)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Deep Learning Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Single_GRU(embed_size=len(token2int), \n                    sequence_length=sequence_length, \n                    predicted_length=predicted_length,\n                    embed_dim=embed_dim,\n                    hidden_dim=hidden_dim,\n                    n_layers=n_layers)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train,validation_data=(x_test, y_test),\n                    batch_size=64,epochs=50,verbose=1,\n                    callbacks=[\n                            tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n                            tf.keras.callbacks.ModelCheckpoint('Project.h5')\n                    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curves(history, label, epochs, min_value, max_value):\n    data = {}\n    data[label] = history.history[label]\n    data['val_'+label] = history.history['val_'+label]\n    pd.DataFrame(history.history).plot(figsize=(8,5))\n    plt.grid(True)\n    plt.axis([0, epochs, min_value, max_value])\n    plt.show()\n\nplot_learning_curves(history, 'loss', 100, 0, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Predictions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"public_model = Single_GRU(embed_size=len(token2int), \n                           sequence_length=107, \n                           predicted_length=107,\n                           embed_dim=embed_dim,\n                           hidden_dim=hidden_dim,\n                           n_layers=n_layers)\nprivate_model = Single_GRU(embed_size=len(token2int), \n                           sequence_length=130, \n                           predicted_length=130,\n                           embed_dim=embed_dim,\n                           hidden_dim=hidden_dim,\n                           n_layers=n_layers)\n\npublic_model.load_weights('Project.h5')\nprivate_model.load_weights('Project.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_preds = public_model.predict(public_inputs)\nprivate_preds = private_model.predict(private_inputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Post_process"},{"metadata":{"trusted":true},"cell_type":"code","source":"Post_process('submission.csv', sample_df, public_df, public_preds, private_df, private_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# **LightGBM AND XGBOOST**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = light_lgb(1000, 0.005)\nmodel2 = xgboost(1000, 0.001)\nmodel_process(model1, 'lightlgb1', predict_columns, fit_fuc, 0)\nmodel_process(model2, 'xgboost', predict_columns, fit_fuc, 1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}