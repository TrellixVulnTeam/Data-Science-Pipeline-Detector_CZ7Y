{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pickle\nimport os\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport tensorflow.keras.layers as L\nimport tensorflow as tf\nimport plotly.express as px\nimport kerastuner as kt\nfrom kerastuner.tuners import RandomSearch\nfrom kerastuner import HyperModel\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs('/kaggle/tmp/', exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define helper functions and useful vars"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will tell us the columns we are predicting\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_trial_state(trial):\n    state = trial.get_state()\n    out = {}\n    out['best_step'] = state['best_step']\n    out['trial_id'] = state['trial_id']\n    out['score'] = state['score']\n    out.update(state['hyperparameters']['values'])\n    \n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class HyperGRU(HyperModel):\n\n    def __init__(self, embed_size, seq_len=107, pred_len=68):\n        self.embed_size = embed_size\n        self.seq_len = seq_len\n        self.pred_len = pred_len\n\n    def MCRMSE(self, y_true, y_pred):\n        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n\n    def gru_layer(self, hidden_dim, dropout):\n        return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True))\n    \n    def build(self, hp):\n        # Hyperparameters we will explore\n        lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n        dropout = hp.Choice('dropout', values=[0., 0.1, 0.25, 0.5])\n        embed_dim = hp.Int('embed_dim', min_value=50, max_value=150, step=25)\n        hidden_dim = hp.Int('hidden_dim', min_value=32, max_value=256, step=32)\n        n_layers = hp.Int('n_layers', 2, 3)\n        \n        inputs = L.Input(shape=(self.seq_len, 3))\n\n        embed = L.Embedding(input_dim=self.embed_size, output_dim=embed_dim)(inputs)\n        hidden = tf.reshape(\n            embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n        )\n        \n        for i in range(n_layers):\n            hidden = self.gru_layer(hidden_dim, dropout)(hidden)\n\n        # Since we are only making predictions on the first part of each sequence, we have\n        # to truncate it\n        truncated = hidden[:, :self.pred_len]\n\n        out = L.Dense(5, activation='linear')(truncated)\n\n        model = tf.keras.Model(inputs=inputs, outputs=out)\n\n        model.compile(tf.keras.optimizers.Adam(lr), loss=self.MCRMSE)\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, token2int, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load and preprocess data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_json('/kaggle/input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('/kaggle/input/stanford-covid-vaccine/test.json', lines=True)\nsample_df = pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = preprocess_inputs(train, token2int)\ntrain_labels = np.array(train[pred_cols].values.tolist()).transpose((0, 2, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is seed 34 a magic number? We shall find out\nx_train, x_val, y_train, y_val = train_test_split(\n    train_inputs, train_labels, test_size=.1, random_state=34\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build and train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"hypermodel = HyperGRU(embed_size=len(token2int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"tuner = kt.tuners.RandomSearch(\n    hypermodel,\n    objective='val_loss',\n    max_trials=35,\n    executions_per_trial=3,\n    seed=2020,\n    directory='/kaggle/tmp/',\n    project_name='open_vaccine'\n)\n\ntuner.search(\n    x_train, y_train,\n    batch_size=64,\n    epochs=100,\n    verbose=0,\n    validation_data=(x_val, y_val),\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=4),\n        tf.keras.callbacks.EarlyStopping(patience=8)\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unhide below to see all trials results:"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"trials_df = pd.DataFrame([\n    parse_trial_state(t) for t in tuner.oracle.trials.values()\n])\n\ntrials_df.to_csv('trials_table.csv', index=False)\n\ntrials_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best hyperparameter is:"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"best_hp = tuner.get_best_hyperparameters(1)[0]\nbest_hp.get_config()['values']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save model and best hyperparams"},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(best_hp, open('best_hp.pickle', 'wb'))\n\nbest_model = tuner.get_best_models(1)[0]\nbest_model.save('best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict on test set"},{"metadata":{},"cell_type":"markdown","source":"Public and private sets have different sequence lengths, so we will preprocess them separately and load models of different tensor shapes."},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\n\npublic_inputs = preprocess_inputs(public_df, token2int)\nprivate_inputs = preprocess_inputs(private_df, token2int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Caveat: The prediction format requires the output to be the same length as the input,\n# although it's not the case for the training data.\nmodel_short = HyperGRU(seq_len=107, pred_len=107, embed_size=len(token2int)).build(best_hp)\nmodel_long = HyperGRU(seq_len=130, pred_len=130, embed_size=len(token2int)).build(best_hp)\n\nmodel_short.load_weights('best_model.h5')\nmodel_long.load_weights('best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_preds = model_short.predict(public_inputs)\nprivate_preds = model_long.predict(private_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(public_preds.shape, private_preds.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Post-processing and submit"},{"metadata":{},"cell_type":"markdown","source":"For each sample, we take the predicted tensors of shape (107, 5) or (130, 5), and convert them to the long format (i.e. $629 \\times 107, 5$ or $3005 \\times 130, 5$):"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_ls = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}