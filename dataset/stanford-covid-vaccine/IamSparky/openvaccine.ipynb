{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchcontrib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport torch_xla\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.data_parallel as dp\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.utils.utils as xu\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_json ('../input/stanford-covid-vaccine/train.json', lines=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os.path\nfrom os import path\n\npath.exists(\"../input/stanford-covid-vaccine/bpps/id_724185d34.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_json ('../input/stanford-covid-vaccine/test.json', lines=True)\n\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['index'], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics\nround(statistics.mean(df.reactivity_error[0]) , 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['reactivity_error'] = df['reactivity_error'].apply(lambda x : round(statistics.mean(x) , 4))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['deg_error_Mg_pH10'] = df['deg_error_Mg_pH10'].apply(lambda x : round(statistics.mean(x) , 4))\ndf['deg_error_pH10'] = df['deg_error_pH10'].apply(lambda x : round(statistics.mean(x) , 4))\ndf['deg_error_Mg_50C'] = df['deg_error_Mg_50C'].apply(lambda x : round(statistics.mean(x) , 4))\ndf['deg_error_50C'] = df['deg_error_50C'].apply(lambda x : round(statistics.mean(x) , 4))\ndf['reactivity'] = df['reactivity'].apply(lambda x : round(statistics.mean(x) , 4))\ndf['deg_Mg_pH10'] = df['deg_Mg_pH10'].apply(lambda x : round(statistics.mean(x) , 4))\ndf['deg_pH10'] = df['deg_pH10'].apply(lambda x : round(statistics.mean(x) , 4))\ndf['deg_Mg_50C'] = df['deg_Mg_50C'].apply(lambda x : round(statistics.mean(x) , 4))\ndf['deg_50C'] = df['deg_50C'].apply(lambda x : round(statistics.mean(x) , 4))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sequence[0].count('G')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['G_in_sequence'] = df['sequence'].apply(lambda x : x.count('G'))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(\"\".join(list(df[\"predicted_loop_type\"])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['A_in_sequence'] = df['sequence'].apply(lambda x : x.count('A'))\ndf['U_in_sequence'] = df['sequence'].apply(lambda x : x.count('U'))\ndf['C_in_sequence'] = df['sequence'].apply(lambda x : x.count('C'))\n\ndf['._in_structure'] = df['structure'].apply(lambda x : x.count('.'))\ndf['(_in_structure'] = df['structure'].apply(lambda x : x.count('('))\ndf[')_in_structure'] = df['structure'].apply(lambda x : x.count(')'))\n\ndf['B_in_predicted_loop_type'] = df['predicted_loop_type'].apply(lambda x : x.count('B'))\ndf['E_in_predicted_loop_type'] = df['predicted_loop_type'].apply(lambda x : x.count('E'))\ndf['H_in_predicted_loop_type'] = df['predicted_loop_type'].apply(lambda x : x.count('H'))\ndf['I_in_predicted_loop_type'] = df['predicted_loop_type'].apply(lambda x : x.count('I'))\ndf['M_in_predicted_loop_type'] = df['predicted_loop_type'].apply(lambda x : x.count('M'))\ndf['S_in_predicted_loop_type'] = df['predicted_loop_type'].apply(lambda x : x.count('X'))\ndf['X_in_predicted_loop_type'] = df['predicted_loop_type'].apply(lambda x : x.count('S'))\n\ndf = df.drop(['sequence', 'structure', 'predicted_loop_type' , 'seq_length' , 'seq_scored'], axis=1)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colums_order = ['id','G_in_sequence','A_in_sequence', 'U_in_sequence', 'C_in_sequence',\n        '._in_structure','(_in_structure', ')_in_structure',\n        'B_in_predicted_loop_type','E_in_predicted_loop_type', 'H_in_predicted_loop_type',\n       'I_in_predicted_loop_type', 'M_in_predicted_loop_type',\n       'S_in_predicted_loop_type', 'X_in_predicted_loop_type',\n        'signal_to_noise', 'SN_filter', 'reactivity_error', 'deg_error_Mg_pH10',\n       'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C',\n        'reactivity','deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\ndf = df[colums_order]\n\nfor i in range(1,-5):\n    df[colums_order[i]] = df[colums_order[i]].apply(lambda x : round(float(x),4))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt\n\ndata = np.load('../input/stanford-covid-vaccine/bpps/id_0051b1d76.npy')\nprint(data.shape)\nplt.imshow(data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimg = np.load('../input/stanford-covid-vaccine/bpps/id_000ae4237.npy') # ../input/stanford-covid-vaccine/bpps/id_09be4ee60.npy\n        \nimg = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n\nprint(img.shape)\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset\nimport cv2\nimport torch\nfrom torchvision import transforms\nimport albumentations\nfrom PIL import Image\n\nclass openVaccine(Dataset):\n    def __init__(self, id , tabular , image, mean , std , is_valid):\n        self.id = id\n        self.tabular = tabular\n        self.image = image\n        self.is_valid = is_valid\n        if self.is_valid == 1: # transforms for validation images\n            self.aug = albumentations.Compose([\n               albumentations.Normalize(mean , std , always_apply = True) \n            ])\n        else:                  # transfoms for training images \n            self.aug = albumentations.Compose([\n                albumentations.Normalize(mean , std , always_apply = True),\n                albumentations.ShiftScaleRotate(shift_limit = 0.0625,\n                                                scale_limit = 0.1 ,\n                                                rotate_limit = 5,\n                                                p = 0.9)\n            ]) \n            \n            \n        self.reactivity = tabular.reactivity.values\n        self.deg_Mg_pH10 = tabular.deg_Mg_pH10.values\n        self.deg_pH10 = tabular.deg_pH10.values\n        self.deg_Mg_50C = tabular.deg_Mg_50C.values\n        self.deg_50C = tabular.deg_50C.values\n        \n    def __len__(self):\n        return len(self.id)\n    \n    def __getitem__(self, index):\n        id = self.id[index]\n        \n        # converting jpg format of images to numpy array\n        img = np.load('../input/stanford-covid-vaccine/bpps/'+ self.image[index] +'.npy') \n        \n        img = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n        img = Image.fromarray(img).convert('RGB')\n        img = self.aug(image = np.array(img))['image']\n        img = np.transpose(img, (2,0,1)).astype(np.float32) # 2,0,1 because pytorch excepts image channel first then dimension of image\n        \n        tabular = self.tabular.iloc[:,:]\n        \n        X = tabular[['G_in_sequence','A_in_sequence', 'U_in_sequence', 'C_in_sequence',\n                     '._in_structure','(_in_structure', ')_in_structure',\n                     'B_in_predicted_loop_type','E_in_predicted_loop_type', 'H_in_predicted_loop_type','I_in_predicted_loop_type', 'M_in_predicted_loop_type','S_in_predicted_loop_type', 'X_in_predicted_loop_type',\n                     'signal_to_noise', 'SN_filter', \n                     'reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C']]\n        X = X.values[index]\n        \n       \n        return {\n            'image' : torch.tensor(img, dtype = torch.long) , \n            'tabular_data' : torch.tensor(X, dtype = torch.float) , \n            'reactivity_output' : torch.tensor(self.reactivity[index], dtype = torch.float), \n            'deg_Mg_pH10_output' : torch.tensor(self.deg_Mg_pH10[index], dtype = torch.float), \n            'deg_pH10_output' : torch.tensor(self.deg_pH10[index], dtype = torch.float),  \n            'deg_Mg_50C_output' : torch.tensor(self.deg_Mg_50C[index], dtype = torch.float),  \n            'deg_50C_output' : torch.tensor(self.deg_50C[index], dtype = torch.float)\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the data into train and test set\nfrom sklearn import model_selection\ndf_train, df_valid = model_selection.train_test_split(df, test_size=0.3, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.reset_index(drop = True)\ndf_valid = df_valid.reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare transforms standard to MNIST\ntrain_data = openVaccine(id = [i for i in range(len(df_train))], \n                         tabular = df_train, \n                         image = df_train['id'],  \n                         mean = (0.485, 0.456, 0.406),\n                         std = (0.229, 0.224, 0.225) , is_valid = 0)\n\nval_data = openVaccine(id = [i for i in range(len(df_valid))], \n                       tabular = df_valid, \n                       image = df_valid['id'],  \n                       mean = (0.485, 0.456, 0.406),\n                       std = (0.229, 0.224, 0.225) , is_valid = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dry run \nidx = 100 # taking validation data index for 100th image out of 51000 images\n\nimg = val_data[idx][\"image\"]\nplt.imshow(np.transpose(img, (1,2,0)))\nprint(val_data[idx][\"tabular_data\"])\nprint(val_data[idx][\"reactivity_output\"])\nprint(val_data[idx][\"deg_Mg_pH10_output\"])\nprint(val_data[idx][\"deg_pH10_output\"])\nprint(val_data[idx][\"deg_Mg_50C_output\"])\nprint(val_data[idx][\"deg_50C_output\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sampler = torch.utils.data.distributed.DistributedSampler(\n          train_data,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=True)\n\nvalid_sampler = torch.utils.data.distributed.DistributedSampler(\n          val_data,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_BATCH_SIZE = 32\n\nfrom torch.utils.data import DataLoader\n\ntraining_dataloader = DataLoader(train_data,\n                        num_workers=4,\n                        batch_size=TRAIN_BATCH_SIZE,\n                        sampler=train_sampler,\n                        drop_last=True\n                       )\n\nval_dataloader = DataLoader(val_data,\n                        num_workers=4,\n                        batch_size=TRAIN_BATCH_SIZE,\n                        sampler=valid_sampler,\n                        drop_last=False\n                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = xm.xla_device()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch\n\nimport efficientnet_pytorch\n\nmodel = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# increasing few layers in our model\nclass EfficientNet_b0(nn.Module):\n    def __init__(self):\n        super(EfficientNet_b0, self).__init__()\n        self.model = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b0')\n        \n        self.image_dense_layer_1 = nn.Linear(1280 , 512)\n        self.relu = nn.ReLU()\n        self.batchnorm = nn.BatchNorm1d(512)\n        self.dropout = nn.Dropout2d(0.5)\n        self.image_dense_layer_2 = nn.Linear(512, 1)\n        \n        self.tabular_dense_layer_1 = nn.Linear(21, 16)\n        self.tabular_dense_layer_2 = nn.Linear(16, 8)\n        self.tabular_dense_layer_3 = nn.Linear(8, 4)\n        self.tabular_dense_layer_4 = nn.Linear(4, 1)\n        \n        self.reactivity_layer = nn.Linear(2 , 1)\n        self.deg_Mg_pH10_layer = nn.Linear(2 , 1)\n        self.deg_pH10_layer = nn.Linear(2 , 1)\n        self.deg_Mg_50C_layer = nn.Linear(2 , 1)\n        self.deg_50C_layer = nn.Linear(2 , 1)\n        \n        \n    def forward(self, image_inputs , tabular_data_inputs):\n        x = self.model.extract_features(image_inputs)\n\n        # Pooling and final linear layer\n        x = self.model._avg_pooling(x)\n        x = x.flatten(start_dim=1)\n        x = self.model._dropout(x)\n        \n        x = self.image_dense_layer_1(x)\n        x = self.relu(x)\n        x = self.batchnorm(x)\n        x = self.dropout(x)\n        x = self.image_dense_layer_2(x)\n        x = self.relu(x)\n        \n        tab = self.tabular_dense_layer_1(tabular_data_inputs)\n        tab = self.relu(tab)\n        tab = self.tabular_dense_layer_2(tab)\n        tab = self.relu(tab)\n        tab = self.tabular_dense_layer_3(tab)\n        tab = self.relu(tab)\n        tab = self.tabular_dense_layer_4(tab)\n        tab = self.relu(tab)\n        \n        x = torch.cat((x, tab), dim=1)\n        x = self.relu(x)\n\n        return self.reactivity_layer(x) , self.deg_Mg_pH10_layer(x) , self.deg_pH10_layer(x), self.deg_Mg_50C_layer(x) , self.deg_50C_layer(x)\n    \nmodel = EfficientNet_b0()\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(predicted , actual):\n    predicted_reactivity , predicted_deg_Mg_pH10 ,predicted_deg_pH10 , predicted_deg_Mg_50C , predicted_deg_50C = predicted \n    actual_reactivity , actual_deg_Mg_pH10 ,actual_deg_pH10 , actual_deg_Mg_50C , actual_deg_50C = actual\n    \n    reactivity_loss = torch.nn.MSELoss()(predicted_reactivity , actual_reactivity)\n    deg_Mg_pH10_loss = torch.nn.MSELoss()(predicted_deg_Mg_pH10 , actual_deg_Mg_pH10)\n    deg_pH10_loss = torch.nn.MSELoss()(predicted_deg_pH10 , actual_deg_pH10)\n    deg_Mg_50C_loss = torch.nn.MSELoss()(predicted_deg_Mg_50C , actual_deg_Mg_50C)\n    deg_50C_loss = torch.nn.MSELoss()(predicted_deg_50C , actual_deg_50C)\n    \n    return (reactivity_loss + deg_Mg_pH10_loss + deg_pH10_loss + deg_Mg_50C_loss + deg_50C_loss)/ 5\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for Stochastic Weight Averaging in PyTorch\nfrom torchcontrib.optim import SWA\n\nEPOCHS = 25\nnum_train_steps = int(len(train_data) / TRAIN_BATCH_SIZE / xm.xrt_world_size() * EPOCHS)\n\n# printing the no of training steps for each epoch of our training dataloader  \nxm.master_print(f'num_train_steps = {num_train_steps}, world_size={xm.xrt_world_size()}')\n\nparams = list(model.image_dense_layer_1.parameters()) + \\\n         list(model.image_dense_layer_2.parameters()) + \\\n         list(model.tabular_dense_layer_1.parameters()) + \\\n         list(model.tabular_dense_layer_2.parameters()) + \\\n         list(model.tabular_dense_layer_3.parameters()) + \\\n         list(model.tabular_dense_layer_4.parameters()) + \\\n         list(model.reactivity_layer.parameters()) + \\\n         list(model.deg_Mg_pH10_layer.parameters()) + \\\n         list(model.deg_pH10_layer.parameters()) + \\\n         list(model.deg_Mg_50C_layer.parameters()) + \\\n         list(model.deg_50C_layer.parameters())\n\nbase_optimizer = torch.optim.Adam(params, lr=1e-4* xm.xrt_world_size())\n\noptimizer = SWA(base_optimizer, swa_start=5, swa_freq=5, swa_lr=0.05)\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining the training loop\ndef train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n    running_loss = 0.0\n    model.train()\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        reactivity_output = dataset[\"reactivity_output\"]\n        deg_Mg_pH10_output = dataset[\"deg_Mg_pH10_output\"]\n        deg_pH10_output = dataset[\"deg_pH10_output\"]\n        deg_Mg_50C_output = dataset[\"deg_Mg_50C_output\"]\n        deg_50C_output = dataset[\"deg_50C_output\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        reactivity_output = reactivity_output.to(device, dtype=torch.float)\n        deg_Mg_pH10_output = deg_Mg_pH10_output.to(device, dtype=torch.float)\n        deg_pH10_output = deg_pH10_output.to(device, dtype=torch.float)\n        deg_Mg_50C_output = deg_Mg_50C_output.to(device, dtype=torch.float)\n        deg_50C_output = deg_50C_output.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n\n        outputs = model(image, tabular_data)\n        targets = (reactivity_output , deg_Mg_pH10_output , deg_pH10_output , deg_Mg_50C_output , deg_50C_output)\n        loss = loss_fn(outputs , targets)\n\n        loss.backward()\n        xm.optimizer_step(optimizer)\n\n        running_loss += loss.item()\n\n    if scheduler is not None:\n        scheduler.step()\n            \n    train_loss = running_loss / float(len(train_data))\n    xm.master_print('training Loss: {:.4f}'.format(train_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_loop_fn(data_loader, model, device):\n    running_loss = 0.0\n    model.eval()\n    \n    for batch_index,dataset in enumerate(data_loader):\n        image = dataset[\"image\"]\n        tabular_data = dataset[\"tabular_data\"]\n        reactivity_output = dataset[\"reactivity_output\"]\n        deg_Mg_pH10_output = dataset[\"deg_Mg_pH10_output\"]\n        deg_pH10_output = dataset[\"deg_pH10_output\"]\n        deg_Mg_50C_output = dataset[\"deg_Mg_50C_output\"]\n        deg_50C_output = dataset[\"deg_50C_output\"]\n        \n        image = image.to(device, dtype=torch.float)\n        tabular_data = tabular_data.to(device, dtype=torch.float)\n        reactivity_output = reactivity_output.to(device, dtype=torch.float)\n        deg_Mg_pH10_output = deg_Mg_pH10_output.to(device, dtype=torch.float)\n        deg_pH10_output = deg_pH10_output.to(device, dtype=torch.float)\n        deg_Mg_50C_output = deg_Mg_50C_output.to(device, dtype=torch.float)\n        deg_50C_output = deg_50C_output.to(device, dtype=torch.float)\n        \n\n        outputs = model(image, tabular_data)\n        targets = (reactivity_output , deg_Mg_pH10_output , deg_pH10_output , deg_Mg_50C_output , deg_50C_output)\n        loss = loss_fn(outputs , targets)\n\n        running_loss += loss.item()\n    \n    valid_loss = running_loss / float(len(val_data))\n    xm.master_print('validation Loss: {:.4f}'.format(valid_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _run():\n    for param in model.parameters():\n        param.requires_grad = False\n    \n    for param in params:\n        param.requires_grad = True\n    \n    for epoch in range(EPOCHS):\n        xm.master_print(f\"Epoch --> {epoch+1} / {EPOCHS}\")\n        xm.master_print(f\"-------------------------------\")\n        para_loader = pl.ParallelLoader(training_dataloader, [device])\n        train_loop_fn(para_loader.per_device_loader(device), model, optimizer, device, scheduler=scheduler)\n\n        para_loader = pl.ParallelLoader(val_dataloader, [device])\n        eval_loop_fn(para_loader.per_device_loader(device), model, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _mp_fn(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    a = _run()\n    optimizer.swap_swa_sgd()\n    \n# applying multiprocessing so that images get paralley trained in different cores of kaggle-tpu\nFLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=1, start_method='fork')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}