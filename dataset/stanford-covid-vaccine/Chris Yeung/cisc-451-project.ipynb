{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport itertools\nimport tensorflow.keras.layers as L\nimport tensorflow as tf\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom tensorboard.plugins.hparams import api as hp\n%load_ext tensorboard\n# clear previous logs\n# !rm -rf ./logs/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load data\ndata_dir = '/kaggle/input/stanford-covid-vaccine/'\ndata = pd.read_json(data_dir + 'train.json', lines=True)\ntest = pd.read_json(data_dir + 'test.json', lines=True)\nsample_sub = pd.read_csv(data_dir + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\nif ~data.isnull().values.any():\n    print(\"No missing values.\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Signal-to-noise and SN filter columns useful for incorporating the quality of the samples\nfig, ax = plt.subplots(1, 2, figsize=(15, 5))\nsns.kdeplot(data['signal_to_noise'], shade=True, ax=ax[0])\nsns.countplot(data['SN_filter'], ax=ax[1])\n\nax[0].set_title('Signal/Noise Distribution')\nax[1].set_title('Signal/Noise Filter Distribution');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pre-Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensure reproducibility\ntf.random.set_seed(2020)\nnp.random.seed(2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction columns\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert dataframe to a numpy array\ndef df_to_array(df):\n    return np.transpose(np.array(df.values.tolist()), (0, 2, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change letter variables to numeric\ndef preprocess(df, token2int, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return df_to_array(df[cols].applymap(lambda seq: [token2int[x] for x in seq]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dictionary of integer values for sequence, structure, and loop type\ntoken2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into training and test sets\ntrain, test = train_test_split(data, test_size=0.2, random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocess the training data\ntrain = train.query(\"signal_to_noise >= 1\")\ntrain_input = preprocess(train, token2int)\ntrain_pred = df_to_array(train[pred_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into training and validation sets\nx_train, x_val, y_train, y_val = train_test_split(train_input, train_pred, test_size=.1, random_state=34, stratify=train.SN_filter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process test set\ntest_input = preprocess(test, token2int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation metric\ndef MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(\n        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(embed_size, seq_len=107, pred_len=68, dropout=0.5, \n                sp_dropout=0.2, embed_dim=200, hidden_dim=256, n_layers=3):\n    inputs = L.Input(shape=(seq_len, 3))\n    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n    \n    for x in range(n_layers):\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :pred_len]\n    out = L.Dense(5, activation=\"linear\")(truncated)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(tf.optimizers.Adam(), loss=MCRMSE)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build GRU model\nmodel = build_model(embed_size=len(token2int), dropout=0.2, sp_dropout=0.5, n_layers=5)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nhistory = model.fit(\n    x_train, y_train,\n    validation_data=(x_val, y_val),\n    batch_size=64,\n    epochs=75,\n    verbose=2,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5')\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot training and validation loss\nfig = px.line(\n    history.history, y=['loss', 'val_loss'],\n    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n    title='Training History')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\ntest_pred = model.predict(test_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print score\ntest_true = df_to_array(test[pred_cols])\nprint(tf.reduce_mean(MCRMSE(test_true, test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# modify model building for hyperparameter tuning\ndef train_test_model(hparams, embed_size, test_input=test_input, test_target=test[pred_cols], seq_len=107,\n                     pred_len=68, dropout=0.5, sp_dropout=0.2, embed_dim=200, hidden_dim=256, n_layers=3, \n                     x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val):\n    inputs = L.Input(shape=(seq_len, 3))\n    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    hidden = L.SpatialDropout1D(hparams[HP_SP_DROPOUT])(reshaped)\n    \n    for x in range(hparams[HP_NUM_LAYERS]):\n        hidden = gru_layer(hidden_dim, hparams[HP_DROPOUT])(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :pred_len]\n    out = L.Dense(5, activation=\"linear\")(truncated)\n        \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(hparams[HP_OPTIMIZER], loss=MCRMSE)\n    \n    model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=25)\n    test_pred = model.predict(test_input)\n    test_true = df_to_array(test[pred_cols])\n    mcrmse = tf.reduce_mean(MCRMSE(test_true, test_pred))\n    return mcrmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# run model and create log\ndef run(run_dir, hparams):\n    with tf.summary.create_file_writer(run_dir).as_default():\n        hp.hparams(hparams)  # record the values used in this trial\n        accuracy = train_test_model(hparams, embed_size=len(token2int))\n        tf.summary.scalar(\"MCRMSE\", accuracy, step=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters to tune for grid search\nHP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.5))\nHP_SP_DROPOUT = hp.HParam('sp_dropout', hp.RealInterval(0.1, 0.5))\nHP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', \"rmsprop\"]))\nHP_NUM_LAYERS = hp.HParam('n_layers', hp.Discrete([2, 5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid search\n# session_num = 0\n# for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n#     for optimizer in HP_OPTIMIZER.domain.values:\n#         for sp_dropout_rate in (HP_SP_DROPOUT.domain.min_value, HP_SP_DROPOUT.domain.max_value):\n#             for num_layer in HP_NUM_LAYERS.domain.values:\n#                 hparams = {\n#                     HP_DROPOUT: dropout_rate,\n#                     HP_OPTIMIZER: optimizer,\n#                     HP_SP_DROPOUT: sp_dropout_rate,\n#                     HP_NUM_LAYERS: num_layer,\n#                 }\n#                 run_name = \"grid_run-%d\" % session_num\n#                 print('--- Starting trial: %s' % run_name)\n#                 print({h.name: hparams[h] for h in hparams})\n#                 run('logs/hparam_tuning/' + run_name, hparams)\n#                 session_num += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters to tune for random search\nHP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1, 0.2, 0.3, 0.4, 0.5]))\nHP_SP_DROPOUT = hp.HParam('sp_dropout', hp.Discrete([0.1, 0.2, 0.3, 0.4, 0.5]))\nHP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', \"rmsprop\"]))\nHP_NUM_LAYERS = hp.HParam('n_layers', hp.Discrete([2, 3, 4, 5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random search hyperparameter space 10 times\n# for i in range(10):\n#     hparams = {\n#         HP_DROPOUT: HP_DROPOUT.domain.sample_uniform(),\n#         HP_OPTIMIZER: HP_OPTIMIZER.domain.sample_uniform(),\n#         HP_SP_DROPOUT: HP_SP_DROPOUT.domain.sample_uniform(),\n#         HP_NUM_LAYERS: HP_NUM_LAYERS.domain.sample_uniform(),\n#     }\n#     run_name = \"random_run-%d\" % i\n#     print('--- Starting trial: %s' % run_name)\n#     print({h.name: hparams[h] for h in hparams})\n#     run('logs/hparam_tuning/' + run_name, hparams)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view tuning logs\n# %tensorboard --logdir='logs\\hparam_tuning'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build GRU model with new hyperparameters\nfinal_model = build_model(embed_size=len(token2int), dropout=0.2, sp_dropout=0.1, n_layers=4)\nfinal_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train new model\nfinal_history = final_model.fit(\n    x_train, y_train,\n    validation_data=(x_val, y_val),\n    batch_size=64,\n    epochs=75,\n    verbose=2,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5')\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make new loss plot\nfig = px.line(\n    final_history.history, y=['loss', 'val_loss'],\n    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n    title='Training History')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\ntest_pred = final_model.predict(test_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_true = df_to_array(test[pred_cols])\nprint(tf.reduce_mean(MCRMSE(test_true, test_pred)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}