{"cells":[{"metadata":{},"cell_type":"markdown","source":"Initial data exploration & some preparation of it in order to start getting ready to feed some models :)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport collections\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path = Path('../input/stanford-covid-vaccine')\nos.listdir(input_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_json(input_path/'train.json', lines=True)\ntest_df = pd.read_json(input_path/'test.json', lines=True)\nsample_sub = pd.read_csv(input_path/'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we are attempting to predict the degredation (& reactivity) at EVERY point in the sequence.\n\nWhile we're required to predict these 5 values, only three contribute to the score:<br>\n1) **Reactivity**: reactivty values for the first 68 bases as denoted in sequence -- used to determine the likely structure of the RNA sample <br>\n\n2) **deg_Mg_pH10**:used to determine the likelihood of degredation at the base/linkage in question, after incubating with megnesium in high pH (pH10)\n\n3) **deg_Mg_50c**:used to determine the likelihood of degredation at the base/linkage in question, after incubating with megnesium at a high temperature (50 degrees celcius)\n--> that's 120+ degrees in fahrenheit, why is this being used as a metric when the competition mentions a concern about degredation during shipment, shouldn't we be concerned with a lower temperature point that could be more representative? "},{"metadata":{"trusted":true},"cell_type":"code","source":"#we're getting alot of information in addition to this though\nlist(train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, test_df.shape, sample_sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#way lower than length of submission file bc it features rows that\n#are not present and are meant to be ignored (idk why included)\n3634*107 #num test samples * num of basepairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of positions used in scoring -- \ntrain_df['seq_scored'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#length of sequence -- same for all test samples\ntrain_df['seq_length'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all of the sequences have 107 basepairs (characters)\nlen(train_df['sequence'][0]), train_df['sequence'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of nucleotides in first training sample\ncollections.Counter(train_df['sequence'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['structure'][0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The structure is interesting, it describes whether a base is estimated to be paired or unpaired. Paired bases are denoted by opening and closing parenthesis <br>\n(....)<br>\nThis means that base 0 is paired with base 5 and bases 1-4 are unpaired\n\nWhat the heck does that mean??"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sequence = train_df.iloc[0]['sequence']\nsample_structure = train_df.iloc[0]['structure']\nsample_sequence, sample_structure","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Copy and paste those two lines into the following: http://rna.tbi.univie.ac.at/forna/ <br>\n\nWhat you'll see is a visualization of this RNA sequences secondary structure(!) "},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sequence[98:], sample_structure[70:80]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The samples within this sample mRNA that were selected in previous cell are to show that the visual represntation maps onto what's shown in the data. The last few base pairs around 100 seem to match up and the region between 70 and 80 in the structure shows a bunch of base pairs being paired with one another -- which is confirmed by the snippet"},{"metadata":{},"cell_type":"markdown","source":"So in the training data we are given reactivity and degredation values for the first 68 base pairs and then we are asked to predict values for 107 base pairs. Does it make sense that the first 68 base pairs will be able to provide that much useful insight into the nearly 40 base pairs afterwards? Couldn't it be the case that there's some crazy folding going on later in the sequence? Could you argue that the first 68 base pairs represent a scaffolding for the rest of the molecule? Ehhh, how does the direction of this get determined and is it the same always? "},{"metadata":{"trusted":true},"cell_type":"code","source":"#the number of positions used in scoring with predicted values\ntest_df['seq_scored'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's the test set -- the reason there is a difference is because in the private test set, you are predicting on 91 positions vs 68 in the public test and training sets\n\nThere's more information like *_error_* and degredation values in different conditions, but these are not given in the test data, so we will not consider them right now.\n\nThere's also a whole folder \"bpps\" with numpy arrays representing matrices of base pair probilities... (https://www.kaggle.com/c/stanford-covid-vaccine/discussion/182021) -- some people have been representing them visually, which is a cool idea -- we could feed this visual representation of the data into a model(!) But that's for another time"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The predicted loop type is a 107 character string that describes the structural context of each character in the sequence.<br>\n(S): Paired Stem <br>\n(M): Multiloop <br>\n(I): Internal Loop <br>\n(B): Bulge <br>\n(H): Hairpin Loop<br>\n(E): Dangling End <br>\n(X): external loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['predicted_loop_type'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Loop types for single sequence of mRNA')\nplt.hist(np.array(list(train_df['predicted_loop_type'][0])));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's a big range of values in degredation across the conditions"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = train_df.iloc[0]\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(np.array(sample['deg_Mg_50C']) > np.array(sample['deg_50C'])).sum() / len(sample['deg_50C'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Under a third of the base pairs in this sequence have a higher degredation value in the 50 degrees celcius AND magnesium condition vs the 50 degree celcius condition -- does that make sense?\n\nhttps://pubmed.ncbi.nlm.nih.gov/10488562/ -- uhh??"},{"metadata":{"trusted":true},"cell_type":"code","source":"(np.array(sample['deg_error_Mg_pH10']) / np.array(sample['deg_error_pH10'])).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The errors in the magnesium condition are 88% bigger than the condition with out it\n\nWe'll come back and explore this more in the coming days"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, train_df['reactivity'].shape, len(train_df['reactivity'][0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So in the training data - we have 2,400 sequence samples - each of these samples has their own reactivity information. Inside of this is a list of values (68) that represent the reactivity of the first 68 base pairs (each get's it's own value).\n\nHow are we going  to map this data into a way to feed our models?\n\nThe pandas explode fxn seems promising! (https://www.kaggle.com/c/stanford-covid-vaccine/discussion/182118) -- although we need to see it's impact on ordering as mentioned in comments.\n\nLet's try something a bit uglier by hand :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#reminder of the columns in our training, test and submission dataframes\nlist(train_df.columns), list(test_df.columns), list(sample_sub.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's reformat the data into the way we need it -- each sequence has X basepairs -- come up with something without looking up an easy solution!"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_sample = train_df.iloc[0]\nsequence = list(one_sample['sequence'])[0:68]\nreactivity = one_sample['reactivity']\ndeg_50C = one_sample['deg_50C']\nsample_df = pd.DataFrame([sequence, reactivity, deg_50C]).T\nsample_df.columns= ['basepair', 'reactivity', 'deg_50C']\nsample_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to relabel each basepair to have a sequence position value which is done like below"},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_pos = []\nfor x in range(68):\n    seq_pos.append(one_sample['id'] + '_' + str(x))\nseq_pos[0:4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok now that we know this works -- let's wrap it up into a fxn\n\nSo we want a df with the columns in the test df which represent our independent variables and the columns in our sample submission file which represent our dependent variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_sample(sample):\n    seq_pos = []\n    for x in range(68):\n        seq_pos.append(sample['id'] + '_' + str(x))\n    sequence = list(sample['sequence'])[0:68]\n    structure = list(sample['structure'])[0:68]\n    predicted_loop_type = list(sample['predicted_loop_type'])[0:68]\n    reactivity = sample['reactivity']\n    deg_Mg_pH10 = sample['deg_Mg_pH10']\n    deg_pH10 = sample['deg_pH10']\n    deg_Mg_50C = sample['deg_Mg_50C']\n    deg_50C = sample['deg_50C']\n    sample_df = pd.DataFrame([seq_pos, sequence, structure,\n                               predicted_loop_type, reactivity,\n                              deg_Mg_pH10, deg_pH10, deg_Mg_50C,\n                              deg_50C]).T\n    sample_df.columns= ['seq_pos', 'basepair', 'structure',\n                        'predicted_loop_type', 'reactivity', \n                        'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C',\n                        'deg_50C']\n                       \n    return sample_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"extract_sample(one_sample)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That was probably more roundabout than needed, but whatever(!)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntraining_data = pd.DataFrame()\nfor x in range(0, train_df.shape[0]):\n    df = extract_sample(train_df.iloc[x])\n    training_data = training_data.append(df).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reformatting the data into a pandas dataframe in this way will make it easier to analyze the data, but we're still missing some columns that will need to be added next time :)\\\n\nOne minute to do that wasn't terrible -- but if this was a bigger dataset, that way of going about things is probably too hamfisted"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}