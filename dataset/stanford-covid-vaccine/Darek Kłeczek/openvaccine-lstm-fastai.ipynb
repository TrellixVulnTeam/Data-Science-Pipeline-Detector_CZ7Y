{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Open Vaccine Fastai RNN"},{"metadata":{},"cell_type":"markdown","source":"I will use this notebook to experiment with various RNN approaches to Open Vaccine competition using fastai library. To read more about RNN with fastai, read this: https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb"},{"metadata":{},"cell_type":"markdown","source":"## All updates:\n- FIX: predict for 130-long sequences in test\n- Visualize predictions\n- loss function (from xhlulu)\n- FIX: kernel now running on GPU! (thanks to fast.ai forums, especially Satyabrata Pal and Zach Mueller!)\n- some hyperparameter tuning...\n- improved inference time with pandas explode\n- add bpps feature (from tito)\n- k-fold validation and ensemble\n- hyperparam tuning\n    - epochs count\n    - batch size\n    - learning rates\n    - embedding / hidden sizes / n-layers\n    - dropout"},{"metadata":{},"cell_type":"markdown","source":"# Imports, installs, reading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html -q\n!pip install fastai==2.0.13 -q","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from fastai.text.all import *\nimport pandas as pd\nimport numpy as np\nfrom tqdm.autonotebook import tqdm\nfrom torch import nn\nfrom sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '/kaggle/input/stanford-covid-vaccine'\ntrain = pd.read_json(f'{path}/train.json',lines=True)\ntest = pd.read_json(f'{path}/test.json', lines=True)\nsub = pd.read_csv(f'{path}/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, train['id'].nunique(), test.shape, sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# BPPS features from: https://www.kaggle.com/its7171/gru-lstm-with-feature-engineering-and-augmentation\n\ndef read_bpps_sum(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").sum(axis=1))\n    return bpps_arr\n\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ndef read_bpps_nb(df):\n    # normalized non-zero number\n    # from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n    bpps_nb_mean = 0.077522 # mean of bpps_nb across all training data\n    bpps_nb_std = 0.08914   # std of bpps_nb across all training data\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\")\n        bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n        bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n        bpps_arr.append(bpps_nb)\n    return bpps_arr \n\ntrain['bpps_sum'] = read_bpps_sum(train)\ntest['bpps_sum'] = read_bpps_sum(test)\ntrain['bpps_max'] = read_bpps_max(train)\ntest['bpps_max'] = read_bpps_max(test)\ntrain['bpps_nb'] = read_bpps_nb(train)\ntest['bpps_nb'] = read_bpps_nb(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sample(frac=1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing the data for RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"all1 = []\nall2 = []\nall3 = []\nfor i in range(len(train)):\n    all1.extend(train['sequence'].loc[i])\n    all2.extend(train['structure'].loc[i])\n    all3.extend(train['predicted_loop_type'].loc[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all1 = L(all1)\nall2 = L(all2)\nall3 = L(all3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab1 = all1.unique()\nvocab2 = all2.unique()\nvocab3 = all3.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2idx1 = {w:i for i,w in enumerate(vocab1)}\nword2idx2 = {w:i for i,w in enumerate(vocab2)}\nword2idx3 = {w:i for i,w in enumerate(vocab3)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def joiner(row):\n    l1 =  list(row[0])\n    l2 =  list(row[1])\n    l3 =  list(row[2])\n    l4 =  list(row[3])\n    l5 =  list(row[4])\n    l6 =  list(row[5])\n    out = [[word2idx1[l1[i]], word2idx2[l2[i]], word2idx3[l3[i]], l4[i], l5[i], l6[i]] for i in range(len(l1))]\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['seqs'] = train[['sequence', 'structure', 'predicted_loop_type', 'bpps_sum', 'bpps_max', 'bpps_nb']].apply(joiner, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['SN_filter'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txts = L([x for x in train['seqs'].values])\ntgts1 = L([x for x in train['reactivity'].values])\ntgts2 = L([x for x in train['deg_Mg_pH10'].values])\ntgts3 = L([x for x in train['deg_pH10'].values])\ntgts4 = L([x for x in train['deg_Mg_50C'].values])\ntgts5 = L([x for x in train['deg_50C'].values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seqs = L((tensor(txts[i]), tensor([tgts1[i], tgts2[i], tgts3[i], tgts4[i], tgts5[i]])) for i in range(len(txts)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['seqs'] = test[['sequence', 'structure', 'predicted_loop_type', 'bpps_sum', 'bpps_max', 'bpps_nb']].apply(joiner, axis=1)\ntest107 = test[test['seq_length'] == 107].reset_index(drop=True)\ntest130 = test[test['seq_length'] == 130].reset_index(drop=True)\nlen(test107), len(test130)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 107-length"},{"metadata":{"trusted":true},"cell_type":"code","source":"test107_ids = pd.DataFrame()\ntest107_ids['id'] = test107['id']\nfor i in range(11): # fill up the batch for prediction\n    test107_ids.loc[len(test107_ids)] = 'id_dummy'    \ntest107_ids['seqnum'] = ''    \ntest107_ids['seqnum'] = test107_ids['seqnum'].astype(object)\nsn = np.array(list(range(107)))\nfor i in range(len(test107_ids)):\n    test107_ids['seqnum'].loc[i] = sn\ntest107_ids = test107_ids.explode('seqnum').reset_index(drop=True)\ntest107_ids['id_seqpos'] = test107_ids.apply(lambda r: str(r[0]) + '_' + str(r[1]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test107_seqs = [(tensor(x), torch.zeros(5,68)) for x in test107['seqs'].values]\nlen(test107_seqs)\n#11 empty seqs to fill up the batch :/\ntest107_seqs_empty = [(torch.zeros((107,6), dtype=torch.long), torch.zeros(5,68)) for i in range(11)]\ntest107_seqs += test107_seqs_empty\ntest107_seqs = L(test107_seqs)\nlen(test107_seqs), len(test107_seqs) % 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test107_seqs = [(a.to('cuda'), b.to('cuda')) for (a,b) in test107_seqs]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 130-length"},{"metadata":{"trusted":true},"cell_type":"code","source":"test130_ids = pd.DataFrame()\ntest130_ids['id'] = test130['id']\nfor i in range(3): # fill up the batch for prediction\n    test130_ids.loc[len(test130_ids)] = 'id_dummy'    \ntest130_ids['seqnum'] = ''    \ntest130_ids['seqnum'] = test130_ids['seqnum'].astype(object)\nsn = np.array(list(range(130)))\nfor i in range(len(test130_ids)):\n    test130_ids['seqnum'].loc[i] = sn\ntest130_ids = test130_ids.explode('seqnum').reset_index(drop=True)\ntest130_ids['id_seqpos'] = test130_ids.apply(lambda r: str(r[0]) + '_' + str(r[1]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test130_seqs = [(tensor(x), torch.zeros(5,68)) for x in test130['seqs'].values]\nlen(test130_seqs)\n#3 empty seqs to fill up the batch :/\ntest130_seqs_empty = [(torch.zeros((130,6), dtype=torch.long), torch.zeros(5,68)) for i in range(3)]\ntest130_seqs += test130_seqs_empty\ntest130_seqs = L(test130_seqs)\nlen(test130_seqs), len(test130_seqs) % 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test130_seqs = [(a.to('cuda'), b.to('cuda')) for (a,b) in test130_seqs]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"BS = 32 # batch size \nES = 32 # embedding size\nNH = 512 # number hidden units\nNL = 3 # number layers\nDO = 0.3 # dropout\nEP = 20 # epochs\nLR = 0.009281670019785143 # learning rate\nWD = 0.0 # weight decay","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model and loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"sl = 107\n\nclass OVModel(Module):\n    def __init__(self, vocab1_sz, vocab2_sz, vocab3_sz, emb_sz, n_hidden, n_layers, p, y_range=None):\n        self.y_range = y_range\n        self.i_h1 = nn.Embedding(vocab1_sz, emb_sz)\n        self.i_h2 = nn.Embedding(vocab2_sz, emb_sz)\n        self.i_h3 = nn.Embedding(vocab3_sz, emb_sz)\n        self.rnn = nn.LSTM(emb_sz*3+3, n_hidden, n_layers, batch_first=True, bidirectional=True)\n        self.drop = nn.Dropout(p)\n        self.h_o = nn.Linear(n_hidden*2, 5)\n        self.h = [torch.zeros(n_layers*2, BS, n_hidden).to('cuda') for _ in range(2)]\n        \n    def forward(self, x):\n        e1 = self.i_h1(x[:,:,0].long())\n        e2 = self.i_h2(x[:,:,1].long())\n        e3 = self.i_h3(x[:,:,2].long())\n        bp = x[:,:,3:]\n        e = torch.cat((e1, e2, e3, bp), dim=2)\n        raw,h = self.rnn(e, self.h)\n        do = self.drop(raw)\n        out = self.h_o(do)\n        if self.y_range is None: \n            self.h = [h_.detach() for h_ in h]\n            return out, raw, do        \n        out = torch.sigmoid(out) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]\n        self.h = [h_.detach() for h_ in h]\n        return out, raw, do\n    \n    def reset(self): \n        for h in self.h: h.zero_()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_func(inp, targ):\n    inp = inp[0]\n    inp = inp[:,:68,:]\n    l1 = F.mse_loss(inp[:,:,0], targ[:,0,:])\n    l2 = F.mse_loss(inp[:,:,1], targ[:,1,:])\n    l3 = F.mse_loss(inp[:,:,2], targ[:,2,:])\n    l4 = F.mse_loss(inp[:,:,3], targ[:,3,:])\n    l5 = F.mse_loss(inp[:,:,4], targ[:,4,:])\n    return torch.sqrt((l1 + l2 + l3 + l4 +l5)/5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loaders, Training, Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dl107 = DataLoader(dataset=test107_seqs, bs=BS, shuffle=False, drop_last=True)\ntest_dl130 = DataLoader(dataset=test130_seqs, bs=BS, shuffle=False, drop_last=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spltidx = np.array(range(len(seqs)))\nkf = KFold(n_splits=5)\nsplts = list(kf.split(spltidx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_preds107 = []\nall_preds130 = []\n\nfor i in range(5):\n    dls = DataLoaders.from_dsets(seqs[splts[i][0]], seqs[splts[i][1]], bs=BS, drop_last=True, shuffle=True).cuda()\n    net = OVModel(len(vocab1), len(vocab2), len(vocab3), ES, NH, NL, DO, y_range=None)\n    learn = Learner(dls, net, loss_func=loss_func, cbs=ModelResetter)\n    learn.fit_one_cycle(EP, LR, wd=WD)\n    preds107 = learn.get_preds(dl=test_dl107, reorder=False)\n    all_preds107.append(preds107[0][0])\n    preds130 = learn.get_preds(dl=test_dl130, reorder=False)\n    all_preds130.append(preds130[0][0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions107 = sum(all_preds107) / len(all_preds107)\npredictions107.shape\n\npredictions130 = sum(all_preds130) / len(all_preds130)\npredictions130.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s107 = pd.DataFrame()\ns107['id_seqpos'] = test107_ids['id_seqpos']\ns107['reactivity'] = predictions107[:,:,0].flatten().numpy().tolist()\ns107['deg_Mg_pH10'] = predictions107[:,:,1].flatten().numpy().tolist()\ns107['deg_pH10'] = predictions107[:,:,2].flatten().numpy().tolist()\ns107['deg_Mg_50C'] = predictions107[:,:,3].flatten().numpy().tolist()\ns107['deg_50C'] = predictions107[:,:,4].flatten().numpy().tolist()\ns107 = s107.iloc[:-11*107]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s130 = pd.DataFrame()\ns130['id_seqpos'] = test130_ids['id_seqpos']\ns130['reactivity'] = predictions130[:,:,0].flatten().numpy().tolist()\ns130['deg_Mg_pH10'] = predictions130[:,:,1].flatten().numpy().tolist()\ns130['deg_pH10'] = predictions130[:,:,2].flatten().numpy().tolist()\ns130['deg_Mg_50C'] = predictions130[:,:,3].flatten().numpy().tolist()\ns130['deg_50C'] = predictions130[:,:,4].flatten().numpy().tolist()\ns130 = s130.iloc[:-3*130]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = pd.concat([s107, s130], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"viz = pd.DataFrame()\nviz['reactivity'] = predictions130[:,:,0].numpy().tolist()\nviz['deg_Mg_pH10'] = predictions130[:,:,1].numpy().tolist()\nviz['deg_Mg_50C'] = predictions130[:,:,3].numpy().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(21,9), sharex=True, sharey=True)\nfig.suptitle('Reactivity', fontsize=24, color='blue')\nfor i, ax in enumerate(axes.flatten()):\n    ax.plot(viz['reactivity'].loc[i])\n    ax.axvline(x=68, color='red')\n    ax.axvline(x=91, color='blue')\n    ax.axvline(x=107, color='green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(21,9), sharex=True, sharey=True)\nfig.suptitle('deg_Mg_pH10', fontsize=24, color='blue')\nfor i, ax in enumerate(axes.flatten()):\n    ax.plot(viz['deg_Mg_pH10'].loc[i])\n    ax.axvline(x=68, color='red')\n    ax.axvline(x=91, color='blue')\n    ax.axvline(x=107, color='green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(21,9), sharex=True, sharey=True)\nfig.suptitle('deg_Mg_50C', fontsize=24, color='blue')\nfor i, ax in enumerate(axes.flatten()):\n    ax.plot(viz['deg_Mg_50C'].loc[i])\n    ax.axvline(x=68, color='red')\n    ax.axvline(x=91, color='blue')\n    ax.axvline(x=107, color='green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}