{"cells":[{"metadata":{"id":"96YyCSur8cM5","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"Bt7wG2cmHu0F","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsubmission = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"85Mtd434I2J0","outputId":"dee1de87-3a94-4e9e-efc2-cbd25f7b14f0","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"cPaMUxSKJMg6","outputId":"8b49036b-3205-4af9-b761-53b54c07ff70","trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"jwGT6yE2JNTF","outputId":"89f32e69-a9c3-4a88-d8b5-803dbd274ebc","trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"VmNy_KVXNRqZ"},"cell_type":"markdown","source":"Ah! Got something. If we look at the train set columns and test set columns, here is what I found."},{"metadata":{"id":"FCwa2z_8NBBC","outputId":"84d87303-b39a-439d-eea9-d29459bab934","trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"mm10q2CSJUgh","outputId":"3da81402-d956-4b78-efa9-6d1521ccbf9d","trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"N-532YsDNVRL","outputId":"57faa504-fbe0-49d9-e7bf-bda9f5cf852d","trusted":true},"cell_type":"code","source":"set(train.columns).difference(test.columns).difference(submission.columns)","execution_count":null,"outputs":[]},{"metadata":{"id":"rzbOx9ZWNrWy"},"cell_type":"markdown","source":"Apart from the columns from submission files, we have the above columns extra in our train set. This thing is mentiond in the Data section of the competition, however I am summarizing a few points as per my understading."},{"metadata":{"id":"D2v05EI2O2RT"},"cell_type":"markdown","source":"\n\n*   There were 3029 RNA sequeces.\n*   Experiments were done using first 68 values of the 107-length sequence.\n-   These 3069 (107-base) were split into 2400 train + 629 test with filters being applied to choose the 629 samples. The filters are as follows:\n\n\n\n---\n\n1. Minimum value across all 5 conditions must be greater than -0.5.\n2. Mean signal/noise across all 5 conditions must be greater than 1.0. [Signal/noise is defined as mean( measurement value over 68 nts )/mean( statistical error in measurement value over 68 nts)]\n3. To help ensure sequence diversity, the resulting sequences were clustered into clusters with less than 50% sequence similarity, and the 629 test set sequences were chosen from clusters with 3 or fewer members. That is, any sequence in the test set should be sequence similar to at most 2 other sequences.\n\n---\nAnd as per the instructions, Private LB scoring will be made on 130-base 3005 sequences where the measurement is done on the basis of first 91 bases.\n\n> Note that, the above filters won't be applied to these 3005 samples."},{"metadata":{"id":"gvjz7imGOr6V","trusted":true},"cell_type":"code","source":"# let's do some cleaning and understand our data more clearly\ntrain = train.drop(['index'], axis=1)\ntest = test.drop(['index'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"15AS73A4SJbO"},"cell_type":"markdown","source":"# Understading our Train set"},{"metadata":{"id":"C4ibb_1PSIwG","outputId":"f624b98a-dd66-4674-9ba7-581b2f29858d","trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"u0m15DebSczl"},"cell_type":"markdown","source":"No null values present in the train set."},{"metadata":{"id":"cUNoNv3NR-X-","outputId":"00da57c7-dcbb-49c8-a6e7-201c0b55b58f","trusted":true},"cell_type":"code","source":"print(train['sequence'].apply(lambda x: len(x)).value_counts())  # all the sequences have 107 bases\nprint(train['structure'].apply(lambda x: len(x)).value_counts())  # all the structures have 107 bases\nprint(train['predicted_loop_type'].apply(lambda x: len(x)).value_counts())  # all the structures have 107 bases","execution_count":null,"outputs":[]},{"metadata":{"id":"OILrhjbUVOpm"},"cell_type":"markdown","source":"And reactivity_error,\tdeg_error_Mg_pH10,\tdeg_error_pH10,\tdeg_error_Mg_50C,\tdeg_error_50C,\treactivity,\tdeg_Mg_pH10,\tdeg_pH10,\tdeg_Mg_50C,\tdeg_50C; these columns have length 68 as its measured on first 68 bases."},{"metadata":{"id":"4p9aTYyaSrvQ","outputId":"a360145c-d1c6-4796-dd7d-ad6219509896","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"BZucBqaRbGZv","outputId":"20f55a6d-4296-4d90-8995-8215548b23be","trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"7L9Nv7T5i5HI"},"cell_type":"markdown","source":"Some Measure clues that you might miss:\n- Test set has two types of sequences one of length 107 and another of length 130. \n- As mentioned earlier, the 107 base sequences are filtered out from the 3029 samples of the previous dataset, and these consists of public leader board.\n- Rest 3005 samples are of length 130."},{"metadata":{"id":"7ml5miwOi2wG","outputId":"e895af72-c55a-4d19-d2a1-7442ce0adcbf","trusted":true},"cell_type":"code","source":"3005 * 130 + 629 * 107","execution_count":null,"outputs":[]},{"metadata":{"id":"CbfTuAAwjfsg"},"cell_type":"markdown","source":"This is what is the lenght of our submission file. So, we gotta predict the five measurements for each base of each sequence, or say it in terms of Sequence models, we gotta predict sequences of length x from sequences of length x, where the values of x can be 107 -> 107 and 130 -> 130 for test cases and 107 -> 68 for train cases."},{"metadata":{"id":"OEONmtNCkW0J"},"cell_type":"markdown","source":"# EDA on RNA Sequences"},{"metadata":{"id":"vC71frOWkbWs"},"cell_type":"markdown","source":"## For Sequences:\n\n- The possible values are A, G, C and U."},{"metadata":{"id":"odbee9mYkO18","outputId":"af7ededc-cd8d-45a6-cbe5-cd49396ff50c","trusted":true},"cell_type":"code","source":"train['seq_counts'] = train['sequence'].apply(lambda x: Counter(x.upper()))\ntrain['seq_counts']","execution_count":null,"outputs":[]},{"metadata":{"id":"fX2Q1tCDspo9","outputId":"7456e00b-5c28-4163-ad92-c20074cae0e5","trusted":true},"cell_type":"code","source":"train['seq_counts'].apply(lambda x: (x.keys(), x.values()))","execution_count":null,"outputs":[]},{"metadata":{"id":"kSXV2qhuv15l","outputId":"4b7322a1-b5d1-46a0-d342-91376d25ec1c","trusted":true},"cell_type":"code","source":"# doing a bit of feature engieering by taking up the contribution of each code\npercentage = []\nfor i in range(len(train)):\n  count = train.iloc[i]['seq_counts']\n  percentage.append((count['A']/train.iloc[i]['seq_length'],\n                     count['G']/train.iloc[i]['seq_length'],\n                     count['C']/train.iloc[i]['seq_length'],\n                     count['U']/train.iloc[i]['seq_length']))\n  \npercentage = pd.DataFrame(percentage, columns=['A_p', 'G_p', 'C_p', 'U_p'])\npercentage","execution_count":null,"outputs":[]},{"metadata":{"id":"vQfZ4_xoWPWi"},"cell_type":"markdown","source":"In RNA, its sequence that matters. Let's have a look on the paired-sequence. (We will focus on 3-gram model later on.)"},{"metadata":{"id":"3OVXqTc2WNKb","outputId":"f94b7325-71f3-4213-9108-7f9438c3ab74","trusted":true},"cell_type":"code","source":"pairs = []\nall_partners = []\nfor j in range(len(train)):\n    partners = [-1 for i in range(130)]\n    pairs_dict = {}\n    queue = []\n    for i in range(0, len(train.iloc[j]['structure'])):\n        if train.iloc[j]['structure'][i] == '(':\n            queue.append(i)\n        if train.iloc[j]['structure'][i] == ')':\n            first = queue.pop()\n            try:\n                pairs_dict[(train.iloc[j]['sequence'][first], train.iloc[j]['sequence'][i])] += 1\n            except:\n                pairs_dict[(train.iloc[j]['sequence'][first], train.iloc[j]['sequence'][i])] = 1\n                \n            partners[first] = i\n            partners[i] = first\n    \n    all_partners.append(partners)\n    \n    pairs_num = 0\n    pairs_unique = [('U', 'G'), ('C', 'G'), ('U', 'A'), ('G', 'C'), ('A', 'U'), ('G', 'U')]\n    for item in pairs_dict:\n        pairs_num += pairs_dict[item]\n    add_tuple = list()\n    for item in pairs_unique:\n        try:\n            add_tuple.append(pairs_dict[item]/pairs_num)\n        except:\n            add_tuple.append(0)\n    pairs.append(add_tuple)\n    \npairs = pd.DataFrame(pairs, columns=['U-G', 'C-G', 'U-A', 'G-C', 'A-U', 'G-U'])\npairs","execution_count":null,"outputs":[]},{"metadata":{"id":"xAXdBBU96FxU"},"cell_type":"markdown","source":"## For Structures"},{"metadata":{"id":"Mq8ZkG2j3TqT","outputId":"bdb8ac79-56ec-4ed4-95f0-240c69460eb7","trusted":true},"cell_type":"code","source":"pairs_rate = []\n\nfor j in range(len(train)):\n    res = dict(Counter(train.iloc[j]['structure']))\n    pairs_rate.append(res['('] / 53.5)  # 2 * res['(']/107\n    \npairs_rate = pd.DataFrame(pairs_rate, columns=['pairs_rate'])\npairs_rate","execution_count":null,"outputs":[]},{"metadata":{"id":"2of9HJsS6IE6"},"cell_type":"markdown","source":"## For Predicted Loop Type"},{"metadata":{"id":"U42kswwN6QJZ","outputId":"c2b6e8ae-36a9-41c4-c03d-b4ed7685fa6b","trusted":true},"cell_type":"code","source":"loops = []\nfor j in range(len(train)):\n    counts = dict(Counter(train.iloc[j]['predicted_loop_type']))\n    available = ['E', 'S', 'H', 'B', 'X', 'I', 'M']\n    row = []\n    for item in available:\n        try:\n            row.append(counts[item] / 107)\n        except:\n            row.append(0)\n    loops.append(row)\n    \nloops = pd.DataFrame(loops, columns=available)\nloops","execution_count":null,"outputs":[]},{"metadata":{"id":"fhkDLXPwnvUk"},"cell_type":"markdown","source":"## BBPS features"},{"metadata":{"id":"EF_8EmuhnyMf"},"cell_type":"markdown","source":"This is a great insight found by [Hidehisa Arai](https://https://www.kaggle.com/hidehisaarai1213/openvaccine-checkout-bpps). Let's cultivate on it."},{"metadata":{"id":"cuihKEvMoFq6","outputId":"f6f6af1c-391c-4512-beff-3e75ccc6cfc8","trusted":true},"cell_type":"code","source":"bbps_dir = '../input/stanford-covid-vaccine/bpps'\n\nbbps_fns = os.listdir(bbps_dir)\nlen(train) + len(test) == len(bbps_fns)","execution_count":null,"outputs":[]},{"metadata":{"id":"6gf2oM3pojXq"},"cell_type":"markdown","source":"Each  ```.npy``` file corresponds to each sample in our train and test dataset IDs.\n\n"},{"metadata":{"id":"rSmndJhvozm3"},"cell_type":"markdown","source":"### Compare between Structure and BPPS files"},{"metadata":{"id":"tYAlOt-moi6F","trusted":true},"cell_type":"code","source":"def get_bppm(id_):\n    return np.load(os.path.join(bbps_dir, bbps_fns[id_]))\n\n\ndef draw_structure(structure: str):\n    pm = np.zeros((len(structure), len(structure)))\n    start_token_indices = []\n    for i, token in enumerate(structure):\n        if token == \"(\":\n            start_token_indices.append(i)\n        elif token == \")\":\n            j = start_token_indices.pop()\n            pm[i, j] = 1.0\n            pm[j, i] = 1.0\n    return pm\n\n\ndef plot_structures(bppm: np.ndarray, pm: np.ndarray):\n    fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n    axes[0].imshow(bppm)\n    axes[0].set_title(\"BPPM\")\n    axes[1].imshow(pm)\n    axes[1].set_title(\"structure\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"K-fQ68BTptxh","outputId":"78e8c41c-21d7-4f3c-9406-c3f254474f5c","trusted":true},"cell_type":"code","source":"for _ in range(5):\n  idx = np.random.randint(len(bbps_fns))\n  fn = bbps_fns[idx]\n  df_id = fn.split('.')[0]\n\n  print(fn)\n  bbps_ff = get_bppm(idx)\n  struct = train[train['id']==df_id]['structure'].values[0] if df_id in train['id'].to_list() else test[test['id']==df_id]['structure'].values[0]\n  plot_struct = draw_structure(struct)\n  plot_structures(bbps_ff, plot_struct)","execution_count":null,"outputs":[]},{"metadata":{"id":"h0zBKYL2aB-i"},"cell_type":"markdown","source":"From here, I will go for a very simple model by stacking 3 seq-models and one DNN model for our created features. Let's move ahead."},{"metadata":{"id":"0PDemwrwahyk"},"cell_type":"markdown","source":"Our target columns are"},{"metadata":{"id":"0AgY3b65ag1_","outputId":"f731ea32-598d-442c-c096-bf877ea74b2b","trusted":true},"cell_type":"code","source":"target_cols = submission.columns.to_list()[1:]\nfor col in target_cols:\n  print(train[col].apply(lambda x: len(x)).sum()/len(train))\n\n# prediction sequence lenght is 68","execution_count":null,"outputs":[]},{"metadata":{"id":"hiQ4dTWIa26B"},"cell_type":"markdown","source":"And interestingly, our result will be measured or evalulated on 'reactivity', 'deg_Mg_pH10', 'deg_Mg_50C'. However, we gotta predict for all the 5 values."},{"metadata":{"id":"e8FagHq95n2H"},"cell_type":"markdown","source":"# Model\nSo my plan is to use the sequences, structures and predicted loops features along with bbps features (via CNN layers) with separate custom embedding for each sequential input and then concatenating them all together to get our desired output sequence of measures."},{"metadata":{"id":"iY_z8g-w7aak","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import layers as L\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold","execution_count":null,"outputs":[]},{"metadata":{"id":"07Ci2KlUaS1e","outputId":"3505ce99-0274-4780-ee29-ccc95a307ac0","trusted":true},"cell_type":"code","source":"def tokentoInt(bases):\n  return {x:i for i, x in enumerate(bases)}\n  pass\n\nprint(tokentoInt(\"\".join([x for x in loops.columns])))","execution_count":null,"outputs":[]},{"metadata":{"id":"EQCbXXgh61c8","trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))\n\ndef lstm_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.LSTM(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))","execution_count":null,"outputs":[]},{"metadata":{"id":"Kx3U6BlR62d_","trusted":true},"cell_type":"code","source":"# source : https://www.kaggle.com/c/stanford-covid-vaccine/discussion/183211\ndef MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"mvE8CPwy8pL2","trusted":true},"cell_type":"code","source":"def encoding(df, col):\n  \"\"\"\n  df: dataframe containing sequences and the features\n  col: column to apply encoding\n      : valid values are: 'sequence', 'structure' and 'predicted_loop_type'\n  \"\"\"\n  try:\n    if col == 'sequence':\n      seq_encoding = tokentoInt('AGCU')\n      \n    elif col == 'structure':\n      seq_encoding = tokentoInt('(.)')\n\n    elif col == 'predicted_loop_type':\n      seq_encoding = tokentoInt(\"\".join([x for x in loops.columns]))\n\n    return np.array(df[col].apply(lambda seq: [seq_encoding[x] for x in seq]).values.tolist())\n\n  except KeyError:\n    print('Invalid arguments as col')","execution_count":null,"outputs":[]},{"metadata":{"id":"1K0YSrhZH5tR"},"cell_type":"markdown","source":"## Preparing Data to fit into our Model\n- Sequence Model\n- Structure Model\n- Predicted Loop Type\n- CNN model for BPPS files"},{"metadata":{"id":"zjj0ReDOOZHk","trusted":true},"cell_type":"code","source":"from tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"id":"Y9wHPIt_Uw1j"},"cell_type":"markdown","source":"So I plan to split the data like following:\n- train: `train_data` and `valid_data` by filtering on SN_filer == 1\n- test: `private_test` and `public_test` filtered on seq_length"},{"metadata":{"id":"0kK3t1uwVgcS","trusted":true},"cell_type":"code","source":"private_test = test.query(\"seq_length==130\").copy()\npublic_test = test.query(\"seq_length==107\").copy()\n\n# this split on train set is applied if none of the cv folding aren't applied\ntrain_data = train.query('SN_filter==0')\nval_data = train.query('SN_filter==1')","execution_count":null,"outputs":[]},{"metadata":{"id":"6PTfeparLyhn"},"cell_type":"markdown","source":"### Features"},{"metadata":{"id":"dAUdQM4vILq7","trusted":true},"cell_type":"code","source":"def get_features(df):\n  seq_inp = encoding(df, 'sequence')\n  struc_inp = encoding(df, 'structure')\n  plt_inp = encoding(df, 'predicted_loop_type')\n  '''\n  bpps_arr = []\n  for i in tqdm(range(len(df))):\n    idx = df.loc[i]['id']\n    bpps_arr.append(np.expand_dims(np.load(os.path.join(bbps_dir, str(idx)+'.npy')), axis=-1))\n\n  cnn_inp = np.array(bpps_arr) # cnn data input\n  '''\n  return seq_inp, struc_inp, plt_inp #, cnn_inp","execution_count":null,"outputs":[]},{"metadata":{"id":"50vECoyCL0tK"},"cell_type":"markdown","source":"### Labels"},{"metadata":{"id":"88fsih4AL23T","outputId":"4481ab60-1765-45de-dd02-75ce46ff9b5d","trusted":true},"cell_type":"code","source":"train_labels = np.array(train[target_cols].values.tolist()).transpose(0, 2, 1)\ntrain_labels[0, 0, :]","execution_count":null,"outputs":[]},{"metadata":{"id":"V3RQvxvBFgGq","trusted":true},"cell_type":"code","source":"def seq_model(encoding_dict,\n              seq_len=107,\n              pred_len=68,\n              dropout=0.4,\n              sp_dropout=0.2,\n              embed_size=128,\n              hidden_dim=256,\n              layers=2,\n              gru=False):\n  \n  # one sequence at a time of len 107 (if training specified)\n  input = L.Input(shape=(seq_len, ))\n\n  # apply embedding layer\n  embed = L.Embedding(input_dim=len(encoding_dict),\n                      output_dim=embed_size)(input)\n\n  '''reshaped = tf.reshape(embed,\n                        shape=(-1, embed.shape[1], embed.shape[2] * embed.shape[3]))'''\n  hidden = tf.keras.layers.SpatialDropout1D(sp_dropout)(embed)\n  # apply bidirectional lstm/gru layers * layers count\n  if gru:\n    for _ in range(layers):\n      hidden = gru_layer(hidden_dim, dropout)(hidden)\n  else:\n    for _ in range(layers):\n      hidden = gru_layer(hidden_dim, dropout)(hidden)\n  \n  return tf.keras.Model(input, hidden)\n  pass","execution_count":null,"outputs":[]},{"metadata":{"id":"v2I-QH47KUmD","trusted":true},"cell_type":"code","source":"def cnn_model(input_shape=(107, 107), flag=False):\n  \"\"\"\n  can be of shape 107*107(train and public set) and 130*130(private set) \n  \"\"\"\n  input = L.Input(shape=(*input_shape, 1))  # images are of 2-D\n\n  # let's just go with 3 layers of CNN\n  x = L.Conv2D(kernel_size=(5, 5),\n               filters=64,\n               strides=(2, 2))(input)\n  x = L.MaxPool2D(pool_size=(2, 2))(x)\n  x = L.Activation('relu')(x)\n\n  x = L.Conv2D(kernel_size=(3, 3),\n               filters=256)(x)\n  x = L.MaxPool2D(pool_size=(2, 2))(x)\n  x = L.Activation('relu')(x)\n  \n  x = L.Conv2D(kernel_size=(1, 4), filters=512)(x)\n  x = L.Activation('relu')(x)\n  \n  if flag:\n    x = L.Conv2D(kernel_size=(2, 2), filters=512)(x)\n    x = L.Activation('relu')(x)\n    x = tf.reshape(x, shape=(-1, x.shape[1]*x.shape[2], x.shape[-1], 1))\n    return tf.keras.Model(input, x)\n\n  x = tf.reshape(x, shape=(-1, x.shape[1]*x.shape[2], x.shape[-1], 1))\n  x = L.Conv2D(kernel_size=(2, 1), filters=1)(x)\n  x = L.Activation('relu')(x)\n\n\n\n\n  return tf.keras.Model(input, x)\n  pass","execution_count":null,"outputs":[]},{"metadata":{"id":"XZm3WoR7MY4S","trusted":true},"cell_type":"code","source":"def main_model(seq_len=107, pred_len=68, cnn_input_shape=(107, 107), flag=False):\n  \"\"\"\n  Consists of four models, one seq_model each for sequence, structure and predicted_loop\n  and one CNN for BPPS files.\n  \"\"\"\n  # extract from sequences\n  Seq_model = seq_model(tokentoInt('AGCU'), seq_len=seq_len, pred_len=pred_len, dropout=0.0)\n  Seq_op = Seq_model.output  # for train,  seq_len = 107\n\n  Struct_model = seq_model(tokentoInt('(.)'), seq_len=seq_len, pred_len=pred_len, dropout=0.0)\n  Struct_op = Struct_model.output\n\n  PLT_model = seq_model(tokentoInt(\"\".join([x for x in loops.columns])), seq_len=seq_len, pred_len=pred_len, dropout=0.0)\n  PLT_op = PLT_model.output\n  '''\n  # add cnn layer output\n  CNN_model = cnn_model(cnn_input_shape, flag=flag)\n  CNN_op = CNN_model.output\n  CNN_op = tf.reshape(CNN_op, shape=(-1, CNN_op.shape[1], CNN_op.shape[2] * CNN_op.shape[3]))\n  \n  print(Seq_op.shape, Struct_op.shape, PLT_op.shape, CNN_op.shape)\n  '''\n  # now we got 4 tensors of shape (BS, 107, 512)\n  ip = tf.add_n([Seq_op, Struct_op, PLT_op])/3\n  print(ip.shape)\n  ip = ip[:, :pred_len]\n  ip = L.Dense(5, activation='linear')(ip)\n  print(ip.shape)\n  return tf.keras.Model(inputs=[Seq_model.input, Struct_model.input, PLT_model.input], outputs=ip)\n  pass","execution_count":null,"outputs":[]},{"metadata":{"id":"gC2cxtqqt0kc","outputId":"445ab519-35e0-4756-e1c6-59baa3a94dec","trusted":true},"cell_type":"code","source":"model = main_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"nUmYcJWONH7K","trusted":true},"cell_type":"code","source":"model.compile(loss=MCRMSE,\n           optimizer=tf.keras.optimizers.Adam(lr=0.001))","execution_count":null,"outputs":[]},{"metadata":{"id":"9MJEqNJskiji","trusted":true},"cell_type":"code","source":"lr_callback = tf.keras.callbacks.ReduceLROnPlateau(patience=5)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint(f'lstm.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"yhzqxGf7rwPE","trusted":true},"cell_type":"code","source":"model.fit(get_features(train), train_labels,\n       epochs=75, batch_size=64,\n       callbacks=[lr_callback, sv_lstm])","execution_count":null,"outputs":[]},{"metadata":{"id":"8zTN2mBdcVvV","trusted":true},"cell_type":"code","source":"model_long = main_model(seq_len=130, pred_len=130, cnn_input_shape=(130, 130), flag=True)\nmodel_long.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"DSHY48hzckuF","trusted":true},"cell_type":"code","source":"model_long.load_weights('./lstm.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"GLHTxW8xmeYJ","outputId":"72a6843a-eb0d-4bac-aa9c-77e3db8dd993","trusted":true},"cell_type":"code","source":"pred_long = model_long.predict(get_features(private_test), verbose=1)\npred_long.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"0g86E4ZDnSPe","trusted":true},"cell_type":"code","source":"model_short = main_model(seq_len=107, pred_len=107, cnn_input_shape=(107, 107), flag=True)\nmodel_short.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"6EvsRjs0n96C","outputId":"bca98829-03cb-4f10-f107-738512e17f8a","trusted":true},"cell_type":"code","source":"model_short.load_weights('./lstm.h5')\npred_short = model_short.predict(get_features(public_test), verbose=1)\npred_short.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"0zE630S9ojQl","trusted":true},"cell_type":"code","source":"def format_predictions(public_preds, private_preds):\n    preds = []\n    \n    for df, preds_ in [(public_test, public_preds), (private_test, private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds_[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds.append(single_df)\n\n    return pd.concat(preds).groupby('id_seqpos')","execution_count":null,"outputs":[]},{"metadata":{"id":"1v6Bz4WTpsMD","outputId":"b4beb6f6-356d-4f4c-d2b0-b6219213aede","trusted":true},"cell_type":"code","source":"df = format_predictions(pred_short, pred_long)\ndf.first()","execution_count":null,"outputs":[]},{"metadata":{"id":"I0afl4wCp6Js","trusted":true},"cell_type":"code","source":"submission = df.sum().reset_index()\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"id":"XknZgNi_sf3_","trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you find this notebook, consider upvoting the same, I will experimenting with other approaches, I set this as my base model as of now. Thank you for reading so far."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}