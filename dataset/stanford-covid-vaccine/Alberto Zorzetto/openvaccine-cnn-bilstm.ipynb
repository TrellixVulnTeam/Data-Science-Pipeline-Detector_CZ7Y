{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import (Dense,Input,Conv1D,Dropout,LSTM,Bidirectional,GRU,SpatialDropout1D,Embedding,Activation,concatenate,AveragePooling1D,\n                                    MaxPooling1D,BatchNormalization,GlobalMaxPooling1D,GlobalAveragePooling1D,add,PReLU,Flatten,TimeDistributed,Reshape)\nfrom tensorflow.keras import regularizers\nfrom tensorflow import reshape\nfrom tensorflow.keras.utils import plot_model\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport random\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom sklearn.cluster import KMeans\n\nimport numpy as np\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed = 34):\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nseed_everything()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_json('/kaggle/input/stanford-covid-vaccine/train.json',lines=True).drop('index',axis=1)\ntest=pd.read_json('/kaggle/input/stanford-covid-vaccine/test.json',lines=True).drop('index',axis=1)\nsample_sub=pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_bpps_sum(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").sum(axis=1))\n    return bpps_arr\n\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ndef read_bpps_nb(df):\n    #mean and std from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n    bpps_nb_mean = 0.077522\n    bpps_nb_std = 0.08914\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\")\n        bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n        bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n        bpps_arr.append(bpps_nb)\n    return bpps_arr \n\ntrain['bpps_sum'] = read_bpps_sum(train)\ntest['bpps_sum'] = read_bpps_sum(test)\ntrain['bpps_max'] = read_bpps_max(train)\ntest['bpps_max'] = read_bpps_max(test)\ntrain['bpps_nb'] = read_bpps_nb(train)\ntest['bpps_nb'] = read_bpps_nb(test)\n\n#sanity check\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot_char(s,enum={c : i for i, c in enumerate('ACGUBEHIMSX.()')}):\n    one_hot_s = []\n    for i in range(len(s)):\n        one_hot_c=np.zeros(len(enum))\n        one_hot_c[enum[s[i]]] = 1\n        one_hot_s.append(one_hot_c)\n    return one_hot_s\n\none_hot_char(\"GAAAGCUAGGACGUGG\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"def decode_one_hot(arr, enum={c : i for i, c in enumerate('ACGUBEHIMSX.()')}):\n    s=[]\n    inv_enum= { i : c for c, i in enum.iteritems()}\n    for i in range(len(arr)):\n        s+=inv_enum\n                        "},{"metadata":{"trusted":true},"cell_type":"code","source":"textencoding={c : i for i, c in enumerate('ACGUBEHIMSX.()')}\ntextencoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [textencoding[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def denoise(df,tresh=0.25):\n    df=df[df['signal_noise' > tresh]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = preprocess_inputs(train)\ntrain_labels = np.array(train[targets].values.tolist()).transpose((0, 2, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nimport keras.backend as K\n\ndef rmse(y_actual, y_pred):\n    mse = keras.losses.mean_squared_error(y_actual, y_pred)\n    return K.sqrt(mse)\n\ndef mcrmse(y_actual, y_pred, num_scored=len(targets)):\n    score = 0\n    for i in range(num_scored):\n        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / num_scored\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(one_hot = False, conv_bias_reg = regularizers.l2(0.00001), conv_kern_reg = regularizers.l2(0.00001), \n                embed = 120, lstm=100, dropout=0.3, opt='adam', input_length=68, seq_len=107, pred_len=68):\n \n    \n    inputs = Input((seq_len, 3))\n    emb=Embedding(len(textencoding), embed, input_length=input_length, trainable=True)(inputs)\n    \n    reshaped = reshape(emb, shape=(-1, emb.shape[1],  emb.shape[2] * emb.shape[3]))  \n    \n    dropout_layer=SpatialDropout1D(0.2)(reshaped)\n\n    conv_1=Conv1D(512, 3,padding='same',kernel_initializer='he_uniform',\n                 kernel_regularizer=conv_kern_reg, bias_regularizer=conv_bias_reg) (dropout_layer)\n    batch_1=BatchNormalization()(conv_1)\n    act_1=Activation('relu')(batch_1) \n    max_pool_1=MaxPooling1D(pool_size=2,strides=1,padding='same') (act_1)\n\n        \n    lstm_1 = Bidirectional(LSTM(lstm, return_sequences=True, dropout=dropout, kernel_initializer='orthogonal'))(act_1)\n    \n    lstm_2 = Bidirectional(LSTM(lstm, return_sequences=True, dropout=dropout, kernel_initializer='orthogonal'))(lstm_1)\n    \n    lstm_3 = Bidirectional(LSTM(lstm, return_sequences=True, dropout=dropout, kernel_initializer='orthogonal'))(lstm_2)\n\n    truncated = lstm_3[:, :pred_len]\n\n\n    x=TimeDistributed(Dense(1024,activation='relu'))(truncated) \n    x=Dropout(0.3)(x)\n\n    x=TimeDistributed(Dense(512,activation='relu'))(x)\n    x=Dropout(0.3)(x) \n\n    x=TimeDistributed(Dense(5,activation='linear'))(x)\n\n\n\n    model = Model(inputs=inputs, outputs=x) \n                \n    model.compile(optimizer = opt, loss = mcrmse, metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_and_infer( STRATIFY=True, FOLDS=4, EPOCHS=50, BATCH_SIZE=64,\n                    REPEATS=3, SEED=34, VERBOSE=2):\n\n    #get test now for OOF \n    public_df = test.query(\"seq_length == 107\").copy()\n    private_df = test.query(\"seq_length == 130\").copy()\n    private_preds = np.zeros((private_df.shape[0], 130, 5))\n    public_preds = np.zeros((public_df.shape[0], 107, 5))\n    public_inputs = preprocess_inputs(public_df)\n    private_inputs = preprocess_inputs(private_df)\n\n    #to evaluate TTA effects/post processing\n    holdouts = []\n    holdout_preds = []\n    \n    #to view learning curves\n    histories = []\n    \n    #put similar RNA in the same fold\n    gkf = GroupKFold(n_splits=FOLDS)\n    kf=KFold(n_splits=FOLDS, random_state=SEED)\n    kmeans_model = KMeans(n_clusters=200, random_state=SEED).fit(preprocess_inputs(train)[:,:,0])\n    train['cluster_id'] = kmeans_model.labels_\n\n    for _ in range(REPEATS):\n        \n        for f, (train_index, val_index) in enumerate((gkf if STRATIFY else kf).split(train,\n                train['reactivity'], train['cluster_id'] if STRATIFY else None)):\n\n            #define training callbacks\n            lr_callback = tf.keras.callbacks.ReduceLROnPlateau(patience=8, \n                                                               factor=.1,\n                                                               #min_lr=1e-5,\n                                                               verbose=VERBOSE)\n            save = tf.keras.callbacks.ModelCheckpoint(f'model-{f}.h5')\n\n            #define sample weight function\n            epsilon = .1\n            sample_weighting = np.log1p(train.iloc[train_index]['signal_to_noise'] + epsilon) / 2\n\n            #get train data\n            trn = train.iloc[train_index]\n            trn_ = preprocess_inputs(trn)\n            trn_labs = np.array(trn[targets].values.tolist()).transpose((0, 2, 1))\n\n            #get validation data\n            val = train.iloc[val_index]\n            val_all = preprocess_inputs(val)\n            val = val[val.SN_filter == 1]\n            val_ = preprocess_inputs(val)\n            val_labs = np.array(val[targets].values.tolist()).transpose((0, 2, 1))\n\n            #pre-build models for different sequence lengths\n            model = build_model()\n            model_short = build_model(seq_len=107, pred_len=107)\n            model_long = build_model(seq_len=130, pred_len=130)\n\n            #train model\n            history = model.fit(\n                trn_, trn_labs,\n                validation_data = (val_, val_labs),\n                batch_size=BATCH_SIZE,\n                epochs=EPOCHS,\n                sample_weight=sample_weighting,\n                callbacks=[save, lr_callback],\n                verbose=VERBOSE\n            )\n\n            histories.append(history)\n\n            #load best models\n            model.load_weights(f'model-{f}.h5')\n            model_short.load_weights(f'model-{f}.h5')\n            model_long.load_weights(f'model-{f}.h5')\n\n            holdouts.append(train.iloc[val_index])\n            holdout_preds.append(model.predict(val_all))\n\n            public_preds += model_short.predict(public_inputs) / (FOLDS * REPEATS)\n            private_preds += model_long.predict(private_inputs) / (FOLDS * REPEATS)\n        \n        del model, model_short, model_long\n        \n    return holdouts, holdout_preds, public_df, public_preds, private_df, private_preds, histories\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_holdouts, lstm_holdout_preds, public_df, lstm_public_preds, private_df, lstm_private_preds, lstm_histories = train_and_infer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_error(preds):\n    val = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\n\n    val_data = []\n    for mol_id in val['id'].unique():\n        sample_data = val.loc[val['id'] == mol_id]\n        sample_seq_length = sample_data.seq_length.values[0]\n        for i in range(68):\n            sample_dict = {\n                           'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                           'reactivity_gt' : sample_data['reactivity'].values[0][i],\n                           'deg_Mg_pH10_gt' : sample_data['deg_Mg_pH10'].values[0][i],\n                           'deg_Mg_50C_gt' : sample_data['deg_Mg_50C'].values[0][i],\n                           }\n            \n            val_data.append(sample_dict)\n            \n    val_data = pd.DataFrame(val_data)\n    val_data = val_data.merge(preds, on='id_seqpos')\n\n    rmses = []\n    mses = []\n    \n    for col in ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']:\n        rmse = ((val_data[col] - val_data[col+'_gt']) ** 2).mean() ** .5\n        mse = ((val_data[col] - val_data[col+'_gt']) ** 2).mean()\n        rmses.append(rmse)\n        mses.append(mse)\n        print(col, rmse, mse)\n    print(np.mean(rmses), np.mean(mses))\n    print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(f'model-0.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_predictions(test_df, test_preds, val=False):\n    preds = []\n    \n    for df, preds_ in zip(test_df, test_preds):\n        for i, uid in enumerate(df['id']):\n            single_pred = preds_[i]\n\n            single_df = pd.DataFrame(single_pred, columns= targets)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n            if val: single_df['SN_filter'] = df[df['id'] == uid].SN_filter.values[0]\n\n            preds.append(single_df)\n    return  pd.concat(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_val_preds = format_predictions(lstm_holdouts, lstm_holdout_preds, val=True)\n\nget_error(lstm_val_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = [public_df, private_df]\nlstm_preds = [lstm_public_preds,lstm_private_preds]\nlstm_preds = format_predictions(test_df, lstm_preds)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_sub[['id_seqpos']].merge(lstm_preds, on=['id_seqpos'])\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(f'submission_new.csv', index=False)\nprint('Submission saved')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}