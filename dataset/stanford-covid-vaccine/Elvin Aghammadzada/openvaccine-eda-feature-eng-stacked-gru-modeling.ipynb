{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport tensorflow.keras.layers as L","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Competition Overview\nIn this new competition we are helping to fight against the worldwide pandemic COVID-19. mRNA vaccines are the fastest vaccine candidates to treat COVID-19 but they currently facing several limitations. In particular, it is a challenge to design stable messenger RNA molecules. Typical vaccines are packaged in syringes and shipped under refrigeration around the world, but that is not possible for mRNA vaccines (currently).\n\nResearches have noticed that RNA molecules tend to spontaneously degrade, which is highly problematic because a single cut can render mRNA vaccines useless. Not much is known about which part of the backbone of a particular RNA is most susceptible to being damaged.\n\nWithout this knowledge, the current mRNA vaccines are shopped under intense refrigeration and are unlikely to reach enough humans unless they can be stabilized. This is our task as Kagglers: we must create a model to predict the most likely degradation rates at each base of an RNA molecule.\n\nWe are given a subset of an Eterna dataset comprised of over 3000 RNA molecules and their degradation rates at each position. Our models are then tested on the new generation of RNA sequences that were just created by Eterna players for COVID-19 mRNA vaccines\n\nBefore we get started, please check out other's notebook here as this one is based on other: I just added comments, made minor code changes, an LSTM, and fold training:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_json(\"../input/stanford-covid-vaccine/train.json\", lines=True)\ntest = pd.read_json(\"../input/stanford-covid-vaccine/test.json\", lines=True)\nsample_df = pd.read_csv(\"../input/stanford-covid-vaccine/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install datasist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merge Train and Test for Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datasist as ds\nds.structdata.check_train_test_set(train, test, index=None, col=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ds.structdata.describe(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missingno - Automated ML library for some feature engineering (can also be used in EDA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import missingno as msno\nmsno.matrix(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('max_columns', 100)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['structure'][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length = []\nfor struct in train['structure']:\n    length.append(len(struct))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"flag\"] = \"train\"\ntest[\"flag\"] = \"test\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install datasist\nimport datasist as ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data, ntrain, ntest = ds.structdata.join_train_and_test(train, test)\n# #later splitting after transformations\n# train_new = all_data[:ntrain]\n# test_new = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nlistof = []\nfor data in all_data['predicted_loop_type']:\n    for letter in str(data):\n        if letter == \"S\":\n            count += 1\n#     listof.append(count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding S, M, I, B, H, X columns based off of the number of corresponding letters in predicted_loop_type column"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"S\"] = all_data['predicted_loop_type'].str.count(\"S\")\nall_data[\"M\"] = all_data['predicted_loop_type'].str.count(\"M\")\nall_data[\"I\"] = all_data['predicted_loop_type'].str.count(\"I\")\nall_data[\"B\"] = all_data['predicted_loop_type'].str.count(\"B\")\nall_data[\"H\"] = all_data['predicted_loop_type'].str.count(\"H\")\nall_data[\"X\"] = all_data['predicted_loop_type'].str.count(\"X\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Unmerge"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = all_data[:ntrain]\ntest = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train['S'] = \ntrain['predicted_loop_type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\ntrain[pred_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train[pred_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array(train[train.signal_to_noise > 1][pred_cols].values.tolist()).transpose((0, 2, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = preprocess_inputs(train[train.signal_to_noise > 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True))\n\ndef build_model(seq_len=107, pred_len=68, dropout=0.5, embed_dim=100, hidden_dim=128):\n    inputs = L.Input(shape=(seq_len, 3))\n\n    embed = L.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n\n    hidden = gru_layer(hidden_dim, dropout)(reshaped)\n    hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, we have\n    # to truncate it\n    truncated = hidden[:, :pred_len]\n    out1 = L.BatchNormalization()(truncated)\n    out = L.Dense(5, activation='linear')(out1)\n\n    model = tf.keras.Model(inputs=inputs, outputs=out)\n\n    model.compile(tf.keras.optimizers.Adam(), loss='mse')\n    \n    return model\nmodel = build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    X, y, \n    batch_size=64,\n    epochs=150,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(),\n        tf.keras.callbacks.ModelCheckpoint('model.h5')\n    ],\n    validation_split=0.25\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# loss = pd.DataFrame({loss: model.history.history[\"loss\"], acc: model.history.history[\"val_loss\"] })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\n\npublic_inputs = preprocess_inputs(public_df)\nprivate_inputs = preprocess_inputs(private_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# although it's not the case for the training data.\nmodel_short = build_model(seq_len=107, pred_len=107)\nmodel_long = build_model(seq_len=130, pred_len=130)\n\nmodel_short.load_weights('model.h5')\nmodel_long.load_weights('model.h5')\n\npublic_preds = model_short.predict(public_inputs)\nprivate_preds = model_long.predict(private_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_ls = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission1234.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1, figsize = (20, 10))\n\nax[0].plot(history.history['loss'])\nax[0].plot(history.history['val_loss'])\n\n\nax[0].set_title('GRU')\n\nax[0].legend(['train', 'validation'], loc = 'upper right')\n\nax[0].set_ylabel('Loss')\nax[0].set_xlabel('Epoch')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}