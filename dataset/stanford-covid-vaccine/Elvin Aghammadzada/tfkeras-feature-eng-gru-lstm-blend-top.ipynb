{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_json(\"../input/stanford-covid-vaccine/train.json\", lines=True)\ntest = pd.read_json(\"../input/stanford-covid-vaccine/test.json\", lines=True)\nsample_df = pd.read_csv(\"../input/stanford-covid-vaccine/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install datasist\nimport datasist as ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data, ntrain, ntest = ds.structdata.join_train_and_test(train, test)\n# join\n# train = all_data[:ntrain]\n# test  = all_datal[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[\"S\"] = all_data['predicted_loop_type'].str.count(\"S\")\nall_data[\"M\"] = all_data['predicted_loop_type'].str.count(\"M\")\nall_data[\"I\"] = all_data['predicted_loop_type'].str.count(\"I\")\nall_data[\"B\"] = all_data['predicted_loop_type'].str.count(\"B\")\nall_data[\"H\"] = all_data['predicted_loop_type'].str.count(\"H\")\nall_data[\"X\"] = all_data['predicted_loop_type'].str.count(\"X\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = all_data[:ntrain]\ntest  = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\ntrain[pred_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train[pred_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array(train[train.signal_to_noise > 1][pred_cols].values.tolist()).transpose((0, 2, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = preprocess_inputs(train[train.signal_to_noise > 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#the basics\nimport pandas as pd, numpy as np\nimport math, json, gc, random, os, sys\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\n#tensorflow deep learning basics\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\n\n#for model evaluation\nfrom sklearn.model_selection import train_test_split, KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.GRU(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lstm_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.LSTM(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def build_model(gru=1,seq_len=107, pred_len=68, dropout=0.5,\n#                 embed_dim=75, hidden_dim=128):\n    \n#     inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n\n#     embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n#     reshaped = tf.reshape(\n#         embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    \n#     reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n    \n#     if gru==1:\n#         hidden = gru_layer(hidden_dim, dropout)(reshaped)\n#         hidden = gru_layer(hidden_dim, dropout)(hidden)\n#         hidden = gru_layer(hidden_dim, dropout)(hidden)\n#         hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n#     elif gru==0:\n#         hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n#         hidden = lstm_layer(hidden_dim, dropout)(hidden)\n#         hidden = lstm_layer(hidden_dim, dropout)(hidden)\n#         hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n#     elif gru==3:\n#         hidden = gru_layer(hidden_dim, dropout)(reshaped)\n#         hidden = gru_layer(hidden_dim, dropout)(hidden)\n#         hidden = gru_layer(hidden_dim, dropout)(hidden)\n#         hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n#     elif gru==4:\n#         hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n#         hidden = lstm_layer(hidden_dim, dropout)(hidden)\n#         hidden = lstm_layer(hidden_dim, dropout)(hidden)\n#         hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n#     #only making predictions on the first part of each sequence\n#     truncated = hidden[:, :pred_len]\n    \n#     out1 = tf.keras.layers.BatchNormalization()(truncated)\n#     out = tf.keras.layers.Dense(5, activation='linear')(out1)\n\n#     model = tf.keras.Model(inputs=inputs, outputs=out)\n\n#     #some optimizers\n#     adam = tf.optimizers.Adam()\n#     radam = tfa.optimizers.RectifiedAdam()\n#     lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n#     ranger = tfa.optimizers.Lookahead(radam, sync_period=6)\n    \n#     model.compile(optimizer = adam, loss='mse')\n    \n#     return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True))\n\ndef build_model(seq_len=107, pred_len=68, dropout=0.5, embed_dim=100, hidden_dim=128):\n    inputs = L.Input(shape=(seq_len, 3))\n\n    embed = L.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n\n    hidden = gru_layer(hidden_dim, dropout)(reshaped)\n    hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, we have\n    # to truncate it\n    truncated = hidden[:, :pred_len]\n    out1 = L.BatchNormalization()(truncated)\n    out = L.Dense(5, activation='linear')(out1)\n\n    model = tf.keras.Model(inputs=inputs, outputs=out)\n\n    model.compile(tf.keras.optimizers.Adam(), loss='mse')\n    \n    return model\nmodel = build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport gc\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Masking\nfrom tensorflow.keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, Dropout\nfrom tensorflow.keras.preprocessing import text, sequence\nfrom tqdm import tqdm_notebook as tqdm\nimport fasttext","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \n    q_in = Input(shape=(None,))\n    q = embedding(q_in)\n    q = SpatialDropout1D(0.2)(q)\n    q = Bidirectional(LSTM(100, return_sequences=True))(q)\n    q = GlobalMaxPooling1D()(q)\n    \n    \n    t_in = Input(shape=(None,))\n    t = embedding(t_in)\n    t = SpatialDropout1D(0.2)(t)\n    t = Bidirectional(LSTM(150, return_sequences=True))(t)\n    t = GlobalMaxPooling1D()(t)\n    \n    hidden = concatenate([q, t])\n    hidden = Dense(300, activation='relu')(hidden)\n    hidden = Dropout(0.5)(hidden)\n    hidden = Dense(300, activation='relu')(hidden)\n    hidden = Dropout(0.5)(hidden)\n    \n    out1 = Dense(1, activation='sigmoid')(hidden)\n    \n    model = Model(inputs=[t_in, q_in], outputs=out1)\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs, val_inputs, train_labels, val_labels = train_test_split(X, y,\n                                                                     test_size=.1, random_state=34)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if tf.config.list_physical_devices('GPU') is not None:\n    print('Training on GPU')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru = build_model(gru=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_callback = tf.keras.callbacks.ReduceLROnPlateau()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sv_gru = tf.keras.callbacks.ModelCheckpoint('model_gru.h5')\n\nhistory_gru = gru.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_gru],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_gru.history['loss'])}, min validation loss={min(history_gru.history['val_loss'])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm = build_model(gru=0)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_lstm.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm = build_model(gru=3)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb1.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm = build_model(gru=4)\nsv_lstm = tf.keras.callbacks.ModelCheckpoint('model_hyb2.h5')\n\nhistory_lstm = lstm.fit(\n    train_inputs, train_labels, \n    validation_data=(val_inputs,val_labels),\n    batch_size=64,\n    epochs=100,\n    callbacks=[lr_callback,sv_lstm],\n    verbose = 2\n)\n\nprint(f\"Min training loss={min(history_lstm.history['loss'])}, min validation loss={min(history_lstm.history['val_loss'])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\n\npublic_inputs = preprocess_inputs(public_df)\nprivate_inputs = preprocess_inputs(private_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 2, figsize = (20, 10))\n\nax[0].plot(history_lstm.history['loss'])\nax[0].plot(history_lstm.history['val_loss'])\n\nax[0].plot(history_gru.history['loss'])\nax[0].plot(history_gru.history['val_loss'])\n\n\nax[0].set_title('GRU')\n\nax[0].legend(['train', 'validation'], loc = 'upper right')\n\nax[0].set_ylabel('Loss')\nax[0].set_xlabel('Epoch')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build all models\ngru_short = build_model(gru=1, seq_len=107, pred_len=107)\ngru_long = build_model(gru=1, seq_len=130, pred_len=130)\nlstm_short = build_model(gru=0, seq_len=107, pred_len=107)\nlstm_long = build_model(gru=0, seq_len=130, pred_len=130)\nhyb1_short = build_model(gru=3, seq_len=107, pred_len=107)\nhyb1_long = build_model(gru=3, seq_len=130, pred_len=130)\nhyb2_short = build_model(gru=4, seq_len=107, pred_len=107)\nhyb2_long = build_model(gru=4, seq_len=130, pred_len=130)\n\n\n#load pre-trained model weights\ngru_short.load_weights('model_gru.h5')\ngru_long.load_weights('model_gru.h5')\nlstm_short.load_weights('model_lstm.h5')\nlstm_long.load_weights('model_lstm.h5')\nhyb1_short.load_weights('model_hyb1.h5')\nhyb1_long.load_weights('model_hyb1.h5')\nhyb2_short.load_weights('model_hyb2.h5')\nhyb2_long.load_weights('model_hyb2.h5')\n\n#and predict\ngru_public_preds = gru_short.predict(public_inputs)\ngru_private_preds = gru_long.predict(private_inputs)\nlstm_public_preds = lstm_short.predict(public_inputs)\nlstm_private_preds = lstm_long.predict(private_inputs)\nhyb1_public_preds = hyb1_short.predict(public_inputs)\nhyb1_private_preds = hyb1_long.predict(private_inputs)\nhyb2_public_preds = hyb2_short.predict(public_inputs)\nhyb2_private_preds = hyb2_long.predict(private_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_gru = []\n\nfor df, preds in [(public_df, gru_public_preds), (private_df, gru_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_gru.append(single_df)\n\npreds_gru_df = pd.concat(preds_gru)\npreds_gru_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_lstm = []\n\nfor df, preds in [(public_df, lstm_public_preds), (private_df, lstm_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_lstm.append(single_df)\n\npreds_lstm_df = pd.concat(preds_lstm)\npreds_lstm_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_hyb1 = []\n\nfor df, preds in [(public_df, hyb1_public_preds), (private_df, hyb1_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_hyb1.append(single_df)\n\npreds_hyb1_df = pd.concat(preds_hyb1)\npreds_hyb1_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_hyb2 = []\n\nfor df, preds in [(public_df, hyb2_public_preds), (private_df, hyb2_private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_hyb2.append(single_df)\n\npreds_hyb2_df = pd.concat(preds_hyb2)\npreds_hyb2_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blend_preds_df = pd.DataFrame()\nblend_preds_df['id_seqpos'] = preds_gru_df['id_seqpos']\nblend_preds_df['reactivity'] = 0.25*preds_gru_df['reactivity'] + 0.25*preds_lstm_df['reactivity'] + 0.25*preds_hyb1_df['reactivity'] + 0.25*preds_hyb2_df['reactivity']\nblend_preds_df['deg_Mg_pH10'] = 0.25*preds_gru_df['deg_Mg_pH10'] + 0.25*preds_lstm_df['deg_Mg_pH10'] + 0.25*preds_hyb1_df['deg_Mg_pH10'] + 0.25*preds_hyb2_df['deg_Mg_pH10']\nblend_preds_df['deg_pH10'] = 0.25*preds_gru_df['deg_pH10'] + 0.25*preds_lstm_df['deg_pH10'] + 0.25*preds_hyb1_df['deg_pH10'] + 0.25*preds_hyb2_df['deg_pH10']\nblend_preds_df['deg_Mg_50C'] = 0.25*preds_gru_df['deg_Mg_50C'] + 0.25*preds_lstm_df['deg_Mg_50C'] + 0.25*preds_hyb1_df['deg_Mg_50C'] + 0.25*preds_hyb2_df['deg_Mg_50C']\nblend_preds_df['deg_50C'] = 0.25*preds_gru_df['deg_50C'] + 0.25*preds_lstm_df['deg_50C'] + 0.25*preds_hyb1_df['deg_50C'] + 0.25*preds_hyb2_df['deg_Mg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_df[['id_seqpos']].merge(blend_preds_df, on=['id_seqpos'])\n\n#sanity check\nsubmission.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nprint('Submission saved')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n\n# create a link to download the dataframe\ncreate_download_link(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}