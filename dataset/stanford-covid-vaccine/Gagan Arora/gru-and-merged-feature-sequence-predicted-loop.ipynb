{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This is based on [this notebook](https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model) by [xhlulu](https://www.kaggle.com/xhlulu) and added few functions. Here I have combined 2 new features, sequence and predicted loop type.**\n\n**Example: Sequence='xyz...' predicte_loop_type='abc....' then new feature is 'xaybzc...' where xa,yb, zc is tokenized. This could have potential positive impact in training if merged sequence have better correlation with the reactivity and deg_* variables. In coming days I will be experimenting with more merge feature.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\n\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport tensorflow.keras.layers as L\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set seed to ensure reproducibility"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.random.set_seed(19)\nnp.random.seed(19)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper functions and useful variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will tell us the columns we are predicting\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = tf.random.normal((32, 68, 3))\ny_pred = tf.random.normal((32, 68, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(\n        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pandas_list_to_array(df):\n    \"\"\"\n    Input: dataframe of shape (x, y), containing list of length l\n    Return: np.array of shape (x, l, y)\n    \"\"\"\n    \n    return np.transpose(\n        np.array(df.values.tolist()),\n        (0,2, 1)\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, token2int, cols=['sequence', 'structure', 'predicted_loop_type','seq_loop']):\n    return pandas_list_to_array(\n        df[cols].applymap(lambda seq: [token2int[x] for x in seq])\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def addExtraCol(df):\n    seq_list=list(df['sequence'])\n    pre_list=list(df['predicted_loop_type'])\n    seq_loop_list=[]\n    for i in range(len(seq_list)):\n        tmp=''\n        for j in range(len(seq_list[i])):\n            tmp=tmp+merged_seq[seq_list[i][j]+pre_list[i][j]]\n        seq_loop_list.append(tmp)\n\n    df['seq_loop']=seq_loop_list\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load and preprocess data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '/kaggle/input/stanford-covid-vaccine/'\ntrain = pd.read_json(data_dir + 'train.json', lines=True)\ntest = pd.read_json(data_dir + 'test.json', lines=True)\nsample_df = pd.read_csv(data_dir + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n[](http://)"},{"metadata":{},"cell_type":"markdown","source":"**Sequence has 4 unique chracters and predicted loop types contains 7 unique character. We can use characters abcde....xyz12 to reprsent 28 characters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Sequence=['A', 'G', 'U', 'C']\nPredicted_loop_types= ['S','M','I','B','H','E','X']\nchars='abcdefghijklmnopqrstuvwxyz12'\nmerged_seq={}\ni=0\nfor s in Sequence:\n    for p in Predicted_loop_types:\n        merged_seq[s+p]=chars[i]\n        i=i+1\n        \nprint(merged_seq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.query(\"signal_to_noise >= 1\")\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Adding new coolum seq_loop which pairwise string of sequence and predicted loop type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=addExtraCol(train)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use this dictionary to map each character to an integer\n# so that it can be used as an input in keras\ntoken2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\nprint(len(token2int))\n\ni=14\nfor k,v in merged_seq.items():\n    token2int[v]=i\n    i=i+1\n    \n    \nprint(token2int)\n\ntrain_inputs = preprocess_inputs(train, token2int)\ntrain_labels = pandas_list_to_array(train[pred_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(\n    train_inputs, train_labels, test_size=.1, random_state=34, stratify=train.SN_filter)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Public and private sets have different sequence lengths, so we will preprocess them separately and load models of different tensor shapes."},{"metadata":{"trusted":true},"cell_type":"code","source":"test=addExtraCol(test)\npublic_df = test.query(\"seq_length == 107\")\nprivate_df = test.query(\"seq_length == 130\")\n\n\npublic_inputs = preprocess_inputs(public_df, token2int)\nprivate_inputs = preprocess_inputs(private_df, token2int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build and train model\n\nWe will train a bi-directional GRU model. It has three layer and has dropout. To learn more about RNNs, LSTM and GRU, please see [this blog post](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(embed_size, \n                seq_len=107, \n                pred_len=68, \n                dropout=0.4, \n                sp_dropout=0.2,\n                embed_dim=200, \n                hidden_dim=256, \n                n_layers=3):\n    \n    inputs = L.Input(shape=(seq_len, 4))\n    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    \n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n    )\n    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n    \n    for x in range(n_layers):\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :pred_len]\n    out = L.Dense(5, activation='linear')(truncated)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(tf.optimizers.Adam(learning_rate=0.0025,\n    beta_1=0.8,\n    beta_2=0.999,\n    epsilon=1e-07), loss=MCRMSE)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodel = build_model(embed_size=len(token2int))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"history = model.fit(\n    x_train, y_train,\n    #sample_weight=x_train_sn,\n    validation_data=(x_val, y_val),\n    batch_size=64,\n    epochs=70,\n    verbose=2,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5')\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(\n    history.history, y=['loss', 'val_loss'],\n    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n    title='Training History')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate training history\n\nLet's use Plotly to quickly visualize the training and validation loss throughout the epochs."},{"metadata":{},"cell_type":"markdown","source":"## Load models and make predictions"},{"metadata":{},"cell_type":"markdown","source":"Public and private sets have different sequence lengths, so we will preprocess them separately and load models of different tensor shapes. This is possible because RNN models can accept sequences of varying lengths as inputs."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Caveat: The prediction format requires the output to be the same length as the input,\n# although it's not the case for the training data.\nmodel_public = build_model(seq_len=107, pred_len=107, embed_size=len(token2int))\nmodel_private = build_model(seq_len=130, pred_len=130, embed_size=len(token2int))\n\nmodel_public.load_weights('model.h5')\nmodel_private.load_weights('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_preds = model_public.predict(public_inputs)\nprivate_preds = model_private.predict(private_inputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Post-processing and submit"},{"metadata":{},"cell_type":"markdown","source":"For each sample, we take the predicted tensors of shape (107, 5) or (130, 5), and convert them to the long format (i.e. $629 \\times 107, 5$ or $3005 \\times 130, 5$):"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_ls = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}