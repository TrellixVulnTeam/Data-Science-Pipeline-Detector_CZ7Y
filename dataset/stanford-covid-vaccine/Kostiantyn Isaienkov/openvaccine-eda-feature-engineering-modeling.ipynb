{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>OpenVaccine || EDA || Feature engineering || Modeling</center></h1>\n\n<center><img src=\"https://daslab.stanford.edu/site_data/news_img/openvaccine_lores.png\"></center>"},{"metadata":{},"cell_type":"markdown","source":"### In this kernel I am going to present some basic data overview, feature engineering and prepare keras neural network model. Let's fo it and have fun!\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation</center></h2>\n\n* [1. Quick Data Overview](#1)\n* [2. Sample Analysis](#2)\n* [3. Feature Engineering](#3)\n* [4. Keras Neural Network Model](#4)\n* [5. Prepare submission file](#5)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:black; border:0; color:white'><center>1. Quick Data Overview</center><h2>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport plotly.express as px\nfrom collections import Counter as count\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input, Dense\nfrom sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n\nprint('Train shapes: ', train.shape)\nprint('Test shapes: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### So we have 2400 sequences in training set and 3634 in test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check all training features"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"seq_scored\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As we can see every sequence from training set has only 68 scored bases (first 68 bases)."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.histogram(\n    train, \n    \"signal_to_noise\", \n    nbins=25, \n    title='signal_to_noise column distribution', \n    width=700,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = train['SN_filter'].value_counts().reset_index()\nds.columns = ['SN_filter', 'count']\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"SN_filter\", \n    title='SN_filter bar chart', \n    width=500, \n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['seq_length'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['seq_length'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['seq_scored'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['seq_scored'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:black; border:0; color:white'><center>2. Sample Analysis</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"#### Let's explore 1 sample from train set. We will focus on some columns and see values."},{"metadata":{},"cell_type":"markdown","source":"#### We have 3 columns that represent structure of sequence: sequence, structure and predicted_loop_type"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sample = train.iloc[0]\nsample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Sequence"},{"metadata":{},"cell_type":"markdown","source":"### We have 4 possible nitrogeneous bases for RNA:\n\n1) Guanine (G) <br>\n2) Adenine (A) <br>\n3) Cytosine (C) <br>\n4) Uracil (U) <br>\n\n#### For more details you can check <a href=\"https://en.wikipedia.org/wiki/Nucleobase\">here.</a>\n\n<center><img src=\"https://www.thoughtco.com/thmb/jnQVk0_RZ4TRJHeFKR7xxqSV1Pk=/1500x1000/filters:fill(auto,1)/dna-versus-rna-608191_sketch_Final-54acdd8f8af04c73817e8811c32905fa.png\" width=\"700\" height=\"500\"></center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['sequence']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(count(sample['sequence']))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"bases = []\n\nfor j in range(len(train)):\n    counts = dict(count(train.iloc[j]['sequence']))\n    bases.append((\n        counts['A'] / 107,\n        counts['G'] / 107,\n        counts['C'] / 107,\n        counts['U'] / 107\n    ))\n    \nbases = pd.DataFrame(bases, columns=['A_percent', 'G_percent', 'C_percent', 'U_percent'])\nbases","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The length of sequence should be equal to value in ```seq_length``` column"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sample['sequence']) == sample['seq_length']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['structure']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Here we can see 3 different types of characters. Chaacter ```.``` means that base is without pair. ```(``` - is start of pair, ```)``` - the end for current pair. So the number of ```(``` should be equal to ```)```."},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(count(sample['structure']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs_rate = []\n\nfor j in range(len(train)):\n    res = dict(count(train.iloc[j]['structure']))\n    pairs_rate.append(res['('] / 53.5)\n    \npairs_rate = pd.DataFrame(pairs_rate, columns=['pairs_rate'])\npairs_rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check all pairs for our sample"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pairs_dict = {}\nqueue = []\nfor i in range(0, len(sample['structure'])):\n    if sample['structure'][i] == '(':\n        queue.append(i)\n    if sample['structure'][i] == ')':\n        first = queue.pop()\n        try:\n            pairs_dict[(sample['sequence'][first], sample['sequence'][i])] += 1\n        except:\n            pairs_dict[(sample['sequence'][first], sample['sequence'][i])] = 1\npairs_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs = []\nall_partners = []\nfor j in range(len(train)):\n    partners = [-1 for i in range(130)]\n    pairs_dict = {}\n    queue = []\n    for i in range(0, len(train.iloc[j]['structure'])):\n        if train.iloc[j]['structure'][i] == '(':\n            queue.append(i)\n        if train.iloc[j]['structure'][i] == ')':\n            first = queue.pop()\n            try:\n                pairs_dict[(train.iloc[j]['sequence'][first], train.iloc[j]['sequence'][i])] += 1\n            except:\n                pairs_dict[(train.iloc[j]['sequence'][first], train.iloc[j]['sequence'][i])] = 1\n                \n            partners[first] = i\n            partners[i] = first\n    \n    all_partners.append(partners)\n    \n    pairs_num = 0\n    pairs_unique = [('U', 'G'), ('C', 'G'), ('U', 'A'), ('G', 'C'), ('A', 'U'), ('G', 'U')]\n    for item in pairs_dict:\n        pairs_num += pairs_dict[item]\n    add_tuple = list()\n    for item in pairs_unique:\n        try:\n            add_tuple.append(pairs_dict[item]/pairs_num)\n        except:\n            add_tuple.append(0)\n    pairs.append(add_tuple)\n    \npairs = pd.DataFrame(pairs, columns=['U-G', 'C-G', 'U-A', 'G-C', 'A-U', 'G-U'])\npairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['partners'] = all_partners","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's do it for all samples"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pairs_dict = {}\nqueue = []\nfor j in range(len(train)):\n    sam = train.iloc[j]\n    for i in range(0, len(sam['structure'])):\n        if sam['structure'][i] == '(':\n            queue.append(i)\n        if sam['structure'][i] == ')':\n            first = queue.pop()\n            try:\n                pairs_dict[(sam['sequence'][first], sam['sequence'][i])] += 1\n            except:\n                pairs_dict[(sam['sequence'][first], sam['sequence'][i])] = 1\n                \npairs_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Basically I don't know now is ('C', 'G') and ('G', 'C') the same - so I leave it as is."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"names = []\nvalues = []\nfor item in pairs_dict:\n    names.append(item)\n    values.append(pairs_dict[item])\n    \ndf = pd.DataFrame()\ndf['pair'] = names\ndf['count'] = values\ndf['pair'] = df['pair'].astype(str)\n\nfig = px.bar(\n    df, \n    x='pair', \n    y=\"count\", \n    orientation='v', \n    title='Pair types', \n    height=400, \n    width=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can see that the most popular pair is with G and C, the less popular with U and G. And there is only 3 possible combinations of pairs - G and C, U and G, U and A."},{"metadata":{},"cell_type":"markdown","source":"### 3. Predicted loop type"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['predicted_loop_type']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"S: paired \"Stem\" <br>\nM: Multiloop  <br>\nI: Internal loop <br>\nB: Bulge <br>\nH: Hairpin loop <br>\nE: dangling End <br>\nX: eXternal loop <br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(count(sample['predicted_loop_type']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loops = []\nfor j in range(len(train)):\n    counts = dict(count(train.iloc[j]['predicted_loop_type']))\n    available = ['E', 'S', 'H', 'B', 'X', 'I', 'M']\n    row = []\n    for item in available:\n        try:\n            row.append(counts[item] / 107)\n        except:\n            row.append(0)\n    loops.append(row)\n    \nloops = pd.DataFrame(loops, columns=available)\nloops","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check for all samples"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"res_dict = {}\nfor j in range(len(train)):\n    sam = train.iloc[j]\n    prom = dict(count(sam['predicted_loop_type']))\n    for item in prom:\n        try:\n            res_dict[item] += prom[item]\n        except:\n            res_dict[item] = prom[item]\nres_dict","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"names = []\nvalues = []\nfor item in res_dict:\n    names.append(item)\n    values.append(res_dict[item])\n    \ndf = pd.DataFrame()\ndf['loop_type'] = names\ndf['count'] = values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(\n    df, \n    x='loop_type', \n    y=\"count\", \n    orientation='v', \n    title='Predicted loop types', \n    height=400, \n    width=600\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:black; border:0; color:white'><center>3. Feature Engineering</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"### From documentation:\n\n```\nAt the beginning of the competition, Stanford scientists have data on 3029 RNA sequences of length 107. \nFor technical reasons, measurements cannot be carried out on the final bases of these RNA sequences, so we have experimental data (ground truth) in 5 conditions for the first 68 bases.\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([train, bases, pairs, loops, pairs_rate], axis=1)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = []\nfor mol_id in train['id'].unique():\n    sample_data = train.loc[train['id'] == mol_id]\n    for i in range(68): \n        if i < 3:\n            previousA = -1\n            previousB = -1\n            previousC = -1\n        else:\n            if i%3 == 0:\n                previousA = sample_data['sequence'].values[0][i - 3]\n                previousB = sample_data['sequence'].values[0][i - 2]\n                previousC = sample_data['sequence'].values[0][i - 1]\n            if i%3 == 1:\n                previousA = sample_data['sequence'].values[0][i - 4]\n                previousB = sample_data['sequence'].values[0][i - 3]\n                previousC = sample_data['sequence'].values[0][i - 2]\n            if i%3 == 2:\n                previousA = sample_data['sequence'].values[0][i - 5]\n                previousB = sample_data['sequence'].values[0][i - 4]\n                previousC = sample_data['sequence'].values[0][i - 3]\n            \n            \n        if i%3 == 0:\n            a = sample_data['sequence'].values[0][i]\n            b = sample_data['sequence'].values[0][i + 1]\n            c = sample_data['sequence'].values[0][i + 2]\n            \n            nextA = sample_data['sequence'].values[0][i + 3]\n            nextB = sample_data['sequence'].values[0][i + 4]\n            nextC = sample_data['sequence'].values[0][i + 5]\n            next2A = sample_data['sequence'].values[0][i + 6]\n            next2B = sample_data['sequence'].values[0][i + 7]\n            next2C = sample_data['sequence'].values[0][i + 8]\n            next3A = sample_data['sequence'].values[0][i + 9]\n            next3B = sample_data['sequence'].values[0][i + 10]\n            next3C = sample_data['sequence'].values[0][i + 11]\n            \n        if i%3 == 1:\n            a = sample_data['sequence'].values[0][i - 1]\n            b = sample_data['sequence'].values[0][i]\n            c = sample_data['sequence'].values[0][i + 1]\n            \n            nextA = sample_data['sequence'].values[0][i + 2]\n            nextB = sample_data['sequence'].values[0][i + 3]\n            nextC = sample_data['sequence'].values[0][i + 4]\n            next2A = sample_data['sequence'].values[0][i + 5]\n            next2B = sample_data['sequence'].values[0][i + 6]\n            next2C = sample_data['sequence'].values[0][i + 7]\n            next3A = sample_data['sequence'].values[0][i + 8]\n            next3B = sample_data['sequence'].values[0][i + 9]\n            next3C = sample_data['sequence'].values[0][i + 10]\n            \n        if i%3 == 2:\n            a = sample_data['sequence'].values[0][i - 2]\n            b = sample_data['sequence'].values[0][i - 1]\n            c = sample_data['sequence'].values[0][i]\n            \n            nextA = sample_data['sequence'].values[0][i + 1]\n            nextB = sample_data['sequence'].values[0][i + 2]\n            nextC = sample_data['sequence'].values[0][i + 3]\n            next2A = sample_data['sequence'].values[0][i + 4]\n            next2B = sample_data['sequence'].values[0][i + 5]\n            next2C = sample_data['sequence'].values[0][i + 6]\n            next3A = sample_data['sequence'].values[0][i + 7]\n            next3B = sample_data['sequence'].values[0][i + 8]\n            next3C = sample_data['sequence'].values[0][i + 9]\n            \n        if a==b and b==c:\n            all_the_same = 1\n        else:\n            all_the_same = 0\n            \n        if sample_data['structure'].values[0][i] == ')' or sample_data['structure'].values[0][i] == '(':\n            isPair = 1\n        else:\n            isPair = 0\n        \n        partner_index = sample_data['partners'].values[0][i]\n        if partner_index != -1:\n            partner =  sample_data['sequence'].values[0][partner_index]\n        else:\n            partner = -1\n        \n        sample_tuple = (\n            sample_data['id'].values[0], \n            sample_data['sequence'].values[0][i],\n            sample_data['structure'].values[0][i], \n            sample_data['predicted_loop_type'].values[0][i],\n            sample_data['reactivity'].values[0][i], \n            sample_data['reactivity_error'].values[0][i],\n            sample_data['deg_Mg_pH10'].values[0][i], \n            sample_data['deg_error_Mg_pH10'].values[0][i],\n            sample_data['deg_pH10'].values[0][i], \n            sample_data['deg_error_pH10'].values[0][i],\n            sample_data['deg_Mg_50C'].values[0][i], \n            sample_data['deg_error_Mg_50C'].values[0][i],\n            sample_data['deg_50C'].values[0][i], \n            sample_data['deg_error_50C'].values[0][i],\n            sample_data['A_percent'].values[0], \n            sample_data['G_percent'].values[0],\n            sample_data['C_percent'].values[0], \n            sample_data['U_percent'].values[0],\n            sample_data['U-G'].values[0], \n            sample_data['C-G'].values[0],\n            sample_data['U-A'].values[0], \n            sample_data['G-C'].values[0],\n            sample_data['A-U'].values[0], \n            sample_data['G-U'].values[0], \n            sample_data['E'].values[0],\n            sample_data['S'].values[0], \n            sample_data['H'].values[0],\n            sample_data['B'].values[0], \n            sample_data['X'].values[0],\n            sample_data['I'].values[0], \n            sample_data['M'].values[0],\n            sample_data['pairs_rate'].values[0],\n            i%3,\n            a,\n            b,\n            c,\n            (i%107) / 68,\n            all_the_same, \n            isPair,\n            previousA,\n            previousB,\n            previousC,\n            nextA,\n            nextB,\n            nextC,\n            next2A,\n            next2B,\n            next2C,\n            next3A,\n            next3B,\n            next3C,\n            partner\n        )\n        train_data.append(sample_tuple)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.DataFrame(\n    train_data, \n    columns=[\n        'id', \n        'sequence', \n        'structure', \n        'predicted_loop_type', \n        'reactivity', \n        'reactivity_error', \n        'deg_Mg_pH10', \n        'deg_error_Mg_pH10',\n        'deg_pH10', \n        'deg_error_pH10', \n        'deg_Mg_50C', \n        'deg_error_Mg_50C', \n        'deg_50C', \n        'deg_error_50C',\n        'A_percent',\n        'G_percent',\n        'C_percent',\n        'U_percent',\n        'U-G', \n        'C-G',\n        'U-A', \n        'G-C',\n        'A-U', \n        'G-U', \n        'E',\n        'S', \n        'H',\n        'B', \n        'X',\n        'I', \n        'M',\n        'pairs_rate',\n        'codon_position',\n        'base_0',\n        'base_1',\n        'base_2',\n        'general_position',\n        'all_bases_same',\n        'isPair',\n        'prevCodon_0',\n        'prevCodon_1',\n        'prevCodon_2',\n        'nextCodon_0',\n        'nextCodon_1',\n        'nextCodon_2',\n        'next2Codon_0',\n        'next2Codon_1',\n        'next2Codon_2',\n        'next3Codon_0',\n        'next3Codon_1',\n        'next3Codon_2',\n        'partner'\n    ])\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bases = []\nfor j in range(len(test)):\n    counts = dict(count(test.iloc[j]['sequence']))\n    bases.append((\n        counts['A'] / test.iloc[j]['seq_length'],\n        counts['G'] / test.iloc[j]['seq_length'],\n        counts['C'] / test.iloc[j]['seq_length'],\n        counts['U'] / test.iloc[j]['seq_length']\n    ))\n    \nbases = pd.DataFrame(bases, columns=['A_percent', 'G_percent', 'C_percent', 'U_percent'])\nbases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs = []\nall_partners = []\nfor j in range(len(test)):\n    partners = [-1 for i in range(130)]\n    pairs_dict = {}\n    queue = []\n    for i in range(0, len(test.iloc[j]['structure'])):\n        if test.iloc[j]['structure'][i] == '(':\n            queue.append(i)\n        if test.iloc[j]['structure'][i] == ')':\n            first = queue.pop()\n            try:\n                pairs_dict[(test.iloc[j]['sequence'][first], test.iloc[j]['sequence'][i])] += 1\n            except:\n                pairs_dict[(test.iloc[j]['sequence'][first], test.iloc[j]['sequence'][i])] = 1\n                \n            partners[first] = i\n            partners[i] = first\n    \n    all_partners.append(partners)\n    \n    pairs_num = 0\n    pairs_unique = [('U', 'G'), ('C', 'G'), ('U', 'A'), ('G', 'C'), ('A', 'U'), ('G', 'U')]\n    for item in pairs_dict:\n        pairs_num += pairs_dict[item]\n    add_tuple = list()\n    for item in pairs_unique:\n        try:\n            add_tuple.append(pairs_dict[item]/pairs_num)\n        except:\n            add_tuple.append(0)\n    pairs.append(add_tuple)\n    \npairs = pd.DataFrame(pairs, columns=['U-G', 'C-G', 'U-A', 'G-C', 'A-U', 'G-U'])\npairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['partners'] = all_partners","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs_rate = []\nfor j in range(len(test)):\n    res = dict(count(test.iloc[j]['structure']))\n    pairs_rate.append(res['('] / (test.iloc[j]['seq_length']/2))\n    \npairs_rate = pd.DataFrame(pairs_rate, columns=['pairs_rate'])\npairs_rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loops = []\nfor j in range(len(test)):\n    counts = dict(count(test.iloc[j]['predicted_loop_type']))\n    available = ['E', 'S', 'H', 'B', 'X', 'I', 'M']\n    row = []\n    for item in available:\n        try:\n            row.append(counts[item] / test.iloc[j]['seq_length'])\n        except:\n            row.append(0)\n    loops.append(row)\n    \nloops = pd.DataFrame(loops, columns=available)\nloops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.concat([test, bases, pairs, loops, pairs_rate], axis=1)\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = []\nfor mol_id in test['id'].unique():\n    sample_data = test.loc[test['id'] == mol_id]\n    for i in range(sample_data['seq_scored'].values[0]):\n        if i < 3:\n            previousA = -1\n            previousB = -1\n            previousC = -1\n        else:\n            if i%3 == 0:\n                previousA = sample_data['sequence'].values[0][i - 3]\n                previousB = sample_data['sequence'].values[0][i - 2]\n                previousC = sample_data['sequence'].values[0][i - 1]\n            if i%3 == 1:\n                previousA = sample_data['sequence'].values[0][i - 4]\n                previousB = sample_data['sequence'].values[0][i - 3]\n                previousC = sample_data['sequence'].values[0][i - 2]\n            if i%3 == 2:\n                previousA = sample_data['sequence'].values[0][i - 5]\n                previousB = sample_data['sequence'].values[0][i - 4]\n                previousC = sample_data['sequence'].values[0][i - 3]\n                    \n        if i%3 == 0:\n            a = sample_data['sequence'].values[0][i]\n            b = sample_data['sequence'].values[0][i + 1]\n            c = sample_data['sequence'].values[0][i + 2]\n            \n            nextA = sample_data['sequence'].values[0][i + 3]\n            nextB = sample_data['sequence'].values[0][i + 4]\n            nextC = sample_data['sequence'].values[0][i + 5]\n            next2A = sample_data['sequence'].values[0][i + 6]\n            next2B = sample_data['sequence'].values[0][i + 7]\n            next2C = sample_data['sequence'].values[0][i + 8]\n            next3A = sample_data['sequence'].values[0][i + 9]\n            next3B = sample_data['sequence'].values[0][i + 10]\n            next3C = sample_data['sequence'].values[0][i + 11]\n            \n        if i%3 == 1:\n            a = sample_data['sequence'].values[0][i - 1]\n            b = sample_data['sequence'].values[0][i]\n            c = sample_data['sequence'].values[0][i + 1]\n            \n            nextA = sample_data['sequence'].values[0][i + 2]\n            nextB = sample_data['sequence'].values[0][i + 3]\n            nextC = sample_data['sequence'].values[0][i + 4]\n            next2A = sample_data['sequence'].values[0][i + 5]\n            next2B = sample_data['sequence'].values[0][i + 6]\n            next2C = sample_data['sequence'].values[0][i + 7]\n            next3A = sample_data['sequence'].values[0][i + 8]\n            next3B = sample_data['sequence'].values[0][i + 9]\n            next3C = sample_data['sequence'].values[0][i + 10]\n            \n        if i%3 == 2:\n            a = sample_data['sequence'].values[0][i - 2]\n            b = sample_data['sequence'].values[0][i - 1]\n            c = sample_data['sequence'].values[0][i]\n            \n            nextA = sample_data['sequence'].values[0][i + 1]\n            nextB = sample_data['sequence'].values[0][i + 2]\n            nextC = sample_data['sequence'].values[0][i + 3]\n            next2A = sample_data['sequence'].values[0][i + 4]\n            next2B = sample_data['sequence'].values[0][i + 5]\n            next2C = sample_data['sequence'].values[0][i + 6]\n            next3A = sample_data['sequence'].values[0][i + 7]\n            next3B = sample_data['sequence'].values[0][i + 8]\n            next3C = sample_data['sequence'].values[0][i + 9]\n            \n        if a==b and b==c:\n            all_the_same = 1\n        else:\n            all_the_same = 0\n            \n        if sample_data['structure'].values[0][i] == ')' or sample_data['structure'].values[0][i] == '(':\n            isPair = 1\n        else:\n            isPair = 0\n            \n        partner_index = sample_data['partners'].values[0][i]\n        if partner_index != -1:\n            partner =  sample_data['sequence'].values[0][partner_index]\n        else:\n            partner = -1\n            \n        sample_tuple = (\n            sample_data['id'].values[0] + f'_{i}', \n            sample_data['sequence'].values[0][i],\n            sample_data['structure'].values[0][i], \n            sample_data['predicted_loop_type'].values[0][i],\n            sample_data['A_percent'].values[0], \n            sample_data['G_percent'].values[0],\n            sample_data['C_percent'].values[0], \n            sample_data['U_percent'].values[0],\n            sample_data['U-G'].values[0], \n            sample_data['C-G'].values[0],\n            sample_data['U-A'].values[0], \n            sample_data['G-C'].values[0],\n            sample_data['A-U'].values[0], \n            sample_data['G-U'].values[0], \n            sample_data['E'].values[0],\n            sample_data['S'].values[0], \n            sample_data['H'].values[0],\n            sample_data['B'].values[0], \n            sample_data['X'].values[0],\n            sample_data['I'].values[0], \n            sample_data['M'].values[0],\n            sample_data['pairs_rate'].values[0],\n            i%3,\n            a,\n            b,\n            c,\n            (i%sample_data['seq_scored'].values[0]) / sample_data['seq_scored'].values[0],\n            all_the_same, \n            isPair,\n            previousA,\n            previousB,\n            previousC,\n            nextA,\n            nextB,\n            nextC,\n            next2A,\n            next2B,\n            next2C,\n            next3A,\n            next3B,\n            next3C,\n            partner\n        )\n        test_data.append(sample_tuple)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.DataFrame(\n    test_data, \n    columns=[\n        'id', \n        'sequence', \n        'structure', \n        'predicted_loop_type', \n        'A_percent',\n        'G_percent',\n        'C_percent',\n        'U_percent',\n        'U-G', \n        'C-G',\n        'U-A', \n        'G-C',\n        'A-U', \n        'G-U', \n        'E',\n        'S', \n        'H',\n        'B', \n        'X',\n        'I', \n        'M',\n        'pairs_rate',\n        'codon_position',\n        'base_0',\n        'base_1',\n        'base_2',\n        'general_position',\n        'all_bases_same',\n        'isPair',\n        'prevCodon_0',\n        'prevCodon_1',\n        'prevCodon_2',        \n        'nextCodon_0',\n        'nextCodon_1',\n        'nextCodon_2',        \n        'next2Codon_0',\n        'next2Codon_1',\n        'next2Codon_2',\n        'next3Codon_0',\n        'next3Codon_1',\n        'next3Codon_2',\n        'partner'\n    ])\ntest_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq = pd.get_dummies(train_data['sequence'], prefix='Base')\nstruc = pd.get_dummies(train_data['structure'], prefix='Structure')\nloop = pd.get_dummies(train_data['predicted_loop_type'], prefix='Loop')\nposition = pd.get_dummies(train_data['codon_position'], prefix='Position')\nbase0 = pd.get_dummies(train_data['base_0'], prefix='Base0')\nbase1 = pd.get_dummies(train_data['base_1'], prefix='Base1')\nbase2 = pd.get_dummies(train_data['base_2'], prefix='Base2')\ncodon0 = pd.get_dummies(train_data['prevCodon_0'], prefix='prevCodon0')\ncodon1 = pd.get_dummies(train_data['prevCodon_1'], prefix='prevCodon1')\ncodon2 = pd.get_dummies(train_data['prevCodon_2'], prefix='prevCodon2') \nnext_codon0 = pd.get_dummies(train_data['nextCodon_0'], prefix='nextCodon0')\nnext_codon1 = pd.get_dummies(train_data['nextCodon_1'], prefix='nextCodon1')\nnext_codon2 = pd.get_dummies(train_data['nextCodon_2'], prefix='nextCodon2')\nnext2_codon0 = pd.get_dummies(train_data['next2Codon_0'], prefix='next2Codon0')\nnext2_codon1 = pd.get_dummies(train_data['next2Codon_1'], prefix='next2Codon1')\nnext2_codon2 = pd.get_dummies(train_data['next2Codon_2'], prefix='next2Codon2')\nnext3_codon0 = pd.get_dummies(train_data['next3Codon_0'], prefix='next3Codon0')\nnext3_codon1 = pd.get_dummies(train_data['next3Codon_1'], prefix='next3Codon1')\nnext3_codon2 = pd.get_dummies(train_data['next3Codon_2'], prefix='next3Codon2')\npart = pd.get_dummies(train_data['partner'], prefix='partner')\n\ntrain_set = pd.concat([seq, struc, loop, position, base0, base1, base2, codon0, codon1, codon2, \n                       next_codon0, next_codon1, next_codon2, next2_codon0, next2_codon1, next2_codon2, next3_codon0, next3_codon1, next3_codon2, part, train_data], \n                      axis=1).drop(['sequence', 'structure', 'predicted_loop_type', 'codon_position', 'base_0', \n                                    'base_1', 'base_2', 'prevCodon_0', 'prevCodon_1', 'prevCodon_2', \n                                    'nextCodon_0', 'nextCodon_1', 'nextCodon_2', 'next2Codon_0', 'next2Codon_1', 'next2Codon_2',\n                                    'next3Codon_0', 'next3Codon_1', 'next3Codon_2', 'partner'], axis=1)\ntrain_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq = pd.get_dummies(test_data['sequence'], prefix='Base')\nstruc = pd.get_dummies(test_data['structure'], prefix='Structure')\nloop = pd.get_dummies(test_data['predicted_loop_type'], prefix='Loop')\nposition = pd.get_dummies(test_data['codon_position'], prefix='Position')\nbase0 = pd.get_dummies(test_data['base_0'], prefix='Base0')\nbase1 = pd.get_dummies(test_data['base_1'], prefix='Base1')\nbase2 = pd.get_dummies(test_data['base_2'], prefix='Base2')\ncodon0 = pd.get_dummies(test_data['prevCodon_0'], prefix='prevCodon0')\ncodon1 = pd.get_dummies(test_data['prevCodon_1'], prefix='prevCodon1')\ncodon2 = pd.get_dummies(test_data['prevCodon_2'], prefix='prevCodon2') \nnext_codon0 = pd.get_dummies(test_data['nextCodon_0'], prefix='nextCodon0')\nnext_codon1 = pd.get_dummies(test_data['nextCodon_1'], prefix='nextCodon1')\nnext_codon2 = pd.get_dummies(test_data['nextCodon_2'], prefix='nextCodon2') \nnext2_codon0 = pd.get_dummies(test_data['next2Codon_0'], prefix='next2Codon0')\nnext2_codon1 = pd.get_dummies(test_data['next2Codon_1'], prefix='next2Codon1')\nnext2_codon2 = pd.get_dummies(test_data['next2Codon_2'], prefix='next2Codon2')\nnext3_codon0 = pd.get_dummies(test_data['next3Codon_0'], prefix='next3Codon0')\nnext3_codon1 = pd.get_dummies(test_data['next3Codon_1'], prefix='next3Codon1')\nnext3_codon2 = pd.get_dummies(test_data['next3Codon_2'], prefix='next3Codon2')\npart = pd.get_dummies(test_data['partner'], prefix='partner')\n\ntest_set = pd.concat([seq, struc, loop, position, base0, base1, base2, codon0, codon1, codon2, \n                       next_codon0, next_codon1, next_codon2, next2_codon0, next2_codon1, next2_codon2, next3_codon0, next3_codon1, next3_codon2, part, test_data], \n                      axis=1).drop(['sequence', 'structure', 'predicted_loop_type', 'codon_position', 'base_0', \n                                    'base_1', 'base_2', 'prevCodon_0', 'prevCodon_1', 'prevCodon_2', \n                                    'nextCodon_0', 'nextCodon_1', 'nextCodon_2', 'next2Codon_0', 'next2Codon_1', 'next2Codon_2',\n                                    'next3Codon_0', 'next3Codon_1', 'next3Codon_2', 'partner'], axis=1)\ntest_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target = train_set[['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']]\ntrain_set = train_set.drop(['id', 'reactivity', 'reactivity_error', 'deg_Mg_pH10', 'deg_error_Mg_pH10', 'deg_pH10', 'deg_error_pH10',\n                            'deg_Mg_50C', 'deg_error_Mg_50C', 'deg_50C', 'deg_error_50C'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = test_set['id']\ntest_set = test_set.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_columns = ['partner_-1', 'prevCodon1_-1', 'prevCodon2_-1', 'isPair', 'pairs_rate']\n\ntrain_set = train_set.drop(drop_columns, axis=1)\ntest_set = test_set.drop(drop_columns, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h2 style='background:black; border:0; color:white'><center>4. Keras Neural Network Model</center><h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE(y_true, y_pred):\n    colwise_mse = K.mean(K.square(y_true - y_pred))\n    return K.mean(K.sqrt(colwise_mse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(101),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(500, activation=\"relu\"),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.6),\n        tf.keras.layers.Dense(50, activation=\"relu\"),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(3, activation=\"elu\")\n    ])\n    model.compile(optimizer='adam', loss=MCRMSE)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse\nimport math\n\ndef rmse(y_true, y_pred):\n    return math.sqrt(mse(y_true, y_pred)) / 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train_target[['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df = pd.DataFrame()\npreds_df['id'] = test_id\npreds_df.loc[:, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] = 0\nres = target.copy()\nfor n, (tr, te) in enumerate(KFold(n_splits=10, random_state=666, shuffle=True).split(target)):\n    print(f'Fold {n}')\n    \n    model = create_model()\n    \n    model.fit(\n        train_set.values[tr],\n        target.values[tr],\n        epochs=45, \n        batch_size=64\n    )\n    \n    preds_df.loc[:, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] += model.predict(test_set)\n    res.loc[te, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] = model.predict(train_set.values[te])\n    \npreds_df.loc[:, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] /= (n+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics = []\nfor _target in target.columns:\n    metrics.append(rmse(target.loc[:, _target], res.loc[:, _target]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check our cross validation score"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'OOF Metric: {np.mean(metrics)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n<h2 style='background:black; border:0; color:white'><center>5. Prepare submission file</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"#### So the final step is to prepare submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.merge(sub[['id_seqpos']], preds_df, left_on='id_seqpos', right_on='id', how='left').drop(['id'],axis=1)\nsub = sub.fillna(0)\nsub['deg_pH10'] = 0\nsub['deg_50C'] = 0\nsub = sub[['id_seqpos', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']]\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}