{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://gitee.com/greitzmann/ELMo-keras/tree/master/elmo","metadata":{}},{"cell_type":"markdown","source":"Use (tab) for autocompleteting:","metadata":{}},{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:40:31.227735Z","iopub.execute_input":"2022-03-31T15:40:31.227992Z","iopub.status.idle":"2022-03-31T15:40:31.242222Z","shell.execute_reply.started":"2022-03-31T15:40:31.227963Z","shell.execute_reply":"2022-03-31T15:40:31.241375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n__init__.py\nInitial Commit\n\ndropout.py\nFix token character encodings + Improve documentation\n\nhighway.py\nInitial Commit\n\nmasking.py\nFix token character encodings + Improve documentation\n\nsampled_softmax.py\nAdd full Softmax option in projection layer","metadata":{}},{"cell_type":"code","source":"# !pip install tensorflow==1.15\n# this is very vital as the baseline ELMo is just compatible with this V of Tensorflow\n#     ValueError: The two structures don't have the same sequence length. Input structure has length 0, while shallow structure has length 2.\n#Note: Run it just at the beggining of each session for saving time \n!pip install bilm\n!pip install data\n# -*- coding: utf-8 -*-\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:40:31.26248Z","iopub.execute_input":"2022-03-31T15:40:31.2629Z","iopub.status.idle":"2022-03-31T15:40:46.456117Z","shell.execute_reply.started":"2022-03-31T15:40:31.262867Z","shell.execute_reply":"2022-03-31T15:40:46.455221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install 'h5py==2.10.0' --force-reinstall","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:40:46.458891Z","iopub.execute_input":"2022-03-31T15:40:46.459406Z","iopub.status.idle":"2022-03-31T15:40:59.056964Z","shell.execute_reply.started":"2022-03-31T15:40:46.459346Z","shell.execute_reply":"2022-03-31T15:40:59.056121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Degradation Prediction:","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport pandas as pd\nfrom collections import Counter\nimport pandas as pd, numpy as np, seaborn as sns\nimport math, json, os, random\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\nimport tensorflow as tf\n# import tensorflow_addons as tfa\nfrom tensorflow.keras import backend as K\n\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom sklearn.cluster import KMeans\n\nseed = 34\ndef seed_everything(seed= 34):\n    os.environ['PYTHONHASHSEED']=str(seed)\n#     tf.random.set_random_seed(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    \nseed_everything()\n\n\n#get comp data\ntrain = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsample_sub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n\naug_df = pd.read_csv('../input/augmentaion/aug_data.csv')\nprint(aug_df.shape)\n# aug_df.head()\n\n\n\n\n\n#sneak peak\nprint(train.shape)\nif ~train.isnull().values.any(): print('No missing values')\ntrain.head()\n\n#sneak peak\nprint(test.shape)\nif ~test.isnull().values.any(): print('No missing values')\ntest.head()\n\n#sneak peak\nprint(sample_sub.shape)\nif ~sample_sub.isnull().values.any(): print('No missing values')\nsample_sub.head()\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 5))\nsns.kdeplot(train['signal_to_noise'], shade=True, ax=ax[0])\nsns.countplot(train['SN_filter'], ax=ax[1])\n\nax[0].set_title('Signal/Noise Distribution')\nax[1].set_title('Signal/Noise Filter Distribution');\n\nprint(f\"Samples with signal_to_noise greater than 1: {len(train.loc[(train['signal_to_noise'] > 1 )])}\")\nprint(f\"Samples with SN_filter = 1: {len(train.loc[(train['SN_filter'] == 1 )])}\")\nprint(f\"Samples with signal_to_noise greater than 1, but SN_filter == 0: {len(train.loc[(train['signal_to_noise'] > 1) & (train['SN_filter'] == 0)])}\")\n\ndef read_bpps_sum(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").sum(axis=1))\n    return bpps_arr\n\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ndef read_bpps_nb(df):\n    #mean and std from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n    bpps_nb_mean = 0.077522\n    bpps_nb_std = 0.08914\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\")\n        bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n        bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n        bpps_arr.append(bpps_nb)\n    return bpps_arr \n\ntrain['bpps_sum'] = read_bpps_sum(train)\ntest['bpps_sum'] = read_bpps_sum(test)\ntrain['bpps_max'] = read_bpps_max(train)\ntest['bpps_max'] = read_bpps_max(test)\ntrain['bpps_nb'] = read_bpps_nb(train)\ntest['bpps_nb'] = read_bpps_nb(test)\n\n#sanity check\ntrain.head()\n\n\nfig, ax = plt.subplots(3, figsize=(15, 10))\nsns.kdeplot(np.array(train['bpps_max'].to_list()).reshape(-1),\n            color=\"Blue\", ax=ax[0], label='Train')\nsns.kdeplot(np.array(test[test['seq_length'] == 107]['bpps_max'].to_list()).reshape(-1),\n            color=\"Red\", ax=ax[0], label='Public test')\nsns.kdeplot(np.array(test[test['seq_length'] == 130]['bpps_max'].to_list()).reshape(-1),\n            color=\"Green\", ax=ax[0], label='Private test')\nsns.kdeplot(np.array(train['bpps_sum'].to_list()).reshape(-1),\n            color=\"Blue\", ax=ax[1], label='Train')\nsns.kdeplot(np.array(test[test['seq_length'] == 107]['bpps_sum'].to_list()).reshape(-1),\n            color=\"Red\", ax=ax[1], label='Public test')\nsns.kdeplot(np.array(test[test['seq_length'] == 130]['bpps_sum'].to_list()).reshape(-1),\n            color=\"Green\", ax=ax[1], label='Private test')\nsns.kdeplot(np.array(train['bpps_nb'].to_list()).reshape(-1),\n            color=\"Blue\", ax=ax[2], label='Train')\nsns.kdeplot(np.array(test[test['seq_length'] == 107]['bpps_nb'].to_list()).reshape(-1),\n            color=\"Red\", ax=ax[2], label='Public test')\nsns.kdeplot(np.array(test[test['seq_length'] == 130]['bpps_nb'].to_list()).reshape(-1),\n            color=\"Green\", ax=ax[2], label='Private test')\n\nax[0].set_title('Distribution of bpps_max')\nax[1].set_title('Distribution of bpps_sum')\nax[2].set_title('Distribution of bpps_nb')\nplt.tight_layout();\n\nAUGMENT=True \ndef aug_data(df):\n    target_df = df.copy()\n    new_df = aug_df[aug_df['id'].isin(target_df['id'])]\n                         \n    del target_df['structure']\n    del target_df['predicted_loop_type']\n    new_df = new_df.merge(target_df, on=['id','sequence'], how='left')\n\n    df['cnt'] = df['id'].map(new_df[['id','cnt']].set_index('id').to_dict()['cnt'])\n    df['log_gamma'] = 100\n    df['score'] = 1.0\n    df = df.append(new_df[df.columns])\n    return df\n\n\nprint(f\"Samples in train before augmentation: {len(train)}\")\nprint(f\"Samples in test before augmentation: {len(test)}\")\n\nif AUGMENT:\n    train = aug_data(train)\n    test = aug_data(test)\n\nprint(f\"Samples in train after augmentation: {len(train)}\")\nprint(f\"Samples in test after augmentation: {len(test)}\")\n\nprint(f\"Unique sequences in train: {len(train['sequence'].unique())}\")\nprint(f\"Unique sequences in test: {len(test['sequence'].unique())}\")\n\nDENOISE = True\n\n\n\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n\n\n\n\ntoken2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n\n\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    base_fea = np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\n    bpps_sum_fea = np.array(df['bpps_sum'].to_list())[:,:,np.newaxis]\n    bpps_max_fea = np.array(df['bpps_max'].to_list())[:,:,np.newaxis]\n    return np.concatenate([base_fea,bpps_sum_fea,bpps_max_fea], 2)\n\n\nif DENOISE:\n    train = train[train['signal_to_noise'] > .25]\n    \n    \n    # https://www.kaggle.com/c/stanford-covid-vaccine/discussion/183211\ndef rmse(y_actual, y_pred):\n    mse = tf.keras.losses.mean_squared_error(y_actual, y_pred)\n    return K.sqrt(mse)\n\ndef mcrmse(y_actual, y_pred, num_scored=len(target_cols)):\n    score = 0\n    for i in range(num_scored):\n        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / num_scored\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:40:59.060625Z","iopub.execute_input":"2022-03-31T15:40:59.06085Z","iopub.status.idle":"2022-03-31T15:41:27.587638Z","shell.execute_reply.started":"2022-03-31T15:40:59.060822Z","shell.execute_reply":"2022-03-31T15:41:27.586921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model.py**","metadata":{}},{"cell_type":"markdown","source":"ELMo Object initializer changed!\n\nInput dimention changed!\n\nself.compile_elmo() got exra parameters!\n\n","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/c/stanford-covid-vaccine/discussion/183211\ndef rmse(y_actual, y_pred):\n    mse = tf.keras.losses.mean_squared_error(y_actual, y_pred)\n    return K.sqrt(mse)\n\ndef mcrmse(y_actual, y_pred, num_scored=len(target_cols)):\n    score = 0\n    for i in range(num_scored):\n        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / num_scored\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:41:27.589703Z","iopub.execute_input":"2022-03-31T15:41:27.592217Z","iopub.status.idle":"2022-03-31T15:41:27.597518Z","shell.execute_reply.started":"2022-03-31T15:41:27.592187Z","shell.execute_reply":"2022-03-31T15:41:27.596622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport plotly.express as px\n\nimport numpy as np\n# from tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Input, SpatialDropout1D,BatchNormalization\nfrom tensorflow.keras.layers import LSTM, Activation\nfrom tensorflow.keras.layers import Lambda, Embedding, Conv2D, GlobalMaxPool1D\nfrom tensorflow.keras.layers import add, concatenate\nfrom tensorflow.keras.layers import TimeDistributed\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adagrad\nfrom tensorflow.keras.constraints import MinMaxNorm\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras import optimizers\n\n# from data import MODELS_DIR\nMODELS_DIR='./'\n\n# from .custom_layers import TimestepDropout, Camouflage, Highway, SampledSoftmax\n\n\nclass ELMo(object):\n    def __init__(self, parameters, \n                dropout=.4, sp_dropout=.2, embed_dim=300,\n                hidden_dim=256, layers=3,\n                seq_len=107, pred_len=68):\n        #pre-build models for different sequence lengths\n        self._model = None\n        self._elmo_model = None\n        self.parameters = parameters\n        self.seq_len=seq_len\n        self.pred_len=pred_len\n        self.compile_elmo()\n\n    def __del__(self):\n        K.clear_session()\n        del self._model\n\n    def char_level_token_encoder(self):\n        charset_size = self.parameters['charset_size']\n        char_embedding_size = self.parameters['char_embedding_size']\n        token_embedding_size = self.parameters['hidden_units_size']\n        n_highway_layers = self.parameters['n_highway_layers']\n        filters = self.parameters['cnn_filters']\n        token_maxlen = self.parameters['token_maxlen']\n\n        # Input Layer, word characters (samples, words, character_indices), Size= (None, None)\n#         inputs = Input(shape=(None, token_maxlen,), dtype='int32')\n        inputs = Input(shape=(self.seq_len, 5))\n        # Embed characters (samples, words, characters, character embedding),Size= (None, None, 200)\n        embeds = Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n        token_embeds = []\n        # Apply multi-filter 2D convolutions + 1D MaxPooling + tanh\n        for (window_size, filters_size) in filters:\n            convs = Conv2D(filters=filters_size, kernel_size=[window_size, char_embedding_size], strides=(1, 1),\n                           padding=\"same\")(embeds)\n            convs = TimeDistributed(GlobalMaxPool1D())(convs)\n            convs = Activation('tanh')(convs)\n            convs = Camouflage(mask_value=0)(inputs=[convs, inputs])\n            token_embeds.append(convs)\n        token_embeds = concatenate(token_embeds)\n        # Apply highways networks\n        for i in range(n_highway_layers):\n            token_embeds = TimeDistributed(Highway())(token_embeds)\n            token_embeds = Camouflage(mask_value=0)(inputs=[token_embeds, inputs])\n        # Project to token embedding dimensionality\n        token_embeds = TimeDistributed(Dense(units=token_embedding_size, activation='linear'))(token_embeds)\n        token_embeds = Camouflage(mask_value=0)(inputs=[token_embeds, inputs])\n\n        token_encoder = Model(inputs=inputs, outputs=token_embeds, name='token_encoding')\n        return token_encoder\n\n    def compile_elmo(self,embed_dim=300, print_summary=True):\n        \"\"\"\n        Compiles a Language Model RNN based on the given parameters\n        \"\"\"\n\n        if self.parameters['token_encoding'] == 'word':\n            # Train word embeddings from scratch\n            word_inputs = Input(shape=(self.seq_len, 5), name='word_indices')\n            #Size= [(None, None)]\n            categorical_feats = word_inputs[:, :, :3]\n            numerical_feats = word_inputs[:, :, 3:]\n            embeddings =tf.keras.layers.Embedding(name='token_encoding',input_dim=len(token2int),\n                                      output_dim=300)\n#             embeddingsformalite = Embedding(len(token2int), \n#                                             603, trainable=True,\n#                                             name='token_encodingformalite')\n            inputs = embeddings(categorical_feats)\n#           inputs: Tensor(\"token_encoding/embedding_lookup/Identity_1:0\", shape=(?, 107, 3, 200)\n\n            reshaped = tf.reshape(inputs, shape=(-1, inputs.shape[1],  inputs.shape[2] * inputs.shape[3]))\n#             reshaped1: Tensor(\"Reshape:0\", shape=(?, 107, 600), dtype=float32) \n\n            reshaped = tf.keras.layers.concatenate([reshaped, numerical_feats], axis=2)\n            \n#              reshaped2: Tensor(\"concatenate/concat:0\", shape=(?, 107, 602), dtype=float32) \n\n            \n            # Token embeddings for Input\n            drop_inputs = SpatialDropout1D(self.parameters['dropout_rate'])(reshaped)\n            drop_inputs=BatchNormalization()(drop_inputs)\n\n            lstm_inputs = TimestepDropout(self.parameters['word_dropout_rate'])(drop_inputs)\n            lstm_inputs= BatchNormalization()(lstm_inputs)\n\n#              lstm_inputs: Tensor(\"timestep_dropout/cond/Merge:0\", shape=(?, 107, 602), dtype=float32) \n#              drop_inputs: Tensor(\"timestep_dropout/cond/Merge:0\", shape=(?, 107, 602), dtype=float32) \n\n            # Pass outputs as inputs to apply sampled softmax\n            next_ids = Input(shape=(None, 1), name='next_ids')\n#              next_ids: Tensor(\"next_ids:0\", shape=(?, ?, 1), dtype=float32) \n            previous_ids = Input(shape=(None, 1), name='previous_ids')\n#              previous_ids: Tensor(\"previous_ids:0\", shape=(?, ?, 1), dtype=float32) \n\n        elif self.parameters['token_encoding'] == 'char':\n            # Train character-level representation\n            word_inputs = Input(shape=(None, self.parameters['token_maxlen'],), name='char_indices')\n            inputs = self.char_level_token_encoder()(word_inputs)\n            categorical_feats = word_inputs[:, :, :3]\n            numerical_feats = word_inputs[:, :, 3:]\n#             print(' inputs:', inputs,'inputs size',inputs.shape)\n            \n            reshaped = tf.reshape(inputs, shape=(-1, inputs.shape[1],  inputs.shape[2] * inputs.shape[3]))\n            reshaped = tf.keras.layers.concatenate([reshaped, numerical_feats], axis=2)\n#             print(' reshaped:', reshaped,'reshaped size',reshaped.shape)\n\n\n            \n            # Token embeddings for Input\n            drop_inputs = SpatialDropout1D(self.parameters['dropout_rate'])(reshaped)\n            lstm_inputs = TimestepDropout(self.parameters['word_dropout_rate'])(drop_inputs)\n\n            # Pass outputs as inputs to apply sampled softmax\n            next_ids = Input(shape=(None, 1), name='next_ids')\n            previous_ids = Input(shape=(None, 1), name='previous_ids')\n\n        # Reversed input for backward LSTMs\n        re_lstm_inputs = Lambda(function=ELMo.reverse)(lstm_inputs)\n        re_lstm_inputs=BatchNormalization()(re_lstm_inputs)\n        mask = Lambda(function=ELMo.reverse)(drop_inputs)\n        mask=BatchNormalization()(mask)\n\n        # Forward LSTMs\n        for i in range(self.parameters['n_lstm_layers']):\n            if self.parameters['cuDNN']:\n                lstm = CuDNNLSTM(units=self.parameters['lstm_units_size'], return_sequences=True,\n                                 kernel_constraint=MinMaxNorm(-1*self.parameters['cell_clip'],\n                                                              self.parameters['cell_clip']),\n                                 recurrent_constraint=MinMaxNorm(-1*self.parameters['cell_clip'],\n                                                                 self.parameters['cell_clip']))(lstm_inputs)\n            else:\n                lstm = LSTM(units=self.parameters['lstm_units_size'], return_sequences=True,\n                            activation=\"tanh\",\n                            recurrent_activation='sigmoid',\n                            kernel_constraint=MinMaxNorm(-1 * self.parameters['cell_clip'],\n                                                         self.parameters['cell_clip']),\n                            recurrent_constraint=MinMaxNorm(-1 * self.parameters['cell_clip'],\n                                                            self.parameters['cell_clip'])\n                            )(lstm_inputs)\n\n            lstm=BatchNormalization()(lstm)\n            lstm = Camouflage(mask_value=0)(inputs=[lstm, drop_inputs])\n            lstm=BatchNormalization()(lstm) \n            # Projection to hidden_units_size\n            proj = TimeDistributed(Dense(self.parameters['hidden_units_size'], activation='linear',\n                                         kernel_constraint=MinMaxNorm(-1 * self.parameters['proj_clip'],\n                                                                      self.parameters['proj_clip'])\n                                         ))(lstm)\n            proj=BatchNormalization()(proj)\n\n            print(' lstm_inputs:', lstm_inputs,'lstm_inputs size',lstm_inputs.shape)\n            print(' proj:', proj,'proj size',proj.shape)\n\n            # Merge Bi-LSTMs feature vectors with the previous ones\n            lstm_inputs = add([proj, lstm_inputs], name='f_block_{}'.format(i + 1))\n            lstm_inputs=BatchNormalization()(lstm_inputs)\n\n            # Apply variational drop-out between BI-LSTM layers\n            lstm_inputs = SpatialDropout1D(self.parameters['dropout_rate'])(lstm_inputs)\n            lstm_inputs=BatchNormalization()(lstm_inputs)\n\n        # Backward LSTMs\n        for i in range(self.parameters['n_lstm_layers']):\n            if self.parameters['cuDNN']:\n                re_lstm = CuDNNLSTM(units=self.parameters['lstm_units_size'], return_sequences=True,\n                                    kernel_constraint=MinMaxNorm(-1*self.parameters['cell_clip'],\n                                                                 self.parameters['cell_clip']),\n                                    recurrent_constraint=MinMaxNorm(-1*self.parameters['cell_clip'],\n                                                                    self.parameters['cell_clip']))(re_lstm_inputs)\n            else:\n                re_lstm = LSTM(units=self.parameters['lstm_units_size'], return_sequences=True, activation='tanh',\n                               recurrent_activation='sigmoid',\n                               kernel_constraint=MinMaxNorm(-1 * self.parameters['cell_clip'],\n                                                            self.parameters['cell_clip']),\n                               recurrent_constraint=MinMaxNorm(-1 * self.parameters['cell_clip'],\n                                                               self.parameters['cell_clip'])\n                               )(re_lstm_inputs)\n            re_lstm = BatchNormalization()(re_lstm)\n            re_lstm = Camouflage(mask_value=0)(inputs=[re_lstm, mask])\n            re_lstm = BatchNormalization()(re_lstm)   \n            # Projection to hidden_units_size\n            re_proj = TimeDistributed(Dense(self.parameters['hidden_units_size'], activation='linear',\n                                            kernel_constraint=MinMaxNorm(-1 * self.parameters['proj_clip'],\n                                                                         self.parameters['proj_clip'])\n                                            ))(re_lstm)\n            re_proj = BatchNormalization()(re_proj)\n\n            # Merge Bi-LSTMs feature vectors with the previous ones\n            re_lstm_inputs = add([re_proj, re_lstm_inputs], name='b_block_{}'.format(i + 1))\n            re_lstm_inputs = BatchNormalization()(re_lstm_inputs)\n\n            # Apply variational drop-out between BI-LSTM layers\n            re_lstm_inputs = SpatialDropout1D(self.parameters['dropout_rate'])(re_lstm_inputs)\n            re_lstm_inputs = BatchNormalization()(re_lstm_inputs)\n\n        # Reverse backward LSTMs' outputs = Make it forward again\n        re_lstm_inputs = Lambda(function=ELMo.reverse, name=\"reverse\")(re_lstm_inputs)\n        re_lstm_inputs = BatchNormalization()(re_lstm_inputs)\n\n        # Project to Vocabulary with Sampled Softmax\n#         sampled_softmax = SampledSoftmax(num_classes=self.parameters['vocab_size'],\n#                                          num_sampled=int(self.parameters['num_sampled']),\n#                                          tied_to=reshaped if self.parameters['weight_tying']\n#                                          and self.parameters['token_encoding'] == 'word' else None)\n#         print(' next_ids:', next_ids,'next_ids size',next_ids.shape)\n#         print(' lstm_inputs:', lstm_inputs,'lstm_inputs size',lstm_inputs.shape)\n\n#         outputs = sampled_softmax([lstm_inputs, next_ids])\n#         re_outputs = sampled_softmax([re_lstm_inputs, previous_ids])\n#         self._model = Model(inputs=[word_inputs, next_ids, previous_ids],outputs=[outputs, re_outputs])\n\n\n#         outputs = tf.keras.layers.Softmax([lstm_inputs])\n#         re_outputs = tf.keras.layers.Softmax(re_lstm_inputs)\n        merge = add([lstm_inputs,re_lstm_inputs])\n        merge = BatchNormalization()(merge)\n        \n        \n        \n        \n        \n        \n#         merge = tf.expand_dims(merge, axis=-1)\n\n        \n        \n#         charset_size = self.parameters['charset_size']\n#         char_embedding_size = self.parameters['char_embedding_size']\n#         token_embedding_size = self.parameters['hidden_units_size']\n#         n_highway_layers = self.parameters['n_highway_layers']\n#         filters = self.parameters['cnn_filters']\n#         token_maxlen = self.parameters['token_maxlen']\n\n#         # Input Layer, word characters (samples, words, character_indices), Size= (None, None)\n# #         inputs = Input(shape=(None, token_maxlen,), dtype='int32')\n#         inputs = Input(shape=(self.seq_len, 5))\n#         # Embed characters (samples, words, characters, character embedding),Size= (None, None, 200)\n#         embeds = Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n        token_embeds = []\n        # Apply multi-filter 2D convolutions + 1D MaxPooling + tanh\n        \n#         for (window_size, filters_size) in filters:\n#             convs = Conv2D(filters=filters_size, kernel_size=[window_size, char_embedding_size], strides=(1, 1),\n#                            padding=\"same\")(merge)\n#             convs = TimeDistributed(GlobalMaxPool1D())(convs)\n#             convs = Activation('tanh')(convs)\n# #             convs = Camouflage(mask_value=0)(inputs=[convs, word_inputs])\n#             token_embeds.append(convs)\n#         token_embeds = concatenate(token_embeds)\n      \n        \n        conv_dim=512\n        merge = tf.keras.layers.Conv1D(conv_dim, 5, padding='same', activation=tf.keras.activations.swish)(merge)\n    \n        \n        conv_dim=64\n        merge = tf.keras.layers.Conv1D(conv_dim, 5, padding='same', activation=tf.keras.activations.swish)(merge)\n    \n \n        out = merge[:, :self.pred_len]\n        out = tf.keras.layers.Dense(5, activation='linear')(out)\n        out = BatchNormalization()(out)\n\n        self._model = tf.keras.Model(inputs=word_inputs, outputs=out)\n        adam = tf.keras.optimizers.Adam()\n        self._model.compile(optimizer=adam, loss=mcrmse)\n\n#         self._model.compile(optimizer=Adagrad(lr=self.parameters['lr'], clipvalue=self.parameters['clip_value']),loss=None)              \n        \n#         self._model.save(i'model-{i}.hp5')\n        if print_summary:\n            self._model.summary()\n\n    def train(self):\n\n        ######################################################################\n        STRATIFY=False\n        FOLDS=4\n        \n      \n        histories = []\n\n        #get test now for OOF \n        public_df = test.query(\"seq_length == 107\").copy()\n        private_df = test.query(\"seq_length == 130\").copy()\n        private_preds = np.zeros((private_df.shape[0], 130, 5))\n        public_preds = np.zeros((public_df.shape[0], 107, 5))\n        public_inputs = preprocess_inputs(public_df)\n        private_inputs = preprocess_inputs(private_df)\n        pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n        train_inputs = preprocess_inputs(train)\n        train_labels = np.array(train[pred_cols].values.tolist()).transpose((0, 2, 1))\n        from sklearn.model_selection import KFold\n        kf = KFold(n_splits=FOLDS,shuffle=True,random_state=seed)\n        # with tf.device('/gpu'):\n        # Recreate the exact same model, including its weights and the optimizer\n#         self._model.load_weights('../input/model0h5/model0.h5')\n#         print('new summary:')\n#         # Show the model architecture\n#         self._model.summary()\n\n        for fold,(idxT,idxV) in enumerate(kf.split(train_inputs)):\n                self.seq_len=107\n                self.pred_len=107\n                self.compile_elmo()\n                model_short=self._model\n\n                self.seq_len=130\n                self.pred_len=130 \n                self.compile_elmo()\n                model_long=self._model\n                \n                self.seq_len=107\n                self.pred_len=68\n                self.compile_elmo()\n                history = self._model.fit(\n                    train_inputs[idxT,:,:], train_labels[idxT,:,:], \n                    batch_size=self.parameters['batch_size'],\n                    epochs=self.parameters['epochs'],\n                    validation_split=0.05,\n                        callbacks=[\n                    tf.keras.callbacks.ReduceLROnPlateau(),\n                    tf.keras.callbacks.ModelCheckpoint('model'+str(fold)+'.h5',save_weights_only=True,save_best_only=True),\n                    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=self.parameters['patience'])\n                ],verbose=2\n                )\n                histories.append(history)\n\n                # Caveat: The prediction format requires the output to be the same length as the input,\n                # although it's not the case for the training data.\n\n                #for evaluation you should make a universal pred length adnd seq length and here set dem and check out with ifs\n                #in the comlile elmo method.\n                \n                model_short.load_weights('model'+str(fold)+'.h5')\n                model_long.load_weights('model'+str(fold)+'.h5')\n\n                if fold == 0:\n                    public_preds =  model_short.predict([public_inputs])/1\n                    private_preds = model_long.predict([private_inputs])/1\n                else:\n                    public_preds +=  model_short.predict([public_inputs])/FOLDS\n                    private_preds +=  model_long.predict([private_inputs])/FOLDS\n   \n\n                \n        results = {\"models\" : ['elmo','elmo'],\"histories\" : [histories,histories]}\n        fig, ax = plt.subplots(1, len(results['histories']), figsize = (20, 10))\n        for i, result in enumerate(results['histories']):\n                for history in result:\n                    ax[i].plot(history.history['loss'], color='C0')\n                    ax[i].plot(history.history['val_loss'], color='C1')\n                    ax[i].set_title(f\"{results['models'][i]}\")\n                    ax[i].set_ylabel('MCRMSE')\n                    ax[i].set_xlabel('Epoch')\n                    ax[i].legend(['train', 'validation'], loc = 'upper right')\n\n                        \n\n        preds_ls = []\n        for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n            for i, uid in enumerate(df.id):\n                single_pred = preds[i]\n\n                single_df = pd.DataFrame(single_pred, columns=pred_cols)\n                single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n                preds_ls.append(single_df)\n        sample_df = pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv')\n\n        preds_df = pd.concat(preds_ls)\n        submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n        submission.to_csv('submission.csv', index=False)\n        print('Submission saved')\n    def evaluate(self, test_data):\n\n        def unpad(x, y_true, y_pred):\n            y_true_unpad = []\n            y_pred_unpad = []\n            for i, x_i in enumerate(x):\n                for j, x_ij in enumerate(x_i):\n                    if x_ij == 0:\n                        y_true_unpad.append(y_true[i][:j])\n                        y_pred_unpad.append(y_pred[i][:j])\n                        break\n            return np.asarray(y_true_unpad), np.asarray(y_pred_unpad)\n\n        # Generate samples\n        x, y_true_forward, y_true_backward = [], [], []\n        for i in range(len(test_data)):\n            test_batch = test_data[i][0]\n            x.extend(test_batch[0])\n            y_true_forward.extend(test_batch[1])\n            y_true_backward.extend(test_batch[2])\n        x = np.asarray(x)\n        y_true_forward = np.asarray(y_true_forward)\n        y_true_backward = np.asarray(y_true_backward)\n\n        # Predict outputs\n        y_pred_forward, y_pred_backward = self._model.predict([x, y_true_forward, y_true_backward])\n\n        # Unpad sequences\n        y_true_forward, y_pred_forward = unpad(x, y_true_forward, y_pred_forward)\n        y_true_backward, y_pred_backward = unpad(x, y_true_backward, y_pred_backward)\n\n        # Compute and print perplexity\n        print('Forward Langauge Model Perplexity: {}'.format(ELMo.perplexity(y_pred_forward, y_true_forward)))\n        print('Backward Langauge Model Perplexity: {}'.format(ELMo.perplexity(y_pred_backward, y_true_backward)))\n\n    def wrap_multi_elmo_encoder(self, print_summary=False, save=False):\n        \"\"\"\n        Wrap ELMo meta-model encoder, which returns an array of the 3 intermediate ELMo outputs\n        :param print_summary: print a summary of the new architecture\n        :param save: persist model\n        :return: None\n        \"\"\"\n\n        elmo_embeddings = list()\n        elmo_embeddings.append(concatenate([self._model.get_layer('token_encoding').output, self._model.get_layer('token_encoding').output],\n                                           name='elmo_embeddings_level_0'))\n        for i in range(self.parameters['n_lstm_layers']):\n            elmo_embeddings.append(concatenate([self._model.get_layer('f_block_{}'.format(i + 1)).output,\n                                                Lambda(function=ELMo.reverse)\n                                                (self._model.get_layer('b_block_{}'.format(i + 1)).output)],\n                                               name='elmo_embeddings_level_{}'.format(i + 1)))\n\n        camos = list()\n        for i, elmo_embedding in enumerate(elmo_embeddings):\n            camos.append(Camouflage(mask_value=0.0, name='camo_elmo_embeddings_level_{}'.format(i + 1))([elmo_embedding,\n                                                                                                         self._model.get_layer(\n                                                                                                             'token_encoding').output]))\n\n        self._elmo_model = Model(inputs=[self._model.get_layer('word_indices').input], outputs=camos)\n\n        if print_summary:\n            self._elmo_model.summary()\n\n        if save:\n            self._elmo_model.save(os.path.join(MODELS_DIR, 'ELMo_Encoder.hd5'))\n            print('ELMo Encoder saved successfully')\n\n    def save(self, sampled_softmax=False):\n        \"\"\"\n        Persist model in disk\n        :param sampled_softmax: reload model using the full softmax function\n        :return: None\n        \"\"\"\n        if not sampled_softmax:\n            self.parameters['num_sampled'] = self.parameters['vocab_size']\n#         self._model.load_weights(os.path.join(MODELS_DIR, 'elmo_best_weights.hdf5'))\n\n        self._model.save(os.path.join(MODELS_DIR, 'ELMo_LM_EVAL.hd5'))\n        print('ELMo Language Model saved successfully')\n\n    def load(self):\n        self._model = load_model(os.path.join(MODELS_DIR, 'ELMo_LM.h5'),custom_objects={'TimestepDropout': TimestepDropout,'Camouflage': Camouflage})\n\n    def load_elmo_encoder(self):\n        self._elmo_model = load_model(os.path.join(MODELS_DIR, 'ELMo_Encoder.hd5'),custom_objects={'TimestepDropout': TimestepDropout,'Camouflage': Camouflage})\n\n    def get_outputs(self, test_data, output_type='word', state='last'):\n        \"\"\"\n       Wrap ELMo meta-model encoder, which returns an array of the 3 intermediate ELMo outputs\n       :param test_data: data generator\n       :param output_type: \"word\" for word vectors or \"sentence\" for sentence vectors\n       :param state: 'last' for 2nd LSTMs outputs or 'mean' for mean-pooling over inputs, 1st LSTMs and 2nd LSTMs\n       :return: None\n       \"\"\"\n        # Generate samples\n        x = []\n        for i in range(len(test_data)):\n            test_batch = test_data[i][0]\n            x.extend(test_batch[0])\n\n        preds = np.asarray(self._elmo_model.predict(np.asarray(x)))\n        if state == 'last':\n            elmo_vectors = preds[-1]\n        else:\n            elmo_vectors = np.mean(preds, axis=0)\n\n        if output_type == 'words':\n            return elmo_vectors\n        else:\n            return np.mean(elmo_vectors, axis=1)\n\n    @staticmethod\n    def reverse(inputs, axes=1):\n        return K.reverse(inputs, axes=axes)\n\n    @staticmethod\n    def perplexity(y_pred, y_true):\n\n        cross_entropies = []\n        for y_pred_seq, y_true_seq in zip(y_pred, y_true):\n            # Reshape targets to one-hot vectors\n            y_true_seq = to_categorical(y_true_seq, y_pred_seq.shape[-1])\n            # Compute cross_entropy for sentence words\n            cross_entropy = K.categorical_crossentropy(K.tf.convert_to_tensor(y_true_seq, dtype=K.tf.float32),K.tf.convert_to_tensor(y_pred_seq, dtype=K.tf.float32))\n            cross_entropies.extend(cross_entropy.eval(session=K.get_session()))\n\n        # Compute mean cross_entropy and perplexity\n        cross_entropy = np.mean(np.asarray(cross_entropies), axis=-1)\n\n        return pow(2.0, cross_entropy)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:41:27.599238Z","iopub.execute_input":"2022-03-31T15:41:27.599708Z","iopub.status.idle":"2022-03-31T15:41:27.686789Z","shell.execute_reply.started":"2022-03-31T15:41:27.599672Z","shell.execute_reply":"2022-03-31T15:41:27.685945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model should be sth like:\n\nLayer (type)                    Output Shape         Param #     Connected to                     \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 107, 5)]     0                                            \n__________________________________________________________________________________________________\ntf_op_layer_strided_slice_3 (Te [(None, 107, 3)]     0           input_2[0][0]                    \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 107, 3, 200)  2800        tf_op_layer_strided_slice_3[0][0]\n__________________________________________________________________________________________________\ntf_op_layer_Reshape_1 (TensorFl [(None, 107, 600)]   0           embedding_1[0][0]          ","metadata":{}},{"cell_type":"code","source":"                                                                                                                                                                                                                                                                                                                                                                   \nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Layer\n\nfrom tensorflow.keras.layers import InputSpec\n# from tensorflow.keras.layers import Dropout\n\nclass TimestepDropout(Dropout):\n    \"\"\"Word Dropout.\n\n    This version performs the same function as Dropout, however it drops\n    entire timesteps (e.g., words embeddings) instead of individual elements (features).\n\n    # Arguments\n        rate: float between 0 and 1. Fraction of the timesteps to drop.\n\n    # Input shape\n        3D tensor with shape:\n        `(samples, timesteps, channels)`\n\n    # Output shape\n        Same as input\n\n    # References\n        - N/A\n    \"\"\"\n\n    def __init__(self, rate, **kwargs):\n        super(TimestepDropout, self).__init__(rate, **kwargs)\n        self.input_spec = InputSpec(ndim=3)\n\n    def _get_noise_shape(self, inputs):\n        input_shape = K.shape(inputs)\n        noise_shape = (input_shape[0], input_shape[1], 1)\n        return noise_shape\n    \nfrom tensorflow.keras import initializers, regularizers, constraints, activations\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras import backend as K\n\n\nclass Highway(Layer):\n    \"\"\"Highway network, a natural extension of LSTMs to feedforward networks.\n\n    # Arguments\n        activation: Activation function to use\n            (see [activations](../activations.md)).\n            Default: no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).\n        transform_activation: Activation function to use\n            for the transform unit\n            (see [activations](../activations.md)).\n            Default: sigmoid (`sigmoid`).\n            If you pass `None`, no activation is applied\n            (ie. \"linear\" activation: `a(x) = x`).x\n        kernel_initializer: Initializer for the `kernel` weights matrix,\n            used for the linear transformation of the inputs\n            (see [initializers](../initializers.md)).\n        transform_initializer: Initializer for the `transform` weights matrix,\n            used for the linear transformation of the inputs\n            (see [initializers](../initializers.md)).\n        bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n        transform_bias_initializer: Initializer for the bias vector\n            (see [initializers](../initializers.md)).\n            Default: -2 constant.\n        kernel_regularizer: Regularizer function applied to\n            the `kernel` weights matrix\n            (see [regularizer](../regularizers.md)).\n        transform_regularizer: Regularizer function applied to\n            the `transform` weights matrix\n            (see [regularizer](../regularizers.md)).\n        bias_regularizer: Regularizer function applied to the bias vector\n            (see [regularizer](../regularizers.md)).\n        transform_bias_regularizer: Regularizer function applied to the transform bias vector\n            (see [regularizer](../regularizers.md)).\n        kernel_constraint: Constraint function applied to\n            the `kernel` weights matrix\n            (see [constraints](../constraints.md)).\n        bias_constraint: Constraint function applied to the bias vector\n            (see [constraints](../constraints.md)).\n    # Input shape\n        2D tensor with shape: `(nb_samples, input_dim)`.\n    # Output shape\n        2D tensor with shape: `(nb_samples, input_dim)`.\n    # References\n        - [Highway Networks](http://arxiv.org/pdf/1505.00387v2.pdf)\n    \"\"\"\n\n    def __init__(self,\n                 activation='relu',\n                 transform_activation='sigmoid',\n                 kernel_initializer='glorot_uniform',\n                 transform_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 transform_bias_initializer=-2,\n                 kernel_regularizer=None,\n                 transform_regularizer=None,\n                 bias_regularizer=None,\n                 transform_bias_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        self.activation = activations.get(activation)\n        self.transform_activation = activations.get(transform_activation)\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.transform_initializer = initializers.get(transform_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        if isinstance(transform_bias_initializer, int):\n            self.transform_bias_initializer = Constant(value=transform_bias_initializer)\n        else:\n            self.transform_bias_initializer = initializers.get(transform_bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.transform_regularizer = regularizers.get(transform_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.transform_bias_regularizer = regularizers.get(transform_bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        super(Highway, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 2\n        input_dim = input_shape[-1]\n\n        self.W = self.add_weight(shape=(input_dim, input_dim),\n                                 name='{}_W'.format(self.name),\n                                 initializer=self.kernel_initializer,\n                                 regularizer=self.kernel_regularizer,\n                                 constraint=self.kernel_constraint)\n        self.W_transform = self.add_weight(shape=(input_dim, input_dim),\n                                           name='{}_W_transform'.format(self.name),\n                                           initializer=self.transform_initializer,\n                                           regularizer=self.transform_regularizer,\n                                           constraint=self.kernel_constraint)\n\n        self.bias = self.add_weight(shape=(input_dim,),\n                                 name='{}_bias'.format(self.name),\n                                 initializer=self.bias_initializer,\n                                 regularizer=self.bias_regularizer,\n                                 constraint=self.bias_constraint)\n\n        self.bias_transform = self.add_weight(shape=(input_dim,),\n                                           name='{}_bias_transform'.format(self.name),\n                                           initializer=self.transform_bias_initializer,\n                                           regularizer=self.transform_bias_regularizer)\n\n        self.built = True\n\n    def call(self, x, mask=None):\n        x_h = self.activation(K.dot(x, self.W) + self.bias)\n        x_trans = self.transform_activation(K.dot(x, self.W_transform) + self.bias_transform)\n        output = x_h * x_trans + (1 - x_trans) * x\n        return output\n\n    def get_config(self):\n        config = {'activation': activations.serialize(self.activation),\n                  'transform_activation': activations.serialize(self.transform_activation),\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'transform_initializer': initializers.serialize(self.transform_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'transform_bias_initializer': initializers.serialize(self.transform_bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'transform_regularizer': regularizers.serialize(self.transform_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'transform_bias_regularizer': regularizers.serialize(self.transform_bias_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint)\n                  }\n        base_config = super(Highway, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n    \n    # -*- coding: utf-8 -*-\n\"\"\"Core Keras layers.\n\"\"\"\n\n\nclass Camouflage(Layer):\n    \"\"\"Masks a sequence by using a mask value to skip timesteps based on another sequence.\n       LSTM and Convolution layers may produce fake tensors for padding timesteps. We need\n       to eliminate those tensors by replicating their initial values presented in the second input.\n\n       inputs = Input()\n       lstms = LSTM(units=100, return_sequences=True)(inputs)\n       padded_lstms = Camouflage()([lstms, inputs])\n       ...\n    \"\"\"\n\n    def __init__(self, mask_value=0., **kwargs):\n        super(Camouflage, self).__init__(**kwargs)\n        self.mask_value = mask_value\n\n    def call(self, inputs):\n        boolean_mask = K.any(K.not_equal(inputs[1], self.mask_value),\n                             axis=-1, keepdims=True)\n        return inputs[0] * K.cast(boolean_mask, K.dtype(inputs[0]))\n\n    def get_config(self):\n        config = {'mask_value': self.mask_value}\n        base_config = super(Camouflage, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0]\n    \n\n\nclass SampledSoftmax(Layer):\n    \"\"\"Sampled Softmax, a faster way to train a softmax classifier over a huge number of classes.\n\n        # Arguments\n            num_classes: number of classes\n            num_sampled: number of classes to be sampled at each batch\n            tied_to: layer to be tied with (e.g., Embedding layer)\n            kwargs:\n        # Input shape\n            2D tensor with shape: `(nb_samples, input_dim)`.\n        # Output shape\n            2D tensor with shape: `(nb_samples, input_dim)`.\n        # References\n            - [Tensorflow code](tf.nn.sampled_softmax_loss)\n            - [Sampled SoftMax](https://www.tensorflow.org/extras/candidate_sampling.pdf)\n        \"\"\"\n    def __init__(self, num_classes=50000, num_sampled=1000, tied_to=None, **kwargs):\n            super(SampledSoftmax, self).__init__(**kwargs)\n            self.num_sampled = num_sampled\n            self.num_classes = num_classes\n            self.tied_to = tied_to\n            self.sampled = (self.num_classes != self.num_sampled)\n\n    def build(self, input_shape):\n            if self.tied_to is None:\n                self.softmax_W = self.add_weight(shape=(self.num_classes, input_shape[0][-1]), name='W_soft', initializer='lecun_normal')\n            self.softmax_b = self.add_weight(shape=(self.num_classes,), name='b_soft', initializer='zeros')\n            self.built = True\n\n    def call(self, x, mask=None):\n        lstm_outputs, next_token_ids = x\n\n    def sampled_softmax(x):\n            lstm_outputs_batch, next_token_ids_batch = x\n            batch_losses = tf.nn.sampled_softmax_loss(\n                self.softmax_W if self.tied_to is None else self.tied_to.weights[0], self.softmax_b,\n                next_token_ids_batch, lstm_outputs_batch,\n                num_classes=self.num_classes,\n                num_sampled=self.num_sampled\n#                 ,partition_strategy='div'\n            )\n            batch_losses = tf.reduce_mean(batch_losses)\n            return [batch_losses, batch_losses]\n\n    def softmax(x):\n            lstm_outputs_batch, next_token_ids_batch = x\n            logits = tf.matmul(lstm_outputs_batch,\n                                 tf.transpose(self.softmax_W) if self.tied_to is None else tf.transpose(self.tied_to.weights[0]))\n            logits = tf.nn.bias_add(logits, self.softmax_b)\n            batch_predictions = tf.nn.softmax(logits)\n            labels_one_hot = tf.one_hot(tf.cast(next_token_ids_batch, dtype=tf.int32), self.num_classes)\n            batch_losses = tf.nn.softmax_cross_entropy_with_logits(labels=labels_one_hot, logits=logits)\n            return [batch_losses, batch_predictions]\n        \n            losses, predictions = tf.map_fn(sampled_softmax if self.sampled else softmax, [lstm_outputs, next_token_ids])\n            self.add_loss(0.5 * tf.reduce_mean(losses[0]))\n            return lstm_outputs if self.sampled else predictions\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0] if self.sampled else (input_shape[0][0], input_shape[0][1], self.num_classes)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:41:27.688655Z","iopub.execute_input":"2022-03-31T15:41:27.689125Z","iopub.status.idle":"2022-03-31T15:41:29.352248Z","shell.execute_reply.started":"2022-03-31T15:41:27.689089Z","shell.execute_reply":"2022-03-31T15:41:29.351285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LMDataGenerator.py**\n\n**if token_encoding ==word : assigns each word in a sentence a pre-assigned integer value from vocab.token. processes all the corpus line by line. at the end encryptes each sentence to a 1 x 100 array of integers.\n\n**\n\ntrain_generator.indices#array([    1,     3,     5, ..., 36713, 36715, 36717]) even numbers in a row\n\nlen(train_generator.vocab)#28914\n\nlen(train_generator.indices)#18359\n\ntrain_generator.__getitem__(18358)# last can be reached\n\ntrain_generator.indices#array([    1,     3,     5, ..., 36713, 36715, 36717]) even numbers in a row\n\nlen(train_generator.vocab)#28914\n\nlen(train_generator.indices)#18359\n\ntrain_generator.__getitem__(18358)# last can be reached\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow import keras \n\n\n# class LMDataGenerator(keras.utils.Sequence):\n#     \"\"\"Generates data for Keras\"\"\"\n\n#     def __len__(self):\n#         \"\"\"Denotes the number of batches per epoch\"\"\"\n#         return int(np.ceil(len(self.indices)/self.batch_size))\n\n#     def __init__(self, corpus, vocab, sentence_maxlen=100, token_maxlen=50, batch_size=32, shuffle=True, token_encoding='word'):\n#         \"\"\"Compiles a Language Model RNN based on the given parameters\n#         :param corpus: filename of corpus\n#         :param vocab: filename of vocabulary\n#         :param sentence_maxlen: max size of sentence\n#         :param token_maxlen: max size of token in characters\n#         :param batch_size: number of steps at each batch\n#         :param shuffle: True if shuffle at the end of each epoch\n#         :param token_encoding: Encoding of token, either 'word' index or 'char' indices\n#         :return: Nothing\n#         \"\"\"\n\n#         self.corpus = corpus\n#         self.vocab = {line.split()[0]: int(line.split()[1]) for line in open(vocab).readlines()}\n#         self.sent_ids = corpus\n#         self.batch_size = batch_size\n#         self.shuffle = shuffle\n#         self.sentence_maxlen = sentence_maxlen\n#         self.token_maxlen = token_maxlen\n#         self.token_encoding = token_encoding\n#         with open(self.corpus) as fp:\n#             self.indices = np.arange(len(fp.readlines()))\n#             newlines = [index for index in range(0, len(self.indices), 2)]\n#             self.indices = np.delete(self.indices, newlines)\n\n#     def __getitem__(self, index):\n#         \"\"\"Generate one batch of data\"\"\"\n#         # Generate indexes of the batch\n#         batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n\n#         # Read sample sequences\n#         word_indices_batch = np.zeros((len(batch_indices), self.sentence_maxlen), dtype=np.int32)\n#         if self.token_encoding == 'char':\n#             word_char_indices_batch = np.full((len(batch_indices), self.sentence_maxlen, self.token_maxlen), 260, dtype=np.int32)\n\n#         for i, batch_id in enumerate(batch_indices):\n#             # Read sentence (sample)\n#             word_indices_batch[i] = self.get_token_indices(sent_id=batch_id)\n#             if self.token_encoding == 'char':\n#                 word_char_indices_batch[i] = self.get_token_char_indices(sent_id=batch_id)\n\n#         # Build forward targets\n#         for_word_indices_batch = np.zeros((len(batch_indices), self.sentence_maxlen), dtype=np.int32)\n\n#         padding = np.zeros((1,), dtype=np.int32)\n\n#         for i, word_seq in enumerate(word_indices_batch ):\n#             for_word_indices_batch[i] = np.concatenate((word_seq[1:], padding), axis=0)\n\n#         for_word_indices_batch = for_word_indices_batch[:, :, np.newaxis]\n\n#         # Build backward targets\n#         back_word_indices_batch = np.zeros((len(batch_indices), self.sentence_maxlen), dtype=np.int32)\n\n#         for i, word_seq in enumerate(word_indices_batch):\n#             back_word_indices_batch[i] = np.concatenate((padding, word_seq[:-1]), axis=0)\n\n#         back_word_indices_batch = back_word_indices_batch[:, :, np.newaxis]\n\n#         return [word_indices_batch if self.token_encoding == 'word' else word_char_indices_batch, for_word_indices_batch, back_word_indices_batch], []\n\n#     def on_epoch_end(self):\n#         \"\"\"Updates indexes after each epoch\"\"\"\n#         if self.shuffle:\n#             np.random.shuffle(self.indices)\n\n#     def get_token_indices(self, sent_id: int):\n#         with open(self.corpus) as fp:\n#             for i, line in enumerate(fp):\n#                 if i == sent_id:\n#                     token_ids = np.zeros((self.sentence_maxlen,), dtype=np.int32)\n#                     # Add begin of sentence index\n#                     token_ids[0] = self.vocab['<bos>']\n#                     for j, token in enumerate(line.split()[:self.sentence_maxlen - 2]):\n#                         if token.lower() in self.vocab:\n#                             token_ids[j + 1] = self.vocab[token.lower()]\n#                         else:\n#                             token_ids[j + 1] = self.vocab['<unk>']\n#                     # Add end of sentence index\n#                     if token_ids[1]:\n#                         token_ids[j + 2] = self.vocab['<eos>']\n#                     return token_ids\n\n#     def get_token_char_indices(self, sent_id: int):\n#         def convert_token_to_char_ids(token, token_maxlen):\n#             bos_char = 256  # <begin sentence>\n#             eos_char = 257  # <end sentence>\n#             bow_char = 258  # <begin word>\n#             eow_char = 259  # <end word>\n#             pad_char = 260  # <pad char>\n#             char_indices = np.full([token_maxlen], pad_char, dtype=np.int32)\n#             # Encode word to UTF-8 encoding\n#             word_encoded = token.encode('utf-8', 'ignore')[:(token_maxlen - 2)]\n#             # Set characters encodings\n#             # Add begin of word char index\n#             char_indices[0] = bow_char\n#             if token == '<bos>':\n#                 char_indices[1] = bos_char\n#                 k = 1\n#             elif token == '<eos>':\n#                 char_indices[1] = eos_char\n#                 k = 1\n#             else:\n#                 # Add word char indices\n#                 for k, chr_id in enumerate(word_encoded, start=1):\n#                     char_indices[k] = chr_id + 1\n#             # Add end of word char index\n#             char_indices[k + 1] = eow_char\n#             return char_indices\n\n#         with open(self.corpus) as fp:\n#             for i, line in enumerate(fp):\n#                 if i == sent_id:\n#                     token_ids = np.zeros((self.sentence_maxlen, self.token_maxlen), dtype=np.int32)\n#                     # Add begin of sentence char indices\n#                     token_ids[0] = convert_token_to_char_ids('<bos>', self.token_maxlen)\n#                     # Add tokens' char indices\n#                     for j, token in enumerate(line.split()[:self.sentence_maxlen - 2]):\n#                         token_ids[j + 1] = convert_token_to_char_ids(token, self.token_maxlen)\n#                     # Add end of sentence char indices\n#                     if token_ids[1]:\n#                         token_ids[j + 2] = convert_token_to_char_ids('<eos>', self.token_maxlen)\n#         return token_ids","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:41:29.354694Z","iopub.execute_input":"2022-03-31T15:41:29.354985Z","iopub.status.idle":"2022-03-31T15:41:29.366824Z","shell.execute_reply.started":"2022-03-31T15:41:29.354948Z","shell.execute_reply":"2022-03-31T15:41:29.366103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport tensorflow.keras.backend as K\n\n# from data import DATA_SET_DIR\nDATA_SET_DIR='../input/wikielmo/data/datasets'\n# from elmo.lm_generator import LMDataGenerator\n# from elmo.model import ELMo\n\nparameters = {\n    'multi_processing': False,\n    'n_threads': 4,\n    'cuDNN': False,\n    'train_dataset': 'wikitext-2/wiki.train.tokens',\n    'valid_dataset': 'wikitext-2/wiki.valid.tokens',\n    'test_dataset': 'wikitext-2/wiki.test.tokens',\n    'vocab': 'wikitext-2/wiki.vocab',\n    'vocab_size': 28914,\n    'num_sampled': 1000,\n    'charset_size': 262,\n    'sentence_maxlen': 135,\n    'token_maxlen': 50,\n    'token_encoding': 'word',\n    'epochs': 400,\n    'patience': 50,\n    'batch_size': 64,\n    'clip_value': 1,\n    'cell_clip': 5,\n    'proj_clip': 5,\n    'lr': 0.01,\n    'shuffle': True,\n    'n_lstm_layers': 6,\n    'n_highway_layers': 2,\n    'cnn_filters': [[1, 32],\n                    [2, 32]\n#                     [3, 64]\n#                     [4, 128]\n#                     [5, 256],\n#                     [6, 512],\n#                     [7, 512]\n                    ],\n    'lstm_units_size': 400,\n    'hidden_units_size': 902,# as proj should be same length as input_lstm for adding \n    'char_embedding_size': 16,\n    'dropout_rate': 0.1,\n    'word_dropout_rate': 0.02,\n    'weight_tying': False,# I changed this to false as in sampled softmax with embeddings paramertee as \"tied into\" the dimension is not compatible with reshaped one (602 & 200) by changing\n#     it manually youu'll get tensor has no weight_tying parameter \n}\n\n\n# Compile ELMo\nelmo_model = ELMo(parameters)\nelmo_model.compile_elmo(print_summary=True)\n\n# Train ELMo\n# elmo_model.train(train_data=train_generator, valid_data=val_generator)\nelmo_model.train()\n\n\n\n\n\n\n\n# Persist ELMo Bidirectional Language Model in disk\nelmo_model.save(sampled_softmax=False)\n\n# Evaluate Bidirectional Language Model\n# elmo_model.evaluate(test_generator)\n\n     \n\n\n# Build ELMo meta-model to deploy for production and persist in disk\n# elmo_model.wrap_multi_elmo_encoder(print_summary=True, save=True)\n\n# Load ELMo encoder\n# elmo_model.load_elmo_encoder()\n\n# Get ELMo embeddings to feed as inputs for downstream tasks\n# elmo_embeddings = elmo_model.get_outputs(test_generator, output_type='word', state='mean')\n\n# BUILD & TRAIN NEW KERAS MODEL FOR DOWNSTREAM TASK (E.G., TEXT CLASSIFICATION)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T15:41:29.368091Z","iopub.execute_input":"2022-03-31T15:41:29.368719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('tf version:',tf.__version__)\n# !python --version\n# print('h5py version:',h5py.__version__)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}