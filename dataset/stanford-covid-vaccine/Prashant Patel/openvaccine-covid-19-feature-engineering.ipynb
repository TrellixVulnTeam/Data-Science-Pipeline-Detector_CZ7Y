{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = train.iloc[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['sequence']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['structure']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter(sample['structure'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['predicted_loop_type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sample['deg_Mg_pH10'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bases = []\nfor i in range(len(train)):\n    count_dict = Counter(train.iloc[i]['sequence'])\n    bases.append(count_dict) \nbases = pd.DataFrame.from_dict(bases)\nbases    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_percent = bases.div(train['seq_length'],axis=0)\nbase_percent.columns = ['G_percent','A_percent','C_percent','U_percent']\nbase_percent['id'] = train['id']\nbase_percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_pairs = []\nall_partners = []\nfor idx in range(len(train)):\n    sample = train.iloc[idx]\n    stack=[]\n    pair_freq = {}\n    partners = [-1 for i in range(sample['seq_length'])]\n    for i in range(len(sample['structure'])):\n        if sample['structure'][i] == '(':\n                stack.append(i)\n        elif sample['structure'][i] == ')':\n                poped = stack.pop()\n                pair = sample['sequence'][i] + sample['sequence'][poped]\n                partners[i] = sample['sequence'][poped]\n                partners[poped] = sample['sequence'][i]\n                if pair not in pair_freq:\n                    pair_freq[pair] = 1\n                else:\n                    pair_freq[pair] += 1\n    all_pairs.append(pair_freq)     \n    all_partners.append(partners)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_pairs[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_partners_df = pd.DataFrame(all_partners)\nall_partners_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs_df = pd.DataFrame.from_dict(all_pairs)\npairs_df.fillna(0,inplace=True)\npairs_df['tot_pair'] = pairs_df.sum(axis=1)\npairs_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs_percent = pairs_df.iloc[:,:-1].div(pairs_df['tot_pair'],axis=0)\npairs_percent['tot_pair_percent'] = pairs_df['tot_pair'].div(train['seq_length']/2,axis=0)\npairs_percent.columns = ['GU_percent','GC_percent','AU_percent','CG_percent','UA_percent','UG_percent','tot_pair_percent']\npairs_percent['id'] = train['id']\npairs_percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loop_type = []\nfor i in range(len(train)):\n    count_dict = Counter(train.iloc[i]['predicted_loop_type'])\n    loop_type.append(count_dict)\nloop_type[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loop_type = pd.DataFrame(loop_type)\nloop_type.fillna(0,inplace=True)\nloop_type","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loop_type_percent = loop_type.div(train['seq_length'],axis=0)\nloop_type_percent.columns = ['E_percent','S_percent','H_percent','B_percent',\n                            'X_percent','I_percent','M_percent']\nloop_type_percent['id'] = train['id']\nloop_type_percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['id','base','loop_type','paired_with','prev_base1','prev_base2','prev_base3'\n        ,'prev_base4','prev_base5','prev_base6','next_base1','next_base2',\n        'next_base3','next_base4','next_base5','next_base6']\n\nextracted_features = pd.DataFrame(columns = cols)\nall_target = pd.DataFrame(columns = ['id','reactivity','deg_Mg_pH10','deg_Mg_50C'])\n\nfor idx in train['index']:\n    sample = train.iloc[idx]\n    neighbor_bases = []\n    \n    for i in range(sample['seq_scored']):\n        temp_neighbor_bases = [-1 for j in range(12)]\n        for j in range(6):\n            temp_neighbor_bases[j] = sample['sequence'][i-j-1]\n            \n        k = i\n        for j in range(6,12):\n            temp_neighbor_bases[j] = sample['sequence'][k+1]\n            k +=1\n            \n        neighbor_bases.append(temp_neighbor_bases)\n        neighbor_bases_df = pd.DataFrame(neighbor_bases,columns = cols[4:])\n        \n            \n    neighbor_bases_df['id'] = sample['id']\n    neighbor_bases_df['base'] = list(sample['sequence'][:68])\n    neighbor_bases_df['loop_type'] = list(sample['predicted_loop_type'][:68])\n    neighbor_bases_df['paired_with'] = list(all_partners_df.loc[idx][:68])\n    \n    target = pd.DataFrame(columns = ['id','reactivity','deg_Mg_pH10','deg_Mg_50C'])\n    target['reactivity'] = sample['reactivity']\n    target['deg_Mg_pH10'] = sample['deg_Mg_pH10']\n    target['deg_Mg_50C'] = sample['deg_Mg_50C']\n    target['id'] = sample['id']\n    \n    all_target = pd.concat([all_target,target],axis = 0, ignore_index = True)\n    extracted_features = pd.concat([extracted_features,neighbor_bases_df], axis = 0, ignore_index = True )\n    \nextracted_features['is_paired'] = np.where(extracted_features['paired_with'] == -1,0,1)     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"extracted_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import reduce\n\ndfs = [extracted_features,base_percent,pairs_percent,loop_type_percent]\nfinal_train_data = reduce(lambda left,right: pd.merge(left,right), dfs)\nfinal_train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_columns = ['base', 'loop_type', 'paired_with', 'prev_base1', 'prev_base2',\n                   'prev_base3', 'prev_base4', 'prev_base5', 'prev_base6', 'next_base1',\n                   'next_base2', 'next_base3', 'next_base4', 'next_base5', 'next_base6',]\n\nX_train = pd.DataFrame()\nfor col in dummy_columns:\n    X_train = pd.concat([X_train,pd.get_dummies(final_train_data[col],prefix=col)],axis=1)\n\nX_train = pd.concat([X_train, final_train_data[['is_paired', 'G_percent', 'A_percent', 'C_percent', 'U_percent',\n                                               'GU_percent', 'GC_percent', 'AU_percent', 'CG_percent', 'UA_percent',\n                                               'UG_percent', 'tot_pair_percent', 'E_percent', 'S_percent', 'H_percent',\n                                               'B_percent', 'X_percent', 'I_percent', 'M_percent']]],axis=1)\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = all_target[['reactivity','deg_Mg_pH10','deg_Mg_50C']]\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_test_features_func():\n    bases = []\n    for i in range(len(test)):\n        count_dict = Counter(test.iloc[i]['sequence'])\n        bases.append(count_dict) \n    bases = pd.DataFrame.from_dict(bases)\n    base_percent = bases.div(test['seq_length'],axis=0)\n    base_percent.columns = ['G_percent','A_percent','C_percent','U_percent']\n    base_percent['id'] = test['id']\n\n\n    all_pairs = []\n    all_partners = []\n    for idx in range(len(test)):\n        sample = test.iloc[idx]\n        stack=[]\n        pair_freq = {}\n        partners = [-1 for i in range(sample['seq_length'])]\n        for i in range(len(sample['structure'])):\n            if sample['structure'][i] == '(':\n                    stack.append(i)\n            elif sample['structure'][i] == ')':\n                    poped = stack.pop()\n                    pair = sample['sequence'][i] + sample['sequence'][poped]\n                    partners[i] = sample['sequence'][poped]\n                    partners[poped] = sample['sequence'][i]\n                    if pair not in pair_freq:\n                        pair_freq[pair] = 1\n                    else:\n                        pair_freq[pair] += 1\n        all_pairs.append(pair_freq)     \n        all_partners.append(partners)    \n    all_partners_df = pd.DataFrame(all_partners)\n    pairs_df = pd.DataFrame.from_dict(all_pairs)\n    pairs_df.fillna(0,inplace=True)\n    pairs_df['tot_pair'] = pairs_df.sum(axis=1)\n    pairs_percent = pairs_df.iloc[:,:-1].div(pairs_df['tot_pair'],axis=0)\n    pairs_percent['tot_pair_percent'] = pairs_df['tot_pair'].div(test['seq_length']/2,axis=0)\n    pairs_percent.columns = ['GU_percent','GC_percent','AU_percent','CG_percent','UA_percent','UG_percent','tot_pair_percent']\n    pairs_percent['id'] = test['id']\n\n\n\n    loop_type = []\n    for i in range(len(test)):\n        count_dict = Counter(test.iloc[i]['predicted_loop_type'])\n        loop_type.append(count_dict)\n    loop_type = pd.DataFrame(loop_type)\n    loop_type.fillna(0,inplace=True)\n    loop_type_percent = loop_type.div(test['seq_length'],axis=0)\n    loop_type_percent.columns = ['E_percent','S_percent','H_percent','B_percent',\n                                'X_percent','I_percent','M_percent']\n    loop_type_percent['id'] = test['id']\n\n\n\n    cols = ['id','base','loop_type','paired_with','prev_base1','prev_base2','prev_base3'\n            ,'prev_base4','prev_base5','prev_base6','next_base1','next_base2',\n            'next_base3','next_base4','next_base5','next_base6']\n    extracted_features = pd.DataFrame(columns = cols)\n    for idx in test['index']:\n        sample = test.iloc[idx]\n        neighbor_bases = []\n\n        for i in range(sample['seq_length']):\n            temp_neighbor_bases = [-1 for j in range(12)]\n            for j in range(6):\n                temp_neighbor_bases[j] = sample['sequence'][i-j-1]\n            k = i\n            for j in range(6,12):\n                temp_neighbor_bases[j] = sample['sequence'][(k+1) % sample['seq_length']]\n                k +=1\n\n            neighbor_bases.append(temp_neighbor_bases)\n            neighbor_bases_df = pd.DataFrame(neighbor_bases,columns = cols[4:])        \n        neighbor_bases_df['id'] = sample['id']\n        neighbor_bases_df['base'] = list(sample['sequence'][:sample['seq_length']])\n        neighbor_bases_df['loop_type'] = list(sample['predicted_loop_type'][:sample['seq_length']])\n        neighbor_bases_df['paired_with'] = list(all_partners_df.loc[idx][:sample['seq_length']])\n        extracted_features = pd.concat([extracted_features,neighbor_bases_df], axis = 0, ignore_index = True )\n    extracted_features['is_paired'] = np.where(extracted_features['paired_with'] == -1,0,1)\n    dfs = [extracted_features,base_percent,pairs_percent,loop_type_percent]\n    final_test_data = reduce(lambda left,right: pd.merge(left,right), dfs)\n\n\n    \n    dummy_columns = ['base', 'loop_type', 'paired_with', 'prev_base1', 'prev_base2',\n                       'prev_base3', 'prev_base4', 'prev_base5', 'prev_base6', 'next_base1',\n                       'next_base2', 'next_base3', 'next_base4', 'next_base5', 'next_base6',]\n    X_test = pd.DataFrame()\n    for col in dummy_columns:\n        X_test = pd.concat([X_test,pd.get_dummies(final_test_data[col],prefix=col)],axis=1)\n    X_test = pd.concat([X_test, final_test_data[['is_paired', 'G_percent', 'A_percent', 'C_percent', 'U_percent',\n                                                   'GU_percent', 'GC_percent', 'AU_percent', 'CG_percent', 'UA_percent',\n                                                   'UG_percent', 'tot_pair_percent', 'E_percent', 'S_percent', 'H_percent',\n                                                   'B_percent', 'X_percent', 'I_percent', 'M_percent']]],axis=1)\n    \n    return X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = extract_test_features_func()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns == X_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(512,kernel_initializer = 'uniform', input_dim = X_train.shape[1], activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(64,kernel_initializer = 'uniform',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Dense(3, kernel_initializer = 'uniform',activation='linear'))\n\n\n#Setting the Optimizer\nopt=Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n\n\n# Compile the network :\nmodel.compile(\n    optimizer=opt,\n    loss='mse',\n    metrics=[keras.metrics.MeanSquaredError()])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, epochs=80, batch_size=64, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(X_test)\nprediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = pd.DataFrame(prediction,columns = ['reactivity','deg_Mg_pH10','deg_Mg_50C'])\nprediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction['id_seqpos'] = sub['id_seqpos']\nprediction['deg_pH10'] = 0\nprediction['deg_50C'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = prediction[sub.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}