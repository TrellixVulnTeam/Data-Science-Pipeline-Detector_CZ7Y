{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install seaborn\n# !pip install --upgrade catboost\nimport catboost\nimport optuna\nimport imblearn\nfrom catboost import CatBoostRegressor\nfrom imblearn.under_sampling import RandomUnderSampler\nimport numpy as np\nimport pandas as pd\nfrom catboost import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom catboost import Pool\nfrom datetime import datetime\nfrom numpy import mean\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.linear_model import LinearRegression,RidgeCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score\nfrom scipy.stats import norm,skew\nfrom scipy import stats\nfrom sklearn.metrics import mean_squared_error,make_scorer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom tqdm import tqdm\nimport pandas as pd\nimport nltk\nimport operator\nimport re\nimport sys\nfrom scipy import stats\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# from multiprocessing import Pool\nnltk.download(\"stopwords\")\nnltk.download(\"punkt\")\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport time","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json',lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nss = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\ntrain.shape, test.shape, ss.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# S: paired \"Stem\" M: Multiloop I: Internal loop B: Bulge H: Hairpin loop E: dangling End X: eXternal loop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['E']=[sum([i=='E' for i in j])/len(j) for j in test['predicted_loop_type']]\ntest['S']=[sum([i=='S' for i in j])/len(j) for j in test['predicted_loop_type']]\ntest['B']=[sum([i=='B' for i in j])/len(j) for j in test['predicted_loop_type']]\ntest['H']=[sum([i=='H' for i in j])/len(j) for j in test['predicted_loop_type']]\ntest['I']=[sum([i=='I' for i in j])/len(j) for j in test['predicted_loop_type']]\ntest['X']=[sum([i=='X' for i in j])/len(j) for j in test['predicted_loop_type']]\ntest['M']=[sum([i=='M' for i in j])/len(j) for j in test['predicted_loop_type']]\n\ntest['G']=[sum([i=='G' for i in j])/len(j) for j in test['sequence']]\ntest['A']=[sum([i=='A' for i in j])/len(j) for j in test['sequence']]\ntest['C']=[sum([i=='C' for i in j])/len(j) for j in test['sequence']]\ntest['U']=[sum([i=='U' for i in j])/len(j) for j in test['sequence']]\ntest['Paired']=[sum([i=='(' or i==')' for i in j])/len(j) for j in test['structure']]\ntest['Unpaired']=[sum([i=='.' for i in j])/len(j) for j in test['structure']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['E']=[sum([i=='E' for i in j])/len(j) for j in train['predicted_loop_type']]\ntrain['S']=[sum([i=='S' for i in j])/len(j) for j in train['predicted_loop_type']]\ntrain['B']=[sum([i=='B' for i in j])/len(j) for j in train['predicted_loop_type']]\ntrain['H']=[sum([i=='H' for i in j])/len(j) for j in train['predicted_loop_type']]\ntrain['I']=[sum([i=='I' for i in j])/len(j) for j in train['predicted_loop_type']]\ntrain['X']=[sum([i=='X' for i in j])/len(j) for j in train['predicted_loop_type']]\ntrain['M']=[sum([i=='M' for i in j])/len(j) for j in train['predicted_loop_type']]\ntrain['G']=[sum([i=='G' for i in j])/len(j) for j in train['sequence']]\ntrain['A']=[sum([i=='A' for i in j])/len(j) for j in train['sequence']]\ntrain['C']=[sum([i=='C' for i in j])/len(j) for j in train['sequence']]\ntrain['U']=[sum([i=='U' for i in j])/len(j) for j in train['sequence']]\ntrain['Paired']=[sum([i=='(' or i==')' for i in j])/len(j) for j in train['structure']]\ntrain['Unpaired']=[sum([i=='.' for i in j])/len(j) for j in train['structure']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train['reactivity']=[np.mean(x) for x in train['reactivity']]\n# train['deg_error_Mg_pH10']=[np.mean(x) for x in train['deg_Mg_pH10']]\n# train['deg_error_pH10']=[np.mean(x) for x in train['deg_pH10']]\n# train['deg_error_Mg_50C']=[np.mean(x) for x in train['deg_Mg_50C']]\n# train['deg_error_50C']=[np.mean(x) for x in train['deg_50C']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train=train[['id', 'sequence', 'structure', 'predicted_loop_type',\n#        'signal_to_noise', 'SN_filter', 'seq_length', 'seq_scored',\n#        'reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10',\n#        'deg_error_Mg_50C', 'deg_error_50C', 'reactivity', 'deg_Mg_pH10',\n#        'deg_pH10', 'deg_Mg_50C', 'deg_50C', 'G', 'A', 'C', 'U', 'Paired',\n#        'Unpaired']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in [ 'G', 'A', 'C', 'U']:\n    train[a+'_position']=[np.sum([i for i in range(len(j)) if j[i]==a])/len([i for i in range(len(j)) if j[i]==a]) for j in train['sequence']]\n    test[a+'_position']=[np.sum([i for i in range(len(j)) if j[i]==a])/len([i for i in range(len(j)) if j[i]==a]) for j in test['sequence']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in [ 'E', 'S', 'H',]:\n    train[a+'_position']=[np.sum([i for i in range(len(j)) if j[i]==a])/len([i for i in range(len(j)) if j[i]==a]) for j in train['predicted_loop_type']]\n    test[a+'_position']=[np.sum([i for i in range(len(j)) if j[i]==a])/len([i for i in range(len(j)) if j[i]==a]) for j in test['predicted_loop_type']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in [ 'E', 'S', 'H',]:\n    train[a+'']=[np.sum([i for i in range(len(j)) if j[i]==a])/len([i for i in range(len(j)) if j[i]==a]) for j in train['predicted_loop_type']]\n    test[a+'_position']=[np.sum([i for i in range(len(j)) if j[i]==a])/len([i for i in range(len(j)) if j[i]==a]) for j in test['predicted_loop_type']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a='S'\n[np.sum([i for i in range(len(j)) if j[i]==a])/len([i for i in range(len(j)) if j[i]==a]) for j in train['predicted_loop_type']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import seaborn as sns\n# plt.subplots(figsize=(20,10))\n# sns.heatmap(train.corr()[[ 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C',\n#        'deg_50C']],annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ex=pd.DataFrame()\nfor index in train.index:\n    temp=pd.DataFrame()\n    temp['id_seqpos']=[str(str(train['id'][index])+'_'+str(i)) for i in range(train['seq_scored'][index])]\n#     temp['sequence']=[train['sequence'][index][i] for i in range(train['seq_scored'][index])]\n    temp['sequence_loop']=[str(train['sequence'][index][i]+train['predicted_loop_type'][index][i]) for i in range(train['seq_scored'][index])]\n    temp['structure']=[train['structure'][index][i] for i in range(train['seq_scored'][index])]\n#     temp['predicted_loop_type']=[train['predicted_loop_type'][index][i] for i in range(train['seq_scored'][index])]\n    for r in range(1,20):\n        temp[str(str(r)+'forward_predicted_loop_type')]=[train['predicted_loop_type'][index][i+r] if i+r<train['seq_scored'][index] else -1 for i in range(train['seq_scored'][index])]\n        temp[str(str(r)+'backward_predicted_loop_type')]=[train['predicted_loop_type'][index][i-r] for i in range(train['seq_scored'][index])]\n        temp[str(str(r)+'forward_structure')]=[train['structure'][index][i+r] if i+r<train['seq_scored'][index] else -1 for i in range(train['seq_scored'][index])]\n        temp[str(str(r)+'backward_structure')]=[train['structure'][index][i-r] for i in range(train['seq_scored'][index])]\n        temp[str(str(r)+'forward_sequence')]=[train['sequence'][index][i+r] if i+r<train['seq_scored'][index] else -1 for i in range(train['seq_scored'][index])]\n        temp[str(str(r)+'backward_sequence')]=[train['sequence'][index][i-r] for i in range(train['seq_scored'][index])]\n    temp['E']=train['E'][index]\n    temp['S']=train['S'][index]\n    temp['B']=train['B'][index]\n    temp['H']=train['H'][index]\n    temp['I']=train['I'][index]\n    temp['G']=train['G'][index]\n    temp['A']=train['A'][index]\n    temp['C']=train['C'][index]\n    temp['U']=train['U'][index]\n    temp['index']=[i for i in range(train['seq_scored'][index])]\n    temp['Paired']=train['Paired'][index]\n    temp['Unpaired']=train['Unpaired'][index]\n    temp['G_position']=train['G_position'][index]\n    temp['A_position']=train['A_position'][index]\n    temp['C_position']=train['C_position'][index]\n    temp['U_position']=train['U_position'][index]\n    temp['E_position']=train['E_position'][index]\n    temp['S_position']=train['S_position'][index]\n    temp['H_position']=train['H_position'][index]\n    temp['reactivity']=[train['reactivity'][index][i] for i in range(train['seq_scored'][index])]\n    temp['deg_Mg_pH10']=[train['deg_Mg_pH10'][index][i] for i in range(train['seq_scored'][index])]\n    temp['deg_pH10']=[train['deg_pH10'][index][i] for i in range(train['seq_scored'][index])]\n    temp['deg_Mg_50C']=[train['deg_Mg_50C'][index][i] for i in range(train['seq_scored'][index])]\n    temp['deg_50C']=[train['deg_50C'][index][i] for i in range(train['seq_scored'][index])]\n    train_ex=train_ex.append(temp)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ex['sequence_loop'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ex=pd.DataFrame()\nfor index in test.index:\n    temp=pd.DataFrame()\n    temp['id_seqpos']=[str(str(test['id'][index])+'_'+str(i)) for i in range(test['seq_length'][index])]\n#     temp['sequence']=[test['sequence'][index][i] for i in range(test['seq_length'][index])]\n    temp['sequence_loop']=[str(test['sequence'][index][i]+test['predicted_loop_type'][index][i]) for i in range(test['seq_length'][index])]\n    temp['structure']=[test['structure'][index][i] for i in range(test['seq_length'][index])]\n#     temp['predicted_loop_type']=[test['predicted_loop_type'][index][i] for i in range(test['seq_length'][index])]\n    \n    for r in range(1,20):\n        temp[str(str(r)+'forward_predicted_loop_type')]=[test['predicted_loop_type'][index][i+r] if i+r<test['seq_length'][index] else -1 for i in range(test['seq_length'][index])]\n        temp[str(str(r)+'backward_predicted_loop_type')]=[test['predicted_loop_type'][index][i-r] for i in range(test['seq_length'][index])]\n        temp[str(str(r)+'forward_structure')]=[test['structure'][index][i+r] if i+r<test['seq_length'][index] else -1 for i in range(test['seq_length'][index])]\n        temp[str(str(r)+'backward_structure')]=[test['structure'][index][i-r] for i in range(test['seq_length'][index])]\n        temp[str(str(r)+'forward_sequence')]=[test['sequence'][index][i+r] if i+r<test['seq_length'][index] else -1 for i in range(test['seq_length'][index])]\n        temp[str(str(r)+'backward_sequence')]=[test['sequence'][index][i-r] for i in range(test['seq_length'][index])]\n    temp['E']=test['E'][index]\n    temp['S']=test['S'][index]\n    temp['B']=test['B'][index]\n    temp['H']=test['H'][index]\n    temp['I']=test['I'][index]\n    temp['G']=test['G'][index]\n    temp['A']=test['A'][index]\n    temp['C']=test['C'][index]\n    temp['U']=test['U'][index]\n    temp['index']=[i for i in range(test['seq_length'][index])]\n    temp['Paired']=test['Paired'][index]\n    temp['Unpaired']=test['Unpaired'][index]\n    temp['G_position']=test['G_position'][index]\n    temp['A_position']=test['A_position'][index]\n    temp['C_position']=test['C_position'][index]\n    temp['U_position']=test['U_position'][index]\n    temp['E_position']=test['E_position'][index]\n    temp['S_position']=test['S_position'][index]\n    temp['H_position']=test['H_position'][index]\n    test_ex=test_ex.append(temp)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=test_ex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_columns=[i for i in np.intersect1d(test_ex.columns,train_ex.columns) if i!='id_seqpos']\nx_test=test_ex[test_columns]\nx_t=train_ex[test_columns]\nx_test=pd.get_dummies(x_test)\nx_t=pd.get_dummies(x_t)\ntest_dum_columns=[i for i in np.intersect1d(x_t.columns,x_test.columns)]\ny_t=train_ex[['reactivity', 'deg_Mg_pH10',\n       'deg_pH10', 'deg_Mg_50C', 'deg_50C']]\nx_t=x_t[test_dum_columns]\nx_test=x_test[test_dum_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(x_t)\n\nx_t = scaler.transform(x_t)\nx_test = scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_valid,y_train,y_valid=train_test_split(x_t,y_t,test_size=0.1,shuffle=True)\nprint(x_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\nimport xgboost as xgb\nimport sklearn\ncolumn='reactivity'\ndef objective(trial):\n    column='reactivity'\n    dtrain = xgb.DMatrix(x_train, label=y_train[column])\n    dvalid = xgb.DMatrix(x_valid, label=y_valid[column])\n    \n    param = {\n        \"silent\": 1,\n#           \"scale_pos_weight\":trial.suggest_int(\"scale_pos_weight\", 1, 10),\n          \"eval_metric\": \"rmse\",\n        \"booster\": \"gbtree\",\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n        'tree_method' : 'gpu_hist'\n        \n    }\n\n    if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n#         param[\"eta\"] = trial.suggest_loguniform(\"eta\", 1e-8, 1.0)\n#         param[\"gamma\"] = trial.suggest_loguniform(\"gamma\", 1e-8, 1.0)\n#         param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n\n\n    # Add a callback for pruning.\n#     pruning_callback = optuna.integration.XGBoostPruningCallback(trial, str(\"validation-\"+param[\"eval_metric\"]))\n    bst = xgb.train(param, dtrain, evals=[(dvalid, \"validation\")])\n    preds = bst.predict(dvalid)\n    rmse=np.sqrt(sklearn.metrics.mean_squared_error(y_valid[column], preds))\n    return rmse\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study()\nstudy.optimize(objective, n_trials=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(study.best_params)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(x_train, label=y_train[column])\ndvalid = xgb.DMatrix(x_valid, label=y_valid[column])\ndtest = xgb.DMatrix(x_test)\nbst = xgb.train( study.best_params,dtrain, evals=[(dvalid, \"validation\")])\npreds = bst.predict(dtest)\nresult[column]=preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\nimport xgboost as xgb\nimport sklearn\ncolumn='deg_Mg_pH10'\ndef objective(trial):\n    column='deg_Mg_pH10'\n    dtrain = xgb.DMatrix(x_train, label=y_train[column])\n    dvalid = xgb.DMatrix(x_valid, label=y_valid[column])\n\n    param = {\n        \"silent\": 1,\n#           \"scale_pos_weight\":trial.suggest_int(\"scale_pos_weight\", 1, 10),\n          \"eval_metric\": \"rmse\",\n        \"booster\": \"gbtree\",\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n        'tree_method' : 'gpu_hist'\n        \n    }\n\n    if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n#         param[\"eta\"] = trial.suggest_loguniform(\"eta\", 1e-8, 1.0)\n#         param[\"gamma\"] = trial.suggest_loguniform(\"gamma\", 1e-8, 1.0)\n#         param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n\n\n    # Add a callback for pruning.\n#     pruning_callback = optuna.integration.XGBoostPruningCallback(trial, str(\"validation-\"+param[\"eval_metric\"]))\n    bst = xgb.train(param, dtrain, evals=[(dvalid, \"validation\")])\n    preds = bst.predict(dvalid)\n    rmse=np.sqrt(sklearn.metrics.mean_squared_error(y_valid[column], preds))\n    return rmse\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study()\nstudy.optimize(objective, n_trials=200)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study.best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(x_train, label=y_train[column])\ndvalid = xgb.DMatrix(x_valid, label=y_valid[column])\ndtest = xgb.DMatrix(x_test)\nbst = xgb.train( study.best_params,dtrain, evals=[(dvalid, \"validation\")])\npreds = bst.predict(dtest)\nresult[column]=preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\nimport xgboost as xgb\nimport sklearn\ncolumn='deg_Mg_50C'\ndef objective(trial):\n    column='deg_Mg_50C'\n    dtrain = xgb.DMatrix(x_train, label=y_train[column])\n    dvalid = xgb.DMatrix(x_valid, label=y_valid[column])\n\n    param = {\n        \"silent\": 1,\n#           \"scale_pos_weight\":trial.suggest_int(\"scale_pos_weight\", 1, 10),\n          \"eval_metric\": \"rmse\",\n        \"booster\": \"gbtree\",\n        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n        'tree_method' : 'gpu_hist'\n        \n    }\n\n    if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n#         param[\"eta\"] = trial.suggest_loguniform(\"eta\", 1e-8, 1.0)\n#         param[\"gamma\"] = trial.suggest_loguniform(\"gamma\", 1e-8, 1.0)\n#         param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n\n\n    # Add a callback for pruning.\n#     pruning_callback = optuna.integration.XGBoostPruningCallback(trial, str(\"validation-\"+param[\"eval_metric\"]))\n    bst = xgb.train(param, dtrain, evals=[(dvalid, \"validation\")])\n    preds = bst.predict(dvalid)\n    rmse=np.sqrt(sklearn.metrics.mean_squared_error(y_valid[column], preds))\n    return rmse\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study()\nstudy.optimize(objective, n_trials=200)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study.best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(x_train, label=y_train[column])\ndvalid = xgb.DMatrix(x_valid, label=y_valid[column])\ndtest = xgb.DMatrix(x_test)\nbst = xgb.train( study.best_params,dtrain, evals=[(dvalid, \"validation\")])\npreds = bst.predict(dtest)\nresult[column]=preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['deg_pH10']=0\nresult['deg_50C']=0\nresult[['id_seqpos','reactivity', 'deg_Mg_pH10',\n       'deg_pH10', 'deg_Mg_50C', 'deg_50C']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result[['id_seqpos','reactivity', 'deg_Mg_pH10',\n       'deg_pH10', 'deg_Mg_50C', 'deg_50C']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}