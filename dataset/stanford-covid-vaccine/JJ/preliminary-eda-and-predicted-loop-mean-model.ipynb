{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/stanford-covid-vaccine'\n\ntrain = pd.read_json(f'{PATH}/train.json',lines=True).drop(columns=['index'])\ntest = pd.read_json(f'{PATH}/test.json', lines=True).drop(columns=['index'])\nsubmission = pd.read_csv(f'{PATH}/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Variables\n\n#### Sequence Variables\n\n* `sequence` - provides the nucleotide sequence\n* `structure` - provides the pairing data where `(` and `)` refer to paired sequences at their respective indices while `.` means an unpaired sequence\n* `predicted_loop_type` - describe the structural context of the sequence\n  * S: paired \"Stem\" \n  * M: Multiloop \n  * I: Internal loop \n  * B: Bulge \n  * H: Hairpin loop \n  * E: dangling End \n  * X: eXternal loop\n  \n#### Evaluation\n\n* The model will be predicting `reactivity`, `deg_Mg_pH10`, `deg_pH10`, `deg_Mg_50C`, and `deg_50C` for each nucleotide position in the mRNA\n* However the model will only be evaluated on the first `seq_scored` nucleotides since the competition organizers use a next-generation sequencer that provides measurements for all samples in a single reaction, however \"padding\" nucleotides are used for demultiplexing (https://www.kaggle.com/c/stanford-covid-vaccine/discussion/181991)\n* The *mean column-wise root mean squared error (MCRMSE)* is used"},{"metadata":{},"cell_type":"markdown","source":"## Ideas\n\n* From a structural perspective, it seems that each nucleotide's reactivity is dependent on its place in the overall structure\n* Perhaps one of the things to ask is what is the overall stability of the molecule itself?\n  * I would hypothesize that a more stable molecule is less likely to have individual nucleotides that are more reactive\n* However we're tasked with finding the local stability as well\n  * Likely this will be dependent on the following:\n    * Nucleotide type - G/C tend to be more stable compared to A/T due to three vs two hydrogen bonds\n    * Surrounding structure - anticipate that change points in surrounding structures will correlate to weaknesses"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_structure_mean_value(row, col):\n    r_d = {'S': [], 'M': [], 'I': [], 'B': [], 'H': [], 'E': [], 'X': []}\n    for p, r in zip(row['predicted_loop_type'], row[col]):\n        r_d[p].append(r)\n\n    r_m = {}\n    for k in r_d.keys():\n        r_m[k] = np.mean(r_d[k])\n    return r_m['S'], r_m['M'], r_m['I'], r_m['B'], r_m['H'], r_m['E'], r_m['X']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r_vals = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\ne_vals = ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in r_vals:\n    train[f'S_{col}'], train[f'M_{col}'], train[f'I_{col}'], train[f'B_{col}'], train[f'H_{col}'], train[f'E_{col}'], train[f'X_{col}'] = zip(*train.apply(lambda x: get_structure_mean_value(x, col), axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_loop_type_values(df, col, xlim):\n    df[[f'S_{col}', f'M_{col}', f'I_{col}', f'B_{col}', f'H_{col}', f'E_{col}', f'X_{col}']].plot.kde(title=col, xlim=xlim)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see the reactivity by the Predicted Loop Type. Makes sense to think that the stems should be less reactive while the dangling ends are the most reactive."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in r_vals:\n    plot_loop_type_values(train, col, xlim=[-2, 3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dumb Model\n\nLet's make a dumb model that only uses the averages of the overall `predicted_loop_type` values per predicted column."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"loop_type = ['S', 'M', 'I', 'B', 'H', 'E', 'X']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_mean_loop_vals = {}\nsn_train = train[train['SN_filter']==1]\nfor col in r_vals:\n    mean_loop_vals = {}\n    for loop in loop_type:\n        v = sn_train[f'{loop}_{col}']\n        mean_loop_vals[loop] = np.nanmean(v.values)\n    all_mean_loop_vals[col] = mean_loop_vals","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dumb Model CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only use the ones that qualify according the Signal to Noise Filter\ncv_train = train[train['SN_filter']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_train = cv_train[['id', 'predicted_loop_type'] + r_vals]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_out = {}\nfor col in r_vals:\n    cv_out[col] = np.array([np.array(x) for x in cv_train[col].values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the predicted values according to the dumb model\ncv_preds = {}\nfor col in r_vals:\n    data = []\n    for i, loop in enumerate(cv_train['predicted_loop_type']):\n        vals = np.zeros(len(loop))\n        for j, nt in enumerate(loop):\n            vals[j] = all_mean_loop_vals[col][nt]\n        data.append(vals[:68])\n    cv_preds[col] = np.array(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mcrmse(y_grd, y_hat):\n    r_vals = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n    cv_score = []\n    for col in r_vals:\n        cv_score.append(np.sqrt(np.mean(np.square(y_grd[col] - y_hat[col]))))\n    return np.mean(cv_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation\n\nInterestingly, this is scoring better than some of the other XGBoost and LightGBM models out there!"},{"metadata":{"trusted":true},"cell_type":"code","source":"mcrmse(cv_out, cv_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_rows = []\nfor j,r in test[['id', 'predicted_loop_type']].iterrows():\n    for i, loop in enumerate(r['predicted_loop_type']):\n        #print(loop)\n        row = {}\n        row['id_seqpos'] = f'{r[\"id\"]}_{i}'\n        for col in r_vals:\n            row[col] = all_mean_loop_vals[col][loop]\n        all_rows.append(row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(all_rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}