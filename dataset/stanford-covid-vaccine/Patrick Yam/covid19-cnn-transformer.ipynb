{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from shutil import copyfile\ncopyfile(src = \"../usr/lib/modellib/modellib.py\", dst = \"../working/ModelLib.py\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import TensorDataset, Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom tqdm.auto import tqdm\nfrom ModelLib import Create_model,stratified_group_k_fold\nimport random\nimport os\nfrom copy import deepcopy\nimport math\nfrom glob import glob","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"random.seed(831)\nos.environ['PYTHONHASHSEED'] = str(721)\nnp.random.seed(1111)\ntorch.manual_seed(1117)\ntorch.cuda.manual_seed(1001)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n# device = 'cpu'\ndevice = 'cuda'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_x = np.load('../input/covid19fe/train_x.npy')\n# test_x = np.load('../input/covid19fe/test_x.npy')\ntrain_x = np.load('../input/covid19fe/train_aug_x.npy')\ntest_x = np.load('../input/covid19fe/test_aug_x.npy')\ntrain_bpps = np.load('../input/covid19fe/train_bpps.npy')\ntest_bpps = np.load('../input/covid19fe/test_bpps.npy')\ntrain_viennarna_bpps = np.load('../input/covid19extrafeatures/train_viennarna_bpps.npy')\ntest_viennarna_bpps = np.load('../input/covid19extrafeatures/test_viennarna_bpps.npy')\ntrain_mat = np.load('../input/covid19extrafeatures/train_mat.npy')\ntest_mat = np.load('../input/covid19extrafeatures/test_mat.npy')\ntrain_aug_mat = np.load('../input/covid19fe/train_aug_mat.npy')\ntest_aug_mat = np.load('../input/covid19fe/test_aug_mat.npy')\nlabel = np.load('../input/covid19fe/label.npy')\nlabel_error = np.load('../input/covid19fe/label_error.npy')\nsignal_to_noise = np.load('../input/covid19fe/signal_to_noise.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train_x[:,:,[0,2,3,4,5]]\ntest_x = test_x[:,:,[0,2,3,4,5]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_bpps = np.concatenate([np.expand_dims(train_bpps,axis=1),np.expand_dims(train_viennarna_bpps,axis=1),np.expand_dims(train_mat,axis=1),np.expand_dims(train_aug_mat,axis=1)],axis=1)\ntest_bpps = np.concatenate([np.expand_dims(test_bpps,axis=1),np.expand_dims(test_viennarna_bpps,axis=1),np.expand_dims(test_mat,axis=1),np.expand_dims(test_aug_mat,axis=1)],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json',lines=True).drop('index',axis=1)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json',lines=True).drop('index',axis=1)\n\ntrain_length = train.seq_length.values\ntest_length = test.seq_length.values\n\ntrain_scored = train.seq_scored.values\ntest_scored = test.seq_scored.values\n\nSN_filter_mask = (train.SN_filter==1).values\nSN_filter = np.where(SN_filter_mask)[0]\nsignal_filter = np.where(signal_to_noise > 1)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import OneHotEncoder,scale\n# from sklearn.cluster import KMeans\n# cluster_features = OneHotEncoder().fit_transform(train_x[:,:107,0].reshape(-1,1)).toarray().reshape([len(train),-1])\n# cluster_features = scale(cluster_features,axis=0)\n# kmeans_model = KMeans(n_clusters=200, random_state=721).fit(cluster_features)\n# cluster = kmeans_model.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Covid19Dataset(Dataset):\n    def __init__(self,X,bpps,mat,seq_length,scored_length,label=None,label_error=None,signal_to_noise=None,SN_filter_mask=None):\n        self.X = X.astype(np.int)\n#         self.bpps = np.log(bpps + 1e-8).astype(np.float32)\n        self.bpps = bpps.astype(np.float32)\n        \n#         self.bpps = np.log(bpps + 1e-8)\n#         self.bpps = np.concatenate([bpps.reshape([-1,130,130,1]),mat.reshape([-1,130,130,1])],axis=-1).astype(np.float32)\n        if label is not None:\n            self.label = label.astype(np.float32)\n            self.signal_to_noise = signal_to_noise.astype(np.float32)\n            self.label_error=label_error.astype(np.float32)\n            self.SN_filter_mask = SN_filter_mask\n        else:\n            self.label = None\n        self.mask = np.zeros([len(X),130],dtype=bool)\n        for i in range(len(seq_length)):\n            if seq_length[i] < 130:\n                self.mask[i,seq_length[i]:] = True\n        self.scored_mask = np.ones([len(X),130],dtype=bool)\n        for i in range(len(scored_length)):\n            if scored_length[i] < 130:\n                self.scored_mask[i,scored_length[i]:] = False\n        self.seq_length = seq_length\n\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        N = self.seq_length[idx]\n        X = self.X[idx,:N]\n        bpps = self.bpps[idx,:,:N,:N]\n        mask = self.mask[idx,:N]\n        scored_mask = self.scored_mask[idx,:N]\n        if self.label is not None:\n            label = self.label[idx,:N]\n            label_error= self.label_error[idx,:N]\n            signal_to_noise = self.signal_to_noise[idx]\n            SN_filter_mask = self.SN_filter_mask[idx]\n            return X,bpps,mask,scored_mask,label,label_error,signal_to_noise,SN_filter_mask\n        else:\n            return X,bpps,mask,scored_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nepochs = 500\nn_fold = 5\nkf = StratifiedKFold(n_fold,shuffle=True,random_state=721)\n\ndataset = Covid19Dataset(train_x,train_bpps,train_mat,train_length,train_scored,label,label_error,signal_to_noise,SN_filter_mask)\ncv_score = []\n# cv_score = [0.20199335118134817, 0.19580934941768646, 0.19966551661491394]\nloss_weights = torch.Tensor([1.2,1.2,1.2,0.7,0.7]).reshape(1,5).to(device)\noof = np.zeros([len(train_x),68,3])\n# oof = np.load('temp_oof.npy')\nfor fold,(trn_group, test_group) in tqdm(enumerate(kf.split(train_x,SN_filter_mask)),total=n_fold):\n#     trn_group = np.intersect1d(trn_group,signal_filter)\n    test_group = np.intersect1d(test_group,signal_filter)\n    traindataset = Covid19Dataset(train_x[trn_group],\n                             train_bpps[trn_group],\n                             train_mat[trn_group],\n                             train_length[trn_group],\n                             train_scored[trn_group],\n                             label[trn_group],\n                             label_error[trn_group],\n                             signal_to_noise[trn_group],\n                             SN_filter_mask[trn_group])\n    valdataset = Covid19Dataset(train_x[test_group],\n                             train_bpps[test_group],\n                             train_mat[test_group],\n                             train_length[test_group],\n                             train_scored[test_group],\n                             label[test_group],\n                             label_error[test_group],\n                             signal_to_noise[test_group],\n                             SN_filter_mask[test_group])\n    \n    args_loader = {'batch_size': 96, 'shuffle': True, 'num_workers': 0, 'pin_memory': True, 'drop_last': True}\n    train_loader = DataLoader(traindataset, **args_loader)\n    args_loader = {'batch_size': 96, 'shuffle': False, 'num_workers': 0, 'pin_memory': True, 'drop_last': False}\n    val_loader = DataLoader(valdataset, **args_loader)\n    \n    dataloaders = {'train' : train_loader, 'val' : val_loader}\n    \n    model,optimizer,scheduler = Create_model(device)\n    best_model = {'reactivity':None,'deg_Mg_pH10':None,\"deg_Mg_50C\":None}\n    best_loss = {'reactivity': np.inf,'deg_Mg_pH10': np.inf,'deg_Mg_50C': np.inf}\n    stop_count = 0\n    for epoch in tqdm(range(nepochs)):\n        epoch_loss = {'train': 0.0, 'val': 0.0, 'val_clean': 0.0, 'val_aug': 0.0,\n                      'reactivity': 0.0,'deg_Mg_pH10': 0.0,'deg_Mg_50C': 0.0\n                     }\n        MA_loss = []\n        test_pred = []\n        test_pred_aug = []\n        test_y = []\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            for x_b,bpps_b,mask_b,scored_mask_b,label_b,label_error_b,signal_to_noise_b,SN_filter_mask_b in dataloaders[phase]:\n                x_b = x_b.long().to(device)\n                bpps_b = bpps_b.to(device)\n                mask_b = mask_b.to(device)\n                label_b = label_b.to(device)\n                label_error_b = label_error_b.to(device)\n                signal_to_noise_b = signal_to_noise_b.to(device).unsqueeze(1).unsqueeze(1)\n                signal_to_noise_b = torch.clamp(signal_to_noise_b/4.5,0,10)\n#                 signal_to_noise_b = torch.clamp(signal_to_noise_b/5,0,10)\n#                 signal_to_noise_b = torch.clamp(torch.log(1 + signal_to_noise_b)/1.5,0,10)\n#                 signal_to_noise_b = torch.sqrt(torch.clamp(signal_to_noise_b,0,999))/2\n\n                label_error_b = torch.log(1+1.0/label_error_b[:,:68]) / 2.2496114573105803\n    \n                SN_filter_mask_b = SN_filter_mask_b.to(device)\n                if phase=='train':\n                    aug_mask = torch.randint(low=0,high=2,size=[len(bpps_b)],dtype=bool).to(device)\n                    x_b[aug_mask,:,-4] = x_b[aug_mask,:,-2]\n                    x_b[aug_mask,:,-3] = x_b[aug_mask,:,-1]\n                    x_b = x_b[:,:,:-2]\n                    bpps_b[aug_mask,-2] = bpps_b[aug_mask,-1]\n                    bpps_b = bpps_b[:,:-1]\n                else:\n                    x_b_aug = x_b.clone()\n                    x_b_aug[:,:,-4] = x_b_aug[:,:,-2]\n                    x_b_aug[:,:,-3] = x_b_aug[:,:,-1]\n                    x_b_aug  = x_b_aug[:,:,:-2]\n                    bpps_b_aug = bpps_b.clone()\n                    bpps_b_aug[:,-2] = bpps_b_aug[:,-1]\n                    bpps_b_aug = bpps_b_aug[:,:-1]\n                    \n                    x_b = x_b[:,:,:-2]\n                    bpps_b = bpps_b[:,:-1]\n                \n#                 if phase=='train':\n#                     label_b += torch.normal(torch.zeros_like(label_b),1) * 0.001*label_error_b\n                \n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase=='train'):\n                    preds = model(x_b,bpps_b)\n                    if phase=='val':\n                        preds_aug = model(x_b_aug,bpps_b_aug)\n                        preds2 = 0.5*(preds + preds_aug)\n                        test_pred.append(preds[:,:68,:3].detach().cpu().numpy())\n                        test_pred_aug.append(preds2[:,:68,:3].detach().cpu().numpy())\n                        test_y.append(label_b[:,:68,:3].detach().cpu().numpy())\n\n        \n                    loss = (preds[:,:68] - label_b[:,:68])**2\n                    loss = torch.sqrt((loss * signal_to_noise_b).reshape(-1,5).mean(0)).mean()\n#                     loss = torch.sqrt((loss * signal_to_noise_b).reshape(-1,5)[:,:3].mean(0)).mean()\n                \n#                     loss = (preds[:,:68] - label_b[:,:68])**2\n#                     loss = (label_error_b * loss).mean()\n\n                    if phase=='train':\n                        loss.backward()\n#                         torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n                        optimizer.step()\n#                         scheduler.step()\n                if phase == 'train':\n                    running_loss += loss.item() / len(dataloaders[phase])\n                else:\n                    running_loss += loss.item() / len(dataloaders[phase])\n            if phase == 'train':\n                epoch_loss['train'] = running_loss\n            else:\n                epoch_loss['val'] = running_loss\n                test_pred = np.concatenate(test_pred,axis=0)\n                test_pred_aug = np.concatenate(test_pred_aug,axis=0)\n                test_y = np.concatenate(test_y,axis=0)\n                epoch_loss['val_clean'] = np.sqrt(((test_pred-test_y)**2).reshape(-1,3).mean(0)).mean()\n                res = ((test_pred_aug-test_y)**2).reshape(-1,3)\n                epoch_loss['val_aug'] = np.sqrt(res.mean(0)).mean()\n                epoch_loss['reactivity'] = np.sqrt(res[:,0].mean())\n                epoch_loss['deg_Mg_pH10'] = np.sqrt(res[:,1].mean())\n                epoch_loss['deg_Mg_50C'] = np.sqrt(res[:,2].mean())\n        scheduler.step()\n        for i,cat in enumerate(['reactivity','deg_Mg_pH10','deg_Mg_50C']):\n            if epoch_loss[cat] < best_loss[cat]:\n                best_loss[cat] = epoch_loss[cat]\n                torch.save(model.state_dict(), f'fold{fold+1}_{cat}_model.pt')\n                oof[test_group,:,i] = test_pred_aug[:,:,i]\n                stop_count = 0\n        stop_count += 1\n        print(\"Epoch {}/{}   -   loss: {:5.5f} - val_loss: {:5.5f} - val_best_loss: {:5.5f} - val_aug_loss: {:5.5f} - reactivity: {:5.5f} - deg_Mg_pH10: {:5.5f} - deg_Mg_50C: {:5.5f}\".format(epoch+1, nepochs, epoch_loss['train'], epoch_loss['val'], sum(best_loss.values())/3, epoch_loss['val_aug'], epoch_loss['reactivity'], epoch_loss['deg_Mg_pH10'], epoch_loss['deg_Mg_50C']))\n        if stop_count > 50:\n            break\n#     cv_score += best_score / 5\n    cv_score.append(sum(best_loss.values())/3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(n_fold):\n    print(f\"fold {i+1} score:\",cv_score[i])\nprint()\nprint(\"CV score:\",np.mean(cv_score))\nnp.save('oof_{:5.5f}'.format(np.mean(cv_score)),oof)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = Covid19Dataset(test_x,test_bpps,test_mat,test_length,test_scored)\nargs_loader = {'batch_size': 1, 'shuffle': False, 'num_workers': 0, 'pin_memory': True, 'drop_last': False}\ntest_loader = DataLoader(dataset, **args_loader)\ntest_predictions = np.zeros([len(test_x),130,5])\nfor j,col in enumerate(['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']):\n    paths = glob(f'fold*_{col}_model.pt')\n    with torch.no_grad():\n        for path in tqdm(paths):\n            model.load_state_dict(torch.load(path))\n            model.eval().to(device)\n            predictions = []\n            for x_b,bpps_b,mask_b,scored_mask_b in test_loader:\n                x_b = x_b.long().to(device)\n                bpps_b = bpps_b.to(device)\n                mask_b = mask_b.to(device)\n                x_b_aug = x_b.clone()\n                x_b_aug[:,:,-4] = x_b_aug[:,:,-2]\n                x_b_aug[:,:,-3] = x_b_aug[:,:,-1]\n                x_b_aug  = x_b_aug[:,:,:-2]\n                bpps_b_aug = bpps_b.clone()\n                bpps_b_aug[:,-2] = bpps_b_aug[:,-1]\n                bpps_b_aug = bpps_b_aug[:,:-1]\n                x_b = x_b[:,:,:-2]\n                bpps_b = bpps_b[:,:-1]\n\n                preds = model(x_b,bpps_b)\n                preds_aug = model(x_b_aug,bpps_b_aug)\n                preds = 0.5*(preds + preds_aug)\n\n                p = torch.zeros([preds.shape[0],130,preds.shape[2]])\n                p[:,:preds.shape[1]] = preds.cpu()\n                predictions.append(p)\n            predictions = torch.cat(predictions,dim=0).numpy()\n            test_predictions[:,:,j] += predictions[:,:,j] / len(paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv(\"../input/stanford-covid-vaccine/sample_submission.csv\",index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n,row in tqdm(test.iterrows(),total=len(test)):\n    test_id = row['id']\n    seq_len = row['seq_length']\n    for i in range(seq_len):\n        for j,col in enumerate(['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']):\n            ss.loc[test_id+'_'+str(i),col] = test_predictions[n,i,j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv(\"submission_cnn_{:5.5f}.csv\".format(np.mean(cv_score)),index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}