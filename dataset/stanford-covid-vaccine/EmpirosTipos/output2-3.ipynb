{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"import os \nimport sys\nimport json\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nimport gc\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom sklearn.model_selection import train_test_split, KFold,  StratifiedKFold\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nseed = 42\ndropout_model = 0.36\nhidden_dim_first = 128\nhidden_dim_second = 248\nhidden_dim_third = 208\n\ncommits_df = pd.DataFrame(columns = ['commit_num', 'dropout_model', 'hidden_dim_first', 'hidden_dim_second', 'hidden_dim_third', 'LB_score'])\n\nn=0\ncommits_df.loc[n,'commit_num'] = 0\ncommits_df.loc[n,'dropout_model'] = 0.4\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 128\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25883\n\n\nn=1\ncommits_df.loc[n,'commit_num'] = 3\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 256\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25855\n\n\nn=2\ncommits_df.loc[n,'commit_num'] = 4\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 256\ncommits_df.loc[n,'hidden_dim_second'] = 256\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25887\n\n\n\nn=3\ncommits_df.loc[n,'commit_num'] = 5\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 384\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25880\n\n\nn=4\ncommits_df.loc[n,'commit_num'] = 6\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 384\ncommits_df.loc[n,'hidden_dim_second'] = 128\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25989\n\n\nn=5\ncommits_df.loc[n,'commit_num'] = 7\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 192\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25877\n\n\nn=6\ncommits_df.loc[n,'commit_num'] = 8\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 224\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25868\n\nn=7\ncommits_df.loc[n,'commit_num'] = 9\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 288\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25881\n\n\nn=8\ncommits_df.loc[n,'commit_num'] = 10\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25850\n\nn=9\ncommits_df.loc[n,'commit_num'] = 11\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 240\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25868\n\n\nn=10\ncommits_df.loc[n,'commit_num'] = 12\ncommits_df.loc[n,'dropout_model'] = 0.35\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25884\n\nn=11\ncommits_df.loc[n,'commit_num'] = 13\ncommits_df.loc[n,'dropout_model'] = 0.3\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25879\n\nn=12\ncommits_df.loc[n,'commit_num'] = 15\ncommits_df.loc[n,'dropout_model'] = 0.45\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25920\n\nn=13\ncommits_df.loc[n,'commit_num'] = 17\ncommits_df.loc[n,'dropout_model'] = 0.37\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 128\ncommits_df.loc[n,'LB_score'] = 0.25885\n\nn=14\ncommits_df.loc[n,'commit_num'] = 18\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 248\ncommits_df.loc[n,'LB_score'] = 0.25841\n\n\nn=15\ncommits_df.loc[n,'commit_num'] = 19\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 384\ncommits_df.loc[n,'LB_score'] = 0.25956\n\nn=16\ncommits_df.loc[n,'commit_num'] = 20\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 128\ncommits_df.loc[n,'hidden_dim_third'] = 248\ncommits_df.loc[n,'LB_score'] = 0.25891\n\nn=17\ncommits_df.loc[n,'commit_num'] = 21\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 240\ncommits_df.loc[n,'LB_score'] = 0.25831\n\nn=18\ncommits_df.loc[n,'commit_num'] = 22\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 216\ncommits_df.loc[n,'LB_score'] = 0.25827\n\nn=19\ncommits_df.loc[n,'commit_num'] = 23\ncommits_df.loc[n,'dropout_model'] = 0.36\ncommits_df.loc[n,'hidden_dim_first'] = 128\ncommits_df.loc[n,'hidden_dim_second'] = 248\ncommits_df.loc[n,'hidden_dim_third'] = 184\ncommits_df.loc[n,'LB_score'] = 0.25898\n\n\ncommits_df['LB_score'] = pd.to_numeric(commits_df['LB_score'])\ncommits_df['best'] = 0\ncommits_df.loc[commits_df['LB_score'].idxmin(), 'best'] = 1\n\ncommits_df.sort_values(by=['LB_score'])\n\n\nfig = px.scatter_3d(commits_df, x='hidden_dim_first', y='hidden_dim_second', z='LB_score', color = 'best', \n                    symbol = 'dropout_model',\n                    title='hidden_dim_1st & 2nd and LB score visualization of COVID-19 mRNA VDP solutions')\nfig.update(layout=dict(title=dict(x=0.07)))\n\n\n# Interactive plot with results of parameters tuning\nfig = px.scatter_3d(commits_df, x='hidden_dim_second', y='dropout_model', z='LB_score', color = 'best', \n                    symbol = 'hidden_dim_first',\n                    title='hidden_dim_2nd & dropout and LB score visualization of COVID-19 mRNA VDP solutions')\nfig.update(layout=dict(title=dict(x=0.07)))\n\n\n\nfig = px.scatter_3d(commits_df, x='hidden_dim_second', y='hidden_dim_third', z='LB_score', color = 'best', \n                    symbol = 'hidden_dim_first',\n                    title='hidden_dim_2nd & 3nd and LB score visualization of COVID-19 mRNA VDP solutions')\nfig.update(layout=dict(title=dict(x=0.07)))\ndef Funcs(train,test,sample_sub):\n\n    trainNew = train.iloc[:2000,:]\n    testNew = train.loc[2000:,test.columns]\n    \n    test2= testNew.reset_index().iloc[:,1:]\n    test = pd.concat([test2,test.iloc[3631:3633,:]])\n    \n    test= test.reset_index().iloc[:,1:]\n    test.iloc[:,0] = list(range(0,402))\n    \n    \n    \n\n    v=[]\n\n    for i in range(0,400):\n        a = test.id.iloc[i] + '_'\n        for j in range(0,107):\n            #v = a + str(j)\n            v.append(a + str(j))\n            \n    for i in range(400,402):\n        a = test.id.iloc[i] + '_'\n        for j in range(0,130):\n            #v = a + str(j)\n            v.append(a + str(j))\n        \n        \n\n\n    sample_subNew = sample_sub[:len(v)]\n    sample_subNew.iloc[:,0] = v\n    \n    sample_sub = sample_subNew\n    train = trainNew\n\n    \n    return(train,test,sample_sub)for ddd in range(1,2):\n\n    train = pd.read_json('/kaggle/input/stanford-covid-vaccine/train.json', lines=True)\n    test = pd.read_json('/kaggle/input/stanford-covid-vaccine/test.json', lines=True)\n    sample_sub = pd.read_csv(\"/kaggle/input/stanford-covid-vaccine/sample_submission.csv\")    \n    \n    \n   \n\n    if ddd == 0:\n        S = pd.concat([train.iloc[2000:],train.iloc[:2000,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n\n    \n    if ddd == 1:\n        S = pd.concat([train.iloc[1600:],train.iloc[:1600,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n        \n    if ddd == 2:\n        S = pd.concat([train.iloc[1200:],train.iloc[:1200,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n        \n    if ddd == 3:\n        S = pd.concat([train.iloc[800:],train.iloc[:800,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n    \n    if ddd == 4:\n        S = pd.concat([train.iloc[400:],train.iloc[:400,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n    \n        \n        \n        \n        \n    train , test ,sample_sub = Funcs(train,test,sample_sub)\n    \n    target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n    \n    token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n\n    def get_pair_index_structure(structure):\n        structure = np.array([struc for struc in structure], dtype=\"<U4\")\n\n        open_index = np.where(structure == \"(\")[0]\n        closed_index = np.where(structure == \")\")[0]\n\n        structure[open_index] = range(0, len(open_index))\n        structure[closed_index] = range(len(open_index)-1, -1, -1)\n        structure[structure == \".\"] = -1\n        structure = structure.astype(int)\n\n        pair_structure = np.array([-1]*len(structure))\n        for i in range(len(open_index)):\n            start, end = np.where(structure == i)[0]\n            pair_structure[start] = end\n            pair_structure[end] = start    \n\n        return pair_structure\n    \n    \n    def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n        return np.transpose(\n            np.array(\n                df[cols]\n                .applymap(lambda seq: [token2int[x] for x in seq])\n                .values\n                .tolist()\n            ),\n            (0, 2, 1)\n        )\n\n    train_inputs_all = preprocess_inputs(train)\n    train_labels_all = np.array(train[target_cols].values.tolist()).transpose((0, 2, 1))\n    \n    \n    \n    \n    def MCRMSE(y_true, y_pred):\n        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n\n    def gru_layer(hidden_dim, dropout):\n        return tf.keras.layers.Bidirectional(\n                                    tf.keras.layers.GRU(hidden_dim,\n                                    dropout=dropout,\n                                    return_sequences=True,\n                                    kernel_initializer = 'orthogonal'))\n\n    def lstm_layer(hidden_dim, dropout):\n        return tf.keras.layers.Bidirectional(\n                                    tf.keras.layers.LSTM(hidden_dim,\n                                    dropout=dropout,\n                                    return_sequences=True,\n                                    kernel_initializer = 'orthogonal'))\n\n    def build_model(model_type=1, seq_len=107, pred_len=68, embed_dim=100, \n                    dropout=dropout_model, hidden_dim_first = hidden_dim_first, \n                    hidden_dim_second = hidden_dim_second, hidden_dim_third = hidden_dim_third):\n\n        inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n\n        embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n        reshaped = tf.reshape(\n            embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n\n        reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n\n        if model_type == 0:\n            hidden = gru_layer(hidden_dim_first, dropout)(reshaped)\n            hidden = gru_layer(hidden_dim_second, dropout)(hidden)\n            hidden = gru_layer(hidden_dim_third, dropout)(hidden)\n\n        elif model_type == 1:\n            hidden = lstm_layer(hidden_dim_first, dropout)(reshaped)\n            hidden = lstm_layer(hidden_dim_second, dropout)(hidden)\n            hidden = lstm_layer(hidden_dim_third, dropout)(hidden)\n\n        elif model_type == 2:\n            hidden = gru_layer(hidden_dim_first, dropout)(reshaped)\n            hidden = lstm_layer(hidden_dim_second, dropout)(hidden)\n            hidden = lstm_layer(hidden_dim_third, dropout)(hidden)\n\n        elif model_type == 3:\n            hidden = lstm_layer(hidden_dim_first, dropout)(reshaped)\n            hidden = gru_layer(hidden_dim_second, dropout)(hidden)\n            hidden = gru_layer(hidden_dim_third, dropout)(hidden)\n\n        elif model_type == 4:\n            hidden = lstm_layer(hidden_dim_first, dropout)(reshaped)\n            hidden = gru_layer(hidden_dim_second, dropout)(hidden)\n            hidden = lstm_layer(hidden_dim_third, dropout)(hidden)\n\n        truncated = hidden[:, :pred_len]\n\n        out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n\n        model = tf.keras.Model(inputs=inputs, outputs=out)\n\n        adam = tf.optimizers.Adam()\n        model.compile(optimizer=adam, loss=MCRMSE)\n\n        return model\n    \n    \n    def train_and_predict(n_folds=5, model_name=\"model\", model_type=0, epochs=90, debug=False,\n                          dropout_model=dropout_model, hidden_dim_first = hidden_dim_first, \n                          hidden_dim_second = hidden_dim_second, hidden_dim_third = hidden_dim_third,\n                          seed=seed):\n\n        print(\"Model:\", model_name)\n\n        ensemble_preds = pd.DataFrame(index=sample_sub.index, columns=target_cols).fillna(0) # test dataframe with 0 values\n        kf = KFold(n_folds, shuffle=True, random_state=seed)\n        skf = StratifiedKFold(n_folds, shuffle=True, random_state=seed)\n        val_losses = []\n        historys = []\n\n        for i, (train_index, val_index) in enumerate(skf.split(train_inputs_all, train['SN_filter'])):\n            print(\"Fold:\", str(i+1))\n\n            model_train = build_model(model_type=model_type, \n                                      dropout=dropout_model, \n                                      hidden_dim_first = hidden_dim_first, \n                                      hidden_dim_second = hidden_dim_second, \n                                      hidden_dim_third = hidden_dim_third)\n            model_short = build_model(model_type=model_type, seq_len=107, pred_len=107,\n                                      dropout=dropout_model, \n                                      hidden_dim_first = hidden_dim_first, \n                                      hidden_dim_second = hidden_dim_second, \n                                      hidden_dim_third = hidden_dim_third)\n            model_long = build_model(model_type=model_type, seq_len=130, pred_len=130,\n                                     dropout=dropout_model, \n                                     hidden_dim_first = hidden_dim_first, \n                                     hidden_dim_second = hidden_dim_second, \n                                     hidden_dim_third = hidden_dim_third)\n\n            train_inputs, train_labels = train_inputs_all[train_index], train_labels_all[train_index]\n            val_inputs, val_labels = train_inputs_all[val_index], train_labels_all[val_index]\n\n            checkpoint = tf.keras.callbacks.ModelCheckpoint(f'{model_name}.h5')\n\n            history = model_train.fit(\n                train_inputs , train_labels, \n                validation_data=(val_inputs,val_labels),\n                batch_size=64,\n                epochs=epochs, # changed 70\n                callbacks=[tf.keras.callbacks.ReduceLROnPlateau(), checkpoint],\n                verbose=2 if debug else 0\n            )\n\n            print(f\"{model_name} Min training loss={min(history.history['loss'])}, min validation loss={min(history.history['val_loss'])}\")\n\n            val_losses.append(min(history.history['val_loss']))\n            historys.append(history)\n\n            model_short.load_weights(f'{model_name}.h5')\n            model_long.load_weights(f'{model_name}.h5')\n\n            public_preds = model_short.predict(public_inputs)\n            private_preds = model_long.predict(private_inputs)\n\n            preds_model = []\n            for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n                for i, uid in enumerate(df.id):\n                    single_pred = preds[i]\n\n                    single_df = pd.DataFrame(single_pred, columns=target_cols)\n                    single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n                    preds_model.append(single_df)\n\n            preds_model_df = pd.concat(preds_model)\n            ensemble_preds[target_cols] += preds_model_df[target_cols].values / n_folds\n\n            if debug:\n                print(\"Intermediate ensemble result\")\n                print(ensemble_preds[target_cols].head())\n\n        ensemble_preds[\"id_seqpos\"] = preds_model_df[\"id_seqpos\"].values\n        ensemble_preds = pd.merge(sample_sub[\"id_seqpos\"], ensemble_preds, on=\"id_seqpos\", how=\"left\")\n\n        print(\"Mean Validation loss:\", str(np.mean(val_losses)))\n\n        if debug:\n            fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n            for i, history in enumerate(historys):\n                ax.plot(history.history['loss'])\n                ax.plot(history.history['val_loss'])\n                ax.set_title('model_'+str(i+1))\n                ax.set_ylabel('Loss')\n                ax.set_xlabel('Epoch')\n            plt.show()\n\n        return ensemble_preds\n\n\n    public_df = test.query(\"seq_length == 107\").copy()\n    private_df = test.query(\"seq_length == 130\").copy()\n    public_inputs = preprocess_inputs(public_df)\n    private_inputs = preprocess_inputs(private_df)\n\n    ensembles = []\n\n    for i in range(5):\n        model_name = \"model_\"+str(i+1)\n\n        ensemble = train_and_predict(n_folds=5, model_name=model_name, model_type=i, epochs=100,\n                                     dropout_model=dropout_model, hidden_dim_first = hidden_dim_first, \n                                     hidden_dim_second = hidden_dim_second, hidden_dim_third = hidden_dim_third,\n                                     seed=seed)\n        ensembles.append(ensemble)\n    \n    ensemble_final = ensembles[0].copy()\n    ensemble_final[target_cols] = 0\n\n    for ensemble in ensembles:\n        ensemble_final[target_cols] += ensemble[target_cols].values / len(ensembles)\n\n    \n    if ddd == 0:\n        ensemble_final.to_csv('Inputs2_2.csv', index=False)\n    if ddd == 1:\n        ensemble_final.to_csv('Inputs2_3.csv', index=False)\n    if ddd == 2:\n        ensemble_final.to_csv('Inputs2_4.csv', index=False)\n    if ddd == 3:\n        ensemble_final.to_csv('Inputs2_5.csv', index=False)\n    if ddd == 4:\n        ensemble_final.to_csv('Inputs2_6.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}