{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nimport gc\n\nimport tensorflow as tf\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\ndef Funcs(train,test,sample_sub):\n\n    trainNew = train.iloc[:2000,:]\n    testNew = train.loc[2000:,test.columns]\n    \n    test2= testNew.reset_index().iloc[:,1:]\n    test = pd.concat([test2,test.iloc[3631:3633,:]])\n    \n    test= test.reset_index().iloc[:,1:]\n    test.iloc[:,0] = list(range(0,402))\n    \n    \n    \n\n    v=[]\n\n    for i in range(0,400):\n        a = test.id.iloc[i] + '_'\n        for j in range(0,107):\n            #v = a + str(j)\n            v.append(a + str(j))\n            \n    for i in range(400,402):\n        a = test.id.iloc[i] + '_'\n        for j in range(0,130):\n            #v = a + str(j)\n            v.append(a + str(j))\n        \n        \n\n\n    sample_subNew = sample_sub[:len(v)]\n    sample_subNew.iloc[:,0] = v\n    \n    sample_sub = sample_subNew\n    train = trainNew\n\n    \n    return(train,test,sample_sub)\n\n\nfor ddd in range(2,3):\n    train = pd.read_json('../input/stanford-covid-vaccine/train.json',lines=True)\n    test = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\n    sample_sub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\n    \n    \n    if ddd == 0:\n        S = pd.concat([train.iloc[2000:],train.iloc[:2000,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n\n    \n    if ddd == 1:\n        S = pd.concat([train.iloc[1600:],train.iloc[:1600,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n        \n    if ddd == 2:\n        S = pd.concat([train.iloc[1200:],train.iloc[:1200,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n        \n    if ddd == 3:\n        S = pd.concat([train.iloc[800:],train.iloc[:800,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n    \n    if ddd == 4:\n        S = pd.concat([train.iloc[400:],train.iloc[:400,:]])\n        S.iloc[:,0] = list(range(0,2400))\n        train = S.reset_index().iloc[:,1:]\n    \n    \n    \n    train , test ,sample_sub = Funcs(train,test,sample_sub)\n    \n    \n    def get_encoder():\n        seq = list('AGUC')\n        stru = list('.()')\n        loop = list('SEHIXMB')\n        encoder = dict()\n        for i, prod in enumerate(itertools.product(seq, stru, loop)):\n            concat_prod = prod[0] + prod[1] + prod[2]\n            encoder[concat_prod] = i\n        return encoder    \n\n    def get_bpp_seqs(id_seqs):\n        bpp = [np.load(f'../input/stanford-covid-vaccine/bpps/{seq}.npy') \n               for seq in id_seqs]\n        # get quantiles\n        bpp = [(1 - np.floor(bi.sum(axis=1)) * 100) for bi in bpp]\n        return np.array(bpp)\n\n    def preprocess_train(df_train, cols=['sequence', 'structure', 'predicted_loop_type'],\n                         targets=['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']):\n        # transform into list\n        vecs = np.array(df_train[cols].applymap(list).values.tolist()).transpose(0, 2, 1)\n        # concatenate all 3 positions\n        seqs = np.array([[vii[0] + vii[1] + vii[2] for vii in vi]\n                         for vi in vecs])\n        # encode\n        assert df_train.seq_length.max() == df_train.seq_length.min()\n        seq_len = df_train.seq_length.max()\n        X = np.array([[encoder[sii] for sii in si] for si in seqs]).reshape(-1, seq_len, 1)\n\n        # bpp\n        Xbpp = get_bpp_seqs(df_train.id.values)\n\n        # target\n        y = np.array(df_train[targets].values.tolist()).transpose(0, 2, 1)\n\n        return X, Xbpp, y, encoder\n\n    def preprocess_test(df_test, cols=['sequence', 'structure', 'predicted_loop_type']):\n        # transform into list\n        vecs = np.array(df_test[cols].applymap(list).values.tolist()).transpose(0, 2, 1)\n        # concatenate all 3 positions\n        seqs = np.array([[vii[0] + vii[1] + vii[2] for vii in vi]\n                         for vi in vecs])\n        # encode\n        assert df_test.seq_length.max() == df_test.seq_length.min()\n        seq_len = df_test.seq_length.max()\n        X = np.array([[encoder[sii] for sii in si] for si in seqs]).reshape(-1, seq_len, 1)\n\n        # bpp\n        Xbpp = get_bpp_seqs(df_test.id.values)\n\n        return X, Xbpp\n\n    encoder = get_encoder()\n    X_train, Xbpp_train, y_train, encoder = preprocess_train(train.loc[train.signal_to_noise >= 1])\n    X_test_pub, Xbpp_test_pub = preprocess_test(test.query(\"seq_length == 107\"))\n    X_test_pvt, Xbpp_test_pvt = preprocess_test(test.query(\"seq_length == 130\"))\n\n    def mcrmse(y_true, y_pred):\n        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n\n    def get_model(seq_len=107, pred_len=68, loss='mse', opt='adam', emb_dim_seq=32, emb_dim_bpp=32):\n        # input concat sequences\n        input_seq = tf.keras.Input(shape=(seq_len, 1))\n\n        # embedding\n        x_seq = tf.keras.layers.Embedding(input_dim=len(encoder), output_dim=emb_dim_seq, input_length=seq_len)(input_seq)\n        x_seq = tf.keras.layers.Reshape((x_seq.shape[1], x_seq.shape[2] * x_seq.shape[3]))(x_seq)\n        x_seq = tf.keras.layers.SpatialDropout1D(0.2)(x_seq)\n        # lstm\n        x_seq = tf.keras.layers.Bidirectional(\n                    tf.keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2, \n                                         return_sequences=True))(x_seq)\n        x_seq = tf.keras.layers.Bidirectional(\n                    tf.keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2, \n                                         return_sequences=True))(x_seq)\n        x_seq = tf.keras.layers.Attention()([x_seq, x_seq])\n\n\n        # bpp\n        input_bpp = tf.keras.Input(shape=(seq_len, 1))\n\n        # embedding\n        x_bpp = tf.keras.layers.Embedding(input_dim=100, output_dim=emb_dim_bpp, input_length=seq_len)(input_bpp)\n        x_bpp = tf.keras.layers.Reshape((x_bpp.shape[1], x_bpp.shape[2] * x_bpp.shape[3]))(x_bpp)\n        x_bpp = tf.keras.layers.SpatialDropout1D(0.2)(x_bpp)\n\n        # lstm\n        x_bpp = tf.keras.layers.Bidirectional(\n                    tf.keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2,\n                                         return_sequences=True))(x_bpp)\n        x_bpp = tf.keras.layers.Bidirectional(\n                    tf.keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2, \n                                         return_sequences=True))(x_bpp)\n\n        x_bpp = tf.keras.layers.Attention()([x_bpp, x_bpp])\n\n        # concat\n        x = tf.keras.layers.Concatenate(axis=-1)([x_seq, x_bpp])\n\n        # truncate\n        x = x[:, :pred_len, :]\n\n        # dense\n        x = tf.keras.layers.Dropout(0.3)(x)\n\n        x = tf.keras.layers.Dense(32)(x)\n        x = tf.keras.layers.LeakyReLU()(x)\n        x = tf.keras.layers.Dropout(0.3)(x)\n\n        x = tf.keras.layers.Dense(5, activation='linear')(x)\n\n        model = tf.keras.Model(inputs=[input_seq, input_bpp], outputs=x)\n\n        model.compile(optimizer=opt, loss=loss, metrics=[mcrmse])\n        return model\n\n    from sklearn.model_selection import KFold\n\n    n_folds = 5\n    seed = 12\n    epochs = 50\n    batch_size = 32\n    loss = mcrmse\n    emb_dim_seq = 64\n    emb_dim_bpp = 64\n\n    # placeholders\n    models = list()\n    val_metrics = list()\n    histories = list()\n    public_preds = np.zeros((test.query(\"seq_length == 107\").shape[0], 107, 5))\n    private_preds = np.zeros((test.query(\"seq_length == 130\").shape[0], 130, 5))\n\n\n    # folds\n    folds = KFold(n_folds, shuffle=True, random_state=seed).split(X_train, y_train)\n    for fold, (train_ix, test_ix) in enumerate(folds):\n        print('-'*30, f'Fold {fold+1}/{n_folds}', '-'*30, '\\n\\n')\n        tf.keras.backend.clear_session()\n\n        # splits data\n        xtrain_fold, xbpp_train_fold, y_train_fold = X_train[train_ix], Xbpp_train[train_ix], y_train[train_ix]\n        xval_fold, xbpp_val_fold, y_val_fold = X_train[test_ix], Xbpp_train[test_ix], y_train[test_ix]\n        # model\n        opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n        with tpu_strategy.scope():\n            m = get_model(emb_dim_seq=emb_dim_seq, emb_dim_bpp=emb_dim_bpp, opt=opt, loss=loss)\n            # callback\n            lr_callback = tf.keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.2, verbose=1,\n                                                               min_delta=0.007, monitor='val_loss')\n            ckpt = tf.keras.callbacks.ModelCheckpoint(f'model-{fold}.h5')\n        # fit\n        gc.collect()\n        h = m.fit((xtrain_fold, xbpp_train_fold), y_train_fold, \n                  validation_data=((xval_fold, xbpp_val_fold), y_val_fold),\n                  epochs=epochs, batch_size=batch_size,\n                  callbacks=[lr_callback, ckpt])\n        # save\n        histories.append(h)\n\n        # predict test\n        model_short = get_model(seq_len=107, pred_len=107, emb_dim_seq=emb_dim_seq, \n                                emb_dim_bpp=emb_dim_bpp, opt=opt, loss=loss)\n        model_short.load_weights(f'model-{fold}.h5')\n        model_public_pred = model_short.predict((X_test_pub, Xbpp_test_pub)) / (n_folds)\n\n        model_long = get_model(seq_len=130, pred_len=130, emb_dim_seq=emb_dim_seq, \n                               emb_dim_bpp=emb_dim_bpp, opt=opt, loss=loss)\n        model_long.load_weights(f'model-{fold}.h5')\n        model_private_pred = model_long.predict((X_test_pvt, Xbpp_test_pvt)) / (n_folds)\n\n        public_preds += model_public_pred\n        private_preds += model_private_pred\n\n    targets = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n    def format_predictions(public_preds, private_preds):\n        preds = []\n\n        for df, preds_ in [(test.query(\"seq_length == 107\"), public_preds), \n                           (test.query(\"seq_length == 130\"), private_preds)]:\n            for i, uid in enumerate(df.id):\n                single_pred = preds_[i]\n\n                single_df = pd.DataFrame(single_pred, columns=targets)\n                single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n                preds.append(single_df)\n\n        return pd.concat(preds)\n\n\n    preds = format_predictions(public_preds, private_preds)\n    submission = sample_sub[['id_seqpos']].merge(preds, on=['id_seqpos'])\n\n    submission.to_csv('Inputs4.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}