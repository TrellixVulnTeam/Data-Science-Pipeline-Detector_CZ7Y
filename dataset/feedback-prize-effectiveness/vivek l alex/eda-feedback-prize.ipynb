{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background:#926AA6   ;border-radius:5px; font-family:'Times';font-size:35px;color:  #f2f2f2\" ><center>&ensp; üìöFeedback Prize - Predicting Effective Arguments</center></div>","metadata":{}},{"cell_type":"markdown","source":"![](https://images.unsplash.com/photo-1610484826967-09c5720778c7?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=870&q=80)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#926AA6   ;border-radius:5px; font-family:'Times';font-size:35px;color:  #f2f2f2\" >&ensp; üååStory</div>","metadata":{}},{"cell_type":"markdown","source":" <div style=\"background:#343148   ;font-family: mono;font-size:15px;color:  #f2f2f2\" >\n     Writing is crucial for success. In particular, argumentative writing fosters critical thinking and civic engagement skills, and can be strengthened by practice. However, only 13 percent of eighth-grade teachers ask their students to write persuasively each week. Additionally, resource constraints disproportionately impact Black and Hispanic students, so they are more likely to write at the ‚Äúbelow basic‚Äù level as compared to their white peers. An automated feedback tool is one way to make it easier for teachers to grade writing tasks assigned to their students that will also improve their writing skills.\n <p style=\"font-family: mono;font-size:15px;color:  #f2f2f2\">'''There are numerous automated writing feedback tools currently available, but they all have limitations, especially with argumentative writing. Existing tools often fail to evaluate the quality of argumentative elements, such as organization, evidence, and idea development. Most importantly, many of these writing tools are inaccessible to educators due to their cost, which most impacts already underserved schools.\n <p style=\"font-family: mono;font-size:15px;color:  #f2f2f2\">'''Georgia State University (GSU) is an undergraduate and graduate urban public research institution in Atlanta. U.S. News & World Report ranked GSU as one of the most innovative universities in the nation. GSU awards more bachelor‚Äôs degrees to African-Americans than any other non-profit college or university in the country. GSU and The Learning Agency Lab, an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.\n<p style=\"font-family: mono;font-size:15px;color:  #f2f2f2\">  '''To best prepare all students, GSU and The Learning Agency Lab have joined forces to encourage data scientists to improve automated writing assessments. This public effort could also encourage higher quality and more accessible automated writing tools. If successful, students will receive more feedback on the argumentative elements of their writing and will apply the skill across many disciplines.\n\n  ","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#926AA6   ;font-family:'Times';font-size:35px;color:  #f2f2f2\" >&ensp;üíæ Data</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>Importing Libraries</b></div>","metadata":{}},{"cell_type":"code","source":"import os\nimport logging\nfrom types import SimpleNamespace\nfrom pathlib import Path\nfrom datetime import datetime\nimport math\nimport random\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import log_loss\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\nfrom transformers import TrainingArguments, Trainer\nfrom tqdm import tqdm\nfrom scipy.special import softmax\nfrom IPython.core.display import display, HTML\nfrom IPython.display import display, HTML\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset, load_metric\n\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:46.173351Z","iopub.execute_input":"2022-06-16T20:22:46.174385Z","iopub.status.idle":"2022-06-16T20:22:46.187197Z","shell.execute_reply.started":"2022-06-16T20:22:46.174341Z","shell.execute_reply":"2022-06-16T20:22:46.185936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>Data Overview</b></div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#343148   ;font-family: mono;font-size:15px;color:  #f2f2f2\" >&ensp;\n    The dataset presented here contains argumentative essays written by U.S students in grades 6-12. These essays were annotated by expert raters for discourse elements commonly found in argumentative writing:\n<ul>\n<li><b>Lead - </b>an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader‚Äôs attention and point toward the thesis\n<li><b>Position</b> - an opinion or conclusion on the main question\n<li><b>Claim</b> - a claim that supports the position\n<li><b>Counterclaim</b> - a claim that refutes another claim or gives an opposing reason to the position\n<li><b>Rebuttal</b> - a claim that refutes a counterclaim\n<li><b>Evidence</b> - ideas or examples that support claims, counterclaims, or rebuttals.\n<li><b>Concluding Statement</b>- a concluding statement that restates the claims\n</ul>\n    Your task is to predict the quality rating of each discourse element. Human readers rated each rhetorical or argumentative element, in order of increasing quality, as one of:\n    \n<ul>\n<li><b>Ineffective</b>\n<li><b>Adequate</b>\n<li><b>Effective</b>\n</ul>    \n</div>","metadata":{}},{"cell_type":"markdown","source":"<body>\n\n<table style=\"width:100%\">\n  <tr>\n    <th style=\"color:black; font-size: 20px\", bgcolor='#926AA6'>Feature</th>\n    <th style=\"color:black; font-size: 20px\", bgcolor='#926AA6'>Description</th> \n    \n  </tr>\n  <tr>\n      <td style=\" font-size: 17px\"><b>discourse_id</b></td>\n      <td style=\"font-size: 17px\">ID code for discourse element</td>\n    </tr>\n      <tr>\n      <td style=\" font-size: 17px\"><b>essay_id </b></td>\n      <td style=\"font-size: 17px\">ID code for essay response. This ID code corresponds to the name of the full-text file in the train/ folder.</td>\n    </tr>\n          <tr>\n      <td style=\" font-size: 17px\"><b>discourse_text  </b></td>\n      <td style=\"font-size: 17px\">Text of discourse element.</td>\n    </tr>\n       <tr>\n      <td style=\" font-size: 17px\"><b>discourse_type  </b></td>\n      <td style=\"font-size: 17px\">Class label of discourse element. </td>\n    </tr>\n  <tr>\n      <td style=\" font-size: 17px\"><b>discourse_type_num </b></td>\n      <td style=\"font-size: 17px\">Enumerated class label of discourse element.</td>\n    </tr>\n  <tr>\n      <td style=\" font-size: 17px\"><b>discourse_effectiveness - </b></td>\n      <td style=\"font-size: 17px\">Quality rating of discourse element, the target.</td>\n    </tr>\n\n    \n    \n</table>\n\n</body>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>Reading Data</b></div>\n","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:46.702723Z","iopub.execute_input":"2022-06-16T20:22:46.703109Z","iopub.status.idle":"2022-06-16T20:22:46.961308Z","shell.execute_reply.started":"2022-06-16T20:22:46.703078Z","shell.execute_reply":"2022-06-16T20:22:46.960427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def overview(df):\n    num_rows=len(df.index)\n    num_col=len(df.columns)\n    fig, ax = plt.subplots()\n      \n    #create values for table\n    lab = ['Number Of Rows', 'Number Of Columns']\n    table_data=[\n    [num_rows,num_col]\n        ]\n    ax.set_title('Number of Samples', \n             fontweight =\"bold\") \n    #create table\n    table = ax.table(cellText=table_data, colLabels=lab,colColours =[\"#926AA6\"] * 10, loc='center')\n\n    #modify table\n    table.set_fontsize(14)\n    table.scale(2,4)\n    ax.axis('off')\n    #display table\n    plt.show()\n    \noverview(train_df) ","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:47.202686Z","iopub.execute_input":"2022-06-16T20:22:47.203727Z","iopub.status.idle":"2022-06-16T20:22:47.306336Z","shell.execute_reply.started":"2022-06-16T20:22:47.203674Z","shell.execute_reply":"2022-06-16T20:22:47.305175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>First and Last Five rows</b></div>\n","metadata":{}},{"cell_type":"code","source":"first_five=train_df.head(5)\nlast_five =train_df.tail(5)\nprint(\"First Five Rows\")\ndisplay(first_five)\nprint(\"=\"*100)\nprint(\"=\"*100)\nprint(\"=\"*100)\nprint(\"Last Five Rows\")\ndisplay(last_five)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:47.884941Z","iopub.execute_input":"2022-06-16T20:22:47.885615Z","iopub.status.idle":"2022-06-16T20:22:47.914432Z","shell.execute_reply.started":"2022-06-16T20:22:47.88558Z","shell.execute_reply":"2022-06-16T20:22:47.913449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"first_five","metadata":{}},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>General informations</b></div>\n","metadata":{}},{"cell_type":"code","source":"\ndef info(df):\n    missing= train_df.isnull().sum()\n    percent_missing = (train_df.isnull().sum() * 100 / len(train_df)).round(2)\n    dtypes=train_df.dtypes\n    data=df\n    data=pd.DataFrame([np.array(list(train_df.columns)).T,np.array(list(missing)).T,np.array(list(percent_missing)).T,np.array(list(dtypes)).T])\n    data = data.transpose()\n    data.columns=['Features','Num of Missing values','percentage Missing','DataType']\n   \n    fig, ax = plt.subplots()\n      \n    #create values for tabl\n\n    #create table\n    ax.set_title(\"General Informations\", fontsize=40, y=1.5)\n    table = ax.table(cellText=data.values, colLabels=data.columns,colColours =[\"#926AA6\"] * len(data.columns), loc='center')\n\n    #modify table\n    table.set_fontsize(14)\n    table.scale(5,5)\n    ax.axis('off')\n    #display table\n  \n    plt.show()\ninfo(train_df)    ","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:48.638908Z","iopub.execute_input":"2022-06-16T20:22:48.639996Z","iopub.status.idle":"2022-06-16T20:22:49.050328Z","shell.execute_reply.started":"2022-06-16T20:22:48.639956Z","shell.execute_reply":"2022-06-16T20:22:49.049575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>Target Distributions</b></div>\n","metadata":{}},{"cell_type":"code","source":"def pie_target(df,col,title):\n            colors = [\"#570990\",\"#e4b6fe\",'#8b22ba', \"#8a3cf6\"]    \n            fig, ax = plt.subplots(1,2,figsize=(16, 8))\n            fig.suptitle(title, size = 20)\n            labels = list(df[col].value_counts().index)\n            values = df[col].value_counts()\n            ax[0].pie( values,colors=colors[:2],explode=(.05,0,0),startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.6)\n           \n            sns.countplot(x=col, data=df, hue=col,palette=colors[:2], ax=ax[1])\n\n            ax[0].add_artist(plt.Circle((0,0),0.4,fc='white'))\n            plt.show()\n            \npie_target(train_df,'discourse_effectiveness','Label Distrubtion')            ","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:49.347661Z","iopub.execute_input":"2022-06-16T20:22:49.348766Z","iopub.status.idle":"2022-06-16T20:22:49.794892Z","shell.execute_reply.started":"2022-06-16T20:22:49.348701Z","shell.execute_reply":"2022-06-16T20:22:49.793532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>Discourse Types</b></div>\n","metadata":{}},{"cell_type":"code","source":"\ndef pie_target(feat,df):\n            fig, ax = plt.subplots(figsize=(12,8))\n\n        \n            colors = [\"#570990\",\"#e4b6fe\",'#8b22ba', \"#8a3cf6\"]\n\n            plt.title ('Discourse Types',fontdict={'fontsize':20})\n        \n            labels = list(df[feat[0]].value_counts().index)\n           \n            values = df[feat[0]].value_counts()\n            \n          #  ax[1].pie( values,colors=colors,startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.6)\n         #   ax[1].title.set_text(f'Count Plot for ')\n            sns.countplot(x=feat[0],data=df,palette=colors )\n        #    ax[1].add_artist(plt.Circle((0,0),0.4,fc='white'))\n            fig.tight_layout()        \n            plt.show()\ncat_features=['discourse_type']\n\npie_target(cat_features,train_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:49.818204Z","iopub.execute_input":"2022-06-16T20:22:49.818844Z","iopub.status.idle":"2022-06-16T20:22:50.12573Z","shell.execute_reply.started":"2022-06-16T20:22:49.818776Z","shell.execute_reply":"2022-06-16T20:22:50.124465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef pie_target(feat,df):\n            fig, ax = plt.subplots(figsize=(8,8))\n\n        \n            colors = [\"#570990\",\"#e4b6fe\",'#8b22ba', \"#8a3cf6\"]\n            plt.title ('Discourse Type',fontdict={'fontsize':20})\n        \n            labels = list(df[feat[0]].value_counts().index)\n           \n            values = df[feat[0]].value_counts()\n            \n            ax.pie( values,colors=colors,startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.6)\n            ax.title.set_text(f'Count Plot Discourse Type ')\n           \n            ax.add_artist(plt.Circle((0,0),0.4,fc='white'))\n            fig.tight_layout()        \n            plt.show()\ncat_features=['discourse_type']\n\npie_target(cat_features,train_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:50.290631Z","iopub.execute_input":"2022-06-16T20:22:50.29104Z","iopub.status.idle":"2022-06-16T20:22:50.544237Z","shell.execute_reply.started":"2022-06-16T20:22:50.291007Z","shell.execute_reply":"2022-06-16T20:22:50.542692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>Discourse Type vs Discourse Effectiveness</b></div>\n","metadata":{}},{"cell_type":"code","source":"\ncat_features=['discourse_type']\nplt.figure(figsize = (18,18))\ndef rel_tar(df,feat_list,target):\n    \n        for i in enumerate(feat_list):\n             \n                colors = [ \"#570990\",\"#e4b6fe\",'#8b22ba', \"#8a3cf6\", '#967032', '#2734DE'] \n                rand_col = colors[random.sample(range(6),1)[0]]\n                plt.subplot(2,2,i[0]+1)\n                sns.countplot(x=i[1], data=df, hue=target,palette='BuPu')\n                plt.title (i[1]+f' vs {target}',fontdict={'fontsize':20})\n                plt.xlabel(\" \")\n                plt.ylabel(\" \")\n                plt.xticks(rotation = 45)\n                plt.tight_layout()\n                \n                \nrel_tar(train_df,cat_features,'discourse_effectiveness')         \n","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:50.548421Z","iopub.execute_input":"2022-06-16T20:22:50.549178Z","iopub.status.idle":"2022-06-16T20:22:50.918106Z","shell.execute_reply.started":"2022-06-16T20:22:50.54914Z","shell.execute_reply":"2022-06-16T20:22:50.917052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>Discourse Text</b></div>\n","metadata":{}},{"cell_type":"code","source":"train_df['wrd_cnt'] = train_df['discourse_text'].apply(lambda x : len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:50.927126Z","iopub.execute_input":"2022-06-16T20:22:50.927575Z","iopub.status.idle":"2022-06-16T20:22:51.074387Z","shell.execute_reply.started":"2022-06-16T20:22:50.927538Z","shell.execute_reply":"2022-06-16T20:22:51.073722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hist(col,title):\n    \n    plt.figure(figsize = (10,8))\n    \n    ax = sns.histplot(col,kde=False);\n    \n    values = np.array([patch.get_height() for patch in ax.patches])\n    \n    #normalizing the values to get a range of colours\n    norm = plt.Normalize(values.min(), values.max())\n    \n    #range of colours from colourmap-rainbow\n    colors = plt.cm.RdPu(norm(values))\n    ax.grid(False)\n    #set colour for each patch\n    for patch, color in zip(ax.patches, colors):\n        patch.set_color(color)\n\n    plt.title(title, size = 20)\n    \nhist(train_df['wrd_cnt'],'Distribution of word count in discourse text')","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:51.421425Z","iopub.execute_input":"2022-06-16T20:22:51.421845Z","iopub.status.idle":"2022-06-16T20:22:52.70905Z","shell.execute_reply.started":"2022-06-16T20:22:51.421811Z","shell.execute_reply":"2022-06-16T20:22:52.707939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def  dist_plot(feat,df):\n            fig, ax = plt.subplots(1,3,figsize=(22,8))\n   \n        \n            colors = [\"#570990\",\"#e4b6fe\",'#8b22ba', \"#8a3cf6\"]\n            fig.suptitle('Word Density Based on Effectiveness', size = 29)\n            ax[0].title.set_text(f'Count Plot')\n            sns.histplot(df[df['discourse_effectiveness']==\"Adequate\"][feat[0]], ax=ax[0])\n             #normalizing the values to get a range of colours\n            valuesp = np.array([patch.get_height() for patch in ax[0].patches])    \n            norm = plt.Normalize(valuesp.min(), valuesp.max())\n            #range of colours from colourmap-rainbow\n            colors = plt.cm.RdPu(norm(valuesp))\n            ax[0].grid(False)\n            #set colour for each patch\n            for patch, color in zip(ax[0].patches, colors):\n                patch.set_color(color)\n\n\n            ax[1].title.set_text(f'Ineffective')\n            sns.histplot(df[df['discourse_effectiveness']==\"Ineffective\"][feat[0]], ax=ax[1])\n            valuesp = np.array([patch.get_height() for patch in ax[1].patches])    \n            norm = plt.Normalize(valuesp.min(), valuesp.max())\n            #range of colours from colourmap-rainbow\n            colors = plt.cm.RdPu(norm(valuesp))\n            ax[1].grid(False)\n            #set colour for each patch\n            for patch, color in zip(ax[1].patches, colors):\n                patch.set_color(color)\n\n      \n            ax[2].title.set_text(f'Effective')\n            sns.histplot(df[df['discourse_effectiveness']==\"Effective\"][feat[0]], ax=ax[2])\n            valuesp = np.array([patch.get_height() for patch in ax[2].patches])    \n            norm = plt.Normalize(valuesp.min(), valuesp.max())\n            #range of colours from colourmap-rainbow\n            colors = plt.cm.RdPu(norm(valuesp))\n            ax[2].grid(False)\n            #set colour for each patch\n            for patch, color in zip(ax[2].patches, colors):\n                patch.set_color(color)\n\n            \n            \n            fig.tight_layout()        \n            plt.show()\nfloat_features=['wrd_cnt']\n\ndist_plot(float_features,train_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:52.710821Z","iopub.execute_input":"2022-06-16T20:22:52.711689Z","iopub.status.idle":"2022-06-16T20:22:54.219955Z","shell.execute_reply.started":"2022-06-16T20:22:52.711654Z","shell.execute_reply":"2022-06-16T20:22:54.218571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def colors(i):\n    valuesp = np.array([patch.get_height() for patch in ax[i].patches])    \n    norm = plt.Normalize(valuesp.min(), valuesp.max())\n    #range of colours from colourmap-rainbow\n    colors = plt.cm.RdPu(norm(valuesp))\n    ax[i].grid(False)\n    #set colour for each patch\n    for patch, color in zip(ax[i].patches, colors):\n        patch.set_color(color)\n\ndiscourse_types = train_df.discourse_type.unique()\n\nfig, ax = plt.subplots(1, len(discourse_types), sharex='col', sharey='row', figsize=(25, 5))\nfor i, discourse_type in enumerate(discourse_types):\n   \n    filtered_df = train_df[train_df.discourse_type == discourse_type]\n    sns.histplot(data=filtered_df[\"wrd_cnt\"], ax=ax[i])\n    colors(i)\n    ax[i].set_title(discourse_type)\nfig.suptitle('Word Density Based On Discourse Type', size = 22)    \nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:54.221319Z","iopub.execute_input":"2022-06-16T20:22:54.221646Z","iopub.status.idle":"2022-06-16T20:22:56.09202Z","shell.execute_reply.started":"2022-06-16T20:22:54.221616Z","shell.execute_reply":"2022-06-16T20:22:56.090937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, len(discourse_types), sharex='col', sharey='row', figsize=(25, 5))\nfor i, discourse_type in enumerate(discourse_types):\n   \n    filtered_df = train_df[train_df.discourse_type == discourse_type].query('discourse_effectiveness==\"Effective\"')\n    sns.histplot(data=filtered_df[\"wrd_cnt\"], ax=ax[i])\n    colors(i)\n    ax[i].set_title(discourse_type)\nfig.suptitle('Word Density of Effective essays', size = 22)    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:56.093977Z","iopub.execute_input":"2022-06-16T20:22:56.094558Z","iopub.status.idle":"2022-06-16T20:22:57.420655Z","shell.execute_reply.started":"2022-06-16T20:22:56.094519Z","shell.execute_reply":"2022-06-16T20:22:57.419605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, len(discourse_types), sharex='col', sharey='row', figsize=(25, 5))\nfor i, discourse_type in enumerate(discourse_types):\n   \n    filtered_df = train_df[train_df.discourse_type == discourse_type].query('discourse_effectiveness==\"Ineffective\"')\n    sns.histplot(data=filtered_df[\"wrd_cnt\"], ax=ax[i])\n    colors(i)\n    ax[i].set_title(discourse_type)\nfig.suptitle('Word Density of Ineffective essays', size = 22)    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:57.421789Z","iopub.execute_input":"2022-06-16T20:22:57.422075Z","iopub.status.idle":"2022-06-16T20:22:59.212348Z","shell.execute_reply.started":"2022-06-16T20:22:57.422047Z","shell.execute_reply":"2022-06-16T20:22:59.211123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, len(discourse_types), sharex='col', sharey='row', figsize=(25, 5))\nfor i, discourse_type in enumerate(discourse_types):\n   \n    filtered_df = train_df[train_df.discourse_type == discourse_type].query('discourse_effectiveness==\"Adequate\"')\n    sns.histplot(data=filtered_df[\"wrd_cnt\"], ax=ax[i])\n    colors(i)\n    ax[i].set_title(discourse_type)\nfig.suptitle('Word Density of Adequate essays', size = 22)    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:22:59.213626Z","iopub.execute_input":"2022-06-16T20:22:59.214007Z","iopub.status.idle":"2022-06-16T20:23:00.833435Z","shell.execute_reply.started":"2022-06-16T20:22:59.213977Z","shell.execute_reply":"2022-06-16T20:23:00.83243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b >Discourse Text Examples</b></div>\n","metadata":{}},{"cell_type":"code","source":"from IPython.core.display import display, HTML\n\ndef show_examples_for_discourse_type(discourse_type, topic):\n    filt = train_df.query(f'discourse_type == \"{discourse_type}\"').sample(frac=1, random_state=420)\n    display(HTML(\n        f\"\"\"\n        <h4 style=\"background:#cc0088 ;color: black; font-size: 20px; width:10%\" >{discourse_type }</h4>\n        <table>\n            <tr>\n              <th style=\"color:black; font-size: 15px\", bgcolor='#8b22ba' width=33%>Ineffective</th>\n              <th style=\"color:black; font-size: 15px\", bgcolor='#8b22ba' width=33%>Adequate</th>\n              <th style=\"color:black; font-size: 15px\", bgcolor='#8b22ba' width=33%>Effective</th>\n            </tr>\n            <tr>\n              <td>{filt.query(\"discourse_effectiveness == 'Ineffective'\").iloc[0].discourse_text}</td>\n              <td>{filt.query(\"discourse_effectiveness == 'Adequate'\").iloc[0].discourse_text}</td>\n              <td>{filt.query(\"discourse_effectiveness == 'Effective'\").iloc[0].discourse_text}</td>\n            </tr>\n        </table>\n        \"\"\"\n    ))","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:23:31.8823Z","iopub.execute_input":"2022-06-16T20:23:31.882725Z","iopub.status.idle":"2022-06-16T20:23:31.890255Z","shell.execute_reply.started":"2022-06-16T20:23:31.882679Z","shell.execute_reply":"2022-06-16T20:23:31.889317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"for dt in set(train_df.discourse_type.values):\n    show_examples_for_discourse_type(dt, 10)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:23:33.734549Z","iopub.execute_input":"2022-06-16T20:23:33.735035Z","iopub.status.idle":"2022-06-16T20:23:33.882431Z","shell.execute_reply.started":"2022-06-16T20:23:33.734999Z","shell.execute_reply":"2022-06-16T20:23:33.881576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\";font-family:'Times';font-size:30px;color:  #FA7A35\" >üìå <b>Word Cloud On Discourse Text</b></div>\n","metadata":{}},{"cell_type":"code","source":"from wordcloud  import WordCloud\nfig, ax = plt.subplots(7,3, sharex='col', sharey='row', figsize=(30, 30))\nfor i, discourse_type in enumerate(discourse_types):\n    for j,effect in enumerate(set(train_df.discourse_effectiveness.values)):\n            #sns.histplot(data=train_df[\"wrd_cnt\"], ax=ax[i,j])\n            wc=WordCloud(background_color='white').generate(str(train_df.query(f'discourse_type == \"{discourse_type}\" and discourse_effectiveness==\"{effect}\"')['discourse_text']))\n             \n            ax[i,j].imshow(wc)\n            ax[i,j].axis('off');\n            ax[i,j].set_title(f'{effect } {discourse_type}', fontsize=30);\n            \nfig.suptitle('Word Cloud on Discourse Type and Effectiveness', size = 40)    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T20:27:03.504351Z","iopub.execute_input":"2022-06-16T20:27:03.504867Z","iopub.status.idle":"2022-06-16T20:27:09.295039Z","shell.execute_reply.started":"2022-06-16T20:27:03.504829Z","shell.execute_reply":"2022-06-16T20:27:09.292849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background:#926AA6   ;font-family:'Times';font-size:35px;color:  white\" ><center>&ensp;Thank you</center></div>\n<div style=\"background:#926AA6   ;font-family:'Times';font-size:35px;color:  white\" ><center>&ensp;‚ö† WORK IN PROGRESS ‚ö†\n<br>Please consider upvoting the kernel if you found it useful.</center></div>\n","metadata":{}}]}