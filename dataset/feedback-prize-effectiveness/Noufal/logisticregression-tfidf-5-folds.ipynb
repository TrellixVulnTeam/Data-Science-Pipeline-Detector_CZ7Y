{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-07T19:00:53.892924Z","iopub.execute_input":"2022-06-07T19:00:53.893374Z","iopub.status.idle":"2022-06-07T19:00:53.898753Z","shell.execute_reply.started":"2022-06-07T19:00:53.893339Z","shell.execute_reply":"2022-06-07T19:00:53.897649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\ndftr = pd.read_csv(\"../input/feedback-prize-effectiveness/train.csv\")\nprint(dftr.shape,dftr.discourse_id.nunique())\ndfte = pd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")\nprint(dfte.shape,dfte.discourse_id.nunique())\ndfs = pd.read_csv(\"../input/feedback-prize-effectiveness/sample_submission.csv\")\n\ndftr[\"text\"] = dftr[\"essay_id\"].apply(lambda x: open(f'../input/feedback-prize-effectiveness/train/{x}.txt').read())\ndfte[\"text\"] = dfte[\"essay_id\"].apply(lambda x: open(f'../input/feedback-prize-effectiveness/test/{x}.txt').read())\nFOLDS = 5\nfrom sklearn.model_selection import StratifiedKFold\ntarget_map = {\"Adequate\":1,\"Effective\":2,\"Ineffective\":0}\ndftr[\"target\"] = dftr[\"discourse_effectiveness\"].map(target_map)\ndftr = dftr.reset_index(drop=True)\n# print(dftr[\"target\"].value_counts())\nskf = StratifiedKFold(n_splits=FOLDS,shuffle=True,random_state=FOLDS)\nfor i,(train_index, test_index) in enumerate(skf.split(dftr, dftr[\"target\"])):\n    dftr.loc[test_index,\"fold\"] = i\nprint(dftr.fold.value_counts())    \n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:00:57.199247Z","iopub.execute_input":"2022-06-07T19:00:57.200162Z","iopub.status.idle":"2022-06-07T19:01:13.23849Z","shell.execute_reply.started":"2022-06-07T19:00:57.200116Z","shell.execute_reply":"2022-06-07T19:01:13.237754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom scipy import sparse\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\nimport numpy as np\npreds = []\nfor fold in range(FOLDS):\n    dftr_ = dftr[dftr[\"fold\"]!=fold]\n    dfev_ = dftr[dftr[\"fold\"]==fold]\n    tf = TfidfVectorizer(ngram_range=(1,2))\n    tr_text_feats = tf.fit_transform(dftr_[\"discourse_text\"])\n    ev_text_feats = tf.transform(dfev_[\"discourse_text\"])\n    te_text_feats = tf.transform(dfte[\"discourse_text\"])\n    tf = TfidfVectorizer(ngram_range=(1,2))\n    tr_text_feats2 = tf.fit_transform(dftr_[\"text\"])\n    ev_text_feats2 = tf.transform(dfev_[\"text\"])\n    te_text_feats2 = tf.transform(dfte[\"text\"])\n    ohe = OneHotEncoder()\n    tr_feats1 = sparse.csr_matrix(ohe.fit_transform(dftr_[\"discourse_type\"].values.reshape(-1,1)))\n    ev_feats1 = sparse.csr_matrix(ohe.transform(dfev_[\"discourse_type\"].values.reshape(-1,1)))\n    te_feats1 = sparse.csr_matrix(ohe.transform(dfte[\"discourse_type\"].values.reshape(-1,1)))\n    tr_feats = sparse.hstack((tr_feats1,tr_text_feats,tr_text_feats2))\n    ev_feats = sparse.hstack((ev_feats1,ev_text_feats,ev_text_feats2))\n    te_feats = sparse.hstack((te_feats1,te_text_feats,te_text_feats2))\n    clf = LogisticRegression(max_iter=500,penalty=\"l2\",C=1.0131816333513533)\n    clf.fit(tr_feats, dftr_[\"target\"].values)\n    ev_preds = clf.predict_proba(ev_feats)\n    ev_loss = log_loss(dfev_[\"target\"].values,ev_preds)\n    print(\"Fold : {} EV score: {}\".format(fold,ev_loss))\n    preds.append(clf.predict_proba(te_feats))\n    # break","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:59:30.605659Z","iopub.status.idle":"2022-06-07T18:59:30.606233Z","shell.execute_reply.started":"2022-06-07T18:59:30.605947Z","shell.execute_reply":"2022-06-07T18:59:30.605973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = np.array(preds).mean(0)\nprint(all_preds.shape)\ndfs.loc[:,\"Ineffective\"] = all_preds[:,0]\ndfs.loc[:,\"Adequate\"] = all_preds[:,1]\ndfs.loc[:,\"Effective\"] = all_preds[:,2]\ndfs.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:59:30.607568Z","iopub.status.idle":"2022-06-07T18:59:30.60809Z","shell.execute_reply.started":"2022-06-07T18:59:30.607837Z","shell.execute_reply":"2022-06-07T18:59:30.607862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs.to_csv('submission.csv',index=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:59:30.609311Z","iopub.status.idle":"2022-06-07T18:59:30.609823Z","shell.execute_reply.started":"2022-06-07T18:59:30.609563Z","shell.execute_reply":"2022-06-07T18:59:30.609588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}