{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This dataset in this competition is a subset of the dataset from the [Feedback Prize - Evaluating Student Writing](https://www.kaggle.com/competitions/feedback-prize-2021) (2021) competition. It seems likely that the entire dataset's use will be part of the top solutions in this competition.\n\nAs a first pass at using the 2021 dataset, I take the 5-fold DeBerta v3 model trained on my original [Training notebook](https://www.kaggle.com/code/lextoumbourou/feedback-prize-eda-and-model-training) and make predictions on the entire 2021 dataset. I average the softmax probability of the 2021 data from each fold.\n\nI have included a field that represents whether the row is in the 2022 set, so you can plan validation folds accordingly.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm\nfrom pathlib import Path\nfrom types import SimpleNamespace\nimport logging\n\nfrom datasets import Dataset\n\nimport transformers\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, DataCollatorWithPadding\nfrom transformers import TrainingArguments, Trainer\nfrom scipy.special import softmax\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import log_loss\n\n# To work around the aggressive HuggingFace log spam.\nlogging.disable(logging.WARNING)\n\n# From this Gist: https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\ndef seed_everything(seed: int):\n    import random, os\n    import numpy as np\n    import torch\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:25.000611Z","iopub.execute_input":"2022-06-25T00:17:25.0012Z","iopub.status.idle":"2022-06-25T00:17:33.735622Z","shell.execute_reply.started":"2022-06-25T00:17:25.001089Z","shell.execute_reply":"2022-06-25T00:17:33.734833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compare Datasets","metadata":{}},{"cell_type":"markdown","source":"Let's do a quick comparison of datasets.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain_2021_df = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntotal_size_2021 = len(train_2021_df)\nnum_essays_2021 = train_2021_df.id.nunique()\ntrain_df = pd.read_csv(f'../input/feedback-prize-eda-and-model-training/train_folds.csv')\ntotal_size_2022 = len(train_df)\nnum_essays_2022 = train_df.essay_id.nunique()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T00:17:49.705163Z","iopub.execute_input":"2022-06-25T00:17:49.705492Z","iopub.status.idle":"2022-06-25T00:17:51.490942Z","shell.execute_reply.started":"2022-06-25T00:17:49.705458Z","shell.execute_reply":"2022-06-25T00:17:51.490063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Firstly, let's compare total number of rows and number of unique essays across datasets.","metadata":{}},{"cell_type":"code","source":"comp_df = pd.DataFrame(\n    [('2021', total_size_2021, num_essays_2021),\n    ('2022', total_size_2022, num_essays_2022)],\n    columns=['dataset', 'total', 'unique essays']\n).set_index('dataset')\ncomp_df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T00:17:51.494716Z","iopub.execute_input":"2022-06-25T00:17:51.495173Z","iopub.status.idle":"2022-06-25T00:17:51.519928Z","shell.execute_reply.started":"2022-06-25T00:17:51.495137Z","shell.execute_reply":"2022-06-25T00:17:51.519048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(18, 5))\nfor i, field in enumerate(['total', 'unique essays']):\n    comp_df[field].plot.bar(title=field, ax=axes[i])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T00:17:51.521274Z","iopub.execute_input":"2022-06-25T00:17:51.521625Z","iopub.status.idle":"2022-06-25T00:17:51.841706Z","shell.execute_reply.started":"2022-06-25T00:17:51.521586Z","shell.execute_reply":"2022-06-25T00:17:51.840695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So with **11,403** additional essays and **107,527** total extra rows, last year's competition data seems useful.","metadata":{}},{"cell_type":"markdown","source":"Let's also compare `discourse_type` distribution.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(18, 5))\nfor i, (year, df) in enumerate([(2021, train_2021_df), (2022, train_df)]):\n    df.discourse_type.value_counts(normalize=True).plot.bar(ax=axes[i], title=f'{year}')\nfig.suptitle('Discourse Type Distribution Comparison', y=1.08)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T00:17:51.843804Z","iopub.execute_input":"2022-06-25T00:17:51.8441Z","iopub.status.idle":"2022-06-25T00:17:52.193157Z","shell.execute_reply.started":"2022-06-25T00:17:51.844065Z","shell.execute_reply":"2022-06-25T00:17:52.192289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems very similar indeed!","metadata":{}},{"cell_type":"markdown","source":"Let's check to see if all the ids in the 2022 competition set exist in the original.","metadata":{}},{"cell_type":"code","source":"ids_2022 = set(train_df.essay_id.unique())\nids_2021 = set(train_2021_df.id.unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:52.400542Z","iopub.execute_input":"2022-06-25T00:17:52.400777Z","iopub.status.idle":"2022-06-25T00:17:52.424991Z","shell.execute_reply.started":"2022-06-25T00:17:52.40075Z","shell.execute_reply":"2022-06-25T00:17:52.424274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids_2022 - ids_2021","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:52.558335Z","iopub.execute_input":"2022-06-25T00:17:52.560136Z","iopub.status.idle":"2022-06-25T00:17:52.567965Z","shell.execute_reply.started":"2022-06-25T00:17:52.560107Z","shell.execute_reply":"2022-06-25T00:17:52.56709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**All essays in 2022 are also in 2021.**","metadata":{}},{"cell_type":"code","source":"len(ids_2021 - ids_2022)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:52.995889Z","iopub.execute_input":"2022-06-25T00:17:52.996338Z","iopub.status.idle":"2022-06-25T00:17:53.004908Z","shell.execute_reply.started":"2022-06-25T00:17:52.996286Z","shell.execute_reply":"2022-06-25T00:17:53.004225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"11,403 essays exist in 2021 that aren't in 2022.","metadata":{}},{"cell_type":"markdown","source":"Let's see an example to ensure they're otherwise identical.","metadata":{}},{"cell_type":"code","source":"from IPython.core.display import display, HTML\ndisplay(HTML(\n    f\"\"\"\n    <table>\n        <tr>\n          <td>Essay id <b>007ACE74B050</b> in <b>2021</b> dataset</th>\n          <td>Essay id <b>007ACE74B050</b> in <b>2022</b> dataset</th>\n        </tr>\n        <tr>\n          <td>{'<br><br>'.join(list(train_2021_df[train_2021_df.id == '007ACE74B050'].discourse_text.values))}</td>\n          <td>{'<br><br>'.join(list(train_df[train_df.essay_id == '007ACE74B050'].discourse_text.values))}</td>\n        </tr>\n    </table>\n    \n    \"\"\"\n))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T00:17:53.586696Z","iopub.execute_input":"2022-06-25T00:17:53.587404Z","iopub.status.idle":"2022-06-25T00:17:53.625732Z","shell.execute_reply.started":"2022-06-25T00:17:53.58737Z","shell.execute_reply":"2022-06-25T00:17:53.624841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks good to me!","metadata":{}},{"cell_type":"markdown","source":"I will create a new column in the 2021 set for any essay in the 2022 set to ignore during training.","metadata":{}},{"cell_type":"code","source":"train_2021_df['in_2022'] = train_2021_df.id.apply(lambda x: x in ids_2022)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:54.378554Z","iopub.execute_input":"2022-06-25T00:17:54.379122Z","iopub.status.idle":"2022-06-25T00:17:54.422734Z","shell.execute_reply.started":"2022-06-25T00:17:54.379071Z","shell.execute_reply":"2022-06-25T00:17:54.422111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2021_df.in_2022.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:54.537153Z","iopub.execute_input":"2022-06-25T00:17:54.537447Z","iopub.status.idle":"2022-06-25T00:17:54.547443Z","shell.execute_reply.started":"2022-06-25T00:17:54.537421Z","shell.execute_reply":"2022-06-25T00:17:54.545464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(f'../input/feedback-prize-effectiveness/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:54.697556Z","iopub.execute_input":"2022-06-25T00:17:54.697795Z","iopub.status.idle":"2022-06-25T00:17:54.707199Z","shell.execute_reply.started":"2022-06-25T00:17:54.697769Z","shell.execute_reply":"2022-06-25T00:17:54.706348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{"execution":{"iopub.status.busy":"2022-05-31T08:29:46.292807Z","iopub.execute_input":"2022-05-31T08:29:46.293409Z","iopub.status.idle":"2022-05-31T08:29:54.823905Z","shell.execute_reply.started":"2022-05-31T08:29:46.293354Z","shell.execute_reply":"2022-05-31T08:29:54.823071Z"}}},{"cell_type":"code","source":"config = SimpleNamespace()\n\nconfig.n_folds = 5\nconfig.seed = 420\nconfig.lr = 1e-5\nconfig.weight_decay = 0.01\nconfig.epochs = 3\nconfig.batch_size = 16\nconfig.warm_up_ratio = 0.1\nconfig.max_len = 256\nconfig.hidden_dropout_prob = 0.2\nconfig.label_smoothing_factor = 0\nconfig.output_path = Path('./')\nconfig.model_path = Path('../input/feedback-prize-eda-and-model-training')\nconfig.input_path = Path('../input/feedback-prize-effectiveness')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:54.997498Z","iopub.execute_input":"2022-06-25T00:17:54.998191Z","iopub.status.idle":"2022-06-25T00:17:55.005718Z","shell.execute_reply.started":"2022-06-25T00:17:54.998156Z","shell.execute_reply":"2022-06-25T00:17:55.004844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformers.logging.set_verbosity_error()\n\nseed_everything(config.seed)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:55.666652Z","iopub.execute_input":"2022-06-25T00:17:55.667161Z","iopub.status.idle":"2022-06-25T00:17:55.673808Z","shell.execute_reply.started":"2022-06-25T00:17:55.667121Z","shell.execute_reply":"2022-06-25T00:17:55.67305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Topics","metadata":{}},{"cell_type":"code","source":"train_2021_df = train_2021_df.rename(columns={'id': 'essay_id'})","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:56.891612Z","iopub.execute_input":"2022-06-25T00:17:56.891889Z","iopub.status.idle":"2022-06-25T00:17:56.915625Z","shell.execute_reply.started":"2022-06-25T00:17:56.891853Z","shell.execute_reply":"2022-06-25T00:17:56.91486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_pred_df = pd.read_csv('../input/feedback-topics-identification-with-bertopic/topic_model_feedback.csv')\ntopic_pred_df = topic_pred_df.drop(columns={'prob'})\ntopic_pred_df = topic_pred_df.rename(columns={'id': 'essay_id'})\n\ntopic_meta_df = pd.read_csv('../input/feedback-topics-identification-with-bertopic/topic_model_metadata.csv')\ntopic_meta_df = topic_meta_df.rename(columns={'Topic': 'topic', 'Name': 'topic_name'}).drop(columns=['Count'])\ntopic_meta_df.topic_name = topic_meta_df.topic_name.apply(lambda n: ' '.join(n.split('_')[1:]))\n\ntopic_pred_df = topic_pred_df.merge(topic_meta_df, on='topic', how='left')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:57.55555Z","iopub.execute_input":"2022-06-25T00:17:57.556097Z","iopub.status.idle":"2022-06-25T00:17:57.599028Z","shell.execute_reply.started":"2022-06-25T00:17:57.556059Z","shell.execute_reply":"2022-06-25T00:17:57.598353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2021_df = train_2021_df.merge(topic_pred_df, on='essay_id', how='left')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:57.955617Z","iopub.execute_input":"2022-06-25T00:17:57.956296Z","iopub.status.idle":"2022-06-25T00:17:58.037832Z","shell.execute_reply.started":"2022-06-25T00:17:57.956257Z","shell.execute_reply":"2022-06-25T00:17:58.037079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data","metadata":{}},{"cell_type":"code","source":"labels = ['Adequate', 'Effective', 'Ineffective']\ntokenizer = AutoTokenizer.from_pretrained(config.model_path / 'fold_0')\n\ndef tokenizer_func(x):\n    return tokenizer(x[\"inputs\"], get_essay(x['essay_fn']), truncation=True, return_overflowing_tokens=False)\n\ndef get_essay(essay_fns):\n    essay_cache = {}\n\n    output = []\n    for essay_fn in essay_fns:\n        if essay_fn not in essay_cache:\n            essay_txt = open(essay_fn).read()\n            essay_cache[essay_fn] = essay_txt\n        output.append(essay_cache[essay_fn])\n\n    return output\n\ndef add_inputs(df, basepath):\n    df['essay_fn'] = basepath + '/' + df.essay_id + '.txt'\n    df['inputs'] = df.discourse_type + ' ' + tokenizer.sep_token + ' ' + df.topic_name + ' ' + tokenizer.sep_token + ' ' + df.discourse_text\n    return df\n\ntrain_2021_df = add_inputs(train_2021_df, '../input/feedback-prize-2021/train')\ntrain_df = add_inputs(train_df, str(config.input_path / 'train'))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:58.587818Z","iopub.execute_input":"2022-06-25T00:17:58.588388Z","iopub.status.idle":"2022-06-25T00:17:59.58909Z","shell.execute_reply.started":"2022-06-25T00:17:58.588345Z","shell.execute_reply":"2022-06-25T00:17:59.588135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom transformers import AutoConfig, AutoModelForSequenceClassification\nfrom transformers.models.deberta_v2.modeling_deberta_v2 import ContextPooler\nfrom transformers.models.deberta_v2.modeling_deberta_v2 import StableDropout\nfrom transformers.modeling_outputs import TokenClassifierOutput\nfrom transformers import DebertaV2ForSequenceClassification\n\ndef get_dropouts(num, start_prob, increment):\n    return [nn.Dropout(start_prob + (increment * i)) for i in range(num)]  \n\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\nclass CustomModel(nn.Module):\n    def __init__(self, backbone):\n        super(CustomModel, self).__init__()\n        \n        self.model = backbone\n        self.config = self.model.config\n        self.num_labels = self.config.num_labels\n\n        # self.pooler = ContextPooler(self.config)\n        self.pooler = MeanPooling()\n        \n        self.classifier = nn.Linear(self.config.hidden_size, self.num_labels)\n    \n        self.dropouts = get_dropouts(num=5, start_prob=0.1, increment=0.1)\n    \n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        inputs_embeds=None,\n        labels=None,\n        output_attentions=None,\n        output_hidden_states=None,\n        return_dict=None\n    ):\n        outputs = self.model.deberta(\n            input_ids,\n            token_type_ids=token_type_ids,\n            attention_mask=attention_mask,\n            position_ids=position_ids,\n            inputs_embeds=inputs_embeds,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n        \n        encoder_layer = outputs[0]\n        pooled_output = self.pooler(encoder_layer, attention_mask)\n                      \n        # Multi-sample dropout.\n        num_dps = float(len(self.dropouts))\n        for ii, drop in enumerate(self.dropouts):\n            if ii == 0:\n                logits = (self.classifier(drop(pooled_output)) / num_dps)\n            else:\n                logits += (self.classifier(drop(pooled_output)) / num_dps)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            logits = logits.view(-1, self.num_labels)\n            loss = loss_fn(logits, labels.view(-1))\n\n        output = (logits,) + outputs[1:]\n\n        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:59.59121Z","iopub.execute_input":"2022-06-25T00:17:59.591758Z","iopub.status.idle":"2022-06-25T00:17:59.657095Z","shell.execute_reply.started":"2022-06-25T00:17:59.591721Z","shell.execute_reply":"2022-06-25T00:17:59.656202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model_config = AutoConfig.from_pretrained(config.model_path / 'backbone_config/config.json')\n    model = DebertaV2ForSequenceClassification(model_config)\n    \n    return CustomModel(model)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:17:59.661269Z","iopub.execute_input":"2022-06-25T00:17:59.661618Z","iopub.status.idle":"2022-06-25T00:17:59.670348Z","shell.execute_reply.started":"2022-06-25T00:17:59.661561Z","shell.execute_reply":"2022-06-25T00:17:59.669421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"#train_2021_df = train_2021_df.sample(n=100)\n#train_df = train_df.sample(n=100)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:55:33.302188Z","iopub.execute_input":"2022-06-25T00:55:33.302554Z","iopub.status.idle":"2022-06-25T00:55:33.317909Z","shell.execute_reply.started":"2022-06-25T00:55:33.302509Z","shell.execute_reply":"2022-06-25T00:55:33.31722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_2021_data = np.zeros((config.n_folds, len(train_2021_df), len(labels)))\nall_val_preds = []\n\nfor fold_num in range(config.n_folds):\n    print(f'Do fold {fold_num}')\n\n    tokenizer = AutoTokenizer.from_pretrained(config.model_path / f'fold_{fold_num}')\n    tokenizer.model_max_length = config.max_len\n\n    model = get_model()\n\n    state_dict = torch.load(config.model_path / f'fold_{fold_num}/pytorch_model.bin')\n    model.load_state_dict(state_dict)  \n\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='longest')\n\n    args = TrainingArguments(\n        output_dir=config.output_path,\n        learning_rate=config.lr,\n        lr_scheduler_type='cosine',\n        fp16=True,\n        evaluation_strategy='epoch',\n        per_device_train_batch_size=config.batch_size,\n        per_device_eval_batch_size=config.batch_size * 2,\n        report_to=\"none\",\n        save_strategy='no',\n        label_smoothing_factor=config.label_smoothing_factor\n    )\n    \n    trainer = Trainer(\n        model,\n        args,\n        tokenizer=tokenizer,\n        data_collator=data_collator\n    )\n\n    # Make predictions on the OOF data (to verify my model works okay).\n    val_df = train_df.query(f'fold == {fold_num}').reset_index(drop=True)\n    val_dataset = Dataset.from_pandas(val_df[['inputs', 'essay_fn']])\n    \n    print('Predict on 2022 dataset')\n    val_tok_dataset = val_dataset.map(tokenizer_func, batched=True, remove_columns=('inputs', 'essay_fn'))\n    val_preds = trainer.predict(val_tok_dataset)\n    val_preds_softmax = softmax(val_preds.predictions, axis=1)\n    val_df[labels] = val_preds_softmax\n    all_val_preds.append(val_df)\n    \n    # Make predictions on 2021 data\n    print('Predict on 2021 dataset')\n    val_dataset_2021 = Dataset.from_pandas(train_2021_df[['inputs', 'essay_fn']])\n    val_tok_dataset_2021 = val_dataset_2021.map(tokenizer_func, batched=True, remove_columns=('inputs', 'essay_fn'))\n    outputs_2021 = trainer.predict(val_tok_dataset_2021) \n    softmax_outputs_2021 = softmax(outputs_2021.predictions, axis=1)\n    \n    all_2021_data[fold_num] = softmax_outputs_2021","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:55:35.067289Z","iopub.execute_input":"2022-06-25T00:55:35.067613Z","iopub.status.idle":"2022-06-25T00:56:56.848182Z","shell.execute_reply.started":"2022-06-25T00:55:35.067574Z","shell.execute_reply":"2022-06-25T00:56:56.847443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate Results\n\nLet's check to see that the model is returning the CV results we expect on this competition's data.","metadata":{}},{"cell_type":"code","source":"val_preds_df = pd.concat(all_val_preds)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:56:56.849802Z","iopub.execute_input":"2022-06-25T00:56:56.850152Z","iopub.status.idle":"2022-06-25T00:56:56.859331Z","shell.execute_reply.started":"2022-06-25T00:56:56.850114Z","shell.execute_reply":"2022-06-25T00:56:56.858512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_loss(val_preds_df['discourse_effectiveness'], val_preds_df[labels])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:56:56.860565Z","iopub.execute_input":"2022-06-25T00:56:56.860887Z","iopub.status.idle":"2022-06-25T00:56:56.874125Z","shell.execute_reply.started":"2022-06-25T00:56:56.860851Z","shell.execute_reply":"2022-06-25T00:56:56.873352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Save Results","metadata":{}},{"cell_type":"markdown","source":"Before saving results, I will format to match the 2022 data.","metadata":{}},{"cell_type":"code","source":"preds_2021 = np.mean(all_2021_data, axis=0)\ntrain_2021_df = train_2021_df.rename(columns={'id': 'essay_id'})\ntrain_2021_df_output = train_2021_df.drop(columns=['discourse_start', 'discourse_end', 'discourse_type_num', 'predictionstring', 'inputs'])\ntrain_2021_df_output[labels] = preds_2021\ntrain_2021_df_output['discourse_effectiveness'] = train_2021_df_output[labels].idxmax(axis=1)\ntrain_2021_df_output.to_csv('train_2021_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:57:18.165985Z","iopub.execute_input":"2022-06-25T00:57:18.166301Z","iopub.status.idle":"2022-06-25T00:57:18.183527Z","shell.execute_reply.started":"2022-06-25T00:57:18.166271Z","shell.execute_reply":"2022-06-25T00:57:18.182863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2021_df_output.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T00:57:18.715527Z","iopub.execute_input":"2022-06-25T00:57:18.715784Z","iopub.status.idle":"2022-06-25T00:57:18.734541Z","shell.execute_reply.started":"2022-06-25T00:57:18.715754Z","shell.execute_reply":"2022-06-25T00:57:18.733514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}