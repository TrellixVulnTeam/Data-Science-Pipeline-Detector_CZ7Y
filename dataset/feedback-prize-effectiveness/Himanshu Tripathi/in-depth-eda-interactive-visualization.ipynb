{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-31T05:00:32.004978Z","iopub.execute_input":"2022-05-31T05:00:32.005435Z","iopub.status.idle":"2022-05-31T05:00:32.811224Z","shell.execute_reply.started":"2022-05-31T05:00:32.005391Z","shell.execute_reply":"2022-05-31T05:00:32.810215Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Description\n\nThe dataset presented here contains argumentative essays written by U.S students in grades 6-12. These essays were annotated by expert raters for discourse elements commonly found in argumentative writing:\n\n- Lead - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the readerâ€™s attention and point toward the thesis\n- Position - an opinion or conclusion on the main question\n- Claim - a claim that supports the position\n- Counterclaim - a claim that refutes another claim or gives an opposing reason to the position\n- Rebuttal - a claim that refutes a counterclaim\n- Evidence - ideas or examples that support claims, counterclaims, or rebuttals.\n- Concluding Statement - a concluding statement that restates the claims\n\nYour task is to predict the quality rating of each discourse element. Human readers rated each rhetorical or argumentative element, in order of increasing quality, as one of:\n\n- Ineffective\n- Adequate\n- Effective\n\n**Training Data**\n\nThe training set consist of a .csv file containing the annotated discourse elements each essay, including the quality ratings, together with .txt files containing the full text of each essay. It is important to note that some parts of the essays will be unannotated (i.e., they do not fit into one of the classifications above) and they will lack a quality rating. We do not include the unannotated parts in train.csv.\n\n- train.csv - Contains the annotated discourse elements for all essays in the test set.\n\n- discourse_id - ID code for discourse element\n- essay_id - ID code for essay response. This ID code corresponds to the name of the full-text file in the train/ folder.\n- discourse_text - Text of discourse element.\n- discourse_type - Class label of discourse element.\n- discourse_type_num - Enumerated class label of discourse element .\n- discourse_effectiveness - Quality rating of discourse element, the target.\n\nExample Test Data\nTo help you author submission code, we include a few example instances selected from the test set. When you submit your notebook for scoring, this example data will be replaced by the actual test data, including the sample_submission.csv file.\n\ntest/ - A folder containing an example essay from the test set. The actual test set comprises about 3,000 essays in a format similar to the training set essays. The test set essays are distinct from the training set essays.\ntest.csv - Annotations for the test set essays, containing all of the fields of train.csv except the target, discourse_effectiveness.\nsample_submission.csv - A sample submission file in the correct format. See the Evaluation page for more details.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/feedback-prize-effectiveness/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:11:52.696333Z","iopub.execute_input":"2022-05-31T05:11:52.696832Z","iopub.status.idle":"2022-05-31T05:11:53.090569Z","shell.execute_reply.started":"2022-05-31T05:11:52.696797Z","shell.execute_reply":"2022-05-31T05:11:53.089379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:12:12.855289Z","iopub.execute_input":"2022-05-31T05:12:12.85577Z","iopub.status.idle":"2022-05-31T05:12:12.881607Z","shell.execute_reply.started":"2022-05-31T05:12:12.855733Z","shell.execute_reply":"2022-05-31T05:12:12.880537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:12:24.286624Z","iopub.execute_input":"2022-05-31T05:12:24.287098Z","iopub.status.idle":"2022-05-31T05:12:24.298907Z","shell.execute_reply.started":"2022-05-31T05:12:24.287064Z","shell.execute_reply":"2022-05-31T05:12:24.297914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:32:38.331887Z","iopub.execute_input":"2022-05-31T05:32:38.332393Z","iopub.status.idle":"2022-05-31T05:32:38.337599Z","shell.execute_reply.started":"2022-05-31T05:32:38.332355Z","shell.execute_reply":"2022-05-31T05:32:38.336567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if there is any null value\nprint(train_df.isnull().sum())\nprint(\"-\"*50)\nsns.heatmap(train_df.isnull());","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:32:39.273109Z","iopub.execute_input":"2022-05-31T05:32:39.273606Z","iopub.status.idle":"2022-05-31T05:32:39.88395Z","shell.execute_reply.started":"2022-05-31T05:32:39.273569Z","shell.execute_reply":"2022-05-31T05:32:39.882771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA for discourse_type\nprint(train_df['discourse_type'].value_counts())\nprint(\"-\"*50)\nsns.countplot(train_df['discourse_type']);\nplt.xticks(rotation=90);","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:32:40.477445Z","iopub.execute_input":"2022-05-31T05:32:40.477882Z","iopub.status.idle":"2022-05-31T05:32:40.726507Z","shell.execute_reply.started":"2022-05-31T05:32:40.477845Z","shell.execute_reply":"2022-05-31T05:32:40.725853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA for discourse_effectiveness\nprint(train_df['discourse_effectiveness'].value_counts())\nprint(\"-\"*50)\nsns.countplot(train_df['discourse_effectiveness']);\n\n# we can see that we have unbalanced data","metadata":{"execution":{"iopub.status.busy":"2022-05-31T05:34:47.518887Z","iopub.execute_input":"2022-05-31T05:34:47.519563Z","iopub.status.idle":"2022-05-31T05:34:47.748314Z","shell.execute_reply.started":"2022-05-31T05:34:47.519507Z","shell.execute_reply":"2022-05-31T05:34:47.74728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generate Statistical Count Features","metadata":{}},{"cell_type":"code","source":"!pip install chart_studio","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:18:57.86378Z","iopub.execute_input":"2022-05-31T06:18:57.864238Z","iopub.status.idle":"2022-05-31T06:19:11.139118Z","shell.execute_reply.started":"2022-05-31T06:18:57.864202Z","shell.execute_reply":"2022-05-31T06:19:11.13786Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport plotly\nimport chart_studio.plotly as py\nfrom plotly import tools\ninit_notebook_mode(connected=True)\n\nimport string\npunc = string.punctuation","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:36:51.239586Z","iopub.execute_input":"2022-05-31T07:36:51.240047Z","iopub.status.idle":"2022-05-31T07:36:51.247788Z","shell.execute_reply.started":"2022-05-31T07:36:51.24001Z","shell.execute_reply":"2022-05-31T07:36:51.246508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train_df.copy()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:10:01.222372Z","iopub.execute_input":"2022-05-31T06:10:01.222807Z","iopub.status.idle":"2022-05-31T06:10:01.241603Z","shell.execute_reply.started":"2022-05-31T06:10:01.222765Z","shell.execute_reply":"2022-05-31T06:10:01.240659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['word_count'] = df['discourse_text'].apply(lambda x : len(x.split()))\ndf['char_count'] = df['discourse_text'].apply(lambda x : len(x.replace(\" \",\"\")))\ndf['word_density'] = df['word_count'] / (df['char_count'] + 1)\ndf['punc_count'] = df['discourse_text'].apply(lambda x : len([a for a in x if a in punc]))\n\ndf[['word_count', 'char_count', 'word_density', 'punc_count']].head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:11:17.962101Z","iopub.execute_input":"2022-05-31T06:11:17.96251Z","iopub.status.idle":"2022-05-31T06:11:18.789665Z","shell.execute_reply.started":"2022-05-31T06:11:17.962479Z","shell.execute_reply":"2022-05-31T06:11:18.788821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Word count Distrubiton of discourse_text**","metadata":{}},{"cell_type":"code","source":"words = df.word_count\ntrace1 = go.Histogram(x=words, opacity=0.65, name=\"Word Count\", marker=dict(color='rgba(17, 50, 96, 0.6)'))\ndata = [trace1]\nlayout = go.Layout(barmode='overlay',\n                   title='Word Count of discourse_text',\n                   xaxis=dict(title='Word Count'),\n                   yaxis=dict( title='Number of discourse_text'))\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:20:45.854179Z","iopub.execute_input":"2022-05-31T06:20:45.854687Z","iopub.status.idle":"2022-05-31T06:20:45.915874Z","shell.execute_reply.started":"2022-05-31T06:20:45.854646Z","shell.execute_reply":"2022-05-31T06:20:45.91338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Character count Distrbution**","metadata":{}},{"cell_type":"code","source":"chars = df.char_count\ntrace1 = go.Histogram(x=chars, opacity=0.65, name=\"Word Count\", marker=dict(color='rgba(120, 40, 106, 0.6)'))\ndata = [trace1]\nlayout = go.Layout(barmode='overlay',\n                   title='Char Count of discourse_text',\n                   xaxis=dict(title='Char Count'),\n                   yaxis=dict( title='Number of discourse_text'))\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:22:58.644717Z","iopub.execute_input":"2022-05-31T06:22:58.645788Z","iopub.status.idle":"2022-05-31T06:22:58.705839Z","shell.execute_reply.started":"2022-05-31T06:22:58.645739Z","shell.execute_reply":"2022-05-31T06:22:58.704729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Word Density**","metadata":{}},{"cell_type":"code","source":"wd = df.word_density\ntrace1 = go.Histogram(x=wd, opacity=0.65, name=\"Word Count\", marker=dict(color='rgba(0, 120, 0, 0.6)'))\ndata = [trace1]\nlayout = go.Layout(barmode='overlay',\n                   title='Word Density of discourse_text',\n                   xaxis=dict(title='Word Density'),\n                   yaxis=dict( title='Number of discourse_text'))\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:24:03.284834Z","iopub.execute_input":"2022-05-31T06:24:03.285373Z","iopub.status.idle":"2022-05-31T06:24:03.399473Z","shell.execute_reply.started":"2022-05-31T06:24:03.285332Z","shell.execute_reply":"2022-05-31T06:24:03.398477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Punctuation Count**","metadata":{}},{"cell_type":"code","source":"punc_count = df.punc_count\ntrace1 = go.Histogram(x=punc_count, opacity=0.75, name=\"Word Count\", marker=dict(color='rgba(10, 22, 200, 0.6)'))\ndata = [trace1]\nlayout = go.Layout(barmode='overlay',\n                   title='Punctuation Count of discourse_text',\n                   xaxis=dict(title='Punctuation Count'),\n                   yaxis=dict( title='Number of discourse_text'))\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:26:12.414788Z","iopub.execute_input":"2022-05-31T06:26:12.415279Z","iopub.status.idle":"2022-05-31T06:26:12.472288Z","shell.execute_reply.started":"2022-05-31T06:26:12.415225Z","shell.execute_reply":"2022-05-31T06:26:12.471139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating WordCloud","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-05-31T06:58:22.719142Z","iopub.execute_input":"2022-05-31T06:58:22.719537Z","iopub.status.idle":"2022-05-31T06:58:22.727681Z","shell.execute_reply.started":"2022-05-31T06:58:22.719505Z","shell.execute_reply":"2022-05-31T06:58:22.726675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['discourse_effectiveness'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:07:58.438518Z","iopub.execute_input":"2022-05-31T07:07:58.438952Z","iopub.status.idle":"2022-05-31T07:07:58.453557Z","shell.execute_reply.started":"2022-05-31T07:07:58.438913Z","shell.execute_reply":"2022-05-31T07:07:58.452778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text(text):\n    type_text = df[df['discourse_effectiveness']==text]\n    value = str(type_text['discourse_text'])\n    return value","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:10:05.879843Z","iopub.execute_input":"2022-05-31T07:10:05.880994Z","iopub.status.idle":"2022-05-31T07:10:05.885992Z","shell.execute_reply.started":"2022-05-31T07:10:05.880953Z","shell.execute_reply":"2022-05-31T07:10:05.885144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\n\nwordcloud1 = WordCloud(background_color='white').generate(generate_text(\"Adequate\"))\nwordcloud2 = WordCloud(background_color='white').generate(generate_text(\"Effective\"))\nwordcloud3 = WordCloud(background_color='white').generate(generate_text(\"Ineffective\"))\nwordcloud4 = WordCloud(background_color='white').generate(str(df['discourse_text']))\n\nfig, axes = plt.subplots(2, 2, figsize=(18, 10))\n\nax = axes[0, 0]\nax.imshow(wordcloud1)\nax.axis('off');\nax.set_title(\"Adequate\", fontsize=30);\n\nax = axes[0, 1]\nax.imshow(wordcloud2)\nax.axis('off');\nax.set_title(\"Effective\", fontsize=30);\n\nax = axes[1, 0]\nax.imshow(wordcloud3)\nax.axis('off');\nax.set_title(\"Ineffective\", fontsize=30);\n\nax = axes[1, 1]\nax.imshow(wordcloud4)\nax.axis('off');\nax.set_title(\"All 3\", fontsize=30);","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:12:17.989701Z","iopub.execute_input":"2022-05-31T07:12:17.990309Z","iopub.status.idle":"2022-05-31T07:12:18.959153Z","shell.execute_reply.started":"2022-05-31T07:12:17.990272Z","shell.execute_reply":"2022-05-31T07:12:18.95835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-- We can see that word \"people\" takes more space in All 3 plot, and \"people\" also found in \"Adequate\", that because we've more data for \"Adequate\"","metadata":{}},{"cell_type":"code","source":"\"\"\"\n    That's it for now, next i'm going to work on model creation, Stay tuned for that..\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-05-31T07:45:09.095049Z","iopub.execute_input":"2022-05-31T07:45:09.095548Z","iopub.status.idle":"2022-05-31T07:45:09.102795Z","shell.execute_reply.started":"2022-05-31T07:45:09.095509Z","shell.execute_reply":"2022-05-31T07:45:09.101741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}