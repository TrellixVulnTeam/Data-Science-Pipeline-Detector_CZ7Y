{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Feedback Prize - BERT\n\nThis is a **training** notebook. The inference notebook can be found [Feedback Prize - BERT Inference](https://www.kaggle.com/code/morodertobias/feedback-prize-bert-inference/notebook).\n\nWe fine-tune a pretrained BERT base model and start with a classification acting on ``discourse_type [SEP] discourse_text`` only.\n\n\n## References\n\nWe mainly used the following references, also corresponding to former challenges:\n\n- [Semantic Similarity with BERT](https://keras.io/examples/nlp/semantic_similarity_with_bert/)\n- [US Phrase Matching: TF-Keras Train [TPU]](https://www.kaggle.com/code/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu/notebook)\n- [TensorFlow - LongFormer - NER - [CV 0.633]](https://www.kaggle.com/code/cdeotte/tensorflow-longformer-ner-cv-0-633/notebook)\n- [【Tensorflow】FeedBack BERT-Baseline](https://www.kaggle.com/code/imvision12/tensorflow-feedback-bert-baseline/notebook)\n- [TFRecord Experiments - Upsample and Coarse Dropout](https://www.kaggle.com/code/cdeotte/tfrecord-experiments-upsample-and-coarse-dropout)","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers==4.18.0","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:46:58.699984Z","iopub.execute_input":"2022-06-25T19:46:58.700893Z","iopub.status.idle":"2022-06-25T19:47:16.235556Z","shell.execute_reply.started":"2022-06-25T19:46:58.700769Z","shell.execute_reply":"2022-06-25T19:47:16.234531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pathlib\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport transformers","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:47:20.632099Z","iopub.execute_input":"2022-06-25T19:47:20.63241Z","iopub.status.idle":"2022-06-25T19:47:27.325638Z","shell.execute_reply.started":"2022-06-25T19:47:20.63237Z","shell.execute_reply":"2022-06-25T19:47:27.324785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\nprint(transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:47:27.327551Z","iopub.execute_input":"2022-06-25T19:47:27.327867Z","iopub.status.idle":"2022-06-25T19:47:27.333865Z","shell.execute_reply.started":"2022-06-25T19:47:27.327828Z","shell.execute_reply":"2022-06-25T19:47:27.332656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    print(\"TPU failed!\")\n    tpu = None\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:47:27.335183Z","iopub.execute_input":"2022-06-25T19:47:27.335486Z","iopub.status.idle":"2022-06-25T19:47:33.659624Z","shell.execute_reply.started":"2022-06-25T19:47:27.335457Z","shell.execute_reply":"2022-06-25T19:47:33.658677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config\n\nLet us use a config object holding all parameters, settings and configs.","metadata":{}},{"cell_type":"code","source":"class Config:\n    seed = 887\n    model_name = \"tpu_bert_v7\"\n    n_fold = 5\n    one_fold = False\n    # inputs\n    input_dir = pathlib.Path(\"/kaggle/input/feedback-prize-effectiveness/\")\n    path_train = input_dir / \"train.csv\"\n    train_dir = input_dir / \"train\"\n    path_test = input_dir / \"test.csv\"\n    test_dir = input_dir / \"test\"\n    path_submission = input_dir / \"sample_submission.csv\"\n    labels = [\"Ineffective\", \"Adequate\", \"Effective\"]\n    label_dict = {v: i for i, v in enumerate(labels)}\n    num_classes = len(labels)\n    id_col = \"discourse_id\"\n    # model\n    pretrained = \"bert-base-uncased\"\n    pretrained_dir = pathlib.Path(\"/kaggle/working/pretrained\")\n    max_len = 512\n    dropout = 0.4\n    # train\n    learning_rate = 3e-6  #0.001\n    batch_size = 128\n    epochs = 25  # 50\n    patience = 3\n    verbose = 2\n    \ncfg = Config()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:47:44.621576Z","iopub.execute_input":"2022-06-25T19:47:44.622192Z","iopub.status.idle":"2022-06-25T19:47:44.630764Z","shell.execute_reply.started":"2022-06-25T19:47:44.622156Z","shell.execute_reply":"2022-06-25T19:47:44.629882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download pretrained files\n\nLet us follow the ideas of [TensorFlow - LongFormer - NER - [CV 0.633]](https://www.kaggle.com/code/cdeotte/tensorflow-longformer-ner-cv-0-633/notebook) and download  tokenizer and model, and store them into a notebook output folder in order to use them directly in the inference notebook or for creating a versioned dataset.","metadata":{}},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(cfg.pretrained)\ntokenizer.save_pretrained(cfg.pretrained_dir)\nconfig = transformers.AutoConfig.from_pretrained(cfg.pretrained)\nconfig.save_pretrained(cfg.pretrained_dir)\nbase_model = transformers.TFAutoModel.from_pretrained(cfg.pretrained, config=config, from_pt=True)\nbase_model.save_pretrained(cfg.pretrained_dir)\nos.listdir(cfg.pretrained_dir)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:48:14.720084Z","iopub.execute_input":"2022-06-25T19:48:14.720797Z","iopub.status.idle":"2022-06-25T19:48:34.68496Z","shell.execute_reply.started":"2022-06-25T19:48:14.72075Z","shell.execute_reply":"2022-06-25T19:48:34.684123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation\n\nLoad data and prepare the text ``discourse_type [SEP] discourse_text`` used in classification. \n\nThe tokenizer will encode this into ``[CLS] discourse_type [SEP] discourse_text [SEP]`` as can be seen by the example below.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(cfg.path_train)\ndata[\"label\"] = data[\"discourse_effectiveness\"].map(cfg.label_dict)\ndata","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:48:34.686376Z","iopub.execute_input":"2022-06-25T19:48:34.686588Z","iopub.status.idle":"2022-06-25T19:48:35.012862Z","shell.execute_reply.started":"2022-06-25T19:48:34.686565Z","shell.execute_reply":"2022-06-25T19:48:35.011864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(cfg.pretrained_dir)\ntokenizer","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:48:35.0141Z","iopub.execute_input":"2022-06-25T19:48:35.014373Z","iopub.status.idle":"2022-06-25T19:48:35.04778Z","shell.execute_reply.started":"2022-06-25T19:48:35.014323Z","shell.execute_reply":"2022-06-25T19:48:35.046929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"text\"] = data[\"discourse_type\"] + tokenizer.sep_token + data[\"discourse_text\"]\ndata","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:48:35.05017Z","iopub.execute_input":"2022-06-25T19:48:35.05053Z","iopub.status.idle":"2022-06-25T19:48:35.088031Z","shell.execute_reply.started":"2022-06-25T19:48:35.050491Z","shell.execute_reply":"2022-06-25T19:48:35.086986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Look at a random example","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:23:45.382576Z","iopub.execute_input":"2022-06-16T12:23:45.383666Z","iopub.status.idle":"2022-06-16T12:23:45.389863Z","shell.execute_reply.started":"2022-06-16T12:23:45.383624Z","shell.execute_reply":"2022-06-16T12:23:45.389014Z"}}},{"cell_type":"code","source":"rec = data.sample(n=1).iloc[0].to_dict()\nrec","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:48:35.089675Z","iopub.execute_input":"2022-06-25T19:48:35.090268Z","iopub.status.idle":"2022-06-25T19:48:35.108228Z","shell.execute_reply.started":"2022-06-25T19:48:35.090233Z","shell.execute_reply":"2022-06-25T19:48:35.107163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"original:\", rec[\"text\"])\nprint(\"tokenized:\", tokenizer.tokenize(rec[\"text\"]))\nprint(\"encode_plus:\", tokenizer.encode_plus(rec[\"text\"]))\nprint(\"decoded:\", tokenizer.decode(tokenizer.encode_plus(rec[\"text\"])['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:48:35.109246Z","iopub.execute_input":"2022-06-25T19:48:35.109556Z","iopub.status.idle":"2022-06-25T19:48:35.117869Z","shell.execute_reply.started":"2022-06-25T19:48:35.109525Z","shell.execute_reply":"2022-06-25T19:48:35.117089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset\n\nWe like to map ``tokenizer.encode_plus`` to all texts in the dataset; this does not seem to directly work on a tensorflow dataset, hence we compute the results beforehand... as done in the reference notebooks.","metadata":{}},{"cell_type":"code","source":"options = tf.data.Options()\noptions.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n\n\ndef encode_text(text):\n    \"\"\"Encode text with tokenizer and return dictionary of numpy results.\"\"\"\n    encoded = tokenizer.batch_encode_plus(\n        text,\n        max_length=cfg.max_len,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_token_type_ids=True,\n        return_tensors=\"tf\",\n    )\n    return {\n        \"input_ids\": encoded[\"input_ids\"].numpy(),\n        \"attention_masks\": encoded[\"attention_mask\"].numpy(),\n        \"token_type_ids\": encoded[\"token_type_ids\"].numpy(),\n    }\n\n\ndef get_dataset(data, batch_size=cfg.batch_size, shuffle=False, cache=False, include_label=True):\n    \"\"\"Get dataset\"\"\"\n    encoded_text = encode_text(data['text'].to_list())\n    tensor_slices = encoded_text\n    if include_label:\n        tensor_slices = (encoded_text, data[\"label\"].to_list())\n    ds = tf.data.Dataset.from_tensor_slices(tensor_slices)\n    ds = ds.with_options(options)\n    if shuffle:\n        ds = ds.shuffle(2048)\n    ds = ds.batch(batch_size)\n    if cache:\n        ds = ds.cache()\n    ds = ds.prefetch(tf.data.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:49:22.344173Z","iopub.execute_input":"2022-06-25T19:49:22.345023Z","iopub.status.idle":"2022-06-25T19:49:22.360981Z","shell.execute_reply.started":"2022-06-25T19:49:22.344975Z","shell.execute_reply":"2022-06-25T19:49:22.359882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Verify dataset creation","metadata":{}},{"cell_type":"code","source":"data.iloc[:5]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:49:56.145735Z","iopub.execute_input":"2022-06-25T19:49:56.146034Z","iopub.status.idle":"2022-06-25T19:49:56.165373Z","shell.execute_reply.started":"2022-06-25T19:49:56.146007Z","shell.execute_reply":"2022-06-25T19:49:56.164597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = get_dataset(data.iloc[:5], batch_size=2)\nds.element_spec","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:49:56.559177Z","iopub.execute_input":"2022-06-25T19:49:56.559525Z","iopub.status.idle":"2022-06-25T19:49:56.591955Z","shell.execute_reply.started":"2022-06-25T19:49:56.559495Z","shell.execute_reply":"2022-06-25T19:49:56.590955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elem = next(iter(ds))\nelem","metadata":{"execution":{"iopub.status.busy":"2022-06-25T20:00:58.185641Z","iopub.execute_input":"2022-06-25T20:00:58.185965Z","iopub.status.idle":"2022-06-25T20:00:58.333126Z","shell.execute_reply.started":"2022-06-25T20:00:58.185925Z","shell.execute_reply":"2022-06-25T20:00:58.332302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\n\nThe model is straightforward, i.e., inputs > base_model > output head.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import Model, layers, losses, optimizers, metrics, callbacks, backend","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:50:02.256868Z","iopub.execute_input":"2022-06-25T19:50:02.257168Z","iopub.status.idle":"2022-06-25T19:50:02.262275Z","shell.execute_reply.started":"2022-06-25T19:50:02.25714Z","shell.execute_reply":"2022-06-25T19:50:02.26126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    # inputs\n    input_ids = layers.Input(shape=(cfg.max_len,), dtype=\"int32\", name=\"input_ids\")\n    attention_masks = layers.Input(shape=(cfg.max_len,), dtype=\"int32\", name=\"attention_masks\")\n    token_type_ids = layers.Input(shape=(cfg.max_len,), dtype=\"int32\", name=\"token_type_ids\")\n    # base_model\n    base_model_config = transformers.AutoConfig.from_pretrained(\n        cfg.pretrained_dir / \"config.json\"\n    )\n    base_model = transformers.TFAutoModel.from_pretrained(\n        cfg.pretrained_dir / \"tf_model.h5\", config=base_model_config\n    )\n    # base_model.trainable = False\n    base_model_output = base_model(\n        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n    )\n    x = base_model_output.last_hidden_state[:, 0, :]\n    # head\n    x = layers.Dropout(cfg.dropout)(x)\n    output = layers.Dense(cfg.num_classes, activation=\"softmax\")(x)\n    model = Model(\n        inputs=[input_ids, attention_masks, token_type_ids],\n        outputs=output,\n        name=cfg.model_name,\n    )\n    # compile\n    model.compile(\n        optimizer=optimizers.Adam(cfg.learning_rate),\n        loss=losses.SparseCategoricalCrossentropy(),\n        metrics=[\"acc\"],\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:50:03.209664Z","iopub.execute_input":"2022-06-25T19:50:03.210411Z","iopub.status.idle":"2022-06-25T19:50:03.220591Z","shell.execute_reply.started":"2022-06-25T19:50:03.210369Z","shell.execute_reply":"2022-06-25T19:50:03.219754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Verify model creation","metadata":{}},{"cell_type":"code","source":"backend.clear_session()\nwith strategy.scope():\n    model = create_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:50:04.67991Z","iopub.execute_input":"2022-06-25T19:50:04.6802Z","iopub.status.idle":"2022-06-25T19:50:22.892761Z","shell.execute_reply.started":"2022-06-25T19:50:04.68017Z","shell.execute_reply":"2022-06-25T19:50:22.891709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(elem[0]), elem[1]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:50:53.270198Z","iopub.execute_input":"2022-06-25T19:50:53.270952Z","iopub.status.idle":"2022-06-25T19:51:02.449518Z","shell.execute_reply.started":"2022-06-25T19:50:53.270907Z","shell.execute_reply":"2022-06-25T19:51:02.44856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training helper functions","metadata":{}},{"cell_type":"code","source":"import sklearn.metrics as sk_metrics","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:51:02.451251Z","iopub.execute_input":"2022-06-25T19:51:02.451533Z","iopub.status.idle":"2022-06-25T19:51:03.180283Z","shell.execute_reply.started":"2022-06-25T19:51:02.451505Z","shell.execute_reply":"2022-06-25T19:51:03.179456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_callbacks(filepath):\n    \"\"\"Create callbacks for training\"\"\"\n    return [\n        callbacks.ModelCheckpoint(\n            filepath=filepath, save_best_only=True, save_weights_only=True, verbose=1\n        ),\n        callbacks.EarlyStopping(\n            patience=cfg.patience, restore_best_weights=False, verbose=1\n        ),\n    ]\n\n\ndef show_history(history):\n    \"\"\"Show history\"\"\"\n    history_df = pd.DataFrame(history.history)\n    history_df.index = pd.Index(history.epoch, name=\"epoch\")\n    display(\n        history_df.style.highlight_min(\n            color=\"green\", subset=[\"val_loss\"]\n        ).highlight_max(color=\"green\", subset=[\"val_acc\"])\n    )\n    fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n    history_df[[\"loss\", \"val_loss\"]].plot(ax=ax[0], title=\"loss\")\n    history_df[[\"acc\", \"val_acc\"]].plot(ax=ax[1], title=\"acc\")\n    plt.tight_layout()\n    plt.show()\n    \n    \ndef compute_oof(model, valid):\n    \"\"\"Compute OOF\"\"\"\n    valid_ds = get_dataset(valid)\n    pred = model.predict(valid_ds, verbose=0)\n    oof = pd.DataFrame(pred, columns=cfg.labels, index=valid[cfg.id_col])\n    oof[\"label\"] = valid.set_index(cfg.id_col)[\"label\"]\n    return oof    \n    \n\ndef compute_score(x):\n    \"\"\"Compute score\"\"\"\n    return sk_metrics.log_loss(y_true=x[\"label\"], y_pred=x[cfg.labels])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:51:03.181648Z","iopub.execute_input":"2022-06-25T19:51:03.181961Z","iopub.status.idle":"2022-06-25T19:51:03.196408Z","shell.execute_reply.started":"2022-06-25T19:51:03.181921Z","shell.execute_reply":"2022-06-25T19:51:03.195434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(train, valid, filename):\n    \"\"\"Run training\"\"\"\n    # https://www.kaggle.com/code/cdeotte/tfrecord-experiments-upsample-and-coarse-dropout\n    if tpu:\n        tf.tpu.experimental.initialize_tpu_system()\n    # create datasets\n    train_ds = get_dataset(train, shuffle=True)\n    valid_ds = get_dataset(valid)\n    # create model\n    backend.clear_session()\n    with strategy.scope():\n        model = create_model()\n    # fit\n    hist = model.fit(\n        train_ds,\n        epochs=cfg.epochs,\n        validation_data=valid_ds,\n        callbacks=create_callbacks(filename),\n        verbose=cfg.verbose,\n    )\n    model.load_weights(filename)\n    # oof\n    oof = compute_oof(model, valid)\n    return hist, oof","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:51:03.199041Z","iopub.execute_input":"2022-06-25T19:51:03.199461Z","iopub.status.idle":"2022-06-25T19:51:03.212459Z","shell.execute_reply.started":"2022-06-25T19:51:03.199422Z","shell.execute_reply":"2022-06-25T19:51:03.211442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run training\n\nWe use stratified splitting in creating training and validation folds.","metadata":{"execution":{"iopub.status.busy":"2022-06-16T15:41:56.057774Z","iopub.execute_input":"2022-06-16T15:41:56.058314Z","iopub.status.idle":"2022-06-16T15:41:56.063774Z","shell.execute_reply.started":"2022-06-16T15:41:56.058279Z","shell.execute_reply":"2022-06-16T15:41:56.063005Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:51:46.747448Z","iopub.execute_input":"2022-06-25T19:51:46.74841Z","iopub.status.idle":"2022-06-25T19:51:46.767973Z","shell.execute_reply.started":"2022-06-25T19:51:46.748299Z","shell.execute_reply":"2022-06-25T19:51:46.767216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\nskf","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:51:47.289746Z","iopub.execute_input":"2022-06-25T19:51:47.290041Z","iopub.status.idle":"2022-06-25T19:51:47.29661Z","shell.execute_reply.started":"2022-06-25T19:51:47.290011Z","shell.execute_reply":"2022-06-25T19:51:47.295821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nd_oof = {}\nfor fold, (iloc_train, iloc_valid) in enumerate(skf.split(data, data['label'])):\n    print(f\"fold: {fold}\")\n    train = data.iloc[iloc_train]\n    valid = data.iloc[iloc_valid]\n    model_filepath = f\"weights__{cfg.model_name}__fold-{fold}.h5\"\n    print(f\"#train: {len(train)},  #valid: {len(valid)} \")\n    print(f\"model_filepath: {model_filepath}\")\n    hist, oof = run_training(train, valid, model_filepath)\n    print(\"OOF score:\", compute_score(oof))\n    show_history(hist)\n    d_oof[fold] = oof\n    if cfg.one_fold:\n        break    ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T19:56:31.170761Z","iopub.execute_input":"2022-06-25T19:56:31.171593Z","iopub.status.idle":"2022-06-25T20:00:18.55591Z","shell.execute_reply.started":"2022-06-25T19:56:31.171557Z","shell.execute_reply":"2022-06-25T20:00:18.555096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF\n\nFinalize OOF prediction and score summary.","metadata":{}},{"cell_type":"code","source":"oof = pd.concat(d_oof, names=['fold']).reset_index('fold')\noof.to_csv(\"oof.csv\")\nscore_by_fold = oof.groupby('fold').apply(compute_score)\ndisplay(score_by_fold)\nscore = compute_score(oof)\nprint(f\"\\nOOF score: {score:.6f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T19:49:56.08034Z","iopub.execute_input":"2022-06-17T19:49:56.080846Z","iopub.status.idle":"2022-06-17T19:49:56.467762Z","shell.execute_reply.started":"2022-06-17T19:49:56.080805Z","shell.execute_reply":"2022-06-17T19:49:56.466719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}