{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-23T17:28:48.613823Z","iopub.execute_input":"2022-06-23T17:28:48.614294Z","iopub.status.idle":"2022-06-23T17:29:06.564085Z","shell.execute_reply.started":"2022-06-23T17:28:48.614199Z","shell.execute_reply":"2022-06-23T17:29:06.562626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Table of Contents:\n1. Setup Environment\n2. Imports\n3. Constants\n4. Read Data\n5. EDA\n6. Dataset and Dataloaders\n7. Model\n8. Training loop\n9. Validation\n10. Inference\n11. Submission Generation","metadata":{}},{"cell_type":"code","source":"import os\nimport copy\nimport time\nfrom datetime import timedelta\nimport random\nimport string\nimport wandb\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom accelerate import Accelerator\nfrom transformers import AutoTokenizer, DataCollatorWithPadding, get_scheduler, \\\n    AutoModelForSequenceClassification\n\ncolors = ['#9B5DE5', '#F15BB5', '#FEE440', '#00BBF9', '#00F5D4']\nsns.palplot(sns.color_palette(colors))\nsns.set_palette(colors)\n\nclass color:\n    '''S from Start & E from End.'''\n    S = '\\033[1m' + '\\033[93m'\n    E = '\\033[0m'\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:06.571177Z","iopub.execute_input":"2022-06-23T17:29:06.574052Z","iopub.status.idle":"2022-06-23T17:29:17.681166Z","shell.execute_reply.started":"2022-06-23T17:29:06.573968Z","shell.execute_reply":"2022-06-23T17:29:17.679748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    # data paths\n    'TRAIN_DIR': os.path.abspath('../input/feedback-prize-effectiveness/train'),\n    'TEST_DIR': os.path.abspath('../input/feedback-prize-effectiveness/test'),\n    'TRAIN_DATA_PATH': os.path.abspath('../input/feedback-prize-effectiveness/train.csv'),\n    'TEST_DATA_PATH': os.path.abspath('../input/feedback-prize-effectiveness/test.csv'),\n    'SAMPLE_SUMISSION_PATH': os.path.abspath('../input/feedback-prize-effectiveness/sample_submission.csv'),\n    \n    # pre-processing\n    'checkpoint': 'microsoft/deberta-v3-base',\n    'max_length': 512,\n    'num_classes': 3,\n    'device': torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n    \n    'batch_size': 8,\n    'seed': 42,\n    'num_epochs': 5,\n    \n    'use_kfold': False,\n    'use_wandb': False,\n    'hash_name': \"\".join(random.SystemRandom().choice(string.ascii_lowercase + string.digits) for _ in range(12))\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:39:33.078697Z","iopub.execute_input":"2022-06-23T17:39:33.07911Z","iopub.status.idle":"2022-06-23T17:39:33.092727Z","shell.execute_reply.started":"2022-06-23T17:39:33.07908Z","shell.execute_reply":"2022-06-23T17:39:33.091505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(config['seed'])\n","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:36.911724Z","iopub.execute_input":"2022-06-23T17:29:36.912283Z","iopub.status.idle":"2022-06-23T17:29:36.922821Z","shell.execute_reply.started":"2022-06-23T17:29:36.912236Z","shell.execute_reply":"2022-06-23T17:29:36.921577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config['use_wandb']:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n    wandb.login(key=api_key)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:40.801089Z","iopub.execute_input":"2022-06-23T17:29:40.801594Z","iopub.status.idle":"2022-06-23T17:29:43.331626Z","shell.execute_reply.started":"2022-06-23T17:29:40.80154Z","shell.execute_reply":"2022-06-23T17:29:43.330566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(config['TRAIN_DATA_PATH'])\ntest_df = pd.read_csv(config['TEST_DATA_PATH'])\ndisplay(df.head())\ndisplay(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:46.700938Z","iopub.execute_input":"2022-06-23T17:29:46.70134Z","iopub.status.idle":"2022-06-23T17:29:47.084947Z","shell.execute_reply.started":"2022-06-23T17:29:46.701308Z","shell.execute_reply":"2022-06-23T17:29:47.08378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_to_id = {}\nid_to_label = {}\n\ntype_to_id = {}\nid_to_type = {}\n\nfor idx, para_label in enumerate(df['discourse_effectiveness'].unique()):\n    label_to_id[para_label] = idx\n    id_to_label[idx] = para_label\n\nfor idx, para_type in enumerate(df['discourse_type'].unique()):\n    type_to_id[para_type] = idx\n    id_to_type[idx] = para_type\n\nprint(label_to_id)\nprint(type_to_id)\n\ndf['discourse_effectiveness'] = df['discourse_effectiveness'].replace(label_to_id)\ndf['discourse_type'] = df['discourse_type'].replace(type_to_id)\ntest_df['discourse_type'] = test_df['discourse_type'].replace(type_to_id)\n\ndisplay(df.head(10))\ndisplay(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:48.15611Z","iopub.execute_input":"2022-06-23T17:29:48.156844Z","iopub.status.idle":"2022-06-23T17:29:48.255429Z","shell.execute_reply.started":"2022-06-23T17:29:48.156809Z","shell.execute_reply":"2022-06-23T17:29:48.25415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type_distribution = df['discourse_effectiveness'].value_counts()\nsns.barplot(x=type_distribution.values, y=list(id_to_label.values()), palette=colors, saturation=0.7)\nplt.title('Discourse Effectiveness Distribution')\nplt.xlabel('Frequency')\nplt.ylabel('Discourse Effectiveness')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:48.982698Z","iopub.execute_input":"2022-06-23T17:29:48.983131Z","iopub.status.idle":"2022-06-23T17:29:49.216836Z","shell.execute_reply.started":"2022-06-23T17:29:48.983083Z","shell.execute_reply":"2022-06-23T17:29:49.215749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discourse_type_distribution = df['discourse_type'].value_counts()\nsns.barplot(\n    x=discourse_type_distribution.values,\n    y=list(id_to_type.values()),\n    palette=colors, saturation=0.7\n)\nplt.title('Discourse Type Distribution')\nplt.xlabel('Frequency')\nplt.ylabel('Discourse Type')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:49.98125Z","iopub.execute_input":"2022-06-23T17:29:49.982609Z","iopub.status.idle":"2022-06-23T17:29:50.230969Z","shell.execute_reply.started":"2022-06-23T17:29:49.98256Z","shell.execute_reply":"2022-06-23T17:29:50.229611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FeedbackDataset(Dataset):\n    \n    def __init__(self, df, tokenizer, is_test=False):\n        self.df = df\n        self.is_test = is_test\n        self.preprocessed_text = tokenizer(\n            df['discourse_text'].values.tolist(),\n            padding = True,\n            truncation = True,\n            add_special_tokens=True,\n            max_length = config['max_length'],\n            return_tensors = 'pt'\n        )\n    \n    def __len__(self):\n        return len(self.preprocessed_text)\n    \n    def __getitem__(self, idx):\n        if self.is_test:\n            return {\n                \"attention_mask\": self.preprocessed_text[\"attention_mask\"][idx],\n                \"input_ids\": self.preprocessed_text[\"input_ids\"][idx]\n            }\n        else:\n            return {\n                \"attention_mask\": self.preprocessed_text[\"attention_mask\"][idx],\n                \"input_ids\": self.preprocessed_text[\"input_ids\"][idx],\n                \"labels\": torch.tensor(self.df['discourse_effectiveness'].values[idx])\n            }","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:50.869582Z","iopub.execute_input":"2022-06-23T17:29:50.869981Z","iopub.status.idle":"2022-06-23T17:29:50.895956Z","shell.execute_reply.started":"2022-06-23T17:29:50.869947Z","shell.execute_reply":"2022-06-23T17:29:50.892825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for batch in dataloader:\n#     break\n# {k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:52.075316Z","iopub.execute_input":"2022-06-23T17:29:52.076219Z","iopub.status.idle":"2022-06-23T17:29:52.080934Z","shell.execute_reply.started":"2022-06-23T17:29:52.076183Z","shell.execute_reply":"2022-06-23T17:29:52.079627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(config['checkpoint'], \n                                                           num_labels=len(id_to_type.keys())).to(config['device'])\n\noutputs = model(**batch)\nprint(outputs.loss, outputs.logits.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:29:53.405008Z","iopub.execute_input":"2022-06-23T17:29:53.405393Z","iopub.status.idle":"2022-06-23T17:30:17.72156Z","shell.execute_reply.started":"2022-06-23T17:29:53.405363Z","shell.execute_reply":"2022-06-23T17:30:17.719675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def step(model, dataset, dataloader, criterion, optimizer, scheduler=None, mode='train'):\n    if mode == 'train':\n        model.train()\n    else:\n        model.eval()\n    \n    running_loss = 0.0\n    running_correct = 0\n    total = 0\n    \n    for data in tqdm(dataloader, total=len(dataloader)):\n        input_ids = data['input_ids'].to(config['device'])\n        attention_masks = data['attention_mask'].to(config['device'])\n        targets = data['labels'].to(config['device'])\n        \n        outputs = model(input_ids, attention_masks)\n        \n        loss = criterion(outputs.logits, targets)\n        running_loss += loss.item()\n        loss.backward()\n        \n        _, preds = torch.max(outputs.logits, 1)\n        running_correct += (preds == targets).sum().item()\n        total += targets.size(0)\n\n        # adjust parameters based on the calculated gradients\n        if mode == 'train':\n            optimizer.step()\n            optimizer.zero_grad()\n        \n            if scheduler is not None:\n                scheduler.step()\n\n    loss = running_loss/total\n    accuracy = 100. * running_correct/total\n    \n    #gc.collect()\n\n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:36:26.567224Z","iopub.execute_input":"2022-06-23T17:36:26.567798Z","iopub.status.idle":"2022-06-23T17:36:27.674292Z","shell.execute_reply.started":"2022-06-23T17:36:26.567753Z","shell.execute_reply":"2022-06-23T17:36:27.673037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config['use_wandb']:\n    run = wandb.init(\n        project='Feedback Effectiveness Competition',\n        entity=\"raghavprabhakar\",\n        config=config,\n        job_type='Train'\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:30:18.379563Z","iopub.execute_input":"2022-06-23T17:30:18.380023Z","iopub.status.idle":"2022-06-23T17:30:31.441413Z","shell.execute_reply.started":"2022-06-23T17:30:18.379992Z","shell.execute_reply":"2022-06-23T17:30:31.440155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not config['use_kfold']:\n    train_df, valid_df = train_test_split(df, test_size=0.2, random_state=config['seed'])\n    print(train_df.shape)\n    print(valid_df.shape)\n\ntokenizer = AutoTokenizer.from_pretrained(config['checkpoint'])\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntrain_dataset = FeedbackDataset(train_df, tokenizer)\nvalid_dataset = FeedbackDataset(valid_df, tokenizer)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=data_collator)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, collate_fn=data_collator)\n\ncriterion = nn.CrossEntropyLoss()\n\nnum_training_steps = config['num_epochs'] * len(train_dataloader)\n\noptimizer = AdamW(model.parameters(), lr=3e-4)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:38:42.387114Z","iopub.execute_input":"2022-06-23T17:38:42.387547Z","iopub.status.idle":"2022-06-23T17:39:16.847007Z","shell.execute_reply.started":"2022-06-23T17:38:42.387491Z","shell.execute_reply":"2022-06-23T17:39:16.845939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = {\n    'train_loss': [],\n    'train_acc': [], \n    'valid_loss': [],\n    'valid_acc': []\n}\n\ntrainig_start_time = time.time()\nbest_model_weights = copy.deepcopy(model.state_dict())\nbest_epoch_loss = np.inf\n\nfor epoch in range(config['num_epochs']):\n    train_epoch_loss, train_epoch_acc = step(model, train_dataset, train_dataloader, criterion, optimizer, lr_scheduler, mode='train')\n    valid_epoch_loss, valid_epoch_acc = step(model, valid_dataset, valid_dataloader, criterion, optimizer, lr_scheduler, mode='valid')\n    \n    print('Train Loss: {:.5f} | Train Accuracy: {:.5f}'.format(train_epoch_loss, train_epoch_acc))\n    print('Valid Loss: {:.5f} | Valid Accuracy: {:.5f}'.format(train_epoch_loss, train_epoch_acc))\n    \n    history['train_loss'].append(train_epoch_loss)\n    history['train_acc'].append(train_epoch_acc)\n    history['valid_loss'].append(valid_epoch_loss)\n    history['valid_acc'].append(valid_epoch_loss)\n    \n    if config['use_wandb']:\n        wandb.log({\n            \"Train Loss\": train_epoch_loss,\n            \"Valid Loss\": valid_epoch_loss,\n            \"Train Accuracy\": train_epoch_acc,\n            \"Valid Accuracy\": valid_epoch_acc\n        })\n        wandb.watch(model)\n    \n    if valid_epoch_loss <= best_epoch_loss:\n        print(f\"Validation Loss Improved ({best_epoch_loss} ---> {valid_epoch_loss})\")\n        best_epoch_loss = valid_epoch_loss\n        run.summary[\"Best Loss\"] = best_epoch_loss\n        best_model_wts = copy.deepcopy(model.state_dict())\n        PATH = f\"deberta-epoch-{epoch}.pt\"\n        torch.save(model.state_dict(), PATH)\n        print(f\"Model Saved\\n\")\n\ntraining_end_time = time.time()\ntraining_duration = training_end_time - trainig_start_time\n\nprint(f'Training complete in {timedelta(training_duration)}')\nprint(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n\nif config['use_wandb']: run.finish()","metadata":{"execution":{"iopub.status.busy":"2022-06-23T17:39:37.198256Z","iopub.execute_input":"2022-06-23T17:39:37.19869Z","iopub.status.idle":"2022-06-23T17:39:37.952668Z","shell.execute_reply.started":"2022-06-23T17:39:37.198659Z","shell.execute_reply":"2022-06-23T17:39:37.951027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}