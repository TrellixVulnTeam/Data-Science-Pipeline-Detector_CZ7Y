{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install 'git+https://github.com/PyTorchLightning/lightning-flash.git#egg=lightning-flash[text]' -q","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:46:57.39547Z","iopub.execute_input":"2021-12-16T16:46:57.39585Z","iopub.status.idle":"2021-12-16T16:47:41.812639Z","shell.execute_reply.started":"2021-12-16T16:46:57.395761Z","shell.execute_reply":"2021-12-16T16:47:41.811816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from flash import Trainer\nfrom flash.text import QuestionAnsweringData, QuestionAnsweringTask\nfrom flash.text.question_answering.input import QuestionAnsweringInputBase, QuestionAnsweringDictionaryInput\nimport pandas as pd\nimport json\nfrom typing import Union","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:47:41.814482Z","iopub.execute_input":"2021-12-16T16:47:41.814753Z","iopub.status.idle":"2021-12-16T16:47:51.865811Z","shell.execute_reply.started":"2021-12-16T16:47:41.814717Z","shell.execute_reply":"2021-12-16T16:47:51.865026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load short and long answers","metadata":{}},{"cell_type":"code","source":"def load_data(file_path, questions_start, questions_end, short_answer=True):\n    ids = []\n    titles = []\n    contexts = []\n    questions = []\n    answers = []\n    \n    with open(file_path) as file:\n        for i in range(questions_start, questions_end):\n            line = json.loads(file.readline())\n            result = process_data(line, short_answer)\n            if result:\n                id_, title, context, question, answer = result\n                if answer:\n                    ids.append(id_)\n                    titles.append(title)\n                    contexts.append(context)\n                    questions.append(question)\n                    answers.append(answer['text'])\n                    \n    data = {\"id\": ids, \"title\": titles, \"context\": contexts, \"question\": questions, \"answer\": answers}\n    \n    return pd.DataFrame(data)\n                \ndef process_data(entry, short_answer=True):\n    question = entry['question_text']\n    text = entry['document_text'].split(' ')\n    annotations = entry['annotations'][0]\n    id_ = entry['example_id']\n\n    for i, candidate in enumerate(entry['long_answer_candidates']):\n        isThereIndex = True if i == annotations['long_answer']['candidate_index'] else False\n        long_start = candidate['start_token']\n        long_end = candidate['end_token']\n        if isThereIndex:\n            short_start = 0 \n            short_end = 0\n            if len(annotations['short_answers']) > 0:\n                short_start = annotations['short_answers'][0]['start_token']\n                short_end = annotations['short_answers'][0]['end_token']\n\n                short_start = short_start - long_start\n                short_end = short_end - long_start\n            long_answer = ' '.join(text[long_start:long_end])\n            short_answer = ' '.join(long_answer.split(' ')[short_start:short_end])\n            if short_answer:\n                return (id_, '', ' '.join(text), question, {\"text\": short_answer, \"answer_start\": [short_start]})\n            else:\n                return (id_, '', ' '.join(text), question, {\"text\": long_answer, \"answer_start\": [long_start]})","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:48:38.203379Z","iopub.execute_input":"2021-12-16T16:48:38.203852Z","iopub.status.idle":"2021-12-16T16:48:38.216231Z","shell.execute_reply.started":"2021-12-16T16:48:38.203815Z","shell.execute_reply":"2021-12-16T16:48:38.215419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_data('../input/tensorflow2-question-answering/simplified-nq-train.jsonl', 0, 5, short_answer=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:48:38.723717Z","iopub.execute_input":"2021-12-16T16:48:38.723993Z","iopub.status.idle":"2021-12-16T16:48:38.743426Z","shell.execute_reply.started":"2021-12-16T16:48:38.723959Z","shell.execute_reply":"2021-12-16T16:48:38.742562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_data('../input/tensorflow2-question-answering/simplified-nq-train.jsonl', 0, 5, short_answer=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:48:40.161479Z","iopub.execute_input":"2021-12-16T16:48:40.162311Z","iopub.status.idle":"2021-12-16T16:48:40.181081Z","shell.execute_reply.started":"2021-12-16T16:48:40.162265Z","shell.execute_reply":"2021-12-16T16:48:40.180282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://github.com/PyTorchLightning/lightning-flash/blob/052ed5299ac08e0cf94fa5b1697d64a97bbbe06e/flash/text/question_answering/input.py#L292\n# SQUAD data","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:48:45.001333Z","iopub.execute_input":"2021-12-16T16:48:45.001592Z","iopub.status.idle":"2021-12-16T16:48:45.005537Z","shell.execute_reply.started":"2021-12-16T16:48:45.001564Z","shell.execute_reply":"2021-12-16T16:48:45.004765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using flash","metadata":{}},{"cell_type":"code","source":"class QuestionAnsweringTFInput(QuestionAnsweringDictionaryInput):\n    \n    def _process_data(self, entry, short_answer=True):\n        question = entry['question_text']\n        text = entry['document_text'].split(' ')\n        annotations = entry['annotations'][0]\n        id_ = entry['example_id']\n\n        for i, candidate in enumerate(entry['long_answer_candidates']):\n            isThereIndex = True if i == annotations['long_answer']['candidate_index'] else False\n            long_start = candidate['start_token']\n            long_end = candidate['end_token']\n            if isThereIndex:\n                short_start = 0 \n                short_end = 0\n                if len(annotations['short_answers']) > 0:\n                    short_start = annotations['short_answers'][0]['start_token']\n                    short_end = annotations['short_answers'][0]['end_token']\n\n                    short_start = short_start - long_start\n                    short_end = short_end - long_start\n                long_answer = ' '.join(text[long_start:long_end])\n                short_answer = ' '.join(long_answer.split(' ')[short_start:short_end])\n                if short_answer:\n                    return (id_, '', ' '.join(text), question, {\"text\": short_answer, \"answer_start\": [short_start]})\n                else:\n                    return (id_, '', ' '.join(text), question, {\"text\": long_answer, \"answer_start\": [long_start]})\n            \n    def load_data(\n        self,\n        json_file,\n        max_source_length: int = 384,\n        max_target_length: int = 30,\n        padding: Union[str, bool] = \"max_length\",\n        question_column_name: str = \"question\",\n        context_column_name: str = \"context\",\n        answer_column_name: str = \"answer\",\n        doc_stride: int = 128,\n        **kws\n    ):\n        ids = []\n        titles = []\n        contexts = []\n        questions = []\n        answers = []\n        \n        with open(json_file) as stream:\n            for i in range(0, 5):\n                line = json.loads(stream.readline())\n                result = self._process_data(line, short_answer=True)\n                if result:\n                    id_, title, context, question, answer = result\n                    if answer:\n                        ids.append(id_)\n                        titles.append(title)\n                        contexts.append(title)\n                        questions.append(question)\n                        answers.append(answer)\n\n        data = {\"id\": ids, \"title\": titles, \"context\": contexts, \"question\": questions, \"answer\": answers}\n\n        return super().load_data(\n            data,\n            max_source_length=max_source_length,\n            max_target_length=max_target_length,\n            padding=padding,\n            question_column_name=question_column_name,\n            context_column_name=context_column_name,\n            answer_column_name=answer_column_name,\n            doc_stride=doc_stride,\n        )","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:49:59.181923Z","iopub.execute_input":"2021-12-16T16:49:59.182435Z","iopub.status.idle":"2021-12-16T16:49:59.201394Z","shell.execute_reply.started":"2021-12-16T16:49:59.182396Z","shell.execute_reply":"2021-12-16T16:49:59.200591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Create the DataModule\ndatamodule = QuestionAnsweringData.from_json(\n    train_file='../input/tensorflow2-question-answering/simplified-nq-train.jsonl',\n    input_cls=QuestionAnsweringTFInput,\n    batch_size=1,\n    max_source_length=128,\n    doc_stride=64,\n)\n\n# 2. Build the task\nmodel = QuestionAnsweringTask(backbone='distilroberta-base')\n\n# # 3. Create the trainer and finetune the model\ntrainer = Trainer(max_epochs=1, gpus=1, precision=16, limit_train_batches=3, limit_val_batches=0)\ntrainer.fit(model, datamodule=datamodule)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:50:00.615879Z","iopub.execute_input":"2021-12-16T16:50:00.616638Z","iopub.status.idle":"2021-12-16T16:50:01.999314Z","shell.execute_reply.started":"2021-12-16T16:50:00.6166Z","shell.execute_reply":"2021-12-16T16:50:01.997612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}