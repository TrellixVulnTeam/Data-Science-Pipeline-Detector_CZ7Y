{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this kernel\n\nThis is the inference kernel for my previous kernel, [TF2 QA: LSTM for long answers predictions](https://www.kaggle.com/xhlulu/tf2-qa-lstm-for-long-answers-predictions). "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import text, sequence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_test(test_path):\n    with open(test_path) as f:\n        processed_rows = []\n\n        for line in tqdm(f):\n            line = json.loads(line)\n\n            text = line['document_text'].split(' ')\n            question = line['question_text']\n            example_id = line['example_id']\n\n            for candidate in line['long_answer_candidates']:\n                start = candidate['start_token']\n                end = candidate['end_token']\n\n                processed_rows.append({\n                    'text': \" \".join(text[start:end]),\n                    'question': question,\n                    'example_id': example_id,\n                    'PredictionString': f'{start}:{end}'\n\n                })\n\n        test = pd.DataFrame(processed_rows)\n    \n    return test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Test dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"directory = '/kaggle/input/tensorflow2-question-answering/'\ntest_path = directory + 'simplified-nq-test.jsonl'\ntest = build_test(test_path)\nsubmission = pd.read_csv(\"../input/tensorflow2-question-answering/sample_submission.csv\")\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Infer using trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_text_and_questions(test, tokenizer):\n    test_text = tokenizer.texts_to_sequences(test.text.values)\n    test_questions = tokenizer.texts_to_sequences(test.question.values)\n    \n    test_text = sequence.pad_sequences(test_text, maxlen=300)\n    test_questions = sequence.pad_sequences(test_questions)\n    \n    return test_text, test_questions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Model and Tokenizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model('/kaggle/input/tf-qa-new-start/model.h5')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/tf-qa-new-start/tokenizer.pickle', 'rb') as f:\n    tokenizer = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load test text and q's"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_text, test_questions = compute_text_and_questions(test, tokenizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test['text']\ndel test['question']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_target = model.predict([test_text, test_questions], batch_size=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['target'] = test_target\n\nresult = (\n    test.query('target > 0.3')\n    .groupby('example_id')\n    .max()\n    .reset_index()\n    .loc[:, ['example_id', 'PredictionString']]\n)\n\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.concat([\n    result.assign(example_id=lambda example_id: example_id + '_long'),\n    result.assign(example_id=lambda example_id: example_id + '_short')\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission = (\n    submission.drop(columns='PredictionString')\n    .merge(result, on=['example_id'], how='left')\n)\n\nfinal_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}