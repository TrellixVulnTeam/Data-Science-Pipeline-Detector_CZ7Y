{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom tqdm import tqdm\nfrom glob import glob\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport shutil\n\nimport torch\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.nn as nn\nimport albumentations\nimport torchvision \nfrom torchvision import transforms, models\n\nimport random\nfrom skimage import io,transform\nfrom PIL import Image\n\nimport warnings \n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT = \"../input/ultrasound-nerve-segmentation/\"\ntrainpath = \"../input/ultrasound-nerve-segmentation/train/\"\ntestpath = \"../input/ultrasound-nerve-segmentation/test/\"\n\nmasks = [os.path.join(trainpath,i) for i in os.listdir(trainpath) if \"mask\" in i]\nimgs = [i.replace(\"_mask\",\"\") for i in masks]\n\ndf = pd.DataFrame({\"Image\":imgs,\"Mask\":masks})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\n\ndef makesplits(df,k):\n    df[\"kfold\"] = -1\n    df = df.sample(frac=1).reset_index(drop=True)\n    kf = model_selection.KFold(n_splits=k)\n\n    for f,(t_,v_) in enumerate(kf.split(df)):\n        df.loc[v_,\"kfold\"] = f\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"kfold_ = makesplits(df,5)\nkfold_.to_csv(\"Kfolds.csv\",index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainaugs():\n    transform =  [\n                albumentations.HorizontalFlip(),\n                albumentations.VerticalFlip()\n            ]\n    return albumentations.Compose(transform)\n\ndef valaugs():\n    transform = [\n                albumentations.HorizontalFlip(),\n                albumentations.VerticalFlip()\n            ]\n    return albumentations.Compose(transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NerveDataset(Dataset):\n    def __init__(self,imagespath,maskspath,augment=None):\n        self.imagespath = imagespath\n        self.maskspath = maskspath\n        self.augment = augment\n        \n    def __len__(self):\n        return len(self.imagespath)\n    \n    def __getitem__(self,idx):\n        image = self.imagespath[idx]\n        mask = self.maskspath[idx]\n        image = io.imread(image)\n        mask = io.imread(mask)\n        image = transform.resize(image=image,output_shape=(256,256,3)) # (256,256,3)\n        image = image/255.0\n        mask = transform.resize(mask,(256,256))  # (256,256,1)\n        mask = mask / 255.0\n        \n        if self.augment:\n            sample = self.augment(image=image, mask=mask)\n            image,mask = sample['image'],sample['mask']\n            \n        image = image.transpose((2, 0, 1)) # (3,256,256)\n        mask = np.expand_dims(mask,axis=-1).transpose((2,0,1)) # (1,256,256)\n            \n        image = torch.from_numpy(image)\n        mask = torch.from_numpy(mask)\n            \n        return image,mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms, utils\nfrom torch import nn\n\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\n\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self,in_channels,out_channels,kernel_size=(3,3),padding=1):\n        super(ConvBlock,self).__init__()\n        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size,padding=padding,bias=False)\n        self.batchnorm = nn.BatchNorm2d(out_channels,eps=1e-4)\n        self.relu = nn.ReLU(inplace=True)\n        \n    def forward(self,x):\n        x = self.conv(x)\n        x = self.batchnorm(x)\n        x = self.relu(x)\n        return x\n        \n        \nclass StackEncoder(nn.Module):\n    def __init__(self,channel1,channel2,kernel_size=(3,3),padding=1):\n        super(StackEncoder,self).__init__()\n        self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n        self.block = nn.Sequential(\n            ConvBlock(channel1,channel2,kernel_size,padding),\n            ConvBlock(channel2,channel2,kernel_size,padding),     \n        )\n        \n    def forward(self,x):\n        big_out = self.block(x)\n        poolout = self.maxpool(big_out)\n        return big_out,poolout\n    \nclass StackDecoder(nn.Module):\n    def __init__(self,big_channel,channel1,channel2,kernel_size=(3,3),padding=1):\n        super(StackDecoder,self).__init__()\n        self.block = nn.Sequential(\n            ConvBlock(channel1+big_channel,channel2,kernel_size,padding),\n            ConvBlock(channel2,channel2,kernel_size,padding),\n            ConvBlock(channel2,channel2,kernel_size,padding),\n        )\n        \n    def forward(self,x,down_tensor):\n            _, channels, height, width = down_tensor.size()  \n            x = F.upsample(x, size=(height, width), mode='bilinear')\n            x = torch.cat([x, down_tensor], 1)  #combining channels of  input from encoder and upsampling input\n            x = self.block(x)\n            return x\n        \n        \nclass Unet256(nn.Module):\n    def __init__(self,input_shape):\n        super(Unet256,self).__init__()\n        \n        channel,height,width = input_shape\n        \n        self.down1 = StackEncoder(channel,12,kernel_size=(3,3))  #256\n        self.down2 = StackEncoder(12,24,kernel_size=(3,3))  # 128\n        self.down3 = StackEncoder(24,46,kernel_size=(3,3))  # 64\n        self.down4 = StackEncoder(46,64,kernel_size=(3,3))  # 32\n        self.down5 = StackEncoder(64,128,kernel_size=(3,3))  #16\n        \n        self.center = ConvBlock(128,128,kernel_size=(3,3),padding=1) #16\n        self.up5 = StackDecoder(128,128,64,kernel_size=(3,3))  #32\n        self.up4 = StackDecoder(64,64,46,kernel_size=(3,3)) #64\n        self.up3 = StackDecoder(46,46,24,kernel_size=(3,3))\n        self.up2 = StackDecoder(24,24,12,kernel_size=(3,3))\n        self.up1 = StackDecoder(12,12,12,kernel_size=(3,3))\n        self.conv = Conv2d(12,1,kernel_size=(1,1),bias=True)\n        \n    def forward(self,x):\n        down1,out = self.down1(x)  \n        down2,out = self.down2(out)  \n        down3,out = self.down3(out)\n        down4,out = self.down4(out)\n        down5,out = self.down5(out)\n        \n        \n        out = self.center(out)\n        \n        up5 = self.up5(out,down5)\n        up4 = self.up4(up5,down4)\n        up3 = self.up3(up4,down3)\n        up2 = self.up2(up3,down2)\n        up1 = self.up1(up2,down1)\n        \n        out = self.conv(up1)\n\n\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DiceBCELoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        bce_weight = 0.5\n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        loss_final = BCE * bce_weight + dice_loss * (1 - bce_weight)\n        return loss_final\n    \n    \n\nclass IoU(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(IoU, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        intersection = (inputs * targets).sum()\n        total = (inputs + targets).sum()\n        union = total - intersection \n        \n        IoU = (intersection + smooth)/(union + smooth)\n                \n        return IoU * 100\n\n    \n    \nclass DiceScore(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceScore, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        intersection = (inputs * targets).sum()                            \n        dice_score = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth) \n        return dice_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom tqdm import tqdm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainfold(fold):\n    train_loss = []\n    train_iou = []\n    train_dice = []\n    val_loss = []\n    val_iou = []\n    val_dice = []\n    epochs = 2\n    train_bs= 8\n    val_bs = 4\n    \n    FILE = f\"./savedmodels/model_Fold_{fold}.pth\"\n    \n    if not os.path.exists(\"./savedmodels\"):\n        os.mkdir(\"savedmodels\")\n        \n    print(f\"*\"*20,\"FOLD\",fold, \"*\"*20)\n    df = pd.read_csv(\"Kfolds.csv\")\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_val = df[df.kfold == fold].reset_index(drop=True)\n    \n    traindata = NerveDataset(imagespath = df_train['Image'].tolist(),\n                            maskspath = df_train['Mask'].tolist(),\n                        augment=trainaugs())\n\n    validationdata = NerveDataset(imagespath = df_val['Image'].tolist(),\n                                maskspath = df_val['Mask'].tolist(),augment=valaugs())\n\n    trainloader = DataLoader(traindata,batch_size = train_bs,shuffle=True)\n    valloader = DataLoader(validationdata,batch_size=val_bs,shuffle=False)\n    \n    model = Unet256((3,256,256)).to(device)\n    iou_ = IoU()\n    criterion = DiceBCELoss()\n    learning_rate = 1e-3\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    \n    for epoch in range(epochs):\n        print('Epoch {}/{}'.format(epoch + 1, epochs))\n        start_time = time.time()\n        running_train_loss = []\n        running_train_iou = []\n\n        tk_train = tqdm(trainloader,total = len(trainloader))\n        for image,mask in tk_train: \n                image = image.to(device,dtype=torch.float)\n                mask = mask.to(device,dtype=torch.float)\n\n                pred_mask = model.forward(image) # forward propogation\n                loss = criterion(pred_mask,mask)\n                iou = iou_(pred_mask,mask)\n                optimizer.zero_grad() # setting gradient to zero\n                loss.backward()\n                optimizer.step()\n                running_train_loss.append(loss.item())\n                running_train_iou.append(iou.item())\n        else:           \n            running_val_loss = []\n            running_val_iou = []\n            \n            with torch.no_grad():\n                tk_val = tqdm(valloader,total = len(valloader))\n                for image,mask in tk_val:\n                        image = image.to(device,dtype=torch.float)\n                        mask = mask.to(device,dtype=torch.float)                            \n                        pred_mask = model.forward(image)\n                        loss = criterion(pred_mask,mask)\n                        iou = iou_(pred_mask,mask)\n                        running_val_loss.append(loss.item())\n                        running_val_iou.append(iou.item())\n\n        epoch_train_loss = np.mean(running_train_loss) \n        print(f'Fold: {fold} <---> Epoch: {epoch + 1} <---> Train DiceBCELoss: {epoch_train_loss}')                       \n        train_loss.append(epoch_train_loss)\n        \n        epoch_val_loss = np.mean(running_val_loss)\n        print(f'Fold: {fold} <---> Epoch: {epoch + 1} <---> Validation DiceBCELoss: {epoch_val_loss}')                                \n        val_loss.append(epoch_val_loss)\n        \n        epoch_train_iou = np.mean(running_train_iou)\n        print(f'Fold: {fold} <---> Epoch: {epoch + 1} <---> Train IOU: {epoch_train_iou}')                                \n        train_iou.append(epoch_train_iou)\n        \n        epoch_val_iou = np.mean(running_val_iou)\n        print(f'Fold: {fold} <---> Epoch: {epoch + 1} <---> Validation IOU: {epoch_val_iou}')                                \n        val_iou.append(epoch_val_iou)\n        \n\n        time_elapsed = time.time() - start_time\n        print('Fold {}: Time Taken: {:.0f}m {:.0f}s'.format(fold,time_elapsed // 60, time_elapsed % 60))\n        \n    torch.save(model.state_dict(), FILE)\n        \n    return train_loss, val_loss,train_iou,val_iou\n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainfold(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def trainfold(fold):\n#     train_loss = []\n#     val_loss = []\n#     epochs = 25\n#     train_bs= 16\n#     val_bs = 8\n#     FILE = f\"./savedmodels/model_Fold_{fold}.pth\"\n    \n#     if not os.path.exists(\"./savedmodels\"):\n#         os.mkdir(\"savedmodels\")\n        \n#     print(f\"*\"*20,\"FOLD\",fold, \"*\"*20)\n#     df = pd.read_csv(\"./Kfolds.csv\")\n#     df_train = df[df.kfold != fold].reset_index(drop=True)\n#     df_val = df[df.kfold == fold].reset_index(drop=True)\n    \n#     traindata = NerveDataset(imagespath = df_train['Image'].tolist(),\n#                             maskspath = df_train['Mask'].tolist(),\n#                         augment=trainaugs())\n\n#     validationdata = NerveDataset(imagespath = df_val['Image'].tolist(),\n#                                 maskspath = df_val['Mask'].tolist(),augment=valaugs())\n\n#     trainloader = DataLoader(traindata,batch_size = train_bs,shuffle=True)\n#     valloader = DataLoader(validationdata,batch_size=val_bs,shuffle=False)\n    \n#     model = Unet256((3,256,256)).to(device)\n#     criterion = DiceBCELoss()\n#     learning_rate = 1e-3\n#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    \n#     for epoch in range(epochs):\n#         print('Epoch {}/{}'.format(epoch + 1, epochs))\n#         start_time = time.time()\n#         running_train_loss = []\n\n#         tk_train = tqdm(trainloader,total = len(trainloader))\n#         for image,mask in tk_train: \n#                 image = image.to(device,dtype=torch.float)\n#                 mask = mask.to(device,dtype=torch.float)\n\n#                 pred_mask = model.forward(image) # forward propogation\n#                 loss = criterion(pred_mask,mask)\n#                 optimizer.zero_grad() # setting gradient to zero\n#                 loss.backward()\n#                 optimizer.step()\n#                 running_train_loss.append(loss.item())\n#         else:           \n#             running_val_loss = []\n            \n#             with torch.no_grad():\n#                 tk_val = tqdm(valloader,total = len(valloader))\n#                 for image,mask in tk_val:\n#                         image = image.to(device,dtype=torch.float)\n#                         mask = mask.to(device,dtype=torch.float)                            \n#                         pred_mask = model.forward(image)\n#                         loss = criterion(pred_mask,mask)\n#                         running_val_loss.append(loss.item())\n\n#         epoch_train_loss = np.mean(running_train_loss) \n#         print(f'Fold: {fold} <---> Epoch: {epoch + 1} <---> Train loss: {epoch_train_loss}')                       \n#         train_loss.append(epoch_train_loss)\n        \n#         epoch_val_loss = np.mean(running_val_loss)\n#         print(f'Fold: {fold} <---> Epoch: {epoch + 1} <---> Validation loss: {epoch_val_loss}')                                \n#         val_loss.append(epoch_val_loss)\n        \n\n#         time_elapsed = time.time() - start_time\n#         print('Fold {}: Time Taken: {:.0f}m {:.0f}s'.format(fold,time_elapsed // 60, time_elapsed % 60))\n        \n#     torch.save(model.state_dict(), FILE)\n        \n#     return train_loss, val_loss\n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}