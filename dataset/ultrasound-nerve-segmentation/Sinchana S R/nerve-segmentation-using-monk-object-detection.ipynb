{"cells":[{"metadata":{},"cell_type":"markdown","source":"# [Monk Object Detection](https://github.com/Tessellate-Imaging/Monk_Object_Detection)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*A one-stop repository for low-code easily-installable object detection pipelines.*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Monk Format\n\n# Dataset Directory Structure\n  \n  \n  root_dir\n  \n      |\n      | \n      |         \n      |----train_img_dir\n      |       |\n      |       |---------img1.jpg\n      |       |---------img2.jpg\n      |                |---------..........(and so on) \n      |\n      |----train_mask_dir\n      |       |\n      |       |---------img1.jpg\n      |       |---------img2.jpg\n      |                |---------..........(and so on)\n      |\n      |----val_img_dir (optional)\n      |       |\n      |       |---------img1.jpg\n      |       |---------img2.jpg\n      |                |---------..........(and so on)\n      |\n      |----val_mask_dir (optional)\n      |       |\n      |       |---------img1.jpg\n      |       |---------img2.jpg\n      |                |---------..........(and so on)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Converting the dataset into MONK format","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Convert .tif image into .jpeg or .png format and also structure the dataset as required","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"! mkdir trainJPEG testJPEG","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! mkdir trainJPEG/trainimg trainJPEG/trainmask testJPEG/testimg testJPEG/testmask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, sys\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for infile in os.listdir(\"/kaggle/input/ultrasound-nerve-segmentation/train/\"):\n    #print(\"file : \" + infile)\n    \n    if infile[-3:] == \"tif\":\n        \n        if infile[-8:-4] == \"mask\":\n            file = \"/kaggle/input/ultrasound-nerve-segmentation/train/\" + infile\n            outfile = \"/kaggle/working/trainJPEG/trainmask/\"+ infile[:-9] + \".jpeg\"\n            im = Image.open(file)\n            out = im.convert(\"RGB\")\n            out.save(outfile, \"JPEG\", quality=100)\n        else:\n            fileImg = \"/kaggle/input/ultrasound-nerve-segmentation/train/\" + infile\n            outfileImg = \"/kaggle/working/trainJPEG/trainimg/\"+ infile[:-3] + \"jpeg\"\n            imImg = Image.open(fileImg)\n            outImg = imImg.convert(\"RGB\")\n            outImg.save(outfileImg, \"JPEG\", quality=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for infile in os.listdir(\"/kaggle/input/ultrasound-nerve-segmentation/test/\"):\n    #print(\"file : \" + infile)\n    \n    if infile[-3:] == \"tif\":\n        \n        if infile[-8:-4] == \"mask\":\n            file = \"/kaggle/input/ultrasound-nerve-segmentation/test/\" + infile\n            outfile = \"/kaggle/working/testJPEG/testmask/\"+ infile[:-9] + \".jpeg\"\n            im = Image.open(file)\n            out = im.convert(\"RGB\")\n            out.save(outfile, \"JPEG\", quality=100)\n        else:\n            fileImg = \"/kaggle/input/ultrasound-nerve-segmentation/test/\" + infile\n            outfileImg = \"/kaggle/working/testJPEG/testimg/\"+ infile[:-3] + \"jpeg\"\n            imImg = Image.open(fileImg)\n            outImg = imImg.convert(\"RGB\")\n            outImg.save(outfileImg, \"JPEG\", quality=100)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nf, axarr = plt.subplots(2,4)\n\nimg1 = cv2.imread('/kaggle/working/trainJPEG/trainimg/10_103.jpeg')\nimg2 = cv2.imread('/kaggle/working/trainJPEG/trainmask/10_103.jpeg')\nimg3 = cv2.imread('/kaggle/working/trainJPEG/trainimg/10_104.jpeg')\nimg4 = cv2.imread('/kaggle/working/trainJPEG/trainmask/10_104.jpeg')\n\nimg5 = cv2.imread('/kaggle/working/trainJPEG/trainimg/10_109.jpeg')\nimg6 = cv2.imread('/kaggle/working/trainJPEG/trainmask/10_109.jpeg')\nimg7 = cv2.imread('/kaggle/working/trainJPEG/trainimg/10_112.jpeg')\nimg8 = cv2.imread('/kaggle/working/trainJPEG/trainmask/10_112.jpeg')\n\naxarr[0,0].imshow(img1)\naxarr[0,1].imshow(img2)\naxarr[1,0].imshow(img3)\naxarr[1,1].imshow(img4)\n\naxarr[0,2].imshow(img5)\naxarr[0,3].imshow(img6)\naxarr[1,2].imshow(img7)\naxarr[1,3].imshow(img8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Installation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Run these commands\n\n* git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git\n\n* cd Monk_Object_Detection/9_segmentation_models/installation\n\nSelect the right requirements file and run\n\ncat requirements_cuda9.0.txt | xargs -n 1 -L 1 pip install","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"! git clone https://github.com/Tessellate-Imaging/Monk_Object_Detection.git","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* For colab use the command below\n\n! cd Monk_Object_Detection/9_segmentation_models/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n\n\n* For Local systems and cloud select the right CUDA version\n\n! cd Monk_Object_Detection/9_segmentation_models/installation && cat requirements_cuda10.0.txt | xargs -n 1 -L 1 pip install","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"! cd Monk_Object_Detection/9_segmentation_models/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training your own segmenter","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/working/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nsys.path.append(\"Monk_Object_Detection/9_segmentation_models/lib/\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from train_segmentation import Segmenter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf = Segmenter();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dir = \"/kaggle/working/trainJPEG/trainimg/\";\nmask_dir = \"/kaggle/working/trainJPEG/trainmask/\";","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes_dict = {\n    'background': 0, \n    'nerves': 1,\n};\nclasses_to_train = ['background', 'nerves'];","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Train_Dataset(img_dir, mask_dir, classes_dict, classes_to_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dir = \"/kaggle/working/testJPEG/testimg/\";\nmask_dir = \"/kaggle/working/testJPEG/testmask/\";","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Val_Dataset(img_dir, mask_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.List_Backbones();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Data_Params(batch_size=2, backbone=\"efficientnetb3\", image_shape=[580, 420])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.List_Models();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Model_Params(model=\"Linknet\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Params","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Train_Params(lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Setup();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Train(num_epochs=5);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Visualize_Training_History();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from infer_segmentation import Infer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf = Infer();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes_dict = {\n    'background': 0, \n    'nerves': 1,\n};\nclasses_to_train = ['nerves'];","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Data_Params(classes_dict, classes_to_train, image_shape=[580, 420])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Model_Params(model=\"Linknet\", backbone=\"efficientnetb3\", path_to_model='best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Setup();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf.Predict(\"/kaggle/working/trainJPEG/trainimg/10_103.jpeg\", vis=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread(\"/kaggle/working/trainJPEG/trainmask/10_103.jpeg\", 0)\ncv2.imwrite(\"tmp.jpg\", img)\n\nfrom IPython.display import Image\nImage(filename=\"tmp.jpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# [Tessellate Imaging](https://www.tessellateimaging.com/)\n\n# Check out \n\n# [Monk AI](https://github.com/Tessellate-Imaging/monk_v1)\n\n*Monk is a low code Deep Learning tool and a unified wrapper for Computer Vision.*\n\n**Monk features**\n\n    - low-code\n    - unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n    - syntax invariant wrapper\n\n**Enables developers**\n\n    - to create, manage and version control deep learning experiments\n    - to compare experiments across training metrics\n    - to quickly find best hyper-parameters\n    \n\n# [Monk GUI](https://github.com/Tessellate-Imaging/Monk_Gui)\n\n*A Graphical user Interface for deep learning and computer vision over Monk Libraries*\n\n# [Pytorch Tutorial](https://github.com/Tessellate-Imaging/Pytorch_Tutorial)\n\n*A set of jupyter notebooks on pytorch functions with examples*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# To contribute to Monk AI or Monk Object Detection repository raise an issue in the git-repo or DM us on linkedin\n\n* Abhishek - https://www.linkedin.com/in/abhishek-kumar-annamraju/\n* Akash - https://www.linkedin.com/in/akashdeepsingh01/","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}