{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/qubvel/segmentation_models.pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/Bjarten/early-stopping-pytorch.git esp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision \nfrom torchvision import transforms\n\nimport pandas as pd\nimport numpy as np\nimport os\n\nfrom torchvision import transforms\nfrom PIL import Image\n\nimport segmentation_models_pytorch as smp\nfrom esp.pytorchtools import EarlyStopping\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Kostyl'"},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_checkpoint(self, val_loss, model):\n    import pickle       \n    if self.verbose:\n        self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n    with open(self.path, 'wb') as f:\n        pickle.dump(model, f) # torch.save(model.state_dict(), self.path)\n    self.val_loss_min = val_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EarlyStopping.save_checkpoint = save_checkpoint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_ = '../input/ultrasound-nerve-segmentation'\n\ntrain_path = f'{input_}/train'\ntest_path = f'{input_}/test'\n\ntrain_csv_path = 'train_annotation.csv'\ntest_path = '../input/ultrasound-nerve-segmentation/test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_csv(data_path, out_csv_path, key_word='mask'):\n    to_delete = f'_{key_word}'\n\n    for file_name in os.listdir(data_path):\n        if key_word in file_name:\n            img = file_name.replace(to_delete, '')\n            data = pd.DataFrame([img], index=['img']).transpose()\n            data.insert(0, 'mask', file_name)\n\n        else:                \n            if not os.path.exists(out_csv_path):\n                data.to_csv(out_csv_path, header=True, index=False)\n            else:\n                data.to_csv(out_csv_path, mode='a', header=False, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_csv(data_path=train_path, out_csv_path=train_csv_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        self.df = df\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n       \n        mask = Image.open(os.path.join(self.root_dir, self.df.iloc[idx, 0]))\n        image = Image.open(os.path.join(self.root_dir, self.df.iloc[idx, 1]))  \n    \n        if self.transform:\n            return self.transform(image), self.transform(mask)\n    \n        return image, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(train_csv_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples = ImageDataset(df=train_df, root_dir=train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_samples(data, n_col, n_row):\n    fig = plt.figure(figsize=(15, 5))\n        \n    for i in range(1, n_col + 1):\n        img_ax = fig.add_subplot(n_row, n_col, i)\n        msk_ax = fig.add_subplot(n_row, n_col, i + n_col)\n        \n        img_ax.imshow(data[i-1][0], cmap='gray')\n        msk_ax.imshow(data[i-1][1], cmap='gray')\n        \n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_samples(data=train_samples, n_col=5, n_row=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"ENCODER = 'vgg11_bn'\nENCODER_WEIGHTS = 'imagenet'\nACTIVATION = 'sigmoid'\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = smp.Unet(\n    encoder_name=ENCODER,\n    encoder_weights=ENCODER_WEIGHTS,\n    in_channels=1,\n    classes=1,\n    activation=ACTIVATION\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU()]\noptimizer = torch.optim.Adam\nscheduler = lr_scheduler.StepLR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_transforms = transforms.Compose([\n    transforms.Resize(size=(224, 224)),\n    transforms.ToTensor()\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_df(df, fraction=0.8):  \n    df_1 = df.sample(frac=fraction)\n    return df_1, df.drop(df_1.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, train_df, train_dir, optimizer, loss, metrics, \n          learning_rate=0.01, batch_size=20, epochs=10, patience=3,\n          scheduler=None, step_size=5, gamma=0.1, device='cpu', transform=None):   \n    \n    early_stopping = EarlyStopping(patience, path='best_model.pkl', verbose=True)\n    optimizer = optimizer(model.parameters(), learning_rate)\n\n    if scheduler:\n        scheduler = scheduler(optimizer, step_size, gamma) \n\n    train_epoch = smp.utils.train.TrainEpoch(\n        model, loss, metrics, optimizer, device, verbose=True\n    )\n    \n    valid_epoch = smp.utils.train.ValidEpoch(\n        model, loss, metrics, device, verbose=True\n    ) \n    \n    train_logs, valid_logs = [], []\n    \n    for epoch in range(epochs):   \n        train_dataframe, val_dataframe = split_df(train_df) \n          \n        train_dataset = ImageDataset(train_dataframe, train_dir, transform=transform)\n\n        valid_dataset = ImageDataset(val_dataframe, train_dir, transform=transform)\n\n        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                                   batch_size=batch_size, \n                                                   shuffle=True)    \n\n        valid_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                                   batch_size=batch_size, \n                                                   shuffle=False)        \n\n        print(f'\\nEpoch: {epoch+1}/{epochs}')\n\n        train_log = train_epoch.run(train_loader)\n        valid_log = valid_epoch.run(valid_loader)\n        \n        train_logs.append(train_log)\n        valid_logs.append(valid_log)\n   \n        early_stopping(valid_log[loss.__name__], model)\n        \n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n\n        if scheduler:\n            scheduler.step()\n\n    return train_logs, valid_logs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = train(model=model,\n            train_df=train_df, \n            train_dir=train_path, \n            optimizer=optimizer,\n            loss=loss,\n            learning_rate=0.01,\n            metrics=metrics,\n            batch_size=20,\n            epochs=20,\n            scheduler=scheduler,\n            step_size=10,\n            patience=3,\n            device=DEVICE, \n            transform=my_transforms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save results / Load best checkpoint"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('results.pkl', 'wb') as f:\n    pickle.dump(res, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('best_model.pkl', 'rb') as f:\n    best_model = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Draw graphics"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_logs_df = pd.DataFrame(res[0])\nvalid_logs_df = pd.DataFrame(res[1])\n\nres_dict = {'train': train_logs_df, 'valid': valid_logs_df}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_graphic(df_dict, title, criteria, xlab, ylab, colors=['b', 'r'], \n                 legend_loc='best', figsize=(10, 5), fontsize=16):\n    fig = plt.figure(figsize=figsize)\n    for i, key in enumerate(df_dict):\n        plt.plot(df_dict[key].index.tolist(), df_dict[key][criteria].tolist(), colors[i], lw=3, label=key)\n    plt.xlabel(xlab, fontsize=fontsize)\n    plt.ylabel(ylab, fontsize=fontsize)\n    plt.title(title, fontsize=fontsize)\n    plt.legend(loc=legend_loc, fontsize=fontsize)\n    plt.grid()\n    fig.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_graphic(df_dict=res_dict, title='IoU Scores', criteria='iou_score', xlab='epochs', ylab='IoU score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_graphic(df_dict=res_dict, title='Dice Losses', criteria='dice_loss', xlab='epochs', ylab='IoU score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_encoding(x):\n    dots = np.where(x.T.flatten()==1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs = [f for f in os.listdir(test_path)]\nimgs = sorted(imgs, key=lambda s: int(s.split('.')[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_csv_submission(model, data_path, img_list, out_path):\n    submission_df = pd.DataFrame(columns=['img', 'pixels'])\n    model.to(DEVICE)\n    model.eval()\n    \n    for i, img in enumerate(tqdm(img_list)):\n        x = Image.open(os.path.join(data_path, img))\n\n        x = my_transforms(x)\n\n        x = x.unsqueeze(0).to(DEVICE)\n        pred_mask = model.predict(x)\n\n        pred_mask = pred_mask.cpu()#.numpy().round().astype(np.uint8)\n        pred_mask = transforms.Resize(size=(420, 580))(pred_mask)\n\n        encoding = rle_encoding(pred_mask)\n\n        pixels = ' '.join(map(str, encoding))\n        submission_df.loc[i] = [str(i+1), pixels]\n\n    submission_df.to_csv(out_path, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_csv_submission(model=model, \n                      data_path=test_path, \n                      img_list=imgs,\n                      out_path='submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}