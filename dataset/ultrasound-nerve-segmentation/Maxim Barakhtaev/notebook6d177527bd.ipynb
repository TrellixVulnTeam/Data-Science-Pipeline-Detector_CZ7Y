{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from google.colab import drive\ndrive.mount(\"/content/drive\", force_remount=True)","metadata":{"id":"Ky2NmX-CfYPU","outputId":"230aecec-2afd-465b-e624-be3355ca18d0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = \"/content/drive/MyDrive/data/ultrasound-nerve\"\n\n","metadata":{"id":"EzCtttC9fjZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /content/drive/MyDrive/data/ultrasound-nerve-segmentation.zip -d /content/drive/MyDrive/data/ultrasound-nerve/\n","metadata":{"id":"FXzFIHhHqTah"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install segmentation_models_pytorch albumentations && pip install -U git+https://github.com/albu/albumentations --no-cache-dir && pip install pytorch-ignite\n","metadata":{"id":"ya9Mjak9n-01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport os\nimport csv\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport itertools\n\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport shutil\n\nimport torch\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.nn as nn\nimport torchvision \nfrom torchvision import transforms, models\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.handlers import EarlyStopping\nfrom ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\nfrom ignite.contrib.handlers.param_scheduler import LRScheduler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n\nimport segmentation_models_pytorch as smp\nfrom PIL import Image\n\ntrainpath = f\"{root_dir}/train/\"\ntestpath = f\"{root_dir}/test/\"\n\nmasks = [os.path.join(trainpath,i) for i in os.listdir(trainpath) if \"mask\" in i]\nimgs = [i.replace(\"_mask\",\"\") for i in masks]\n\ndf = pd.DataFrame({\"image\":imgs,\"mask\":masks})\ndf_train, df_test = train_test_split(df,test_size = 0.1)\ndf_train, df_val = train_test_split(df_train,test_size = 0.2)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","metadata":{"id":"Dx-PFEP7jHku","outputId":"37d94dfa-7453-4930-fb83-d2af54513ab6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\nrows,cols=3,3\nfig=plt.figure(figsize=(10,10))\nfor i in range(1,rows*cols+1):\n    ii = random.randint(0, len(df))\n    fig.add_subplot(rows,cols,i)\n    img_path=df['image'][ii]\n    msk_path=df['mask'][ii]\n    plt.imshow(np.array(Image.open(img_path)), cmap = 'gray')\n    plt.imshow(np.array(Image.open(msk_path)),alpha=0.4, cmap = 'gray')\nplt.show()","metadata":{"id":"rgGOT8ZSko0A","outputId":"c5bcff39-6ce7-4e12-d759-182875ae6dd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport albumentations as albu\ndef convert_to_tensor(x,**kwargs):\n    return x.transpose(2,0,1).astype(\"float32\")\n\ndef func_for_preprocessing(preprocessing_fn=None):\n    transform = []\n    if preprocessing_fn:\n        transform.append(albu.Lambda(image=preprocessing_fn))\n    transform.append(albu.Lambda(image=convert_to_tensor))\n    return albu.Compose(transform)\n\ndef trainaugs():\n    transform =  [\n                albu.Resize(height=224,width=224,interpolation=Image.BILINEAR),\n                albu.HorizontalFlip(),\n            ]\n    return albu.Compose(transform)\n\ndef valaugs():\n    transform = [\n                albu.Resize(height=224,width=224,interpolation=Image.BILINEAR),\n            ]\n    return albu.Compose(transform)\n\n\nclass GetDataset(Dataset):\n    def __init__(self,imagespath,maskspath,augment=None,preprocess=None):\n        self.imagespath = imagespath\n        self.maskspath = maskspath\n        self.augment = augment\n        self.preprocess = preprocess\n        \n    def __len__(self):\n        return len(self.imagespath)\n    \n    def __getitem__(self,idx):\n        image = cv2.cvtColor(cv2.imread(self.imagespath[idx]),cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.maskspath[idx], cv2.IMREAD_GRAYSCALE)\n\n        if self.augment:\n            sample = self.augment(image=image, mask=mask)\n            image,mask = sample['image'],sample['mask']\n        if self.preprocess:\n            sample = self.preprocess(image=image,mask=mask)\n            image,mask = sample['image'],sample['mask']\n\n        mask = (mask / 255).astype(np.float32)\n        mask = np.expand_dims(mask, axis=0)\n\n        return image,mask\n\nclass Dataset(Dataset):\n    def __init__(self,imagespath,maskspath,augmentation=None,preprocessing=None):\n        self.imagespath = imagespath\n        self.maskspath = maskspath\n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n        \n    def __len__(self):\n        return len(self.imagespath)\n    \n    def __getitem__(self,idx):\n        image = cv2.cvtColor(cv2.imread(self.imagespath[idx]),cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.maskspath[idx], cv2.IMREAD_GRAYSCALE)\n\n        if self.augmentation:\n            sample = self.augmentation(image=image, mask=mask)\n            image,mask = sample['image'],sample['mask']\n        if self.preprocessing:\n            sample = self.preprocessing(image=image,mask=mask)\n            image,mask = sample['image'],sample['mask']\n\n        mask = (mask / 255).astype(np.float32)\n        mask = np.expand_dims(mask, axis=0)\n\n        return image,mask","metadata":{"id":"JWKWApP37WMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = \"resnet18\"\nencoder_wts = \"imagenet\"\nactivation = \"sigmoid\"\n\nmodel = smp.Unet(encoder_name=encoder,activation=activation,encoder_weights=encoder_wts)\n\npreprocess_func = smp.encoders.get_preprocessing_fn(encoder,encoder_wts)\n\ntraindata = GetDataset(imagespath = df_train['image'].tolist(),\n                            maskspath = df_train['mask'].tolist(),\n                            augment = trainaugs(),\n                            preprocess = func_for_preprocessing(preprocess_func))\n\nvalidationdata = GetDataset(imagespath = df_val['image'].tolist(),\n                            maskspath = df_val['mask'].tolist(),\n                            augment = valaugs(),\n                           preprocess = func_for_preprocessing(preprocess_func))\n\nbatch_size = 16\ntrainloader = DataLoader(traindata,batch_size = batch_size,shuffle=True)\nvalloader = DataLoader(validationdata,batch_size=batch_size,shuffle=False)","metadata":{"id":"K0r0fVu5k50L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\ndevice = \"cuda\"\nloss = smp.utils.losses.DiceLoss()\nmetrics = [ smp.utils.metrics.IoU(threshold=0.5) ]\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\nreduce_on_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\ntrainepoch = smp.utils.train.TrainEpoch(model,loss=loss,optimizer=optimizer,metrics=metrics,device=device,verbose=True)\nvalidepoch = smp.utils.train.ValidEpoch(model,loss=loss,metrics=metrics,device=device,verbose=True)","metadata":{"id":"Zbn4QT8_7dy_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_iou_score = 0.0 \ntrain_logs_list, valid_logs_list = [], []\nfor i in range(0,epochs):\n    print('\\nEpoch: {}'.format(i))\n    trainlogs = trainepoch.run(trainloader)\n    validlogs = validepoch.run(valloader)\n    reduce_on_plateau.step(validlogs['iou_score'])\n    \n    train_logs_list.append(trainlogs)\n    valid_logs_list.append(validlogs)\n    if best_iou_score < validlogs['iou_score']:\n        best_iou_score = validlogs['iou_score']\n        torch.save(model, './best_model.pth')\n    if i == 25:\n        optimizer.param_groups[0]['lr'] = 1e-5\n        print('Decrease decoder learning rate to 1e-5!')\nprint(\"Model Training completed successfully !\")","metadata":{"id":"zWWAARW_7fHV","outputId":"6336bd91-1762-4a8e-87f3-f5b023dac9ed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs_df = pd.DataFrame(train_logs_list)\nvalid_logs_df = pd.DataFrame(valid_logs_list)\ntrain_logs_df.T\n\nplt.figure(figsize=(10,4))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(),'g-',lw=3, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(),'r-' ,lw=3, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('IoU Score', fontsize=20)\nplt.title('IoU Score Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.show()\n\nplt.figure(figsize=(10,4))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.dice_loss.tolist(),'g-',lw=3, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.dice_loss.tolist(),'r-' ,lw=3, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('Dice Loss', fontsize=20)\nplt.title('Dice Loss', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.show()","metadata":{"id":"bIN57XSuUyEJ","outputId":"1c2ab21e-48a1-4e5c-e6c0-a396f0ed7e2f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = torch.load('./best_model.pth')\n\ntest_dataset = GetDataset(imagespath = df_test['image'].tolist(),\n                            maskspath = df_test['mask'].tolist(),\n                            augment = valaugs(),\n                           preprocess = func_for_preprocessing(preprocess_func))\n\n\ntest_dataset_vis = GetDataset(imagespath = df_test['image'].tolist(),\n                            maskspath = df_test['mask'].tolist())\n\ndef visualize(**images):\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        if image.shape[0] == 3:\n            image = image.transpose([1, 2, 0])\n        plt.imshow(image)\n    plt.show()\n\nfor i in range(25):\n    n = np.random.choice(len(test_dataset))\n    \n    image_vis = test_dataset_vis[n][0].astype('uint8')\n    mask_vis = test_dataset_vis[n][1].astype('uint8')\n    image, gt_mask = test_dataset[n]\n    \n    gt_mask = gt_mask.squeeze()\n    x_tensor = torch.from_numpy(image).to(device).unsqueeze(0)\n    pr_mask = best_model.predict(x_tensor)\n    pr_mask = pr_mask.squeeze().cpu().numpy().round()\n\n    kernel = np.ones((5,5),np.uint8)\n    pr_mask = cv2.resize(pr_mask, (580, 420))\n    mask_vis = mask_vis.squeeze()\n\n    visualize(\n        image=image_vis, \n        ground_truth_mask=mask_vis, \n        predicted_mask=pr_mask\n    )","metadata":{"id":"njgoCc8QU74a","outputId":"f51de19c-9677-483a-c97f-14ac6b0404d9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encoding(x):\n    dots = np.where(x.T.flatten()==1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\n\nimgs = [f for f in os.listdir(testpath)]\nimgs = sorted(imgs, key=lambda s: int(s.split('.')[0]))\n\nencodings = []\n\nfor m in tqdm(imgs):\n    x = cv2.imread(os.path.join(testpath, m))\n\n    x = valaugs()(image=x)['image']\n    x = func_for_preprocessing(preprocess_func)(image=x)['image']\n\n    x_tensor = torch.from_numpy(x).to(device).unsqueeze(0)\n    pr_mask = best_model.predict(x_tensor)\n\n    pr_mask = pr_mask.squeeze().cpu().numpy().round().astype(np.uint8)\n    pr_mask = albumentations.Resize(height=420,width=580,interpolation=Image.NEAREST)(image=pr_mask)['image']\n\n    encodings.append(rle_encoding(pr_mask))","metadata":{"id":"LoVF1iIMVBca","outputId":"4dd8436e-51a4-46b6-97cb-bfd5f539f48c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('submission.csv', 'w', newline='') as csvfile:\n    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n    spamwriter.writerow([\"img\", \"pixels\"])\n    \n    for i, encoding in enumerate(encodings):\n        spamwriter.writerow([str(i+1), ' '.join(map(str, encoding))])","metadata":{"id":"7UBEOpm-Vzrl"},"execution_count":null,"outputs":[]}]}