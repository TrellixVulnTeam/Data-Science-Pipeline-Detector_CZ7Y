{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Установка полезностей "},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install segmentation_models_pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! git clone https://github.com/Bjarten/early-stopping-pytorch.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! mv ./early-stopping-pytorch ./lib","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Импорты"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Торч\nimport torch\nimport torchvision\nimport segmentation_models_pytorch as smp\nfrom lib.pytorchtools import *\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# Данные\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Картинки\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as mpplot\nfrom PIL import Image\n\n# Разное\nimport math\nimport sys\nimport cv2\nimport time\nimport copy\nimport random\nimport os \nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ход работы"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Фиксируем рандомы\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\ntorch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подготовка данных\ndata_folder = \"/kaggle/input/ultrasound-nerve-segmentation/\"\ntrain_folder = os.path.join(data_folder, \"train\")\ntest_folder = os.path.join(data_folder, \"test\")\n\nmasks = [os.path.join(train_folder, i) for i in os.listdir(train_folder) if \"_mask.tif\" in i]\nimgs = [i.replace(\"_mask\",\"\") for i in masks]\n\ndf = pd.DataFrame({\"images\":imgs,\"masks\":masks})\n\ntrain_df, val_df = train_test_split(df,test_size = 0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создание класса датасета\nclass UltrasoundDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.images = df.images.tolist()\n        self.masks = df.masks.tolist()\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        image_name = self.images[idx]\n        mask_name = self.masks[idx]\n       \n        image = Image.open(image_name)\n        mask = Image.open(mask_name)  \n    \n        if self.transform:\n            image = self.transform(image)\n            mask = self.transform(mask)\n    \n        return image, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создание датасетов и даталоадеров\ntransform = transforms.Compose([\n    transforms.Resize(size=(256, 256)),\n    transforms.ToTensor()\n])\n\nbatch_size = 32\n\ntrain_dataset = UltrasoundDataset(train_df, transform)\nval_dataset = UltrasoundDataset(val_df, transform)\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Используемое устройство: \", device)\nprint('Тренировочный сет:\\n', \"\\tКоличество батчей: \", len(train_dataloader), \"\\n\\tКоличество изображений в датасете: \", len(train_dataset))\nprint('Валидационный сет:\\n', \"\\tКоличество батчей: \", len(val_dataloader), \"\\n\\tКоличество изображений в датасете: \", len(val_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отрисовка изображений\ndef show_overlayed(data, n):\n    fig = plt.figure(figsize=(25, 25))\n        \n    for i in range(1, n + 1):\n        ax = fig.add_subplot(-(-n // 5), 5, i)\n        \n        image = data[i-1][0].permute(1, 2, 0).numpy()\n        mask = data[i-1][1].permute(1, 2, 0).numpy()\n        \n        ax.imshow(image, cmap='gray')\n        ax.imshow(mask, alpha=0.5, cmap='gray')\n       \n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_overlayed(train_dataset, 25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подготовка модели\nencoder = 'densenet161'\nencoder_w = 'imagenet'\nactivation = 'sigmoid'\n\nmodel = smp.Unet(\n    encoder_name=encoder,\n    encoder_weights=encoder_w,\n    in_channels=1,\n    classes=1,\n    activation=activation\n)\n\nloss_function = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU()]\nlearning_rate = 0.001\nepochs = 50\n\nstopper = EarlyStopping(patience=3)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n\ntrain_epoch = smp.utils.train.TrainEpoch(model,\n                                          loss=loss_function,\n                                          optimizer=optimizer,\n                                          metrics=metrics,\n                                          device=device,\n                                          verbose=True)\n\nval_epoch = smp.utils.train.ValidEpoch(model,\n                                          loss=loss_function,\n                                          metrics=metrics,\n                                          device=device,\n                                          verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем\nmodel.to(device)\n\ntrain_loss_history = []\nval_loss_history= []\ntrain_iou_history = []\nval_iou_history = []\n\nfor epoch in range(epochs):\n    print('\\nEpoch: {}'.format(epoch))\n    train_log = train_epoch.run(train_dataloader)\n    val_log = val_epoch.run(val_dataloader)\n\n    scheduler.step()\n\n    train_loss_history.append(train_log[loss_function.__name__])\n    val_loss_history.append(val_log[loss_function.__name__])\n\n    train_iou_history.append(train_log['iou_score']) \n    val_iou_history.append(val_log['iou_score'])\n\n    stopper(val_log[loss_function.__name__], model)\n    if stopper.early_stop:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим на историю обучения \ndef visualize_history(train, val, title):\n    \n    plt.plot(range(len(train)), train, label = 'Train')\n    plt.plot(range(len(val)), val, label = 'Val')\n    \n    plt.ylabel(title)\n    plt.xlabel('epoch')\n    \n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_history(train_loss_history, val_loss_history, 'Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_history(train_iou_history, val_iou_history, 'IoU')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сжимаем\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten()==1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предсказываем маски, сжимаем и записываем в цсв\nimgs = [f for f in os.listdir(test_folder)]\nimgs = sorted( imgs, key=lambda s: int(s.split('.')[0]))\n\nsubmission_df = pd.DataFrame(columns=['img', 'pixels'])\nmodel.to(device)\nmodel.eval()\n\nfor i, img in enumerate(tqdm(imgs)):\n    x = Image.open(os.path.join(test_folder, img))\n\n    x = transform(x)\n\n    x = x.unsqueeze(0).to(device)\n    prediction = model.predict(x)\n\n    prediction = prediction.cpu()\n    prediction = transforms.Resize(size=(420, 580))(prediction)\n\n    encoding = rle_encoding(prediction)\n\n    pixels = ' '.join(map(str, encoding))\n    submission_df.loc[i] = [str(i+1), pixels]\n\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}