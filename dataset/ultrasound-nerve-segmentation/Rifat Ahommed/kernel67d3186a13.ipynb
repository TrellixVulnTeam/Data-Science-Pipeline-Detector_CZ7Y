{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"V000z_TVFFnk","trusted":true,"outputId":"bee415d1-3f82-44f7-b54e-66ed900c2d86"},"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom tqdm import tqdm\nfrom glob import glob\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nK.set_image_data_format('channels_last')","execution_count":null,"outputs":[]},{"metadata":{"id":"H36EHCoUFFoL"},"cell_type":"markdown","source":"## Building the training dataset.\nLet's look at the train image list","execution_count":null},{"metadata":{"_kg_hide-output":false,"id":"5IQvMMbEFFoO","trusted":true,"outputId":"daffa930-8ec1-45d8-ab59-abf26f66a147"},"cell_type":"code","source":"path = \"../input/ultrasound-nerve-segmentation/train/\"\nfile_list = os.listdir(path)\nfile_list[:20]","execution_count":null,"outputs":[]},{"metadata":{"id":"w0rkSYxsFFoc"},"cell_type":"markdown","source":"**Sort the file list in ascending order and seperate it into images and masks**<br/>\nEach file has the form of either \"subject_imageNum.tif\" or \"subject_imageNum_mask.tif\", so we can extract `subject` and `imageNum` from each file name by using regular expression. `\"[0-9]+\"` means to find the first consecutive number.<br/>","execution_count":null},{"metadata":{"id":"UiEiHaJHFFor","trusted":true,"outputId":"4308a5f1-6043-408c-9ccc-e226f7ec93a4"},"cell_type":"code","source":"train_image = []\ntrain_mask = glob(path + '*_mask*')\n\nfor i in train_mask:\n    train_image.append(i.replace('_mask', ''))\n        \nprint(train_image[:10],\"\\n\" ,train_mask[:10])","execution_count":null,"outputs":[]},{"metadata":{"id":"hjv-upiCFFo3","trusted":true,"outputId":"07eee35d-1a8f-4e10-96a1-4c328ed33e7b"},"cell_type":"code","source":"# Display the first image and mask of the first subject.\nimage1 = np.array(Image.open(path+\"1_1.tif\"))\nimage1_mask = np.array(Image.open(path+\"1_1_mask.tif\"))\nimage1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n\nfig, ax = plt.subplots(1,3,figsize = (16,12))\nax[0].imshow(image1, cmap = 'gray')\n\nax[1].imshow(image1_mask, cmap = 'gray')\n\nax[2].imshow(image1, cmap = 'gray', interpolation = 'none')\nax[2].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)","execution_count":null,"outputs":[]},{"metadata":{"id":"fxk0ICSrFFpD"},"cell_type":"markdown","source":"Now, I try to load all image files and store them variables X and y. Afther doing this, I recognize that it takes very much memory.<br/>\nPlease let me know if there are several efficient ways to store image file","execution_count":null},{"metadata":{"id":"31B8z8M9FFpF"},"cell_type":"markdown","source":"## How to deal with train_masks.csv ?","execution_count":null},{"metadata":{"id":"YPvr7aOOFFpQ","trusted":true},"cell_type":"code","source":"width = 128\nheight = 128","execution_count":null,"outputs":[]},{"metadata":{"id":"FQhxK5L0FFps"},"cell_type":"markdown","source":"Let's check that I did well","execution_count":null},{"metadata":{"id":"F21ZRTvPFFpu"},"cell_type":"markdown","source":"Let's modularize this work.","execution_count":null},{"metadata":{"id":"Gpbv3Zc4FFqi","trusted":true},"cell_type":"code","source":"from keras.models import Model, Input, load_model\nfrom keras.layers import Input, Activation, BatchNormalization\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"id":"xyAgRz_tFFqp","trusted":true},"cell_type":"code","source":"smooth = 1.\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true) + K.sum(y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac","execution_count":null,"outputs":[]},{"metadata":{"id":"z8oVv_j7uEJX","trusted":false},"cell_type":"code","source":"def unet_wobn(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","execution_count":null,"outputs":[]},{"metadata":{"id":"M_d0LZZj3zOz","trusted":true},"cell_type":"code","source":"def unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(32, (3, 3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(32, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(64, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(64, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(128, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(128, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(256, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(256, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(512, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(512, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(256, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(128, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(64, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(32, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","execution_count":null,"outputs":[]},{"metadata":{"id":"IEX0f8GhFFq3","trusted":true},"cell_type":"code","source":"def train_generator(data_frame, batch_size, train_path, aug_dict,\n        image_color_mode=\"grayscale\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n    '''\n    can generate image and mask at the same time use the same seed for\n    image_datagen and mask_datagen to ensure the transformation for image\n    and mask is the same if you want to visualize the results of generator,\n    set save_to_dir = \"your path\"\n    '''\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        directory = train_path,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        directory = train_path,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img / 255\n    mask = mask / 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"zO4WD60TQ_HL"},"cell_type":"code","source":"pos_mask = []\npos_img = []\nneg_mask = []\nneg_img = []\n\nfor mask_path, img_path in zip(train_mask, train_image):\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    if np.sum(mask) == 0:\n        neg_mask.append(mask_path)\n        neg_img.append(img_path)\n    else:\n        pos_mask.append(mask_path)\n        pos_img.append(img_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"YGNJWh6ZQ_HW"},"cell_type":"code","source":"!mkdir generated\n!mkdir generated/img","execution_count":null,"outputs":[]},{"metadata":{"id":"_vN5uEKUjzeK","trusted":false},"cell_type":"code","source":"def flip_up_down(img):\n    newImg = img.copy()\n    return cv2.flip(newImg, 0)\n\ndef flip_right_left(img):\n    newImg = img.copy()\n    return cv2.flip(newImg, 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"bL-tRF1DhR-J","outputId":"d4551879-7c9b-4a23-c2ec-57d7acf9569a","trusted":false},"cell_type":"code","source":"gen_img = []\ngen_mask = []\n\nfor (img_path, mask_path) in tqdm(zip(pos_img, pos_mask)):\n    image_name = img_path.split('/')[-1].split('.')[0]\n\n    uf_img_path = 'generated/img/'+image_name+'_uf.jpg'\n    uf_mask_path = 'generated/img/'+image_name+'_uf_mask.jpg'\n    rf_img_path = 'generated/img/'+image_name+'_rf.jpg'\n    rf_mask_path = 'generated/img/'+image_name+'_rf_mask.jpg'\n\n    img = cv2.imread(img_path)\n    mask = cv2.imread(mask_path)\n\n    uf_img = flip_up_down(img)\n    uf_mask = flip_up_down(mask)\n    rf_img = flip_right_left(img)\n    rf_mask = flip_right_left(mask)\n\n    cv2.imwrite(uf_img_path, uf_img)\n    cv2.imwrite(uf_mask_path, uf_mask)\n    cv2.imwrite(rf_img_path, rf_img)\n    cv2.imwrite(rf_mask_path, rf_mask)\n    \n    gen_img.append(uf_img_path)\n    gen_mask.append(uf_mask_path)\n    gen_img.append(rf_img_path)\n    gen_mask.append(rf_mask_path)","execution_count":null,"outputs":[]},{"metadata":{"id":"dXlzh9nwFFq_","trusted":true},"cell_type":"code","source":"aug_img = gen_img + train_image\naug_mask = gen_mask + train_mask\n\ndf_ = pd.DataFrame(data={\"filename\": aug_img, 'mask' : aug_mask})\ndf = df_.sample(frac=1).reset_index(drop=True)\n\nkf = KFold(n_splits = 5, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZlGRbdQ2FFrG","trusted":false,"outputId":"df302092-24a0-436f-96f2-db94c872a40f"},"cell_type":"code","source":"histories = []\nlosses = []\naccuracies = []\ndicecoefs = []\nious = []\n\ntrain_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\n\nEPOCHS = 20\nBATCH_SIZE = 32\n\nfor k, (train_index, test_index) in enumerate(kf.split(df)):\n    train_data_frame = df.iloc[train_index]\n    test_data_frame = df.iloc[test_index]\n    \n    train_gen = train_generator(train_data_frame, BATCH_SIZE,\n                                None,\n                                train_generator_args,\n                                target_size=(height, width))\n\n    test_gener = train_generator(test_data_frame, BATCH_SIZE,\n                                None,\n                                dict(),\n                                target_size=(height, width))\n\n    model = unet(input_size=(height,width, 1))\n    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, \\\n                      metrics=[iou, dice_coef, 'binary_accuracy'])\n\n    model_checkpoint = ModelCheckpoint(str(k+1) + '_unet_ner_seg.hdf5', \n                                       verbose=1, \n                                       save_best_only=True)\n\n    history = model.fit_generator(train_gen,\n                                  steps_per_epoch=len(train_data_frame) / BATCH_SIZE, \n                                  epochs=EPOCHS, \n                                  callbacks=[model_checkpoint],\n                                  validation_data = test_gener,\n                                  validation_steps=len(test_data_frame) / BATCH_SIZE)\n    \n    model = load_model(str(k+1) + '_unet_ner_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})\n    \n    test_gen = train_generator(test_data_frame, BATCH_SIZE,\n                                None,\n                                dict(),\n                                target_size=(height, width))\n    results = model.evaluate_generator(test_gen, steps=len(test_data_frame))\n    results = dict(zip(model.metrics_names,results))\n    \n    histories.append(history)\n    accuracies.append(results['binary_accuracy'])\n    losses.append(results['loss'])\n    dicecoefs.append(results['dice_coef'])\n    ious.append(results['iou'])\n\n    # dev purpose \n    break","execution_count":null,"outputs":[]},{"metadata":{"id":"JG6XfYBQFFrO","trusted":false,"outputId":"27721406-b993-4fd5-c92b-450f6b41e4a9"},"cell_type":"code","source":"for h, history in enumerate(histories):\n\n    keys = history.history.keys()\n    fig, axs = plt.subplots(1, 4, figsize = (25, 5))\n    fig.suptitle('No. ' + str(h+1) + ' Fold Results', fontsize=30)\n\n    for k, key in enumerate(list(keys)[len(keys)//2:]):\n        training = history.history[key]\n        validation = history.history['val_' + key]\n\n        epoch_count = range(1, len(training) + 1)\n\n        axs[k].plot(epoch_count, training, 'r--')\n        axs[k].plot(epoch_count, validation, 'b-')\n        axs[k].legend(['Training ' + key, 'Validation ' + key])","execution_count":null,"outputs":[]},{"metadata":{"id":"_EhgaH9kFFrU","trusted":false,"outputId":"c6c93007-46b0-4731-8317-81889a40fa4e"},"cell_type":"code","source":"print('average accuracy : ', np.mean(np.array(accuracies)), '+-', np.std(np.array(accuracies)))\nprint('average loss : ', np.mean(np.array(losses)), '+-', np.std(np.array(losses)))\nprint('average iou : ', np.mean(np.array(ious)), '+-', np.std(np.array(ious)))\nprint('average dice_coe : ', np.mean(np.array(dicecoefs)), '+-', np.std(np.array(dicecoefs)))","execution_count":null,"outputs":[]},{"metadata":{"id":"KXFmYOt8SVN1","trusted":false},"cell_type":"code","source":"model = load_model('1_unet_ner_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","execution_count":null,"outputs":[]},{"metadata":{"id":"W8HL2A2cFR7h","trusted":false,"outputId":"347226ad-ed4c-4e18-c5e3-24e9b5844029"},"cell_type":"code","source":"for i in range(20):\n    index=np.random.randint(0,len(test_data_frame))\n    print(i+1, index)\n    img = cv2.imread(test_data_frame['filename'][index], cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, (height, width))\n    img = img[:, :, np.newaxis]\n    img = img / 255\n    pred=model.predict([[img]])\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,4,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,4,2)\n    plt.imshow(np.squeeze(cv2.resize(cv2.imread(test_data_frame['mask'][index]), (height, width))))\n    plt.title('Original Mask')\n    plt.subplot(1,4,3)\n    plt.imshow(np.squeeze(pred))\n    plt.title('pred')\n    plt.subplot(1,4,4)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('pred')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"bmkDoOhVSVz6","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}