{"cells":[{"metadata":{"id":"uVKH-RugwO4x"},"cell_type":"markdown","source":"## Init"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"2A16cMW7wJbm"},"cell_type":"code","source":"! pip install segmentation_models_pytorch albumentations\n! pip install -U git+https://github.com/albu/albumentations --no-cache-dir\n","execution_count":null,"outputs":[]},{"metadata":{"id":"3s_ii3ou6sH9","trusted":true},"cell_type":"code","source":"\nimport os\nimport csv\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport itertools\n\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport shutil\n\nimport torch\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.nn as nn\nimport albumentations\nimport torchvision \nfrom torchvision import transforms, models\n\nimport random\n\nimport segmentation_models_pytorch as smp\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"id":"twhEk37ZAAVH","executionInfo":{"status":"ok","timestamp":1616238962444,"user_tz":-420,"elapsed":489,"user":{"displayName":"Bob Sideshow","photoUrl":"","userId":"17451318496692579775"}},"outputId":"30e0f8e0-a374-4086-a3fa-e8b386186d08","trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"id":"p79_tNEWDBk6"},"cell_type":"markdown","source":"## Main"},{"metadata":{"trusted":true,"id":"chKpXFhdwJbs","executionInfo":{"status":"ok","timestamp":1616238964685,"user_tz":-420,"elapsed":559,"user":{"displayName":"Bob Sideshow","photoUrl":"","userId":"17451318496692579775"}},"outputId":"1d5eb015-576d-4cec-8b3b-82662fbfddb4"},"cell_type":"code","source":"ROOT = \"/kaggle/input/ultrasound-nerve-segmentation/\"\ntrainpath = \"/kaggle/input/ultrasound-nerve-segmentation/train/\"\ntestpath = \"/kaggle/input/ultrasound-nerve-segmentation/test/\"\n\nmasks = [os.path.join(trainpath,i) for i in os.listdir(trainpath) if \"mask\" in i]\nimgs = [i.replace(\"_mask\",\"\") for i in masks]\n\ndf = pd.DataFrame({\"image\":imgs,\"mask\":masks})\n\ndf_train, df_val = train_test_split(df,test_size = 0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"2ODZxgi9wJbu","executionInfo":{"status":"ok","timestamp":1616238003459,"user_tz":-420,"elapsed":2240,"user":{"displayName":"Bob Sideshow","photoUrl":"","userId":"17451318496692579775"}},"outputId":"24e5f440-9b85-4e73-d225-6118784dd163"},"cell_type":"code","source":"rows,cols=3,3\nfig=plt.figure(figsize=(10,10))\nfor i in range(1,rows*cols+1):\n    ii = random.randint(0, len(df))\n    fig.add_subplot(rows,cols,i)\n    img_path=df['image'][ii]\n    msk_path=df['mask'][ii]\n    plt.imshow(np.array(Image.open(img_path)), cmap = 'gray')\n    plt.imshow(np.array(Image.open(msk_path)),alpha=0.4, cmap = 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"DUNcujXmwJbu"},"cell_type":"code","source":"def rle_encoding(x):\n    dots = np.where(x.T.flatten()==1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef convert_to_tensor(x,**kwargs):\n    return x.transpose(2,0,1).astype(\"float32\")\n\ndef func_for_preprocessing(preprocessing_fn=None):\n    transform = []\n    if preprocessing_fn:\n        transform.append(albumentations.Lambda(image=preprocessing_fn))\n    transform.append(albumentations.Lambda(image=convert_to_tensor))\n    return albumentations.Compose(transform)\n\ndef trainaugs():\n    transform =  [\n                albumentations.Resize(height=224,width=224,interpolation=Image.BILINEAR),\n                albumentations.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0),\n                albumentations.ShiftScaleRotate(rotate_limit=15, shift_limit=0.15, scale_limit=0.2),\n                albumentations.HorizontalFlip(),\n            ]\n    return albumentations.Compose(transform)\n\ndef valaugs():\n    transform = [\n                albumentations.Resize(height=224,width=224,interpolation=Image.BILINEAR),\n            ]\n    return albumentations.Compose(transform)\n\n\nclass GetDataset(Dataset):\n    def __init__(self,imagespath,maskspath,augment=None,preprocess=None):\n        self.imagespath = imagespath\n        self.maskspath = maskspath\n        self.augment = augment\n        self.preprocess = preprocess\n        \n    def __len__(self):\n        return len(self.imagespath)\n    \n    def __getitem__(self,idx):\n        image = cv2.cvtColor(cv2.imread(self.imagespath[idx]),cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.maskspath[idx], cv2.IMREAD_GRAYSCALE)\n\n        if self.augment:\n            sample = self.augment(image=image, mask=mask)\n            image,mask = sample['image'],sample['mask']\n        if self.preprocess:\n            sample = self.preprocess(image=image,mask=mask)\n            image,mask = sample['image'],sample['mask']\n\n        mask = (mask / 255).astype(np.float32)\n        mask = np.expand_dims(mask, axis=0)\n\n        return image,mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"k2DcBUqUwJbw"},"cell_type":"code","source":"encoder = \"resnet34\"\nencoder_wts = \"imagenet\"\nactivation = \"sigmoid\"\n\n\nmodel = smp.Unet(encoder_name=encoder,activation=activation,encoder_weights=encoder_wts)\npreprocess_func = smp.encoders.get_preprocessing_fn(encoder,encoder_wts)\n\n\ntraindata = GetDataset(imagespath = df_train['image'].tolist(),\n                            maskspath = df_train['mask'].tolist(),\n                            augment = trainaugs(),\n                            preprocess = func_for_preprocessing(preprocess_func))\n\nvalidationdata = GetDataset(imagespath = df_val['image'].tolist(),\n                            maskspath = df_val['mask'].tolist(),\n                            augment = valaugs(),\n                           preprocess = func_for_preprocessing(preprocess_func))\n\nbatch_size = 16\ntrainloader = DataLoader(traindata,batch_size = batch_size,shuffle=True)\nvalloader = DataLoader(validationdata,batch_size=batch_size,shuffle=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"vu36-j1AwJbx"},"cell_type":"code","source":"trainmodel = True\nepochs = 20\ndevice = \"cuda\"\nloss = smp.utils.losses.DiceLoss()\nmetrics = [ smp.utils.metrics.IoU(threshold=0.5) ]\noptimizer = torch.optim.Adam([dict(params=model.parameters(), lr=0.001)])\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n\ntrainepoch = smp.utils.train.TrainEpoch(model,loss=loss,optimizer=optimizer,metrics=metrics,device=device,verbose=True)\nvalidepoch = smp.utils.train.ValidEpoch(model,loss=loss,metrics=metrics,device=device,verbose=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"LlkGgnHZwJby","executionInfo":{"status":"ok","timestamp":1616243273706,"user_tz":-420,"elapsed":4289069,"user":{"displayName":"Bob Sideshow","photoUrl":"","userId":"17451318496692579775"}},"outputId":"1aad3807-c52f-4fa8-8bd9-4bd3db937ca1"},"cell_type":"code","source":"best_iou_score = 0.0 \ntrain_logs_list, valid_logs_list = [], []\nfor i in range(0,epochs):\n    print('\\nEpoch: {}'.format(i))\n    trainlogs = trainepoch.run(trainloader)\n    validlogs = validepoch.run(valloader)\n    lr_scheduler.step()\n\n    train_logs_list.append(trainlogs)\n    valid_logs_list.append(validlogs)\n    if best_iou_score < validlogs['iou_score']:\n        best_iou_score = validlogs['iou_score']\n        torch.save(model, './best_model.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"4epEGzICwJby","executionInfo":{"status":"ok","timestamp":1616243651248,"user_tz":-420,"elapsed":652,"user":{"displayName":"Bob Sideshow","photoUrl":"","userId":"17451318496692579775"}},"outputId":"3d8fff18-3eee-4d8f-f041-9baeb81f525f"},"cell_type":"code","source":"train_logs_df = pd.DataFrame(train_logs_list)\nvalid_logs_df = pd.DataFrame(valid_logs_list)\ntrain_logs_df.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"MtQP7_27wJbz","executionInfo":{"status":"ok","timestamp":1616243653573,"user_tz":-420,"elapsed":1389,"user":{"displayName":"Bob Sideshow","photoUrl":"","userId":"17451318496692579775"}},"outputId":"70e1b926-4945-42d4-a28d-d5f31c532be6"},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.iou_score.tolist(),'g-',lw=3, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.iou_score.tolist(),'r-' ,lw=3, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('IoU Score', fontsize=20)\nplt.title('IoU Score Plot', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.show()\n\nplt.figure(figsize=(10,4))\nplt.plot(train_logs_df.index.tolist(), train_logs_df.dice_loss.tolist(),'g-',lw=3, label = 'Train')\nplt.plot(valid_logs_df.index.tolist(), valid_logs_df.dice_loss.tolist(),'r-' ,lw=3, label = 'Valid')\nplt.xlabel('Epochs', fontsize=20)\nplt.ylabel('Dice Loss', fontsize=20)\nplt.title('Dice Loss', fontsize=20)\nplt.legend(loc='best', fontsize=16)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"jJ86IMVPJl-K"},"cell_type":"markdown","source":"## Test best saved model"},{"metadata":{"id":"jYidA43gK_an","executionInfo":{"status":"ok","timestamp":1616243713408,"user_tz":-420,"elapsed":8958,"user":{"displayName":"Bob Sideshow","photoUrl":"","userId":"17451318496692579775"}},"outputId":"34ca935e-7b9b-4d6e-a4da-7bc1b30ac391","trusted":true},"cell_type":"code","source":"best_model = torch.load('./best_model.pth')\n\ntest_dataset = GetDataset(imagespath = df_val['image'].tolist(),\n                            maskspath = df_val['mask'].tolist(),\n                            augment = valaugs(),\n                           preprocess = func_for_preprocessing(preprocess_func))\n\n\ntest_dataset_vis = GetDataset(imagespath = df_val['image'].tolist(),\n                            maskspath = df_val['mask'].tolist())\n\n\ndef visualize(**images):\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        if image.shape[0] == 3:\n            image = image.transpose([1, 2, 0])\n        plt.imshow(image)\n    plt.show()\n\nfor i in range(25):\n    n = np.random.choice(len(test_dataset))\n    \n    image_vis = test_dataset_vis[n][0].astype('uint8')\n    mask_vis = test_dataset_vis[n][1].astype('uint8')\n    image, gt_mask = test_dataset[n]\n    \n    gt_mask = gt_mask.squeeze()\n    \n    x_tensor = torch.from_numpy(image).to(device).unsqueeze(0)\n    pr_mask = best_model.predict(x_tensor)\n    pr_mask = pr_mask.squeeze().cpu().numpy().round()\n\n    kernel = np.ones((5,5),np.uint8)\n    pr_mask_er = cv2.erode(pr_mask,kernel,iterations = 4)\n    pr_mask_er = cv2.dilate(pr_mask_er,kernel,iterations = 4)\n\n    pr_mask = cv2.resize(pr_mask, (580, 420))\n    pr_mask_er = cv2.resize(pr_mask_er, (580, 420))\n\n    mask_vis = mask_vis.squeeze()\n\n    visualize(\n        image=image_vis, \n        ground_truth_mask=mask_vis, \n        predicted_mask=pr_mask,\n        predicted_mask_erosion_with_dilation=pr_mask_er\n    )","execution_count":null,"outputs":[]},{"metadata":{"id":"KQ2omdq0W26N"},"cell_type":"markdown","source":"## Test evaluation"},{"metadata":{"id":"-Re_PuSdyii6","executionInfo":{"status":"ok","timestamp":1616244054057,"user_tz":-420,"elapsed":296236,"user":{"displayName":"Bob Sideshow","photoUrl":"","userId":"17451318496692579775"}},"outputId":"f2e65b4c-4b2d-4ded-c527-cd8cfb235cfe","trusted":true},"cell_type":"code","source":"imgs = [f for f in os.listdir(testpath)]\nimgs = sorted(imgs, key=lambda s: int(s.split('.')[0]))\n\nencodings = []\n\nfor m in tqdm(imgs):\n    x = cv2.imread(os.path.join(testpath, m))\n\n    x = valaugs()(image=x)['image']\n    x = func_for_preprocessing(preprocess_func)(image=x)['image']\n\n    x_tensor = torch.from_numpy(x).to(device).unsqueeze(0)\n    pr_mask = best_model.predict(x_tensor)\n\n    pr_mask = pr_mask.squeeze().cpu().numpy().round().astype(np.uint8)\n    pr_mask = albumentations.Resize(height=420,width=580,interpolation=Image.NEAREST)(image=pr_mask)['image']\n\n    encodings.append(rle_encoding(pr_mask))","execution_count":null,"outputs":[]},{"metadata":{"id":"xnIjixIG3i8x","trusted":true,"collapsed":true},"cell_type":"code","source":"df_submission = pd.DataFrame(columns=[\"img\", \"pixels\"])\nfor i, encoding in enumerate(encodings):\n    pixels = ' '.join(map(str, encoding))\n    df_submission.loc[i] = [str(i+1), pixels]\n\ndf_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}