{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi, I am a semantic segmentation beginner.(I'm sorry for my poor English in advance)<br/>\n(I refered to many part of this [site](https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/submission.py))"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\n\nK.set_image_data_format('channels_last')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the training dataset.\nLet's look at the train image list"},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"path = \"../input/train/\"\nfile_list = os.listdir(path)\nfile_list[:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sort the file list in ascending order and seperate it into images and masks**<br/>\nEach file has the form of either \"subject_imageNum.tif\" or \"subject_imageNum_mask.tif\", so we can extract `subject` and `imageNum` from each file name by using regular expression. `\"[0-9]+\"` means to find the first consecutive number.<br/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = re.compile(\"[0-9]+\")\n\ntemp1 = list(map(lambda x: reg.match(x).group(), file_list)) \ntemp1 = list(map(int, temp1))\n\ntemp2 = list(map(lambda x: reg.match(x.split(\"_\")[1]).group(), file_list))\ntemp2 = list(map(int, temp2))\n\nfile_list = [x for _,_,x in sorted(zip(temp1, temp2, file_list))]\nfile_list[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image = []\ntrain_mask = []\nfor idx, item in enumerate(file_list):\n    if idx % 2 == 0:\n        train_image.append(item)\n    else:\n        train_mask.append(item)\n        \nprint(train_image[:10],\"\\n\" ,train_mask[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the first image and mask of the first subject.\nimage1 = np.array(Image.open(path+\"1_1.tif\"))\nimage1_mask = np.array(Image.open(path+\"1_1_mask.tif\"))\nimage1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n\nfig, ax = plt.subplots(1,3,figsize = (16,12))\nax[0].imshow(image1, cmap = 'gray')\n\nax[1].imshow(image1_mask, cmap = 'gray')\n\nax[2].imshow(image1, cmap = 'gray', interpolation = 'none')\nax[2].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, I try to load all image files and store them variables X and y. Afther doing this, I recognize that it takes very much memory.<br/>\nPlease let me know if there are several efficient ways to store image file"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Storing data\nX = []\ny = []\nfor image, mask in zip(train_image, train_mask):\n    X.append(np.array(Image.open(path+image)))\n    y.append(np.array(Image.open(path+mask)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you load images by using cv2.imread(filepath), it gives you image as data type \"np.darray\"<br/>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)\n\nprint(\"X_shape : \", X.shape)\nprint(\"y_shape : \", y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How to deal with train_masks.csv ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_df = pd.read_csv(\"../input/train_masks.csv\")\nmask_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**How to deal with `pixels` column ?**<br/>\nLet me try to convert the first `pixels` column to the mask image.<br/>\nActually, this work could be not necessary, since we are provided mask_image. But other competition that I want to join provide only run length encoded data, so I do this to practice. "},{"metadata":{"trusted":true},"cell_type":"code","source":"width = 580\nheight = 420\n\ntemp = mask_df[\"pixels\"][0]\ntemp = temp.split(\" \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask1 = np.zeros(height * width)\nfor i, num in enumerate(temp):\n    if i % 2 == 0:\n        run = int(num) -1             # very first pixel is 1, not 0\n        length = int(temp[i+1])\n        mask1[run:run+length] = 255 \n\n#Since pixels are numbered from top to bottom, then left to right, we are careful to change the shape\nmask1 = mask1.reshape((width, height))\nmask1 = mask1.T ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check that I did well"},{"metadata":{"trusted":true},"cell_type":"code","source":"(mask1 != y[0]).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's modularize this work."},{"metadata":{"trusted":true},"cell_type":"code","source":"# RLE : run-length-encoding\ndef RLE_to_image(rle):\n    '''\n    rle : array in mask_df[\"pixels\"]\n    '''\n    width, height = 580, 420\n    \n    if rle == 0:\n        return np.zeros((height,width))\n    \n    else:\n        rle = rle.split(\" \")\n        mask = np.zeros(width * height)\n        for i, num in enumerate(rle):\n            if i % 2 == 0:\n                run = int(num) - 1\n                length = int(rle[i+1])\n                mask[run:run+length] = 255\n\n        mask = mask.reshape((width, height))\n        mask = mask.T \n\n        return mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory data analysis\nFirst of all, let's check how many train data we have."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of train data : \", X.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One can find the number of subjects in train data by `groupby` method on `mask_df`."},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_df.head()\nsubject_df = mask_df[['subject', 'img']].groupby(by = 'subject').agg('count').reset_index()\nsubject_df.columns = ['subject', 'N_of_img']\nsubject_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(subject_df['N_of_img']).reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are total 47 subjects and almost almost all subjects have 120 images except for 5 subjects who have 119 images.<br/>\nI want to know whether test dataset has similar distribution or not. Let's check this by using the similar way when we listed the train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/test\")[0:15])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each test image name is numbered in different way, so we cannot exploit subject information when we predict test data."},{"metadata":{},"cell_type":"markdown","source":"## Let's define U-net and train our model by using 100 data\nSince the whole data size is quite big, it may lead to over-memory if we load whole data on X and y as we did earier. <br/>\nSo our strategy is to use `data generator` that allow us to load a few of data and to use them to train our model.<br/>\nBefore that, we first use only 100 data to check our model works well"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model, Input, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Randomly choose the indices of data used to train our model.\nindices = np.random.choice(range(len(train_image)), replace = False ,size = 100)\ntrain_image_sample = np.array(train_image)[indices]\ntrain_mask_sample = np.array(train_mask)[indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the dataset.\nIMG_HEIGHT = 96\nIMG_WIDTH = 96\n\nX = np.empty(shape = (len(indices), IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\ny = np.empty(shape = (len(indices), IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n\nfor i, (image_path, mask_path) in enumerate(zip(train_image_sample, train_mask_sample)):\n    image = cv2.imread(\"../input/train/\" + image_path, 0)\n    mask = cv2.imread(\"../input/train/\" + mask_path, 0)\n    \n    image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n    mask = cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n    \n    X[i] = image\n    y[i] = mask\n\nX = X[:,:,:,np.newaxis] / 255\ny = y[:,:,:,np.newaxis] / 255\nprint(\"X shape : \", X.shape)\nprint(\"y shape : \", y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we define the dice loss and metrics. I refered to this [site](https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/train.py)."},{"metadata":{"trusted":true},"cell_type":"code","source":"smooth = 1.\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build U-net model. I also refered to this [site](https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/train.py). "},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((IMG_HEIGHT, IMG_WIDTH, 1))\n\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\nconv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\nconv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\nup6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\nup7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\nconv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\nconv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\nup8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\nconv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\nconv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\nup9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\nconv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\nconv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\nconv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\nmodel = Model(inputs=[inputs], outputs=[conv10])\nmodel.compile(optimizer=Adam(lr = 1e-5), loss=dice_coef_loss, metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.fit(X, y, validation_split=0.1, batch_size=4, epochs=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It worked !! This was my first semantic segmentation models :)<br/>\nLet's keep going on !"},{"metadata":{},"cell_type":"markdown","source":"## Define image_generator"},{"metadata":{},"cell_type":"markdown","source":"In order to define data generator, I refer this [site](https://towardsdatascience.com/a-keras-pipeline-for-image-segmentation-part-1-6515a421157d)  "},{"metadata":{"trusted":true},"cell_type":"code","source":"def Generator(X_list, y_list, batch_size = 16):\n    c = 0\n\n    while(True):\n        X = np.empty((batch_size, IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n        y = np.empty((batch_size, IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n        \n        for i in range(c,c+batch_size):\n            image = cv2.imread(\"../input/train/\" + X_list[i], 0)\n            mask = cv2.imread(\"../input/train/\" + y_list[i], 0)\n    \n            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n            mask = cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n    \n            X[i - c] = image\n            y[i - c] = mask\n        \n        X = X[:,:,:,np.newaxis] / 255\n        y = y[:,:,:,np.newaxis] / 255\n        \n        c += batch_size\n        if(c+batch_size >= len(X_list)):\n            c = 0\n        yield X, y    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train_image, train_mask, test_size = 0.3, random_state = 1)\n\nepochs = 10\nbatch_size = 8\nsteps_per_epoch = int(len(X_train) / batch_size)\nvalidation_steps = int(len(X_val) / batch_size)\n\ntrain_gen = Generator(X_train, y_train, batch_size = batch_size)\nval_gen = Generator(X_val, y_val, batch_size = batch_size)\n\nmodel = Model(inputs=[inputs], outputs=[conv10])\nmodel.compile(optimizer=Adam(lr = 1e-5), loss=dice_coef_loss, metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_gen, steps_per_epoch=steps_per_epoch, epochs = epochs,\n                             validation_data = val_gen, validation_steps = validation_steps)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's predict the test data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/sample_submission.csv\")\ntest_list = os.listdir(\"../input/test\")\n\nprint(\"The number of test data : \", len(test_list))\n\n# Sort the test set in ascending order.\nreg = re.compile(\"[0-9]+\")\n\ntemp1 = list(map(lambda x: reg.match(x).group(), test_list)) \ntemp1 = list(map(int, temp1))\n\ntest_list = [x for _,x in sorted(zip(temp1, test_list))]\n\ntest_list[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = np.empty((len(test_list), IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\nfor i, item in enumerate(test_list):\n    image = cv2.imread(\"../input/test/\" + item, 0)\n    image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n    X_test[i] = image\nX_test = X_test[:,:,:,np.newaxis] / 255\n\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I refered to the this [site](https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/submission.py) to submit my prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_length_enc(label):\n    from itertools import chain\n    x = label.transpose().flatten()\n    y = np.where(x > 0)[0]\n    if len(y) < 10:  # consider as empty\n        return ''\n    z = np.where(np.diff(y) > 1)[0]\n    start = np.insert(y[z+1], 0, y[0])\n    end = np.append(y[z], y[-1])\n    length = end - start\n    res = [[s+1, l+1] for s, l in zip(list(start), list(length))]\n    res = list(chain.from_iterable(res))\n    return ' '.join([str(r) for r in res])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rles = []\nfor i in range(X_test.shape[0]):\n    img = y_pred[i, :, :, 0]\n    img = img > 0.5\n    img = resize(img, (420, 580), preserve_range=True)\n    rle = run_length_enc(img)\n    rles.append(rle)\n    if i % 100 == 0:\n            print('{}/{}'.format(i, X_test.shape[0]), end = \"\\r\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['pixels'] = rles\nsub.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It gives me 0.44690 score."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}