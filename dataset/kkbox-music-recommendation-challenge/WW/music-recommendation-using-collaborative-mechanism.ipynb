{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### What is LightFM?","metadata":{}},{"cell_type":"markdown","source":"**LightFM is a hybrid matrix factorisation model representing users and items as linear combinations of their content features’ latent factors. The model outperforms both collaborative and content-based models in cold-start or sparse interaction data scenarios (using both user and item metadata), and performs at least as well as a pure collaborative matrix factorisation model where interaction data is abundant.**\n\nIn LightFM, like in a collaborative filtering model, users and items are represented as latent vectors (embeddings). For example, if the movie ‘Wizard of Oz’ is described by the following features: ‘musical fantasy’, ‘Judy Garland’, and ‘Wizard of Oz’, then its latent representation will be given by the sum of these features’ latent representations. In doing so, LightFM unites the advantages of contentbased and collaborative recommenders.\n\n**How LightFM works**: To put it simply in words, lightFM model learns embeddings (latent representations in a high-dimensional space) for users and items in a way that encodes user preferences over items. When multiplied together, these representations produce scores for every item for a given user; items scored highly are more likely to be interesting to the user","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\n# import lightgbm as lgb\nimport os\nimport sys\nimport shutil\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\n# from catboost import CatBoostClassifier\n\n\nfrom lightfm import LightFM\nimport scipy.sparse as sp\n\n\n!pip install pyunpack\n!pip install patool\nfrom pyunpack.cli import Archive\nos.system('apt-get install p7zip')\nprint(os.getcwd()) #/kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:51:53.128549Z","iopub.execute_input":"2022-03-09T18:51:53.128889Z","iopub.status.idle":"2022-03-09T18:52:15.983655Z","shell.execute_reply.started":"2022-03-09T18:51:53.128788Z","shell.execute_reply":"2022-03-09T18:52:15.982246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using datatable library for managing large datasets on Kaggle without fearing the out of memory error\nimport datatable as dt","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:52:15.986089Z","iopub.execute_input":"2022-03-09T18:52:15.986411Z","iopub.status.idle":"2022-03-09T18:52:16.05481Z","shell.execute_reply.started":"2022-03-09T18:52:15.986368Z","shell.execute_reply":"2022-03-09T18:52:16.054142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndirectory = '/kaggle/working/'\nArchive('/kaggle/input/kkbox-music-recommendation-challenge/train.csv.7z').extractall(directory)\nArchive('/kaggle/input/kkbox-music-recommendation-challenge/test.csv.7z').extractall(directory)\nArchive('/kaggle/input/kkbox-music-recommendation-challenge/songs.csv.7z').extractall(directory)\nArchive('/kaggle/input/kkbox-music-recommendation-challenge/members.csv.7z').extractall(directory)\nArchive('/kaggle/input/kkbox-music-recommendation-challenge/song_extra_info.csv.7z').extractall(directory)\n\n#sys.exit(\"Error message\")\ntrain = dt.fread('./train.csv').to_pandas()\ntest = dt.fread('./test.csv').to_pandas()\nsongs = dt.fread('./songs.csv').to_pandas() #'composer', 'lyricist'\nmembers = dt.fread('./members.csv').to_pandas()\nsongs_extra = dt.fread('./song_extra_info.csv',fill=True).to_pandas()\n\nprint('Data loading completed!')\nprint(train.shape, test.shape, songs.shape, members.shape, songs_extra.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:52:16.05603Z","iopub.execute_input":"2022-03-09T18:52:16.056563Z","iopub.status.idle":"2022-03-09T18:53:05.091235Z","shell.execute_reply.started":"2022-03-09T18:52:16.05652Z","shell.execute_reply":"2022-03-09T18:53:05.090354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA and Feature preprocessing\nExploring the train dataset","metadata":{}},{"cell_type":"code","source":"print(\"Train users: \", len(train.msno.unique()),\"Train songs: \", len(train.song_id.unique()))\nprint(\"Test users: \", len(test.msno.unique()),\"Test songs: \", len(test.song_id.unique()))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:37:05.145771Z","iopub.execute_input":"2022-03-09T18:37:05.146251Z","iopub.status.idle":"2022-03-09T18:37:05.287848Z","shell.execute_reply.started":"2022-03-09T18:37:05.146213Z","shell.execute_reply":"2022-03-09T18:37:05.287042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of songs and their repeat frequency\ndict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\ndict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\n# dict_count_song_played_train","metadata":{"execution":{"iopub.status.busy":"2022-03-09T03:10:51.400665Z","iopub.execute_input":"2022-03-09T03:10:51.401099Z","iopub.status.idle":"2022-03-09T03:10:54.33052Z","shell.execute_reply.started":"2022-03-09T03:10:51.401059Z","shell.execute_reply":"2022-03-09T03:10:54.329855Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    if train[col].dtype == object:\n        train[col] = train[col].astype('category')\n        test[col] = test[col].astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:53:11.182367Z","iopub.execute_input":"2022-03-09T18:53:11.182654Z","iopub.status.idle":"2022-03-09T18:53:22.909346Z","shell.execute_reply.started":"2022-03-09T18:53:11.182621Z","shell.execute_reply":"2022-03-09T18:53:22.908392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Treatment of songs and user names\nThe userid and songid is difficult to interpret giving its huge alphanumeric names, hence we will map it onto some names to make it easier to understand the insights drawn from them. <br>\n\nApproach: Although we have 30,755 users in the train set, We have been able to curate 149 Korean names. Hence we could map it to any user randomly or we can also map these names to top users of this music app to be able to draw deeper insight into their music listening behaviour.","metadata":{}},{"cell_type":"code","source":"# Fetching Song names\ntrain= train.merge(songs_extra, on= 'song_id', how='left')\ntrain.rename(columns= {'msno':'userid','target':'repeat_listener','name':'song'}, inplace=True)\ntrain[:3]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:53:22.911105Z","iopub.execute_input":"2022-03-09T18:53:22.911376Z","iopub.status.idle":"2022-03-09T18:53:28.542902Z","shell.execute_reply.started":"2022-03-09T18:53:22.911336Z","shell.execute_reply":"2022-03-09T18:53:28.541616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have randomly selected 139 Korean usernames to rename some top user id's just to make it easier to interpret our results!","metadata":{}},{"cell_type":"code","source":"username= pd.read_csv('/kaggle/input/names/Korean_names.csv')\nnames= username.loc[:,'name'].tolist()\nnames[:5]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:53:34.914549Z","iopub.execute_input":"2022-03-09T18:53:34.915089Z","iopub.status.idle":"2022-03-09T18:53:34.927791Z","shell.execute_reply.started":"2022-03-09T18:53:34.915049Z","shell.execute_reply":"2022-03-09T18:53:34.927138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\n# User name manipulation\n\n# Storing concatenation of the userid into the user column\ntrain['user']= train['userid'].str[:10]\n\n# Fetching a list of the top users\ntop_users= train.user.value_counts()[:139].index.tolist()\n\n# Creating a dict with username mapping\nuser_mapping= {top_users[i]: names[i] for i in range(len(top_users))}\n\n# Assign names wrt name mapping\ntrain= train.replace({'user': user_mapping, 'repeat_listener':{True:1, False:0}})\ntrain.user.value_counts()[:15]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:53:41.319992Z","iopub.execute_input":"2022-03-09T18:53:41.320473Z","iopub.status.idle":"2022-03-09T18:54:52.011523Z","shell.execute_reply.started":"2022-03-09T18:53:41.320436Z","shell.execute_reply":"2022-03-09T18:54:52.010734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:54:52.013408Z","iopub.execute_input":"2022-03-09T18:54:52.013704Z","iopub.status.idle":"2022-03-09T18:54:52.271636Z","shell.execute_reply.started":"2022-03-09T18:54:52.013666Z","shell.execute_reply":"2022-03-09T18:54:52.270708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Missing Value Imputation","metadata":{}},{"cell_type":"markdown","source":"For feeding data into the recommendation engine, we basically need a user-item dataset in the form of a sparse matrix. For this purpose we will be using columns- user and song.","metadata":{}},{"cell_type":"code","source":"# For recommendation algorithm we need the dataframe in the user-item matrix format\ndf= train[['user','song','repeat_listener']]\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:39:11.533219Z","iopub.execute_input":"2022-03-09T18:39:11.53348Z","iopub.status.idle":"2022-03-09T18:39:11.746299Z","shell.execute_reply.started":"2022-03-09T18:39:11.533445Z","shell.execute_reply":"2022-03-09T18:39:11.745567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:39:36.414738Z","iopub.execute_input":"2022-03-09T18:39:36.415422Z","iopub.status.idle":"2022-03-09T18:39:37.938537Z","shell.execute_reply.started":"2022-03-09T18:39:36.415383Z","shell.execute_reply":"2022-03-09T18:39:37.937669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking out a user\ndf.loc[df.user=='Gyeong-nim']","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:39:41.223633Z","iopub.execute_input":"2022-03-09T18:39:41.224421Z","iopub.status.idle":"2022-03-09T18:39:42.235367Z","shell.execute_reply.started":"2022-03-09T18:39:41.224381Z","shell.execute_reply":"2022-03-09T18:39:42.234661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sparsity challenge\nEven though it might possible to pivot transform the data, pivoting isn't exactly the best strategy because user-item data is notoriously sparse. Instead, we'll create a sparse user-item matrix with the coo_matrix function from scipy.sparse. The following is lifted from the coo_matrix docstring:\n<pre>\n\nrow = np.array([0, 0, 1, 2, 2, 2])\ncol = np.array([0, 2, 2, 0, 1, 2])\ndata = np.array([1, 2, 3, 4, 5, 6])\n\nsp.coo_matrix((data, (row, col)), shape=(3, 3)).todense()","metadata":{}},{"cell_type":"code","source":"# Convert boolean to integer\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings= np.array(train['repeat_listener'])\nusers= np.array(train['user'])\nsongs= np.array(train['song'])\n\nsp.coo_matrix((ratings, (users, songs)), shape=(len(users), len(songs)))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T18:42:40.919103Z","iopub.execute_input":"2022-03-09T18:42:40.919558Z","iopub.status.idle":"2022-03-09T18:42:41.757161Z","shell.execute_reply.started":"2022-03-09T18:42:40.919521Z","shell.execute_reply":"2022-03-09T18:42:41.755116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a simple class to return the coo matrix in the form of an interactions matrix\n\nclass Interactions:\n    def __init__(self):\n        self.user_encoder= LabelEncoder()\n        self.song_encoder= LabelEncoder()\n    \n    def fit(self, users, songs):\n        self.user_encoder.fit(users)\n        self.song_encoder.fit(songs)\n        return self\n    \n    def transform(self, users, songs, ratings=None):\n        if ratings is None:\n            ratings= [1]* len(users)\n        uid= self.user_encoder.transform(users)\n        iid= self.song_encoder.transform(songs)\n        n_users= len(np.unique(uid))\n        n_songs= len(np.unique(iid))\n        interactions= sp.coo_matrix((ratings, (uid, iid)), shape= (n_users, n_songs))\n        return interactions","metadata":{"execution":{"iopub.status.busy":"2022-03-09T03:24:02.434908Z","iopub.execute_input":"2022-03-09T03:24:02.435459Z","iopub.status.idle":"2022-03-09T03:24:02.44263Z","shell.execute_reply.started":"2022-03-09T03:24:02.435419Z","shell.execute_reply":"2022-03-09T03:24:02.44184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate an interactions machine\n\ninteractions= Interactions()\ninteractions.fit(df['user'], df['song'])\n\nmatrix= interactions.transform(df['user'], df['song'], df['repeat_listener'])\n\nprint(\"Original train size:\",sys.getsizeof(train))\nprint(\"Coordinate train size:\",sys.getsizeof(matrix))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T03:51:46.301441Z","iopub.execute_input":"2022-03-09T03:51:46.30163Z","iopub.status.idle":"2022-03-09T03:52:04.475449Z","shell.execute_reply.started":"2022-03-09T03:51:46.301606Z","shell.execute_reply":"2022-03-09T03:52:04.474691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# You can take a peek using toarray()\nmatrix.toarray()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T03:31:16.769859Z","iopub.execute_input":"2022-03-09T03:31:16.770211Z","iopub.status.idle":"2022-03-09T03:31:22.109679Z","shell.execute_reply.started":"2022-03-09T03:31:16.770176Z","shell.execute_reply":"2022-03-09T03:31:22.108831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightFM","metadata":{}},{"cell_type":"code","source":"model= LightFM()\nmodel.fit(matrix)\n\n# model= LightFM(no_components=100, k=5, learning_rate=0.05, random_state=33)\n\n# model.fit(matrix,epochs= 50, num_threads= 2)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T03:39:50.871599Z","iopub.execute_input":"2022-03-09T03:39:50.871857Z","iopub.status.idle":"2022-03-09T03:39:55.544598Z","shell.execute_reply.started":"2022-03-09T03:39:50.871829Z","shell.execute_reply":"2022-03-09T03:39:55.543873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Recommendation analysis for a particular user\nPredict the likelihood of the user Dong-geon will have recurring listening event(s) triggered within a month for the songs 'Good Grief' and 'Sleep Without You'?","metadata":{}},{"cell_type":"code","source":"print(\"User encoding: \", interactions.user_encoder.transform(['Dong-geon']))\nprint(\"Song encoding: \", interactions.song_encoder.transform(['Good Grief','Sleep Without You']))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T03:45:12.837022Z","iopub.execute_input":"2022-03-09T03:45:12.837584Z","iopub.status.idle":"2022-03-09T03:45:13.152306Z","shell.execute_reply.started":"2022-03-09T03:45:12.837548Z","shell.execute_reply":"2022-03-09T03:45:13.150601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(7425, [51441, 121825])\n\n# Although these values do not convey meaning independently but negative values signify less likelihood","metadata":{"execution":{"iopub.status.busy":"2022-03-09T03:45:53.817541Z","iopub.execute_input":"2022-03-09T03:45:53.817796Z","iopub.status.idle":"2022-03-09T03:45:53.826895Z","shell.execute_reply.started":"2022-03-09T03:45:53.817766Z","shell.execute_reply":"2022-03-09T03:45:53.82606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking Dong-geon once again and running through all the songs to get the closest matches of his liking\nmodel.predict(7425, np.arange(len(interactions.song_encoder.classes_)))[:10]\n\n# Storing them into a dataframe\nsongs_7425= pd.DataFrame({'song': interactions.song_encoder.classes_,\n                          'pred': model.predict(7425, np.arange(len(interactions.song_encoder.classes_)))}).sort_values('pred', ascending=False).head(10)\n\nsongs_7425","metadata":{"execution":{"iopub.status.busy":"2022-03-09T04:14:08.618968Z","iopub.execute_input":"2022-03-09T04:14:08.619588Z","iopub.status.idle":"2022-03-09T04:14:08.719682Z","shell.execute_reply.started":"2022-03-09T04:14:08.619552Z","shell.execute_reply":"2022-03-09T04:14:08.718829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **EVALUATION AND TUNING OUR MODEL**","metadata":{}},{"cell_type":"code","source":"from lightfm.evaluation import auc_score, precision_at_k\nprint(\"auc:\",auc_score(model, matrix, num_threads=4).mean())\nprint(\"prec:\",precision_at_k(model, matrix, k=10, num_threads=4).mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AUC SCORE**<br>\nAUC measures the quality of the overall ranking. In the binary case, it can be interpreted as the probability that a randomly chosen positive item is ranked higher than a randomly chosen negative item.<br> \nConsequently, an AUC close to 1.0 will suggest that, by and large, your ordering is correct: and this can be true even if none of the first K items are positives. This metric may be more appropriate if you do not exert full control on which results will be presented to the user; it may be that the first K recommended items are not available any more (say, they are out of stock), and you need to move further down the ranking. A high AUC score will then give you confidence that your ranking is of high quality throughout.","metadata":{}},{"cell_type":"markdown","source":"**PRECISION AT K**<BR>\nMeasure the precision at k metric for a model: the fraction of known positives in the first k positions of the ranked list of results. A perfect score is 1.0.","metadata":{}},{"cell_type":"code","source":"from lightfm.cross_validation import random_train_test_split\ntrain, test= random_train_test_split(matrix, test_percentage=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = LightFM()\n# model.fit(train, epochs=500)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LightFM()\n\nscores = []\nfor e in range(100):\n    model.fit_partial(train, epochs=1)\n    auc_train = auc_score(model, train).mean()\n    auc_test = auc_score(model, test).mean()\n    scores.append((auc_train, auc_test))\n    \nscores = np.array(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n%matplotlib inline\n\nplt.plot(scores[:, 0], label='train')\nplt.plot(scores[:, 1], label='test')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random_train_test_split(matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loss Evaluation","metadata":{}},{"cell_type":"markdown","source":"**WARP**: Weighted Approximate-Rank Pairwise loss. Maximises the rank of positive examples by repeatedly sampling negative examples until rank violating one is found. Useful when only positive interactions are present and optimising the top of the recommendation list (precision@k) is desired.","metadata":{}},{"cell_type":"code","source":"from lightfm.evaluation import auc_score, precision_at_k\nmodel= LightFM(loss='warp')\nscores=[]\nfor e in range(25):\n    model.fit_partial(train, epochs=1, num_threads=4)\n    auc_train= auc_score(model, train, num_threads=4).mean()\n    auc_test= auc_score(model, test, num_threads=4).mean()\n    scores.append((auc_train, auc_test))\n    \nscores = np.array(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n%matplotlib inline\n\nplt.plot(scores[:,0], label='train')\nplt.plot(scores[:,1], label='test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**BPR**: <br>Bayesian Personalised Ranking - pairwise loss. Maximises the prediction difference between a positive example and a randomly chosen negative example. Useful when only positive interactions are present and optimising ROC AUC is desired.","metadata":{}},{"cell_type":"code","source":"#Loss- 'bpr'\nmodel= LightFM(loss='bpr')\n\nscores=[]\nfor e in range(25):\n    model.fit_partial(train, epochs=1, num_threads=4)\n    auc_train = auc_score(model, train, num_threads=4).mean()\n    auc_test= auc_score(model, test, num_threads=4).mean()\n    scores.append((auc_train, auc_test))\n    \nscores= np.array(scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.plot(scores[:,0], label='train')\nplt.plot(scores[:,1], label='test')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's design EARLY STOPPING to obtain the optimum model in least training epochs**","metadata":{}},{"cell_type":"code","source":"from copy import deepcopy\n\nmodel= LightFM(loss='bpr')\n\ncount = 0\nbest = 0\nscores = []\nfor e in range(50):\n    if count>5:\n        break\n    model.fit_partial(train, epochs=1)\n    auc_train= auc_score(model, train).mean()\n    auc_test= auc_score(model, test).mean()\n    print(f'Epoch: {e}, Train AUC={auc_train:.3f}, Test AUC={auc_test:.3f}')\n    scores.append((auc_train, auc_test))\n    if auc_test > best:\n        best_model = deepcopy(model)\n        best = auc_test\n    else:\n        count += 1\n\nmodel= deepcopy(best_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"References: \nhttps://making.lyst.com/lightfm/docs/lightfm.html\nhttps://towardsdatascience.com/using-pythons-datatable-library-seamlessly-on-kaggle-f221d02838c7\n\nDo refer this well-documented kernel on LightFM:\n   https://www.kaggle.com/niyamatalmass/lightfm-hybrid-recommendation-system","metadata":{}},{"cell_type":"markdown","source":"**Why LightFM**:<br>\n\nIn both cold-start and low density scenarios, LightFM performs at least as well as pure content-based models, substantially outperforming them when either collaborative information is available in the training set or user features are included in the model. This is really useful for our Music recommendation system beacause we will have many new songs and users that makes a very good environment for the cold start problem.\n\nWhen collaborative data is abundant (warm-start, dense user-item matrix), LightFM performs at least as well as the Matrix Factorization model.\n\nEmbeddings produced by LightFM encode important semantic information about features, and can be used for related recommendation tasks such as tag recommendations. This is also very important for our problem. Because there are useful for finding similar tags so that model can recommend questions that has similiar tags to professionals tags.\n\n***Want to learn more about LightFM library?: *** <br>\nIf you want to deep dive how to use this library please visit it's official page: https://making.lyst.com/lightfm/docs/index.html. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}