{"cells":[{"cell_type":"markdown","source":"I'm here to make friends to work on this interesting challenge together. Skype me: sarazxy\n\nWelcome your comments.","metadata":{"_uuid":"85cb9739ea0476d4531d697c87a71d7a0887c470","_cell_guid":"bb65b899-a334-4269-9439-f449727362ab"}},{"source":"import numpy as np\nimport pandas as pd\nfrom time import gmtime, strftime\nimport gc\n\nfrom sklearn.model_selection import (train_test_split, GridSearchCV)\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\nfrom tqdm import tqdm\nfrom sklearn.metrics import (roc_curve, auc, accuracy_score)","cell_type":"code","metadata":{"_uuid":"98b1b738c4285aa51d184cf109d76874aededec4","_cell_guid":"07eb4438-192b-4587-ae85-88ac2cd09600","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Load data","metadata":{"_uuid":"c59349538fbb10ac7894f3f0a096709dec819fa7","_cell_guid":"3e612e55-fd10-4f24-b0fe-57b74dcf1967"}},{"source":"# read the first 99 rows for demo\ntrain = pd.read_csv('../input/train.csv', nrows=99)\ntest = pd.read_csv('../input/test.csv',nrows=99)\nsongs = pd.read_csv('../input/songs.csv')\nmembers = pd.read_csv('../input/members.csv')\n\n# Merge datasets with song attributes\nsong_cols = ['song_id', 'artist_name', 'genre_ids', 'song_length', 'language']\ntrain = train.merge(songs[song_cols], on='song_id', how='left')\ntest = test.merge(songs[song_cols], on='song_id', how='left')\n\n# Merge datasets with member features\nmembers['registration_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[0:4]))\nmembers['registration_month'] = members['registration_init_time'].apply(lambda x: int(str(x)[4:6]))\nmembers['registration_date'] = members['registration_init_time'].apply(lambda x: int(str(x)[6:8]))\n\nmembers['expiration_year'] = members['expiration_date'].apply(lambda x: int(str(x)[0:4]))\nmembers['expiration_month'] = members['expiration_date'].apply(lambda x: int(str(x)[4:6]))\nmembers['expiration_date'] = members['expiration_date'].apply(lambda x: int(str(x)[6:8]))\nmembers = members.drop(['registration_init_time'], axis=1)\n\nmembers_cols = members.columns\ntrain = train.merge(members[members_cols], on='msno', how='left')\ntest = test.merge(members[members_cols], on='msno', how='left')\n\ntrain = train.fillna(-1)\ntest = test.fillna(-1)\n\ndel members, songs; gc.collect();\n\ncols = list(train.columns)\ncols.remove('target')\n\nfor col in tqdm(cols):\n    if train[col].dtype == 'object':\n        train[col] = train[col].apply(str)\n        test[col] = test[col].apply(str)\n\n        le = LabelEncoder()\n        train_vals = list(train[col].unique())\n        test_vals = list(test[col].unique())\n        le.fit(train_vals + test_vals)\n        train[col] = le.transform(train[col])\n        test[col] = le.transform(test[col])\n\n","cell_type":"code","metadata":{"_uuid":"5107cf9bc022a686194503e3ba9ca53282fc6cbf","_cell_guid":"0e032b61-0cd5-4eca-926a-66ea753b25e7"},"execution_count":null,"outputs":[]},{"source":"X = np.array(train.drop(['target'], axis=1))\ny = train['target'].values","cell_type":"code","metadata":{"_uuid":"f0bbac632567137937fffc77f01f2476d02c9e22","_cell_guid":"9f4e2140-3f34-402c-987b-1f26d849e530","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Initiate a model","metadata":{"_uuid":"28574180eb2fab50b26d80ad457c50d7a5c74087","_cell_guid":"ee32b3e7-a9af-47d3-8d3d-23c05cba2df5"}},{"source":"params = {\n    'application': 'binary', # for binary classification\n#     'num_class' : 1, # used for multi-classes\n    'boosting': 'gbdt', # traditional gradient boosting decision tree\n    'num_iterations': 100, \n    'learning_rate': 0.05,\n    'num_leaves': 62,\n    'device': 'cpu', # you can use GPU to achieve faster learning\n    'max_depth': -1, # <0 means no limit\n    'max_bin': 510, # Small number of bins may reduce training accuracy but can deal with over-fitting\n    'lambda_l1': 5, # L1 regularization\n    'lambda_l2': 10, # L2 regularization\n    'metric' : 'binary_error',\n    'subsample_for_bin': 200, # number of samples for constructing bins\n    'subsample': 1, # subsample ratio of the training instance\n    'colsample_bytree': 0.8, # subsample ratio of columns when constructing the tree\n    'min_split_gain': 0.5, # minimum loss reduction required to make further partition on a leaf node of the tree\n    'min_child_weight': 1, # minimum sum of instance weight (hessian) needed in a leaf\n    'min_child_samples': 5# minimum number of data needed in a leaf\n}\n\n# Initiate classifier to use\nmdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n          objective = 'binary', \n          n_jobs = 5, \n          silent = True,\n          max_depth = params['max_depth'],\n          max_bin = params['max_bin'], \n          subsample_for_bin = params['subsample_for_bin'],\n          subsample = params['subsample'], \n          min_split_gain = params['min_split_gain'], \n          min_child_weight = params['min_child_weight'], \n          min_child_samples = params['min_child_samples'])\n\n# To view the default model parameters:\nmdl.get_params().keys()\n\n","cell_type":"code","metadata":{"_uuid":"c802408e8464cd4e89d5d5036c872ebcea16f58d","_cell_guid":"f9857e93-e3db-4458-b50b-f6d7576561cd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Grid search","metadata":{"_uuid":"c80ab7d33a1ba3158dc204b96498542d36fd44e0","_cell_guid":"837e4025-aaa5-4756-95b0-4c5bfab1ba45"}},{"source":"gridParams = {\n    'learning_rate': [0.005, 0.01],\n    'n_estimators': [8,16,24],\n    'num_leaves': [6,8,12,16], # large num_leaves helps improve accuracy but might lead to over-fitting\n    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n    'objective' : ['binary'],\n    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n    'random_state' : [500],\n    'colsample_bytree' : [0.64, 0.65, 0.66],\n    'subsample' : [0.7,0.75],\n    'reg_alpha' : [1,1.2],\n    'reg_lambda' : [1,1.2,1.4],\n    }\n\ngrid = GridSearchCV(mdl, gridParams, verbose=1, cv=4, n_jobs=-1)\n# Run the grid\ngrid.fit(X, y)\n\n# Print the best parameters found\nprint(grid.best_params_)\nprint(grid.best_score_)\n\n","cell_type":"code","metadata":{"_uuid":"b1795cff61b6c664ffd3abf627f3fc6d81a76f1b","_cell_guid":"70f58452-119b-4922-ada6-2bf76a02955b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Use the best model","metadata":{"_uuid":"e3d4faa1bc298ced1adc8f0c15e2ae6045a5958f","_cell_guid":"a5246d75-8725-40d8-90f3-a0cea9362f77"}},{"source":"params['colsample_bytree'] = grid.best_params_['colsample_bytree']\nparams['learning_rate'] = grid.best_params_['learning_rate'] \nparams['max_bin'] = grid.best_params_['max_bin']\nparams['num_leaves'] = grid.best_params_['num_leaves']\nparams['reg_alpha'] = grid.best_params_['reg_alpha']\nparams['reg_lambda'] = grid.best_params_['reg_lambda']\nparams['subsample'] = grid.best_params_['subsample']\n\n\nX_test = np.array(test.drop(['id'], axis=1))\nids = test['id'].values\n\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state = 12)\n    \ndel X, y; gc.collect();\n\nd_train = lgb.Dataset(X_train, label=y_train)\nd_valid = lgb.Dataset(X_valid, label=y_valid) \n\nwatchlist = [d_train, d_valid]\n\n\nmodel = lgb.train(params, train_set=d_train, num_boost_round=1000, valid_sets=watchlist, early_stopping_rounds=50, verbose_eval=4)\n\np_test = model.predict(X_test)\n\nsubm = pd.DataFrame()\nsubm['id'] = ids\nsubm['target'] = p_test\nsubmName = strftime(\"%Y%m%d%H%M%S\", gmtime()) + '_submission.csv.gz'\nsubm.to_csv(submName, compression = 'gzip', index=False, float_format = '%.5f')","cell_type":"code","metadata":{"_uuid":"3b539ca753600af5e819790d228d1eb4f5564fcd","_cell_guid":"1fefcf44-600b-4428-bea5-e3aab6f259b8","collapsed":true},"execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":1,"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","name":"python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","file_extension":".py","version":"3.6.3","nbconvert_exporter":"python"}}}