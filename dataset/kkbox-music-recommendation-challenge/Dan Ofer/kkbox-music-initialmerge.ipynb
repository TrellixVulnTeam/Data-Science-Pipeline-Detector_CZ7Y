{"nbformat":4,"nbformat_minor":1,"cells":[{"execution_count":null,"cell_type":"code","outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport datetime\nimport math\nimport gc\n\npd.set_option('display.max_columns', 100)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"c8542907ead88c658cfe43c79118b30fc19487bf","_cell_guid":"216be500-721f-45ac-ab63-6b0b67ec5fb9"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"print('Loading data...')\ndata_path = '../input/'\ntrain = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                  'source_screen_name' : 'category',\n                                                  'source_type' : 'category',\n                                                  'target' : np.uint8,\n                                                  'song_id' : 'category'})\ntest = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                'source_screen_name' : 'category',\n                                                'source_type' : 'category',\n                                                'song_id' : 'category'})\nsongs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n                                                  'language' : 'category',\n#                                                   'artist_name' : 'category',\n#                                                   'composer' : 'category',\n#                                                   'lyricist' : 'category',\n                                                  'song_id' : 'category'})\nmembers = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n                                                      'bd' : np.uint8,\n                                                      'gender' : 'category',\n                                                      'registered_via' : 'category'},\n                     parse_dates=['registration_init_time','expiration_date'])\nsongs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\nprint('Done loading...')","metadata":{"_uuid":"81f223f194c6f6f8fb54b908a434a527a3f66c8c","_cell_guid":"91dfcb80-f6a5-48b8-b889-2b4df0e4a4e1"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"print('Data merging...')\n\ntrain = train.merge(songs, on='song_id', how='left')\ntest = test.merge(songs, on='song_id', how='left')\n\nmembers['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n\n# members['registration_year'] = members['registration_init_time'].dt.year\n# members['registration_month'] = members['registration_init_time'].dt.month\n# members['registration_date'] = members['registration_init_time'].dt.day\n\n# members['expiration_year'] = members['expiration_date'].dt.year\n# members['expiration_month'] = members['expiration_date'].dt.month\n# members['expiration_date'] = members['expiration_date'].dt.day\n# members = members.drop(['registration_init_time'], axis=1)\n\ndef isrc_to_year(isrc):\n    if type(isrc) == str:\n        if int(isrc[5:7]) > 17:\n            return 1900 + int(isrc[5:7])\n        else:\n            return 2000 + int(isrc[5:7])\n    else:\n        return np.nan\n        \nsongs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\nsongs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n\ntrain = train.merge(members, on='msno', how='left')\ntest = test.merge(members, on='msno', how='left')\n\ntrain = train.merge(songs_extra, on = 'song_id', how = 'left')\n# train.song_length.fillna(200000,inplace=True)\n# train.song_length = train.song_length.astype(np.uint32)\n# train.song_id = train.song_id.astype('category')\n\n\ntest = test.merge(songs_extra, on = 'song_id', how = 'left')\n# test.song_length.fillna(200000,inplace=True)\n# test.song_length = test.song_length.astype(np.uint32)\n# test.song_id = test.song_id.astype('category')\n\n# import gc\n# del members, songs; gc.collect();\n\nprint('Done merging...')","metadata":{"_uuid":"95fae49636554eeb26dde3370054fbf6788335a8","_cell_guid":"24e253c9-b8f8-4c56-b1a5-5faa9bb17c8d"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def id_count(x):\n    return x.count('|') + 1","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# def genre_id_count(x):\n# #     if x == NaN:\n# #     if np.isnan(float(x)):\n#     if x == np.nan:\n#         print(\"n\")\n#         return 0    \n#     else:\n#         return x.count('|') + 0\n\n# train['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\n\n\ntrain['genre_ids_count'] = train['genre_ids'].apply(id_count).astype(np.int8)\ntest['genre_ids_count'] = test['genre_ids'].apply(id_count).astype(np.int8)\n\ntrain.loc[train['genre_ids'].isnull(),'genre_ids_count'] = 0\ntest.loc[train['genre_ids'].isnull(),'genre_ids_count'] = 0","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"train.loc[train['genre_ids'].isnull()].head()","metadata":{"scrolled":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"train.loc[train['lyricist'].str.len()>3].head()","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"def lyricist_count(x):\n    if x == ' ':\n        return 0\n    else:\n        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n\ntrain['lyricist'].fillna(' ',inplace=True)\ntest['lyricist'].fillna(' ',inplace=True)\ntrain['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\ntest['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"print (\"Adding new features\")\n# def genre_id_count(x):\n#     if x == 'no_genre_id':\n#         return 0\n#     else:\n#         return x.count('|') + 1\n\n# train['genre_ids'].fillna('no_genre_id',inplace=True)\n# test['genre_ids'].fillna('no_genre_id',inplace=True)\n# train['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\n# test['genre_ids_count'] = test['genre_ids'].apply(genre_id_count).astype(np.int8)\n\n# def lyricist_count(x):\n#     if x == 'no_lyricist':\n#         return 0\n#     else:\n#         return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n#     return sum(map(x.count, ['|', '/', '\\\\', ';']))\n\n# train['lyricist'].fillna('no_lyricist',inplace=True)\n# test['lyricist'].fillna('no_lyricist',inplace=True)\n# train['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\n# test['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)\n\ndef composer_count(x):\n    if x == 'no_composer':\n        return 0\n    else:\n        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n\ntrain['composer'].fillna('no_composer',inplace=True)\ntest['composer'].fillna('no_composer',inplace=True)\ntrain['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\ntest['composer_count'] = test['composer'].apply(composer_count).astype(np.int8)\n\ndef is_featured(x):\n    if 'feat' in str(x) :\n        return 1\n    return 0\n\ntrain['artist_name'].fillna('no_artist',inplace=True)\ntest['artist_name'].fillna('no_artist',inplace=True)\ntrain['is_featured'] = train['artist_name'].apply(is_featured).astype(np.int8)\ntest['is_featured'] = test['artist_name'].apply(is_featured).astype(np.int8)\n\ndef artist_count(x):\n    if x == 'no_artist':\n        return 0\n    else:\n        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n\ntrain['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\ntest['artist_count'] = test['artist_name'].apply(artist_count).astype(np.int8)\n\n# if artist is same as composer\ntrain['artist_composer'] = (train['artist_name'] == train['composer']).astype(np.int8)\ntest['artist_composer'] = (test['artist_name'] == test['composer']).astype(np.int8)\n\n# if artist, lyricist and composer are all three same\ntrain['artist_composer_lyricist'] = ((train['artist_name'] == train['composer']) & (train['artist_name'] == train['lyricist']) & (train['composer'] == train['lyricist'])).astype(np.int8)\ntest['artist_composer_lyricist'] = ((test['artist_name'] == test['composer']) & (test['artist_name'] == test['lyricist']) & (test['composer'] == test['lyricist'])).astype(np.int8)\n\n# is song language 17 or 45. \ndef song_lang_boolean(x):\n    if '17.0' in str(x) or '45.0' in str(x):\n        return 1\n    return 0\n\ntrain['song_lang_boolean'] = train['language'].apply(song_lang_boolean).astype(np.int8)\ntest['song_lang_boolean'] = test['language'].apply(song_lang_boolean).astype(np.int8)\n\n\n_mean_song_length = np.mean(train['song_length'])\ndef smaller_song(x):\n    if x < _mean_song_length:\n        return 1\n    return 0\n\ntrain['smaller_song'] = train['song_length'].apply(smaller_song).astype(np.int8)\ntest['smaller_song'] = test['song_length'].apply(smaller_song).astype(np.int8)\n\n# number of times a song has been played before\n_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n_dict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\ndef count_song_played(x):\n    try:\n        return _dict_count_song_played_train[x]\n    except KeyError:\n        try:\n            return _dict_count_song_played_test[x]\n        except KeyError:\n            return 0\n    \n\ntrain['count_song_played'] = train['song_id'].apply(count_song_played).astype(np.int64)\ntest['count_song_played'] = test['song_id'].apply(count_song_played).astype(np.int64)\n\n# number of times the artist has been played\n_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n_dict_count_artist_played_test = {k: v for k, v in test['artist_name'].value_counts().iteritems()}\ndef count_artist_played(x):\n    try:\n        return _dict_count_artist_played_train[x]\n    except KeyError:\n        try:\n            return _dict_count_artist_played_test[x]\n        except KeyError:\n            return 0\n\ntrain['count_artist_played'] = train['artist_name'].apply(count_artist_played).astype(np.int64)\ntest['count_artist_played'] = test['artist_name'].apply(count_artist_played).astype(np.int64)\n\n\nprint (\"Done adding features\")","metadata":{"_uuid":"2f5475aa07fa7f4b59e8e8928d03f67bbcac9347","_cell_guid":"6d0e7314-91f0-4ff5-9081-ebdcb9b1406d"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"train[\"song_year\"] = pd.to_datetime(train[\"song_year\"],format=\"%Y.0\",errors=\"coerce\")\ntest[\"song_year\"] = pd.to_datetime(test[\"song_year\"],format=\"%Y.0\",errors=\"coerce\")","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"train.head()","metadata":{"_uuid":"79ce165c39ba8722eddaa877d76908f979d5772c","scrolled":true,"_cell_guid":"4e2b91e1-8662-47e2-8807-01d757bae658"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"train.to_csv(\"train_merged_kkMusicRec.csv.gz\",index=False,compression=\"gzip\")\ntest.to_csv(\"test_merged_kkMusicRec.csv.gz\",index=False,compression=\"gzip\")","metadata":{"collapsed":true}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# print (\"Train test and validation sets\")\n# for col in train.columns:\n#     if train[col].dtype == object:\n#         train[col] = train[col].astype('category')\n#         test[col] = test[col].astype('category')\n\n\n# X_train = train.drop(['target'], axis=1)\n# y_train = train['target'].values\n\n\n# X_test = test.drop(['id'], axis=1)\n# ids = test['id'].values\n\n\n# # del train, test; gc.collect();\n\n# d_train_final = lgb.Dataset(X_train, y_train)\n# watchlist_final = lgb.Dataset(X_train, y_train)\n# print('Processed data...')","metadata":{"_uuid":"577e8f31dccc7262514f854b96bb213396aea8f6","collapsed":true,"_cell_guid":"05ee917e-dc12-4201-8fe6-0b515286253c"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# params = {\n#         'objective': 'binary',\n#         'metric': 'binary_logloss',\n#         'boosting': 'gbdt',\n#         'learning_rate': 0.3 ,\n#         'verbose': 0,\n#         'num_leaves': 108,\n#         'bagging_fraction': 0.95,\n#         'bagging_freq': 1,\n#         'bagging_seed': 1,\n#         'feature_fraction': 0.9,\n#         'feature_fraction_seed': 1,\n#         'max_bin': 256,\n#         'max_depth': 10,\n#         'num_rounds': 200,\n#         'metric' : 'auc'\n#     }\n\n# %time model_f1 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)","metadata":{"_uuid":"42e044686bd89948d06c2471892c9542605a8a05","collapsed":true,"_cell_guid":"8a7cfb94-afdb-47b1-94d7-88791baa47e5"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# params = {\n#         'objective': 'binary',\n#         'metric': 'binary_logloss',\n#         'boosting': 'dart',\n#         'learning_rate': 0.3 ,\n#         'verbose': 0,\n#         'num_leaves': 108,\n#         'bagging_fraction': 0.95,\n#         'bagging_freq': 1,\n#         'bagging_seed': 1,\n#         'feature_fraction': 0.9,\n#         'feature_fraction_seed': 1,\n#         'max_bin': 256,\n#         'max_depth': 10,\n#         'num_rounds': 210,\n#         'metric' : 'auc'\n#     }\n\n# %time model_f2 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)","metadata":{"_uuid":"a2e8293a6c5ff0c0efdb52fb82f053cfb773e55c","collapsed":true,"_cell_guid":"10895c7a-73f8-45a0-a9b7-e4e489b06268"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# print('Making predictions')\n# p_test_1 = model_f1.predict(X_test)\n# p_test_2 = model_f2.predict(X_test)\n# p_test_avg = np.mean([p_test_1, p_test_2], axis = 0)\n\n\n# print('Done making predictions')","metadata":{"_uuid":"ea33e6b678757c4f45e1cddfac4a37ce06962d33","collapsed":true,"_cell_guid":"89048be8-a137-4e0d-811c-740645c17d1a"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# print ('Saving predictions Model model of gbdt')\n\n# subm = pd.DataFrame()\n# subm['id'] = ids\n# subm['target'] = p_test_avg\n# subm.to_csv('submission_lgbm_avg.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n\n# print('Done!')","metadata":{"_uuid":"28888fb62a1efccb51efb762ac1266695bb82002","collapsed":true,"_cell_guid":"e7b31f60-187f-4744-9416-3c9c876fa838"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# train[\"registration_datetime\"] = pd.to_datetime([train.registration_year,train.registration_month,train.registration_date],infer_datetime_format=True)","metadata":{"_uuid":"5aebbcc7405fe5a69024847f868cd310ee6a8d3d","collapsed":true,"_cell_guid":"16d55440-1072-4be3-a878-874b59f679cb"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"","metadata":{"_uuid":"86d26dec7704adc86d5c7aeb1305395adfce4a1d","collapsed":true,"_cell_guid":"cbdb5b33-6931-43c6-94f6-8764c54b0937"}}],"metadata":{"language_info":{"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}}}