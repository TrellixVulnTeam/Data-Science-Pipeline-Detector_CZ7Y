{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom glob import glob\nimport os\nfrom sklearn.preprocessing import StandardScaler\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#############function to read data###########\n\ndef prepare_data_train(fname):\n    \"\"\" read and prepare training data \"\"\"\n    # Read data\n    data = pd.read_csv(fname)\n    # events file\n    events_fname = fname.replace('_data','_events')\n    # read event file\n    labels= pd.read_csv(events_fname)\n    clean=data.drop(['id' ], axis=1)#remove id\n    labels=labels.drop(['id' ], axis=1)#remove id\n    return  clean,labels\n\ndef prepare_data_test(fname):\n    \"\"\" read and prepare test data \"\"\"\n    # Read data\n    data = pd.read_csv(fname)\n    return data\n\nscaler= StandardScaler()\ndef data_preprocess_train(X):\n    X_prep=scaler.fit_transform(X)\n    #do here your preprocessing\n    return X_prep\ndef data_preprocess_test(X):\n    X_prep=scaler.transform(X)\n    #do here your preprocessing\n    return X_prep\n\n##downsamplig naive like this is not correct, if you do not low pass filter.\n##this down sampling here it needed only to keep the script run below 10 minutes.\n## please do not downsample or use correct procedure to decimate data without alias\nsubsample=100 # training subsample.if you want to downsample the training data\n#######columns name for labels#############\ncols = ['HandStart','FirstDigitTouch',\n        'BothStartLoadPhase','LiftOff',\n        'Replace','BothReleased']\n\n#######number of subjects###############\nsubjects = range(1,13)\nids_tot = []\npred_tot = []\n\n###loop on subjects and 8 series for train data + 2 series for test data\nfor subject in subjects:\n    y_raw= []\n    raw = []\n    ################ READ DATA ################################################\n    fnames =  glob('../input/train/subj%d_series*_data.csv' % (subject))\n    for fname in fnames:\n      data,labels=prepare_data_train(fname)\n      raw.append(data)\n      y_raw.append(labels)\n\n    X = pd.concat(raw)\n    y = pd.concat(y_raw)\n    #transform in numpy array\n    #transform train data in numpy array\n    X_train =np.asarray(X.astype(float))\n    y = np.asarray(y.astype(float))\n\n\n    ################ Read test data #####################################\n    \n    fnames =  glob('../input/test/subj%d_series*_data.csv' % (subject))\n    test = []\n    idx=[]\n    for fname in fnames:\n      data=prepare_data_test(fname)\n      test.append(data)\n      idx.append(np.array(data['id']))\n    X_test= pd.concat(test)\n    ids=np.concatenate(idx)\n    ids_tot.append(ids)\n    X_test=X_test.drop(['id' ], axis=1)#remove id\n    #transform test data in numpy array\n    X_test =np.asarray(X_test.astype(float))\n\n\n    ################ Train classifiers ########################################\n    lr = LogisticRegression()\n    pred = np.empty((X_test.shape[0],6))\n    X_train=data_preprocess_train(X_train)\n    X_test=data_preprocess_test(X_test)\n    for i in range(6):\n        y_train= y[:,i]\n        print('Train subject %d, class %s' % (subject, cols[i]))\n        lr.fit(X_train[::subsample,:],y_train[::subsample])\n        pred[:,i] = lr.predict_proba(X_test)[:,1]   # ??\n\n    pred_tot.append(pred)\n\n# submission file\nsubmission_file = 'grasp-sub-simple.csv'\n# create pandas object for sbmission\nsubmission = pd.DataFrame(index=np.concatenate(ids_tot),\n                          columns=cols,\n                          data=np.concatenate(pred_tot))\n\n# write file\nsubmission.to_csv(submission_file,index_label='id',float_format='%.3f')\n\nfname =  glob('../input/train/subj1_series*_data.csv')\ndata = pd.read_csv(fname)\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"fname =  glob('../input/train/subj1_series*_data.csv')\ndata = pd.read_csv(fname)\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}