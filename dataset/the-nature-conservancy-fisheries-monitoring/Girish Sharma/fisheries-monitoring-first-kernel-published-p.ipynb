{"metadata":{"anaconda-cloud":{},"language_info":{"version":"3.5.3","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","name":"python","file_extension":".py","nbconvert_exporter":"python"},"kernelspec":{"language":"python","name":"conda-env-aind-dog-py","display_name":"Python [conda env:aind-dog]"}},"cells":[{"metadata":{},"source":"# 1. Import Datasets","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from sklearn.datasets import load_files\nfrom keras.utils import np_utils\nimport numpy as np\nfrom glob import glob","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#function to load the dataset\ndef load_dataset(path):\n    data = load_files(path)\n    fish_files = np.array(data['filenames'])\n    fish_target = np_utils.to_categorical(np.array(data['target']), 8)\n    return fish_files,fish_target","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#loading the paths of training set\ntrain_files, train_targets = load_dataset('fishImages/train')\n\n#loading the paths of testing set\ntest_files, _ = load_dataset('fishImages/test')\n\n#printing the number of samples in test and trainig sets.\nprint (\"There are %d images in training dataset\"%len(train_files))\nprint (\"There are %d images in the training set\"%len(test_files))","cell_type":"code"},{"metadata":{},"source":"# 2. Visualizations\n","cell_type":"markdown"},{"metadata":{"scrolled":true},"outputs":[],"execution_count":null,"source":"import matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\n\nsns.set(color_codes=True)\n\n#finding the number of samles in each class\n[ALB, BET, DOL, LAG, NoF, OTHER, SHARK, YFT] = sum(train_targets)\n\n\nfish_count =[ALB, BET, DOL, LAG, NoF, OTHER, SHARK, YFT]\n\nx=np.arange(8)\n\n#plotting the barplot between name of classes and number of samples in each class \nfig, ax = plt.subplots()\nplt.bar(x, fish_count)\nplt.xticks(x, ('ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'))\nplt.xlabel(\"Class Name\")\nplt.ylabel(\"Number of samples in the class\")\nplt.show()","cell_type":"code"},{"metadata":{"scrolled":false},"outputs":[],"execution_count":null,"source":"#function for plotting a histogram for the color intensity of an image\n\ndef intensity_dist(path):\n    #reading the image from its path\n    img = cv2.imread(path)\n    color = ('b','g','r')\n    #calculating the number of pixels of each color\n    for i, col in enumerate(color):\n        histr = cv2.calcHist([img], [i], None, [256], [0,256])\n        plt.plot(histr, color=col)\n    print(\"Histogram for color Internsity of the image below:\")\n    \n    #showing the histogram\n    plt.xlabel(\"value of the pixel for the given channel\")\n    plt.ylabel(\"Number of pixels\")\n    plt.show()\n    \n    #showing the image\n    plt.imshow(img)\n    plt.show()\n    height, width, channels = img.shape\n    print(\"Size of the image - (%d , %d)\"%(height,width)) \n    print(\"-\"*100)\n    \nintensity_dist(train_files[56])\nintensity_dist(train_files[667])\nintensity_dist(train_files[660])\nintensity_dist(train_files[1547])\n","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#intensity_dist(train_files[1147])\n#intensity_dist(test_files[12455])\nintensity_dist(test_files[60])","cell_type":"code"},{"metadata":{},"source":"# 3. Data pre-processing","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"from keras.preprocessing import image\nfrom tqdm import tqdm\n\n#converting image to tensor\ndef path_to_tensor(img_path):\n    # loads RGB image\n    img = image.load_img(img_path, target_size=(224,224))\n    #convering the image to 3-D tensor with shape (224,224,3)\n    x = image.img_to_array(img)\n    #convert 3D tensor to 4D tensor\n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from PIL import ImageFile                            \nImageFile.LOAD_TRUNCATED_IMAGES = True \n\n#preprocessing the data\ntest_tensors = paths_to_tensor(test_files).astype('float32')/255","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"train_tensors = paths_to_tensor(train_files).astype('float32')/255","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#shape of the tensor\nprint(np.shape(train_tensors))","cell_type":"code"},{"metadata":{},"source":"# 4. Creating Benchmark Model","cell_type":"markdown"},{"metadata":{"scrolled":true},"outputs":[],"execution_count":null,"source":"from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\nfrom keras.models import Sequential\n\nbenchmark = Sequential()\n\n# model Convolution layer\nbenchmark.add(Conv2D(filters=16,kernel_size=2,strides=1,activation='relu',input_shape=(224,224,3)))\n# Max Pooling layer to reduce the dimensionality\nbenchmark.add(MaxPooling2D(pool_size=2,strides=2))\n#Dropout layer, for turning off each node with the probability of 0.3\nbenchmark.add(Dropout(0.3))\nbenchmark.add(Conv2D(filters=32, kernel_size=2,strides=1,activation='relu'))\nbenchmark.add(Dropout(0.3))\nbenchmark.add(GlobalAveragePooling2D())\n#A fully connected dense layer with 8 nodes (no of classes of fish)\nbenchmark.add(Dense(8,activation='softmax'))\nbenchmark.summary()","cell_type":"code"},{"metadata":{},"source":"### Compiling the Model","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"benchmark.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","cell_type":"code"},{"metadata":{},"source":"### Train the Model","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\n\nepochs = 5\n\n#checkpointer saves the best weights.\ncheckpointer = ModelCheckpoint(filepath='saved_models/weights.best.benchmark.hdf5', verbose=1, save_best_only=True)\n\nbenchmark.fit(train_tensors, train_targets, batch_size=20, epochs=epochs, callbacks=[checkpointer], validation_split=0.2, verbose=1)","cell_type":"code"},{"metadata":{},"source":"# 5. Making Predictions for Benchmark","cell_type":"markdown"},{"metadata":{},"source":"### Loading the  weights of Benchmark model","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"benchmark.load_weights('saved_models/weights.best.benchmark.hdf5')","cell_type":"code"},{"metadata":{},"source":"### Predictions","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"benchmark_model_prediction = [benchmark.predict(np.expand_dims(img_tensor, axis=0)) for img_tensor in test_tensors]","cell_type":"code"},{"metadata":{},"source":"### Processing the Predictions","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#visaulizing the array\nprint(benchmark_model_prediction[:][0])","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#swapping the axes of the benchmark_model_prediction for easy handling\nbenchmark_model_prediction = np.swapaxes(benchmark_model_prediction,0,1)\n\n#creating a pandas dataframe for with benchmark model's prediction\ndf_pred_model1 = pd.DataFrame(benchmark_model_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])\n\n#first five rows of df_pred_model1 dataframe\nprint(df_pred_model1[:5])","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#extracting name of the image form its path\nimage_names = [test_files[i][22:] for i in range(len(test_files))]\n\n\n#adjusting the filename of the image to match the submission guidelines\nfor i in range(13153):\n    if image_names[i][5]=='_':\n        image_names[i] = \"test_stg2/\" + image_names[i]","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#adding image names to our dataframe\ndf_pred_model1['image'] = pd.DataFrame(image_names)\n\n#reindexing the dataframe\ndf_pred_model1 = df_pred_model1.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)\n\n#printing the first five rows of dataframe\nprint(df_pred_model1[:5])","cell_type":"code"},{"metadata":{},"source":"### Generating .csv file for submission","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"df_pred_model1.to_csv('submission0.csv',index=False)","cell_type":"code"},{"metadata":{"collapsed":true},"source":".\n\n\n.\n\n\n.\n\n\n\n\n\n# Score Achieved by Model 1 - 2.00267\n\n\n.\n\n\n.\n\n\n.\n\n\n","cell_type":"markdown"},{"metadata":{},"source":"# 6. Model 2 (Using Transfer Learning, Extracted VGG-19 features)","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from keras.applications.vgg19 import VGG19\nfrom keras.preprocessing import image\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Input\nimport numpy as np\n\n#Extracting the weights of VGG19 model pretrained on Imagenet\n#defing the Input shape\ninput_tensor = Input(shape=(224,224,3))\n#extracting the weights wof VGG19, without top layers\n#and MaxPooling as pooling layer\nbase_model = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False, pooling=max)\n#removing the last layer\noutput = base_model.get_layer(index = -1).output\n#defining the model\nVGG19_model2 = Model(base_model.input, output)\nVGG19_model2.summary()","cell_type":"code"},{"metadata":{},"source":"### Extracting VGG19 features for training and testing datasets","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"VGG19_features = [VGG19_model2.predict(np.expand_dims(train_tensor, axis=0)) for train_tensor in train_tensors]\n\nVGG19_features_test = [VGG19_model2.predict(np.expand_dims(test_tensor, axis=0)) for test_tensor in test_tensors]","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print (\"Shape of VGG_19_features: {0}\".format(np.shape(VGG19_features)))\n\nprint (\"Shape of VGG_19_features_test: {0}\".format(np.shape(VGG19_features_test)))\n","cell_type":"code"},{"metadata":{},"source":"### Pre-processing the features","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#VGG_19_features having 5 dimensions, so we have to squeeze it to a 4 dim array by removing extra dimension\nsqueezed_VGG19_train = np.squeeze(VGG19_features, axis=1)\n#squeezing the test features\nsqueezed_VGG19_test = np.squeeze(VGG19_features_test, axis=1)\n\nprint (\"Shape of squeezed_VGG19_train: {0}\".format(np.shape(squeezed_VGG19_train)))\nprint (\"Shape of squeezed_VGG_19_test: {0}\".format(np.shape(squeezed_VGG19_test)))\n","cell_type":"code"},{"metadata":{},"source":"### Defining the Model architecture","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from keras.models import Sequential\nfrom keras.layers import MaxPooling2D, GlobalMaxPooling2D, Dense\n\nfish_model = Sequential()\n#adding a GlobalMaxPooling2D layer with with input shape same as the shape of Squeezed_VGG19_train.\nfish_model.add(GlobalMaxPooling2D(input_shape=squeezed_VGG19_train.shape[1:]))\n#adding a fully connected dense layer with relu activation function\nfish_model.add(Dense(1024, activation='relu'))\n#adding a dense layer with softmax activation function.\n#no of nodes are same as the number of classes of fish.\nfish_model.add(Dense(8, activation = 'softmax'))\nfish_model.summary()","cell_type":"code"},{"metadata":{},"source":"### Compiling the Model 2","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#compiling the model with rmsprop optimizer\nfish_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","cell_type":"code"},{"metadata":{},"source":"### Training Model 2","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#training fish_model on the trainig dataset\nfrom keras.callbacks import ModelCheckpoint\n\n#checkpointer for saving only best weights\ncheckpointer_VGG = ModelCheckpoint(filepath='saved_models/weights.best.VGG19.hdf5', verbose=1, save_best_only=True)\n\nfish_model.fit(squeezed_VGG19_train,train_targets,validation_split=0.3,batch_size=20,\n               epochs=5,callbacks=[checkpointer_VGG],verbose=1)","cell_type":"code"},{"metadata":{},"source":"# 7. Making Predictions with Model 2","cell_type":"markdown"},{"metadata":{},"source":"### Loading the weights ","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"fish_model.load_weights('saved_models/weights.best.VGG19.hdf5')","cell_type":"code"},{"metadata":{},"source":"### Prediction","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#making the predictions from fish_model\nfish_model_prediction = [fish_model.predict(np.expand_dims(feature, axis=0)) for feature in squeezed_VGG19_test]","cell_type":"code"},{"metadata":{},"source":"### Pre-processing the predictions","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print(fish_model_prediction[1])","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print(np.shape(fish_model_prediction))","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#swapping the axes for better handling\nfish_model_prediction = np.swapaxes(fish_model_prediction,0,1)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"import pandas as pd\n\n#creating a pandas dataframe for with benchmark model's prediction\ndf_pred_fish_model = pd.DataFrame(fish_model_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print(df_pred_fish_model[:5])","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#extracting name of the image form its path\nimage_names = [test_files[i][22:] for i in range(len(test_files))]\n\n\n#adjusting the filename of the image to match the submission guidelines\nfor i in range(13153):\n    if image_names[i][5]=='_':\n        image_names[i] = \"test_stg2/\" + image_names[i]","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#adding image names to our dataframe\ndf_pred_fish_model['image'] = pd.DataFrame(image_names)\n\n#reindexing the dataframe\ndf_pred_fish_model = df_pred_fish_model.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)\n\n#printing the first five rows of dataframe\nprint(df_pred_fish_model[:5])","cell_type":"code"},{"metadata":{},"source":"### Generating .csv file for submission","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"df_pred_fish_model.to_csv('submission2.csv',index=False)","cell_type":"code"},{"metadata":{"collapsed":true},"source":".\n\n\n.\n\n\n.\n\n\n\n\n\n# Score Achieved by Model 2 - 2.28866\n\n\n.\n\n\n.\n\n\n.\n\n\n","cell_type":"markdown"},{"metadata":{},"source":"# 8. Model-3 (Using less layers of VGG19)","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from keras.applications.vgg19 import VGG19\nfrom keras.preprocessing import image\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Input\nimport numpy as np\n\n#Extracting the weights of VGG19 model pretrained on Imagenet\n#defing the Input shape\ninput_tensor = Input(shape=(224,224,3))\n#extracting the weights wof VGG19, without top layers\n#and MaxPooling as pooling layer\nbase_model = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False, pooling=max)\n#removing the last 11 layers\noutput = base_model.get_layer(index = -11).output\n#defining the model\nVGG19_model3 = Model(base_model.input, output)\nVGG19_model3.summary()","cell_type":"code"},{"metadata":{},"source":"### Extracting VGG19 features for training and testing datasets","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"VGG_19_features_2 = [VGG19_model3.predict(np.expand_dims(train_tensor, axis=0)) for train_tensor in train_tensors]\n\nVGG_19_features_test_2 = [VGG19_model3.predict(np.expand_dims(test_tensor, axis=0)) for test_tensor in test_tensors]","cell_type":"code"},{"metadata":{},"source":"### Pre-processing the features","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"squeezed_VGG19_train_2 = np.squeeze(VGG_19_features_2, axis=1)\nprint (\"Shape of squeezed_VGG19_train_2: {0}\".format(np.shape(squeezed_VGG19_train_2)))","cell_type":"code"},{"metadata":{},"source":"## MEMORY ERROR","cell_type":"markdown"},{"metadata":{"scrolled":true},"outputs":[],"execution_count":null,"source":"squeezed_VGG19_test_2 = np.squeeze(VGG_19_features_test_2, axis=1)\n\nprint (\"Shape of squeezed_VGG_19_test_2: {0}\".format(np.shape(squeezed_VGG19_test_2)))","cell_type":"code"},{"metadata":{},"source":"### MEMORY ERROR","cell_type":"markdown"},{"metadata":{},"source":"# 9. Model 4 (New Model From scratch)","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\nfrom keras.models import Sequential\n\nmodel4 = Sequential()\n\n# model Convolution layer\nmodel4.add(Conv2D(filters=16,kernel_size=2,strides=1,activation='relu',input_shape=(224,224,3)))\n# Max Pooling layer to reduce the dimensionality\nmodel4.add(MaxPooling2D(pool_size=2,strides=2))\n#Dropout layer, for turning off each node with the probability of 0.2\nmodel4.add(Dropout(0.2))\nmodel4.add(Conv2D(filters=32, kernel_size=2,strides=1,activation='relu'))\nmodel4.add(MaxPooling2D(pool_size=2,strides=2))\nmodel4.add(Dropout(0.2))\nmodel4.add(Conv2D(filters=64,kernel_size=2,strides=1,activation='relu'))\nmodel4.add(MaxPooling2D(pool_size=2,strides=2))\nmodel4.add(Dropout(0.2))\nmodel4.add(GlobalAveragePooling2D())\n#A fully connected dense layer with 8 nodes (no of classes of fish)\nmodel4.add(Dense(8,activation='softmax'))\nmodel4.summary()","cell_type":"code"},{"metadata":{},"source":"### Compiling the Model","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","cell_type":"code"},{"metadata":{},"source":"### Train the Model","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\n\nepochs = 10\n\n#checkpointer saves the weight of the best model only\ncheckpointer_4 = [EarlyStopping(monitor='val_loss',min_delta=0.01, patience=0, verbose=1), ModelCheckpoint(filepath='saved_models/weights.best.from_scratch_6.hdf5',\n                                  verbose=1, save_best_only=True)]\n\nmodel4.fit(train_tensors, train_targets, batch_size=20, epochs=epochs, callbacks=checkpointer_4, validation_split=0.3, verbose=1)","cell_type":"code"},{"metadata":{},"source":"# 10. Making Predictions for Model 4","cell_type":"markdown"},{"metadata":{},"source":"### Loading the  weights","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#loading the weights of pretrained model\nmodel4.load_weights('saved_models/weights.best.from_scratch_6.hdf5')","cell_type":"code"},{"metadata":{},"source":"### Predictions","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#making predictions\nmodel4_prediction = [model4.predict(np.expand_dims(img_tensor, axis=0)) for img_tensor in test_tensors]","cell_type":"code"},{"metadata":{},"source":"### Processing the Predictions","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#swapping the axes of the model4_prediction for easy handling\nmodel4_prediction = np.swapaxes(model4_prediction,0,1)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"import pandas as pd\n\n#creating a pandas dataframe for with benchmark model's prediction\ndf_pred_model4 = pd.DataFrame(model4_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#extracting name of the image form its path\nimage_names = [test_files[i][22:] for i in range(len(test_files))]\n\n\n#adjusting the filename of the image to match the submission guidelines\nfor i in range(13153):\n    if image_names[i][5]=='_':\n        image_names[i] = \"test_stg2/\" + image_names[i]","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#adding image names to our dataframe\ndf_pred_model4['image'] = pd.DataFrame(image_names)\n\n#reindexing the dataframe\ndf_pred_model4 = df_pred_model4.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)","cell_type":"code"},{"metadata":{},"source":"### Generating .csv file for submission","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"df_pred_model4.to_csv('submission4.csv',index=False)","cell_type":"code"},{"metadata":{"collapsed":true},"source":".\n\n\n.\n\n\n.\n\n\n\n\n\n# Score Achieved by Model 4 - 1.65209\n\n\n.\n\n\n.\n\n\n.\n\n\n","cell_type":"markdown"},{"metadata":{},"source":"# 11. Model 5 (Refining Model 4)","cell_type":"markdown"},{"metadata":{"scrolled":true},"outputs":[],"execution_count":null,"source":"from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\nfrom keras.models import Sequential\n\nmodel5 = Sequential()\n\n#Model architecture.\n#Convolution layer\nmodel5.add(Conv2D(filters=32,kernel_size=2,strides=1,activation='relu',input_shape=(224,224,3)))\n# Max Pooling layer to reduce the dimensionality\nmodel5.add(MaxPooling2D(pool_size=2,strides=2))\n#Dropout layer, for turning off each node with the probability of 0.5\nmodel5.add(Dropout(0.5))\nmodel5.add(Conv2D(filters=64, kernel_size=2,strides=1,activation='relu'))\nmodel5.add(MaxPooling2D(pool_size=2,strides=2))\n#Dropout layer, for turning off each node with the probability of 0.4\nmodel5.add(Dropout(0.4))\nmodel5.add(Conv2D(filters=128,kernel_size=2,strides=1,activation='relu'))\nmodel5.add(MaxPooling2D(pool_size=2,strides=2))\n#Dropout layer, for turning off each node with the probability of 0.2\nmodel5.add(Dropout(0.2))\n#Global Average Pooling layer for object localization\nmodel5.add(GlobalAveragePooling2D())\n#A fully connected dense layer with 8 nodes (no of classes of fish)\nmodel5.add(Dense(8,activation='softmax'))\n#printing the summary of the architecture\nmodel5.summary()","cell_type":"code"},{"metadata":{},"source":"### Compiling the Model","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","cell_type":"code"},{"metadata":{},"source":"### Train the Model","cell_type":"markdown"},{"metadata":{"scrolled":true},"outputs":[],"execution_count":null,"source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\n#number of epochs\nepochs = 5\nbatch_size=20\n#split the training data into training and validation datasets (30% for validation and 70 % for training).\nvalidation_split=0.3\n# print the progress\nverbose=0.1\n\n#checkpointer saves the weight of the best model only\ncheckpointer_5 = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', verbose=1, save_best_only=True)\n\nmodel5.fit(train_tensors, train_targets, batch_size=batch_size, epochs=epochs, \n           callbacks=[checkpointer_5], validation_split=validation_split, verbose=verbose)","cell_type":"code"},{"metadata":{},"source":"# 12. Making Predictions for Model 5","cell_type":"markdown"},{"metadata":{},"source":"### Loading the  weights","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"model5.load_weights('saved_models/weights.best.from_scratch.hdf5')","cell_type":"code"},{"metadata":{},"source":"### Predictions","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"model5_prediction = [model5.predict(np.expand_dims(img_tensor, axis=0)) for img_tensor in test_tensors]","cell_type":"code"},{"metadata":{},"source":"### Processing the Predictions","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#visaulizing the array\nprint(model5_prediction[:][0])","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#swapping the axes of the model4_prediction for easy handling\nmodel5_prediction = np.swapaxes(model5_prediction,0,1)\n\n#creating a pandas dataframe for with benchmark model's prediction\ndf_pred_model5 = pd.DataFrame(model5_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])\n\n#first five rows of df_pred_model1 dataframe\nprint(df_pred_model5[:5])","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#extracting name of the image form its path\nimage_names = [test_files[i][22:] for i in range(len(test_files))]\n\n\n#adjusting the filename of the image to match the submission guidelines\nfor i in range(13153):\n    if image_names[i][5]=='_':\n        image_names[i] = \"test_stg2/\" + image_names[i]","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#adding image names to our dataframe\ndf_pred_model5['image'] = pd.DataFrame(image_names)\n\n#reindexing the dataframe\ndf_pred_model5 = df_pred_model5.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)\n\n#printing the first five rows of dataframe\nprint(df_pred_model5[:5])","cell_type":"code"},{"metadata":{},"source":"### Generating .csv file for submission","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"df_pred_model5.to_csv('submission5.csv',index=False)","cell_type":"code"},{"metadata":{"collapsed":true},"source":".\n\n\n.\n\n\n.\n\n\n\n\n\n# Score Achieved by Model 5 - 1.56079\n\n\n.\n\n\n.\n\n\n.\n\n\n","cell_type":"markdown"},{"metadata":{},"source":"# 13. Model 6 (Refining Model 5)","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\nfrom keras.models import Sequential\n\nmodel6 = Sequential()\n\n# model Convolution layer\nmodel6.add(Conv2D(filters=32,kernel_size=2,strides=1,activation='relu',input_shape=(224,224,3)))\n# Max Pooling layer to reduce the dimensionality\nmodel6.add(MaxPooling2D(pool_size=2,strides=2))\n#Dropout layer, for turning off each node with the probability of 0.2 \nmodel6.add(Dropout(0.2))\nmodel6.add(Conv2D(filters=64, kernel_size=2,strides=1,activation='relu'))\nmodel6.add(MaxPooling2D(pool_size=2,strides=2))\n#Dropout layer, for turning off each node with the probability of 0.2\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv2D(filters=128,kernel_size=2,strides=1,activation='relu'))\nmodel6.add(MaxPooling2D(pool_size=2,strides=2))\n#Dropout layer, for turning off each node with the probability of 0.2\nmodel6.add(Dropout(0.2))\nmodel6.add(GlobalAveragePooling2D())\n#A fully connected dense layer with 8 nodes (no of classes of fish)\nmodel6.add(Dense(8,activation='softmax'))\nmodel6.summary()","cell_type":"code"},{"metadata":{},"source":"### Compiling the Model","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"model6.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","cell_type":"code"},{"metadata":{},"source":"### Train the Model","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\n\nepochs = 10\n\n#checkpointer saves the weight of the best model only\ncheckpointer_6 = [EarlyStopping(monitor='val_loss',min_delta=0.01, patience=0, verbose=1), ModelCheckpoint(filepath='saved_models/weights.best.from_scratch_5.hdf5',\n                                  verbose=1, save_best_only=True)]\n\nmodel6.fit(train_tensors, train_targets, batch_size=20, epochs=epochs, callbacks=checkpointer_6, validation_split=0.3, verbose=1)","cell_type":"code"},{"metadata":{},"source":"# 14. Making Predictions for Model 6","cell_type":"markdown"},{"metadata":{},"source":"### Loading the  weights","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#loading the weights of pretrained model\nmodel6.load_weights('saved_models/weights.best.from_scratch_5.hdf5')","cell_type":"code"},{"metadata":{},"source":"### Predictions","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#making predictions\nmodel6_prediction = [model6.predict(np.expand_dims(img_tensor, axis=0)) for img_tensor in test_tensors]","cell_type":"code"},{"metadata":{},"source":"### Processing the Predictions","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#swapping the axes of the model6_prediction for easy handling\nmodel6_prediction = np.swapaxes(model6_prediction,0,1)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"import pandas as pd\n\n#creating a pandas dataframe for with benchmark model's prediction\ndf_pred_model6 = pd.DataFrame(model6_prediction[0][:], columns=['ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'])","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"#extracting name of the image form its path\nimage_names = [test_files[i][22:] for i in range(len(test_files))]\n\n\n#adjusting the filename of the image to match the submission guidelines\nfor i in range(13153):\n    if image_names[i][5]=='_':\n        image_names[i] = \"test_stg2/\" + image_names[i]","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"#adding image names to our dataframe\ndf_pred_model6['image'] = pd.DataFrame(image_names)\n\n#reindexing the dataframe\ndf_pred_model6 = df_pred_model6.reindex_axis(['image','ALB','BET','DOL','LAG','NoF','OTHER','SHARK','YFT'], axis=1)","cell_type":"code"},{"metadata":{},"source":"### Generating .csv file for submission","cell_type":"markdown"},{"metadata":{},"outputs":[],"execution_count":null,"source":"df_pred_model6.to_csv('submission6.csv',index=False)","cell_type":"code"},{"metadata":{"collapsed":true},"source":".\n\n\n.\n\n\n.\n\n\n\n\n\n# Score Achieved by Model 6 - 1.51518\n\n\n.\n\n\n.\n\n\n.\n\n\n","cell_type":"markdown"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"","cell_type":"code"}],"nbformat":4,"nbformat_minor":1}