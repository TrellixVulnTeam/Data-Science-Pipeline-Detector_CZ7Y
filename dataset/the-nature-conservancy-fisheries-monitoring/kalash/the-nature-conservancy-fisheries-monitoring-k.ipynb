{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nimport cv2\nimport os, glob\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten, Activation\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D,ZeroPadding2D\nfrom keras.utils import np_utils\nfrom matplotlib import pyplot as plt\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(data_dir):\n    \n    # Get all subdirectories of data_dir. Each represents a label.\n    directories = [d for d in os.listdir(data_dir)\n                   if os.path.isdir(os.path.join(data_dir, d))]\n    # Loop through the label directories and collect the data in\n    # two lists, labels and images.\n    labels = []\n    images = []\n\n    category = 0\n    for d in directories:\n        label_dir = os.path.join(data_dir, d)\n        file_names = [os.path.join(label_dir, f)\n                      for f in os.listdir(label_dir)\n                      if f.endswith(\".jpg\")]\n        \n        # adding an early stop for sake of speed\n        #stop = 0\n        for f in file_names:\n            img = cv2.imread(f)\n            imresize = cv2.resize(img, (200,125))\n            #plt.imshow(imresize)\n            images.append(imresize)\n            labels.append(category)\n            # remove this to use full data set\n            '''\n            if stop > 30:\n                break\n            stop += 1'\n            # end early stop\n            '''\n        category += 1\n        \n    return images, labels\n\ndata_dir = \"../input/kkkkkkkkkkkkkkkkkkk/train\"\nimages, labels = load_data(data_dir)\n\n# confirm that we have the data\nprint(images[0:10])\nprint(labels[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\ndef cross_validate(Xs, ys):\n    X_train, X_test, y_train, y_test = train_test_split(\n            Xs, ys, test_size=0.2, random_state=0)\n    return X_train, X_test, y_train, y_test\n\nX_train, X_valid, y_train, y_valid = cross_validate(images, labels)\n\n# confirm we got our data\nprint(y_valid[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train).astype('float32')\nX_valid = np.array(X_valid).astype('float32')\nX_train = X_train / 255.0\nX_valid = X_valid / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.array(y_train)\ny_valid = np.array(y_valid)\ny_train = np_utils.to_categorical(y_train)\ny_valid = np_utils.to_categorical(y_valid)\nnum_classes = y_valid.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = RMSprop(lr=1e-4)\nobjective = 'categorical_crossentropy'\n\ndef center_normalize(x):\n    return (x - K.mean(x)) / K.std(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Activation(activation=center_normalize, input_shape=(125,200,3)))\n#model.add(Convolution2D(32, 3, 3, input_shape=(250,400, 3), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n\nmodel.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\nmodel.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss=objective, optimizer=optimizer)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, batch_size=64, nb_epoch=30,\n              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\n\npreds = model.predict(X_valid, verbose=1)\nprint(\"Validation Log Loss: {}\".format(log_loss(y_valid, preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"model = Sequential()\nmodel.add(Convolution2D(32, 3, 3, input_shape=(125, 200, 3), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\nmodel.add(Dropout(0.2))\nmodel.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n# Compile model\nepochs = 30\nlrate = 0.01\ndecay = lrate/epochs\nsgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\nprint(model.summary())"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"seed = 7\nnp.random.seed(seed)\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=epochs, batch_size=64)\n# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from keras.models import load_model\n\nmodel.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"},{"metadata":{"trusted":true},"cell_type":"code","source":"path1  = '../input/kalashkalash/test_stg1'\nfile_names1 = [os.path.join(path1, f)\n                      for f in os.listdir(path1)\n                      if f.endswith(\".jpg\")]\nimages1 = []\nfor f in file_names1:\n    img = cv2.imread(f)\n    imresize = cv2.resize(img, (200, 125))\n    #plt.imshow(imresize)\n    images1.append(imresize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path2  = '../input/testdataset/test_stg2/test_stg2'\nfile_names2 = [os.path.join(path2, f)\n                      for f in os.listdir(path2)\n                      if f.endswith(\".jpg\")]\nfor f in file_names2:\n    img = cv2.imread(f)\n    imresize = cv2.resize(img, (200, 125))\n    #plt.imshow(imresize)\n    images1.append(imresize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = np.array(images1).astype('float32')\ntest = test/255.0\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = model.predict(test, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imfile = []\nfor f in file_names1:\n    k = f.split('/')\n    imfile.append(k[-1])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(imfile)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in file_names2:\n    k = f.split('/')\n    imfile.append('test_stg2/'+k[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\nsubmission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\nsubmission.insert(0, 'image', imfile)\nsubmission[1005:1010]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('mycsvfile2.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}