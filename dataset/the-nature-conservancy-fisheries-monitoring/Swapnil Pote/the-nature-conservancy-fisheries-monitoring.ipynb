{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport json\nimport cv2\nimport keras\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Dropout, Lambda, Activation, Flatten, Input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5458/bet_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5459/shark_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5460/dol_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5461/yft_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5462/alb_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147157/5463/lag_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/147332/5471/other_labels.json\n!wget https://storage.googleapis.com/kaggle-forum-message-attachments/158691/5864/NoF_labels.json","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\".\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip -q ../input/train.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_images = []\ntrn_labels = []\n\nfor category in os.listdir(\"train/\"):\n    if os.path.isdir(\"train/%s\" % (category)):\n        for img in os.listdir(\"train/%s\" % (category)):\n            if img.endswith(\".jpg\"):\n                trn_images.append(\"train/%s/%s\" % (category, img))\n                trn_labels.append(\"%s\" % (category))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_images[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_labels[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.DataFrame({\"images\": trn_images, \"labels\": trn_labels})\ndataset.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = dataset.groupby(\"labels\")\ngrouped.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = [img[0] for img in grouped.first().values]\nlabels = [filename.split(\"/\")[1] for filename in filenames]\nprint(filenames)\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = []\ny = []\nfor filename, label in zip(filenames, labels):\n    img = cv2.imread(filename)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (224, 224))\n    x.append(img)\n    y.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print images of each class\nfig, axs = plt.subplots(2, 4, figsize=(25, 15))\nfor ax, img, label in zip(axs.flatten(), x, y):\n    ax.set_title(label, fontsize=15)\n    ax.imshow(img)\n    ax.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label2idx = {k:i for i, k in enumerate(labels)}\nidx2label = {i:k for i, k in enumerate(labels)}\n\nprint(label2idx)\nprint(idx2label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.zeros((3777, 224, 224, 3))\ny_train = []\ntrn_size = np.zeros((3777, 2))\ntrn_filename = np.empty(3777, dtype=np.object)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, len(y_train), trn_size.shape, trn_filename.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = 0\nfor rec in dataset.values:\n    img = cv2.imread(rec[0])\n    height, width, channel = img.shape\n    img = cv2.resize(img, (224, 224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    X_train[counter] = img\n    y_train.append(label2idx.get(rec[1]))\n    trn_size[counter][0] = width\n    trn_size[counter][1] = height\n    trn_filename[counter] = rec[0].split('/')[2]\n\n    counter += 1\n\ny_train = keras.utils.to_categorical(y_train, 8)\npermutation = np.random.permutation(X_train.shape[0])\nX_train = X_train[permutation]\ny_train = y_train[permutation]\ntrn_size = trn_size[permutation]\ntrn_filename = trn_filename[permutation]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train[100:102]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(trn_size[0:5])\nprint(trn_filename[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anno_classes = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bb_json = {}\n\nfor c in anno_classes:\n    j = json.load(open('{}_labels.json'.format(c), 'r'))\n    \n    for l in j:\n        if 'annotations' in l.keys() and len(l['annotations']) > 0:\n            bb_json[l['filename']] = l['annotations'][-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bb_json['img_07763.jpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"empty_bbox = {'height': 0., 'width': 0., 'x': 0., 'y': 0.}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in trn_filename:\n    if not f in bb_json.keys(): bb_json[f] = empty_bbox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bb_json['img_07763.jpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_bb(img, width, height):\n    bb = []\n    conv_x = (224. / width)\n    conv_y = (224. / height)\n    bb.append(bb_json[img]['height'] * conv_y)\n    bb.append(bb_json[img]['width'] * conv_x)\n    bb.append(max(bb_json[img]['x'] * conv_x, 0))\n    bb.append(max(bb_json[img]['y'] * conv_y, 0))\n    return bb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(bb_json.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_resize_dim = []\ntrn_bbox = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(trn_filename)):\n    trn_bbox.append(convert_bb(trn_filename[i], trn_size[i][0], trn_size[i][1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_bbox = np.asarray(trn_bbox)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(trn_bbox[100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(trn_filename[100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bb_json.get('img_03693.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_img = Input(shape=(224, 224, 3))\n\nx = Conv2D(32, (3, 3), padding = 'same', activation = 'relu')(input_img)\nx = Conv2D(32, (3, 3), padding = 'same', activation = 'relu')(x)\nx = MaxPooling2D((2, 2))(x)\n\nx = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(x)\nx = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(x)\nx = MaxPooling2D((2, 2))(x)\n\nx = Flatten()(x)\nx = Dense(512, activation = 'relu')(x)\nx = Dense(512, activation = 'relu')(x)\n\nx_bb = Dense(4, name='bb')(x)\nx_class = Dense(8, activation='softmax', name='class')(x)\n\nmodel = Model([input_img], [x_bb, x_class])\nmodel.compile(Adam(lr=0.001), loss=['mse', 'categorical_crossentropy'], metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, [trn_bbox, y_train], batch_size=64, epochs=10, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = cv2.imread('train/ALB/img_00003.jpg')\ntest = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\ntest = cv2.resize(test, (224, 224))\ntest = test.reshape(1, 224, 224, 3)\n\nresult = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result[1], np.argmax(result[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}