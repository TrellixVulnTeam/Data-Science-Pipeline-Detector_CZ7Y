{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b35aca4-9fe8-b58f-0a17-01ecc37fa0aa"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport cv2\nfrom sklearn.cross_validation import KFold\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\nfrom keras.optimizers import SGD, Adagrad\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom keras.constraints import maxnorm\nfrom sklearn.metrics import log_loss\nfrom keras import __version__ as keras_version\nimport tensorflow as tf\nprint('完成读取相应包')\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7900a874-a987-55ef-9700-0a2c30f73eb5"},"outputs":[],"source":"#img = cv2.imread('../input/train/ALB/img_00967.jpg')\n#resized = cv2.resize(img, (128, 128), cv2.INTER_LINEAR)\n#Gray = resized[:,:,1]*0.299 + resized[:,:,1]*0.587 + resized[:,:,1]*0.114"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c5c5a92f-5b45-c6bc-b404-75adf536a72f"},"outputs":[],"source":"def get_im_cv2(path):\n    img = cv2.imread(path)\n    resized = cv2.resize(img, (128, 128), cv2.INTER_LINEAR)\n    resized = resized[:,:,1]*0.299 + resized[:,:,2]*0.587 + resized[:,:,3]*0.114\n    return resized\n\ndef load_train():\n    X_train = []\n    X_train_id = []\n    y_train = []\n\n    print('Read train images')\n    folders = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n    for fld in folders:\n        index = folders.index(fld)\n        print('Load folder {} (Index: {})'.format(fld, index))\n        path = os.path.join('..', 'input', 'train', fld, '*.jpg')\n        files = glob.glob(path)\n        for fl in files:\n            flbase = os.path.basename(fl)\n            img = get_im_cv2(fl)\n            X_train.append(img)\n            X_train_id.append(flbase)\n            y_train.append(index)\n\n    return X_train, y_train, X_train_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"04cc2dd0-34a7-fdfa-79ef-a14f42763bef"},"outputs":[],"source":"def load_test():\n    path = os.path.join('..', 'input', 'test_stg1', '*.jpg')\n    files = sorted(glob.glob(path))\n\n    X_test = []\n    X_test_id = []\n    for fl in files:\n        flbase = os.path.basename(fl)\n        img = get_im_cv2(fl)\n        X_test.append(img)\n        X_test_id.append(flbase)\n\n    return X_test, X_test_id\n\ndef create_submission(predictions, test_id, info):\n    result1 = pd.DataFrame(predictions, columns=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n    result1.loc[:, 'image'] = pd.Series(test_id, index=result1.index)\n    sub_file = 'submission1.csv'\n    result1.to_csv(sub_file, index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58ded619-074d-0a58-a9e6-95aa3eb57720"},"outputs":[],"source":"#读取数据\ntrain_data, train_target, train_id = load_train()\n#转换为array\ntrain_data = np.array(train_data, dtype=np.uint8)\ntrain_target = np.array(train_target, dtype=np.uint8)\n#转换矩阵顺序\n#train_data = train_data.transpose((0, 3, 1, 2))\n#数据归一化到0~1之间\ntrain_data = train_data.astype('float32')\ntrain_data = train_data / 255\n#label转换为哑变量\ntrain_target = np_utils.to_categorical(train_target, 8)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69cbe1c7-aecb-5b5d-b35b-f288fc8d8c56"},"outputs":[],"source":"#读取测试数据\ntest_data, test_id = load_test()\ntest_data = np.array(test_data, dtype=np.uint8)\ntest_data = test_data.transpose((0, 3, 1, 2))\ntest_data = test_data.astype('float32')\ntest_data = test_data / 255"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb2f73f8-ee84-7fe6-797d-476c828ba1ef"},"outputs":[],"source":"def dict_to_list(d):\n    ret = []\n    for i in d.items():\n        ret.append(i[1])\n    return ret\n\n\ndef merge_several_folds_mean(data, nfolds):\n    a = np.array(data[0])\n    for i in range(1, nfolds):\n        a += np.array(data[i])\n    a /= nfolds\n    return a.tolist()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60db4ffe-2816-8253-b9d1-0e2801db0de2"},"outputs":[],"source":"learning_rate = 0.001\ntraining_iters = 2000\nbatch_size = 128\ndisplay_step = 10\n\n# Network Parameters\nn_input = 16384 #data input (img shape: 128*128)\nn_classes = 8 # total classes (0-7 digits)\ndropout = 0.75 # Dropout, probability to keep units\n\nx = tf.placeholder(tf.float32, [None, n_input])\ny = tf.placeholder(tf.float32, [None, n_classes])\nkeep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n\n# Create some wrappers for simplicity\ndef conv2d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n\n\ndef maxpool2d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n                          padding='SAME')\n\n\n# Create model\ndef conv_net(x, weights, biases, dropout):\n    # Reshape input picture\n    x = tf.reshape(x, shape=[-1, 128, 128, 1])\n\n    # Convolution Layer\n    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n    # Max Pooling (down-sampling)\n    conv1 = maxpool2d(conv1, k=2)\n\n    # Convolution Layer\n    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n    # Max Pooling (down-sampling)\n    conv2 = maxpool2d(conv2, k=2)\n\n    # Fully connected layer\n    # Reshape conv2 output to fit fully connected layer input\n    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n    fc1 = tf.nn.relu(fc1)\n    # Apply Dropout\n    fc1 = tf.nn.dropout(fc1, dropout)\n\n    # Output, class prediction\n    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n    return out\n\n# Store layers weight & bias\nweights = {\n    # 5x5 conv, 1 input, 32 outputs\n    'wc1': tf.Variable(tf.random_normal([16, 16, 1, 32])),\n    # 5x5 conv, 32 inputs, 64 outputs\n    'wc2': tf.Variable(tf.random_normal([16, 16, 32, 64])),\n    # fully connected, 7*7*64 inputs, 1024 outputs\n    'wd1': tf.Variable(tf.random_normal([32*32*64, 1024])),\n    # 1024 inputs, 10 outputs (class prediction)\n    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bd1': tf.Variable(tf.random_normal([1024])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9528c7fd-ef3b-e4eb-7045-3a5d6244ae6f"},"outputs":[],"source":"pred = conv_net(x, weights, biases, keep_prob)\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n# Initializing the variables\ninit = tf.initialize_all_variables()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9fd11823-ad19-1b77-13a0-03387afbfa35"},"outputs":[],"source":"train_target.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"39ed4358-5931-cdcf-99c0-a58569334f9d"},"outputs":[],"source":"sess = tf.Session()\nsess.run(init)\n\nfor i in range(training_iters):\n    feed={x:train_data, y:train_target,keep_prob: dropout}\n    sess.run(optimizer, feed_dict=feed)\n    if i % 1000 == 0 or i == ITERATIONS-1:\n        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x, y: batch_y,keep_prob: 1.})\n        print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\nprint(\"Optimization Finished!\")        "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7a8f072-cf47-653c-3c55-a475e2b875bb"},"outputs":[],"source":"predicted = sess.run(y, feed_dict={x:test_features})\n\n\nsess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n                                      y: mnist.test.labels[:256],\n                                      keep_prob: 1.}))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}