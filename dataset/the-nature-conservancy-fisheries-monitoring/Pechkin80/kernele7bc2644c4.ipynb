{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\n# # The Nature Conservancy Fisheries Monitoring\n\n# https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring\n\nimport os\nimport json\nfrom glob import glob\nimport sys\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom IPython.display import HTML\nimport base64\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport keras.backend as K\n\n# # Загружаем разметку\nimport os\nprint(os.listdir(\"./\"))\n\n#CUDA_VISIBLE_DEVICES=''\n# TODO: скачайте данные и сохраните в директорию:\nTRAIN_PREFIX = '../input/the-nature-conservancy-fisheries-monitoring/train'\nVALIDATION_PREFIX = './data/fish/test_stg1'\nORIGINAL_IMG_HEIGHT = 750\nORIGINAL_IMG_WIDTH = 1200\nIMG_HEIGHT = 468#int(750/1.6)\nIMG_WIDTH = 752#int(1200/1.6)\n\nANCHOR_WIDTH = 100#150.\nANCHOR_HEIGHT = 100#150. \n\nlabel_encoder = dict()\nstr_labels = []\n\nFEATURE_SHAPE = (14,23) #(14,23)\n\nGRID_STEP_H = IMG_HEIGHT / FEATURE_SHAPE[0]\nGRID_STEP_W = IMG_WIDTH / FEATURE_SHAPE[1]\n\nANCHOR_CENTERS = np.mgrid[GRID_STEP_H/2:IMG_HEIGHT:GRID_STEP_H,\n                          GRID_STEP_W/2:IMG_WIDTH:GRID_STEP_W]\n\ndef load_boxes(path_mask = '../input/boxesjson/boxes/boxes/*.json', prefix=TRAIN_PREFIX):\n    boxes = dict()\n    for path in glob(path_mask):\n        label = os.path.basename(path).split('_', 1)[0]\n        with open(path) as src:\n            boxes[label] = json.load(src)\n            for annotation in boxes[label]:\n                basename = os.path.basename(annotation['filename'])\n                annotation['filename'] = os.path.join(TRAIN_PREFIX, label.upper(), basename)\n            for annotation in boxes[label]:\n                for rect in annotation['annotations']:\n                    rect['x'] += rect['width'] / 2\n                    rect['y'] += rect['height'] / 2\n    return boxes\n\n\n\ndef load_valid_boxes():\n    return load_boxes(path_mask = './data/fish/validation_boxes/*.json',\n\t\t      prefix = VALIDATION_PREFIX)\n\ndef load_NoFiles():\n    files = list()\n    files = [file for file in glob('./data/fish/train/NoF/*.jpg')]\n    return files\n\ndef draw_boxes(annotation, rectangles=None, image_size=None):\n    \n    def _draw(img, rectangles, scale_x, scale_y, color=(0, 255, 0)):\n        for rect in rectangles:\n            pt1 = (int((rect['x'] - rect['width'] / 2) * scale_x),\n                   int((rect['y'] - rect['height'] / 2) * scale_y))\n            pt2 = (int((rect['x'] + rect['width'] / 2) * scale_x),\n                   int((rect['y'] + rect['height'] / 2) * scale_y))\n            img = cv2.rectangle(img.copy(), pt1, pt2, \n                                color=color, thickness=4)\n        return img\n    \n    scale_x, scale_y = 1., 1. \n    \n    img = cv2.imread(annotation['filename'], cv2.IMREAD_COLOR)[...,::-1]\n    if image_size is not None:\n        scale_x = 1. * image_size[0] / img.shape[1]\n        scale_y = 1. * image_size[1] / img.shape[0]\n        img = cv2.resize(img, image_size)\n        \n    img = _draw(img, annotation['annotations'], scale_x, scale_y)\n    \n    if rectangles is not None:\n        img = _draw(img, rectangles, 1., 1., (255, 0, 0))\n\n    return img\n\ndef make_labels(aux_lb = []):\n\tlabels = []\n\tfor path in glob('../input/boxesjson/boxes/boxes/*.json'):\n\t\tlabels.append(os.path.basename(path).split('_', 1)[0].upper())\n\tfor str1 in aux_lb:\n\t\tlabels.append(str1)\n\tlabels_cat = pd.get_dummies(labels)\n\tlabels_cat = labels_cat.sort_values(by=labels[0], ascending=False).values.tolist()\n\tlabel_dict = {dkey: dval for dkey, dval in zip(labels, labels_cat)}\n\tglobal label_encoder;\n\tlabel_encoder = label_dict\n\tglobal str_labels\n\tstr_labels = labels\n\treturn label_dict, labels\n\nlabel_encoder, str_labels = make_labels([])\n\ndef get_feature_tensor():\n\t#features = keras.applications.vgg16.VGG16(include_top=False,\n\t#\t\t\t\t          weights='imagenet',\n\t#\t\t\t\t          input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\t#output = features.layers[-1].output\n\t#global FEATURE_SHAPE\n\t#FEATURE_SHAPE = (output.shape[1].value,\n    #             output.shape[2].value)\n    #FEATURE_SHAPE = (14, 23)\n\tglobal GRID_STEP_H\n\tGRID_STEP_H = IMG_HEIGHT / FEATURE_SHAPE[0]\n\tglobal GRID_STEP_W\n\tGRID_STEP_W = IMG_WIDTH / FEATURE_SHAPE[1]\n\tglobal ANCHOR_CENTERS\n\tANCHOR_CENTERS = np.mgrid[GRID_STEP_H/2:IMG_HEIGHT:GRID_STEP_H,\n\t\t                  GRID_STEP_W/2:IMG_WIDTH:GRID_STEP_W]\n\treturn features\n\ndef iou(rect, x_scale, y_scale, anchor_x, anchor_y,\n        anchor_w=ANCHOR_WIDTH, anchor_h=ANCHOR_HEIGHT):\n    \n    rect_x1 = (rect['x'] - rect['width'] / 2) * x_scale\n    rect_x2 = (rect['x'] + rect['width'] / 2) * x_scale\n    \n    rect_y1 = (rect['y'] - rect['height'] / 2) * y_scale\n    rect_y2 = (rect['y'] + rect['height'] / 2) * y_scale\n    \n    anch_x1, anch_x2 = anchor_x - anchor_w / 2, anchor_x + anchor_w / 2\n    anch_y1, anch_y2 = anchor_y - anchor_h / 2, anchor_y + anchor_h / 2\n    \n    dx = (min(rect_x2, anch_x2) - max(rect_x1, anch_x1))\n    dy = (min(rect_y2, anch_y2) - max(rect_y1, anch_y1))\n    \n    intersection = dx * dy if (dx > 0 and dy > 0) else 0.\n    \n    anch_square = (anch_x2 - anch_x1) * (anch_y2 - anch_y1)\n    rect_square = (rect_x2 - rect_x1) * (rect_y2 - rect_y1)\n    union = anch_square + rect_square - intersection\n    \n    return intersection / union\n\ndef encode_anchors(annotation, img_shape, iou_thr=0.):\n    encoded = np.zeros(shape=(FEATURE_SHAPE[0],\n                              FEATURE_SHAPE[1], 5 + len(str_labels)), \n                              dtype=np.float32)\n    x_scale = 1. * img_shape[1]/ORIGINAL_IMG_WIDTH\n    y_scale = 1. * img_shape[0]/ORIGINAL_IMG_HEIGHT\n    label = annotation['filename'].split(\"train/\", 1)[1]\n    label = label.split(\"img\", 1)[0]\n    label = label.split(\"/\", 1)[0]\n    for rect in annotation['annotations']:\n        scores = []\n        for row in range(FEATURE_SHAPE[0]):\n            for col in range(FEATURE_SHAPE[1]):\n                anchor_x = ANCHOR_CENTERS[1, row, col]\n                anchor_y = ANCHOR_CENTERS[0, row, col]\n                score = iou(rect, x_scale, y_scale, anchor_x, anchor_y)\n                scores.append((score, anchor_x, anchor_y, row, col))\n        \n        scores = sorted(scores, reverse=True)\n        if scores[0][0] < iou_thr:\n            scores = [scores[0]]  # default anchor\n        else:\n            scores = [e for e in scores if e[0] > iou_thr]\n\n        for score, anchor_x, anchor_y, row, col in scores:\n            dx = (anchor_x - rect['x'] * x_scale) / ANCHOR_WIDTH\n            dy = (anchor_y - rect['y'] * y_scale) / ANCHOR_HEIGHT\n            dw = (ANCHOR_WIDTH - rect['width'] * x_scale) / ANCHOR_WIDTH\n            dh = (ANCHOR_HEIGHT - rect['height'] * y_scale) / ANCHOR_HEIGHT\n            encoded[row, col] = [1., dx, dy, dw, dh] + label_encoder[label]\n            #encoded[row, col] = [1., dx, dy, dw, dh] + label_encoder[label]\n    return encoded\n\ndef _sigmoid(x):\n    return 1. / (1. + np.exp(-x))\n\ndef decode_prediction(prediction, conf_thr=0.1):\n    rectangles = []\n    conf = 0\n    maxcol = 0\n    maxrow = 0\n    for row in range(FEATURE_SHAPE[0]):\n        for col in range(FEATURE_SHAPE[1]):\n            class_probabilities = list(range(len(str_labels)))\n            logit =  prediction[row, col][0]\n            new_conf = _sigmoid(logit)\n            if (new_conf > conf):\n                conf = new_conf\n                maxcol = col\n                maxrow = row\n    logit, dx, dy, dw, dh =  prediction[maxrow, maxcol][0:5]\n    conf = _sigmoid(logit)\n    class_logits =  prediction[maxrow, maxcol][5:]\n    class_probabilities = _sigmoid(class_logits)\n    class_probab_NoF = (1 - conf)\n    class_probab_Other = int(conf > 0.5)*(1 - max(class_probabilities))\n    class_norma = sum(class_probabilities) + class_probab_NoF + class_probab_Other\n    class_probabilities = class_probabilities/class_norma\n    class_probab_NoF = class_probab_NoF/class_norma\n    class_probab_Other = class_probab_Other/class_norma\n    if ((class_probab_Other <= 0.5) & (class_probab_NoF <= 0.5)):\n        class_label = [int(e > 0.5) for e in class_probabilities]\n        class_name = [key for key in label_encoder.keys() if (label_encoder[key] == class_label)]\n        class_label.append(0)\n        class_label.append(0)\n    elif (class_probab_Other > 0.5):\n        class_label = [0, 0, 0, 0, 0, 0, 0, 1]\n        class_name = \"OTHER\"\n    elif (class_probab_NoF > 0.5):\n        class_label = [0, 0, 0, 0, 0, 0, 1, 0]\n        class_name = \"NoF\"\n    class_probabilities = np.append(class_probabilities, class_probab_NoF)\n    class_probabilities = np.append(class_probabilities, class_probab_Other)\n    class_probabilities = np.append(class_probabilities[:4] , [class_probabilities[6:] , class_probabilities[4:6]])\n    anchor_x = ANCHOR_CENTERS[1, maxrow, maxcol]\n    anchor_y = ANCHOR_CENTERS[0, maxrow, maxcol]\n    rectangles.append({'x': anchor_x - dx * ANCHOR_WIDTH,\n\t           'y': anchor_y - dy * ANCHOR_HEIGHT,\n\t           'width': ANCHOR_WIDTH - dw * ANCHOR_WIDTH,\n\t           'height': ANCHOR_HEIGHT - dh * ANCHOR_HEIGHT,\n\t           'conf': conf,\n\t           'class_probab': class_probabilities,\n\t           'class_name': class_name})\n    return rectangles\n\nboxes = load_boxes()\n\ndef load_img(path, target_size=(IMG_WIDTH, IMG_HEIGHT)):\n    img = cv2.imread(path, cv2.IMREAD_COLOR)[...,::-1]\n    img_shape = img.shape\n    img_resized = cv2.resize(img, target_size)\n    return img_shape, keras.applications.vgg16.preprocess_input(img_resized.astype(np.float32))\n\nK = tf.keras.backend\n\nbatch_loss_arr = tf.Variable(0.0)\n\ndef confidence_loss(y_true, y_pred):\n    #return tf.constant(-0.0)*y_pred\n    #return confidence_loss(0.5, 1)\n    conf_loss = K.binary_crossentropy(y_true[..., 0], \n                                      y_pred[..., 0],\n                                      from_logits=True)\n    return conf_loss\n    #return  tf.cond(tf.equal(K.shape(y_true)[1], tf.constant(6)), \n    #               lambda: tf.constant(-0.0)*y_pred, \n    #               lambda: conf_loss)\n    \n\ndef smooth_l1(y_true, y_pred):\n    abs_loss = K.abs(y_true[..., 1:5] - y_pred[..., 1:5])\n    square_loss = 0.5 * K.square(y_true[..., 1:5] - y_pred[..., 1:5])\n    mask = K.cast(K.greater(abs_loss, 1.), 'float32')\n    total_loss = (abs_loss - 0.5) * mask + 0.5 * square_loss * (1. - mask)\n    return K.sum(total_loss, axis=-1)\ncopyten = 111\n\n       \ndef total_loss(y_true, y_pred, neg_pos_ratio=3):\n    batch_size = K.shape(y_true)[0]\n    \n    # TODO: добавьте функцию потерь для классификации детекции\n    \n    y_true = K.reshape(y_true, (batch_size, -1, 11))\n    y_pred = K.reshape(y_pred, (batch_size, -1, 11))\n    pos_mask =  y_true[...,5] == 0\n    \n    y_true_pos = tf.boolean_mask(y_true,y_true[...,0])\n    y_pred_pos = tf.boolean_mask(y_pred,y_true[...,0])\n    class_loss = K.categorical_crossentropy(y_true_pos[...,5:], \n                                                y_pred_pos[...,5:],\n                                                from_logits=True,\n                                                axis=-1)\n    class_loss = K.mean(class_loss)\n    #pos_class_loss = K.sum(class_loss * y_true[..., 0], axis=-1)\n    pos_class_loss = K.mean(class_loss)\n    # confidence loss\n    conf_loss = K.mean(confidence_loss(y_true, y_pred))\n    \n    conf_loss = 0.5*conf_loss + 0.5*pos_class_loss\n\n    # smooth l1 loss\n    loc_loss = smooth_l1(y_true, y_pred)\n    \n    # positive examples loss\n    pos_conf_loss = K.sum(conf_loss * y_true[..., 0], axis=-1)\n    pos_loc_loss = K.sum(loc_loss * y_true[..., 0], axis=-1)\n    \n    # negative examples loss\n    anchors = K.shape(y_true)[1]\n    num_pos = K.sum(y_true[..., 0], axis=-1)\n    num_pos_avg = K.mean(num_pos)\n    num_neg = K.min([neg_pos_ratio * (num_pos_avg) + 1., K.cast(anchors, 'float32')])\n    \n    # hard negative mining\n    neg_conf_loss, _ = tf.nn.top_k(conf_loss * (1. - y_true[..., 0]),\n                                   k=K.cast(num_neg, 'int32'))\n\n    neg_conf_loss = K.sum(neg_conf_loss, axis=-1)\n    \n    # total conf loss\n    total_conf_loss = (neg_conf_loss + pos_conf_loss) / (num_neg + num_pos + 1e-32)\n    loc_loss = pos_loc_loss / (num_pos + 1e-32)\n    result = total_conf_loss + 0.5 * loc_loss\n    global batch_loss_arr\n    batch_loss_arr = tf.cond(tf.equal(tf.rank(batch_loss_arr) ,tf.rank(result)), \n    lambda: (result +  batch_loss_arr)/2,\n    lambda: result)\n    return batch_loss_arr\n#def debug_loss(y_true, y_pred, neg_pos_ratio=3):\n#    return tf.cond(tf.equal(tf.size(y_true), tf.constant(6)), \n#                   lambda: tf.constant(0.1)*y_pred, \n#                   lambda: total_loss(y_pred, y_true, neg_pos_ratio))\ndef debug_loss(y_true, y_pred, neg_pos_ratio=3):\n    def debug_loss2(y_true, y_pred, neg_pos_ratio=3):\n        batch_size = K.shape(y_true)[0]\n        #resultten = tf.zeros_like(y_pred)*y_pred\n        y_pred = tf.reshape(y_pred, (batch_size, -1,5 + len(str_labels)))\n        y_true = K.reshape(y_true, (batch_size, -1, 5 + len(str_labels)))\n        #rrr = tf.constant([0,0,0])#y_true([0])\n        #yy_true = y_true[0,0,...]\n        print_op = tf.print(\"y_true: \", K.shape(y_true),\"y_pred: \", K.shape(y_pred))\n        #print_op = tf.print(\"y_true: \", y_true[2])\n        #y_true = K.reshape(y_true, (batch_size, -1, 5))\n        print_op = tf.print(\"y_true: \", K.shape(y_true),\"y_pred: \", K.shape(y_pred))\n        with tf.control_dependencies([print_op]):\n            return tf.zeros_like(y_pred)*y_pred\n    return debug_loss2(y_true, y_pred, neg_pos_ratio)\n\n#features = get_feature_tensor()\n#output = features.layers[-1].output\nmodel = keras.models.load_model('../input/model3-tesla/model3-fishes-vgg16.hdf5', \n                                        custom_objects={'total_loss': total_loss})\n\nif True:\n    example = boxes['lag'][7]\n    print(example)\n    _, sample_img = load_img(example['filename'])\n    with tf.device('/device:CPU:0'):\n        pred = model.predict(np.array([sample_img,]))[0]\n\n    decoded = decode_prediction(pred, conf_thr=0.0)\n    decoded = sorted(decoded, key=lambda e: -e['conf'])\n\n    plt.figure(figsize=(6, 6), dpi=120)\n    img = draw_boxes(example, decoded[:3], (IMG_WIDTH, IMG_HEIGHT))\n    plt.imshow(img)\n    #plt.title('{}x{}'.format(*img.shape));\n    print(decoded[0]['class_probab'])\n    plt.title(decoded[0]['class_name'][0]);\n    \ndef make_table():\n    ptable = pd.DataFrame(columns=['image', 'ALB', 'BET', 'DOL', 'LAG',\n                                   'NoF', 'OTHER', 'SHARK','YFT'])\n    for i, file in enumerate(glob('../input/the-nature-conservancy-fisheries-monitoring/test_stg1/*.jpg')):\n        bn = os.path.basename(file)\n        #bn = \"test_stg1/\" + bn\n        _, sample_img = load_img(file)\n        pred = model.predict(np.array([sample_img,]))[0]\n        decoded = decode_prediction(pred, conf_thr=0.5)\n        predictions = decoded[0]['class_probab']#[0, 1, 0, 1, 0, 1, 0, 1]\n        print(i,predictions)\n        pred_str = [str(ps) for ps in predictions]\n        ptable.loc[len(ptable)] = [bn] + pred_str\n        \n    for i, file in enumerate(glob('../input/test-stg2/test_stg2/test_stg2/*.jpg')):\n        bn = os.path.basename(file)\n        bn = \"test_stg2/\" + bn\n        _, sample_img = load_img(file)\n        pred = model.predict(np.array([sample_img,]))[0]\n        decoded = decode_prediction(pred, conf_thr=0.5)\n        predictions = decoded[0]['class_probab']#[0, 1, 0, 1, 0, 1, 0, 1]\n        print(i,predictions)\n        pred_str = [str(ps) for ps in predictions]\n        ptable.loc[len(ptable)] = [bn] + pred_str\n    return ptable        \n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\nif True:\n    print(\"start_predictions\")\n    pred_table = make_table()\n    pred_table.to_csv(\"netol_submit_stg1_stg2.csv\", index=False)\n    #create_download_link(pred_table)\n    #print(\"url=\",url)\n    print(os.listdir(\"./\"))\n\n# import the modules we'll need\n\n\n\n\n# create a random sample dataframe\n#df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n\n# create a link to download the dataframe\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}