{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2d054a07-f49d-cb3e-95ea-317776dc3c5e"},"source":"Test simple convolution"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"85948edd-9b17-8cc8-38d8-9db7938c55cc"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a20776da-092f-9b1a-19f5-2cf74119cfd9"},"outputs":[],"source":"import os, cv2, random\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\n%matplotlib inline \n\nTRAIN_DIR = '../input/train/'\nTEST_DIR = '../input/test_stg1/'\nFISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\nROWS = 720\nCOLS = 1280\nCHANNELS = 3"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe8924b4-5c08-e8aa-f39a-62a649da7d24"},"outputs":[],"source":"def get_images(fish,dirr=TRAIN_DIR):\n    \"\"\"Load files from train folder\"\"\"\n    fish_dir = dirr +'{}'.format(fish)\n    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n    return images\n\ndef read_image(src):\n    \"\"\"Read and resize individual images\"\"\"\n    im = cv2.imread(src, cv2.IMREAD_COLOR)\n    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n    return im\n\n\nfiles = []\ny_all = []\nfor i,fish in enumerate(FISH_CLASSES):\n    fish_files = get_images(fish)\n    files.extend(fish_files)\n    \n    y_fish = np.tile(i, len(fish_files))\n    y_all.extend(y_fish)\n    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n    \ny_all = np.array(y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab72fae2-ef66-19e8-fb8a-b53056527f3a"},"outputs":[],"source":"X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n\nfor i, im in enumerate(files): \n    #X_all[i] = read_image(TRAIN_DIR+im)\n    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n\nprint(X_all.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb8bfb50-dc46-e524-a0eb-d3d081a7eb5d"},"outputs":[],"source":"plt.imshow(X_all[3])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30d33dc0-9258-153e-80ed-c3dcb8ec17c4"},"outputs":[],"source":"import tensorflow as tf\nimport tensorflow.contrib.slim as slim\ndef CNN(inputs, is_training = True,num_classes=8):        \n        batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\n        with slim.arg_scope([slim.conv2d, slim.fully_connected],\n                            normalizer_fn=slim.batch_norm,\n                            normalizer_params=batch_norm_params):\n            #x = tf.reshape(inputs, [-1, ROWS, COLS, CHANNELS])\n\n            # For slim.conv2d, default argument values are like\n            # normalizer_fn = None, normalizer_params = None, <== slim.arg_scope changes these arguments\n            # padding='SAME', activation_fn=nn.relu,\n            # weights_initializer = initializers.xavier_initializer(),\n            # biases_initializer = init_ops.zeros_initializer,\n            layers = 8\n            net = inputs\n            for i in range(layers):\n                net = slim.conv2d(net, 8*(2**(i)), [5, 5], scope='conv{}'.format(i))\n                net = slim.max_pool2d(net, [2, 2], scope='pool{}'.format(i))\n            print(net.get_shape().as_list())\n            net = slim.flatten(net, scope='flatten3')\n\n            # For slim.fully_connected, default argument values are like\n            # activation_fn = nn.relu,\n            # normalizer_fn = None, normalizer_params = None, <== slim.arg_scope changes these arguments\n            # weights_initializer = initializers.xavier_initializer(),\n            # biases_initializer = init_ops.zeros_initializer,\n            net = slim.fully_connected(net, 1024, scope='fc3')\n            net = slim.dropout(net, is_training=is_training, scope='dropout3')  # 0.5 by default\n            outputs = slim.fully_connected(net, num_classes, activation_fn=None, normalizer_fn=None, scope='fco')\n        return outputs "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4919e95-8f24-ca0d-7480-90a2bb9e1034"},"outputs":[],"source":"tf.__version__"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c5be8a8-0d68-2b93-a05c-4cfd7bfe2c98"},"outputs":[],"source":"inp = tf.placeholder(tf.float32, [None, ROWS, COLS, CHANNELS])\nlab = tf.placeholder(tf.float32, [None, 8])\n\nlogits = CNN(inp)\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=lab, logits=logits))\narg_predict = tf.argmax(logits,1)\ncorrect_prediction = tf.equal(arg_predict, tf.argmax(lab,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nlearning_rate = 0.01\ntrain_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f96910a-4918-85bd-78dc-3d6a730d7e90"},"outputs":[],"source":"saverM = tf.train.Saver(tf.trainable_variables())\nsess = tf.Session()\ninit = tf.global_variables_initializer()\nsess.run(init)\n\ntloss= 0\ntacc = 0\ndisplay_step = 2\nglobal_step = 0\nepoch = 110\nbatch_size = 2\ndef norm(batch):\n    m = np.amax(batch)\n    mi = np.amin(batch)\n    batch = (batch - mi) / (m-mi)\n    return  (batch-0.5)\n    \ndef to_one_hot(batch,cl=8):\n    y = np.zeros((len(batch),cl))\n    #batch = [np.int32(i) for i in batch]\n    y[batch] = 1.0\n    return y\n\ndef  get_batch(batch_size):\n    X_all = np.ndarray((batch_size, ROWS, COLS, CHANNELS), dtype=np.uint8)\n    ids_train = random.sample(range(0, len(files)), batch_size)\n    for i, im in enumerate(files[ids_train]): \n        X_all[i] = read_image(TRAIN_DIR+im)\n        \n    return X_all, y_all[ids_train]\n    \nfor i in range(global_step,epoch):\n            \n            #batch_xs = X_all[ids_train]\n            #batch_ys = y_all[ids_train]\n            batch_xs, batch_ys = get_batch(batch_size)\n            _,loss, acc = sess.run([train_step,cross_entropy,accuracy ],\n                                        feed_dict={inp: norm(batch_xs), \n                                                   lab: to_one_hot(batch_ys)})\n            tloss += loss\n            tacc += acc\n            if i% display_step == 0 and i>0:\n                print('step:',i, ' loss train:',round(tloss/display_step,4), \n                      ', acc train:', round(tacc/display_step,4))\n                tloss= 0\n                tacc = 0\nif False:     \n    model_dir = \"\"\n    if not os.path.isdir(model_dir) and False:\n                  os.makedirs(model_dir)\n    checkpoint_file = os.path.join(model_dir, 'checkpoint')\n    saverM.save(sess, checkpoint_file, global_step=epoch)\n    print('model saved!')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7e7e275-f27d-3919-3a55-246a560b6fca"},"outputs":[],"source":"batch_size"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31710463-f68f-6d39-c91d-956867421d90"},"outputs":[],"source":"test_files = [im for im in os.listdir(TEST_DIR)]\ntest = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\nid_img = []\n\nfor i, im in enumerate(test_files): \n    test[i] = read_image(TEST_DIR+im)\n    id_img.append(im)\ntest.shape , id_img[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33a540eb-23ca-25f2-c9a8-ee7e368ae84f"},"outputs":[],"source":"submit = open('submit.SVM.csv','w')\nsubmit.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\ni=0\nwhile i<test.shape[0]:\n    xx = norm(test[i:i+batch_size])\n    y_pred = sess.run([logits],feed_dict={inp: xx, lab: np.zeros((len(xx),8))})\n    \n    for idx in range(len(y_pred)):\n        probs=['%s' % p for p in y_pred[idx]]        \n        submit.write('%s,%s\\n' % (id_img[(i)+idx],','.join(probs)))\n        \n    i += batch_size\nsubmit.close()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7c300e0d-7c71-638b-7eac-4da11311d43a"},"outputs":[],"source":"!ls"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"502d76b9-87bc-9013-9d34-1368c071ea70"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dbf4c54c-4e86-d030-7ff9-c38ee7c038fa"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}