{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"efdbb763-380f-5723-7268-7b451629b384"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c26ebd01-3be4-4ba6-dda2-ae13192e2f4e"},"outputs":[],"source":"np.random.seed(2016)\n\nimport os\nimport glob\nimport cv2\nimport datetime\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nfrom keras import __version__ as keras_version"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5d4d87d-0916-e6c0-891a-3068e7b4f464"},"outputs":[],"source":"def get_im_cv2(path,im):\n    img = cv2.imread(path)\n    resized = cv2.resize(img, (im[0],im[1]), cv2.INTER_LINEAR)\n    return resized"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92023ef6-899a-1c2a-249e-fb79e5eaac97"},"outputs":[],"source":"def load_train(im):\n    X_train = []\n    X_train_id = []\n    y_train = []\n    start_time = time.time()\n\n    print('Read train images')\n    folders = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n    for fld in folders:\n        index = folders.index(fld)\n        print('Load folder {} (Index: {})'.format(fld, index))\n        path = os.path.join('..', 'input', 'train', fld, '*.jpg')\n        files = glob.glob(path)\n        for fl in files:\n            flbase = os.path.basename(fl)\n            img = get_im_cv2(fl,im)\n            X_train.append(img)\n            X_train_id.append(flbase)\n            y_train.append(index)\n\n    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n    return X_train, y_train, X_train_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59117fab-a06f-358e-274d-f844b976e04f"},"outputs":[],"source":"def load_test(im):\n    path = os.path.join('..', 'input', 'test_stg1', '*.jpg')\n    files = sorted(glob.glob(path))\n\n    X_test = []\n    X_test_id = []\n    for fl in files:\n        flbase = os.path.basename(fl)\n        img = get_im_cv2(fl,im)\n        X_test.append(img)\n        X_test_id.append(flbase)\n\n    return X_test, X_test_id\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb5ca274-312d-586f-db77-ad0ec73f48e4"},"outputs":[],"source":"def read_and_normalize_train_data(im):\n    train_data, train_target, train_id = load_train(im)\n\n    print('Convert to numpy...')\n    train_data = np.array(train_data, dtype=np.uint8)\n    train_target = np.array(train_target, dtype=np.uint8)\n\n    print('Reshape...')\n    train_data = train_data.transpose((0, 3, 1, 2))\n\n    print('Convert to float...')\n    train_data = train_data.astype('float32')\n    train_data = train_data / 255\n    train_target = np_utils.to_categorical(train_target, 8)\n\n    print('Train shape:', train_data.shape)\n    print(train_data.shape[0], 'train samples')\n    return train_data, train_target, train_id\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76a9c03b-7d18-9356-aec3-cc2d621b4f27"},"outputs":[],"source":"def read_and_normalize_test_data(im):\n    start_time = time.time()\n    test_data, test_id = load_test(im)\n\n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.transpose((0, 3, 1, 2))\n\n    test_data = test_data.astype('float32')\n    test_data = test_data / 255\n\n    print('Test shape:', test_data.shape)\n    print(test_data.shape[0], 'test samples')\n    print('Read and process test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n    return test_data, test_id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20a3b7b8-157c-3060-6d49-fe9906336663"},"outputs":[],"source":"def create_submission(predictions, test_id, info):\n    result1 = pd.DataFrame(predictions, columns=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n    result1.loc[:, 'image'] = pd.Series(test_id, index=result1.index)\n    now = datetime.datetime.now()\n    sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n    result1.to_csv(sub_file, index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8dbd3328-ae6f-11fe-5c79-9de74fc9a359"},"outputs":[],"source":"im_1 = [28,28]\nim_2 = [56,56]\nim_3 = [112,112]\nim_4 = [224,224]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6fc74db7-128b-d793-9bee-b721eaf4b3de"},"outputs":[],"source":"train_data_1, train_target, train_id = read_and_normalize_train_data(im_1)\ntest_data_1, test_id = read_and_normalize_test_data(im_1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3f5fd30-667d-8771-2a07-44fed685dabb"},"outputs":[],"source":"train_data_2, train_target, train_id = read_and_normalize_train_data(im_2)\ntest_data_2, test_id = read_and_normalize_test_data(im_2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73cb8421-935d-8766-b97a-ebdfd2f91fdd"},"outputs":[],"source":"train_data_3, train_target, train_id = read_and_normalize_train_data(im_3)\ntest_data_3, test_id = read_and_normalize_test_data(im_3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3a8c7faa-ed18-cd1f-71b9-9a8574a076fe"},"outputs":[],"source":"train_data_4, train_target, train_id = read_and_normalize_train_data(im_4)\ntest_data_4, test_id = read_and_normalize_test_data(im_4)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4924dbd6-874d-1c1d-1e1a-e5b20506b881"},"outputs":[],"source":"from keras import backend as K\nK.image_dim_ordering()\n\nK.set_image_dim_ordering('th')\nK.image_dim_ordering()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2cb8ae8d-d44c-45ab-9fb2-4eeccc0ebad5"},"outputs":[],"source":"from keras.layers import Merge\nfrom keras.layers import Dense, Dropout, Activation\n\nmodel_1 = Sequential()\nmodel_1.add(Convolution2D(32, 3, 3, init='he_normal', border_mode='same', input_shape=(3, 28, 28)))\nmodel_1.add(Activation('relu'))\n#model_1.add(Convolution2D(32, 3, 3, init='he_normal',border_mode='same'))\n#model_1.add(Activation('relu'))\nmodel_1.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel_1.add(Dropout(0.25))\n\nmodel_1.add(Convolution2D(64, 3, 3, init='he_normal',border_mode='same'))\nmodel_1.add(Activation('relu'))\n#model_1.add(Convolution2D(64, 3, 3, init='he_normal',border_mode='same'))\n#model_1.add(Activation('relu'))\nmodel_1.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel_1.add(Dropout(0.25))\n\n#output 64x7x7"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0380ecd6-a3b6-2eff-93db-b3f3d5065f7f"},"outputs":[],"source":"model_2 = Sequential()\nmodel_2.add(Convolution2D(32, 5, 5, init='he_normal', border_mode='same', input_shape=(3, 56, 56)))\nmodel_2.add(Activation('relu'))\n#model_2.add(Convolution2D(32, 5, 5, init='he_normal',border_mode='same'))\n#model_2.add(Activation('relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel_2.add(Dropout(0.25))\n\nmodel_2.add(Convolution2D(32, 3, 3, init='he_normal', border_mode='same'))\nmodel_2.add(Activation('relu'))\n#model_2.add(Convolution2D(32, 3, 3, init='he_normal',border_mode='same'))\n#model_2.add(Activation('relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel_2.add(Dropout(0.25))\n\nmodel_2.add(Convolution2D(64, 3, 3, init='he_normal', border_mode='same'))\nmodel_2.add(Activation('relu'))\n#model_2.add(Convolution2D(64, 3, 3, init='he_normal',border_mode='same'))\n#model_2.add(Activation('relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel_2.add(Dropout(0.25))\n\n#output 64x7x7"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d3031f6-7b20-299e-04c1-d19f0c9f66a4"},"outputs":[],"source":"model_3 = Sequential()\nmodel_3.add(Convolution2D(32, 5, 5, init='he_normal', border_mode='same', input_shape=(3, 112, 112)))\nmodel_3.add(Activation('relu'))\n#model_3.add(Convolution2D(32, 5, 5, init='he_normal', border_mode='same'))\n#model_3.add(Activation('relu'))\nmodel_3.add(MaxPooling2D(pool_size=(4, 4),dim_ordering=\"th\"))\nmodel_3.add(Dropout(0.25))\n\nmodel_3.add(Convolution2D(32, 3, 3, init='he_normal', border_mode='same'))\nmodel_3.add(Activation('relu'))\n#model_3.add(Convolution2D(32, 3, 3, init='he_normal', border_mode='same'))\n#model_3.add(Activation('relu'))\nmodel_3.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel_3.add(Dropout(0.25))\n\nmodel_3.add(Convolution2D(64, 3, 3, init='he_normal',  border_mode='same'))\nmodel_3.add(Activation('relu'))\n#model_3.add(Convolution2D(64, 3, 3, init='he_normal', border_mode='same'))\n#model_3.add(Activation('relu'))\nmodel_3.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel_3.add(Dropout(0.25))\n\n#output 64x7x7"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2645258a-5979-b57f-6d32-1121b3a8e055"},"outputs":[],"source":"model_4 = Sequential()\nmodel_4.add(Convolution2D(32, 5, 5, init='he_normal', border_mode='same', input_shape=(3, 224, 224)))\nmodel_4.add(Activation('relu'))\n#model_4.add(Convolution2D(32, 5, 5, init='he_normal', border_mode='same'))\n#model_4.add(Activation('relu'))\nmodel_4.add(MaxPooling2D(pool_size=(4, 4),dim_ordering=\"th\"))\nmodel_4.add(Dropout(0.25))\n\nmodel_4.add(Convolution2D(32, 5, 5, init='he_normal', border_mode='same'))\nmodel_4.add(Activation('relu'))\n#model_4.add(Convolution2D(32, 5, 5, init='he_normal', border_mode='same'))\n#model_4.add(Activation('relu'))\nmodel_4.add(MaxPooling2D(pool_size=(4, 4),dim_ordering=\"th\"))\nmodel_4.add(Dropout(0.25))\n\nmodel_4.add(Convolution2D(64, 3, 3, init='he_normal', border_mode='same'))\nmodel_4.add(Activation('relu'))\n#model_4.add(Convolution2D(64, 3, 3, init='he_normal', border_mode='same'))\n#model_4.add(Activation('relu'))\nmodel_4.add(MaxPooling2D(pool_size=(2, 2),dim_ordering=\"th\"))\nmodel_4.add(Dropout(0.25))\n\n#output 64x7x7"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"766d1bb9-f12e-95bf-4836-f511c577b7b8"},"outputs":[],"source":"merged = Merge([model_1, model_2, model_3], mode='concat')\n\nfinal_model = Sequential()\nfinal_model.add(merged)\n\nfinal_model.add(Convolution2D(64, 3, 3, init='he_normal', border_mode='valid'))\nfinal_model.add(Activation('relu'))\nfinal_model.add(Dropout(0.25))\n\nfinal_model.add(Flatten())\nfinal_model.add(Dense(256,init='he_normal'))\nfinal_model.add(Activation('relu'))\nfinal_model.add(Dropout(0.5))\nfinal_model.add(Dense(8, init='he_normal', activation='softmax'))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06453913-19a3-0afd-171e-f5ef67e9eff3"},"outputs":[],"source":"from keras.optimizers import rmsprop,adam\n\n#rmsprop = rmsprop(lr=0.005, rho=0.9, epsilon=1e-08, decay=0.0001)\nfinal_model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics = ['accuracy'])\nprint(final_model.summary())\nhistory = final_model.fit([train_data_1, train_data_2, train_data_3,], train_target, validation_split=0.33,shuffle=True, nb_epoch=30, batch_size=64, verbose=1)  # we pass one data array per model input\npredictions = final_model.predict([test_data_1, test_data_2, test_data_3], batch_size=32, verbose=1)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"add55a49-4544-7a55-7406-0460cc6ec030"},"outputs":[],"source":"#model_1.add(Convolution2D(64, 3, 3, init='he_normal', border_mode='valid'))\n#model_1.add(Activation('relu'))\n#model_1.add(Dropout(0.25))\n\n#model_1.add(Flatten())\n#model_1.add(Dense(256,init='he_normal'))\n#model_1.add(Activation('relu'))\n#model_1.add(Dropout(0.5))\n#model_1.add(Dense(8, init='he_normal', activation='softmax'))\n#model_1.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics = ['accuracy'])\n#print(model_1.summary())\n#history = model_1.fit(train_data_1, train_target, validation_split=0.33,shuffle=True, nb_epoch=10, batch_size=32, verbose=1)  # we pass one data array per model input\n#predictions = model_1.predict(test_data_1, batch_size=32, verbose=1)\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef765ce3-78e9-15bc-7314-45f17c9a241d"},"outputs":[],"source":"# list all data in history\nprint(history.history.keys())\n\n# summarize history for accuracy\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7fb690f4-304f-200f-a8f8-3a602e5116a7"},"outputs":[],"source":"create_submission(predictions, test_id, 'Trail_1')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9daf8939-a594-ac86-4359-3971183d4269"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}