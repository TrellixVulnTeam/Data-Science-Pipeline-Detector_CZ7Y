{"cells":[{"metadata":{"_uuid":"8df402e3-e390-40f9-9949-4caa4cce21d6","_cell_guid":"f8be8249-718d-4b2f-bcfc-d7e90af105b1","trusted":true},"cell_type":"markdown","source":"# The Nature Conservancy Fisheries Monitoring"},{"metadata":{"_uuid":"c3517d46-bd6b-4f7a-86c3-51ebfeef50f0","_cell_guid":"d7788b1f-1f5c-4f83-a4eb-c4d6a6b90e77","trusted":true},"cell_type":"markdown","source":"https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring"},{"metadata":{"_uuid":"00616b1d-1aa5-4c9b-9571-185b50d763c7","_cell_guid":"589f552e-8433-4b5f-91ea-1e338c464e15","trusted":true},"cell_type":"code","source":"import os\n\nprint(os.listdir('../input/the-nature-conservancy-fisheries-monitoring'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfe81351-f418-409b-8d03-cf3e14f18956","_cell_guid":"4361e01c-cd10-416b-8494-d0254846011f","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%matplotlib inline\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5491712-5178-47ec-ac49-cca216238b21","_cell_guid":"fd59700c-cc22-4c65-9057-71f586e6fb98","trusted":true},"cell_type":"markdown","source":"# Загружаем разметку"},{"metadata":{"_uuid":"44ef82b1-a4b7-4de8-8042-af5901ec87c5","_cell_guid":"729df334-c511-4c9a-a2bd-7434e5ed6a4c","trusted":true},"cell_type":"code","source":"import os\nimport json\nfrom glob import glob\n\n# TODO: скачайте данные и сохраните в директорию:\nTRAIN_PREFIX = '../input/the-nature-conservancy-fisheries-monitoring/train'\n\ndef load_boxes():\n    boxes = dict()\n    \n    for path in glob('../input/boxes-labels/*.json'):\n        label = os.path.basename(path).split('_', 1)[0]\n        with open(path) as src:\n            boxes[label] = json.load(src)\n            for annotation in boxes[label]:\n                basename = os.path.basename(annotation['filename'])\n                annotation['filename'] = os.path.join(TRAIN_PREFIX, label.upper(), basename)\n            for annotation in boxes[label]:\n                for rect in annotation['annotations']:\n                    rect['x'] += rect['width'] / 2\n                    rect['y'] += rect['height'] / 2\n    return boxes\n\ndef draw_boxes(annotation, rectangles=None, image_size=None):\n    \n    def _draw(img, rectangles, scale_x, scale_y, color=(0, 255, 0)):\n        for rect in rectangles:\n            pt1 = (int((rect['x'] - rect['width'] / 2) * scale_x),\n                   int((rect['y'] - rect['height'] / 2) * scale_y))\n            pt2 = (int((rect['x'] + rect['width'] / 2) * scale_x),\n                   int((rect['y'] + rect['height'] / 2) * scale_y))\n            img = cv2.rectangle(img.copy(), pt1, pt2, \n                                color=color, thickness=4)\n        return img\n    \n    scale_x, scale_y = 1., 1.\n    \n    img = cv2.imread(annotation['filename'], cv2.IMREAD_COLOR)[...,::-1]\n    if image_size is not None:\n        scale_x = 1. * image_size[0] / img.shape[1]\n        scale_y = 1. * image_size[1] / img.shape[0]\n        img = cv2.resize(img, image_size)\n        \n    img = _draw(img, annotation['annotations'], scale_x, scale_y)\n    \n    if rectangles is not None:\n        img = _draw(img, rectangles, 1., 1., (255, 0, 0))\n\n    return img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b4d1489-49d0-45ed-8617-1868fd8a7aa7","_cell_guid":"5ebdada8-db74-4b6d-9bac-1fef4d86705d","trusted":true},"cell_type":"markdown","source":"### Визуализируем разметку"},{"metadata":{"_uuid":"37df54cf-e247-45a0-b2b6-70c85f8202d2","_cell_guid":"77d56c3a-7da4-43c3-8dc4-6a2fb4e3609c","trusted":true},"cell_type":"code","source":"boxes = load_boxes()  # разметка детекций","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caa46b4c-96ef-4f95-9cbf-72498914ff1c","_cell_guid":"b43490b6-9c39-442f-88ef-9e0422d45fcf","trusted":true},"cell_type":"code","source":"pd.DataFrame([(k, len(v)) for k, v in boxes.items()],\n             columns=['class', 'count'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc3ec481-52f2-4ee5-9ed3-e67321ac8262","_cell_guid":"40be2299-8343-4faf-ba63-5d88735544db","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 6), dpi=120)\nimg = draw_boxes(boxes['lag'][17])\nplt.imshow(img)\nplt.title('{}x{}'.format(*img.shape));","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b7ad815-b6ed-40e4-86ff-acca2e6b3015","_cell_guid":"cf17550f-e4b9-4078-8552-276c5aad9d57","trusted":true},"cell_type":"markdown","source":"### Распределение размеров разметки"},{"metadata":{"_uuid":"c1d0bc25-0d52-434b-9abd-5fbabcf30588","_cell_guid":"639fda13-dea1-4d64-863c-dc65f9c6c122","trusted":true},"cell_type":"code","source":"annotations = sum([box['annotations']\n                  for box in sum(boxes.values(), [])], [])\n\nwidths = [rect['width'] for rect in annotations]\nheights = [rect['height'] for rect in annotations]\n\nplt.hist(widths)\nplt.hist(heights);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"248bb0e4-096b-497d-ab82-8919b84628a1","_cell_guid":"f23941e9-9109-40e6-b553-69fa7f154167","trusted":true},"cell_type":"markdown","source":"# Экстрактор признаков"},{"metadata":{"_uuid":"3456a98d-ce01-4f79-bd09-a07fb3888485","_cell_guid":"148a0f12-8ecd-44a6-937b-8b59fce50b80","trusted":true},"cell_type":"code","source":"IMG_HEIGHT = 270\nIMG_WIDTH = 480\n\nfeatures = keras.applications.vgg16.VGG16(include_top=False,\n                                          weights='imagenet',\n                                          input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\nfeature_tensor = features.layers[-1].output\n\n# дообучаем последние 5 слоев\nfor layer in features.layers[:-5]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4c05844-1229-46f9-a13b-3cbe2570264f","_cell_guid":"e38fd47e-2055-4b83-9624-5b083bcf4338","trusted":true},"cell_type":"markdown","source":"# Сетка якорей (anchor grid)"},{"metadata":{"_uuid":"9e288c2b-dde2-413d-81a5-64271a02edad","_cell_guid":"6b43fd2a-1d24-4133-8cab-600c8191a1d6","trusted":true},"cell_type":"code","source":"FEATURE_SHAPE = (feature_tensor.shape[1].value,\n                 feature_tensor.shape[2].value)\n\nGRID_STEP_H = IMG_HEIGHT / FEATURE_SHAPE[0]\nGRID_STEP_W = IMG_WIDTH / FEATURE_SHAPE[1]\n\nANCHOR_WIDTH = 150.\nANCHOR_HEIGHT = 150. \n\nANCHOR_CENTERS = np.mgrid[GRID_STEP_H/2:IMG_HEIGHT:GRID_STEP_H,\n                          GRID_STEP_W/2:IMG_WIDTH:GRID_STEP_W]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"390ae8e2-2f33-4086-bcd7-f237adb192ae","_cell_guid":"1ff31b7f-8de0-43bb-85b2-8e0fcb3ffb17","trusted":true},"cell_type":"code","source":"def iou(rect, x_scale, y_scale, anchor_x, anchor_y,\n        anchor_w=ANCHOR_WIDTH, anchor_h=ANCHOR_HEIGHT):\n    \n    rect_x1 = (rect['x'] - rect['width'] / 2) * x_scale\n    rect_x2 = (rect['x'] + rect['width'] / 2) * x_scale\n    \n    rect_y1 = (rect['y'] - rect['height'] / 2) * y_scale\n    rect_y2 = (rect['y'] + rect['height'] / 2) * y_scale\n    \n    anch_x1, anch_x2 = anchor_x - anchor_w / 2, anchor_x + anchor_w / 2\n    anch_y1, anch_y2 = anchor_y - anchor_h / 2, anchor_y + anchor_h / 2\n    \n    dx = (min(rect_x2, anch_x2) - max(rect_x1, anch_x1))\n    dy = (min(rect_y2, anch_y2) - max(rect_y1, anch_y1))\n    \n    intersection = dx * dy if (dx > 0 and dy > 0) else 0.\n    \n    anch_square = (anch_x2 - anch_x1) * (anch_y2 - anch_y1)\n    rect_square = (rect_x2 - rect_x1) * (rect_y2 - rect_y1)\n    union = anch_square + rect_square - intersection\n    \n    return intersection / union\n\ndef encode_anchors(annotation, img_shape, iou_thr=0.5):\n    encoded = np.zeros(shape=(FEATURE_SHAPE[0],\n                              FEATURE_SHAPE[1], 5), dtype=np.float32)\n    x_scale = 1. * IMG_WIDTH / img_shape[1]\n    y_scale = 1. * IMG_HEIGHT / img_shape[0]\n    for rect in annotation['annotations']:\n        scores = []\n        for row in range(FEATURE_SHAPE[0]):\n            for col in range(FEATURE_SHAPE[1]):\n                anchor_x = ANCHOR_CENTERS[1, row, col]\n                anchor_y = ANCHOR_CENTERS[0, row, col]\n                score = iou(rect, x_scale, y_scale, anchor_x, anchor_y)\n                scores.append((score, anchor_x, anchor_y, row, col))\n        \n        scores = sorted(scores, reverse=True)\n        if scores[0][0] < iou_thr:\n            scores = [scores[0]]  # default anchor\n        else:\n            scores = [e for e in scores if e[0] > iou_thr]\n\n        for score, anchor_x, anchor_y, row, col in scores:\n            dx = (anchor_x - rect['x'] * x_scale) / ANCHOR_WIDTH\n            dy = (anchor_y - rect['y'] * y_scale) / ANCHOR_HEIGHT\n            dw = (ANCHOR_WIDTH - rect['width'] * x_scale) / ANCHOR_WIDTH\n            dh = (ANCHOR_HEIGHT - rect['height'] * y_scale) / ANCHOR_HEIGHT\n            encoded[row, col] = [1., dx, dy, dw, dh]\n            \n    return encoded\n\ndef _sigmoid(x):\n    return 1. / (1. + np.exp(-x))\n\ndef decode_prediction(prediction, conf_thr=0.1):\n    rectangles = []\n    for row in range(FEATURE_SHAPE[0]):\n        for col in range(FEATURE_SHAPE[1]):\n            logit, dx, dy, dw, dh = prediction[row, col]\n            conf = _sigmoid(logit)\n            if conf > conf_thr:\n                anchor_x = ANCHOR_CENTERS[1, row, col]\n                anchor_y = ANCHOR_CENTERS[0, row, col]\n                rectangles.append({'x': anchor_x - dx * ANCHOR_WIDTH,\n                                   'y': anchor_y - dy * ANCHOR_HEIGHT,\n                                   'width': ANCHOR_WIDTH - dw * ANCHOR_WIDTH,\n                                   'height': ANCHOR_HEIGHT - dh * ANCHOR_HEIGHT,\n                                   'conf': conf})\n    return rectangles","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc87cc01-fecc-42bb-a2c8-cf607c4a7d5e","_cell_guid":"889b3eac-91ae-4707-a1aa-336fa6978907","trusted":true},"cell_type":"markdown","source":"### Валидация енкодинга/декодинга"},{"metadata":{"_uuid":"00d0593e-8639-4982-aca1-785387971a7f","_cell_guid":"696047fa-2353-40e1-bc78-04b72ed1a4fb","trusted":true,"scrolled":false},"cell_type":"code","source":"example = boxes['alb'][15]\n\nencoded = encode_anchors(example, (IMG_HEIGHT, IMG_WIDTH))\n\ndecoded = decode_prediction(encoded, conf_thr=0.5)\ndecoded = sorted(decoded, key = lambda e: -e['conf'])\n\nplt.figure(figsize=(6, 6), dpi=120)\nplt.imshow(draw_boxes(example, decoded[:10]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a70e1441-1beb-4dd0-98e3-478e3b808208","_cell_guid":"24fc7717-49d7-4175-a752-52256542c905","trusted":true},"cell_type":"markdown","source":"## Функция потерь"},{"metadata":{"_uuid":"f8248e30-b526-41f0-8495-bd49f5832eb4","_cell_guid":"d3e9ebd9-444e-466e-9d9c-21ac98d70a00","trusted":true},"cell_type":"code","source":"K = tf.keras.backend\n\ndef confidence_loss(y_true, y_pred):\n    conf_loss = K.binary_crossentropy(y_true[..., 0], \n                                      y_pred[..., 0],\n                                      from_logits=True)\n    return conf_loss\n\ndef smooth_l1(y_true, y_pred):\n    abs_loss = K.abs(y_true[..., 1:] - y_pred[..., 1:])\n    square_loss = 0.5 * K.square(y_true[..., 1:] - y_pred[..., 1:])\n    mask = K.cast(K.greater(abs_loss, 1.), 'float32')\n    total_loss = (abs_loss - 0.5) * mask + 0.5 * square_loss * (1. - mask)\n    return K.sum(total_loss, axis=-1)\n\ndef class_loss(y_true, y_pred):\n    y_true = K.reshape(y_true[1], (-1, 6))\n    y_pred = K.reshape(y_pred[1], (-1, 6))\n    class_loss = K.categorical_crossentropy(y_true, y_pred, from_logits=True)\n    return class_loss\n\ndef total_loss(y_true, y_pred, neg_pos_ratio=3):\n    batch_size = K.shape(y_true[0])[0]\n    \n    y_true = K.reshape(y_true[0], (batch_size, -1, 5))\n    y_pred = K.reshape(y_pred[0], (batch_size, -1, 5))\n\n    # confidence loss\n    conf_loss = confidence_loss(y_true, y_pred)\n    \n    # smooth l1 loss\n    loc_loss = smooth_l1(y_true, y_pred)\n    \n    # positive examples loss\n    pos_conf_loss = K.sum(conf_loss * y_true[..., 0], axis=-1)\n    pos_loc_loss = K.sum(loc_loss * y_true[..., 0], axis=-1)\n    \n    # negative examples loss\n    anchors = K.shape(y_true)[1]\n    num_pos = K.sum(y_true[..., 0], axis=-1)\n    num_pos_avg = K.mean(num_pos)\n    num_neg = K.min([neg_pos_ratio * (num_pos_avg) + 1., K.cast(anchors, 'float32')])\n    \n    # hard negative mining\n    neg_conf_loss, _ = tf.nn.top_k(conf_loss * (1. - y_true[..., 0]),\n                                   k=K.cast(num_neg, 'int32'))\n\n    neg_conf_loss = K.sum(neg_conf_loss, axis=-1)\n    \n    # total conf loss\n    total_conf_loss = (neg_conf_loss + pos_conf_loss) / (num_neg + num_pos + 1e-32)\n    loc_loss = pos_loc_loss / (num_pos + 1e-32)\n    \n    return total_conf_loss + 0.5 * loc_loss","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77097652-0253-4eae-9173-20c14d811bbb","_cell_guid":"58141c90-027f-4239-a36e-d05341acd8d0","trusted":true},"cell_type":"markdown","source":"## Загрузка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\nTRAIN_DIR = '../input/the-nature-conservancy-fisheries-monitoring/train/'\nROWS = 270\nCOLS = 480\nCHANNELS = 3\n\ndef get_images(fish):\n    fish_dir = TRAIN_DIR+'{}'.format(fish)\n    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n    return images\n\ndef read_image(src):\n    im = cv2.imread(src, cv2.IMREAD_COLOR)\n    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n    return im\n\n\nfiles = []\ny_all = []\n\nfor fish in FISH_CLASSES:\n    fish_files = get_images(fish)\n    files.extend(fish_files)\n    \n    y_fish = np.tile(fish, len(fish_files))\n    y_all.extend(y_fish)\n    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n    \ny_all = np.array(y_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n\nfor i, im in enumerate(files): \n    X_all[i] = read_image(TRAIN_DIR+im)\n    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n\nprint(X_all.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding Labels\nfrom keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\ny_all = LabelEncoder().fit_transform(y_all)\ny_all = np_utils.to_categorical(y_all)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47c75364-c8ef-4cad-b715-27dc631159db","_cell_guid":"faf03130-37cf-432d-bbd2-e6a399ca2814","trusted":true},"cell_type":"markdown","source":"## Добавляем выход детектора"},{"metadata":{"_uuid":"6de77856-ef83-4360-8a7b-aafbe6ae0a47","_cell_guid":"735aca06-97c4-4249-acce-750063b6b5f1","trusted":true},"cell_type":"code","source":"output = keras.layers.BatchNormalization()(feature_tensor)\nfrom keras.regularizers import l2\n\nx = keras.layers.Flatten()(output)\n\nx = keras.layers.Dense(256, activation='relu', name='dense_one')(x)\nx = keras.layers.Dropout(0.5)(x)\nx = keras.layers.Dense(128, activation='relu', name='dense_two')(x)\nx = keras.layers.Dropout(0.5)(x)\nx = keras.layers.Dense(64, activation='relu', name='dense_three')(x)\nx = keras.layers.Dropout(0.5)(x)\n\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(8, activation='sigmoid', kernel_regularizer=keras.regularizers.l1(1e-4), name='output')(x)\n\nmodel = keras.models.Model(inputs=features.inputs, outputs=x)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be1560f1-d1b3-4fc8-9d0e-f61d2abe0ea9","_cell_guid":"9d9cdea1-7624-4a9a-9290-f2ba305ca6f5","trusted":true},"cell_type":"markdown","source":"## Обучение"},{"metadata":{"_uuid":"c214ae13-2e29-4a19-b8e8-d486f88723e9","_cell_guid":"f2619246-2a49-438d-98f9-c80e119ae04e","trusted":true},"cell_type":"code","source":"adam = keras.optimizers.Adam(lr=3e-4, decay=1e-6)\n#model.compile(optimizer=adam, \n#              loss=total_loss,\n#              metrics={'dense_1': confidence_loss})\n\nmodel.compile(loss='categorical_crossentropy', optimizer=adam)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fe8f1b3-4d47-4b48-8f24-74fb39fbac17","_cell_guid":"bdfbd402-23dd-4e84-95fc-7d282514616a","trusted":true,"scrolled":false},"cell_type":"code","source":"model.fit(X_all, y_all, batch_size=64, nb_epoch=3,\n              validation_split=0.2, verbose=1, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_DIR = '../input/the-nature-conservancy-fisheries-monitoring/test_stg1/'\n\n\ntest_files = [im for im in os.listdir(TEST_DIR)]\ntest = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n\nfor i, im in enumerate(test_files): \n    test[i] = read_image(TEST_DIR+im)\n    \ntest_preds = model.predict(test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission1 = pd.DataFrame(test_preds, columns=FISH_CLASSES)\nsubmission1.insert(0, 'image', test_files)\nsubmission1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_DIR = '../input/testfiles/test_s2/test_s2/'\n\n\ntest_files = [im for im in os.listdir(TEST_DIR)]\ntest = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n\nfor i, im in enumerate(test_files): \n    test[i] = read_image(TEST_DIR+im)\n    \ntest_preds = model.predict(test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission2 = pd.DataFrame(test_preds, columns=FISH_CLASSES)\nsubmission2.insert(0, 'image', test_files)\nsubmission2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission2['image'] = 'test_stg2/' + submission2['image']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([submission1, submission2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submit.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8b5243a-40ef-4972-ac79-25e1ec768ad1","_cell_guid":"3b92d4c5-ac36-4c07-9199-8864728bc73d","trusted":true},"cell_type":"code","source":"# TODO: предскажите класс рыбы для фотографии из тестовой выборки\n#\n# Подготовьте файл с предсказаниями вероятностей для каждой фотографии:\n# image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\n# img_00001.jpg,1,0,0,0,0,...,0\n# img_00002.jpg,0.3,0.1,0.6,0,...,0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}