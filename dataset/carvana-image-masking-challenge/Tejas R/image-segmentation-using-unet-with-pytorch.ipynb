{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-25T08:39:29.174364Z","iopub.execute_input":"2022-06-25T08:39:29.17534Z","iopub.status.idle":"2022-06-25T08:39:29.189034Z","shell.execute_reply.started":"2022-06-25T08:39:29.175294Z","shell.execute_reply":"2022-06-25T08:39:29.188033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# U-Net Original Research Paper\n### Paper Name: U-Net: Convolutional Networks for Biomedical Image Segmentation\n### Paper Link: https://arxiv.org/pdf/1505.04597.pdf","metadata":{}},{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"class ROOTDIR:\n    train = \"./train\"\n    train_mask = \"./train_masks\"","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:29.245111Z","iopub.execute_input":"2022-06-25T08:39:29.24555Z","iopub.status.idle":"2022-06-25T08:39:29.254014Z","shell.execute_reply.started":"2022-06-25T08:39:29.245484Z","shell.execute_reply":"2022-06-25T08:39:29.253198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# General Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport zipfile\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:29.29044Z","iopub.execute_input":"2022-06-25T08:39:29.291134Z","iopub.status.idle":"2022-06-25T08:39:29.296522Z","shell.execute_reply.started":"2022-06-25T08:39:29.291091Z","shell.execute_reply":"2022-06-25T08:39:29.29575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Files","metadata":{}},{"cell_type":"code","source":"dirs = [\"../input/carvana-image-masking-challenge/train.zip\",\n        \"../input/carvana-image-masking-challenge/train_masks.zip\",\n        \"../input/carvana-image-masking-challenge/metadata.csv.zip\"]\n\nfor i in tqdm(dirs):\n    with zipfile.ZipFile(i) as z:\n        z.extractall()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:29.337886Z","iopub.execute_input":"2022-06-25T08:39:29.338204Z","iopub.status.idle":"2022-06-25T08:39:37.89975Z","shell.execute_reply.started":"2022-06-25T08:39:29.338173Z","shell.execute_reply":"2022-06-25T08:39:37.898914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Working with CSV","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"./metadata.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:37.901416Z","iopub.execute_input":"2022-06-25T08:39:37.901946Z","iopub.status.idle":"2022-06-25T08:39:37.926861Z","shell.execute_reply.started":"2022-06-25T08:39:37.901906Z","shell.execute_reply":"2022-06-25T08:39:37.926124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:37.92802Z","iopub.execute_input":"2022-06-25T08:39:37.928829Z","iopub.status.idle":"2022-06-25T08:39:37.944413Z","shell.execute_reply.started":"2022-06-25T08:39:37.928792Z","shell.execute_reply":"2022-06-25T08:39:37.943586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Working with Train Images and Masks","metadata":{}},{"cell_type":"code","source":"train_img_lst = os.listdir(ROOTDIR.train) # \"./train\"\ntrain_mask_lst = os.listdir(ROOTDIR.train_mask) # \"./train_masks\"","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:37.946435Z","iopub.execute_input":"2022-06-25T08:39:37.946771Z","iopub.status.idle":"2022-06-25T08:39:37.957093Z","shell.execute_reply.started":"2022-06-25T08:39:37.946737Z","shell.execute_reply":"2022-06-25T08:39:37.956342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_mask_lst[:5])\nprint(train_img_lst[:5])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:37.958088Z","iopub.execute_input":"2022-06-25T08:39:37.958671Z","iopub.status.idle":"2022-06-25T08:39:37.96279Z","shell.execute_reply.started":"2022-06-25T08:39:37.958635Z","shell.execute_reply":"2022-06-25T08:39:37.962064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_mask_lst))\nprint(len(train_img_lst))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:37.964046Z","iopub.execute_input":"2022-06-25T08:39:37.964572Z","iopub.status.idle":"2022-06-25T08:39:37.976151Z","shell.execute_reply.started":"2022-06-25T08:39:37.964537Z","shell.execute_reply":"2022-06-25T08:39:37.975471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Sorting to make sure we get right image and right mask","metadata":{}},{"cell_type":"code","source":"sorted_train_mask_lst = sorted(train_mask_lst)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:37.977259Z","iopub.execute_input":"2022-06-25T08:39:37.977675Z","iopub.status.idle":"2022-06-25T08:39:37.987076Z","shell.execute_reply.started":"2022-06-25T08:39:37.977639Z","shell.execute_reply":"2022-06-25T08:39:37.986382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_train_img_lst = sorted(train_img_lst)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:37.988305Z","iopub.execute_input":"2022-06-25T08:39:37.988646Z","iopub.status.idle":"2022-06-25T08:39:37.99898Z","shell.execute_reply.started":"2022-06-25T08:39:37.988611Z","shell.execute_reply":"2022-06-25T08:39:37.998105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sorted_train_mask_lst[:16])\nprint(sorted_train_img_lst[:16])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:37.999967Z","iopub.execute_input":"2022-06-25T08:39:38.000813Z","iopub.status.idle":"2022-06-25T08:39:38.00937Z","shell.execute_reply.started":"2022-06-25T08:39:38.000777Z","shell.execute_reply":"2022-06-25T08:39:38.008351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Images with their Mask\n### Making sure images and mask are paired correctly.","metadata":{}},{"cell_type":"code","source":"def show_images(imgs_lst,masks_lst,loops=2):\n    for i in range(loops):\n        img_path = os.path.join(ROOTDIR.train,imgs_lst[i])\n        mask_path = os.path.join(ROOTDIR.train_mask,masks_lst[i])\n        img = Image.open(img_path)\n        mask = Image.open(mask_path)\n        print(img_path)\n        print(img.size)\n        print(type(img))\n        plt.imshow(img)\n        plt.show()\n        print(mask_path)\n        print(mask.size)\n        plt.imshow(mask)\n        plt.show()\n        print(\"----------------------------------------------------\")\n\nshow_images(sorted_train_img_lst, sorted_train_mask_lst)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:38.01426Z","iopub.execute_input":"2022-06-25T08:39:38.014706Z","iopub.status.idle":"2022-06-25T08:39:39.60894Z","shell.execute_reply.started":"2022-06-25T08:39:38.01467Z","shell.execute_reply":"2022-06-25T08:39:39.608143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PyTorch Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport albumentations as A\nimport torch.optim as optim\nfrom torchvision import models\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom albumentations.pytorch import ToTensorV2 \nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:39.610265Z","iopub.execute_input":"2022-06-25T08:39:39.611142Z","iopub.status.idle":"2022-06-25T08:39:39.617809Z","shell.execute_reply.started":"2022-06-25T08:39:39.611103Z","shell.execute_reply":"2022-06-25T08:39:39.616904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PyTorch Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    split_pct = 0.2\n    learning_rate = 3e-4\n    batch_size = 4\n    epochs = 3","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:39.618963Z","iopub.execute_input":"2022-06-25T08:39:39.619753Z","iopub.status.idle":"2022-06-25T08:39:39.629154Z","shell.execute_reply.started":"2022-06-25T08:39:39.619714Z","shell.execute_reply":"2022-06-25T08:39:39.628432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 123\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:39.631726Z","iopub.execute_input":"2022-06-25T08:39:39.632139Z","iopub.status.idle":"2022-06-25T08:39:39.643799Z","shell.execute_reply.started":"2022-06-25T08:39:39.632115Z","shell.execute_reply":"2022-06-25T08:39:39.643057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.device","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:39.645191Z","iopub.execute_input":"2022-06-25T08:39:39.645834Z","iopub.status.idle":"2022-06-25T08:39:39.653928Z","shell.execute_reply.started":"2022-06-25T08:39:39.645799Z","shell.execute_reply":"2022-06-25T08:39:39.653265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Working with data","metadata":{}},{"cell_type":"markdown","source":"### Shuffling the data.","metadata":{}},{"cell_type":"code","source":"permuted_train_img_lst = np.random.permutation(np.array(sorted_train_img_lst))\npermuted_train_mask_lst = [x.replace(\".jpg\", \"_mask.gif\") for x in permuted_train_img_lst]\nprint(permuted_train_img_lst[:5])\nprint(permuted_train_mask_lst[:5])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:39.655068Z","iopub.execute_input":"2022-06-25T08:39:39.655475Z","iopub.status.idle":"2022-06-25T08:39:39.669239Z","shell.execute_reply.started":"2022-06-25T08:39:39.655439Z","shell.execute_reply":"2022-06-25T08:39:39.66852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(permuted_train_img_lst,permuted_train_mask_lst)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:39.670226Z","iopub.execute_input":"2022-06-25T08:39:39.670625Z","iopub.status.idle":"2022-06-25T08:39:41.65608Z","shell.execute_reply.started":"2022-06-25T08:39:39.670591Z","shell.execute_reply":"2022-06-25T08:39:41.652679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting into Training and Validation","metadata":{}},{"cell_type":"code","source":"length = len(permuted_train_img_lst)\nprint(length*0.2) # convert this to int","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:41.65768Z","iopub.execute_input":"2022-06-25T08:39:41.658064Z","iopub.status.idle":"2022-06-25T08:39:41.665922Z","shell.execute_reply.started":"2022-06-25T08:39:41.658017Z","shell.execute_reply":"2022-06-25T08:39:41.66486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images_list = permuted_train_img_lst[int(CFG.split_pct*len(permuted_train_img_lst)) :]\ntrain_masks_list = permuted_train_mask_lst[int(CFG.split_pct*len(permuted_train_mask_lst)) :]\nprint(len(train_masks_list))\n\nval_images_list = permuted_train_img_lst[: int(CFG.split_pct*len(permuted_train_img_lst))]\nval_masks_list = permuted_train_mask_lst[: int(CFG.split_pct*len(permuted_train_mask_lst))]\nprint(len(val_masks_list))\n\n# 4071+1017=5088 (split includes all items)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:41.667629Z","iopub.execute_input":"2022-06-25T08:39:41.668175Z","iopub.status.idle":"2022-06-25T08:39:41.677301Z","shell.execute_reply.started":"2022-06-25T08:39:41.668111Z","shell.execute_reply":"2022-06-25T08:39:41.67631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Train Dataset","metadata":{}},{"cell_type":"code","source":"show_images(train_images_list,train_masks_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:41.6787Z","iopub.execute_input":"2022-06-25T08:39:41.679377Z","iopub.status.idle":"2022-06-25T08:39:43.290718Z","shell.execute_reply.started":"2022-06-25T08:39:41.679312Z","shell.execute_reply":"2022-06-25T08:39:43.289922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Validation Dataset","metadata":{}},{"cell_type":"code","source":"show_images(val_images_list,val_masks_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:43.292195Z","iopub.execute_input":"2022-06-25T08:39:43.292809Z","iopub.status.idle":"2022-06-25T08:39:44.886573Z","shell.execute_reply.started":"2022-06-25T08:39:43.292768Z","shell.execute_reply":"2022-06-25T08:39:44.88366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class CarvanaDataset(Dataset):\n    def __init__(self,img_list,mask_list,transform=None):\n        self.img_list = img_list\n        self.mask_list = mask_list\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.img_list)\n    \n    def __getitem__(self,index):\n        img_path = os.path.join(ROOTDIR.train,self.img_list[index])\n        mask_path = os.path.join(ROOTDIR.train_mask,self.mask_list[index])\n        img = Image.open(img_path)\n        mask = Image.open(mask_path)\n        img = np.array(img)\n        mask = np.array(mask)\n        mask[mask==255.0] = 1.0\n        #img_mask_dict = {\"image\": img, \"mask\": mask}\n        \n        if self.transform:\n            augmentation = self.transform(image=img, mask=mask)\n            img = augmentation[\"image\"]\n            mask = augmentation[\"mask\"]\n            mask = torch.unsqueeze(mask,0)\n            #transformations = self.transform(image=img, mask=mask)\n            #img = transformations[\"image\"]\n            #mask = transformations[\"mask\"]\n            \n        return img,mask","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:44.888044Z","iopub.execute_input":"2022-06-25T08:39:44.888544Z","iopub.status.idle":"2022-06-25T08:39:44.897063Z","shell.execute_reply.started":"2022-06-25T08:39:44.888503Z","shell.execute_reply":"2022-06-25T08:39:44.896264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([A.Resize(572,572), \n                             A.Rotate(limit=15,p=0.1),\n                             A.HorizontalFlip(p=0.5),\n                             A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255),\n                             ToTensorV2()])\n\nval_transform = A.Compose([A.Resize(572,572),\n                           A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255),\n                           ToTensorV2()])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:44.898263Z","iopub.execute_input":"2022-06-25T08:39:44.899093Z","iopub.status.idle":"2022-06-25T08:39:44.908036Z","shell.execute_reply.started":"2022-06-25T08:39:44.899057Z","shell.execute_reply":"2022-06-25T08:39:44.907197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CarvanaDataset(train_images_list, train_masks_list, transform = train_transform)\nval_dataset = CarvanaDataset(val_images_list, val_masks_list, transform = train_transform)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:44.909331Z","iopub.execute_input":"2022-06-25T08:39:44.909962Z","iopub.status.idle":"2022-06-25T08:39:44.922281Z","shell.execute_reply.started":"2022-06-25T08:39:44.909925Z","shell.execute_reply":"2022-06-25T08:39:44.921259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 200\nimg,mask = train_dataset[idx]","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:44.923598Z","iopub.execute_input":"2022-06-25T08:39:44.923933Z","iopub.status.idle":"2022-06-25T08:39:44.978568Z","shell.execute_reply.started":"2022-06-25T08:39:44.923897Z","shell.execute_reply":"2022-06-25T08:39:44.977728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:44.979678Z","iopub.execute_input":"2022-06-25T08:39:44.980169Z","iopub.status.idle":"2022-06-25T08:39:44.986577Z","shell.execute_reply.started":"2022-06-25T08:39:44.980129Z","shell.execute_reply":"2022-06-25T08:39:44.98581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.max()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:44.987918Z","iopub.execute_input":"2022-06-25T08:39:44.988497Z","iopub.status.idle":"2022-06-25T08:39:44.999494Z","shell.execute_reply.started":"2022-06-25T08:39:44.988461Z","shell.execute_reply":"2022-06-25T08:39:44.998718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_single_img(img,mask,index=None,train=True):\n    if index:\n        if train:\n            img,mask = train_dataset[index]\n        else:\n            img,mask = val_dataset[index]\n    plt.imshow(img.permute(1,2,0),cmap=\"gray\")  # Convert (3, 572, 572) -> (572, 572, 3)\n    plt.show()\n    plt.imshow(mask.permute(1,2,0), cmap=\"gray\")  # Convert (1, 572, 572) -> (572, 572, 1)\n    print(mask.shape)\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:45.001248Z","iopub.execute_input":"2022-06-25T08:39:45.001838Z","iopub.status.idle":"2022-06-25T08:39:45.008805Z","shell.execute_reply.started":"2022-06-25T08:39:45.001801Z","shell.execute_reply":"2022-06-25T08:39:45.007954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"---------------Train---------------\")\nshow_single_img(img,mask,index=15,train=False)\nprint(\"---------------Validation---------------\")\nshow_single_img(img,mask,index=15,train=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:45.014997Z","iopub.execute_input":"2022-06-25T08:39:45.015648Z","iopub.status.idle":"2022-06-25T08:39:45.886135Z","shell.execute_reply.started":"2022-06-25T08:39:45.015593Z","shell.execute_reply":"2022-06-25T08:39:45.885344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset,batch_size=CFG.batch_size,shuffle=True)\nval_dataloader = DataLoader(val_dataset,batch_size=CFG.batch_size,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:45.88757Z","iopub.execute_input":"2022-06-25T08:39:45.887932Z","iopub.status.idle":"2022-06-25T08:39:45.893436Z","shell.execute_reply.started":"2022-06-25T08:39:45.887894Z","shell.execute_reply":"2022-06-25T08:39:45.892388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = iter(train_dataloader)\nimg,mask = a.next()\nprint(img.shape,mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:45.895006Z","iopub.execute_input":"2022-06-25T08:39:45.895556Z","iopub.status.idle":"2022-06-25T08:39:46.086076Z","shell.execute_reply.started":"2022-06-25T08:39:45.895522Z","shell.execute_reply":"2022-06-25T08:39:46.084473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utility Functions","metadata":{}},{"cell_type":"code","source":"def double_conv(in_ch, out_ch):\n    conv = nn.Sequential(\n        nn.Conv2d(in_channels=in_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n        nn.BatchNorm2d(out_ch),                                                            \n        nn.ReLU(inplace=True),\n        nn.Conv2d(in_channels=out_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1), \n        nn.BatchNorm2d(out_ch),                                                            \n        nn.ReLU(inplace=True)\n    )\n    \n    return conv\n\n#def cropper(og_tensor, target_tensor):\n#    og_shape = og_tensor.shape[2]\n#    target_shape = target_tensor.shape[2]\n#    delta = (og_shape - target_shape) // 2\n#    cropped_og_tensor = og_tensor[:,:,delta:og_shape-delta,delta:og_shape-delta]\n#    return cropped_og_tensor\n \n\ndef addPadding(srcShapeTensor, tensor_whose_shape_isTobechanged):\n\n    if(srcShapeTensor.shape != tensor_whose_shape_isTobechanged.shape):\n        target = torch.zeros(srcShapeTensor.shape)\n        target[:, :, :tensor_whose_shape_isTobechanged.shape[2],\n               :tensor_whose_shape_isTobechanged.shape[3]] = tensor_whose_shape_isTobechanged\n        return target.to(CFG.device)\n    return tensor_whose_shape_isTobechanged.to(CFG.device)\n    \ndef padder(left_tensor, right_tensor): \n    # left_tensor is the tensor on the encoder side of UNET\n    # right_tensor is the tensor on the decoder side  of the UNET\n    \n    if left_tensor.shape != right_tensor.shape:\n        padded = torch.zeros(left_tensor.shape)\n        padded[:, :, :right_tensor.shape[2], :right_tensor.shape[3]] = right_tensor\n        return padded.to(CFG.device)\n    \n    return right_tensor.to(CFG.device)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.087632Z","iopub.execute_input":"2022-06-25T08:39:46.087995Z","iopub.status.idle":"2022-06-25T08:39:46.097374Z","shell.execute_reply.started":"2022-06-25T08:39:46.087958Z","shell.execute_reply":"2022-06-25T08:39:46.096462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNET MODEL FROM SCRATCH","metadata":{}},{"cell_type":"code","source":"class UNET(nn.Module):\n    def __init__(self,in_chnls, n_classes):\n        super(UNET,self).__init__()\n        \n        self.in_chnls = in_chnls\n        self.n_classes = n_classes\n        \n        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        self.down_conv_1 = double_conv(in_ch=self.in_chnls,out_ch=64)\n        self.down_conv_2 = double_conv(in_ch=64,out_ch=128)\n        self.down_conv_3 = double_conv(in_ch=128,out_ch=256)\n        self.down_conv_4 = double_conv(in_ch=256,out_ch=512)\n        self.down_conv_5 = double_conv(in_ch=512,out_ch=1024)\n        #print(self.down_conv_1)\n        \n        self.up_conv_trans_1 = nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n        self.up_conv_trans_2 = nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=2,stride=2)\n        self.up_conv_trans_3 = nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=2,stride=2)\n        self.up_conv_trans_4 = nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=2,stride=2)\n        \n        self.up_conv_1 = double_conv(in_ch=1024,out_ch=512)\n        self.up_conv_2 = double_conv(in_ch=512,out_ch=256)\n        self.up_conv_3 = double_conv(in_ch=256,out_ch=128)\n        self.up_conv_4 = double_conv(in_ch=128,out_ch=64)\n        \n        self.conv_1x1 = nn.Conv2d(in_channels=64,out_channels=self.n_classes,kernel_size=1,stride=1)\n        \n    def forward(self,x):\n        \n        # encoding\n        x1 = self.down_conv_1(x)\n        #print(\"X1\", x1.shape)\n        p1 = self.max_pool(x1)\n        #print(\"p1\", p1.shape)\n        x2 = self.down_conv_2(p1)\n        #print(\"X2\", x2.shape)\n        p2 = self.max_pool(x2)\n        #print(\"p2\", p2.shape)\n        x3 = self.down_conv_3(p2)\n        #print(\"X2\", x3.shape)\n        p3 = self.max_pool(x3)\n        #print(\"p3\", p3.shape)\n        x4 = self.down_conv_4(p3)\n        #print(\"X4\", x4.shape)\n        p4 = self.max_pool(x4)\n        #print(\"p4\", p4.shape)\n        x5 = self.down_conv_5(p4)\n        #print(\"X5\", x5.shape)\n        \n        # decoding\n        d1 = self.up_conv_trans_1(x5)  # up transpose convolution (\"up sampling\" as called in UNET paper)\n        crop1 = padder(x4,d1) # padding d1 to match x4 shape\n        cat1 = torch.cat([x4,crop1],dim=1) # concatenating padded d1 and x4 on channel dimension(dim 1) [batch(dim 0),channel(dim 1),height(dim 2),width(dim 3)]\n        uc1 = self.up_conv_1(cat1) # 1st up double convolution\n        \n        d2 = self.up_conv_trans_2(uc1)\n        crop2 = padder(x3,d2)\n        cat2 = torch.cat([x3,crop2],dim=1)\n        uc2 = self.up_conv_2(cat2)\n        \n        d3 = self.up_conv_trans_3(uc2)\n        crop3 = padder(x2,d3)\n        cat3 = torch.cat([x2,crop3],dim=1)\n        uc3 = self.up_conv_3(cat3)\n        \n        d4 = self.up_conv_trans_4(uc3)\n        crop4 = padder(x1,d4)\n        cat4 = torch.cat([x1,crop4],dim=1)\n        uc4 = self.up_conv_4(cat4)\n        \n        conv_1x1 = self.conv_1x1(uc4)\n        return conv_1x1\n        #print(conv_1x1.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.098644Z","iopub.execute_input":"2022-06-25T08:39:46.09914Z","iopub.status.idle":"2022-06-25T08:39:46.118234Z","shell.execute_reply.started":"2022-06-25T08:39:46.099104Z","shell.execute_reply":"2022-06-25T08:39:46.117454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and Validation","metadata":{}},{"cell_type":"markdown","source":"### Train Function\n","metadata":{}},{"cell_type":"code","source":"def train_model(model,dataloader,criterion,optimizer):\n    model.train()\n    train_running_loss = 0.0\n    for j,img_mask in enumerate(tqdm(dataloader)):\n        img = img_mask[0].float().to(CFG.device)\n        #print(\" ----- IMAGE -----\")\n        #print(img)\n        mask = img_mask[1].float().to(CFG.device)\n        #print(\" ----- MASK -----\")\n        #print(mask)\n        \n        y_pred = model(img)\n        #print(\" ----- Y PRED -----\")\n        #print(y_pred)\n        #print(\" ----- Y PRED SHAPE -----\")#\n        #print(y_pred.shape)\n        optimizer.zero_grad()\n        \n        loss = criterion(y_pred,mask)\n        \n        train_running_loss += loss.item() * CFG.batch_size\n        \n        loss.backward()\n        optimizer.step()\n        \n    train_loss = train_running_loss / (j+1)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.119466Z","iopub.execute_input":"2022-06-25T08:39:46.119927Z","iopub.status.idle":"2022-06-25T08:39:46.131422Z","shell.execute_reply.started":"2022-06-25T08:39:46.119876Z","shell.execute_reply":"2022-06-25T08:39:46.130614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation Function","metadata":{}},{"cell_type":"code","source":"def val_model(model,dataloader,criterion,optimizer):\n    model.eval()\n    val_running_loss = 0\n    with torch.no_grad():\n        for j,img_mask in enumerate(tqdm(dataloader)):\n            img = img_mask[0].float().to(CFG.device)\n            mask = img_mask[1].float().to(CFG.device)\n            y_pred = model(img)\n            loss = criterion(y_pred,mask)\n            \n            val_running_loss += loss.item() * CFG.batch_size\n            \n        val_loss = val_running_loss / (j+1)\n    return val_loss","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.132516Z","iopub.execute_input":"2022-06-25T08:39:46.133068Z","iopub.status.idle":"2022-06-25T08:39:46.14246Z","shell.execute_reply.started":"2022-06-25T08:39:46.133033Z","shell.execute_reply":"2022-06-25T08:39:46.141737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNET(in_chnls = 3, n_classes = 1).to(CFG.device)\noptimizer = optim.Adam(model.parameters(), lr = CFG.learning_rate)\ncriterion = nn.BCEWithLogitsLoss()\ntrain_loss_lst = []\nval_loss_lst = []  ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:40:51.84787Z","iopub.execute_input":"2022-06-25T08:40:51.848259Z","iopub.status.idle":"2022-06-25T08:40:52.136939Z","shell.execute_reply.started":"2022-06-25T08:40:51.848207Z","shell.execute_reply":"2022-06-25T08:40:52.136142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train and Validation Loop","metadata":{}},{"cell_type":"code","source":"for i in tqdm(range(CFG.epochs)):\n    train_loss = train_model(model=model,dataloader=train_dataloader,criterion=criterion,optimizer=optimizer)\n    val_loss = val_model(model=model,dataloader=val_dataloader,criterion=criterion,optimizer=optimizer)\n    train_loss_lst.append(train_loss)\n    val_loss_lst.append(val_loss)\n    print(f\" Train Loss : {train_loss:.4f}\")\n    print(f\" Validation Loss : {val_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:40:53.346975Z","iopub.execute_input":"2022-06-25T08:40:53.347354Z","iopub.status.idle":"2022-06-25T08:41:45.005933Z","shell.execute_reply.started":"2022-06-25T08:40:53.347323Z","shell.execute_reply":"2022-06-25T08:41:45.004664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training and Validation Loss Plot","metadata":{}},{"cell_type":"code","source":"plt.plot(train_loss_lst, color=\"green\", label='train loss')\nplt.plot(val_loss_lst, color=\"red\", label='validation loss')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:41:45.006876Z","iopub.status.idle":"2022-06-25T08:41:45.007911Z","shell.execute_reply.started":"2022-06-25T08:41:45.007666Z","shell.execute_reply":"2022-06-25T08:41:45.007691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model","metadata":{}},{"cell_type":"code","source":"TRAINED_FILE = \"./unet_scratch.pth\"","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.177908Z","iopub.status.idle":"2022-06-25T08:39:46.178365Z","shell.execute_reply.started":"2022-06-25T08:39:46.178126Z","shell.execute_reply":"2022-06-25T08:39:46.178148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), TRAINED_FILE)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.179773Z","iopub.status.idle":"2022-06-25T08:39:46.180204Z","shell.execute_reply.started":"2022-06-25T08:39:46.179988Z","shell.execute_reply":"2022-06-25T08:39:46.18001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(TRAINED_FILE)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.181652Z","iopub.status.idle":"2022-06-25T08:39:46.182291Z","shell.execute_reply.started":"2022-06-25T08:39:46.182046Z","shell.execute_reply":"2022-06-25T08:39:46.18207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"trained_model = UNET(in_chnls = 3, n_classes = 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.183402Z","iopub.status.idle":"2022-06-25T08:39:46.184026Z","shell.execute_reply.started":"2022-06-25T08:39:46.1838Z","shell.execute_reply":"2022-06-25T08:39:46.183823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model.load_state_dict(torch.load(TRAINED_FILE))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.18513Z","iopub.status.idle":"2022-06-25T08:39:46.185769Z","shell.execute_reply.started":"2022-06-25T08:39:46.185531Z","shell.execute_reply":"2022-06-25T08:39:46.185565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model = trained_model.to(\"cuda\")\ntrained_model.eval()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.186885Z","iopub.status.idle":"2022-06-25T08:39:46.187511Z","shell.execute_reply.started":"2022-06-25T08:39:46.187286Z","shell.execute_reply":"2022-06-25T08:39:46.187309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = \"../input/carvana-image-masking-challenge/29bb3ece3180_11.jpg\"\n\nimg = cv2.imread(img_path)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.188631Z","iopub.status.idle":"2022-06-25T08:39:46.189269Z","shell.execute_reply.started":"2022-06-25T08:39:46.189025Z","shell.execute_reply":"2022-06-25T08:39:46.189049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.190401Z","iopub.status.idle":"2022-06-25T08:39:46.191038Z","shell.execute_reply.started":"2022-06-25T08:39:46.190808Z","shell.execute_reply":"2022-06-25T08:39:46.190831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_transform = A.Compose([A.Resize(572,572),\n                           A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255),\n                           ToTensorV2()])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.192173Z","iopub.status.idle":"2022-06-25T08:39:46.192827Z","shell.execute_reply.started":"2022-06-25T08:39:46.192589Z","shell.execute_reply":"2022-06-25T08:39:46.192614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image = test_transform(image = img)\n\nprint(test_image)\n\nprint(test_image[\"image\"].dtype)\nprint(test_image[\"image\"].shape)\n\nimg = test_image[\"image\"].unsqueeze(0)\nprint(img.shape)\n\nimg = img.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.19396Z","iopub.status.idle":"2022-06-25T08:39:46.194596Z","shell.execute_reply.started":"2022-06-25T08:39:46.19436Z","shell.execute_reply":"2022-06-25T08:39:46.194384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = trained_model(img)\npred.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.19579Z","iopub.status.idle":"2022-06-25T08:39:46.196452Z","shell.execute_reply.started":"2022-06-25T08:39:46.196201Z","shell.execute_reply":"2022-06-25T08:39:46.19624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = pred.squeeze(0).cpu().detach().numpy()\nprint(mask.shape)\nmask = mask.transpose(1,2,0)\nprint(mask.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.197678Z","iopub.status.idle":"2022-06-25T08:39:46.198409Z","shell.execute_reply.started":"2022-06-25T08:39:46.198128Z","shell.execute_reply":"2022-06-25T08:39:46.198155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_test_img = test_image[\"image\"].cpu().detach().numpy()\nprint(display_test_img.shape)\ndisplay_test_img = display_test_img.transpose(1,2,0)\ndisplay_test_img.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.201241Z","iopub.status.idle":"2022-06-25T08:39:46.201878Z","shell.execute_reply.started":"2022-06-25T08:39:46.20165Z","shell.execute_reply":"2022-06-25T08:39:46.201674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask[mask<0]=0\nmask[mask>0]=1","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.203Z","iopub.status.idle":"2022-06-25T08:39:46.203656Z","shell.execute_reply.started":"2022-06-25T08:39:46.203412Z","shell.execute_reply":"2022-06-25T08:39:46.203435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"-------Original Image-------\")\nplt.imshow(display_test_img, cmap=\"gray\")\nplt.show()\nprint(\"-------Image Mask-------\")\nplt.imshow(mask,cmap=\"gray\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:39:46.204797Z","iopub.status.idle":"2022-06-25T08:39:46.205449Z","shell.execute_reply.started":"2022-06-25T08:39:46.205201Z","shell.execute_reply":"2022-06-25T08:39:46.205238Z"},"trusted":true},"execution_count":null,"outputs":[]}]}