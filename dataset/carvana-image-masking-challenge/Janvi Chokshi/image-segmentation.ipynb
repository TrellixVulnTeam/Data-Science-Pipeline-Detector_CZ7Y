{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!unzip '/kaggle/input/carvana-image-masking-challenge/train_hq.zip' -d './'\n!unzip '/kaggle/input/carvana-image-masking-challenge/train_masks.zip' -d './'\n!unzip '/kaggle/input/carvana-image-masking-challenge/train.zip' -d './'\n!unzip '/kaggle/input/carvana-image-masking-challenge/train_masks.csv.zip' -d './'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install git+https://github.com/tensorflow/examples.git\n!pip install -U tfds-nightly\nimport tensorflow as tf\nfrom tensorflow_examples.models.pix2pix import pix2pix\nimport tensorflow_datasets as tfds\nimport numpy as np\nimport pandas as pd \nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\nimport glob\nfrom PIL import Image\nfrom keras.preprocessing import image\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glob.glob('./*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_csv=pd.read_csv('./train_masks.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glob.glob('./train/*')[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(15, 15))\nimg=cv2.imread('./train/d46244bc42ed_04.jpg')\nmask=Image.open('./train_masks/d46244bc42ed_04_mask.gif')\nfiles=[img,mask]\nfor i in range(len(files)):\n    plt.subplot(1, 2 , i+1)\n    plt.imshow(files[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape,image.img_to_array(mask).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_image(img,mask,train=True):\n    input_img=cv2.resize(img,(128,128))/255.0\n    input_mask=cv2.resize(mask,(128,128))\n    return input_img,input_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_imgs(name):\n    input_img=cv2.imread('./train/'+name+'.jpg')\n    input_mask=image.img_to_array(Image.open('./train_masks/'+name+'_mask.gif'))\n    input_img,input_mask=preprocess_image(input_img,input_mask)\n    return input_img,input_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data=[]\ny_data=[]\nimgs_path=glob.glob('./train/*')\nfor i in range(len(imgs_path)):\n    input_img,input_mask=load_imgs(imgs_path[i][8:-4])\n    x_data.append(input_img)\n    y_data.append(input_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_d=np.array(x_data)\ny_d=np.array(y_data)\ntrain_data=int((x_d.shape[0]*0.80))\nx_train=x_d[:train_data]\ny_train=y_d[:train_data]\nx_test=x_d[train_data:]\ny_test=y_d[train_data:]\nprint(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n\ny_train=y_train[...,np.newaxis]\ny_test=y_test[...,np.newaxis]\nprint(x_train.shape,y_train.shape,x_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTPUT_CHANNELS = 2\nbase_model = keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n\n# Use the activations of these layers\nlayer_names = [\n    'block_1_expand_relu',   # 64x64\n    'block_3_expand_relu',   # 32x32\n    'block_6_expand_relu',   # 16x16\n    'block_13_expand_relu',  # 8x8\n    'block_16_project',      # 4x4\n]\nlayers = [base_model.get_layer(name).output for name in layer_names]\n\n# Create the feature extraction model\ndown_stack = keras.Model(inputs=base_model.input, outputs=layers)\n\ndown_stack.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"up_stack = [\n    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unet_model(output_channels):\n    inputs = keras.layers.Input(shape=[128, 128, 3])\n    x = inputs\n\n  # Downsampling through the model\n    skips = down_stack(x)\n    x = skips[-1]\n    skips = reversed(skips[:-1])\n\n  # Upsampling and establishing the skip connections\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        concat = keras.layers.Concatenate()\n        x = concat([x, skip])\n\n  # This is the last layer of the model\n    last = keras.layers.Conv2DTranspose(output_channels, 3, strides=2,padding='same')  #64x64 -> 128x128\n\n    x = last(x)\n\n    return keras.Model(inputs=inputs, outputs=x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = unet_model(OUTPUT_CHANNELS)\nmodel.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_history = model.fit(x_train,y_train, epochs=1,validation_data=(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=580\npred_mask = model.predict(x_test[i:i+1])\nprint(pred_mask.shape)\ny_pred=np.argmax(pred_mask[0],-1)\ny_pred=y_pred[...,np.newaxis]\nprint(y_pred.shape)\nfig=plt.figure(figsize=(15, 15))\nimg=x_test[i]\ntrue_mask=keras.preprocessing.image.array_to_img(y_test[i])\npred_mask=keras.preprocessing.image.array_to_img(y_pred)\nfiles=[img,true_mask,pred_mask]\nfor i in range(len(files)):\n    plt.subplot(1, len(files) , i+1)\n    plt.imshow((files[i]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}