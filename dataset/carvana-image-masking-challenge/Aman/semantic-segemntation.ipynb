{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/carvana-image-masking-challenge/train/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/carvana-image-masking-challenge/train.zip -d /kaggle/carvana-image-masking-challenge/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/carvana-image-masking-challenge/train_masks.zip -d /kaggle/carvana-image-masking-challenge/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport pandas as pd\nimport os\nimport pandas as pd\nfrom sklearn.utils import shuffle\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.linear_model import LogisticRegression\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import concatenate, Conv2DTranspose, Input, Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization,GlobalMaxPooling2D\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.vgg16 import VGG16\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files_path = '../carvana-image-masking-challenge/train'\ntarget_files_path = '../carvana-image-masking-challenge/train_masks'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_files = {}\ndata_target = {}\ndata_files['files_path'] = []\ndata_target['target_files_path'] = []\ndata_files['files_path'] = list(glob.glob(files_path + \"/*\"))\ndata_target['target_files_path'] = list(glob.glob(target_files_path + \"/*\"))\n\ndata_files = pd.DataFrame(data_files)\ndata_target = pd.DataFrame(data_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def file_name(x):\n    return x.split(\"/\")[-1].split(\".\")[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_files[\"file_name\"] = data_files[\"files_path\"].apply(lambda x: file_name(x))\ndata_target[\"file_name\"] = data_target[\"target_files_path\"].apply(lambda x: file_name(x)[:-5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(data_files, data_target, on = \"file_name\", how = \"inner\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data = data.sample(frac=0.3, replace=False, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and Testing Splitting ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n = int(round(data.shape[0] * 0.7,0))\ndata_train = data[0:n]\ndata_test = data[n:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_test = np.array([img_to_array(\n                    load_img(img, target_size=(256,256))\n                    ) for img in data_test['files_path'].values.tolist()])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train = np.array([img_to_array(\n                    load_img(img, target_size=(256,256))\n                    ) for img in data_train['files_path'].values.tolist()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train = images_train.astype('float32')/255.0\nimages_test = images_test.astype('float32')/255.0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_test_target = np.array([np.average(img_to_array(\n                    load_img(img, target_size=(256,256))\n                    )/255, axis=-1) for img in data_test['target_files_path'].values.tolist()])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#images_test_target = images_test_target.astype('bool')/255\n#images_test_target = np.average(images_test_target, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train_target = np.array([np.average(img_to_array(\n                    load_img(img, target_size=(256,256))\n                    )/255, axis=-1) for img in data_train['target_files_path'].values.tolist()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train_target = images_train_target[:,:,:,None]\nimages_test_target = images_test_target[:,:,:,None]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_test_target[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#images_train_target_a = None\n#images_test_target_a = None\n\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(12, 12))\nax1, ax2 = axes\nax1.imshow(images_train[0]);\n#ax1.set_grid(True);\nax1.set_xticks([]);\nax1.set_yticks([]);\nax1.set_title(\"Original Image Train\")\n\nax2.imshow(np.squeeze(images_train_target[0]));\n#ax2.set_grid(True);\nax2.set_xticks([]);\nax2.set_yticks([])\nax2.set_title(\"Mask\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, axes = plt.subplots(ncols=2, figsize=(12, 12))\nax1, ax2 = axes\nax1.imshow(images_test[0]);\n#ax1.set_grid(True);\nax1.set_xticks([]);\nax1.set_yticks([]);\nax1.set_title(\"Original Image Test\")\n\nax2.imshow(np.squeeze(images_test_target[0]));\n#ax2.set_grid(True);\nax2.set_xticks([]);\nax2.set_yticks([])\nax2.set_title(\"Mask\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# U-Net Architecture\n\nThe below u-net architecture and metric function for Semantic Segmentation are motivated from [Link](https://medium.com/@pallawi.ds/semantic-segmentation-with-u-net-train-and-test-on-your-custom-data-in-keras-39e4f972ec89) ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_HEIGHT = 256\nIMG_WIDTH = 256\nIMG_CHANNELS = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def iou_loss_score(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n    iou = (intersection + smooth) / ( union + smooth)\n    return iou","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n#s = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[iou_loss_score])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(images_train, images_train_target, epochs = 10, batch_size = 64, validation_data = (images_test, images_test_target))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_train = (model.predict(images_train[0][None]) > 0.5).astype(np.uint8)\nfig, axes = plt.subplots(ncols=3, figsize=(12, 12))\nax1, ax2, ax3 = axes\nax1.imshow(images_train[0]);\n#ax1.set_grid(True);\nax1.set_xticks([]);\nax1.set_yticks([]);\nax1.set_title(\"Original Image Train\")\n\nax2.imshow(np.squeeze(images_train_target[0]));\n#ax2.set_grid(True);\nax2.set_xticks([]);\nax2.set_yticks([])\nax2.set_title(\"Mask\")\n\n\nax3.imshow(np.squeeze(preds_train[0]));\n#ax2.set_grid(True);\nax3.set_xticks([]);\nax3.set_yticks([])\nax3.set_title(\"Predicted Mask\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test = (model.predict(images_test[0][None]) > 0.5).astype(np.uint8)\nfig, axes = plt.subplots(ncols=3, figsize=(12, 12))\nax1, ax2, ax3 = axes\nax1.imshow(images_test[0]);\n#ax1.set_grid(True);\nax1.set_xticks([]);\nax1.set_yticks([]);\nax1.set_title(\"Original Image Test\")\n\nax2.imshow(np.squeeze(images_test_target[0]));\n#ax2.set_grid(True);\nax2.set_xticks([]);\nax2.set_yticks([])\nax2.set_title(\"Mask\")\n\n\nax3.imshow(np.squeeze(preds_test[0]));\n#ax2.set_grid(True);\nax3.set_xticks([]);\nax3.set_yticks([])\nax3.set_title(\"Predicted Mask\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}