{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, Input, MaxPool2D, UpSampling2D, Concatenate, Conv2DTranspose\nimport tensorflow as tf\nfrom keras.optimizers import Adam\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n%matplotlib inline\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/carvana-image-masking-challenge\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_zip_path = '../input/carvana-image-masking-challenge/train_hq.zip'\nmasks_zip_path = '../input/carvana-image-masking-challenge/train_masks.zip'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\n#Extract train images.\nwith zipfile.ZipFile(train_zip_path,'r') as zip_ref:\n    zip_ref.extractall('/kaggle/working')\n#Extract train masks/labels.\nwith zipfile.ZipFile(masks_zip_path,'r') as zip_ref:\n    zip_ref.extractall('/kaggle/working')\ndata_size = len(os.listdir('/kaggle/working/train_hq'))\nwith zipfile.ZipFile('../input/carvana-image-masking-challenge/train.zip','r') as zip_ref:\n    zip_ref.extractall('/kaggle/working')\ndata_size = len(os.listdir('/kaggle/working/train_hq'))\nwith zipfile.ZipFile('../input/carvana-image-masking-challenge/metadata.csv.zip','r') as zip_ref:\n    zip_ref.extractall('/kaggle/working')\ndata_size = len(os.listdir('/kaggle/working/train_hq'))\nprint('Number of train images: ', len(os.listdir('/kaggle/working/train_hq')))\nprint('Number of train masks: ', len(os.listdir('/kaggle/working/train_masks')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom glob import glob\ntrain_files = glob(os.path.join('/kaggle/working/train', \"*.jpg\"))\ntrain_ids = [s[len('/kaggle/working/train')+1:-4] for s in train_files]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_filename(image_id, image_type):\n    check_dir = False\n    if \"Train\" == image_type:\n        ext = 'jpg'\n        data_path = '/kaggle/working/train'\n        suffix = ''\n    elif \"Train_mask\" in image_type:\n        ext = 'gif'\n        data_path = TRAIN_MASKS_DATA\n        suffix = '_mask'\n    elif \"Test\" in image_type:\n        ext = 'jpg'\n        data_path = TEST_DATA\n        suffix = ''\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    if check_dir and not os.path.exists(data_path):\n        os.makedirs(data_path)\n\n    return os.path.join(data_path, \"{}{}.{}\".format(image_id, suffix, ext))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom PIL import Image\n\n\ndef get_image_data(image_id, image_type, **kwargs):\n    if 'mask' in image_type:\n        img = _get_image_data_pil(image_id, image_type, **kwargs)\n    else:\n        img = _get_image_data_opencv(image_id, image_type, **kwargs)\n    return img\n\ndef _get_image_data_opencv(image_id, image_type, **kwargs):\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\n\ndef _get_image_data_pil(image_id, image_type, return_exif_md=False, return_shape_only=False):\n    fname = get_filename(image_id, image_type)\n    try:\n        img_pil = Image.open(fname)\n    except Exception as e:\n        assert False, \"Failed to read image : %s, %s. Error message: %s\" % (image_id, image_type, e)\n\n    if return_shape_only:\n        return img_pil.size[::-1] + (len(img_pil.getbands()),)\n\n    img = np.asarray(img_pil)\n    assert isinstance(img, np.ndarray), \"Open image is not an ndarray. Image id/type : %s, %s\" % (image_id, image_type)\n    if not return_exif_md:\n        return img\n    else:\n        return img, img_pil._getexif()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_images = os.listdir('/kaggle/working/train_hq')\ntrain_images, validation_images = train_test_split(all_images, train_size=0.8, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '/kaggle/working/train_hq/'\nmask_dir = '/kaggle/working/train_masks/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_ids = sorted(os.listdir('/kaggle/working/train_hq'))\nmask_ids = sorted(os.listdir('/kaggle/working/train_masks'))\nrnd_ind = list(np.random.choice(data_size,8))\nfor i in rnd_ind:\n    print(\"Car image id: '{}' -- Corressponding Mask id '{}'\".format(car_ids[i], mask_ids[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display car and mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 0\ncar_id = car_ids[n]\nmask_id = mask_ids[n]\ncar = load_img('/kaggle/working/train_hq/' + car_id)\nmask = load_img('/kaggle/working/train_masks/' + mask_id)\nprint(\"Image Size: \", car.size)\nprint(\"Mask Size: \", mask.size)\nfig, ax = plt.subplots(1, 2, figsize=(20,20))\nfig.subplots_adjust(hspace=.1, wspace=.01)\nax[0].imshow(car)\nax[0].axis('off')\nax[0].title.set_text('Car Image')\nax[1].imshow(mask)\nax[1].axis('off')\nax[1].title.set_text('Car Mask')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_ids, X_val_ids, y_train_ids, y_val_ids= train_test_split(car_ids, mask_ids,\n                                                                 test_size=.2, train_size=.8,\n                                                                 random_state=42)\nX_train_size = len(X_train_ids)\nX_val_size = len(X_val_ids)\nprint('Training images size:', X_train_size)\nprint('Validation images size:', X_val_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_train_ids = list(train_ids)\nnp.random.shuffle(_train_ids)\n_train_ids = _train_ids[:50]\ntile_size = (256, 256)\nn = 8\n\nm = int(np.ceil(len(_train_ids) * 1.0 / n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    for j in range(n):\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        if counter == len(_train_ids):\n            break\n        image_id = _train_ids[counter]; counter+=1\n        img = get_image_data(image_id, 'Train')\n        img = cv2.resize(img, dsize=tile_size)\n        img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n    if counter == len(_train_ids):\n        break    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = complete_image.shape[0] / (tile_size[0] + 2)\nk = 5\nn = int(np.ceil(m / k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image[ys:ye,:,:])\n    plt.title(\"Training dataset, part %i\" % i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_MASKS_CSV['id'] = TRAIN_MASKS_CSV['img'].apply(lambda x: x[:-7])\nall_318_car_ids = TRAIN_MASKS_CSV['id'].unique()\nall_318_cars_image_ids = [_id + '_03' for _id in all_318_car_ids]\n\n_train_ids = list(all_318_cars_image_ids)\ntile_size = (256, 256)\nn = 8\n\nm = int(np.ceil(len(_train_ids) * 1.0 / n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    for j in range(n):\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        if counter == len(_train_ids):\n            break\n        image_id = _train_ids[counter]; counter+=1\n        img = get_image_data(image_id, 'Train')\n        img = cv2.resize(img, dsize=tile_size)\n        img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n    if counter == len(_train_ids):\n        break   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = complete_image.shape[0] / (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m / k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image[ys:ye,:,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img1 = get_image_data('683ddec95b82_03','Train')\nimg2 = get_image_data('42b3feca1993_03', 'Train')\nimage = [img1, img2]\nplt.figure(figsize=(14, 6))\nfor i in image:\n    plt.figure(figsize=(5, 5))\n    plt.imshow(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resize"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = [128, 128, 3]\ndef data_generator(images_path, masks_path, image_ids, mask_ids, batch_size, img_size=input_size):\n    data_size = len(image_ids)\n    while True:\n        rnd_ind = np.random.choice(np.arange(data_size),batch_size)\n        imgs = []\n        masks = []\n        for i in rnd_ind:\n            img_id, mask_id = image_ids[i], mask_ids[i]\n            img = load_img(images_path + img_id, target_size=img_size) \n            mask = load_img(masks_path + mask_id, target_size=img_size[:-1], color_mode = 'grayscale')\n            imgs.append(img_to_array(img))\n            masks.append(img_to_array(mask).reshape(img_size[:-1] + [1]))\n        yield np.array(imgs, dtype=np.float16) / 255., np.array(masks, dtype=np.float16) / 255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen = data_generator('/kaggle/working/train_hq/', '/kaggle/working/train_masks/',\n                    X_val_ids, y_val_ids, batch_size=32)\n\nimgs, masks = next(gen)\nprint('Images batch shape: ', imgs.shape)\nprint('Masks batch shape: ', imgs.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 4, figsize=(15,7))\nfig.subplots_adjust(hspace=.1, wspace=.05)\ncar_samples, mask_samples = imgs[:4].astype(np.float32), masks[:4][:,:,:,0].astype(np.float32)\nfor i, (car, mask) in enumerate(zip(car_samples, mask_samples)):\n    ax[0, i].imshow(car)\n    ax[0, i].axis('off')\n    ax[0, i].title.set_text('Car Image')\n    \n    ax[1, i].imshow(mask, cmap='gray')\n    ax[1, i].axis('off')\n    ax[1, i].title.set_text('Car Mask')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model U-net"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport keras.backend as K\n\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\n\ndef Unet(input_shape=(128, 128, 3),\n                 num_classes=1):\n    inputs = Input(shape=input_shape)\n\n    down1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    down1 = BatchNormalization()(down1)\n    down1 = Activation('relu')(down1)\n    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n    down1 = BatchNormalization()(down1)\n    down1 = Activation('relu')(down1)\n    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n\n    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n    down2 = BatchNormalization()(down2)\n    down2 = Activation('relu')(down2)\n    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n    down2 = BatchNormalization()(down2)\n    down2 = Activation('relu')(down2)\n    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n\n    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n    down3 = BatchNormalization()(down3)\n    down3 = Activation('relu')(down3)\n    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n    down3 = BatchNormalization()(down3)\n    down3 = Activation('relu')(down3)\n    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n\n    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n    down4 = BatchNormalization()(down4)\n    down4 = Activation('relu')(down4)\n    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n    down4 = BatchNormalization()(down4)\n    down4 = Activation('relu')(down4)\n    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n\n    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n    center = BatchNormalization()(center)\n    center = Activation('relu')(center)\n    center = Conv2D(1024, (3, 3), padding='same')(center)\n    center = BatchNormalization()(center)\n    center = Activation('relu')(center)\n\n    up4 = UpSampling2D((2, 2))(center)\n    up4 = concatenate([down4, up4], axis=3)\n    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n    up4 = BatchNormalization()(up4)\n    up4 = Activation('relu')(up4)\n    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n    up4 = BatchNormalization()(up4)\n    up4 = Activation('relu')(up4)\n    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n    up4 = BatchNormalization()(up4)\n    up4 = Activation('relu')(up4)\n\n    up3 = UpSampling2D((2, 2))(up4)\n    up3 = concatenate([down3, up3], axis=3)\n    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n    up3 = BatchNormalization()(up3)\n    up3 = Activation('relu')(up3)\n    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n    up3 = BatchNormalization()(up3)\n    up3 = Activation('relu')(up3)\n    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n    up3 = BatchNormalization()(up3)\n    up3 = Activation('relu')(up3)\n\n    up2 = UpSampling2D((2, 2))(up3)\n    up2 = concatenate([down2, up2], axis=3)\n    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n    up2 = BatchNormalization()(up2)\n    up2 = Activation('relu')(up2)\n    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n    up2 = BatchNormalization()(up2)\n    up2 = Activation('relu')(up2)\n    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n    up2 = BatchNormalization()(up2)\n    up2 = Activation('relu')(up2)\n\n    up1 = UpSampling2D((2, 2))(up2)\n    up1 = concatenate([down1, up1], axis=3)\n    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n    up1 = BatchNormalization()(up1)\n    up1 = Activation('relu')(up1)\n    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n    up1 = BatchNormalization()(up1)\n    up1 = Activation('relu')(up1)\n    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n    up1 = BatchNormalization()(up1)\n    up1 = Activation('relu')(up1)\n\n    \n    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up1)\n\n    model = Model(inputs=inputs, outputs=classify)\n\n    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n\n    return model\n\nmodel = Unet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 40\ntrain_gen = data_generator('/kaggle/working/train_hq/', '/kaggle/working/train_masks/',\n                           X_train_ids, y_train_ids, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(train_gen, steps_per_epoch=100, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_masks = model.predict(imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(32, 3, figsize=(20,150))\nfor i in range(32):\n    ax[i, 0].imshow(imgs[i].astype(np.float32))\n    ax[i, 0].axis('off')\n    ax[i, 0].title.set_text('Car')\n    \n    ax[i, 1].imshow(masks[i,:,:,0].astype(np.float32), cmap='gray')\n    ax[i, 1].axis('off')\n    ax[i, 1].title.set_text('Real Mask')\n    \n    ax[i, 2].imshow(pred_masks[i,:,:,0], cmap='gray')\n    ax[i, 2].axis('off')\n    ax[i, 2].title.set_text('Predicted Mask')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}