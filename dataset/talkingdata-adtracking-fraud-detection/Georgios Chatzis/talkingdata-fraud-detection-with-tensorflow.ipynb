{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-29T19:47:29.813004Z","iopub.execute_input":"2021-10-29T19:47:29.814225Z","iopub.status.idle":"2021-10-29T19:47:29.830994Z","shell.execute_reply.started":"2021-10-29T19:47:29.814069Z","shell.execute_reply":"2021-10-29T19:47:29.829669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore the sample dataset with pandas","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/talkingdata-adtracking-fraud-detection/train_sample.csv')\nprint(df.shape)\nprint(df.info())\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:29.833264Z","iopub.execute_input":"2021-10-29T19:47:29.834017Z","iopub.status.idle":"2021-10-29T19:47:30.022316Z","shell.execute_reply.started":"2021-10-29T19:47:29.833966Z","shell.execute_reply":"2021-10-29T19:47:30.021064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['click_time_parsed'] = pd.to_datetime(df['click_time'])\ndf['year'] = df['click_time_parsed'].dt.year\ndf['month'] = df['click_time_parsed'].dt.month\ndf['day'] = df['click_time_parsed'].dt.day\ndf['hour'] = df['click_time_parsed'].dt.hour\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:30.023679Z","iopub.execute_input":"2021-10-29T19:47:30.023944Z","iopub.status.idle":"2021-10-29T19:47:30.127232Z","shell.execute_reply.started":"2021-10-29T19:47:30.023912Z","shell.execute_reply":"2021-10-29T19:47:30.1261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:30.129809Z","iopub.execute_input":"2021-10-29T19:47:30.130077Z","iopub.status.idle":"2021-10-29T19:47:30.215963Z","shell.execute_reply.started":"2021-10-29T19:47:30.130046Z","shell.execute_reply":"2021-10-29T19:47:30.214985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ncols = [\"ip\", \"app\", \"device\", \"os\", \"channel\", \"day\", \"hour\"]\n\nscaler = MinMaxScaler()\nscaler.fit(df[cols])\n\nX_min = scaler.data_min_\nX_max = scaler.data_max_\n\nprint(X_min)\nprint(X_max)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:30.217296Z","iopub.execute_input":"2021-10-29T19:47:30.218338Z","iopub.status.idle":"2021-10-29T19:47:30.572117Z","shell.execute_reply.started":"2021-10-29T19:47:30.218298Z","shell.execute_reply":"2021-10-29T19:47:30.571268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train - Valid split","metadata":{}},{"cell_type":"code","source":"filepath = \"/kaggle/input/talkingdata-adtracking-fraud-detection/train_sample.csv\"\n#filepath = \"/kaggle/input/talkingdata-adtracking-fraud-detection/train.csv\"\n\ntrain_path='train.csv'\nvalid_path='valid.csv'\n\nif os.path.exists(train_path):\n    os.remove(train_path)\n    \nif os.path.exists(valid_path):\n    os.remove(valid_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:30.573557Z","iopub.execute_input":"2021-10-29T19:47:30.574259Z","iopub.status.idle":"2021-10-29T19:47:30.581048Z","shell.execute_reply.started":"2021-10-29T19:47:30.574215Z","shell.execute_reply":"2021-10-29T19:47:30.580191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nsplit = 10000\n\nif split:\n    with open(filepath) as f:\n        reader = csv.reader(f, delimiter=',')\n        first_line = True\n        count = 0\n        for row in reader:\n            if first_line:\n                first_line = False\n\n                with open(train_path, 'wt', encoding='utf-8') as train_file:\n                    csv_writer = csv.writer(train_file, delimiter=',')\n                    csv_writer.writerow(row)\n\n                with open(valid_path, 'wt', encoding='utf-8') as valid_file:\n                    csv_writer = csv.writer(valid_file, delimiter=',')\n                    csv_writer.writerow(row)\n\n            else:\n                count +=1\n                if count<=split:\n                    with open(valid_path, 'a', encoding='utf-8') as valid_file:\n                        csv_writer = csv.writer(valid_file)\n                        csv_writer.writerow(row)\n                else:\n                    with open(train_path, 'a', encoding='utf-8') as train_file:\n                        csv_writer = csv.writer(train_file)\n                        csv_writer.writerow(row)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:30.582492Z","iopub.execute_input":"2021-10-29T19:47:30.585501Z","iopub.status.idle":"2021-10-29T19:47:33.673066Z","shell.execute_reply.started":"2021-10-29T19:47:30.585421Z","shell.execute_reply":"2021-10-29T19:47:33.671802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# keras Data API","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndataset = tf.data.TextLineDataset(train_path).skip(1)\n\nfor line in dataset.take(5):\n    print(line.numpy())","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:33.674386Z","iopub.execute_input":"2021-10-29T19:47:33.674612Z","iopub.status.idle":"2021-10-29T19:47:35.426625Z","shell.execute_reply.started":"2021-10-29T19:47:33.674584Z","shell.execute_reply":"2021-10-29T19:47:35.425292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\n\ndef preprocess(line):\n    defs = [0]*5 + [\"\"]*2 + [tf.constant([], dtype=tf.string)]\n    fields = tf.io.decode_csv(line, record_defaults=defs)\n    \n    # parse date\n    day = tf.strings.to_number(tf.strings.substr(fields[5], 8, len=2), tf.int32)\n    hour = tf.strings.to_number(tf.strings.substr(fields[5], 11, len=2), tf.int32)\n    \n    # features\n    features = fields[:-3]\n    features.append(day)\n    features.append(hour)\n    \n    x = tf.stack(features)\n    y = tf.stack(fields[-1])\n    #return x, y\n    return (x - X_min) / (X_max - X_min), y=='1'\n    \ntest = b'83230,3,1,13,379,2017-11-06 14:32:21,,0'\npreprocess(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:35.428792Z","iopub.execute_input":"2021-10-29T19:47:35.429152Z","iopub.status.idle":"2021-10-29T19:47:35.44716Z","shell.execute_reply.started":"2021-10-29T19:47:35.429104Z","shell.execute_reply":"2021-10-29T19:47:35.44588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.TextLineDataset(filepath).skip(1)\ndataset = dataset.map(preprocess)\n\nfor line in dataset.take(1):\n    print(line)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:35.449112Z","iopub.execute_input":"2021-10-29T19:47:35.450024Z","iopub.status.idle":"2021-10-29T19:47:35.665728Z","shell.execute_reply.started":"2021-10-29T19:47:35.449971Z","shell.execute_reply":"2021-10-29T19:47:35.664949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def csv_reader_dataset(filepath, shuffle_buffer_size=10000, batch_size=256, n_parse_threads=5):\n    dataset = tf.data.TextLineDataset(filepath).skip(1)\n    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n    dataset = dataset.shuffle(shuffle_buffer_size)\n    return dataset.batch(batch_size).prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:35.667251Z","iopub.execute_input":"2021-10-29T19:47:35.668301Z","iopub.status.idle":"2021-10-29T19:47:35.675003Z","shell.execute_reply.started":"2021-10-29T19:47:35.668231Z","shell.execute_reply":"2021-10-29T19:47:35.67379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deep Learning","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\ntrain_set = csv_reader_dataset(train_path)\nvalid_set = csv_reader_dataset(valid_path)\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(50, activation='relu', input_shape=[7]),\n    tf.keras.layers.Dense(30, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC()])","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:35.677028Z","iopub.execute_input":"2021-10-29T19:47:35.677418Z","iopub.status.idle":"2021-10-29T19:47:36.265747Z","shell.execute_reply.started":"2021-10-29T19:47:35.677374Z","shell.execute_reply":"2021-10-29T19:47:36.264464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\n\nmodel.fit(train_set, epochs=100, validation_data=valid_set, callbacks=[early_stopping_cb])","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:47:36.269033Z","iopub.execute_input":"2021-10-29T19:47:36.269855Z","iopub.status.idle":"2021-10-29T19:51:10.347427Z","shell.execute_reply.started":"2021-10-29T19:47:36.269813Z","shell.execute_reply":"2021-10-29T19:51:10.346493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Predictions","metadata":{}},{"cell_type":"code","source":"test_path ='/kaggle/input/talkingdata-adtracking-fraud-detection/test.csv'\n\ndataset = tf.data.TextLineDataset(test_path).skip(1)\nfor line in dataset.take(5):\n    print(line.numpy())","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:51:10.350627Z","iopub.execute_input":"2021-10-29T19:51:10.35128Z","iopub.status.idle":"2021-10-29T19:51:10.392521Z","shell.execute_reply.started":"2021-10-29T19:51:10.351231Z","shell.execute_reply":"2021-10-29T19:51:10.391559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_forecast(line):\n    defs = [0]*6 + [\"\"] \n    fields = tf.io.decode_csv(line, record_defaults=defs)\n    \n    # parse date\n    day = tf.strings.to_number(tf.strings.substr(fields[-1], 8, len=2), tf.int32)\n    hour = tf.strings.to_number(tf.strings.substr(fields[-1], 11, len=2), tf.int32)\n    \n    # features\n    features = fields[1:-1]\n    features.append(day)\n    features.append(hour)\n    \n    x = tf.stack(features)\n    return (x - X_min) / (X_max - X_min)\n    \n\ndataset = tf.data.TextLineDataset(test_path).skip(1)\ndataset = dataset.map(preprocess_forecast)\n\nfor line in dataset.take(1):\n    print(line)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:51:10.394394Z","iopub.execute_input":"2021-10-29T19:51:10.394752Z","iopub.status.idle":"2021-10-29T19:51:10.579817Z","shell.execute_reply.started":"2021-10-29T19:51:10.394706Z","shell.execute_reply":"2021-10-29T19:51:10.578915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_forecast(model, filepath):\n    dataset = tf.data.TextLineDataset(filepath).skip(1)\n    dataset = dataset.map(preprocess_forecast, num_parallel_calls=5)\n    dataset =  dataset.batch(256).prefetch(1)\n    prediction = model.predict(dataset)\n    return prediction\n\ny_pred = model_forecast(model, test_path)\ny_pred.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-29T19:51:10.581849Z","iopub.execute_input":"2021-10-29T19:51:10.582159Z","iopub.status.idle":"2021-10-29T20:01:32.679064Z","shell.execute_reply.started":"2021-10-29T19:51:10.582125Z","shell.execute_reply":"2021-10-29T20:01:32.678021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(test_path)\ndf['is_attributed'] = y_pred\ndf[['click_id','is_attributed']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-29T20:01:32.681036Z","iopub.execute_input":"2021-10-29T20:01:32.683245Z","iopub.status.idle":"2021-10-29T20:02:51.576812Z","shell.execute_reply.started":"2021-10-29T20:01:32.683173Z","shell.execute_reply":"2021-10-29T20:02:51.57534Z"},"trusted":true},"execution_count":null,"outputs":[]}]}