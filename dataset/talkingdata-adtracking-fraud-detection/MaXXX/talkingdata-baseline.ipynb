{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nfrom contextlib import contextmanager\nimport psutil\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 计算当前代码所使用的内存和时间\n@contextmanager\ndef timer_memory(name):\n    t0 = time.time()\n    yield\n    print(f'Memory: {(psutil.Process(os.getpid()).memory_info().rss/2**30):.02f}GB')\n    print(f'{name} done in {time.time()-t0:.0f}s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 计算列分组下下一次点击的时间间隔\ndef next_click(df, cols,feat):\n    name = '{}_nextclick'.format('_'.join(cols))\n    df['ct'] = (df['click_time'].astype(np.int64)//10**9).astype(np.int32)\n    df[name] = (df.groupby(cols).ct.shift(-1)-df.ct).astype(np.float32)\n    df[name] = df[name].fillna(df[name].mean())\n    df[name] = df[name].astype('uint32')\n    df.drop(['ct'],axis=1,inplace=True)\n    gc.collect()\n    feat.append(name)\n    print(f'{name} max: {df[name].max()}')\n    return df,feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 计算列分组大小\ndef dcount(df ,cols, dtype, feat):\n    name = '{}_count'.format('_'.join(cols))  \n    gp = df[cols].groupby(cols).size().rename(name).to_frame().reset_index()\n    df = pd.merge(df,gp,on=cols,how='left')\n    df[name] = df[name].astype(dtype)\n    del gp\n    gc.collect()\n    feat.append(name)\n    print(f'{name} max: {df[name].max()}')\n    return df,feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 计算列分组取值空间个数\ndef dcountun(df ,cols, dtype,feat):\n    name = '{}_countun'.format('_'.join(cols))  \n    gp = df[cols].groupby(cols[:len(cols)-1])[cols[len(cols)-1]].nunique().rename(name).to_frame().reset_index()\n    df = pd.merge(df,gp,on=cols[:len(cols)-1],how='left')\n    df[name] = df[name].astype(dtype)\n    del gp\n    gc.collect()\n    feat.append(name)\n    print(f'{name} max: {df[name].max()}')\n    return df,feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 计算列取值累计次数\n'''\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.cumcount.html\n\ndf = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n\ndf.groupby('A').cumcount()\n0    0\n1    1\n2    2\n3    0\n4    1\n5    3\n'''\ndef dcumcount(df ,cols, dtype,feat):\n    name = '{}_cumcount'.format('_'.join(cols))  \n    df[name] = df[cols].groupby(cols).cumcount()+1\n    df[name] = df[name].astype(dtype)\n    gc.collect()\n    feat.append(name)\n    print(f'{name} max: {df[name].max()}')\n    return df,feat   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../input/talkingdata-adtracking-fraud-detection/train.csv'\ntest_path = '../input/talkingdata-adtracking-fraud-detection/test.csv'\ntrain_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time']\ntest_cols  = ['ip', 'app', 'device', 'os', 'channel', 'click_time']\ndtypes = {\n    'ip'            : 'uint32',\n    'app'           : 'uint16',\n    'device'        : 'uint16',\n    'os'            : 'uint16',\n    'channel'       : 'uint16',\n    'is_attributed' : 'uint8',\n    'click_id'      : 'uint32'\n    }\ndebug = False\nchunk = 87000000\nvalsize = 5000000\nstart = 184903891-chunk\nif debug == True:\n    chunk = 45000\n    valsize=50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer_memory('Open files'):\n    train = pd.read_csv(train_path, skiprows=range(1, start), usecols=train_cols,dtype=dtypes, nrows=chunk,parse_dates=['click_time'])\n    test = pd.read_csv(test_path, usecols = test_cols, dtype=dtypes ,parse_dates=['click_time'])\n    feat = ['app','device','os','channel','hour'] #list with features \n    cat = ['app','device','os','channel','hour'] #list with categorical features\n    merge: pd.DataFrame = pd.concat([train, test])\n    print('Merge shape:',merge.shape)\n    print('Merge shape:\\n ',merge.dtypes)\n    del train\n    del test\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer_memory('New features'):\n    merge['hour'] = pd.to_datetime(merge.click_time).dt.hour.astype('uint8')\n    merge['day'] = pd.to_datetime(merge.click_time).dt.day.astype('uint8')\n    #merge , feat = next_click(merge,['app','channel'],feat)\n    merge , feat = next_click(merge,['ip','os','device','app'],feat)\n    merge.drop(['click_time'], axis = 1, inplace = True) ; gc.collect()\n    merge['in_test_hh'] = (2-merge['hour'].isin([4, 5, 9, 10, 13, 14])).astype('uint8')\n    merge , feat = dcount(merge , ['ip','day','in_test_hh'],'uint32',feat)\n    merge.drop(['in_test_hh'], axis = 1, inplace = True) ; gc.collect()\n    merge , feat = dcount(merge , ['day','hour','app','channel'],'uint16',feat)\n    merge , feat = dcount(merge , ['ip','day','hour','device'],'uint16',feat)\n    merge , feat = dcount(merge , ['ip','app'],'uint32',feat)\n    merge , feat = dcountun(merge , ['day','hour','app','channel'],'uint8',feat)\n    merge.drop(['day'], axis = 1, inplace = True) ; gc.collect()\n    merge , feat = dcountun(merge , ['ip','app'],'uint8',feat)\n    merge , feat = dcountun(merge , ['ip','channel'],'uint8',feat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer_memory('Preparing for training'):\n    import lightgbm as lgb\n    train = merge[:chunk-valsize]\n    val = merge[chunk-valsize:chunk] #validation, last 5mil rows from train dataset\n    test = merge[chunk:]\n    del merge\n    gc.collect()\n    y_train = (pd.read_csv(train_path, skiprows=range(1, start), usecols=['is_attributed'],dtype='uint8',nrows=chunk-valsize))['is_attributed'].values\n    y_val = (pd.read_csv(train_path, skiprows=range(1, start+chunk-valsize), usecols=['is_attributed'],dtype='uint8',nrows=valsize))['is_attributed'].values\n    d_train = lgb.Dataset(train[feat].values.astype(np.float32),label=y_train, feature_name=feat,categorical_feature=cat)\n    d_valid = lgb.Dataset(val[feat].values.astype(np.float32),label=y_val,feature_name=feat, categorical_feature=cat)\n    del train\n    del val\n    del y_train\n    del y_val\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer_memory('Training'):\n    params = {\"objective\": \"binary\",\n        'metric': {'auc'},\n        \"boosting_type\": \"gbdt\",\n        \"verbosity\": -1,\n        \"num_threads\": 4,\n        \"bagging_fraction\": 0.8,\n        \"feature_fraction\": 0.8,\n        \"learning_rate\": 0.08, \n        \"num_leaves\": 90,\n        'max_depth': 7,\n        \"verbose\": -1,\n        \"min_split_gain\": .3,\n        \"reg_alpha\": .3,\n        'scale_pos_weight': 99.7, \n        'two_round':True}\n    model = lgb.train(params,train_set=d_train,num_boost_round=2500,valid_sets=[d_valid],verbose_eval=True,early_stopping_rounds=25)\n    del d_train\n    del d_valid\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with timer_memory('Predict and submission file'):\n    test['click_id'] = pd.read_csv(test_path, usecols = ['click_id'], dtype='uint32')['click_id'].values\n    test['click_id'] = test['click_id'].astype('uint32')\n    gc.collect()\n    test['is_attributed'] = model.predict(test[feat].values.astype(np.float32),num_iteration=model.best_iteration)\n    test[['click_id','is_attributed']].to_csv('lgb87mil.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}