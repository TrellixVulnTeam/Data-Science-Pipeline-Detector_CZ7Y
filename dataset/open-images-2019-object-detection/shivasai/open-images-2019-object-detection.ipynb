{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nfrom pprint import pprint\nfrom six import BytesIO\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image, ImageColor, ImageDraw, ImageFont, ImageOps\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_prediction_string(image_id, result):\n    prediction_strings = []\n    \n    for i in range(len(result['detection_scores'])):\n        class_name = result['detection_class_names'][i].decode(\"utf-8\")\n        boxes = result['detection_boxes'][i]\n        score = result['detection_scores'][i]\n        \n        prediction_strings.append(\n            f\"{class_name} {score} \" + \" \".join(map(str, boxes))\n        )\n        \n    prediction_string = \" \".join(prediction_strings)\n\n    return {\n        \"ImageID\": image_id,\n        \"PredictionString\": prediction_string\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_image(image):\n    fig = plt.figure(figsize=(20, 15))\n    plt.grid(False)\n    plt.axis('off')\n    plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n    colors = list(ImageColor.colormap.values())\n\n    try:\n        font = ImageFont.truetype(\n            \"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n            25)\n    except IOError:\n        print(\"Font not found, using default font.\")\n        font = ImageFont.load_default()\n\n    for i in range(min(boxes.shape[0], max_boxes)):\n        if scores[i] >= min_score:\n            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n                                           int(100 * scores[i]))\n            color = colors[hash(class_names[i]) % len(colors)]\n            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n            draw_bounding_box_on_image(\n                image_pil,\n                ymin,\n                xmin,\n                ymax,\n                xmax,\n                color,\n                font,\n                display_str_list=[display_str])\n            np.copyto(image, np.array(image_pil))\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\n\nINPUT_PATH_PNG = \"../input/aptos2019-blindness-detection/train_images/\"\nfiles_png_init = sorted(glob.glob(INPUT_PATH_PNG + '*.png'))\nfiles_png_init = files_png_init[:300]\nprint('PNG Files: {}'.format(len(files_png_init)))\n\nos.mkdir('/dev/shm/4/')\nfiles_png = []\nfor f in files_png_init:\n    new_path = '/dev/shm/4/' + os.path.basename(f)\n    shutil.copy(f, new_path)\n    files_png.append(new_path)\n\nINPUT_PATH_JPG_SMALL = \"../input/open-images-2019-object-detection/test/\"\nfiles_jpg_small_init = sorted(glob.glob(INPUT_PATH_JPG_SMALL + '*.jpg'))\nfiles_jpg_small_init = files_jpg_small_init[:3000]\nprint('JPG small files: {}'.format(len(files_jpg_small_init)))\n\nos.mkdir('/dev/shm/5/')\nfiles_jpg_small = []\nfor f in files_jpg_small_init:\n    new_path = '/dev/shm/5/' + os.path.basename(f)\n    shutil.copy(f, new_path)\n    files_jpg_small.append(new_path)\n\nINPUT_PATH_JPG_BIG = \"../input/sp-society-camera-model-identification/train/\"\nfiles_jpg_big_init = sorted(glob.glob(INPUT_PATH_JPG_BIG + '*/*.jpg'))\nfiles_jpg_big_init = files_jpg_big_init[:300]\nprint('JPG big files: {}'.format(len(files_jpg_big_init)))\n\nos.mkdir('/dev/shm/6/')\nfiles_jpg_big = []\nfor f in files_jpg_big_init:\n    new_path = '/dev/shm/6/' + os.path.basename(f)\n    shutil.copy(f, new_path)\n    files_jpg_big.append(new_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\nstart_time = time.time()\nd = []\nfor f in files_jpg_small:\n    a = jpeg.JPEG(f).decode()\n    d.append(a)\nprint('Time to read {} JPEGs small for libjpeg-turbo (jpeg4py): {:.2f} sec'.format(len(files_jpg_small), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_jpg_big:\n    a = jpeg.JPEG(f).decode()\n    d.append(a)\nprint('Time to read {} JPEGs big for libjpeg-turbo (jpeg4py): {:.2f} sec'.format(len(files_jpg_big), time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nd = []\nfor f in files_jpg_small:\n    b = cv2.imread(f)\n    # b = np.transpose(b, (1, 0, 2))\n    # b = np.flip(b, axis=0)\n    b = cv2.cvtColor(b, cv2.COLOR_BGR2RGB)\n    d.append(b)\nprint('Time to read {} JPEGs small for cv2 with BGR->RGB conversion: {:.2f} sec'.format(len(files_jpg_small), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_jpg_big:\n    b = cv2.imread(f)\n    # b = np.transpose(b, (1, 0, 2))\n    # b = np.flip(b, axis=0)\n    b = cv2.cvtColor(b, cv2.COLOR_BGR2RGB)\n    d.append(b)\nprint('Time to read {} JPEGs big for cv2 with BGR->RGB conversion: {:.2f} sec'.format(len(files_jpg_big), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_png:\n    b = cv2.imread(f)\n    # b = np.transpose(b, (1, 0, 2))\n    # b = np.flip(b, axis=0)\n    b = cv2.cvtColor(b, cv2.COLOR_BGR2RGB)\n    d.append(b)\nprint('Time to read {} PNGs for cv2 with BGR->RGB conversion: {:.2f} sec'.format(len(files_png), time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nd = []\nfor f in files_jpg_small:\n    b = cv2.imread(f)\n    d.append(b)\nprint('Time to read {} JPEGs small for cv2 no conversion: {:.2f} sec'.format(len(files_jpg_small), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_jpg_big:\n    b = cv2.imread(f)\n    d.append(b)\nprint('Time to read {} JPEGs big for cv2 no conversion: {:.2f} sec'.format(len(files_jpg_big), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_png:\n    b = cv2.imread(f)\n    d.append(b)\nprint('Time to read {} PNGs for cv2 no conversion: {:.2f} sec'.format(len(files_png), time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nd = []\nfor f in files_jpg_small:\n    c = Image.open(f)\n    c = np.array(c)\n    d.append(c)\nprint('Time to read {} JPEGs small for PIL: {:.2f} sec'.format(len(files_jpg_small), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_jpg_big:\n    c = Image.open(f)\n    c = np.array(c)\n    d.append(c)\nprint('Time to read {} JPEGs big for PIL: {:.2f} sec'.format(len(files_jpg_big), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_png:\n    c = Image.open(f)\n    c = np.array(c)\n    d.append(c)\nprint('Time to read {} PNGs for PIL: {:.2f} sec'.format(len(files_png), time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nd = []\nplugin = 'matplotlib'\nfor f in files_jpg_small:\n    c = skimage.io.imread(f, plugin=plugin)\n    c = np.array(c)\n    d.append(c)\nprint('Time to read {} JPEGs small for skimage.io Plugin: {}: {:.2f} sec'.format(len(files_jpg_small), plugin, time.time() - start_time))\n\nstart_time = time.time()\nd = []\nplugin = 'matplotlib'\nfor f in files_jpg_big:\n    c = skimage.io.imread(f, plugin=plugin)\n    c = np.array(c)\n    d.append(c)\nprint('Time to read {} JPEGs big for skimage.io Plugin: {}: {:.2f} sec'.format(len(files_jpg_big), plugin, time.time() - start_time))\n\nstart_time = time.time()\nd = []\nplugin = 'matplotlib'\nfor f in files_png:\n    c = skimage.io.imread(f, plugin=plugin)\n    c = np.array(c)\n    d.append(c)\nprint('Time to read {} PNGs for skimage.io Plugin: {}: {:.2f} sec'.format(len(files_png), plugin, time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(\"../input/sample_submission.csv\").head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nd = []\nfor f in files_jpg_small:\n    c = imageio.imread(f)\n    d.append(c)\nprint('Time to read {} JPEGs small for Imageio (no rotate): {:.2f} sec'.format(len(files_jpg_small), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_jpg_big:\n    c = imageio.imread(f)\n    d.append(c)\nprint('Time to read {} JPEGs big for Imageio (no rotate): {:.2f} sec'.format(len(files_jpg_big), time.time() - start_time))\n\nstart_time = time.time()\nd = []\nfor f in files_png:\n    c = imageio.imread(f)\n    d.append(c)\nprint('Time to read {} PNGs for Imageio (no rotate): {:.2f} sec'.format(len(files_png), time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = os.listdir(\"../input/test\")\nimages[:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\n\n\n#read the first jpg file\nimg = cv2.imread('../input/test/b4c3b52a8723d431.jpg',0)\n#img = cv2.imread('../input/test/b4c3b52a8723d431.jpg')\n\n#check the array of the first jpg file\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#view the array as an image\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x= '../input/test/'\nmyList = [ x + i for i in images[:100]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in myList:\n    plt.imshow( cv2.imread(i) ) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_filenames = os.listdir(\"../input/test/\")\n\nimport random\nfor i in range(10):\n    index = random.randrange(len(image_filenames))\n    path = \"../input/test/\" + \"/\" + image_filenames[index]\n    src_img = cv2.imread(path)\n    fig=plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n    plt.imshow(cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n\nimport tempfile\nfrom six.moves.urllib.request import urlopen\nfrom six import BytesIO\n\nfrom PIL import Image\nfrom PIL import ImageColor\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageOps\n\nimport time\n\nprint(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_image(image):\n    fig = plt.figure(figsize=(20, 15))\n    plt.grid(False)\n    plt.imshow(image)\n\n\ndef download_and_resize_image(url, new_width=256, new_height=256,\n                              display=False):\n    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n    response = urlopen(url)\n    image_data = response.read()\n    image_data = BytesIO(image_data)\n    pil_image = Image.open(image_data)\n    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n    pil_image_rgb = pil_image.convert(\"RGB\")\n    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n    print(\"Image downloaded to %s.\" % filename)\n    if display:\n        display_image(pil_image)\n    return filename\n\n\ndef draw_bounding_box_on_image(image, ymin, xmin, ymax, xmax, color, font, thickness=4, display_str_list=()):\n    draw = ImageDraw.Draw(image)\n    im_width, im_height = image.size\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n    draw.line([(left, top), (left, bottom), (right, bottom), (right, top), (left, top)], width=thickness, fill=color)\n\n    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n    if top > total_display_str_height:\n        text_bottom = top\n    else:\n        text_bottom = bottom + total_display_str_height\n    for display_str in display_str_list[::-1]:\n        text_width, text_height = font.getsize(display_str)\n        margin = np.ceil(0.05 * text_height)\n        draw.rectangle([(left, text_bottom - text_height - 2 * margin), (left + text_width, text_bottom)], fill=color)\n        draw.text((left + margin, text_bottom - text_height - margin), display_str, fill=\"black\", font=font)\n        text_bottom -= text_height - 2 * margin\n\n\ndef draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n    colors = list(ImageColor.colormap.values())\n\n    try:\n        font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n                              25)\n    except IOError:\n        print(\"Font not found, using default font.\")\n        font = ImageFont.load_default()\n\n    for i in range(min(boxes.shape[0], max_boxes)):\n        if scores[i] >= min_score:\n            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"), int(100 * scores[i]))\n            color = colors[hash(class_names[i]) % len(colors)]\n            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n            draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color, font, display_str_list=[display_str])\n        np.copyto(image, np.array(image_pil))\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_url = \"https://farm1.staticflickr.com/4032/4653948754_c0d768086b_o.jpg\"  #@param\ndownloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_urls = [\"https://farm7.staticflickr.com/8092/8592917784_4759d3088b_o.jpg\",\n              \"https://farm6.staticflickr.com/2598/4138342721_06f6e177f3_o.jpg\"]\n\nfor image_url in image_urls:\n    image_path = download_and_resize_image(image_url, 640, 480)\n    with tf.gfile.Open(image_path, \"rb\") as binfile:\n        image_string = binfile.read()\n\n    inference_start_time = time.clock()\n    result_out, image_out = session.run([result, decoded_image], feed_dict={image_string_placeholder: image_string})\n    print(\"Found %d objects.\" % len(result_out[\"detection_scores\"]))\n    print(\"Inference took %.2f seconds.\" % (time.clock()-inference_start_time))\n\n    image_with_boxes = draw_boxes(\n    np.array(image_out), result_out[\"detection_boxes\"],\n    result_out[\"detection_class_entities\"], result_out[\"detection_scores\"])\n\n    display_image(image_with_boxes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.3/imageai-2.0.3-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_sub = pd.read_csv('../input/sample_submission.csv')\ns_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filename = os.listdir('../input/test')\ntest_filename[:5]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelMap = pd.read_csv('class-descriptions-boxable.csv', header=None, names=['labelName', 'Label'])\nlabelMap.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show one image\ndef show_image_by_index(i):\n    sample_image = plt.imread(f'../input/test/{test_filename[i]}')\n    plt.imshow(sample_image)\n\ndef show_image_by_filename(filename):\n    sample_image = plt.imread(filename)\n    plt.imshow(sample_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image_by_index(22)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image_by_filename(f'../input/test/e7c0991d9a37bdef.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imageai.Detection import ObjectDetection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the path to the working directory\nexecution_path = os.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# load model\ndetector = ObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(os.path.join(execution_path, \"yolo.h5\"))\ndetector.loadModel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# test detection on one image\ndetections = detector.detectObjectsFromImage(input_image=os.path.join('../input/test', 'e7c0991d9a37bdef.jpg'),\n                                                                      #test_filename[64]), \n                                             output_image_path=os.path.join(execution_path , \"result.jpg\"),\n#                                            output_type = 'array',\n                                             extract_detected_objects = False)\nfor eachObject in detections:\n    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n\n# show the result\nshow_image_by_filename('./result.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#view detection variable\ndetections\ndef format_prediction_string(image_id, result, labelMap, xSize, ySize):\n    prediction_strings = []\n    #print(xSize, ySize)\n    for i in range(len(result)):\n        class_name = result[i]['name'].capitalize()\n        class_name = pd.DataFrame(labelMap.loc[labelMap['Label'].isin([class_name])]['labelName'])\n        #print(result[i]['box_points'])\n        xMin = result[i]['box_points'][0] / xSize\n        xMax = result[i]['box_points'][2] / xSize\n        yMin = result[i]['box_points'][1] / ySize\n        yMax = result[i]['box_points'][3] / ySize\n        \n        if len(class_name) > 0:\n            class_name = class_name.iloc[0]['labelName']\n            boxes = [xMin, yMin, xMax, yMax]#result[i]['box_points']\n            score = result[i]['percentage_probability']\n\n            prediction_strings.append(\n                f\"{class_name} {score} \" + \" \".join(map(str, boxes))\n            )\n        \n    prediction_string = \" \".join(prediction_strings)\n\n    return {\n            \"ImageID\": image_id,\n            \"PredictionString\": prediction_string\n            }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Test prediction on input images\nres = []\nfor i in tqdm(os.listdir('../input/test')[20:25]):\n    detections = detector.detectObjectsFromImage(input_image=os.path.join('../input/test', i),\n                                                 output_image_path=os.path.join(execution_path , \"result.jpg\"),\n                                                 #output_type = 'array',\n                                                 extract_detected_objects = False)\n    currentImg = Image.open(os.path.join('../input/test', i))\n    xSize = currentImg.size[0]\n    ySize = currentImg.size[1]\n    #print(xSize, ySize)\n    p = format_prediction_string(i, detections, labelMap, xSize, ySize)\n    res.append(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert res variable to DataFrame\npred_df = pd.DataFrame(res)\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the file name without extension\npred_df['ImageID'] = pred_df['ImageID'].map(lambda x: x.split(\".\")[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}