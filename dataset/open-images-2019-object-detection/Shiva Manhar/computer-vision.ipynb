{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\nfrom PIL import Image\n\n'''import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_green = cv2.imread(\"/kaggle/input/open-images-2019-object-detection/test/34ff94b34c6851bf.jpg\")\nprint(img_green.shape)\nplt.imshow(img_green)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"img = cv2.imread(\"/kaggle/input/open-images-2019-object-detection/test/149d7a017153bc72.jpg\")\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Total image chanal "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the image into RGB\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nprint(img_rgb.shape)\nplt.imshow(img_rgb)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Color channel value "},{"metadata":{"trusted":true},"cell_type":"code","source":"bicycle1 = np.copy(img_rgb)\nbicycle1[:,:,0] = 5*bicycle1[:,:,0]\nbicycle1[:,:,1] = bicycle1[:,:,1]/2 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(bicycle1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Draw a rectange"},{"metadata":{"trusted":true},"cell_type":"code","source":"bicycle2 = np.copy(img_rgb)\ncv2.rectangle(bicycle2, pt1=(100,400), pt2=(200, 600), color=(0, 255,0), thickness=5)\nplt.imshow(bicycle2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Draw a circle"},{"metadata":{"trusted":true},"cell_type":"code","source":"bicycle3 = np.copy(img_rgb)\ncv2.circle(bicycle3, center=(200, 200), radius=50, thickness=5, color=(0, 0, 255))\nplt.imshow(bicycle3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add text"},{"metadata":{"trusted":true},"cell_type":"code","source":"bicycle4 = img_rgb.copy()\ncv2.putText(bicycle4, text=\"Sense Tech\", org=(250, 260), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(255, 10, 100), thickness=2, lineType=cv2.LINE_AA )\nplt.imshow(bicycle4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 6))\nax1.hist(bicycle4[:,:,0].ravel(), bins=20)\nax2.hist(bicycle4[:,:,1].ravel(), bins=20)\nax3.hist(bicycle4[:,:,2].ravel(), bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''bicycle5 = np.copy(img_rgb)\ndef draw_circle(event, x, y, flags, param):\n    if event == cv2.EVENT_LBUTTONDOWN:\n        cv2.circle(bicycle5, center = (x,y), radius=5, color=(87, 184, 237), thinkness=-1)\n    elif event == cv2.EVENT_RBUTTONDOWN:\n        cv2.circle(bicycle5, center=(x,y), radius=10, color=(85, 185, 234), thinkness=1)\n\ncv2.namedWindow(winname='my_drawing')\ncv2.setMouseCallback('my_drawing', draw_circle)\n\nwhile True:\n    cv2.imshow('my_drawing', bicycle5)\n    if cv2.waitKey(10) & 0xFF == 27:\n        break\n    cv2.destroyAllWindows()'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Blurring"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Average blurring\nbicycle5 = np.copy(img_rgb)\n#\nkernels = [5, 11, 17]\n\nplt.imshow(bicycle5)\nplt.show()\nfig, axs = plt.subplots(nrows= 1, ncols=3, figsize=(20,20))\nfor ind, s in enumerate(kernels):\n    img_blurred = cv2.blur(bicycle5, ksize=(s,s))\n    ax = axs[ind]\n    ax.imshow(img_blurred)\n    ax.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_0 = cv2.blur(img_rgb, ksize=(7,7))\nimg_1 = cv2.GaussianBlur(img_rgb, ksize=(7,7), sigmaX=0)\nimg_2 = cv2.medianBlur(img_rgb, 7)\nimg_3 = cv2.bilateralFilter(img_rgb, 7, sigmaSpace=75, sigmaColor=75)\n\nimages = [img_0, img_1, img_2, img_3]\nfig, axs = plt.subplots(nrows =1, ncols =4, figsize=(20,20))\n\nfor ind, p in enumerate(images):\n    ax = axs[ind]\n    ax.imshow(p)\n    ax.axis('off')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Types of thresholding\n<ol>\n    <li> Binary </li>\n    <li> The inverse of Binary </li>\n    <li> Threshold to zero </li>\n    <li> The inverse of Threshold to zero </li>\n    <li> Threshold trunction </li>\n</ol>"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, thresh_0 = cv2.threshold(img_rgb, 127, 255, cv2.THRESH_BINARY)\n_, thresh_1 = cv2.threshold(img_rgb, 127, 255, cv2.THRESH_BINARY_INV)\n_, thresh_2 = cv2.threshold(img_rgb, 127, 255, cv2.THRESH_TOZERO)\n_, thresh_3 = cv2.threshold(img_rgb, 127, 255, cv2.THRESH_TOZERO_INV)\n_, thresh_4 = cv2.threshold(img_rgb, 127, 255, cv2.THRESH_TRUNC)\n\nimages = [img, thresh_0, thresh_1, thresh_2, thresh_3, thresh_4]\n\nfig, axs = plt.subplots(nrows= 2, ncols=3, figsize=(13,13))\n\nfor ind, p in enumerate(images):\n    ax = axs[ind//3, ind%3]\n    ax.imshow(p)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient"},{"metadata":{"trusted":true},"cell_type":"code","source":"sobel_x = cv2.Sobel(img_rgb, cv2.CV_64F, dx=1, dy=0, ksize=5)\nsobel_y = cv2.Sobel(img_rgb, cv2.CV_64F, dx=0, dy=1, ksize=5)\n\nblended = cv2.addWeighted(src1=sobel_x, alpha=0.5, src2 = sobel_y, beta=0.5, gamma=0)\nlaplacian = cv2.Laplacian(img_rgb, cv2.CV_64F)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = [sobel_x, sobel_y, blended, laplacian]\n\nplt.figure(figsize=(20,20))\nfor i in range(4):\n    plt.subplot(1, 4, i+1)\n    plt.imshow(images[i], cmap='gray')\n    plt.axis('off')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index_210 = img_rgb > 110\nbicycle6 = np.copy(img_rgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bicycle6[index_210] = 250","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.imshow(bicycle6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"small_img = np.copy(img_rgb)\nsmall_img = small_img[350:-200:]\nprint(small_img.shape)\nplt.figure(figsize=(20,20))\nplt.imshow(small_img)\nplt.axis('off')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"edges = cv2.Canny(image= small_img, threshold1=250, threshold2=250)\nedges[100:,:,]\nplt.figure(figsize=(20,20))\nplt.imshow(edges)\nplt.axis('off')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set the lower and upper threshold\nmed_val = np.median(small_img)\nlower = int(max(0, .7*med_val))\nupper = int(min(255, 1.3*med_val))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Blurring with ksize= 5\nimg_k5 = cv2.blur(small_img, ksize=(5,5))\n\n#Canny detection with different thresholds\nedges_k5 = cv2.Canny(img_k5, threshold1=lower, threshold2 = upper)\n\nedges_k5_2 = cv2.Canny(img_k5, lower, upper+100)\n\n#blurring with ksize=9\nimg_k9 = cv2.blur(small_img, ksize=(9,9))\n\n#Canny detection with different thresholds\nedges_k9 = cv2.Canny(img_k9, lower, upper)\nedges_k5_2 = cv2.Canny(img_k9, lower, upper)\n\n#plot the images\nimages = [edges_k5, edges_k5, edges_k9, edges_k5_2]\nplt.figure(figsize=(20, 5))\n\nfor i in range(4):\n    plt.subplot(2,2, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr = np.array([[[3, 4], [8, 2], [1, 9]],\n               [[3, 0], [8, 2], [1, 10]],\n               [[3, 4], [8, 2], [1, 9]]])\narr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(arr[:,:,1],  cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr[:,:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr = np.array([[[3, 4, 5], [8, 2, 5], [1, 9, 5]],\n               [[3, 0, 1], [8, 2, 7], [1, 10, 3]],\n               [[3, 44, 6], [8, 2, 7], [1, 9, 8]],\n               [[3, 4, 0], [8, 2, 1], [1, 9,1 ]],\n               [[3, 0, 1], [98, 26, 88], [1, 10,1]],\n               [[250, 250,250], [120, 110, 250], [1, 9, 250]],\n               [[3, 4, 4], [8, 2,6], [1, 9, 4]],\n               [[3, 0, 2], [8, 2, 5], [1, 10,2]],\n               [[3, 4, 0], [8, 2,1], [1, 9, 3]]])\narr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr2 = np.copy(arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(arr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr_condition = arr < 250\narr2[arr_condition] += 100 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(arr2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the image into gray scale\nimg_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nprint(img_gray.shape)\nplt.figure(figsize=(16, 8))\nplt.imshow(img_gray, cmap = 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np_img = np.array(img_gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np_img[10:-5, 10:-5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img2 = np.copy(img_gray)\nimg2[100:200, 10:100] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img2, cmap = 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_green = cv2.cvtColor(img_green, cv2.COLOR_BGR2RGB)\nplt.figure(figsize=(16, 8))\nplt.imshow(img_green)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_green = cv2.cvtColor(img_green, cv2.COLOR_BGR2GRAY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img3 = np.copy(img2)\nimg3[100:200, 10:100] = img_green[100:200, 10:100] \nplt.figure(figsize=(16, 8))\nplt.imshow(img3, cmap = 'gray')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}