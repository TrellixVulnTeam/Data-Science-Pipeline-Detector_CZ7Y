{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!pip install ../input/rsnapkgs/timm-0.2.2-py3-none-any.whl\n!pip install ../input/pytorch-transformers/pytorch_transformers-1.2.0-py3-none-any.whl\n!cp ../input/gdcm-conda-install/gdcm.tar .\n!tar -xvzf gdcm.tar\n!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\nprint(\"done\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport platform\nimport os\nimport gc\nimport glob\nimport gdcm\nimport pydicom\nfrom PIL import Image\nimport timm\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport cv2\nfrom collections import defaultdict, namedtuple\nimport sys\nimport torch\nfrom torch.backends import cudnn\nfrom torch.nn import DataParallel\nfrom torch.utils.data import DataLoader\n\nfrom tqdm import tqdm\nimport torch.distributed as dist\nimport platform\nfrom torch.utils.data import Dataset\nfrom torch.utils.data.sampler import Sampler\nimport albumentations as A\nfrom albumentations.pytorch import ToTensor\nfrom torch import nn\nfrom torch.nn.modules.dropout import Dropout\nfrom torch.nn.modules.linear import Linear\nfrom torch.nn.modules.pooling import AdaptiveAvgPool2d\nfrom pytorch_transformers.modeling_bert import BertConfig, BertEncoder\nimport torch.nn.functional as F\nfrom torch import nn\nPATH = '../input/rsnasubcheck'\nsys.path.append(PATH)\n\nPATH = '../input/rsnastr2020/rsnastr'\nsys.path.append(PATH)\nnp. set_printoptions(suppress=True)\nfrom training.tools.utils import ip_window\nfrom training.tools.utils import get_logger\nfrom training.tools.config import load_config, RSNA_CFG\nfrom training.zoo import classifiers\nfrom training.zoo.sequence import SpatialDropout, LSTMNet, TransformerNet\nfrom training.tools.utils import RSNA_CFG as CFG\nfrom consistency_check import clean_sub, check_consistency\n\n#from training.zoo import classifiers\nlogger = get_logger('Kaggle', 'INFO') \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class args:\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    batchsize = 1\n    imgbatchsize = 128\n    folds = [0,1,2]\n    load_train = False\n    do_full = True\n    delta = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cfg = load_config(args.config, defaults=RSNA_CFG)\ndef dict2class(cfg):\n    cfg['device'] = args.device\n    cfg = namedtuple('Struct', cfg.keys())(*cfg.values())\n    return cfg\ncfgimg = dict2class(load_config(f'{PATH}/configs/effnetb5_lr5e4_multi.json'))\ncfgseq1 = dict2class(load_config(f'{PATH}/configs/b5_seq_lstm.json', defaults=RSNA_CFG))\ncfgseq2 = dict2class(load_config(f'{PATH}/configs/b5_seq_transformer_1layer.json', defaults=RSNA_CFG))\ncfgseq3 = dict2class(load_config(f'{PATH}/configs/b5_seq_transformer_2layer.json', defaults=RSNA_CFG))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class RSNAImageSequenceDataset(Dataset):\n\n    def __init__(self, \n                 datadf,\n                 folddf,\n                 mode=\"train\"):\n        self.mode = mode\n        self.datadf = datadf\n        self.folddf = folddf\n        self.imgclasses = CFG['image_target_cols']\n        self.studyclasses = CFG['exam_target_cols']\n\n    def __len__(self):\n        return len(self.folddf)\n\n    def __getitem__(self, idx):\n        # idx = 1\n        studyidx = self.folddf.iloc[idx].StudyInstanceUID\n        seriesidx = self.folddf.iloc[idx].SeriesInstanceUID\n        studydf = self.datadf.query('StudyInstanceUID == @studyidx')\\\n                        .query('SeriesInstanceUID == @seriesidx')\n        imgs = []\n        imgnames = []\n        imglabels = []\n        if self.mode == 'train':\n            studylabels = studydf[self.studyclasses].iloc[0].values\n        for i, samp in studydf.reset_index().iterrows():\n            if self.mode == 'train':\n                imglabels.append(samp['pe_present_on_image'])\n            sampkey, img_name = self.image_file(samp)\n            try:\n                dicom_object = pydicom.read_file(img_name)\n                img = ip_window(dicom_object)\n            except:\n                img = np.zeros(shape=(512,512,3), dtype=np.uint8)\n            imgs.append(img)\n            imgnames.append(sampkey)\n        imgs = np.stack(imgs)\n        if self.mode == 'train':\n            labels = torch.tensor(imglabels)\n            return {'img_name': imgnames, 'image': imgs, 'imglabels': imglabels, 'studylabels': studylabels}\n        return {'img_name': imgnames, 'image': imgs}\n    \n    def image_file(self, samp):\n        sampkey = '/'.join([samp.StudyInstanceUID, samp.SeriesInstanceUID,samp.SOPInstanceUID])\n        imgname = os.path.join('../input/rsna-str-pulmonary-embolism-detection', \n                                self.mode,\n                                sampkey) + '.dcm'\n        return sampkey, imgname\n\ndef collateimgfn(batch):\n    \n    maxlen = max([l['image'].shape[0] for l in batch])\n    for b in batch:\n        masklen = maxlen-len(b['image'])\n        b['mask'] = np.ones((maxlen))\n        b['mask'][:masklen] = 0\n    \n    outbatch = {'image': np.concatenate([b['image'] for b in batch], 0)}\n    outbatch['mask'] = torch.tensor(np.vstack([np.expand_dims(b['mask'], 0) \\\n                                                for b in batch])).float()\n    outbatch['img_name'] = []\n    for b in batch:\n        outbatch['img_name'] += b['img_name'] \n        \n    if 'imglabels' in batch[0]:\n        for b in batch:\n            masklen = maxlen-len(b['image'])\n            b['imglabelsout'] = np.ones((maxlen))*-1\n            b['imglabelsout'][masklen:] = b['imglabels']\n        outbatch['imglabels'] = torch.tensor(np.vstack([np.expand_dims(b['imglabelsout'], 0) \\\n                                                for b in batch])).long()\n        outbatch['studylabels'] = torch.tensor(np.vstack([np.expand_dims(b['studylabels'], 0) \\\n                                                for b in batch])).long()\n    return outbatch\n\ndef batchPredsfn(studypreds, imgpreds, imgnames):\n    preds = []\n    batchdf = pd.DataFrame([i.split('/') for i in imgnames], \n                           columns = ['StudyInstanceUID', 'SeriesInstanceUID','SOPInstanceUID'])\n    studies = batchdf.StudyInstanceUID.unique().tolist()\n    for study, row in zip(studies, studypreds):\n        for col, pred in zip(CFG['exam_target_cols'], row):\n            preds.append([f'{study}_{col}', pred])\n    for nm, pred in zip(batchdf.SOPInstanceUID, imgpreds):\n        preds.append([nm, pred])\n    return preds\n\ndef aug_batch(imgs, mean_, std_, device):\n    imgs = imgs.to(device).float()\n    return (((imgs / 255) - mean_) / std_).permute(0, 3, 1, 2).half()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../input/rsna-str-pulmonary-embolism-detection/sample_submission.csv submission.csv\nif args.load_train:\n    trndf = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/train.csv')\nif os.path.exists('../input/rsna-str-pulmonary-embolism-detection/train') and not args.do_full:\n    tstdf = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/test.csv').head(2000)\nelse:\n    tstdf = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/test.csv')\n\nkeycols = ['StudyInstanceUID', 'SeriesInstanceUID']\nDEBUG = (tstdf.shape[0]==146853)\nDEBUG","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loaderargs = {'num_workers' : 4, 'pin_memory': False, 'drop_last': False, 'collate_fn' : collateimgfn}\nif args.load_train:\n    trndataset = RSNAImageSequenceDataset(mode = 'train', \n                                folddf = trndf[keycols].drop_duplicates().reset_index(drop=True), \n                                datadf = trndf)\n    trnloader = DataLoader(trndataset, batch_size=args.batchsize, shuffle=False, **loaderargs)\n    \ntstdataset = RSNAImageSequenceDataset(mode = 'test', \n                                folddf = tstdf[keycols].drop_duplicates().reset_index(drop=True), \n                                datadf = tstdf)\ntstloader = DataLoader(tstdataset, batch_size=args.batchsize, shuffle=False, **loaderargs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image_model(wtsnm, conf, device = args.device):\n    nclasses = len(conf.image_target_cols) + len(conf.exam_target_cols)\n    model = classifiers.__dict__[conf.network](encoder=f\"{conf.encoder}_infer\",\n                                                  nclasses = nclasses,\n                                                 infer = True)\n    checkpoint = torch.load(wtsnm, map_location=torch.device(device))\n    model.load_state_dict(checkpoint['state_dict'])\n    model = model.half().to(device)\n    model = model.eval()\n    return model\n\ndef load_exam_model(wtsnm, cfg, embed_size = 2048, device = args.device):\n    model = LSTMNet(embed_size, \n                       nimgclasses = len(cfg.image_target_cols), \n                       nstudyclasses = len(cfg.exam_target_cols),\n                       LSTM_UNITS=cfg.lstm_units, \n                       DO = cfg.dropout)\n    checkpoint = torch.load(wtsnm, map_location=torch.device(device))\n    model.load_state_dict(checkpoint)\n    model = model.half().to(device)\n    model = model.eval()\n    return model\n\ndef load_exam_modelx(wtsnm, cfg, device = args.device):\n    model = TransformerNet(cfg)\n    checkpoint = torch.load(wtsnm, map_location=torch.device(device))\n    model.load_state_dict(checkpoint)\n    model = model.half().to(device)\n    model = model.eval()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load image model\nimgmodels = {}\nfor fold in args.folds:\n    wtsnm = f'../input/rsnastr2020weights/classifier__RSNAClassifier_tf_efficientnet_b5_ns_04d_fold{fold}_img512_accum1___best'\n    logger.info(f'Load image model : {wtsnm}')\n    imgmodels[fold] = load_image_model(wtsnm, conf = cfgimg, device = args.device)\n\n# Load image model\nexammodels = defaultdict(list)\nembed_size = 2048\nfor fold in args.folds:\n    wtsnm = f'../input/rsnastr2020weights/exam_lstm_classifier__RSNAClassifier_tf_efficientnet_b5_ns_04d_fold{fold}_img512_accum1___best__all_size512_hidden512_best.bin'\n    logger.info(f'Load lstm  exam model : {wtsnm}')\n    exammodels[fold].append( load_exam_model(wtsnm, cfgseq1, embed_size = embed_size, device = args.device) )\n    \n# Load exam model\nexammodelsx = defaultdict(list)\nfor fold in args.folds:\n    for cfg in [cfgseq2, cfgseq3]:\n        wtsnm = '../input/rsnastr2020weights/exam_transformer_classifier__RSNAClassifier_tf_efficientnet_b5_ns_04d_'\n        wtsnm += f'fold{fold}_img512_accum1___best__all_size512_nlayers{cfg.nlayers}_intermediate{cfg.intermediate_size}_hidden{cfg.hidden_size}_best.bin'\n        logger.info(f'Load xfrmr exam model : {wtsnm}')\n        exammodelsx[fold].append( load_exam_modelx(wtsnm, cfg, device = args.device) )      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subdf =  pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/sample_submission.csv')\nsubdf = subdf.set_index('id')\nmean_ =  torch.tensor(cfgimg.normalize['mean'])[None, None, None, :].to(args.device)\nstd_  =  torch.tensor(cfgimg.normalize['std'])[None, None, None, :].to(args.device)\nsubdf.label = 0.49999 # A lot of special consistency conditions for exactly 0.5 prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pbar = tqdm(enumerate(tstloader), total = 1 + len(tstdataset)//tstloader.batch_size, ncols=0)\nfor step, batch in pbar:\n    try:\n        # Add in a loop here for dataloader\n        emb = defaultdict(list)\n        studypredsls = []\n        imgpredsls = []\n        embbatch = {}\n        imgs = torch.tensor(batch[\"image\"])\n        imgnames = batch['img_name']\n        mask = batch['mask'].half().to(args.device)\n        # Split the batch into chunks and infer all the images\n        for imgchunk in torch.split(imgs, args.imgbatchsize, dim=0):\n            imgchunk = aug_batch(imgchunk, mean_, std_, args.device)\n            imgchunk = imgchunk.to(args.device)\n            with torch.no_grad():\n                for fold in args.folds:\n                    emb[fold].append(imgmodels[fold](imgchunk))\n        del imgchunk, imgs, batch\n        # Line up the embedding in single 2d array\n        for fold in args.folds:\n            emb[fold] = torch.cat(emb[fold], 0)\n            # Use the mask to populate in (batch, maxlen of images, emb dim)\n            embbatch[fold] = torch.zeros(len(mask.flatten()), emb[fold].shape[-1]).half().to(args.device)\n            embbatch[fold][mask.flatten()==1] = emb[fold]\n            embbatch[fold] = embbatch[fold].reshape((*mask.shape, emb[fold].shape[-1]))\n            del emb[fold]\n            for mod in exammodels[fold]:\n                with torch.no_grad():\n                    studylogits, imglogits = mod(embbatch[fold], mask)\n                # Unmask the images\n                imglogits = imglogits.flatten()[(mask==1).flatten()]\n                # Detach and create out sub\n                studypredsls.append( torch.sigmoid(studylogits).detach().cpu().numpy())\n                imgpredsls.append( torch.sigmoid(imglogits).detach().cpu().numpy())\n            try:\n                for mod in exammodelsx[fold]:\n                    with torch.no_grad():\n                        encoded_layers = mod.encoder(embbatch[fold], *mod.extended_mask(mask ))\n                        imglogits = mod.img_linear_out(encoded_layers[-1]).squeeze()\n                        studylogits = mod.study_linear_out(encoded_layers[-1][:, -1]).squeeze()\n                    # Unmask the images\n                    imglogits = imglogits.flatten()[(mask==1).flatten()]\n                    # Detach and create out sub\n                    studypredsls.append( torch.sigmoid(studylogits).detach().cpu().numpy())\n                    imgpredsls.append( torch.sigmoid(imglogits).detach().cpu().numpy())\n            except:\n                logger.info(f'Transformer failed ...{e}')\n                torch.cuda.empty_cache()\n            \n        # Bag the batch\n        studypreds = sum(studypredsls)/len(studypredsls)\n        imgpreds = sum(imgpredsls)/len(imgpredsls)\n        subbatch = batchPredsfn(studypreds, imgpreds, imgnames)\n        subbatch = pd.DataFrame(subbatch, columns = ['id', 'label'])\n        subdf.loc[subbatch.id, 'label'] = subbatch.label.values\n        del mask, embbatch, imglogits, studylogits\n    except Exception as e:\n        logger.info(f'Failed ...{e}')\n    if step % 1 == 0:\n        torch.cuda.empty_cache()\n    if step % 5 == 0:\n        gc.collect()\nsubdf = subdf.reset_index()\nsuborig = subdf.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tstdf = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/test.csv')\nsubdf = clean_sub(subdf, tstdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = check_consistency(subdf, tstdf)\nif errors.shape[0] == 0:\n    subdf.to_csv('submission.csv', index = False)\nelse:\n    print(errors.broken_rule.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(subdf.shape)\nsubdf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"((subdf.label - suborig.label)!=0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(subdf.label - suborig.label)[(subdf.label - suborig.label)!=0].hist(bins = 100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}