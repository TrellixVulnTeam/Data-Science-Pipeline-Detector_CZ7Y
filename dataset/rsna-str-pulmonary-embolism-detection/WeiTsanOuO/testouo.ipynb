{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport time\nfrom IPython.display import clear_output\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint as MC\nfrom tensorflow.keras import backend as K\n\n\nroot = '/kaggle/input/rsna-str-pulmonary-embolism-detection'\nfor item in os.listdir(root):\n    path = os.path.join(root, item)\n    if os.path.isfile(path):\n        print(path)\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-11-04T03:09:58.767636Z","iopub.status.busy":"2020-11-04T03:09:58.766927Z","iopub.status.idle":"2020-11-04T03:10:03.707567Z","shell.execute_reply":"2020-11-04T03:10:03.708092Z"},"papermill":{"duration":4.96478,"end_time":"2020-11-04T03:10:03.708255","exception":false,"start_time":"2020-11-04T03:09:58.743475","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('Reading train data...')\ntrain = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/train.csv\")\nprint(train.shape)\ntrain.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-11-04T03:10:03.745598Z","iopub.status.busy":"2020-11-04T03:10:03.744986Z","iopub.status.idle":"2020-11-04T03:10:07.448312Z","shell.execute_reply":"2020-11-04T03:10:07.447687Z"},"papermill":{"duration":3.724122,"end_time":"2020-11-04T03:10:07.44846","exception":false,"start_time":"2020-11-04T03:10:03.724338","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### print('Reading test data...')\ntest = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/test.csv\")\nprint(test.shape)\ntest.head()","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:07.490535Z","iopub.status.busy":"2020-11-04T03:10:07.489802Z","iopub.status.idle":"2020-11-04T03:10:07.653322Z","shell.execute_reply":"2020-11-04T03:10:07.65392Z"},"papermill":{"duration":0.188265,"end_time":"2020-11-04T03:10:07.654224","exception":false,"start_time":"2020-11-04T03:10:07.465959","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Reading sample data...')\nss = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/sample_submission.csv\")\nprint(ss.shape)\nss.head()","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:07.697875Z","iopub.status.busy":"2020-11-04T03:10:07.697176Z","iopub.status.idle":"2020-11-04T03:10:07.802687Z","shell.execute_reply":"2020-11-04T03:10:07.803161Z"},"papermill":{"duration":0.130159,"end_time":"2020-11-04T03:10:07.803298","exception":false,"start_time":"2020-11-04T03:10:07.673139","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = ss.id\ncounter = [1 for _ in range(10)]\nmapper = []\nfor i in ids:\n    n = '_'.join(i.split('_')[1:])\n    if n not in mapper:\n        mapper.append(n)\n    else:\n        counter[mapper.index(n)] += 1\nprint(\"List of keys:\")\nprint(mapper, sep='\\n')\nprint()\nprint(\"Count of items per key:\")\nprint(counter)","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:07.870958Z","iopub.status.busy":"2020-11-04T03:10:07.855508Z","iopub.status.idle":"2020-11-04T03:10:08.045745Z","shell.execute_reply":"2020-11-04T03:10:08.045099Z"},"papermill":{"duration":0.221492,"end_time":"2020-11-04T03:10:08.045914","exception":false,"start_time":"2020-11-04T03:10:07.824422","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import vtk\nfrom vtk.util import numpy_support\nimport cv2\n\nreader = vtk.vtkDICOMImageReader()\ndef get_img(path):\n    reader.SetFileName(path)\n    reader.Update()\n    _extent = reader.GetDataExtent()\n    ConstPixelDims = [_extent[1]-_extent[0]+1, _extent[3]-_extent[2]+1, _extent[5]-_extent[4]+1]\n\n    ConstPixelSpacing = reader.GetPixelSpacing()\n    imageData = reader.GetOutput()\n    pointData = imageData.GetPointData()\n    arrayData = pointData.GetArray(0)\n    ArrayDicom = numpy_support.vtk_to_numpy(arrayData)\n    ArrayDicom = ArrayDicom.reshape(ConstPixelDims, order='F')\n    ArrayDicom = cv2.resize(ArrayDicom,(512,512))\n    return ArrayDicom","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:08.096151Z","iopub.status.busy":"2020-11-04T03:10:08.095414Z","iopub.status.idle":"2020-11-04T03:10:09.547808Z","shell.execute_reply":"2020-11-04T03:10:09.548733Z"},"papermill":{"duration":1.482316,"end_time":"2020-11-04T03:10:09.548906","exception":false,"start_time":"2020-11-04T03:10:08.06659","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpath = \"../input/rsna-str-pulmonary-embolism-detection/train/0003b3d648eb/d2b2960c2bbf/00ac73cfc372.dcm\"\nds = get_img(fpath)\n\nimport matplotlib.pyplot as plt\n\n#Convert dcom file to 8bit color\nfunc = lambda x: int((2**15 + x)*(255/2**16))\nint16_to_uint8 = np.vectorize(func)\n\ndef show_dicom_images(dcom):\n    f, ax = plt.subplots(1,2, figsize=(16,20))\n    data_row_img = int16_to_uint8(ds)\n    ax[0].imshow(data_row_img, cmap=plt.cm.bone)\n    ax[1].imshow(ds, cmap=plt.cm.bone)\n    #print(data_row_img)\n    ax[0].axis('off')\n    ax[0].set_title('8-bit DICOM Image')\n    ax[1].axis('off')\n    ax[1].set_title('16-bit DICOM Image')\n    plt.show()\n    \nshow_dicom_images(ds)","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:09.623505Z","iopub.status.busy":"2020-11-04T03:10:09.622778Z","iopub.status.idle":"2020-11-04T03:10:10.081184Z","shell.execute_reply":"2020-11-04T03:10:10.081676Z"},"papermill":{"duration":0.512093,"end_time":"2020-11-04T03:10:10.081809","exception":false,"start_time":"2020-11-04T03:10:09.569716","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"papermill":{"duration":0.027048,"end_time":"2020-11-04T03:10:10.136859","exception":false,"start_time":"2020-11-04T03:10:10.109811","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow import keras\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D\n\n# inputs = Input((128, 128, 3))\n# #x = Conv2D(3, (1, 1), activation='relu')(inputs)\n# base_model = keras.applications.DenseNet121(\n#     include_top=False,\n#     weights=\"imagenet\"\n# )\n\n# base_model.trainable = False\n\n# outputs = base_model(inputs, training=False)\n# outputs = keras.layers.GlobalAveragePooling2D()(outputs)\n# outputs = Dropout(0.25)(outputs)\n# outputs = Dense(1024, activation='relu')(outputs)\n# outputs = Dense(256, activation='relu')(outputs)\n# outputs = Dense(64, activation='relu')(outputs)\n# ppoi = Dense(1, activation='sigmoid', name='pe_present_on_image')(outputs)\n# rlrg1 = Dense(1, activation='sigmoid', name='rv_lv_ratio_gte_1')(outputs)\n# rlrl1 = Dense(1, activation='sigmoid', name='rv_lv_ratio_lt_1')(outputs) \n# lspe = Dense(1, activation='sigmoid', name='leftsided_pe')(outputs)\n# cpe = Dense(1, activation='sigmoid', name='chronic_pe')(outputs)\n# rspe = Dense(1, activation='sigmoid', name='rightsided_pe')(outputs)\n# aacpe = Dense(1, activation='sigmoid', name='acute_and_chronic_pe')(outputs)\n# cnpe = Dense(1, activation='sigmoid', name='central_pe')(outputs)\n# indt = Dense(1, activation='sigmoid', name='indeterminate')(outputs)\n\n# model = Model(inputs=inputs, outputs={'pe_present_on_image':ppoi,\n#                                       'rv_lv_ratio_gte_1':rlrg1,\n#                                       'rv_lv_ratio_lt_1':rlrl1,\n#                                       'leftsided_pe':lspe,\n#                                       'chronic_pe':cpe,\n#                                       'rightsided_pe':rspe,\n#                                       'acute_and_chronic_pe':aacpe,\n#                                       'central_pe':cnpe,\n#                                       'indeterminate':indt})\n\n# opt = keras.optimizers.Adam(lr=0.001)\n\n# model.compile(optimizer=opt,\n#               loss='binary_crossentropy',\n#               metrics=['accuracy'])\n\n# model.summary()\n# model.save('pe_detection_model.h5')\n# del model\n# K.clear_session()\n# gc.collect()","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:10.197808Z","iopub.status.busy":"2020-11-04T03:10:10.195937Z","iopub.status.idle":"2020-11-04T03:10:10.198644Z","shell.execute_reply":"2020-11-04T03:10:10.199108Z"},"papermill":{"duration":0.035332,"end_time":"2020-11-04T03:10:10.199217","exception":false,"start_time":"2020-11-04T03:10:10.163885","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nBaseline model -> UNet\n\"\"\"\n\nimport os\n\nimport tensorflow.keras as keras\n\nfrom tensorflow.keras.layers import (\n    Input,\n    Conv2D,\n    Conv2DTranspose,\n    BatchNormalization,\n    Activation,\n    MaxPooling2D,\n    Dropout,\n    concatenate,\n    Dense,\n    Flatten\n)\n\n# from keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.utils import plot_model\n\nimport tensorflow as tf\n\n    \n# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nlog_level = True\nprint(\"Logging: \", log_level)\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\n\nclass UNet:\n    \"\"\"\n    UNet Class Model\n    \"\"\"\n\n    def __init__(\n        self,\n        input_height: int = 128,\n        input_width: int = 128,\n        input_features: int = 3,\n        num_inputs: int = 1,\n        filter_size: int = 12,\n        depth: int = 6,\n        output_features: int = 1,\n        num_outputs: int = 9,\n        logging=log_level,\n    ):\n\n        self.input_height = input_height\n        self.input_width = input_width\n        self.num_inputs = num_inputs\n        self.input_features = input_features\n\n        self.input_size = (input_height, input_width, num_inputs * input_features)\n        self.filter_size = filter_size\n        self.kernel_size = 3\n        self.depth = depth\n\n        self.logging = logging\n\n        self.num_outputs = num_outputs\n        self.output_features = output_features\n\n        self.output_size = num_outputs * output_features\n\n    def input_layer(self):\n        x = Input(self.input_size)\n        return x\n\n    def single_conv_2d(self, input_layer, n_filters):\n        x = Conv2D(\n            filters=n_filters, padding=\"same\", kernel_size=(self.kernel_size, self.kernel_size), activation=\"sigmoid\",\n        )(input_layer)\n        return x\n\n    def double_conv_2d(self, input_layer, n_filters):\n        x = Conv2D(\n            filters=n_filters,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            padding=\"same\",\n            kernel_initializer=\"he_normal\",\n        )(input_layer)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        x = Conv2D(\n            filters=n_filters,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            padding=\"same\",\n            kernel_initializer=\"he_normal\",\n        )(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        return x\n\n    def deconv_2d(self, input_layer, n_filters, stride=2):\n        x = Conv2DTranspose(\n            filters=n_filters,\n            kernel_size=(self.kernel_size, self.kernel_size),\n            strides=(stride, stride),\n            padding=\"same\",\n        )(input_layer)\n        return x\n\n    def pool_and_drop(self, input_layer, dropout_rate=0.1, pool=2):\n        x = MaxPooling2D(pool_size=(pool, pool))(input_layer)\n        x = Dropout(rate=dropout_rate)(x)\n        return x\n\n    def generate_input_layers(self):\n        inputs = []\n        for _ in range(self.num_inputs):\n            inputs.append(Input((self.input_height, self.input_width, self.input_features)))\n        x = concatenate(inputs)\n        return inputs, x\n\n    def build_model(self):\n\n        # Initialize the Input\n        input_layer = Input(self.input_size)\n\n        conv2d_layers = []\n        pool_layers = []\n        for i in range(self.depth):\n            if len(conv2d_layers) == 0:\n                x = self.double_conv_2d(input_layer, self.filter_size)\n                conv2d_layers.append(x)\n            else:\n                x = self.double_conv_2d(pool_layers[-1], self.filter_size * (2 ** i))\n                conv2d_layers.append(x)\n\n            x = self.pool_and_drop(conv2d_layers[-1])\n            pool_layers.append(x)\n\n        mid = self.double_conv_2d(pool_layers[-1], self.filter_size * (2 ** self.depth))\n\n        deconv_layers = []\n        for i in range(self.depth - 1, -1, -1):\n            if len(deconv_layers) == 0:\n                x = self.deconv_2d(mid, self.filter_size * (2 ** i))\n                deconv_layers.append(x)\n                x = concatenate([conv2d_layers[i], deconv_layers[-1]])\n                x = self.double_conv_2d(x, self.filter_size * (2 ** i))\n                conv2d_layers.append(x)\n\n            else:\n                x = self.deconv_2d(conv2d_layers[-1], self.filter_size * (2 ** i))\n                deconv_layers.append(x)\n                x = concatenate([conv2d_layers[i], deconv_layers[-1]])\n                x = self.double_conv_2d(x, self.filter_size * (2 ** i))\n\n                conv2d_layers.append(x)\n\n        outputs = self.single_conv_2d(conv2d_layers[-1], self.num_outputs * self.output_features)\n        outputs = Dense(1024)(outputs)\n        outputs = Dense(256)(outputs)\n        outputs = Dense(32)(outputs)\n#         outputs = Dense(64)(outputs)\n        outputs = keras.layers.GlobalAveragePooling2D()(outputs)\n        outputs = Flatten()(outputs)\n\n        ppoi = Dense(1, activation='sigmoid', name='pe_present_on_image')(outputs)\n        rlrg1 = Dense(1, activation='sigmoid', name='rv_lv_ratio_gte_1')(outputs)\n        rlrl1 = Dense(1, activation='sigmoid', name='rv_lv_ratio_lt_1')(outputs) \n        lspe = Dense(1, activation='sigmoid', name='leftsided_pe')(outputs)\n        cpe = Dense(1, activation='sigmoid', name='chronic_pe')(outputs)\n        rspe = Dense(1, activation='sigmoid', name='rightsided_pe')(outputs)\n        aacpe = Dense(1, activation='sigmoid', name='acute_and_chronic_pe')(outputs)\n        cnpe = Dense(1, activation='sigmoid', name='central_pe')(outputs)\n        indt = Dense(1, activation='sigmoid', name='indeterminate')(outputs)\n\n        model = Model(input_layer, outputs={'pe_present_on_image':ppoi,\n                                      'rv_lv_ratio_gte_1':rlrg1,\n                                      'rv_lv_ratio_lt_1':rlrl1,\n                                      'leftsided_pe':lspe,\n                                      'chronic_pe':cpe,\n                                      'rightsided_pe':rspe,\n                                      'acute_and_chronic_pe':aacpe,\n                                      'central_pe':cnpe,\n                                      'indeterminate':indt})\n\n        plot_model(model, to_file='model.png')\n\n        if self.logging:\n            print(model.summary())\n        return model\n\nmodel = UNet().build_model()\n\nopt = keras.optimizers.Adam(lr=0.0001)\n\nmodel.compile(optimizer=opt,\n              loss='binary_crossentropy',\n              metrics=['accuracy','mse'])\n\n# model.summary()\nmodel.save('multi_unet_1.h5')\ndel model\nK.clear_session()\ngc.collect()","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:10.300737Z","iopub.status.busy":"2020-11-04T03:10:10.269167Z","iopub.status.idle":"2020-11-04T03:10:16.906914Z","shell.execute_reply":"2020-11-04T03:10:16.906404Z"},"papermill":{"duration":6.682384,"end_time":"2020-11-04T03:10:16.907025","exception":false,"start_time":"2020-11-04T03:10:10.224641","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import wandb\n\n# # Initialize a new run\n# wandb.init(anonymous='allow', project=\"rsna-pe-detection\", name=\"UNet  Deep\",tags=['lr=0.0001','Global Average Pool'])","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:16.966757Z","iopub.status.busy":"2020-11-04T03:10:16.966016Z","iopub.status.idle":"2020-11-04T03:10:16.969982Z","shell.execute_reply":"2020-11-04T03:10:16.970561Z"},"papermill":{"duration":0.036022,"end_time":"2020-11-04T03:10:16.970695","exception":false,"start_time":"2020-11-04T03:10:16.934673","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_rgb(array):\n    bin_size = 512 // 128\n    array = array.reshape((128, bin_size, \n                                   128, bin_size, 1)).max(3).max(1)\n    array = array.reshape((128, 128, 1))\n    return np.stack([array, array, array], axis=2).reshape((128, 128, 3))\n    \ndef custom_dcom_image_generator(batch_size, dataset, test=False, debug=False):\n    \n    fnames = dataset[['StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID']]\n    \n    if not test:\n        Y = dataset[['pe_present_on_image', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1', 'leftsided_pe',\n                     'chronic_pe', 'rightsided_pe', 'acute_and_chronic_pe', 'central_pe', 'indeterminate'\n                    ]]\n        prefix = 'input/rsna-str-pulmonary-embolism-detection/train'\n        \n    else:\n        prefix = 'input/rsna-str-pulmonary-embolism-detection/test'\n    \n    X = []\n    batch = 0\n    for st, sr, so in fnames.values:\n        if debug:\n            print(f\"Current file: ../{prefix}/{st}/{sr}/{so}.dcm\")\n\n        dicom = get_img(f\"../{prefix}/{st}/{sr}/{so}.dcm\")\n        image = convert_to_rgb(dicom)\n        X.append(image)\n        \n        del st, sr, so\n        \n        if len(X) == batch_size:\n            if test:\n                yield np.array(X)\n                del X\n            else:\n                yield np.array(X), Y[batch*batch_size:(batch+1)*batch_size].values\n                del X\n                \n            gc.collect()\n            X = []\n            batch += 1\n        \n    if test:\n        yield np.array(X)\n    else:\n        yield np.array(X), Y[batch*batch_size:(batch+1)*batch_size].values\n        del Y\n    del X\n    gc.collect()\n    return","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:17.046572Z","iopub.status.busy":"2020-11-04T03:10:17.044365Z","iopub.status.idle":"2020-11-04T03:10:17.047499Z","shell.execute_reply":"2020-11-04T03:10:17.048075Z"},"papermill":{"duration":0.050276,"end_time":"2020-11-04T03:10:17.048211","exception":false,"start_time":"2020-11-04T03:10:16.997935","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget https://github.com/aniketbiprojit/cdn/raw/master/dense121_3.h5 './pe_detection_model.h5'","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:17.110368Z","iopub.status.busy":"2020-11-04T03:10:17.109718Z","iopub.status.idle":"2020-11-04T03:10:17.112723Z","shell.execute_reply":"2020-11-04T03:10:17.113168Z"},"papermill":{"duration":0.034118,"end_time":"2020-11-04T03:10:17.113285","exception":false,"start_time":"2020-11-04T03:10:17.079167","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = {}\nstart = time.time()\ndebug = 0\nbatch_size = 1000 \ntrain_size = int(batch_size*0.8)\n\nmax_train_time = 3600 * 4 #hours to seconds of training\n# from wandb.keras import WandbCallback\n\ncheckpoint = [MC(filepath='../working/multi_unet_1.h5', monitor='val_loss', save_best_only=True, verbose=1)]\n#Train loop\n\nfor n, (x, y) in enumerate(custom_dcom_image_generator(batch_size, train.sample(frac=1), False, debug)):\n\n    if len(x) < 10: #Tries to filter out empty or short data\n        break\n\n#     clear_output(wait=True)\n    print(\"Training batch: %i - %i\" %(batch_size*n, batch_size*(n+1)))\n\n    model = load_model('./multi_unet_1.h5')\n    hist = model.fit(\n        x[:train_size], #Y values are in a dict as there's more than one target for training output\n        {'pe_present_on_image':y[:train_size, 0],\n         'rv_lv_ratio_gte_1':y[:train_size, 1],\n         'rv_lv_ratio_lt_1':y[:train_size, 2],\n         'leftsided_pe':y[:train_size, 3],\n         'chronic_pe':y[:train_size, 4],\n         'rightsided_pe':y[:train_size, 5],\n         'acute_and_chronic_pe':y[:train_size, 6],\n         'central_pe':y[:train_size, 7],\n         'indeterminate':y[:train_size, 8]},\n\n        callbacks = checkpoint,\n\n        validation_split=0.2,\n        epochs=3,\n        batch_size=8,\n        verbose=debug\n    )\n\n    print(\"Metrics for batch validation:\")\n    model.evaluate(x[train_size:],\n                   {'pe_present_on_image':y[train_size:, 0],\n                    'rv_lv_ratio_gte_1':y[train_size:, 1],\n                    'rv_lv_ratio_lt_1':y[train_size:, 2],\n                    'leftsided_pe':y[train_size:, 3],\n                    'chronic_pe':y[train_size:, 4],\n                    'rightsided_pe':y[train_size:, 5],\n                    'acute_and_chronic_pe':y[train_size:, 6],\n                    'central_pe':y[train_size:, 7],\n                    'indeterminate':y[train_size:, 8]\n                   }\n                  )\n\n    try:\n        for key in hist.history.keys():\n            history[key] = np.concatenate([history[key], hist.history[key]], axis=0)\n    except:\n        for key in hist.history.keys():\n            history[key] = hist.history[key]\n\n    #To make sure that our model don't train overtime\n    if time.time() - start >= max_train_time:\n        print(\"Time's up!\")\n        break\n\n    model.save('multi_unet_1.h5')\n    del model, x, y, hist\n    K.clear_session()\n    gc.collect()","metadata":{"execution":{"iopub.execute_input":"2020-11-04T03:10:17.189451Z","iopub.status.busy":"2020-11-04T03:10:17.188544Z","iopub.status.idle":"2020-11-04T07:10:42.814493Z","shell.execute_reply":"2020-11-04T07:10:42.813978Z"},"papermill":{"duration":14425.674271,"end_time":"2020-11-04T07:10:42.814626","exception":false,"start_time":"2020-11-04T03:10:17.140355","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('ok')","metadata":{"execution":{"iopub.execute_input":"2020-11-04T07:10:45.577782Z","iopub.status.busy":"2020-11-04T07:10:45.57635Z","iopub.status.idle":"2020-11-04T07:10:45.580212Z","shell.execute_reply":"2020-11-04T07:10:45.578373Z"},"papermill":{"duration":1.403699,"end_time":"2020-11-04T07:10:45.580332","exception":false,"start_time":"2020-11-04T07:10:44.176633","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in history.keys():\n    if key.startswith('val'):\n        continue\n    else:\n        epoch = range(len(history[key]))\n        plt.plot(epoch, history[key]) #X=epoch, Y=value\n        plt.plot(epoch, history['val_'+key])\n        plt.title(key)\n        if 'accuracy' in key:\n            plt.axis([0, len(history[key]), -0.1, 1.1]) #Xmin, Xmax, Ymin, Ymax\n        plt.legend(['train', 'validation'], loc='upper right')\n        plt.show()","metadata":{"execution":{"iopub.execute_input":"2020-11-04T07:10:48.725365Z","iopub.status.busy":"2020-11-04T07:10:48.724364Z","iopub.status.idle":"2020-11-04T07:10:53.54489Z","shell.execute_reply":"2020-11-04T07:10:53.544269Z"},"papermill":{"duration":6.289187,"end_time":"2020-11-04T07:10:53.544995","exception":false,"start_time":"2020-11-04T07:10:47.255808","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = {}\nstopper = 3600 * 4 #4 hours limit for prediction\npred_start_time = time.time()\n\np, c = time.time(), time.time()\nbatch_size = 500\n    \nl = 0\nn = test.shape[0]\n\nfor x in custom_dcom_image_generator(batch_size, test, True, False):\n    clear_output(wait=True)\n    model = load_model(\"../working/multi_unet_1.h5\")\n    preds = model.predict(x, batch_size=8, verbose=1)\n    \n    try:\n        for key in preds.keys():\n            predictions[key] += preds[key].flatten().tolist()\n            \n    except Exception as e:\n        print(e)\n        for key in preds.keys():\n            predictions[key] = preds[key].flatten().tolist()\n            \n    l = (l+batch_size)%n\n    print('Total predicted:', len(predictions['indeterminate']),'/', n)\n    p, c = c, time.time()\n    print(\"One batch time: %.2f seconds\" %(c-p))\n    print(\"ETA: %.2f\" %((n-l)*(c-p)/batch_size))\n    \n    if c - pred_start_time >= stopper:\n        print(\"Time's up!\")\n        break\n    \n    del model\n    K.clear_session()\n    \n    del x, preds\n    gc.collect()","metadata":{"execution":{"iopub.execute_input":"2020-11-04T07:10:56.769968Z","iopub.status.busy":"2020-11-04T07:10:56.768977Z","iopub.status.idle":"2020-11-04T08:00:15.310841Z","shell.execute_reply":"2020-11-04T08:00:15.306466Z"},"papermill":{"duration":2960.050758,"end_time":"2020-11-04T08:00:15.310965","exception":false,"start_time":"2020-11-04T07:10:55.260207","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in predictions.keys():\n    print(key, np.array(predictions[key]).shape)\n","metadata":{"execution":{"iopub.execute_input":"2020-11-04T08:00:18.518766Z","iopub.status.busy":"2020-11-04T08:00:18.486007Z","iopub.status.idle":"2020-11-04T08:00:18.565557Z","shell.execute_reply":"2020-11-04T08:00:18.564909Z"},"papermill":{"duration":1.694547,"end_time":"2020-11-04T08:00:18.566599","exception":false,"start_time":"2020-11-04T08:00:16.872052","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = []\nfor v in test.StudyInstanceUID:\n    if v not in test_ids:\n        test_ids.append(v)\n        \ntest_preds = test.copy()\ntest_preds = pd.concat([test_preds, pd.DataFrame(predictions)], axis=1)\ntest_preds.to_csv('test_predictions.csv', index=False)\ntest_preds","metadata":{"execution":{"iopub.execute_input":"2020-11-04T08:00:21.472991Z","iopub.status.busy":"2020-11-04T08:00:21.462813Z","iopub.status.idle":"2020-11-04T08:00:27.131792Z","shell.execute_reply":"2020-11-04T08:00:27.130797Z"},"papermill":{"duration":7.098243,"end_time":"2020-11-04T08:00:27.131905","exception":false,"start_time":"2020-11-04T08:00:20.033662","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.special import softmax\n\nlabel_agg = {key:[] for key in \n             ['id', 'negative_exam_for_pe', 'rv_lv_ratio_gte_1',\n              'rv_lv_ratio_lt_1', 'leftsided_pe', 'chronic_pe',\n              'rightsided_pe', 'acute_and_chronic_pe',\n              'central_pe', 'indeterminate']\n            }\n\nfor uid in test_ids:\n    temp = test_preds.loc[test_preds.StudyInstanceUID ==uid]\n    label_agg['id'].append(uid)\n    \n    n = temp.shape[0]\n    #Check for any image level presence of PE of high confidence\n    positive = any(temp.pe_present_on_image >= 0.5) #50% threshhold\n    \n    #Only one from positive, negative and indeterminate should have value>0.5\n    #per exam\n    if positive: \n        label_agg['indeterminate'].append(temp.indeterminate.min()/2)\n        label_agg['negative_exam_for_pe'].append(0)\n    else:\n        if any(temp.indeterminate >= 0.5):\n            label_agg['indeterminate'].append(temp.indeterminate.max())\n            label_agg['negative_exam_for_pe'].append(1)\n        else:\n            label_agg['indeterminate'].append(temp.indeterminate.min()/2)\n            label_agg['negative_exam_for_pe'].append(1)\n    \n    #I decided that the total ratio should be equal to 1, so I used softmax\n    #We modify the weights by multiplying the bigger by 2 and dividing the smaller by 2\n    a, b = temp[['rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1']].mean().values\n    if a > b:\n        a, b = a*2, b/2\n    elif a < b:\n        a, b = a/2, b*2\n    a, b = softmax([a, b])\n    if positive:\n        label_agg['rv_lv_ratio_gte_1'].append(a)\n        label_agg['rv_lv_ratio_lt_1'].append(b)\n    else:\n        label_agg['rv_lv_ratio_gte_1'].append(a/2)\n        label_agg['rv_lv_ratio_lt_1'].append(b/2)\n    \n    #Next is for Chronic (C), Acute-Chronic (AC) and Acute (A) PE\n    #We need to see if we got a high confidence value from either C or AC\n    #If there is, we add it to a 50% based score for high confidence\n    #and half weight for low confidence score\n    if any(temp['acute_and_chronic_pe'] > 0.5): #50% confidence level\n        label_agg['acute_and_chronic_pe'].append(0.5 + temp['acute_and_chronic_pe'].mean()/2)\n        label_agg['chronic_pe'].append(temp['chronic_pe'].mean()/2)\n        \n    elif any(temp['chronic_pe'] > 0.5):\n        label_agg['acute_and_chronic_pe'].append(temp['acute_and_chronic_pe'].mean()/2)\n        label_agg['chronic_pe'].append(0.5 + temp['chronic_pe'].mean()/2)\n        \n    else: #Else, we set both to half values, as we declare the A as the value\n        label_agg['acute_and_chronic_pe'].append(temp['acute_and_chronic_pe'].mean()/2)\n        label_agg['chronic_pe'].append(temp['chronic_pe'].mean()/2)\n    \n    #for right, left, central, we use the same metric above\n    for key in ['leftsided_pe', 'rightsided_pe', 'central_pe']:\n        if positive:\n            label_agg[key].append(0.5 + temp[key].mean()/2)\n        else:\n            label_agg[key].append(temp[key].mean()/2)\n","metadata":{"execution":{"iopub.execute_input":"2020-11-04T08:00:30.314071Z","iopub.status.busy":"2020-11-04T08:00:30.313161Z","iopub.status.idle":"2020-11-04T08:00:47.023743Z","shell.execute_reply":"2020-11-04T08:00:47.023117Z"},"papermill":{"duration":18.221711,"end_time":"2020-11-04T08:00:47.023871","exception":false,"start_time":"2020-11-04T08:00:28.80216","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"uid = []\nlabels = []\ndf = pd.DataFrame(label_agg)\nfor key in ['negative_exam_for_pe', 'rv_lv_ratio_gte_1', 'rv_lv_ratio_lt_1', 'leftsided_pe', 'chronic_pe',\n            'rightsided_pe', 'acute_and_chronic_pe', 'central_pe', 'indeterminate']:\n    for i in df.id:\n        uid.append('_'.join([i, key]))\n        labels.append(df.loc[df.id==i][key].values[0])\ndel df\ngc.collect()\n\nuid += test_preds.SOPInstanceUID.tolist()\nlabels += test_preds['pe_present_on_image'].tolist()\n\nsub = pd.DataFrame({\"id\":uid, 'label':labels})\nsub\n","metadata":{"execution":{"iopub.execute_input":"2020-11-04T08:00:50.1101Z","iopub.status.busy":"2020-11-04T08:00:50.10903Z","iopub.status.idle":"2020-11-04T08:00:54.0042Z","shell.execute_reply":"2020-11-04T08:00:54.005661Z"},"papermill":{"duration":5.570249,"end_time":"2020-11-04T08:00:54.005874","exception":false,"start_time":"2020-11-04T08:00:48.435625","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.fillna(0.2, inplace=True)\nsub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.execute_input":"2020-11-04T08:00:57.298923Z","iopub.status.busy":"2020-11-04T08:00:57.298071Z","iopub.status.idle":"2020-11-04T08:00:57.943348Z","shell.execute_reply":"2020-11-04T08:00:57.942243Z"},"papermill":{"duration":2.098682,"end_time":"2020-11-04T08:00:57.943509","exception":false,"start_time":"2020-11-04T08:00:55.844827","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}