{"cells":[{"metadata":{},"cell_type":"markdown","source":"# RSNA: Pytorch Baseline-inference\n\n[Here](https://www.kaggle.com/maunish/rsna-super-cool-eda-and-pytorch-baseline-train) is notebook for training code.\n"},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries ðŸ“˜"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import random\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import models\nfrom torch.utils.data import Dataset,DataLoader\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom collections import Counter\n\nfrom sklearn.model_selection import KFold\n\nimport vtk\nfrom vtk.util import numpy_support\nfrom tqdm.auto import tqdm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = \"../input/rsna-str-pulmonary-embolism-detection\"\ntrain_path = folder_path + \"/train/\"\ntest_path = folder_path + \"/test/\"\n    \n# train_data = pd.read_csv(folder_path + \"/train.csv\")\ntest_data  = pd.read_csv(folder_path + \"/test.csv\")\nsample = pd.read_csv(folder_path + \"/sample_submission.csv\")\n\ncols_ID = [\"StudyInstanceUID\",\"SeriesInstanceUID\",\"SOPInstanceUID\"]\ntest_data[\"ImagePath\"] = test_path+ test_data[cols_ID[0]]+\"/\"+test_data[cols_ID[1]]+\"/\"+test_data[cols_ID[2]]+\".dcm\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"SEED  = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASSEED']  = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = ['pe_present_on_image', 'negative_exam_for_pe', 'rv_lv_ratio_gte_1', \n                  'rv_lv_ratio_lt_1','leftsided_pe', 'chronic_pe','rightsided_pe', \n                  'acute_and_chronic_pe', 'central_pe', 'indeterminate']\n\nstudy_level_columns = [ 'negative_exam_for_pe', 'rv_lv_ratio_gte_1', \n                  'rv_lv_ratio_lt_1','leftsided_pe', 'chronic_pe','rightsided_pe', \n                  'acute_and_chronic_pe', 'central_pe', 'indeterminate']\n\nclasses = len(target_columns)\nmodel = models.resnet18(pretrained=False)\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features,classes)\n\nmodel_path = \"../input/rsna-super-cool-eda-and-pytorch-baseline-train/\"\n\nconfig={\n       \"learning_rate\":0.001,\n       \"train_batch_size\":32,\n        \"valid_batch_size\":32,\n        \"test_batch_size\":64,\n       \"epochs\":10,\n       \"nfolds\":3,\n       \"number_of_samples\":7000\n       }\n\nreader = vtk.vtkDICOMImageReader()\ndef get_img(path):\n    reader.SetFileName(path)\n    reader.Update()\n    _extent = reader.GetDataExtent()\n    ConstPixelDims = [_extent[1]-_extent[0]+1, _extent[3]-_extent[2]+1, _extent[5]-_extent[4]+1]\n\n    ConstPixelSpacing = reader.GetPixelSpacing()\n    imageData = reader.GetOutput()\n    pointData = imageData.GetPointData()\n    arrayData = pointData.GetArray(0)\n    ArrayDicom = numpy_support.vtk_to_numpy(arrayData)\n    ArrayDicom = ArrayDicom.reshape(ConstPixelDims, order='F')\n    ArrayDicom = cv2.resize(ArrayDicom,(512,512))\n    return ArrayDicom\n\n\ndef convert_to_rgb(array):\n    array = array.reshape((512, 512, 1))\n    return np.stack([array, array, array], axis=2).reshape((3,512, 512))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RsnaDataset(Dataset):\n    \n    def __init__(self,df,transforms=None):\n        super().__init__()\n        self.image_paths = df['ImagePath'].unique()\n        self.df = df\n        self.study_ids= df[cols_ID[1]].values\n        self.sop_ids = df[cols_ID[2]].values\n        self.transforms = transforms\n    \n    def __getitem__(self,index):\n        \n        image_path = self.image_paths[index]\n        image = get_img(image_path)\n        image = convert_to_rgb(image)\n        \n        study_id = self.study_ids[index]\n        sop_id = self.sop_ids[index]\n        \n        if self.transforms:\n            image = self.transforms(image=image)['image']\n        \n\n        image = torch.tensor(image,dtype=torch.float)        \n        \n        return {\"image\":image,\n                \"study_id\":study_id,\n                \"sop_id\":sop_id}   \n    \n    def __len__(self):\n        return self.image_paths.shape[0]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference():\n    model.eval()\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    all_prediction = np.zeros((test_data.shape[0],len(target_columns)))\n    study_ids = list()\n    sop_ids = list()\n    for i in range(config[\"nfolds\"]):\n        model.load_state_dict(torch.load(f\"{model_path}model{i}.bin\"))\n        predictions = list()\n        model.to(device)\n        test_ds = RsnaDataset(test_data)\n        test_dl = DataLoader(test_ds,\n                        batch_size=config['test_batch_size'],\n                        shuffle=False)\n        \n        tqdm_loader = tqdm(test_dl)\n        \n        with torch.no_grad():\n            for inputs in tqdm_loader:\n                images = inputs[\"image\"].to(device, dtype=torch.float)\n                outputs = model(images) \n                predictions.extend(outputs.cpu().detach().numpy())\n                if i == 0:\n                    study_ids.extend(inputs[\"study_id\"])\n                    sop_ids.extend(inputs[\"sop_id\"])\n\n        all_prediction += np.array(predictions)/config['nfolds']\n        \n    return all_prediction, study_ids, sop_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions,study_ids,sop_ids = inference()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(predictions)\ndf.columns = target_columns\ndf[\"StudyInstanceUID\"] = study_ids\ndf[\"SOPInstanceUID\"] = sop_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp1 = df.groupby(\"StudyInstanceUID\")[target_columns].mean().reset_index()\ntemp1.drop(\"pe_present_on_image\",inplace=True,axis=1)\ntemp1 = pd.melt(temp1, id_vars=[\"StudyInstanceUID\"], value_vars=study_level_columns)\ntemp1[\"label\"] = temp1[\"StudyInstanceUID\"].astype(str) + \"_\" +temp1[\"variable\"].astype(str)\ntemp1.drop([\"StudyInstanceUID\",\"variable\"],axis=1,inplace=True)\ntemp1.columns = [\"label\",\"id\"]\n\ntemp2 = df.drop(study_level_columns +[\"StudyInstanceUID\"],axis=1)\ntemp2 = pd.melt(temp2, id_vars=[\"SOPInstanceUID\"], value_vars=['pe_present_on_image'])\ntemp2[\"label\"] = temp2[\"SOPInstanceUID\"].astype(str) \ntemp2.drop([\"SOPInstanceUID\",\"variable\"],axis=1,inplace=True)\ntemp2.columns = [\"label\",\"id\"]\n\nsubmission = temp2.append(temp1)\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter(sample.id) == Counter(submission.id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission.shape)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Todo\n\nchecking for logical consistency"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}