{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../input/gdcm-conda-install/gdcm.tar .\n!tar -xvzf gdcm.tar\n!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gdcm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport cv2\nimport os\nfrom matplotlib import pyplot as plt\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nimport albumentations as albu\nimport functools\nimport torch\nfrom tqdm.auto import tqdm\nfrom joblib import Parallel, delayed\nfrom joblib import parallel_backend\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test_csv_path = '../input/rsna-str-pulmonary-embolism-detection/test.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(test_csv_path)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydicom\nimport cv2\nimport os, os.path as osp\n\nfrom scipy.ndimage.interpolation import zoom\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\ndef pixel_array(d):\n    return d.pixel_array\ndef load_dicom_array(f):\n    dicom_files = glob.glob(osp.join(f, '*.dcm'))\n    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n    M = float(dicoms[0].RescaleSlope)\n    B = float(dicoms[0].RescaleIntercept)\n    z_pos = [float(d.ImagePositionPatient[-1]) for d in dicoms]\n    dicoms = np.asarray([d.pixel_array for d in dicoms])\n    dicoms = dicoms[np.argsort(z_pos)]\n    dicoms = dicoms * M\n    dicoms = dicoms + B\n    return dicoms, np.asarray(dicom_files)[np.argsort(z_pos)]\n\n\ndef window(img, WL=50, WW=350):\n    upper, lower = WL+WW//2, WL-WW//2\n    X = np.clip(img.copy(), lower, upper)\n    X = X - np.min(X)\n    X = X / np.max(X)\n    X = (X*255.0).astype('uint8')\n    return X\n\n\ndef save_array(X, save_dir, file_names):\n    for ind, img in enumerate(X):\n        savefile = osp.join(save_dir, file_names[ind])\n        if not osp.exists(osp.dirname(savefile)): \n            os.makedirs(osp.dirname(savefile))\n        _ = cv2.imwrite(osp.join(save_dir, file_names[ind]), img)\n\n\ndef edit_filenames(files):\n    dicoms = [f\"{ind:04d}_{f.split('/')[-1].replace('dcm','jpg')}\" for ind,f in enumerate(files)]\n    series = ['/'.join(f.split('/')[-3:-1]) for f in files]\n    return [osp.join(s,d) for s,d in zip(series, dicoms)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_augmentation(y=256,x=256):\n    train_transform = [albu.RandomBrightnessContrast(p=0.3),\n                           albu.VerticalFlip(p=0.5),\n                           albu.HorizontalFlip(p=0.5),\n                           albu.Downscale(p=1.0,scale_min=0.35,scale_max=0.75,),\n                           albu.Resize(y, x)]\n    return albu.Compose(train_transform)\n\n\nformatted_settings = {\n            'input_size': [3, 224, 224],\n            'input_range': [0, 1],\n            'mean': [0.485, 0.456, 0.406],\n            'std': [0.229, 0.224, 0.225],}\ndef preprocess_input(\n    x, mean=None, std=None, input_space=\"RGB\", input_range=None, **kwargs\n):\n\n    if input_space == \"BGR\":\n        x = x[..., ::-1].copy()\n\n    if input_range is not None:\n        if x.max() > 1 and input_range[1] == 1:\n            x = x / 255.0\n\n    if mean is not None:\n        mean = np.array(mean)\n        x = x - mean\n\n    if std is not None:\n        std = np.array(std)\n        x = x / std\n\n    return x\n\ndef get_preprocessing(preprocessing_fn):\n    _transform = [\n        albu.Lambda(image=preprocessing_fn),\n        albu.Lambda(image=to_tensor, mask=to_tensor),\n    ]\n    return albu.Compose(_transform)\n\ndef get_validation_augmentation(y=256,x=256):\n    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n    test_transform = [albu.Resize(y, x)]\n    return albu.Compose(test_transform)\n\ndef to_tensor(x, **kwargs):\n    \"\"\"\n    Convert image or mask.\n    \"\"\"\n    return x.transpose(2, 0, 1).astype('float32')\n\ndef norm(img):\n    img-=img.min()\n    return img/img.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class config:\n    model_name=\"resnext50\"\n    batch_size = 1\n    WORKERS = 0\n    classes =14\n    resume = False\n    epochs = 1\n    MODEL_PATH = 'log/cpt'\n    if not os.path.exists(MODEL_PATH):\n        os.makedirs(MODEL_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nclass Lungs:\n    def __init__(self, dicom_folders):\n        self.dicom_folders = dicom_folders\n        self.transforms = get_validation_augmentation()\n        self.preprocessing = get_preprocessing(functools.partial(preprocess_input, **formatted_settings))\n    def __len__(self): \n        return len(self.dicom_folders)\n    def get(self, i):\n        s = time.time()\n        data = load_dicom_array(self.dicom_folders[i])\n        image, files = data\n        image_lung = np.expand_dims(window(image, WL=-600, WW=1500), axis=3)\n        image_mediastinal = np.expand_dims(window(image, WL=40, WW=400), axis=3)\n        image_pe_specific = np.expand_dims(window(image, WL=100, WW=700), axis=3)\n        image = np.concatenate([image_mediastinal, image_pe_specific, image_lung], axis=3)\n        rat = MAX_LENGTH / np.max(image.shape[1:])\n#         image = zoom(image, [1.,rat,rat,1.], prefilter=False, order=1)\n        names = [row.split(\".dcm\")[0].split(\"/\")[-3:] for row in files]\n        images = []\n        for img in image:\n            if self.transforms:\n                img = self.transforms(image=img)['image']\n            if self.preprocessing:\n                img = self.preprocessing(image=img)['image']\n            images.append(img)\n        return torch.from_numpy(np.array(images)),names\n    \n    def __getitem__(self, i):\n        try:\n            return self.get(i)\n        except Exception as e:\n            print(e)\n            return None,None\n\nMAX_LENGTH = 256.\n\ndicom_folders = list(('../input/rsna-str-pulmonary-embolism-detection/test/' + df.StudyInstanceUID + '/'+ df.SeriesInstanceUID).unique())\ndset = Lungs(dicom_folders)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = DataLoader(dset, batch_size=config.batch_size, shuffle=False, num_workers=config.WORKERS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\nmodel = models.resnext50_32x4d(pretrained=False)\nmodel.fc = torch.nn.Linear(in_features=2048, out_features=config.classes, bias=True)\nmodel = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load(\"../input/fork-of-pulmonary-embolism-pytorch-train/log/cpt/resnext50_best.pth\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = list(pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/train.csv\").columns[3:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ['{}_pe_present_on_image',\n '{}_negative_exam_for_pe',\n '{}_qa_motion',\n '{}_qa_contrast',\n '{}_flow_artifact',\n '{}_rv_lv_ratio_gte_1',\n '{}_rv_lv_ratio_lt_1',\n '{}_leftsided_pe',\n '{}_chronic_pe',\n '{}_true_filling_defect_not_pe',\n '{}_rightsided_pe',\n '{}_acute_and_chronic_pe',\n '{}_central_pe',\n '{}_indeterminate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/sample_submission.csv\")\nsub.id = sub.id.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"do_all = len(os.listdir(\"../input/rsna-str-pulmonary-embolism-detection/test/\"))>700","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if do_all:\n    model.eval()\n    pred_df = []\n    for imgs_batchs,names in tqdm(test):\n        imgs_batch = imgs_batchs[0].cuda().float()\n        with torch.no_grad():\n            predicted = model(imgs_batch) +torch.flip(model(imgs_batch),[-1])+torch.flip(model(imgs_batch),[-2])\n            predicted = torch.sigmoid(predicted/3).cpu().numpy()\n            for ids in range(len(predicted)):\n                pred = predicted[ids]\n                name = names[ids]\n                mini_df = pd.DataFrame(list(pred)+[pred[0]],columns=['pred'])\n                new_name = [str(c.format(name[0][0])) for c in classes] + [name[2][0]]\n                mini_df['id'] = new_name\n                pred_df.append(mini_df)\n    pred_sub = pd.concat(pred_df).groupby(\"id\").max().reset_index()\n    sub = sub.merge(pred_sub,on='id',how='left')\n    sub = sub[['id','pred']]\n    sub.columns = ['id','label']\n    print(sub.isna().sum())\n    sub.fillna(0.5)\n    sub.to_csv(\"submission.csv\",index=False)\nelse:\n    sub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}