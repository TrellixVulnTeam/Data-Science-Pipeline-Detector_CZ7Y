{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../input/gdcm-conda-install/gdcm.tar .\n!tar -xvzf gdcm.tar\n!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/efficientnet-pytorch063/efficientnet_pytorch-0.6.3-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q ../input/noamior/monai-0.3.0-202010042353-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gdcm\nfrom efficientnet_pytorch import EfficientNet\nimport efficientnet_pytorch\nimport torch\nefficientnet_pytorch.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_cnn(filepath,name):\n    cnn5 = EfficientNet.from_name(name).cuda()\n    if name == 'efficientnet-b5':\n        cnn5._fc = torch.nn.Linear(in_features=2048, out_features=1, bias=True)\n    elif name == 'efficientnet-b4':\n        cnn5._fc = torch.nn.Linear(in_features=1536+256, out_features=1, bias=True)\n    elif name == 'efficientnet-b3':\n        cnn5._fc = torch.nn.Linear(in_features=1536, out_features=1, bias=True)\n    elif name == 'efficientnet-b2':\n        cnn5._fc = torch.nn.Linear(in_features=1408, out_features=1, bias=True)\n    cnn5 = torch.nn.DataParallel(cnn5)\n    cnn5.load_state_dict(torch.load(filepath))\n    cnn5.eval()\n    return cnn5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir('../input/rsnalstm2/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnnb3 = [load_cnn(f'../input/rsnalstm2/efficientnet-b3_cnn_{row}_best.pth','efficientnet-b3') for row in [1,2]]\ncnnb4 = [load_cnn(f'../input/rsnalstm2/efficientnet-b4_cnn_{row}_best.pth','efficientnet-b4') for row in [3,4]]\ncnnb5 = [load_cnn(f'../input/rsnalstm2/efficientnet-b5_cnn_{row}_best.pth','efficientnet-b5') for row in [2,0]]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport cv2\nimport os\nfrom matplotlib import pyplot as plt\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nimport albumentations as albu\nimport functools\nimport torch\nfrom tqdm.auto import tqdm\nfrom joblib import Parallel, delayed\nfrom joblib import parallel_backend","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test_csv_path = '../input/rsna-str-pulmonary-embolism-detection/test.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(test_csv_path)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydicom\nimport cv2\nimport os, os.path as osp\n\nfrom scipy.ndimage.interpolation import zoom\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\ndef pixel_array(d):\n    return d.pixel_array\ndef load_dicom_array(f):\n    dicom_files = glob.glob(osp.join(f, '*.dcm'))\n    dicoms = [pydicom.dcmread(d) for d in dicom_files]\n    M = float(dicoms[0].RescaleSlope)\n    B = float(dicoms[0].RescaleIntercept)\n    z_pos = [float(d.ImagePositionPatient[-1]) for d in dicoms]\n    dicoms = np.asarray([d.pixel_array for d in dicoms])\n    dicoms = dicoms[np.argsort(z_pos)]\n    dicoms = dicoms * M\n    dicoms = dicoms + B\n    return dicoms, np.asarray(dicom_files)[np.argsort(z_pos)]\n\n\ndef window(img, WL=50, WW=350):\n    upper, lower = WL+WW//2, WL-WW//2\n    X = np.clip(img.copy(), lower, upper)\n    X = X - np.min(X)\n    X = X / np.max(X)\n    X = (X*255.0).astype('uint8')\n    return X\n\n\ndef save_array(X, save_dir, file_names):\n    for ind, img in enumerate(X):\n        savefile = osp.join(save_dir, file_names[ind])\n        if not osp.exists(osp.dirname(savefile)): \n            os.makedirs(osp.dirname(savefile))\n        _ = cv2.imwrite(osp.join(save_dir, file_names[ind]), img)\n\n\ndef edit_filenames(files):\n    dicoms = [f\"{ind:04d}_{f.split('/')[-1].replace('dcm','jpg')}\" for ind,f in enumerate(files)]\n    series = ['/'.join(f.split('/')[-3:-1]) for f in files]\n    return [osp.join(s,d) for s,d in zip(series, dicoms)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class config:\n    model_name=\"b5\"\n    batch_size = 1\n    WORKERS = 0\n    classes =14\n    resume = False\n    epochs = 1\n    MODEL_PATH = 'log/cpt'\n    if not os.path.exists(MODEL_PATH):\n        os.makedirs(MODEL_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_augmentation(y=256,x=256):\n    train_transform = [albu.RandomBrightnessContrast(p=0.3),\n                           albu.VerticalFlip(p=0.5),\n                           albu.HorizontalFlip(p=0.5),\n                           albu.Downscale(p=1.0,scale_min=0.35,scale_max=0.75,),\n                           albu.Resize(y, x)]\n    return albu.Compose(train_transform)\n\n\nformatted_settings = {\n            'input_size': [3, 224, 224],\n            'input_range': [0, 1],\n            'mean': [0.485, 0.456, 0.406],\n            'std': [0.229, 0.224, 0.225],}\ndef preprocess_input(\n    x, mean=None, std=None, input_space=\"RGB\", input_range=None, **kwargs\n):\n\n    if input_space == \"BGR\":\n        x = x[..., ::-1].copy()\n\n    if input_range is not None:\n        if x.max() > 1 and input_range[1] == 1:\n            x = x / 255.0\n\n#     if mean is not None:\n#         mean = np.array(mean)\n#         x = x - mean\n\n#     if std is not None:\n#         std = np.array(std)\n#         x = x / std\n\n    return x\n\ndef get_preprocessing(preprocessing_fn):\n    _transform = [\n        albu.Lambda(image=preprocessing_fn),\n        albu.Lambda(image=to_tensor, mask=to_tensor),\n    ]\n    return albu.Compose(_transform)\n\ndef get_validation_augmentation(y=224,x=224):\n    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n    test_transform = [albu.Resize(256, 256),albu.CenterCrop(y,x)]\n    return albu.Compose(test_transform)\n\ndef to_tensor(x, **kwargs):\n    \"\"\"\n    Convert image or mask.\n    \"\"\"\n    return x.transpose(2, 0, 1).astype('float32')\n\ndef norm(img):\n    img-=img.min()\n    return img/img.max()\n\nimport monai\nfrom monai.transforms import LoadNifti, Randomizable, apply_transform\nfrom monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, ToTensor\nfrom monai.utils import get_seed\nimport time\nclass Lungs(Dataset, Randomizable):\n    def __init__(self, dicom_folders):\n        self.dicom_folders = dicom_folders\n        self.transforms = get_validation_augmentation()\n        self.preprocessing = get_preprocessing(functools.partial(preprocess_input, **formatted_settings))\n        self.transform3d = Compose([ScaleIntensity(), Resize((160, 160, 160)), ToTensor()])\n    def __len__(self): \n        return len(self.dicom_folders)\n    \n    def randomize(self) -> None:\n        MAX_SEED = np.iinfo(np.uint32).max + 1\n        self._seed = self.R.randint(MAX_SEED, dtype=\"uint32\") \n        \n    def get(self, i):\n        s = time.time()\n        data = load_dicom_array(self.dicom_folders[i])\n        image, files = data\n        image_lung = np.expand_dims(window(image, WL=-600, WW=1500), axis=3)\n        image_mediastinal = np.expand_dims(window(image, WL=40, WW=400), axis=3)\n        image_pe_specific = np.expand_dims(window(image, WL=100, WW=700), axis=3)\n        image = np.concatenate([image_mediastinal, image_pe_specific, image_lung], axis=3)\n        rat = MAX_LENGTH / np.max(image.shape[1:])\n        names = [row.split(\".dcm\")[0].split(\"/\")[-3:] for row in files]\n        images = []\n        for img in image:\n            if self.transforms:\n                img = self.transforms(image=img)['image']\n            if self.preprocessing:\n                img = self.preprocessing(image=img)['image']\n            images.append(img)\n        images = np.array(images)\n        img = images[:,::-1].transpose(1,2,3,0)\n        if self.transform3d is not None:\n            if isinstance(self.transform3d, Randomizable):\n                self.transform3d.set_random_state(seed=self._seed)\n            img = apply_transform(self.transform3d, img)\n            \n        return torch.from_numpy(images),names,img\n    \n    def __getitem__(self, i):\n        self.randomize()\n        try:\n            return self.get(i)\n        except Exception as e:\n            print(e)\n            return None,None\n\nMAX_LENGTH = 256.\n\ndicom_folders = list(('../input/rsna-str-pulmonary-embolism-detection/test/' + df.StudyInstanceUID + '/'+ df.SeriesInstanceUID).unique())\ndset = Lungs(dicom_folders)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = DataLoader(dset, batch_size=config.batch_size, shuffle=False, num_workers=config.WORKERS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,n,x1 = dset[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 12,5\nfor i in range(1):\n    f, axarr = plt.subplots(1,3)\n    _,_,img = dset[i]\n    print(img.shape)\n    for j in range(3):            \n        axarr[j].imshow(img.numpy().transpose(1,2,3,0).mean(axis=j))        \n        axarr[j].set_title(i)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = list(pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/train.csv\").columns[3:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/sample_submission.csv\")\nsub.id = sub.id.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"do_all = len(os.listdir(\"../input/rsna-str-pulmonary-embolism-detection/test/\"))>700\n# do_all=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\nfrom torch.nn import functional as F\nimport torch\n\nsigmoid = nn.Sigmoid()\n\n\n\nclass Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\n\nclass Swish_Module(nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)\n    \nclass GaussianNoise(nn.Module):\n    def __init__(self, sigma=0.1, is_relative_detach=True):\n        super().__init__()\n        self.sigma = sigma\n        self.is_relative_detach = is_relative_detach\n        self.noise = torch.tensor(0).cuda().float()\n\n    def forward(self, x):\n        if self.training and self.sigma != 0:\n            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n            x = x + sampled_noise\n        return x \n\nclass NeuralNet2(nn.Module):\n    def __init__(self, embed_size=5379, LSTM_UNITS=512, DO = 0.2,g=0.05):\n        super(NeuralNet2, self).__init__()\n        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True,dropout=0.0)\n        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True,dropout=0.0)\n        self.Noise = GaussianNoise(g)\n        self.linear1 = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        self.linear2 = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        self.avd3d = nn.AdaptiveAvgPool3d(1)\n        self.avd1d = nn.AdaptiveAvgPool1d(1)\n        \n        self.linear_rv = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        self.linear_rlc = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        self.linear_pe = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        \n        self.linear_pe = nn.Linear(LSTM_UNITS*2, 1)\n        self.linear_global_fc0 = nn.Linear(3073, 3) #ALL_PE,NEG,IND\n        self.linear_global_fc1 = nn.Linear(LSTM_UNITS*2*2, 3) #RV>1,RV<1,Not PE\n        self.linear_global_fc2 = nn.Linear(3073, 4) #Chronic, Chronic+Acute, Not PE,Acute\n        self.linear_global_fc3 = nn.Linear(LSTM_UNITS*2*2, 3) #right,left,center\n        self.dropuot3d = nn.Dropout3d(DO)\n        self.dropuot1d = nn.Dropout(DO)\n        self.s3d = Swish_Module()\n        self.s1d = Swish_Module()\n        self.s2d = Swish_Module()\n        \n        \n    def forward(self, x, x_rv,x_rlc,x_pe):\n        \n        x_rv = self.dropuot3d(x_rv)\n        x_rv = self.avd3d(x_rv).reshape(1,-1)\n        x_rv1 = self.s3d(self.linear_rv(x_rv))\n        x_rv = x_rv.reshape(1,-1)\n        x_rv1 = x_rv1.reshape(1,-1)\n        \n        \n        x_rlc = self.dropuot3d(x_rlc)\n        x_rlc = self.avd3d(x_rlc).reshape(1,-1)\n        x_rlc1 = self.s3d(self.linear_rlc(x_rlc))\n        x_rlc = x_rlc.reshape(1,-1)\n        x_rlc1 = x_rlc1.reshape(1,-1)\n        \n        \n        x_pe = self.dropuot3d(x_pe)\n        x_pe = self.avd3d(x_pe).reshape(1,-1)\n        x_pe1 = self.s3d(self.linear_pe(x_pe))\n        x_pe = x_pe.reshape(1,-1)\n        x_pe1 = x_pe1.reshape(1,-1)\n        \n        b,f = x.shape\n        embedding = x.reshape(1,b,f)\n        self.lstm1.flatten_parameters()\n        h_lstm1, _ = self.lstm1(embedding)\n        self.lstm2.flatten_parameters()\n        h_lstm2, _ = self.lstm2(h_lstm1)\n        \n        h_conc_linear1  = self.s1d(self.linear1(h_lstm1))\n        h_conc_linear2  = self.s2d(self.linear2(h_lstm2))\n        \n        hidden = h_lstm1 + h_lstm2 + h_conc_linear1 + h_conc_linear2\n        \n        output = self.linear_pe(hidden)\n        \n        hidden2 = self.avd1d(hidden.transpose(2,1))\n        hidden_rv = torch.cat([hidden2[:,:,0],x_rv+x_rv1],-1)\n        hidden_rlc = torch.cat([hidden2[:,:,0],x_rlc+x_rlc1],-1)\n        \n        hidden_global = torch.cat([hidden2[:,:,0],x_pe1,x_pe,x_rlc+x_rlc1],-1)\n\n        output_global0 = self.linear_global_fc0(hidden_global)\n    \n        output_global1 = self.linear_global_fc1(hidden_rv)\n        \n        output_global2 = self.linear_global_fc2(hidden_global)\n        \n        output_global3 = self.linear_global_fc3(hidden_rlc)\n        return output,output_global0,output_global1,output_global2,output_global3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\nfrom torch.nn import functional as F\nimport torch\n\nsigmoid = nn.Sigmoid()\n\n\n\nclass Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\n\nclass Swish_Module(nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)\n    \nclass GaussianNoise(nn.Module):\n    def __init__(self, sigma=0.1, is_relative_detach=True):\n        super().__init__()\n        self.sigma = sigma\n        self.is_relative_detach = is_relative_detach\n        self.noise = torch.tensor(0).cuda().float()\n\n    def forward(self, x):\n        if self.training and self.sigma != 0:\n            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n            x = x + sampled_noise\n        return x \n\nclass NeuralNet(nn.Module):\n    def __init__(self, embed_size=5379, LSTM_UNITS=512, DO = 0.3,g=0.05):\n        super(NeuralNet, self).__init__()\n        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True,dropout=0.0)\n        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True,dropout=0.0)\n        self.Noise = GaussianNoise(g)\n        self.linear1 = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        self.linear2 = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        self.avd3d = nn.AdaptiveAvgPool3d(1)\n        self.avd1d = nn.AdaptiveAvgPool1d(1)\n        \n        self.linear_rv = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        self.linear_rlc = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n        \n        self.linear_pe = nn.Linear(LSTM_UNITS*2, 1)\n        self.linear_global_fc0 = nn.Linear(LSTM_UNITS*2*4, 3) #ALL_PE,NEG,IND\n        self.linear_global_fc1 = nn.Linear(LSTM_UNITS*2*2, 3) #RV>1,RV<1,Not PE\n        self.linear_global_fc2 = nn.Linear(LSTM_UNITS*2*4, 4) #Chronic, Chronic+Acute, Not PE,Acute\n        self.linear_global_fc3 = nn.Linear(LSTM_UNITS*2*2, 3) #right,left,center\n        self.dropuot3d = nn.Dropout3d(DO)\n        self.dropuot1d = nn.Dropout(DO)\n        self.s3d = Swish_Module()\n        self.s1d = Swish_Module()\n        self.s2d = Swish_Module()\n        \n        \n    def forward(self, x, x_rv,x_rlc):\n        \n        x_rv = self.dropuot3d(x_rv)\n        x_rv = self.Noise(self.avd3d(x_rv).reshape(1,-1))\n        x_rv1 = self.s3d(self.linear_rv(x_rv))\n        x_rv = x_rv.reshape(1,-1)\n        x_rv1 = x_rv1.reshape(1,-1)\n        \n        \n        x_rlc = self.dropuot3d(x_rlc)\n        x_rlc = self.Noise(self.avd3d(x_rlc).reshape(1,-1))\n        x_rlc1 = self.s3d(self.linear_rlc(x_rlc))\n        x_rlc = x_rlc.reshape(1,-1)\n        x_rlc1 = x_rlc1.reshape(1,-1)\n        \n        b,f = x.shape\n        embedding = x.reshape(1,b,f)\n        self.lstm1.flatten_parameters()\n        h_lstm1, _ = self.lstm1(embedding)\n        self.lstm2.flatten_parameters()\n        h_lstm2, _ = self.lstm2(h_lstm1)\n        \n        h_conc_linear1  = self.s1d(self.linear1(h_lstm1))\n        h_conc_linear2  = self.s2d(self.linear2(h_lstm2))\n        \n        hidden = h_lstm1 + h_lstm2 + h_conc_linear1 + h_conc_linear2\n        \n        output = self.linear_pe(hidden)\n        \n        hidden2 = self.avd1d(hidden.transpose(2,1))\n        hidden_rv = torch.cat([hidden2[:,:,0],x_rv+x_rv1],-1)\n        hidden_rlc = torch.cat([hidden2[:,:,0],x_rlc+x_rlc1],-1)\n        \n        hidden_global = torch.cat([hidden_rv,hidden_rlc],-1)\n        \n        output_global0 = self.linear_global_fc0(hidden_global)\n    \n        output_global1 = self.linear_global_fc1(hidden_rv)\n        \n        output_global2 = self.linear_global_fc2(hidden_global)\n        \n        output_global3 = self.linear_global_fc3(hidden_rlc)\n        return output,output_global0,output_global1,output_global2,output_global3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"../input/rsnape3d/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models =[]\n# for file in os.listdir(\"../input/lstmrsnacpt/\"):\n# for file in [\"../input/rsnalstm3d/lstm_pe_neg_best.pth\",\"../input/lstem-fold20/lstm_pe_neg_best_fold0.pth\",\"../input/lstem-fold20/lstm_pe_negfold 2_best.pth\"]:\nfor file in [\"../input/rsnape3d/liniar_pe_neg_fold_0_fold_0_best.pth\"]:\n    model = NeuralNet2().cuda()\n    model.load_state_dict(torch.load(file))\n    model.eval()\n    models.append(model)\nprint(len(models))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_old =[]\n# for file in os.listdir(\"../input/lstmrsnacpt/\"):\n# for file in [\"../input/rsnalstm3d/lstm_pe_neg_best.pth\",\"../input/lstem-fold20/lstm_pe_neg_best_fold0.pth\",\"../input/lstem-fold20/lstm_pe_negfold 2_best.pth\"]:\nfor file in [\"../input/pth-lstm-543/best0.pth\"]:\n    model = NeuralNet().cuda()\n    model.load_state_dict(torch.load(file))\n    model.eval()\n    models_old.append(model)\nprint(len(models_old))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_classes = '{}_pe_present_on_image'\nglobal_class = ['{}_negative_exam_for_pe', '{}_rv_lv_ratio_gte_1', '{}_rv_lv_ratio_lt_1',\n       '{}_leftsided_pe', '{}_chronic_pe','{}_rightsided_pe', '{}_acute_and_chronic_pe', '{}_central_pe', '{}_indeterminate']\n\ntarget_cols3d = [\n        'negative_exam_for_pe', # exam level\n        'rv_lv_ratio_gte_1', # exam level\n        'rv_lv_ratio_lt_1', # exam level\n        'leftsided_pe', # exam level\n        'chronic_pe', # exam level\n        'rightsided_pe', # exam level\n        'acute_and_chronic_pe', # exam level\n        'central_pe', # exam level\n        'indeterminate' # exam level\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lstm_results(y,y1,y2):\n    predicted0,predicted1,predicted2,predicted3,predicted4 = 0,0,0,0,0\n    for i,model in enumerate(models):\n        predicted = model(y,y1,y2)\n        if i>0:\n            predicted0_,predicted1_,predicted2_,predicted3_,predicted4_ = predicted[0],predicted[1],predicted[2],predicted[3],predicted[4]\n            predicted0+=predicted0_\n            predicted1+=predicted1_\n            predicted2+=predicted2_\n            predicted3+=predicted3_\n            predicted4+=predicted4_\n        else:\n            predicted0,predicted1,predicted2,predicted3,predicted4 = predicted[0],predicted[1],predicted[2],predicted[3],predicted[4]\n    return [predicted0/len(models),predicted1/len(models),predicted2/len(models),predicted3/len(models),predicted4/len(models)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/lstm3d/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_files_rlc = ['../input/lstm3d/densenet121_rlc_best_fold2.pth','../input/lstm3d/densenet121_rlc_model_fold1.pth','../input/lstm3d/densenet121_rlc_model_fold4.pth']\nmodel_fils_rv = [f'../input/lstm3d/densenet121_best_fold2.pth',f'../input/lstm3d/densenet121_best_fold0.pth',f'../input/lstm3d/densenet121_best_fold3.pth']\nmodel_fils_pe = [f'../input/rsnape3d/densenet121_pe_best_fold3.pth',f'../input/rsnape3d/densenet121_pe_best_fold1.pth',f'../input/rsnape3d/densenet121_pe_best_fold0.pth']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model(model_file,c=1):\n    print(model_file)\n    model = monai.networks.nets.densenet.densenet121(spatial_dims=3, in_channels=3, out_channels=c).cuda()\n\n    try:  # single GPU model_file\n        model.load_state_dict(torch.load(model_file), strict=True)\n    except:  # multi GPU model_file\n        state_dict = torch.load(model_file)\n        state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n        model.load_state_dict(state_dict, strict=True)\n\n    model.eval()    \n    return model\n\nmodels_3d_rlc = [load_model(model3d,3) for i,model3d in enumerate(model_files_rlc)]\nmodels_3d_rv = [load_model(model3d,1) for i,model3d in enumerate(model_fils_rv)]\nmodels_3d_pe = [load_model(model3d,1) for i,model3d in enumerate(model_fils_pe)]\nlen(models_3d_rv),len(models_3d_rlc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do_all=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if do_all:\n    model.eval()\n    pred_df = []\n    for imgs_batchs,names,imgs_batchs_3d in tqdm(test):\n        if True:\n            imgs_batch = imgs_batchs[0].cuda().float()\n            imgs_batchs_3d = imgs_batchs_3d.cuda().float()\n            with torch.no_grad():\n                logits_rv = models_3d_rv[0].features(imgs_batchs_3d)/3.0 +models_3d_rv[1].features(imgs_batchs_3d)/3.0 + models_3d_rv[2].features(imgs_batchs_3d)/3.0\n                logits_rlc = models_3d_rlc[0].features(imgs_batchs_3d)/3.0 +models_3d_rlc[1].features(imgs_batchs_3d)/3.0 + models_3d_rlc[2].features(imgs_batchs_3d)/3.0\n                logits_pe = models_3d_pe[0].features(imgs_batchs_3d)/3.0 +models_3d_pe[1].features(imgs_batchs_3d)/3.0 + models_3d_pe[2].features(imgs_batchs_3d)/3.0\n#                 prob_rv = torch.softmax(models_3d_rv[0].class_layers(logits_rv),-1)\n#                 prob_rv = torch.softmax(models_3d_rlc[0].class_layers(logits_rlc),-1)\n                y = torch.zeros([len(cnnb5),len(imgs_batch),2048+1+1792+1+1536+1]).float().cuda()\n                predicteds = []\n                global_predicteds = []\n                for fold in range(len(cnnb5)):\n                    for row in range(0,len(imgs_batch),100):\n                        fet = cnnb5[fold].module.extract_features(imgs_batch[row:row+100].cuda().float())\n                        y[fold][row:row+100,:2048] = torch.nn.AdaptiveAvgPool2d(1)(fet)[:,:,0,0]\n                        y[fold][row:row+100,2048:2049] = cnnb5[fold].module._fc(cnnb5[fold].module._avg_pooling(fet).flatten(start_dim=1))\n#                         print((cnnb5[fold].module._fc(cnnb5[fold].module._avg_pooling(fet).flatten(start_dim=1))==cnnb5[fold](imgs_batch[row:row+100].cuda().float())).all())\n\n                        fet4 = cnnb4[fold].module.extract_features(imgs_batch[row:row+100].cuda().float())\n                        y[fold][row:row+100,2049:2049+1792] = torch.nn.AdaptiveAvgPool2d(1)(fet4)[:,:,0,0]\n                        y[fold][row:row+100,1792+2048:1792+2048+1] = cnnb4[fold].module._fc(cnnb4[fold].module._avg_pooling(fet4).flatten(start_dim=1))\n            \n                        fet3 = cnnb3[fold].module.extract_features(imgs_batch[row:row+100].cuda().float())\n                        y[fold][row:row+100,2049+1793:2049+1793+1536] = torch.nn.AdaptiveAvgPool2d(1)(fet3)[:,:,0,0]\n                        y[fold][row:row+100,2049+1793+1536:2049+1793+1536+1] = cnnb3[fold].module._fc(cnnb3[fold].module._avg_pooling(fet3).flatten(start_dim=1))\n                \n#                 predictedOld = model(y.mean(0).cuda().float())    \n                predicted = models[0](y.mean(0).cuda().float(),logits_rv.cuda().float(),logits_rlc.cuda().float(),logits_pe.cuda().float())\n                predicted_old = models_old[0](y.mean(0).cuda().float(),logits_rv.cuda().float(),logits_rlc.cuda().float())\n#                 predicted = lstm_results(y.mean(0).cuda().float(),logits_rv.cuda().float(),logits_rlc.cuda().float(),logits_pe.cuda().float())\n                predicted0 = 0.5*torch.sigmoid(predicted_old[0]).cpu().numpy().reshape(-1) + 0.5*torch.sigmoid(predicted[0]).cpu().numpy().reshape(-1)\n                PE_NEG_IND = 0.5*torch.softmax(predicted_old[1],dim=1).cpu().numpy().reshape(-1) +0.5*torch.softmax(predicted[1],dim=1).cpu().numpy().reshape(-1)\n                RV_RV1_NEG = 0.5*torch.softmax(predicted_old[2],dim=1).cpu().numpy().reshape(-1) + 0.5*torch.softmax(predicted[2],dim=1).cpu().numpy().reshape(-1)\n                RLC = 0.5*torch.sigmoid(predicted_old[4]).cpu().numpy().reshape(-1) + 0.5*torch.sigmoid(predicted[4]).cpu().numpy().reshape(-1)\n                CH_CHAC_NEG_AC = 0.5*torch.softmax(predicted_old[3],dim=1).cpu().numpy().reshape(-1) + 0.5*torch.softmax(predicted[3],dim=1).cpu().numpy().reshape(-1)\n                if predicted0.max()<=0.5 and PE_NEG_IND[0]<0.5:\n                    rule = 'neg'\n                elif PE_NEG_IND[1]>0.85:\n                    rule = 'neg'\n                elif PE_NEG_IND[1]>0.7 and predicted0.max()<0.85:\n                    rule = 'neg'\n                elif PE_NEG_IND[1]>0.6 and predicted0.max()<0.75:\n                    rule = 'neg'\n                elif PE_NEG_IND[1]>0.5 and predicted0.max()<0.6:\n                    rule = 'neg'\n                else:\n                    rule = 'pos'\n                if rule == 'neg':\n                    predicted0[predicted0>0.49999]=min(np.mean(predicted0),0.49999)\n                    if PE_NEG_IND[1] > PE_NEG_IND[2]:\n                        PE_NEG_IND[1] = max(PE_NEG_IND[1],0.50001)\n                        PE_NEG_IND[2] = min(PE_NEG_IND[2],0.49999)\n                    else:\n                        PE_NEG_IND[2] = max(PE_NEG_IND[2],0.50001)\n                        PE_NEG_IND[1] = min(PE_NEG_IND[1],0.49999)\n                        \n                    RLC[0] = min(RLC[0],0.4999)\n                    RLC[1] = min(RLC[1],0.4999)\n                    RLC[2] = min(RLC[2],0.4999)\n                    \n                    RV_RV1_NEG[0] = min(RV_RV1_NEG[0],0.4999)\n                    RV_RV1_NEG[1] = min(RV_RV1_NEG[1],0.4999)\n                    \n                    CH_CHAC_NEG_AC[0] = min(CH_CHAC_NEG_AC[0],0.4999)\n                    CH_CHAC_NEG_AC[1] = min(CH_CHAC_NEG_AC[1],0.4999)\n                    \n                elif rule == 'pos':\n                    if RV_RV1_NEG[0]>RV_RV1_NEG[1]:\n                        RV_RV1_NEG[0] = max(RV_RV1_NEG[0],0.50001)\n                        RV_RV1_NEG[1] = min(RV_RV1_NEG[1],0.49999)\n                    else:\n                        RV_RV1_NEG[1] = max(RV_RV1_NEG[1],0.50001)\n                        RV_RV1_NEG[0] = min(RV_RV1_NEG[0],0.49999)\n                    \n                    if RLC.max()<=0.5:\n                        RLC[RLC.argmax()] = 0.50001\n                        \n                    if CH_CHAC_NEG_AC[0] >0.5 and  CH_CHAC_NEG_AC[1]>0.5:\n                        if CH_CHAC_NEG_AC[0]>CH_CHAC_NEG_AC[1]:\n                            CH_CHAC_NEG_AC[1]= 0.49999\n                        else:\n                            CH_CHAC_NEG_AC[0]=0.49999\n                            \n                    if predicted0.max()<=0.5:\n                        predicted0[predicted0.argmax()] = 0.50001\n                    \n                    PE_NEG_IND[1] = min(PE_NEG_IND[1],0.499999)\n                    PE_NEG_IND[2] = min(PE_NEG_IND[2],0.499999)\n                        \n                    \n\n#                 if (PE_NEG_IND[0]<0.5 or PE_NEG_IND[1]>0.5) and predicted0.max()>0.49999999:\n#                     predicted0[predicted0>0.49999]=min(np.mean(predicted0),0.49999)\n                PE_NEG_IND = PE_NEG_IND.tolist()\n                RV_RV1_NEG = RV_RV1_NEG.tolist()\n                RLC = RLC.tolist()\n                CH_CHAC_NEG_AC = CH_CHAC_NEG_AC.tolist()\n                predicteds.append(predicted0)\n                pred_global = [PE_NEG_IND[1]] + [RV_RV1_NEG[0]] + [RV_RV1_NEG[1]] + [RLC[1]] + [CH_CHAC_NEG_AC[0]]+ [RLC[0]]+ [CH_CHAC_NEG_AC[1]]+ [RLC[2]] + [PE_NEG_IND[2]]\n                pred_global = np.array(pred_global)\n                global_predicteds.append(pred_global)\n                        \n                pred_global = np.array(global_predicteds).mean(0) \n                predicted0 = np.array(predicteds).mean(0)\n                \n                blobal_name = [str(c.format(names[0][0][0])) for c in global_class]\n                df_global = pd.DataFrame(pred_global,blobal_name).reset_index()\n                df_global.columns = ['id','pred']\n                print(df_global)\n                df_per_image = []\n                for ids in range(len(predicted0)):\n                    pred = predicted0[ids]\n                    name = names[ids][2][0]\n                    df_per_image.append([name,pred])\n                df_per_image = pd.DataFrame(df_per_image)\n                df_per_image.columns = ['id','pred']\n                print(df_per_image.pred.max())\n                df = pd.concat([df_per_image,df_global])\n                pred_df.append(df)\n    sub = pd.concat(pred_df).groupby(\"id\").max().reset_index()\n#     sub = sub.merge(pred_sub,on='id',how='left')\n    sub = sub[['id','pred']]\n    sub.columns = ['id','label']\n    print(sub.isna().sum())\n    sub.fillna(0.5)\n    sub.to_csv(\"submission.csv\",index=False)\nelse:\n    sub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test  = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/test.csv')\ndef check_consistency(sub, test):\n    \n    '''\n    Checks label consistency and returns the errors\n    \n    Args:\n    sub   = submission dataframe (pandas)\n    test  = test.csv dataframe (pandas)\n    '''\n    \n    # EXAM LEVEL\n    for i in test['StudyInstanceUID'].unique():\n        df_tmp = sub.loc[sub.id.str.contains(i, regex = False)].reset_index(drop = True)\n        df_tmp['StudyInstanceUID'] = df_tmp['id'].str.split('_').str[0]\n        df_tmp['label_type']       = df_tmp['id'].str.split('_').str[1:].apply(lambda x: '_'.join(x))\n        del df_tmp['id']\n        if i == test['StudyInstanceUID'].unique()[0]:\n            df = df_tmp.copy()\n        else:\n            df = pd.concat([df, df_tmp], axis = 0)\n    df_exam = df.pivot(index = 'StudyInstanceUID', columns = 'label_type', values = 'label')\n    \n    # IMAGE LEVEL\n    df_image = sub.loc[sub.id.isin(test.SOPInstanceUID)].reset_index(drop = True)\n    df_image = df_image.merge(test, how = 'left', left_on = 'id', right_on = 'SOPInstanceUID')\n    df_image.rename(columns = {\"label\": \"pe_present_on_image\"}, inplace = True)\n    del df_image['id']\n    \n    # MERGER\n    df = df_exam.merge(df_image, how = 'left', on = 'StudyInstanceUID')\n    ids    = ['StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID']\n    labels = [c for c in df.columns if c not in ids]\n    df = df[ids + labels]\n    \n    # SPLIT NEGATIVE AND POSITIVE EXAMS\n    df['positive_images_in_exam'] = df['StudyInstanceUID'].map(df.groupby(['StudyInstanceUID']).pe_present_on_image.max())\n    df_pos = df.loc[df.positive_images_in_exam >  0.5]\n    df_neg = df.loc[df.positive_images_in_exam <= 0.5]\n    \n    # CHECKING CONSISTENCY OF POSITIVE EXAM LABELS\n    rule1a = df_pos.loc[((df_pos.rv_lv_ratio_lt_1  >  0.5)  & \n                         (df_pos.rv_lv_ratio_gte_1 >  0.5)) | \n                        ((df_pos.rv_lv_ratio_lt_1  <= 0.5)  & \n                         (df_pos.rv_lv_ratio_gte_1 <= 0.5))].reset_index(drop = True)\n    rule1a['broken_rule'] = '1a'\n    rule1b = df_pos.loc[(df_pos.central_pe    <= 0.5) & \n                        (df_pos.rightsided_pe <= 0.5) & \n                        (df_pos.leftsided_pe  <= 0.5)].reset_index(drop = True)\n    rule1b['broken_rule'] = '1b'\n    rule1c = df_pos.loc[(df_pos.acute_and_chronic_pe > 0.5) & \n                        (df_pos.chronic_pe           > 0.5)].reset_index(drop = True)\n    rule1c['broken_rule'] = '1c'\n\n    # CHECKING CONSISTENCY OF NEGATIVE EXAM LABELS\n    rule2a = df_neg.loc[((df_neg.indeterminate        >  0.5)  & \n                         (df_neg.negative_exam_for_pe >  0.5)) | \n                        ((df_neg.indeterminate        <= 0.5)  & \n                         (df_neg.negative_exam_for_pe <= 0.5))].reset_index(drop = True)\n    rule2a['broken_rule'] = '2a'\n    rule2b = df_neg.loc[(df_neg.rv_lv_ratio_lt_1     > 0.5) | \n                        (df_neg.rv_lv_ratio_gte_1    > 0.5) |\n                        (df_neg.central_pe           > 0.5) | \n                        (df_neg.rightsided_pe        > 0.5) | \n                        (df_neg.leftsided_pe         > 0.5) |\n                        (df_neg.acute_and_chronic_pe > 0.5) | \n                        (df_neg.chronic_pe           > 0.5)].reset_index(drop = True)\n    rule2b['broken_rule'] = '2b'\n    \n    # MERGING INCONSISTENT PREDICTIONS\n    errors = pd.concat([rule1a, rule1b, rule1c, rule2a, rule2b], axis = 0)\n    \n    # OUTPUT\n    print('Found', len(errors), 'inconsistent predictions')\n    return errors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"e = check_consistency(sub, test)\nif len(e)>0:\n    sub = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/sample_submission.csv\")\n    sub.to_csv(\"submission.csv\",index=False)\n    sub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}