{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../input/gdcm-conda-install/gdcm.tar .\n!tar -xvzf gdcm.tar\n!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gdcm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import ast\nimport gc\nimport math\nimport os\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torch.optim as optim\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms\nfrom torchvision import models\n\nfrom fastprogress import progress_bar\n\nprint(os.cpu_count())\nn_gpu = torch.cuda.device_count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seeds(SEED):\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    if n_gpu > 0:\n        torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    # torch.backends.cudnn.benchmark = True\n\nset_seeds(SEED=2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 8\nnum_workers = os.cpu_count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# commit時に時間がかからないようにフラグを立てる\ndo_all = len(os.listdir(\"../input/rsna-str-pulmonary-embolism-detection/test/\")) > 700\n# print(do_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do_all = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract meta data from test data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/rsna-str-pulmonary-embolism-detection/test.csv')\n# test_df = test_df[:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef get_file_paths(df, base_dir):\n    PATH = \"../input/rsna-str-pulmonary-embolism-detection/\"\n    df[\"file_path\"] = df.apply(lambda x: (PATH + base_dir + \n                                    x[\"StudyInstanceUID\"] + \"/\" + \n                                    x[\"SeriesInstanceUID\"]+ \"/\" +\n                                    x[\"SOPInstanceUID\"]+ \".dcm\"), axis=1)\n    return df\n\ntest_df = get_file_paths(test_df, \"test/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/kozodoi/extract-meta-features-from-training-images\ndef extract_meta_feats(file_path):\n    image = pydicom.dcmread(file_path)\n\n    study_uid = image.StudyInstanceUID\n    series_uid = image.SeriesInstanceUID\n    sop_uid = image.SOPInstanceUID\n    image_position_patient = image.ImagePositionPatient\n\n    return [study_uid, series_uid, sop_uid, image_position_patient]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nif do_all:\n    test_files = test_df[\"file_path\"].values.tolist()\n    results = Parallel(n_jobs=-1, verbose=1)(map(delayed(extract_meta_feats), test_files))\n    test_meta_df = pd.DataFrame(results, columns=[\n        \"StudyInstanceUID\", \"SeriesInstanceUID\", \"SOPInstanceUID\", \"ImagePositionPatient\"])\n    test_meta_df.to_csv('test_metadata.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_meta_df.shape)\nprint(test_meta_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test_meta_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract ResNet18 Features for Seqeunce Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pixel_array(d):\n    return d.pixel_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dicom_array(file_path):\n    dicom = pydicom.dcmread(file_path)\n    M = float(dicom.RescaleSlope)\n    B = float(dicom.RescaleIntercept)\n    dicom = pixel_array(dicom)\n    dicom = dicom * M\n    dicom = dicom + B\n    return dicom","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def window(img, WL=50, WW=350):\n    upper, lower = (WL+WW)//2, (WL-WW)//2\n    X = np.clip(img.copy(), lower, upper)\n    X = X - np.min(X)\n    X = X / np.max(X)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_3ch_image(image, transform=None):\n    image_lung = window(image, WL=-600, WW=1500).astype(np.float32)\n    image_mediastinal = window(image, WL=40, WW=400).astype(np.float32)\n    image_pe_specific = window(image, WL=100, WW=700).astype(np.float32)\n    \n    if transform:\n        image_lung = transform(image=image_lung)['image']\n        image_mediastinal = transform(image=image_mediastinal)['image']\n        image_pe_specific = transform(image=image_pe_specific)['image']\n    \n    image_array = np.stack([image_lung, image_mediastinal, image_pe_specific], axis=-1)\n    image_array = image_array.transpose(2, 0, 1)\n    return image_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageDataset(data.Dataset):\n    def __init__(self, df, img_list, img_size=512, transform=None):\n        self.df = df\n        self.img_list = img_list\n        self.img_size = img_size\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        img_path = self.img_list[idx]\n        img_array = get_3ch_image(load_dicom_array(img_path), self.transform)\n        \n        item = {\"img\": img_array, \n                \"StudyInstanceUID\": row[\"StudyInstanceUID\"],\n                \"SeriesInstanceUID\": row[\"SeriesInstanceUID\"],\n                \"SOPInstanceUID\": row[\"SOPInstanceUID\"]}\n        \n        return item","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_columns = [\"StudyInstanceUID\", \"SeriesInstanceUID\", \"SOPInstanceUID\"]\n\ntest_loader = data.DataLoader(ImageDataset(test_df[id_columns], img_list=test_df[\"file_path\"].values,),\n                              batch_size=batch_size,\n                              shuffle=False,\n                              num_workers=num_workers,\n                              pin_memory=True,\n                              drop_last=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader.dataset[4][\"img\"].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN Net Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, pretrained=False,\n                 num_classes=2):\n        super().__init__()\n        base_model = models.__getattribute__(\"resnet18\")(\n            pretrained=pretrained)\n        layers = list(base_model.children())[:-2]\n        layers.append(nn.AdaptiveMaxPool2d(1))\n        self.encoder = nn.Sequential(*layers)\n\n        in_features = base_model.fc.in_features\n\n        self.classifier = nn.Sequential(\n            nn.Linear(in_features, 512), nn.ReLU(), nn.Dropout(p=0.5),\n            nn.Linear(512, 2))\n        \n    def forward(self, x):\n        batch_size = x.size(0)\n        features = self.encoder(x).view(batch_size, -1)\n        x = self.classifier(features)\n        return F.softmax(x, dim=1), features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = ResNet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = torch.load(\"../input/0927-resnet18-loss03220/train.4.pth\", map_location=device)\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nmodel.to(device)\nmodel.eval()\nprint(\"model load finish\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN Net Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nif do_all:\n    embs, predictions = [], []\n    StudyInstanceUIDs, SeriesInstanceUIDs, SOPInstanceUIDs = [], [], []\n    for batch in progress_bar(test_loader):\n        with torch.no_grad():\n            logits, emb = model(batch[\"img\"].to(device, dtype=torch.float, non_blocking=True))\n            embs.append(emb.detach().cpu().numpy())\n            predictions.append(logits.transpose(1, 0)[1].detach().cpu().numpy())\n\n            StudyInstanceUID = batch[\"StudyInstanceUID\"]\n            SeriesInstanceUID = batch[\"SeriesInstanceUID\"]\n            SOPInstanceUID = batch[\"SOPInstanceUID\"]\n            StudyInstanceUIDs.append(StudyInstanceUID)\n            SeriesInstanceUIDs.append(SeriesInstanceUID)\n            SOPInstanceUIDs.append(SOPInstanceUID)\n\n    predictions = np.concatenate(predictions, 0).astype(np.float32)\n\n    out_embs = np.concatenate(embs, 0).astype(np.float32)\n    print(\"Write embeddings: shape {} {}\".format(*out_embs.shape))\n\n    out_StudyInstanceUIDs = np.concatenate(StudyInstanceUIDs, 0)\n    out_SeriesInstanceUIDs = np.concatenate(SeriesInstanceUIDs, 0)\n    out_SOPInstanceUIDs = np.concatenate(SOPInstanceUIDs, 0)\n    assert len(out_embs) == len(out_StudyInstanceUIDs), \"{} {}\".format(len(out_embs), len(out_StudyInstanceUIDs))\n    assert len(out_StudyInstanceUIDs) == len(out_SeriesInstanceUIDs), \"{} {}\".format(len(out_StudyInstanceUIDs), len(out_SeriesInstanceUIDs))\n    assert len(out_SOPInstanceUIDs) == len(out_SeriesInstanceUIDs), \"{} {}\".format(len(out_SOPInstanceUIDs), len(out_SeriesInstanceUIDs))\n    print(\"MODE: test Size: {}\".format(len(out_StudyInstanceUIDs)))\n\n    out_dict = {\n        \"embeddings\": out_embs,\n        \"StudyInstanceUID\": out_StudyInstanceUIDs,\n        \"SeriesInstanceUID\": out_SeriesInstanceUIDs,\n        \"SOPInstanceUID\": out_SOPInstanceUIDs\n    }\n    # print(out_dict)\n\n    output_filename = \"emb_test_embdim512\"\n    print(\"Embedding file name: {}\".format(output_filename))\n    np.savez_compressed(output_filename, **out_dict)\n    print(\"file Saved.\")\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if do_all:\n    preds_df = pd.DataFrame({\n        \"id\": test_df[\"SOPInstanceUID\"].values[:len(predictions)],\n        \"pred\" : predictions\n    })\n    print(preds_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test_loader, model\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"## Transformer Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols = [\n    \"negative_exam_for_pe\",\n    \"rv_lv_ratio_gte_1\",\n    \"rv_lv_ratio_lt_1\",\n    \"leftsided_pe\",\n    \"chronic_pe\",\n    \"rightsided_pe\",\n    \"acute_and_chronic_pe\",\n    \"central_pe\",\n    \"indeterminate\",\n]\n\nn_classes = 9\nbatch_size = 8\nnum_workers = os.cpu_count()\n\n# LSTM_UNITS = 512\nlr = 1e-5\nlrgamma = 0.95\nDECAY = 0.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transformer Test preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"tstmdf = pd.read_csv('test_metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntstmdf['SliceID'] = tstmdf[['SeriesInstanceUID', 'StudyInstanceUID']].apply(\n    lambda x: '{}__{}'.format(*x.tolist()), 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tstmdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nposcols = ['ImagePos{}'.format(i) for i in range(1, 4)]\ntstmdf[poscols] = pd.DataFrame(tstmdf['ImagePositionPatient']\\\n              .apply(lambda x: list(map(float, ast.literal_eval(x)))).tolist())\n\ntstmdf = tstmdf.sort_values(['SliceID']+poscols)\\\n                [['StudyInstanceUID', 'SliceID', 'SOPInstanceUID']+poscols].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tstmdf['seq'] = (tstmdf.groupby(['SliceID']).cumcount() + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tstmdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keepcols = ['StudyInstanceUID', 'SliceID', 'SOPInstanceUID', 'seq']\ntstmdf = tstmdf[keepcols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntest_emb_f = np.load(\"emb_test_embdim512.npz\")\n\ntest_emb = test_emb_f[\"embeddings\"]\ntstdf = pd.DataFrame({\n    \"StudyInstanceUID\": test_emb_f[\"StudyInstanceUID\"], \n    \"SeriesInstanceUID\": test_emb_f[\"SeriesInstanceUID\"],\n    \"SOPInstanceUID\": test_emb_f[\"SOPInstanceUID\"]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tstdf = tstdf[[\"SOPInstanceUID\"]].merge(tstmdf, on=\"SOPInstanceUID\", how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tstdf.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tstdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tstdf['embidx'] = range(tstdf.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tstdf.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tstdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test_df, tstmdf\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class PEDataset(data.Dataset):\n    def __init__(self, df, mat, labels=True):\n        self.data = df\n        self.mat = mat\n        self.labels = labels\n        self.patients = df.SliceID.unique()\n        self.data = self.data.set_index('SliceID')\n\n    def __len__(self):\n        return len(self.patients)\n\n    def __getitem__(self, idx):\n        patidx = self.patients[idx]\n        study_id = self.data.loc[patidx][\"StudyInstanceUID\"].values[0]\n        # print(study_id)\n        patdf = self.data.loc[patidx].sort_values('seq')\n        patemb = self.mat[patdf['embidx'].values]\n\n        patdeltalag  = np.zeros(patemb.shape)\n        patdeltalead = np.zeros(patemb.shape)\n        patdeltalag[1:] = patemb[1:] - patemb[:-1]\n        patdeltalead[:-1] = patemb[:-1] - patemb[1:]\n\n        patemb = np.concatenate((patemb, patdeltalag, patdeltalead), -1)\n        # print(patemb.shape)\n        \n        ids = torch.tensor(patdf['embidx'].values)\n        \n        assert len(patemb) == len(ids), \"emb size: {} id size: {}\".format(len(patemb), len(ids))\n        \n        if self.labels:\n            labels = torch.tensor(patdf[label_cols].values[0])\n            return {'emb': patemb, 'embidx' : ids, 'labels': labels, \"StudyInstanceUID\": study_id}    \n        else:      \n            return {'emb': patemb, 'embidx' : ids, \"StudyInstanceUID\": study_id}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collatefn(batch):\n    maxlen = max([l['emb'].shape[0] for l in batch])\n    embdim = batch[0]['emb'].shape[1]\n    withlabel = 'labels' in batch[0]\n#     if withlabel:\n#         labdim = batch[0]['labels'].shape[1]\n        \n    for b in batch:\n        masklen = maxlen-len(b['emb'])\n        b['emb'] = np.vstack((np.zeros((masklen, embdim)), b['emb']))\n        b['embidx'] = torch.cat((torch.ones((masklen),dtype=torch.long)*-1, b['embidx']))\n        b['mask'] = np.ones((maxlen))\n        b['mask'][:masklen] = 0.\n#         if withlabel:\n#             b['labels'] = np.vstack((np.zeros((maxlen-len(b['labels']), labdim)), b['labels']))\n            \n    outbatch = {'emb' : torch.tensor(np.vstack([np.expand_dims(b['emb'], 0) \\\n                                                for b in batch])).float()}  \n    outbatch['mask'] = torch.tensor(np.vstack([np.expand_dims(b['mask'], 0) \\\n                                                for b in batch])).float()\n    outbatch['embidx'] = torch.tensor(np.vstack([np.expand_dims(b['embidx'], 0) \\\n                                                for b in batch])).float()\n    if withlabel:\n        # outbatch['labels'] = torch.tensor(np.vstack([np.expand_dims(b['labels'], 0) for b in batch])).float()\n        outbatch[\"labels\"] = torch.tensor(np.vstack([b[\"labels\"] for b in batch])).float()\n    \n    outbatch[\"StudyInstanceUID\"] = [b[\"StudyInstanceUID\"] for b in batch]\n    return outbatch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = PEDataset(tstdf, test_emb, labels=False)\ntest_loader = data.DataLoader(test_dataset, \n                              batch_size=batch_size, \n                              shuffle=False, \n                              num_workers=num_workers, \n                              collate_fn=collatefn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transformer Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, dropout=0.1, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return self.dropout(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PETransformerModel(nn.Module):\n    def __init__(self, n_classes, ninp, nhead, nhid, nlayers, dropout=0.5):\n        super(PETransformerModel, self).__init__()\n        self.pos_encoder = PositionalEncoding(ninp, dropout)\n        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n        self.ninp = ninp\n        self.decoder = nn.Linear(ninp, n_classes)\n        \n        self.init_weigths()\n    \n    def init_weigths(self):\n        initrange = 0.1\n        self.decoder.bias.data.zero_()\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n        \n    def forward(self, x):\n        x = x * math.sqrt(self.ninp)\n        x = self.pos_encoder(x)\n        hidden = self.transformer_encoder(x)\n        # print(hidden.size())\n        output = self.decoder(hidden.mean(1))\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nhid = 768\nnlayers = 2\nnhead = 2\ndropout = 0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_size = test_emb.shape[-1] * 3\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = PETransformerModel(n_classes, embed_size, nhead, nhid, nlayers, dropout=dropout)\ncheckpoint = torch.load(\"../input/pe-transformer-model/transformer_epoch15.pth\", map_location=device)\nmodel.load_state_dict(checkpoint)\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = [\n    \"{}_negative_exam_for_pe\",\n    \"{}_rv_lv_ratio_gte_1\",\n    \"{}_rv_lv_ratio_lt_1\",\n    \"{}_leftsided_pe\",\n    \"{}_chronic_pe\",\n    \"{}_rightsided_pe\",\n    \"{}_acute_and_chronic_pe\",\n    \"{}_central_pe\",\n    \"{}_indeterminate\",\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/rsna-str-pulmonary-embolism-detection/sample_submission.csv\")\nprint(sub.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\npreds_all_df = []\n\nif do_all:\n    tqdm_loader = tqdm(test_loader)\n    for step, batch in enumerate(tqdm_loader):\n        mask = batch['mask'].to(device, dtype=torch.int)\n        inputs = batch[\"emb\"]\n        inputs = inputs.to(device, dtype=torch.float, non_blocking=True)\n        StudyInstanceUIDs = batch[\"StudyInstanceUID\"]\n        # print(StudyInstanceUIDs)\n        \n        with torch.no_grad():\n            logits = model(inputs)\n            preds = torch.sigmoid(logits).detach().cpu().numpy()\n            \n            for i, pred in enumerate(preds):\n                StudyInstanceUID = StudyInstanceUIDs[i]\n                id_names = [c.format(StudyInstanceUID) for c in classes]\n                tmp_df = pd.DataFrame({\"id\": id_names, \"pred\": pred.tolist()})\n                preds_all_df.append(tmp_df)\n    \n    preds_all_df.append(preds_df)\n    pred_sub = pd.concat(preds_all_df, 0)\n    sub = sub.merge(pred_sub, on=\"id\", how=\"left\")\n    sub = sub[[\"id\", \"pred\"]]\n    sub.columns = [\"id\", \"label\"]\n    print(sub.isna().sum())\n    sub = sub.fillna(0.5)\n    sub.to_csv(\"submission.csv\", index=False)\nelse:\n    sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}