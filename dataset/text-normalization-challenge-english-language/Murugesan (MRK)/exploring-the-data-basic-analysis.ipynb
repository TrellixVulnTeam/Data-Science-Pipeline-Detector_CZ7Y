{"nbformat_minor":1,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"nbconvert_exporter":"python","mimetype":"text/x-python","name":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","pygments_lexer":"ipython3","version":"3.6.2"}},"cells":[{"source":"import os\nimport pandas as pd\nimport numpy as np\nimport random\nfrom matplotlib import pyplot as plt\nimport plotly.plotly as py\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nimport seaborn as sns\n\n%matplotlib inline","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"train_text = pd.read_csv(\"../input/en_train.csv\")","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"##Checking Null values\nprint(\"Null values\\n\")\nprint(train_text.isnull().sum(axis = 0))\nprint(\"Total non-null values per column\\n\")\nprint(train_text.count())","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"train_text[train_text['before'].isnull()].head(10)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#Getting the location of tokens with NaN values. Mostly they appear at the beginning of the sentence\nplt.hist(train_text[train_text['before'].isnull()]['token_id'])","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#Analysing the dataframe\nprint(train_text.dtypes)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"print(train_text.head())\nprint(train_text.tail())","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"train_text['class'].value_counts()\n\n#This shows the unique classes and the count of each class\n#Clearly Plain token dominates everything else","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"train_text['change'] = train_text['before'] != train_text['after']\ntrain_text['change'].value_counts()\n\n#Less han 10% of the data get normalized","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### Looking at the classes where there are token changes","metadata":{},"cell_type":"markdown"},{"source":"train_text[train_text['change'] == True]['class'].value_counts()\n\n#Interestingly Plain is not the highest here, and all the Date and Cardinal fields are changing","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### Distribution analysis","metadata":{},"cell_type":"markdown"},{"source":"random.seed(0)\ntrain_sample = train_text","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### Class analysis","metadata":{},"cell_type":"markdown"},{"source":"class_value = train_sample['class'].value_counts()\ntrain_sample['class'].value_counts().plot(kind  = \"bar\")","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"np.log(train_sample['class'].value_counts()).plot(kind  = \"bar\")","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### Aggregating data by class and change column and analysing","metadata":{},"cell_type":"markdown"},{"source":"agg_count = train_sample.loc[:,['class','change']].groupby(['class','change'])['class'].count()\nagg_count = agg_count.unstack(1)\nagg_count_log = np.log(agg_count).unstack(1)\n\n\nagg_count['Total']= agg_count[True].fillna(0) + agg_count[False].fillna(0)\n\nagg_count.sort_values([0],ascending = [0]).plot(kind = \"bar\", title = \"Analysis in terms of absolute values\")\n\nnp.log(agg_count).sort_values([0],ascending = [0]).plot(kind = \"bar\", title = \"Analysis in log scale\")","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### Observations: Punctuations don't get normalized while the other groups from Address to Time, even though they are small in absolute number, almost of them are normalized","metadata":{},"cell_type":"markdown"},{"source":"((agg_count/ agg_count['Total'].sum(axis = 0)) * 100).sort_values(['Total'], ascending = [0]).fillna(0)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### There seems to be no change in the Puntucations and the major changes are in Date, Letters and Cardinal","metadata":{},"cell_type":"markdown"},{"source":"### Token analysis","metadata":{},"cell_type":"markdown"},{"source":"plt.hist(train_sample['token_id'], log = True, bins = 100);\n#Note: we have transformed the scale to log","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### Closer anlaysis of sentences with lesser tokens","metadata":{},"cell_type":"markdown"},{"source":"token_hist = plt.hist(train_sample['token_id'][train_sample['token_id'] < 50], bins = 100);","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"percent = ((token_hist[0]/train_sample.shape[0]) * 100)\n\nfor i in range(5):\n    percent_data = round(sum(percent[0:((i+1)*10)]),2)\n    token_size = token_hist[1][(i+1)*10]\n    \n    print(percent_data, \"% of data with tokens less than \" ,round(token_size))","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### Analysing of tokens within a class","metadata":{},"cell_type":"markdown"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(18,10)\nsns.boxplot( y ='token_id', x = 'class', data = train_sample , linewidth = 2)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### Log scale - closer analysis","metadata":{},"cell_type":"markdown"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(18,10)\nsns.boxplot( y =np.log(train_sample['token_id']), x = 'class', data = train_sample , linewidth = 2)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### Plain, Punctuation and Verbatim ususally have higher token values\n#### Telephone mostly appears at the beginning of the sentence","metadata":{},"cell_type":"markdown"},{"source":"max_token = pd.DataFrame(train_sample[['class','sentence_id','token_id']].\n                         groupby(['sentence_id'])['token_id'].agg({'max_token':'max'}))","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"train_sample_token = pd.merge(left = train_sample, right = max_token, right_index = True, how = 'left', left_on = 'sentence_id')\n\ntrain_sample_token['relative_position'] = (train_sample_token['token_id'])/(train_sample_token['max_token'])\n","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(18,10)\nsns.boxplot( y ='relative_position', x = 'class', data = train_sample_token , linewidth = 2)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### Certainly punctuations should appear at the end of the sentance, and it is how it is in the training data set. Telephone number seems to occur relatively at the beginning of the sentence.","metadata":{},"cell_type":"markdown"},{"source":"### Analysing the changed tokens","metadata":{},"cell_type":"markdown"},{"source":"train_sample_change = train_sample[train_sample['change'] == True]","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"train_sample_change['class'].unique()","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### Analysing each class - Word clouds\n### Date","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'DATE' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head())\nprint(train_wc.tail())\n#Note: All of the date format is changed in the output","metadata":{"scrolled":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)))\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000,background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)))\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"#### Note: Few of the normalization is seen as twenty eleven and few as two thousand and eleven","metadata":{},"cell_type":"markdown"},{"source":"### Letters","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'LETTERS' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head())\nprint(train_wc.tail())\n#Note: All of the letter format is changed in the output","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)))\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000,background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)))\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### Cardinal","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'CARDINAL' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head())\nprint(train_wc.tail())\n#Note: There are numbers/roman numerals","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)))\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000,background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)))\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### PLAIN","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'PLAIN' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head(10))\nprint(train_wc.tail(10))\n#Note: There are numbers/roman numerals","metadata":{"scrolled":false},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)))\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000, background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)))\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### VERBATIM","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'VERBATIM' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head(10))\nprint(train_wc.tail(10))","metadata":{"scrolled":false},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)).strip())\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000, background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)).strip())\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### MEASURE","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'MEASURE' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head(10))\nprint(train_wc.tail(10))\n#Note: There are numbers/roman numerals","metadata":{"scrolled":false},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)))\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000, background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)))\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### ORDINAL","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'ORDINAL' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head(10))\nprint(train_wc.tail(10))\n#Note: There are numbers/roman numerals","metadata":{"scrolled":false},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)))\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000,background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)))\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### DECIMAL","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'DECIMAL' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head(10))\nprint(train_wc.tail(10))\n#Note: There are numbers/roman numerals","metadata":{"scrolled":false},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)))\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000,background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)))\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### MONEY","metadata":{},"cell_type":"markdown"},{"source":"#Sample of date class\nclass_val = 'MONEY' \n\ntrain_wc = train_sample_change[train_sample_change['class'] == class_val]\ntrain_all_wc = train_sample[train_sample['class'] == class_val]\n\nprint(train_wc.head(10))\nprint(train_wc.tail(10))\n#Note: There are numbers/roman numerals","metadata":{"scrolled":false},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"fig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC_all = WordCloud(width = 2000, height = 1000).generate(' '.join(train_all_wc['before'].astype(str)))\nplt.imshow(WC_all)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,10)\nrandom.seed(0)\nWC = WordCloud(width = 2000, height = 1000,background_color = \"white\").generate(' '.join(train_wc['after'].astype(str)))\nplt.imshow(WC)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"### -Work in progress","metadata":{},"cell_type":"markdown"},{"source":"","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"}],"nbformat":4}