{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python","version":"3.6.3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1,"cells":[{"metadata":{"collapsed":true},"source":"","cell_type":"code","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4e4d8917-87bd-4c7d-b530-8c5e8354a13d","_kg_hide-input":true,"_uuid":"29c9d02c4c9e86617f09c8840263f82ed3ac6bc3"},"source":"import numpy as np\nimport os\nimport pickle\nimport gc #garabag collection\nimport xgboost as xgb\nimport re\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n#max_num_features = 10\n#pad_size = 1\n#boundary_letter = -1\n#space_letter = 0\nmax_data_size = 960000\nmax_num_features = 10\n\ndef ascii(x, max_num_features = 10, space_letter = 0):\n    try:\n        t = map(ord, x[0])\n    except:\n        return max_num_features*[space_letter] + [-1]\n    l = min(len(t), max_num_features)\n    return t[:l] + (max_num_features-l)*[space_letter] + [x[-1]]\n\ndef context_window(data, pad_pre = 1, pad_pos = 1, boundary_letter = -1):\n    #pad_before: num of words before\n    new_data = []\n    pad = max_num_features*[0] + [-1]\n    emp = [boundary_letter]+(max_num_features)*[0]\n    data = [pad for i in range(pad_pre)] + data + [pad for i in range(pad_pos)]\n    for i in range(pad_pre, len(data) - pad_pos):\n        l = data[i][-1]\n        t, tmp = [], []\n        for j in range(i-pad_pre, i+pad_pos+1):\n            if data[j][boundary_letter] == l:\n                tmp += [j]\n                t += [boundary_letter] + data[j][:-1]\n        new_data.append(emp*(tmp[0]-i+pad_pre) + t + emp*(i+pad_pos-tmp[-1])+[boundary_letter])\n    return new_data\n\nout_path = r'.'\ndf = pd.read_csv(r'en_train.csv')\ngc.collect()\n#sentence_id + ascii\nx_data = map(ascii, [[df['before'][i],df['sentence_id'][i]] for i in range(max_data_size)]) \ngc.collect()\nx_data = x_data[:max_data_size]\nx_data = np.array(context_window(x_data))\n\ny_data =  pd.factorize(df['class'])\nlabels = y_data[1]\ny_data = np.array(y_data[0][:max_data_size])","cell_type":"code","execution_count":null,"outputs":[]}]}