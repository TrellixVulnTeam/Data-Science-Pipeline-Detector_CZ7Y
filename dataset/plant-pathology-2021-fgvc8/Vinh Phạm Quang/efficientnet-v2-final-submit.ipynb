{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import MultiLabelBinarizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T07:53:59.056632Z","iopub.execute_input":"2021-11-28T07:53:59.058357Z","iopub.status.idle":"2021-11-28T07:54:05.091436Z","shell.execute_reply.started":"2021-11-28T07:53:59.058311Z","shell.execute_reply":"2021-11-28T07:54:05.090254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEIGHT = 480\nWIDTH = 480\nCHANNELS = 3\nCLASSES = 6\ntop_dropout_rate = 0.2","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:53:56.942461Z","iopub.execute_input":"2021-11-28T07:53:56.943257Z","iopub.status.idle":"2021-11-28T07:53:56.961399Z","shell.execute_reply.started":"2021-11-28T07:53:56.943132Z","shell.execute_reply":"2021-11-28T07:53:56.960698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_path = \"../input/efficientnetv2model/EfficientNet_V2.h5\"\nhub_url = '../input/efficientnetv2-tfhub-weight-files/tfhub_models/efficientnetv2-l-21k-ft1k/feature_vector'","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:05.107595Z","iopub.execute_input":"2021-11-28T07:54:05.108187Z","iopub.status.idle":"2021-11-28T07:54:05.118776Z","shell.execute_reply.started":"2021-11-28T07:54:05.10815Z","shell.execute_reply":"2021-11-28T07:54:05.117959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    model = tf.keras.Sequential([\n            tf.keras.layers.InputLayer(input_shape = [HEIGHT, WIDTH, CHANNELS]),\n            hub.KerasLayer(hub_url, trainable = True),\n            Dropout(top_dropout_rate, name = \"top_dropout\"),\n            Dense(CLASSES, activation = 'sigmoid')\n        ])\n    model.build((HEIGHT, WIDTH, CHANNELS))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:05.122784Z","iopub.execute_input":"2021-11-28T07:54:05.12306Z","iopub.status.idle":"2021-11-28T07:54:05.13489Z","shell.execute_reply.started":"2021-11-28T07:54:05.123025Z","shell.execute_reply":"2021-11-28T07:54:05.133839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.load_weights(weights_path)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:06.274945Z","iopub.execute_input":"2021-11-28T07:54:06.275256Z","iopub.status.idle":"2021-11-28T07:54:49.311105Z","shell.execute_reply.started":"2021-11-28T07:54:06.275204Z","shell.execute_reply":"2021-11-28T07:54:49.310327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = '../input/plant-pathology-2021-fgvc8/test_images'\nsubmission = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:49.313514Z","iopub.execute_input":"2021-11-28T07:54:49.313772Z","iopub.status.idle":"2021-11-28T07:54:49.346091Z","shell.execute_reply.started":"2021-11-28T07:54:49.313736Z","shell.execute_reply":"2021-11-28T07:54:49.345479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(image_id):\n    file_path = str(image_id)\n    img = cv2.imread(test_img+'/'+file_path)\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:49.34735Z","iopub.execute_input":"2021-11-28T07:54:49.347647Z","iopub.status.idle":"2021-11-28T07:54:49.35455Z","shell.execute_reply.started":"2021-11-28T07:54:49.347612Z","shell.execute_reply":"2021-11-28T07:54:49.353707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def insect_augmentation(image, n_insects = 2, dark_insect=False, p = 0.5, insects_folder='../input/insect/insect'):\n    aug_prob = random.random()\n    flag = False\n    if aug_prob < p:\n        flag = True\n        height, width, _ = image.shape  # target image width and height\n        insects_images = os.listdir(insects_folder)\n        img_shape = image.shape\n\n        for _ in range(n_insects):\n            insect = cv2.cvtColor(cv2.imread(os.path.join(insects_folder, random.choice(insects_images))), cv2.COLOR_RGB2BGR)\n            insect = cv2.flip(insect, random.choice([-1, 0, 1]))\n            insect = cv2.rotate(insect, random.choice([0, 1, 2]))\n            insect = cv2.resize(insect, (width, height))\n\n            h_height, h_width, _ = insect.shape  # insect image width and height\n            roi_ho = random.randint(0, image.shape[0] - insect.shape[0])\n            roi_wo = random.randint(0, image.shape[1] - insect.shape[1])\n            roi = image[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width]\n\n            # Creating a mask and inverse mask \n            img2gray = cv2.cvtColor(insect, cv2.COLOR_BGR2GRAY)\n            ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n            #mask_inv = cv2.cvtColor(cv2.bitwise_not(mask),cv2.COLOR_BGR2GRAY)\n            mask_inv = cv2.bitwise_not(mask)\n\n            # Now black-out the area of insect in ROI\n            img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n\n            # Take only region of insect from insect image.\n            if dark_insect:\n                img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n                insect_fg = cv2.bitwise_and(img_bg, img_bg, mask=mask)\n            else:\n                insect_fg = cv2.bitwise_and(insect, insect, mask=mask)\n\n            # Put insect in ROI and modify the target image\n            dst = cv2.add(img_bg, insect_fg, dtype = cv2.CV_64F)\n\n            image[roi_ho:roi_ho + h_height, roi_wo:roi_wo + h_width] = dst\n\n\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:49.356783Z","iopub.execute_input":"2021-11-28T07:54:49.35708Z","iopub.status.idle":"2021-11-28T07:54:49.371904Z","shell.execute_reply.started":"2021-11-28T07:54:49.357044Z","shell.execute_reply":"2021-11-28T07:54:49.371155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_full_augment(image):\n    \n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n     # Insect\n    n = random.randint(1, 2)\n    image = insect_augmentation(image, n_insects = n, dark_insect=False, p = 0.2)\n\n    # Pixel-level transforms\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n\n\n\n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90\n\n        \n    # Crops\n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.8)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.9)\n\n    elif p_crop > .4:\n        HEIGHT1 = image.shape[0]\n        WIDTH1 = image.shape[1]\n        crop_size_h = tf.random.uniform([], int(HEIGHT1*.8), HEIGHT1, dtype=tf.float32)\n        crop_size_w = tf.random.uniform([], int(WIDTH1*.8), WIDTH1, dtype=tf.float32)\n        image = tf.image.random_crop(image, size=[crop_size_h, crop_size_w, 3])\n\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:49.373431Z","iopub.execute_input":"2021-11-28T07:54:49.373695Z","iopub.status.idle":"2021-11-28T07:54:49.388888Z","shell.execute_reply.started":"2021-11-28T07:54:49.37366Z","shell.execute_reply":"2021-11-28T07:54:49.388034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process(img):\n    img = data_full_augment(img)\n    img = tf.cast(img, tf.float32) / 255.0\n    img = np.array(img)\n    return cv2.resize(img , (HEIGHT, WIDTH)).reshape(-1, HEIGHT, WIDTH, 3)\ndef predict(img):\n    img = load_image(img)\n    tta_steps = 5\n    predictions = []\n    for i in range(tta_steps):\n        pred = model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n        predictions.append(pred)\n    result = np.median(predictions, axis=0)\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:49.392181Z","iopub.execute_input":"2021-11-28T07:54:49.392613Z","iopub.status.idle":"2021-11-28T07:54:49.401366Z","shell.execute_reply.started":"2021-11-28T07:54:49.392577Z","shell.execute_reply":"2021-11-28T07:54:49.400585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_label = ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']\nlabel = []\nfor i in range(len(submission['image'])):\n    test_images = submission['image'][i]\n    preds = predict(test_images)\n    answer = []\n    for j in range(len(preds)):\n        if preds[j] > 0.09:\n            answer.append(n_label[j])\n    answer = ' '.join(answer)\n    label.append(answer)\nsubmission['labels'] = label\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:54:49.40263Z","iopub.execute_input":"2021-11-28T07:54:49.402916Z","iopub.status.idle":"2021-11-28T07:55:04.772679Z","shell.execute_reply.started":"2021-11-28T07:54:49.40288Z","shell.execute_reply":"2021-11-28T07:55:04.772016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T07:55:20.316147Z","iopub.execute_input":"2021-11-28T07:55:20.316989Z","iopub.status.idle":"2021-11-28T07:55:20.32481Z","shell.execute_reply.started":"2021-11-28T07:55:20.316953Z","shell.execute_reply":"2021-11-28T07:55:20.32379Z"},"trusted":true},"execution_count":null,"outputs":[]}]}