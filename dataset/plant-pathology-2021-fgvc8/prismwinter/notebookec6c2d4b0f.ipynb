{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#adapted from \n#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n\nimport os\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as T\nimport torch\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nfrom torchvision.utils import save_image\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport torch.optim as optim\nimport time\nfrom PIL import Image\nimport pandas as pd\n\nstart = time.time()\n\ntrain_image_path = '../input/resized-plant2021/img_sz_256/' #uses smaller version of dataset for efficiency\ntest_image_path = '../input/plant-pathology-2021-fgvc8/test_images/'\ntrain_df_path = '../input/plant-pathology-2021-fgvc8/train.csv'\ntest_df_path = '../input/plant-pathology-2021-fgvc8/sample_submission.csv'\n\ntrain_df = pd.read_csv(train_df_path)\n\nclasses_ = train_df.labels.unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T02:05:52.237539Z","iopub.execute_input":"2021-12-05T02:05:52.238472Z","iopub.status.idle":"2021-12-05T02:05:52.280361Z","shell.execute_reply.started":"2021-12-05T02:05:52.238431Z","shell.execute_reply":"2021-12-05T02:05:52.279091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PlantDataSet(Dataset):\n    def __init__(self, main_dir, transform):\n        self.main_dir = main_dir\n        self.transform = transform\n        self.all_imgs = os.listdir(main_dir)\n\n    def __len__(self):\n        return len(self.all_imgs)\n\n    def __getitem__(self, idx):\n        img_loc = os.path.join(self.main_dir, self.all_imgs[idx])\n        image = Image.open(img_loc).convert(\"RGB\")\n        tensor_image = self.transform(image)\n        label = classes_.index(train_df.iloc[idx]['labels'])\n        return tensor_image, label","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:42:53.797301Z","iopub.execute_input":"2021-12-05T01:42:53.79762Z","iopub.status.idle":"2021-12-05T01:42:53.805922Z","shell.execute_reply.started":"2021-12-05T01:42:53.797578Z","shell.execute_reply":"2021-12-05T01:42:53.804714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.RandomHorizontalFlip(),\n     transforms.RandomResizedCrop(256),\n     transforms.ToTensor()])\n\nBATCH_SIZE = 256\n\nmy_dataset = PlantDataSet(train_image_path, transform=transform)\ntrain_loader = DataLoader(my_dataset , batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:42:53.807892Z","iopub.execute_input":"2021-12-05T01:42:53.808546Z","iopub.status.idle":"2021-12-05T01:42:53.83025Z","shell.execute_reply.started":"2021-12-05T01:42:53.808493Z","shell.execute_reply":"2021-12-05T01:42:53.828904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(59536, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 12)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-05T01:42:53.831906Z","iopub.execute_input":"2021-12-05T01:42:53.832187Z","iopub.status.idle":"2021-12-05T01:42:53.893991Z","shell.execute_reply.started":"2021-12-05T01:42:53.832155Z","shell.execute_reply":"2021-12-05T01:42:53.892959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(10):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, torch.tensor(labels))\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')\n\nPATH = './cifar_net.pth'\ntorch.save(net.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T01:42:53.896904Z","iopub.execute_input":"2021-12-05T01:42:53.897508Z","iopub.status.idle":"2021-12-05T01:56:47.565706Z","shell.execute_reply.started":"2021-12-05T01:42:53.897455Z","shell.execute_reply":"2021-12-05T01:56:47.564595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = Net()\nnet.load_state_dict(torch.load(PATH))\n\nmy_dataset = PlantDataSet(test_image_path, transform=transform)\ntestloader = DataLoader(my_dataset , batch_size=256)\n\npreds = []\n\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        # calculate outputs by running images through the network\n        outputs = net(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        for pred in predicted:\n            preds.append(classes_[pred])\n        \ntest_df = pd.read_csv(test_df_path)\ntest_df['labels'] = preds\ntest_df.to_csv('submission.csv', index=False)\n\nend = time.time()\nprint(end - start)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T02:07:00.277826Z","iopub.execute_input":"2021-12-05T02:07:00.278485Z","iopub.status.idle":"2021-12-05T02:07:01.132325Z","shell.execute_reply.started":"2021-12-05T02:07:00.278438Z","shell.execute_reply":"2021-12-05T02:07:01.13139Z"},"trusted":true},"execution_count":null,"outputs":[]}]}