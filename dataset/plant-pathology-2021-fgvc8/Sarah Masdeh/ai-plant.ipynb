{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport cv2\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T00:55:34.653505Z","iopub.execute_input":"2021-06-02T00:55:34.653984Z","iopub.status.idle":"2021-06-02T00:55:35.58682Z","shell.execute_reply.started":"2021-06-02T00:55:34.653889Z","shell.execute_reply":"2021-06-02T00:55:35.585877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from cycler import cycler\nimport matplotlib as mpl\n\nraw_light_palette = [\n    (0, 122, 255), # Blue\n    (255, 149, 0), # Orange\n    (52, 199, 89), # Green\n    (255, 59, 48), # Red\n    (175, 82, 222),# Purple\n    (255, 45, 85), # Pink\n    (88, 86, 214), # Indigo\n    (90, 200, 250),# Teal\n    (255, 204, 0)  # Yellow\n]\nraw_dark_palette = [\n    (10, 132, 255), # Blue\n    (255, 159, 10), # Orange\n    (48, 209, 88),  # Green\n    (255, 69, 58),  # Red\n    (191, 90, 242), # Purple\n    (94, 92, 230),  # Indigo\n    (255, 55, 95),  # Pink\n    (100, 210, 255),# Teal\n    (255, 214, 10)  # Yellow\n]\nraw_gray_light_palette = [\n    (142, 142, 147),# Gray\n    (174, 174, 178),# Gray (2)\n    (199, 199, 204),# Gray (3)\n    (209, 209, 214),# Gray (4)\n    (229, 229, 234),# Gray (5)\n    (242, 242, 247),# Gray (6)\n]\nraw_gray_dark_palette = [\n    (142, 142, 147),# Gray\n    (99, 99, 102),  # Gray (2)\n    (72, 72, 74),   # Gray (3)\n    (58, 58, 60),   # Gray (4)\n    (44, 44, 46),   # Gray (5)\n    (28, 28, 39),   # Gray (6)\n]\n\nlight_palette = np.array(raw_light_palette)/255\ndark_palette = np.array(raw_dark_palette)/255\ngray_light_palette = np.array(raw_gray_light_palette)/255\ngray_dark_palette = np.array(raw_gray_dark_palette)/255\n\nmpl.rcParams['axes.prop_cycle'] = cycler('color',dark_palette)\nmpl.rcParams['figure.facecolor']  = gray_dark_palette[-2]\nmpl.rcParams['figure.edgecolor']  = gray_dark_palette[-2]\nmpl.rcParams['axes.facecolor'] =  gray_dark_palette[-2]\n\nwhite_color = gray_light_palette[-2]\nmpl.rcParams['text.color'] = white_color\nmpl.rcParams['axes.labelcolor'] = white_color\nmpl.rcParams['axes.edgecolor'] = white_color\nmpl.rcParams['xtick.color'] = white_color\nmpl.rcParams['ytick.color'] = white_color\n\nmpl.rcParams['figure.dpi'] = 200\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right'] = False\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:55:35.588177Z","iopub.execute_input":"2021-06-02T00:55:35.58846Z","iopub.status.idle":"2021-06-02T00:55:35.59989Z","shell.execute_reply.started":"2021-06-02T00:55:35.588403Z","shell.execute_reply":"2021-06-02T00:55:35.5989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list with the filepaths for training and testing\ntrain_img_Path = '../input/plant-pathology-2021-fgvc8/train_images'\n\ntest_img_Path = '../input/plant-pathology-2021-fgvc8/test_images'\n\nimg_Path = '../input/resized-plant2021/img_sz_256'\n#samples=500, nrows=samples)\ntrain = pd.read_csv(r'../input/plant-pathology-2021-fgvc8/train.csv')\n\nsample_submission = pd.read_csv(r'../input/plant-pathology-2021-fgvc8/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:55:35.601418Z","iopub.execute_input":"2021-06-02T00:55:35.601713Z","iopub.status.idle":"2021-06-02T00:55:35.662507Z","shell.execute_reply.started":"2021-06-02T00:55:35.601686Z","shell.execute_reply":"2021-06-02T00:55:35.661621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:55:35.664104Z","iopub.execute_input":"2021-06-02T00:55:35.664463Z","iopub.status.idle":"2021-06-02T00:55:35.688266Z","shell.execute_reply.started":"2021-06-02T00:55:35.66441Z","shell.execute_reply":"2021-06-02T00:55:35.687454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['labels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:55:35.689284Z","iopub.execute_input":"2021-06-02T00:55:35.689553Z","iopub.status.idle":"2021-06-02T00:55:35.701446Z","shell.execute_reply.started":"2021-06-02T00:55:35.689525Z","shell.execute_reply":"2021-06-02T00:55:35.700688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,7))\nb = sns.countplot(x='labels', data=train, order=sorted(train['labels'].unique()))\nfor item in b.get_xticklabels():\n    item.set_rotation(90)\nplt.title('Label Distribution', weight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:55:35.702387Z","iopub.execute_input":"2021-06-02T00:55:35.702664Z","iopub.status.idle":"2021-06-02T00:55:36.182089Z","shell.execute_reply.started":"2021-06-02T00:55:35.702639Z","shell.execute_reply":"2021-06-02T00:55:36.181477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,40))\ni=1\nfor idx,s in train.head(9).iterrows():\n    img_path = os.path.join(img_Path,s['image'])\n    img=cv2.imread(img_path)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    fig=plt.subplot(9,3,i)\n    fig.imshow(img)\n    fig.set_title(s['labels'])\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:55:36.183034Z","iopub.execute_input":"2021-06-02T00:55:36.183396Z","iopub.status.idle":"2021-06-02T00:55:38.598417Z","shell.execute_reply.started":"2021-06-02T00:55:36.183361Z","shell.execute_reply":"2021-06-02T00:55:38.597414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASSES = train['labels'].unique().tolist()\nprint(CLASSES)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:55:38.600986Z","iopub.execute_input":"2021-06-02T00:55:38.601325Z","iopub.status.idle":"2021-06-02T00:55:38.608019Z","shell.execute_reply.started":"2021-06-02T00:55:38.601292Z","shell.execute_reply":"2021-06-02T00:55:38.607203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n# Preprocessing the Training set\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   shear_range = 0.1,\n                                   zoom_range = 0.1,\n                                   horizontal_flip = True,\n                                   validation_split=0.25)\n\ntrain_data = train_datagen.flow_from_dataframe(train,\n                                              directory=img_Path,\n                                              classes=CLASSES,\n                                              x_col=\"image\",\n                                              y_col=\"labels\",\n                                              target_size=(150, 150),\n                                              subset='training')\n\nval_data = train_datagen.flow_from_dataframe(train,\n                                            directory=img_Path,\n                                            classes=CLASSES,\n                                            x_col=\"image\",\n                                            y_col=\"labels\",\n                                            target_size=(150, 150),\n                                            subset='validation')\nprint(len(CLASSES))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:55:38.61036Z","iopub.execute_input":"2021-06-02T00:55:38.610704Z","iopub.status.idle":"2021-06-02T00:56:34.494248Z","shell.execute_reply.started":"2021-06-02T00:55:38.610671Z","shell.execute_reply":"2021-06-02T00:56:34.493488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_classes = train_data.class_indices\ndict_classes","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:56:34.495611Z","iopub.execute_input":"2021-06-02T00:56:34.496022Z","iopub.status.idle":"2021-06-02T00:56:34.501038Z","shell.execute_reply.started":"2021-06-02T00:56:34.495975Z","shell.execute_reply":"2021-06-02T00:56:34.500246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.applications import InceptionResNetV2, DenseNet169, ResNet152V2\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom sklearn.metrics import classification_report\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:56:34.5019Z","iopub.execute_input":"2021-06-02T00:56:34.502115Z","iopub.status.idle":"2021-06-02T00:56:34.712368Z","shell.execute_reply.started":"2021-06-02T00:56:34.502093Z","shell.execute_reply":"2021-06-02T00:56:34.711503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BS=128\nEPOCHS=20","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:56:34.713474Z","iopub.execute_input":"2021-06-02T00:56:34.713723Z","iopub.status.idle":"2021-06-02T00:56:34.717304Z","shell.execute_reply.started":"2021-06-02T00:56:34.713698Z","shell.execute_reply":"2021-06-02T00:56:34.716362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### VGG16","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input\n\nbase_VGG = VGG16(include_top = False, \n                weights = 'imagenet', \n                input_shape = train_data.image_shape, \n                pooling='avg',\n                classes = CLASSES)\n\n#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_VGG = Sequential()\nmodel_VGG.add(base_VGG)\nmodel_VGG.add(Dense(12, activation=('softmax')))\nmodel_VGG.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel_VGG.summary()\n\n\n# Training the CNN on the Train data and evaluating it on the val data\n# b = model_VGG.fit(train_data, validation_data = val_data, epochs = EPOCHS, batch_size=BS)\nH_VGG = model_VGG.fit(train_data, validation_data = val_data, epochs = EPOCHS, batch_size=BS)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T00:56:34.718366Z","iopub.execute_input":"2021-06-02T00:56:34.718636Z","iopub.status.idle":"2021-06-02T06:01:42.74988Z","shell.execute_reply.started":"2021-06-02T00:56:34.718612Z","shell.execute_reply":"2021-06-02T06:01:42.747437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H_VGG.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H_VGG.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H_VGG.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H_VGG.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.751166Z","iopub.status.idle":"2021-06-02T06:01:42.751763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(val_data.labels))\nprint(len(dict_classes))\npredIdxs_VGG = model_VGG.predict(val_data, batch_size=BS)\nprint(len(predIdxs_VGG))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.753057Z","iopub.status.idle":"2021-06-02T06:01:42.753487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs_VGG = model_VGG.predict(val_data, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs_VGG = np.argmax(predIdxs_VGG, axis=1)\n# show a nicely formatted classification report\nprint(classification_report(val_data.labels, predIdxs_VGG, labels=[0,1, 2, 3,4,5,6,7,8,9,10,11]))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.754262Z","iopub.status.idle":"2021-06-02T06:01:42.754633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\n\nprint (\"f1_score\",metrics.f1_score(val_data.labels, predIdxs_VGG, average='weighted', labels=np.unique(predIdxs_VGG)))\nprint (\"accuracy\",accuracy_score(val_data.labels, predIdxs_VGG))\nprint (\"recall_score\",recall_score(val_data.labels, predIdxs_VGG, average='micro'))\nprint (\"precision_score\",precision_score(val_data.labels, predIdxs_VGG, average='micro'))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.755731Z","iopub.status.idle":"2021-06-02T06:01:42.756075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ResNet152V2 ","metadata":{}},{"cell_type":"code","source":"base_Net = ResNet152V2(include_top = False, \n                         weights = '../input/keras-pretrained-models/ResNet152V2_NoTop_ImageNet.h5', \n                         input_shape = train_data.image_shape, \n                         pooling='avg',\n                         classes = CLASSES)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.75738Z","iopub.status.idle":"2021-06-02T06:01:42.757742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_ResNet = Sequential()\nmodel_ResNet.add(base_Net)\nmodel_ResNet.add(Dense(12, activation=('softmax')))\n\nmodel_ResNet.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel_ResNet.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\nH_ResNet152V2 = model_ResNet.fit(train_data, validation_data = val_data, epochs = EPOCHS, batch_size=BS)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.758792Z","iopub.status.idle":"2021-06-02T06:01:42.759156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H_ResNet152V2.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H_ResNet152V2.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H_ResNet152V2.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H_ResNet152V2.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.760155Z","iopub.status.idle":"2021-06-02T06:01:42.760535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions on the testing set\npredIdxs_ResNet = model_ResNet.predict(val_data, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs_ResNet = np.argmax(predIdxs_ResNet, axis=1)\n# show a nicely formatted classification report\n#we can use the target name nested of labels but it will give error because of sizes or labels=np.unique(predIdxs_VGG) buth appear onlt non zero classes\nprint(classification_report(val_data.labels, predIdxs_ResNet, labels=[0,1, 2, 3,4,5,6,7,8,9,10,11]))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.761529Z","iopub.status.idle":"2021-06-02T06:01:42.761884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\n\nprint (\"f1_score\",metrics.f1_score(val_data.labels, predIdxs_VGG, average='weighted', labels=np.unique(predIdxs_VGG)))\nprint (\"accuracy\",accuracy_score(val_data.labels, predIdxs_VGG))\nprint (\"recall_score\",recall_score(val_data.labels, predIdxs_VGG, average='micro'))\nprint (\"precision_score\",precision_score(val_data.labels, predIdxs_VGG, average='micro'))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.762811Z","iopub.status.idle":"2021-06-02T06:01:42.763161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####  InceptionResNetV2","metadata":{}},{"cell_type":"code","source":"base_InceptionResNetV2 = InceptionResNetV2(include_top = False, \n                         weights = '../input/keras-pretrained-models/InceptionResNetV2_NoTop_ImageNet.h5', \n                         input_shape = train_data.image_shape, \n                         pooling='avg',\n                         classes = CLASSES)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.764113Z","iopub.status.idle":"2021-06-02T06:01:42.764482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_INResNet2 = Sequential()\nmodel_INResNet2.add(base_InceptionResNetV2)\nmodel_INResNet2.add(Dense(12, activation=('softmax')))\n\nmodel_INResNet2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel_INResNet2.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\nH_INResNet = model_INResNet2.fit(train_data, validation_data = val_data, epochs = EPOCHS, batch_size=BS)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.765179Z","iopub.status.idle":"2021-06-02T06:01:42.765544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H_INResNet.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H_INResNet.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H_INResNet.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H_INResNet.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.766391Z","iopub.status.idle":"2021-06-02T06:01:42.766783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs_INResNet2 = model_INResNet2.predict(val_data, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs_INResNet2 = np.argmax(predIdxs_INResNet2, axis=1)\n# show a nicely formatted classification report\nprint(classification_report(val_data.labels, predIdxs_INResNet2, labels=[0,1, 2, 3,4,5,6,7,8,9,10,11]))\n##\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.767628Z","iopub.status.idle":"2021-06-02T06:01:42.768014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\n\nprint (\"f1_score\",metrics.f1_score(val_data.labels, predIdxs_VGG, average='weighted', labels=np.unique(predIdxs_VGG)))\nprint (\"accuracy\",accuracy_score(val_data.labels, predIdxs_VGG))\nprint (\"recall_score\",recall_score(val_data.labels, predIdxs_VGG, average='micro'))\nprint (\"precision_score\",precision_score(val_data.labels, predIdxs_VGG, average='micro'))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.7694Z","iopub.status.idle":"2021-06-02T06:01:42.769782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####  DenseNet169 ","metadata":{}},{"cell_type":"code","source":"base_DenseNet169 = DenseNet169(include_top = False, \n                         weights = '../input/keras-pretrained-models/DenseNet169_NoTop_ImageNet.h5', \n                         input_shape = train_data.image_shape, \n                         pooling='avg',\n                         classes = CLASSES)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.770565Z","iopub.status.idle":"2021-06-02T06:01:42.770923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_dense = Sequential()\nmodel_dense.add(base_DenseNet169)\nmodel_dense.add(Dense(12, activation=('softmax')))\n\nmodel_dense.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel_dense.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\nH_Dense = model_dense.fit(train_data, validation_data = val_data, epochs = EPOCHS, batch_size=BS)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.771701Z","iopub.status.idle":"2021-06-02T06:01:42.772059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H_Dense.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H_Dense.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H_Dense.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H_Dense.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on COVID-19 Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.772851Z","iopub.status.idle":"2021-06-02T06:01:42.773205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions on the testing set\nprint(\"[INFO] evaluating network...\")\npredIdxs_dense = model_dense.predict(val_data, batch_size=BS)\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs_dense = np.argmax(predIdxs_dense, axis=1)\n# show a nicely formatted classification report\nprint(classification_report(val_data.labels, predIdxs_dense, labels=[0,1, 2, 3,4,5,6,7,8,9,10,11]))\n##\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.773937Z","iopub.status.idle":"2021-06-02T06:01:42.774285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\n\nprint (\"f1_score\",metrics.f1_score(val_data.labels, predIdxs_VGG, average='weighted', labels=np.unique(predIdxs_VGG)))\nprint (\"accuracy\",accuracy_score(val_data.labels, predIdxs_VGG))\nprint (\"recall_score\",recall_score(val_data.labels, predIdxs_VGG, average='micro'))\nprint (\"precision_score\",precision_score(val_data.labels, predIdxs_VGG, average='micro'))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T06:01:42.775047Z","iopub.status.idle":"2021-06-02T06:01:42.775404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}