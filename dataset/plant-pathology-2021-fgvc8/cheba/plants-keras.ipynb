{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:05.399258Z","iopub.execute_input":"2022-01-25T18:06:05.399596Z","iopub.status.idle":"2022-01-25T18:06:05.422551Z","shell.execute_reply.started":"2022-01-25T18:06:05.399512Z","shell.execute_reply":"2022-01-25T18:06:05.421933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import NASNetLarge, ResNet101, DenseNet121\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tqdm.keras import TqdmCallback\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, ModelCheckpoint\n\nfrom keras.models import load_model\n\nprint(f'tf version - {tf.__version__}')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:06.28283Z","iopub.execute_input":"2022-01-25T18:06:06.283296Z","iopub.status.idle":"2022-01-25T18:06:11.319548Z","shell.execute_reply.started":"2022-01-25T18:06:06.283257Z","shell.execute_reply":"2022-01-25T18:06:11.31872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_PATH = '../input/plant-pathology-2021-224x224/train_imgs'","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:11.321269Z","iopub.execute_input":"2022-01-25T18:06:11.321525Z","iopub.status.idle":"2022-01-25T18:06:11.325513Z","shell.execute_reply.started":"2022-01-25T18:06:11.321491Z","shell.execute_reply":"2022-01-25T18:06:11.324911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:14.392464Z","iopub.execute_input":"2022-01-25T18:06:14.393046Z","iopub.status.idle":"2022-01-25T18:06:14.43921Z","shell.execute_reply.started":"2022-01-25T18:06:14.393005Z","shell.execute_reply":"2022-01-25T18:06:14.438554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train.labels.unique())","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:19.309577Z","iopub.execute_input":"2022-01-25T18:06:19.310297Z","iopub.status.idle":"2022-01-25T18:06:19.324496Z","shell.execute_reply.started":"2022-01-25T18:06:19.310257Z","shell.execute_reply":"2022-01-25T18:06:19.323695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nImage.open(os.path.join('../input/plant-pathology-2021-fgvc8/train_images', train[train.labels == 'rust'].image.iloc[0]))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:20.024518Z","iopub.execute_input":"2022-01-25T18:06:20.02526Z","iopub.status.idle":"2022-01-25T18:06:21.531167Z","shell.execute_reply.started":"2022-01-25T18:06:20.025219Z","shell.execute_reply":"2022-01-25T18:06:21.530396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:21.532525Z","iopub.execute_input":"2022-01-25T18:06:21.5328Z","iopub.status.idle":"2022-01-25T18:06:21.545563Z","shell.execute_reply.started":"2022-01-25T18:06:21.532761Z","shell.execute_reply":"2022-01-25T18:06:21.54501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASSES = train['labels'].unique().tolist()\nBATH_SIZE = 128\nEPOCH = 10","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:28.475376Z","iopub.execute_input":"2022-01-25T18:06:28.475632Z","iopub.status.idle":"2022-01-25T18:06:28.481203Z","shell.execute_reply.started":"2022-01-25T18:06:28.475603Z","shell.execute_reply":"2022-01-25T18:06:28.480483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_generator = ImageDataGenerator(\n    validation_split=0.15,\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:29.67909Z","iopub.execute_input":"2022-01-25T18:06:29.679675Z","iopub.status.idle":"2022-01-25T18:06:29.683359Z","shell.execute_reply.started":"2022-01-25T18:06:29.679627Z","shell.execute_reply":"2022-01-25T18:06:29.682485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_loader = data_generator.flow_from_dataframe(\n    train,\n    directory=IMAGE_PATH,\n    classes=CLASSES,\n    x_col=\"image\",\n    y_col=\"labels\",\n    target_size=(150, 150),\n    subset='training'\n)\n\nval_data_loader = data_generator.flow_from_dataframe(\n    train,\n    directory=IMAGE_PATH,\n    classes=CLASSES,\n    x_col=\"image\",\n    y_col=\"labels\",\n    target_size=(150, 150),\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:06:30.194986Z","iopub.execute_input":"2022-01-25T18:06:30.195729Z","iopub.status.idle":"2022-01-25T18:07:01.606232Z","shell.execute_reply.started":"2022-01-25T18:06:30.195685Z","shell.execute_reply":"2022-01-25T18:07:01.605517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_classes = train_data_loader.class_indices\ndict_classes","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:07:05.379179Z","iopub.execute_input":"2022-01-25T18:07:05.379439Z","iopub.status.idle":"2022-01-25T18:07:05.385095Z","shell.execute_reply.started":"2022-01-25T18:07:05.37941Z","shell.execute_reply":"2022-01-25T18:07:05.384447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nCALLBACKS = [ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=0.5, factor=0.5),\n             EarlyStopping(monitor='val_loss', verbose=1, patience=5),\n             TqdmCallback(verbose=0)]","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:07:05.817586Z","iopub.execute_input":"2022-01-25T18:07:05.818401Z","iopub.status.idle":"2022-01-25T18:07:05.865653Z","shell.execute_reply.started":"2022-01-25T18:07:05.818351Z","shell.execute_reply":"2022-01-25T18:07:05.864917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_resnet = ResNet101(\n                    weights='../input/keras-pretrained-models/ResNet101_NoTop_ImageNet.h5',\n                    include_top=False, \n                    pooling='avg', \n                    input_shape=(150, 150, 3))\n\nmodel_resnet = Sequential()\nmodel_resnet.add(base_resnet)\nmodel_resnet.add(layers.Dense(12, activation='softmax'))\n\nmodel_resnet.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy', 'Precision', 'Recall'])\nmodel_resnet.summary()\n\nhistory_resnet = model_resnet.fit(train_data_loader, \n                            validation_data=val_data_loader, \n                            batch_size=BATH_SIZE,\n                            epochs=9,\n                            callbacks=CALLBACKS)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:13:13.463092Z","iopub.execute_input":"2022-01-25T18:13:13.46339Z","iopub.status.idle":"2022-01-25T18:15:09.360466Z","shell.execute_reply.started":"2022-01-25T18:13:13.463359Z","shell.execute_reply":"2022-01-25T18:15:09.359784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_DenseNet121 = tf.keras.applications.DenseNet121(\n                    weights='../input/keras-pretrained-models/DenseNet121_NoTop_ImageNet.h5',\n                    include_top=False, \n                    pooling='avg', \n                    input_shape=(150, 150, 3))\n\nmodel_DenseNet121 = Sequential()\nmodel_DenseNet121.add(base_DenseNet121)\nmodel_DenseNet121.add(layers.Dense(12, activation='softmax'))\n\nmodel_DenseNet121.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\nmodel_DenseNet121.summary()\n\nhistory_DenseNet121 = model_DenseNet121.fit(train_data_loader, \n                                  validation_data=val_data_loader, \n                                  batch_size=BATH_SIZE,\n                                  epochs=15,\n                                  callbacks=CALLBACKS)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:15:09.362353Z","iopub.execute_input":"2022-01-25T18:15:09.362625Z","iopub.status.idle":"2022-01-25T18:16:35.085986Z","shell.execute_reply.started":"2022-01-25T18:15:09.362588Z","shell.execute_reply":"2022-01-25T18:16:35.085251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_MobileNetV2 = tf.keras.applications.MobileNetV2(\n                    weights='../input/keras-pretrained-models/MobileNetV2_NoTop_ImageNet.h5',\n                    include_top=False, \n                    pooling='avg', \n                    input_shape=(150, 150, 3))\n\nmodel_MobileNetV2 = Sequential()\nmodel_MobileNetV2.add(base_MobileNetV2)\nmodel_MobileNetV2.add(layers.Dense(12, activation='softmax'))\n\nmodel_MobileNetV2.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\nmodel_MobileNetV2.summary()\n\nhistory_MobileNetV2 = model_MobileNetV2.fit(train_data_loader, \n                                  validation_data=val_data_loader, \n                                  batch_size=BATH_SIZE,\n                                  epochs=15,\n                                  callbacks=CALLBACKS)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:16:35.087414Z","iopub.execute_input":"2022-01-25T18:16:35.087759Z","iopub.status.idle":"2022-01-25T18:17:38.612034Z","shell.execute_reply.started":"2022-01-25T18:16:35.087723Z","shell.execute_reply":"2022-01-25T18:17:38.611292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statistics\nfrom statistics import mode\n\n\ndef most_common(predict_list: list):\n    return(mode(predict_list))\n\n\ndef prepare_predicts(predicts: list):\n    for i in range(len(predicts)):\n        predicts[i] = np.argmax(predicts[i])\n    return predicts\n\n\ntest_dir = '/kaggle/input/plant-pathology-2021-fgvc8/test_images/'\ntest_df = pd.DataFrame({'image':os.listdir(test_dir)})\n\ntest_set = data_generator.flow_from_dataframe(dataframe=test_df,\n                                    directory=test_dir,\n                                    x_col=\"image\",\n                                    y_col=None,\n                                    batch_size=64,\n                                    seed=42,\n                                    shuffle=False,\n                                    class_mode=None,\n                                    target_size=(150,150))\n\npred_resnet = model_resnet.predict(test_set).tolist()\npred_densnet = model_DenseNet121.predict(test_set).tolist()\npred_mobile = model_MobileNetV2.predict(test_set).tolist()\n\npred_resnet = prepare_predicts(pred_resnet)\npred_densnet = prepare_predicts(pred_densnet)\npred_mobile = prepare_predicts(pred_mobile)\n                                                               \n\nres = []\n \nfor i in range(len(pred_resnet)):\n    try:\n        res.append(most_common([pred_resnet[i], pred_densnet[i], pred_mobile[i]]))\n    except:\n        res.append(pred_resnet[i])\n\n    \ndef get_key(val):\n    for key, value in dict_classes.items():\n        if val == value:\n            return key\n        \n\nfor i in range(len(res)):\n    res[i] = get_key(res[i])","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:17:42.856249Z","iopub.execute_input":"2022-01-25T18:17:42.856506Z","iopub.status.idle":"2022-01-25T18:17:50.149186Z","shell.execute_reply.started":"2022-01-25T18:17:42.856475Z","shell.execute_reply":"2022-01-25T18:17:50.148409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['labels'] = res\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:18:13.021949Z","iopub.execute_input":"2022-01-25T18:18:13.022205Z","iopub.status.idle":"2022-01-25T18:18:13.032256Z","shell.execute_reply.started":"2022-01-25T18:18:13.022179Z","shell.execute_reply":"2022-01-25T18:18:13.0315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T18:18:15.002358Z","iopub.execute_input":"2022-01-25T18:18:15.002629Z","iopub.status.idle":"2022-01-25T18:18:15.010344Z","shell.execute_reply.started":"2022-01-25T18:18:15.002593Z","shell.execute_reply":"2022-01-25T18:18:15.009616Z"},"trusted":true},"execution_count":null,"outputs":[]}]}