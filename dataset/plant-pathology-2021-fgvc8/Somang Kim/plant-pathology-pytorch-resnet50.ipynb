{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image     # pillow calls image\nfrom tqdm import tqdm       # tqdm shows processing\nimport copy \nimport torchvision\nfrom torchvision import transforms, models   # torchvision - pretrained model for image, video in pytorch \nfrom torch import optim        # optim: package for optimization algorithm \nimport torch.nn as nn\nfrom torch.optim import lr_scheduler    #lr_schedule adjusts learning rate based on number of epochs\nimport torch     # machine learning library\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_train = transforms.Compose([     #transforming image  #combines all transforms into one\n        transforms.RandomResizedCrop(224),   # extracts (224, 224) size from input image randomly. crops random location of the image \n        transforms.RandomHorizontalFlip(),  # just flipping it , part of data augmentation \n        transforms.ToTensor(),      # converts image to pytorch tensor \n        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])    # within range -1,1  keep value center around 0 \n    ])       # [mean], [std] input data scaling, distribution - makes data within range 3 cause RGB\ntransform_valid = transforms.Compose([\n        transforms.Resize(256),   # resize input image to (256,256)\n        transforms.CenterCrop(224),   # crops center part of the image shape (224,224)\n        transforms.ToTensor(),   #for image transformation\n        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # always use 0.5 since we are getting PIL images\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob           # to check directory ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(glob('../input/plant-pathology-2021-fgvc8/train_images/*')))             # count dataset \nprint(len(glob('../input/plant-pathology-2021-fgvc8/test_images/*')))      ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glob('../input/plant-pathology-2021-fgvc8/*')        # shows what's in the directory * ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nwith open('../input/plant-pathology-2021-fgvc8/train.csv', 'r') as f:   # 'r': reading\n    csv = f.readlines()[1:]    # excludes 0 cause headline \n    for _ in range(5):            #randomize data so not in order range(5): 5 times\n        random.shuffle(csv)\n    cnt = int(len(csv)*0.9)      # cnt = 90% of data \n    train_csv = csv[:cnt]           # from beginning to cnt \n    valid_csv = csv[cnt:]                  # from cnt: end ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = {i.split(',')[1] for i in train_csv}  # train name and label -> split-> just label ([1])\ntest2 = {i.split(',')[1] for i in valid_csv}\nprint({label:idx for idx, label in enumerate(test)})  # give index for each label \nprint({label:idx for idx, label in enumerate(test2)}) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class torchvision_Dataset(torch.utils.data.Dataset): \n    def __init__(self, data_root, csv, transforms=None):     # read and save meta data: data that explains other data\n        self.data = csv    #use self so you can call it later on on a different cell\n        self.image_path = data_root     # root: directory where you want to save the dataset\n        label = {i.split(',')[1] for i in self.data}  # split label and name of image from csv file\n        self.label = {label:idx for idx, label in enumerate(label)}   # enumerate indexes each label  so label:index \n        self.transform = transforms\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):                    # calls image data\n        image_name, label_name = self.data[idx].split(',')  # split so can get image_name, label_name \n        img = Image.open(os.path.join(self.image_path, image_name))\n        if self.transform:\n            x = self.transform(img)\n        return x, self.label[label_name]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = torchvision_Dataset('../input/plant-pathology-2021-fgvc8/train_images', train_csv, transform_train)\nvalid_dataset = torchvision_Dataset('../input/plant-pathology-2021-fgvc8/train_images', valid_csv, transform_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloaders = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4) # to reduce overfitting Group into 16 number of batches and shuffle within the batch \nvalid_dataloaders = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=4)  #num_workers: cpu->gpu faster","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   #to use gpu for torch \nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Resnet50(nn.Module):\n    def __init__(self, num_classes =12):\n        super().__init__()\n        resnet = torchvision.models.resnet50(pretrained=True)\n        resnet.fc = nn.Linear(in_features=resnet.fc.in_features, out_features = num_classes, bias= True)\n        self.base_model = resnet\n    def forward(self,x):\n        return self.base_model(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = Resnet50(num_classes = 12)\nmodel_ft.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9) # learning rate: size of step momentum: speeds (previous step matters the most)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train Model ","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        running_corrects = 0.0\n        train_corrects = 0\n        train_data_cnt = 0\n        train_progress_bar = tqdm(train_dataloaders)\n        \n        for inputs, labels in train_progress_bar: # image, label name from get item (data augmentation applied )\n            model.train()\n            \n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            \n            outputs = model(inputs)   # put inputs into the model predict class -> output\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)   # calculate loss of the predicted output \n            \n            loss.backward()   # backprop\n            optimizer.step()\n            \n            running_loss += loss.item() * inputs.size(0)\n            train_corrects += torch.sum(preds == labels.data)\n            train_data_cnt += inputs.size(0)\n            train_progress_bar.set_description(f\" Epoch[{epoch+1}/{num_epochs}] train : runing_Loss {running_loss / train_data_cnt:.5f}, train_acc {train_corrects / train_data_cnt:.5f}\")\n        \n        scheduler.step()\n        \n        valid_corrects = 0\n        valid_data_cnt = 0\n        valid_progress_bar = tqdm(valid_dataloaders)\n        for inputs, labels in valid_progress_bar:\n            model.eval()\n            \n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            with torch.no_grad():\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                \n            valid_corrects += torch.sum(preds == labels.data)\n            valid_data_cnt += inputs.size(0)\n            valid_progress_bar.set_description(f\" Epoch[{epoch+1}/{num_epochs}] valid : valid_acc {valid_corrects / valid_data_cnt}\")\n            \n        epoch_acc = running_corrects / valid_dataset.__len__() \n        if epoch_acc > best_acc:\n            best_acc = epoch_acc\n            best_epoch = epoch\n            best_model_wts = copy.deepcopy(model.state_dict())\n            print(f\"best epoch : {best_epoch}\")\n    model.load_state_dict(best_model_wts)\n    return best_model_wts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checkpoint = {'model': Resnet50(num_classes =12),\n#               'state_dict':model_ft.state_dict(),\n#               'optimizer': optimizer_ft.state_dict()}\n# torch.save(checkpoint, 'checkpoint.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission","metadata":{}},{"cell_type":"code","source":"from glob import glob\nimport csv\nimg_paths = glob(\"../input/plant-pathology-2021-fgvc8/test_images/*\")\nidx2label = {idx:label.strip() for idx, label in enumerate(test2)}\n\nsubmission = open('submission.csv', 'w', newline='')\nwr = csv.writer(submission)\nwr.writerow(['image','label'])\n\n\nbest_model =  models.resnet50(pretrained=True)\nbest_model.fc = torch.nn.Linear(2048,12)\nbest_model.load_state_dict(model_ft)\nbest_model.cuda()\n\n\nfor img_path in img_paths:\n    best_model.eval()\n    img = Image.open(img_path)\n    img = transform_valid(img)\n    img = img.unsqueeze(0)\n    with torch.no_grad():\n        pred = best_model(img.cuda())\n    print(pred)\n    _,top_one = torch.max(pred,1)\n    print(top_one)\n    print(idx2label[int(top_one)])\n    img_path = img_path.split('/')[-1]\n    print(img_path, ',', idx2label[int(top_one)])\n    \n    \n    wr.writerow([img_path, idx2label[int(top_one)]])\n    \nsubmission.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}