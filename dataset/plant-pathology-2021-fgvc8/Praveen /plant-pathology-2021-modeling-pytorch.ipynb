{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.nn as nn\nimport albumentations as A\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\n\n\nfrom torch.utils.data import Dataset,DataLoader\nimport torchvision\nfrom torchvision import models,datasets,transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\n\nfrom albumentations.core.composition import Compose,OneOf\nfrom albumentations.augmentations.transforms import CLAHE , GaussNoise ,ISONoise\n\nfrom albumentations.pytorch import ToTensorV2\n\nfrom pytorch_lightning import Trainer,seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import model_checkpoint, EarlyStopping\n\n\nfrom sklearn.model_selection import StratifiedKFold\n\n\nimport time\nimport os\nimport copy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    \n    seed = 42\n    model_name = 'resnet50'\n    pretrained = False\n    img_size = 640\n    num_classes = 12\n    batch_size = 32\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"../input/plant-pathology-2021-fgvc8/\"\n\ntrain_path =  PATH+'train_images/'\ntest_path = PATH+'test_images/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(PATH+'train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['labels'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(df_train['labels'].value_counts().keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbl_dict = dict(zip(list(df_train['labels'].value_counts().keys()),range(12)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbl_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train1= df_train.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train1['labels'] = df_train['labels'].map(lbl_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Class","metadata":{}},{"cell_type":"code","source":"def get_transform(phase: str):\n    if phase == 'train':\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PlantPatho(Dataset):\n    \n    def __init__(self,df,transform=None):\n        \n        self.image_id = df['image'].values\n        self.labels = df['labels'].values\n        \n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self,idx):\n        \n        image_id = self.image_id[idx]\n        label = self.labels[idx]\n        \n        image_path = train_path + image_id \n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        \n        augmented = self.transform(image=image)\n        \n        image = augmented['image']\n        \n        #image = np.transpose(image,(2,0,1)).astype(np.float32)\n        \n        return {'image':image ,'label':label}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = PlantPatho(df_train1,get_transform('train'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"?torch.utils.data.DataLoader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset,batch_size=CFG.batch_size,shuffle=False,num_workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let see how the image tensor looks like ","metadata":{}},{"cell_type":"code","source":"for x in train_dataset:\n    print(x['image'][0].shape)\n    break\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data in train_loader:\n    print(data)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Finetuning and Convert the Pretrained model - RESNET18","metadata":{}},{"cell_type":"code","source":"model_ft = models.resnet18(pretrained=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_ftrs =  model_ft.fc.in_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft.fc = nn.Linear(num_ftrs,12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft.fc ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = model_ft.to(CFG.device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observe that all parameters are being optimized","metadata":{}},{"cell_type":"code","source":"optimizer = optim.SGD(model_ft.parameters(),lr=0.001,momentum=0.9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decay LR by a factor of 0.1 every 7 epochs","metadata":{}},{"cell_type":"code","source":"exp_lr_scheduler = lr_scheduler.StepLR(optimizer,step_size = 7,gamma=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Referance -- Plant Pathology 2020 - Pytorch\n\nhttps://www.kaggle.com/pestipeti/plant-pathology-2020-pytorch\nhttps://www.kaggle.com/akasharidas/plant-pathology-2020-in-pytorch\n","metadata":{}},{"cell_type":"code","source":"def train_model(data_loader,model,criterion,optimizer,sheduler,device,num_epochs=25):\n    \n    since = time.time()\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    \n    for epoch in range(num_epochs):\n        \n        print('Epoch {}/{}'.format(epoch,num_epochs-1))\n        print('='*15)\n        \n        ## Each Epoch have training and Validation Phase\n        \n        for phase in ['train']:\n            \n            if phase=='train':\n                \n                model.train()\n                \n            else:\n                \n                model.eval()\n                \n            running_loss = 0.0\n            running_corrects = 0\n            \n            ## Iterate over the data\n            i=0 \n            \n            for data in data_loader:\n                \n                \n                image = data['image'][i].to(device)\n                labels =data['label'][i].to(device)\n                \n                i=i+1\n                \n                # Zero the optimizer gradients \n                \n                optimizer.zero_grad()\n                \n                \n                ## Forword Pass\n                \n                with torch.set_grad_enabled(phase=='train'):\n                    \n                    output = model(image)\n                    \n                    _,preds = torch.max(output,1)\n                    \n                    loss = criterion(output,labels)\n                    \n                    \n                    if phase=='train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                # statistics\n                running_loss += loss.item() * image.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n                \n            if phase=='train':\n                \n                sheduler.step()\n                \n            epoch_loss = running_loss / ((len(train_dataset)/CFG.batch_size))\n            epoch_acc = running_corrects.double()/ ((len(train_dataset)/CFG.batch_size))\n                                                    \n                                                    \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n                                         \n    time_elapsed = time.time() - since\n        \n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    model.load_state_dict(best_model_wts)\n                                         \n    return model\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(train_loader,model_ft, criterion, optimizer, exp_lr_scheduler,CFG.device,num_epochs=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"i=0\nfor data in train_loader:\n    \n    print(data['image'][i])\n    i=i+1\n    \n    break ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}