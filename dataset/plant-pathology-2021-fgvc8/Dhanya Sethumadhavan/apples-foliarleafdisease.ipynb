{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download Dataset\n","metadata":{}},{"cell_type":"markdown","source":"A dataset containing 18632 images of infected as well as healthy leaf images are in the train_images.The test_images folder contains 3 test images.Create a tf.data.Dataset for training and validation using the tf.keras.preprocessing.image_dataset_from_directory utility. ","metadata":{}},{"cell_type":"markdown","source":"### Count the Number of images in Trainset and Validationset","metadata":{}},{"cell_type":"code","source":"from glob import *\nimport pathlib\ntrain_dir = '../input/plant-pathology-2021-fgvc8/train_images/'\ntest_dir = '../input/plant-pathology-2021-fgvc8/test_images/'\ntrain_dir = pathlib.Path(train_dir)\ntest_dir = pathlib.Path(test_dir)\nprint(\"Trainset Count:\", len(list(train_dir.glob('*.jpg'))))\nprint(\"TestSet Count:\", len(list(test_dir.glob('*.jpg'))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print the first image in the training set","metadata":{}},{"cell_type":"code","source":"Infected_leaf = list(train_dir.glob('*.jpg'))\nPIL.Image.open(str(Infected_leaf[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initially I tried to use the tf.keras.preprocessing.image_dataset_from_directory to create the directories for the train and test images. As the file names are numbers Keras API is considering it in float32.To resolve this problem we are doing the following steps below. So I decided to use the ImageDataGenerator. For this I nees to get the image names from the train.csv file.","metadata":{}},{"cell_type":"markdown","source":"So first I will get the train.csv file and convert it into dataframe and print the dataframe head(). There are two colums, image id and the target classes, the labels  a space delimited list of all diseases found in the image. Unhealthy leaves with too many diseases to classify visually will have the complex class, and may also have a subset of the diseases identified.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 12 target classes. Each images belong to one of these classes.\n","metadata":{}},{"cell_type":"code","source":"df['labels'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let us see the distribution of data i.e.how many images belongs to each disease and how many images are categorised as healthy and how many leaves with multiple disease are categorized to complex. It seems the class 'scabe' has the most number of images. The data is highly imbalanced.","metadata":{}},{"cell_type":"code","source":"df.labels.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us plot and see the distribution of data. You can clearly view how imbalanced the dataset is.Also there are classes which holds the subset of diseases. For example rust frog_eye_leaf_spot complex,  scab frog_eye_leaf_spot complex etc. This is a multi label classification problem as there are more than one disease in one image.","metadata":{}},{"cell_type":"code","source":"df['labels'] = df['labels'].astype(str)\nplt.figure(figsize=(8,5))\nsns.countplot(data = df,y='labels')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets view one sample from each class. ","metadata":{}},{"cell_type":"code","source":"import cv2\ntrain_dir = '../input/plant-pathology-2021-fgvc8/train_images/'\ntest_dir = '../input/plant-pathology-2021-fgvc8/test_images/'\nfor label in list(df['labels'].unique()):\n    fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n    idx = df[df['labels']==label].index[0]\n    image = cv2.imread(train_dir+df.loc[idx, 'image'])\n    image =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    ax.imshow(image)\n    ax.set_title(label)\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding Duplicates","metadata":{}},{"cell_type":"code","source":"Image.open((train_dir+df['image'])[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport imagehash\n\n# image_fns : List of training image files\nimg_hashes = {}\ni=0\nfor img in list(df['image']):\n#for img_fn in sorted(image_fns):\n    #idx = df[df['labels']==label].index[i]\n    #i=i+1\n    #image = cv2.imread(train_dir+df.loc[idx, 'image'])\n    #image =cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = train_dir+img\n    hash = imagehash.average_hash(Image.open(image))\n    if hash in img_hashes:\n        print( '{} duplicate of {}'.format(image, img_hashes[hash]) )\n    else:\n        img_hashes[hash] = image","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}