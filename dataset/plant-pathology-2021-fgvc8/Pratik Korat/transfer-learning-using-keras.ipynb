{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:34.753874Z","iopub.execute_input":"2021-08-17T17:26:34.754306Z","iopub.status.idle":"2021-08-17T17:26:40.631052Z","shell.execute_reply.started":"2021-08-17T17:26:34.754278Z","shell.execute_reply":"2021-08-17T17:26:40.629908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/plant-pathology-2021-fgvc8/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:40.632725Z","iopub.execute_input":"2021-08-17T17:26:40.633169Z","iopub.status.idle":"2021-08-17T17:26:40.673259Z","shell.execute_reply.started":"2021-08-17T17:26:40.633115Z","shell.execute_reply":"2021-08-17T17:26:40.672242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:40.675449Z","iopub.execute_input":"2021-08-17T17:26:40.675869Z","iopub.status.idle":"2021-08-17T17:26:40.706887Z","shell.execute_reply.started":"2021-08-17T17:26:40.675826Z","shell.execute_reply":"2021-08-17T17:26:40.705534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_image_dir_path = \"../input/plant-pathology-2021-fgvc8/train_images/\"","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:40.708951Z","iopub.execute_input":"2021-08-17T17:26:40.709418Z","iopub.status.idle":"2021-08-17T17:26:40.715011Z","shell.execute_reply.started":"2021-08-17T17:26:40.709377Z","shell.execute_reply":"2021-08-17T17:26:40.713502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"image_path\"] = [f\"{base_image_dir_path}{image_id}\" for image_id in data[\"image\"].values]","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:40.717143Z","iopub.execute_input":"2021-08-17T17:26:40.717604Z","iopub.status.idle":"2021-08-17T17:26:40.735565Z","shell.execute_reply.started":"2021-08-17T17:26:40.717561Z","shell.execute_reply":"2021-08-17T17:26:40.734287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:40.737252Z","iopub.execute_input":"2021-08-17T17:26:40.737684Z","iopub.status.idle":"2021-08-17T17:26:40.751027Z","shell.execute_reply.started":"2021-08-17T17:26:40.737642Z","shell.execute_reply":"2021-08-17T17:26:40.749535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting the unique values for label and double crossing\ndata[\"image\"].loc[0], data[\"image_path\"].loc[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:47.097629Z","iopub.execute_input":"2021-08-17T17:26:47.098048Z","iopub.status.idle":"2021-08-17T17:26:47.105999Z","shell.execute_reply.started":"2021-08-17T17:26:47.098007Z","shell.execute_reply":"2021-08-17T17:26:47.104574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_dir = {value : key for key,value in enumerate(list(data[\"labels\"].unique()))}","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:49.322411Z","iopub.execute_input":"2021-08-17T17:26:49.322821Z","iopub.status.idle":"2021-08-17T17:26:49.332413Z","shell.execute_reply.started":"2021-08-17T17:26:49.322792Z","shell.execute_reply":"2021-08-17T17:26:49.331097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_dir","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:51.364601Z","iopub.execute_input":"2021-08-17T17:26:51.36512Z","iopub.status.idle":"2021-08-17T17:26:51.376825Z","shell.execute_reply.started":"2021-08-17T17:26:51.365054Z","shell.execute_reply":"2021-08-17T17:26:51.375593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"labels\"] = data[\"labels\"].map(target_dir)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:54.202468Z","iopub.execute_input":"2021-08-17T17:26:54.202858Z","iopub.status.idle":"2021-08-17T17:26:54.213323Z","shell.execute_reply.started":"2021-08-17T17:26:54.202829Z","shell.execute_reply":"2021-08-17T17:26:54.211872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:55.950791Z","iopub.execute_input":"2021-08-17T17:26:55.951173Z","iopub.status.idle":"2021-08-17T17:26:55.965963Z","shell.execute_reply.started":"2021-08-17T17:26:55.951138Z","shell.execute_reply":"2021-08-17T17:26:55.964653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(*IMAGE_SIZE,3)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:26:58.553338Z","iopub.execute_input":"2021-08-17T17:26:58.553684Z","iopub.status.idle":"2021-08-17T17:26:58.848238Z","shell.execute_reply.started":"2021-08-17T17:26:58.553654Z","shell.execute_reply":"2021-08-17T17:26:58.846323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image resolution for eff net model\n\"\"\"\nBase model\tresolution\nEfficientNetB0\t224\nEfficientNetB1\t240\nEfficientNetB2\t260\nEfficientNetB3\t300\nEfficientNetB4\t380\nEfficientNetB5\t456\nEfficientNetB6\t528\nEfficientNetB7\t600\n\n\"\"\"\n\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nIMAGE_SIZE = [260, 260]\nEPOCHS = 40\nSEED = 24\nBATCH_SIZE = 32 \n\n\ndef prepare_images(image, label):\n    img = tf.io.read_file(image)\n    # Decode Jpeg files\n    img = tf.image.decode_jpeg(img, channels = 3)\n    img = tf.image.resize(img, size = IMAGE_SIZE, method = \"bicubic\")\n    \n    return img,label\n\ndef augment_image(image,label):\n    img = tf.image.random_flip_up_down(image, seed = SEED)\n    img = tf.image.rot90(img)\n    img = tf.image.flip_left_right(img)\n\n    \n    return img, label\n\n\ndef decode_tensor_to_image(tensor):\n    if len(tensor.shape) >= 4:\n        if tensor.shape[0] == 1:\n            tensor = tf.squeeze(tensor, axis = 0)\n        else:\n            tensor = tensor[0]\n    img = tf.keras.preprocessing.image.array_to_img(tensor)\n    \n    return img\n\ndef process_function(image,label):\n    img = tf.keras.applications.efficientnet.preprocess_input(image)\n    return img, label","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:27:02.631967Z","iopub.execute_input":"2021-08-17T17:27:02.632349Z","iopub.status.idle":"2021-08-17T17:27:02.647204Z","shell.execute_reply.started":"2021-08-17T17:27:02.632319Z","shell.execute_reply":"2021-08-17T17:27:02.64607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:27:05.565828Z","iopub.execute_input":"2021-08-17T17:27:05.566588Z","iopub.status.idle":"2021-08-17T17:27:06.366339Z","shell.execute_reply.started":"2021-08-17T17:27:05.566542Z","shell.execute_reply":"2021-08-17T17:27:06.365249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files , valid_files = train_test_split(data, test_size = 0.1)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:28:06.122922Z","iopub.execute_input":"2021-08-17T17:28:06.123283Z","iopub.status.idle":"2021-08-17T17:28:06.134896Z","shell.execute_reply.started":"2021-08-17T17:28:06.123254Z","shell.execute_reply":"2021-08-17T17:28:06.133766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(files, batch_size):\n    image_dataset = tf.data.Dataset.from_tensor_slices(files[\"image_path\"].values)\n    labels_dataset = tf.data.Dataset.from_tensor_slices(files[\"labels\"].values)\n    final_dataset = tf.data.Dataset.zip((image_dataset, labels_dataset))\n    final_dataset = final_dataset.shuffle(1000)\n    final_dataset = final_dataset.map(prepare_images, num_parallel_calls = AUTO)\n    final_dataset = final_dataset.map(augment_image, num_parallel_calls = AUTO)\n    final_dataset = final_dataset.map(process_function, num_parallel_calls = AUTO)\n    final_dataset = final_dataset.batch(batch_size, drop_remainder = False)\n    final_dataset = final_dataset.prefetch(4)\n    \n    return final_dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:30:31.362236Z","iopub.execute_input":"2021-08-17T17:30:31.36266Z","iopub.status.idle":"2021-08-17T17:30:31.372585Z","shell.execute_reply.started":"2021-08-17T17:30:31.362628Z","shell.execute_reply":"2021-08-17T17:30:31.371097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = get_dataset(train_files, batch_size = 32)\nvalid_dataset = get_dataset(valid_files, batch_size = 24)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:30:40.169269Z","iopub.execute_input":"2021-08-17T17:30:40.169639Z","iopub.status.idle":"2021-08-17T17:30:40.365565Z","shell.execute_reply.started":"2021-08-17T17:30:40.169602Z","shell.execute_reply":"2021-08-17T17:30:40.364477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = next(iter(valid_dataset))\nimage = decode_tensor_to_image(img)\nimage","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:28:25.573138Z","iopub.execute_input":"2021-08-17T17:28:25.573481Z","iopub.status.idle":"2021-08-17T17:28:26.92982Z","shell.execute_reply.started":"2021-08-17T17:28:25.573452Z","shell.execute_reply":"2021-08-17T17:28:26.928738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"model = keras.applications.EfficientNetB2(include_top = True,weights = None, input_shape = (*IMAGE_SIZE,3) , classes = 12, classifier_activation = \"softmax\")\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:27:20.414399Z","iopub.execute_input":"2021-08-17T17:27:20.414774Z","iopub.status.idle":"2021-08-17T17:27:23.100156Z","shell.execute_reply.started":"2021-08-17T17:27:20.414743Z","shell.execute_reply":"2021-08-17T17:27:23.098884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = \"adam\", loss = keras.losses.SparseCategoricalCrossentropy(), metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:28:37.244954Z","iopub.execute_input":"2021-08-17T17:28:37.245351Z","iopub.status.idle":"2021-08-17T17:28:37.273254Z","shell.execute_reply.started":"2021-08-17T17:28:37.245321Z","shell.execute_reply":"2021-08-17T17:28:37.272022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = \"./model\",monitor = \"val_accuracy\", mode = \"max\",save_best_only = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:31:51.884501Z","iopub.execute_input":"2021-08-17T17:31:51.884853Z","iopub.status.idle":"2021-08-17T17:31:51.891452Z","shell.execute_reply.started":"2021-08-17T17:31:51.884823Z","shell.execute_reply":"2021-08-17T17:31:51.890185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_dataset, epochs = EPOCHS, callbacks = model_checkpoint, validation_data = valid_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T17:31:54.304567Z","iopub.execute_input":"2021-08-17T17:31:54.304897Z"},"trusted":true},"execution_count":null,"outputs":[]}]}