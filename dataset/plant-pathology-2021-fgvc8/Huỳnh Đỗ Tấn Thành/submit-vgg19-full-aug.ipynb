{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import thư viện","metadata":{}},{"cell_type":"code","source":"import cv2\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import VGG19","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-29T05:46:40.15465Z","iopub.execute_input":"2021-11-29T05:46:40.154976Z","iopub.status.idle":"2021-11-29T05:46:40.163034Z","shell.execute_reply.started":"2021-11-29T05:46:40.154944Z","shell.execute_reply":"2021-11-29T05:46:40.161503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show kết quả quá trình training","metadata":{}},{"cell_type":"code","source":"def plot_hist(path):\n  history = pd.read_csv(path)\n\n  acc = history['accuracy']\n  val_acc = history['val_accuracy']\n\n  loss = history['loss']\n  val_loss = history['val_loss']\n  plt.style.use('fivethirtyeight')\n  plt.figure(figsize=(20, 10))\n\n  plt.subplot(1, 2, 1)\n  plt.plot(acc, label='Training Accuracy')\n  plt.plot(val_acc, label='Validation Accuracy')\n  plt.legend(loc='lower right')\n  plt.ylabel('Accuracy')\n  plt.ylim([min(plt.ylim()), 1])\n  plt.title('Training and Validation Accuracy')\n  plt.xlabel('epoch')\n\n  plt.subplot(1, 2, 2)\n  plt.plot(loss, label='Training Loss')\n  plt.plot(val_loss, label='Validation Loss')\n  plt.legend(loc='upper right')\n  plt.ylabel('Categorical Crossentropy')\n  plt.ylim([min(plt.ylim()), max(plt.ylim())])\n  plt.title('Training and Validation Loss')\n\n  plt.xlabel('epoch')\n  plt.savefig('evaluation.jpg')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:46:42.548072Z","iopub.execute_input":"2021-11-29T05:46:42.548473Z","iopub.status.idle":"2021-11-29T05:46:42.565535Z","shell.execute_reply.started":"2021-11-29T05:46:42.548428Z","shell.execute_reply":"2021-11-29T05:46:42.56428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(\"../input/fgvc8vgg19/FGVC8-VGG19.log\")","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:46:59.90267Z","iopub.execute_input":"2021-11-29T05:46:59.903648Z","iopub.status.idle":"2021-11-29T05:47:00.735901Z","shell.execute_reply.started":"2021-11-29T05:46:59.903601Z","shell.execute_reply":"2021-11-29T05:47:00.734856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load model","metadata":{}},{"cell_type":"code","source":"HEIGHT = 480\nWIDTH = 480\nCHANNELS = 3\nCLASSES = 6\ntop_dropout_rate = 0.2\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:48:23.065198Z","iopub.execute_input":"2021-11-29T05:48:23.065496Z","iopub.status.idle":"2021-11-29T05:48:23.071569Z","shell.execute_reply.started":"2021-11-29T05:48:23.065465Z","shell.execute_reply":"2021-11-29T05:48:23.070174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_path = \"../input/fgvc8vgg19/FGVC8-VGG19t.h5\"","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:48:31.69689Z","iopub.execute_input":"2021-11-29T05:48:31.698623Z","iopub.status.idle":"2021-11-29T05:48:31.710664Z","shell.execute_reply.started":"2021-11-29T05:48:31.698572Z","shell.execute_reply":"2021-11-29T05:48:31.709464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    VGG19_MODEL = tf.keras.applications.VGG19(weights=None ,include_top=False, input_shape=(HEIGHT, WIDTH, 3))\n    \n    x=VGG19_MODEL.output\n    x=GlobalAveragePooling2D()(x)\n    x=Dense(256,activation='relu')(x)\n    x=Dropout(0.2)(x)\n    x=Dense(128,activation='relu')(x)\n    prediction=Dense(6,activation='sigmoid')(x)\n\n    model=Model(inputs=VGG19_MODEL.input, outputs=prediction)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:49:15.628116Z","iopub.execute_input":"2021-11-29T05:49:15.629213Z","iopub.status.idle":"2021-11-29T05:49:15.640447Z","shell.execute_reply.started":"2021-11-29T05:49:15.629164Z","shell.execute_reply":"2021-11-29T05:49:15.639278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.load_weights(weights_path)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:49:16.519928Z","iopub.execute_input":"2021-11-29T05:49:16.52021Z","iopub.status.idle":"2021-11-29T05:49:18.85935Z","shell.execute_reply.started":"2021-11-29T05:49:16.520181Z","shell.execute_reply":"2021-11-29T05:49:18.85807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data test","metadata":{}},{"cell_type":"code","source":"test_img = '../input/plant-pathology-2021-fgvc8/test_images'\nsubmission = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:49:32.011998Z","iopub.execute_input":"2021-11-29T05:49:32.012914Z","iopub.status.idle":"2021-11-29T05:49:32.038376Z","shell.execute_reply.started":"2021-11-29T05:49:32.012877Z","shell.execute_reply":"2021-11-29T05:49:32.037333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing test data","metadata":{}},{"cell_type":"code","source":"def load_image(image_id):\n    file_path = str(image_id)\n    img = cv2.imread(test_img+'/'+file_path)\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:50:13.859254Z","iopub.execute_input":"2021-11-29T05:50:13.859556Z","iopub.status.idle":"2021-11-29T05:50:13.866405Z","shell.execute_reply.started":"2021-11-29T05:50:13.859528Z","shell.execute_reply":"2021-11-29T05:50:13.865172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_full_augment(image):\n    \n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    flag = False\n\n    # Pixel-level transforms\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n        flag = True\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n        flag = True\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        flag = True\n\n\n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        flag = True\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270º\n        flag = True\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180º\n        flag = True\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90\n        flag = True\n        \n    # Crops\n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.8)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.9)\n        flag = True\n    elif p_crop > .4:\n        HEIGHT1 = image.shape[0]\n        WIDTH1 = image.shape[1]\n        crop_size_h = tf.random.uniform([], int(HEIGHT1*.8), HEIGHT1, dtype=tf.float32)\n        crop_size_w = tf.random.uniform([], int(WIDTH1*.8), WIDTH1, dtype=tf.float32)\n        image = tf.image.random_crop(image, size=[crop_size_h, crop_size_w, 3])\n        flag = True\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:50:14.410845Z","iopub.execute_input":"2021-11-29T05:50:14.411246Z","iopub.status.idle":"2021-11-29T05:50:14.427764Z","shell.execute_reply.started":"2021-11-29T05:50:14.411215Z","shell.execute_reply":"2021-11-29T05:50:14.426542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process(path):\n    img = load_image(path)\n    img = data_full_augment(img)\n    img = tf.cast(img, tf.float32) / 255.0\n    img = np.array(img)\n    return cv2.resize(img , (480, 480)).reshape(-1, 480, 480, 3)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:51:41.717076Z","iopub.execute_input":"2021-11-29T05:51:41.717416Z","iopub.status.idle":"2021-11-29T05:51:41.724169Z","shell.execute_reply.started":"2021-11-29T05:51:41.717386Z","shell.execute_reply":"2021-11-29T05:51:41.722806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"preds = []\nfor i in range(len(submission['image'])):\n    test_images = submission['image'][i]\n    pred = model.predict(process(test_images))[0]\n    preds.append(pred)\n    \npreds = np.array(preds)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:51:43.658866Z","iopub.execute_input":"2021-11-29T05:51:43.659694Z","iopub.status.idle":"2021-11-29T05:51:51.964366Z","shell.execute_reply.started":"2021-11-29T05:51:43.659652Z","shell.execute_reply":"2021-11-29T05:51:51.963354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perdict = (preds>0.33)\nn_label = ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']\nanswer = []\n\nfor i in range(perdict.shape[0]):\n    temp = []\n    for j, k in enumerate(n_label):\n        if perdict[i, j]:\n            temp.append(k)\n    if len(temp) > 1 and \"healthy\" in temp:\n        temp.remove(\"healthy\")\n    elif len(temp) == 0:\n        temp.append('healthy')\n    answer.append(temp)\n    \nanswer = [' '.join(n) for n in answer]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:51:57.744459Z","iopub.execute_input":"2021-11-29T05:51:57.745411Z","iopub.status.idle":"2021-11-29T05:51:57.755203Z","shell.execute_reply.started":"2021-11-29T05:51:57.745345Z","shell.execute_reply":"2021-11-29T05:51:57.753121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['labels'] = np.array(answer)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:51:58.899104Z","iopub.execute_input":"2021-11-29T05:51:58.899432Z","iopub.status.idle":"2021-11-29T05:51:58.911592Z","shell.execute_reply.started":"2021-11-29T05:51:58.899403Z","shell.execute_reply":"2021-11-29T05:51:58.910167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T05:52:40.249171Z","iopub.execute_input":"2021-11-29T05:52:40.249934Z","iopub.status.idle":"2021-11-29T05:52:40.256746Z","shell.execute_reply.started":"2021-11-29T05:52:40.249897Z","shell.execute_reply":"2021-11-29T05:52:40.255132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}