{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import thư viện","metadata":{}},{"cell_type":"code","source":"import cv2\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import VGG16","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-29T08:25:30.417373Z","iopub.execute_input":"2021-11-29T08:25:30.417933Z","iopub.status.idle":"2021-11-29T08:25:30.425353Z","shell.execute_reply.started":"2021-11-29T08:25:30.417889Z","shell.execute_reply":"2021-11-29T08:25:30.424664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show kết quả quá trình training","metadata":{}},{"cell_type":"code","source":"def plot_hist(path):\n  history = pd.read_csv(path)\n\n  acc = history['accuracy']\n  val_acc = history['val_accuracy']\n\n  loss = history['loss']\n  val_loss = history['val_loss']\n  plt.style.use('fivethirtyeight')\n  plt.figure(figsize=(20, 10))\n\n  plt.subplot(1, 2, 1)\n  plt.plot(acc, label='Training Accuracy')\n  plt.plot(val_acc, label='Validation Accuracy')\n  plt.legend(loc='lower right')\n  plt.ylabel('Accuracy')\n  plt.ylim([min(plt.ylim()), 1])\n  plt.title('Training and Validation Accuracy')\n  plt.xlabel('epoch')\n\n  plt.subplot(1, 2, 2)\n  plt.plot(loss, label='Training Loss')\n  plt.plot(val_loss, label='Validation Loss')\n  plt.legend(loc='upper right')\n  plt.ylabel('Categorical Crossentropy')\n  plt.ylim([min(plt.ylim()), max(plt.ylim())])\n  plt.title('Training and Validation Loss')\n\n  plt.xlabel('epoch')\n  plt.savefig('evaluation.jpg')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:25:31.894247Z","iopub.execute_input":"2021-11-29T08:25:31.894864Z","iopub.status.idle":"2021-11-29T08:25:31.907866Z","shell.execute_reply.started":"2021-11-29T08:25:31.894825Z","shell.execute_reply":"2021-11-29T08:25:31.907068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(\"../input/fgvc8vgg16/FGVC8-VGG16.log\")","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:25:40.55404Z","iopub.execute_input":"2021-11-29T08:25:40.554338Z","iopub.status.idle":"2021-11-29T08:25:41.298681Z","shell.execute_reply.started":"2021-11-29T08:25:40.554308Z","shell.execute_reply":"2021-11-29T08:25:41.297967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load model","metadata":{}},{"cell_type":"code","source":"HEIGHT = 480\nWIDTH = 480\nCHANNELS = 3\nCLASSES = 6\ntop_dropout_rate = 0.2\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:10.122591Z","iopub.execute_input":"2021-11-29T08:26:10.123264Z","iopub.status.idle":"2021-11-29T08:26:10.127939Z","shell.execute_reply.started":"2021-11-29T08:26:10.123225Z","shell.execute_reply":"2021-11-29T08:26:10.126972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_path = \"../input/fgvc8vgg16/FGVC8-VGG16.h5\"","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:20.98737Z","iopub.execute_input":"2021-11-29T08:26:20.98766Z","iopub.status.idle":"2021-11-29T08:26:20.991629Z","shell.execute_reply.started":"2021-11-29T08:26:20.98763Z","shell.execute_reply":"2021-11-29T08:26:20.990901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    VGG16_MODEL = tf.keras.applications.VGG16(weights=None ,include_top=False, input_shape=(HEIGHT, WIDTH, 3))\n    \n    x=VGG16_MODEL.output\n    x=GlobalAveragePooling2D()(x)\n    x=Dense(256,activation='relu')(x)\n    x=Dropout(0.2)(x)\n    x=Dense(128,activation='relu')(x)\n    prediction=Dense(6,activation='sigmoid')(x)\n\n    model=Model(inputs=VGG16_MODEL.input, outputs=prediction)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:41.64538Z","iopub.execute_input":"2021-11-29T08:26:41.645674Z","iopub.status.idle":"2021-11-29T08:26:41.652615Z","shell.execute_reply.started":"2021-11-29T08:26:41.645641Z","shell.execute_reply":"2021-11-29T08:26:41.651479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.load_weights(weights_path)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:42.596671Z","iopub.execute_input":"2021-11-29T08:26:42.596961Z","iopub.status.idle":"2021-11-29T08:26:44.300578Z","shell.execute_reply.started":"2021-11-29T08:26:42.596933Z","shell.execute_reply":"2021-11-29T08:26:44.299808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data test","metadata":{}},{"cell_type":"code","source":"test_img = '../input/plant-pathology-2021-fgvc8/test_images'\nsubmission = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:44.879085Z","iopub.execute_input":"2021-11-29T08:26:44.879678Z","iopub.status.idle":"2021-11-29T08:26:44.900361Z","shell.execute_reply.started":"2021-11-29T08:26:44.879635Z","shell.execute_reply":"2021-11-29T08:26:44.899696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing test data","metadata":{}},{"cell_type":"code","source":"def load_image(image_id):\n    file_path = str(image_id)\n    img = cv2.imread(test_img+'/'+file_path)\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:48.12845Z","iopub.execute_input":"2021-11-29T08:26:48.12888Z","iopub.status.idle":"2021-11-29T08:26:48.133389Z","shell.execute_reply.started":"2021-11-29T08:26:48.128845Z","shell.execute_reply":"2021-11-29T08:26:48.132707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_full_augment(image):\n    \n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    flag = False\n\n    # Pixel-level transforms\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n        flag = True\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n        flag = True\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        flag = True\n\n\n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        flag = True\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270º\n        flag = True\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180º\n        flag = True\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90\n        flag = True\n        \n    # Crops\n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.8)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.9)\n        flag = True\n    elif p_crop > .4:\n        HEIGHT1 = image.shape[0]\n        WIDTH1 = image.shape[1]\n        crop_size_h = tf.random.uniform([], int(HEIGHT1*.8), HEIGHT1, dtype=tf.float32)\n        crop_size_w = tf.random.uniform([], int(WIDTH1*.8), WIDTH1, dtype=tf.float32)\n        image = tf.image.random_crop(image, size=[crop_size_h, crop_size_w, 3])\n        flag = True\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:49.631299Z","iopub.execute_input":"2021-11-29T08:26:49.632182Z","iopub.status.idle":"2021-11-29T08:26:49.647676Z","shell.execute_reply.started":"2021-11-29T08:26:49.632143Z","shell.execute_reply":"2021-11-29T08:26:49.646795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process(path):\n    img = load_image(path)\n    img = data_full_augment(img)\n    img = tf.cast(img, tf.float32) / 255.0\n    img = np.array(img)\n    return cv2.resize(img , (480, 480)).reshape(-1, 480, 480, 3)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:51.22615Z","iopub.execute_input":"2021-11-29T08:26:51.226749Z","iopub.status.idle":"2021-11-29T08:26:51.232029Z","shell.execute_reply.started":"2021-11-29T08:26:51.226704Z","shell.execute_reply":"2021-11-29T08:26:51.230987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"preds = []\nfor i in range(len(submission['image'])):\n    test_images = submission['image'][i]\n    pred = model.predict(process(test_images))[0]\n    preds.append(pred)\n    \npreds = np.array(preds)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:53.267437Z","iopub.execute_input":"2021-11-29T08:26:53.268213Z","iopub.status.idle":"2021-11-29T08:27:01.353658Z","shell.execute_reply.started":"2021-11-29T08:26:53.26817Z","shell.execute_reply":"2021-11-29T08:27:01.352918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perdict = (preds>0.2)\nn_label = ['complex', 'frog_eye_leaf_spot', 'healthy', 'powdery_mildew', 'rust', 'scab']\nanswer = []\n\nfor i in range(perdict.shape[0]):\n    temp = []\n    for j, k in enumerate(n_label):\n        if perdict[i, j]:\n            temp.append(k)\n    if len(temp) > 1 and \"healthy\" in temp:\n        temp.remove(\"healthy\")\n    elif len(temp) == 0:\n        temp.append('healthy')\n    answer.append(temp)\n    \nanswer = [' '.join(n) for n in answer]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:01.356904Z","iopub.execute_input":"2021-11-29T08:27:01.357108Z","iopub.status.idle":"2021-11-29T08:27:01.363701Z","shell.execute_reply.started":"2021-11-29T08:27:01.357083Z","shell.execute_reply":"2021-11-29T08:27:01.362772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['labels'] = np.array(answer)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:01.365322Z","iopub.execute_input":"2021-11-29T08:27:01.365654Z","iopub.status.idle":"2021-11-29T08:27:01.378997Z","shell.execute_reply.started":"2021-11-29T08:27:01.365617Z","shell.execute_reply":"2021-11-29T08:27:01.378056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:01.765216Z","iopub.execute_input":"2021-11-29T08:27:01.765792Z","iopub.status.idle":"2021-11-29T08:27:01.773243Z","shell.execute_reply.started":"2021-11-29T08:27:01.765754Z","shell.execute_reply":"2021-11-29T08:27:01.772428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}