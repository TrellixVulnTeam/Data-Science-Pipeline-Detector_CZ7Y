{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Configurations","metadata":{}},{"cell_type":"markdown","source":"### 1. Libraries","metadata":{}},{"cell_type":"code","source":"# General\nimport numpy as np\nimport pandas as pd\nimport glob\nimport os\nimport PIL\nfrom PIL import Image\nimport cv2\nfrom collections import Counter\n\n# Encoding\nfrom sklearn import preprocessing\n\n\n# Visualizations\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Neural Network\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Notebook Configurations","metadata":{}},{"cell_type":"code","source":"print('Using:')\nprint('\\nPyTorch version:', torch.__version__)\nprint('\\n Running on GPU' if torch.cuda.is_available() else 'GPU device not found. Running on CPU')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Classes","metadata":{}},{"cell_type":"code","source":"class PlantPathology(Dataset):\n  def __init__(self,root_dir, image_names, labels, transform=None):\n    self.root_dir = root_dir\n    self.image_names = image_names\n    self.labels = labels\n    self.transform = transform\n\n  def __len__(self):\n    return len(self.labels)\n  \n  def __getitem__(self, index):\n\n    label = self.labels[index]\n    image = Image.open(os.path.join(self.root_dir, self.image_names[index]))\n    #image = cv2.imread(image_name)\n\n    if self.transform is not None:\n      image = self.transform(image)\n\n    return image, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Functions","metadata":{}},{"cell_type":"code","source":"def data_details(label_path, img_path):\n    '''\n    Input: Path to labels, path to images\n    Action: Get details of the labels and the images\n    Output: Details of labels and images\n    '''\n    # Label Details\n    df = pd.read_csv(label_path)\n    n_rows = df.shape[0]\n    n_classes = df['labels'].nunique()\n    classes = df['labels'].value_counts()\n    classes = classes.to_frame()\n    describe = df.describe()\n    classes = classes.apply(lambda x: round((x/n_rows)*100,0))\n    duplicates = df[df.duplicated()]\n    \n    # Image Details\n    num_images = len([name for name in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, name))])\n    image_dimensions = []\n    \n    images = [name for name in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, name))]\n    \n    for name in images[:100]:\n        img = cv2.imread('../input/plant-pathology-2021-fgvc8/train_images/'+name)\n        dim = (img.shape[1],img.shape[0])\n        image_dimensions.append(dim)\n    \n    dimensions = Counter(image_dimensions).keys() # equals to list(set(words))\n    dimensions_frequency = Counter(image_dimensions).values() # counts the elements' frequency\n    \n    print('Train Data Details')\n    print('\\n')\n    print('\\nShape of the label file: ', df.shape)\n    print('\\nData types of the columns:', df.info())\n    print('\\nData Description:', describe)\n    print('\\nTotal number of classes',n_classes)\n    print('\\nClasses:')\n    print('\\n',classes)\n    print('\\nRow duplicates:',duplicates)\n    print('\\nSample rows:')\n    print('\\n',df.head())\n    print('\\nIMAGE DETAILS')\n    print('\\nNumber of images in the training folder:',num_images)\n    print('\\nUnique dimensions from a sample of 100 images:',dimensions)\n    print('Frequencies of dimensions from a sample of 100 images:',dimensions_frequency)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_loader_exploration(data_loader):\n    '''\n    Input: Data loader\n    Action: Get batch details\n    Output: Batch details\n    '''\n    batch = next(iter(train_loader))\n    images, labels = batch\n    \n    print('\\nNumber of components in the batch:',len(batch))\n    print('Type of batch:',type(batch))\n    print('Shape of a batch:',images.shape)\n    print('Length of the batch:',len(images))\n    print('\\n')\n    grid = torchvision.utils.make_grid(images, nrow=10)\n    plt.figure(figsize=(15,15))\n    plt.imshow(np.transpose(grid, (1,2,0)))\n    print('\\nlabels:', labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Raw Data Exploration","metadata":{}},{"cell_type":"code","source":"img_path = '../input/plant-pathology-2021-fgvc8/train_images'\nlabel_path = '../input/plant-pathology-2021-fgvc8/train.csv'\ndata_details(label_path,img_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data Preparation","metadata":{}},{"cell_type":"markdown","source":"### 1. Label Encoding","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(label_path)\nlabel_encoder = preprocessing.LabelEncoder()\nlabel_encoder.fit(train_df['labels'])\ntrain_df['label_id'] = label_encoder.transform(train_df['labels'])\nlabels = train_df['label_id'].values\nimage_names = train_df['image'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Data Transform","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Resize((128, 128)),\n     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Define Dataset","metadata":{}},{"cell_type":"code","source":"train_set = PlantPathology(root_dir=img_path,\n                           image_names=image_names,\n                           labels = labels,\n                           transform=transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Define Data Loader","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_set,\n                          batch_size=64,\n                          shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Loader Exploration","metadata":{}},{"cell_type":"code","source":"data_loader_exploration(train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}