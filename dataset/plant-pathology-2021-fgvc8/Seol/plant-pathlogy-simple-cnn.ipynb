{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = list(df['labels'].value_counts().index)\nclass_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\nnb_classes = len(class_names)\nIMAGE_SIZE = (150, 150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    dataset = '../input/plant-pathology-2021-fgvc8/train_images'\n    output = []\n    images = []\n    labels = []\n    \n    print(\"Loading {}\".format(dataset))\n    for file in tqdm(os.listdir(dataset)[:1000]):\n        img_path = os.path.join(dataset, file)\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, IMAGE_SIZE)\n        \n        label = class_names_label[df.loc[df['image'] == file, 'labels'].values[0]]\n        images.append(image)\n        labels.append(label)\n        \n    images = np.array(images, dtype = 'float32')\n    labels = np.array(labels, dtype = 'int32')\n    \n    return images, labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images, train_labels = load_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.savez('./image_label_array', img=train_images, labels=train_labels)\n# load_array = np.load('../input/arraydata/image_label_array.npz')\n# train_images = load_array['img']\n# train_labels = load_array['labels']\n# del load_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images, train_labels = shuffle(train_images, train_labels, random_state=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_train = train_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, train_counts = np.unique(train_labels, return_counts=True)\npd.DataFrame({'train': train_counts}, index=class_names).plot.bar()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.pie(train_counts, labels=class_names, autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_images / 255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_examples(class_names, images, labels):\n\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(12):\n        plt.subplot(4,3,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_examples(class_names, train_images, train_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(12, activation=tf.nn.softmax)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_callbacks():\n    \n    cpk_path = './best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        mode='max',\n        patience=3, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_images, train_labels, batch_size=32, epochs=5, validation_split = 0.4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist(hist):\n    plt.plot(hist.history[\"accuracy\"])\n    plt.plot(hist.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(train_images)     # Vector of probabilities\npred_labels = np.argmax(predictions, axis = 1) # We take the highest probability","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n    \n    BOO = (train_labels == pred_labels)\n    mislabeled_indices = np.where(BOO == 0)\n    mislabeled_images = train_images[mislabeled_indices]\n    mislabeled_labels = pred_labels[mislabeled_indices]\n\n    title = \"Some examples of mislabeled images by the classifier:\"\n    display_examples(class_names,  mislabeled_images, mislabeled_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CM = confusion_matrix(train_labels, pred_labels)\nax = plt.axes()\nsn.heatmap(CM, annot=True, \n           annot_kws={\"size\": 10}, \n           xticklabels=class_names, \n           yticklabels=class_names, ax = ax)\nax.set_title('Confusion matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nmodel = VGG16(weights='imagenet', include_top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = model.predict(train_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_train, x, y, z = train_features.shape\nnumFeatures = x * y * z","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import decomposition\n\npca = decomposition.PCA(n_components = 2)\n\nX = train_features.reshape((n_train, x*y*z))\npca.fit(X)\n\nC = pca.transform(X) # Repr√©sentation des individus dans les nouveaux axe\nC1 = C[:,0]\nC2 = C[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(10,10))\n\nfor i, class_name in enumerate(class_names):\n    plt.scatter(C1[train_labels == i][:1000], C2[train_labels == i][:1000], label = class_name, alpha=0.4)\nplt.legend()\nplt.title(\"PCA Projection\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n    tf.keras.layers.Dense(12, activation=tf.nn.softmax)\n])\n\nmodel2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory2 = model2.fit(train_features, train_labels, batch_size=128, epochs=15, validation_split = 0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(seed=1997)\n# Number of estimators\nn_estimators = 10\n# Proporition of samples to use to train each training\nmax_samples = 0.8\n\nmax_samples *= n_train\nmax_samples = int(max_samples)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = list()\nrandom = np.random.randint(50, 100, size = n_estimators)\n\nfor i in range(n_estimators):\n    \n    # Model\n    model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape = (x, y, z)),\n                                # One layer with random size\n                                    tf.keras.layers.Dense(random[i], activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n                                ])\n    \n    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    # Store model\n    models.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"histories = []\n\nfor i in range(n_estimators):\n    # Train each model on a bag of the training data\n    train_idx = np.random.choice(len(train_features), size = max_samples)\n    histories.append(models[i].fit(train_features[train_idx], train_labels[train_idx], batch_size=128, epochs=10, validation_split = 0.1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor i in range(n_estimators):\n    predictions.append(models[i].predict(train_features))\n    \npredictions = np.array(predictions)\npredictions = predictions.sum(axis = 0)\npred_labels = predictions.argmax(axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy : {}\".format(accuracy_score(train_labels, pred_labels)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model\n\nmodel = VGG16(weights='imagenet', include_top=False)\nmodel = Model(inputs=model.inputs, outputs=model.layers[-5].output)\n\ntrain_features = model.predict(train_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Dense, Conv2D, Activation , MaxPooling2D, Flatten\n\nmodel2 = VGG16(weights='imagenet', include_top=False)\n\ninput_shape = model2.layers[-4].get_input_shape_at(0) # get the input shape of desired layer\nlayer_input = Input(shape = (9, 9, 512)) # a new input tensor to be able to feed the desired layer\n# https://stackoverflow.com/questions/52800025/keras-give-input-to-intermediate-layer-and-get-final-output\n\nx = layer_input\nfor layer in model2.layers[-4::1]:\n    x = layer(x)\n    \nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Flatten()(x)\nx = Dense(100,activation='relu')(x)\nx = Dense(6,activation='softmax')(x)\n\n# create the model\nnew_model = Model(layer_input, x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = new_model.fit(train_features, train_labels, batch_size=128, epochs=10, validation_split = 0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\npredictions = new_model.predict(train_features)    \npred_labels = np.argmax(predictions, axis = 1)\nprint(\"Accuracy : {}\".format(accuracy_score(train_labels, pred_labels)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}