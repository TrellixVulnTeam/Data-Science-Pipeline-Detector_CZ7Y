{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch_xla\nimport torch_xla.core.xla_model as xm\n\nimport os\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport albumentations\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\n\nfrom typing import Tuple, Callable\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import hamming_loss\nfrom sklearn.model_selection import train_test_split\nfrom albumentations.pytorch import ToTensorV2 as AT\n\n\n# System constants\nSEED = 42\nDEFAULT_TENSOR_TYPE = 'torch.FloatTensor'\nWORKERS = 0  # number of cpu cores, 0 means \"use everything\"\n\n# Path constants\nMAIN_FOLDER = '../input/plant-pathology-2021-fgvc8'\nDATA_FOLDER = '../input/plant-pathology-2021-224x224/train_imgs'  # absolute path to the folder with train images\nDATAFRAME_PATH = os.path.join(MAIN_FOLDER, 'train.csv')\nMODEL_FILE = 'model.pt'\n\n# DF related constants\nIMAGES_COL_NAME = 'image'\nLABELS_COL_NAME = 'labels'\n\n# Image parameters\nIMG_SIZE = (224, 224)\n\n# Data manipulating constants\nN_EPOCHS = 1\nBATCH_SIZE = 1024\nK = 5  # number of folds per split\nTEST_SIZE = 0.25  # the size of the test set in shares\n\n# Optimazation constants\nLR = 1e-2\nFACTOR = 0.805\nSCHEDULER_PATIENCE = 2\n\n\nDataColumns = Tuple[pd.Series, pd.Series]\nDataSample = Tuple[torch.Tensor, torch.Tensor]\nModelPrediction = Tuple[np.ndarray, np.ndarray]\nDataFramesPair = Tuple[pd.DataFrame, pd.DataFrame]\nDataloadersPair = Tuple[DataLoader, DataLoader]\nLossFn = nn.Module\nScheduleFn = ReduceLROnPlateau\nScoreFn = Callable[[np.ndarray, np.ndarray], float]\n\ntrain_transforms = albumentations.Compose([\n    albumentations.Resize(*IMG_SIZE),\n    albumentations.Flip(p=0.5),\n    albumentations.RandomBrightnessContrast(p=0.5),\n    albumentations.ShiftScaleRotate(p=0.5),\n    albumentations.Normalize(),\n    albumentations.CoarseDropout(p=0.5),\n    albumentations.Cutout(p=0.5),\n    AT()\n])\n\nvalidaton_transforms = albumentations.Compose([\n    albumentations.Resize(*IMG_SIZE),\n    albumentations.Normalize(),\n    AT()\n])\n\ntest_transforms = validaton_transforms\n\n  \nclass PathologyDataset(Dataset):\n    '''\n    Class that represents data from Plant Pathology Challenge. This dataset is used to train models.\n    '''\n    \n    def __init__(self, df: pd.DataFrame, images_path: str, transforms=None):\n        images_names = df[IMAGES_COL_NAME].tolist()\n        labels = df[LABELS_COL_NAME].tolist()\n            \n        self.images_names = images_names\n        self.labels = labels\n        self.images_path = images_path\n        self.transforms = transforms\n    \n    def __len__(self) -> int:\n        return len(self.images_names)\n    \n    def __getitem__(self, idx: int) -> DataSample:\n        image_name = self.images_names[idx]\n        label = self.labels[idx]\n        \n        image = cv2.imread(os.path.join(self.images_path, image_name))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = PathologyDataset.__transform_image(image, self.transforms)\n        label = torch.tensor(label)\n        \n        return image, label\n    \n    @staticmethod\n    def __transform_image(image: np.ndarray, transforms) -> torch.Tensor:\n        '''\n        Method that encapsulates augmentation library API\n        '''\n        if transforms is not None:\n            augmented = transforms(image=image)\n            return augmented['image']\n        return image\n    \n    \nclass TrainEngine:\n    '''\n    Class that provides API to train neural networks\n    '''\n    @staticmethod\n    def train_model(model: nn.Module, df: pd.DataFrame, criterion: nn.Module, optimizer: optim.Optimizer,\n                scheduler: ScheduleFn, n_epochs: int) -> None:\n        '''\n        Train loop with cross-validation. It also uses logging and saves best model.\n        '''\n        max_validation_score = -np.inf\n        kf = KFold(n_splits=K, shuffle=True, random_state=SEED)\n\n        for epoch in range(1, n_epochs + 1):\n            print('Epoch: #', epoch, sep='')\n            mean_validation_score = 0\n            \n            for fold, (train_indices, val_indices) in enumerate(kf.split(df[IMAGES_COL_NAME], df[LABELS_COL_NAME])):\n                trainloader, validloader = TrainEngine.__prepare_dataloaders(df, train_indices, val_indices)\n                TrainEngine.__train_one_fold(model, criterion, optimizer, trainloader, fold + 1)\n                \n                with torch.no_grad():\n                    mean_validation_score += \\\n                    TrainEngine.__validate_one_fold(model, criterion, optimizer, scheduler, validloader)\n                del trainloader, validloader\n                \n            mean_validation_score /= K\n            \n            #end of epoch\n            print('Mean validation score: {:.4f}'.format(mean_validation_score))\n            \n            if mean_validation_score > max_validation_score:\n                print('Saving model...')\n                max_validation_score = mean_validation_score\n                xm.save(model.state_dict(), MODEL_FILE)\n    \n    @staticmethod\n    def get_device_type() -> torch.device:\n        return TrainEngine.__device\n    \n    @staticmethod\n    def __prepare_dataloaders(df: pd.DataFrame, train_indices: np.ndarray, valid_indices: np.ndarray) -> DataloadersPair:\n        train_ = df.iloc[train_indices, :].reset_index(drop=True)\n        valid_ = df.iloc[valid_indices, :].reset_index(drop=True)\n\n        train_ds = PathologyDataset(train_, DATA_FOLDER, train_transforms)\n        valid_ds = PathologyDataset(valid_, DATA_FOLDER, validaton_transforms)\n\n        trainloader = DataLoader(train_ds, batch_size=BATCH_SIZE, pin_memory=False, drop_last=False, num_workers=WORKERS)\n        validloader = DataLoader(valid_ds, batch_size=BATCH_SIZE, pin_memory=False, shuffle=False, num_workers=WORKERS)\n\n        return trainloader, validloader\n    \n    @staticmethod\n    def __train_one_fold(model: nn.Module, criterion: LossFn, optimizer: optim.Optimizer,\n                         dataloader: DataLoader, fold: int) -> None:\n        print(time.ctime(), 'Fold:', fold)\n        \n        model.train()\n        train_loss = 0.0\n        \n        for images, labels in dataloader:\n            images = images.to(TrainEngine.__device)\n            labels = labels.to(TrainEngine.__device)\n            \n            optimizer.zero_grad()\n            \n            output = torch.sigmoid(model(images))\n            loss = criterion(output, labels)\n            loss.backward()\n            xm.optimizer_step(optimizer, barrier=True)\n            \n            train_loss += loss.item()\n        \n        print('Training loss: {:.4f}'.format(train_loss))\n        \n    @staticmethod\n    def __validate_one_fold(model: nn.Module, criterion: LossFn, optimizer: optim.Optimizer,\n                            scheduler: ScheduleFn, dataloader: DataLoader) -> float:\n        model.eval()\n        \n        val_loss = 0.0\n        val_image_predictions = []\n        val_image_labels = []\n        \n        for images, labels in dataloader:\n            images = images.to(TrainEngine.__device)\n            labels = labels.to(TrainEngine.__device)\n\n            output = torch.sigmoid(model(images))\n            loss = criterion(output, labels)\n\n            val_loss += loss.item()\n            val_image_predictions += [torch.round(output).cpu().detach().numpy()]\n            val_image_labels += [labels.cpu().detach().numpy()]\n        \n        scheduler.step(val_loss)\n        \n        val_image_predictions = np.concatenate(val_image_predictions)\n        val_image_labels = np.concatenate(val_image_labels)\n        val_hamming = hamming_loss(val_image_predictions, val_image_labels)\n        print('Validation multi-label Hamming accuracy: {:.4f}'.format(1 - val_hamming))\n        \n        return (1 - val_hamming)\n    \n    __device = xm.xla_device()\n\n    \nclass TestEngine:\n    '''\n    Class that provides API to test neural networks\n    '''\n    @staticmethod\n    def test_model(model: nn.Module, df: pd.DataFrame) -> None:\n        testloader = TestEngine.__prepare_dataloader(df)\n        test_image_predictions, test_image_labels = TestEngine.__get_predictions(model, testloader)\n        \n        test_hamming = hamming_loss(np.round(test_image_predictions), test_image_labels)\n        print('Test multi-label Hamming accuracy: {:.4f}'.format(1 - test_hamming))\n    \n    @staticmethod\n    def __prepare_dataloader(df: pd.DataFrame) -> DataLoader:\n        test_ds = PathologyDataset(df, DATA_FOLDER, test_transforms)\n        testloader = DataLoader(test_ds, batch_size=BATCH_SIZE, pin_memory=False, shuffle=False, num_workers=WORKERS)\n        \n        return testloader\n    \n    @staticmethod\n    def __get_predictions(model: nn.Module, dataloader: DataLoader) -> ModelPrediction:\n        model.eval()\n        \n        test_image_predictions = []\n        test_image_labels = []\n        \n        for images, labels in dataloader:\n            images = images.to(TrainEngine.get_device_type())\n            labels = labels.to(TrainEngine.get_device_type())\n\n            output = torch.sigmoid(model(images))\n\n            test_image_predictions += [torch.round(output).cpu().detach().numpy()]\n            test_image_labels += [labels.cpu().detach().numpy()]\n        \n        test_image_predictions = np.concatenate(test_image_predictions)\n        test_image_labels = np.concatenate(test_image_labels)\n        \n        return test_image_predictions, test_image_labels\n\n\ndef seed_everything(seed: int) -> None:\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.mdeterministic = True\n\n\ndef read_data(df_path: str) -> DataFramesPair:\n    df = pd.read_csv(df_path)\n    df[IMAGES_COL_NAME] = os.listdir('../input/plant-pathology-2021-224x224/train_imgs')\n    df[LABELS_COL_NAME] = df[LABELS_COL_NAME].apply(str.split).apply(tuple)\n    df[LABELS_COL_NAME] = MultiLabelBinarizer().fit_transform(df[LABELS_COL_NAME]).astype('float32').tolist()\n    \n    train_images, test_images, train_labels, test_labels = train_test_split(\n        df[IMAGES_COL_NAME], df[LABELS_COL_NAME], test_size=TEST_SIZE,\n        shuffle=True, random_state=SEED\n    )\n    train_df = pd.DataFrame({IMAGES_COL_NAME: train_images, LABELS_COL_NAME: train_labels}).reset_index()\n    test_df = pd.DataFrame({IMAGES_COL_NAME: test_images, LABELS_COL_NAME: test_labels}).reset_index()\n    \n    return train_df, test_df\n\n\ndef get_n_classes(df: pd.DataFrame) -> int:\n    return len(df[LABELS_COL_NAME][0])\n\n\ndef create_model(n_classes: int) -> nn.Module:\n    model = models.resnet18(pretrained=True)\n    \n    for child in model.children():\n        for param in child.parameters():\n            param.requires_grad = False\n    \n    model.fc = nn.Linear(512, n_classes)\n    model = model.to(TrainEngine.get_device_type())\n    \n    return model\n\n\ndef begin_session() -> None:\n    print('\\n' * 5)\n\n\ndef main():\n    seed_everything(SEED)\n    torch.set_default_tensor_type(DEFAULT_TENSOR_TYPE)\n    \n    train_df, test_df = read_data(DATAFRAME_PATH)\n    n_classes = get_n_classes(train_df)\n\n    model = create_model(n_classes)\n    criterion = nn.BCELoss().to(TrainEngine.get_device_type())\n    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n    scheduler = ReduceLROnPlateau(optimizer, factor=FACTOR, patience=SCHEDULER_PATIENCE)\n    \n    begin_session()\n    TrainEngine.train_model(model, train_df, criterion, optimizer, scheduler, N_EPOCHS)\n    print('Training complited.', end='\\n\\n')\n    \n    print('Using model with test set...')\n    with torch.no_grad():\n        TestEngine.test_model(model, test_df)\n    \n    del model, criterion, optimizer, scheduler\n    torch.cuda.empty_cache()\n    \n    \nif __name__ == '__main__':\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}