{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Background removal using Sementic Segmentation Network Unet\n\n","metadata":{"_uuid":"f2f11a400a20f8133d84c60a1a4c81fe25b97cf4"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\nfrom tensorflow.python.keras.optimizers import Adadelta, Nadam ,Adam\nfrom tensorflow.python.keras.models import Model, load_model\nfrom tensorflow.python.keras.utils import multi_gpu_model, plot_model ,Sequence\nfrom tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.python.keras.preprocessing.image import load_img,img_to_array\nimport tensorflow as tf\nfrom tensorflow.python.keras.losses import binary_crossentropy\nfrom scipy.ndimage import morphology as mp\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom glob import glob  # for getting list paths of image and labels\nfrom random import choice,sample\nfrom matplotlib import pyplot as plt\nimport cv2 # saving and loading images\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T10:24:02.018566Z","iopub.execute_input":"2021-06-14T10:24:02.018837Z","iopub.status.idle":"2021-06-14T10:24:03.038813Z","shell.execute_reply.started":"2021-06-14T10:24:02.01878Z","shell.execute_reply":"2021-06-14T10:24:03.038068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# listing image and their respective labels \nalso here we are asserting the presence of label file w.r.t each image.","metadata":{"_uuid":"f9a5b388afa002f143e28c4ed7ec0b4326932807"}},{"cell_type":"code","source":"train_img_dir = '../input/plant-pathology-2021-fgvc8/train_images/' \ntrain_mask_dir = '../input/eron-masks/masks/'\ntrain_imgs = os.listdir(train_mask_dir)# if you have an error take a look here ...\ntrain_masks = os.listdir(train_mask_dir)\ntrain_imgs= [ i for i in train_imgs if \"jpg\" in i][:-1000]\ntrain_masks= [ i for i in train_masks if \"jpg\" in i][:-1000]\nprint(len(train_imgs))\nprint(len(train_masks))\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-06-14T10:40:21.354416Z","iopub.execute_input":"2021-06-14T10:40:21.354698Z","iopub.status.idle":"2021-06-14T10:40:21.373998Z","shell.execute_reply.started":"2021-06-14T10:40:21.35465Z","shell.execute_reply":"2021-06-14T10:40:21.372655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Repeat same steps for validation dataset**","metadata":{"_uuid":"ae0e33d6dab3ae2891714b4e89938320758abaa3"}},{"cell_type":"code","source":"val_img_dir = '../input/plant-pathology-2021-fgvc8/train_images/'\nval_mask_dir = '../input/eron-masks/masks/'\nval_imgs = train_imgs[-1000:]#os.listdir(val_mask_dir)\nval_masks = train_masks[-1000:]#os.listdir(val_mask_dir)\nprint(len(val_imgs))\nprint(len(val_masks))","metadata":{"_uuid":"1b5acb3a4164f57ad5c6deddcc37b183888f4291","execution":{"iopub.status.busy":"2021-06-14T10:40:27.490692Z","iopub.execute_input":"2021-06-14T10:40:27.490968Z","iopub.status.idle":"2021-06-14T10:40:27.496314Z","shell.execute_reply.started":"2021-06-14T10:40:27.49092Z","shell.execute_reply":"2021-06-14T10:40:27.49555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Here we impliment keras custom data generator to get batch images and labels without loading whole dataset in the active memory\n","metadata":{"_uuid":"b0874d1c19836d557689de0f3b84a508b49cbc1d"}},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, images,image_dir,labels,label_dir ,batch_size=16, dim=(224,224,3) ,shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.images = images\n        self.image_dir = image_dir\n        self.labels = labels\n        self.label_dir = label_dir\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.images) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [k for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.images))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        batch_imgs = list()\n        batch_labels = list()\n\n        # Generate data\n        for i in list_IDs_temp:\n            # Store sample\n            img = load_img(self.image_dir + self.images[i] ,target_size=self.dim)\n            img = img_to_array(img)/255.\n            batch_imgs.append(img)\n           # Store class\n            label = load_img(self.label_dir + self.labels[i] ,target_size=self.dim)\n            label = img_to_array(label)[:,:,0]\n            label = label != 0\n            label = mp.binary_erosion(mp.binary_erosion(label))\n            label = mp.binary_dilation(mp.binary_dilation(mp.binary_dilation(label)))\n            label = np.expand_dims((label)*1 , axis=2)\n            batch_labels.append(label)\n            \n        return np.array(batch_imgs) ,np.array(batch_labels)","metadata":{"_uuid":"20683f6d4cc5789aa700f12a7860e44ed7487ca6","execution":{"iopub.status.busy":"2021-06-14T10:30:02.434363Z","iopub.execute_input":"2021-06-14T10:30:02.434669Z","iopub.status.idle":"2021-06-14T10:30:02.445228Z","shell.execute_reply.started":"2021-06-14T10:30:02.434621Z","shell.execute_reply":"2021-06-14T10:30:02.444366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **Now we need to define our training and validation generator using above implimented class.**","metadata":{"_uuid":"25ca7a71bddacc5041317e3d21127a604b8eace3"}},{"cell_type":"code","source":"train_generator = DataGenerator(train_imgs,train_img_dir,train_masks,train_mask_dir,batch_size=36, dim=(224,224,3) ,shuffle=True)\ntrain_steps = train_generator.__len__()\ntrain_steps","metadata":{"_uuid":"44b5697993d190246ab850be5aef4c865eb99aca","scrolled":true,"execution":{"iopub.status.busy":"2021-06-14T10:30:04.859025Z","iopub.execute_input":"2021-06-14T10:30:04.859486Z","iopub.status.idle":"2021-06-14T10:30:04.866179Z","shell.execute_reply.started":"2021-06-14T10:30:04.859251Z","shell.execute_reply":"2021-06-14T10:30:04.865399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After defining generator lets check the some of the dataset it generates for the training and visualize them**","metadata":{"_uuid":"9fdd63fd5fa29124ba8c99371312ee1ff62198c9"}},{"cell_type":"code","source":"X,y = train_generator.__getitem__(5)\nt = 27\nplt.figure(figsize=(8,8))\nplt.subplot(121)\nplt.imshow(X[t])\nplt.subplot(122)\nplt.imshow(np.reshape(y[t],(224,224)))\n#print(np.unique(y[t],return_counts=True))","metadata":{"_uuid":"1c5f246ee62cd0451631ebf65a507673bebd782a","execution":{"iopub.status.busy":"2021-06-14T10:30:06.975177Z","iopub.execute_input":"2021-06-14T10:30:06.975672Z","iopub.status.idle":"2021-06-14T10:30:07.220321Z","shell.execute_reply.started":"2021-06-14T10:30:06.975573Z","shell.execute_reply":"2021-06-14T10:30:07.218977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator = DataGenerator(val_imgs,val_img_dir,val_masks,val_mask_dir,batch_size=36, dim=(224,224,3) ,shuffle=True)\nval_steps = val_generator.__len__()\nval_steps","metadata":{"_uuid":"3417f30905b0ff185ddea15fde6ea33c1e327a5f","execution":{"iopub.status.busy":"2021-06-14T10:30:16.643859Z","iopub.execute_input":"2021-06-14T10:30:16.64414Z","iopub.status.idle":"2021-06-14T10:30:16.651516Z","shell.execute_reply.started":"2021-06-14T10:30:16.644087Z","shell.execute_reply":"2021-06-14T10:30:16.650566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# After preparing input pipeline we are going to define our U-net model\n\nhere we first define down convolution (encoder ) and up convolution layer (decoder) and stack them up with a short circuting features from down sampling to corresponding up sampling\n\nfull detail of the  architecture is present here - https://arxiv.org/abs/1505.04597","metadata":{"_uuid":"b5f3b24584baff455a9774964b365b228752e0e6"}},{"cell_type":"code","source":"def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\n\ndef deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n    y = concatenate([y, residual], axis=3)\n    y = conv_block(y, nfilters)\n    return y\n\n\ndef Unet(h, w, filters):\n# down\n    input_layer = Input(shape=(h, w, 3), name='image_input')\n    conv1 = conv_block(input_layer, nfilters=filters)\n    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = conv_block(conv1_out, nfilters=filters*2)\n    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = conv_block(conv2_out, nfilters=filters*4)\n    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = conv_block(conv3_out, nfilters=filters*8)\n    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv4_out = Dropout(0.5)(conv4_out)\n    conv5 = conv_block(conv4_out, nfilters=filters*16)\n    conv5 = Dropout(0.5)(conv5)\n# up\n    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n    deconv6 = Dropout(0.5)(deconv6)\n    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n    deconv7 = Dropout(0.5)(deconv7) \n    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n    output_layer = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(deconv9)\n    # using sigmoid activation for binary classification\n    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n    return model","metadata":{"_uuid":"2512ae33c973cd7c8e701867ffef891741172233","execution":{"iopub.status.busy":"2021-06-14T10:30:18.538654Z","iopub.execute_input":"2021-06-14T10:30:18.538929Z","iopub.status.idle":"2021-06-14T10:30:18.550234Z","shell.execute_reply.started":"2021-06-14T10:30:18.53888Z","shell.execute_reply":"2021-06-14T10:30:18.549185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Unet(224 , 224 , 34)\n#model.summary()","metadata":{"_uuid":"de09610ae39d2abcede22b0daffddc30d29c2dd6","execution":{"iopub.status.busy":"2021-06-14T10:30:19.56518Z","iopub.execute_input":"2021-06-14T10:30:19.565551Z","iopub.status.idle":"2021-06-14T10:30:21.012298Z","shell.execute_reply.started":"2021-06-14T10:30:19.565494Z","shell.execute_reply":"2021-06-14T10:30:21.011612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Here we define keras custom metric for the loss and accuracy computation\n\nJaccard distance loss - this loss help to get rid of the side effects of unbalanced class label in a image (like - 80% background , 20 % human )  https://en.wikipedia.org/wiki/Jaccard_index\n\ndice_coef - To evaluate accuracy of the segmentation.   https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient","metadata":{"_uuid":"9c4f3dd8099b29e8af444c86d93d03d28dae77c8"}},{"cell_type":"code","source":"def jaccard_distance_loss(y_true, y_pred,smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 - jac) * smooth\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","metadata":{"_uuid":"55b012c74590e7294ac313645dc3b6f24121a8c9","execution":{"iopub.status.busy":"2021-06-14T10:30:21.01365Z","iopub.execute_input":"2021-06-14T10:30:21.013931Z","iopub.status.idle":"2021-06-14T10:30:21.020443Z","shell.execute_reply.started":"2021-06-14T10:30:21.013888Z","shell.execute_reply":"2021-06-14T10:30:21.019513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining callbacks and compile model with adam optimiser with default learning rate.","metadata":{"_uuid":"772a38d1d54496ec554c602175cfdb55f2173be5"}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss=jaccard_distance_loss ,metrics = [dice_coef, 'accuracy'])\nmc = ModelCheckpoint(mode='max', filepath='top-weights.h5', monitor='val_dice_coef',save_best_only='True', save_weights_only='True', verbose=1)\nes = EarlyStopping(mode='max', monitor='val_dice_coef', patience=3, verbose=1)\ncallbacks = [mc, es]\nmodel.metrics_names","metadata":{"_uuid":"e238c0f4d3f0dc334f7719d1c6822154f260416e","execution":{"iopub.status.busy":"2021-06-14T10:30:22.251366Z","iopub.execute_input":"2021-06-14T10:30:22.251649Z","iopub.status.idle":"2021-06-14T10:30:22.330525Z","shell.execute_reply.started":"2021-06-14T10:30:22.251601Z","shell.execute_reply":"2021-06-14T10:30:22.329562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now finally train our model with above configuration and train data generator.","metadata":{"_uuid":"74c35b0cadd8fde7dbdd5ee398880aaaf84a3bd0"}},{"cell_type":"code","source":"# model.load_weights('../input/background-removal/top-weights.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:30:24.35379Z","iopub.execute_input":"2021-06-14T10:30:24.354063Z","iopub.status.idle":"2021-06-14T10:30:24.358164Z","shell.execute_reply.started":"2021-06-14T10:30:24.354013Z","shell.execute_reply":"2021-06-14T10:30:24.357202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nresults = model.fit_generator(train_generator, steps_per_epoch=train_steps,epochs=10,callbacks=callbacks,validation_data=val_generator,validation_steps=val_steps)","metadata":{"_uuid":"b1dd9aed28791724335cf6f8a92d95b3f5a5899d","execution":{"iopub.status.busy":"2021-06-14T10:30:25.185532Z","iopub.execute_input":"2021-06-14T10:30:25.185843Z","iopub.status.idle":"2021-06-14T10:32:41.129667Z","shell.execute_reply.started":"2021-06-14T10:30:25.185788Z","shell.execute_reply":"2021-06-14T10:32:41.128825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.history.keys()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:34:59.487099Z","iopub.execute_input":"2021-06-14T10:34:59.487399Z","iopub.status.idle":"2021-06-14T10:34:59.492844Z","shell.execute_reply.started":"2021-06-14T10:34:59.48735Z","shell.execute_reply":"2021-06-14T10:34:59.491823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = results.history[\"loss\"]\nval_loss = results.history[\"val_loss\"]\n\ndice_coef = results.history[\"dice_coef\"]\nval_dice_coef = results.history[\"val_dice_coef\"]\n\nacc = results.history[\"acc\"]\nval_acc = results.history[\"val_acc\"]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:36:41.367711Z","iopub.execute_input":"2021-06-14T10:36:41.367998Z","iopub.status.idle":"2021-06-14T10:36:41.372689Z","shell.execute_reply.started":"2021-06-14T10:36:41.367946Z","shell.execute_reply":"2021-06-14T10:36:41.371769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(loss,label = \"loss\")\nplt.plot(val_loss,label  = \"val loss\")\nplt.xlabel(\"iterations\")\n# plt.ylabel(\"X axis label\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:38:56.349911Z","iopub.execute_input":"2021-06-14T10:38:56.350186Z","iopub.status.idle":"2021-06-14T10:38:56.560248Z","shell.execute_reply.started":"2021-06-14T10:38:56.350137Z","shell.execute_reply":"2021-06-14T10:38:56.559442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(dice_coef,label = \"dice_coef\")\nplt.plot(val_dice_coef,label  = \"val dice_coef\")\nplt.xlabel(\"iterations\")\n# plt.ylabel(\"X axis label\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:39:26.326103Z","iopub.execute_input":"2021-06-14T10:39:26.326438Z","iopub.status.idle":"2021-06-14T10:39:26.550646Z","shell.execute_reply.started":"2021-06-14T10:39:26.326379Z","shell.execute_reply":"2021-06-14T10:39:26.549707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(acc,label = \"acc\")\nplt.plot(val_acc,label  = \"val acc\")\nplt.xlabel(\"iterations\")\n# plt.ylabel(\"X axis label\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:39:51.871257Z","iopub.execute_input":"2021-06-14T10:39:51.87162Z","iopub.status.idle":"2021-06-14T10:39:52.103361Z","shell.execute_reply.started":"2021-06-14T10:39:51.871562Z","shell.execute_reply":"2021-06-14T10:39:52.102403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('top-weights.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:24:11.775372Z","iopub.execute_input":"2021-06-14T10:24:11.775896Z","iopub.status.idle":"2021-06-14T10:24:14.152309Z","shell.execute_reply.started":"2021-06-14T10:24:11.775814Z","shell.execute_reply":"2021-06-14T10:24:14.151444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Visualizing train and val loss w.r.t epoch**","metadata":{"_uuid":"537547ed7ccd5a312bd2ee615bbf916394865d53"}},{"cell_type":"code","source":"# plt.figure(figsize=(8, 8))\n# plt.title(\"Learning curve\")\n# plt.plot(results.history[\"loss\"], label=\"loss\")\n# plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n# plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"log_loss\")\n# plt.legend();","metadata":{"_uuid":"c2e5587103ce3cbc3143e93f9cc742a7a1a56e32","execution":{"iopub.status.busy":"2021-06-14T10:24:14.153694Z","iopub.execute_input":"2021-06-14T10:24:14.154073Z","iopub.status.idle":"2021-06-14T10:24:14.159811Z","shell.execute_reply.started":"2021-06-14T10:24:14.154021Z","shell.execute_reply":"2021-06-14T10:24:14.15844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.load_weights('/kaggle/input/background-removal/weights.08-0.97.h5')\n#k = model.evaluate_generator(generator=val_generator,steps=val_steps)","metadata":{"_uuid":"02514a1cf003e7f0e90ab8db95222eb0c8545913","execution":{"iopub.status.busy":"2021-06-14T10:24:14.162199Z","iopub.execute_input":"2021-06-14T10:24:14.162676Z","iopub.status.idle":"2021-06-14T10:24:14.169434Z","shell.execute_reply.started":"2021-06-14T10:24:14.162489Z","shell.execute_reply":"2021-06-14T10:24:14.168539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now its time to make some predictions","metadata":{"_uuid":"5f75a87b3a7bc74f913017d082ea732a2b949f6a"}},{"cell_type":"code","source":"test_image = glob('../input/plant-pathology-2021-fgvc8/test_images')\n#mask_set = glob('/kaggle/input/back-remove/binary_segment/binary_segment/train/masks/1004.jpg')\n#len(test_image)","metadata":{"_uuid":"f4fe68b2f6e167172d0f02c3e1fbd55df5f02b46","execution":{"iopub.status.busy":"2021-06-14T10:24:14.170985Z","iopub.execute_input":"2021-06-14T10:24:14.171359Z","iopub.status.idle":"2021-06-14T10:24:14.177731Z","shell.execute_reply.started":"2021-06-14T10:24:14.171292Z","shell.execute_reply":"2021-06-14T10:24:14.177012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def jaccard_distance(y_true, y_pred, smooth=100):\n#     intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n#     sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n#     jac = (intersection + smooth) / (sum_ - intersection + smooth)\n#     return (1 - jac) * smooth\n\n# def jaccard_acc(y_true, y_pred):\n#     intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n#     sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n#     jac = intersection / sum_ - intersection\n#     return jac\n\n# img = img_to_array(load_img(test_image[0]))\n# mask = img_to_array(load_img(mask_set[0]))\n# plt.imshow(mask/255.)\n\n# jaccard_distance_loss(mask[:,:,0],mask[:,:,0])","metadata":{"_uuid":"21ed7f0b2e87bf434ccdd964c19a7d24b5fb70bf","execution":{"iopub.status.busy":"2021-06-14T10:24:14.179081Z","iopub.execute_input":"2021-06-14T10:24:14.179632Z","iopub.status.idle":"2021-06-14T10:24:14.185783Z","shell.execute_reply.started":"2021-06-14T10:24:14.179415Z","shell.execute_reply":"2021-06-14T10:24:14.18488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Function to make prediction \nNote:-  Dont forget to Normalise image dataset (here i divided every pixel by 255. )**","metadata":{"_uuid":"a1fa61c5bfdb41cb61462514b80fe9e120ea37cd"}},{"cell_type":"code","source":"def make_prediction(model,image,shape):\n    img = img_to_array(load_img(image,target_size=shape))\n    img = np.expand_dims(img,axis=0)/255.\n    mask = model.predict(img)\n    \n    mask = (mask[0] > 0.5)*1\n#     print(np.unique(mask,return_counts=True))\n    mask = np.reshape(mask,(224,224))\n    return mask                       ","metadata":{"_uuid":"44bc9cb617f25cbf713dd10ea083a174cc834e71","execution":{"iopub.status.busy":"2021-06-14T10:24:14.187779Z","iopub.execute_input":"2021-06-14T10:24:14.188408Z","iopub.status.idle":"2021-06-14T10:24:14.196552Z","shell.execute_reply.started":"2021-06-14T10:24:14.188197Z","shell.execute_reply":"2021-06-14T10:24:14.195639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = \"../input/plant-pathology-2021-fgvc8/train_images/802b59956a7aa5e7.jpg\"\nimg = img_to_array(load_img(image))\nplt.imshow(img/255.)\nimg.shape","metadata":{"_uuid":"4f583854e1bef10653ff6fc6384a05d2b92c1ff5","execution":{"iopub.status.busy":"2021-06-14T10:24:14.197858Z","iopub.execute_input":"2021-06-14T10:24:14.198601Z","iopub.status.idle":"2021-06-14T10:24:15.549264Z","shell.execute_reply.started":"2021-06-14T10:24:14.198259Z","shell.execute_reply":"2021-06-14T10:24:15.548126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = \"../input/eron-masks/masks/802b59956a7aa5e7.jpg\"\ni = img_to_array(load_img(im))\n# i = cv2.resize(i,(img.shape[1],img.shape[0]))\nplt.imshow(i)\ni.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T10:24:15.550852Z","iopub.execute_input":"2021-06-14T10:24:15.551453Z","iopub.status.idle":"2021-06-14T10:24:15.749006Z","shell.execute_reply.started":"2021-06-14T10:24:15.551136Z","shell.execute_reply":"2021-06-14T10:24:15.748172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = make_prediction(model,image,(224,224,3))\nmask2 = cv2.merge([mask,mask,mask])\nprint(img.shape,mask.shape)\nmask2 = cv2.resize(mask2,(img.shape[1],img.shape[0]))\n# print(mask.shape)\nplt.imshow(mask2)","metadata":{"_uuid":"20c88863cf50e6e3d8a3f70b91fb42d207b07aca","execution":{"iopub.status.busy":"2021-06-14T10:24:15.750324Z","iopub.execute_input":"2021-06-14T10:24:15.750758Z","iopub.status.idle":"2021-06-14T10:24:18.214913Z","shell.execute_reply.started":"2021-06-14T10:24:15.750708Z","shell.execute_reply":"2021-06-14T10:24:18.161363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now use the mask to get the segmented image**","metadata":{"_uuid":"e037049fb4b63d080d1727a95750c8ac62bbf160"}},{"cell_type":"code","source":"h,w = img.shape[:2]\nmask_resized = cv2.resize(np.uint8(mask*1),(w,h))\nmask_resized = mask_resized != 0\n#print(np.unique(mask_resized,return_counts=True))\nsegment = np.zeros((h,w,3))\nsegment[:,:,0] = img[:,:,0]*mask_resized\nsegment[:,:,1] = img[:,:,1]*mask_resized\nsegment[:,:,2] = img[:,:,2]*mask_resized\nsegment[np.where((segment == [0,0,0]).all(axis=2))] = [0,0,0]\n#img[np.where((img==[255,255,255]).all(axis=2))] = [0,0,0];","metadata":{"_uuid":"fe6f6172c278a972771a72167a38b68ecbef38f5","execution":{"iopub.status.busy":"2021-06-14T10:24:18.162005Z","iopub.status.idle":"2021-06-14T10:24:18.162366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.imshow(segment/255.)","metadata":{"_uuid":"c54c84edcb2a39572c9b94e60657784ba8288e0c","execution":{"iopub.status.busy":"2021-06-14T10:24:18.163185Z","iopub.status.idle":"2021-06-14T10:24:18.163609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"85c60dc95737d082468cbb1dbd675642bf6ea8a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"bf34a547e207680e1b21bdea3284524c988a6785","trusted":true},"execution_count":null,"outputs":[]}]}