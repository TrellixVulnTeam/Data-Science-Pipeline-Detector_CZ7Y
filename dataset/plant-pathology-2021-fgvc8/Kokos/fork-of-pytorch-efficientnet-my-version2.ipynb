{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T10:38:40.75897Z","iopub.execute_input":"2021-05-25T10:38:40.759326Z","iopub.status.idle":"2021-05-25T10:38:40.762977Z","shell.execute_reply.started":"2021-05-25T10:38:40.759294Z","shell.execute_reply":"2021-05-25T10:38:40.762102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv').sample(frac=1, random_state=666)#грузим датасет с котором метки категориальные и имя файла(картинки)\ntrain_df['path'] =  train_df['image'].apply(lambda x: '../input/plant2021-downscaled-images-dataset/' + x)#создаем третью колонку в датасете с полным путем к файлу\ntrain_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:41.09232Z","iopub.execute_input":"2021-05-25T10:38:41.092627Z","iopub.status.idle":"2021-05-25T10:38:41.133772Z","shell.execute_reply.started":"2021-05-25T10:38:41.092599Z","shell.execute_reply":"2021-05-25T10:38:41.132835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmean_label_val = train_df.groupby('labels').count().mean()[0].astype(int)\nprint(f'mean_label_val: {mean_label_val}')\n\ntrain_df.groupby('labels').count()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:42.288793Z","iopub.execute_input":"2021-05-25T10:38:42.289128Z","iopub.status.idle":"2021-05-25T10:38:42.317152Z","shell.execute_reply.started":"2021-05-25T10:38:42.289098Z","shell.execute_reply":"2021-05-25T10:38:42.315974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_list = [x for x in train_df.labels.unique()]\n\ndef fill_image_amount(df, mean_label_val, labels_list):\n\n    for label in labels_list:\n        if mean_label_val > df[(df['labels'] ==  label)].count()[0]:\n            dif = mean_label_val - df[(df['labels'] ==  label)].count()[0]\n            print(label, ' ',  dif)\n\n            temp_df = df[(df['labels'] ==   label)].sample(n=dif, replace=True)\n            df = df.append(temp_df, ignore_index=True)\n            del temp_df\n    return df\n\n\ntrain_df_extend = fill_image_amount(train_df, mean_label_val, labels_list)\ntrain_df_extend.groupby('labels').count()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:43.519639Z","iopub.execute_input":"2021-05-25T10:38:43.519978Z","iopub.status.idle":"2021-05-25T10:38:43.648291Z","shell.execute_reply.started":"2021-05-25T10:38:43.519948Z","shell.execute_reply":"2021-05-25T10:38:43.647385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# train_df2.loc[:, train_df2['labels'] == 'rust complex']\n\n# train_df2.groupby(['labels']).apply(train_df[train_df['labels'] == 'rust complex'])\ntrain_df[train_df['labels'] == 'powdery_mildew complex'].groupby('labels').nunique()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:45.497561Z","iopub.execute_input":"2021-05-25T10:38:45.497889Z","iopub.status.idle":"2021-05-25T10:38:45.515453Z","shell.execute_reply.started":"2021-05-25T10:38:45.497843Z","shell.execute_reply":"2021-05-25T10:38:45.51443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.width', 1000)\npd.set_option('display.max_colwidth', 100)\n\n\ntrain_df_extend[train_df_extend['image'] == 'ff331233da9091ca.jpg']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:46.368824Z","iopub.execute_input":"2021-05-25T10:38:46.369172Z","iopub.status.idle":"2021-05-25T10:38:46.384788Z","shell.execute_reply.started":"2021-05-25T10:38:46.369142Z","shell.execute_reply":"2021-05-25T10:38:46.383973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabel = LabelEncoder()\nlabel.fit(train_df_extend['labels'])\ntrain_df_extend['label_id'] = label.transform(train_df_extend['labels'])\nlabel_dic = dict(sorted(train_df_extend[['label_id', 'labels']].values.tolist())) #save for submission# сохранили в словарь что бы потом при сабмите понимать где какая метка(всего 12 меток)\nprint(label_dic)\nclasses = len(train_df_extend['labels'].value_counts()) #12\n\ndel train_df_extend['labels'] \n\nimage_labels = np.array(train_df_extend['label_id'].values)#[ 9  6  9  9  3  9  3 10  6  6]\nimage_list = np.array(train_df_extend['path'].values)#path to img\n\nprint(image_list.shape) #18632\nprint(image_labels[:10])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:47.428396Z","iopub.execute_input":"2021-05-25T10:38:47.428715Z","iopub.status.idle":"2021-05-25T10:38:47.467042Z","shell.execute_reply.started":"2021-05-25T10:38:47.428685Z","shell.execute_reply":"2021-05-25T10:38:47.46604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2_var = train_df_extend.iloc[:2000]\ntrain_df2_train = train_df_extend.iloc[2000:].sample(frac = 1)\ntrain_df2 = train_df2_var.append(train_df2_train, ignore_index = True)\n\ntrain_df2.tail(30)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:48.318762Z","iopub.execute_input":"2021-05-25T10:38:48.319111Z","iopub.status.idle":"2021-05-25T10:38:48.341876Z","shell.execute_reply.started":"2021-05-25T10:38:48.319079Z","shell.execute_reply":"2021-05-25T10:38:48.341025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2[train_df2['image'] == 'e969c081c53d8fdc.jpg']","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:49.414253Z","iopub.execute_input":"2021-05-25T10:38:49.414571Z","iopub.status.idle":"2021-05-25T10:38:49.432501Z","shell.execute_reply.started":"2021-05-25T10:38:49.414541Z","shell.execute_reply":"2021-05-25T10:38:49.431424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import LabelEncoder\n\n# label = LabelEncoder()\n# label.fit(train_df['labels'])\n# train_df['label_id'] = label.transform(train_df['labels'])\n# label_dic = dict(sorted(train_df[['label_id', 'labels']].values.tolist())) #save for submission# сохранили в словарь что бы потом при сабмите понимать где какая метка(всего 12 меток)\n# print(label_dic)\n# classes = len(train_df['labels'].value_counts()) #12\n\n# del train_df['labels'] \n\n# image_labels = np.array(train_df['label_id'].values)#[ 9  6  9  9  3  9  3 10  6  6]\n# image_list = np.array(train_df['path'].values)#path to img\n\n# print(image_list.shape) #18632\n# print(image_labels[:10])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:50.348801Z","iopub.execute_input":"2021-05-25T10:38:50.349166Z","iopub.status.idle":"2021-05-25T10:38:50.353964Z","shell.execute_reply.started":"2021-05-25T10:38:50.349137Z","shell.execute_reply":"2021-05-25T10:38:50.352973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#train_df.groupby('label_id').size()\ncls_weight = list((1.0001/(train_df2.groupby('label_id').size() / 4826)).values)\n\n\ncls_weight\n\ndisplay(train_df2)\ncls_weight\ntrain_df2.groupby('label_id').size()\n(train_df2.groupby('label_id').size() / 4826)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:51.183811Z","iopub.execute_input":"2021-05-25T10:38:51.184157Z","iopub.status.idle":"2021-05-25T10:38:51.206719Z","shell.execute_reply.started":"2021-05-25T10:38:51.184128Z","shell.execute_reply":"2021-05-25T10:38:51.205592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2[18620:18632] , train_df2[26947:26957]\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:52.256662Z","iopub.execute_input":"2021-05-25T10:38:52.257041Z","iopub.status.idle":"2021-05-25T10:38:52.267721Z","shell.execute_reply.started":"2021-05-25T10:38:52.257007Z","shell.execute_reply":"2021-05-25T10:38:52.266674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install ../input/pyturbojpeg/libturbojpeg_1.4.2-0ubuntu3.4_amd64.deb\n!pip install ../input/pyturbojpeg/PyTurboJPEG-1.4.1","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:38:53.110476Z","iopub.execute_input":"2021-05-25T10:38:53.110813Z","iopub.status.idle":"2021-05-25T10:39:33.228827Z","shell.execute_reply.started":"2021-05-25T10:38:53.110783Z","shell.execute_reply":"2021-05-25T10:39:33.227954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport albumentations as A\nimport cv2, torch\nimport torchvision.transforms as transforms\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom turbojpeg import TurboJPEG\n\ndevice = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n\n#######################################\n\nfrom albumentations.pytorch import ToTensor\n\ndef get_training_augmentation():\n    \n    augmentation_pipeline = A.Compose(\n        [\n            A.SmallestMaxSize(224),\n            A.RandomCrop(224, 224),\n            A.RandomContrast(), \n            A.OneOf(\n                [\n                    A.RandomGamma(), \n                    A.RandomBrightness(), \n                ],\n                p = 0.2\n            ),\n            A.OneOf(\n                [\n                    A.GaussNoise(),\n                    A.RandomContrast(),\n                    A.RandomBrightnessContrast(brightness_limit=1, contrast_limit=1),\n                    A.ChannelShuffle(),\n                    A.RandomGamma(),\n                    A.Rotate(limit=60), \n                    A.MotionBlur(blur_limit=20)\n                ],\n                p = 0.2\n            ),\n            A.OneOf(\n                [\n                    A.Rotate(limit=360),\n                    A.Flip(p=0.2),                \n                ],\n                p = 0.2\n            ),            \n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]\n                ),\n            ToTensor() \n        ],\n        p = 1\n    )\n    return lambda img:augmentation_pipeline(image=np.array(img))['image']\n\n\n\ndef transform_valid():\n    \n    augmentation_pipeline = A.Compose(\n        [\n            A.SmallestMaxSize(224),\n            A.RandomCrop(224, 224),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225]\n                ),\n            ToTensor() \n        ],\n        p = 1\n    )\n    return lambda img:augmentation_pipeline(image=np.array(img))['image']\n\n######################################\n\njpeg_reader = TurboJPEG()\n\ndef read_img(img):\n    with open(img, \"rb\") as f:\n        return jpeg_reader.decode(f.read(), 0) \n    \n\nclass dataset(Dataset) :\n    def __init__(self, image_list, image_labels, transform, device) :\n        self.image_list = image_list\n        self.image_labels = image_labels\n        self.transform = transform\n    \n    def __len__(self) :\n        return len(self.image_list)\n    \n    def __getitem__(self, index) :\n        x = read_img(self.image_list[index])\n        x = self.transform(x).to(device)\n        \n        y = self.image_labels[index]\n        y = torch.LongTensor([y,]).to(device)\n        \n        return x, y\n\n\ntrain_data = dataset(image_list[2000:], image_labels[2000:], get_training_augmentation(), device)#:26957#24000:26957\n\nprint(len(train_data))\n\ntrain_data = DataLoader(train_data, batch_size = 15, shuffle = True)\n\n##########\n# validation loader\nvalid_data = dataset(image_list[:2000], image_labels[:2000], transform_valid(), device)\nprint(len(valid_data))\nvalid_data = DataLoader(valid_data, batch_size = 15, shuffle = True)\n########","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:39:33.23285Z","iopub.execute_input":"2021-05-25T10:39:33.23314Z","iopub.status.idle":"2021-05-25T10:39:33.304784Z","shell.execute_reply.started":"2021-05-25T10:39:33.23311Z","shell.execute_reply":"2021-05-25T10:39:33.303801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = {\n    'train': train_data , \n    'val': valid_data\n}\n\ndataset_sizes = {\n    'train': 24957, #15000\n    'val': 2000 #3632\n}","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:39:47.144707Z","iopub.execute_input":"2021-05-25T10:39:47.145047Z","iopub.status.idle":"2021-05-25T10:39:47.149271Z","shell.execute_reply.started":"2021-05-25T10:39:47.145016Z","shell.execute_reply":"2021-05-25T10:39:47.14814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gallery(array, ncols=3):\n    nindex, height, width, intensity = array.shape\n    nrows = nindex//ncols\n    assert nindex == nrows * ncols\n    result = (array.reshape(nrows, ncols, height, width, intensity)\n              .swapaxes(1, 2)\n              .reshape(height*nrows, width*ncols, intensity))\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:39:48.267379Z","iopub.execute_input":"2021-05-25T10:39:48.267727Z","iopub.status.idle":"2021-05-25T10:39:48.273403Z","shell.execute_reply.started":"2021-05-25T10:39:48.26769Z","shell.execute_reply":"2021-05-25T10:39:48.272173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = read_img('../input/plant2021-downscaled-images-dataset/800113bb65efe69e.jpg')\nimages_aug = np.array([(get_training_augmentation()(image)).permute((1,2,0)).numpy() for _ in range(25)])\n\nplt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(gallery(images_aug, ncols=5))\nplt.title('Augmentation pipeline examples')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:39:49.263519Z","iopub.execute_input":"2021-05-25T10:39:49.263852Z","iopub.status.idle":"2021-05-25T10:39:49.865778Z","shell.execute_reply.started":"2021-05-25T10:39:49.26382Z","shell.execute_reply":"2021-05-25T10:39:49.864875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_training_augmentation()(image).numpy().reshape(1,3,224,224).shape","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:12.173847Z","iopub.execute_input":"2021-05-25T10:40:12.174268Z","iopub.status.idle":"2021-05-25T10:40:12.184722Z","shell.execute_reply.started":"2021-05-25T10:40:12.174235Z","shell.execute_reply":"2021-05-25T10:40:12.183578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = enet.EfficientNet.from_name('efficientnet-b7')\n\n# model.load_state_dict(torch.load('../input/efficientnet-pytorch/efficientnet-b7-dcc49843.pth'))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:14.442606Z","iopub.execute_input":"2021-05-25T10:40:14.443Z","iopub.status.idle":"2021-05-25T10:40:14.449325Z","shell.execute_reply.started":"2021-05-25T10:40:14.442963Z","shell.execute_reply":"2021-05-25T10:40:14.448328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport torch.nn as nn\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master\")\nfrom efficientnet_pytorch import model as enet\n\n\n\n\n\nmodel = enet.EfficientNet.from_name('efficientnet-b7')\nmodel.load_state_dict(torch.load('../input/efficientnet-pytorch/efficientnet-b7-dcc49843.pth'))#, map_location=torch.device('cpu')#../input/pytorch-efficientnet-my-version/best_model.pth\nmodel._fc = nn.Linear(in_features=2560, out_features=12).cuda()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:15.278924Z","iopub.execute_input":"2021-05-25T10:40:15.279277Z","iopub.status.idle":"2021-05-25T10:40:16.311202Z","shell.execute_reply.started":"2021-05-25T10:40:15.279246Z","shell.execute_reply":"2021-05-25T10:40:16.310207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model._fc","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:19.19639Z","iopub.execute_input":"2021-05-25T10:40:19.196697Z","iopub.status.idle":"2021-05-25T10:40:19.205826Z","shell.execute_reply.started":"2021-05-25T10:40:19.196668Z","shell.execute_reply":"2021-05-25T10:40:19.204985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass FocalLoss(nn.Module):\n    \"\"\"\n    The focal loss for fighting against class-imbalance\n    \"\"\"\n    def __init__(self, alpha=1, gamma=2):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.epsilon = 1e-12  # prevent training from Nan-loss error\n        self.cls_weights = torch.tensor([cls_weight],dtype=torch.float, requires_grad=False, device=device)\n\n    def forward(self, logits, target):\n        \"\"\"\n        logits & target should be tensors with shape [batch_size, num_classes]\n        \"\"\"\n        probs = torch.sigmoid(logits)\n        one_subtract_probs = 1.0 - probs\n        # add epsilon\n        probs_new = probs + self.epsilon\n        one_subtract_probs_new = one_subtract_probs + self.epsilon\n        # calculate focal loss\n        log_pt = target * torch.log(probs_new) + (1.0 - target) * torch.log(one_subtract_probs_new)\n        pt = torch.exp(log_pt)\n        focal_loss = -1.0 * (self.alpha * (1 - pt) ** self.gamma) * log_pt\n        focal_loss = focal_loss * self.cls_weights\n        return torch.mean(focal_loss)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:20.965857Z","iopub.execute_input":"2021-05-25T10:40:20.966215Z","iopub.status.idle":"2021-05-25T10:40:20.97664Z","shell.execute_reply.started":"2021-05-25T10:40:20.966186Z","shell.execute_reply":"2021-05-25T10:40:20.975921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class F1_Loss(nn.Module):\n\n    def __init__(self, epsilon=1e-7):\n        super().__init__()\n        self.epsilon = epsilon\n        \n    def forward(self, y_pred, y_true):\n        assert y_pred.ndim == 2\n        assert y_true.ndim == 1\n        y_true = torch.nn.functional.one_hot(y_true, 12).to(torch.float32)\n        y_pred = torch.nn.functional.softmax(y_pred, dim=1)\n        \n        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n        \n        precision = tp / (tp + fp + self.epsilon)\n        recall = tp / (tp + fn + self.epsilon)\n        \n        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n        return 1 - f1.mean()\n\nf1_loss = F1_Loss().cuda()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:21.865141Z","iopub.execute_input":"2021-05-25T10:40:21.865464Z","iopub.status.idle":"2021-05-25T10:40:21.874913Z","shell.execute_reply.started":"2021-05-25T10:40:21.865431Z","shell.execute_reply":"2021-05-25T10:40:21.873918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model._fc = nn.Linear(in_features=2560, out_features=12).cuda()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:22.690184Z","iopub.execute_input":"2021-05-25T10:40:22.690495Z","iopub.status.idle":"2021-05-25T10:40:22.694906Z","shell.execute_reply.started":"2021-05-25T10:40:22.690465Z","shell.execute_reply":"2021-05-25T10:40:22.693608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.optim import lr_scheduler\n\n# model._fc = torch.nn.Linear(in_features=1280, out_features=classes) #change the last FC layer\n\nmodel = model.to(device)\ncriterion = FocalLoss().to(device) #nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001) # lr, SGD\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:26.214453Z","iopub.execute_input":"2021-05-25T10:40:26.214944Z","iopub.status.idle":"2021-05-25T10:40:26.371169Z","shell.execute_reply.started":"2021-05-25T10:40:26.214899Z","shell.execute_reply":"2021-05-25T10:40:26.370233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_sizes","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:27.479891Z","iopub.execute_input":"2021-05-25T10:40:27.480222Z","iopub.status.idle":"2021-05-25T10:40:27.486239Z","shell.execute_reply.started":"2021-05-25T10:40:27.480186Z","shell.execute_reply":"2021-05-25T10:40:27.48507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport copy\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                optimizer.step()\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.reshape(-1).to(device) #\n                #print(labels)\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, torch.nn.functional.one_hot(labels, num_classes=12).long())\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                torch.save(model.state_dict(), 'best_model.pth')\n\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:30.131511Z","iopub.execute_input":"2021-05-25T10:40:30.131856Z","iopub.status.idle":"2021-05-25T10:40:30.144441Z","shell.execute_reply.started":"2021-05-25T10:40:30.131824Z","shell.execute_reply":"2021-05-25T10:40:30.143213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T10:40:31.544124Z","iopub.execute_input":"2021-05-25T10:40:31.544441Z","iopub.status.idle":"2021-05-25T15:11:13.57258Z","shell.execute_reply.started":"2021-05-25T10:40:31.544411Z","shell.execute_reply":"2021-05-25T15:11:13.571412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_valid(?)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:35:18.882328Z","iopub.execute_input":"2021-05-22T18:35:18.882819Z","iopub.status.idle":"2021-05-22T18:35:18.892974Z","shell.execute_reply.started":"2021-05-22T18:35:18.882777Z","shell.execute_reply":"2021-05-22T18:35:18.891708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\nvalid_image_list = glob('../input/plant-pathology-2021-fgvc8/test_images/*.jpg')\n\nmodel.eval()\npredict_list = []\nimage_name_list = []\nfor i, image in tqdm(enumerate(valid_image_list)) :\n    image_name = image[48:]\n    \n    img = read_img(image)\n    img = transform_valid()(img)\n    \n    result_list = torch.FloatTensor(np.zeros((classes))).to(device)\n    img = img.to(device)\n    img = img.reshape(-1, 3, 224, 224)\n    predict = model(img)\n    predict = predict.reshape(-1)\n    result_list += predict\n    \n    predict_list.append(torch.argmax(result_list).item())\n    image_name_list.append(image_name)\n    \npredict_list = np.array(predict_list)\nimage_name_list = np.array(image_name_list)\nprint(image_name_list)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['image'] = image_name_list\nsubmission_df['label_id'] = predict_list\nsubmission_df['labels'] = submission_df['label_id'].map(label_dic)\ndel submission_df['label_id']\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:35:20.293534Z","iopub.execute_input":"2021-05-22T18:35:20.293913Z","iopub.status.idle":"2021-05-22T18:35:21.006064Z","shell.execute_reply.started":"2021-05-22T18:35:20.293881Z","shell.execute_reply":"2021-05-22T18:35:21.004624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:35:26.1364Z","iopub.execute_input":"2021-05-22T18:35:26.136985Z","iopub.status.idle":"2021-05-22T18:35:26.151384Z","shell.execute_reply.started":"2021-05-22T18:35:26.136925Z","shell.execute_reply":"2021-05-22T18:35:26.149583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T18:35:32.870661Z","iopub.execute_input":"2021-05-22T18:35:32.871064Z","iopub.status.idle":"2021-05-22T18:35:33.211365Z","shell.execute_reply.started":"2021-05-22T18:35:32.87103Z","shell.execute_reply":"2021-05-22T18:35:33.210437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}