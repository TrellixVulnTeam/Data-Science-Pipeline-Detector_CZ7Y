{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle: Plant Pathology 2021 - FGVC8\n\nto use these dataset and models out of the box simple install https://github.com/Borda/kaggle_plant-pathology","metadata":{}},{"cell_type":"code","source":"! pip install pytorch-lightning -q\n! pip list | grep torch\n! nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data exploration\n\nChecking what data do we have available and what is the labels distribution...","metadata":{}},{"cell_type":"code","source":"# jsu to see what is the data location\n! ls /kaggle/input -l\n! ls /kaggle/input/plant-pathology-2021-fgvc8 -l\n! ls /kaggle/input/plant-pathology-2021-fgvc8-960px -l\n\n# ! apt-get install -qq -y imagemagick --fix-missing\n# #! mogrify -resize 960 /kaggle/input/plant-pathology-2021-fgvc8/train_images/*.jpg\n\n# import os, tqdm, glob\n# import multiprocessing\n\n# ls_images = glob.glob(\"/kaggle/input/plant-pathology-2021-fgvc8/train_images/*.jpg\")\n# print(f'found images: {len(ls_images)}')\n\n# def _convert(pimg: str):\n#     os.system(f'convert -resize 960 point {pimg} {pimg}')\n\n# nb_cpu = multiprocessing.cpu_count()\n# pbar = tqdm.tqdm(total=len(ls_images), desc=f\"using {nb_cpu} proc.\")\n# pool = multiprocessing.Pool(processes=nb_cpu)\n# for i, _ in enumerate(pool.imap(_convert, ls_images)):\n#     if i % 250 == 0:  # updtae only N steps to reduce update load\n#         pbar.update(250)\n# pool.close()\n# pool.join() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking in the training dataset table, what colums and what is the data representation...","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\nimport os\nimport json\nimport pandas as pd\nfrom pprint import pprint\n\nbase_path = '/kaggle/input/plant-pathology-2021-fgvc8-960px'\npath_csv = os.path.join(base_path, 'train.csv')\ntrain_data = pd.read_csv(path_csv)\nprint(train_data.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that each image can have multiple labels so lets check what is the mos common label count...\n\n*The target classes, a space delimited list of all diseases found in the image.\nUnhealthy leaves with too many diseases to classify visually will have the complex class, and may also have a subset of the diseases identified.*","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ntrain_data['nb_classes'] = [len(lbs.split(\" \")) for lbs in train_data['labels']]\nlb_hist = dict(zip(range(10), np.bincount(train_data['nb_classes'])))\npprint(lb_hist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Browse the label distribution, enrolling all labels in the dataset, so in case an image has two labels both are used in this stat...","metadata":{}},{"cell_type":"code","source":"import itertools\nimport seaborn as sns\n\nlabels_all = list(itertools.chain(*[lbs.split(\" \") for lbs in train_data['labels']]))\n\nax = sns.countplot(y=sorted(labels_all), orient='v')\nax.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get some stat for labels combinations...","metadata":{}},{"cell_type":"code","source":"labels_unique = set(labels_all)\nprint(f\"unique labels: {labels_unique}\")\ntrain_data['labels_sorted'] = [\" \".join(sorted(lbs.split(\" \"))) for lbs in train_data['labels']]\n\nlabels_combine = {}\nfor comb in train_data['labels_sorted']:\n    labels_combine[comb] = labels_combine.get(comb, 0) + 1\n\nshow_counts = '\\n'.join(sorted(f'\\t{k}: {v}' for k, v in labels_combine.items()))\nprint(f\"unique combinations: \\n\" + show_counts)\nprint(f\"total: {sum(labels_combine.values())}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And add visualisation over each case, so five a few examples per labe combination...","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nnb_samples = 6\nn, m = len(np.unique(train_data['labels_sorted'])), nb_samples,\nfig, axarr = plt.subplots(nrows=n, ncols=m, figsize=(m * 2, n * 2))\nfor ilb, (lb, df_) in enumerate(train_data.groupby('labels_sorted')):\n    img_names = list(df_['image'])\n    for i in range(m):\n        img_name = img_names[i]\n        img = plt.imread(os.path.join(base_path, f\"train_images/{img_name}\"))\n        axarr[ilb, i].imshow(img)\n        if i == 0:\n            axarr[ilb, i].set_title(f\"{lb} #{len(df_)}\")\n        axarr[ilb, i].set_xticks([])\n        axarr[ilb, i].set_yticks([])\nplt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset & DataModule\n\nCreating standard PyTorch dataset to define how the data shall be loaded and set representations.\nWe define the sample pair as:\n - RGB image\n - one-hot lable encding\n\nA DataModule standardizes the training, val, test splits, data preparation and transforms.\nThe main advantage is consistent data splits, data preparation and transforms across models.","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\nclass PlantPathologyDataset(Dataset):\n    def __init__(\n        self,\n        path_csv: str = os.path.join(base_path, 'train.csv'),\n        path_img_dir: str = os.path.join(base_path, 'train_images'),\n        transforms = None,\n        mode: str = 'train',\n        split: float = 0.8,\n    ):\n        self.path_img_dir = path_img_dir\n        self.transforms = transforms\n        self.mode = mode\n\n        self.data = pd.read_csv(path_csv)\n        labels_all = list(itertools.chain(*[lbs.split(\" \") for lbs in self.data['labels']]))\n        self.labels_unique = sorted(set(labels_all))\n        self.labels_lut = {lb: i for i, lb in enumerate(self.labels_unique)}\n        self.num_classes = len(self.labels_unique)\n        # shuffle data\n        self.data = self.data.sample(frac=1, random_state=42).reset_index(drop=True)\n\n        # split dataset\n        assert 0.0 <= split <= 1.0\n        frac = int(split * len(self.data))\n        self.data = self.data[:frac] if mode == 'train' else self.data[frac:]\n        self.img_names = list(self.data['image'])\n        self.labels = list(self.data['labels'])\n\n    def to_one_hot(self, labels: str) -> tuple:\n        one_hot = [0] * len(self.labels_unique)\n        for lb in labels.split(\" \"):\n            one_hot[self.labels_lut[lb]] = 1\n        return tuple(one_hot)\n\n    def __getitem__(self, idx: int) -> tuple:\n        img_path = os.path.join(self.path_img_dir, self.img_names[idx])\n        assert os.path.isfile(img_path)\n        label = self.labels[idx]\n        img = plt.imread(img_path)\n\n        # augmentation\n        if self.transforms:\n            img = self.transforms(Image.fromarray(img))\n        label = self.to_one_hot(label)\n        return img, torch.tensor(label)\n\n    def __len__(self) -> int:\n        return len(self.data)\n\n# ==============================\n# ==============================\n\ndataset = PlantPathologyDataset()\n\n# quick view\nfig = plt.figure(figsize=(9, 6))\nfor i in range(9):\n    img, lb = dataset[i]\n    ax = fig.add_subplot(3, 3, i + 1, xticks=[], yticks=[])\n    ax.imshow(img)\n    ax.set_title(lb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us define some standard image augmentaion procedures and color normalizations...","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms as T\n\nTRAIN_TRANSFORM = T.Compose([\n    T.Resize(512),\n    T.RandomPerspective(),\n    T.RandomResizedCrop(224),\n    T.RandomHorizontalFlip(),\n    T.RandomVerticalFlip(),\n    T.ToTensor(),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    # T.Normalize([0.431, 0.498,  0.313], [0.237, 0.239, 0.227]),  # custom\n])\n\nVALID_TRANSFORM = T.Compose([\n    T.Resize(256),\n    T.CenterCrop(224),\n    T.ToTensor(),\n    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    # T.Normalize([0.431, 0.498,  0.313], [0.237, 0.239, 0.227]),  # custom\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The DataModule include creating training and validation dataset with given split and feading it to particular data loaders...","metadata":{}},{"cell_type":"code","source":"import multiprocessing as mproc\nimport pytorch_lightning as pl\nfrom torch.utils.data import DataLoader\n\nclass PlantPathologyDM(pl.LightningDataModule):\n    dataset_cls = PlantPathologyDataset\n\n    def __init__(\n        self,\n        path_csv: str = os.path.join(base_path, 'train.csv'),\n        path_img_dir: str = os.path.join(base_path, 'train_images'),\n        batch_size: int = 128,\n        num_workers: int = None,\n    ):\n        super().__init__()\n        self.path_csv = path_csv\n        self.path_img_dir = path_img_dir\n        self.batch_size = batch_size\n        self.num_workers = num_workers if num_workers is not None else mproc.cpu_count()\n        self.train_dataset = None\n        self.valid_dataset = None\n\n    def prepare_data(self):\n        pass\n\n    @property\n    def num_classes(self) -> int:\n        assert self.train_dataset and self.valid_dataset\n        return max(self.train_dataset.num_classes, self.valid_dataset.num_classes)\n\n    def setup(self, stage=None):\n        self.train_dataset = self.dataset_cls(self.path_csv, self.path_img_dir, mode='train', transforms=TRAIN_TRANSFORM)\n        print(f\"training dataset: {len(self.train_dataset)}\")\n        self.valid_dataset = self.dataset_cls(self.path_csv, self.path_img_dir, mode='valid', transforms=VALID_TRANSFORM)\n        print(f\"validation dataset: {len(self.valid_dataset)}\")\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            shuffle=True,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.valid_dataset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            shuffle=False,\n        )\n\n    def test_dataloader(self):\n        pass\n\n# ==============================\n# ==============================\n\ndm = PlantPathologyDM()\ndm.setup()\nprint(dm.num_classes)\n\n# quick view\nfig = plt.figure(figsize=(3, 7))\nfor imgs, lbs in dm.train_dataloader():\n    print(f'batch labels: {torch.sum(lbs, axis=0)}')\n    print(f'image size: {imgs[0].shape}')\n    for i in range(3):\n        ax = fig.add_subplot(3, 1, i + 1, xticks=[], yticks=[])\n        # print(np.rollaxis(imgs[i].numpy(), 0, 3).shape)\n        ax.imshow(np.rollaxis(imgs[i].numpy(), 0, 3))\n        ax.set_title(lbs[i])\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model\n\nWe start with some stanrd CNN models taken from torch vision.\nThen we define Ligthning module including training and validation step and configure optimizer/schedular.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchmetrics\nimport torchvision\nfrom torch import nn\nfrom torch.nn import functional as F\n\n\nclass LitResnet(nn.Module):\n    def __init__(self, arch: str, pretrained: bool = True, num_classes: int = 6):\n        super().__init__()\n        self.arch = arch\n        self.num_classes = num_classes\n        self.model = torchvision.models.__dict__[arch](pretrained=pretrained)\n        num_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_features, num_classes)\n\n    def forward(self, x):\n        return self.model(x)\n\n\nclass LitPlantPathology(pl.LightningModule):\n\n    def __init__(self, model, lr: float = 1e-4):\n        super().__init__()\n        self.model = model\n        self.arch = self.model.arch\n        self.num_classes = self.model.num_classes\n        self.train_accuracy = torchmetrics.Accuracy()\n        self.val_accuracy = torchmetrics.Accuracy()\n        self.val_f1_score = torchmetrics.F1(self.num_classes)\n        self.learn_rate = lr\n        self.loss = nn.BCEWithLogitsLoss()\n\n    def forward(self, x):\n        return F.sigmoid(self.model(x))\n\n    def compute_loss(self, y_hat, y):\n        return self.loss(y_hat, y.to(float))\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.compute_loss(y_hat, y)\n        self.log(\"train_loss\", loss, prog_bar=True)\n        self.log(\"train_acc\", self.train_accuracy(y_hat, y), prog_bar=False)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.compute_loss(y_hat, y)\n        self.log(\"valid_loss\", loss, prog_bar=False)\n        self.log(\"valid_acc\", self.val_accuracy(y_hat, y), prog_bar=True)\n        self.log(\"valid_f1\", self.val_f1_score(y_hat, y), prog_bar=True)\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learn_rate)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, self.trainer.max_epochs, 0)\n        return [optimizer], [scheduler]\n\n# ==============================\n# ==============================\n\n# see: https://pytorch.org/vision/stable/models.html\nnet = LitResnet(arch='resnet50', num_classes=dm.num_classes)\n# print(net)\nmodel = LitPlantPathology(model=net)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training\n\nWe use Pytorch Lightning which allow us to drop all the boilet plate code and simplify all training just to use/call Trainer...","metadata":{}},{"cell_type":"code","source":"# # Step 1: Install Torch-XLA (PyTorch with Accelerated Linear Algebra (XLA) support)\n# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n# !python pytorch-xla-env-setup.py --version 1.8 --apt-packages libomp5 libopenblas-dev\n# ! pip install -q https://github.com/PyTorchLightning/pytorch-lightning/archive/refs/heads/master.zip\n# !pip list | grep torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = pl.loggers.CSVLogger(save_dir='logs/', name=model.arch)\n\n# ==============================\n\ntrainer = pl.Trainer(\n    # fast_dev_run=True,\n    gpus=1,\n    # tpu_cores=8,\n    # callbacks=[swa],\n    logger=logger,\n    max_epochs=10,\n    #precision=16,\n    accumulate_grad_batches=8,\n    val_check_interval=0.25,\n    progress_bar_refresh_rate=1,\n    weights_summary='top',\n)\n\n# ==============================\n\n# trainer.tune(model, datamodule=dm)\ntrainer.fit(model=model, datamodule=dm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Quick visualization of the training process...","metadata":{}},{"cell_type":"code","source":"metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\nprint(metrics.head())\n\naggreg_metrics = []\nagg_col = \"epoch\"\nfor i, dfg in metrics.groupby(agg_col):\n    agg = dict(dfg.mean())\n    agg[agg_col] = i\n    aggreg_metrics.append(agg)\n\ndf_metrics = pd.DataFrame(aggreg_metrics)\ndf_metrics[['train_loss', 'valid_loss']].plot(grid=True, legend=True, xlabel=agg_col)\ndf_metrics[['valid_f1', 'valid_acc', 'train_acc']].plot(grid=True, legend=True, xlabel=agg_col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}