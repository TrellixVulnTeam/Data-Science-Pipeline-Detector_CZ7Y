{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## How I created my model.\n\n1. I created two datasets basing on [PP2021 - Ultimate Preprocessing](https://www.kaggle.com/nickuzmenkov/pp2021-ultimate-preprocessing) notebook. Particular dataset was divided into augmented trainset and not augmented validationset. Unlike original notebook I replaced rough resize of image with resize shorter axis to arbitrary size (224 for cassava model and 640 for iception model), subsequently cropped randomly desirable image. \n2. Both models were trained on augmented sets. On validation sets results for f1 measure were over 90% and over 85%  respectively for cassava and inception models.\n3. In order to concatenate results I used original not augmented full dataset and created multilabel tree model with 12 input variables and 6 output.\n4. Later I noticed that because of random crop of image I am getting different results with every run. So I calculate results on 3 different crops and average results. Later I found that multiplaing results of models by some coefficient give me better results on LB. \n5. Results of my model because of such approach differ with every run but my best results I obtained with previous run was 0.761.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow_hub as hub\nfrom tensorflow.keras.applications import InceptionResNetV2\nimport tensorflow_addons as tfa\nimport albumentations\nimport PIL\nimport matplotlib.pyplot as plt\nfrom multiprocessing import Pool\nimport pickle\nimport shutil","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 640\ntransform = albumentations.Compose([\n    albumentations.SmallestMaxSize(max_size=image_size),\n    albumentations.RandomCrop(image_size,image_size)\n    ])\n\nos.mkdir('./Pictures1')\nos.mkdir('./Pictures2')\nos.mkdir('./Pictures3')\ndf = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv').iloc[:,0]\n\ndef save_img(df):\n    for p in df:\n        img = PIL.Image.open('../input/plant-pathology-2021-fgvc8/test_images/'+p)\n        img = np.asarray(img)\n        for n in ['1','2','3']:\n            img1 = transform(image=img)['image']\n            img1 = PIL.Image.fromarray(img1.astype('uint8'), 'RGB')\n            img1.save('./Pictures'+n+'/'+p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = df.shape[0]//4\nwith Pool(4) as p:\n    p.map(save_img, [df.iloc[0:l],df.iloc[l:(2*l)],df.iloc[(2*l):(3*l)],df.iloc[(3*l):]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,15))\nax1.imshow(PIL.Image.open('./Pictures1/'+df[0]))\nax2.imshow(PIL.Image.open('./Pictures2/'+df[0]))\nax3.imshow(PIL.Image.open('./Pictures3/'+df[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(folder):\n    def load_image(image_path):\n        img = tf.io.read_file('./Pictures'+folder+'/'+image_path)\n        img = tf.image.decode_jpeg(img, channels=3)\n        img = tf.cast(img, tf.float32) / 255.\n        return img\n    return load_image\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ntraining_data = tf.data.Dataset.from_tensor_slices(df)\n\ntraining_data1 = training_data.map(load_image('1'), num_parallel_calls=AUTOTUNE)\ntraining_data_batches1 = training_data1.batch(16).prefetch(buffer_size=AUTOTUNE)\n\ntraining_data2 = training_data.map(load_image('2'), num_parallel_calls=AUTOTUNE)\ntraining_data_batches2 = training_data2.batch(16).prefetch(buffer_size=AUTOTUNE)\n\ntraining_data3 = training_data.map(load_image('3'), num_parallel_calls=AUTOTUNE)\ntraining_data_batches3 = training_data3.batch(16).prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -R ../input/cassava-layer/ /kaggle/working/cassava-layer/\nos.environ[\"TFHUB_CACHE_DIR\"] = \"/kaggle/working/cassava-layer/\"\n\ncassava = hub.KerasLayer('https://tfhub.dev/google/cropnet/classifier/cassava_disease_V1/2', \n                         trainable=False)\nmodel = tf.keras.Sequential([tf.keras.Input(shape=(224,224,3)),\n                            cassava])\nmodel.load_weights('../input/apple-train-cassava/cassava_model_weights.h5')\ninputs = keras.Input(shape=(image_size,image_size,3))\nresize = keras.layers.experimental.preprocessing.Resizing(224, 224)(inputs)\noutput = model(resize)\nmodel_2 = keras.Model(inputs, output, name = 'model_2')\n\nmodel_1 = tf.keras.Sequential([\n        InceptionResNetV2(\n            input_shape=(image_size, image_size, 3),\n            weights=None,\n            include_top=False\n        ),\n        keras.layers.GlobalMaxPooling2D(),\n        keras.layers.Dense(6, activation='softmax')\n    ], name = 'model_1')\nmodel_1.load_weights('../input/apple-train-inception/inception_model_weights.h5')\nmodel_1.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = keras.Input(shape=(image_size,image_size,3))\nx = model_1(inputs)\ny = model_2(inputs)\noutput = tf.keras.layers.Concatenate()([x, y])\n\nmodel = keras.Model(inputs, output, name = 'model')\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1=model.predict(training_data_batches1) \nX2=model.predict(training_data_batches2) \nX3=model.predict(training_data_batches3) \nX=X1+X2+X3\nX=X/3 * 1.4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pkl_filename = \"../input/apple-train-tree/tree_model.pkl\"\nwith open(pkl_filename, 'rb') as file:\n    pickle_model = pickle.load(file)\n\nresponse = pickle_model.predict(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = response.tolist()\n\nindices = []\nfor pred in preds:\n    temp = []\n    for i in range(6):\n        if pred[i]==1:\n            temp.append(i)\n    if temp!=[]:\n        indices.append(temp)\n    else:\n        temp.append(np.argmax(pred))\n        indices.append(temp)\n    \nprint(indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['complex', 'frog_eye_leaf_spot', 'powdery_mildew', 'rust', 'scab', 'healthy']\n\ntestlabels = []\n\n\nfor image in indices:\n    temp = []\n    for i in image:\n        temp.append(str(labels[i]))\n    testlabels.append(' '.join(temp))\n\nprint(testlabels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\nsub['labels'] = testlabels\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.rmtree('./Pictures1')\nshutil.rmtree('./Pictures2')\nshutil.rmtree('./Pictures3')\nshutil.rmtree('./cassava-layer')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}