{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/plant-pathology-2021-fgvc8/train.csv\")\ntrain['labels'] = train['labels'].apply(lambda s: s.split(' '))\ntrain['labels'][:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Instantiation\nAlexNet = Sequential()\n\n#1st Convolutional Layer\nAlexNet.add(Conv2D(filters=96, input_shape=(256,256,3), kernel_size=(11,11), strides=(4,4), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n#2nd Convolutional Layer\nAlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n#3rd Convolutional Layer\nAlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n\n#4th Convolutional Layer\nAlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n\n#5th Convolutional Layer\nAlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\nAlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n\n\n#Passing it to a Fully Connected layer\nAlexNet.add(Flatten())\n# 1st Fully Connected Layer\nAlexNet.add(Dense(4096, input_shape=(32,32,3,)))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n# Add Dropout to prevent overfitting\nAlexNet.add(Dropout(0.4))\n\n#2nd Fully Connected Layer\nAlexNet.add(Dense(4096))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n#Add Dropout\nAlexNet.add(Dropout(0.4))\n\n#3rd Fully Connected Layer\nAlexNet.add(Dense(4096))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('relu'))\n#Add Dropout\nAlexNet.add(Dropout(0.4))\n\n#Output Layer\nAlexNet.add(Dense(6))\nAlexNet.add(BatchNormalization())\nAlexNet.add(Activation('softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AlexNet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport tensorflow_addons as tfa\nimport keras as keras\nf1 = tfa.metrics.F1Score(num_classes=6, average='macro')\nAlexNet.compile(loss = \"binary_crossentropy\", optimizer= keras.optimizers.SGD(lr=0.03, decay=1e-4, momentum=0.8, nesterov=True),\n                metrics=[f1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_gauss_noise(x,sigma2=0.05):\n    return x+np.random.normal(0, sigma2, x.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range = 10,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    brightness_range = None,\n    shear_range = 0.1,\n    zoom_range = 0.1,\n    rescale = 1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    preprocessing_function = add_gauss_noise,\n    validation_split= 0.1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bsize = 16\ntrain_data = datagen.flow_from_dataframe(\n    train,\n    directory = '../input/resized-plant2021/img_sz_256',\n    x_col = 'image',\n    y_col = 'labels',\n    subset=\"training\",\n    color_mode=\"rgb\",\n    target_size = (256,256),\n    class_mode=\"categorical\",\n    batch_size=bsize,\n    shuffle=False,\n    seed=40,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_data = datagen.flow_from_dataframe(\n    train,\n    directory = '../input/resized-plant2021/img_sz_256',\n    x_col = 'image',\n    y_col = 'labels',\n    subset=\"validation\",\n    color_mode=\"rgb\",\n    target_size = (256,256),\n    class_mode=\"categorical\",\n    batch_size=bsize,\n    shuffle=False,\n    seed=40,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks_list=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = AlexNet.fit(\n    train_data,  \n#             steps_per_epoch=1,    \n            epochs=15,\n            callbacks=callbacks_list, \n            validation_data=valid_data, \n#             validation_steps = 1,\n            verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accname = 'f1_score'\n\ndef plot_history(history): \n    fig, ax1 = plt.subplots()\n    \n    ax1.plot(history.history['loss'], 'r', label=\"training loss ({:.6f})\".format(history.history['loss'][-1]))\n    ax1.plot(history.history['val_loss'], 'r--', label=\"validation loss ({:.6f})\".format(history.history['val_loss'][-1]))\n    ax1.grid(True)\n    ax1.set_xlabel('iteration')\n    ax1.legend(loc=\"best\", fontsize=9)    \n    ax1.set_ylabel('loss', color='r')\n    ax1.tick_params('y', colors='r')\n\n    if accname in history.history:\n        ax2 = ax1.twinx()\n\n        ax2.plot(history.history[accname], 'b', label=\"training f1_score ({:.4f})\".format(history.history[accname][-1]))\n        ax2.plot(history.history['val_'+accname], 'b--', label=\"validation f1_score ({:.4f})\".format(history.history['val_'+accname][-1]))\n\n        ax2.legend(loc=\"lower right\", fontsize=9)\n        ax2.set_ylabel('acc', color='b')        \n        ax2.tick_params('y', colors='b')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, f1score = AlexNet.evaluate_generator(valid_data,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport PIL\n\ntest = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\n\nfor img_name in tqdm(test['image']):\n    path = '../input/plant-pathology-2021-fgvc8/test_images/'+str(img_name)\n    with PIL.Image.open(path) as img:\n        img = img.resize((256,256))\n        img.save(f'./{img_name}')\n        \ntest_data = datagen.flow_from_dataframe(\n    test,\n    directory = './',\n    x_col=\"image\",\n    y_col= None,\n    color_mode=\"rgb\",\n    target_size = (256,256),\n    classes=None,\n    class_mode=None,\n    batch_size=bsize,\n    shuffle=False,\n    seed=40,\n)\nbest_threshold = 0.4\npreds = AlexNet.predict(test_data)\nprint(preds)\npreds = preds.tolist()\n\nindices = []\nfor pred in preds:\n    temp = []\n    for category in pred:\n        if category>=best_threshold:\n            temp.append(pred.index(category))\n    if temp!=[]:\n        indices.append(temp)\n    else:\n        temp.append(np.argmax(pred))\n        indices.append(temp)\n    \nprint(indices)\nlabels = (train_data.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nprint(labels)\n\ntestlabels = []\n\n\nfor image in indices:\n    temp = []\n    for i in image:\n        temp.append(str(labels[i]))\n    testlabels.append(' '.join(temp))\n\nprint(testlabels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delfiles = tf.io.gfile.glob('./*.jpg')\n\nfor file in delfiles:\n    os.remove(file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/plant-pathology-2021-fgvc8/sample_submission.csv')\nsub['labels'] = testlabels\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}