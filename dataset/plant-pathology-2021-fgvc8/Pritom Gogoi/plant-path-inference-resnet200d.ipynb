{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install /kaggle/input/timmwhl/timm-0.4.5-py3-none-any.whl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## imports","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport random\nimport cv2\n\nimport timm\nimport torch\nimport torch.optim as optim\nfrom torch.optim import Adam\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport torchvision\n\nfrom tqdm.notebook import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialization\ntrain_csv_loc= '../input/plant-pathology-2021-fgvc8/train.csv' \ntest_csv_loc='../input/plant-pathology-2021-fgvc8/sample_submission.csv'\ntest_image_loc = '../input/plant-pathology-2021-fgvc8/test_images'\ntrain_image_loc = '../input/plant-pathology-2021-fgvc8/train_images'\n\ndata_csv = pd.read_csv(train_csv_loc)\ntest_csv = pd.read_csv(test_csv_loc)\nsub_csv = data_csv[:200]\n\nimage_size = 288\nmodel_name = 'resnet200d'\nseed = 719\nbatch_size = 32\nnum_workers = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Processing the dataset csv","metadata":{}},{"cell_type":"code","source":"# GPU settings\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class parseDataset(Dataset):\n    def __init__(self, out_csv, image_loc, transform=None, test=False):\n        self.out_csv = out_csv\n        self.image_loc = image_loc\n        self.transform = transform\n        self.test = test\n\n    def __len__(self):\n        return len(self.out_csv)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.image_loc,\n                                self.out_csv.iloc[idx, 0])\n        image = cv2.imread(img_name)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#         image = image.astype(np.uint8)\n        if self.transform:\n            image = self.transform(image)\n        \n        if self.test:\n            return image\n        else:\n            categories = self.out_csv.iloc[idx,1:]\n            categories = np.array(categories)\n            categories = categories.astype(np.uint8)\n            sample = [image, categories]\n\n            return sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Resize((image_size, image_size)),\n        transforms.Normalize(\n         mean=[0.485, 0.456, 0.406],\n         std=[0.229, 0.224, 0.225],\n     ),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## define model","metadata":{}},{"cell_type":"code","source":"class ResNet200D(nn.Module):\n    def __init__(self, model_name='resnet200d'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        \n        # load pretrained weights\n        self.model.load_state_dict(torch.load('../input/resnet200dpretrainedweights/resnet200d_ra2-bdba9bf9.pth'))\n        \n#         self.model.conv1[0].in_channels = 1\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n      \n        self.fc = nn.Sequential(\n                        nn.Linear(n_features, 256),\n                        nn.Dropout(p=0.2),\n                        nn.Linear(256, 6),\n                    )\n    \n        for param in self.model.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = ResNet200D(model_name = 'resnet200d')\nnet = net.to(device)\n# print(net)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAST_WEIGHT_PATH = '../input/plantpathweightsresnet288x288/resnet200d_fold_0_epoch_50.pth'\nif device == 'cpu':\n    net.load_state_dict(torch.load(LAST_WEIGHT_PATH, map_location=torch.device('cpu')))\nelse:\n    net.load_state_dict(torch.load(LAST_WEIGHT_PATH, map_location=torch.device('cpu')))\n    \nprint(\"[INFO] weights loaded to \" + device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## testing","metadata":{}},{"cell_type":"code","source":"labels = {'0': 'complex', '1': 'frog_eye_leaf_spot', '2': 'healthy', '3': 'powdery_mildew', '4': 'rust', '5': 'scab'}\ninv_labels = {'complex': 0, 'frog_eye_leaf_spot': 1, 'healthy': 2, 'powdery_mildew': 3, 'rust': 4, 'scab': 5}\n\ndef get_labels(row, labels, ths):\n    try:\n        row = [i for i, x in enumerate(row) if x > ths[i]]\n        row = [labels[str(i)] for i in row]\n        if ('healthy' in row or len(row) == 0):\n            row = 'healthy'\n        elif 'complex' in row:\n            row = 'complex'\n        else:\n            row = ' '.join(row)\n\n    except:\n        print(row)\n    return row","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\n\ndef inference(in_csv, img_loc, device, net, criterion):\n\n    batch_size = min(len(in_csv), 25)\n\n    # parse dataset and create dataloader\n    test_dataset = parseDataset(in_csv, img_loc, transform = data_transform, test=True)\n    test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=2)\n\n    preds_list = []\n\n    # get output\n    t = tqdm(test_dataloader, desc='testing: ', colour=\"#557f50\")\n    for images in t:\n        images = images.to(device)\n\n        outputs = net(images)\n\n        preds = outputs.sigmoid().detach().cpu().numpy()\n        preds_list += [ preds ]\n    return np.array(preds_list).reshape((-1, 6))\n\nrepeat = 2\ntmp_p_list = []\nfor i in range(repeat):\n    p_list = inference(test_csv, test_image_loc, device, net, criterion)\n    tmp_p_list.append(p_list)\n    \n# average over some inferences\np_list = np.array(tmp_p_list).mean(axis = 0)\n\n# from experiments\nths = [0.21000000000000002, 0.27, 0.51, 0.25, 0.08, 0.45]\ntest_csv['labels'] = [get_labels(x, labels, ths) for x in p_list]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}