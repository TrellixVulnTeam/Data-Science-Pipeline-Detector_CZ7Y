{"cells":[{"metadata":{"papermill":{"duration":0.035338,"end_time":"2021-01-01T21:01:42.166436","exception":false,"start_time":"2021-01-01T21:01:42.131098","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Prequels/sequels\n\n- **Kaggle Machine Learning & Data Science (data-prep)** | [Extended Dataset](https://www.kaggle.com/neomatrix369/kaggle-machine-learning-data-science-survey-ext) | [Additional Dataset](https://www.kaggle.com/neomatrix369/world-bank-data-1960-to-2016-extended)\n- [Kaggle Global Outreach (analysis)](https://www.kaggle.com/neomatrix369/kaggle-global-outreach-analysis/)"},{"metadata":{"papermill":{"duration":0.033772,"end_time":"2021-01-01T21:01:42.234475","exception":false,"start_time":"2021-01-01T21:01:42.200703","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Installing and importing libraries and packages"},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-01-01T21:01:42.306437Z","iopub.status.busy":"2021-01-01T21:01:42.305827Z","iopub.status.idle":"2021-01-01T21:01:51.17632Z","shell.execute_reply":"2021-01-01T21:01:51.175726Z"},"papermill":{"duration":8.907783,"end_time":"2021-01-01T21:01:51.17644","exception":false,"start_time":"2021-01-01T21:01:42.268657","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!pip install -U missingno","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install fuzzywuzzy","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-01-01T21:01:51.263814Z","iopub.status.busy":"2021-01-01T21:01:51.262908Z","iopub.status.idle":"2021-01-01T21:01:52.309976Z","shell.execute_reply":"2021-01-01T21:01:52.309325Z"},"papermill":{"duration":1.096734,"end_time":"2021-01-01T21:01:52.310086","exception":false,"start_time":"2021-01-01T21:01:51.213352","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numexpr\nimport math\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport missingno as msno\n\nimport gc\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"whitegrid\", font_scale=1.75)\n\n# prettify plots\nplt.rcParams['figure.figsize'] = [20.0, 5.0]\nsns.set_palette(sns.color_palette(\"muted\"))\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.035615,"end_time":"2021-01-01T21:01:52.382204","exception":false,"start_time":"2021-01-01T21:01:52.346589","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Loading datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"def strip_spaces_from_all_columns(dataframe: pd.DataFrame) -> pd.DataFrame:\n    string_type_cols = dataframe.columns[\n        (dataframe.dtypes == 'object') | \n        (dataframe.dtypes == 'str')\n    ]\n    \n    for each_column in string_type_cols:\n        dataframe[each_column] = dataframe[each_column].apply(lambda x: x.strip() if type(x) == 'str' else x)\n\n    category_type_cols = dataframe.columns[dataframe.dtypes == 'category']\n    for each_column in category_type_cols:\n        dataframe[each_column] = dataframe[each_column].astype('str')\n        dataframe[each_column] = dataframe[each_column].apply(lambda x: x.strip())\n        dataframe[each_column] = dataframe[each_column].astype('category')\n    \n    if (len(string_type_cols) > 0) or (len(category_type_cols) > 0):\n        print(f'Stripped leading and trailing spaces from these columns: {string_type_cols}, {category_type_cols}')\n\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Reference: https://hackersandslackers.com/compare-rows-pandas-dataframes/\ndef dataframe_difference(first: pd.DataFrame, other: pd.DataFrame, which=None):\n    \"\"\"Find rows which are different between two DataFrames.\"\"\"\n    comparison_df = first.merge(\n        other,\n        indicator=True,\n        how='inner'\n    )\n    if which is None:\n        diff_df = comparison_df[comparison_df['_merge'] != 'both']\n    else:\n        diff_df = comparison_df[comparison_df['_merge'] == which]\n    return diff_df","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T21:01:52.459069Z","iopub.status.busy":"2021-01-01T21:01:52.458374Z","iopub.status.idle":"2021-01-01T21:01:52.461417Z","shell.execute_reply":"2021-01-01T21:01:52.460941Z"},"papermill":{"duration":0.043325,"end_time":"2021-01-01T21:01:52.461522","exception":false,"start_time":"2021-01-01T21:01:52.418197","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"DATASET_UPLOAD_FOLDER='/kaggle/working/upload'\nPREPROCESSED_DATASET_UPLOAD_FOLDER='/kaggle/working/upload/preprocessed-kaggle-2017-to-2020'\nNOT_AVAILABLE = \"Unknown / Not Specified\"","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T21:01:52.5416Z","iopub.status.busy":"2021-01-01T21:01:52.538218Z","iopub.status.idle":"2021-01-01T21:02:26.407885Z","shell.execute_reply":"2021-01-01T21:02:26.40875Z"},"papermill":{"duration":33.911121,"end_time":"2021-01-01T21:02:26.408962","exception":false,"start_time":"2021-01-01T21:01:52.497841","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"%%bash\nUPLOAD_FOLDER=\"/kaggle/working/upload\"\nPREPROCESSED_UPLOAD_FOLDER='/kaggle/working/upload/preprocessed-kaggle-2017-to-2020'\nmkdir -p ${UPLOAD_FOLDER} ${PREPROCESSED_UPLOAD_FOLDER}\ncp -fr /kaggle/input/stack-overflow-developer-survey-2020/* ${UPLOAD_FOLDER} || true\n\nfolders=( \"kaggle-survey-2020\" \"kaggle-survey-2019\" \"kaggle-survey-2018\" \"kaggle-survey-2017\" \"so-survey-2017\" \"stack-overflow-developer-survey-2020\" \n\"cleaned-mcr-kaggle-survey-2019\" \"stack-overflow-2018-developer-survey\" \"stack-overflow-developer-survey-results-2019\"\n\"kaggle-survey-20172020-merged-data\" \"world-development-indicators\" )\n\nfor each_folder in \"${folders[@]}\"\ndo\n    echo \"~~~ Zipping files in ${each_folder}\"\n    cd \"/kaggle/input/${each_folder}\"\n    zip -r9 ${UPLOAD_FOLDER}/${each_folder}.zip *\n    echo \"~~~ ${each_folder}.zip ready to be used/copied.\"\n    echo \"\"\n    cd ..\ndone","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T21:02:34.68804Z","iopub.status.busy":"2021-01-01T21:02:34.687325Z","iopub.status.idle":"2021-01-01T21:02:34.690289Z","shell.execute_reply":"2021-01-01T21:02:34.689699Z"},"papermill":{"duration":0.064241,"end_time":"2021-01-01T21:02:34.690398","exception":false,"start_time":"2021-01-01T21:02:34.626157","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def check_missing_values(dataframe):\n    missing_values_data = []\n    for column in list(dataframe.columns):\n        values = (dataframe[column].isna()).value_counts()\n        value = 0\n        if len(values) > 1:\n            value = values[1]\n\n        missing_values_data.append({'column_name': column, 'missing_values_count': value})\n        \n    df_missing_values = pd.DataFrame(missing_values_data)\n    return df_missing_values.sort_values(by='missing_values_count', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing merged dataset from @harveenchadha (from 2017 to 2020)"},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_questions_and_responses_ref_df = pd.read_csv('../input/kaggle-survey-20172020-merged-data/kaggle_survey_17_20_v2.csv')\nprint(f\"Before kaggle_questions_and_responses_ref_df: {kaggle_questions_and_responses_ref_df.shape[0]}\")\nkaggle_questions_and_responses_ref_df = kaggle_questions_and_responses_ref_df.fillna(NOT_AVAILABLE)\nif 'index' in kaggle_questions_and_responses_ref_df.columns:\n    kaggle_questions_and_responses_ref_df = kaggle_questions_and_responses_ref_df.drop('index', axis=1)\nfinal_rows_count = kaggle_questions_and_responses_ref_df.shape[0]\nprint(f\"After kaggle_questions_and_responses_ref_df: {final_rows_count}\")\nrows_count_after_dropping_duplicates = kaggle_questions_and_responses_ref_df.drop_duplicates(keep='first').shape[0]\nprint('if duplicates dropped in kaggle_questions_and_responses_ref_df: ' \\\n      f\"{rows_count_after_dropping_duplicates} (difference: {final_rows_count - rows_count_after_dropping_duplicates})\")\nkaggle_questions_and_responses_ref_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Picking a handful more columns missed in the above merge process"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(filepath: str, column_mappings: dict, encoding='utf-8') -> pd.DataFrame:\n    dataset = pd.read_csv(filepath, encoding=encoding)\n    dataset = dataset.rename(columns=column_mappings)\n    dataset = dataset.drop([0], errors='ignore')\n    columns_found = list(set(column_mappings.values()) & set(dataset.columns))\n    columns_missing = list(set(column_mappings.values()) - set(columns_found))\n    if columns_missing:\n        dataset[columns_missing] = NOT_AVAILABLE\n        print(f'columns missing (replaced with \"{NOT_AVAILABLE}\" values):', columns_missing)\n    return dataset[list(column_mappings.values())]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Kaggle Survey 2017"},{"metadata":{"trusted":true},"cell_type":"code","source":"question_id_to_human_readable_2017 = {\n    'Age':'Age',\n    'GenderSelect':'Gender',\n    'Country':'Country',\n    'FormalEducation':'Degree',\n    'CurrentJobTitleSelect':'Job Title',\n    'EmployerSize':'Company Size',\n    #'EmployerSizeChange':'Team Size',\n    #'EmployerMLTime':'ML Status in Company',\n    'CompensationAmount':'Compensation Status',\n    'N/A1' : 'Current role experience (in years)',\n    'N/A2': 'Role Important at work',\n    'N/A11': 'Programming language choice',\n    'LanguageRecommendationSelect': 'Recommend Programming language', \n    'N/A12': 'Coding experience (in years)', ## CodeWriter field does not have the right data for this year\n    'N/A3': 'Notebook product', \n    'N/A4': 'Computing platform', \n    'N/A5': '% of current ML/DS training categories',\n    'HardwarePersonalProjectsSelect': 'Specialised HW',\n    'N/A6': 'TPU Usage',      # not available in 2018\n    'N/A7': 'ML Methods experience (in years)',\n    'N/A8': 'Tools to manage ML experiments', # not available  in 2018\n    'N/A9': 'Completed DS courses', # also check CoursePlatformSelect\n    'N/A10':'Favourite media sources'\n}\nkaggle_2017 = load_dataset('../input/kaggle-survey-2017/multipleChoiceResponses.csv', question_id_to_human_readable_2017, encoding='latin-1')\nkaggle_2017['Year'] = 2017\nkaggle_2017.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Kaggle Survey 2018"},{"metadata":{"trusted":true},"cell_type":"code","source":"question_id_to_human_readable_2018 = {\n    'Time from Start to Finish (seconds)':'Time',\n    'Q2':'Age',\n    'Q1':'Gender',\n    'Q3':'Country',\n    'Q4':'Degree',\n    'Q6':'Job Title',\n    # 'Q8':'Team Size', ## wrong\n    # 'Q9':'Company Size', ## wrong                       \n    'Q10':'ML Status in Company', \n    'Q9':'Compensation Status',\n    # 'Q11':'Money Spent' ## wrong    \n    'Q8' : 'Current role experience (in years)',\n    'Q11_Part_1': 'Role Important at work 1',\n    'Q11_Part_2': 'Role Important at work 2',\n    'Q11_Part_3': 'Role Important at work 3',\n    'Q11_Part_4': 'Role Important at work 4',\n    'Q11_Part_5': 'Role Important at work 5',\n    'Q11_Part_6': 'Role Important at work 6',\n    'Q11_Part_7': 'Role Important at work 7',\n    'Q11_OTHER_TEXT': 'Role Important at work 8',\n    'Q17': 'Programming language choice', \n#     'N/A1': 'Recommend Programming language', \n    'Q14_Part_1': 'Notebook product 1', \n    'Q14_Part_2': 'Notebook product 2', \n    'Q14_Part_3': 'Notebook product 3',     \n    'Q14_Part_4': 'Notebook product 4', \n    'Q14_Part_5': 'Notebook product 5', \n    'Q14_Part_6': 'Notebook product 6',     \n    'Q14_Part_7': 'Notebook product 7', \n    'Q14_Part_8': 'Notebook product 8', \n    'Q14_Part_9': 'Notebook product 9',     \n    'Q14_Part_10': 'Notebook product 10', \n    'Q14_Part_11': 'Notebook product 11',     \n    'Q14_OTHER_TEXT': 'Notebook product 12',\n    'Q15_Part_1': 'Cloud Computing platform 1', \n    'Q15_Part_2': 'Cloud Computing platform 2', \n    'Q15_Part_3': 'Cloud Computing platform 3', \n    'Q15_Part_4': 'Cloud Computing platform 4', \n    'Q15_Part_5': 'Cloud Computing platform 5', \n    'Q15_Part_6': 'Cloud Computing platform 6', \n    'Q15_Part_7': 'Cloud Computing platform 7',     \n    'Q15_OTHER_TEXT': 'Computing platform 8',  \n    'Q35_Part_1': '% of current ML/DS training categories 1',\n    'Q35_Part_2': '% of current ML/DS training categories 2',\n    'Q35_Part_3': '% of current ML/DS training categories 3',    \n    'Q35_Part_4': '% of current ML/DS training categories 4',\n    'Q35_Part_5': '% of current ML/DS training categories 5',\n    'Q35_Part_6': '% of current ML/DS training categories 6',    \n    'Q35_OTHER_TEXT': '% of current ML/DS training categories 7',\n#     'N/A1': 'Specialised HW', # not available in 2018\n#     'N/A2': 'TPU Usage',      # not available in 2018\n#     'N/A3': 'ML Methods experience (in years)',  # not available in 2018\n#     'N/A4': 'Tools to manage ML experiments', # not available  in 2018\n    'Q36_Part_1': 'Completed DS courses 1',\n    'Q36_Part_2': 'Completed DS courses 2',\n    'Q36_Part_3': 'Completed DS courses 3',    \n    'Q36_Part_4': 'Completed DS courses 4',\n    'Q36_Part_5': 'Completed DS courses 5',\n    'Q36_Part_6': 'Completed DS courses 6',    \n    'Q36_Part_7': 'Completed DS courses 7',\n    'Q36_Part_8': 'Completed DS courses 8',\n    'Q36_Part_9': 'Completed DS courses 9',    \n    'Q36_Part_10': 'Completed DS courses 10',\n    'Q36_Part_11': 'Completed DS courses 11',\n    'Q36_Part_12': 'Completed DS courses 12',    \n    'Q36_Part_13': 'Completed DS courses 13',  \n    'Q36_OTHER_TEXT': 'Completed DS courses 14',\n    'Q38_Part_1':'Favourite media sources 1',\n    'Q38_Part_2':'Favourite media sources 2',\n    'Q38_Part_3':'Favourite media sources 3',\n    'Q38_Part_4':'Favourite media sources 4',\n    'Q38_Part_5':'Favourite media sources 5',    \n    'Q38_Part_6':'Favourite media sources 6',\n    'Q38_Part_7':'Favourite media sources 7',\n    'Q38_Part_8':'Favourite media sources 8',\n    'Q38_Part_9':'Favourite media sources 9',\n    'Q38_Part_10':'Favourite media sources 10',\n    'Q38_Part_11':'Favourite media sources 11',\n    'Q38_Part_12':'Favourite media sources 12',\n    'Q38_Part_13':'Favourite media sources 13',\n    'Q38_Part_14':'Favourite media sources 14',\n    'Q38_Part_15':'Favourite media sources 15',\n    'Q38_Part_16':'Favourite media sources 16',\n    'Q38_Part_17':'Favourite media sources 17',\n    'Q38_Part_18':'Favourite media sources 18',    \n    'Q38_Part_19':'Favourite media sources 19',        \n    'Q38_Part_20':'Favourite media sources 20',        \n    'Q38_Part_21':'Favourite media sources 21',\n    'Q38_Part_22':'Favourite media sources 22',\n    'Q38_OTHER_TEXT': 'Favourite media sources 23'\n}\nkaggle_2018 = load_dataset('../input/kaggle-survey-2018/multipleChoiceResponses.csv', question_id_to_human_readable_2018)\nkaggle_2018['Year'] = 2018\nkaggle_2018.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Kaggle Survey 2019"},{"metadata":{"trusted":true},"cell_type":"code","source":"question_id_to_human_readable_2019 = {\n    'Time from Start to Finish (seconds)':'Time',\n    'Q1':'Age',\n    'Q2':'Gender',\n    'Q3':'Country',\n    'Q4':'Degree',\n    'Q5':'Job Title',\n    'Q6':'Team Size', ## wrong\n#     'Q9':'Company Size', ## wrong                       \n    'Q10':'Compensation Status',\n    'Q8':'ML Status in Company',     \n    # 'Q11':'Money Spent' ## wrong        \n#     'N/A1' : 'Current role experience (in years)',\n    'Q9_Part_1': 'Role Important at work 1',\n    'Q9_Part_2': 'Role Important at work 2',\n    'Q9_Part_3': 'Role Important at work 3',\n    'Q9_Part_4': 'Role Important at work 4',\n    'Q9_Part_5': 'Role Important at work 5',\n    'Q9_Part_6': 'Role Important at work 6',\n    'Q9_Part_7': 'Role Important at work 7',\n    'Q9_OTHER_TEXT': 'Role Important at work 8',\n    'Q18_Part_1': 'Programming language choice 1', \n    'Q18_Part_2': 'Programming language choice 2',     \n    'Q18_Part_3': 'Programming language choice 3', \n    'Q18_Part_4': 'Programming language choice 4', \n    'Q18_Part_5': 'Programming language choice 5', \n    'Q18_Part_6': 'Programming language choice 6', \n    'Q18_Part_7': 'Programming language choice 7', \n    'Q18_Part_8': 'Programming language choice 8',   \n    'Q18_Part_9': 'Programming language choice 9',   \n    'Q18_Part_10': 'Programming language choice 10',   \n    'Q18_Part_11': 'Programming language choice 11',   \n    'Q18_Part_12': 'Programming language choice 12',       \n    'Q19_OTHER_TEXT': 'Programming language choice 13',\n    'Q19': 'Recommend Programming language', \n    'Q17_Part_1': 'Notebook product 1', \n    'Q17_Part_2': 'Notebook product 2', \n    'Q17_Part_3': 'Notebook product 3',     \n    'Q17_Part_4': 'Notebook product 4', \n    'Q17_Part_5': 'Notebook product 5', \n    'Q17_Part_6': 'Notebook product 6',     \n    'Q17_Part_7': 'Notebook product 7', \n    'Q17_Part_8': 'Notebook product 8', \n    'Q17_Part_9': 'Notebook product 9',     \n    'Q17_Part_10': 'Notebook product 10', \n    'Q17_Part_11': 'Notebook product 11',    \n    'Q17_Part_12': 'Notebook product 12',    \n    'Q17_OTHER_TEXT': 'Notebook product 13',\n    'Q29_Part_1': 'Cloud Computing platform 1', \n    'Q29_Part_2': 'Cloud Computing platform 2', \n    'Q29_Part_3': 'Cloud Computing platform 3', \n    'Q29_Part_4': 'Cloud Computing platform 4', \n    'Q29_Part_5': 'Cloud Computing platform 5', \n    'Q29_Part_6': 'Cloud Computing platform 6', \n    'Q29_Part_7': 'Cloud Computing platform 7',   \n    'Q29_Part_7': 'Cloud Computing platform 8',   \n    'Q29_Part_7': 'Cloud Computing platform 9',   \n    'Q29_Part_7': 'Cloud Computing platform 10',   \n    'Q29_Part_7': 'Cloud Computing platform 11',  \n    'Q29_Part_7': 'Cloud Computing platform 12',    \n    'Q29_OTHER_TEXT': 'Computing platform 13',  \n#     'N/A2': '% of current ML/DS training categories 1',\n#     'N/A3': '% of current ML/DS training categories 2',\n#     'N/A4': '% of current ML/DS training categories 3',    \n#     'N/A5': '% of current ML/DS training categories 4',\n#     'N/A6': '% of current ML/DS training categories 5',\n#     'N/A7': '% of current ML/DS training categories 6',    \n#     'N/A8': '% of current ML/DS training categories 7',\n    'Q21_Part_1': 'Specialised HW 1',\n    'Q21_Part_2': 'Specialised HW 2',\n    'Q21_Part_3': 'Specialised HW 3',\n    'Q21_Part_4': 'Specialised HW 4',\n    'Q21_Part_5': 'Specialised HW 5',\n    'Q21_Part_6': 'Specialised HW 6',\n    'Q21_OTHER_TEXT': 'Specialised HW 7',    \n    'Q22': 'TPU Usage',      \n    'Q23': 'ML Methods experience (in years)', \n#     'N/A9': 'Tools to manage ML experiments', \n    'Q13_Part_1': 'Completed DS courses 1',\n    'Q13_Part_2': 'Completed DS courses 2',\n    'Q13_Part_3': 'Completed DS courses 3',    \n    'Q13_Part_4': 'Completed DS courses 4',\n    'Q13_Part_5': 'Completed DS courses 5',\n    'Q13_Part_6': 'Completed DS courses 6',    \n    'Q13_Part_7': 'Completed DS courses 7',\n    'Q13_Part_8': 'Completed DS courses 8',\n    'Q13_Part_9': 'Completed DS courses 9',    \n    'Q13_Part_10': 'Completed DS courses 10',\n    'Q13_Part_11': 'Completed DS courses 11',\n    'Q13_Part_12': 'Completed DS courses 12',    \n    'Q13_Part_13': 'Completed DS courses 13',  \n    'Q13_OTHER_TEXT': 'Completed DS courses 14',\n    'Q12_Part_1':'Favourite media sources 1',\n    'Q12_Part_2':'Favourite media sources 2',\n    'Q12_Part_3':'Favourite media sources 3',\n    'Q12_Part_4':'Favourite media sources 4',\n    'Q12_Part_5':'Favourite media sources 5',    \n    'Q12_Part_6':'Favourite media sources 6',\n    'Q12_Part_7':'Favourite media sources 7',\n    'Q12_Part_8':'Favourite media sources 8',\n    'Q12_Part_9':'Favourite media sources 9',\n    'Q12_Part_10':'Favourite media sources 10',\n    'Q12_Part_11':'Favourite media sources 11',\n    'Q12_Part_12':'Favourite media sources 12',\n    'Q12_OTHER_TEXT': 'Favourite media sources 13'\n}\nkaggle_2019 = load_dataset('../input/kaggle-survey-2019/multiple_choice_responses.csv', question_id_to_human_readable_2019)\nkaggle_2019['Year'] = 2019\nkaggle_2019.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Kaggle Survey 2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"question_id_to_human_readable_2020 = {\n    'Time from Start to Finish (seconds)':'Time',\n    'Q1':'Age',\n    'Q2':'Gender',\n    'Q3':'Country',\n    'Q4':'Degree',\n    'Q5':'Job Title',\n    'Q20':'Company Size',\n    'Q21':'Team Size',\n    'Q22':'ML Status in Company',\n    'Q24':'Compensation Status',\n    'Q25':'Money Spent',\n    'Q6': 'Coding experience (in years)', \n    'Q7_Part_1': 'Programming language choice 1', \n    'Q7_Part_2': 'Programming language choice 2', \n    'Q7_Part_3': 'Programming language choice 3', \n    'Q7_Part_4': 'Programming language choice 4', \n    'Q7_Part_5': 'Programming language choice 5', \n    'Q7_Part_6': 'Programming language choice 6',     \n    'Q7_Part_7': 'Programming language choice 7',     \n    'Q7_Part_8': 'Programming language choice 8',    \n    'Q7_Part_9': 'Programming language choice 9', \n    'Q7_Part_10': 'Programming language choice 10', \n    'Q7_Part_11': 'Programming language choice 11', \n    'Q7_Part_12': 'Programming language choice 12',     \n    'Q7_OTHER': 'Programming language choice 13', \n    'Q8': 'Recommend Programming language', \n    'Q10_Part_1': 'Notebook product 1', \n    'Q10_Part_2': 'Notebook product 2', \n    'Q10_Part_3': 'Notebook product 3',     \n    'Q10_Part_4': 'Notebook product 4', \n    'Q10_Part_5': 'Notebook product 5', \n    'Q10_Part_6': 'Notebook product 6',     \n    'Q10_Part_7': 'Notebook product 7', \n    'Q10_Part_8': 'Notebook product 8', \n    'Q10_Part_9': 'Notebook product 9',     \n    'Q10_Part_10': 'Notebook product 10', \n    'Q10_Part_11': 'Notebook product 11',    \n    'Q10_Part_12': 'Notebook product 12',    \n    'Q10_Part_13': 'Notebook product 13',        \n    'Q10_OTHER': 'Notebook product 14',\n    'Q26_A_Part_1': 'Cloud Computing platform 1', \n    'Q26_A_Part_2': 'Cloud Computing platform 2', \n    'Q26_A_Part_3': 'Cloud Computing platform 3',     \n    'Q26_A_Part_4': 'Cloud Computing platform 4',    \n    'Q26_A_Part_5': 'Cloud Computing platform 5',    \n    'Q26_A_Part_6': 'Cloud Computing platform 6',    \n    'Q26_A_Part_7': 'Cloud Computing platform 7',\n    'Q26_A_Part_8': 'Cloud Computing platform 8',    \n    'Q26_A_Part_9': 'Cloud Computing platform 9',    \n    'Q26_A_Part_10': 'Cloud Computing platform 10',    \n    'Q26_A_Part_11': 'Cloud Computing platform 11',\n    'Q26_A_OTHER': 'Cloud Computing platform 12',\n    'Q12_Part_1': 'Specialised HW 1', \n    'Q12_Part_2': 'Specialised HW 2', \n    'Q12_Part_3': 'Specialised HW 3', \n    'Q12_OTHER': 'Specialised HW 4',     \n    'Q13': 'TPU Usage', \n    'Q15': 'ML Methods experience (in years)', \n    'Q23_Part_1': 'Role Important at work 1', \n    'Q23_Part_2': 'Role Important at work 2', \n    'Q23_Part_3': 'Role Important at work 3', \n    'Q23_Part_4': 'Role Important at work 4',\n    'Q23_Part_5': 'Role Important at work 5',\n    'Q23_Part_6': 'Role Important at work 6',\n    'Q23_Part_7': 'Role Important at work 7',\n    'Q23_OTHER': 'Role Important at work 8',\n    'Q35_A_Part_1': 'Tools to manage ML experiments 1',\n    'Q35_A_Part_2': 'Tools to manage ML experiments 2',  \n    'Q35_A_Part_3': 'Tools to manage ML experiments 3',   \n    'Q35_A_Part_4': 'Tools to manage ML experiments 4',  \n    'Q35_A_Part_5': 'Tools to manage ML experiments 5',  \n    'Q35_A_Part_6': 'Tools to manage ML experiments 6',  \n    'Q35_A_Part_7': 'Tools to manage ML experiments 7',  \n    'Q35_A_Part_8': 'Tools to manage ML experiments 8',\n    'Q35_A_Part_9': 'Tools to manage ML experiments 9',  \n    'Q35_A_Part_10': 'Tools to manage ML experiments 10',      \n    'Q35_A_OTHER': 'Tools to manage ML experiments 11',  \n    'Q37_Part_1': 'Completed DS courses 1',\n    'Q37_Part_2': 'Completed DS courses 2',\n    'Q37_Part_3': 'Completed DS courses 3',    \n    'Q37_Part_4': 'Completed DS courses 4',\n    'Q37_Part_5': 'Completed DS courses 5',\n    'Q37_Part_6': 'Completed DS courses 6',    \n    'Q37_Part_7': 'Completed DS courses 7',\n    'Q37_Part_8': 'Completed DS courses 8',\n    'Q37_Part_9': 'Completed DS courses 9',    \n    'Q37_Part_10': 'Completed DS courses 10',\n    'Q37_Part_11': 'Completed DS courses 11',\n    'Q37_OTHER': 'Completed DS courses 12', \n    'Q39_Part_1':'Favourite media sources 1',\n    'Q39_Part_2':'Favourite media sources 2',\n    'Q39_Part_3':'Favourite media sources 3',\n    'Q39_Part_4':'Favourite media sources 4',\n    'Q39_Part_5':'Favourite media sources 5',    \n    'Q39_Part_6':'Favourite media sources 6',\n    'Q39_Part_7':'Favourite media sources 7',\n    'Q39_Part_8':'Favourite media sources 8',\n    'Q39_Part_9':'Favourite media sources 9',\n    'Q39_Part_10':'Favourite media sources 10',\n    'Q39_Part_11':'Favourite media sources 11',\n    'Q39_OTHER': 'Favourite media sources 12'\n}\n\nkaggle_2020 = load_dataset('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv', question_id_to_human_readable_2020)\nkaggle_2020['Year'] = 2020\nkaggle_2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Time', 'Year', 'Age', 'Gender', 'Country', 'Degree', 'Job Title', 'Company Size', 'Team Size', \n           'ML Status in Company','Compensation Status','Money Spent', 'Current role experience (in years)',\n           'Programming language choice', 'Recommend Programming language', 'Coding experience (in years)', \n           'Specialised HW', 'TPU Usage', 'ML Methods experience (in years)']\n\nkaggle_combined = pd.concat([kaggle_2017, kaggle_2018, kaggle_2019, kaggle_2020])\nkaggle_combined = kaggle_combined[columns]\nkaggle_combined = kaggle_combined.fillna(NOT_AVAILABLE)\nprint(f'Count before dropping duplicates: {kaggle_combined.shape}')\nkaggle_combined = kaggle_combined.sort_values(['Year', 'Country'])\nkaggle_combined = kaggle_combined.reset_index(drop=True)\n# kaggle_combined = kaggle_combined.drop_duplicates(keep='first')\nkaggle_combined.insert(0, 'Unique_Id', kaggle_combined.index.to_list())\nprint(f'Count after dropping duplicates: {kaggle_combined.shape}')\nprint(f'Dataset shape: {kaggle_combined.shape}')\nkaggle_combined.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del kaggle_2017, kaggle_2018, kaggle_2019, kaggle_2020\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_age_2018(row):\n    if type(row) == float:\n        if (float(row) >= 70.0):\n            return '70+'\n        if (float(row) < 18.0):\n            return '18-21'\n        \n    if row == '80+':\n        return '70+'\n    elif row == '70-79':\n        return '70+'\n    else:\n        return row\n    \nkaggle_combined['Age'] = kaggle_combined['Age'].apply(combine_age_2018)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_ranges = kaggle_combined['Age'].unique()\n\ndef combine_age_2017(row):\n    if row.Year == 2017:\n        for local_age in age_ranges:\n            if type(local_age) != float:\n                if (local_age[-1] == '+'):\n                    if row.Age >= 70:\n                        return '70+'\n                else:\n                    ranges = local_age.split('-')\n                    try:\n                        if int(row.Age) >= int(ranges[0]) and int(row.Age) <= int(ranges[1]):\n                            return local_age\n                    except:\n                        return row.Age\n    else:\n        return row.Age\n    \nkaggle_combined['Age'] = kaggle_combined.apply(combine_age_2017, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_combined['Age'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_gender(row):\n    if row['Gender'] == 'Man':\n        return 'Male'\n    elif row['Gender'] == 'Woman':\n        return 'Female'\n    elif row['Gender'].strip() == 'A different identity':\n        return 'Prefer not to say'\n    elif row['Gender'].strip() == 'Non-binary, genderqueer, or gender non-conforming':\n        return 'Nonbinary'\n    else:\n        return row['Gender']\n    \nkaggle_combined['Gender'] = kaggle_combined.apply(change_gender, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_combined['Gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Degree / qualification"},{"metadata":{"trusted":true},"cell_type":"code","source":"def degree_change(row):\n    if row.Degree == 'I did not complete any formal education past high school':\n        return 'No formal education past high school'\n    elif row.Degree == 'Master\\'s degree':\n        return 'Master’s degree'\n    elif row.Degree == 'Bachelor\\'s degree':\n        return 'Bachelor’s degree'\n    elif row.Degree == 'Some college/university study without earning a bachelor\\'s degree':\n        return 'Some college/university study without earning a bachelor’s degree'\n    else:\n        return row.Degree\n    \nkaggle_combined['Degree'] = kaggle_combined.apply(degree_change, axis=1)\nkaggle_combined['Degree'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Company Size"},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_company_size(row):\n    if row.Year == 2019:\n        if row['Company Size'] == '> 10,000 employees':\n            return '10,000 or more employees'   \n        else:\n            return row['Company Size']\n\n    if row['Company Size'] == '10 to 19 employees' or row['Company Size'] == 'Fewer than 10 employees':\n        return '0-49 employees'\n    elif row['Company Size'] == '20 to 99 employees' or row['Company Size'] == '100 to 499 employees':\n        return '50-249 employees'\n    elif row['Company Size'] == '500 to 999 employees':\n        return '250-999 employees'\n    elif row['Company Size'] == '1,000 to 4,999 employees' or row['Company Size'] == '5,000 to 9,999 employees':\n        return '1000-9,999 employees'\n    elif row['Company Size'] == '10,000 or more employees':\n        return '10,000 or more employees'\n    else:\n        return row['Company Size']\n    \nkaggle_combined['Company Size'] = kaggle_combined.apply(change_company_size, axis=1)\nkaggle_combined['Company Size'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compensation Status"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_salary_2018_mapping = {'0-10,000':'0-10,000','10-20,000': '10,001-20,000', '20-30,000': '20,001-30,000', '30-40,000':'30,000-39,999',\n                           '40-50,000':'40,000-49,999', '50-60,000':'50,000-59,999', '60-70,000':'60,000-69,999',\n                           '70-80,000':'70,000-79,999', '80-90,000':'80,000-89,999', '90-100,000':'90,000-99,999',\n                           '100-125,000':'100,000-124,999', '125-150,000':'125,000-149,999', '150-200,000': '150,000-199,999',\n                           '200-250,000':'200,000-249,999', '250-300,000': '250,000-299,999', '300-400,000':'300,000-500,000',\n                           '400-500,000':'300,000-500,000','500,000+':'> $500,000', 'I do not wish to disclose my approximate yearly compensation':'Cant Disclose',\n                           NOT_AVAILABLE: NOT_AVAILABLE, np.nan:np.nan}\n\ndef change_salary(row):\n    if row.Year == 2019 or row.Year == 2020:\n        if row['Compensation Status']=='$0-999' or row['Compensation Status'] == '1,000-1,999' or row['Compensation Status'] == '2,000-2,999' \\\n            or row['Compensation Status']=='3,000-3,999' or row['Compensation Status']=='4,000-4,999' or row['Compensation Status']=='5,000-7,499' or row['Compensation Status']=='7,500-9,999':\n            return '0-10,000'\n        elif row['Compensation Status'] == '10,000-14,999' or row['Compensation Status'] == '15,000-19,999':\n            return '10,001-20,000'\n        elif row['Compensation Status'] == '20,000-24,999' or row['Compensation Status'] == '25,000-29,999':\n            return '20,001-30,000'\n        else:\n            return row['Compensation Status']\n\n    elif row.Year == 2018:\n        #if not row['Compensation Status'].isna():\n        value_to_return = dict_salary_2018_mapping[row['Compensation Status']]\n        return value_to_return\n    else:\n        return row['Compensation Status']\n    \nkaggle_combined['Compensation Status'] = kaggle_combined.apply(change_salary, axis=1)\n\nlist_values = list(dict_salary_2018_mapping.values())\nlist_values.remove(np.nan)\n\ndef change_salary_2017(row):\n    if row['Year'] == 2017:\n        for i in list_values:\n            ranges = i.split('-')\n            if len(ranges)==2:\n                try:\n                    if int(row['Compensation Status'].replace(',',''))>=int(ranges[0].replace(',','')) and int(row['Compensation Status'].replace(',','')) <= int(ranges[1].replace(',','')):\n                        return i\n                except:\n                    return 'Cant Disclose'\n            else:\n                try:\n                    if int(row['Compensation Status'].replace(',',''))>500000:\n                        return '> $500,000'\n                    else:\n                        return 'Cant Disclose'\n                except:\n                    return 'Cant Disclose'\n                #> 5,000,000, can't disclose\n                \n    else:\n        return row['Compensation Status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_combined['Compensation Status'] = kaggle_combined.apply(change_salary_2017, axis=1)\nkaggle_combined['Compensation Status'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"consistent_country_name = {\n    'United States of America': 'United States', \n    'Republic of China': 'China',\n    'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n    \"People 's Republic of China\": 'China', \n    'Republic of Korea': 'South Korea',\n    'Hong Kong (S.A.R.)': 'Hong Kong',\n    'Iran, Islamic Republic of...': 'Iran',\n    'Viet Nam': 'Vietnam'\n}\nkaggle_combined['Country'] = kaggle_combined['Country'].apply(lambda x: x.strip())\nkaggle_combined = kaggle_combined.replace({'Country': consistent_country_name})\nkaggle_combined = kaggle_combined.replace({'Country': {'I do not wish to disclose my location': NOT_AVAILABLE}})\nkaggle_combined = kaggle_combined.replace({'Country': {'I do not wish to disclose my location': NOT_AVAILABLE}})\nkaggle_combined = strip_spaces_from_all_columns(kaggle_combined)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = [country[0] for country in dict(kaggle_combined[['Country']].value_counts()).keys()]\ncountries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Dataset shape: {kaggle_combined.shape}')\nkaggle_combined.to_csv(f'{PREPROCESSED_DATASET_UPLOAD_FOLDER}/kaggle_2017_to_2020.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_countries_in_2020 = ['New Zealand', 'Denmark', 'Finland', 'Norway', 'UK', 'Czech Republic', 'Hungary',\n                            'Austria', 'Norway', 'Algeria']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparing combined dataset with individual tables and combined counts from them"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_rows = kaggle_2017.shape[0] + kaggle_2018.shape[0] + kaggle_2019.shape[0] + kaggle_2020.shape[0] \nprint(f\"Individual tables: total: {total_rows}, \\n  kaggle_2017: {kaggle_2017.shape[0]},   \\n  kaggle_2018: {kaggle_2018.shape[0]}, \" \\\n      f\"\\n  kaggle_2019: {kaggle_2019.shape[0]},  \\n  kaggle_2020: {kaggle_2020.shape[0]}\")\nprint(f\"Combined table: kaggle_combined: {kaggle_combined.shape[0]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparing combined dataset with a reference dataset for differences and discrepancies"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_rows = kaggle_2017.shape[0] + kaggle_2018.shape[0] + kaggle_2019.shape[0] + kaggle_2020.shape[0] \nprint(f\"Individual tables: total: {total_rows}, \\n  kaggle_2017: {kaggle_2017.shape[0]},   \\n  kaggle_2018: {kaggle_2018.shape[0]}, \" \\\n      f\"\\n  kaggle_2019: {kaggle_2019.shape[0]},  \\n  kaggle_2020: {kaggle_2020.shape[0]}\")\nprint(f\"Combined table: kaggle_combined: {kaggle_combined.shape[0]}\")\nprint(f\"Reference table: kaggle_questions_and_responses_ref_df: {kaggle_questions_and_responses_ref_df.shape[0]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(kaggle_questions_and_responses_ref_df.columns)\nprint(kaggle_combined.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_df = dataframe_difference(\n    kaggle_questions_and_responses_ref_df,\n    kaggle_combined[kaggle_questions_and_responses_ref_df.columns]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Combined table: kaggle_combined: {kaggle_combined.shape[0]}\\n\")\nprint(diff_df['_merge'].value_counts(), \"\\n\")\nprint(f\"Differences table: diff_df: {diff_df.shape[0]}\\n\")\nprint(\"Total of merged table differences:\", sum(diff_df['_merge'].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is possible the reference table and the newly combined tables differ for good reasons, and could be checked later on, why."},{"metadata":{},"cell_type":"markdown","source":"### Checking for missing data (by country and/or year)"},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_missing_countries = (kaggle_combined['Country'].isin(missing_countries_in_2020)) & (kaggle_combined['Year'] != 2020)\nkaggle_combined[filter_missing_countries]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_missing_countries = (kaggle_combined['Country'].isin(missing_countries_in_2020)) & (kaggle_combined['Year'] == 2020)\nkaggle_combined[filter_missing_countries]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combining Kaggle dataset with Countries and Continents dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Before combining kaggle_combined.shape: {kaggle_combined.shape}')\ncountry_and_continent_info = pd.read_csv('../input/world-bank-data-1960-to-2016-extended/Countries_and_continents_of_the_world.csv')\nprint(f'   Before dropping duplicates from country_and_continent_info: {country_and_continent_info.shape}')\ncountry_and_continent_info = country_and_continent_info.rename(columns={'Country Name': 'Country'})\ncountry_and_continent_info = country_and_continent_info.drop_duplicates(subset = ['Country'], keep='first')\nprint(f'   After dropping duplicates from country_and_continent_info: {country_and_continent_info.shape}')\ncountry_and_continent_info[['Region', 'Continent', 'Country']] = \\\n                                    country_and_continent_info[['Region', 'Continent', 'Country']].fillna(NOT_AVAILABLE)\ncountry_and_continent_info = country_and_continent_info.reset_index(drop=True)\ncountry_and_continent_info = strip_spaces_from_all_columns(country_and_continent_info)\n\nprint()\nprint('    --- country_and_continent_info combined with kaggle_combined into kaggle_combined_country_and_continents ---')\nprint()\n\nkaggle_combined_country_and_continents = kaggle_combined.merge(country_and_continent_info, how='left', on='Country', indicator=True)\nprint(\"We won't be removing duplicates for the reason that they end up\\n\")\n# print(f'   Before dropping duplicates from kaggle_combined_country_and_continents: {kaggle_combined_country_and_continents.shape}')\n# kaggle_combined_country_and_continents = kaggle_combined_country_and_continents.drop_duplicates(keep='first')\n# print(f'   After dropping duplicates from kaggle_combined_country_and_continents: {kaggle_combined_country_and_continents.shape}')\nkaggle_combined_country_and_continents[['Region', 'Continent', 'Country']] = \\\n                                    kaggle_combined_country_and_continents[['Region', 'Continent', 'Country']].fillna(NOT_AVAILABLE)\nkaggle_combined_country_and_continents = strip_spaces_from_all_columns(kaggle_combined_country_and_continents)\nkaggle_combined_country_and_continents = kaggle_combined_country_and_continents.reset_index(drop=True)\nkaggle_combined_country_and_continents = strip_spaces_from_all_columns(kaggle_combined_country_and_continents)\nprint(f'After combining kaggle_combined.shape: {kaggle_combined_country_and_continents.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_and_continent_info['Region'] = country_and_continent_info['Region'].apply(lambda x: x.strip())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_and_continent_info['Region'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_and_continent_info['Continent'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def exclude_columns_in_df(dataframe: pd.DataFrame, columns_to_exclude: list = []) -> pd.DataFrame:\n    current_columns = dataframe.columns\n    excluded_columns = list(set(current_columns) - set(columns_to_exclude))\n    return dataframe[excluded_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_df1 = exclude_columns_in_df(kaggle_combined, ['_merge']).sort_values(by=['Year', 'Country']) \nsorted_df2 = exclude_columns_in_df(kaggle_combined_country_and_continents[kaggle_combined.columns], ['_merge']).sort_values(by=['Year', 'Country'])\ndiff_df1 = dataframe_difference(sorted_df1, sorted_df2[sorted_df1.columns])\ndiff_df2 = dataframe_difference(sorted_df2[sorted_df1.columns], sorted_df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'diff_df1: {diff_df1.shape[0]} diff_df2: {diff_df2.shape[0]}')\nprint(f'kaggle_combined: {kaggle_combined.shape[0]}, ' \\\n      f'kaggle_combined_country_and_continents: {kaggle_combined_country_and_continents.shape[0]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_indices = set(kaggle_combined.index) - set(kaggle_combined_country_and_continents.index)\nlen(diff_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.testing import assert_frame_equal\n\ntry:\n    assert_frame_equal(kaggle_combined, kaggle_combined_country_and_continents[kaggle_combined.columns])\nexcept Exception as ex:\n    print(ex)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n!mkdir -p /kaggle/working/tmp\nos.environ['sorted_df1_filename'] = '/kaggle/working/tmp/kaggle_combined.csv'\nos.environ['sorted_df2_filename'] = '/kaggle/working/tmp/kaggle_combined_country_and_continents.csv'\nsorted_df1_filename = os.environ['sorted_df1_filename']\nsorted_df2_filename = os.environ['sorted_df2_filename']\nsorted_df1.to_csv(sorted_df1_filename, index=False)\nsorted_df2[sorted_df1.columns].to_csv(sorted_df2_filename, index=False)\n!head -n 1 $sorted_df1_filename\n! echo \"\"\n!head -n 1 $sorted_df2_filename\n! echo \"\"\n!diff --suppress-common-lines -y $sorted_df1_filename $sorted_df2_filename\nprint(\"Download the two .csv files and compare them using diff (just like the above command)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Doing the above, seems like an old-school way to compare datasets but it gives a better idea why there is a difference between the datasets, so far it seems semantically the datasets are different but if we have to look at it literally they differ a bit. Comparisons and analysis further on will show the differences."},{"metadata":{"trusted":true},"cell_type":"code","source":"original_index = sorted(kaggle_combined.index.to_list())\nindex_after_merge = sorted(kaggle_combined_country_and_continents.index.to_list())\nprint(kaggle_combined.shape[0], kaggle_combined_country_and_continents.shape[0], \n      kaggle_combined.shape[0] - kaggle_combined_country_and_continents.shape[0], \n      len(set(original_index) - set(index_after_merge)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the shape (row count) functions return a mismatch although the `merge()` and `concat()` (after dropping duplicates) do not seem to find"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fuzzywuzzy import fuzz\nFILTER_COLUMN = 'Country'\n\ncentral_countries_list = list(set(country_and_continent_info[FILTER_COLUMN].values))\nprint(f'No of countries in the \"country_and_continent_info\" table: {len(central_countries_list)}')\n\ncountries_active_on_kaggle = list(set(kaggle_combined_country_and_continents[FILTER_COLUMN].values))\nprint(f'No of countries active on Kaggle (\"kaggle_combined_country_and_continents\" table): {len(countries_active_on_kaggle)}')\n\ncountries_active_on_kaggle = list(set(kaggle_combined[FILTER_COLUMN].values))\nprint(f'No of countries active on Kaggle (\"kaggle_combined\" table): {len(countries_active_on_kaggle)}')\n\nprint()\nfilter_not_active_on_kaggle = ~country_and_continent_info[FILTER_COLUMN].isin(countries_active_on_kaggle)\ncountries_not_active_on_kaggle = list(set(country_and_continent_info[filter_not_active_on_kaggle][FILTER_COLUMN].values))\nprint(f'No of countries NOT active on Kaggle: {len(countries_not_active_on_kaggle)}')\n\nfound_pairs = {}\nfor not_an_active_country in countries_not_active_on_kaggle:\n    for active_country in countries_active_on_kaggle:\n        ratio = fuzz.token_sort_ratio(not_an_active_country, active_country)\n        if ratio >= 70:\n            found_pairs.update({not_an_active_country: active_country})\n\nprint(f'No of countries that match (between countries_active_on_kaggle and countries_not_active_on_kaggle) due to fuzzy similarity: {len(found_pairs)}')\n\ncountry_and_continent_info['active_on_kaggle'] = 1\ncountry_and_continent_info.loc[filter_not_active_on_kaggle, 'active_on_kaggle'] = 0\nactive_filter = country_and_continent_info['active_on_kaggle'] == 1\nprint()\nprint(f'No of countries NOT active on Kaggle: {country_and_continent_info[~active_filter].shape[0]}')\nprint(f'No of countries active on Kaggle: {country_and_continent_info[active_filter].shape[0]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_and_continent_info['Region'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_and_continent_info['Continent'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(country_and_continent_info[country_and_continent_info['Country Code'].isna()])\ndisplay(country_and_continent_info[['Country', 'Country Code']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_and_continent_info.to_csv(f'{PREPROCESSED_DATASET_UPLOAD_FOLDER}/country_and_continent_info.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for correctness after merging the datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"countries_check_df = pd.concat([kaggle_combined['Country'].value_counts(), \n                                kaggle_combined_country_and_continents['Country'].value_counts()], axis=1)\ncountries_check_df.columns=['Before merging count', 'After merging count']\ncountries_check_df['Difference'] = countries_check_df['After merging count'] - countries_check_df['Before merging count']\nfilter_differences = countries_check_df['Difference'] != 0\nprint(f\"Sum of all the differences: {abs(countries_check_df['Difference'].sum())}\")\ncountries_check_df[filter_differences]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checks on Turkey data"},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_turkey_kc = (kaggle_combined['Country'] == 'Turkey')\nfilter_turkey_kccc = (kaggle_combined_country_and_continents['Country'] == 'Turkey')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\n    \"kaggle_combined row count:\", kaggle_combined[filter_turkey_kc].shape[0], \n    \"\\nkaggle_combined_country_and_continents row count:\", kaggle_combined_country_and_continents[filter_turkey_kccc][kaggle_combined.columns].shape[0]\n)\nprint()\nprint(\"With limited (as that of kaggle_combined) columns (after dropping duplicates):\", kaggle_combined_country_and_continents.loc[filter_turkey_kccc, kaggle_combined.columns].drop_duplicates(keep='first').shape)\nprint(\"With all columns (after dropping duplicates):\", kaggle_combined_country_and_continents.loc[filter_turkey_kccc].drop_duplicates(keep='first').shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above we can say more or less that all the new data seems to be good, the mismatch in row counts arise when we try to drop duplicates (especially when we scope the columns to only that of the `kaggle_combined` dataset."},{"metadata":{},"cell_type":"markdown","source":"#### Checks on Hong Kong data"},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_extra_HK_2020_data = (kaggle_combined['Country'] == 'Hong Kong') & (kaggle_combined['Year'] != 2020) \nprint('Before merging countries')\nprint('   - Original count:', kaggle_combined[filter_extra_HK_2020_data].shape)\nprint('   - Duplicates dropped count:', kaggle_combined[filter_extra_HK_2020_data].drop_duplicates().shape)\nprint('After merging countries')\nfilter_extra_HK_2020_data = (kaggle_combined_country_and_continents['Country'] == 'Hong Kong') & (kaggle_combined_country_and_continents['Year'] != 2020) \nprint('   - Duplicates dropped count:', kaggle_combined_country_and_continents[filter_extra_HK_2020_data].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_HK_2020_data = (kaggle_combined['Country'] == 'Hong Kong') & (kaggle_combined['Year'] == 2020) \nkaggle_combined[filter_HK_2020_data]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can confirm that there is no data for **Hong Kong** in **2020**. Also there are no duplicates present."},{"metadata":{},"cell_type":"markdown","source":"### Let's check Denmark, Canada, HK or another country"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_to_check = 'Finland'\nfilter_country_c = kaggle_combined['Country'] == country_to_check\nfilter_country_cc = kaggle_combined_country_and_continents['Country'] == country_to_check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = kaggle_combined[filter_country_c].sort_index().reset_index(drop=True)\nb = kaggle_combined_country_and_continents[filter_country_cc][kaggle_combined.columns].sort_index().reset_index(drop=True)\ndataframe_difference(a, b, 'both')\nprint(a['Year'].value_counts(), b['Year'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_combined_country_and_continents.to_csv(\n    f'{PREPROCESSED_DATASET_UPLOAD_FOLDER}/kaggle_2017_to_2020_and_countries.csv', index=False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Survey response v/s total Kaggle members stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_users_count_upto_end_of(year: int) -> int:\n    filter_year = (kaggle_users['RegisterDate'] <= f'12/31/{year}') ## MM/DD/YYYY date format (US format)\n    return kaggle_users[filter_year]['RegisterDate'].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nforce_generate = True\nif force_generate:\n    kaggle_users = pd.read_csv('../input/meta-kaggle/Users.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nkaggle_members_count_stats = {\n    'Year': ['2020', '2019', '2018', '2017'], \n    'Total_members_count': [get_users_count_upto_end_of(2020), get_users_count_upto_end_of(2019), \n              get_users_count_upto_end_of(2018), get_users_count_upto_end_of(2017)]\n}\n\nkaggle_members_count_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del kaggle_users\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_response_count_for(year: int) -> int:\n    filter_year = preprocessed_kaggle_combined['Year'] == year\n    return preprocessed_kaggle_combined[filter_year].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_kaggle_combined = pd.read_csv('../input/kaggle-machine-learning-data-science-survey-ext/preprocessed-kaggle-2017-to-2020/kaggle_2017_to_2020.csv')\nkaggle_response_count_stats = {\n    'Year': ['2020', '2019', '2018', '2017'], \n    'Total_responses_count': [get_response_count_for(2020), get_response_count_for(2019), \n              get_response_count_for(2018), get_response_count_for(2017)]\n}\n\nkaggle_response_count_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_response_stats_df = pd.DataFrame(kaggle_response_count_stats).merge(\n    pd.DataFrame(kaggle_members_count_stats), \n    how ='inner', on='Year'\n)\nsurvey_response_stats_df = survey_response_stats_df.sort_values(by='Year').reset_index(drop=True)\nsurvey_response_stats_df['Members_to_response_ratio'] = survey_response_stats_df['Total_responses_count'] / survey_response_stats_df['Total_members_count']\n\ncolumns = list(set(survey_response_stats_df.columns) - set(['Year']))\n\nfor each_column in columns:\n    if 'pct_change' not in each_column:\n        new_column = f'{each_column}_pct_change'\n        survey_response_stats_df[new_column] = survey_response_stats_df[each_column].pct_change()\nsurvey_response_stats_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"survey_response_stats_df.to_csv(f'{PREPROCESSED_DATASET_UPLOAD_FOLDER}/survey_response_stats.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Zipping the respective directories"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\nUPLOAD_FOLDER=\"/kaggle/working/upload\"\nPREPROCESSED_UPLOAD_FOLDER='/kaggle/working/upload/preprocessed-kaggle-2017-to-2020'\n\necho \"~~~ Zipping folder: ${PREPROCESSED_UPLOAD_FOLDER}\"\ncd \"${PREPROCESSED_UPLOAD_FOLDER}\"\nzip -r9 ${PREPROCESSED_UPLOAD_FOLDER}.zip *\necho \"~~~ ${PREPROCESSED_UPLOAD_FOLDER}.zip ready to be used/copied.\"\ncd ${UPLOAD_FOLDER}\nls -lash *.zip \necho \"\"","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.063918,"end_time":"2021-01-01T21:02:37.371949","exception":false,"start_time":"2021-01-01T21:02:37.308031","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Uploading newly created/updated csv to your Kaggle Dataset\n\nSetup your local environment with your Kaggle login details (`KAGGLE_KEY` and `KAGGLE_USERNAME`)."},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T21:02:37.513283Z","iopub.status.busy":"2021-01-01T21:02:37.512538Z","iopub.status.idle":"2021-01-01T21:02:39.379506Z","shell.execute_reply":"2021-01-01T21:02:39.378927Z"},"papermill":{"duration":1.943857,"end_time":"2021-01-01T21:02:39.379642","exception":false,"start_time":"2021-01-01T21:02:37.435785","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nimport os\nos.environ['KAGGLE_KEY'] = user_secrets.get_secret(\"KAGGLE_KEY\")\nos.environ['KAGGLE_USERNAME'] = user_secrets.get_secret(\"KAGGLE_USERNAME\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.061854,"end_time":"2021-01-01T21:02:39.503203","exception":false,"start_time":"2021-01-01T21:02:39.441349","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Using the `kaggle` Python client login, into your account from within the kernel."},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T21:02:39.632056Z","iopub.status.busy":"2021-01-01T21:02:39.631374Z","iopub.status.idle":"2021-01-01T21:02:39.695202Z","shell.execute_reply":"2021-01-01T21:02:39.694574Z"},"papermill":{"duration":0.130529,"end_time":"2021-01-01T21:02:39.695314","exception":false,"start_time":"2021-01-01T21:02:39.564785","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import kaggle\nkaggle.api.authenticate()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.061922,"end_time":"2021-01-01T21:02:39.81958","exception":false,"start_time":"2021-01-01T21:02:39.757658","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Get the metadata for the dataset you have already created manually - it's best to manually create it and upload the initial csv file(s) into it, to avoid subsequent issues with updating the dataset (as seen during my own end-to-end cycle).\n\nSave the metadata file as a json file but before that, add/update two keys id and id_no with the respective details as shown below and then save it."},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T21:02:39.951175Z","iopub.status.busy":"2021-01-01T21:02:39.950453Z","iopub.status.idle":"2021-01-01T21:02:40.892599Z","shell.execute_reply":"2021-01-01T21:02:40.891105Z"},"papermill":{"duration":1.011645,"end_time":"2021-01-01T21:02:40.892744","exception":false,"start_time":"2021-01-01T21:02:39.881099","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"OWNER_SLUG='neomatrix369'\nDATASET_SLUG='kaggle-machine-learning-data-science-survey-ext'\ndataset_metadata = kaggle.api.metadata_get(OWNER_SLUG, DATASET_SLUG)\ndataset_metadata['id'] = dataset_metadata[\"ownerUser\"] + \"/\" + dataset_metadata['datasetSlug']\ndataset_metadata['id_no'] = dataset_metadata['datasetId']\nimport json\nwith open(f'{DATASET_UPLOAD_FOLDER}/dataset-metadata.json', 'w') as file:\n    json.dump(dataset_metadata, file, indent=4)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.106089,"end_time":"2021-01-01T21:02:41.061476","exception":false,"start_time":"2021-01-01T21:02:40.955387","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Finally call the dataset_create_version() api and pass it the folder where the metadata file exists and also where your .csv and .fth file(s) - those file(s) that you would like to upload into your existing Dataset (as a new version)."},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T21:02:41.191366Z","iopub.status.busy":"2021-01-01T21:02:41.190357Z","iopub.status.idle":"2021-01-01T21:03:54.814456Z","shell.execute_reply":"2021-01-01T21:03:54.813938Z"},"papermill":{"duration":73.690922,"end_time":"2021-01-01T21:03:54.81457","exception":false,"start_time":"2021-01-01T21:02:41.123648","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"%%time\n# !kaggle datasets version -m \"Updating datasets\" -p /kaggle/working/upload\nkaggle.api.dataset_create_version(DATASET_UPLOAD_FOLDER, 'Updating datasets')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.082104,"end_time":"2021-01-01T21:03:54.97921","exception":false,"start_time":"2021-01-01T21:03:54.897106","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Cleanup "},{"metadata":{"execution":{"iopub.execute_input":"2021-01-01T21:03:55.154575Z","iopub.status.busy":"2021-01-01T21:03:55.148923Z","iopub.status.idle":"2021-01-01T21:03:55.893473Z","shell.execute_reply":"2021-01-01T21:03:55.89279Z"},"papermill":{"duration":0.83214,"end_time":"2021-01-01T21:03:55.893596","exception":false,"start_time":"2021-01-01T21:03:55.061456","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!rm -fr /kaggle/working/upload","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thanks / Credits\n\n- [sahilmaheshwari](https://www.kaggle.com/sahilmaheshwari/) (https://www.kaggle.com/thedatabeast/cleaned-mcr-kaggle-survey-2019)\n- [rblcoder](https://www.kaggle.com/rblcoder/) (https://www.kaggle.com/aitzaz/stack-overflow-developer-survey-2020)\n- [harveenchadha](https://www.kaggle.com/harveenchadha) (https://www.kaggle.com/harveenchadha/kaggle-survey-20172020-merged-data) - special thanks for your data preparatory kernel (https://www.kaggle.com/harveenchadha/merging-all-historical-survey-data-2017-2020), I have reused a number of things from it\n\nFor sharing a number of additional survey/country/region/world related datasets."},{"metadata":{"papermill":{"duration":0.081822,"end_time":"2021-01-01T21:03:56.058155","exception":false,"start_time":"2021-01-01T21:03:55.976333","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Prequels/sequels\n\n- **Kaggle Machine Learning & Data Science (data-prep)** | [Extended Dataset](https://www.kaggle.com/neomatrix369/kaggle-machine-learning-data-science-survey-ext) | [Additional Dataset](https://www.kaggle.com/neomatrix369/world-bank-data-1960-to-2016-extended)\n- [Kaggle Global Outreach (analysis)](https://www.kaggle.com/neomatrix369/kaggle-global-outreach-analysis/)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}