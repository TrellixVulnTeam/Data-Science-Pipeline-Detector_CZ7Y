{"cells":[{"metadata":{"toc":true},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Business-Understanding\" data-toc-modified-id=\"Business-Understanding-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Business Understanding</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Data-Understanding\" data-toc-modified-id=\"Data-Understanding-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Understanding</a></span><ul class=\"toc-item\"><li><span><a href=\"#Describe-Data\" data-toc-modified-id=\"Describe-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Describe Data</a></span></li><li><span><a href=\"#Verify-Data-Quality\" data-toc-modified-id=\"Verify-Data-Quality-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Verify Data Quality</a></span><ul class=\"toc-item\"><li><span><a href=\"#Missing-Data\" data-toc-modified-id=\"Missing-Data-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Missing Data</a></span></li></ul></li><li><span><a href=\"#Initial-Data-Exploration\" data-toc-modified-id=\"Initial-Data-Exploration-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Initial Data Exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distributions\" data-toc-modified-id=\"Distributions-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Distributions</a></span></li></ul></li><li><span><a href=\"#Professional-Distributions\" data-toc-modified-id=\"Professional-Distributions-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Professional Distributions</a></span></li></ul></li><li><span><a href=\"#Data-Prep\" data-toc-modified-id=\"Data-Prep-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Prep</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Kmeans\" data-toc-modified-id=\"Kmeans-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Kmeans</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li></ul></li><li><span><a href=\"#Deploy\" data-toc-modified-id=\"Deploy-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Deploy</a></span></li></ul></div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from IPython.display import Markdown, display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_(text):\n    result = \"<p style='border:2px; border-style:solid; border-color:#8D90A6; padding: 1em; background-color:#EBEDF6;'>\" + text + \"</p>\" \n    display(Markdown(result))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* # What type of Data Scientist are you?\n\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/who-are-you/whoareyou.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Applying CRISP-DM to Kaggle Survey.**"},{"metadata":{},"cell_type":"markdown","source":"The objective is explore the data by professions and understanding the profile of Data Scientists using Cluster algorithms."},{"metadata":{},"cell_type":"markdown","source":"# Business Understanding"},{"metadata":{},"cell_type":"markdown","source":"* **What are the desired outputs of the project?**\n\n    - Tell a history about Kaggle users that answers the Survey"},{"metadata":{},"cell_type":"markdown","source":"* **What Questions Are We Trying To Answer**?\n    - What are the characteristics from professionals?  (Quais são as caracteristicas dos diferentes profissionais que responderam ao survey?\n    - It's possible to identify profiles of Data Scientits? (É possivel identificar perfis diferentes de cientistas?)"},{"metadata":{},"cell_type":"markdown","source":"* **Key Results:**\n - There are some curiosities when we analyzed the data by professions, like, there are some Machine Learning Engineers thar working in companies that don't uses Machine Learning.  \n - We identified 4 profiles of data scientists, they are:\n     - The Beginner\n     - The Intermediate\n     - The Advanced\n     - The Ghost\n     \nRead more to find another curiosities! And if you like, give me a comment or a upvote (="},{"metadata":{},"cell_type":"markdown","source":"# Functions"},{"metadata":{},"cell_type":"markdown","source":"Section to create utils functions!"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def quantile_plot1(x, **kwargs):\n#     title = kwargs.get('title')\n    with sns.plotting_context(\"notebook\",font_scale=15):\n        sns.set(style=\"ticks\", color_codes=True)\n        \n        ax = sns.barplot(x=x, data=c_counts,  y='percentage', hue=\"Q5\", dodge=False)\n#         ax.set_title(title)\n        for p in ax.patches:\n            ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()),\n                        ha='center', va='bottom',\n                        color= 'black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def counts(x):\n    c_counts = (df_modelagem_.groupby(['Q5'])[x]\n                     .value_counts(normalize=True)\n                     .rename('percentage')\n                     .mul(100)\n                     .reset_index()\n                     .sort_values(x))\n    return c_counts\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def missing_values_table(df):\n        mis_val = df.isnull().sum()\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def count_values_table(df):\n        count_val = df.value_counts()\n        count_val_percent = 100 * df.value_counts() / len(df)\n        count_val_table = pd.concat([count_val, count_val_percent.round(1)], axis=1)\n        count_val_table_ren_columns = count_val_table.rename(\n        columns = {0 : 'Count Values', 1 : '% of Total Values'})\n        return count_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def counts_plot(df, col, title):\n    sns.countplot(x=df[col])\n    # Add labels to the plot\n    style = dict(size=10, color='gray')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Histogram\ndef hist_chart(df, col, title):\n    plt.style.use('seaborn')\n#     plt.hist(df[col].dropna(), edgecolor = 'k');\n    plt.hist(df[col].dropna())\n    plt.xlabel(col)\n    plt.ylabel('Number of Entries')\n    plt.xticks(rotation='vertical')\n    plt.rc('xtick', labelsize=8)\n    plt.title(title)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def hist_chart(df, col, title, patche_c):\n#     plt.style.use('seaborn')\n    fig, ax = plt.subplots(1, figsize=(16,6))\n    n, bins, patches = plt.hist(df[col].dropna(),color = \"skyblue\")\n    # define minor ticks and draw a grid with them\n    minor_locator = AutoMinorLocator(10)\n    plt.gca().xaxis.set_minor_locator(minor_locator)\n#     plt.grid(which='minor', color='white', lw = 0.5)\n    # x ticks\n    xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n    xticks_labels = [ \"{:.2f}\\nto\\n{:.2f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n#     plt.xticks(xticks, labels = xticks_labels)\n#     ax.tick_params(axis='x', which='both',length=0)\n    # remove y ticks\n    plt.yticks([])\n    plt.xticks(rotation='vertical')\n\n    patches[patche_c].set_fc('steelblue')\n    # Hide the right and top spines\n    ax.spines['bottom'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['top'].set_visible(False)\n    # plot values on top of bars\n    for idx, value in enumerate(n):\n        if value > 0:\n            plt.text(xticks[idx], value+5, int(value), ha='center')\n    plt.title(title, loc = 'left', fontsize = 18)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Understanding"},{"metadata":{},"cell_type":"markdown","source":"In this sections we start to understanding the dataset. We will analyze shape, missing, what type of columns we have and think about data prep. \nHere we will start our analyze about the respondents. This analyzes will be done grouped by professions; "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Import Libraries Required\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import AutoMinorLocator\nfrom matplotlib import gridspec\n%matplotlib inline\nimport numpy as np\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Source Query location: \npath =  '../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv'\n# reads the data from the file - denotes as CSV, it has no header, sets column headers\ndf =  pd.read_csv(path, sep=',')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Describe Data "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 2037 respondents and 355 questions. All columns are objects (str), and maybe we will need do some transformations;"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#df.info()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# used to see the questions\npd.DataFrame(df.loc[0].values).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Verify Data Quality"},{"metadata":{},"cell_type":"markdown","source":" ### Missing Data"},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nprint('Preview of missing columns')\npd.DataFrame(df.isnull().sum()).head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"missing_values_table(df).tail(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will import matplotlib to resize our plot figure\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.figure(figsize=(20, 10))\n\n# cubehelix palette is a part of seaborn that produces a colormap\ncmap = sns.cubehelix_palette(light=1, as_cmap=True, reverse=True)\nsns.heatmap(df.isnull(), cmap=cmap)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This graph shows us that are a lot of missing values. Let's select the columns with more than 50% of missing values and remove"},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Get the columns with > 50% missing\nmissing_df = missing_values_table(df);\nmissing_columns = list(missing_df[missing_df['% of Total Values'] > 50].index)\nprint('We will remove %d columns.' % len(missing_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Drop the columns\ndf_ = df.drop(list(missing_columns), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We believe that is not interesting to analyse columns with a lot of missing. So, we removed that columns. This is important too, because we want to do a model."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initial Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"### Distributions"},{"metadata":{},"cell_type":"markdown","source":"Here we will analyse some variables to all dataset. In the graphs, we can see the absolute values and in the table, there are the percentages"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"col = 'Q1'\nfig, ax = plt.subplots(figsize=(12, 4))\n\nsns.countplot(x=df.iloc[1:,].Q1, ax=ax, order = df.iloc[1:,].Q1.value_counts().index)\n# Add labels to the plot\nplt.annotate('20% has betwen 25-29 years and 0.4% has 70+', xy=(5, 3500))\nplt.show()\n\ncount_values_table(df.Q1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"col = 'Q2'\nfig, ax = plt.subplots(figsize=(12, 4))\n\nsns.countplot(x=df.iloc[1:,].Q2, ax=ax, order = df.iloc[1:,].Q2.value_counts().index)\n# Add labels to the plot\nplt.annotate('78% are Man, 19.4% are Woman and less than 2% are others diversityes', xy=(1, 14000))\nplt.show()\ncount_values_table(df.Q2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = 'Q3'\nfig, ax = plt.subplots(figsize=(22, 8))\n\nsns.countplot(x=df.iloc[1:,].Q3.sort_values(), ax=ax, order = df.iloc[1:,].Q3.value_counts().index)\n# Add labels to the plot\nplt.annotate('India and USA  have almost 50% of professionals. Brasil is the 4th of the list with 3.5%.', xy=(18, 4000))\nplt.xticks(rotation=45)\nplt.show()\ncount_values_table(df.Q3)\n\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"col = 'Q4'\nfig, ax = plt.subplots(figsize=(12, 4))\n\nsns.countplot(x=df.iloc[1:,].Q4.sort_values(), ax=ax, order = df.iloc[1:,].Q4.value_counts().index)\n# Add labels to the plot\nplt.annotate('74% of professionals are Masters or bachelors and 1% has no formal education', xy=(2, 4000))\nplt.xticks(rotation=75)\nplt.show()\ncount_values_table(df.Q4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = 'Q5'\nfig, ax = plt.subplots(figsize=(12, 4))\n\nsns.countplot(x=df.iloc[1:,].Q5.sort_values(), ax=ax, order = df.iloc[1:,].Q5.value_counts().index)\n# Add labels to the plot\nplt.annotate('25% of respondents are Students, 13% are DS (our public of interest). DBA represents just 0.6' , xy=(2, 4000))\nplt.xticks(rotation=75)\nplt.show()\n\ncount_values_table(df.Q5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Professional Distributions"},{"metadata":{},"cell_type":"markdown","source":"Here we will perform analysis by title of professionals:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_modelagem = df_.iloc[1:, 1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analise by title:\nt1 = df_modelagem[df_modelagem['Q5'] == 'Student']\nt2 = df_modelagem[df_modelagem['Q5'] == 'Data Engineer']\nt3 = df_modelagem[df_modelagem['Q5'] == 'Software Engineer']\nt4 = df_modelagem[df_modelagem['Q5'] == 'Data Scientist']\nt5 = df_modelagem[df_modelagem['Q5'] == 'Data Analyst']\nt6 = df_modelagem[df_modelagem['Q5'] == 'Research Scientist']\nt7 = df_modelagem[df_modelagem['Q5'] == 'Other']\nt8 = df_modelagem[df_modelagem['Q5'] == 'Currently not employed']\nt9 = df_modelagem[df_modelagem['Q5'] == 'Statistician']\nt10 = df_modelagem[df_modelagem['Q5'] == 'Product/Project Manager']\nt11 = df_modelagem[df_modelagem['Q5'] == 'Machine Learning Engineer']\nt12= df_modelagem[df_modelagem['Q5'] == 'Unknown']\nt13 = df_modelagem[df_modelagem['Q5'] == 'Business Analyst']\nt13 = df_modelagem[df_modelagem['Q5'] == 'DBA/Database Engineer']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_modelagem_ =  df_modelagem.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Disclaimer** : this graps are in wraped because I can't resize then in Kaggle Notebooks "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_.iloc[0,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nc_counts = counts(\"Q1\")\n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4)\ng.map(quantile_plot1, \"Q1\", title=df_.iloc[0,1])\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,1]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion\n- Data Scientist: 25% has between 25-29 years and 1% has 70+\n- ML Engineer: 27% has between 25-29 years and anyone has 70+\n- Students: 49% has between 18-21 years,\n- Statistican: 19% has between 25-29 years and 18% 22-24. 2% has 70+\n- BA: 22% has between 25-29 years\n- Product/Project Manager: There are representations in all intervals. \n- Data Analyst: 27% has between 25-29 years and 1% has 70+\n- Software Engineer: 21% has between 22-24 and 21% 25-29 years\n- Data Engineer: 25% has between 25-29 years\n- Resercher: 20% has between 30-34 years\n- Not Employed: 26% has between 25-29 years\n\n\nThe most part of respondents has between 25-29 years old. As expected, students are the most youngs and Reserchers are in 30-34 years old, probably after finish his doctor degreed. \n\n\n\n    \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q2\")\n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4)\ng.map(quantile_plot1, \"Q2\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=10.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,2]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion\n\nAs expected, the large majority are man. Data Analyst, Students and Statisticians are profession with most representativity that others; But away from a fair world"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nc_counts = counts(\"Q3\")\nc_counts = c_counts.sort_values(by=[ 'percentage', 'Q5',], ascending=False).head(100)\ng = sns.FacetGrid(c_counts, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q3\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,3]) \nfor ax in g.axes.flat:\n    ax.set_xticklabels(ax.get_xticklabels(),size = 12)\n    for label in ax.get_xticklabels():\n        label.set_rotation(90)\n\n\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's explore:"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts[c_counts.Q3 != 'India'].sort_values(by='percentage', ascending=False).head(50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts[c_counts.Q3 == 'Brazil'].sort_values(by='percentage', ascending=False).head(50)\n# c_counts.sort_values(by='percentage', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion:\nThe most part of respondents are from India, and they are in the most part Students or not employed, folowed by Software Engineer.  \nThe second part of respondents are form USA, where they are 17% Product/Project Manager,the others professions are aproximately 15% in each; \n\nIn Brazil are 6.14% of BA and the less representative profession are from Machine Learning Engineers;"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q4\")\n\ng = sns.FacetGrid(c_counts,col=\"Q5\", col_wrap=4, height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q4\")\ng.fig.tight_layout()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,4]) \nfor ax in g.axes.flat:\n    ax.set_xticklabels(ax.get_xticklabels(),size = 12)\n    for label in ax.get_xticklabels():\n        label.set_rotation(90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"About education, its possible observe that Researchers are in the most part Doctors; \nNot employed, are in the most part bachelors or some study without bachelor degree; \nAnother interesting observation, is that the most part of professionals choose not respond;"},{"metadata":{"code_folding":[],"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"c_counts = counts(\"Q6\")\nc_counts = c_counts.drop(55, axis=0)\n\ng = sns.FacetGrid(c_counts,sharex=False, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q6\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,6]) \nfor ax in g.axes.flat:\n    labels = ax.get_xticklabels() # get x labels\n    ax.set_xticklabels(labels, rotation=30) # set new labels\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most experients with programming are  DBA with 20+ years of experience (21%); followed by Researchs (16%); \nThe less experients are Bussiness Analyst, with 12% has never written code; followed by Managers and not employed;\nSoftware engineers has the less % of respondents tha never write code (1%)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(df_.iloc[0,7])\nc_counts = counts(\"Q7_Part_1\")\n\ng = sns.FacetGrid(c_counts,sharex=False, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q7_Part_1\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,7]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All respondents uses Python"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nc_counts = counts(\"Q8\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q8 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i) \n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q8\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,8]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And the most recommended language is Python. R and Sql are also recomended."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nc_counts = counts(\"Q9_Part_1\")\n# i = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q9_Part_1 == 'Null')].index.tolist()\n# c_counts = c_counts.drop(i) \n\ng = sns.FacetGrid(c_counts,sharex=False, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q9_Part_1\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,9]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All uses Jupyter"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q11\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q11 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i) \n\ng = sns.FacetGrid(c_counts, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q11\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,10]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts.sort_values(by=['Q5', 'percentage'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most part uses a personal computer or laptop. Machine Learning Engineer, Data Scients and Data Engineers are the users of cloud computing "},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q13\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q13 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i) \n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q13\")\ng.fig.tight_layout(pad=0.5, w_pad=0.5, h_pad=8.0)\n\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,11]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most part has never used TPU. 21% of Machine Learning Engineers has used 2-5 times  and 19% of Data Engineers too;"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q14_Part_1\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q14_Part_1 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i) \n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q14_Part_1\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,12]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All uses Matplotlib"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q15\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q15 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i) \n\ng = sns.FacetGrid(c_counts,sharex=False, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q15\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,13]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most experiences with ML methods are DS and ML Engineers, approximately 12% with 5-10years. The less are Database Engineers (27% do not use ML and 30% under 1 year)"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q16_Part_1\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q16_Part_1 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i) \n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q16_Part_1\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,14]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q17_Part_1\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q17_Part_1 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i)\n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q17_Part_1\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,15]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q20\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q20 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i)\n\ng = sns.FacetGrid(c_counts,sharex=False, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q20\")\ng.fig.tight_layout(pad=0.5, w_pad=0.5, h_pad=8.0)\n\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,16]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most part of respondents working in small companies with 0-49 employees; But there is a good percentage working in big companies (10000 or more)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nc_counts = counts(\"Q21\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q21 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i)\n\n\n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q21\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\n\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,17]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A curiosity observation, is that some Data Scientists (9%) answered that there is 0 individuals responsible by data science workload in your companies; And the most part of others answered that there is 1-2 responsible; "},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q22\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q22 == 'Null')].index.tolist()\nc_counts = c_counts.drop(i)\nc_counts = c_counts.replace({'No (we do not use ML methods)': 'No','We are exploring ML methods (and may one day put a model into production)': 'Exploring', 'We use ML methods for generating insights (but do not put working models into production)': 'Insights', 'We recently started using ML methods (i.e., models in production for less than 2 years)': 'recently stated', 'We have well established ML methods (i.e., models in production for more than 2 years)': 'well established'  })\n\n\ng = sns.FacetGrid(c_counts,sharex=False, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q22\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,18]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts.sort_values(by=['Q22','percentage'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we can see another curiosity. There is **Data Scientists and Machine Leaning Engineers that work in companies that don't uses ML** methods. Between statistician, 30% do not uses ML "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q24\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q24 == 'Null')].index\nc_counts = c_counts.drop(i, axis=0)\n\nsns.set(font_scale=0.5)  # crazy big\n\ng = sns.FacetGrid(c_counts, sharex=False,col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q24\")\ng.fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=4.0)\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,19]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Professions with bigger salary are DBAs (>500.000). The most part of respondents earn between 0-999; And, the most part with this salary are statisticians\n"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q25\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q25 == 'Null')].index\nc_counts = c_counts.drop(i, axis=0)\n\ng = sns.FacetGrid(c_counts,sharex=False, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q25\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,20]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most part does not spent money in cloud computing services; Followed by spent 100-999. And 12% of DS spent more than \\$100.000"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts = counts(\"Q38\")\ni = c_counts[(c_counts.Q5 == 'Null') & (c_counts.Q38 == 'Null')].index\nc_counts = c_counts.drop(i)\n\ng = sns.FacetGrid(c_counts,sharex=False, col=\"Q5\", col_wrap=4,  height=8, aspect=0.5)\ng.map(quantile_plot1, \"Q38\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle(df_.iloc[0,21]) \nfor ax in g.axes.flat:\n    for label in ax.get_xticklabels():\n        label.set_rotation(45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_counts.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Basic statistical software  or Local development environments  is the majority choises; Statisticians are that users of advanced softwares"},{"metadata":{},"cell_type":"markdown","source":"#  Data Prep"},{"metadata":{},"cell_type":"markdown","source":"In this section, we will made some treatments to test some models;"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds = df_modelagem[df_modelagem.Q5 == 'Data Scientist']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(df_cds.Q4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds.Q4 = df_cds.Q4.replace({\"Master’s degree\": 'Master', 'Doctoral degree': 'Doctor', 'Bachelor’s degree': 'Bachelor', 'I prefer not to answer':'Not answer', 'No formal education past high school': 'NFE', 'Some college/university study without earning a bachelor’s degree': 'college/university without bachelor'  })","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# !pip install country_converter --upgrade\n# ! pip install pycountry --upgrade","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pycountry\ninput_countries = df_cds.Q3\n\ncountries = {}\nfor country in pycountry.countries:\n    countries[country.name] = country.alpha_2\n\ncodes = [countries.get(country, country) for country in input_countries]\n\n# codes =  pd.Series(codes)\n\n# codes.replace({'United States of America': 'USA','Iran, Islamic Republic of...': 'Iran', 'United Kingdom of Great Britain and Northern Ireland': 'Great Britain'})\n\ndf_cds['Q3_renamed'] =  codes\n\n\n# df_cds.Q3_renamed = df_cds.Q3_renamed.replace({'United States of America': 'USA','Iran, Islamic Republic of...': 'Iran', 'United Kingdom of Great Britain and Northern Ireland': 'Great Britain'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds.Q22 =  df_cds.Q22.replace({'No (we do not use ML methods)': 'No','We are exploring ML methods (and may one day put a model into production)': 'Exploring', 'We use ML methods for generating insights (but do not put working models into production)': 'Insights', 'We recently started using ML methods (i.e., models in production for less than 2 years)': 'recently stated', 'We have well established ML methods (i.e., models in production for more than 2 years)': 'well established'  })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove years\n# df_cds.replace(['years'],'')\n# employees","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds.Q11.replace({})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds = df_cds.fillna('Unknow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds_wna = df_cds.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model\n\nHere we are interested in buil a model to identify profiles of Data Scientists. 3 models will be tested: Hyerarchy with Gower distance; K-means and DBSCAN with MCA.\n\nWe will perfom some tests with some missings and removing all of then. \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_modelagem = df_.iloc[1:, 1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import DistanceMetric","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"! pip install gower\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import linkage, fcluster, dendrogram, leaves_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"! pip install prince","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gower\nimport prince # for multiple correspondence analysis\nfrom sklearn.feature_selection import SelectKBest, chi2 # for chi-squared feature selection\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gower distance is used with categorical features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dm = gower.gower_matrix(df_cds)\ndm_wna = gower.gower_matrix(df_cds_wna)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we used a hierarchical algorithm to find the clusters:"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# dendrogram(Zd) \nZ = linkage(dm, 'ward')\nfig = plt.figure(figsize=(25, 10))\ndn = dendrogram(Z, color_threshold=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dendrogram(Zd) \nZ_wna = linkage(dm_wna, 'ward')\nfig = plt.figure(figsize=(25, 10))\ndn = dendrogram(Z_wna, color_threshold=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cld = fcluster(Z, 3, criterion='maxclust')\ncld","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_cds_wna = df_cds_wna.drop(['H_CLUSTER', 'D_Clusters', 'K_Clusters'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'ts possible to see 3 clusters. To explore more, we will use MCA to transform features and use K-means and DBSCAN"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"mca = prince.MCA(\n        n_components=4,\n        n_iter=3,\n        copy=True,\n        check_input=True,\n        engine='auto',\n        random_state=42\n        )\nmca = mca.fit(df_cds)\n\nax = mca.plot_coordinates(\n        X=df_cds,\n        ax=None,\n        figsize=(16, 30),\n        show_row_points=False,\n        row_points_size=0,\n        show_row_labels=False,\n        show_column_points=True,\n        column_points_size=30,\n        show_column_labels=True,\n        legend_n_cols=1\n               ).legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\nplt.savefig('mca_plot.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### test without NA cases:\n\nmca_wna = prince.MCA(\n        n_components=4,\n        n_iter=3,\n        copy=True,\n        check_input=True,\n        engine='auto',\n        random_state=42\n        )\nmca_wna = mca_wna.fit(df_cds_wna)\n\nax = mca_wna.plot_coordinates(\n        X=df_cds_wna,\n        ax=None,\n        figsize=(16, 30),\n        show_row_points=False,\n        row_points_size=0,\n        show_row_labels=False,\n        show_column_points=True,\n        column_points_size=30,\n        show_column_labels=True,\n        legend_n_cols=1\n               ).legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\nplt.savefig('mca_plot_wna.png')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_cds_mca = mca.transform(df_cds)\ndf_cds_mca.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds_mca_wna = mca_wna.transform(df_cds_wna)\ndf_cds_mca_wna.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MCA was used to transform categorical data in numeric to perform others clusters algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\nX  = df_cds_mca\nX_wna = df_cds_mca_wna","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_kwargs = {\n    \"init\": \"random\",\n    \"n_init\": 10,\n    \"max_iter\": 300,\n    \"random_state\": 42,\n}\n\n# A list holds the SSE values for each k\nsse = []\nfor k in range(1, 11):\n    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n    kmeans.fit(X)\n    sse.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"fivethirtyeight\")\nplt.plot(range(1, 11), sse)\nplt.xticks(range(1, 11))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"SSE\")\nplt.show()\nplt.savefig('n_clusters_kmeans.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_kwargs = {\n    \"init\": \"random\",\n    \"n_init\": 10,\n    \"max_iter\": 300,\n    \"random_state\": 42,\n}\n\n# A list holds the SSE values for each k\nsse_wna = []\nfor k in range(1, 11):\n    kmeans_wna = KMeans(n_clusters=k, **kmeans_kwargs)\n    kmeans_wna.fit(X_wna)\n    sse_wna.append(kmeans_wna.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"fivethirtyeight\")\nplt.plot(range(1, 11), sse_wna)\nplt.xticks(range(1, 11))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"SSE\")\nplt.show()\nplt.savefig('n_clusters_kmeans.png')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install pip install kneed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kneed import KneeLocator\n\nkl = KneeLocator(\n    range(1, 11), sse_wna, curve=\"convex\", direction=\"decreasing\"\n)\n\nkl.elbow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kl.plot_knee()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kneed import KneeLocator\n\nkl = KneeLocator(\n    range(1, 11), sse, curve=\"convex\", direction=\"decreasing\"\n)\n\nprint(kl.elbow)\nkl.plot_knee()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using this lib and prior knowledge, we will use 4 clusters"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"\nkmeans = KMeans(n_clusters=4, random_state=0).fit(X)\nkmeans.labels_\n\ny_kmeans = kmeans.predict(X)\n\n# kmeans.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y_kmeans, s=50, cmap='viridis')\n\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nkmeans_wna = KMeans(n_clusters=4, random_state=0).fit(X_wna)\nkmeans_wna.labels_\n\ny_kmeans_wna = kmeans_wna.predict(X_wna)\n\nkmeans_wna.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(X_wna.iloc[:, 0], X_wna.iloc[:, 1], c=y_kmeans_wna, s=50, cmap='viridis')\n\ncenters_wna = kmeans_wna.cluster_centers_\nplt.scatter(centers_wna[:, 0], centers_wna[:, 1], c='black', s=200, alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**obs**: remove rows with NA does not makes difference to kmeans"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import DBSCAN\nfrom sklearn.metrics import adjusted_rand_score, silhouette_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate k-means and dbscan algorithms\nkmeans = KMeans(n_clusters=4, random_state=0)\ndbscan = DBSCAN(eps=0.3)\n\n# Fit the algorithms to the features\nkmeans.fit(X)\ndbscan.fit(X)\n\n# Compute the silhouette scores for each algorithm\nkmeans_silhouette = silhouette_score(\n    X, kmeans.labels_\n).round(2)\ndbscan_silhouette = silhouette_score(\n   X, dbscan.labels_\n).round (2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('kmeans_silhouette', kmeans_silhouette)\nprint('dbscan_silhouette', dbscan_silhouette)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\n# Compute DBSCAN\ndb = DBSCAN(eps=0.3, min_samples=10).fit(X)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\n# Number of clusters in labels, ignoring noise if present.\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise_ = list(labels).count(-1)\n\nprint('Estimated number of clusters: %d' % n_clusters_)\nprint('Estimated number of noise points: %d' % n_noise_)\n# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n# print(\"Adjusted Rand Index: %0.3f\"\n#       % metrics.adjusted_rand_score(labels_true, labels))\n# print(\"Adjusted Mutual Information: %0.3f\"\n#       % metrics.adjusted_mutual_info_score(labels_true, labels))\n# print(\"Silhouette Coefficient: %0.3f\"\n#       % metrics.silhouette_score(X, labels))\n\n# #############################################################################\n# Plot result\nimport matplotlib.pyplot as plt\n\n# Black removed and is used for noise instead.\nunique_labels = set(labels)\ncolors = [plt.cm.Spectral(each)\n          for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n        # Black used for noise.\n        col = [0, 0, 0, 1]\n\n    class_member_mask = (labels == k)\n\n    xy = X.iloc[class_member_mask & core_samples_mask]\n    plt.plot(xy.iloc[:, 0], xy.iloc[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=14)\n\n    xy = X.iloc[class_member_mask & ~core_samples_mask]\n    plt.plot(xy.iloc[:, 0], xy.iloc[:, 1], 'o', markerfacecolor=tuple(col),\n             markeredgecolor='k', markersize=6)\n\nplt.title('Estimated number of clusters: %d' % n_clusters_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(db.labels_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds['D_Clusters'] = db.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = df_cds[df_cds.D_Clusters == 0]\nd2 = df_cds[df_cds.D_Clusters == 1]\nd3 = df_cds[df_cds.D_Clusters == 2]\nd4 = df_cds[df_cds.D_Clusters == 3]\nd5 = df_cds[df_cds.D_Clusters == 4]\nd6 = df_cds[df_cds.D_Clusters == 5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds['K_Clusters'] = kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(kmeans.labels_)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_cds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k1 = df_cds[df_cds.K_Clusters == 0]\nk2 = df_cds[df_cds.K_Clusters == 1]\nk3 = df_cds[df_cds.K_Clusters == 2]\nk4 = df_cds[df_cds.K_Clusters == 3]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation"},{"metadata":{},"cell_type":"markdown","source":"Let's do some exploratory analysis in each cluster that was found:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.offsetbox import AnchoredText\n\ndef plot_KDE(df, col, nClusters, cluster, title=None):\n    df = df.copy()\n    new_colum = col+\"_f\"\n    df[new_colum] = pd.factorize(df[col] )[0]\n    \n    dict_ = {}\n    for key,value in zip(df[new_colum].drop_duplicates(),df.loc[df[new_colum].drop_duplicates().index][col] ): \n        dict_[key] = value\n    \n    plt.subplots(figsize=(10,7), dpi=100)\n    colors = ['orange', 'deeppink', 'green', 'blue','firebrick', 'skyblue']\n    \n    if cluster == 'H_CLUSTER':\n        r = range(1, nClusters+1)\n    else:\n        r= range(0, nClusters+1)\n    \n    for i in r:\n        try:\n            ax = sns.distplot( df.loc[df[cluster]==i, new_colum] , color=colors[i], label=i)\n        except RuntimeError as re:\n            if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n                ax =  sns.distplot( df.loc[df[cluster]==i, new_colum] , color=colors[i], label=i, kde_kws={'bw': 0.1})\n            else:\n                raise re\n                \n    plt.legend(fontsize='small')\n\n    plt.title(title)\n#     size = dict(size=plt.rcParams['legend.fontsize'])\n    size={'family': 'Ubuntu Condensed', 'size': 12, 'fontweight': 'light'}\n    anchored_text = AnchoredText(dict_, loc='upper left',prop=size, pad=0., borderpad=0.5)\n    if len(dict_) < 15:\n        ax.add_artist(anchored_text)\n    \n#     return df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hierarchical"},{"metadata":{},"cell_type":"markdown","source":"Let's see the distributions of clusters founded by Hierarchical clustering:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds['H_CLUSTER']= cld","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h1 = df_cds[df_cds.H_CLUSTER == 1]\nh2 = df_cds[df_cds.H_CLUSTER == 2]\nh3 = df_cds[df_cds.H_CLUSTER == 3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pct3 = df_cds.replace({'18-21':18, '22-24':22, '25-29':25, '30-34':30,'35-39':35, '40-44':40, '45-49':45,'50-54':50, '55-59':55, '60-69':60, '70+':70})\na = plot_KDE(pct3, 'Q1', 3,'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(pct3, 'Q2', 3,'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = plot_KDE(pct3, 'Q3', 3,'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(h1['Q3'].value_counts()[:n].index.tolist())\nprint(h2['Q3'].value_counts()[:n].index.tolist())\nprint(h3['Q3'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q4', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q6', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q8', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q11', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q13', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q15', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q20', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q21', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q22', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q24', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q25', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q38', 3, 'H_CLUSTER')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This results shows that are different types of Data Scientists;  "},{"metadata":{},"cell_type":"markdown","source":"### DBSCAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# pct3 = (df_cds.groupby(['K_Clusters','Q1']).size() / df_cds.groupby(['K_Clusters']).size()).reset_index().rename({0:'percent'}, axis=1)\npct3 = df_cds.replace({'18-21':18, '22-24':22, '25-29':25, '30-34':30,'35-39':35, '40-44':40, '45-49':45,'50-54':50, '55-59':55, '60-69':60, '70+':70})\nplot_KDE(df_cds, 'Q1', 5, 'D_Clusters')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q2', 5, 'D_Clusters')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(d1['Q3'].value_counts()[:n].index.tolist())\nprint(d2['Q3'].value_counts()[:n].index.tolist())\nprint(d3['Q3'].value_counts()[:n].index.tolist())\nprint(d4['Q3'].value_counts()[:n].index.tolist())\nprint(d5['Q3'].value_counts()[:n].index.tolist())\nprint(d6['Q3'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q3', 5, 'D_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most of clusters are overrrided, so we will explore K-means!"},{"metadata":{},"cell_type":"markdown","source":"### Kmeans"},{"metadata":{},"cell_type":"markdown","source":"* Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q1'].value_counts()[:n].index.tolist())\nprint(k2['Q1'].value_counts()[:n].index.tolist())\nprint(k3['Q1'].value_counts()[:n].index.tolist())\nprint(k4['Q1'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds_wna","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pct3 = (df_cds.groupby(['K_Clusters','Q1']).size() / df_cds.groupby(['K_Clusters']).size()).reset_index().rename({0:'percent'}, axis=1)\npct3 = df_cds.replace({'18-21':18, '22-24':22, '25-29':25, '30-34':30,'35-39':35, '40-44':40, '45-49':45,'50-54':50, '55-59':55, '60-69':60, '70+':70})\n\nplot_KDE(df_cds, 'Q1', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: 25-29\n* Cluster 1: 25-29\n* Cluster 2: 30-34\n* Cluster 3: 22-24"},{"metadata":{},"cell_type":"markdown","source":"* Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q2', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The clusters are composed mostly by men"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q2'].value_counts()[:n].index.tolist())\nprint(k2['Q2'].value_counts()[:n].index.tolist())\nprint(k3['Q2'].value_counts()[:n].index.tolist())\nprint(k4['Q2'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds.groupby('Q3_renamed').size().sort_values().plot(kind='barh',figsize=(10,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds['Q3_f'] = pd.factorize( df_cds.Q3 )[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplot_KDE(df_cds, 'Q3', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most part of DS are form India; Just the Cluster 02 is composed mostly by Americans. The first clusters has a percentage of Brazilians."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# plt.rcParams[\"figure.figsize\"] = (30,3)\n\n# pct3 = (df_cds.groupby(['K_Clusters','Q3']).size() / df_cds.groupby(['K_Clusters']).size()).reset_index().rename({0:'percent'}, axis=1)\n# sns.barplot(x='Q3', hue='K_Clusters', y='percent', data=pct3.sort_values(by='percent', ascending=False))\n# plt.xticks(rotation=70)\n# plt.legend(loc='upper right')\n# plt.tight_layout()\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q3'].value_counts()[:n].index.tolist())\nprint(k2['Q3'].value_counts()[:n].index.tolist())\nprint(k3['Q3'].value_counts()[:n].index.tolist())\nprint(k4['Q3'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0: Master’s degree; 1:Doctoral degree, 2:Bachelor’s; 3:Some college/university study without earningbachelor; 4:I prefer not to answer; 5: Professional degree; 6:No formal education past high school\nplot_KDE(df_cds, 'Q4', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost data scients are Masters. Cluster 02 has doctors and 03 has more bachelors than masters;"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# plt.rcParams[\"figure.figsize\"] = (20,3)\n\n# pct3 = (df_cds.groupby(['K_Clusters','Q4']).size() / df_cds.groupby(['K_Clusters']).size()).reset_index().rename({0:'percent'}, axis=1)\n# sns.barplot(x='Q4', hue='K_Clusters', y='percent', data=pct3.sort_values(by='percent', ascending=False))\n# plt.xticks(rotation=70)\n# plt.legend(loc='upper right')\n# plt.tight_layout()\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q4'].value_counts()[:n].index.tolist())\nprint(k2['Q4'].value_counts()[:n].index.tolist())\nprint(k3['Q4'].value_counts()[:n].index.tolist())\nprint(k4['Q4'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cds['Q6_f'] = pd.factorize( df_cds.Q6 )[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q6', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: 0-10 years and 3-5 years (has medium experience)\n* Cluster 1: 3-5 years; Never write code (has medium experience)\n* Cluster 2: 10-20 years; >20years (has a lot of experience)\n* Cluster 3: < 1years; 1-2years (has litter experience)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q6'].value_counts()[:n].index.tolist())\nprint(k2['Q6'].value_counts()[:n].index.tolist())\nprint(k3['Q6'].value_counts()[:n].index.tolist())\nprint(k4['Q6'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,7]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q7_Part_1'].value_counts()[:n].index.tolist())\nprint(k2['Q7_Part_1'].value_counts()[:n].index.tolist())\nprint(k3['Q7_Part_1'].value_counts()[:n].index.tolist())\nprint(k4['Q7_Part_1'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q8', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nn=3\nprint(k1['Q8'].value_counts()[:n].index.tolist())\nprint(k2['Q8'].value_counts()[:n].index.tolist())\nprint(k3['Q8'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,9]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q9_Part_1'].value_counts()[:n].index.tolist())\nprint(k2['Q9_Part_1'].value_counts()[:n].index.tolist())\nprint(k3['Q9_Part_1'].value_counts()[:n].index.tolist())\nprint(k4['Q9_Part_1'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q11', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: Personal computer and cloud and deep learning station\n* Cluster 1: Unknow\n* Cluster 2: Personal computer and cloud, others\n* Cluster 3: Personal computer and Cloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_cds[['Q11_f', 'Q11']].head(30)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q11'].value_counts()[:n].index.tolist())\nprint(k2['Q11'].value_counts()[:n].index.tolist())\nprint(k3['Q11'].value_counts()[:n].index.tolist())\nprint(k4['Q11'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q13', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: Never and 2-5 times\n* Cluster 1: Unknow or Never\n* Cluster 2: Never or more than 25 times\n* Cluster 3: Never"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q13'].value_counts()[:n].index.tolist())\nprint(k2['Q13'].value_counts()[:n].index.tolist())\nprint(k3['Q13'].value_counts()[:n].index.tolist())\nprint(k4['Q13'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,12]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q14_Part_1'].value_counts()[:n].index.tolist())\nprint(k2['Q14_Part_1'].value_counts()[:n].index.tolist())\nprint(k3['Q14_Part_1'].value_counts()[:n].index.tolist())\nprint(k4['Q14_Part_1'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,13]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q15', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: 1-2; 3-4 years\n* Cluster 1: Unknow\n* Cluster 2: 5-10 years\n* Cluster 3: Under 1 year"},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q15'].value_counts()[:n].index.tolist())\nprint(k2['Q15'].value_counts()[:n].index.tolist())\nprint(k3['Q15'].value_counts()[:n].index.tolist())\nprint(k4['Q15'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,14]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q16_Part_1'].value_counts()[:n].index.tolist())\nprint(k2['Q16_Part_1'].value_counts()[:n].index.tolist())\nprint(k3['Q16_Part_1'].value_counts()[:n].index.tolist())\nprint(k4['Q16_Part_1'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q17_Part_1'].value_counts()[:n].index.tolist())\nprint(k2['Q17_Part_1'].value_counts()[:n].index.tolist())\nprint(k3['Q17_Part_1'].value_counts()[:n].index.tolist())\nprint(k4['Q17_Part_1'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,16]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q20', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: 0-49 \n* Cluster 1: Unknow\n* Cluster 2: 10,0000- 99999\n* Cluster 3 0-49"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q20'].value_counts()[:n].index.tolist())\nprint(k2['Q20'].value_counts()[:n].index.tolist())\nprint(k3['Q20'].value_counts()[:n].index.tolist())\nprint(k4['Q20'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,17]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q21', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: 3-4\n* Cluster 1: Unknow or 0\n* Cluster 2: 20+\n* Cluster 3 1-2 or 0"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q21'].value_counts()[:n].index.tolist())\nprint(k2['Q21'].value_counts()[:n].index.tolist())\nprint(k3['Q21'].value_counts()[:n].index.tolist())\nprint(k4['Q21'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,18]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q22', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: Recently started\n* Cluster 1: Unknow ; I do not know\n* Cluster 2: Well established\n* Cluster 3: Exploring"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q22'].value_counts()[:n].index.tolist())\nprint(k2['Q22'].value_counts()[:n].index.tolist())\nprint(k3['Q22'].value_counts()[:n].index.tolist())\nprint(k4['Q22'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,19]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q24', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: 30,000-39,999'\n* Cluster 1: Unknow ; 0-999\n* Cluster 2: 100,000-124,999\n* Cluster 3: 0-999"},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q24'].value_counts()[:n].index.tolist())\nprint(k2['Q24'].value_counts()[:n].index.tolist())\nprint(k3['Q24'].value_counts()[:n].index.tolist())\nprint(k4['Q24'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q25', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cluster 0: 1000-9,999\n* Cluster 1: Unknow or 0\n* Cluster 2: 100,000 or more\n* Cluster 3: 0"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q25'].value_counts()[:n].index.tolist())\nprint(k2['Q25'].value_counts()[:n].index.tolist())\nprint(k3['Q25'].value_counts()[:n].index.tolist())\nprint(k4['Q25'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.iloc[0,21]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_KDE(df_cds, 'Q38', 3, 'K_Clusters')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"n=3\nprint(k1['Q38'].value_counts()[:n].index.tolist())\nprint(k2['Q38'].value_counts()[:n].index.tolist())\nprint(k3['Q38'].value_counts()[:n].index.tolist())\nprint(k4['Q38'].value_counts()[:n].index.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion "},{"metadata":{},"cell_type":"markdown","source":"So, who are you?\n\nI'm in the Profile 0 (=  with some exceptions!"},{"metadata":{},"cell_type":"markdown","source":"* Profile 0 - Intemediate: earn more, work in medium companies,uses more softwares sophisticated, are in yours 25-29; \n* Profile 1:  Ghost  Don't answer :( or dont Know\n* Profile 2 - Advanced - has more experience with code, work in large companies that has ML methods in production. They are older and has more schooling and the most part already uses ML\n* Profile 3 - Begginner - earn little, has little experience and are youngers \n"},{"metadata":{},"cell_type":"markdown","source":"# Deploy"},{"metadata":{},"cell_type":"markdown","source":"- Next work:\n    *  Create a dash to visualize and compare years\n    * Identify clusters to all professions"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}