{"cells":[{"metadata":{},"cell_type":"markdown","source":"****Objective:**** \nTo study the behavior of various ^generations such as\n* Baby Boomers(Age group: 55 to 70+)\n* Gen X(Age group: 40 to 54)\n* Gen Y(Age group: 25 to 39)\n* Gen Z(Age group: 18 to 24)\n\nwith respect to\n\n1. Demographics\n2. User Profile\n3. Usage\n4. Data Science and ML Career Goal\n5. Organisation\n\n****Reference:****\nThe segmentation of age groups to various generation names has no thumb rule but has been inspired from the link ^[here](https://www.kasasa.com/articles/generations/gen-x-gen-y-gen-z).\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"# Import libraries\nimport os\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n\n# Read data from file,skip 2nd row which contains the decription\ndf = pd.read_csv(\"/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv\",skiprows=lambda x: x in [1]) \n\n#Store column names\ncol_df=df.columns\n\n#Creation of Segment variable based on Age group\ndf['Segment']= np.where(((df['Q1'] =='18-21') | (df['Q1'] =='22-24')), 'Gen Z', \n                        np.where(((df['Q1'] =='25-29') | (df['Q1'] =='30-34') | (df['Q1'] =='35-39')),'Gen Y',\n                        np.where(((df['Q1'] =='40-44') | (df['Q1'] =='45-49') | (df['Q1'] =='50-54')),'Gen X','Baby Boomers')))\n\n#Renaming th evalues of Q25 since output values in dataframe loses $ symbol\ndf['Q25']= np.where(df['Q25'] =='$0 ($USD)', '0 USD',\n                          np.where(df['Q25'] =='$1-$99','1 USD to 99 USD',\n                                   np.where(df['Q25'] =='$100-$999','100 USD to 9999 USD',\n                                           np.where(df['Q25'] =='$1000-$9,999','1000 USD to 9999 USD',\n                                                   np.where(df['Q25'] =='$10,000-$99,999','10K USD to 99999 USD',\n                                                           np.where(df['Q25'] =='$100,000 or more ($USD)','More than 100K USD',None))))))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"#Data Preprocessing\n\n#There are two kinds of questions,questions with single choice selection and questions with multiple choice selection.\n\n#Single choice selection  questions are named as Non-Underscore columns(unscr_cols).For e.g Q1,Q2,etc\n#Multiple choice selection questions are named as Underscore columns(unscr_cols) For e.g (Q7_Part_1,Q7_Part_2,etc)\n#Supplemetary questions are names as supp_cols\n\nunscr_cols=[]\nfor i in col_df:\n    if i.find('_')>0:\n        unscr_pos=i.find('_')#Identifying Multiple choice question\n        cols=i[:unscr_pos]\n        unscr_cols.append(cols)\n\n#Remove duplicates\nfinal_unscr_cols = [] \nfor i in unscr_cols: \n    if i not in final_unscr_cols: \n        final_unscr_cols.append(i)\n\nnon_unscr_cols=[]\nfor i in col_df:\n    if i.find('_')<0 and len(i)<=4:#Identifying Single choice question where underscore won't be present and negative value be returned\n        cols=i\n        non_unscr_cols.append(cols) \n\n#Remove duplicates\nfinal_non_unscr_cols = [] \nfor i in non_unscr_cols: \n    if i not in final_non_unscr_cols: \n        final_non_unscr_cols.append(i) \n\n#All unique columns\nall_cols=final_non_unscr_cols+final_unscr_cols\n\n#Sort columns\nall_cols.sort(key=len)\n\nsupp_cols=[]\nfor i in col_df:\n    if i.find('_B_')>0:\n        cols=i\n        supp_cols.append(cols)  \n\nsupp_unscr_cols=[]\nfor i in df.columns:\n    if i.find('_B')>0:#Identifying supplementary column\n        supp_unscr_pos=i.find('_B')\n        cols=i[:supp_unscr_pos]\n        supp_unscr_cols.append(cols)\n        \n#Remove Supplementary column duplicates\nfinal_supp_unscr_cols = [] \nfor i in supp_unscr_cols: \n    if i not in final_supp_unscr_cols: \n        final_supp_unscr_cols.append(i)\n\n#Non Supplementary\nnon_supp_cols = [item for item in col_df if item not in supp_cols]\n\nstr1=\"df\"\nstr2=\"ovr_df\"\nstr3=\"seg_df\"\nstr4='cols'\nall_cols_df = [\"{}{}{}\".format(i,'_',str1) for i in all_cols]\nall_ovr_cols_df = [\"{}{}{}\".format(i,'_',str2) for i in all_cols]\nall_seg_cols_df = [\"{}{}{}\".format(i,'_',str3) for i in all_cols]\n\nnon_unscr_cols_list = [\"{}{}{}\".format(i,'_',str1) for i in final_non_unscr_cols]\nnon_unscr_ovr_cols_list = [\"{}{}{}\".format(i,'_',str2) for i in final_non_unscr_cols]\nnon_unscr_seg_cols_list = [\"{}{}{}\".format(i,'_',str3) for i in final_non_unscr_cols]\n\nunscr_cols_list = [\"{}{}{}\".format(i,'_',str1) for i in final_unscr_cols]\nunscr_ovr_cols_list = [\"{}{}{}\".format(i,'_',str2) for i in final_unscr_cols]\nunscr_seg_cols_list = [\"{}{}{}\".format(i,'_',str3) for i in final_unscr_cols]\n\n\nunscr_subs_cols_list = [\"{}{}\".format(i,'_') for i in final_unscr_cols]\nunscr_col_names_list = [\"{}{}{}\".format(i,'_',str4) for i in final_unscr_cols]\n\nsupp_unscr_subs_cols_list = [\"{}{}\".format(i,'_B_') for i in final_supp_unscr_cols]\nsupp_unscr_col_names_list = [\"{}{}{}\".format(i,'_B_',str4) for i in final_supp_unscr_cols]\n\nsupp_unscr_cols_list = [\"{}{}{}\".format(i,'_B_',str1) for i in final_supp_unscr_cols]\nsupp_unscr_ovr_cols_list = [\"{}{}{}\".format(i,'_B_',str2) for i in final_supp_unscr_cols]\nsupp_unscr_seg_cols_list = [\"{}{}{}\".format(i,'_B_',str3) for i in final_supp_unscr_cols]\n\n#Setting caption for the output tables for each question\nnon_unscr_desc={'Q1':'Age',\n                'Q2':'Gender',\n                'Q3':'Country',\n                'Q4':'Education',\n                'Q5':'Current Role',\n                'Q6':'Code Experience',\n                'Q8':'Recommended Programming Language',\n                'Q11':'Current Computing Platform',\n                'Q13':'Current TPU Usage Frequency',\n                'Q15':'Machine Learning Experience',\n                'Q20':'Size of The Company',\n                'Q21':'Data Science Team Size',\n                'Q22':'Machine Learning Adoption',\n                'Q24':'Current Yearly Compensation',\n                'Q25':'ML/Cloud Computing Investment Past 5 years',\n                'Q30':'Current Big Data Usage',\n                'Q32':'Current BI Tool Usage',\n                'Q38':'Primary Tool for Data Analysis'\n                }\n\nunscr_desc= {   'Q7':'Regular Programming Language',\n                'Q9':'Regular IDE',\n                'Q10':'Regular Notebook Products',\n                'Q12':'Reguar Specialized Hardware',\n                'Q14':'Regular Visualization Tools/Libraries',\n                'Q16':'Regular Machine Learning Frameworks',\n                'Q17':'Regular Machine Learning Algorithms',\n                'Q18':'Regular Computer Vision Methods',\n                'Q19':'Regular Natural Language Processing Methods',\n                'Q23':'Work Activities',\n                'Q26':'Regular Computing Platforms',\n                'Q27':'Regular Cloud Computing Products',\n                'Q28':'Regular Machine Learning Products',\n                'Q29':'Regular Big Data Products',\n                'Q31':'Regular BI Tools',\n                'Q33':'Regular AutoML Tools',\n                'Q34':'Regular AutoML Tools',\n                'Q35':'Tools to help ML Experiments',\n                'Q36':'Deploy Platform',\n                'Q37':'Datascience Courses Learning',\n                'Q39':'Favorite Media Sources'\n                }\n\nsupp_unscr_desc= { \n                'Q26':'Next 2 years Cloud Computing Platform',\n                'Q27':'Next 2 years Cloud Computing Products',\n                'Q28':'Next 2 years ML Products',\n                'Q29':'Next 2 years Big Data Products',\n                'Q31':'Next 2 years BI Tools',\n                'Q33':'Next 2 years AutoML Category Tools',\n                'Q34':'Next 2 years AutoML Specific Tools',\n                'Q35':'Next 2 years Manage ML Experiment Tools'\n                }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"#Non-Underscore Columns Preprocessing(Single Choice Questions)\n\n#Overall Non Underscore columns\nnon_unscr_ovr_cols_df=pd.DataFrame(non_unscr_ovr_cols_list ,columns=['col'])\nnon_unscr_ovr_cols_dict = {elem : pd.DataFrame() for elem in non_unscr_ovr_cols_list}\n\nfor key in non_unscr_ovr_cols_dict.keys():\n    non_unscr_ovr_cols_dict[key] = non_unscr_ovr_cols_df[:][non_unscr_ovr_cols_df.col == key]\n\nfor key,i in zip(non_unscr_ovr_cols_dict.keys(),non_unscr_cols):\n    non_unscr_ovr_cols_dict[key]=df[i].value_counts(normalize=True,dropna=True).round(3).reset_index()\n    non_unscr_ovr_cols_dict[key].columns = [i,'Overall']       \n\n#Segment Non Underscore columns\nnon_unscr_seg_cols_df=pd.DataFrame(non_unscr_seg_cols_list,columns=['col'])\n\nnon_unscr_seg_cols_dict = {elem : pd.DataFrame() for elem in non_unscr_seg_cols_list}\n\nfor key in non_unscr_seg_cols_dict.keys():\n    non_unscr_seg_cols_dict[key] = non_unscr_seg_cols_df[:][non_unscr_seg_cols_df.col == key]\n\nfor key,i in zip(non_unscr_seg_cols_dict.keys(),non_unscr_cols):\n    non_unscr_seg_cols_dict[key]=pd.crosstab(df[i], df.Segment,dropna=True).apply(lambda r: (r/r.sum()), axis=0).round(2).reset_index()\n\n#Combine Overall and Segment Non Underscore columns\nnon_unscr_cols_df=pd.DataFrame(non_unscr_cols_list,columns=['col'])\nnon_unscr_cols_dict = {elem : pd.DataFrame() for elem in non_unscr_cols_list}\nfor key in non_unscr_cols_dict.keys():\n    non_unscr_cols_dict[key] = non_unscr_cols_df[:][non_unscr_cols_df.col == key]\n    \nfor key,i,key_ovr,key_seg in zip(non_unscr_cols_dict.keys(),non_unscr_cols,non_unscr_ovr_cols_dict.keys(),non_unscr_seg_cols_dict.keys()):\n    non_unscr_cols_dict[key]=pd.merge(non_unscr_ovr_cols_dict[key_ovr], non_unscr_seg_cols_dict[key_seg],how='inner',on=i)\n\n#Final Non Underscore column\nnon_unscr_col_names_dict = {elem : [] for elem in final_non_unscr_cols}\nfor key,key2,val in zip(non_unscr_cols_dict.keys(),non_unscr_col_names_dict.keys(),non_unscr_desc.values()):\n    non_unscr_col_names_dict[key2]=non_unscr_cols_dict[key].style\\\n    .format({'Overall': \"{:.0%}\",'Baby Boomers': \"{:.0%}\",'Gen X': \"{:.0%}\",'Gen Y': \"{:.0%}\",'Gen Z': \"{:.0%}\"})\\\n    .background_gradient(cmap='Blues',axis=1)\\\n    .set_properties(**{'text-align': 'center'})\\\n    .set_caption(val)\\\n    .set_table_styles([{\n        'selector': 'caption',\n        'props': [\n        ('color', 'black'),\n        ('font-size', '18px')\n        ]\n        }])\\\n    .hide_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"#Underscore Columns Preprocessing(Multiple choice questions)\n\n#Storing Underscore column names in the dict\nunscr_subs_col_names_dict = {elem : [] for elem in unscr_col_names_list}\nfor key,i in zip(unscr_subs_col_names_dict.keys(),unscr_subs_cols_list):\n    unscr_subs_col_names_dict[key] = [col for col in non_supp_cols if i in col]\n\n#Overall Underscore columns\nunscr_ovr_cols_dict = {elem : pd.DataFrame() for elem in unscr_ovr_cols_list}\nfor key,value,j in zip(unscr_ovr_cols_dict.keys(),unscr_subs_col_names_dict.values(),final_unscr_cols) :\n    for i in value:\n        tmp=pd.DataFrame(df[i].value_counts().rename_axis(j).reset_index(name='Overall'))\n        unscr_ovr_cols_dict[key]=pd.concat([unscr_ovr_cols_dict[key],tmp],ignore_index=True)\n        unscr_ovr_cols_dict[key]=unscr_ovr_cols_dict[key].sort_values(by=['Overall'], ascending=False)\n    unscr_ovr_cols_dict[key]['Overall']=(unscr_ovr_cols_dict[key]['Overall']/len(df))\n    \n#Segment Underscore columns\nunscr_seg_cols_dict = {i : pd.DataFrame(columns=[j,'Baby Boomers','Gen X','Gen Y','Gen Z']) for i,j in zip(unscr_seg_cols_list,final_unscr_cols)}\n\nfor key,value,j in zip(unscr_seg_cols_dict.keys(),unscr_subs_col_names_dict.values(),final_unscr_cols) :\n    for i in value:\n        tmp=pd.crosstab(df[i],df['Segment']).rename_axis(j).reset_index()\n        unscr_seg_cols_dict[key]=pd.concat([unscr_seg_cols_dict[key],tmp],ignore_index=True)\n\ncols = ['Baby Boomers','Gen X','Gen Y','Gen Z']\nfor key in unscr_seg_cols_dict.keys():\n    for i in cols:\n        unscr_seg_cols_dict[key][i]  = (unscr_seg_cols_dict[key][i]/(len(df[df.Segment== i]))).apply(pd.to_numeric, errors='coerce')\n\n#Combine Overall and Segment Underscore columns\nunscr_cols_dict = {elem : pd.DataFrame() for elem in unscr_cols_list}\nfor key,i,key_ovr,key_seg in zip(unscr_cols_dict.keys(),final_unscr_cols,unscr_ovr_cols_dict.keys(),unscr_seg_cols_dict.keys()):\n    unscr_cols_dict[key]=pd.merge(unscr_ovr_cols_dict[key_ovr], unscr_seg_cols_dict[key_seg],how='inner',on=i)\n\n#Final Underscore Columns Non Supplementary\nunscr_col_names_dict = {elem : [] for elem in final_unscr_cols}\nfor key,key2,val in zip(unscr_cols_dict.keys(),unscr_col_names_dict.keys(),unscr_desc.values()):\n    unscr_col_names_dict[key2]=unscr_cols_dict[key].style\\\n    .format({'Overall': \"{:.0%}\",'Baby Boomers': \"{:.0%}\",'Gen X': \"{:.0%}\",'Gen Y': \"{:.0%}\",'Gen Z': \"{:.0%}\"})\\\n    .background_gradient(cmap='Blues',axis=1)\\\n    .set_properties(**{'text-align': 'center'})\\\n    .set_caption(val)\\\n    .set_table_styles([{\n        'selector': 'caption',\n        'props': [\n        ('color', 'black'),\n        ('font-size', '18px')\n        ]\n        }])\\\n    .hide_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"#Supplementary columns Pre-processing\n\n#Storing Supplementary column names in the dict\nsupp_unscr_subs_col_names_dict = {elem : [] for elem in supp_unscr_col_names_list}\nfor key,i in zip(supp_unscr_subs_col_names_dict.keys(),supp_unscr_subs_cols_list):\n    #print(key,i)\n    supp_unscr_subs_col_names_dict[key] = [col for col in supp_cols if i in col]\n\n#Overall Underscore Supplementary columns\nsupp_unscr_ovr_cols_dict = {elem : pd.DataFrame() for elem in supp_unscr_ovr_cols_list}\n\nfor key,value,j in zip(supp_unscr_ovr_cols_dict.keys(),supp_unscr_subs_col_names_dict.values(),final_supp_unscr_cols) :\n    for i in value:\n        tmp=pd.DataFrame(df[i].value_counts().rename_axis(j).reset_index(name='Overall'))\n        supp_unscr_ovr_cols_dict[key]=pd.concat([supp_unscr_ovr_cols_dict[key],tmp],ignore_index=True)\n        supp_unscr_ovr_cols_dict[key]=supp_unscr_ovr_cols_dict[key].sort_values(by=['Overall'], ascending=False)\n    supp_unscr_ovr_cols_dict[key]['Overall']=(supp_unscr_ovr_cols_dict[key]['Overall']/len(df))\n\n#Segment Underscore Supplementary columns\nsupp_unscr_seg_cols_dict = {i : pd.DataFrame(columns=[j,'Baby Boomers','Gen X','Gen Y','Gen Z']) for i,j in zip(supp_unscr_seg_cols_list,final_supp_unscr_cols)}\n\nfor key,value,j in zip(supp_unscr_seg_cols_dict.keys(),supp_unscr_subs_col_names_dict.values(),final_supp_unscr_cols) :\n    for i in value:\n        tmp=pd.crosstab(df[i],df['Segment']).rename_axis(j).reset_index()\n        supp_unscr_seg_cols_dict[key]=pd.concat([supp_unscr_seg_cols_dict[key],tmp],ignore_index=True)\n\ncols = ['Baby Boomers','Gen X','Gen Y','Gen Z']\nfor key in supp_unscr_seg_cols_dict.keys():\n    for i in cols:\n        supp_unscr_seg_cols_dict[key][i]  = (supp_unscr_seg_cols_dict[key][i]/(len(df[df.Segment== i]))).apply(pd.to_numeric, errors='coerce')\n\n#Combine Overall and Segment Underscore Supplementary columns\nsupp_unscr_cols_dict = {elem : pd.DataFrame() for elem in supp_unscr_cols_list}\nfor key,i,key_ovr,key_seg in zip(supp_unscr_cols_dict.keys(),final_supp_unscr_cols,supp_unscr_ovr_cols_dict.keys(),supp_unscr_seg_cols_dict.keys()):\n    supp_unscr_cols_dict[key]=pd.merge(supp_unscr_ovr_cols_dict[key_ovr], supp_unscr_seg_cols_dict[key_seg],how='inner',on=i)\n\n#Final Supplementary columns\nsupp_unscr_col_names_dict = {elem : [] for elem in final_supp_unscr_cols}\nfor key,key2,val in zip(supp_unscr_cols_dict.keys(),supp_unscr_col_names_dict.keys(),supp_unscr_desc.values()):\n    supp_unscr_col_names_dict[key2]=supp_unscr_cols_dict[key].style\\\n    .format({'Overall': \"{:.0%}\",'Baby Boomers': \"{:.0%}\",'Gen X': \"{:.0%}\",'Gen Y': \"{:.0%}\",'Gen Z': \"{:.0%}\"})\\\n    .background_gradient(cmap='Blues',axis=1)\\\n    .set_properties(**{'text-align': 'center'})\\\n    .set_caption(val)\\\n    .set_table_styles([{\n        'selector': 'caption',\n        'props': [\n        ('color', 'black'),\n        ('font-size', '18px')\n        ]\n        }])\\\n    .hide_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generation Distribution"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"g=sns.color_palette(\"Blues_r\")\nax = sns.countplot(y=\"Segment\", data=df,order = df['Segment'].value_counts().index,palette=g)\n#\"#3498db\"\n\n#plt.title('Generation Distribution')\n#plt.xlabel('Segment')\nsns.set(rc={'figure.figsize':(13,5)})\ntotal = len(df['Segment'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()/2\n        ax.annotate(percentage, (x, y))\nsns.set_style(\"white\")\nsns.despine()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gen Y((Age group: 25 to 39) composition is the highest compared to any other segments"},{"metadata":{},"cell_type":"markdown","source":"\n# Demographics"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"display(non_unscr_col_names_dict['Q2'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Men in Baby Boomer's Segment is over-indexed(more compared to Overall) whereas Women are under-indexed (are very less compared to Overall).\n1. Women in Gen Z are more interested in ML & DS when compared to Overall "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q3']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n1. In India,Gen Z is highly over indexed and Baby Boomers are under indexed which indicates that young age group from India are highly interested in ML & DS whereas the Senior most citizens are less inclined\n2. In US,unlike India Baby Boomers are more interested in ML & DS whereas Gen Z is not much inclined.\n\nHypotheses:\n* Gen Z of India more interested in DS & ML compared to Gen Z of US\n* Marketing Campaigns of Data Science and ML to lure Gen Z of India is more compared to Gen Z of US\n* More diversified opportunities for Gen Z in US compared to less diversified opportunites to Gen Z in India"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q4']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Master's degree education of Gen Y is over indexed compared to Overall\n2. Gen Z is the youngest group so it is logical that Bachelor's degree is more in that segment\n3. Doctoral degree education of Baby Boomer is over indexed compared to Overall"},{"metadata":{},"cell_type":"markdown","source":"# User Profile"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q5']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Software Engineers of Gen X is more inclined towards Ml & DS when compared to Overall\n2. People with Other Job role and Unemployed of Baby Boomers are interested in ML & DS"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q6']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The age group of each generation mostly correlates with the years of code experience with each Segment"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q24']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Users with less than $1000 is 20% which is quite higher than any of the income groups.\n1. Gen Z comprises the youngest age group so it is obvious that they reside in the lowest income group."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q36']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n1. Github,Kaggle and Colab are the mostly shared platforms by users\n1. Gen X and Gen Y are over indexed in platforms-Github and Kaggle.\n1. Baby boomers are quite closed in terms of sharing"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q37']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n1. Coursera,Kaggle and Udemy are the top three learning platforms utilized by Users\n1. Baby boomers over indexed in edX specifically"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q39']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n1. Kaggle,Youtube and Blogs are the top three favorite Media Sources by Users\n1. Baby Boomers are versatile as they are over indexed in learning from media sources such as Kaggle,Email newsletters,Journals,Forums\n"},{"metadata":{},"cell_type":"markdown","source":"# Usage"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q7']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. Gen Z is over-indexed in Python,C++,Java and C compared to Overall\n2. Gen X is over-indexed in R, SQL and Bash compared to Overall\n3. Baby boomers is over-indexed in R and highly over indexed in Other,would be interesting to know what are the other programming languages,SAS,SPSS are not mentioned so Others might be becasue of that"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q8']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. Python is the most recommended programming language\n1. Baby boomers are more incllined in recommending R"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q9']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. Gen Z-Jupyter,Visual Studio Code, Pycharm and Spyder are over indexed compared to overall which indicates that Gen Z are more into Python\n2. Baby Boomer-R Studio,Notepad++ and Visual Studio are over indexed  compared to overall\n\nHypothesis:\nYounger generation inclined towards Python and Older generation inclined towards Non-Python languages"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q10']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"None is highly over indexed for Baby Boomer which has association in Other Programming language,might be the reason for choosing None "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q11']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nPersonal laptop/computer is majorly used as the current computing platform"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q12']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gen Z is more interested in GPUs and Baby boomers are not much inclined towards GPU"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q13']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTPU usage is still in nascent stage as most of the segments have never used it"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q14']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nSeaborn and Matplotlib are the mostly used Visualization libraries followed by Plotly and GGplot\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q15']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The age group of each generation mostly correlates with the years of ML experience with each Segment"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q16']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scikit-learn is the most regular machine learin framework"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q17']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. Baby boomers-Over indexed in CNN,Bayesian Approaches and RNN,this migh be becsause of engagement in Deep Learning\n2. Gen X-Over indexed in Linear/Logistic Regression,Decision Tree/Random Forest,GBM"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q18']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CNN architectures are the most regular Computer vision methods used"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q19']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Word embeddings/vectors are the most regular Computer vision methods used"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q26']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nAWS,GCP and Azure are the regulary used computing platforms"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q27']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nGen X is over-indexing in most of the cloud computing products.\n\nHypothesis:\nGen X is cloud centric"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q28']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nNo regular machine learing products used by the Segments"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q29']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MySQL, PostgresSQL and Micrsoft SQl are the most used big data products\n\nHive SQL,Teradata not present in options?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q30']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Gen Z-Over indexed in MySQL and Mongodb \n2. Gen X-Over indexed in PostgresSQL and Oracle Database\n3. Baby Boomer-Over indexed in Microsoft SQl server and DB2"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q31']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTableau is the most regulary used BI tool"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q32']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTableau and Microsoft power BI are mostly the currently used BI Tools"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q33']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"AutoML tools are not being used majorly"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q34']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unscr_col_names_dict['Q35']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTensorBoard is one of the major tools used to help ML experiments"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q38']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Local development environment and Basic Statistical software are mostly the primary tool used for data analysis\n1. Baby Boomers over indexed in Stastical Softwares(SPSS,SAS) and under indexed in Local development environments "},{"metadata":{},"cell_type":"markdown","source":"# Data Science and Machine Learning Career Goal"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"supp_unscr_col_names_dict['Q26']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. AWS,GCP and Microsoft Azure are the career goals of the non-professionals in the next 2 years\n1. Gen Z is over indexed here as they are hungry to learn everything"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"supp_unscr_col_names_dict['Q27']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nGoogle cloud computing products are the  career goals of the non-professionals in the next 2 years.\n\nHypothesis:\nSkill updated with AWS so planning to upgrade skills to Google's products\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"supp_unscr_col_names_dict['Q28']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"supp_unscr_col_names_dict['Q29']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nMySQL,Mongodb and PostgresSQL are the career goals of the non-professionals in the next 2 years in Big Data Products."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"supp_unscr_col_names_dict['Q31']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTableau,PowerBI and Google data studio are the career goals of the non-professionals in the next 2 years in Big Data Products."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"supp_unscr_col_names_dict['Q33']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"supp_unscr_col_names_dict['Q34']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"supp_unscr_col_names_dict['Q35']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Organization"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q20']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Gen Z higher indexed in 0-49 employees size company\n2. Gen X higher indexed in 10,000 or more employees size company"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q21']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The overall data science team size is 0 which indicates that most of them could be Independent contributors"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q22']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall ML Usage is less(17%+16%=33%) and most of them involved in Non-ML usecases in their type of work"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"non_unscr_col_names_dict['Q25']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall 36%,No-Investment has been done in ML or Cloud computing"},{"metadata":{},"cell_type":"markdown","source":"# Summary\n\n**Baby Boomers:**\n* Men involved in ML &DS is higher whereas Women in the same segment is least involved\n* People with Other Job role and Unemployed are interested in ML & DS\n* In India, they are under indexed which indicates that the Senior most citizens are less inclined towards ML &DS\n* In US, unlike India, they are more interested in ML & DS \n* Doctoral degree education is over indexed compared to Overall, which indicates that most of them are highly qualified\n* Quite closed in terms of sharing\n* Their choice of learning platform in edX is highly indexed\n* They are over indexed in learning from media sources such as Kaggle, Email newsletters, Journals, Forums.\n* Baby boomers are more inclined in recommending R\n* They don’t use regular Notebook Products as they are mainly R users and would work in localR Studio environment\n* They are not much inclined towards GPU\n* Over indexed in engagement in Deep Learning\n* Over indexed in Big data products- Microsoft SQL server and DB2\n* Some respondents of Baby boomers are Over indexed in Statistical Softwares(SPSS,SAS) and under indexed in Local development environments\n\n**Gen X:**\n* Software Engineers of Gen X is more inclined towards ML & DS when compared to Overall\n* Over indexed in platforms-Github and Kaggle\n* over-indexed in R, SQL and Bash compared to Overall\n* Over indexed in Linear/Logistic Regression, Decision Tree/Random Forest,GBM\n* Over-indexing in most of the cloud computing products, which shows that they are cloud centric\n* Over indexed in PostgresSQL and Oracle Database\n* Over indexed in 10,000 or more employees size company\n\n\n**Gen Y:**\n* Highest composition of the segment in the survey and these folks are **Millennials**\n* Master's degree education of Gen Y is over indexed compared to Overall\n* Over indexed in platforms-Github and Kaggle\n* The %response of Gen Y with respect to questions mostly aligns with Overall%, that is the reason they are neither over indexed nor under indexed\n\n**Gen Z:**\n* Women in Gen Z are more interested in ML & DS when compared to Overall\n* In India, Gen Z is highly over indexed which indicates that young age group from India are highly interested in ML & DS\n* In US, they are not much inclined towards ML & DS\n* It is the youngest group so it is logical to find more of them either pursuing/completed Bachelor's degree \n* They are the youngest age group with little experience so it is obvious that they reside in the lowest income group\n* Over-indexed in Programming Languages-Python, C++, Java and C\n* Jupyter,Visual Studio Code, Pycharm and Spyder are over indexed compared to overall which indicates that Gen Z are more into Python\n* More interested in GPUs\n* Over indexed in MySQL and Mongodb\n* Over indexed in all the technologies present in “Next 2 years Cloud Computing Platform” as they are hungry to learn everything\n* Google cloud computing products are the career goals of the non-professionals in the next 2 years.\n* Over indexed in 0-49 employees size company\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}