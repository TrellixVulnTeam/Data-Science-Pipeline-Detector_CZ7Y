{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **How To Get a Job in Data Science**\n\nAt this stage of my life, I am trying to solve one problem, that is how can I successfully transfer from a mechanical engineer to a job in the data science, either an analyst or scientist, or any other titles.\n\nI will be focusing my analysis on the **2020 Kaggle Machine Learning & Data Science Survey** to extract the most recent and valuable information to help myself to gain in-depth understanding of the current job market and to make better strategic decisions in the job hunting process.\n\nHere is a link to the survey\nhttps://www.kaggle.com/c/kaggle-survey-2020\n\nI broke up the analysis into three stages:\n* Since I have been targetting myself to a data scientist role, I will first concentrating on **finding the relationship between the data scientist and below aspectes**, using Data Exploratory Analysis and Correspondence Analysis.\n  * Age\n  * Gender\n  * Country\n  * Education level\n  * Languages and IDE\n* Then I will **build a classifier with various multi-classification models to predict the job role** based on the answers each participant has given, and pick the model with the best performance.\n* Last I will **use the model to find the most suitable positions for me** based on my current skill sets and experience. and I will also search for the most contributing factor to be employed for such a role (hopefully a data scientist), so that I can work on that effectively to get hired soon!"},{"metadata":{},"cell_type":"markdown","source":"## Import Data and General Overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"#install necessary modules\n!pip install prince\n!pip install adjustText","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import all packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom prince import CA, MCA\nimport seaborn as sns\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load data\ndf = pd.read_csv(\"/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv\", low_memory=False)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### General scan of the whole dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove first row and first column\ndf_cp = df.drop(index=0)\ndf_cp = df_cp.drop(columns = \"Time from Start to Finish (seconds)\")\ndf_cp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check missing values\ndf_cp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Restructure the dataset to make it easier to manage\nWe see sub-part questions presents in some of the questions, I will group them together and save them as separate data frames in a dictionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"#initialise the dictionary\nquestions = {}\n\n#create a list of grouped questions\nqnums = list(set([q.split(\"_\")[0] for q in df_cp.columns]))\nqnums = sorted(qnums, key=lambda q:int(q[1:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#group dataframe to the question in the dictionary questions\nfor i in qnums:\n    questions[i] = df_cp[[q for q in df_cp.columns if q.split(\"_\")[0] == i]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#example of Q7 looks like below\nquestions[\"Q7\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA - Overview of Data Science job market\nCorrespondence analysis (CA) are used extensively in this section to connect the dots between the data scientist role and the chosen categorical variables. It allows us an appropriate visualisation of qualitative variables with the help of a map of perception, so that I can obtain a better picture of the whole job market and see where myself is positioned.\n\nMoreover, it is also able to give me some level of confidence indirectly by showing the inertia in the CA to indicate how well the visualisations at hand represent the reality."},{"metadata":{},"cell_type":"markdown","source":"### Data Positions in terms of Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"#correspondence analysis on age & positions\nage_ds = pd.crosstab(df_cp.Q1,df_cp.Q5)\nca_age = CA(n_components=2)\nca_age.fit(age_ds)\nca_age.plot_coordinates(age_ds, figsize=(10,10));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variability is explained 96.26% which gives a good indication of age distribution.\n\nA clear segmentation is shown between job positions to different age groups. Not to mention the apparent where Student are associated with age 18-22, **there is a clear transition from younger age group who tends to work on product and application to a more senior group who does more theoretical research** which normally requires higher education level, i.e. more years is required to reach such positions.\n\nAge 29 (my age) is more associated with Data Analyst, Machine Learning Engineer and Data Scientist and it is also true that I am currently not employed as a data scientist related jobs! (wondering how does the CA figured that out :)"},{"metadata":{},"cell_type":"markdown","source":"Let's take a closer look at the age distribution of being a data scientist"},{"metadata":{"trusted":true},"cell_type":"code","source":"#define sutset for data scientist\ndf_ds = df_cp[df_cp.Q5==\"Data Scientist\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"lightblue\"] * len(df_ds.Q1.value_counts().index)\ncolors[0] = \"lightsalmon\"\n\nfig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Age Distribution of Data Scientist\")))\nfig.add_trace(go.Bar(x= df_ds.Q1.value_counts().index,\n                     y=df_ds.Q1.value_counts().values,\n                     marker_color=colors))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**At age of 29, I think I have a good chance of getting hired! Age ticked!**"},{"metadata":{},"cell_type":"markdown","source":"### Data Positions in terms of Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"#use adjustText module to reduce the overlap between the texts in maps created from CA\nfrom adjustText import adjust_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correspondence analysis on gender & positions\ngender_ds = pd.crosstab(df_cp.Q2,df_cp.Q5)\nca_gender = CA(n_components=2)\nca_gender.fit(gender_ds)\nax = ca_gender.plot_coordinates(gender_ds,\n                                figsize=(10,10),\n                                show_row_labels=False,show_col_labels=False).legend(loc=\"center right\")\n\n#adjust text to overlapping between different labels\ncols=ca_gender.column_coordinates(gender_ds).to_dict()\nxcols=cols[0]\nycols=cols[1]\nrows=ca_gender.row_coordinates(gender_ds).to_dict()\nxrows=rows[0]\nyrows=rows[1]\n\nxglobal={ k : xcols.get(k,0)+xrows.get(k,0) for k in set(xcols) | set(xrows) }\nyglobal={ k : ycols.get(k,0)+yrows.get(k,0) for k in set(ycols) | set(yrows) }\n\nfig = ax.get_figure()\ntexts=[plt.text(xglobal[x],yglobal[x],x,fontsize=10) for x in xglobal.keys()]\nadjust_text(texts,arrowprops=dict(arrowstyle='-', color='red'));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variability is explained 94.11% which gives a good indication of gender distribution.\n\n**There is a huge gender imbalance in the data science industry** where most positions are occupied by Man, indicating the overall job market are male dominated.\n\nLet's take a closer look at the gender distribution of being a data scientist"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"lightblue\"] * len(df_ds.Q2.value_counts().index)\ncolors[0] = \"lightsalmon\"\n\nfig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Gender Distribution of Data Scientist\")))\nfig.add_trace(go.Bar(x= df_ds.Q2.value_counts().index,\n                     y=df_ds.Q2.value_counts().values,\n                     marker_color=colors))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The bar plot demonstrates the same information where number of Man is approximately four times the sum of the other genders, among all the respondents. Hopefully certain schemes or programmes in data science industry can be set up to promote other genders to pursuit a career in the relevant fields.\n\n**Being a man makes me the majority of the workforce in this industry.**"},{"metadata":{},"cell_type":"markdown","source":"### Data Positions in terms of Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"#country distribution on a reduced dataset for clarification, based on the population\n#who took the survey, the first 20 counties with most participants are selected here\n\nn = 20\nreduced_country = df_cp.Q3.value_counts().iloc[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_red = pd.DataFrame()\nfor c in reduced_country.index:\n    df_red = df_red.append(df_cp[df_cp.Q3 == c])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correspondence analysis on country & positions\ncountry_ds = pd.crosstab(df_red.Q3,df_red.Q5)\nca_country = CA(n_components=2)\nca_country.fit(country_ds)\nca_country.plot_coordinates(country_ds, figsize=(10,10),show_row_labels=False,show_col_labels=False)\n\n#adjust text to overlapping between different labels\ncols=ca_country.column_coordinates(country_ds).to_dict()\nxcols=cols[0]\nycols=cols[1]\nrows=ca_country.row_coordinates(country_ds).to_dict()\nxrows=rows[0]\nyrows=rows[1]\n\nxglobal={ k : xcols.get(k,0)+xrows.get(k,0) for k in set(xcols) | set(xrows) }\nyglobal={ k : ycols.get(k,0)+yrows.get(k,0) for k in set(ycols) | set(yrows) }\n\nfig = ax.get_figure()\ntexts=[plt.text(xglobal[x],yglobal[x],x,fontsize=10) for x in xglobal.keys()]\nadjust_text(texts,arrowprops=dict(arrowstyle='-', color='red'));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variability is explained 74.06% which gives an okay indication of country distribution.\n\nThe analysis on countries is more complicated, since there so many other factors associated with countries that would influence the position distribution within an industry, such as educational level, salary level and industry/technology level as a whole. Chances are that the same position can be called differently, or vice versa in different countries. However, **the first principal component is able to draw a line between developed countries (left side of the map) from the developing countries (right side of the map)** whereas the **second principal component differentiate the types of the job roles, from application biased (top of the map) towards research biased (bottom of the map)**.\n\n**Thus, most data science related jobs are concentrated on developed countries; Also Germany and Japan have higher proportion in Research Scientist than the rest of the countries**.\n\nLet's also check the absolute number of respondents' nationality of the survey to make sure we do not draw conclusion without context."},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"lightblue\"] * len(df_red.Q3.value_counts().index)\ncolors[6] = \"lightsalmon\"\n\nfig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Country Distribution of Data Scientist\")))\nfig.add_trace(go.Bar(x= df_red.Q3.value_counts().index,\n                     y=df_red.Q3.value_counts().values,\n                     marker_color=colors))\nfig.update_layout(xaxis_tickangle=45)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, apart from India (developing country), USA (developed country) and Other, the remaining number of respondents are at least on a same level and a rather fair mix of two types of countries, so the above conclusion holds.\n\n**Living in the UK, I am among the first six nations, and I hope that guarantees me a good chance of becoming a data scientist!**"},{"metadata":{},"cell_type":"markdown","source":"### Data Positions in terms of Education Level"},{"metadata":{"trusted":true},"cell_type":"code","source":"#correspondence analysis on education & positions\ndf_edu = df_cp.drop(df_cp[df_cp.Q4 == \"I prefer not to answer\"].index)\nedu_ds = pd.crosstab(df_edu.Q4,df_edu.Q5)\nca_edu = CA(n_components=2)\nca_edu.fit(edu_ds)\nca_edu.plot_coordinates(edu_ds, figsize=(10,10),show_row_labels=False,show_col_labels=False)\n\n#adjust text to overlapping between different labels\ncols=ca_edu.column_coordinates(edu_ds).to_dict()\nxcols=cols[0]\nycols=cols[1]\nrows=ca_edu.row_coordinates(edu_ds).to_dict()\nxrows=rows[0]\nyrows=rows[1]\n\nxglobal={ k : xcols.get(k,0)+xrows.get(k,0) for k in set(xcols) | set(xrows) }\nyglobal={ k : ycols.get(k,0)+yrows.get(k,0) for k in set(ycols) | set(yrows) }\n\nfig = ax.get_figure()\ntexts=[plt.text(xglobal[x],yglobal[x],x,fontsize=10) for x in xglobal.keys()]\nadjust_text(texts,arrowprops=dict(arrowstyle='-', color='red'));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variability is explained 97.53% which gives an good indication of education level.\n\nThree main findings:\n* There is **a distinct relationship between Doctoral degree with research scientist and also a good relationship with statistician**, where these two positisions are normally more educational demanding\n* **Most data science jobs are associated people with Master's degree**\n* **Business analyst and project manager are two unique positions that requires a professional degree**; it makes sense, you will normally required to have proven traceability of industrial and managerial experience to become a business manager."},{"metadata":{},"cell_type":"markdown","source":"Now let's plot the education distribution among data scientist"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"lightblue\"] * len(df_ds.Q4.value_counts().index)\ncolors[0] = \"lightsalmon\"\n\nfig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Education Distribution of Data Scientist\")))\nfig.add_trace(go.Bar(x= df_ds.Q4.value_counts().index,\n                     y=df_ds.Q4.value_counts().values,\n                     marker_color=colors))\nfig.update_layout(xaxis_tickangle=45)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most workforce in data science has Master's degree and luckily I do too! And what is better, my masters is in computational methods, so hopefully it gives me a better edge!**"},{"metadata":{},"cell_type":"markdown","source":"### Data Positions in terms of Language"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Q7 has multiple choices so extra steps are needed for aggregating answers\nquestions[\"Q7\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_lan = questions[\"Q5\"].join(questions[\"Q7\"])\ndf_lan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\"unroll\" the dataframe items of one column of positions plus one column of languages\ncols = list(questions[\"Q7\"].columns)\ndf_lan = (df_lan.melt(id_vars=\"Q5\", value_vars=cols))\ndf_lan.columns = [\"Position\", \"variable\", \"Language\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correspondence analysis on language & positions\nlan_ds = pd.crosstab(df_lan.Position, df_lan.Language)\nca_lan = CA(n_components=2)\nca_lan.fit(lan_ds)\nca_lan.plot_coordinates(lan_ds, figsize=(10,10),show_row_labels=False,show_col_labels=False).legend(loc=\"upper left\")\n\n#adjust text to overlapping between different labels\ncols=ca_lan.column_coordinates(lan_ds).to_dict()\nxcols=cols[0]\nycols=cols[1]\nrows=ca_lan.row_coordinates(lan_ds).to_dict()\nxrows=rows[0]\nyrows=rows[1]\n\nxglobal={ k : xcols.get(k,0)+xrows.get(k,0) for k in set(xcols) | set(xrows) }\nyglobal={ k : ycols.get(k,0)+yrows.get(k,0) for k in set(ycols) | set(yrows) }\n\nfig = ax.get_figure()\ntexts=[plt.text(xglobal[x],yglobal[x],x,fontsize=10) for x in xglobal.keys()]\nadjust_text(texts,arrowprops=dict(arrowstyle='-', color='red'));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variability is explained 77.59% which gives an okay indication of coding languages.\n\nWe can quite distinguish a universal language Python from all the other languages since it is so close to the centre point, telling us **the ratios of people who uses Python as the primary coding language are pretty much the same among all different positions**. Besides that, **a Software Engineer tends to use Javascript and Swift; a data engineer uses Bash and SQL more frequently; a Statistian concentrates more on R and a Research Scientist prefers MATLAB**."},{"metadata":{},"cell_type":"markdown","source":"Again, language preferences within data scientist community below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ds_lan = df_lan[df_lan.Position==\"Data Scientist\"]\ncolors = [\"lightblue\"] * len(df_ds_lan.Language.value_counts().index)\ncolors[0] = \"lightsalmon\"\n\nfig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Language Distribution of Data Scientist\")))\nfig.add_trace(go.Bar(x= df_ds_lan.Language.value_counts().index,\n                     y= df_ds_lan.Language.value_counts().values,\n                     marker_color=colors))\nfig.update_layout(xaxis_tickangle=45)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My primary language for data analysis is luckily Python, so at least I am half foot into the data science club (I hope)!"},{"metadata":{},"cell_type":"markdown","source":"Now I see there is a good fountain for me to become a Data Scientist based on the analysis so far, but we all know I have just scratched the surface by exploring only a few features.\n\nIn order to strategise my job hunting with more precision, let me complete the survey and build a classification model to see which exactly positions that grants me the highest chance of employment!"},{"metadata":{},"cell_type":"markdown","source":"## Build A Classification Model\n* As it is quite an imbalanced dataset in terms of positions, I will first trim it to get rid of the least represented positions and also the ones that I am not interested in\n* Prepare my own answers and transferred into array with the correct shape, ready for prediction.\n* Build the classifier with different models and evaluate their performances to pick up the optimal model\n* Predict the position I should be aiming at and find out how can I increase the odds of getting that job.\n\n### Trim the dataset\nOverview of the population of all the positions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Positions\")))\nfig.add_trace(go.Bar(x= df_cp.Q5.value_counts().index,\n                     y=df_cp.Q5.value_counts().values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As I am looking for a job that I am interested, so I shall only keep the below positions:\n* Data Scientist\n* Data Analyst\n* Machine Learning Engineer\n* Research Scientist\n* Software Engineer"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cls = df_cp[df_cp.Q5.isin([\"Data Scientist\",\"Software Engineer\",\"Data Analyst\",\"Research Scientist\",\"Machine Learning Engineer\"])]\ndf_cls = df_cls[df_cls.Q5.notna()]\ndf_cls.Q5.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like a good number of samples, so lets go ahead and work on this dataset.\n\nLooking at the survey, questions after Q39 is for non-professionals which is out of the interest of this analysis, so I only keep questions before Q39."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_prof = df_cls.iloc[:,:df_cls.columns.get_loc(\"Q39_OTHER\")+1]\ndf_prof.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have an overview of the population distribution of the remaining positions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Positions\")))\nfig.add_trace(go.Bar(x= df_prof.Q5.value_counts().index,\n                     y=df_prof.Q5.value_counts().values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build up my own answers\nI construct my answers as below and I have put comments against some of them which I have guessed or pictured in my future job"},{"metadata":{"trusted":true},"cell_type":"code","source":"#add my own choices to the survey\nquestions_multi = [\"Q7\",\"Q9\",\"Q10\",\"Q12\",\"Q14\",\"Q16\",\"Q17\",\"Q18\",\"Q19\",\"Q23\",\"Q26\",\"Q27\",\"Q28\",\"Q29\",\"Q31\",\"Q33\",\"Q34\",\"Q35\",\"Q36\",\"Q37\",\"Q39\"]\nquestions_AB = [\"Q26\",\"Q27\",\"Q28\",\"Q29\",\"Q31\",\"Q33\",\"Q34\",\"Q35\"]\nchoices = {\"Q1\":[\"25-29\"],\n           \"Q2\":[\"Man\"],\n           \"Q3\":[\"United Kingdom of Great Britain and Northern Ireland\"],\n           \"Q4\":[\"Master’s degree\"],\n           \"Q6\":[\"< 1 years\"],\n           \"Q7\":[\"Python\",\"SQL\"],\n           \"Q8\":[\"Python\"],\n           \"Q9\":[\"Jupyter (JupyterLab, Jupyter Notebooks, etc)\"],\n           \"Q10\":[\"Kaggle Notebooks\",\"Colab Notebooks\"],\n           \"Q11\":[\"A personal computer or laptop\"],\n           \"Q12\":[\"None\"],\n           \"Q13\":[\"Never\"],\n           \"Q14\":[\"Matplotlib\",\"Seaborn\",\"Plotly / Plotly Express\"],\n           \"Q15\":[\"Under 1 year\"],\n           \"Q16\":[\"Scikit-learn\",\"TensorFlow\"],\n           \"Q17\":[\"Linear or Logistic Regression\",\"Decision Trees or Random Forests\"],\n           \"Q18\":[\"None\"],\n           \"Q19\":[\"None\"],\n           \"Q20\":[\"0-49 employees\"],    #not sure\n           \"Q21\":[\"3-4\"],               #guess\n           \"Q22\":[\"I do not know\"],\n           \"Q23\":[\"Analyze and understand data to influence product or business decisions\"],   \n           \"Q24\":[\"60,000-69,999\"],     \n           \"Q25\":[\"$1000-$9,999\"],      #guess\n           \"Q26\":[\"None\"],              \n           \"Q27\":[\"No / None\"],\n           \"Q28\":[\"No / None\"],\n           \"Q29\":[\"PostgresSQL \"],\n           \"Q30\":[\"MySQL \"],\n           \"Q31\":[\"None\"],\n           \"Q32\":[\"Tableau\"],\n           \"Q33\":[\"No / None\"],\n           \"Q34\":[\"No / None\"],\n           \"Q35\":[\"TensorBoard\"],\n           \"Q36\":[\"Kaggle\",\"GitHub\"],\n           \"Q37\":[\"Coursera\",\"Udemy\"],\n           \"Q38\":[\"Local development environments (RStudio, JupyterLab, etc.)\"],\n           \"Q39\":[\"Kaggle (notebooks, forums, etc)\"]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to generate instances for certain questions\ndef answer_generator(question,answer):\n    \"\"\"\n    Generate an list of answers which matches with the survey answer format\n    question: number of the question in string\n    answer: a list of strings of the answers\n    \"\"\"\n    options = questions[question].mode().values\n    for i in range(options.shape[1]):\n        if not options[0,i].strip() in answer:\n            options[0,i] = np.nan\n    return list(options[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#example\nanswer_generator(\"Q7\",[\"Python\",\"Java\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generate the profile for all the questions\ndef profile_generator(questions_multi,questions_AB,choices):\n    \"\"\"\n    Generates the overall profile based on the answers given\n    questions_multi: question numbers which are multiple choices\n    questions_AB: questions numbers which are for both professionals and non-professionals\n    choicecs: the list of the answers\n    \"\"\"\n    profile = []\n    for q in choices.keys():\n        if q in questions_multi:\n            if q in questions_AB:\n                answer = answer_generator(q,choices[q])[:int(len(answer_generator(q,choices[q]))/2)]\n            else:\n                answer = answer_generator(q,choices[q])\n        else:\n            answer = choices[q]\n            \n        profile += answer\n    return profile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#showcase my answer profile which is ready to be inserted into the main dataframe for\n#predictions, NOT for building and training the model\nmy_profile = profile_generator(questions_multi=questions_multi,questions_AB=questions_AB,choices=choices)\nmy_profile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#append my answer profile to last row 20036\ndf_myself = df_prof.drop(\"Q5\", axis=1)\ndf_myself.loc[df_myself.index[-1]+1] = my_profile\ndf_myself.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoding the dataset to get ready for model building"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummies = pd.get_dummies(df_myself)\ndf_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if (df_myself.index == df_dummies.index).sum() == len(df_myself):\n    print(f\"Both index matches {len(df_myself)}, proceed\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dataset for training which excludes my answer\ndf_model = df_prof.Q5.to_frame().join(df_dummies)\narray_myself = df_dummies.loc[df_myself.index[-1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build four baseline models\n* Logistic Regression\n* KNN\n* SVC\n* RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n# Models from Scikit-Learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model Evaluations\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import plot_roc_curve, roc_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_model.drop([\"Q5\"], axis=1)\ny = df_model.Q5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.2,\n                                                    random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Put models in a dictionary\nmodels = {\"Logistic Regression\": LogisticRegression(max_iter=1000),\n          \"KNN\": KNeighborsClassifier(),\n          \"SVC\": SVC(kernel='linear', probability=True,random_state=7),\n          \"Random Forest\": RandomForestClassifier()}\n\n# Create a function to fit and score models\ndef fit_and_score(models, X_train, X_test, y_train, y_test):\n    \"\"\"\n    Fits and evaluates given machine learning models.\n    models : a dict of differetn Scikit-Learn machine learning models\n    X_train : training data (no labels)\n    X_test : testing data (no labels)\n    y_train : training labels\n    y_test : test labels\n    \"\"\"\n    # Set random seed\n    np.random.seed(7)\n    # Make a dictionary to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit the model to the data\n        model.fit(X_train, y_train)\n        # Evaluate the model and append its score to model_scores\n        model_scores[name] = np.mean(cross_val_score(model,X_test, y_test,scoring=\"accuracy\",cv=5))\n    return model_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_scores = fit_and_score(models=models,\n                             X_train=X_train,\n                             X_test=X_test,\n                             y_train=y_train,\n                             y_test=y_test)\n\nmodel_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\nfig = go.Figure([go.Bar(x=model_compare.columns, y=model_compare.iloc[0])])\nfig.update_layout(title=\"Comparison of Model Accuracy\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far, in terms of accuracy, RandomForestClassifier has out ran other models, but Logistici Regression does not come too far behind. Let's tune the two models to reach its full performance.\n\nMoreover,it is known that this dataset is a little imbalanced, number of Data Scientist is more than twice of those of Research Scientist and Machine Learning Engineer. So we'd be careful in choosing the valuation metrics.\n\nWe started the evaluation on accuracy, and then can carry on adopting other metrics which are more suitable for imbalanced dataset after the hyperparametertuning\n\n* Hyperparameter tuning\n* Confusion matrix\n* Precision / Recall / F1 score\n* ROC / AUC"},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter tuning\nBefore moving on to the two best performers, I want to know how much better a KNN model can achieve since it has the simplest algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's tune KNN\n\ntrain_scores = []\ntest_scores = []\n\n# Create a list of differnt values for n_neighbors\nneighbors = range(1, 40)\n\n# Setup KNN instance\nknn = KNeighborsClassifier()\n\n# Loop through different n_neighbors\nfor i in neighbors:\n    knn.set_params(n_neighbors=i)\n    \n    # Fit the algorithm\n    knn.fit(X_train, y_train)\n    \n    # Update the training scores list\n    train_scores.append(knn.score(X_train, y_train))\n    \n    # Update the test scores list\n    test_scores.append(knn.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(neighbors, train_scores, label=\"Train score\")\nplt.plot(neighbors, test_scores, label=\"Test score\")\nplt.xticks(np.arange(1, 40, 1))\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Model score\")\nplt.legend()\n\nprint(f\"Maximum KNN score on the test data: {max(test_scores)*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With a peak accuracy of around 55%, it is safe to treat it as a bottom limit of the prediction accuracy."},{"metadata":{},"cell_type":"markdown","source":"#### Hyperparameter tuning with RandomizedSearchCV\n\nWe're going to tune:\n* LogisticRegression()\n* RandomForestClassifier()"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a hyperparameter grid for LogisticRegression\nlog_reg_grid = {\"C\": np.logspace(-2, 1, 20),\n                \"multi_class\":[\"ovr\",\"multinomial\"],\n                \"solver\":[\"lbfgs\",\"saga\"]}\n\n# Create a hyperparameter grid for RandomForestClassifier\nrf_grid = {\"n_estimators\": np.arange(10, 1000, 50),\n           \"min_samples_split\": np.arange(2, 20, 2),\n           \"min_samples_leaf\": np.arange(1, 20, 2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune LogisticRegression\n\n# Setup random hyperparameter search for LogisticRegression\nrs_log_reg = RandomizedSearchCV(models[\"Logistic Regression\"],\n                                param_distributions=log_reg_grid,\n                                cv=5,\n                                n_iter=10,\n                                verbose=True,\n                                random_state=7)\n\n# Fit random hyperparameter search model for LogisticRegression\nrs_log_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs_log_reg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs_log_reg.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we've tuned LogisticRegression(), let's do the same for RandomForestClassifier()..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup random hyperparameter search for RandomForestClassifier\nrs_rf = RandomizedSearchCV(RandomForestClassifier(), \n                           param_distributions=rf_grid,\n                           cv=5,\n                           n_iter=10,\n                           verbose=True,\n                           random_state=7)\n\n# Fit random hyperparameter search model for RandomForestClassifier()\nrs_rf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the best hyperparameters\nrs_rf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the randomized search RandomForestClassifier model\nrs_rf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After randomised search, the Logistic Regression model outputs a slightly better accuracy comparing to RandomForestClassifier, lets continue."},{"metadata":{},"cell_type":"markdown","source":"### Evaluting our tuned machine learning classifier, using below metrics, in additional to accuracy\n\n* Confusion matrix\n* Precision / Recall / F1 score\n* ROC / AUC"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a function to plot the confusion matrix in a heatmap\nsns.set(font_scale=1.0)\n\ndef plot_conf_mat(y_test, y_preds, labels):\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax = sns.heatmap(confusion_matrix(y_test, y_preds, labels=labels),\n                     annot=True,\n                     cbar=False,\n                     fmt=\"g\")\n    plt.xlabel(\"Predicted label\")\n    plt.ylabel(\"True label\")\n    ax.set_title(\"Confusion Matrix\")\n    ax.xaxis.set_ticklabels(labels)\n    ax.yaxis.set_ticklabels(labels)\n    plt.xticks(rotation=-45); plt.yticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a function to evaluate both Logistic Regression and RandomForestRegressor\ndef evaluate_model(model, X_test, y_test):\n    '''\n    A function to output the confusion matrix and precision/recall/F1 score for\n    a given classifier\n    '''\n    y_preds = model.predict(X_test)\n    labels = y_test.value_counts().index\n    \n    #print precision/recall/F1 score\n    print(classification_report(y_test, y_preds))\n    \n    #plot confusion matrix\n    plot_conf_mat(y_test, y_preds, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluate the tuned Logistic Regressor\nevaluate_model(rs_log_reg, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluate the tuned RandomForestRegressor\nevaluate_model(rs_rf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot ROC curve and calculate and calculate AUC\ndef plot_multiclass_roc(model, X_test, y_test, n_classes, figsize=(17, 6)):\n    y_score = model.predict_proba(X_test)\n\n    #decision_function\n    # structures\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    # calculate dummies once\n    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n    labels = pd.get_dummies(y_test, drop_first=False).columns\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # roc for each class\n    fig, ax = plt.subplots(figsize=figsize)\n    ax.plot([0, 1], [0, 1], \"k--\")\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel(\"False Positive Rate\")\n    ax.set_ylabel(\"True Positive Rate\")\n    ax.set_title(\"Receiver operating characteristic\")\n    for i in range(n_classes):\n        ax.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:0.2f}) for label {labels[i]}')\n    ax.legend(loc=\"best\")\n    ax.grid(alpha=.4)\n    sns.despine()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC/AUC for Logistic Regressor\nplot_multiclass_roc(rs_log_reg, X_test, y_test, n_classes=5, figsize=(16, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC/AUC for RandomForestClassifier\nplot_multiclass_roc(rs_rf, X_test, y_test, n_classes=5, figsize=(16, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a **slightly higher F1 score and AUC for Logistic Regression, comparing to those from the RandomForestRegressor**, although the difference is minimal, the classic Logistic Regression wins and I shall use it to predict my future!"},{"metadata":{},"cell_type":"markdown","source":"### Best strategies to get hired via analysing feature importance\nBefore moving onto predicting my future job, let's have a look what are the important contributions for each of the positions. These information will guide my decision making and hunting strategies."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define and construct the logistic regressor with the best parameters\nlr = LogisticRegression(C=0.01, multi_class=\"multinomial\")\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the first five contributors for each of the positions\nlabels = pd.get_dummies(y_test, drop_first=False).columns\n\nplt.figure(figsize=(10,30))\nfor n in range(len(labels)):\n    ax = plt.subplot(len(labels),1,n+1)\n    feature_dict = dict(zip(X_train.columns, list(lr.coef_[n])))\n    feature_dict = dict(sorted(feature_dict.items(), key=lambda item: item[1], reverse=True))\n\n    # Visualize feature importance\n    feature_df = pd.DataFrame(feature_dict, index=[\"importance\"])\n    feature_df=feature_df.T.head(5).iloc[::-1]\n\n    height = feature_df[\"importance\"]\n    bars = feature_df.index\n    y_pos = np.arange(len(bars))\n\n    # Create horizontal bars\n    plt.barh(y_pos, height)\n \n    # Create names on the y-axis\n    plt.yticks(y_pos, bars)\n    \n    plt.title(f\"Model Coefficients in Logistic Regressor for {labels[n]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Analyze and understand the data to influence product or business decisions** is the biggest contributor in both positions as Data Analyst and Data Scientist, and can be safely concluded one of the most important competencies to have for those two roles. \n* However, as a Data Analyst, you will have to have **more experience in BI tool** while you are not required to be a coding master in terms the years and experience.\n* As a Data Scientist, **R is a good option to get the hands dirty** and you will be required to **gain some traction with Machine learing experience and knowledges**.\n* **Build and improve the operations and performance of the ML models** are the main job of Machining Learning Engineers.\n* Not surprisingly, **getting a phd is kind of your best bet if you want to join as a Research Scientist**, which in turn, you will naturally be required to have the ability to publications and master MATLAB as the numerical computation tool.\n* As for the Software Engineers, **Javascript and Java are the critical skills in demand** and seems like most people lands the job with a Bachelor's degree.\n\nLet's see how much odds it increases to get hired assuming I am good at analyzing the data and driving business decisions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#transfer feature importance coefficient to the increase of odds if certain feature switches from 0 to 1\nodd_analyst = np.exp(np.max(lr.coef_[0]))-1\nodd_scientist = np.exp(np.max(lr.coef_[1]))-1\n\nprint(f\"Being good at 'Analyze and understand the data to influence product or business decisions' increase odds of becoming\\nData Analyst by {odd_analyst*100:.2f}%\\nData Scientist by {odd_scientist*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's take a look at feature importance from the RandomForestClassifier. I will only have a quick look by investigating the mean reduction in tree impurity as the main method for now, to gain a global picture to see how losing each feature impacts the final decision."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=760, min_samples_split=18, min_samples_leaf=1)\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature importance dataframe\nimp_df = pd.DataFrame({'feature': X_train.columns.values,\n                       'importance': rf.feature_importances_})\n \n# Reorder by importance\nordered_df = imp_df.sort_values(by='importance').tail(20)\nimp_range=range(1,len(imp_df.index)+1)\n \n## Barplot with confidence intervals\nheight = ordered_df['importance']\nbars = ordered_df['feature']\ny_pos = np.arange(len(bars))\n\nplt.figure(figsize=(10,10))\n# Create horizontal bars\nplt.barh(y_pos, height)\n \n# Create names on the y-axis\nplt.yticks(y_pos, bars)\n\nplt.title(\"Mean reduction in tree impurity in random forest\")\n\n#plt.tight_layout()\n# Show graphic\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first a few features also appears in the feature importance analysis for Logistic Regressor. What we can read from this chart, together with the previous section, is that a **Doctoral degree, Ability to analyse data and influence decisions and Javascript** have a strong determination in terms of categorising samples into **Research Scientist, Data Analyst / Data Scientist / Software Engineer**, respectively."},{"metadata":{},"cell_type":"markdown","source":"#### Save the classifier\n**This is originally done on my local drive, comment that whole section on kaggle**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# pickle the model\n#import pickle\n#Position_classfier = {'model': lr}\n#pickle.dump(Position_classfier, open('classifier' + \".p\", \"wb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test the pickled model for prediction\n\n#file_name = \"classifier.p\"\n#with open(file_name, 'rb') as pickled:\n#    Position_classfier = pickle.load(pickled)\n#    classifier = Position_classfier['model']\n\n#classifier.predict(X_test.iloc[0,:].values.reshape(1,-1)), y_test.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finally, let's predict the position I can get hired"},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities = lr.predict_proba(array_myself.values.reshape(1,-1))\npositions_proba = pd.DataFrame(probabilities,columns=labels,index=[\"Probability\"])\npositions_proba","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure([go.Bar(x=positions_proba.columns, y=positions_proba.iloc[0])])\nfig.update_layout(title=\"Probabilities of Getting hired at Different Positions\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, not so surprisingly, my future is being directed to the **Data Analyst and with a good 42.6% chance**! However, I might still going to pursuit for a **Data Scientist** role since that has **a good chance of nearly 40% as well**. But the best thing is that, I know what I need to concentrate on improving and demonstrating in my project / interview / future works, that is the skill of **analyse and understand data to influence the business decisions**, regardless of being and analyst or a scientist!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}