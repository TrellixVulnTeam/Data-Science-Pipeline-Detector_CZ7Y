{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center;\">Employed Data Professional's EDA - Differences in Survey Responses per Job Title and Gender </h1>"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"%%html\n<div>\n<table style=\"align:center;font-family: sans-serif; border-collapse: collapse;border: 1px solid #ddd;width:40%\">\n  <tr style=\"background-color: #f2f2f2;\">\n    <th style=\"padding-top: 20px;\n  padding-bottom: 15px;padding-left:20px;font-size:25px;\n  text-align: center;background-color: #4CAF50;\n  color: white;\">Table of Contents</th></tr>\n    <tr><td style=\"text-align:left;font-size:16px;padding-top: 10px;padding-bottom: 5px;\"><a href=\"#1\">1. Introduction</a></td></tr>\n    <tr><td style=\"text-align:left;font-size:16px;padding-top: 10px;padding-bottom: 5px;\"><a href=\"#2\">2. Reshaping Data</a></td></tr>\n    <tr><td style=\"text-align:left;font-size:16px;padding-top: 10px;padding-bottom: 5px;\"><a href=\"#3\">3. Data Preprocessing</a></td></tr>\n    <tr><td style=\"text-align:left;font-size:16px;padding-top: 10px;padding-bottom: 5px;\"><a href=\"#4\">4. General EDA</a></td></tr>\n    <tr><td style=\"text-align:left;font-size:16px;padding-top: 10px;padding-bottom: 5px;\"><a href=\"#5\">5. Job Title Pivot Table (EDA)</a></td></tr>\n        <tr><td style=\"text-align:left;font-size:16px;padding-top: 10px;padding-bottom: 5px;\"><a href=\"#6\">6. Common Tools Per Job Title (EDA)</a></td></tr>\n<tr><td style=\"text-align:left;font-size:16px;padding-top: 10px;padding-bottom: 5px;\"><a href=\"#7\">7. Short Summary</a></td></tr>\n </table>\n</div>","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"1\"></div>"},{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction\n\nWe are going to investigate the 2020 Kaggle Survey data about employment in data-related roles. You can find the survey <a href=\"https://www.kaggle.com/c/kaggle-survey-2020\">here</a>.\n\n\n## 1.1 Goal\n\nThe focus of this notebook will be on **employed data professionals** and the following will be the goals as it relates to such survey respondents: \n- Show current market expectations and job requirements in terms of skills, salary, experience, and tasks.\n- Explore gender differences in data-related roles.\n- Help students make data-driven decisions about their career path.\n\n\n## 1.2 Tasks \n\n**General EDA:**  Relative frequency bar graphs of hard skills, salary, and experience of employed data professionals.\n\n**Job Title Pivot Table W/ Select Variables**: Concentration of answers for variables of interest (salary, age, coding experience, etc.) per job title. Another additional chart showing relative differences in survey answers for males relative to their female counterparts.\n\n**Tool Chart** Top 5 commonly used technical tools per job title\n\n## 1.3 Description of Data\nThe survey data (```kaggle_survey_2020_responses.csv```) consists of 39+ questions and 20,036 responses. Per the site: \n\n> \"Responses to multiple choice questions (only a **single choice** can be selected) were recorded in **individual columns**. Responses to multiple selection questions (**multiple choices** can be selected) were **split into multiple columns** (with one column per answer choice).\"\n"},{"metadata":{},"cell_type":"markdown","source":"## 1.4 Packages Used"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport gc\nimport re\nimport math\nfrom math import log10\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\nrcParams.update({'figure.autolayout': True})\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n!pip install pycountry_convert\nfrom pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.5 Functions Used"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"# functions for visualization purposes\ndef shorten(num, precision=2, suffixes=['', 'K', 'M', 'G', 'T', 'P']):\n    try: float(num)\n    except: return \"Not A Number!\"\n    if num < 1:\n        return num  # avoid dividing by 0 or negatives\n    m = int(log10(num) // 3)\n    return f'{num/1000.0**m:.{precision}f}{suffixes[m]}'\n       \ndef modifyChartBasic(ax,labelSize,xLabel='',yLabel='',grid=False):\n    \"\"\"\n    Function that takes in graph variables for the purpose of customizing basic\n    default settings (ie. setting label size)\n    \"\"\"\n    if grid:\n        ax.grid(axis=grid, alpha=.3)\n    # spines\n    sns.despine()\n    ax.spines['bottom'].set_color('gray')\n    ax.spines['left'].set_color('lightgrey')\n\n    # labels\n    ax.set_ylabel(yLabel, labelpad=5, fontsize=16)\n    ax.set_xlabel(xLabel, labelpad=5, fontsize=16)\n\n    # tick settings\n    ax.tick_params(labelsize=labelSize)\n    ax.tick_params(axis='both', left=False, bottom=False)\n    \ndef modifyChartExtra(ax,maxs=False,topChild=None):\n    \"\"\"\n    Main Function used to create extra modifications to chart.\n    \"\"\"\n    if maxs and topChild is None:\n        topChild = max([(bar,bar.get_width()) for bar  in ax.patches],key=lambda x:x[1])\n    modifyMaxYTickH(ax,topChild[1])\n    # changing size and color of tick labels (ticks are set to 0 to not display)\n    ax.tick_params(size=0)\n\n    \ndef modifyMaxYTickH(ax, maxValue):\n    \"\"\"\n    Function that modifies x-scale to have the top x-tick label represent the maximum value\n    whilst 'preventing' overlap between the last and second to last tick labels\n    \"\"\"\n     # keep all except last  tick - ensure that the ticks don't overlap\n    midCenterQuarter = (ax.get_xticks()[1] - ax.get_xticks()[0]) / 4\n\n    ax.set_xlim(0, maxValue)  # set the xticks\n    # add the last tick value\n    x_ticks = np.append(\n            [i for i in ax.get_xticks() if \n             i < (maxValue - midCenterQuarter)],# skip old max val if near new max val\n              [maxValue]) # new max value\n    # set the modified x ticks\n    ax.set_xticks(x_ticks)\n\ndef count_valuesUpdateDictionary(x, counts):\n    #if numerical, check if null\n    if x=='nan' or x==None or (type(x) in [float, int] and math.isnan(x)):\n        return counts\n\n    #if not null\n    counts.setdefault(x, 0)\n    counts[x] = counts.get(x,0)+1\n    return counts\n\ndef count_values(df, columnName, noFalse=None):\n    \"\"\" Custom count values function that takes into account a list's inner values.\n\n    Args:\n        df (pd.Dataframe): dataframe of interest\n        columnName (str): column of interest\n        noFalse(varies, optional): the value to ignore\n    Return:\n        dict: a dictionary with all the values and their respective counts\n    \"\"\"\n\n    counts={}\n    for val in df[columnName].values:\n        if isinstance(val,(np.ndarray, list)):#if a list\n            for i in val:\n                if isinstance(i,(np.ndarray, list)): #if a sublist\n                    for sub in i:\n                        counts= count_valuesUpdateDictionary(sub, counts)\n                else:  #if not a sublist\n                    counts = count_valuesUpdateDictionary(i, counts)\n        else:\n            counts =count_valuesUpdateDictionary(val, counts)\n\n    if noFalse != None:\n        #filter out the value to ignore, typically a False value\n        return  {i[0]:i[1] for i in counts.items() if i[0] != noFalse}\n    return counts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"2\"></div>"},{"metadata":{},"cell_type":"markdown","source":"# 2. Reshaping Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv\",header=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f\"There are a total of {df.shape[1]} columns and {df.shape[0]:,} rows\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The goal here is to reduce the 355+ columns in the data frame by merging all columns with Q-A combinations (ie. *What programming lang do you use - Python*), into single columns for each question. The end data frame will consist of columns with unique questions only (~48 columns); this will make it much easier to work with during the analysis as well as the next preprocessing stage.\n"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#search for columns containing question-answer combination and save into a new dataframe\nQSubAnswerColumns = df[df.columns[df.columns.str.contains(\" - Selected Choice - \")]]\n\n#for Q-A columns, keep only question (ie. remove \"Selected Choice - Python\")\npattern = \" \\(Select all that apply.+| Selected Choice - .+\"\nkeepOnlyQuestion = pd.Series(df.columns[df.columns.str.contains(\" - Selected Choice - \")]).apply(\n    lambda x: re.sub(pattern,\"\", x).strip()) #keep only question\n\nQSubAnswerColumns.columns = keepOnlyQuestion  #rename columns\n\n# replace nulls with empty string as it'll be used for merging in the next step\nnullValues = [\"No / None\", \"None\", None]\nQSubAnswerColumns = QSubAnswerColumns.fillna(\"NULL\").applymap(lambda x: '' if x==\"NULL\" or x in nullValues else (str(x)))\nQSubAnswerColumns.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def add_mainColumn(df,evaluate):\n     # merge all column values into a single column with a lists of non-null (here an empty string) values \n    new_column = df.apply(lambda x: [i.strip() for i in x if i !=''] ,  1) \n    \n    # length of values in each row must match \n    assert (evaluate == new_column.apply(lambda x: len(x))).all() \n    \n    new_column = new_column.apply(lambda x: \"None\" if x==[]   #if an empty list then turn into \"None\" value\n                            else (x if type(x)==list and len(x)==1 else x)) #if one value in list -> unpack \n    return new_column\n\nfor mainQuestion in np.unique(keepOnlyQuestion):\n    evaluate = QSubAnswerColumns[mainQuestion].applymap(lambda x: 1 if x!='' else 0).sum(1) # sanity check\n    new_column = add_mainColumn(QSubAnswerColumns[mainQuestion], evaluate)\n    QSubAnswerColumns[mainQuestion+\"NEW\"] =new_column #add new to distinguish new columns\n    \n# keep new columns only \nQSubAnswerColumns = QSubAnswerColumns[QSubAnswerColumns.columns[QSubAnswerColumns.columns.str.contains(\"NEW\")]]\nQSubAnswerColumns.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"QSubAnswerColumns.columns = QSubAnswerColumns.columns.str.replace(\"NEW\",\"\")\n\n# merge SINGLE question columns with the NEW Q-A combination columns \ndf = pd.merge(df[df.columns[~df.columns.str.contains(\" - Selected Choice - \")]], #inverse operation\n              QSubAnswerColumns,left_index=True, right_index=True)\n\n# some further cleaning for the column names\ndf.columns = df.columns.str.replace(\": - Selected Choice| - Selected Choice| -\",\"\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f\"There are a total of {df.shape[1]} columns and {df.shape[0]:,} rows\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We went from 355 columns to 48 columns--nice! \n\nThe rows match the original data frame's row count all of which have passed a **sanity check**. Let's move to the next stage"},{"metadata":{},"cell_type":"markdown","source":"<div id=\"3\"></div>"},{"metadata":{},"cell_type":"markdown","source":"# 3. Preprocessing\n\nIn this stage, the goal will be to (1) keep relevant respondents per the definitions set in the intro. and (2) reduce the unique value count for certain columns.\n"},{"metadata":{},"cell_type":"markdown","source":"### 1. Employed respondents\n\nHere we'll define employed as respondents who did not select any of the following: ```Student, Other, Currently not employed, nulls.``` \n\nFurthermore, we'll ignore job titles that are not strictly \"data-related,\" which are the following: ```Product/Project Manager,Software Engineer.```\n\nFinally we'll group job titles with similar functionalities."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"jobTitleCol = 'Select the title most similar to your current role (or most recent title if retired)'\ndataRoles = {\"Statistician\":\"Academic Data Scientist\",\"Research Scientist\":\"Academic Data Scientist\",\n                     \"Data Analyst\":\"Analyst\",\"Business Analyst\":\"Analyst\",\"DBA/Database Engineer\":\"Data Engineer\"}\nnotEmployed = ['Student', 'Other','Currently not employed',\"Product/Project Manager\",\"Software Engineer\",np.nan]\n\ndf = df[~df[jobTitleCol ].isin(notEmployed)].reset_index(drop=True)\ndf[jobTitleCol] = df[jobTitleCol].apply(lambda x: dataRoles[x] if x in dataRoles else x)\n\ndf[jobTitleCol].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that 1/3 of the employed data professionals are data scientists with analysts (~28%) coming making up the other large share of respondents.\n\n### Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"What is your gender?\"].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unfortunately, given the low % of nonbinary values, only ```male``` and ```female``` will be investigated in this notebook. The other values: ```Prefer not to say```, ```Prefer to self-describe``` are ambiguous and will also not be considered given that the goal is to study gender differences."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['What is your gender?'].isin([\"Man\",\"Woman\"])].reset_index(drop=True)\ndf['What is your gender?'].value_counts(normalize=True)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It should be mentioned that the % of employed data professionals is disappointing. Clearly, there is a need for more representation in gender.\n\n### Countries into Continents\nNext we'll create the continent columns using the country column. We'll rename certain countries to be able to apply the function to all of the countries. \n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"countryCol = 'In which country do you currently reside?'\ncontinents = {\n    'NA': 'North America', 'SA': 'South America', 'AS': 'Asia',\n    'OC': 'Australia', 'AF': 'Africa', \"EU\":\"Europe\"\n}\ncountryMap = {'Iran, Islamic Republic of...':\"Iran\",'Republic of Korea':\"South Korea\",\n             'United States of America':\"USA\",'United Kingdom of Great Britain and Northern Ireland':\"United Kingdom\"}\ndf['In which country do you currently reside?']=df['In which country do you currently reside?'].apply(\n    lambda x: countryMap[x] if x in countryMap else x)\n\ncountries = df[countryCol].unique()\ncontinentMap = dict([(country,continents[country_alpha2_to_continent_code(country_name_to_country_alpha2(country))]\n                     ) for country in countries if country !=\"Other\"])\n\ndf[\"continent\"]  = df[countryCol].apply(lambda x: \n                                        continentMap[x] if x in continentMap else x)\ndf[\"continent\"].value_counts(normalize=True)*100\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that the continent of Asia is where the majority (~39%) of respondents reside. One factor for this may be due to the large population size of certain countries (India and China) in that continent. Surely these large % of respondents should be of interest to the Kaggle staff.\n\n### Reducing Media Source Values\n\nRemoving examples withing parantheses for the media source values. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mediaCol = 'Who/what are your favorite media sources that report on data science topics?'\n\ndf[mediaCol] = df[mediaCol].apply(lambda x:\n                            [re.sub(\" \\(.*\",\"\",i) for i in x] if type(x)==list else x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grouping salary ranges "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"to_modify = {'$0-999':\"$0-999\",'> $500,000':'> $249,999'}\ndef salaryRanges(x):\n    if x in to_modify.keys(): \n        return to_modify[x]\n    try:\n        #keeping last value in range\n        if len(x.split('-'))> 1:\n            x =int(x.replace(',','').replace(' ','').split('-')[1]) \n    except: 'nothing here'\n        \n    x =float(x)\n    if x > 999.99 and  x < 9999.99:\n        return '$1,000 - $9,999'\n    elif x > 9999.99 and  x < 19999.99:\n        return '$10,000 - $19,999'\n    elif x > 19999.99 and  x < 39999.99:\n        return '$20,000 - $39,999'\n    elif x > 39999.99 and  x < 69999.99:\n        return '$40,000 - $69,999'\n    elif x > 69999.99 and x < 99999.99:\n        return '$70,000 - $99,999'\n    elif x > 99999.99 and x < 149999.99:\n        return '$100,000 - $150,000'\n    elif x > 149999.99 and x < 249999.99:\n        return '$150,000 - $249,999'\n    elif x > 249999.99: \n        return '> $249,999'\n    \nsalaryCol = 'What is your current yearly compensation (approximate $USD)?'\ndf[salaryCol] = df[salaryCol].apply(lambda x: salaryRanges(x) if type(x) != float else x)\ndf[salaryCol].value_counts(normalize=True)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reducing unique values for other columns"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Age range\nageRange = {\"50-54\":\"50+\", \"55-59\":\"50+\", \"60-69\":\"50+\", \"70+\":\"50+\", \"40-44\":\"40-49\", \"45-49\":\"40-49\"} \ndf['What is your age (# years)?'] = df['What is your age (# years)?'].apply(\n                                    lambda x: ageRange[x] if x in ageRange else x)\n\n# Education\neduCol = 'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?'\neduMap = {\"No formal education past high school\":\"Some college or less\",\"I prefer not to answer\":\"\",\n          \"Some college/university study without earning a bachelor’s degree\":\"Some college or less\"}\ndf[eduCol] = df[eduCol].apply(lambda x: eduMap[x] if x in eduMap else x)\n\n# Activity at work\nactivityCol = 'Select any activities that make up an important part of your role at work:'\nother = 'None of these activities are an important part of my role at work:'\ndf[activityCol] = df[activityCol].apply(lambda x: [\"Other\" if i== other\n                                            else i for i in x ] if type(x)==list else x)\n\n# Company Size\ncompanySizeCol = 'What is the size of the company where you are employed?'\ndf[companySizeCol] = df[companySizeCol].str.replace(\" employees\",'')\n\n# IDEs\nide = \"Which of the following integrated development environments (IDE's) do you use on a regular basis?\"\nvs = {'Visual Studio Code (VSCode)':\"Visual Studio Code\", \"Visual Studio\":\"Visual Studio Code\"}\ndf[ide] = df[ide].apply(lambda x: [re.sub(\" \\(.*\",\"\",i) if not i in vs else vs[i] for i in x] if type(x)==list\n                             else (re.sub(\" \\(.*\",\"\",x) if x!='' else x))\nemployed =  df.copy()\nemployed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"del [QSubAnswerColumns, df]\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Further reducing dataframe size\n\n- Turn 'None' and numpy nan values into empty strings\n- Unpacking lists if only one element in it"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def reduceList(x):\n    if len(x)==1: \n        return x[0]\n    return [i for i in x]\n\n\nemployed = employed.applymap(lambda x: reduceList(x) if type(x)==list  \n                     else ('' if x=='None' or x is np.nan else x))\nemployed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div id=\"4\"></div>"},{"metadata":{},"cell_type":"markdown","source":"# 4. General Exploratory Data Analysis (EDA)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def findCol(df,words):\n    \"\"\"\n    Searches for columns within dataframe. \n    \"\"\"\n    keywords = ''\n    for word in words:\n        keywords+=\"(?=.*{:})\".format(word)\n    cols = df.columns[df.columns.str.contains(keywords)]\n    return cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_color =\"#20BEFF\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot(df, col, initial_color =\"#20BEFF\",figsize=(15, 5)):\n    fig, ax = plt.subplots(figsize=figsize,facecolor=\"#FAFAFA\", constrained_layout=True)\n    #data\n    counts = count_values(df, col, noFalse='')\n    dataRel= (pd.DataFrame(counts.values(),counts.keys())\n               .sort_values(0)\n              .applymap(lambda x: \n                        x/sum([i for i in counts.values()])*100))\n    dataAbs = pd.DataFrame(counts.values(),counts.keys()).sort_values(0)\n    #max of 20\n    if len(dataAbs)>20:\n        dataAbs = dataAbs[-20:]\n        dataRel = dataRel[-20:]\n    #bar plot \n    ax.barh(dataAbs.index,dataAbs[0].values, color=initial_color,zorder=3) \n    ax.set_yticklabels([i[:30] for i in dataAbs.index],fontfamily='serif')\n    ax.grid(axis=\"x\",alpha=.3,zorder=0) \n    params = {\"int\":False,\"percent\":True,\"decimal\":1}\n    \n    for bar,s in zip(ax.patches,dataRel[0].values):\n        x = bar.get_height()/2+ bar.get_width()\n        y = bar.get_y()+ bar.get_height()/2 \n        pos = (\"black\",\"left\") if s<5 else (\"black\",\"right\")\n        ax.text(x,y,f\"{s:.1f}%\",fontsize=13,color=pos[0],ha=pos[1],fontfamily=\"serif\",va=\"center\")\n    \n    modifyChartExtra(ax,maxs=True) \n    modifyChartBasic(ax,13) \n    ax.set_facecolor(\"#FAFAFA\")  \n    ax.set_xticklabels([shorten(i,precision=1) if len(str(int(i)))>3 else int(i) for i in ax.get_xticks()],\n                       fontsize=13) \n    ax.get_yticklabels()[-1].set_fontweight(\"bold\")\n    ax.spines[\"bottom\"].set_color('#FAFAFA')\n    ax.spines['right'].set_visible(True); ax.spines['right'].set_alpha(.1)\n    \n    plt.title(col,fontfamily='serif',fontsize=16)\n    return ax","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Share of Employed Data Professionals by Job Titles"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"title = findCol(employed,[\"title\"])\nax = plot(employed,title,figsize=(11,7))\nax.get_xticklabels()[-1].set_rotation(45)\nplt.suptitle(\"Share of Job Roles\", x = .28,\n             y=.95,fontsize=22,fontweight=\"semibold\", fontfamily='serif')\nplt.title(\"~61% of Data Professionals are Data Scientists or Analysts\",\n                  x = .41, fontsize=16, fontfamily='serif')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:80%\">\nKey points:\n    <br>\n<ul>\n    <li>Not surprisingly, data science and analyst job titles are common amongst employed data professionals. </li>\n    <li> Almost 1/5 of the surveyed data professionals work in academic-related position as a data scientist. </li>\n</ul>   \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Location of Survey Respondents"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot(employed,\"continent\",figsize=(11,7))\nplt.suptitle(\"60% of Respondents Are Located In Asia or Europe\", x = .5,\n             y=.90,fontsize=20,fontweight=\"semibold\", fontfamily='serif')\nplt.title('');plt.show()\n\ncountries = findCol(employed,[\"countr\"])\nax = plot(employed,countries,figsize=(11,7))\nax.get_xticklabels()[-1].set_rotation(45)\nplt.suptitle(\"Top 20 Countries of Survey Respondents\", x = .44,\n             y=.95,fontsize=22,fontweight=\"semibold\", fontfamily='serif')\nplt.title(\"1/3 of Respondents are Located in India or the U.S.\",\n                  x = .32, fontsize=15, fontfamily='serif'    )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:80%\">\nKey points:\n    <br>\n<ul>\n    <li>The large continents of South America and Africa have the least amount of survey respondents in comparison to the other continents.  </li>\n    <li> India is well represented in this survey with ~1/5 of total respondents being located there. </li>\n</ul>   \n</div>"},{"metadata":{},"cell_type":"markdown","source":"## Age"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"age=  findCol(employed,[\"age \\(# years\\)\"])\nax = plot(employed,age,figsize=(11,7))\nax.get_xticklabels()[-1].set_rotation(45)\nplt.suptitle(\"Age Range\", x = .45,\n             y=.95,fontsize=19,fontweight=\"semibold\", fontfamily='serif')\nplt.title(\"Data Professionals are Young: 42% are in their Mid-20s to Mid-30s\",\n                  x = .45, fontsize=14, fontfamily='serif')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gender"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"gender = findCol(employed,[\"gender\"])\ngenderProp = employed[gender].value_counts(normalize=True) * 100\nfig, ax = plt.subplots(facecolor=\"#FAFAFA\")\n\npatches, texts, autotexts = plt.pie(genderProp ,\n                                    labels=['Man', 'Woman'],\n                                    labeldistance=1.1,\n                                    shadow=True,\n                                    colors=[\"#20BEFF\",'#ff9999'],\n                                    autopct='%1.1f%%',\n                                    textprops={\n                                        'fontsize': 16,\n                                        'fontweight': 'bold'\n                                    },wedgeprops=dict(width=0.6),\n                                     startangle=90,pctdistance=0.80,\n                                    radius=1.4)\n \nplt.title(\"Employed Data Professionals - Gender\",\n          pad=40,\n          size=20, x=.5,\n          fontname='sans-serif')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:80%;\">\nKey points:\n    <br>\n<ul>\n    <li>For every five respondents, only one of them will be female. </li>\n    <li>Sadly there is a clear disproportion in gender representation amongst the employed data professional respondents.  </li>\n</ul>   \n</div>\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Yearly Compensation"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"salary = findCol(employed,[\"compensation\"])\nax = plot(employed,salary,figsize=(11,7))\n\nplt.suptitle(\"Yearly Compensation ($USD)\", x = .35,\n             y=.95,fontsize=22,fontweight=\"semibold\", fontfamily='serif')\nplt.title(\"~41% Are Paid less than $10k and ~35% are Paid between \\\\$10k to \\\\$70k\",\n                  x = .42, fontsize=14, fontfamily='serif')\nax.set_xticklabels([shorten(i) if len(str(int(i)))>3 else int(i) for i in ax.get_xticks()],\n                   fontsize=13) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:80%;\">\nKey points:\n    <br>\n<ul>\n    <li> Yearly salaries for the respondents are overwhelmingly low (~41% paid <$10k). However, considering the proportion of respondent's location (ie. ~21% from India), it seems like this was a contributing factor.\n    </li>\n</ul>   \n</div>\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Use of and Recommended Programming Languages To Learn"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"progLang = findCol(employed,[\"programming\"])\nsuptitles = [\"Years Writing Code and/or Programming\",\n             \"First Programming Language Recommendation\",\n            \"Programming Language Used Regularly\"]\ntitles = [\"~44% of data professionals have been coding for 1 - 5 years\",\n         \"Python is overwhelming recommended as a first programming language to learn\",\n         \"Python, SQL, and R are commonly used amongst data professionals\"]\nfor col,sup,t in zip(progLang,suptitles,titles):\n    ax = plot(employed,col,figsize=(12,6))\n    plt.suptitle(sup, y=.96,fontsize=21,fontweight=\"semibold\", fontfamily='serif')\n    plt.title(t, fontsize=14, fontfamily='serif')\n    plt.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:80%;\">\nKey points:\n    <br>\n<ul>\n    <li> ~44% of data professionals have been coding for 1 - 5 years. </li>\n    <li> Python is overwhelmingly recommended as a first programming language to learn. </li>\n    <li> Python, SQL, and R are commonly used amongst employed data professionals </li>\n</ul>   \n</div>\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Education"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"edu=  findCol(employed,[\"formal education\"])\nax = plot(employed,edu,figsize=(11,7))\nax.get_xticklabels()[-1].set_rotation(45)\nplt.suptitle(\"Edu. Planned/Attained Within the Next 2 Years\", x = .45,\n             y=.95,fontsize=19,fontweight=\"semibold\", fontfamily='serif')\nplt.title(\"~90% of Data Professionals Have or Plan On Obtaining A Higher Ed Degree\",\n                  x = .45, fontsize=14, fontfamily='serif')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:80%;\">\nKey points:\n    <br>\n<ul>\n    <li> About half of the respondents indicated having or plan on obtaining a Master's Degree. </li>\n    <li> It seems like obtaining a higher education, at least by those surveyed (~90% plan on or have obtained one), is important. </li>\n</ul>   \n</div>"},{"metadata":{},"cell_type":"markdown","source":"<div id=\"5\"></div>"},{"metadata":{},"cell_type":"markdown","source":"# 5. Job Title and Gender Heatmaps (EDA)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Variables we'll study per job titles: \n1. Education\n2. Common tasks at work\n3. Salary Pay\n\n*Note: Some of the charts do not include a gender differences chart as they pertain to questions that are not expected to be influenced by gender (ie. programming language preferences). "},{"metadata":{},"cell_type":"markdown","source":"For this section we'll retrieve only columns relevant to the aforementioned variables of interest."},{"metadata":{"trusted":true},"cell_type":"code","source":"useThese = [ 'What is your age (# years)?',\n       'What is your gender?', 'In which country do you currently reside?',\n       'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?',\n       'Select the title most similar to your current role (or most recent title if retired)',\n       'For how many years have you been writing code and/or programming?',\n       'What programming language would you recommend an aspiring data scientist to learn first?',\n       'What is the size of the company where you are employed?',\n       'Approximately how many individuals are responsible for data science workloads at your place of business?',\n       'What is your current yearly compensation (approximate $USD)?',\n       'Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?',\n       'Which of the following business intelligence tools do you use most often?',\n       'Select any activities that make up an important part of your role at work:',\n       'What data visualization libraries or tools do you use on a regular basis?',\n       'What programming languages do you use on a regular basis?',\n       'Which of the following cloud computing platforms do you use on a regular basis?',\n       'continent'\n]\nemployedDF = employed[useThese]\n\nnotList = [col for col in employedDF.columns \n           if employedDF[col].apply(lambda x: 1 if type(x)==list else 0).sum() ==0]\nemployedDF[notList] = employedDF[notList].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Heatmap Functions For Pivot Table"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"color_map =plt.cm.get_cmap('bone').reversed()\n    \ndef heatmaps(ax,df,rel,cmap=color_map):\n    kwargs = {'alpha':.9,'linewidth':2, 'linestyle':'--', 'rasterized':False, 'edgecolor':'w',  \"capstyle\":'projecting',}\n    sns.heatmap(data = df,annot=True,linewidths=3,\n                fmt=\".1f\" if rel else \"d\", annot_kws={\"fontsize\":8}, \n                 square=False, ax=ax, cmap= cmap,**kwargs)\n    ax.tick_params(length=0,labelsize=12,pad=0)  \n    if rel:\n        for t in ax.texts: t.set_text(t.get_text() + \" %\")\n    ax.set_ylabel('') \n\ndef relativeVal(male,female):\n    maleSum = male.sum(1)\n    femaleSum = female.sum(1)\n    male = male.apply(lambda x: x/maleSum)*100\n    female = female.apply(lambda x: x/femaleSum)*100\n    return male, female\n\ndef create_plots(ax,col, main, data,male, female,rel):\n    if rel:\n        male, female = relativeVal(male, female)\n    if male.index.nlevels ==1: diff = male -female\n    else: diff = male.droplevel(1) - female.droplevel(1) \n    heatmaps(ax,diff,rel,cmap=plt.cm.get_cmap('bwr').reversed())\n    if any([True for i in diff.columns if len(i)>15]):\n        ax.tick_params(axis='x',labelrotation=60)\n    ax.set_title('\\n'.join([\"\",\"Male Relative to Female\"])) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pivot Table Function (Agg Functions Used: Unique Count and % of Total)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def pivot_table(col,main,data=employedDF, relative=False,gender=False):\n    #retrieve select gender \n    if gender != False:\n        data= data[data[\"What is your gender?\"] == gender]\n        data[\"What is your gender?\"] = data[\"What is your gender?\"].cat.remove_unused_categories() #remove category\n     \n    #create series with select columns. Rows with lists as values are exploded \n    df = data[main+col].explode(col[0]).reset_index()\n    df= df[~df.applymap(lambda x: True if x=='' else False).any(1)] #skip none values\n    \n    # since we have categories, we'll need to remove unused catregories after filtering out none values\n    cats = [col for col in df.columns if df[col].dtype.name=='category' and '' in  df[col].cat.categories]\n    if len(cats)>0: \n        for cols in cats:\n            df[cols] = df[cols].cat.remove_unused_categories()\n    \n    df[\"index\"] = df[\"index\"].astype(np.int16) #convert to int16 type for faster processing\n    \n    # get unique count per select variables (main) for each unique value in the second variable (col)\n    df_pivot = df.pivot_table(index=main, columns=col[0],values=\"index\", aggfunc=\"nunique\")\n    df_pivot.index = df_pivot.index.set_names([\"\" for i in range(len(df_pivot.index.names))]) # no need for column names in plot\n    df_pivot.columns = df_pivot.columns.rename(\"\") # no need for column names in plot\n    \n    if relative: \n        return (df_pivot.sum().div(df_pivot.sum().sum()).sort_values(ascending=False)*100)\n    return df_pivot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Job Titles and Degree"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def mainHeatmap(col, main,cols=None):\n    fig, ax = plt.subplots(figsize=(15,10),nrows=2,ncols=1)\n\n    df_pivot = pivot_table(col,main,data=employedDF,gender=False)\n    df_pivot = df_pivot.apply(lambda x: x/df_pivot.sum(1))*100\n    if type(cols)==type(None): cols= df_pivot.columns\n    df_pivot_M = pivot_table(col, main,data=employedDF,gender=\"Man\")[cols]\n    df_pivot_W = pivot_table(col, main,data=employedDF,gender=\"Woman\")[cols]\n    heatmaps(ax[0],df_pivot[cols], rel=True,cmap='Greens')\n    ax[0].figure.axes[-1].set_yticklabels([str(int(i))+\"%\"\n                                        for i in ax[0].figure.axes[-1].get_yticks()])\n    ax[0].figure.axes[-1].tick_params(labelsize=14)\n    ax[0].figure.axes[-1].set_title(\"% of Total\",x=.6,fontsize=14) \n    create_plots(ax[1],edu, jobTitle, employedDF,df_pivot_M, df_pivot_W,True)\n    ax[1].figure.axes[-1].tick_params(labelsize=14)\n    ax[1].figure.axes[-1].set_yticklabels([str(int(i))+\"%\"\n                                        for i in ax[1].figure.axes[-1].get_yticks()])\n    ax[1].figure.axes[-1].set_title(\"% Difference\",x=.6,fontsize=14) \n    [t.set_fontsize(15) for i in range(2) for t in ax[i].texts]\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"jobTitle = list(findCol(employedDF,['current role']))\nedu = list(findCol(employedDF,['formal education']))\nsortedCols = ['Some college or less','Bachelor’s degree', \n              'Professional degree','Master’s degree', 'Doctoral degree']\nax = mainHeatmap(edu, jobTitle, sortedCols)\n\nax[1].tick_params(labelrotation=0)\ntitles = [\"Degree Planned/Obtained Per Job Title\", \"\\n\\nMale Relative to Female\"]\n[ax[i].set_title(t,fontsize=18,pad=10) for i,t in zip([0,1],titles) ]\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:90%;\">\nKey points:\n    <br>\n<ul>\n     <li> With the next exception of data scientists, obtaining a Master's degree within the next two years is the most common selection (45% - 52%) across all professional groups. </li>\n    <li> Half of academic data scientists have attained or plan to attain a doctoral degree within the next two years. Not surprisingly, these professionals have the highest formal education out of the group.</li>\n    <li> Data Scientists and Machine Learning (ML) Engineers are the next highest formally educated professionals with 17% and 14%, aiming to obtain or have obtained a Doctoral degree.</li>\n    <li> For ML engineer professionals, there were 11% more male respondents who selected having or planning on obtaining a Bachelors's degree relative to their female counterparts.</li>\n     On the other hand, female ML engineers' responses are more concentrated on the higher education choice relative to males--higher Masters and Doctoral Degree percentages.\n         \n  \n</ul>   \n</div> \n\n"},{"metadata":{},"cell_type":"markdown","source":"## Job Titles and Activities at Work"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"activities = list(findCol(employedDF,[\"activities\"]))\n\nactivityMap = dict([(k,v) for k,v in \n      zip(count_values(employedDF, activities,noFalse='').keys(),range(8))])\n\nlegend = (pd.Series(activityMap.values(),activityMap.keys()).to_frame().rename(columns={\n    0:\"Legend\"\n}).T)\n\nax = mainHeatmap(activities,jobTitle)\n\n[ax[i].tick_params(axis=\"x\",labelrotation=0) for i in range(2)]\ntitles = [\"Activities That Are Important For Job Role\", \"\\n\\nMale Relative to Female\"]\n[ax[i].set_title(t,fontsize=18,pad=10) for i,t in zip([0,1],titles)]\n[ax[i].set_xticklabels(\n              [activityMap[x.get_text()] for x in ax[i].get_xticklabels()]\n                      ) for i in range(2)]\nplt.tight_layout()\ndisplay(legend)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:90%;\">\nKey points:\n    <br>\n<ul> <li> We can see that there is a clear variation in terms of import activities per job title. In general, though, <i>analyzing and understanding data</i> plays an important part in the work of all data professionals. </li>\n    <li> Building prototypes for exploring ML applications seem to have higher relative importance for male data engineers and academic data scientists. Relative to their female counterparts, males had a 6% higher concentration of its members selecting the <i>building prototypes</i> choice.  </li>\n</ul>   \n</div>\n"},{"metadata":{},"cell_type":"markdown","source":"## Job Titles and Salary"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"salary = list(findCol(employedDF,[\"compensation\"]))\nsortedCols = ['$0-999', '$1,000 - $9,999', '$10,000 - $19,999','$20,000 - $39,999',\n    '$40,000 - $69,999', '$70,000 - $99,999', '$100,000 - $150,000', \n '$150,000 - $249,999',  '> $249,999']\nax = mainHeatmap(salary,jobTitle,sortedCols)\n\n[ax[i].tick_params(axis=\"x\",labelrotation=15) for i in range(2)]\ntitles = [\"Yearly Salary Expectations\", \"\\n\\nMale Relative to Female\"]\n[ax[i].set_title(t,fontsize=18,pad=10) for i,t in zip([0,1],titles)]\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:90%;\">\nKey points:\n    <br>\n<ul> <li> Across all job titles, yearly salary expectations are concentrated in the \\$0 to \\$10k range. As previously mentioned, this is likely due to the locations of the participants.</li>\n    <li> Across all job titles, males have a higher % of respondents selecting higher salary ranges relative to their female counterparts. This is especially the case for data engineers of whom have ~20% higher concentration of responses for the \\$20 to \\$70k salary ranges.</li>\n    <li> Relative to their male counterparts, the higher concentration of females selecting \\$0 to \\$999 as their expected yearly salary shows some strong hints of a gender pay disparity. </li>\n</ul>   \n</div>\n\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cols = ['For how many years have you been writing code and/or programming?',\n'What programming language would you recommend an aspiring data scientist to learn first?',\n'What is the size of the company where you are employed?',\n'Approximately how many individuals are responsible for data science workloads at your place of business?']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"col = [cols[0]]\nsortedCols = [ 'I have never written code','< 1 years','1-2 years', \n             '3-5 years', '5-10 years', '10-20 years', '20+ years', ]\nax = mainHeatmap(col, jobTitle,sortedCols)\n\n[ax[i].tick_params(axis=\"x\",labelrotation=15) for i in range(2)]\ntitles = [\"Years Coding\", \"\\n\\nMale Relative to Female\"]\n[ax[i].set_title(t,fontsize=18,pad=10) for i,t in zip([0,1],titles)]\n\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:90%;\">\nKey points:\n    <br>\n<ul> <li> Analysts have the least amount of experience in programming with most ~58% having 0 - 2 years of coding experience.</li>\n    <li> Academic data scientists and data engineers have the most experience in programming with 1/3 of professionals stating to have more than 10 years of coding experience.</li>\n    <li> Male respondents have a higher concentration of responses on the higher end of coding experience of which is especially the case for the academic data scientists and data engineers. </li>\n    <li>Interestingly enough, we see that women have a much higher concentration of responses on the low coding experience ranges. If we are to take into account the previous salary statistic, this may have played a role in the low salary ranges for female data engineers relative to their male counterparts.</li>\n</ul>   \n</div>\n\n\n\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"col = [cols[1]]\nax = mainHeatmap(col, jobTitle)\n\ntitles = [\"Programming Language Used Most Often\", \"Male Relative to Female\"]\n[ax[i].set_title(t,fontsize=18,pad=10) for i,t in zip([0,1],titles)]\nax[1].set_visible(False)\nax[1].figure.axes[-1].set_visible(False)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:90%;\">\nKey points:\n    <br>\n<ul> <li> ML engineers have the highest concentration (86%) of respondents who use Python as their main programming language.</li>\n    <li> The heatmap also shows R and SQL being utilized the most for some data professionals.</li>\n</ul>   \n</div>\n\n\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"col = [cols[2]]\nsortedCols = ['0-49','50-249', '250-999', '1000-9,999','10,000 or more']\nax = mainHeatmap(col, jobTitle,sortedCols)\n\ntitles = [\"Size of Company\", \"\\n\\nMale Relative to Female\"]\n[ax[i].set_title(t,fontsize=18,pad=10) for i,t in zip([0,1],titles)]\n#ax[1].set_visible(False)\n#ax[1].figure.axes[-1].set_visible(False)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:90%;\">\nKey points:\n    <br>\n<ul> \n    <li> Across all job titles, a good share of them works for companies with less than 50 employees. ML engineers, in particular, have a high concentration (~54%) of respondents who work at a small-sized business (< 50 employees).</li>  \n    </ul>   \n</div>\n\n\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"col = [cols[3]]\nsortedCols=['0', '1-2','3-4', '5-9', '10-14', '15-19', '20+']\nax = mainHeatmap(col, jobTitle,sortedCols)\n\ntitles = [\"Individuals Responsible for Data Science Workloads\", \"\\n\\nMale Relative to Female\"]\n[ax[i].set_title(t,fontsize=18,pad=10) for i,t in zip([0,1],titles)]\nax[1].set_visible(False)\nax[1].figure.axes[-1].set_visible(False)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:90%;\">\nKey point:\n    <br>\n    <ul> <li> 10 - 19 individuals working on data science workloads is not common. Data professionals either work in small teams (0 - 10) or large teams (20+). </li>\n</ul>   \n</div>\n\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"<div id=\"6\"></div>"},{"metadata":{},"cell_type":"markdown","source":"# 6. Common Tools Per Job Title (EDA)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tools=[]\nfor w in [\"use most often\",\"programming languages\",\"cloud\"]:\n    tools+= list(findCol(employedDF,[w]))\nprint(tools)\n\ndef toolChart(tool):\n    fig, ax = plt.subplots(figsize=(15,7.5),facecolor=\"#03174D\")\n    ax.set_facecolor(\"#03174D\")\n    df_pivot = pivot_table([tool],jobTitle,data=employedDF,gender=False)\n    df_pivot = df_pivot.apply(lambda x: x/df_pivot.sum(1))*100\n    top5 = (df_pivot.transform(np.sort)[::-1]).iloc[0].sort_values().tail(5).index\n    data = df_pivot[top5]\n    sortedRow = data.sum(1).sort_values().index\n    data.loc[sortedRow].plot.barh(stacked=True,ax=ax,width=.7,zorder=3)\n    for bar in ax.patches:\n        x,y,s = bar.get_x()+bar.get_height()*2,bar.get_y()+bar.get_height()/2, bar.get_width()\n        rot= 90 if s< 6 else 0\n        ax.text(x-bar.get_height() if s<= 6 else x, y ,f\"{s:.1f}%\",color=\"white\",\n                fontsize=14,rotation=rot)\n    modifyChartBasic(ax,13,grid='x')\n    ax.set_xlim(0,100)\n    ax.set_xticklabels([f\"{i:.1f}%\" for i in ax.get_xticks()])\n    ax.tick_params(labelcolor=\"white\",labelsize=14)\n    data.loc[sortedRow].applymap(lambda x: 100).iloc[:,-1].rename(\"\").plot.barh(zorder=0,width=.7,edgecolor=\"teal\",\n          legend=None, linewidth=2, facecolor= \"#03174D\")\n    legend = ax.legend(loc=\"upper center\", bbox_to_anchor=(0.47, 1.06),ncol=5,fontsize=15)\n    \n    return ax\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Big Data Products Used Most Often Per Job Title"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"toolChart(tools[0])\nplt.suptitle(\"Top 5 Commonly Used Big Data Products Per Job Title\",y=1.05,\n             color=\"white\",fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:85%;\">\nBig Data Products Used Most Often:\n    <ul> <li><b>Academic Data Scientists: </b>MySQL </li>\n        <li><b>Machine Learning Engineer: </b>MySQL and PostgreSQL </li>\n        <li><b>Analyst: </b>MySQL and Microsoft SQL Server</li>\n        <li><b>Data Scientist: </b>MySQL and PostgreSQL. </li>\n        <li><b>Data Engineer: </b> Microsoft SQL Server</li>\n</ul>   \n</div>"},{"metadata":{},"cell_type":"markdown","source":"### Business Intelligence (BI) Tools Used Most Often Per Job Title"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"toolChart(tools[1])\nplt.suptitle(\"Top 5 Most Used BI Tool Per Job Title\",y=1.05,\n             color=\"white\",fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:85%;\">\nBI Tools Used Regularly:\n    <ul> <li><b>Academic Data Scientists: </b>Tableau, Power BI, and Google Data Studio </li>\n        <li><b>Machine Learning Engineer: </b>Tabeau </li>\n        <li><b>Analyst: </b>Tableau and PowerBI</li>\n        <li><b>Data Scientist: </b>Tableau </li>\n        <li><b>Data Engineer: </b> Power BI</li>\n</ul>   \n</div>"},{"metadata":{},"cell_type":"markdown","source":"### Programming Languages Used Regularly Per Job Title"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"toolChart(tools[2])\nplt.suptitle(\"Top 5 Commonly Used Programming Lang. Per Job Title\",y=1.05,\n             color=\"white\",fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:85%;\">\nProgramming Language Used Regularly:\n    <ul> <li><b>Academic Data Scientists: </b>Python </li>\n        <li><b>Machine Learning Engineer: </b>Python </li>\n        <li><b>Analyst: </b>Python and SQL</li>\n        <li><b>Data Scientist: </b>Python and SQL </li>\n        <li><b>Data Engineer: </b>Python and SQL </li>\n</ul>   \n</div>"},{"metadata":{},"cell_type":"markdown","source":"### Cloud Platforms Used Regularly Per Job Title"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ax = toolChart(tools[3])\nax.legend(loc=\"upper center\", bbox_to_anchor=(0.45, 1.1),ncol=3,fontsize=15)\nplt.suptitle(\"Top 5 Commonly Used Cloud Platform Per Job Title\",\n             y=1.075,color=\"white\",fontsize=25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"font-size:16px;width:85%;\">\nCloud Platform Used Regularly:\n    <ul> <li><b>Academic Data Scientists: </b>AWS and Google Cloud Platform</li>\n        <li><b>Machine Learning Engineer: </b>AWS and Google Cloud Platform </li>\n        <li><b>Analyst: </b>AWS, Google Cloud Platform, and Microsoft Azure </li>\n        <li><b>Data Scientist: </b>AWS, Google Cloud Platform, and Microsoft Azure</li>\n        <li><b>Data Engineer: </b>AWS, Google Cloud Platform, and Microsoft Azure </li>\n</ul>   \n</div>"},{"metadata":{},"cell_type":"markdown","source":"<div id=\"7\"></div>"},{"metadata":{},"cell_type":"markdown","source":"# 7. Short Summary"},{"metadata":{},"cell_type":"markdown","source":"General Demographics of Employed Kagglers\n\nWhile there are inherently some biases (ie. response bias) inherit in the data as well as my own analysis, the general insights obtained from it provide us with some insight on how the current landscape looks for employed data professionals. From the responses, employed data professionals who took the survey are: young (42% are in their mid-20s to mid-30s), mostly located in Asia or Europe (60%), are predominately male (81.5%), and are formally educated (90% have or plan on obtaining a higher-ed degree withing the net 2 years).\n\nRecommendation for Technical Tools To Learn\n\nIf we are to consider the responses from Kagglers who reported being employed data professionals, Python and SQL are great programming languages to learn as they are most commonly used in a professional setting. In addition, learning how to utilize cloud platforms such as AWS, Google Cloud Platform, and Microsoft Azure might be a good idea if one is considering to join a team that works with \"big data.\" For SQL server languages, the following are good choices to learn: SQL, PostgreSQL, or Microsoft SQL Server. Lastly, for those planning on doing work involving BI, knowledge of Tableau and/or Power BI will be great to have."},{"metadata":{},"cell_type":"markdown","source":"## Data Used For Tableau Dashboard \nNote: Data shape is in long format (index is used for unique count)."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"markdown","source":"```forTableau = employedDF[['What is your age (# years)?', 'What is your gender?',\n       'In which country do you currently reside?',\n       'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?',\n       'Select the title most similar to your current role (or most recent title if retired)',\n       'What is your current yearly compensation (approximate $USD)?',\n       'Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?',\n       'What programming languages do you use on a regular basis?',\n    'Approximately how many individuals are responsible for data science workloads at your place of business?',\n       'Which of the following cloud computing platforms do you use on a regular basis?','continent']]```\n\n```containsList=  [col for col in forTableau.columns if (forTableau[col].apply(lambda x: 1 if type(x)==list else 0).sum())>0]```\n\n```for col in containsList:\n    forTableau  = forTableau.explode(col)\nforTableau.to_csv(\"try.csv\")\nforTableau.head()```"},{"metadata":{},"cell_type":"markdown","source":"# How might your job profile look?\n### Use the dashboard below to explore responses in accordance to country, job title, gender, and level of education."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%html\n<div class='tableauPlaceholder' id='viz1609977219722' style='position: relative'><noscript><a href='#'><img alt=' ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ka&#47;KaggleSurvey2020&#47;jobInfographic&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='KaggleSurvey2020&#47;jobInfographic' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Ka&#47;KaggleSurvey2020&#47;jobInfographic&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1609977219722');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.height='2527px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Please don't forget to upvote if you found this notebook helpful and/or insightful! Thanks!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}