{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Science in 2020: NLP vs CV\n\nIn my experience*, people who work in data science are mostly specialized in either CV or NLP, but rarely work in both fields at the same time.\n\n**TL;DR**: This notebook tries to find and explain any significant differences between people working in the two major subfields of data science.\n\n\n#### Testable hypotheses\nBefore looking at the data, I came up with the following ideas:\n* Subfield **specialisation will increase with years of ML experience / work experience / level of education**. For example, while DS students recieve general education and don't assosiate themselves with any particular field, DS professionals devote their time to particular sets of problems inside one field.\n\n* **NLP is more heterogeneous** (in different ways, e.g., programming languages of choice). I believe this because, in my experience, there are much more things that people somehow relate to NLP than in the case with CV.\n\n* There are **more female specialists in NLP** than in CV. I think so because NLP is somewhat related to lingustics which is popular among females, while CV doesn't have any such related field.\n\n\n#### Methodology\nMy judgement of whether a person works in CV or NLP comes from answers the questions Q18 and Q19 (which CV / NLP methods do you use, respectively). If a person has chosen at least one item on either list, I count it as an evidence that they are somehow related to the corresponding field.\n\n\n\\* I am an NLP specialist from Russia. It might well be that my experience is not represantatve."},{"metadata":{},"cell_type":"markdown","source":"### Data preparation"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')\nquestions = df.iloc[0, :].T\ndata = df.iloc[1:, :]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# these are the columns responsible for CV / NLP methods or tools\nq_18_cv_tools = ['Q18_Part_' + str(i) for i in range(1, 7)] + ['Q18_OTHER']\nq_19_nlp_tools = ['Q19_Part_' + str(i) for i in range(1, 6)] + ['Q19_OTHER']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I count a respondent as an NLP / CV person, if they have chosen at least one option in the corresponding list, except for `None`."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_people_indices(subset, columns):\n    people_ids = []\n    for i, line in enumerate(subset[columns].values):\n        \n        # nothing_selected: either the person selected no option or they selected the `None` option\n        nothing_selected = all([type(answer) == float for answer in line]) or line[-2] == 'None'\n        \n        # in other case, the person is related to the field\n        if not nothing_selected:\n            people_ids.append(i)\n    return people_ids","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"cv_people_ids = get_people_indices(data, q_18_cv_tools)\nnlp_people_ids = get_people_indices(data, q_19_nlp_tools)\n\ndata['CV_person'] = [True if i in cv_people_ids else False for i in range(len(data))]\ndata['NLP_person'] = [True if i in nlp_people_ids else False for i in range(len(data))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ratio of CV / NLP specialists"},{"metadata":{},"cell_type":"markdown","source":"It's time to visualize! Now we can compare the ratios."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt; plt.rcdefaults()\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Among all respondents"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"groups = ('CV only', 'NLP only', 'Both CV and NLP')\ny_pos = range(len(groups))\nsizes = [\n    len(data[data['CV_person'] & ~data['NLP_person']]),\n    len(data[data['NLP_person'] & ~data['CV_person']]),\n    len(data[data['NLP_person'] & data['CV_person']])\n]\n\nplt.bar(y_pos, sizes, align='center', alpha=0.5, color=('b', 'g', 'c'))\nplt.xticks(y_pos, groups)\nplt.ylabel('Number of people')\nplt.title('People who use CV / NLP methods')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this graph, it doesn't seem that my observation regarding people only working in either CV or NLP field is correct: the group of people who chose both NLP and CV methods is actualy larger than NLP-only group.\n\nApart from that, we see that **CV seems to be much more popular than NLP**."},{"metadata":{},"cell_type":"markdown","source":"### Non-students only\n\nIt seems reasonable to remove students from our data, since they could be still undecided of their professional career."},{"metadata":{"trusted":true},"cell_type":"code","source":"non_students = data[data['Q5'] != 'Student']\nnon_students.shape","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"groups = ('CV only', 'NLP only', 'Both CV and NLP')\ny_pos = range(len(groups))\nsizes = [\n    len(non_students[non_students['CV_person'] & ~non_students['NLP_person']]),\n    len(non_students[non_students['NLP_person'] & ~non_students['CV_person']]),\n    len(non_students[non_students['NLP_person'] & non_students['CV_person']])\n]\n\nplt.bar(y_pos, sizes, align='center', alpha=0.5, color=('b', 'g', 'c'))\nplt.xticks(y_pos, groups)\nplt.ylabel('Number of people')\nplt.title('Non-students only')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing students doesn't really seem to change things. Let's comare the two distributions.\n\nTo compare the distributions better, this time I divide all numbers by total sizes of corresponding groups."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_field_sizes(dataset):\n    return [\n        len(dataset[dataset['CV_person'] & ~dataset['NLP_person']]),\n        len(dataset[dataset['NLP_person'] & ~dataset['CV_person']]),\n        len(dataset[dataset['NLP_person'] & dataset['CV_person']])\n    ]\n\ndef get_field_ratios(dataset):\n    sizes = get_field_sizes(dataset)\n    return [s / len(dataset[dataset['CV_person'] | dataset['NLP_person']]) for s in sizes]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"groups = ('CV only', 'NLP only', 'Both CV and NLP')\ny_pos = np.arange(len(groups))\nbar_width = 0.35\nopacity=0.8\n\ntotal_ratios = get_field_ratios(data)\ntotal_plot = plt.bar(y_pos, total_ratios, bar_width,\n                    align='center', alpha=opacity,\n                    label='Among all',\n                    color='darkcyan')\n\nnonst_ratios = get_field_ratios(non_students)\nnonst_plot = plt.bar(y_pos + bar_width, nonst_ratios, bar_width,\n                      align='center', alpha=opacity,\n                      label='Among non-students',\n                      color='cyan')\n\n\nplt.xticks(y_pos + bar_width / 2, groups)\nplt.ylabel('Fraction of those who answered')\nplt.title('Total vs Non-students')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At first approximation, it seems that my hypothesis about increasing specialization does not confirm.\n\nBut let's go further and see how this distribution changes as we restrict the group to more and more experienced / professional respondents."},{"metadata":{},"cell_type":"markdown","source":"### Data Scientists / Research Scientists only"},{"metadata":{},"cell_type":"markdown","source":"Let's narrow our group down to these professions. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds_data = data[data['Q5'] == 'Data Scientist']\nrs_data = data[data['Q5'] == 'Research Scientist']\n\nlen(ds_data), len(rs_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The subsets seems rather small, but are probably enough. Let's take a look at ratios, compared to total."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"bar_width = 0.25\n\ntotal_ratios = get_field_ratios(data)\ntotal_plot = plt.bar(y_pos, total_ratios, bar_width,\n                    align='center', alpha=opacity,\n                    label='Among all',\n                    color='darkcyan')\n\nds_ratios = get_field_ratios(ds_data)\nds_plot = plt.bar(y_pos + bar_width, ds_ratios, bar_width,\n                      align='center', alpha=opacity,\n                      label='Among data scientists',\n                      color='cyan')\n\nrs_ratios = get_field_ratios(rs_data)\nrs_plot = plt.bar(y_pos + bar_width * 2, rs_ratios, bar_width,\n                      align='center', alpha=opacity,\n                      label='Among research scientists',\n                      color='deepskyblue')\n\n\nplt.xticks(y_pos + bar_width, groups)\nplt.ylabel('Percentage of subgroup size')\nplt.title('Total vs Data Scientists vs Research Scientists')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For **Data Scentist** group, we see that **ratio of NLP people significantly increased**. However, number of those who use both NLP and CV methods has also increased.\n\nFor **Research Scientists, CV looks much more popular** for some reason.\n\nHowever, I still **don't see any strong evidence for increased specialization**."},{"metadata":{},"cell_type":"markdown","source":"### Experience / age/ salary vs specialization\n\nWhat if we introduce a `specialization` parameter based on ratio of CV-or-NLP-only group to total respondents?\n\n`specialization` is defined as: $$1 - \\frac{|CV and NLP|}{|CV or NLP|}$$ which is a fraction of those who use either NLP or CV methods, but not both."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def count_specialization(dataset):\n    both_size = len(dataset[dataset['CV_person'] & dataset['NLP_person']])\n    union_size = len(dataset[dataset['CV_person'] | dataset['NLP_person']])\n    both_frac = both_size / union_size if union_size else 0\n    return 1 - both_frac","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Programming experience"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"answers = [\n    '< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years',\n]\nscores = []\nfor answer in answers:\n    scores.append(count_specialization(data[data['Q6'] == answer]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"y_pos = range(len(answers))\n\nplt.plot(y_pos, scores, 'bo-')\nplt.xticks(y_pos, answers)\nplt.ylabel('Specialization')\nplt.title('Programming experience')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The trand seems to be quite the opposite of what I thought."},{"metadata":{},"cell_type":"markdown","source":"#### ML experience"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"answers = [\n    'Under 1 year', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5-10 years', '10-20 years', '20 or more years',\n]\nscores = []\nfor answer in answers:\n    scores.append(count_specialization(data[data['Q6'] == answer]))\n    \ny_pos = range(len(answers))\n\nplt.plot(y_pos, scores, 'bo-')\nplt.xticks(y_pos, answers, rotation=45)\nplt.ylabel('Specialization')\nplt.title('Programming experience')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And here we don't see any clear trand."},{"metadata":{},"cell_type":"markdown","source":"## Relation to other answers\n\nFor this part, I choose non-students only as more reliable source of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_people = non_students[non_students['CV_person'] & ~non_students['NLP_person']]\nnlp_people = non_students[non_students['NLP_person'] & ~non_students['CV_person']]\nboth = non_students[non_students['NLP_person'] & non_students['CV_person']]\n\nlen(cv_people), len(nlp_people), len(both)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_feature_sizes(feature_col, feature_name):\n    return [\n        len(cv_people[cv_people[feature_col] == feature_name]),\n        len(nlp_people[nlp_people[feature_col] == feature_name]),\n        len(both[both[feature_col] == feature_name]),\n    ]\n\ndef get_feature_ratios(feature_col, feature_name):\n    sizes = get_feature_sizes(feature_col, feature_name)\n    return [\n        sizes[0] / len(cv_people),\n        sizes[1] / len(nlp_people),\n        sizes[2] / len(both),\n    ]\n\n\ndef get_ingroup_feature_sizes(dataset, feature_col, feature_names):\n    return [\n        len(dataset[dataset[feature_col] == feature_name])\n        for feature_name in feature_names\n    ]\n\ndef get_ingroup_feature_ratios(dataset, feature_col, feature_names):\n    sizes = get_feature_sizes(dataset, feature_col, feature_names)\n    return [s / len(dataset) for s in sizes]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gender"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"groups = ('CV', 'NLP', 'Both')\ny_pos = np.arange(len(groups))\nbar_width = 0.35\nopacity=0.8\n\nfemale_ratios = get_feature_ratios('Q2', 'Woman')\nfem_plot = plt.bar(y_pos, female_ratios, bar_width,\n                    align='center', alpha=opacity,\n                    label='Female',\n                    color='cyan')\n\nmale_ratios = get_feature_ratios('Q2', 'Man')\nmale_plot = plt.bar(y_pos + bar_width, male_ratios, bar_width,\n                    align='center', alpha=opacity,\n                    label='Male',\n                    color='red')\n\nplt.xticks(y_pos + bar_width / 2, groups)\nplt.ylabel('Percentage of respondents')\nplt.title('Male / female scpecialists')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This looks interesting. There are actually a little more female specialists in NLP than in CV, but this difference seems to be insignificant. However, using both CV and NLP methods appears to be a very male thing to do.\n\n(I did not analyze data for non-binary people since their percentage is too small to make any reliable judgement)."},{"metadata":{},"cell_type":"markdown","source":"### Programming languages "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pl_cols = ['Q7_Part_' + str(i + 1) for i in range(11)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preferred languages"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from collections import Counter\n\n\ndef get_multiple_choice_counts(dataset, cols):\n    return Counter(dataset[cols].values.reshape(-1))\n\ndef get_multiple_choice_ratios(dataset, cols):\n    lang_counts = get_multiple_choice_counts(dataset, cols)\n    return {lang: count / len(dataset) for (lang, count) in lang_counts.items()}","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"languages = get_multiple_choice_counts(data, pl_cols)\nlanguages = sorted([l for l in languages if not type(l) == float])\ny_pos = np.arange(len(languages))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"bar_width = 0.35\n\nnlp_lang_ratios = get_multiple_choice_ratios(nlp_people, pl_cols)\nnlp_lang_ratios = [nlp_lang_ratios[l] for l in languages]\nplt.bar(y_pos, nlp_lang_ratios, bar_width, align='center', alpha=0.8,\n        label='NLP',\n        color='deepskyblue')\n\ncv_lang_ratios = get_multiple_choice_ratios(cv_people, pl_cols)\ncv_lang_ratios = [cv_lang_ratios[l] for l in languages]\nplt.bar(y_pos + bar_width, cv_lang_ratios, bar_width, align='center', alpha=0.8,\n        label='CV',\n        color='indigo')\n\n\nplt.xticks(y_pos + bar_width * 0.5, languages, rotation=45)\nplt.ylabel('Fraction of group size')\nplt.title('Languages used by NLP / CV people')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some observations:\n* C / C++ are a bit more popular among CV people\n* on the other handm R and SQL are much more popular among NLP people\n* python is very popular among both groups, as expected"},{"metadata":{},"cell_type":"markdown","source":"I also was intrested in the average number of languages used by either group. It turned out that **both groups are roughly equally multilingual**, so, nothing unexpected here. (Unfold the cells below to see). "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_lang_per_person(dataset):\n    return [\n        len([lang for lang in langs if type(lang) != float])\n        for langs in dataset[pl_cols].values\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"bar_width = 0.35\ngroups = ('NLP people', 'CV people')\ny_pos = np.arange(len(groups))\n\nnlp_langs_count = get_lang_per_person(nlp_people)\nnlp_avg = np.average(nlp_langs_count)\n\ncv_langs_count = get_lang_per_person(cv_people)\ncv_avg = np.average(cv_langs_count)\n\nplt.bar(y_pos, [nlp_avg, cv_avg], bar_width, align='center', alpha=0.8,\n        color=('deepskyblue', 'indigo'))\nplt.xticks(y_pos, groups, rotation=45)\nplt.ylabel('Agerage number of languages')\nplt.title('Number of languages used by NLP / CV people')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ML / DL frameworks"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"framework_cols = ['Q16_Part_' + str(i + 1) for i in range(14)]\n\nframeworks = get_multiple_choice_counts(data, framework_cols)\nframeworks = sorted([l for l in frameworks if not type(l) == float])\ny_pos = np.arange(len(frameworks))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"bar_width = 0.35\n\nnlp_lang_ratios = get_multiple_choice_ratios(nlp_people, framework_cols)\nnlp_lang_ratios = [nlp_lang_ratios[l] for l in frameworks]\nplt.bar(y_pos, nlp_lang_ratios, bar_width, align='center', alpha=0.8,\n        label='NLP',\n        color='deepskyblue')\n\ncv_lang_ratios = get_multiple_choice_ratios(cv_people, framework_cols)\ncv_lang_ratios = [cv_lang_ratios[l] for l in frameworks]\nplt.bar(y_pos + bar_width, cv_lang_ratios, bar_width, align='center', alpha=0.8,\n        label='CV',\n        color='indigo')\n\n\nplt.xticks(y_pos + bar_width * 0.5, [f.strip() for f in frameworks], rotation=45)\nplt.ylabel('Fraction of group size')\nplt.title('Frameworks used by NLP / CV people')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My observations:\n\n1. DL libraries: `Keras` and `TensorFlow` are more popular CV people, while NLP people give a slight preferrence to `PyTorch`.\n2. For some reason, NLP people like `Xgboost` much more than CV people do."},{"metadata":{},"cell_type":"markdown","source":"## Most distinctive features\n\nSo far we've seen lots of answer comparison. But what are the answers that amost certainly tell that a person works in NLP / CV (except for the obvious ones)?\n\nLet's build a binary classification model and see."},{"metadata":{},"cell_type":"markdown","source":"### Answer Vectorizer\n\nFirst, we are building a vectorizer that transforms the responces to vectors of 0s and 1s. Each selection question is transformed to an one-hot encoding vector and then concatenated with the other answers.\n\nSurely, we remove the answers to the defining questions (the ones about CV and NLP tools)."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"STOP_LIST = {\n    'Time from Start to Finish (seconds)', 'CV_person', 'NLP_person',\n    'Q17_Part_7', 'Q17_Part_8', 'Q17_Part_9', 'Q17_Part_10'\n}\nSTOP_LIST.update(q_18_cv_tools)\nSTOP_LIST.update(q_19_nlp_tools)\nSELECTION_QUESTIONS = {\n    'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q8', 'Q11', 'Q13', 'Q15',\n    'Q20', 'Q21', 'Q22', 'Q24', 'Q25', 'Q30', 'Q32', 'Q38'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class AnswerVectorizer:\n    def __init__(self):\n        self.size = 0\n        self.ans_to_id = {}\n        self.id_to_ans = []\n        \n    def add_selection_slots(self, data, col):\n        answers = sorted(set(data[col]))\n        for ans in answers:\n            if not ans:\n                continue\n            self.ans_to_id[(col, ans)] = self.size\n            self.id_to_ans.append((col, ans))\n            self.size += 1\n            \n    def add_simple_answer(self, data, col):\n        answers = list(set(data[col]))\n        answer = answers[0] if answers[0] else answers[1]\n        self.ans_to_id[self.size] = answer\n        self.id_to_ans.append(answer)\n        self.id_to_question.append(col)\n        self.size += 1\n        \n    def fit(self, data):\n        for col in data:\n            if col in STOP_LIST:\n                continue\n                \n            if col in SELECTION_QUESTIONS:\n                self.add_selection_slots(data, col)\n                \n            else:\n                self.add_selection_slots(data, col)\n                \n                \n    def transform(self, data):\n        vectors = np.zeros((len(data), self.size))\n        i = 0\n        for col in data:\n            if col in STOP_LIST:\n                continue\n                \n            if col in SELECTION_QUESTIONS:\n                for i, answer in enumerate(data[col]):\n                    if (col, answer) in self.ans_to_id:\n                        vectors[i][self.ans_to_id[(col, answer)]] = 1\n                        \n            else:\n                for i, answer in enumerate(data[col]):\n                    if (col, answer) in self.ans_to_id:\n                        vectors[i][self.ans_to_id[(col, answer)]] = 1\n            \n        return vectors","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"non_students.fillna('', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Now, we vectorize!\nvec = AnswerVectorizer()\nvec.fit(non_students)\nvectors = vec.transform(non_students)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training a classifier\n\nNow we train a simple logistic regression classifier."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we make a model for predicting NLP people. We are interested in significant features, but let's also track hoe good the classifier performs."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    vectors, non_students['NLP_person'], test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"nlp_prediction_model = LogisticRegression(max_iter=1000)\nnlp_prediction_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"nlp_predicted = nlp_prediction_model.predict(X_test)\nprint(classification_report(y_test, nlp_predicted))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Works not so great. But what about the features?\n\nHere are 5 most predictive answers for NLP, ranked starting from most important:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"indices = nlp_prediction_model.coef_[0].argsort()[-5:]\nfor i, ind in enumerate(reversed(indices)):\n    q, a = vec.id_to_ans[ind]\n    print('{}. Question {}. Answer: {}.\\n'.format(\n        i, questions[q], a))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not very insightful. It looks like those are just a bunch of random answers.\n\nIt works thew same way for CV people:"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    vectors, non_students['CV_person'], test_size=0.1, random_state=42)\n\ncv_prediction_model = LogisticRegression(max_iter=1000)\ncv_prediction_model.fit(X_train, y_train)\n\ncv_predicted = nlp_prediction_model.predict(X_test)\nprint(classification_report(y_test, cv_predicted))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"indices = cv_prediction_model.coef_[0].argsort()[-5:]\nfor i, ind in enumerate(reversed(indices)):\n    q, a = vec.id_to_ans[ind]\n    print('{}. Question {}. Answer: {}.\\n'.format(\n        i, questions[q], a))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusions\n\n1. My hypothesis about increasing specialization did not confirm. It is also possible that specialization with age / experience exists, but many people used some methods of the neighbouring field anyway, even though they didn't do it frequently. This last hypothesis cannot be tested on this survey.\n\n2. My hypothesis about NLP being more female shere also did not confirm. However, I found that men tend to be more interdisciplinary for some reason.\n\n3. C / C++ are a bit more popular among CV people while R and SQL are much more popular among NLP people. Python expectedly is the most popular language for both groups. \n\n4. TensorFlow is more popular among CV people while PyTorch is more popular among CV people (I don't have any idea why)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}