{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport re\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport cv2\nfrom keras import applications\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\nfrom keras.models import Model\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/human-protein-atlas-image-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_SHAPE = (512, 512, 3)\nBATCH_SIZE = 16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_to_train = '/kaggle/input/human-protein-atlas-image-classification/train/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"complete_path\"] = path_to_train + df[\"Id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfig, axes = plt.subplots(3, 4, figsize=(11, 11))\nfor i in range(3):\n    for j in range(4):\n        idx = random.randint(0, df.shape[0])\n        row = df.iloc[idx,:]\n        path = row.complete_path\n        red = np.array(Image.open(path + '_red.png'))\n        green = np.array(Image.open(path + '_green.png'))\n        blue = np.array(Image.open(path + '_blue.png'))\n        im = np.stack((\n                red,\n                green,\n                blue),-1)\n        axes[i][j].imshow(im)\n        axes[i][j].set_title(row.Target)\n        axes[i][j].set_xticks([])\n        axes[i][j].set_yticks([])\nfig.tight_layout()\nfig.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.2, random_state=42)\n\n\ntrain, val = train_test_split(train, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Shape of train: {train.shape}')\nprint(f'Shape of test: {test.shape}')\nprint(f'Shape of val: {val.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_clean_data(df):\n    targets = []\n    paths = []\n    for _, row in df.iterrows():\n        target_np = np.zeros((28))\n        t = [int(t) for t in row.Target.split()]\n        target_np[t] = 1\n        targets.append(target_np)\n        paths.append(row.complete_path)\n    return np.array(paths), np.array(targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path, train_target = get_clean_data(train)\nval_path, val_target = get_clean_data(val)\ntest_path, test_target = get_clean_data(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train path shape: {train_path.shape}')\nprint(f'Train target shape: {train_target.shape}')\nprint(f'Val path shape: {val_path.shape}')\nprint(f'Val target shape: {val_target.shape}')\nprint(f'Test path shape: {test_path.shape}')\nprint(f'Test target shape: {test_target.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = tf.data.Dataset.from_tensor_slices((train_path, train_target))\nval_data = tf.data.Dataset.from_tensor_slices((val_path, val_target))\ntest_data = tf.data.Dataset.from_tensor_slices((test_path, test_target))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(path, target):\n    red = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_red.png'), channels=1), [2])\n    blue = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_blue.png'), channels=1), [2])\n    green = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_green.png'), channels=1), [2])\n    img = tf.stack((\n                red,\n                green,\n                blue), axis=2)\n    return img, target\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_data = train_data.map(load_data, num_parallel_calls=AUTOTUNE)\nval_data = val_data.map(load_data, num_parallel_calls=AUTOTUNE)\ntest_data = test_data.map(load_data, num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_augment(img, target):\n    img = tf.image.random_contrast(img, lower=0.3, upper=1.2)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_brightness(img, max_delta=0.5)\n    return img, target\n    \ntrain_data = train_data.map(image_augment, num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_batches = train_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\nval_data_batches = val_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\ntest_data_batches = test_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet')\n\nresnet_model.trainable = True\n\ninput_layer = Input(shape=INPUT_SHAPE)\nx = resnet_model(input_layer)\nx = Flatten()(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(28, activation='sigmoid')(x)\nmodel = Model(input_layer, output)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=Adam(1e-2), loss='MSLE', metrics=['AUC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_data_batches, steps_per_epoch = 100, validation_data = val_data_batches, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.evaluate(test_data_batches, batch_size=42)\nprint(\"test loss, test acc:\", results)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}