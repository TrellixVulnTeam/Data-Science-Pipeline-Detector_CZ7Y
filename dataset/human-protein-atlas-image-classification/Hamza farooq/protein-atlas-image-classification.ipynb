{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Here Importing the Eseantial libraries **","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport keras\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport cv2\nfrom keras import applications\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\nfrom keras.models import Model\nfrom keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:26:06.738503Z","iopub.execute_input":"2021-06-24T20:26:06.738819Z","iopub.status.idle":"2021-06-24T20:26:07.456407Z","shell.execute_reply.started":"2021-06-24T20:26:06.738791Z","shell.execute_reply":"2021-06-24T20:26:07.455563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Lables of the images from train.csv file ","metadata":{}},{"cell_type":"code","source":"dataframe = pd.read_csv('/kaggle/input/human-protein-atlas-image-classification/train.csv')\ndataframe.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:26:10.587991Z","iopub.execute_input":"2021-06-24T20:26:10.588323Z","iopub.status.idle":"2021-06-24T20:26:10.657513Z","shell.execute_reply.started":"2021-06-24T20:26:10.588291Z","shell.execute_reply":"2021-06-24T20:26:10.656735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" * Defining the input shape of 1st input layer \n * decalare the batch size\n * save the path of train images in the variable 'path_to_train'","metadata":{}},{"cell_type":"code","source":"INPUT_SHAPE = (512, 512, 3)\nBATCH_SIZE = 16\npath_to_train = '/kaggle/input/human-protein-atlas-image-classification/train/'","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:26:13.912345Z","iopub.execute_input":"2021-06-24T20:26:13.91266Z","iopub.status.idle":"2021-06-24T20:26:13.916593Z","shell.execute_reply.started":"2021-06-24T20:26:13.912631Z","shell.execute_reply":"2021-06-24T20:26:13.915504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Adding the column with the name of complete_path and load the full path of each image on csv ","metadata":{}},{"cell_type":"code","source":"dataframe[\"complete_path\"] = path_to_train + dataframe[\"Id\"]\ndataframe.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:02.340495Z","iopub.execute_input":"2021-06-24T20:27:02.340808Z","iopub.status.idle":"2021-06-24T20:27:02.358932Z","shell.execute_reply.started":"2021-06-24T20:27:02.340779Z","shell.execute_reply":"2021-06-24T20:27:02.357978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Visualizing the pictures\n\n","metadata":{}},{"cell_type":"code","source":"import random\nfig, axes = plt.subplots(3, 4, figsize=(10, 10))\nfor i in range(3):\n    for j in range(4):\n        idx = random.randint(0, dataframe.shape[0])\n        row = dataframe.iloc[idx,:]\n        path = row.complete_path\n        red = np.array(Image.open(path + '_red.png'))\n        green = np.array(Image.open(path + '_green.png'))\n        blue = np.array(Image.open(path + '_blue.png'))\n        im = np.stack((\n                red,\n                green,\n                blue),-1)\n        axes[i][j].imshow(im)\n        axes[i][j].set_title(row.Target)\n        axes[i][j].set_xticks([])\n        axes[i][j].set_yticks([])\nfig.tight_layout()\nfig.show(5);","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:05.414934Z","iopub.execute_input":"2021-06-24T20:27:05.415262Z","iopub.status.idle":"2021-06-24T20:27:06.971871Z","shell.execute_reply.started":"2021-06-24T20:27:05.415233Z","shell.execute_reply":"2021-06-24T20:27:06.971105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Spliting the data into parts train and val(valiation)","metadata":{}},{"cell_type":"code","source":"train, val = train_test_split(dataframe, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:11.909802Z","iopub.execute_input":"2021-06-24T20:27:11.910138Z","iopub.status.idle":"2021-06-24T20:27:11.921737Z","shell.execute_reply.started":"2021-06-24T20:27:11.910106Z","shell.execute_reply":"2021-06-24T20:27:11.920912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Shape of train: {train.shape}')\nprint(f'Shape of val: {val.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:15.769146Z","iopub.execute_input":"2021-06-24T20:27:15.769491Z","iopub.status.idle":"2021-06-24T20:27:15.77417Z","shell.execute_reply.started":"2021-06-24T20:27:15.76946Z","shell.execute_reply":"2021-06-24T20:27:15.773309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cleaning the data for better results ","metadata":{}},{"cell_type":"code","source":"def get_clean_data(df):\n    targets = []\n    paths = []\n    for _, row in df.iterrows():\n        target_np = np.zeros((28))\n        t = [int(t) for t in row.Target.split()]\n        target_np[t] = 1\n        targets.append(target_np)\n        paths.append(row.complete_path)\n    return np.array(paths), np.array(targets)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:18.158202Z","iopub.execute_input":"2021-06-24T20:27:18.158547Z","iopub.status.idle":"2021-06-24T20:27:18.163835Z","shell.execute_reply.started":"2021-06-24T20:27:18.158518Z","shell.execute_reply":"2021-06-24T20:27:18.163028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path, train_target = get_clean_data(train)\nval_path, val_target = get_clean_data(val)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:21.391901Z","iopub.execute_input":"2021-06-24T20:27:21.392247Z","iopub.status.idle":"2021-06-24T20:27:24.470227Z","shell.execute_reply.started":"2021-06-24T20:27:21.392198Z","shell.execute_reply":"2021-06-24T20:27:24.46929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"printing train and val path and target\n\n","metadata":{}},{"cell_type":"code","source":"print(f'Train path shape: {train_path.shape}')\nprint(f'Train target shape: {train_target.shape}')\nprint(f'Val path shape: {val_path.shape}')\nprint(f'Val target shape: {val_target.shape}')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:29.135318Z","iopub.execute_input":"2021-06-24T20:27:29.135633Z","iopub.status.idle":"2021-06-24T20:27:29.140638Z","shell.execute_reply.started":"2021-06-24T20:27:29.135607Z","shell.execute_reply":"2021-06-24T20:27:29.139755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# creating datasets from cleaned data.\n","metadata":{}},{"cell_type":"markdown","source":"This module contains experimental Dataset sources and transformations that can be used in conjunction with the tf.data.Dataset API. Note that the tf.data.experimental API is not subject to the same backwards compatibility guarantees as tf.data, but we will provide deprecation advice in advance of removing existing functionality.","metadata":{}},{"cell_type":"code","source":"train_data = tf.data.Dataset.from_tensor_slices((train_path, train_target))\nval_data = tf.data.Dataset.from_tensor_slices((val_path, val_target))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:33.054239Z","iopub.execute_input":"2021-06-24T20:27:33.054563Z","iopub.status.idle":"2021-06-24T20:27:34.909341Z","shell.execute_reply.started":"2021-06-24T20:27:33.054533Z","shell.execute_reply":"2021-06-24T20:27:34.908522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removes dimensions of size 1 from the shape of a tensor.\n\n","metadata":{}},{"cell_type":"code","source":"def load_data(path, target):\n    red = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_red.png'), channels=1), [2])\n    blue = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_blue.png'), channels=1), [2])\n    green = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_green.png'), channels=1), [2])\n    #yellow=tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_yellow.png'), channels=1), [2])\n    img = tf.stack((\n                red,\n                green,\n                blue), axis=2)\n    return img, target\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_data = train_data.map(load_data, num_parallel_calls=AUTOTUNE)\nval_data = val_data.map(load_data, num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:37.718742Z","iopub.execute_input":"2021-06-24T20:27:37.719057Z","iopub.status.idle":"2021-06-24T20:27:37.866343Z","shell.execute_reply.started":"2021-06-24T20:27:37.719026Z","shell.execute_reply":"2021-06-24T20:27:37.865478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apply Augmnetation by changing in image attribute like Adjust the contrast of an image or images by a random factor.\n\n","metadata":{}},{"cell_type":"code","source":"def image_augment(img, target):\n    img = tf.image.random_contrast(img, lower=0.3, upper=2.0)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_brightness(img, max_delta=0.1)\n    return img, target\n    \ntrain_data = train_data.map(image_augment, num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:42.043063Z","iopub.execute_input":"2021-06-24T20:27:42.043431Z","iopub.status.idle":"2021-06-24T20:27:42.149675Z","shell.execute_reply.started":"2021-06-24T20:27:42.043397Z","shell.execute_reply":"2021-06-24T20:27:42.148864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Better performance with the tf.data API\n","metadata":{}},{"cell_type":"code","source":"train_data_batches = train_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\nval_data_batches = val_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:27:44.694759Z","iopub.execute_input":"2021-06-24T20:27:44.695074Z","iopub.status.idle":"2021-06-24T20:27:44.703357Z","shell.execute_reply.started":"2021-06-24T20:27:44.695044Z","shell.execute_reply":"2021-06-24T20:27:44.70239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model Architecture ","metadata":{}},{"cell_type":"markdown","source":"Using transfer learning and fine tuning on ReaNet50","metadata":{}},{"cell_type":"markdown","source":"# Implementing ResNet50","metadata":{}},{"cell_type":"code","source":"resnet_model = applications.ResNet50(include_top=False, weights='imagenet')\n\nresnet_model.trainable = True\n\ninput_layer = Input(shape=INPUT_SHAPE)\nx = resnet_model(input_layer)\nx = Flatten()(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(28, activation='sigmoid')(x)\nmodel = Model(input_layer, output)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing InceptionResNetV2","metadata":{}},{"cell_type":"code","source":"from keras.applications import InceptionResNetV2\nfrom keras.layers import BatchNormalization\ninception_model = applications.InceptionResNetV2(include_top=False, weights='imagenet')\ninception_model.trainable = True\ninput_tensor = Input(shape=INPUT_SHAPE)\nx = inception_model(input_tensor)\nx = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\nx = Flatten()(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(28, activation='sigmoid')(x)\nmodel = Model(input_tensor, output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:29:09.43918Z","iopub.execute_input":"2021-06-24T20:29:09.439546Z","iopub.status.idle":"2021-06-24T20:29:15.672951Z","shell.execute_reply.started":"2021-06-24T20:29:09.439508Z","shell.execute_reply":"2021-06-24T20:29:15.672196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model compilation ","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['binary_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:30:17.773325Z","iopub.execute_input":"2021-06-24T20:30:17.773668Z","iopub.status.idle":"2021-06-24T20:30:17.802818Z","shell.execute_reply.started":"2021-06-24T20:30:17.773638Z","shell.execute_reply":"2021-06-24T20:30:17.801889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now finally fit the model for trianing ...","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_data_batches, steps_per_epoch = 150, validation_data = val_data_batches, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T20:30:22.764905Z","iopub.execute_input":"2021-06-24T20:30:22.765265Z","iopub.status.idle":"2021-06-24T21:13:11.136712Z","shell.execute_reply.started":"2021-06-24T20:30:22.765213Z","shell.execute_reply":"2021-06-24T21:13:11.135809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizing the Results ","metadata":{}},{"cell_type":"code","source":"binary_accuracy=history.history['binary_accuracy']\nval_binary_accuracy=history.history['val_binary_accuracy']\nepochs=range(1,len(binary_accuracy)+1)\nplt.plot(epochs,binary_accuracy,'b',label='Training accuracy')  \nplt.plot(epochs,val_binary_accuracy,'r',label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:38:27.733922Z","iopub.execute_input":"2021-06-24T21:38:27.734341Z","iopub.status.idle":"2021-06-24T21:38:27.901333Z","shell.execute_reply.started":"2021-06-24T21:38:27.734303Z","shell.execute_reply":"2021-06-24T21:38:27.900553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(1,len(binary_accuracy)+1)\nplt.plot(epochs,loss,'b',label='Training loss')\nplt.plot(epochs,val_loss,'r',label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.figure()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:38:39.206659Z","iopub.execute_input":"2021-06-24T21:38:39.206975Z","iopub.status.idle":"2021-06-24T21:38:39.354401Z","shell.execute_reply.started":"2021-06-24T21:38:39.206945Z","shell.execute_reply":"2021-06-24T21:38:39.353642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('New_model2.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T21:39:04.91082Z","iopub.execute_input":"2021-06-24T21:39:04.911133Z","iopub.status.idle":"2021-06-24T21:39:07.567392Z","shell.execute_reply.started":"2021-06-24T21:39:04.911103Z","shell.execute_reply":"2021-06-24T21:39:07.566548Z"},"trusted":true},"execution_count":null,"outputs":[]}]}