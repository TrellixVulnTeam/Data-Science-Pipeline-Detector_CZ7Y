{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport numpy as np\nimport torch.utils.data as dt\nfrom proteindataset import ProteinDataset\nfrom sklearn.metrics import average_precision_score","metadata":{"execution":{"iopub.status.busy":"2022-03-04T10:30:52.051368Z","iopub.execute_input":"2022-03-04T10:30:52.051636Z","iopub.status.idle":"2022-03-04T10:30:53.21963Z","shell.execute_reply.started":"2022-03-04T10:30:52.051607Z","shell.execute_reply":"2022-03-04T10:30:53.218717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_all_seeds(SEED):\n    # REPRODUCIBILITY\n    torch.manual_seed(SEED)\n    np.random.seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:37:51.846511Z","iopub.execute_input":"2022-03-03T14:37:51.847063Z","iopub.status.idle":"2022-03-03T14:37:51.857423Z","shell.execute_reply.started":"2022-03-03T14:37:51.847026Z","shell.execute_reply":"2022-03-03T14:37:51.856538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = '../input/human-protein-atlas-image-classification/train/'\nTEST_DIR = '../input/human-protein-atlas-image-classification/test/'\nLABELS = '../input/hpa-dataset-models/train_upsampled.csv'\ndataset = ProteinDataset(TRAIN_DIR, LABELS, image_size=512)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:37:56.03153Z","iopub.execute_input":"2022-03-03T14:37:56.031989Z","iopub.status.idle":"2022-03-03T14:37:56.178276Z","shell.execute_reply.started":"2022-03-03T14:37:56.03195Z","shell.execute_reply":"2022-03-03T14:37:56.177531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:37:56.180399Z","iopub.execute_input":"2022-03-03T14:37:56.180688Z","iopub.status.idle":"2022-03-03T14:38:04.986746Z","shell.execute_reply.started":"2022-03-03T14:37:56.180652Z","shell.execute_reply":"2022-03-03T14:38:04.985929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nfrom tqdm import tqdm\n\n# Create dataloaders\nbatch_size = 10\ndataset_len = dataset.__len__()\ntrain_size = int(dataset_len*0.8)\nif train_size % batch_size==1:\n        train_size += 1\n\nval_size = dataset_len - train_size\ntrain_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n    \ntrainloader = dt.DataLoader(train_set, batch_size=batch_size)\ntestloader = dt.DataLoader(val_set, batch_size=batch_size)   \n\n# paramaters\nSEED = 123\nlr = 1e-3\nweight_decay = 1e-5\n\n# model\nset_all_seeds(SEED)\nmodel= timm.create_model('efficientnet_b4',pretrained=True,num_classes=28,in_chans=4)\nmodel.load_state_dict(torch.load('../input/hpa-dataset-models/modified_pretrained_model_kaggle_2_1_last.pth'))\nmodel = model.cuda()\n\n# define loss & optimizer\ncriterion = torch.nn.BCEWithLogitsLoss().cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7, verbose=True)\n# training\nbest_val_score = 0 \nfor epoch in range(10):\n    model.train()\n    batch_index = 0\n    epoch_loss = []\n    for data in tqdm(trainloader):\n        batch_index +=1\n        train_data, train_labels = data\n        train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n        y_pred = model(train_data)\n        loss = criterion(y_pred, train_labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n          \n        epoch_loss.append(loss.item())\n        torch.save(model.state_dict(), f'model_kaggle_{epoch}.pth')\n        # validation  \n    test_loss=[]\n    model.eval()\n    with torch.no_grad():    \n        test_pred = []\n        test_true = [] \n        for data in tqdm(testloader):\n                    test_data, test_labels = data\n                    test_data = test_data.cuda()\n                    test_labels = test_labels.cuda()\n                    y_pred = model(test_data)\n                    test_batch_loss = criterion(y_pred, test_labels)\n                    test_loss.append(test_batch_loss.item())\n                    y_pred = torch.sigmoid(y_pred)\n                    test_pred.append(y_pred.cpu().detach().numpy())\n                    test_true.append(test_labels.cpu().detach().numpy())\n                    \n                    \n        test_true = np.concatenate(test_true)\n        test_pred = np.concatenate(test_pred)\n        val_metric =  average_precision_score(test_true, test_pred, average='macro') \n        model.train()\n\n        if best_val_score < val_metric:\n            best_val_score = val_metric\n            torch.save(model.state_dict(), f'model_kaggle_best.pth')\n\n        print ('Epoch=%s, Val_average_precision_score=%.4f, Best_Val_score=%.4f'%(epoch, val_metric, best_val_score ))\n    scheduler.step() \n    print (f\"Epoch loss {np.mean(epoch_loss)}     Val loss {np.mean(test_loss)}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T14:50:42.972027Z","iopub.execute_input":"2022-03-03T14:50:42.972277Z","iopub.status.idle":"2022-03-03T20:28:55.640723Z","shell.execute_reply.started":"2022-03-03T14:50:42.972248Z","shell.execute_reply":"2022-03-03T20:28:55.639995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=weight_decay)\n\n# training\nbest_val_score = 0 \nfor epoch in range(5):\n    model.train()\n    batch_index = 0\n    epoch_loss = []\n    for data in tqdm(trainloader):\n        batch_index +=1\n        train_data, train_labels = data\n        train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n        y_pred = model(train_data)\n        loss = criterion(y_pred, train_labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n          \n        epoch_loss.append(loss.item())\n        torch.save(model.state_dict(), f'modified_pretrained_model_kaggle_2_{epoch}.pth')\n        # validation  \n    test_loss=[]\n    model.eval()\n    with torch.no_grad():    \n        test_pred = []\n        test_true = [] \n        for data in tqdm(testloader):\n                    test_data, test_labels = data\n                    test_data = test_data.cuda()\n                    test_labels = test_labels.cuda()\n                    y_pred = model(test_data)\n                    test_batch_loss = criterion(y_pred, test_labels)\n                    test_loss.append(test_batch_loss.item())\n                    y_pred = torch.sigmoid(y_pred)\n                    test_pred.append(y_pred.cpu().detach().numpy())\n                    test_true.append(test_labels.cpu().detach().numpy())\n                    \n                    \n        test_true = np.concatenate(test_true)\n        test_pred = np.concatenate(test_pred)\n        val_metric =  average_precision_score(test_true, test_pred, average='macro') \n        model.train()\n\n        if best_val_score < val_metric:\n            best_val_score = val_metric\n            torch.save(model.state_dict(), f'modified_pretrained_model_kaggle_best.pth')\n\n        print ('Epoch=%s, Val_average_precision_score=%.4f, Best_Val_score=%.4f'%(epoch, val_metric, best_val_score ))\n    print (f\"Epoch loss {np.mean(epoch_loss)}     Val loss {np.mean(test_loss)}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-03T20:29:34.76912Z","iopub.execute_input":"2022-03-03T20:29:34.769373Z"},"trusted":true},"execution_count":null,"outputs":[]}]}