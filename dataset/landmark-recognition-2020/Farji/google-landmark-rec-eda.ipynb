{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Google Landmark Recognition 2020 EDA**\n\nThis notebook is intended to give an introduction of the competition so that people can do more interesting stuffs after familiarizing with the data using this notebook.\nNo meta data is given which confines EDA to only images and labels given.\n\nWhat the Notebook contains:\n\n* Introduction\n* Class Distribution\n* Contours of Train Images\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import required libs\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom skimage.transform import resize\nfrom skimage.measure import find_contours\nplt.style.use('ggplot')\nimport tensorflow as tf\nimport gc\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# File paths \ntrain_img = np.array(tf.io.gfile.glob('../input/landmark-recognition-2020/train/*/*/*/*.jpg'))\ntest_img = np.array(tf.io.gfile.glob('../input/landmark-recognition-2020/test/*/*/*/*.jpg'))\n\nprint('There are %i images in train and %i images in test'%(len(train_img),len(test_img)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# load labels\nlabel = pd.read_csv('../input/landmark-recognition-2020/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a first look\nprint(label.info())\nlabel.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show few images from both train and test\ndef plot_img(img_files, show_label= False):\n    \"\"\"Show 9 images from img_files\"\"\"\n    plt.figure(figsize=(10, 10))\n    for i, img_file in enumerate(np.random.choice(img_files, size= np.min([len(img_files), 9]), replace= False)):\n        ax = plt.subplot(3, 3, i + 1)\n        img = plt.imread(img_file)\n        img = resize(img, (256, 256), anti_aliasing= True)\n        plt.imshow(img)\n        plt.axis(\"off\")\n        if show_label:\n            img_name = img_file.split('/')[-1].split('.')[-2]\n            img_label = label[label['id'] == img_name]['landmark_id'].values[0]\n            plt.title('Class: ' + str(img_label))\n        # save memory\n        del(img)\n        gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train images\nprint('TRAIN IMAGES')\nplot_img(train_img, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test images\nprint('TEST IMAGES')\nplot_img(test_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking duplicates\nprint('Fraction of unique train images: ', len(label['id'].unique())/len(label))\nprint('Total number of classes: ', len(label['landmark_id'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class distribution\nlabel['landmark_id'].astype('category').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# top class distribution\nfig, ax = plt.subplots(figsize= (12,6))\ntop_class = label['landmark_id'].value_counts().iloc[:30].reset_index()\nsns.barplot(x= 'index', y= 'landmark_id', data= top_class, ax= ax, palette= 'rocket')\nfig.autofmt_xdate()\nplt.xlabel('Image Class')\nplt.ylabel('Frequency')\nplt.margins(0.05)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top images and Contours\n\nIt takes quite a while to find these contours.\nAlso I have used roughly 1/5 of total train images, again because of memory and time constraints.\n\nI took a random sample out of train data so we can approximate our findings to actual dataset of 1.6M images.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find contours in images\n\"\"\"cont_train = pd.DataFrame({\n    'contours': np.zeros(50000)})\nlabels= []\nrandom_sample = np.random.choice(train_img, size= 50000, replace= False)\nfor i, img_file in tqdm(enumerate(random_sample)):\n    img = plt.imread(img_file)\n    img = tf.image.rgb_to_grayscale(img)\n    img = img.numpy().reshape((img.shape[0], img.shape[1]))\n    cont_train['contours'][i] = len(find_contours(img, level= 100))\n    labels.append(label[label['id'] == img_file.split('/')[-1].split('.')[0]]['landmark_id'])\n    # save memory\n    del(img)\n    gc.collect()\n\ncont_train['label'] = labels\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_train = pd.read_csv('../input/train-data-contours/train_contours.csv')\ncont_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = label['landmark_id'].value_counts().sort_values(ascending= False)\n\ntop_class = counts.index[:50].values\ntop_class_df = cont_train[cont_train['label'].isin(top_class).values]\n\nfig, ax = plt.subplots(figsize= (16,4))\nsns.pointplot(x= 'label', y= 'contours', data= top_class_df, ax= ax)\nfig.autofmt_xdate()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you are confused what these contours actually look like in the image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img_name = train_img[13].split('/')[-1].split('.')[0]\nimg = label[label['id'] == img_name]\nsame_imgs = label[label['landmark_id'] == img['landmark_id'].values[0]]\nfor i in same_imgs['id']:\n    img_path = '../input/landmark-recognition-2020/train/' + i[0] + '/' + i[1] + '/' + i[2] + '/' + i + '.jpg'\n    img = plt.imread(img_path)\n    img = tf.image.rgb_to_grayscale(img)\n    img = img.numpy().reshape((img.shape[0], img.shape[1]))\n    conts = find_contours(img, level= 100)\n\n    fig, ax = plt.subplots(1,2, figsize= (10,10))\n    ax[0].imshow(img)\n    ax[0].axis('off')\n\n    ax[1].imshow(img)\n    for cont in conts:\n        ax[1].plot([val[1] for val in cont], [val[0] for val in cont])\n        ax[1].set_title('Number of Contours %i'%len(conts))\n    plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show contours in a test image\nimg = plt.imread(test_img[4])\nimg = tf.image.rgb_to_grayscale(img)\nimg = img.numpy().reshape((img.shape[0], img.shape[1]))\nconts = find_contours(img, level= 100)\n\nfig, ax = plt.subplots(1,2, figsize= (20,20))\nax[0].imshow(img)\nax[0].axis('off')\n\nax[1].imshow(img)\nfor cont in conts:\n    ax[1].plot([val[1] for val in cont], [val[0] for val in cont])\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Images having highest number of instances in train data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_class = label['landmark_id'].value_counts().reset_index()\ntop_class.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_img = label[label['landmark_id'] == 126637][:4].reset_index()\n\ndef make_path(image_name):\n    img_path = '../input/landmark-recognition-2020/train/' + image_name[0] + '/' + image_name[1] + '/' + image_name[2] + '/' + image_name + '.jpg'\n    return img_path\nfreq_img['path'] = freq_img['id'].apply(make_path)\nplot_img(freq_img['path'].values, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_img = label[label['landmark_id'] == 126637][:4].reset_index()\n\ndef make_path(image_name):\n    img_path = '../input/landmark-recognition-2020/train/' + image_name[0] + '/' + image_name[1] + '/' + image_name[2] + '/' + image_name + '.jpg'\n    return img_path\nfreq_img['path'] = freq_img['id'].apply(make_path)\nplot_img(freq_img['path'].values, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_img = label[label['landmark_id'] == 20409][:4].reset_index()\n\ndef make_path(image_name):\n    img_path = '../input/landmark-recognition-2020/train/' + image_name[0] + '/' + image_name[1] + '/' + image_name[2] + '/' + image_name + '.jpg'\n    return img_path\nfreq_img['path'] = freq_img['id'].apply(make_path)\nplot_img(freq_img['path'].values, True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}