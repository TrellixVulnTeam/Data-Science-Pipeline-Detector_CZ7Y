{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport numpy as np\nimport imageio\nimport torch\n\nimport sys\n\nimport scipy\nimport scipy.io\nimport scipy.misc\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/landmark-recognition-2020/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Support functions\ndef get_path_to_image(id_, base_folder='../input/landmark-recognition-2020/train'):\n    return os.path.join(base_folder, id_[0], id_[1], id_[2], id_ + '.jpg')\n    \ndef get_list_of_id_by_landmark_id(df, landmark_id):\n    return df.loc[df['landmark_id'] == landmark_id]['id'].values\n\ndef get_first_id_by_landmark_id(df, landmark_id):\n    return df.loc[df['landmark_id'] == landmark_id]['id'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"landmark_id_set = list(set(train_df['landmark_id'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('lenght of training images set (unique landmark id)', len(landmark_id_set))\nf = open('images_train.txt', 'w')\nfor i in range(len(landmark_id_set) // 100):\n    image_path = get_path_to_image(get_first_id_by_landmark_id(train_df, landmark_id_set[i]))\n    f.write(image_path + '\\n')\n#     print('{}/{}'.format(i, len(landmark_id_set)), end='\\r')\nf.close()\n\npath_to_test = '../input/landmark-recognition-2020/test'\nf = open('images_test.txt', 'w')\nfor root, dirs, files in os.walk(path_to_test, topdown=False):\n   for name in files:\n    image_path = get_path_to_image(name.split('.')[0], base_folder='../input/landmark-recognition-2020/test')\n    f.write(image_path + '\\n')\nf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsys.path.append('../input/googlelandmarkd2netmodel/d2_net')\n\nfrom lib.model_test import D2Net\nfrom lib.utils import preprocess_image\nfrom lib.pyramid import process_multiscale\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n\n\n# # Process the file\npreprocessing = 'caffe'\nmodel_file = '../input/googlelandmarkd2netmodel/d2_net/models/d2_tf.pth'\nmax_edge = 1600\nmax_sum_edges = 2800\nmultiscale = False\nuse_relu = True\n\n# Creating CNN model\nmodel = D2Net(\n    model_file=model_file,\n    use_relu=use_relu,\n    use_cuda=use_cuda\n)\n\ndef predict(path):\n    image = imageio.imread(path)\n    if len(image.shape) == 2:\n        image = image[:, :, np.newaxis]\n        image = np.repeat(image, 3, -1)\n\n    # TODO: switch to PIL.Image due to deprecation of scipy.misc.imresize.\n    resized_image = image\n    if max(resized_image.shape) > max_edge:\n        resized_image = scipy.misc.imresize(\n            resized_image,\n            max_edge / max(resized_image.shape)\n        ).astype('float')\n    if sum(resized_image.shape[: 2]) > max_sum_edges:\n        resized_image = scipy.misc.imresize(\n            resized_image,\n            max_sum_edges / sum(resized_image.shape[: 2])\n        ).astype('float')\n\n    fact_i = image.shape[0] / resized_image.shape[0]\n    fact_j = image.shape[1] / resized_image.shape[1]\n\n    input_image = preprocess_image(\n        resized_image,\n        preprocessing=preprocessing\n    )\n    with torch.no_grad():\n        if multiscale:\n            keypoints, scores, descriptors = process_multiscale(\n                torch.tensor(\n                    input_image[np.newaxis, :, :, :].astype(np.float32),\n                    device=device\n                ),\n                model\n            )\n        else:\n            keypoints, scores, descriptors = process_multiscale(\n                torch.tensor(\n                    input_image[np.newaxis, :, :, :].astype(np.float32),\n                    device=device\n                ),\n                model,\n                scales=[1]\n            )\n\n    # Input image coordinates\n    keypoints[:, 0] *= fact_i\n    keypoints[:, 1] *= fact_j\n    # i, j -> u, v\n    keypoints = keypoints[:, [1, 0, 2]]\n    return keypoints, scores, descriptors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = predict('../input/landmark-recognition-2020/train/0/0/0/0000059611c7d079.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !python3 d2-net/extract_features.py --image_list_file images_train.txt --model_file d2-net/models/d2_tf.pth  --output_path='train_data'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !python3 d2-net/extract_features.py --image_list_file images_test.txt --model_file d2-net/models/d2_tf.pth  --output_path='test_data'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import cv2\n# import csv\n\n# def load_labelmap(path='../input/landmark-recognition-2020/train.csv'):\n#   with open(path, mode='r') as csv_file:\n#     csv_reader = csv.DictReader(csv_file)\n#     labelmap = {row['id']: row['landmark_id'] for row in csv_reader}\n\n#   return labelmap\n\n# def to_hex(image_id) -> str:\n#   return '{0:0{1}x}'.format(image_id, 16)\n\n# def save_submission_csv(predictions=None):\n#   \"\"\"Saves optional `predictions` as submission.csv.\n\n#   The csv has columns {id, landmarks}. The landmarks column is a string\n#   containing the label and score for the id, separated by a ws delimeter.\n\n#   If `predictions` is `None` (default), submission.csv is copied from\n#   sample_submission.csv in `IMAGE_DIR`.\n\n#   Args:\n#     predictions: Optional dict of image ids to dicts with keys {class, score}.\n#   \"\"\"\n\n#   if predictions is None:\n#     # Dummy submission!\n#     shutil.copyfile(\n#         os.path.join(DATASET_DIR, 'sample_submission.csv'), 'submission.csv')\n#     return\n\n#   with open('submission.csv', 'w') as submission_csv:\n#     csv_writer = csv.DictWriter(submission_csv, fieldnames=['id', 'landmarks'])\n#     csv_writer.writeheader()\n#     for image_id, prediction in predictions.items():\n#       label = prediction['class']\n#       score = prediction['score']\n#       csv_writer.writerow({'id': image_id, 'landmarks': f'{label} {score}'})\n\n# def match_descriptors(kp1, desc1, kp2, desc2):\n#     # Match the keypoints with the warped_keypoints with nearest neighbor search\n#     bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n#     matches = bf.match(desc1, desc2)\n#     matches_idx1 = np.array([m.queryIdx for m in matches])\n#     m_kp1 = [kp1[idx] for idx in matches_idx1]\n#     matches_idx2 = np.array([m.trainIdx for m in matches])\n#     m_kp2 = [kp2[idx] for idx in matches_idx2]\n\n\n#     return m_kp1, m_kp2, matches\n\n# def compute_homography(matched_kp1, matched_kp2):\n# #     matched_pts1 = cv2.KeyPoint_convert(matched_kp1)\n# #     matched_pts2 = cv2.KeyPoint_convert(matched_kp2)\n#     matched_kp1 = np.array(matched_kp1)\n#     matched_kp2 = np.array(matched_kp2)\n#     # Estimate the homography between the matches using RANSAC\n\n#     H, inliers = cv2.findHomography(matched_kp1,\n#                                     matched_kp2,\n#                                     cv2.RANSAC)\n#     inliers = inliers.flatten()\n\n#     return H, inliers\n\n# def get_scores(kp1, kp2, m_kp1, m_kp2, desc1, desc2, matches):\n#     x, y = 0, 0\n    \n#     m_desc1 = np.zeros((len(matches), 512), dtype='float')\n#     m_desc2 = np.zeros((len(matches), 512), dtype='float')\n#     data1 = np.zeros((len(matches), 2), dtype='int')\n#     data2 = np.zeros((len(matches), 2), dtype='int')\n#     for idx, mat in enumerate(matches):\n#         img1_idx = mat.queryIdx\n#         img2_idx = mat.trainIdx\n#         m_desc1[idx,:] = desc1[img1_idx]\n#         m_desc2[idx,:] = desc2[img2_idx]\n    \n#         (x1, y1, _) = kp1[img1_idx]\n#         (x2, y2, _) = kp2[img2_idx]\n#         dx = x2\n#         dy = y2\n#         x += x1 - dx\n#         y += y1 - dy\n#         data1[idx, :] = [x1, y1]\n#         data2[idx, :] = [x2, y2]\n\n# #     data3 = np.zeros((len(kp2), 2), dtype='int')\n# #     for idx, kp in enumerate(kp2):\n# #         (x3, y3, _) = kp\n# #         data3[idx, :] = [x3, y3]\n\n#     sigma1 = np.var(data1, axis=0)\n#     sigma1 = sigma1[0] / sigma1[1]\n#     sigma2 = np.var(data2, axis=0)\n#     sigma2 = sigma2[0] / sigma2[1]\n\n\n#     p = (len(m_kp2)) / (len(kp2) + 0.0001)\n#     score = p*np.sqrt(sigma1 / sigma2) if sigma1 < sigma2 else p*np.sqrt(sigma2 / sigma1)\n#     score2 = (2*sigma1*sigma2) / (sigma1**2 + sigma2**2)\n#     score3 = 100*2*len(matches) / (len(kp2) + len(kp1))\n#     cosine = 1 - (np.dot(m_desc1.flatten(), m_desc2.flatten())/(np.linalg.norm(m_desc1.flatten())*np.linalg.norm(m_desc2.flatten())))\n#     print('p, res_c: ', p)\n#     print('score: ', score, score2, np.linalg.norm(data1-data2), len(matches), score3, cosine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labelmap = load_labelmap()\n# for name in os.listdir('0')[0]:\n#     npz_file = np.load(os.path.join('0', name))\n#     desc2 = npz_file['descriptors']\n#     kp2 = npz_file['keypoints']\n#     scores2 = npz_file['scores']\n\n#     for name2 in os.listdir('0')[:2]:\n#         npz_file = np.load(os.path.join('0', name2))\n#         desc1 = npz_file['descriptors']\n#         kp1 = npz_file['keypoints']\n#         scores1 = npz_file['scores']\n        \n#         train_id = name2.split('.')[0]\n#         label = labelmap[train_id]\n                         \n#         m_kp1, m_kp2, matches = match_descriptors(kp1, desc1, kp2, desc2)\n#         H, inliers = compute_homography(m_kp1, m_kp2)\n#         matches = np.array(matches)[inliers.astype(bool)].tolist()\n\n#         print('0' + '0', label)\n#         get_scores(kp1, kp2, m_kp1, m_kp2, m_desc1, m_desc2, matches)\n\n#     for name2 in os.listdir('1'):\n#         npz_file = np.load(os.path.join('1', name2))\n#         desc1 = npz_file['descriptors']\n#         kp1 = npz_file['keypoints']\n#         scores1 = npz_file['scores']\n        \n#         train_id = name2.split('.')[0]\n#         label = labelmap[train_id]\n    \n#         m_kp1, m_kp2, matches = match_descriptors(kp1, desc1, kp2, desc2)\n#         H, inliers = compute_homography(m_kp1, m_kp2)\n#         matches = np.array(matches)[inliers.astype(bool)].tolist()\n#         print('0' + '1', label)\n#         get_scores(kp1, kp2, m_kp1, m_kp2, desc1, desc2, matches)\n#     print('#'*20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}