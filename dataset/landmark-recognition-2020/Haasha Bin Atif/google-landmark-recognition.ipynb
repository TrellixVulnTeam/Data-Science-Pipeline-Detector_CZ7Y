{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install --no-deps '../input/evaluations/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport random\nimport numpy as np\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport os\nimport multiprocessing\nfrom scipy import stats\nfrom torch.utils.data import Dataset,DataLoader\nfrom time import perf_counter\nimport PIL\nfrom PIL import Image, ImageDraw\n#from evaluations.kaggle_2020 import global_average_precision_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"IN_KERNEL = os.environ.get('KAGGLE_WORKING_DIR') is not None\n#MIN_SAMPLES_PER_CLASS = 150\nBATCH_SIZE = 64\nNUM_WORKERS = multiprocessing.cpu_count()\n#MAX_STEPS_PER_EPOCH = 15000\nNUM_EPOCHS = 1\nGPU = torch.cuda.is_available()\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nTRAIN_DIR = '../input/landmark-recognition-2020/train/'\nTEST_DIR = '../input/landmark-recognition-2020/test/'\n#LOG_FREQ = 10\n#NUM_TOP_PREDICTS = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Helper Functions\ndef getPath(FileName,train_dir):\n    Path = FileName + \".jpg\"\n    for i in range(2,-1,-1):\n        Path = os.path.join(FileName[i],Path)\n    Path = os.path.join(train_dir, Path)\n    return Path\ndef imshow(img):\n    #img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\ndef display_images(images, title=None): \n    f, ax = plt.subplots(5,5, figsize=(18,22))\n    if title:\n        f.suptitle(title, fontsize = 30)\n\n    for i, image_id in enumerate(images):\n        image_path = os.path.join(TRAIN_DIR, f'{image_id[0]}/{image_id[1]}/{image_id[2]}/{image_id}.jpg')\n        image = Image.open(image_path)\n        \n        ax[i//5, i%5].imshow(image) \n        image.close()       \n        ax[i//5, i%5].axis('off')\n\n        landmark_id = train[train.id==image_id.split('.')[0]].landmark_id.values[0]\n        ax[i//5, i%5].set_title(f\"ID: {image_id.split('.')[0]}\\nLandmark_id: {landmark_id}\", fontsize=\"12\")\n    plt.show()\ndef getModel(Name, OutFeatures):\n    if Name == \"AlexNet\":\n        model = torchvision.models.alexnet()\n        model.classifier[6] = nn.Linear(4096,OutFeatures,bias=True)\n    elif Name==\"VGG16\":\n        model = torchvision.models.vgg16()\n        model.classifier[6] = nn.Linear(4096,OutFeatures,bias=True)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Reading Files...\")\ntrain = pd.read_csv('../input/landmark-recognition-2020/train.csv')\ntest = pd.read_csv('../input/landmark-recognition-2020/sample_submission.csv')\nprint(\"Reading Completed.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/landmark-recognition-2020/train.csv', index_col=0)\nCorrect_Labels = df_train.to_dict()['landmark_id']\n#Predicted_Labels = {key: (item, random.random()) for key, item in Correct_Labels.items()}\n#global_average_precision_score(Correct_Labels, Predicted_Labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(Correct_Labels['0000059611c7d079'], Predicted_Labels['0000059611c7d079'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Creating Dictionary & LandMarkIDs...\")\nTrain_List = train.values\nTest_List = test.values\nTrain_Dict = {}\nfor Row in Train_List:\n    if str(Row[1]) not in Train_Dict:\n        Train_Dict[str(Row[1])] = [Row[0]]\n    else:\n        Train_Dict[str(Row[1])].append(Row[0])\nLandMarkIDs = np.unique(Train_List[:,1])\nprint(\"Creation Successful.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Images_Per_Landmark = np.unique(train['landmark_id'].tolist(),return_counts=True)\nprint(\"Description of Dataset\")\nprint(\"Number of Landmarks:\",len(train.landmark_id.unique()))\nprint(\"#OfImages Per LandmarkID\")\nprint(\"     Min:\",min(Images_Per_Landmark[1]))\nprint(\"     Max:\",max(Images_Per_Landmark[1]))\nprint(\"     Mean:\",np.mean(Images_Per_Landmark[1]))\nprint(\"     Median:\",np.median(Images_Per_Landmark[1]))\nprint(\"     Mode:\",stats.mode(Images_Per_Landmark[1])[0][0])\nprint(\"#OfTestImages:\",len(test))\nprint(\"\\n\")\nprint(train.head())\nplt.hist(train.landmark_id,bins=1000)\nplt.title('Histogram of number of images per Landmark ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(\"Displaying some Landmarks...\")\n#samples = train.sample(25).id.values\n#display_images(samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetrievalData(Dataset):\n    def __init__(self, Directory, FileNames, Transform, CorrectLabels, Images_Per_Landmark):\n        self.directory = Directory\n        self.filenames = FileNames\n        self.transform = Transform\n        self.correctlabels = CorrectLabels\n        self.images_per_landmark = Images_Per_Landmark\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self,index):\n        x = Image.open(getPath(self.filenames[index],self.directory))\n        if \"train\" in self.directory:\n            if self.transform is not None:\n                return self.transform(x),np.where(self.images_per_landmark[0]==self.correctlabels[self.filenames[index]])[0][0]\n            return x,np.where(self.images_per_landmark[0]==self.correctlabels[self.filenames[index]])[0][0]\n        elif \"test\" in self.directory:\n            if self.transform is not None:\n                return self.transform(x),self.filenames[index]\n            return x,self.filenames[index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Transform = transformations = transforms.Compose([\n                                        transforms.Resize((256, 256)),\n                                        transforms.ToTensor(),\n                                     ])\nTrain_dataset = RetrievalData(TRAIN_DIR, Train_Dict['9'],Transform,Correct_Labels, Images_Per_Landmark)\nTrain_loader=DataLoader(Train_dataset, batch_size=4,num_workers=4)\n\nfor i,data in enumerate(Train_loader):\n    image,Names = data\n    print(' '.join('%5s' % j for j in Names))\n    imshow(torchvision.utils.make_grid(image))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, criterion, optimizer, loader, epochs=10):\n    model.to(DEVICE)\n    criterion.to(DEVICE)\n    epoch_losses = []\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for i,data in enumerate(loader):\n            images,labels = data\n            images = images.to(DEVICE)\n            labels = labels.to(DEVICE)\n            optimizer.zero_grad()\n            pred = model(images)\n            loss = criterion(pred,labels)\n            if i%500==499:\n                break\n            running_loss+=loss.item()\n            loss.backward()\n            optimizer.step()\n        break\n        epoch_losses.append(running_loss/len(loader))\n        print(\"Epoch#\"+str(epoch+1).zfill(2)+\"/\"+str(epochs),\"Loss:\",epoch_losses[epoch])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate_model(model,loader,FinalLayer):\n    model.to(DEVICE)\n    criterion.to(DEVICE)\n    model.eval()\n    for i,data in enumerate(loader):\n        images,labels = data.to(DEVICE)\n        pred = model(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference_model(model,loader):\n    softmax = nn.Softmax(1)\n    model.to(DEVICE)\n    model.eval()\n    with torch.no_grad():\n        with open(\"submission.csv\",\"w\") as File:\n            File.write(\"id,landmarks\\n\")\n            for i,data in enumerate(loader):\n                images,FileNames = data\n                images = images.to(DEVICE)\n                \n                pred = softmax(model(images))\n                if GPU:\n                    pred = pred.to(\"cpu\")\n                pred = pred.numpy()\n                for j in range(len(FileNames)):\n                    Index = np.where(pred[j]==max(pred[j]))[0][0]\n                    File.write(FileNames[j]+\",\"+str(Images_Per_Landmark[0][Index])+ \" \"+ str(pred[j][Index])+\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n    \n    Start = perf_counter()\n    print(\"Started...\")\n    Transform = transformations = transforms.Compose([\n                                        transforms.Resize((256, 256)),\n                                        transforms.ToTensor(),\n                                     ])\n    Train_dataset = RetrievalData(TRAIN_DIR, Train_List[:,0], Transform, Correct_Labels,Images_Per_Landmark)\n    Train_loader = DataLoader(Train_dataset, batch_size=128,shuffle=True, num_workers=NUM_WORKERS)\n    print(\"Minibatches in Train_Loader:\",len(Train_loader))\n    #Code for Training, Validation, Inference + Submission\n    model = getModel(\"AlexNet\",81313)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr = 0.000001)\n    \n    model = train_model(model,criterion,optimizer,Train_loader,1)\n\n    Test_dataset = RetrievalData(TEST_DIR,Test_List[:,0] , Transform, Correct_Labels, Images_Per_Landmark)\n    Test_loader = DataLoader(Test_dataset, batch_size=128,shuffle=False, num_workers=NUM_WORKERS)\n    inference_model(model,Test_loader)\n    Finish = perf_counter()\n    print(\"Ended.\")\n    print(\"Time Taken:\",Finish-Start, \"seconds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission = pd.read_csv(\"./submission.csv\")\nSubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}