{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction\n\nGoogle Landmark Recognition is an image classification challenges like the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), which aims to recognize `1K` general object categories. Landmark recognition is a little different from that: it contains a much larger number of classes (there are more than `81K classes` in this challenge), and the number of training examples per class may not be very large. Landmark recognition is challenging in its own way.\n\n\n![](https://miro.medium.com/max/1280/1*OVP48VCImepxkHl7AVzkug.png)\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1.1 What's new in this year competition\n\nIn the previous editions of this challenge (2018 and 2019), submissions were handled by uploading prediction files to the system. This year's competition is structured in a synchronous rerun format, where participants need to submit their Kaggle notebooks for scoring.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Preliminaries\n\n**Now Let's Begin by Importing the data**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\n\nimport random\nimport seaborn as sns\nimport cv2\n\n# General packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nimport IPython.display as ipd\nimport glob\nimport h5py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom PIL import Image\nfrom tempfile import mktemp\n\nfrom bokeh.layouts import column, row\nfrom bokeh.models import ColumnDataSource, LinearAxis, Range1d\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.palettes import BuGn4\nfrom bokeh.plotting import figure, output_notebook, show\nfrom bokeh.transform import cumsum\nfrom math import pi\n\noutput_notebook()\n\n\nfrom IPython.display import Image, display\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.listdir('../input/landmark-recognition-2020/')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Loading Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = '../input/landmark-recognition-2020'\n\nTRAIN_DIR = f'{BASE_PATH}/train'\nTEST_DIR = f'{BASE_PATH}/test'\n\nprint('Reading data...')\ntrain = pd.read_csv(f'{BASE_PATH}/train.csv')\nsubmission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\nprint('Reading data completed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The dataset comprises of following important files:\n\n* **train.csv**: This file contains, ids and targets\n    * `id`: image id\n    * `landmark_id`: target landmark id\n    \n\n* The training set is available in the `train/` folder, with corresponding landmark labels in `train.csv`. \n* The test set images are listed in the `test/` folder. Each image has a unique id. \n\n> Note: Since there are a large number of images, each image is placed within three subfolders according to the first three characters of the image id (i.e. image abcdef.jpg is placed in a/b/c/abcdef.jpg).\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.head())\nprint(\"Shape of train_data :\", train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(submission.head())\nprint(\"Shape of submission :\", submission.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Let's perform some EDA\n\n\n### 3.1 Target Distribution (Number of images per landmark_id)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying only top 30 landmark\nlandmark = train.landmark_id.value_counts()\nlandmark_df = pd.DataFrame({'landmark_id':landmark.index, 'frequency':landmark.values}).head(30)\n\nlandmark_df['landmark_id'] =   landmark_df.landmark_id.apply(lambda x: f'landmark_id_{x}')\n\nfig = px.bar(landmark_df, x=\"frequency\", y=\"landmark_id\",color='landmark_id', orientation='h',\n             hover_data=[\"landmark_id\", \"frequency\"],\n             height=1000,\n             title='Number of images per landmark_id (Top 30 landmark_ids)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inference**\n\n* There are 81313 unique landmark_ids\n* There is only one landmark which has more than 2300 images (landmark_id: 138982)\n* Number of images per landmark_id ranges from 2 to 6272.\n* Out of 81313, there are 79298 (97.5%) landmark_ids with less than 100 images.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4. Let's visualize few images","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Visualizing random images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nfrom PIL import Image, ImageDraw\n\n\ndef display_images(images, title=None): \n    f, ax = plt.subplots(5,5, figsize=(18,22))\n    if title:\n        f.suptitle(title, fontsize = 30)\n\n    for i, image_id in enumerate(images):\n        image_path = os.path.join(TRAIN_DIR, f'{image_id[0]}/{image_id[1]}/{image_id[2]}/{image_id}.jpg')\n        image = Image.open(image_path)\n        \n        ax[i//5, i%5].imshow(image) \n        image.close()       \n        ax[i//5, i%5].axis('off')\n\n        landmark_id = train[train.id==image_id.split('.')[0]].landmark_id.values[0]\n        ax[i//5, i%5].set_title(f\"ID: {image_id.split('.')[0]}\\nLandmark_id: {landmark_id}\", fontsize=\"12\")\n\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train.sample(25).id.values\ndisplay_images(samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Visualizing landmark with most number of images (landmark_id: 138982)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train.landmark_id == 138982].sample(25).id.values\n\ndisplay_images(samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Visualizing landmark with 2nd most number of images (landmark_id: 126637)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train.landmark_id == 126637].sample(25).id.values\n\ndisplay_images(samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.4 Visualizing landmark with 3rd most number of images (landmark_id: 20409)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train.landmark_id == 20409].sample(25).id.values\n\ndisplay_images(samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.5 Visualizing landmark with 4th most number of images (landmark_id: 83144)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train.landmark_id == 83144].sample(25).id.values\n\ndisplay_images(samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <p><span style=\"color:green\">This Kernel is work in progress, will update as competition progresses :) </br></span></p>\n\n### <p><span style=\"color:red\"><br>Please upvote this kernel if you like it . It motivates me to produce more quality content :)</br></span></p>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}