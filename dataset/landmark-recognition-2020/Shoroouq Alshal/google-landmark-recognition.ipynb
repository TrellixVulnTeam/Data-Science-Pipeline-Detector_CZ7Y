{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-18T23:30:18.282419Z","iopub.execute_input":"2022-04-18T23:30:18.282732Z","iopub.status.idle":"2022-04-18T23:30:30.95153Z","shell.execute_reply.started":"2022-04-18T23:30:18.282653Z","shell.execute_reply":"2022-04-18T23:30:30.94914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense\nfrom keras import Model\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model, Model\nimport tensorflow as tf\nfrom collections import Counter\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:27:13.513768Z","iopub.execute_input":"2022-05-06T11:27:13.514403Z","iopub.status.idle":"2022-05-06T11:27:19.657808Z","shell.execute_reply.started":"2022-05-06T11:27:13.514298Z","shell.execute_reply":"2022-05-06T11:27:19.657008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_df=pd.read_csv('../input/landmark-recognition-2020/train.csv')\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:27:19.659539Z","iopub.execute_input":"2022-05-06T11:27:19.659799Z","iopub.status.idle":"2022-05-06T11:27:21.012567Z","shell.execute_reply.started":"2022-05-06T11:27:19.659764Z","shell.execute_reply":"2022-05-06T11:27:21.011864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmark_counts=pd.value_counts(train_df[\"landmark_id\"])\nlandmark_counts=landmark_counts.reset_index()\nlandmark_counts.rename(columns={\"index\":'landmark_ids','landmark_id':'count'},inplace=True)\nlandmark_counts","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:43:42.42179Z","iopub.execute_input":"2022-05-06T11:43:42.422217Z","iopub.status.idle":"2022-05-06T11:43:42.502729Z","shell.execute_reply.started":"2022-05-06T11:43:42.422176Z","shell.execute_reply":"2022-05-06T11:43:42.502093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"filename\"] = train_df.id.str[0]+\"/\"+train_df.id.str[1]+\"/\"+train_df.id.str[2]+\"/\"+train_df.id+\".jpg\"\ntrain_df[\"label\"] = train_df.landmark_id.astype(str)\nprint(train_df.head(-1))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:43:46.721364Z","iopub.execute_input":"2022-05-06T11:43:46.72193Z","iopub.status.idle":"2022-05-06T11:43:53.051246Z","shell.execute_reply.started":"2022-05-06T11:43:46.721891Z","shell.execute_reply":"2022-05-06T11:43:53.050528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks=train_df.groupby(by='landmark_id').count().loc[:,'id']\nlandmarks","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:43:56.569073Z","iopub.execute_input":"2022-05-06T11:43:56.56936Z","iopub.status.idle":"2022-05-06T11:43:57.381884Z","shell.execute_reply.started":"2022-05-06T11:43:56.569316Z","shell.execute_reply":"2022-05-06T11:43:57.381203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nimport random\n\nc = train_df.landmark_id .values\n\ncount = Counter(c).most_common(1000)\n#print(type(count))\nrandom.shuffle(count)\ncount\n#print(len(count), count[-1])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:44:01.32365Z","iopub.execute_input":"2022-05-06T11:44:01.324337Z","iopub.status.idle":"2022-05-06T11:44:01.853698Z","shell.execute_reply.started":"2022-05-06T11:44:01.324299Z","shell.execute_reply":"2022-05-06T11:44:01.852976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keep_labels = [i[0] for i in count]\n#keep_labels\n#train_df[train_df.landmark_id.isin(keep_labels)]\ntrain_keep = train_df[train_df.landmark_id.isin(keep_labels)].sample(frac=1)\ntrain_keep\n","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:44:05.412438Z","iopub.execute_input":"2022-05-06T11:44:05.413116Z","iopub.status.idle":"2022-05-06T11:44:05.522467Z","shell.execute_reply.started":"2022-05-06T11:44:05.413066Z","shell.execute_reply":"2022-05-06T11:44:05.521693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen =ImageDataGenerator(rescale=1./255 ,\n                        validation_split=0.20,\n                        )\n\ntrain_gen =gen.flow_from_dataframe(\n    dataframe=train_keep,\n    directory='../input/landmark-recognition-2020/train',\n    target_size=(224, 224),\n    x_col=\"filename\",\n    y_col=\"label\",\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=32,\n    seed = 42,\n    subset=\"training\",\n    shuffle=True,\n    validate_filenames=True)\n    \nval_gen = gen.flow_from_dataframe(\n    dataframe=train_keep,\n    directory='../input/landmark-recognition-2020/train',\n    target_size=(224, 224),\n    x_col=\"filename\",\n    y_col=\"label\",\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=32,\n    seed = 42,\n    subset=\"validation\",\n    shuffle=True,\n    validate_filenames=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:47:39.909561Z","iopub.execute_input":"2022-05-06T11:47:39.910524Z","iopub.status.idle":"2022-05-06T11:50:59.258071Z","shell.execute_reply.started":"2022-05-06T11:47:39.910432Z","shell.execute_reply":"2022-05-06T11:50:59.256787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras import applications\nfrom keras.applications import vgg16\nbase_model= keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3) )\n\nbase_model.trainable= True\n\n#base_model.summary()\n\ndrop_out1= keras.layers.Dropout(0.3)\nflatten_layer= keras.layers.Flatten()\ndrop_out2= keras.layers.Dropout(0.3)\noutput=keras.layers.Dense(1000, activation= 'sigmoid')\nmodel=keras.Sequential([base_model,drop_out1,flatten_layer,drop_out2,output])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T11:51:17.331897Z","iopub.execute_input":"2022-05-06T11:51:17.332231Z","iopub.status.idle":"2022-05-06T11:51:17.679711Z","shell.execute_reply.started":"2022-05-06T11:51:17.33219Z","shell.execute_reply":"2022-05-06T11:51:17.678888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.remove(\"'./model.h5'\")\n\ncheckpoint_filepath ='./model.h5' \n\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_filepath,\n                                                               monitor = 'val_loss',\n                                                               mode = 'min',\n                                                               save_best_only = True)\nearly_stopping= tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                                                 mode='max',\n                                                 patience=5,\n                                                 restore_best_weights= True,\n                                                 )","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:02:25.793664Z","iopub.execute_input":"2022-05-06T12:02:25.794323Z","iopub.status.idle":"2022-05-06T12:02:25.800176Z","shell.execute_reply.started":"2022-05-06T12:02:25.794269Z","shell.execute_reply":"2022-05-06T12:02:25.799186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.compile(optimizer='Adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:02:29.46531Z","iopub.execute_input":"2022-05-06T12:02:29.465855Z","iopub.status.idle":"2022-05-06T12:02:29.477809Z","shell.execute_reply.started":"2022-05-06T12:02:29.4658Z","shell.execute_reply":"2022-05-06T12:02:29.476954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory= model.fit_generator(train_gen, steps_per_epoch = train_gen.samples // 32,validation_data=val_gen,validation_steps = val_gen.samples // 32 ,epochs=20,callbacks=[model_checkpoint_callback, early_stopping],shuffle=True )","metadata":{"execution":{"iopub.status.busy":"2022-05-06T12:06:51.997751Z","iopub.execute_input":"2022-05-06T12:06:51.998081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\n\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df=pd.read_csv('../input/landmark-recognition-2020/sample_submission.csv')\nsubmission_df[\"filename\"] = submission_df.id.str[0]+\"/\"+submission_df.id.str[1]+\"/\"+submission_df.id.str[2]+\"/\"+submission_df.id+\".jpg\"\nsubmission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = ImageDataGenerator().flow_from_dataframe(\n    submission_df,\n    directory=\"/kaggle/input/landmark-recognition-2020/test/\",\n    x_col=\"filename\",\n    y_col=None,\n    weight_col=None,\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    classes=None,\n    class_mode=None,\n    batch_size=1,\n    shuffle=True,\n    subset=None,\n    interpolation=\"nearest\",\n    validate_filenames=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_one_hot = checkpoint_filepath.predict_generator(test_gen, verbose=1, steps=len(submission_df))\n\ny_pred = np.argmax(y_pred_one_hot, axis=-1)\ny_prob = np.max(y_pred_one_hot, axis=-1)\nprint(y_pred.shape, y_prob.shape)\n\ny_uniq = np.unique(train_keep.landmark_id.values)\n\ny_pred = [y_uniq[Y] for Y in y_pred]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(submission_df)):\n    submission_df.loc[i, \"landmarks\"] = str(y_pred[i])+\" \"+str(y_prob[i])\nsubmission_df = submission_df.drop(columns=\"filename\")\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# for i in range(len(submission_df)):\n#     submission_df.loc[i, \"landmarks\"] = str(y_pred[i])+\" \"+str(y_prob[i])\n# submission_df.to_csv(\"submission.csv\", index=False)\n# submission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}