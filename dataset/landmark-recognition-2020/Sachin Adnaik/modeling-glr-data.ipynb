{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\"\"\"Baseline kernel for \"Google Landmarks Recognition Challenge 2020\".\n\nGenerates `submission.csv` in Kaggle format. When the number of training images\nindicates that the kernel is being run against the public dataset,\nsimply copies `sample_submission.csv` to allow for quickly starting reruns\non the private dataset. When in a rerun against the private dataset,\nmakes predictions via retrieval, using DELG TensorFlow SavedModels for global\nand local feature extraction.\n\nFirst, ranks all training images by embedding similarity to each test image.\nThen, performs geometric-verification and re-ranking on the `NUM_TO_RERANK`\nmost similar training images. For a given test image, each class' score is\nthe sum of the scores of re-ranked training images, and the predicted\nclass is the one with the highest aggregate score.\n\nNOTE: For speed, this uses `pydegensac` as its RANSAC implementation.\nSince the module has no interface for setting random seeds, RANSAC results\nand submission scores will vary slightly between reruns.\n\"\"\"\n\nimport copy\nimport csv\nimport gc\nimport operator\nimport os\nimport pathlib\nimport shutil\n\nimport pydegensac\nfrom scipy import spatial\nimport tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nfrom glob import glob\nimport gc\nfrom PIL import Image\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image,display\nimport seaborn as sns\nfrom tqdm import tqdm_notebook as tqdm\nimport matplotlib.image as mpimg\nimport scipy.spatial.distance as dist\nfrom sklearn.model_selection import train_test_split\nfrom skimage.measure import compare_ssim\nimport os\n\n# Dataset parameters:\nINPUT_DIR = os.path.join('..', 'input')\n\nDATASET_DIR = os.path.join(INPUT_DIR, 'landmark-recognition-2020')\nTEST_IMAGE_DIR = os.path.join(DATASET_DIR, 'test')\nTRAIN_IMAGE_DIR = os.path.join(DATASET_DIR, 'train')\nTRAIN_LABELMAP_PATH = os.path.join(DATASET_DIR, 'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_PUBLIC_TRAIN_IMAGES = 1580470 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mainPath = '/kaggle/input/landmark-recognition-2020/train/'\n\ntr = pd.read_csv('/kaggle/input/landmark-recognition-2020/train.csv')\nsub = pd.read_csv('/kaggle/input/landmark-recognition-2020/sample_submission.csv')\ntab = tr.landmark_id.value_counts()\n\n\n\nall_img_paths = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0], '*.jpg'))]\nids = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0]))]\nall_filenames = []\nfor filepath in all_img_paths:\n    FileName = os.path.basename(filepath)\n    all_filenames.append(FileName)\npath_dict = dict(zip(all_filenames,all_img_paths))\n\n\ndf=pd.DataFrame()\ndf['fname'] = all_filenames\ndf['pname'] = all_img_paths\ndf['id'] = list(map(lambda x: x[:-4], df.fname))\n\ntrain = pd.merge(tr, df, on = 'id')\n\n\nmainPath = '/kaggle/input/landmark-recognition-2020/test/'\nall_img_paths = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0], '*.jpg'))]\nids = [y for x in os.walk(mainPath) for y in glob(os.path.join(x[0]))]\nall_filenames = []\nfor filepath in all_img_paths:\n    FileName = os.path.basename(filepath)\n    all_filenames.append(FileName)\npath_dict = dict(zip(all_filenames,all_img_paths))\n\ntest=pd.DataFrame()\ntest['fname'] = all_filenames\ntest['pname'] = all_img_paths\n\ntest['id'] = list(map(lambda x: x[:-4], test.fname))\n\n\ndef imtocsv(data):\n    from PIL import Image\n    nrow = []\n    ncol = []\n    pix = []\n    for j in data.pname:\n        image = Image.open(j)\n        nrow.append(image.size[0])\n        ncol.append(image.size[1])\n        pix.append(image.size[0]*image.size[1])\n    out = {'nrow': nrow, 'ncol': ncol, 'pix':pix}\n    df= pd.DataFrame(out)\n    df.insert(0,'id',data.id,True)\n    return df\n\nout=imtocsv(train)\ntrain_50 = pd.merge(train, out, on = 'id')\n\ndel out\nout=imtocsv(test)\ntest_50 = pd.merge(test, out, on = 'id')\n\ntr_2 = train_50.copy()\nts_2 = test_50.copy()\n\n\n\n#os.listdir('../input/siim-isic-melanoma-classification/jpeg/train/')\ndef imtocsv02(data, resize):\n    from PIL import Image\n    r=resize\n    D=np.zeros((data.shape[0],2*r))\n    k = 0\n    for j in data.pname:\n        image = Image.open(j)\n        out=image.resize((r,r))\n        out=np.array(out)\n        out = np.resize(out, (r,r))\n        #print(out.size)\n        a1 =np.diag(out)\n        a2 = np.diag(np.rot90(out))\n        A =np.append(a1,a2)\n        D[k,]=A\n        k = k+1\n    col_list = ['x' + str(x) for x in range(0,2*r)]\n    df= pd.DataFrame(D,columns=col_list)\n    \n    df.insert(0,'id',data.id,True)\n    return df\n\nout=imtocsv02(tr_2,28)\ntrain_28 = pd.merge(tr_2, out, on = 'id')\n\ndel out\nout=imtocsv02(ts_2,28)\ntest_28 = pd.merge(ts_2, out, on = 'id')\n\ntrain = train_28.copy()\ntest = test_28.copy()\n\ndel train_50\ndel test_50\ndel train_28\ndel test_28\ndel tr_2\ndel ts_2\n\ny_tr = train['landmark_id'].copy()\ntr = train.copy()\nts = test.copy()\nimage_id = ts.id.copy()\ntr.drop(['id','landmark_id','fname','pname'],axis = 1, inplace = True)\nts.drop(['id','fname','pname'],axis = 1, inplace = True)\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3,p=1)\n\nknn.fit(tr,y_tr)\nlabel = knn.predict(ts)\nscore = knn.predict_proba(ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_labelmap():\n    with open(TRAIN_LABELMAP_PATH, mode='r') as csv_file:\n        csv_reader = csv.DictReader(csv_file)\n        labelmap = {row['id']: row['landmark_id'] for row in csv_reader}\n    return labelmap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_submission_csv(predictions=None):\n    \"\"\"Saves optional `predictions` as submission.csv.\n\n    The csv has columns {id, landmarks}. The landmarks column is a string\n  containing the label and score for the id, separated by a ws delimeter.\n\n  If `predictions` is `None` (default), submission.csv is copied from\n  sample_submission.csv in `IMAGE_DIR`.\n\n  Args:\n    predictions: Optional dict of image ids to dicts with keys {class, score}.\n  \"\"\"\n\n    if predictions is None:\n       # Dummy submission!\n        shutil.copyfile(os.path.join(DATASET_DIR, 'sample_submission.csv'), 'submission.csv')\n        return\n\n    with open('submission.csv', 'w') as submission_csv:\n        csv_writer = csv.DictWriter(submission_csv, fieldnames=['id', 'landmarks'])\n        csv_writer.writeheader()\n        csv_writer.writerow({'id': image_id, 'landmarks': f'{label} {score}'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def main():\n    labelmap = load_labelmap()\n    num_training_images = len(labelmap.keys())\n    print(f'Found {num_training_images} training images.')\n\n    if num_training_images == NUM_PUBLIC_TRAIN_IMAGES:\n        print(f'Found {NUM_PUBLIC_TRAIN_IMAGES} training images. Copying sample submission.')\n        save_submission_csv()\n        return\n\n    _, post_verification_predictions = get_predictions(labelmap)\n    save_submission_csv(post_verification_predictions)\n\nmain()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}