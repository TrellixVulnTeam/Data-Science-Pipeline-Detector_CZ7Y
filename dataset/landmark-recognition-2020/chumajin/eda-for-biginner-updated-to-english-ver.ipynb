{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Thank you for upvoding and comment.\n## I got a comment that the flow is easy to understand, so I updated not only the Japanese ver but also the English ver."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. すべてのpathを出す # Get all path"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"all_path = []\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        all_path.append(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_path[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_path = '/kaggle/input/landmark-recognition-2020/sample_submission.csv'\ntraincsv_path = '/kaggle/input/landmark-recognition-2020/train.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample submissionの中身を見る # View contents of sample submission \nsample = pd.read_csv(sample_path)\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# traincsvの中身を見る # View contents of train.csv\ntraincsv = pd.read_csv(traincsv_path)\ntraincsv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# traincsvの中身はidとlandmark_idだということがわかる。 # I could understand that the contents of traincsv are composed of id and landmark_id.\n# まずは、idごとにpathをくっつけることを考える。 # Firstly, I considered attaching the path for each id.\n# all_pathからtrainが入っているものと、jpgが入っているものを抜く # I tried to extract the one that contained the \"train\" and \".jpg\" from the all_path.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_path[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. trainデータの確認と解析 # Confirmation the train data and analyzing."},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainフォルダの中の.jpgファイルだけ抜きたい # I wanted to extract only \".jpg\" file in train directory.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainがつくやつだけ抜く # Firstly, I extracted only \"train\" in all path.\ntrain_impath = [s for s in all_path if \"train\" in s]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# <わからない人は・・・>↑は以下と同じ。 # If you cannot understand, the above code is the same as below.\n\ntrain_impath2 = []\n\nfor s in all_path:\n    if \"train\" in s:\n        train_impath2.append(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 同様にさらにjpgファイルだけ抜く # After that, I extracted \".jpg\" in train_impath.\ntrain_impath = [s for s in train_impath if \".jpg\" in s]\ntrain_impath[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ここから.jpgの前のidのみを抜きたい  # From these pathes, I extracted id from path in each, in order to merge with train.csv.\ntrain_id = [s.split(\"/\")[-1] for s in train_impath]\ntrain_id = [s.split(\".\")[0] for s in train_id]\ntrain_id[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataframe化 # Making dataframe.\ndf = pd.DataFrame()\ndf[\"path\"] = train_impath\ndf[\"id\"] = train_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traincsv.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mergeしてidが同じところをくっつける # Merge with the same id.\ntraindf = pd.merge(traincsv,df,on=\"id\",how=\"left\")\ntraindf.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## landmark id = 1の画像を確認 # Confirmation of images with landmark id = 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nexample = traindf[traindf[\"landmark_id\"]==1]\nfor a in example[\"path\"]:\n    plt.figure()\n    img = cv2.imread(a)\n    plt.imshow(img)\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## traindfをもう少し解析 # Analyzing the traindf"},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.to_csv(\"traindf.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\nl = np.array(traindf[\"landmark_id\"])\nc = collections.Counter(l) # get unique counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(c) # 辞書型で、それぞれのidに対する個数が出ている # c is the type of dictionaly and composed of the id and the number of each id.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataframe化したいので、リスト化する # List the c in order to make the dataframe.\nkey = list(c.keys())\ncnt = list(c.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcnt = pd.DataFrame()\ndfcnt[\"id\"] = key\ndfcnt[\"count\"] = cnt\ndfcnt.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 並び替え # sort_values\ndfcnt = dfcnt.sort_values(\"count\")\ndfcnt = dfcnt.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcnt.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcnt.to_csv(\"dfcnt.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(dfcnt[\"id\"],dfcnt[\"count\"])\nplt.xlabel(\"id\",fontsize = 15)\nplt.ylabel(\"count\",fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## id = 138982が6272個で一番多いので、どういう画像か見てみる \n## # Since id = 138982 is the most with 6272, let's see what kind of image."},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\nexample = traindf[traindf[\"landmark_id\"]==dfcnt[\"id\"].iloc[-1]]\n\n\nfor a in range(10):\n    plt.figure()\n    img = cv2.imread(example[\"path\"].iloc[a])\n    plt.imshow(img)\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 黒い枠ぶちが最も多い画像 # I can understand the images have black borders.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. testデータもみてみる # Confirmation of test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# all_pathから抜く # extract the .jpg file path from all_path\ntest_impath = [s for s in all_path if \"test\" in s]\ntest_impath = [s for s in test_impath if \".jpg\" in s]\ntest_impath[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in range(10):\n    plt.figure()\n    img = cv2.imread(test_impath[a])\n    plt.imshow(img)\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# このテスト画像に訓練画像のidを関連付けてconfidenceを出すのが課題。 # The challenge is to associate the id of the training image with this test image to give confidence.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. 最後にsubmission fileの確認 # Confirmaetion of submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## testデータのid, landmark id, confidence（自信)の順になっている。\n## # The order of submission file is the test data id, landmark id, and confidence."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 例えば、landmarksを一番多いidに全部変えて提出してみる (結果はscore 0だけど、提出可能なフォーマットかの確認。)　\n## # For example, I tried changing all the landmarks to the most ids and submit it \n## (the result is score 0, but check if it is in a submittable format)."},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcnt.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcnt[\"id\"].iloc[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_landmarks = str(dfcnt[\"id\"].iloc[-1]) + \" \" + str(1.0)\ntest_landmarks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample[\"landmarks\"] = test_landmarks\nsample.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 提出名はsubmission.csv　右側のsettingでinternet offにして、commitしないと提出できないので、注意。\n## #The file name must be \"submission.csv\". And it notes that the internet must be off by changing the setting on right part of this screen. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsample.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}