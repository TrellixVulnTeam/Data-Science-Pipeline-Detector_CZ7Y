{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt, cv2\nimport tensorflow as tf\nfrom glob import glob\nimport numpy as np # linear algebra  GLR-make-tfrecord-256-0\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom kaggle_datasets import KaggleDatasets\nimport random\n\ndef read_df_0(input_path):\n    mapping = {}\n    df = pd.read_csv(input_path + 'train.csv')\n    \n    \n    files_paths = glob(input_path + 'train/*/*/*/*')\n    for path in files_paths:\n        mapping[path.split('/')[-1].split('.')[0]] = path\n    \n        \n    df['path'] = df['id'].map(mapping)\n    \n    counts_map = dict(df.groupby('landmark_id')['path'].agg(lambda x: len(x)))\n    df['counts'] = df['landmark_id'].map(counts_map)\n    \n    \n    uniques = df['landmark_id'].unique()\n    uniques_map = dict(zip(uniques, range(len(uniques))))\n    df['labels'] = df['landmark_id'].map(uniques_map)\n    return df\n\ndf = read_df_0('../input/landmark-recognition-2020/')\ndf.sort_values('counts',inplace=True)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef serialize_example(feature0, feature1):\n    feature = {\n        'image': _bytes_feature(feature0),\n        'label': _int64_feature(feature1)\n        #'prob': _float_feature(feature2),\n\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()\n\n\n\nSIZE = 56500\ntotal_num = len(df) // SIZE + int(len(df) % SIZE != 0)\nfor j in range(0,2):\n    print('Writing TFRecord %i of %i...' % (j, total_num))\n    num_per_tf = min(SIZE, len(df) - j * SIZE)\n    with tf.io.TFRecordWriter('train%.2i-%i.tfrec' % (j, num_per_tf)) as writer:\n        for k in range(num_per_tf):\n            idx=j * SIZE + k\n            \n            path,label= df.path[idx], df.labels[idx]\n            bits = tf.io.read_file(path)\n            img = tf.image.decode_jpeg(bits, channels=3)\n            print(img.shape)            \n\n            img = tf.image.resize(img, (512,512), method='bilinear')\n            img = tf.cast(img, tf.uint8)\n     \n            plt.imsave('img.jpg',img.numpy())\n            img = open('./img.jpg', 'rb').read()            \n            example = serialize_example(img,label)  # ,str.encode(path)ff\n            writer.write(example)\n            if k % 1000 == 0: print(k, ', ', end='')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}