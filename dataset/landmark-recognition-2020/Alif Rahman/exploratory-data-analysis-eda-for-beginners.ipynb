{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Google Landmark Recognition-2020\n\n**Here, I will try to perform the Exploratory Data Analysis (EDA) on this dataset. I will try to explain each step as clearly as possible. As I'm a beginner myself, if you find any mistakes, please suggest your valuable opinions in the comment section.**\n\nThese notebooks gave me the necessary ideas for this task and I'm really grateful to them:\n1. https://www.kaggle.com/chirag9073/landmark-recognition-exploratory-data-analysis/notebook\n2. https://www.kaggle.com/azaemon/mura-classification\n3. [https://www.kaggle.com/azaemon/eda-data-augmentation-for-beginners?scriptVersionId=40504799](https://www.kaggle.com/azaemon/eda-data-augmentation-for-beginners?scriptVersionId=40504799)\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"**To begin with, Let's first import the necessary modules.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt #for plotting the graphs or images\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization\nimport matplotlib.image as mpimg\n\n# Set Color Palettes for the notebook (https://color.adobe.com/)\ncolors_nude = ['#FFE61A','#B2125F','#FF007B','#14B4CC','#099CB3']\nsns.palplot(sns.color_palette(colors_nude))\n\n# Set Style\nsns.set_style(\"whitegrid\")\nsns.despine(left=True, bottom=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"**Load the training csv file**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data= pd.read_csv(\"../input/landmark-recognition-2020/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Take a look at the first 10 entries. (we defined the number inside the parentheses. You can change the value to whatever you want. By default it is 5)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.head(10))\nprint()\nprint(\"Here, id means Image Id and landmark_id points to a specific ID of the landmark \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now let's take a look at the summary of the loaded data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here I checked for any missing value in the csv file and found that, there is no missing values.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.isna().sum())\nprint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, Let's perform the Exploratory Data Analysis importing the *basic_image_eda* library**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install basic_image_eda\nfrom basic_image_eda import BasicImageEDA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are a total of 1580470 images in the train folder. It will take a huge amout of time to perform EDA over all the images. So, here I am applying this only for one of the subfolders. You can choose any of the subfolder by just changing the path. Like, if you want to use the subfolder \"1\", then the data_dir value will be \"../input/landmark-recognition-2020/train/1\" or if you want to perform the operation over whole training images then, cahnge the value to \"../input/landmark-recognition-2020/train\".**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"../input/landmark-recognition-2020/train/0\"\nextensions = ['jpg']\nthreads = 0\ndimension_plot = True\nchannel_hist = True\nnonzero = False\nhw_division_factor = 1.0\n\nBasicImageEDA.explore(data_dir, extensions, threads, dimension_plot, channel_hist, nonzero, hw_division_factor)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's analyze the number of landmark types and their distributions."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['landmark_id'].value_counts()\nprint(\"Types of Landmarks: {81313}\")\nprint(\"Landmark ID: 138982 has the highest number of images (6272)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most frequent landmark counts (Top 10)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Occurance of landmark_id in decreasing order(Top categories)\ntemp = pd.DataFrame(train_data.landmark_id.value_counts().head(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['Landmark ID','Number of Images']\n\n# Plot the most frequent landmark_ids\nplt.figure(figsize = (9, 10))\nplt.title('Top 10 the mostfrequent landmarks')\nsns.set_color_codes(\"deep\")\nsns.barplot(x=\"Landmark ID\", y=\"Number of Images\", data=temp,\n            label=\"Count\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Least frequent landmark counts (Top 10)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(train_data.landmark_id.value_counts().tail(10))\ntemp.reset_index(inplace=True)\ntemp.columns = ['Landmark ID','Number of Images']\n# Plot the least frequent landmark_ids\nplt.figure(figsize = (9, 10))\nplt.title('Top 10 the least frequent landmarks')\nsns.set_color_codes(\"deep\")\nsns.barplot(x=\"Landmark ID\", y=\"Number of Images\", data=temp,\n            label=\"Count\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's plot some random images"},{"metadata":{"trusted":true},"cell_type":"code","source":"from random import randrange\nfig= plt.figure(figsize=(20,10))\nindex= '../input/landmark-recognition-2020/train/2/3/6/23603d71816b6452.jpg'\na= fig.add_subplot(2,3,1)\na.set_title(index.split(\"/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '../input/landmark-recognition-2020/train/7/0/4/7040a5cfa43e0633.jpg'\na= fig.add_subplot(2,3,2)\na.set_title(index.split(\"/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '../input/landmark-recognition-2020/train/4/1/0/41000aafca574dfe.jpg'\na= fig.add_subplot(2,3,3)\na.set_title(index.split(\"/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '../input/landmark-recognition-2020/train/4/3/1/43101b9ac11ed672.jpg'\na= fig.add_subplot(2,3,4)\na.set_title(index.split(\"/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '../input/landmark-recognition-2020/train/4/3/1/43105797059abd97.jpg'\na= fig.add_subplot(2,3,5)\na.set_title(index.split(\"/\")[-1])\nplt.imshow(plt.imread(index))\n\nindex= '../input/landmark-recognition-2020/train/4/1/0/41008546ba23b770.jpg'\na= fig.add_subplot(2,3,6)\na.set_title(index.split(\"/\")[-1])\nplt.imshow(plt.imread(index))\n\nplt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If you found this notebook helpful or you just liked it , some upvotes would be very much appreciated - That will keep me motivated :)**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}