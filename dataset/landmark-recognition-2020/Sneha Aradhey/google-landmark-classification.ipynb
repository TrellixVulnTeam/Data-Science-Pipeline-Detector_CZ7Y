{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import necessary libraries**","metadata":{}},{"cell_type":"code","source":"import shutil\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\n\n#Seed for making reproducible experiments\nseed = 612","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.image as mpimg","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.chdir(\"../input/landmark-recognition-2020\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/landmark-recognition-2020/train.csv\")\ntrain_data.sample(5, random_state=seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training data size\", train_data.shape)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Unique labels:', train_data['landmark_id'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Images per label:',train_data.groupby('landmark_id').count().mean() )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks_count = (train_data.groupby('landmark_id').count()).sort_values(by ='id',ascending = False).reset_index()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarks_count[50:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\nplt.scatter(landmarks_count[40:]['landmark_id'],landmarks_count[40:]['id'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,7))\nplt.title(\"Top 20 most frequent landmarkrs\")\nsns.barplot(x='landmark_id', y='id', data=landmarks_count.head(20), palette=\"mako\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,7))\nplt.title(\"Top 20 most frequent landmarkrs\")\nsns.barplot(x='landmark_id', y='id', data=landmarks_count.tail(20), palette=\"mako\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\nplt.scatter(landmarks_count[4000:]['landmark_id'],landmarks_count[4000:]['id'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,12))\nplt.scatter(landmarks_count[5:4000]['landmark_id'],landmarks_count[5:4000]['id'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data subset for model","metadata":{}},{"cell_type":"code","source":"data_subset = pd.read_csv('../input/sampled-data-1000/Samples 1000.csv')\ndata_subset_images = train_data[train_data['landmark_id'].isin(data_subset['landmark_id'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of landmarks in sample:', data_subset_images.shape)\nprint('Number of images in sample:',data_subset_images.shape)\nprint(data_subset_images.head(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #Check data distribution\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.pyplot import subplots\n\ncolors = np.array(['#4285f4','#34a853','#fbbc05','#ea4335'])\n#Define the order in which to display the graph\norder = ['1-5','5-10','10-50','50-100','100-200','200-500','>=500']\nf, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n\n\ndef plot_distribution(data_f, data_k, axis):\n    # data['landmark_id'].value_counts()\n    x=data_f.landmark_id.value_counts().index\n    y=pd.DataFrame(data_f.landmark_id.value_counts())\n\n    #Create a variable to group the number of image sin each class\n    y.loc[(y['landmark_id']>=500,'Number of images')] = '>=500'\n    y['Number of images'] = np.where((y['landmark_id']>=200) & (y['landmark_id']<500),'200-500',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=100) & (y['landmark_id']<200),'100-200',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=50) & (y['landmark_id']<100),'50-100',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=10) & (y['landmark_id']<50),'10-50',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=5) & (y['landmark_id']<10),'5-10',y['Number of images'])\n    y['Number of images'] = np.where((y['landmark_id']>=0) & (y['landmark_id']<5),'1-5',y['Number of images'])\n\n    y['Number of images'].value_counts().loc[[x for x in order if any(y['Number of images']==x)]].plot(kind = 'bar',color = colors,width = 0.8, ax=axis)\n    axis.set_xlabel('Number of images',fontsize=15)\n    axis.set_ylabel('Number of classes',fontsize=15)\n    axis.set_title(data_k,fontsize=17)\n#     for item in ([axis.title, axis.xaxis.label, axis.yaxis.label] +\n#              axis.get_xticklabels() + axis.get_yticklabels()):\n#         item.set_fontsize(12)\n    \nplot_distribution(data_subset_images, 'Sample', ax1)\nplot_distribution(train_data, 'Original', ax2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel train_data\ndel landmarks_count\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_subset_images.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"TRAIN_DIR = '../input/landmark-recognition-2020/train/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data_subset_images['id'], data_subset_images['landmark_id'], test_size=0.2, random_state=42, stratify = data_subset_images['landmark_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_subset_images['train'] = 1\ndata_subset_images.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import StratifiedShuffleSplit\n# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n# for train_index, val_index in sss.split(data_subset_images, data_subset_images['landmark_id']):\n#     data_subset_images['train'].iloc[val_index] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train = data_subset_images[data_subset_images['train']==1]['id']\n# X_test = data_subset_images[data_subset_images['train']==0]['id']\n# y_train = data_subset_images[data_subset_images['train']==1]['landmark_id']\n# y_test = data_subset_images[data_subset_images['train']==0]['landmark_id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('X_train:',X_train.shape)\nprint('y_train:',y_train.shape)\nprint('X_test:',X_test.shape)\nprint('y_test:',y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_subset_images[data_subset_images['train']==1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merging traing df\nTraining_images = pd.DataFrame()\nTraining_images['id'] = X_train\nTraining_images['landmark_id'] = y_train\nTraining_images = Training_images[Training_images['landmark_id'].isin(y_test)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Merging test df\nTesting_images = pd.DataFrame()\nTesting_images['id'] = X_test\nTesting_images['landmark_id'] = y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Training_images.to_csv('./Training_images.csv')\nTesting_images.to_csv('./Testing_images.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of labels in test and train\nprint(Training_images['landmark_id'].nunique())\nprint(Testing_images['landmark_id'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training_images = Training_images.drop('Unnamed: 0',axis = 1)\n# Testing_images = Testing_images.drop('Unnamed: 0',axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel X_train\ndel y_train\ndel X_test\ndel y_test\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2,os\nDEST_PATH = '/kaggle/working/resized_images/training_images/'\nos.mkdir('/kaggle/working/resized_images/')\nos.mkdir('/kaggle/working/resized_images/training_images/')\n# Resizing images\ndef images_resize(images):    \n    for i, id in enumerate(images):\n        if os.path.exists(DEST_PATH + f'{id[0]}.jpg'):\n            continue\n        else:\n\n            image_path = os.path.join(TRAIN_DIR, f'{id[0][0]}/{id[0][1]}/{id[0][2]}/{id[0]}.jpg')\n            image = cv2.imread(image_path)\n            new_image = cv2.resize(image,(224,224))\n            cv2.imwrite(os.path.join(DEST_PATH,f'{id[0]}.jpg'),new_image)\n\nimages_resize(Training_images.values)\nprint('Images resized')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for root, dirs, files in os.walk('./resized_images'):\n#     for file in files:\n#         img = cv2.imread(os.path.join(root,file))\n#         print(img,file)\n#         plt.imshow(img)\n#         break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i = 0\n# for root, dirs, files in os.walk('./resized_images'):\n#     for file in files:\n#         img = cv2.imread(os.path.join(root,file))\n#         print(img,file)\n#         plt.imshow(img)\n#         if i == 10:\n#             break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# f.add_subplot(1,2,1)\n# plt.imshow(cv2.imread('../input/landmark-recognition-2020/train/6/d/4/6d4846da6209b860.jpg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"damaged_images = []\nimage_array = []\nfor root, dirs, files in os.walk('./resized_images/training_images'):\n#     print(dirs,root,files)\n    \n    for file in files:\n#         print(root)\n        if root == './resized_images/training_images':\n#             print(root,file,'here')\n            img = cv2.imread(os.path.join(root,file))\n            if img is None:\n                damaged_images.append(file)\n            else:\n                image_array.append(img)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(image_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test dataset\nDEST_PATH_1 = '/kaggle/working/resized_images/testing_images/'\nos.mkdir('/kaggle/working/resized_images/testing_images/')\n# Resizing images\ndef images_resize(images):    \n    for i, id in enumerate(images):\n        \n        if os.path.exists(DEST_PATH_1 + f'{id[0]}.jpg'):\n            continue\n        else:\n            image_path = os.path.join(TRAIN_DIR, f'{id[0][0]}/{id[0][1]}/{id[0][2]}/{id[0]}.jpg')\n            image = cv2.imread(image_path)\n            new_image = cv2.resize(image,(224,224))\n            cv2.imwrite(os.path.join(DEST_PATH_1,f'{id[0]}.jpg'),new_image)\n\nimages_resize(Testing_images.values)\nprint('Images resized')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cv2.imread('/kaggle/working/resized_images/testing_images/0d7d04144065ad08.jpg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEST_PATH_1 = '/kaggle/working/resized_images/testing_images/'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"damaged_images_test = []\nimage_array_test = []\n# numpy_array = []\nfor root, dirs, files in os.walk('./resized_images/testing_images'):\n#     print(dirs,root,files)\n    \n    for file in files:\n#         print(root)\n        if root == './resized_images/testing_images':\n#             print(root,file,'here')\n            img = cv2.imread(os.path.join(root,file))\n#             numpy_array.append(img_to_array(img))\n            if img is None:\n                damaged_images_test.append(file)\n            else:\n                image_array_test.append(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(image_array_test))\nlen(damaged_images_test)\n# image_array_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.optimizers import Adam\nfrom keras.applications import ResNet152\nfrom keras.applications import ResNet101\n# from keras.applications.Res2Net200_vd_26w_4s import\nimport os,cv2\nimport matplotlib.pyplot as plt \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install pretrainedmodels\n# import pretrainedmodels\n\n# Model = pretrainedmodels.__dict__['se_resnext101_32x4d']\n# model = Model(num_classes=1000, pretrained='imagenet')\n# model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import efficientnet.keras as efn \n# model = efn.EfficientNetB3(weights='imagenet') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Download pre-trrained model\n# model = ResNet50(weights='imagenet')\n\n# # model.compile(optimizer = Adam(), loss = 'cross_entropy')\n# # model.fit(X_train,y_train)\n# image_path = os.path.join('./resized_images/training_images/', '5abaf74b3541e6ed.jpg')\n# image = cv2.imread(image_path)\n# plt.imshow(image)\n# # img = img\n# preds = model.predict(image.reshape(1,224,224,3))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('Predicted:', decode_predictions(preds, top=1)[0])\n# label = decode_predictions(preds)\n# # retrieve the most likely result, e.g. highest probability\n# label = label[0][0]\n# # print the classification\n# print('%s (%.2f%%)' % (label[1], label[2]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def display_images_resize_preprocess(images):\n# #     f = plt.figure(figsize=(20,20))\n#     images_list = []\n#     for i, id in enumerate(images):\n# #         print(id,i)\n#         image_path = os.path.join(TRAIN_DIR, f'{id[0][0]}/{id[0][1]}/{id[0][2]}/{id[0]}.jpg')\n#         image_old = cv2.imread(image_path)\n#         new_image = preprocess_input(np.expand_dims(image.img_to_array(cv2.resize(image_old,(256,256))),axis =0))\n#         images_list.append(new_image)\n        \n# #         f.add_subplot(1,10,i+1)\n# #         plt.imshow(new_image)\n# #         f.add_subplot(1,10,i+5)\n# #         plt.imshow(image)\n# #         plt.title(f'Landmark_id: {id[1]} \\nID: {id[0]}')\n    \n#     return images_list\n\n# rec_images_list = display_images_resize_preprocess(data_subset_images.values )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TRAIN_DIR_1 = './resized_images/training_images/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def train_images_preprocess(TRAIN_DIR,images):\n#     images_list = []\n#     image_array =[]\n#     for i, id in enumerate(images):\n#         image_path = os.path.join(TRAIN_DIR, f'{id[0]}.jpg')\n#         image_old = cv2.imread(image_path)\n#         print(image_old)\n#         new_image = preprocess_input(np.expand_dims(image_old,axis =0))\n#         images_list.append(new_image)\n#         image_array.append()\n        \n\n    \n#     return images_list\n\n# X_train_processed = train_images_preprocess(TRAIN_DIR_1,X_train.values )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.chdir('../input')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Training_images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training_images = pd.read_csv('../input/sampled-dataset/Training_images.csv')\n# Testing_images= pd.read_csv('../input/sampled-dataset/Testing_images .csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_model = ResNet50(weights='imagenet', include_top = False, input_shape = (224,224,3))\n\nfor layer in res_model.layers[:143]:\n    layer.trainable = False\n    \n    \nfor i, layer in enumerate(res_model.layers):\n    print(i, layer.name,'-',layer.trainable)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Flatten, BatchNormalization, Dropout, Dense, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n    \ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom sklearn.metrics import log_loss, roc_auc_score, accuracy_score\nfrom keras.losses import categorical_crossentropy\nfrom keras.metrics import categorical_accuracy\nfrom keras import backend as K\nfrom keras.callbacks import *\nMETRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.CategoricalAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n      \"acc\", f1_m\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = Sequential()\n# model.add(res_model)\n# model.add(GlobalAveragePooling2D())\n# model.add(Flatten())\n# model.add(BatchNormalization())\n# model.add(Dense(1024,activation = 'relu'))\n# model.add(Dropout(0.5))\n# model.add(BatchNormalization())\n# model.add(Dense(512,activation = 'relu'))\n# model.add(BatchNormalization())\n# model.add(Dense(943,activation = 'softmax'))\n\n# model.compile(loss='categorical_crossentropy',\n#                   optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n#                   metrics=METRICS)\n# print ('Compilation done.')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.predict_classes()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Training_images['id_new'] = Training_images['id'].astype(str) + '.jpg' \nTraining_images['id_new']\nTesting_images['id_new'] = Testing_images['id'].astype(str) + '.jpg' \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Testing_images['landmark_id_new'] = Testing_images['landmark_id'].astype(str)\nTraining_images['landmark_id_new'] = Training_images['landmark_id'].astype(str)\nTesting_images['id_new'] = Testing_images['id_new'].astype(str)\nTraining_images['id_new'] = Training_images['id_new'].astype(str)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os,cv2\n# numpy_array = []\n# for i in Testing_images.values:\n# #     print(i)\n#     if os.path.exists(DEST_PATH_1+ i[2]):\n#            numpy_array.append(preprocess_input(np.expand_dims(img_to_array(cv2.imread(os.path.join(DEST_PATH_1, i [2]))),axis = 0)).reshape(224,224,3)) \n# #     x = (x,axis=0)\n# # x = (x)\n# numpy_array = np.asarray(numpy_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class Metrics(Callback):\n    \n#     def __init__(self, val_data, batch_size = 20):\n#         super().__init__()\n#         self.validation_data = val_data\n#         self.batch_size = batch_size\n    \n#     def on_train_begin(self, logs={}):\n#         print(self.validation_data)\n#         self.val_f1s = []\n#         self.val_recalls = []\n#         self.val_precisions = []\n        \n#     def on_epoch_end(self, epoch, logs={}):\n#         batches = len(self.validation_data)\n#         total = batches * self.batch_size\n        \n#         val_pred = np.zeros((total,1))\n#         val_true = np.zeros((total))\n        \n#         for batch in range(batches):\n#             xVal, yVal = next(self.validation_data)\n#             val_pred[batch * self.batch_size : (batch+1) * self.batch_size] = np.asarray(self.model.predict(xVal)).round()\n#             val_true[batch * self.batch_size : (batch+1) * self.batch_size] = yVal\n            \n#         val_pred = np.squeeze(val_pred)\n#         _val_f1 = f1_score(val_true, val_pred)\n#         _val_precision = precision_score(val_true, val_pred)\n#         _val_recall = recall_score(val_true, val_pred)\n        \n#         self.val_f1s.append(_val_f1)\n#         self.val_recalls.append(_val_recall)\n#         self.val_precisions.append(_val_precision)\n        \n#         return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epochs = 10\n# history_3 = model.fit(\n#         train_generator,\n# #         steps_per_epoch=50,\n#         epochs=epochs,\n#         validation_data=val_generator)\n# # callbacks=[Metrics(val_generator)])\n# #         validation_steps=150\n# #         callbacks=[ModelCheckpoint(filepath=top_model_weights_path, save_best_only=True, save_weights_only=True)]\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history_3.history['val_f1_m']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def plot_history(history):\n# \t  # plot loss\n#     plt.title('F1')\n#     plt.plot(history.history['f1_m'], color='blue', label='train')\n#     plt.plot(history.history['val_f1_m'], color='red', label='test')\n#     plt.ylabel('F1')\n#     plt.xlabel('Epoch')\n#     plt.legend(['Train', 'Validation'])\n#     plt.show()\n    \n#     # plot accuracy\n#     plt.title('Accuracy')\n#     plt.plot(history.history['accuracy'], color='blue', label='train')\n#     plt.plot(history.history['val_accuracy'], color='red', label='test')\n#     plt.ylabel('Accuracy')\n#     plt.xlabel('Epoch')\n#     plt.legend(['Train', 'Validation'])\n#     plt.show()\n\n# plot_history(history_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.save('history_2.npy',history_2.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred = model.predict(numpy_array, batch_size=64)\n# y_pred_c = model.predict_classes(numpy_array, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predIdxs = model.predict_generator(train_generator)\n\n# predIdxs = np.argmax(predIdxs, axis=1)\n\n# print(classification_report(train_generator.labels, predIdxs))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# assuming you stored your model.fit results in a 'history' variable:\n# history = model.fit(x_train, y_train, epochs=10)\n\n# convert the history.history dict to a pandas DataFrame:     \n# hist_df = pd.DataFrame(history) \n\n# save to json:  \n# hist_json_file = 'history.json' \n# with open(hist_json_file, mode='w') as f:\n#     hist_df.to_json(f)\n\n# or save to csv: \n# hist_csv_file = 'history.csv'\n# with open(hist_csv_file, mode='w') as f:\n#     hist_df.to_csv(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model 3**","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/classification_models.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for keras\nfrom classification_models.keras import Classifiers\n\n# for tensorflow keras\nfrom classification_models.tfkeras import Classifiers\n\nClassifiers.models_names()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SeResNeXT101, preprocess_input = Classifiers.get('seresnext101')\nmodel_SeResNeXT101 = SeResNeXT101(include_top = False, input_shape=(224, 224, 3), weights='imagenet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNet101v2, preprocess_input = Classifiers.get('resnet101v2')\nmodel_ResNet101v2 = ResNet101v2(include_top = False, input_shape=(224, 224, 3), weights='imagenet')\n\nResNet152, preprocess_input = Classifiers.get('resnet152')\nmodel_ResNet152 = ResNet152(include_top = False, input_shape=(224, 224, 3), weights='imagenet')\n!pip install efficientnet\nimport efficientnet.keras as efn \nmodel_EfficientNetB3 = efn.EfficientNetB3(weights='imagenet') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model_SeResNeXT101.layers[:2670]:\n    layer.trainable = False\n    \n    \nfor layer in model_ResNet152.layers[:523]:\n    layer.trainable = False\n\n    \nfor layer in model_ResNet101v2.layers[:302]:\n    layer.trainable = False\n\n    \nfor layer in model_EfficientNetB3.layers[:307]:\n    layer.trainable = False\n\n\n# for i, layer in enumerate(model_EfficientNetB3.layers):\n#     print(i, layer.name,'-',layer.trainable)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1 = Sequential()\nmodel_1.add(model_SeResNeXT101)\nmodel_1.add(GlobalAveragePooling2D())\nmodel_1.add(Flatten())\nmodel_1.add(BatchNormalization())\nmodel_1.add(Dense(1024,activation = 'relu'))\nmodel_1.add(Dropout(0.5))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Dense(512,activation = 'relu'))\nmodel_1.add(BatchNormalization())\nmodel_1.add(Dense(943,activation = 'softmax'))\n\nmodel_1.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2 = Sequential()\nmodel_2.add(model_ResNet152)\nmodel_2.add(GlobalAveragePooling2D())\nmodel_2.add(Flatten())\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(1024,activation = 'relu'))\nmodel_2.add(Dropout(0.5))\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(512,activation = 'relu'))\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(943,activation = 'softmax'))\n\nmodel_2.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_3 = Sequential()\nmodel_3.add(model_ResNet101v2)\nmodel_3.add(GlobalAveragePooling2D())\nmodel_3.add(Flatten())\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dense(1024,activation = 'relu'))\nmodel_3.add(Dropout(0.5))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dense(512,activation = 'relu'))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dense(943,activation = 'softmax'))\n\nmodel_3.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_4 = Sequential()\nmodel_4.add(model_EfficientNetB3)\n# model_4.add(GlobalAveragePooling2D())\nmodel_4.add(Flatten())\nmodel_4.add(BatchNormalization())\nmodel_4.add(Dense(1024,activation = 'relu'))\nmodel_4.add(Dropout(0.5))\nmodel_4.add(BatchNormalization())\nmodel_4.add(Dense(512,activation = 'relu'))\nmodel_4.add(BatchNormalization())\nmodel_4.add(Dense(943,activation = 'softmax'))\n\nmodel_4.compile(loss='categorical_crossentropy',\n                  optimizer=optimizers.Adam(lr=0.001, beta_1=0.9,beta_2=0.999,epsilon=1e-8, decay=0.0),\n                  metrics=METRICS)\nprint ('Compilation done.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 64\ntrain_datagen = ImageDataGenerator()\n#     rescale=1. / 255.,\n#                                        ,rotation_range=90,\n#                                         width_shift_range=0.2,\n#                                         height_shift_range=0.2,\n#                                         zoom_range = 0.5\n                                  \n    \nval_datagen = ImageDataGenerator()\ntrain_generator = train_datagen.flow_from_dataframe(dataframe = Training_images,\n                                                       directory = './resized_images/training_images/',\n                                                       x_col = 'id_new',\n                                                       y_col = 'landmark_id_new',\n                                                    class_mode=\"categorical\",\n                                                    preprocessing_function = preprocess_input\n#                                                    ,batch_size = batch_size\n                                                   )\nval_generator = val_datagen.flow_from_dataframe(dataframe = Testing_images,\n                                                       directory = './resized_images/testing_images/',\n                                                       x_col = 'id_new',\n                                                       y_col = 'landmark_id_new',\n                                                class_mode=\"categorical\",\n                                                preprocessing_function = preprocess_input\n\n#                                     ,batch_size= batch_size\n                                               )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_1 = model_1.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator)\n   \nmodel_1.save('model_1_SEResNeXt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_2 = model_2.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator) \n\nmodel_2.save('model_2_ResNet152')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_3 = model_3.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator)\n\nmodel_3.save('model_3_ResNet101v2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nhistory_4 = model_4.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=val_generator)\n\nmodel_4.save('model_EfficientNetB3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}