{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall typing -y\n!pip install git+https://github.com/catalyst-team/catalyst@master --upgrade -q","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\nimport numpy as np\n\nfrom plotly import graph_objects as go\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\n\nfrom catalyst import dl\nfrom catalyst import utils\nfrom catalyst import data\nfrom catalyst.contrib.nn.criterion import TripletMarginLossWithSampler\n\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.set_global_seed(42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/landmark-recognition-2020/train.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_img(id_: str, train=True, preproc=True):\n    if preproc and train:\n        root = Path(\n            \"../input/google-landmark-retrieval-2020-train-224x224/train_img\"\n        )\n        path_to_img = root / str(id_)\n        img = cv2.imread(str(path_to_img)+\".jpg\")\n        return img\n    if train:\n        root = Path(\"../input/landmark-recognition-2020/train\")\n    else:\n        root = Path(\"../input/landmark-recognition-2020/test\")\n    first_folder = root / str(id_[0])\n    second_folder = first_folder / str(id_[1])\n    third_folder = second_folder / str(id_[2])\n    path_to_img = third_folder / str(id_)\n    img = cv2.imread(str(path_to_img)+\".jpg\")\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImgDataset(Dataset):\n    def __init__(self, df, transforms = None, train: bool = True):\n        self.id = df.id.values\n        if train:\n            self.labels = df.landmark_id.values\n        self.train = train\n        if transforms is None:\n            transforms = A.Compose([\n                A.Resize(width=224, height=224), \n                A.pytorch.ToTensor()\n            ])\n        self.transforms = transforms\n        \n    def __getitem__(self, idx: int):\n        img = load_img(self.id[idx], train=self.train)\n        tensor_img = self.transforms(image=img)[\"image\"]\n        \n        output = {\"features\": tensor_img}\n        if self.train:\n            label = self.labels[idx]\n            output[\"targets\"] = label\n        return output\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def get_labels(self):\n        return np.array(self.labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_, valid_df_ = train_test_split(train_df, random_state=42, stratify=train_df.landmark_id.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = ImgDataset(train_df_)\nvalid_ds = ImgDataset(valid_df_)\nsampler = data.BalanceBatchSampler(labels=train_ds.get_labels(), p=10, k=20)\ntrain_dl = DataLoader(\n    train_ds, sampler=sampler, batch_size=sampler.batch_size, num_workers=4\n)\nvalid_dl = DataLoader(\n    valid_ds, sampler=sampler, batch_size=sampler.batch_size, num_workers=4\n)\nloaders = {\"train\": train_dl, \"valid\": valid_dl}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnext50_32x4d(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\n    \nhead = nn.Sequential(\n    nn.Linear(1000, 512),\n    nn.ReLU(),\n    nn.Linear(512, 100),\n)\nmodel = nn.Sequential(\n    model,\n    head,\n)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import wandb\n\n#wandb.login(\"never\", \"\")\nwandb.init(project=\"landmarks\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MetricLearningRunner(dl.SupervisedRunner):\n    def predict_batch(self, batch):\n        embeddings = self.model(batch[\"features\"].to(self.device))\n        return embeddings, batch[\"targets\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampler_inbatch = data.HardTripletsSampler(norm_required=False)\ncriterion = TripletMarginLossWithSampler(margin=0.5, sampler_inbatch=sampler_inbatch)\n\n# 4. training with catalyst Runner\ncallbacks = [\n    dl.ControlFlowCallback(dl.CriterionCallback(), loaders=\"train\"),\n    #dl.WandbLogger(log_on_batch_end=True, project=\"landmarks\"),\n]\n\nrunner = MetricLearningRunner(device=utils.get_device())\nrunner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    callbacks=callbacks,\n    loaders=loaders,\n    minimize_metric=False,\n    verbose=True,\n    num_epochs=200,\n    check=True,  # disable if you want to train\n)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_embeddings(loader, out_file_emb=\"embeddings.npy\", out_file_labels=\"labels.npy\"):\n    embeddings = None\n    labels = None\n    loader = DataLoader(loader.dataset, batch_size=200, num_workers=2)\n    for c_embeddings, c_labels in tqdm(runner.predict_loader(loader=loader), total=len(loader)):\n        if embeddings is None:\n            embeddings = c_embeddings.cpu().numpy()\n            labels = c_labels.cpu().numpy()\n            continue\n        embeddings = np.vstack((embeddings, c_embeddings.cpu().numpy()))\n        labels = np.vstack((labels, c_labels.cpu().numpy()))\n    np.save(file=out_file_emb, arr=embeddings)\n    np.save(file=out_file_labels, arr=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_embeddings(loaders[\"train\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!catalyst-contrib create-index-model \\\n--in-npy \"embeddings.npy\" --out-npy \"embeddings_pca.npy\" \\\n--out-pipeline \"pipeline.pkl\" --out-knn \"indexes.pkl\" --n-hidden \"32\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}