{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot  as plt # data visualization\nimport cv2\nimport os\n\nplt.rc('axes', titlesize=14)     # fontsize of the axes title\nplt.rc('figure', titlesize=18)  # fontsize of the figure title\n\n\nDATASET_DIR = '/kaggle/input/landmark-recognition-2020'\nTRAIN_IMAGE_DIR = '/kaggle/input/landmark-recognition-2020/train'\nWIKIPEDIA_CATS_PATH = '/kaggle/input/wikipedia-categories-for-glr-2020/gldv2-train-category.csv'\n\n\ndef make_clickable(val):\n    # target _blank to open new window\n    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)\n\ndef plot_images(image_list,rows,cols,title):\n    \n    \n    fig,ax = plt.subplots(rows,cols,figsize = (25,5*rows))\n    ax = ax.flatten()\n    \n    for i, idx in enumerate(image_list[:rows*cols]):\n        image = cv2.imread(TRAIN_IMAGE_DIR+'/{}/{}/{}/{}.jpg'.format(idx[0],idx[1],idx[2],idx))\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        ax[i].imshow(image)\n        ax[i].set_axis_off()\n        ax[i].set_title(idx)\n    \n    plt.suptitle(title)\n\n    \ndef get_image_list (landmark_id):\n    return train.query(\"landmark_id == @landmark_id\")[\"id\"].values    \n\n\ndef show_landmark (landmark_id,rows=5,cols=5, shuffle=True):\n    image_list = get_image_list (landmark_id = landmark_id )\n    if shuffle:\n        np.random.shuffle(image_list)\n    plot_images(image_list,rows=rows,cols=cols,title=f'{landmark_id} - # {rows*cols} of {len(image_list)}' ) \n    \n\ntrain = pd.read_csv(f'{DATASET_DIR}/train.csv')\ncats = pd.read_csv(WIKIPEDIA_CATS_PATH)\nprint(\"Shape of train_data :\", train.shape)\nprint(\"Number of unique landmarks :\", train[\"landmark_id\"].nunique())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Landmarks with highest number of images in train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_landmarks = train.groupby(\"landmark_id\").agg({'id':'count'}).reset_index().rename(columns={\"id\":\"count\"}).sort_values(by=\"count\",ascending=False).reset_index(drop=True)[:10]\ntop_landmarks = top_landmarks.merge(cats, on=\"landmark_id\")\ntop_landmarks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Category:Media_contributed_by_the_ETH-Bibliothek (138982)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"landmark_id=138982\nshow_landmark(landmark_id=landmark_id,rows=3,cols=5)\ncats.query(\"landmark_id == @landmark_id\").style.format({'category': make_clickable})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Category:Corktown,_Toronto (126637)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"landmark_id=126637\nshow_landmark(landmark_id=landmark_id,rows=3,cols=5)\ncats.query(\"landmark_id == @landmark_id\").style.format({'category': make_clickable})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Category:Noraduz_Cemetery (20409) \t","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"landmark_id=20409\nshow_landmark(landmark_id=landmark_id,rows=3,cols=5)\ncats.query(\"landmark_id == @landmark_id\").style.format({'category': make_clickable})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Wikipedia Instances","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image_list_by_istance (df,instance):\n    return df.query(\"instance == @instance\")[\"id\"].values    \n\n\ndef show_instance (df,instance,rows=5,cols=5, shuffle=True):\n    image_list = get_image_list_by_istance (df,instance )\n    if shuffle:\n        np.random.shuffle(image_list)\n    plot_images(image_list,rows=rows,cols=cols,title=f'{instance} - # {rows*cols} of {len(image_list)}' ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats[\"instance\"] = cats[\"instance\"].map(lambda x: str(x).strip() )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats.groupby([\"instance\"]).agg({\"landmark_id\":\"count\"}).reset_index().sort_values(by=\"landmark_id\", ascending=False)[:50]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(cats, on=\"landmark_id\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Instance: church building ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"instance=\"church building\"\nshow_instance(train,instance,rows=3,cols=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Instance: castle","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"instance=\"castle\"\nshow_instance(train,instance,rows=3,cols=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Instance: lighthouse","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"instance=\"lighthouse\"\nshow_instance(train,instance,rows=3,cols=5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}