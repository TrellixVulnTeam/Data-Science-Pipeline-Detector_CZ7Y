{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Landmarks Foreground Extraction-Opencv","metadata":{}},{"cell_type":"markdown","source":"This notebook referred to the following notebook.<br>\nhttps://www.kaggle.com/akhileshdkapse/foreground-extraction-opencv","metadata":{}},{"cell_type":"markdown","source":"\nForeground extraction is a technique which allows an imageâ€™s foreground to be extracted for further processing like object recognition, tracking etc. The algorithm used for foreground extraction here is GrabCut Algorithm. <br/><br/>\nIn this algorithm, the region is drawn in accordance with the foreground, a rectangle is drawn over it.This is the rectangle that encases our main object. The region coordinates are decided over understanding the foreground mask. But this segmentation is not perfect, as it may have marked some foreground region as background and vice versa.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Contents\n\n* Loading data & forecasting\n* Adaptive histogram equalization technique\n* Color Quantization using K-Means\n* Edge detection with required Morphological Transformations\n* Object detection(Drawing bounding boxes around target)\n* Foreground extraction","metadata":{}},{"cell_type":"markdown","source":"# Loading data & forecasting","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm import tqdm\nimport os","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-02-17T05:09:21.961619Z","iopub.execute_input":"2022-02-17T05:09:21.96192Z","iopub.status.idle":"2022-02-17T05:09:21.966203Z","shell.execute_reply.started":"2022-02-17T05:09:21.961894Z","shell.execute_reply":"2022-02-17T05:09:21.965639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_DIR='../input/landmark-recognition-2020/train/0/0/0'","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:21.967648Z","iopub.execute_input":"2022-02-17T05:09:21.967951Z","iopub.status.idle":"2022-02-17T05:09:21.980095Z","shell.execute_reply.started":"2022-02-17T05:09:21.967923Z","shell.execute_reply":"2022-02-17T05:09:21.979631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files0=os.listdir(IMG_DIR)\nfiles=[]\nfor item in files0:\n    if item[-4:]=='.jpg':\n        files+=[item]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:21.980969Z","iopub.execute_input":"2022-02-17T05:09:21.981555Z","iopub.status.idle":"2022-02-17T05:09:22.000955Z","shell.execute_reply.started":"2022-02-17T05:09:21.98153Z","shell.execute_reply":"2022-02-17T05:09:22.000101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load(path, size=128):\n    img= cv2.resize(cv2.imread(path),(size,size))\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\ndef show():\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= os.path.join(IMG_DIR, files[i])\n        ax[i//5][i%5].imshow(load(path, 300), aspect='auto')\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()\n    \nshow()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:22.002752Z","iopub.execute_input":"2022-02-17T05:09:22.003086Z","iopub.status.idle":"2022-02-17T05:09:24.170129Z","shell.execute_reply.started":"2022-02-17T05:09:22.003047Z","shell.execute_reply":"2022-02-17T05:09:24.168753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adaptive histogram equalization technique","metadata":{}},{"cell_type":"code","source":"def adaptive_hist(img, clipLimit= 4.0):\n    window= cv2.createCLAHE(clipLimit= clipLimit, tileGridSize=(8, 8))\n    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n\n    ch1, ch2, ch3 = cv2.split(img_lab)\n    img_l = window.apply(ch1)\n    img_clahe = cv2.merge((img_l, ch2, ch3))\n    return cv2.cvtColor(img_clahe, cv2.COLOR_Lab2BGR)\n\n\ndef show_adhist(clipLimit=4.0):\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= os.path.join(IMG_DIR, files[i])\n        img=load(path, 300)\n        img= adaptive_hist(img, clipLimit)\n        ax[i//5][i%5].imshow(img, aspect='auto')\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:24.171762Z","iopub.execute_input":"2022-02-17T05:09:24.172083Z","iopub.status.idle":"2022-02-17T05:09:24.181973Z","shell.execute_reply.started":"2022-02-17T05:09:24.172055Z","shell.execute_reply":"2022-02-17T05:09:24.181158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_adhist(2.0)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:24.183142Z","iopub.execute_input":"2022-02-17T05:09:24.183316Z","iopub.status.idle":"2022-02-17T05:09:25.928083Z","shell.execute_reply.started":"2022-02-17T05:09:24.183293Z","shell.execute_reply":"2022-02-17T05:09:25.927182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Color Quantization using K-Means","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:25.929701Z","iopub.execute_input":"2022-02-17T05:09:25.930128Z","iopub.status.idle":"2022-02-17T05:09:25.93425Z","shell.execute_reply.started":"2022-02-17T05:09:25.930099Z","shell.execute_reply":"2022-02-17T05:09:25.933109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def k_means(img, n_colors= 4):\n    w, h, d = original_shape = tuple(img.shape)\n    img= img/255.0\n    image_array = np.reshape(img, (w * h, d))\n    kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array)\n    labels = kmeans.predict(image_array)\n    \n    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n    codebook= kmeans.cluster_centers_\n    d = codebook.shape[1]\n    image = np.zeros((w, h, d))\n    label_idx = 0\n    for i in range(w):\n        for j in range(h):\n            image[i][j] = codebook[labels[label_idx]]\n            label_idx += 1\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:25.935471Z","iopub.execute_input":"2022-02-17T05:09:25.93567Z","iopub.status.idle":"2022-02-17T05:09:25.949278Z","shell.execute_reply.started":"2022-02-17T05:09:25.935647Z","shell.execute_reply":"2022-02-17T05:09:25.948403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_kmean(n_colors=4):\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= os.path.join(IMG_DIR, files[i])\n        img=load(path, 300)\n        img= k_means(img , n_colors= n_colors)\n        ax[i//5][i%5].imshow(img, aspect='auto')\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:25.950312Z","iopub.execute_input":"2022-02-17T05:09:25.950542Z","iopub.status.idle":"2022-02-17T05:09:25.962629Z","shell.execute_reply.started":"2022-02-17T05:09:25.950514Z","shell.execute_reply":"2022-02-17T05:09:25.961381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_kmean(n_colors= 4)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:25.965147Z","iopub.execute_input":"2022-02-17T05:09:25.965389Z","iopub.status.idle":"2022-02-17T05:09:57.097446Z","shell.execute_reply.started":"2022-02-17T05:09:25.965347Z","shell.execute_reply":"2022-02-17T05:09:57.096318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Edge detection with required Morphological Transformations","metadata":{}},{"cell_type":"code","source":"def show_edges(n_colors=4):\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= os.path.join(IMG_DIR, files[i])\n        img=load(path, 300)\n        img= k_means(img , n_colors= n_colors)\n        \n        img_gray= cv2.cvtColor(np.uint8(img*255), cv2.COLOR_RGB2GRAY)\n        img_gray= cv2.medianBlur(img_gray,5)\n        edges = cv2.Canny(img_gray,100,200)\n        ax[i//5][i%5].imshow(edges, aspect='auto')\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:57.098364Z","iopub.execute_input":"2022-02-17T05:09:57.098556Z","iopub.status.idle":"2022-02-17T05:09:57.106889Z","shell.execute_reply.started":"2022-02-17T05:09:57.098532Z","shell.execute_reply":"2022-02-17T05:09:57.105999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_edges(n_colors =3)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:09:57.108479Z","iopub.execute_input":"2022-02-17T05:09:57.109484Z","iopub.status.idle":"2022-02-17T05:10:25.061423Z","shell.execute_reply.started":"2022-02-17T05:09:57.109434Z","shell.execute_reply":"2022-02-17T05:10:25.060608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Object detection(Drawing bounding boxes around target)","metadata":{}},{"cell_type":"code","source":"def find_box(edges):\n    #contour masking\n    co, hi = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    con=max(co,key=cv2.contourArea)\n    conv_hull=cv2.convexHull(con)\n    \n    top=tuple(conv_hull[conv_hull[:,:,1].argmin()][0])\n    bottom=tuple(conv_hull[conv_hull[:,:,1].argmax()][0])\n    left=tuple(conv_hull[conv_hull[:,:,0].argmin()][0])\n    right=tuple(conv_hull[conv_hull[:,:,0].argmax()][0])\n    \n    return top, bottom, left, right\n","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:10:25.06312Z","iopub.execute_input":"2022-02-17T05:10:25.063379Z","iopub.status.idle":"2022-02-17T05:10:25.068986Z","shell.execute_reply.started":"2022-02-17T05:10:25.063354Z","shell.execute_reply":"2022-02-17T05:10:25.06836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_bound_box():\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= os.path.join(IMG_DIR, files[i])\n        img=load(path, 300)\n        org=img.copy()\n        img= k_means(img , n_colors= 10)\n        \n        img_gray= cv2.cvtColor(np.uint8(img*255), cv2.COLOR_RGB2GRAY)\n        img_gray= cv2.medianBlur(img_gray,7)\n        edges = cv2.Canny(img_gray,100,200)\n        \n        kernel= cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n        \n        top,bottom,left,right = find_box(edges)\n        org=cv2.rectangle(org, (left[0], top[1]), (right[0], bottom[1]), (0, 255, 0), thickness=3)\n        \n        ax[i//5][i%5].imshow(org, aspect='auto')\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:10:25.069854Z","iopub.execute_input":"2022-02-17T05:10:25.070054Z","iopub.status.idle":"2022-02-17T05:10:25.08386Z","shell.execute_reply.started":"2022-02-17T05:10:25.070029Z","shell.execute_reply":"2022-02-17T05:10:25.082951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_bound_box()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T05:10:25.085099Z","iopub.execute_input":"2022-02-17T05:10:25.085344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Foreground extraction","metadata":{}},{"cell_type":"code","source":"def forgrd_ext(img, rec):\n    mask= np.zeros(img.shape[:2], np.uint8)\n    bgmodel= np.zeros((1, 65), np.float64)\n    fgmodel= np.zeros((1, 65), np.float64)\n    cv2.grabCut(img, mask, rec, bgmodel, fgmodel, 3, cv2.GC_INIT_WITH_RECT)\n    mask2= np.where((mask==2)|(mask==0), 0, 1).astype('uint8')\n    img= img*mask2[:,:,np.newaxis]\n    img[np.where((img == [0,0,0]).all(axis = 2))] = [255.0, 255.0, 255.0]\n    return img\n\ndef ext_frgd():\n    f, ax = plt.subplots(5, 5, figsize=(40,30))\n    for i in tqdm(range(25)):\n        path= os.path.join(IMG_DIR, files[i])\n        img=load(path, 300)\n        org=img.copy()\n        img= k_means(img , n_colors= 10)\n        \n        img_gray= cv2.cvtColor(np.uint8(img*255), cv2.COLOR_RGB2GRAY)\n        img_gray= cv2.medianBlur(img_gray,7)\n        edges = cv2.Canny(img_gray,100,200)\n        \n        kernel= cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n        \n        top,bottom,left,right = find_box(edges)\n        rec= (left[0], top[1], right[0]-left[0], bottom[1]-top[1])\n        forground_img= forgrd_ext(org, rec)\n        \n        ax[i//5][i%5].imshow(forground_img, aspect='auto')\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ext_frgd()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path= os.path.join(IMG_DIR, files[7])\nim1= load(path, 300)\n\nim2= img= k_means(im1 , n_colors= 3)\n\nim3= cv2.cvtColor(np.uint8(im2*255), cv2.COLOR_RGB2GRAY)\nim3= cv2.medianBlur(im3,5)\nim3 = cv2.Canny(im3,100,200)\nkernel= cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\nim31 = cv2.morphologyEx(im3, cv2.MORPH_CLOSE, kernel)\n\ntop,bottom,left,right = find_box(im31)\nim4=cv2.rectangle(im1.copy(), (left[0], top[1]), (right[0], bottom[1]), (0, 255, 0), thickness=3)\n\nrec= (left[0], top[1], right[0]-left[0], bottom[1]-top[1])\nim5= forgrd_ext(im1, rec)\n\ncv2.imwrite('im2.png',cv2.cvtColor(im5,cv2.COLOR_BGR2RGB))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs=[im1,im2,im3,im31,im4,im5]\nf, ax = plt.subplots(2, 3, figsize=(18,10))\nfor i in tqdm(range(6)):\n    r=i//3\n    c=i%3\n    ax[r][c].imshow(imgs[i], aspect='auto')\n    ax[r][c].set_xticks([]) \n    ax[r][c].set_yticks([])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}