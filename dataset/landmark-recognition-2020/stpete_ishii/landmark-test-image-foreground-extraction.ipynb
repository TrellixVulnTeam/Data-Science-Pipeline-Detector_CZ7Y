{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Landmark Test Image Foreground Extraction","metadata":{"papermill":{"duration":0.034721,"end_time":"2022-02-18T11:53:31.755248","exception":false,"start_time":"2022-02-18T11:53:31.720527","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"This notebook referred to the following notebook.<br>\nhttps://www.kaggle.com/akhileshdkapse/foreground-extraction-opencv","metadata":{"papermill":{"duration":0.032802,"end_time":"2022-02-18T11:53:31.823585","exception":false,"start_time":"2022-02-18T11:53:31.790783","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Loading data & forecasting","metadata":{"papermill":{"duration":0.032806,"end_time":"2022-02-18T11:53:31.889689","exception":false,"start_time":"2022-02-18T11:53:31.856883","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm import tqdm\nimport os\nfrom sklearn.cluster import KMeans","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2022-02-18T11:53:31.961609Z","iopub.status.busy":"2022-02-18T11:53:31.960428Z","iopub.status.idle":"2022-02-18T11:53:33.699852Z","shell.execute_reply":"2022-02-18T11:53:33.698394Z","shell.execute_reply.started":"2022-02-18T07:39:10.063406Z"},"papermill":{"duration":1.777215,"end_time":"2022-02-18T11:53:33.700136","exception":false,"start_time":"2022-02-18T11:53:31.922921","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR='../input/landmark-recognition-2020/train'\nTEST_DIR='../input/landmark-recognition-2020/test'","metadata":{"execution":{"iopub.execute_input":"2022-02-18T11:53:33.776135Z","iopub.status.busy":"2022-02-18T11:53:33.775467Z","iopub.status.idle":"2022-02-18T11:53:33.779117Z","shell.execute_reply":"2022-02-18T11:53:33.779702Z","shell.execute_reply.started":"2022-02-18T07:39:11.593188Z"},"papermill":{"duration":0.04245,"end_time":"2022-02-18T11:53:33.779906","exception":false,"start_time":"2022-02-18T11:53:33.737456","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATHS=[]\nfor dirname, _, filenames in os.walk('../input/landmark-recognition-2020/train'):\n    for filename in filenames:\n        TRAIN_PATHS+=[os.path.join(dirname, filename)]\n        \nTEST_PATHS=[]\nfor dirname, _, filenames in os.walk('../input/landmark-recognition-2020/test'):\n    for filename in filenames:\n        TEST_PATHS+=[os.path.join(dirname, filename)]","metadata":{"execution":{"iopub.execute_input":"2022-02-18T11:53:33.852838Z","iopub.status.busy":"2022-02-18T11:53:33.852191Z","iopub.status.idle":"2022-02-18T12:02:51.619232Z","shell.execute_reply":"2022-02-18T12:02:51.619837Z","shell.execute_reply.started":"2022-02-18T07:39:11.597923Z"},"papermill":{"duration":557.806011,"end_time":"2022-02-18T12:02:51.620072","exception":false,"start_time":"2022-02-18T11:53:33.814061","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATHS[0:3]","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:02:51.691444Z","iopub.status.busy":"2022-02-18T12:02:51.690758Z","iopub.status.idle":"2022-02-18T12:02:51.698886Z","shell.execute_reply":"2022-02-18T12:02:51.699402Z","shell.execute_reply.started":"2022-02-18T07:47:49.84262Z"},"papermill":{"duration":0.045375,"end_time":"2022-02-18T12:02:51.6996","exception":false,"start_time":"2022-02-18T12:02:51.654225","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(TRAIN_PATHS).to_csv('train_paths.csv',index=False)\npd.DataFrame(TEST_PATHS).to_csv('test_paths.csv',index=False)","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:02:51.773348Z","iopub.status.busy":"2022-02-18T12:02:51.77266Z","iopub.status.idle":"2022-02-18T12:02:58.267187Z","shell.execute_reply":"2022-02-18T12:02:58.2663Z","shell.execute_reply.started":"2022-02-18T07:47:49.854873Z"},"papermill":{"duration":6.531954,"end_time":"2022-02-18T12:02:58.267368","exception":false,"start_time":"2022-02-18T12:02:51.735414","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/landmark-recognition-2020/train.csv')\ndf.head()","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:02:58.342696Z","iopub.status.busy":"2022-02-18T12:02:58.342036Z","iopub.status.idle":"2022-02-18T12:03:00.059265Z","shell.execute_reply":"2022-02-18T12:03:00.059717Z","shell.execute_reply.started":"2022-02-18T07:47:54.717512Z"},"papermill":{"duration":1.757215,"end_time":"2022-02-18T12:03:00.059951","exception":false,"start_time":"2022-02-18T12:02:58.302736","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load(path, size=128):\n    img= cv2.resize(cv2.imread(path),(size,size))\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\ndef show():\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= TRAIN_PATHS[i]\n        img_id= df.id[i]\n        ax[i//5][i%5].imshow(load(path,128), aspect='auto')\n        ax[i//5][i%5].set_title(img_id)\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:00.138089Z","iopub.status.busy":"2022-02-18T12:03:00.137429Z","iopub.status.idle":"2022-02-18T12:03:00.13988Z","shell.execute_reply":"2022-02-18T12:03:00.140472Z","shell.execute_reply.started":"2022-02-18T07:47:56.586165Z"},"papermill":{"duration":0.046082,"end_time":"2022-02-18T12:03:00.140639","exception":false,"start_time":"2022-02-18T12:03:00.094557","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show()","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:00.213089Z","iopub.status.busy":"2022-02-18T12:03:00.212408Z","iopub.status.idle":"2022-02-18T12:03:02.809174Z","shell.execute_reply":"2022-02-18T12:03:02.808605Z","shell.execute_reply.started":"2022-02-18T07:47:56.598239Z"},"papermill":{"duration":2.634212,"end_time":"2022-02-18T12:03:02.809316","exception":false,"start_time":"2022-02-18T12:03:00.175104","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adaptive histogram equalization technique","metadata":{"papermill":{"duration":0.133874,"end_time":"2022-02-18T12:03:03.067339","exception":false,"start_time":"2022-02-18T12:03:02.933465","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def adaptive_hist(img, clipLimit= 4.0):\n    window= cv2.createCLAHE(clipLimit= clipLimit, tileGridSize=(8,8))\n    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n\n    ch1, ch2, ch3 = cv2.split(img_lab)\n    img_l = window.apply(ch1)\n    img_clahe = cv2.merge((img_l, ch2, ch3))\n    return cv2.cvtColor(img_clahe, cv2.COLOR_Lab2BGR)\n\n\ndef show_adhist(clipLimit=4.0):\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= TRAIN_PATHS[i]\n        img_id= df.id[i]\n        img=load(path,128)\n        img= adaptive_hist(img, clipLimit)\n        ax[i//5][i%5].imshow(img, aspect='auto')\n        ax[i//5][i%5].set_title(img_id)\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:03.5732Z","iopub.status.busy":"2022-02-18T12:03:03.572085Z","iopub.status.idle":"2022-02-18T12:03:03.575113Z","shell.execute_reply":"2022-02-18T12:03:03.574511Z","shell.execute_reply.started":"2022-02-18T07:47:58.909836Z"},"papermill":{"duration":0.39031,"end_time":"2022-02-18T12:03:03.575281","exception":false,"start_time":"2022-02-18T12:03:03.184971","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_adhist(2.0)","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:03.827888Z","iopub.status.busy":"2022-02-18T12:03:03.815949Z","iopub.status.idle":"2022-02-18T12:03:06.392494Z","shell.execute_reply":"2022-02-18T12:03:06.393026Z","shell.execute_reply.started":"2022-02-18T07:47:58.911788Z"},"papermill":{"duration":2.69918,"end_time":"2022-02-18T12:03:06.393238","exception":false,"start_time":"2022-02-18T12:03:03.694058","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.229256,"end_time":"2022-02-18T12:03:06.851578","exception":false,"start_time":"2022-02-18T12:03:06.622322","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Color Quantization using K-Means","metadata":{"papermill":{"duration":0.220554,"end_time":"2022-02-18T12:03:07.294692","exception":false,"start_time":"2022-02-18T12:03:07.074138","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.cluster import KMeans","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:07.746169Z","iopub.status.busy":"2022-02-18T12:03:07.745373Z","iopub.status.idle":"2022-02-18T12:03:07.74811Z","shell.execute_reply":"2022-02-18T12:03:07.747505Z","shell.execute_reply.started":"2022-02-18T07:47:58.913295Z"},"papermill":{"duration":0.232329,"end_time":"2022-02-18T12:03:07.748268","exception":false,"start_time":"2022-02-18T12:03:07.515939","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def k_means(img, n_colors=4):\n    w, h, d = original_shape = tuple(img.shape)\n    img= img/255.0\n    image_array = np.reshape(img,(w*h,d))\n    kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array)\n    labels = kmeans.predict(image_array)\n    \n    \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n    codebook= kmeans.cluster_centers_\n    d = codebook.shape[1]\n    image = np.zeros((w,h,d))\n    label_idx = 0\n    for i in range(w):\n        for j in range(h):\n            image[i][j] = codebook[labels[label_idx]]\n            label_idx += 1\n    return image","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:08.183548Z","iopub.status.busy":"2022-02-18T12:03:08.18291Z","iopub.status.idle":"2022-02-18T12:03:08.191658Z","shell.execute_reply":"2022-02-18T12:03:08.192219Z","shell.execute_reply.started":"2022-02-18T07:47:58.914683Z"},"papermill":{"duration":0.22659,"end_time":"2022-02-18T12:03:08.192395","exception":false,"start_time":"2022-02-18T12:03:07.965805","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_kmean(n_colors=4):\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= TRAIN_PATHS[i]\n        img_id= df.id[i]\n        img=load(path,128)\n        img= k_means(img , n_colors=n_colors)\n        ax[i//5][i%5].imshow(img, aspect='auto')\n        ax[i//5][i%5].set_title(img_id)\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:08.630789Z","iopub.status.busy":"2022-02-18T12:03:08.630143Z","iopub.status.idle":"2022-02-18T12:03:08.63853Z","shell.execute_reply":"2022-02-18T12:03:08.639101Z","shell.execute_reply.started":"2022-02-18T07:47:58.91604Z"},"papermill":{"duration":0.230025,"end_time":"2022-02-18T12:03:08.639305","exception":false,"start_time":"2022-02-18T12:03:08.40928","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_kmean(n_colors=8)","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:09.08723Z","iopub.status.busy":"2022-02-18T12:03:09.08645Z","iopub.status.idle":"2022-02-18T12:03:33.877652Z","shell.execute_reply":"2022-02-18T12:03:33.878358Z","shell.execute_reply.started":"2022-02-18T07:47:58.917331Z"},"papermill":{"duration":25.020369,"end_time":"2022-02-18T12:03:33.878606","exception":false,"start_time":"2022-02-18T12:03:08.858237","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.283189,"end_time":"2022-02-18T12:03:34.456923","exception":false,"start_time":"2022-02-18T12:03:34.173734","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Edge detection with required Morphological Transformations","metadata":{"papermill":{"duration":0.280551,"end_time":"2022-02-18T12:03:35.014934","exception":false,"start_time":"2022-02-18T12:03:34.734383","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def show_edges(n_colors=4):\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path=TRAIN_PATHS[i]\n        img_id= df.id[i]\n        img=load(path,128)\n        img= k_means(img , n_colors= n_colors)\n        \n        img_gray= cv2.cvtColor(np.uint8(img*255), cv2.COLOR_RGB2GRAY)\n        img_gray= cv2.medianBlur(img_gray,5)\n        edges = cv2.Canny(img_gray,100,200)\n        ax[i//5][i%5].imshow(edges, aspect='auto')\n        ax[i//5][i%5].set_title(img_id)\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:35.579772Z","iopub.status.busy":"2022-02-18T12:03:35.57812Z","iopub.status.idle":"2022-02-18T12:03:35.583059Z","shell.execute_reply":"2022-02-18T12:03:35.582484Z","shell.execute_reply.started":"2022-02-18T07:47:58.918387Z"},"papermill":{"duration":0.291384,"end_time":"2022-02-18T12:03:35.583225","exception":false,"start_time":"2022-02-18T12:03:35.291841","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_edges(n_colors =8)","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:03:36.186414Z","iopub.status.busy":"2022-02-18T12:03:36.185273Z","iopub.status.idle":"2022-02-18T12:04:01.172118Z","shell.execute_reply":"2022-02-18T12:04:01.172646Z","shell.execute_reply.started":"2022-02-18T07:47:58.919556Z"},"papermill":{"duration":25.312775,"end_time":"2022-02-18T12:04:01.172855","exception":false,"start_time":"2022-02-18T12:03:35.86008","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.30941,"end_time":"2022-02-18T12:04:01.81089","exception":false,"start_time":"2022-02-18T12:04:01.50148","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Object detection(Drawing bounding boxes around target)","metadata":{"papermill":{"duration":0.309253,"end_time":"2022-02-18T12:04:02.430253","exception":false,"start_time":"2022-02-18T12:04:02.121","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def find_box(edges):\n    #contour masking\n    co, hi = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n    if co!=():\n        con=max(co,key=cv2.contourArea)    \n        conv_hull=cv2.convexHull(con)\n        top=tuple(conv_hull[conv_hull[:,:,1].argmin()][0])\n        bottom=tuple(conv_hull[conv_hull[:,:,1].argmax()][0])\n        left=tuple(conv_hull[conv_hull[:,:,0].argmin()][0])\n        right=tuple(conv_hull[conv_hull[:,:,0].argmax()][0])\n        return top, bottom, left, right\n    else:\n        return (0,0),(0,0),(0,0),(0,0)\n","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:04:03.055238Z","iopub.status.busy":"2022-02-18T12:04:03.054056Z","iopub.status.idle":"2022-02-18T12:04:03.062554Z","shell.execute_reply":"2022-02-18T12:04:03.063176Z","shell.execute_reply.started":"2022-02-18T07:47:58.920652Z"},"papermill":{"duration":0.323708,"end_time":"2022-02-18T12:04:03.063435","exception":false,"start_time":"2022-02-18T12:04:02.739727","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_bound_box():\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= TRAIN_PATHS[i]\n        img_id= df.id[i]\n        img=load(path,128)\n        org=img.copy()\n        img= k_means(img, n_colors= 8)\n        \n        img_gray= cv2.cvtColor(np.uint8(img*255), cv2.COLOR_RGB2GRAY)\n        img_gray= cv2.medianBlur(img_gray,7)\n        edges = cv2.Canny(img_gray,100,200)\n        \n        kernel= cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n        \n        top,bottom,left,right = find_box(edges)\n        org=cv2.rectangle(org, (left[0], top[1]), (right[0], bottom[1]), (0, 255, 0), thickness=3)\n        \n        ax[i//5][i%5].imshow(org, aspect='auto')\n        ax[i//5][i%5].set_title(img_id)\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()\n    ","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:04:03.673964Z","iopub.status.busy":"2022-02-18T12:04:03.672933Z","iopub.status.idle":"2022-02-18T12:04:03.684191Z","shell.execute_reply":"2022-02-18T12:04:03.684767Z","shell.execute_reply.started":"2022-02-18T07:47:58.922465Z"},"papermill":{"duration":0.320816,"end_time":"2022-02-18T12:04:03.684988","exception":false,"start_time":"2022-02-18T12:04:03.364172","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_bound_box()","metadata":{"execution":{"iopub.execute_input":"2022-02-18T12:04:04.30592Z","iopub.status.busy":"2022-02-18T12:04:04.304942Z","iopub.status.idle":"2022-02-18T12:04:06.112215Z","shell.execute_reply":"2022-02-18T12:04:06.11153Z","shell.execute_reply.started":"2022-02-18T07:47:58.923752Z"},"papermill":{"duration":2.117275,"end_time":"2022-02-18T12:04:06.112593","exception":true,"start_time":"2022-02-18T12:04:03.995318","status":"failed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Foreground extraction","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"def forgrd_ext(img, rec):\n    mask= np.zeros(img.shape[:2], np.uint8)\n    bgmodel= np.zeros((1,65), np.float64)\n    fgmodel= np.zeros((1,65), np.float64)\n    cv2.grabCut(img, mask, rec, bgmodel, fgmodel, 3, cv2.GC_INIT_WITH_RECT)\n    mask2= np.where((mask==2)|(mask==0), 0, 1).astype('uint8')\n    img= img*mask2[:,:,np.newaxis]\n    img[np.where((img == [0,0,0]).all(axis = 2))] = [255.0, 255.0, 255.0]\n    return img\n\ndef ext_frgd():\n    f, ax = plt.subplots(3, 5, figsize=(40,20))\n    for i in tqdm(range(15)):\n        path= TRAIN_PATHS[i]\n        img_id= df.id[i]\n        img=load(path,128)\n        org=img.copy()\n        img= k_means(img, n_colors= 8)\n        \n        img_gray= cv2.cvtColor(np.uint8(img*255), cv2.COLOR_RGB2GRAY)\n        img_gray= cv2.medianBlur(img_gray,7)\n        edges = cv2.Canny(img_gray,100,200)\n        \n        kernel= cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n        \n        top,bottom,left,right = find_box(edges)\n        rec= (left[0], top[1], right[0]-left[0], bottom[1]-top[1])\n        forground_img= forgrd_ext(org, rec)\n        \n        ax[i//5][i%5].imshow(forground_img, aspect='auto')\n        ax[i//5][i%5].set_title(img_id)\n        ax[i//5][i%5].set_xticks([]); ax[i//5][i%5].set_yticks([])\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:47:58.924615Z","iopub.status.idle":"2022-02-18T07:47:58.925223Z","shell.execute_reply":"2022-02-18T07:47:58.925094Z","shell.execute_reply.started":"2022-02-18T07:47:58.925075Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ext_frgd()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:47:58.925991Z","iopub.status.idle":"2022-02-18T07:47:58.926243Z","shell.execute_reply":"2022-02-18T07:47:58.926127Z","shell.execute_reply.started":"2022-02-18T07:47:58.92611Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create extraceted images","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"#!mkdir train\n!mkdir test","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:47:58.92715Z","iopub.status.idle":"2022-02-18T07:47:58.927397Z","shell.execute_reply":"2022-02-18T07:47:58.927281Z","shell.execute_reply.started":"2022-02-18T07:47:58.927264Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def train_extract(j):\n    path= TRAIN_PATHS[j]\n    im1= load(path,128)\n    im2= img= k_means(im1 , n_colors= 8)\n    im3= cv2.cvtColor(np.uint8(im2*255), cv2.COLOR_RGB2GRAY)\n    im3= cv2.medianBlur(im3,5)\n    im3 = cv2.Canny(im3,100,200)\n    kernel= cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n    im31 = cv2.morphologyEx(im3, cv2.MORPH_CLOSE, kernel)\n    top,bottom,left,right = find_box(im31)\n    if top!=(0,0):\n        im4=cv2.rectangle(im1.copy(), (left[0], top[1]), (right[0], bottom[1]), (0, 255, 0), thickness=3)\n        rec= (left[0], top[1], right[0]-left[0], bottom[1]-top[1])\n        im5= forgrd_ext(im1, rec)\n        cv2.imwrite('./train/'+path.split('/')[-1],cv2.cvtColor(im5,cv2.COLOR_BGR2RGB))\n        return im5\n    else:\n        return\n\n#for i in tqdm(range(3)):\nfor i in tqdm(range(len(TRAIN_PATHS))):\n    train_extract(i)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:47:58.928096Z","iopub.status.idle":"2022-02-18T07:47:58.928342Z","shell.execute_reply":"2022-02-18T07:47:58.928226Z","shell.execute_reply.started":"2022-02-18T07:47:58.928208Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"def test_extract(j):\n    path= TEST_PATHS[j]\n    im1= load(path,128)\n    im2= img= k_means(im1, n_colors= 8)\n    im3= cv2.cvtColor(np.uint8(im2*255), cv2.COLOR_RGB2GRAY)\n    im3= cv2.medianBlur(im3,5)\n    im3 = cv2.Canny(im3,100,200)\n    kernel= cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n    im31 = cv2.morphologyEx(im3, cv2.MORPH_CLOSE, kernel)\n    top,bottom,left,right = find_box(im31)\n    if top!=(0,0) and top!=bottom:\n        im4=cv2.rectangle(im1.copy(), (left[0], top[1]), (right[0], bottom[1]), (0, 255, 0), thickness=3)\n        rec= (left[0], top[1], right[0]-left[0], bottom[1]-top[1])\n        im5= forgrd_ext(im1, rec)\n        cv2.imwrite('./test/'+path.split('/')[-1],cv2.cvtColor(im5,cv2.COLOR_BGR2RGB))\n        return im5\n    else:\n        return\n    \n#for i in tqdm(range(3)):\nfor i in tqdm(range(len(TEST_PATHS))):\n    test_extract(i)","metadata":{"execution":{"iopub.execute_input":"2022-02-18T00:33:44.302078Z","iopub.status.busy":"2022-02-18T00:33:44.301821Z","iopub.status.idle":"2022-02-18T00:33:48.899199Z","shell.execute_reply":"2022-02-18T00:33:48.898514Z","shell.execute_reply.started":"2022-02-18T00:33:44.302051Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]}]}