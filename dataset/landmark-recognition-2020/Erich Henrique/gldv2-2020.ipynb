{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Google Landmark Recognition Challenge 2020\nSimplified image similarity ranking and re-ranking implementation with:\n* EfficientNetB0 backbone for global feature similarity search\n* DELF module for local feature reranking\n\nReference papers:\n* 2020 Recognition challenge winner: https://arxiv.org/abs/2010.01650\n* 2019 Recognition challend 2nd place: https://arxiv.org/abs/1906.03990","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:50:50.300323Z","iopub.execute_input":"2022-04-10T05:50:50.300901Z","iopub.status.idle":"2022-04-10T05:50:51.017336Z","shell.execute_reply.started":"2022-04-10T05:50:50.300864Z","shell.execute_reply":"2022-04-10T05:50:51.016467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing libraries\nimport os\nimport cv2\nimport shutil\nimport numpy as np\nimport pandas as pd\nfrom scipy import spatial\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:50:53.86949Z","iopub.execute_input":"2022-04-10T05:50:53.869772Z","iopub.status.idle":"2022-04-10T05:51:00.004532Z","shell.execute_reply.started":"2022-04-10T05:50:53.869741Z","shell.execute_reply":"2022-04-10T05:51:00.003791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directories and file paths\nTRAIN_DIR = '../input/landmark-recognition-2020/train'\nTRAIN_CSV = '../input/landmark-recognition-2020/train.csv'\ntrain_df = pd.read_csv(TRAIN_CSV)\n\nTRAIN_PATHS = [os.path.join(TRAIN_DIR, f'{img[0]}/{img[1]}/{img[2]}/{img}.jpg') for img in train_df['id']]\ntrain_df['path'] = TRAIN_PATHS\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:51:00.007271Z","iopub.execute_input":"2022-04-10T05:51:00.007525Z","iopub.status.idle":"2022-04-10T05:51:05.262102Z","shell.execute_reply.started":"2022-04-10T05:51:00.00749Z","shell.execute_reply":"2022-04-10T05:51:05.261436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Subsetting\ntrain_df_grouped = pd.DataFrame(train_df.landmark_id.value_counts())\ntrain_df_grouped.reset_index(inplace=True)\ntrain_df_grouped.columns = ['landmark_id','count']\n\n# Selected landmarks based on inclass frequency\nselected_landmarks = train_df_grouped[(train_df_grouped['count'] <= 155) & (train_df_grouped['count'] >= 150)]\n\ntrain_df_sub = train_df[train_df['landmark_id'].isin(selected_landmarks['landmark_id'])]\nnew_id = []\ncurrent_id = 0\nprevious_id = int(train_df_sub.head(1)['landmark_id'])\nfor landmark_id in train_df_sub['landmark_id']:\n    if landmark_id == previous_id:\n        new_id.append(current_id)\n    else:\n        current_id += 1\n        new_id.append(current_id)\n        previous_id = landmark_id\n\ntrain_df_sub['new_id'] = new_id\n\nNUM_CLASSES = train_df_sub['landmark_id'].nunique()\n\nprint(f\"Unique classes found: {NUM_CLASSES}\")\ntrain_df_sub","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:51:23.798978Z","iopub.execute_input":"2022-04-10T05:51:23.799647Z","iopub.status.idle":"2022-04-10T05:51:23.866489Z","shell.execute_reply.started":"2022-04-10T05:51:23.799613Z","shell.execute_reply":"2022-04-10T05:51:23.865803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training and validation splits\n# 90/10 stratified split for training and validation\nX_train, X_val, y_train, y_val = train_test_split(train_df_sub[['id', 'path']], train_df_sub['new_id'],\n                                                  train_size = 0.9,\n                                                  random_state = 123,\n                                                  shuffle = True,\n                                                  stratify = train_df_sub['new_id'])\n\n# Held-out test set for inference\n# Further 95/5 split -> 5% of original training set left for test set\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\n                                                   train_size = 0.95,\n                                                   random_state = 123,\n                                                   shuffle = True,\n                                                   stratify = y_train)\n\nassert X_train.shape[0] + X_val.shape[0] + X_test.shape[0] == train_df_sub.shape[0]\n\nprint(f\"Training data shape: {X_train.shape}\")\nprint(f\"Training label shape: {y_train.shape}\")\nprint(f\"Validation data shape: {X_val.shape}\")\nprint(f\"Validation label shape: {y_val.shape}\")\nprint(f\"Test data shape: {X_test.shape}\")\nprint(f\"Test label shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:51:34.363226Z","iopub.execute_input":"2022-04-10T05:51:34.363789Z","iopub.status.idle":"2022-04-10T05:51:34.393436Z","shell.execute_reply.started":"2022-04-10T05:51:34.363751Z","shell.execute_reply":"2022-04-10T05:51:34.392486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Unique classes on y_train: {y_train.nunique()}\")\nprint(f\"Unique classes on y_val: {y_val.nunique()}\")\nprint(f\"Unique classes on y_test: {y_test.nunique()}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:51:37.573087Z","iopub.execute_input":"2022-04-10T05:51:37.573765Z","iopub.status.idle":"2022-04-10T05:51:37.579747Z","shell.execute_reply.started":"2022-04-10T05:51:37.573705Z","shell.execute_reply":"2022-04-10T05:51:37.579049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classes distribution on training, validation and test sets\nplt.figure(figsize = (10, 3))\nax = sns.histplot(y_train, bins=75, kde = True)\nax.set_title('Distribution of Landmarks on training set')\nplt.tight_layout()\n\nplt.figure(figsize = (10, 3))\nax = sns.histplot(y_val, bins=75, kde = True)\nax.set_title('Distribution of Landmarks on validation set')\nplt.tight_layout()\n\nplt.figure(figsize = (10, 3))\nax = sns.histplot(y_test, bins=75, kde = True)\nax.set_title('Distribution of Landmarks on test set')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:51:40.69358Z","iopub.execute_input":"2022-04-10T05:51:40.694124Z","iopub.status.idle":"2022-04-10T05:51:41.906723Z","shell.execute_reply.started":"2022-04-10T05:51:40.694086Z","shell.execute_reply":"2022-04-10T05:51:41.90589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r train_sub, test_sub, val_sub && ls","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:51:52.124345Z","iopub.execute_input":"2022-04-10T05:51:52.124948Z","iopub.status.idle":"2022-04-10T05:51:52.802637Z","shell.execute_reply.started":"2022-04-10T05:51:52.124908Z","shell.execute_reply":"2022-04-10T05:51:52.801784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating image directories for classes subset\nNEW_BASE_DIR = \"/kaggle/working\"\n\n# Training set directory\nfor file, path, landmark in tqdm(zip(X_train['id'], X_train['path'], y_train)):\n    dir = f\"{NEW_BASE_DIR}/train_sub/{str(landmark)}\"\n    os.makedirs(dir, exist_ok = True)\n    fname = f\"{file}.jpg\"\n    shutil.copyfile(src = path, dst = f\"{dir}/{fname}\")\n\n# Validation set directory    \nfor file, path, landmark in tqdm(zip(X_val['id'], X_val['path'], y_val)):\n    dir = f\"{NEW_BASE_DIR}/val_sub/{str(landmark)}\"\n    os.makedirs(dir, exist_ok = True)\n    fname = f\"{file}.jpg\"\n    shutil.copyfile(src = path, dst = f\"{dir}/{fname}\")\n\n# Training set directory\nfor file, path, landmark in tqdm(zip(X_test['id'], X_test['path'], y_test)):\n    dir = f\"{NEW_BASE_DIR}/test_sub/{str(landmark)}\"\n    os.makedirs(dir, exist_ok = True)\n    fname = f\"{file}.jpg\"\n    shutil.copyfile(src = path, dst = f\"{dir}/{fname}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:51:54.255583Z","iopub.execute_input":"2022-04-10T05:51:54.255885Z","iopub.status.idle":"2022-04-10T05:53:32.140259Z","shell.execute_reply.started":"2022-04-10T05:51:54.255853Z","shell.execute_reply":"2022-04-10T05:53:32.139532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:53:43.939699Z","iopub.execute_input":"2022-04-10T05:53:43.93996Z","iopub.status.idle":"2022-04-10T05:53:44.617399Z","shell.execute_reply.started":"2022-04-10T05:53:43.93993Z","shell.execute_reply":"2022-04-10T05:53:44.616454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd train_sub && ls","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:53:46.035008Z","iopub.execute_input":"2022-04-10T05:53:46.035659Z","iopub.status.idle":"2022-04-10T05:53:46.70662Z","shell.execute_reply.started":"2022-04-10T05:53:46.035621Z","shell.execute_reply":"2022-04-10T05:53:46.705753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating tensorflow tf.data.Dataset\nfrom tensorflow.keras.utils import image_dataset_from_directory\n\nIMG_SIZE = 224\nBATCH_SIZE = 16\n\nprint(\"Building training dataset...\")\n# Training tf.data.Dataset\ntrain_ds = image_dataset_from_directory(f\"{NEW_BASE_DIR}/train_sub\",\n                                        label_mode = 'int',\n                                        shuffle = True,\n                                        image_size = (IMG_SIZE, IMG_SIZE),\n                                        batch_size = BATCH_SIZE)\n\nprint(\"Building validation dataset...\")\n# Validation tf.data.Dataset\nval_ds = image_dataset_from_directory(f\"{NEW_BASE_DIR}/val_sub\",\n                                        label_mode = 'int',\n                                        shuffle = True,\n                                        image_size = (IMG_SIZE, IMG_SIZE),\n                                        batch_size = BATCH_SIZE)\n\nprint(\"Building test dataset...\")\n# Test tf.data.Dataset\ntest_ds = image_dataset_from_directory(f\"{NEW_BASE_DIR}/test_sub\",\n                                        label_mode = 'int',\n                                        shuffle = True,\n                                        image_size = (IMG_SIZE, IMG_SIZE),\n                                        batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:53:55.619697Z","iopub.execute_input":"2022-04-10T05:53:55.619962Z","iopub.status.idle":"2022-04-10T05:53:56.221606Z","shell.execute_reply.started":"2022-04-10T05:53:55.619933Z","shell.execute_reply":"2022-04-10T05:53:56.220839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing a random batch from training dataset\nfor data_batch, labels_batch in train_ds.take(1):\n    ncols = 4\n    nrows = int(data_batch.shape[0]/ncols)\n    fig, ax = plt.subplots(nrows = nrows, ncols = ncols, figsize=(10, 11),\n                           sharex = True, sharey = True)\n    img_counter = 0\n    for image, label in zip(data_batch, labels_batch):\n        axi = ax.flat[img_counter]\n        axi.imshow(image/255.)\n        label = label.numpy()\n#         axi.set_title(np.where(label == 1)[0])\n        axi.set_title(label)\n        img_counter += 1\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:54:15.012816Z","iopub.execute_input":"2022-04-10T05:54:15.013145Z","iopub.status.idle":"2022-04-10T05:54:17.525579Z","shell.execute_reply.started":"2022-04-10T05:54:15.013104Z","shell.execute_reply":"2022-04-10T05:54:17.524909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####### ALTERNATIVE CODE FOR UNBATCHED DATASET #######\n# ncols = 4\n# nrows = 4\n# fig, ax = plt.subplots(nrows = nrows, ncols = ncols, figsize=(10, 11),\n#                        sharex = True, sharey = True)\n# img_counter = 0\n# for image, label in train_ds.take(16):\n#     axi = ax.flat[img_counter]\n#     axi.imshow(image[0]/255.)\n#     label = label.numpy()\n# #         axi.set_title(np.where(label == 1)[0])\n#     axi.set_title(label)\n#     img_counter += 1\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:36:37.597366Z","iopub.execute_input":"2022-04-10T05:36:37.597852Z","iopub.status.idle":"2022-04-10T05:36:37.602307Z","shell.execute_reply.started":"2022-04-10T05:36:37.597814Z","shell.execute_reply":"2022-04-10T05:36:37.601405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining a data augmentation stage\nimg_augmentation = tf.keras.Sequential(\n    # [layers.RandomFlip(\"horizontal\"),\n    [layers.RandomTranslation(height_factor = 0.1, width_factor = 0.1),\n     layers.RandomRotation(0.02),\n     layers.RandomZoom(0.2)],\n     name = \"img_augmentation\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:54:44.253763Z","iopub.execute_input":"2022-04-10T05:54:44.254057Z","iopub.status.idle":"2022-04-10T05:54:44.286722Z","shell.execute_reply.started":"2022-04-10T05:54:44.254007Z","shell.execute_reply":"2022-04-10T05:54:44.285941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displaying variations of a randomly augmented training image\nplt.figure(figsize=(9, 9))\nfor image, label in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = img_augmentation(image, training = True)\n        plt.imshow(augmented_image[15].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:55:01.849528Z","iopub.execute_input":"2022-04-10T05:55:01.849793Z","iopub.status.idle":"2022-04-10T05:55:02.988544Z","shell.execute_reply.started":"2022-04-10T05:55:01.849764Z","shell.execute_reply":"2022-04-10T05:55:02.987894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####### ALTERNATIVE CODE FOR UNBATCHED DATASET #######\n# # Displaying variations of a randomly augmented training image\n# plt.figure(figsize=(9, 9))\n# for image, label in train_ds.take(16):\n#     for i in range(9):\n#         ax = plt.subplot(3, 3, i + 1)\n#         augmented_image = img_augmentation(image[0], training = True)\n#         plt.imshow(augmented_image.numpy().astype(\"uint8\"))\n#         plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:36:39.843334Z","iopub.execute_input":"2022-04-10T05:36:39.843591Z","iopub.status.idle":"2022-04-10T05:36:39.849575Z","shell.execute_reply.started":"2022-04-10T05:36:39.843556Z","shell.execute_reply":"2022-04-10T05:36:39.847298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB0\n\nMODELS_DIR = f\"{NEW_BASE_DIR}/models\"\n\nos.makedirs(MODELS_DIR, exist_ok = True)\n\n# Model instantiator\ndef build_model(num_classes = None):\n    inputs = keras.Input(shape = (IMG_SIZE, IMG_SIZE, 3))\n    x = img_augmentation(inputs)\n    # EfficientNetB0 backbone\n    model = EfficientNetB0(input_tensor = x,\n                           weights = 'imagenet',\n                           include_top = False,\n                           drop_connect_rate = DROP_CONNECT_RATE)\n    \n    # Freeze pretrained weights\n    model.trainable = False\n    \n    # Rebuild top\n    x = layers.GlobalAveragePooling2D(name = \"avg_pool\")(model.output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(TOP_DROPOUT_RATE, name = \"top_dropout\")(x)\n    \n    # Embedding\n    embedding = layers.Dense(512, name = \"embedding_512\")(x)\n    outputs = layers.Dense(num_classes, activation = \"softmax\", name = \"softmax\")(embedding)\n    \n    # Compile\n    model = tf.keras.Model(inputs, outputs, name = \"EfficientNetB0\")\n    optimizer = tf.keras.optimizers.Adam(learning_rate = ADAM_LR)\n    model.compile(optimizer = optimizer,\n                 loss = \"sparse_categorical_crossentropy\",\n                 metrics = [\"accuracy\"])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:55:34.409237Z","iopub.execute_input":"2022-04-10T05:55:34.409924Z","iopub.status.idle":"2022-04-10T05:55:34.421135Z","shell.execute_reply.started":"2022-04-10T05:55:34.409885Z","shell.execute_reply":"2022-04-10T05:55:34.420345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Model summaries\n# tf.keras.utils.plot_model(model)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:36:41.286389Z","iopub.execute_input":"2022-04-10T05:36:41.287382Z","iopub.status.idle":"2022-04-10T05:36:41.294653Z","shell.execute_reply.started":"2022-04-10T05:36:41.287343Z","shell.execute_reply":"2022-04-10T05:36:41.293705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training history visualization\ndef plot_hist(hist):\n    plt.plot(hist.history[\"accuracy\"])\n    plt.plot(hist.history[\"val_accuracy\"])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:55:59.638962Z","iopub.execute_input":"2022-04-10T05:55:59.639236Z","iopub.status.idle":"2022-04-10T05:55:59.644898Z","shell.execute_reply.started":"2022-04-10T05:55:59.639206Z","shell.execute_reply":"2022-04-10T05:55:59.644022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiating model\n# Hyperparameters\nDROP_CONNECT_RATE = 0.2 # Dropout rate for stochastic depth on EfficientNet\nTOP_DROPOUT_RATE = 0.2  # Top dropout\nINIT_LR = 5e-3          # Initial learning rate\nEPOCHS = 20\n# Adam optimizer learning rate schedule\nADAM_LR = tf.keras.optimizers.schedules.ExponentialDecay(\n    INIT_LR,\n    decay_steps=100,\n    decay_rate=0.96,\n    staircase=True)\n\nmodel = build_model(num_classes = NUM_CLASSES)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:01:02.861707Z","iopub.execute_input":"2022-04-10T07:01:02.86198Z","iopub.status.idle":"2022-04-10T07:01:04.450128Z","shell.execute_reply.started":"2022-04-10T07:01:02.861949Z","shell.execute_reply":"2022-04-10T07:01:04.449445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-04-10T05:56:10.318837Z","iopub.execute_input":"2022-04-10T05:56:10.319234Z","iopub.status.idle":"2022-04-10T05:56:11.015105Z","shell.execute_reply.started":"2022-04-10T05:56:10.319202Z","shell.execute_reply":"2022-04-10T05:56:11.014057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training embedding layer\nmodel_file_path = os.path.join(MODELS_DIR, \"EfficientNetB0_softmax.keras\")\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(model_file_path,\n                                    save_best_only=True,\n                                    monitor = \"val_accuracy\"),\n    keras.callbacks.EarlyStopping(patience = 2,\n                                  monitor = \"val_accuracy\")]\n\nhist = model.fit(train_ds,\n                 epochs = EPOCHS,\n                 validation_data = val_ds,\n                 shuffle = 'batch',\n                 callbacks = callbacks)\n\nplot_hist(hist)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:01:06.828547Z","iopub.execute_input":"2022-04-10T07:01:06.829303Z","iopub.status.idle":"2022-04-10T07:09:15.224362Z","shell.execute_reply.started":"2022-04-10T07:01:06.829266Z","shell.execute_reply":"2022-04-10T07:09:15.223681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluating best model\nmodel = keras.models.load_model(model_file_path)\nprint(\"Predictions on validation set...\")\nprint(f\"Validation accuracy: {model.evaluate(val_ds)[1]*100:.2f} %\")\nprint(\"Predictions on test set...\")\nprint(f\"Test accuracy: {model.evaluate(test_ds)[1]*100:.2f} %\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:09:25.104871Z","iopub.execute_input":"2022-04-10T07:09:25.105394Z","iopub.status.idle":"2022-04-10T07:09:33.579624Z","shell.execute_reply.started":"2022-04-10T07:09:25.105355Z","shell.execute_reply":"2022-04-10T07:09:33.578893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EfficientNetB7","metadata":{}},{"cell_type":"code","source":"# Evaluating best model\n# model = keras.models.load_model(os.path.join(MODELS_DIR, \"EfficientNetB7_softmax.keras\"))\n# print(\"Predictions on validation set...\")\n# print(f\"Validation accuracy: {model.evaluate(val_ds)[1]*100:.2f} %\")\n# print(\"Predictions on test set...\")\n# print(f\"Test accuracy: {model.evaluate(test_ds)[1]*100:.2f} %\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EfficientNetB3","metadata":{}},{"cell_type":"code","source":"# Evaluating best model\n# model = keras.models.load_model(os.path.join(MODELS_DIR, \"EfficientNetB3_softmax.keras\"))\n# print(\"Predictions on validation set...\")\n# print(f\"Validation accuracy: {model.evaluate(val_ds)[1]*100:.2f} %\")\n# print(\"Predictions on test set...\")\n# print(f\"Test accuracy: {model.evaluate(test_ds)[1]*100:.2f} %\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EfficientNetB0","metadata":{}},{"cell_type":"code","source":"# Evaluating best model\n# model = keras.models.load_model(os.path.join(MODELS_DIR, \"EfficientNetB0_softmax.keras\"))\n# print(\"Predictions on validation set...\")\n# print(f\"Validation accuracy: {model.evaluate(val_ds)[1]*100:.2f} %\")\n# print(\"Predictions on test set...\")\n# print(f\"Test accuracy: {model.evaluate(test_ds)[1]*100:.2f} %\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cosine Similarity\nPairwise query: key search for similarity candidates. In the following example:\n* Query images: validation set\n* Key images: training set","metadata":{}},{"cell_type":"code","source":"# Auxiliar functions\n# Load image\ndef get_image(path, resize = False, reshape = False, target_size = None):\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    if resize:\n        img = cv2.resize(img, dsize = (target_size, target_size))\n    if reshape:\n        img = tf.reshape(img, [1, target_size, target_size, 3])\n    return img\n\n# Get landmark samples\ndef get_landmark(landmark_id, samples = 16):\n    nrows = samples // 4\n    random_imgs = np.random.choice(train_df_sub[train_df_sub['new_id'] == landmark_id].index, samples, replace = False)\n    plt.figure(figsize = (12, 10))\n    for i, img in enumerate(train_df_sub.loc[random_imgs, :].values):\n        ax = plt.subplot(nrows, 4, i + 1)\n        plt.imshow(get_image(img[2]))\n        plt.title(f\"{img[0]}\")\n        plt.suptitle(f\"Samples of landmark {landmark_id}\", fontsize = 14, y = 0.94, weight = \"bold\")\n        plt.axis(\"off\")\n\n# Get image embeddings\ndef get_embeddings(model, image_paths, input_size, as_df = True):\n    embeddings = {}\n    embeddings['images_paths'] = []\n    embeddings['embedded_images'] = []\n    \n    target_dir = os.path.split(os.path.split(image_paths[0])[0])[0]\n    \n    print(f\"Retrieving embeddings for {target_dir} with {model.name}...\")\n    for image_path in tqdm(image_paths):\n        embeddings['images_paths'].append(image_path)\n        embedded_image = model.predict(get_image(image_path,\n                                                 resize = True,\n                                                 reshape = True,\n                                                 target_size = input_size))\n        embeddings['embedded_images'].append(embedded_image)\n    \n    if as_df:\n        embeddings = pd.DataFrame(embeddings)\n    \n    return embeddings\n\n# Get similarities between query key pair\ndef get_similarities(query, key):\n    '''\n    Get cosine similarity matrix between query and key pairs\n    Arguments:\n    query, key: embedded images\n    '''\n    query_array = np.stack(query.tolist()).reshape(query.shape[0],\n                                                   query[0].shape[1])\n    key_array = np.stack(key.tolist()).reshape(key.shape[0],\n                                               key[0].shape[1])\n    \n    # Initializing similarity matrix\n    similarity = np.zeros((query_array.shape[0], key_array.shape[0]))\n    \n    # Getting pairwise similarities\n    print(f\"Getting pairwise {query_array.shape[0]} query: {key_array.shape[0]} key similarities...\")\n    for query_index in tqdm(range(query_array.shape[0])):\n        similarity[query_index] = 1 - spatial.distance.cdist(query_array[np.newaxis, query_index, :],\n                                                             key_array,\n                                                             'cosine')[0]\n    return similarity\n\n# Plot top ranked images\ndef plot_similar(similar_imgs, img_paths):\n    '''\n    Plot top N similar samples from similarity index\n    '''\n    plt.figure(figsize = (18, 6))\n    nrows = similar_imgs.shape[0]//5\n    for i, img in enumerate(similar_imgs):\n        ax = plt.subplot(nrows, 5, i + 1)\n        plt.imshow(get_image(img_paths[img]))\n        plt.title(f\"Landmark id: {os.path.split(os.path.split(img_paths[img])[0])[1]}\")\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:04:18.979646Z","iopub.execute_input":"2022-04-10T06:04:18.979909Z","iopub.status.idle":"2022-04-10T06:04:18.999623Z","shell.execute_reply.started":"2022-04-10T06:04:18.979879Z","shell.execute_reply":"2022-04-10T06:04:18.998954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding models\nembedding_layer = 'embedding_512'\nembedding_model = tf.keras.Model(inputs = model.input,\n                                 outputs = model.get_layer(embedding_layer).output,\n                                 name = \"EfficientNetB0_embed512\")","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:09:40.086475Z","iopub.execute_input":"2022-04-10T07:09:40.086735Z","iopub.status.idle":"2022-04-10T07:09:40.107368Z","shell.execute_reply.started":"2022-04-10T07:09:40.086706Z","shell.execute_reply":"2022-04-10T07:09:40.106701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Retrieving embeddings\ntrain_img_paths = train_ds.file_paths\nval_img_paths = val_ds.file_paths\n\ntrain_embeddings = get_embeddings(model = embedding_model,\n                                 image_paths = train_img_paths,\n                                 input_size = IMG_SIZE)\n\nval_embeddings = get_embeddings(model = embedding_model,\n                                 image_paths = val_img_paths,\n                                 input_size = IMG_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:09:45.482221Z","iopub.execute_input":"2022-04-10T07:09:45.482485Z","iopub.status.idle":"2022-04-10T07:18:53.792726Z","shell.execute_reply.started":"2022-04-10T07:09:45.482457Z","shell.execute_reply":"2022-04-10T07:18:53.791922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:14:18.743873Z","iopub.execute_input":"2022-04-10T06:14:18.744417Z","iopub.status.idle":"2022-04-10T06:14:18.761861Z","shell.execute_reply.started":"2022-04-10T06:14:18.744376Z","shell.execute_reply":"2022-04-10T06:14:18.760652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_embeddings.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:14:20.780902Z","iopub.execute_input":"2022-04-10T06:14:20.781356Z","iopub.status.idle":"2022-04-10T06:14:20.809032Z","shell.execute_reply.started":"2022-04-10T06:14:20.781309Z","shell.execute_reply":"2022-04-10T06:14:20.808104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_train_similarity = get_similarities(val_embeddings['embedded_images'],\n                                        train_embeddings['embedded_images'])\nval_train_similarity.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:19:44.945145Z","iopub.execute_input":"2022-04-10T07:19:44.945399Z","iopub.status.idle":"2022-04-10T07:20:03.271502Z","shell.execute_reply.started":"2022-04-10T07:19:44.945371Z","shell.execute_reply":"2022-04-10T07:20:03.270806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating confidence score per submission\ndef confidence_top(query = None, key = None, similarity = None, query_image_index = None, top = 5):\n    '''\n    Arguments:\n    query_image_index = index of query image on similarity matrix query axis\n    Return confidence scores for top N predictions\n    '''\n    query_paths = query['images_paths']\n    key_paths = key['images_paths']\n    \n    similar_n = np.argsort(similarity[query_image_index])[::-1][:top]\n    \n    confidence_df = {}    \n    confidence_df['top_similar'] = []\n    for similar in similar_n:\n        confidence_df['top_similar'].append(similar)\n\n    confidence_df['image_paths'] = []\n    for similar in similar_n:\n        similar_image_path = key_paths[similar]\n        confidence_df['image_paths'].append(similar_image_path)    \n        \n    confidence_df['prediction'] = []\n    for similar in similar_n:\n        similar_image_path = key_paths[similar]\n        y = int(os.path.split(os.path.split(similar_image_path)[0])[1])\n        confidence_df['prediction'].append(y)  \n    \n    confidence_df['cos_similarity'] = []\n    for similar in similar_n:\n        confidence_df['cos_similarity'].append(similarity[query_image_index][similar]) \n    \n    return pd.DataFrame(confidence_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:14:42.407697Z","iopub.execute_input":"2022-04-10T06:14:42.40813Z","iopub.status.idle":"2022-04-10T06:14:42.417372Z","shell.execute_reply.started":"2022-04-10T06:14:42.408093Z","shell.execute_reply":"2022-04-10T06:14:42.416669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 0\ntop_n = 5\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:15:51.930693Z","iopub.execute_input":"2022-04-10T06:15:51.930956Z","iopub.status.idle":"2022-04-10T06:15:52.864371Z","shell.execute_reply.started":"2022-04-10T06:15:51.930927Z","shell.execute_reply":"2022-04-10T06:15:52.863525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:15:55.218979Z","iopub.execute_input":"2022-04-10T06:15:55.219528Z","iopub.status.idle":"2022-04-10T06:15:55.233318Z","shell.execute_reply.started":"2022-04-10T06:15:55.219491Z","shell.execute_reply":"2022-04-10T06:15:55.232666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 4\ntop_n = 5\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:30:32.012851Z","iopub.execute_input":"2022-04-10T06:30:32.013552Z","iopub.status.idle":"2022-04-10T06:30:32.779857Z","shell.execute_reply.started":"2022-04-10T06:30:32.013504Z","shell.execute_reply":"2022-04-10T06:30:32.779202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:30:46.081515Z","iopub.execute_input":"2022-04-10T06:30:46.081783Z","iopub.status.idle":"2022-04-10T06:30:46.09572Z","shell.execute_reply.started":"2022-04-10T06:30:46.081752Z","shell.execute_reply":"2022-04-10T06:30:46.094971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 5\ntop_n = 5\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:30:53.563229Z","iopub.execute_input":"2022-04-10T06:30:53.563478Z","iopub.status.idle":"2022-04-10T06:30:54.406411Z","shell.execute_reply.started":"2022-04-10T06:30:53.56345Z","shell.execute_reply":"2022-04-10T06:30:54.405025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:31:06.361125Z","iopub.execute_input":"2022-04-10T06:31:06.361662Z","iopub.status.idle":"2022-04-10T06:31:06.374499Z","shell.execute_reply.started":"2022-04-10T06:31:06.361623Z","shell.execute_reply":"2022-04-10T06:31:06.373718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 11\ntop_n = 5\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:36:27.191464Z","iopub.execute_input":"2022-04-10T06:36:27.191737Z","iopub.status.idle":"2022-04-10T06:36:28.046Z","shell.execute_reply.started":"2022-04-10T06:36:27.191706Z","shell.execute_reply":"2022-04-10T06:36:28.045343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:36:46.504796Z","iopub.execute_input":"2022-04-10T06:36:46.505072Z","iopub.status.idle":"2022-04-10T06:36:46.517305Z","shell.execute_reply.started":"2022-04-10T06:36:46.50504Z","shell.execute_reply":"2022-04-10T06:36:46.516525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 92\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:30:29.145721Z","iopub.execute_input":"2022-04-10T07:30:29.145977Z","iopub.status.idle":"2022-04-10T07:30:30.37053Z","shell.execute_reply.started":"2022-04-10T07:30:29.145948Z","shell.execute_reply":"2022-04-10T07:30:30.369842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:30:39.472953Z","iopub.execute_input":"2022-04-10T07:30:39.473628Z","iopub.status.idle":"2022-04-10T07:30:39.488197Z","shell.execute_reply.started":"2022-04-10T07:30:39.473592Z","shell.execute_reply":"2022-04-10T07:30:39.487564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Object oclusion example\nObject oclusion is only one of the examples of how a local feature reranking method improves query performance","metadata":{}},{"cell_type":"code","source":"query_image_index = 573\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:24:06.035498Z","iopub.execute_input":"2022-04-10T07:24:06.035757Z","iopub.status.idle":"2022-04-10T07:24:07.384484Z","shell.execute_reply.started":"2022-04-10T07:24:06.035727Z","shell.execute_reply":"2022-04-10T07:24:07.383862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:24:42.363625Z","iopub.execute_input":"2022-04-10T07:24:42.363893Z","iopub.status.idle":"2022-04-10T07:24:42.378577Z","shell.execute_reply.started":"2022-04-10T07:24:42.363864Z","shell.execute_reply":"2022-04-10T07:24:42.377906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DELF module\nLocal features search\n\nReferences:\n* Large-Scale Image Retrieval with Attentive Deep Local Features: https://arxiv.org/abs/1612.06321\n* DELF on Tensorflow Hub: https://github.com/tensorflow/models/tree/master/research/delf\n","metadata":{}},{"cell_type":"code","source":"DELF_IMG_SIZE = 600","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:16:17.475601Z","iopub.execute_input":"2022-04-10T06:16:17.475871Z","iopub.status.idle":"2022-04-10T06:16:17.479548Z","shell.execute_reply.started":"2022-04-10T06:16:17.475842Z","shell.execute_reply":"2022-04-10T06:16:17.47872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_1 = get_image(val_embeddings['images_paths'][573],\n                    resize = True,\n                    target_size = DELF_IMG_SIZE)\n\nplt.figure(figsize = (6, 6))\nplt.imshow(image_1)\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:21:38.56139Z","iopub.execute_input":"2022-04-10T07:21:38.561644Z","iopub.status.idle":"2022-04-10T07:21:38.766495Z","shell.execute_reply.started":"2022-04-10T07:21:38.561615Z","shell.execute_reply":"2022-04-10T07:21:38.765855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_2 = get_image(train_embeddings['images_paths'][similar_n[5]],\n                     resize = True,\n                     target_size = DELF_IMG_SIZE)\n\nplt.figure(figsize = (6, 6))\nplt.imshow(image_2)\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:21:51.981631Z","iopub.execute_input":"2022-04-10T07:21:51.9823Z","iopub.status.idle":"2022-04-10T07:21:52.179025Z","shell.execute_reply.started":"2022-04-10T07:21:51.982263Z","shell.execute_reply":"2022-04-10T07:21:52.178356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from absl import logging\nfrom PIL import Image, ImageOps\nfrom scipy.spatial import cKDTree\nfrom skimage.feature import plot_matches\nfrom skimage.measure import ransac\nfrom skimage.transform import AffineTransform\nfrom six import BytesIO\n\nimport tensorflow_hub as hub\nfrom six.moves.urllib.request import urlopen","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:17:13.331612Z","iopub.execute_input":"2022-04-10T06:17:13.332279Z","iopub.status.idle":"2022-04-10T06:17:14.000222Z","shell.execute_reply.started":"2022-04-10T06:17:13.332244Z","shell.execute_reply":"2022-04-10T06:17:13.999522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delf = hub.load('https://tfhub.dev/google/delf/1').signatures['default']","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:17:15.839741Z","iopub.execute_input":"2022-04-10T06:17:15.839999Z","iopub.status.idle":"2022-04-10T06:17:21.712765Z","shell.execute_reply.started":"2022-04-10T06:17:15.83997Z","shell.execute_reply":"2022-04-10T06:17:21.712028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DELF module\ndef run_delf(image):\n    '''\n    Apply DELF module to the input image\n    Arguments:\n    image: np.array resized image\n    '''\n    float_image = tf.image.convert_image_dtype(image, tf.float32)\n\n    return delf(\n      image = float_image,\n      score_threshold = tf.constant(100.0),\n      image_scales = tf.constant([0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0]),\n      max_feature_num = tf.constant(1000))\n\ndef match_images(image1, image2, result1, result2, verbose = True):\n    distance_threshold = 0.8\n\n    # Read features.\n    num_features_1 = result1['locations'].shape[0]\n    num_features_2 = result2['locations'].shape[0]\n    \n    if verbose:\n        print(\"Loaded image 1's %d features\" % num_features_1)\n        print(\"Loaded image 2's %d features\" % num_features_2)\n\n    # Find nearest-neighbor matches using a KD tree.\n    d1_tree = cKDTree(result1['descriptors'])\n    _, indices = d1_tree.query(\n      result2['descriptors'],\n      distance_upper_bound=distance_threshold)\n\n    # Select feature locations for putative matches.\n    locations_2_to_use = np.array([\n      result2['locations'][i,]\n      for i in range(num_features_2)\n      if indices[i] != num_features_1\n    ])\n    locations_1_to_use = np.array([\n      result1['locations'][indices[i],]\n      for i in range(num_features_2)\n      if indices[i] != num_features_1\n    ])\n\n    # Perform geometric verification using RANSAC.\n    _, inliers = ransac(\n      (locations_1_to_use, locations_2_to_use),\n      AffineTransform,\n      min_samples=3,\n      residual_threshold=20,\n      max_trials=1000)\n    \n    if verbose:\n        print('Found %d inliers' % sum(inliers))\n\n    # Visualize correspondences.\n    _, ax = plt.subplots(figsize = (9, 9))\n    inlier_idxs = np.nonzero(inliers)[0]\n    plot_matches(\n      ax,\n      image1,\n      image2,\n      locations_1_to_use,\n      locations_2_to_use,\n      np.column_stack((inlier_idxs, inlier_idxs)),\n      matches_color='b')\n    ax.axis('off')\n    ax.set_title(f'DELF correspondences: Found {sum(inliers)} inliers')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:17:34.0762Z","iopub.execute_input":"2022-04-10T06:17:34.076867Z","iopub.status.idle":"2022-04-10T06:17:34.090378Z","shell.execute_reply.started":"2022-04-10T06:17:34.076829Z","shell.execute_reply":"2022-04-10T06:17:34.087914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delf_result1 = run_delf(image_1)\ndelf_result2 = run_delf(image_2)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:22:03.336771Z","iopub.execute_input":"2022-04-10T07:22:03.337049Z","iopub.status.idle":"2022-04-10T07:22:03.534784Z","shell.execute_reply.started":"2022-04-10T07:22:03.336998Z","shell.execute_reply":"2022-04-10T07:22:03.534068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"match_images(image_1, image_2, delf_result1, delf_result2)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:22:11.749466Z","iopub.execute_input":"2022-04-10T07:22:11.74972Z","iopub.status.idle":"2022-04-10T07:22:13.058444Z","shell.execute_reply.started":"2022-04-10T07:22:11.749692Z","shell.execute_reply":"2022-04-10T07:22:13.056837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_index in similar_n[:6]:\n    key_image = get_image(train_embeddings['images_paths'][image_index],\n                          resize = True,\n                          target_size = DELF_IMG_SIZE)\n    delf_key_image_result = run_delf(key_image)\n    match_images(image_1, key_image, delf_result1, delf_key_image_result, verbose = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:22:24.968616Z","iopub.execute_input":"2022-04-10T07:22:24.968887Z","iopub.status.idle":"2022-04-10T07:22:32.78806Z","shell.execute_reply.started":"2022-04-10T07:22:24.968856Z","shell.execute_reply":"2022-04-10T07:22:32.787299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reranking\nReranking using DELF local features descriptor","metadata":{}},{"cell_type":"code","source":"def delf_rerank(query = None, key = None, query_image_index = None, confidence_df = None, re_sort = True):\n    distance_threshold = 0.8\n    query_paths = query['images_paths']\n    key_paths = key['images_paths']\n    \n    query_image = get_image(query_paths[query_image_index],\n                            resize = True,\n                            target_size = DELF_IMG_SIZE)\n    \n    delf_result_query = run_delf(query_image)\n    \n    # Read query features\n    num_features_query = delf_result_query['locations'].shape[0]\n    \n    inliers_list = []\n    print(f\"Retrieving local features for top {len(confidence_df['image_paths'])} key images...\")\n    for image_path in tqdm(confidence_df['image_paths']):\n        key_image = get_image(image_path,\n                          resize = True,\n                          target_size = DELF_IMG_SIZE)\n        \n        delf_result_key = run_delf(key_image)\n    \n        # Read key features\n        num_features_key = delf_result_key['locations'].shape[0]\n\n        # Find nearest-neighbor matches using a KD tree.\n        d1_tree = cKDTree(delf_result_query['descriptors'])\n        _, indices = d1_tree.query(\n          delf_result_key['descriptors'],\n          distance_upper_bound=distance_threshold)\n\n        # Select feature locations for putative matches.\n        locations_k_to_use = np.array([\n          delf_result_key['locations'][i,]\n          for i in range(num_features_key)\n          if indices[i] != num_features_query\n        ])\n        locations_q_to_use = np.array([\n          delf_result_query['locations'][indices[i],]\n          for i in range(num_features_key)\n          if indices[i] != num_features_query\n        ])\n\n        # Perform geometric verification using RANSAC.\n        try:\n            _, inliers = ransac(\n              (locations_q_to_use, locations_k_to_use),\n              AffineTransform,\n              min_samples=3,\n              residual_threshold=20,\n              max_trials=1000)\n        except:\n            inliers = [0]\n          \n        total_inliers = sum(inliers)\n        inliers_list.append(total_inliers)\n    \n    confidence_df['inliers'] = inliers_list\n    \n    original_confidence = confidence_df['inliers']\n    reranked_confidence = np.sqrt(original_confidence) * confidence_df['cos_similarity']\n    confidence_df['reranked_conf'] = reranked_confidence\n    \n    if re_sort:\n        confidence_df.sort_values('reranked_conf', ascending = False, inplace = True)\n    \n    return confidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:26:13.688954Z","iopub.execute_input":"2022-04-10T06:26:13.689536Z","iopub.status.idle":"2022-04-10T06:26:13.701376Z","shell.execute_reply.started":"2022-04-10T06:26:13.689497Z","shell.execute_reply":"2022-04-10T06:26:13.700509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reranked_df = delf_rerank(query = val_embeddings,\n                          key = train_embeddings,\n                          query_image_index = query_image_index,\n                          confidence_df = confidence_df,\n                          re_sort = True)\nreranked_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:25:01.030726Z","iopub.execute_input":"2022-04-10T07:25:01.030986Z","iopub.status.idle":"2022-04-10T07:25:10.5824Z","shell.execute_reply.started":"2022-04-10T07:25:01.030955Z","shell.execute_reply":"2022-04-10T07:25:10.581523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 573\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = reranked_df['top_similar'][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:25:31.407742Z","iopub.execute_input":"2022-04-10T07:25:31.407998Z","iopub.status.idle":"2022-04-10T07:25:32.7642Z","shell.execute_reply.started":"2022-04-10T07:25:31.407968Z","shell.execute_reply":"2022-04-10T07:25:32.763557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reranking examples","metadata":{}},{"cell_type":"code","source":"query_image_index = 1\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:21:28.621041Z","iopub.execute_input":"2022-04-10T06:21:28.621734Z","iopub.status.idle":"2022-04-10T06:21:30.670509Z","shell.execute_reply.started":"2022-04-10T06:21:28.621694Z","shell.execute_reply":"2022-04-10T06:21:30.669883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:21:35.883643Z","iopub.execute_input":"2022-04-10T06:21:35.883903Z","iopub.status.idle":"2022-04-10T06:21:35.897548Z","shell.execute_reply.started":"2022-04-10T06:21:35.883873Z","shell.execute_reply":"2022-04-10T06:21:35.896878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reranked_df = delf_rerank(query = val_embeddings,\n                          key = train_embeddings,\n                          query_image_index = query_image_index,\n                          confidence_df = confidence_df,\n                          re_sort = True)\nreranked_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:21:43.201566Z","iopub.execute_input":"2022-04-10T06:21:43.20182Z","iopub.status.idle":"2022-04-10T06:21:54.285209Z","shell.execute_reply.started":"2022-04-10T06:21:43.201789Z","shell.execute_reply":"2022-04-10T06:21:54.283246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 1\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = reranked_df['top_similar'][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:21:57.354744Z","iopub.execute_input":"2022-04-10T06:21:57.355001Z","iopub.status.idle":"2022-04-10T06:21:58.710711Z","shell.execute_reply.started":"2022-04-10T06:21:57.354971Z","shell.execute_reply":"2022-04-10T06:21:58.710084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 2\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:22:56.40984Z","iopub.execute_input":"2022-04-10T06:22:56.410116Z","iopub.status.idle":"2022-04-10T06:22:57.816385Z","shell.execute_reply.started":"2022-04-10T06:22:56.410087Z","shell.execute_reply":"2022-04-10T06:22:57.814783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:23:01.418932Z","iopub.execute_input":"2022-04-10T06:23:01.419619Z","iopub.status.idle":"2022-04-10T06:23:01.433505Z","shell.execute_reply.started":"2022-04-10T06:23:01.419582Z","shell.execute_reply":"2022-04-10T06:23:01.432718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reranked_df = delf_rerank(query = val_embeddings,\n                          key = train_embeddings,\n                          query_image_index = query_image_index,\n                          confidence_df = confidence_df,\n                          re_sort = True)\nreranked_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:26:18.726882Z","iopub.execute_input":"2022-04-10T06:26:18.72743Z","iopub.status.idle":"2022-04-10T06:26:28.500057Z","shell.execute_reply.started":"2022-04-10T06:26:18.727391Z","shell.execute_reply":"2022-04-10T06:26:28.499372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 2\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = reranked_df['top_similar'][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:26:58.680485Z","iopub.execute_input":"2022-04-10T06:26:58.680749Z","iopub.status.idle":"2022-04-10T06:27:00.38064Z","shell.execute_reply.started":"2022-04-10T06:26:58.680714Z","shell.execute_reply":"2022-04-10T06:27:00.379903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 101\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:35:49.420429Z","iopub.execute_input":"2022-04-10T07:35:49.421074Z","iopub.status.idle":"2022-04-10T07:35:50.711482Z","shell.execute_reply.started":"2022-04-10T07:35:49.421028Z","shell.execute_reply":"2022-04-10T07:35:50.71088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_df = confidence_top(query = val_embeddings,\n                               key = train_embeddings,\n                               similarity = val_train_similarity,\n                               query_image_index = query_image_index,\n                               top = top_n)\n\nconfidence_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:36:10.761251Z","iopub.execute_input":"2022-04-10T07:36:10.761513Z","iopub.status.idle":"2022-04-10T07:36:10.775605Z","shell.execute_reply.started":"2022-04-10T07:36:10.761482Z","shell.execute_reply":"2022-04-10T07:36:10.774899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reranked_df = delf_rerank(query = val_embeddings,\n                          key = train_embeddings,\n                          query_image_index = query_image_index,\n                          confidence_df = confidence_df,\n                          re_sort = True)\nreranked_df","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:36:13.976127Z","iopub.execute_input":"2022-04-10T07:36:13.976967Z","iopub.status.idle":"2022-04-10T07:36:24.237625Z","shell.execute_reply.started":"2022-04-10T07:36:13.976926Z","shell.execute_reply":"2022-04-10T07:36:24.23689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_image_index = 101\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = reranked_df['top_similar'][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T07:36:30.984848Z","iopub.execute_input":"2022-04-10T07:36:30.985535Z","iopub.status.idle":"2022-04-10T07:36:32.306565Z","shell.execute_reply.started":"2022-04-10T07:36:30.985496Z","shell.execute_reply":"2022-04-10T07:36:32.305885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Under-represented query image\nEffect of querying images not well represented on the key set","metadata":{}},{"cell_type":"code","source":"query_image_index = 8\ntop_n = 10\n\nimage_id = os.path.split(val_embeddings['images_paths'][query_image_index])[1]\nquery_landmark_id = os.path.split(os.path.split(val_embeddings['images_paths'][query_image_index])[0])[1]\n\nsimilar_n = np.argsort(val_train_similarity[query_image_index])[::-1][:top_n]\n\nprint(f\"Queried image: {image_id}\")\nplt.figure(figsize = (6, 6))\nplt.imshow(get_image(val_embeddings['images_paths'][query_image_index]))\nplt.title(f\"Landmark id: {query_landmark_id}\")\nplt.axis(\"off\")\nplot_similar(similar_n, train_embeddings['images_paths'])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:31:45.582243Z","iopub.execute_input":"2022-04-10T06:31:45.582759Z","iopub.status.idle":"2022-04-10T06:31:47.14054Z","shell.execute_reply.started":"2022-04-10T06:31:45.582725Z","shell.execute_reply":"2022-04-10T06:31:47.13985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's investigate what the model has seen for landmark 36 during training...","metadata":{}},{"cell_type":"code","source":"get_landmark(36)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T06:54:24.115648Z","iopub.execute_input":"2022-04-10T06:54:24.115908Z","iopub.status.idle":"2022-04-10T06:54:25.557502Z","shell.execute_reply.started":"2022-04-10T06:54:24.115877Z","shell.execute_reply":"2022-04-10T06:54:25.554226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Query image has a representative issue when considering how the landmark appears on key set and how it was seen during training","metadata":{}}]}