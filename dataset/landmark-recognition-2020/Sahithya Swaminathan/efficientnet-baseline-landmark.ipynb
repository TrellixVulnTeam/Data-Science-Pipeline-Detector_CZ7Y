{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import glob\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport gc #garbage collection\nimport cv2\nimport tensorflow as tf\nimport os\nimport pathlib\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB0\n#eff_conv = EfficientNetB0(weights='imagenet', include_top=False,input_shape=(384,384,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import tensorflow as tf\n#tf.__version__\n#!pip list | grep tensorflow\n#!pip install tensorflow-gpu==2.3.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Dataset parameters:\nINPUT_DIR = os.path.join('..', 'input')\n\nDATASET_DIR = os.path.join(INPUT_DIR, 'landmark-recognition-2020')\nTEST_IMAGE_DIR = os.path.join(DATASET_DIR, 'test')\nTRAIN_IMAGE_DIR = os.path.join(DATASET_DIR, 'train')\nTRAIN_LABELMAP_PATH = os.path.join(DATASET_DIR, 'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#declare image dimensions\nnrows = 384\nncols = 384\nchannel = 3\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(TRAIN_LABELMAP_PATH)\nFILENAME = glob.glob('../input/landmark-recognition-2020/train/*/*/*/*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_FILENAMES, VALIDATION_FILENAMES = train_test_split(FILENAME, test_size = 0.20, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#[ \\w-]+?(?=\\.)\n#from pathlib import Path\n#print(Path(TRAINING_FILENAMES[0]).name)\n#print(os.path.split(TRAINING_FILENAMES[0])[1][:-4])\ntraining_groups = [os.path.split(filename)[1][:-4] for filename in TRAINING_FILENAMES]\nvalidation_groups = [os.path.split(filename)[1][:-4] for filename in VALIDATION_FILENAMES]\ny_train = df[df.id.isin(training_groups)].landmark_id\ny_val = df[df.id.isin(validation_groups)].landmark_id\ny_train.reset_index(drop=True, inplace=True)\ny_val.reset_index(drop=True, inplace=True)\nprint(f'The number of unique training classes is {y_train.nunique()} of {df.landmark_id.nunique()} total classes')\nprint(f'The number of unique validation classes is {y_val.nunique()} of {df.landmark_id.nunique()} total classes')\nprint(f'Total number of training data {y_train.shape[0]}')\nprint(f'Total number of validation data {y_val.shape[0]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(list_of_images):\n    X = []\n    for image in list_of_images:\n        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows, ncols), interpolation = cv2.INTER_CUBIC)) \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(TRAINING_FILENAMES)\n#sample_num = 500\nXtrain = read_image(TRAINING_FILENAMES)\ny_train = y_train#.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample_num = 500\nXval = read_image(VALIDATION_FILENAMES)\ny_val = y_val#.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import `keras` library"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label Encode\n#y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#num_classes = 500#y_train.max()\nnum_classes = df.landmark_id.nunique()#y_train.max()\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_val = keras.utils.to_categorical(y_val, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Swish defination\nfrom keras.backend import sigmoid\n\nclass SwishActivation(Activation):\n    \n    def __init__(self, activation, **kwargs):\n        super(SwishActivation, self).__init__(activation, **kwargs)\n        self.__name__ = 'swish_act'\n\ndef swish_act(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Activation\nget_custom_objects().update({'swish_act': SwishActivation(swish_act)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model structure\n# loading B0 pre-trained on ImageNet without final aka fiature extractor\nmodel = EfficientNetB0(include_top=False, input_shape=(nrows, ncols,3), pooling='avg', weights='imagenet')\n\n# building 2 fully connected layer \nx = model.output\n\nx = BatchNormalization()(x)\nx = Dropout(0.7)(x)\n\nx = Dense(512)(x)\nx = BatchNormalization()(x)\nx = Activation(swish_act)(x)\nx = Dropout(0.5)(x)\n\nx = Dense(128)(x)\nx = BatchNormalization()(x)\nx = Activation(swish_act)(x)\n\n# output layer\npredictions = Dense(num_classes, activation=\"softmax\")(x)\n\nmodel_final = Model(inputs = model.input, outputs = predictions)\n\nmodel_final.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting keras model for visualization\n\nfrom keras.utils.vis_utils import plot_model\nplot_model(model_final, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# train_datagen = ImageDataGenerator(\n#     rescale=1.0 / 255,\n#     rotation_range=40,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True,\n#     fill_mode=\"nearest\",\n# )\n\n# # Note that the validation data should not be augmented!\n# test_datagen = ImageDataGenerator(rescale=1.0 / 255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain = np.array(Xtrain)\nXval = np.array(Xval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.compile(\n#     loss=\"categorical_crossentropy\",\n#     optimizer=optimizers.RMSprop(lr=2e-5),\n#     metrics=[\"acc\"],\n# )\nmodel_final.compile(loss='categorical_crossentropy',\n              optimizer=Adam(0.0001),\n              metrics=['accuracy'])\n\nmcp_save = ModelCheckpoint('EnetB0_GLAND_TL.h5', save_best_only=True, monitor='val_acc')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, verbose=1,)\n\n#print(\"Training....\")\nmodel_final.fit(Xtrain, y_train,\n              batch_size=32,\n              epochs=32,\n              validation_split=0.1,\n              callbacks=[mcp_save, reduce_lr],\n              shuffle=True,\n              verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, acc = model_final.evaluate(Xval, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/landmark-recognition-2020/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def inference_and_save_submission_csv(train_csv, test_directory, train_directory):\n#     image_paths = [x for x in pathlib.Path(test_directory).rglob('*.jpg')]\n#     test_len = len(image_paths)\n#     if test_len == NUM_PUBLIC_TEST_IMAGES:\n#         # Dummy submission\n#         shutil.copyfile('../input/landmark-recognition-2020/sample_submission.csv', 'submission.csv')\n#         return 'Job Done'\n#     else:\n#         test_ids, train_ids_labels_and_scores = get_similarities(train_csv, test_directory, train_directory)\n#         final = generate_predictions(test_ids, train_ids_labels_and_scores)\n#         return final\nTEST_FILENAME = glob.glob('../input/landmark-recognition-2020/test/*/*/*/*')   \ny_test = read_image(TEST_FILENAME)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = np.amax(model_final.predict(y_test), axis =1)\npredictions = np.argmax(model_final.predict(y_test), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#np.char.array(scores) + ' ' + np.char.array(predictions)\n#map(' '.join, zip(scores, predictions))\nlandmarks = np.array([str(x1) +' '+ str(x2) for x1,x2 in zip(predictions, scores)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#os.path.split(TEST_FILENAME[0])[1].split('.')\ntest_ids = [os.path.split(filename)[1].split('.')[0] for filename in TEST_FILENAME]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = pd.DataFrame({'id': test_ids, 'target': predictions, 'scores': scores})\nfinal['landmarks'] = final['target'].astype(str) + ' ' + final['scores'].astype(str)\nfinal[['id', 'landmarks']].to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}