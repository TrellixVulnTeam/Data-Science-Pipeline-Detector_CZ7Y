{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# overview\nResently, I'm working to learn tensorflow.data API (tf.data) to figure out data importing problem on tensorflow task, especially importing TFRecord file data. And, I find **tf.data** and **TFRecord** are very powerful. Then I will use tf.data API to import data, e.g.train00.tfrecord.  Although [YouTube-8M Tensorflow Starter Code](https://github.com/google/youtube-8m#overview-of-files) has readers.py to import data, it's really confusing. Note that; some API maybe throw-out errors, you should update your tensorflow. The  **tf.parse_single_sequence_example** will get error under tensorflow-1.4, so I update to tensorflow-1.9, everything is OK. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"97b90171d040ffc4f09bfbc05bfc5ba7155f5655"},"cell_type":"code","source":"import tensorflow as tf\nconfig  = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsess = tf.Session(config=config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e1a14781a4bca08cccb6475840a9dc11125adaeb"},"cell_type":"code","source":"# Get file path\nvideo_record = \"../input/video-sample/video/train00.tfrecord\"\nframe_record = \"../input/frame-sample/frame/train00.tfrecord\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5cb06876169155949a5ce8ff94b7959feb026838"},"cell_type":"markdown","source":"# Video-level"},{"metadata":{"_uuid":"8917418b0ed9d0b7a0394dccc8d536bcb0834c3f"},"cell_type":"markdown","source":"##  Analyze TFRecord file \nYou can do these with new TFRecord files, find structur and parse record string."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7fd2621ca70a957fc7f9271bb6d8df0f49560237"},"cell_type":"code","source":"# read file and get record_iterator\nrecord_iterator = tf.python_io.tf_record_iterator(video_record)\n# Maybe many records in oen TFRecord file, we just need one record to analyze structur\nrecord_0 = [record for record in record_iterator][0]\n# parse record string as tf.train.Example\nexample = tf.train.Example.FromString(record_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad5baab35c4b029a1e8db17d4c9517c707ab9fdf","collapsed":true},"cell_type":"code","source":"# analyze structur\n# pleas pay atention to 'key' and 'value' of feature ,especialy the data_type of the value'\nprint(example)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e61fdf722b96014c9949a4ae11ea8c9cd36aebab"},"cell_type":"code","source":"# Ther are two ways to get the value of record.\n# First\nexample.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\nexample.features.feature['labels'].int64_list.value\nexample.features.feature['mean_rgb'].float_list.value\nexample.features.feature['mean_audio'].float_list.value\nexample.features.feature['id'].bytes_list.value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65185b445e67f7662c2d5fa2818037350a1073d0","collapsed":true},"cell_type":"code","source":"# Second \n# encourge to use this way\nfeature_keys  = {'id': tf.FixedLenFeature([],tf.string),\n                 'labels': tf.VarLenFeature(tf.int64),\n                 'mean_rgb': tf.FixedLenFeature([1024],tf.float32),\n                 'mean_audio': tf.FixedLenFeature([128],tf.float32)}\n\nparsed = tf.parse_single_example(record_0,feature_keys)\n# NOTE:: tf.VarLenFeature(tf.int64) will parse and return a sparse tensor, should cover it to dense tensor\n# 3862:: according to YouTube-8M Tensorflow Starter Code, dataset have 3862 labels\nparsed[\"labels\"] = tf.sparse_to_dense(parsed[\"labels\"].values, [3862], 1) \nsess.run(parsed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98706340643f83d945b424437e9732d49cd5f903"},"cell_type":"markdown","source":"##  Automatically read, parse and get training data"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cf7ea5cf55020ffc90ba18a848427d49bf4a8979"},"cell_type":"code","source":"# The function to parse record\ndef parser(record):\n    feature_keys  = {'id': tf.FixedLenFeature([],tf.string),\n                     'labels': tf.VarLenFeature(tf.int64),\n                     'mean_rgb': tf.FixedLenFeature([1024],tf.float32),\n                     'mean_audio': tf.FixedLenFeature([128],tf.float32)}                                                    \n    parsed= tf.parse_single_example(record,feature_keys)\n    parsed[\"labels\"] = tf.sparse_to_dense(parsed[\"labels\"].values, [3862], 1) \n    return parsed\n# The tool\ndef input_video_data(video_path,batch_size=1,num_epoch=1):\n    # Get all TFRecord files in this path\n    # The first item of os.listdir(video_path) is current path\n    filenames = [os.path.join(video_path,file) for file in os.listdir(video_path)][1:]\n    # creat dataset\n    dataset  = tf.data.TFRecordDataset(filenames)\n    # parse every record string \n    dataset = dataset.map(parser)\n    # Random shuffle\n    dataset = dataset.shuffle(buffer_size=1000)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.repeat(num_epoch)\n    iterator = dataset.make_one_shot_iterator()\n    try:\n        next_element = iterator.get_next()\n    except tf.errors.OutOfRangeError:\n        print(\"Iterations exhausted\")\n    return next_element","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c2880b88551537ae60028bb12cdc37a9cb5b8fa","collapsed":true},"cell_type":"code","source":"# Use this tool to get data\nvideo_path = \"../input/video-sample/video\"\nbatch_example = input_video_data(video_path)\n# every training time, sess.run will get a batch of data.\nsess.run(batch_example)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3af6a58f902a37744d2be9fe6b7b07ef72bf6bd0"},"cell_type":"markdown","source":"# Frame-level"},{"metadata":{"_uuid":"ac1eb606e4ccb6e10f6df51d2e82d3e1830e5dcb"},"cell_type":"markdown","source":"##  Analyze TFRecord file "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"04171b8edffc64c98f86659b28ae21a7e974382f"},"cell_type":"code","source":"record_iterator = tf.python_io.tf_record_iterator(frame_record)\nrecord_0 = [record for record in record_iterator][100]\n# NOTE：frame-level TFRecord files contain SequenceExamples\nexample = tf.train.SequenceExample.FromString(record_0)\n\n# print(example)\n\n# keys to parse context_features\nfeature_keys  = {'id': tf.FixedLenFeature([],tf.string),\n                 'labels':tf.VarLenFeature(tf.int64)}\n# keys to parse features_lists\nsequence_features_keys = {'audio': tf.FixedLenSequenceFeature([],tf.string,allow_missing=True),\n                          'rgb': tf.FixedLenSequenceFeature([],tf.string,allow_missing=True)}\n# Use tf.parse_single_sequence_example to parse sequenceExample \nparsed = tf.parse_single_sequence_example(record_0,feature_keys,sequence_features_keys)\nparsed[0][\"labels\"] = tf.sparse_to_dense(parsed[0][\"labels\"].values, [3862], 1) \n# return tuple:（features_dict，sequence_features_dict）\nresult = sess.run(parsed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64ca047eb36f988c7ef24f1ce371c03055214de4"},"cell_type":"markdown","source":"##  Automatically read, parse and get training data"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8f08e15132b7241eeb41cb3e3c7d2faf5e747460"},"cell_type":"code","source":"num_classes = 3862\ndef parser(record):\n    feature_keys  = {'id': tf.FixedLenFeature([],tf.string),\n                     'labels': tf.VarLenFeature(tf.int64)}\n    sequence_features_keys = {'audio': tf.FixedLenSequenceFeature([],tf.string),\n                              'rgb': tf.FixedLenSequenceFeature([],tf.string)}\n    context_parsed, sequence_parsed = tf.parse_single_sequence_example(record,feature_keys,sequence_features_keys)\n    context_parsed[\"labels\"] = tf.sparse_to_dense(context_parsed[\"labels\"].values, [num_classes], 1,validate_indices=False)\n    return context_parsed, sequence_parsed\n\ndef input_frame_data(frame_path,batch_size=1,num_epoch=1):\n    filenames = [os.path.join(frame_path,file) for file in os.listdir(frame_path)][1:]\n    dataset  = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(parser)\n    dataset = dataset.shuffle(buffer_size=1000)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.repeat(num_epoch)\n    iterator = dataset.make_one_shot_iterator()\n    next_element = iterator.get_next()\n    return next_element","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73a3e5d8688d3aabde615818675a129812c2ed50","collapsed":true},"cell_type":"code","source":"frame_path = \"../input/frame-sample/frame\"\nbatch_example = input_frame_data(frame_path)\nresult = sess.run(batch_example)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02df8eacbb3083501be2cea88577c1b3a1a59187","collapsed":true},"cell_type":"code","source":"# 1024 bit features\nlen(result[1]['rgb'][0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9273942411b9bc564c8a59cd24399305b35408ec","collapsed":true},"cell_type":"code","source":"# 300 up frames\nlen(result[1]['rgb'][0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5233a6e19ea3a9f35798f8c8dd328728f01f7d99"},"cell_type":"markdown","source":"I know, it's late to finish this competition. (╯‵□′)╯︵┻━┻\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}