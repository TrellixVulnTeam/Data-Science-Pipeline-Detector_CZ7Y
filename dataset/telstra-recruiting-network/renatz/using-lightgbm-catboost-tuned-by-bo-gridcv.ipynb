{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:33.971635Z","iopub.execute_input":"2021-07-29T13:27:33.972067Z","iopub.status.idle":"2021-07-29T13:27:33.983819Z","shell.execute_reply.started":"2021-07-29T13:27:33.971983Z","shell.execute_reply":"2021-07-29T13:27:33.982603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Data loading and merging","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/telstra-recruiting-network/train.csv.zip')\ntest = pd.read_csv('/kaggle/input/telstra-recruiting-network/test.csv.zip')\nfeature = pd.read_csv('/kaggle/input/telstra-recruiting-network/log_feature.csv.zip')\nevent = pd.read_csv('/kaggle/input/telstra-recruiting-network/event_type.csv.zip')\nresource = pd.read_csv('/kaggle/input/telstra-recruiting-network/resource_type.csv.zip')\nseverity = pd.read_csv('/kaggle/input/telstra-recruiting-network/severity_type.csv.zip')","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:37.20011Z","iopub.execute_input":"2021-07-29T13:27:37.200724Z","iopub.status.idle":"2021-07-29T13:27:37.473776Z","shell.execute_reply.started":"2021-07-29T13:27:37.200671Z","shell.execute_reply":"2021-07-29T13:27:37.472762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_list = [train,test,feature,event,resource,severity]\nfor df in df_list:\n    print(df.columns[-1],':',len(df))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:38.985925Z","iopub.execute_input":"2021-07-29T13:27:38.986324Z","iopub.status.idle":"2021-07-29T13:27:38.994157Z","shell.execute_reply.started":"2021-07-29T13:27:38.986287Z","shell.execute_reply":"2021-07-29T13:27:38.993031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for the training data\nmerge_1 = pd.merge(train,feature) \nmerge_2 = pd.merge(merge_1,event) \nmerge_3 = pd.merge(merge_2,resource) \nmerge_4 = pd.merge(merge_3,severity) \nprint(merge_4.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:40.668723Z","iopub.execute_input":"2021-07-29T13:27:40.669369Z","iopub.status.idle":"2021-07-29T13:27:40.750109Z","shell.execute_reply.started":"2021-07-29T13:27:40.66932Z","shell.execute_reply":"2021-07-29T13:27:40.749364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_4.isna().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:41.73685Z","iopub.execute_input":"2021-07-29T13:27:41.737348Z","iopub.status.idle":"2021-07-29T13:27:41.781106Z","shell.execute_reply.started":"2021-07-29T13:27:41.737314Z","shell.execute_reply":"2021-07-29T13:27:41.780142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_4.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:42.747815Z","iopub.execute_input":"2021-07-29T13:27:42.748204Z","iopub.status.idle":"2021-07-29T13:27:42.767878Z","shell.execute_reply.started":"2021-07-29T13:27:42.748174Z","shell.execute_reply":"2021-07-29T13:27:42.766923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_4.drop_duplicates(subset = 'id', inplace = True) \nmerge_4.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:43.723501Z","iopub.execute_input":"2021-07-29T13:27:43.723871Z","iopub.status.idle":"2021-07-29T13:27:43.748358Z","shell.execute_reply.started":"2021-07-29T13:27:43.723835Z","shell.execute_reply":"2021-07-29T13:27:43.747428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = merge_4.set_index(merge_4.id).drop('id',axis = 1)\ntrain.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:44.723306Z","iopub.execute_input":"2021-07-29T13:27:44.7237Z","iopub.status.idle":"2021-07-29T13:27:44.739393Z","shell.execute_reply.started":"2021-07-29T13:27:44.723651Z","shell.execute_reply":"2021-07-29T13:27:44.738433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for the testing data \nmerge_5 = pd.merge(test,feature) \nmerge_6 = pd.merge(merge_5,event) \nmerge_7 = pd.merge(merge_6,resource) \nmerge_8 = pd.merge(merge_7,severity) \nprint(merge_8.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:45.848922Z","iopub.execute_input":"2021-07-29T13:27:45.849256Z","iopub.status.idle":"2021-07-29T13:27:45.9241Z","shell.execute_reply.started":"2021-07-29T13:27:45.849212Z","shell.execute_reply":"2021-07-29T13:27:45.923166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_8.isna().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:46.892289Z","iopub.execute_input":"2021-07-29T13:27:46.892921Z","iopub.status.idle":"2021-07-29T13:27:46.943067Z","shell.execute_reply.started":"2021-07-29T13:27:46.892872Z","shell.execute_reply":"2021-07-29T13:27:46.942406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_8.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:47.870191Z","iopub.execute_input":"2021-07-29T13:27:47.870595Z","iopub.status.idle":"2021-07-29T13:27:47.884908Z","shell.execute_reply.started":"2021-07-29T13:27:47.870558Z","shell.execute_reply":"2021-07-29T13:27:47.883849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_8.drop_duplicates(subset = 'id', inplace = True) \nprint(merge_8.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:48.810521Z","iopub.execute_input":"2021-07-29T13:27:48.810876Z","iopub.status.idle":"2021-07-29T13:27:48.842014Z","shell.execute_reply.started":"2021-07-29T13:27:48.810847Z","shell.execute_reply":"2021-07-29T13:27:48.841001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merge_8.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:49.646995Z","iopub.execute_input":"2021-07-29T13:27:49.64752Z","iopub.status.idle":"2021-07-29T13:27:49.65991Z","shell.execute_reply.started":"2021-07-29T13:27:49.647474Z","shell.execute_reply":"2021-07-29T13:27:49.659082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = merge_8.set_index(merge_8.id).drop('id',axis = 1)\ntest.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:50.413712Z","iopub.execute_input":"2021-07-29T13:27:50.414188Z","iopub.status.idle":"2021-07-29T13:27:50.433523Z","shell.execute_reply.started":"2021-07-29T13:27:50.414147Z","shell.execute_reply":"2021-07-29T13:27:50.432825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:51.191341Z","iopub.execute_input":"2021-07-29T13:27:51.191861Z","iopub.status.idle":"2021-07-29T13:27:51.205235Z","shell.execute_reply.started":"2021-07-29T13:27:51.191828Z","shell.execute_reply":"2021-07-29T13:27:51.204203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove duplicate prefixes for the trainning set \n# the need for category features of the lgb algorithm\nremoval = train.iloc[:,[0,2,4,5,6]].apply(lambda i:i.apply(lambda x:x.replace(x,x.split(' ')[-1])))\nremoval.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:51.932146Z","iopub.execute_input":"2021-07-29T13:27:51.932544Z","iopub.status.idle":"2021-07-29T13:27:51.98112Z","shell.execute_reply.started":"2021-07-29T13:27:51.932494Z","shell.execute_reply":"2021-07-29T13:27:51.980505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"removal.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:52.938747Z","iopub.execute_input":"2021-07-29T13:27:52.939235Z","iopub.status.idle":"2021-07-29T13:27:52.945391Z","shell.execute_reply.started":"2021-07-29T13:27:52.939203Z","shell.execute_reply":"2021-07-29T13:27:52.944728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([removal,train.iloc[:,[3,1]]],axis = 1)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:54.164072Z","iopub.execute_input":"2021-07-29T13:27:54.164447Z","iopub.status.idle":"2021-07-29T13:27:54.181312Z","shell.execute_reply.started":"2021-07-29T13:27:54.164415Z","shell.execute_reply":"2021-07-29T13:27:54.180377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove duplicate prefixes for the testing set\nremoval = test.iloc[:,[0,1,3,4,5]].apply(lambda i:i.apply(lambda x:x.replace(x,x.split(' ')[-1])))\nremoval.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:27:59.372965Z","iopub.execute_input":"2021-07-29T13:27:59.373367Z","iopub.status.idle":"2021-07-29T13:27:59.431498Z","shell.execute_reply.started":"2021-07-29T13:27:59.373332Z","shell.execute_reply":"2021-07-29T13:27:59.430507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"removal.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:28:00.775674Z","iopub.execute_input":"2021-07-29T13:28:00.776022Z","iopub.status.idle":"2021-07-29T13:28:00.783699Z","shell.execute_reply.started":"2021-07-29T13:28:00.775993Z","shell.execute_reply":"2021-07-29T13:28:00.782744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.concat([removal,test.iloc[:,2]],axis = 1)\ntest.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:28:02.170318Z","iopub.execute_input":"2021-07-29T13:28:02.170687Z","iopub.status.idle":"2021-07-29T13:28:02.186072Z","shell.execute_reply.started":"2021-07-29T13:28:02.170653Z","shell.execute_reply":"2021-07-29T13:28:02.185099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory data analysis","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:28:04.311946Z","iopub.execute_input":"2021-07-29T13:28:04.312306Z","iopub.status.idle":"2021-07-29T13:28:04.333665Z","shell.execute_reply.started":"2021-07-29T13:28:04.312274Z","shell.execute_reply":"2021-07-29T13:28:04.332962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:28:05.425736Z","iopub.execute_input":"2021-07-29T13:28:05.426047Z","iopub.status.idle":"2021-07-29T13:28:05.433353Z","shell.execute_reply.started":"2021-07-29T13:28:05.42602Z","shell.execute_reply":"2021-07-29T13:28:05.432282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Although the location、log_feature、event_type are categorical variables,\nthey own much levels, which is hard to visualize.","metadata":{}},{"cell_type":"code","source":"# plot the pie chart for the target variables\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(3,3))\nplt.pie(x = train.fault_severity.value_counts().values,\n        labels = train.fault_severity.value_counts().index,\n        colors = ('aliceblue','lightsteelblue','pink'),autopct = \"%.2f%%\")\nplt.title('fault_severity')\nplt.legend() \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:19.15414Z","iopub.execute_input":"2021-07-29T13:29:19.154605Z","iopub.status.idle":"2021-07-29T13:29:19.316534Z","shell.execute_reply.started":"2021-07-29T13:29:19.154571Z","shell.execute_reply":"2021-07-29T13:29:19.315767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the bar_chart for the less-level categorical variables\nimport seaborn as sns\nless_level = train.iloc[:,[3,4,6]]\nplt.figure(figsize=(15,5))\ncount = 1\nfor col in less_level.columns[:-1]:\n    plt.subplot(1,2,count)\n    temp = pd.crosstab(less_level.fault_severity,less_level[col])\n    temp1 = temp.T.stack().reset_index()\n    sns.barplot(temp1[col], temp1[0], hue = temp1.fault_severity, palette='PuBu')\n    count += 1","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:28:51.666836Z","iopub.execute_input":"2021-07-29T13:28:51.667202Z","iopub.status.idle":"2021-07-29T13:28:52.307492Z","shell.execute_reply.started":"2021-07-29T13:28:51.66717Z","shell.execute_reply":"2021-07-29T13:28:52.306612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the histograms for the numerical variable\nplt.figure(figsize = (5,5))\nsns.distplot(train[train.fault_severity == 0]['volume'], kde=False, label='NoFault', bins=3)\nsns.distplot(train[train.fault_severity == 1]['volume'], kde=False, label='Several Faults', bins=3)\nsns.distplot(train[train.fault_severity == 2]['volume'], kde=False, label='Serious Faults', bins=3)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:29.771076Z","iopub.execute_input":"2021-07-29T13:29:29.771448Z","iopub.status.idle":"2021-07-29T13:29:29.990752Z","shell.execute_reply.started":"2021-07-29T13:29:29.771415Z","shell.execute_reply":"2021-07-29T13:29:29.989749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing value detection","metadata":{}},{"cell_type":"code","source":"train.isna().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:33.158842Z","iopub.execute_input":"2021-07-29T13:29:33.15921Z","iopub.status.idle":"2021-07-29T13:29:33.172138Z","shell.execute_reply.started":"2021-07-29T13:29:33.159178Z","shell.execute_reply":"2021-07-29T13:29:33.170842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isna().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:34.242317Z","iopub.execute_input":"2021-07-29T13:29:34.242885Z","iopub.status.idle":"2021-07-29T13:29:34.25848Z","shell.execute_reply.started":"2021-07-29T13:29:34.242834Z","shell.execute_reply":"2021-07-29T13:29:34.257471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outliers detection and removing","metadata":{}},{"cell_type":"code","source":"sns.boxplot( x = train.volume,orient = 'v',palette = 'PuBu')","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:36.846293Z","iopub.execute_input":"2021-07-29T13:29:36.846643Z","iopub.status.idle":"2021-07-29T13:29:36.977232Z","shell.execute_reply.started":"2021-07-29T13:29:36.846613Z","shell.execute_reply":"2021-07-29T13:29:36.97637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\nx = np.abs(stats.zscore(train.volume)) < 3\ntrain.volume = np.where(x,train.volume,np.nan)\ntrain.isna().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:40.61565Z","iopub.execute_input":"2021-07-29T13:29:40.615993Z","iopub.status.idle":"2021-07-29T13:29:40.631291Z","shell.execute_reply.started":"2021-07-29T13:29:40.615962Z","shell.execute_reply":"2021-07-29T13:29:40.630341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.volume = train.volume.replace(np.nan, train.volume.sum()/(len(train.volume) - (train.volume.isna()).sum()))\ntrain.isna().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:42.702697Z","iopub.execute_input":"2021-07-29T13:29:42.703063Z","iopub.status.idle":"2021-07-29T13:29:42.720361Z","shell.execute_reply.started":"2021-07-29T13:29:42.703031Z","shell.execute_reply":"2021-07-29T13:29:42.719024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Skewed variables detection ","metadata":{}},{"cell_type":"code","source":"# although the large range didn't affect the performance of the tree model, we conduct the detection.\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:44.906161Z","iopub.execute_input":"2021-07-29T13:29:44.906734Z","iopub.status.idle":"2021-07-29T13:29:44.925546Z","shell.execute_reply.started":"2021-07-29T13:29:44.906686Z","shell.execute_reply":"2021-07-29T13:29:44.924509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.skew()\n# the distribution of the input variables didn't affect the performance of the tree model.\n# no numerical variable is highly skewed(skewness>10).","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:46.93415Z","iopub.execute_input":"2021-07-29T13:29:46.934521Z","iopub.status.idle":"2021-07-29T13:29:46.954538Z","shell.execute_reply.started":"2021-07-29T13:29:46.934487Z","shell.execute_reply":"2021-07-29T13:29:46.953584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (3, 3))\nsns.heatmap(train.corr(), annot = True, vmax=1, vmin=-1, cmap='YlGnBu_r')\nplt.show()\n# the muliticollineity doesn't affect the performance of the boosting tree.","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:54.894005Z","iopub.execute_input":"2021-07-29T13:29:54.894403Z","iopub.status.idle":"2021-07-29T13:29:55.137618Z","shell.execute_reply.started":"2021-07-29T13:29:54.894368Z","shell.execute_reply":"2021-07-29T13:29:55.136634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transform the data types for lgb","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:57.497394Z","iopub.execute_input":"2021-07-29T13:29:57.497779Z","iopub.status.idle":"2021-07-29T13:29:57.504728Z","shell.execute_reply.started":"2021-07-29T13:29:57.497744Z","shell.execute_reply":"2021-07-29T13:29:57.504049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.iloc[:,0:5] = train.iloc[:,0:5].astype('category')\ntrain.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:29:58.52098Z","iopub.execute_input":"2021-07-29T13:29:58.521636Z","iopub.status.idle":"2021-07-29T13:29:58.541851Z","shell.execute_reply.started":"2021-07-29T13:29:58.521597Z","shell.execute_reply":"2021-07-29T13:29:58.540843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data partition","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx = train.iloc[:,0:-1]\ny = train.fault_severity\nx_train, x_val, y_train, y_val= train_test_split(x, y, test_size = 0.2, random_state = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:30:00.306825Z","iopub.execute_input":"2021-07-29T13:30:00.30721Z","iopub.status.idle":"2021-07-29T13:30:00.651036Z","shell.execute_reply.started":"2021-07-29T13:30:00.30718Z","shell.execute_reply":"2021-07-29T13:30:00.650114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nCounter(y_train)\ncount_y = Counter(y_train)\nplt.figure(figsize=(3,3))\nplt.pie(x = count_y.values(), labels = count_y.keys(), \n        colors = ('lightsteelblue','aliceblue','pink'), autopct = \"%.2f%%\")\nplt.title('Class for training data')\nplt.legend() \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:30:16.607113Z","iopub.execute_input":"2021-07-29T13:30:16.607516Z","iopub.status.idle":"2021-07-29T13:30:16.780773Z","shell.execute_reply.started":"2021-07-29T13:30:16.607481Z","shell.execute_reply":"2021-07-29T13:30:16.779715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model building","metadata":{}},{"cell_type":"markdown","source":"to control the consistency of the default value of the parameters for the two algorithms","metadata":{}},{"cell_type":"code","source":"%%time\nfrom lightgbm import LGBMClassifier as lgbc\nfrom catboost import CatBoostClassifier as cbc\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.preprocessing import OneHotEncoder\n\ngbm_b = lgbc(objective = 'multiclass', max_depth = 6, reg_lambda = 3.0, random_state = 1)\ngbm_b = gbm_b.fit(X = x_train, y = y_train, eval_set = (x_val,y_val), early_stopping_rounds = 50, verbose = 10)\nprint('\\t')\nprint('bestTest = ',gbm_b.best_score_['valid_0']['multi_logloss'])\nprint('bestIteration = ',gbm_b.best_iteration_)\nprint('\\t')\n\ncat_b = cbc(objective = 'MultiClass', learning_rate = 0.1, n_estimators = 100, random_state = 1)\ncat_b = cat_b.fit(X = x_train, y = y_train, eval_set = (x_val,y_val), \n                 cat_features = np.where(x_train.dtypes != np.float)[0], \n                 early_stopping_rounds = 50, verbose = 10)\n\nensembles = [gbm_b,cat_b]\nTRAIN_ACC = []\nVAL_ACC = []\nMulti_Logloss = []\nfor model in ensembles:\n    train_acc = model.score(x_train,y_train)\n    TRAIN_ACC.append(train_acc)\n    \n    y_pred = model.predict(x_val)\n    \n    val_acc = accuracy_score(y_val,y_pred)\n    VAL_ACC.append(val_acc)\n    \n    y_pred = y_pred.reshape(-1,1)\n    y_true = np.array(y_val).reshape(-1,1)\n    one_hot = OneHotEncoder(sparse = False)\n    y_true = one_hot.fit_transform(y_true)\n    y_pred = one_hot.fit_transform(y_pred)\n    multi_logloss = log_loss(y_true, y_pred)\n    Multi_Logloss.append(multi_logloss)\n    \nind=['train_acc','val_acc','multi_logloss']\ncol=['gbm_b','cat_b']\nsummary=pd.DataFrame(np.vstack((TRAIN_ACC,VAL_ACC,Multi_Logloss)),columns = col,index = ind)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:30:22.654571Z","iopub.execute_input":"2021-07-29T13:30:22.654946Z","iopub.status.idle":"2021-07-29T13:30:25.319336Z","shell.execute_reply.started":"2021-07-29T13:30:22.654913Z","shell.execute_reply":"2021-07-29T13:30:25.318373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the performance of the two algorithms is similar, hence we conduct tuning for the two models.","metadata":{}},{"cell_type":"markdown","source":"## lgb","metadata":{}},{"cell_type":"markdown","source":"### Trial 1 - BO","metadata":{}},{"cell_type":"markdown","source":"Search all the paramaters through Bayesian Optimization","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom bayes_opt import BayesianOptimization\ntrain_set = lgb.Dataset(data = x_train, label = y_train)\ndef lgb_eval(learning_rate, n_estimators, max_depth, num_leaves, min_data_in_leaf, bagging_fraction, bagging_freq, feature_fraction,\n             lambda_l1, lambda_l2):\n    params = {'objective': 'multiclass', 'num_class': 3, 'learning_rate': 0.1, \n              'seed': 1, 'force_col_wise': True, 'feature_pre_filter': False, 'verbose' : -1 }\n    params['learning_rate'] = learning_rate\n    params['n_estimators'] = round(n_estimators)\n    params['max_depth'] = round(max_depth)\n    params['num_leaves'] = round(num_leaves)\n    params['min_data_in_leaf'] = round(min_data_in_leaf)\n    params['bagging_freq'] = round(bagging_freq)\n    params['bagging_fraction'] = min(bagging_fraction,1.0)\n    params['feature_fraction'] = min(feature_fraction,1.0)\n    params['lambda_l1'] = lambda_l1\n    params['lambda_l2'] = lambda_l2\n    cv_result = lgb.cv(params, train_set, nfold = 5, early_stopping_rounds = 50, \n                       verbose_eval = 50, eval_train_metric = True)\n    return -(min(cv_result['valid multi_logloss-mean']))\n\nlgb_BO_1 = BayesianOptimization(lgb_eval,     \n    {'learning_rate': (0.05,0.2),\n     'n_estimators': (10,500),\n     'max_depth': (3,8),\n     'max_depth': (3,8),\n     'num_leaves': (7, 255),\n     'min_data_in_leaf': (18,22),\n     'bagging_fraction':(0.8,1),\n     'bagging_freq':(1,5),\n     'feature_fraction': (0.8,1),\n     'lambda_l1': (0.1,3), \n     'lambda_l2': (0.1,3)\n}, random_state = 1)\nlgb_BO_1.maximize()\nlgb_BO_1.max","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:31:27.505372Z","iopub.execute_input":"2021-07-29T13:31:27.505877Z","iopub.status.idle":"2021-07-29T13:32:21.212937Z","shell.execute_reply.started":"2021-07-29T13:31:27.505845Z","shell.execute_reply":"2021-07-29T13:32:21.211954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('the multi-logloss improvement:', gbm_b.best_score_['valid_0']['multi_logloss'] - abs(lgb_BO_1.max['target']))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:32:40.818397Z","iopub.execute_input":"2021-07-29T13:32:40.818751Z","iopub.status.idle":"2021-07-29T13:32:40.824919Z","shell.execute_reply.started":"2021-07-29T13:32:40.81872Z","shell.execute_reply":"2021-07-29T13:32:40.82378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trial 2 - BO+","metadata":{}},{"cell_type":"markdown","source":"Use Bayesian optimization to search for all parameters except learning_rate and n_estimators and\ninitialize learning rate as 0.1 and n_estimators as 5000","metadata":{}},{"cell_type":"code","source":"# lr = 0.1, n = 5000\ndef lgb_eval(max_depth, num_leaves, min_data_in_leaf, bagging_fraction, bagging_freq, feature_fraction,\n             lambda_l1, lambda_l2):\n    params = {'objective': 'multiclass', 'num_class': 3, 'seed': 1,\n              'learning_rate': 0.1,  'force_col_wise': True, 'feature_pre_filter': False, 'verbose' : -1 }\n    params['max_depth'] = round(max_depth)\n    params['num_leaves'] = round(num_leaves)\n    params['min_data_in_leaf'] = round(min_data_in_leaf)\n    params['bagging_freq'] = round(bagging_freq)\n    params['bagging_fraction'] = min(bagging_fraction,1.0)\n    params['feature_fraction'] = min(feature_fraction,1.0)\n    params['lambda_l1'] = lambda_l1\n    params['lambda_l2'] = lambda_l2\n    cv_result = lgb.cv(params, train_set, nfold = 5, num_boost_round = 5000, early_stopping_rounds = 50, \n                       verbose_eval = 50, eval_train_metric = True)\n    return -(min(cv_result['valid multi_logloss-mean']))\n\nlgb_BO_2 = BayesianOptimization(lgb_eval,     \n    {'max_depth': (3,8),\n     'num_leaves': (7, 255),\n     'min_data_in_leaf': (18,22),\n     'bagging_fraction':(0.8,1),\n     'bagging_freq':(1,5),\n     'feature_fraction': (0.8,1),\n     'lambda_l1': (0.1,3), \n     'lambda_l2': (0.1,3)\n}, random_state = 1)\n\nlgb_BO_2.maximize()\nlgb_BO_2.max","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:32:46.773295Z","iopub.execute_input":"2021-07-29T13:32:46.773675Z","iopub.status.idle":"2021-07-29T13:33:47.902046Z","shell.execute_reply.started":"2021-07-29T13:32:46.773637Z","shell.execute_reply":"2021-07-29T13:33:47.90131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### learning rate - GSCV","metadata":{}},{"cell_type":"markdown","source":"use gridCV to search the learning rate","metadata":{}},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfolds = KFold(n_splits= 5, shuffle= True, random_state= 1)\nparams = {'learning_rate':[0.005,0.01,0.05,0.08,0.1,0.2]}\ngbm_lr = lgbc(objective = 'multiclass', random_state = 1, \n              num_leaves = 220, max_depth = 8, min_data_in_leaf = 21, bagging_freq = 5, \n              bagging_fraction = 1.0, feature_fraction = 0.8,\n              lambda_l1 = 0.3547216179898903, lambda_l2 = 3.0)\ngs_lr = GridSearchCV(gbm_lr, params, scoring = 'neg_log_loss', cv = folds, n_jobs = -1, verbose = 2, return_train_score = True )\ngs_lr.fit(x_train,y_train) \nprint(gs_lr.best_params_,gs_lr.best_score_)\ngs_lr_results = pd.DataFrame(gs_lr.cv_results_)\ngs_lr_scores = gs_lr_results[['param_learning_rate','mean_test_score','mean_train_score']]\ngs_lr_scores ","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:35:49.847846Z","iopub.execute_input":"2021-07-29T13:35:49.848232Z","iopub.status.idle":"2021-07-29T13:36:00.554108Z","shell.execute_reply.started":"2021-07-29T13:35:49.848199Z","shell.execute_reply":"2021-07-29T13:36:00.553073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### n_estimators - GSCV","metadata":{}},{"cell_type":"markdown","source":"gridCV - for n_estimators with learning_rate = 0.05","metadata":{}},{"cell_type":"code","source":"%%time\nfolds = KFold(n_splits = 5, shuffle = True, random_state = 1)\nparams = {'n_estimators':range(10,201,10)}  \ngbm_n = lgbc(objective = 'multiclass', learning_rate = gs_lr.best_params_['learning_rate'],random_state = 1, \n             num_leaves = 220, max_depth = 8, min_data_in_leaf = 21, bagging_freq = 5, \n             bagging_fraction = 1.0, feature_fraction = 0.8,\n             lambda_l1 = 0.3547216179898903, lambda_l2 = 3.0)\ngs_n = GridSearchCV(gbm_n, params, scoring = 'neg_log_loss', cv = folds, n_jobs = -1, verbose = 2, return_train_score = True )\ngs_n.fit(x_train,y_train) \nprint(gs_n.best_params_,gs_n.best_score_)\ngs_n_results = pd.DataFrame(gs_n.cv_results_)\ngs_n_scores = gs_n_results[['param_n_estimators','mean_test_score','mean_train_score']]\ngs_n_scores ","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:39:50.75729Z","iopub.execute_input":"2021-07-29T13:39:50.757673Z","iopub.status.idle":"2021-07-29T13:40:15.836228Z","shell.execute_reply.started":"2021-07-29T13:39:50.75764Z","shell.execute_reply":"2021-07-29T13:40:15.835305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Narrow the scope to find more accurate paramater.","metadata":{}},{"cell_type":"code","source":"%%time\nfolds = KFold(n_splits= 5, shuffle= True, random_state= 1)\nparams = {'n_estimators':range(70,90,1)}\ngbm_n = lgbc(objective = 'multiclass', learning_rate = gs_lr.best_params_['learning_rate'],random_state = 1, \n             num_leaves = 220, max_depth = 8, min_data_in_leaf = 21, bagging_freq = 5, \n             bagging_fraction = 1.0, feature_fraction = 0.8,\n             lambda_l1 = 0.3547216179898903, lambda_l2 = 3.0)\ngs_n = GridSearchCV(gbm_n, params, scoring = 'neg_log_loss', cv = folds, n_jobs = -1, verbose = 2, return_train_score = True )\ngs_n.fit(x_train,y_train) \nprint(gs_n.best_params_,gs_n.best_score_)\ngs_n_results = pd.DataFrame(gs_n.cv_results_)\ngs_n_scores = gs_n_results[['param_n_estimators','mean_test_score','mean_train_score']]\ngs_n_scores ","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:42:49.824291Z","iopub.execute_input":"2021-07-29T13:42:49.824658Z","iopub.status.idle":"2021-07-29T13:43:07.575692Z","shell.execute_reply.started":"2021-07-29T13:42:49.824628Z","shell.execute_reply":"2021-07-29T13:43:07.575017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### n_estimators - CV","metadata":{}},{"cell_type":"markdown","source":"use lgb.cv to search the n_estimators with learning_rate = 0.05","metadata":{}},{"cell_type":"code","source":"params = {'objective': 'multiclass', 'num_class': 3, 'seed': 1,\n          'force_col_wise': True, 'feature_pre_filter': False, 'verbose' : -1,\n          'learning_rate': gs_lr.best_params_['learning_rate'], 'num_leaves': 220, 'max_depth': 8, \n          'min_data_in_leaf': 21, 'bagging_freq': 5, \n          'bagging_fraction': 1.0, 'feature_fraction': 0.8,  \n          'lambda_l1': 0.3547216179898903, 'lambda_l2': 3.0}\ncv_results = lgb.cv(params, train_set, nfold = 5, num_boost_round = 5000, early_stopping_rounds = 50, \n                    verbose_eval = 50, eval_train_metric = True)\ncv_summary = pd.DataFrame(cv_results)\nprint('best n_estimators:', cv_summary.shape[0])\nprint('best val_logloss score:', cv_summary.iloc[-1,2])","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:43:56.043144Z","iopub.execute_input":"2021-07-29T13:43:56.04374Z","iopub.status.idle":"2021-07-29T13:43:59.365771Z","shell.execute_reply.started":"2021-07-29T13:43:56.043689Z","shell.execute_reply":"2021-07-29T13:43:59.365014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.plot(range(1,cv_summary.shape[0]+1),cv_summary.iloc[:,0],color='lightsteelblue',label='train-logloss')\nplt.plot(range(1,cv_summary.shape[0]+1),cv_summary.iloc[:,2],color='pink',label='val-logloss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:44:01.828397Z","iopub.execute_input":"2021-07-29T13:44:01.828884Z","iopub.status.idle":"2021-07-29T13:44:02.022377Z","shell.execute_reply.started":"2021-07-29T13:44:01.828852Z","shell.execute_reply":"2021-07-29T13:44:02.021596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summary the performance of the lgb\nind = ['lgb_baseline','lgb_BO','lgb_BO_GSCV','lgb_BO_GSCV_CV']\ncol = ['multi-logloss']\nmulti_logloss_lgb = [gbm_b.best_score_['valid_0']['multi_logloss'], abs(lgb_BO_1.max['target']), \n                     abs(gs_n.best_score_), cv_summary.iloc[-1,2]]\nsummary_lgb = pd.DataFrame(multi_logloss_lgb,columns = col,index = ind)\nprint(summary_lgb)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:44:04.516773Z","iopub.execute_input":"2021-07-29T13:44:04.517287Z","iopub.status.idle":"2021-07-29T13:44:04.52638Z","shell.execute_reply.started":"2021-07-29T13:44:04.517253Z","shell.execute_reply":"2021-07-29T13:44:04.525539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that searching all the parameters through BO is better.","metadata":{}},{"cell_type":"markdown","source":"## cb","metadata":{}},{"cell_type":"markdown","source":"### Trial 1","metadata":{}},{"cell_type":"code","source":"# boosting_type = Ordered、auto_class_weights = Balanced\nimport catboost as cb\ntrain_pool = cb.Pool(data = x_train, label = y_train, cat_features = np.where(x_train.dtypes != np.float)[0])\ndef cb_eval(learning_rate, n_estimators, max_depth, reg_lambda):\n    params = {'objective': 'MultiClass', \n              'boosting_type': 'Ordered', 'auto_class_weights': 'Balanced', \n              'random_state': 1 }\n    params['learning_rate'] = learning_rate\n    params['n_estimators'] = round(n_estimators)\n    params['max_depth'] = round(max_depth)\n    params['reg_lambda'] = reg_lambda\n    cv_result = cb.cv(pool = train_pool, params = params, nfold = 5, \n                      early_stopping_rounds = 50, verbose = 50)\n    return -(min(cv_result['test-MultiClass-mean']))\n        \ncb_BO_1 = BayesianOptimization(cb_eval,     \n                             {'learning_rate': (0.05,0.2),\n                              'n_estimators': (10,500),\n                              'max_depth': (4,10),\n                              'reg_lambda': (0.1,3)}, random_state = 1)\ncb_BO_1.maximize(init_points = 5, n_iter = 5)\ncb_BO_1.max\n# 0.706790767154976","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:44:13.991914Z","iopub.execute_input":"2021-07-29T13:44:13.992278Z","iopub.status.idle":"2021-07-29T13:52:06.399469Z","shell.execute_reply.started":"2021-07-29T13:44:13.992234Z","shell.execute_reply":"2021-07-29T13:52:06.398465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trial 2","metadata":{}},{"cell_type":"code","source":"# boosting_type = 'Plain'、auto_class_weights = Balanced\ndef cb_eval(learning_rate, n_estimators, max_depth, reg_lambda):\n    params = {'objective': 'MultiClass', 'auto_class_weights': 'Balanced', 'random_state': 1 }\n    params['learning_rate'] = learning_rate\n    params['n_estimators'] = round(n_estimators)\n    params['max_depth'] = round(max_depth)\n    params['reg_lambda'] = reg_lambda\n    cv_result = cb.cv(pool = train_pool, params = params, nfold = 5, \n                      early_stopping_rounds = 50, verbose = 50)\n    return -(min(cv_result['test-MultiClass-mean']))\n        \ncb_BO_2 = BayesianOptimization(cb_eval,     \n                             {'learning_rate': (0.05,0.2),\n                              'n_estimators': (10,500),\n                              'max_depth': (4,10),\n                              'reg_lambda': (0.1,3)}, random_state = 1)\ncb_BO_2.maximize(init_points = 5, n_iter = 5)\ncb_BO_2.max\n# 0.7092479497327548","metadata":{"execution":{"iopub.status.busy":"2021-07-29T13:56:55.433117Z","iopub.execute_input":"2021-07-29T13:56:55.433668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trial 3","metadata":{}},{"cell_type":"code","source":"# boosting_type = Ordered, auto_class_weights = None = 1\ndef cb_eval(learning_rate, n_estimators, max_depth, reg_lambda):\n    params = {'objective': 'MultiClass', 'boosting_type': 'Ordered', 'random_state': 1 }\n    params['learning_rate'] = learning_rate\n    params['n_estimators'] = round(n_estimators)\n    params['max_depth'] = round(max_depth)\n    params['reg_lambda'] = reg_lambda\n    cv_result = cb.cv(pool = train_pool, params = params, nfold = 5, \n                      early_stopping_rounds = 50, verbose = 50)\n    return -(min(cv_result['test-MultiClass-mean']))\n        \ncb_BO_3 = BayesianOptimization(cb_eval,     \n                             {'learning_rate': (0.05,0.2),\n                              'n_estimators': (10,500),\n                              'max_depth': (4,10),\n                              'reg_lambda': (0.1,3)}, random_state = 1)\ncb_BO_3.maximize(init_points = 5, n_iter = 5)\ncb_BO_3.max\n# 0.6009923381161436","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Keeps the number of optimizations and searches consistent with using LGBM\ndef cb_eval(learning_rate, n_estimators, max_depth, reg_lambda):\n    params = {'objective': 'MultiClass', 'boosting_type': 'Ordered', 'random_state': 1 }\n    params['learning_rate'] = learning_rate\n    params['n_estimators'] = round(n_estimators)\n    params['max_depth'] = round(max_depth)\n    params['reg_lambda'] = reg_lambda\n    cv_result = cb.cv(pool = train_pool, params = params, nfold = 5, \n                      early_stopping_rounds = 50, verbose = 50)\n    return -(min(cv_result['test-MultiClass-mean']))\n        \ncb_BO_4 = BayesianOptimization(cb_eval,     \n                             {'learning_rate': (0.05,0.2),\n                              'n_estimators': (10,500),\n                              'max_depth': (4,10),\n                              'reg_lambda': (0.1,3)}, random_state = 1)\ncb_BO_4.maximize(init_points = 15,n_iter = 15)\ncb_BO_4.max","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind = ['lgb_baseline','cb_baseline','lgb_BO','lgb_BO_GSCV','lgb_BO_GSCV_CV','cb_BO_1', 'cb_BO_2', 'cb_BO_3', 'cb_BO_4']\ncol = ['tuned-multi-logloss']\ntuned_multi_logloss = [gbm_b.best_score_['valid_0']['multi_logloss'],cat_b.best_score_['validation']['MultiClass'],\n                       abs(lgb_BO_1.max['target']), abs(gs_n.best_score_), cv_summary.iloc[-1,2] ,\n                       abs(cb_BO_1.max['target']), abs(cb_BO_2.max['target']), abs(cb_BO_3.max['target']), \n                       abs(cb_BO_4.max['target'])]\ntuning_records = pd.DataFrame(tuned_multi_logloss,columns = col,index = ind)\nprint(tuning_records)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above table, we can see that the last tuning loss is minimal.\nTherefore, we substitute the parameters into the final model, and then train.","metadata":{}},{"cell_type":"code","source":"cat_f = cbc(objective = 'MultiClass', learning_rate = 0.05716226472904498, n_estimators = 292,\n            max_depth = 9, reg_lambda = 1.4979851182199662, random_state = 1)\ncat_f = cat_f.fit(X = train_pool, verbose = 10)\ntrain_acc_f = cat_f.score(x_train,y_train)\ny_pred = cat_f.predict(x_val)\nval_acc_f = accuracy_score(y_val,y_pred)\ny_pred = y_pred.reshape(-1,1)\ny_true = np.array(y_val).reshape(-1,1)\none_hot = OneHotEncoder(sparse = False)\ny_true = one_hot.fit_transform(y_true)\ny_pred = one_hot.fit_transform(y_pred)\nmulti_logloss_f = log_loss(y_true, y_pred)\nprint('train_acc_final: ',train_acc_f)\nprint('val_train_acc_final: ',val_acc_f)\nprint('multi_logloss_final: ',multi_logloss_f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary['cat_f'] = [train_acc_f, val_acc_f,multi_logloss_f]\nsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The loss of the whole model decreases only by', summary.iloc[2,1]-summary.iloc[2,2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# re-tune the n_estimators by cross-validation and set the n_estimators as 300\nval_pool = cb.Pool(data = x_val, label = y_val, cat_features = np.where(x_val.dtypes != np.float)[0])\ncat_f2 = cbc(objective = 'MultiClass', learning_rate = 0.05716226472904498, n_estimators = 300,\n             max_depth = 9, reg_lambda = 1.4979851182199662, random_state = 1)\ncat_f2 = cat_f2.fit(X = train_pool, eval_set = val_pool, use_best_model = True,\n                    early_stopping_rounds = 50, verbose = 10, plot = True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model evaluation","metadata":{}},{"cell_type":"code","source":"train_acc_f2 = cat_f2.score(x_train,y_train)\ny_pred = cat_f2.predict(x_val)\nval_acc_f2 = accuracy_score(y_val,y_pred)\ny_pred = y_pred.reshape(-1,1)\ny_true = np.array(y_val).reshape(-1,1)\none_hot = OneHotEncoder(sparse = False)\ny_true = one_hot.fit_transform(y_true)\ny_pred = one_hot.fit_transform(y_pred)\nmulti_logloss_f2 = log_loss(y_true, y_pred)\nprint('train_acc_final2: ',train_acc_f2)\nprint('val_train_acc_final2: ',val_acc_f2)\nprint('multi_logloss_final2: ',multi_logloss_f2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary['cat_f2'] = [train_acc_f2, val_acc_f2,multi_logloss_f2]\nsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The loss of the whole model decreases by', summary.iloc[2,1]-summary.iloc[2,3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_f2.tree_count_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_f2.best_iteration_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_f2.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the feature importance\ncat_f2_im = cat_f2.feature_importances_\nim_ind = np.argsort(cat_f2_im)[::-1]\nfor f in range(x_train.shape[1]):\n    print(f + 1, x.columns[im_ind[f]], cat_f2_im[im_ind[f]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_columns_ = [x.columns[i] for i in im_ind] \nfor i in range(x.columns.shape[0]): \n    plt.bar(i, cat_f2_im[im_ind[i]], color='lightsteelblue', align='center') \n    plt.xticks(np.arange(x.columns.shape[0]), x_columns_, rotation=90, fontsize=11) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model prediction","metadata":{}},{"cell_type":"code","source":"y_pred = cat_f2.predict_proba(test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(y_pred,columns=['predict_0', 'predict_1', 'predict_2'])\nre_test = test.reset_index()\nsubmission = pd.concat([re_test['id'], submission], axis=1)\nsubmission.to_csv('submission.csv',index = 0)\nsubmission.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}