{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### In this kernel, I mostly use ideas from other kernels. I have added a dihedral angle calculation which gives some boost.\n\n(I updated the kernel regarding the calculations for the dihedral angle. In previous kernel, even though I was using GPU, the use of pandas apply\nfunction was removing any advantage of GPU, so it was not fast. Now, I refactored the code and it the calcuation is fast without using any GPU.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n!git clone --recursive https://github.com/Microsoft/LightGBM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt-get install -y -qq libboost-all-dev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd LightGBM/python-package/;python3 setup.py install --precompile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n!rm -r LightGBM","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport cupy as cp\nfrom sklearn.model_selection import train_test_split,KFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nsns.set()\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv', header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14, 12))\nsns.boxplot(x='type', y='scalar_coupling_constant', data=df_train, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that if we want we can divide by type:\n\n1st: 1JHC\n\n2nd: 1JHN\n\n3rd: 2JHC, 2JHN, 3JHH, 3JHN, 3JHC\n\n4th: 2JHH"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv', header=0)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"structures = pd.read_csv('../input/structures.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"structures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bond calculations\n\n(Thanks to https://www.kaggle.com/adrianoavelar/bond-calculation-lb-0-82?scriptVersionId=15911797)"},{"metadata":{"trusted":true},"cell_type":"code","source":"atomic_radius = {'H':0.38, 'C':0.77, 'N':0.75, 'O':0.73, 'F':0.71} # Without fudge factor\n\nfudge_factor = 0.05\natomic_radius = {k:v + fudge_factor for k,v in atomic_radius.items()}\n\nelectronegativity = {'H':2.2, 'C':2.55, 'N':3.04, 'O':3.44, 'F':3.98}\n\n#structures = pd.read_csv(structures, dtype={'atom_index':np.int8})\n\natoms = structures['atom'].values\natoms_en = [electronegativity[x] for x in tqdm(atoms)]\natoms_rad = [atomic_radius[x] for x in tqdm(atoms)]\n\nstructures['EN'] = atoms_en\nstructures['rad'] = atoms_rad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"structures.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i_atom = structures['atom_index'].values\np = structures[['x', 'y', 'z']].values\np_compare = p\nm = structures['molecule_name'].values\nm_compare = m\nr = structures['rad'].values\nr_compare = r\n\nsource_row = np.arange(len(structures))\nmax_atoms = 28\n\nbonds = np.zeros((len(structures)+1, max_atoms+1), dtype=np.int8)\nbond_dists = np.zeros((len(structures)+1, max_atoms+1), dtype=np.float32)\n\n\nfor i in tqdm(range(max_atoms-1)):\n    p_compare = np.roll(p_compare, -1, axis=0)\n    m_compare = np.roll(m_compare, -1, axis=0)\n    r_compare = np.roll(r_compare, -1, axis=0)\n    \n    mask = np.where(m == m_compare, 1, 0) #Are we still comparing atoms in the same molecule?\n    dists = np.linalg.norm(p - p_compare, axis=1) * mask\n    r_bond = r + r_compare\n    \n    bond = np.where(np.logical_and(dists > 0.0001, dists < r_bond), 1, 0)\n    \n    source_row = source_row\n    target_row = source_row + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n    target_row = np.where(np.logical_or(target_row > len(structures), mask==0), len(structures), target_row) #If invalid target, write to dummy row\n    \n    source_atom = i_atom\n    target_atom = i_atom + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n    target_atom = np.where(np.logical_or(target_atom > max_atoms, mask==0), max_atoms, target_atom) #If invalid target, write to dummy col\n    \n    bonds[(source_row, target_atom)] = bond\n    bonds[(target_row, source_atom)] = bond\n    bond_dists[(source_row, target_atom)] = dists\n    bond_dists[(target_row, source_atom)] = dists\n\nbonds = np.delete(bonds, axis=0, obj=-1) #Delete dummy row\nbonds = np.delete(bonds, axis=1, obj=-1) #Delete dummy col\nbond_dists = np.delete(bond_dists, axis=0, obj=-1) #Delete dummy row\nbond_dists = np.delete(bond_dists, axis=1, obj=-1) #Delete dummy col\n\n\nbonds_numeric = [[i for i,x in enumerate(row) if x] for row in tqdm(bonds)]\nbond_lengths = [[dist for i,dist in enumerate(row) if i in bonds_numeric[j]] for j,row in enumerate(tqdm(bond_dists))]\nbond_lengths_mean = [ np.mean(x) for x in bond_lengths]\nn_bonds = [len(x) for x in bonds_numeric]\n\nbond_data = {'n_bonds':n_bonds, 'bond_lengths_mean': bond_lengths_mean }\nbond_df = pd.DataFrame(bond_data)\nstructures = structures.join(bond_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"structures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dihedral angle\n\nWe are going to compute the dihedral angle. This angle is derived from the first 4 atoms in the molecule.\n\nThe calculations are done on the GPU by using cupy package."},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://stackoverflow.com/questions/20305272/dihedral-torsion-angle-from-four-points-in-cartesian-coordinates-in-python\ndef dihedral_angle(data): \n        \n    vals = np.array(data[:, 3:6], dtype=np.float64)\n    mol_names = np.array(data[:, 0], dtype=np.str)\n \n    result = np.zeros((data.shape[0], 2), dtype=object)\n    # use every 4 rows to compute the dihedral angle\n    for idx in range(0, vals.shape[0] - 4, 4):\n\n        a0 = vals[idx]\n        a1 = vals[idx + 1]\n        a2 = vals[idx + 2]\n        a3 = vals[idx + 3]\n        \n        b0 = a0 - a1\n        b1 = a2 - a1\n        b2 = a3 - a2\n        \n        # normalize b1 so that it does not influence magnitude of vector\n        # rejections that come next\n        b1 /= np.linalg.norm(b1)\n    \n        # vector rejections\n        # v = projection of b0 onto plane perpendicular to b1\n        #   = b0 minus component that aligns with b1\n        # w = projection of b2 onto plane perpendicular to b1\n        #   = b2 minus component that aligns with b1\n\n        v = b0 - np.dot(b0, b1) * b1\n        w = b2 - np.dot(b2, b1) * b1\n\n        # angle between v and w in a plane is the torsion angle\n        # v and w may not be normalized but that's fine since tan is y/x\n        x = np.dot(v, w)\n        y = np.dot(np.cross(b1, v), w)\n       \n        # We want all 4 first rows for every molecule to have the same value\n        # (in order to have the same length as the dataframe)\n        result[idx:idx + 4] = [mol_names[idx], np.degrees(np.arctan2(y, x))]\n        \n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nstartTime = datetime.now()\ndihedral = dihedral_angle(structures[structures.groupby('molecule_name')['atom_index'].transform('count').ge(4)].groupby('molecule_name').head(4).values)\nprint('Time elapsed (hh:mm:ss.ms) {}'.format(datetime.now() - startTime))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"themap = {k:v for k, v in dihedral if k}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"structures['dihedral'] = structures['molecule_name'].map(themap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"structures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that for every molecule we leave the same value for the dihedral angle."},{"metadata":{"trusted":true},"cell_type":"code","source":"def map_atom_info(df, atom_idx):\n    #df = pd.merge(df, structures[['molecule_name', 'atom_index', 'x', 'y', 'z', 'EN', 'rad', 'n_bonds', 'bond_lengths_mean', 'dihedral']], how = 'left',\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = map_atom_info(df_train, 0)\ntrain = map_atom_info(train, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = map_atom_info(df_test, 0)\ntest = map_atom_info(test, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compute some distances"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Euclidean Distance\ndef dist(a, b, ax=1):\n    return cp.linalg.norm(a - b, axis=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_atom_0 = cp.asarray(train[['x_0', 'y_0', 'z_0']].values)\ntrain_atom_1 = cp.asarray(train[['x_1', 'y_1', 'z_1']].values)\n\ntrain['dist'] = dist(train_atom_1, train_atom_0).get()\ntrain['dist_x'] = dist( cp.asarray(train[['x_0']].values),  cp.asarray(train[['x_1']].values)).get()\ntrain['dist_y'] = dist( cp.asarray(train[['y_0']].values),  cp.asarray(train[['y_1']].values)).get()\ntrain['dist_z'] = dist( cp.asarray(train[['z_0']].values),  cp.asarray(train[['z_1']].values)).get()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_atom_0 = cp.asarray(test[['x_0', 'y_0', 'z_0']].values)\ntest_atom_1 = cp.asarray(test[['x_1', 'y_1', 'z_1']].values)\n\ntest['dist'] = dist(test_atom_1, test_atom_0).get()\ntest['dist_x'] = dist( cp.asarray(test[['x_0']].values),  cp.asarray(test[['x_1']].values)).get()\ntest['dist_y'] = dist( cp.asarray(test[['y_0']].values),  cp.asarray(test[['y_1']].values)).get()\ntest['dist_z'] = dist( cp.asarray(test[['z_0']].values),  cp.asarray(test[['z_1']].values)).get()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create some features\n\n(https://www.kaggle.com/artgor/brute-force-feature-engineering)"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''def create_features(df):\n    #df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n    #df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n    #df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n    #df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n    #df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n    #df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n    \n    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n    #df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n    #df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n    #df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n   # df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n    #df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n    #df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n    #df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n    #df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n    #df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n    #df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n    #df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n    #df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n    #df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n    #df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n    #df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n    #df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n    #df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n    #df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n    #df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n    #df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n\n   \n    df = reduce_mem_usage(df)\n    return df'''\ndef create_features(df):\n    #df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n    #df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n    #df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n    #df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n    \n    #df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n    #df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n    #df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n    #df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n    #df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n    #df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n    #df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n    #df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n    #df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n    #df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n   # df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n    #df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n    #df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n    #df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n    #df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n    #df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n    #df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n    #df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n    #df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n    #df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n    #df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n    #df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n    #df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n    #df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n    #df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n    #df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n\n    df = reduce_mem_usage(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = create_features(train)\ntest = create_features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train = train.dropna()\n#test = test.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for i in ['atom_index_0', 'atom_index_1', 'type']:\nfor i in ['atom_0', 'atom_1', 'type']:\n    class_le = LabelEncoder()   \n    train[i] = class_le.fit_transform(train[i].values)\n    test[i] = class_le.fit_transform(test[i].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''cols = [\n\n'id',\n#'molecule_name',\n'atom_index_0', \n'atom_index_1', \n'type', \n#'atom_0',\n'EN_x',\n'rad_x',\n'n_bonds_x',\n'bond_lengths_mean_x',\n'x_0', \n'y_0', \n'z_0', \n'dihedral_x',\n#'atom_1',\n'EN_y',\n'rad_y',\n'n_bonds_y',\n'bond_lengths_mean_y',\n'x_1', \n'y_1', \n'z_1', \n'dihedral_y',\n'dist',\n'dist_x', \n'dist_y', \n'dist_z',\n'molecule_atom_index_0_dist_min',\n#'molecule_atom_index_0_dist_max',\n'molecule_atom_index_1_dist_min',\n'molecule_atom_index_0_dist_mean',\n'molecule_atom_index_0_dist_std',\n'molecule_atom_index_1_dist_std',\n#'molecule_atom_index_1_dist_max',\n'molecule_atom_index_1_dist_mean',\n#'molecule_atom_index_0_dist_max_diff',\n#'molecule_atom_index_0_dist_max_div',\n'molecule_atom_index_0_dist_std_diff',\n'molecule_atom_index_0_dist_std_div',\n#'atom_0_couples_count',\n#'molecule_atom_index_0_dist_min_div',\n'molecule_atom_index_1_dist_std_diff',\n#'molecule_at_mean',\n#'molecule_atom_index_1_dist_max_diff',\n'molecule_atom_index_0_y_1_std',\n#'molecule_atom_index_1_dist_mean_diff',\n'molecule_atom_index_1_dist_std_div',\n#'molecule_atom_index_1_dist_mean_div',\n#'molecule_atom_index_1_dist_min_diff',\n#'molecule_atom_index_1_dist_min_div',\n#'molecule_atom_index_1_dist_max_div',\n'molecule_atom_index_0_z_1_std',\n'molecule_type_dist_std_diff',\n#'molecule_atom_1_dist_min_diff',\n'molecule_atom_index_0_x_1_std',\n#'molecule_dist_min',\n#'molecule_atom_index_0_disom_index_0_dist_mean_div',\n#'atom_1_couples_count',\n#'molecule_atom_index_0_dist_mean_diff',\n#'molecule_couples',\n#'molecule_distt_min_diff',\n'molecule_atom_index_0_y_1_mean_diff',\n#'molecule_type_dist_min',\n#'molecule_atom_1_dist_min_div',\n#'molecule_dist_max',\n#'molecule_atom_1_dist_std_diff',\n#'molecule_type_dist_max',\n#'molecule_atom_index_0_y_1_max_diff',\n'molecule_type_dist_mean_diff',\n#'molecule_atom_1_dist_mean',\n'molecule_atom_index_0_y_1_mean_div',\n'molecule_type_dist_mean_div'\n]'''\ncols = [\n\n'id',\n'atom_index_0', \n'atom_index_1', \n'type', \n'atom_0',\n'EN_x',\n'rad_x',\n'n_bonds_x',\n'bond_lengths_mean_x',\n'x_0', \n'y_0', \n'z_0', \n'dihedral_x',\n'atom_1',\n'EN_y',\n'rad_y',\n'n_bonds_y',\n'bond_lengths_mean_y',\n'x_1', \n'y_1', \n'z_1', \n'dihedral_y',\n'dist',\n'dist_x', \n'dist_y', \n'dist_z',\n'molecule_atom_index_0_dist_min',\n'molecule_atom_index_0_dist_max',\n'molecule_atom_index_1_dist_min',\n'molecule_atom_index_0_dist_mean',\n#'molecule_atom_index_0_dist_std',\n#'molecule_atom_index_1_dist_std',\n'molecule_atom_index_1_dist_max',\n'molecule_atom_index_1_dist_mean',\n#'molecule_atom_index_0_dist_max_diff',\n#'molecule_atom_index_0_dist_max_div',\n#'molecule_atom_index_0_dist_std_diff',\n#'molecule_atom_index_0_dist_std_div',\n#'atom_0_couples_count',\n'molecule_atom_index_0_dist_min_div',\n#'molecule_atom_index_1_dist_std_diff',\n#'molecule_atom_index_0_dist_mean_div',\n#'atom_1_couples_count',\n'molecule_atom_index_0_dist_mean_diff',\n#'molecule_couples',\n#'molecule_dist_mean',\n#'molecule_atom_index_1_dist_max_diff',\n#'molecule_atom_index_0_y_1_std',\n#'molecule_atom_index_1_dist_mean_diff',\n#'molecule_atom_index_1_dist_std_div',\n'molecule_atom_index_1_dist_mean_div',\n#'molecule_atom_index_1_dist_min_diff',\n#'molecule_atom_index_1_dist_min_div',\n#'molecule_atom_index_1_dist_max_div',\n#'molecule_atom_index_0_z_1_std',\n#'molecule_type_dist_std_diff',\n'molecule_atom_1_dist_min_diff',\n#'molecule_atom_index_0_x_1_std',\n'molecule_dist_min',\n#'molecule_atom_index_0_dist_min_diff',\n'molecule_atom_index_0_y_1_mean_diff',\n'molecule_type_dist_min',\n'molecule_atom_1_dist_min_div',\n'molecule_dist_max',\n#'molecule_atom_1_dist_std_diff',\n'molecule_type_dist_max',\n#'molecule_atom_index_0_y_1_max_diff',\n'molecule_type_dist_mean_diff',\n'molecule_atom_1_dist_mean',\n#'molecule_atom_index_0_y_1_mean_div',\n#'molecule_type_dist_mean_div'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data(df):\n    X_train, X_val, y_train, y_val  = train_test_split(df[cols].values,\n                                                       df.loc[:, 'scalar_coupling_constant'].values,\n                                                       test_size=0.2,\n                                                       random_state=1340)\n        \n    return X_train, X_val, y_train, y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test[cols].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_boost_round = 4000\nearly_stopping_rounds = 200\nverbose_eval = 200\n\n#X_train, X_val, y_train, y_val = data(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evals_result = {}\n\nparams = {\n            'boosting_type': 'gbdt',\n            'objective': 'regression',\n            'metric': 'mae',\n            'learning_rate': 0.2,\n            'num_leaves': 900, \n            'reg_alpha': 0.5, \n            'reg_lambda': 0.5, \n            'max_bin': 63,\n            'gpu_use_dp': 'false',\n            'sparse_threshold': 1,\n             #'nthread': 4, \n            'device': 'gpu',\n            'gpu_platform_id': 0,\n            'gpu_device_id': 0,\n            'min_child_samples': 45\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lgb_train = lgb.Dataset(X_train, y_train)\n#lgb_val = lgb.Dataset(X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = lgb.train(params,\n#                  lgb_train,\n#                  num_boost_round=num_boost_round,\n#                  valid_sets=[lgb_val],\n#                  early_stopping_rounds=early_stopping_rounds, \n#                  evals_result=evals_result, \n#                  verbose_eval=verbose_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 2\nk_fold = KFold(n_splits=n_folds, shuffle=True, random_state=2)\npredictions = np.zeros(len(test))\noof = np.zeros(len(train))\n\nfor train_idx, val_idx in k_fold.split(train[cols].values, train.loc[:, 'scalar_coupling_constant'].values):\n#for train_idx, val_idx in k_fold.split(X_train, y_train):\n\n    lgb_train = lgb.Dataset(train[cols].values[train_idx], train.loc[:, 'scalar_coupling_constant'].values[train_idx])\n    \n    lgb_val = lgb.Dataset(train[cols].values[val_idx], train.loc[:, 'scalar_coupling_constant'].values[val_idx])  \n    \n    #lgb_train = lgb.Dataset(X_train[train_idx], y_train[train_idx])\n    \n    #lgb_val = lgb.Dataset(X_train[val_idx], y_train[val_idx])  \n    \n    model = lgb.train(params,\n                      lgb_train,\n                      num_boost_round=num_boost_round,\n                      valid_sets=[lgb_val],\n                      early_stopping_rounds=early_stopping_rounds, \n                      evals_result=evals_result, \n                      verbose_eval=verbose_eval)\n    \n    #model = lgb.LGBMRegressor(**params,\n    #                          n_estimators=num_boost_round,\n    #                          verbose_eval=verbose_eval)\n    \n    \n    #model.fit(train[cols].values[train_idx],\n    #          train.loc[:, 'scalar_coupling_constant'].values[train_idx], \n    #          eval_set=[(train[cols].values[train_idx],train.loc[:, 'scalar_coupling_constant'].values[train_idx]),\n    #                    (train[cols].values[val_idx], train.loc[:, 'scalar_coupling_constant'].values[val_idx])],\n    #          early_stopping_rounds=early_stopping_rounds)\n    \n    #oof[val_idx] = model.predict(train[cols].values[val_idx], num_iteration=model.best_iteration) \n    \n    predictions += model.predict(X_test, num_iteration=model.best_iteration) / n_folds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install thundersvm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!conda install cudatoolkit=9.0 -y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#idx_not_finite = np.where(np.isfinite(X_train[:, 40]) == False)#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train_SVR = np.delete(X_train, idx_not_finite, axis=0)#\n#y_train_SVR = np.delete(y_train, idx_not_finite)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from thundersvm import SVR#\n\n#model_SVR = SVR()\n#model_SVR.fit(X_train_SVR ,y_train_SVR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.save_model('model.txt', num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds = model.predict(X_test, num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def submit(predictions):\n    submit = pd.read_csv('../input/sample_submission.csv')\n    submit[\"scalar_coupling_constant\"] = predictions\n    submit.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit(predictions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}