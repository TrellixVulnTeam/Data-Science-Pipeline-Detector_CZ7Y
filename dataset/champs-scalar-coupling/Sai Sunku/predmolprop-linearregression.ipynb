{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir('/kaggle/input'))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/predmolprop-featureengineering-finaltrain/train_extend.csv\")\ntest = pd.read_csv(\"../input/predmolprop-featureengineering-finaltest/test_extend.csv\")\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode atoms\ndef encode_atoms(df):\n    type2encoding = {'H': 1,'C': 2,'N': 3,'O': 4,'F': 5,'': -1}\n    df['atom_end_type']=df.atom_end_type.map(type2encoding)\n    df['atom_2_type']=df.atom_2_type.map(type2encoding)\n    df['atom_3_type']=df.atom_3_type.map(type2encoding)\n    return df\n\ntrain = encode_atoms(train)\ntest = encode_atoms(test)\n\npd.set_option('display.max_columns', None)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target = train['scalar_coupling_constant']\n\n# Remove some features\ntrain_pop_list = ['id','molecule_name', 'atom_index_0','atom_index_1', 'num_bonds','bond_1', 'atom_0_type2', 'atom_end_type2', 'scalar_coupling_constant']\ntest_pop_list = ['molecule_name', 'atom_index_0','atom_index_1', 'num_bonds','bond_1', 'atom_0_type2', 'atom_end_type2'] # Keep ID as this is needed for submission\n\ntrain_features = train.drop(columns=train_pop_list)\ntest_features = test.drop(columns=test_pop_list)\n\n# Replace NaNs with -1\ntrain_features.fillna(value =-1,inplace= True)\ntest_features.fillna(value =-1,inplace= True)\ntest.fillna(value=-1,inplace=True)\n\npd.set_option('display.max_columns', None)\ntrain_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First train a regressor on 75% of the data and use the rest for validation\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nmae_dict = {}; train_mae_dict = {}; mean_dict = {}; regr_dict = {};\nmae_total = 0;\n\ntypes = train.type.unique()\n# plt.figure(); [fig, axs] = plt.subplots(2,4,figsize=(12, 10));\nfor mol_type in types:\n    print('Now training type: '+str(mol_type))\n    \n    # Prepare data for the model\n    train_by_type = train_features[train_features['type']==mol_type]\n    train_by_type.pop('type')\n    # train_by_type.drop(columns=['mu','spin','path_count']) # Remove some additional features for now\n    target_by_type = train[train['type']==mol_type].scalar_coupling_constant\n    \n    train_X, val_X, train_Y, val_Y = train_test_split(train_by_type, target_by_type,test_size=0.2,random_state=42)\n    \n    mae_dict[mol_type] = []; train_mae_dict[mol_type] = []; mean_dict[mol_type] = []; regr_dict[mol_type] = [];\n    \n    # Make model\n    regr_model = LinearRegression(copy_X=True, n_jobs=-1)\n    fit = regr_model.fit(train_X, train_Y)\n    \n    # Predict\n    pred_Y = regr_model.predict(val_X)\n    \n    # Calculate MSE\n    mae = mean_absolute_error(val_Y, pred_Y) # MSE for validation data\n    train_mae = mean_absolute_error(train_Y, regr_model.predict(train_X)) # MSE for the training data\n    mean = sum(val_Y)/len(val_Y) # Mean of the validation data\n    print('val mae: '+str(mae)+'train mae: '+str(train_mae)+'mean: '+str(mean))\n    \n    # Save all MSEs\n    mae_dict[mol_type].append(mae)\n    train_mae_dict[mol_type].append(train_mae)\n    mean_dict[mol_type].append(mean)\n    regr_dict[mol_type].append(fit)\n\n    # Calculate total MSE\n    min_mae = min(mae_dict[mol_type])\n    # num_val = len(val_Y.index)\n    mae_total += np.log(min_mae)\n    print('mae_total: '+str(mae_total))\n    \n    # axs[j//4, ((j+1)%4)-1].plot(val_Y, pred_Y, 'o')\n    # axs[j//4, ((j+1)%4)-1].set_title(mol_type)\n    # g = sns.FacetGrid(pd.DataFrame({'type':mol_type,'scalar_coupling_constant': val_Y,'predictions':pred_Y}), \n    #                      col=\"type\", col_order = types,sharex=False,sharey=False)\n    # g.map(sns.scatterplot, \"scalar_coupling_constant\",\"predictions\")\n    \n    plt.figure(figsize=[6,6])\n    sns.scatterplot(x=val_Y, y=pred_Y)\n    plt.plot(val_Y,val_Y,color='black')\n    plt.title(mol_type)\n    plt.xlabel('scalar coupling constant')\n    plt.ylabel('predicted value')\n    \n    lims = plt.xlim()\n    width=lims[1]-lims[0]\n    lims=lims[0]-0.1*width,lims[1]+0.1*width\n    plt.xlim(lims)\n    plt.ylim(lims)\n#    xlim=plt.xlim()\n#    ylim=plt.ylim()\n#    plt.xlim(min(xlim[0],ylim[0]),max(xlim[1],ylim[1]))\n#    plt.ylim(min(xlim[0],ylim[0]),max(xlim[1],ylim[1]))\n    plt.show()\n\nmae_total = mae_total/8\nprint('Log MAE using a different linear regressor for each type: '+str(mae_total))\n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}