{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importer des libraire","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\n%matplotlib widget","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:36:05.264263Z","iopub.status.busy":"2022-04-25T04:36:05.263548Z","iopub.status.idle":"2022-04-25T04:36:05.416231Z","shell.execute_reply":"2022-04-25T04:36:05.415664Z","shell.execute_reply.started":"2022-04-25T04:36:05.264214Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import r2_score, accuracy_score, confusion_matrix, classification_report","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:36:05.417967Z","iopub.status.busy":"2022-04-25T04:36:05.417581Z","iopub.status.idle":"2022-04-25T04:36:05.421773Z","shell.execute_reply":"2022-04-25T04:36:05.420847Z","shell.execute_reply.started":"2022-04-25T04:36:05.417926Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyser les données","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"./data/train.csv\")\ntest = pd.read_csv(\"./data/test.csv\")\nsub = pd.read_csv(\"./data/sample_submission.csv\")\nstructures = pd.read_csv(\"./data/structures.csv\")","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:36:05.423568Z","iopub.status.busy":"2022-04-25T04:36:05.423342Z","iopub.status.idle":"2022-04-25T04:36:15.194818Z","shell.execute_reply":"2022-04-25T04:36:15.194017Z","shell.execute_reply.started":"2022-04-25T04:36:05.423534Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Nombre des molécules (train): \",train['molecule_name'].nunique())\nprint(\"************************\\n\")\n\nprint(\"Nombre des molécules (test): \",test['molecule_name'].nunique())\nprint(\"************************\\n\")\n\nprint(\"Atome : \", structures['atom'].nunique())\nprint(structures.atom.value_counts(), \"\\n************************\\n\")\n\nprint(\"Couplage : \",train['type'].nunique())\nprint(train.type.value_counts(), \"\\n************************\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculer le nombre des atomes dans une molécule","metadata":{}},{"cell_type":"code","source":"structures1 = structures.groupby(['molecule_name']).size().reset_index(name=\"num_atom\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"structures2 = pd.merge(structures[\"molecule_name\"], pd.get_dummies(structures[\"atom\"]),left_index=True, right_index=True).groupby(\"molecule_name\").sum().reset_index()\nstructures2 = structures2.rename(columns={'C': 'num_C',\n                        'F': 'num_F',\n                        'H': 'num_H',\n                        'N': 'num_N',\n                        'O': 'num_O'})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculer la distance des atomes","metadata":{}},{"cell_type":"code","source":"def map_atom_info(df, atom_idx):\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df\n\ntrain = pd.merge(train, structures1, left_on = 'molecule_name', right_on = 'molecule_name')\ntrain = pd.merge(train, structures2, left_on = 'molecule_name', right_on = 'molecule_name')\ntrain = map_atom_info(train, 0)\ntrain = map_atom_info(train, 1)\ntrain = train.drop(\"id\",axis=1)\n\ntest = pd.merge(test, structures1, left_on = 'molecule_name', right_on = 'molecule_name')\ntest = pd.merge(test, structures2, left_on = 'molecule_name', right_on = 'molecule_name')\ntest = map_atom_info(test, 0)\ntest = map_atom_info(test, 1)\ntest = test.drop(\"id\",axis=1)","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:36:32.346904Z","iopub.status.busy":"2022-04-25T04:36:32.346135Z","iopub.status.idle":"2022-04-25T04:36:44.320361Z","shell.execute_reply":"2022-04-25T04:36:44.316974Z","shell.execute_reply.started":"2022-04-25T04:36:32.346868Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_p_0 = train[['x_0', 'y_0', 'z_0']].values\ntrain_p_1 = train[['x_1', 'y_1', 'z_1']].values\ntest_p_0 = test[['x_0', 'y_0', 'z_0']].values\ntest_p_1 = test[['x_1', 'y_1', 'z_1']].values\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['dist'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)\ntest['dist'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)\n\ntrain['dist_x'] = np.abs(train['x_0'] - train['x_1'])\ntest['dist_x'] = np.abs(test['x_0'] - test['x_1'])\ntrain['dist_y'] = np.abs(train['y_0'] - train['y_1'])\ntest['dist_y'] = np.abs(test['y_0'] - test['y_1'])\ntrain['dist_z'] = np.abs(train['z_0'] - train['z_1'])\ntest['dist_z'] = np.abs(test['z_0'] - test['z_1'])","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:36:44.325403Z","iopub.status.busy":"2022-04-25T04:36:44.323912Z","iopub.status.idle":"2022-04-25T04:36:44.996067Z","shell.execute_reply":"2022-04-25T04:36:44.995327Z","shell.execute_reply.started":"2022-04-25T04:36:44.325166Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Encoder","metadata":{}},{"cell_type":"code","source":"train.type.value_counts()","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:37:16.495428Z","iopub.status.busy":"2022-04-25T04:37:16.495192Z","iopub.status.idle":"2022-04-25T04:37:16.790668Z","shell.execute_reply":"2022-04-25T04:37:16.789859Z","shell.execute_reply.started":"2022-04-25T04:37:16.495395Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.atom_0.value_counts()","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:37:16.792476Z","iopub.status.busy":"2022-04-25T04:37:16.792202Z","iopub.status.idle":"2022-04-25T04:37:16.990884Z","shell.execute_reply":"2022-04-25T04:37:16.989947Z","shell.execute_reply.started":"2022-04-25T04:37:16.792446Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.atom_1.value_counts()","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:37:16.992483Z","iopub.status.busy":"2022-04-25T04:37:16.992152Z","iopub.status.idle":"2022-04-25T04:37:17.192011Z","shell.execute_reply":"2022-04-25T04:37:17.191221Z","shell.execute_reply.started":"2022-04-25T04:37:16.992442Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type = ['2JHH','3JHH','1JHC','2JHC','3JHC','1JHN','2JHN','3JHN']\n\ndef labelencoder(df):\n    le0 = LabelEncoder()\n    df[\"atom_0\"] = le0.fit_transform(df[\"atom_0\"])\n\n    le1 = LabelEncoder()\n    le1 = le1.fit(['H','C','N'])\n    df[\"atom_1\"] = le1.transform(df[\"atom_1\"])\n\n    le2 = LabelEncoder()\n    le2 = le2.fit(['2JHH','3JHH','1JHC','2JHC','3JHC','1JHN','2JHN','3JHN'])\n    df[\"type\"] = le2.transform(df[\"type\"])\n    \n    return df","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:37:17.193428Z","iopub.status.busy":"2022-04-25T04:37:17.193133Z","iopub.status.idle":"2022-04-25T04:37:17.202632Z","shell.execute_reply":"2022-04-25T04:37:17.201956Z","shell.execute_reply.started":"2022-04-25T04:37:17.193399Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = labelencoder(train)\ntest = labelencoder(test)","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:37:17.204141Z","iopub.status.busy":"2022-04-25T04:37:17.203525Z","iopub.status.idle":"2022-04-25T04:37:20.382172Z","shell.execute_reply":"2022-04-25T04:37:20.381626Z","shell.execute_reply.started":"2022-04-25T04:37:17.204103Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyser la corrélation","metadata":{}},{"cell_type":"code","source":"tabcorr = train.corr()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlations = tabcorr.scalar_coupling_constant\nprint(abs(correlations.drop(['scalar_coupling_constant'],axis=0)).sort_values(ascending=False))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(abs(tabcorr), cmap=\"coolwarm\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.kdeplot(x=\"scalar_coupling_constant\",data=train,hue=\"type\",shade=True, palette=sns.color_palette(\"Paired\",8))\nplt.xlabel(\"Coupling constant\",fontdict={'size': 15})\nplt.ylabel(\"Density\",fontdict={'size': 15})\nplt.legend(labels=type, title = \"Type\", prop={'size': 12}, title_fontsize = \"15\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.kdeplot(x=\"scalar_coupling_constant\",data=train,shade=True)\nplt.xlabel(\"Coupling constant\",fontdict={'size': 15})\nplt.ylabel(\"Density\",fontdict={'size': 15})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.kdeplot(x=\"dist\",data=train,hue=\"type\",shade=True, palette=sns.color_palette(\"Paired\",8))\nplt.xlabel(\"Distance\",fontdict={'size': 15})\nplt.ylabel(\"Density\",fontdict={'size': 15})\nplt.legend(labels=type, title = \"Type\", prop={'size': 12}, title_fontsize = \"15\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.scatterplot(x=\"dist\", y=\"scalar_coupling_constant\", data=train, hue=\"type\", palette=sns.color_palette(\"Paired\", 8))\nplt.xlabel(\"Distance\",fontdict={'size': 15})\nplt.ylabel(\"Coupling constant\",fontdict={'size': 15})\nplt.legend(labels=type, title = \"Type\", prop={'size': 12}, title_fontsize = \"15\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nax=sns.boxplot(x=\"type\", y=\"scalar_coupling_constant\", data=train, palette=sns.color_palette(\"Paired\", 8))\nax.set_xticklabels(labels=type)\nplt.xlabel(\"Coupling type\",fontdict={'size': 15})\nplt.ylabel(\"Coupling constant\",fontdict={'size': 15})\n#plt.legend(labels=type, title = \"Type\", prop={'size': 12}, title_fontsize = \"15\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine learning","metadata":{}},{"cell_type":"markdown","source":"## Fonctions","metadata":{}},{"cell_type":"code","source":"def plot_learning_curve(est, X_train, y_train) :\n    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=5,\n                                                        n_jobs=-1)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.figure(figsize=(8,10))\n    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n    plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n    plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n    plt.grid(visible='on')\n    plt.xlabel('Number of training samples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim([0.2, 1.0])\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_compare2y(y_name,y_test,y_pred):\n    plt.figure(figsize=(8,8))\n    plt.scatter(y_test, y_pred)\n    plt.plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()], color='red', linewidth=3)\n    plt.xlabel(\"Real value\",fontdict={'size': 12})\n    plt.ylabel(\"Prediction\",fontdict={'size': 12})\n    plt.title(y_name,fontdict={'size': 12})\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.xlabel(\"epoch\")\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## X, y","metadata":{}},{"cell_type":"code","source":"#train_s = train.sample(frac=0.1)\n\nX = train.drop(['scalar_coupling_constant', 'atom_0', 'molecule_name'],axis=1)\ny = train['scalar_coupling_constant']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor(n_jobs=-1)\nrf.fit(X_train, y_train)","metadata":{"execution":{"iopub.execute_input":"2022-04-25T04:37:20.383596Z","iopub.status.busy":"2022-04-25T04:37:20.383195Z","iopub.status.idle":"2022-04-25T04:37:20.388264Z","shell.execute_reply":"2022-04-25T04:37:20.387308Z","shell.execute_reply.started":"2022-04-25T04:37:20.383564Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importances_rf = rf.feature_importances_\nindices_rf = np.argsort(importances_rf)\n\nplt.figure(figsize=(12,9))\nplt.barh(range(len(indices_rf)), importances_rf[indices_rf])\nplt.yticks(range(len(indices_rf)), X_train.columns[indices_rf])\nplt.title(\"Importance des caracteristiques (Random Forest)\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = rf.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_compare2y(y_name=\"Coupling Constant [Random Forest] : \"+str(r2_score(y_true=y_test, y_pred=y_pred)),y_test=y_test,y_pred=y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,t in enumerate(type):\n    y_test_tt = y_test[X_test['type'] == i]\n    y_pred_tt = y_pred[X_test['type'] == i]\n    plot_compare2y(y_name=t+\" & Coupling Constant [Random Forest] : \"+str(r2_score(y_true=y_test_tt, y_pred=y_pred_tt)),y_test=y_test_tt,y_pred=y_pred_tt)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest (selon type)","metadata":{}},{"cell_type":"code","source":"train_t, X_t, y_t, X_train_t, X_test_t, y_train_t, y_test_t, y_pred_t = [],[],[],[],[],[],[],[]\nfor i,t in enumerate(type):\n    train_t.append(train[train['type'] == i])\n    X_t.append(train_t[i].drop(['scalar_coupling_constant', 'atom_0', 'molecule_name'],axis=1))\n    y_t.append(train_t[i]['scalar_coupling_constant'])\n    X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = train_test_split(X_t[i], y_t[i], test_size=0.1, random_state=1)\n    X_train_t.append(X_train_tmp)\n    X_test_t.append(X_test_tmp)\n    y_train_t.append(y_train_tmp)\n    y_test_t.append(y_test_tmp)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_t = [RandomForestRegressor(n_jobs=-1)]*8\nfor i,t in enumerate(type):\n    print(type[i])\n    rf_t[i].fit(X_train_t[i], y_train_t[i])\n    y_pred_t.append(rf_t[i].predict(X_test_t[i]))\n    plot_compare2y(y_name=\"Coupling Constant [Random Forest & type] : \"+str(r2_score(y_true=y_test_t[i], y_pred=y_pred_t[i])),y_test=y_test_t[i],y_pred=y_pred_t[i])\n    print()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest (moins X)","metadata":{}},{"cell_type":"code","source":"X_m = train[['type','dist','atom_1']]\n\nX_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_m, y, test_size=0.1, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_m = RandomForestRegressor(n_jobs=-1)\nrf_m.fit(X_train_m, y_train_m)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_m = rf_m.predict(X_test_m)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_compare2y(y_name=\"Coupling Constant [Random Forest & moins X] : \"+str(r2_score(y_true=y_test_m, y_pred=y_pred_m)),y_test=y_test_m,y_pred=y_pred_m)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,t in enumerate(type):\n    y_test_mt = y_test_m[X_test_m['type'] == i]\n    y_pred_mt = y_pred_m[X_test_m['type'] == i]\n    plot_compare2y(y_name=t+\" & Coupling Constant [Random Forest & moins X] : \"+str(r2_score(y_true=y_test_mt, y_pred=y_pred_mt)),y_test=y_test_mt,y_pred=y_pred_mt)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Couche dense","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow import keras\n\nkeras.backend.set_floatx('float64')\n\nimport json","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.002\ncoef1 = 1e-5\nactivation = 'tanh'\nloss = \"mse\"\npath = \"./model/model2\"\noptimizer = keras.optimizers.Adam(learning_rate)\nEPOCHS = 100\n\nmodel_reg = keras.Sequential([\n    keras.Input(shape=(20,), name='layer_in'),\n    keras.layers.Dense(14, activation=activation, name='layer_1', kernel_regularizer=keras.regularizers.l1(coef1)),\n    keras.layers.Dense(14, activation=activation, name='layer_2', kernel_regularizer=keras.regularizers.l1(coef1)),\n    keras.layers.Dense(14, activation=activation, name='layer_3', kernel_regularizer=keras.regularizers.l1(coef1)),\n    keras.layers.Dense(1, name='layer_out')\n    ], name='model_reg')\nmodel_reg.compile(loss=loss, optimizer=optimizer, metrics=['mae', 'mse'])\n\nmodel_reg.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = path + \"/checkpoint/model_reg.ckpt\"\n''' ### if exists saved model load it\n    if os.path.exists(checkpoint_path + '.index'):\n        print('----------------load the model-------------------')\n        model_reg.load_weights(checkpoint_path)\n'''\n\nclass PrintDot(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs):\n        if epoch % 100 == 0 and epoch != 0:\n            print()\n        if epoch % 20 == 0 and epoch != 0:\n            print()\n        if epoch % 1 == 0:\n            print('.', end=' ')\n\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True)\n\nphysical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\nlogical_devices = tf.config.experimental.list_logical_devices(\"GPU\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_reg = model_reg.fit(X_train, y_train, epochs=EPOCHS,\n                    validation_split = 0.1, verbose=0, \n                    callbacks=[early_stop,cp_callback, PrintDot()])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(path + \"/history.json\", \"w\") as json_file:\n    json.dump(history_reg.history, json_file)\n\nmodel_reg.save(path + \"/model_reg.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_reg = tf.keras.models.load_model(\"./model/model2/model_reg.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_reg.evaluate(X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_tf = model_reg.predict(X_test)\nplot_compare2y(y_name=\"Coupling Constant [Dense layer] : \"+str(r2_score(y_true=y_test, y_pred=y_pred_tf)),y_test=y_test,y_pred=y_pred_tf)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,t in enumerate(type):\n    y_test_tt = y_test[X_test['type'] == i]\n    y_pred_tt = y_pred_tf[X_test['type'] == i]\n    plot_compare2y(y_name=t+\" & Coupling Constant [Dense layer] : \"+str(r2_score(y_true=y_test_tt, y_pred=y_pred_tt)),y_test=y_test_tt,y_pred=y_pred_tt)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"y_c1 = pd.cut(y, bins=100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lec = LabelEncoder()\ny_c = lec.fit_transform(y_c1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_c, test_size=0.9, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier(n_jobs=-1)\nrfc.fit(X_train_c, y_train_c)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_c = rfc.predict(X_test_c)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test_c, y_pred_c)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_compare2y(y_name=\"Coupling Constant [Random Forest Classifier] : \",y_test=y_test_c,y_pred=y_pred_c)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Couche dense (classifier)","metadata":{}},{"cell_type":"code","source":"model5 = keras.Sequential()\nmodel5.add(keras.layers.Dense(100, activation='relu'))\nmodel5.add(keras.layers.Dense(100, activation='relu'))\nmodel5.add(keras.layers.Dense(100, activation='softmax'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model5.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train5 = model5.fit(X_train_c , y_train_c , validation_split = 0.1, epochs=100, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model5.evaluate(X_test_c,y_test_c)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplot_scores(train5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_c1 = model5.predict(X_test_c)\nplot_compare2y(y_name=\"Coupling Constant [Random Forest Classifier] : \",y_test=y_test_c,y_pred=y_pred_c1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"./model/model5\"\n\nwith open(path + \"/history.json\", \"w\") as json_file:\n    json.dump(train5.history, json_file)\n\nmodel5.save(path + \"/model_reg.h5\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"train['scalar_coupling_constant'].values.min()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# Soumission\n\npredictions = rf.predict(test[['type','atom_1','dist','dist_x','dist_y','dist_z']])\n\nsample_submission = pd.read_csv(\"./data/sample_submission.csv\")\n\nsample_submission[\"scalar_coupling_constant\"] = predictions\n\nsample_submission.to_csv(\"submission.csv\",index=False)","metadata":{}}]}