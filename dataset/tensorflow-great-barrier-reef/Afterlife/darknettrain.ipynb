{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import wandb\nwandb.login(anonymous='must')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt update\n!apt install --yes python-opencv\n!apt install --yes libopencv-dev\n!/bin/bash -c 'echo \"/opt/conda/lib/\" > /etc/ld.so.conf.d/opencv.conf'\n!ldconfig\n!pip install imagesize","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:39:53.447202Z","iopub.execute_input":"2021-12-31T15:39:53.447556Z","iopub.status.idle":"2021-12-31T15:41:03.10846Z","shell.execute_reply.started":"2021-12-31T15:39:53.447472Z","shell.execute_reply":"2021-12-31T15:41:03.107508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import groupby\nimport numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\nimport os\nimport pickle\nimport cv2\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\n# import cupy as cp\nimport ast\nimport glob\n\nimport shutil\nimport sys\nsys.path.append('../input/tensorflow-great-barrier-reef')\n\nfrom joblib import Parallel, delayed\n\nfrom IPython.display import display, HTML\n\nfrom matplotlib import animation, rc\nrc('animation', html='jshtml')","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:12:29.90588Z","iopub.execute_input":"2022-01-02T13:12:29.906348Z","iopub.status.idle":"2022-01-02T13:12:29.912546Z","shell.execute_reply.started":"2022-01-02T13:12:29.906317Z","shell.execute_reply":"2022-01-02T13:12:29.911765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLD      = 4 # which fold to train\nREMOVE_NOBBOX = True # remove images with no bbox\nROOT_DIR  = '/kaggle/input/tensorflow-great-barrier-reef/'\nIMAGE_DIR = '/kaggle/images' # directory to save images\nLABEL_DIR = '/kaggle/labels' # directory to save labels\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-02T13:12:27.504697Z","iopub.execute_input":"2022-01-02T13:12:27.505019Z","iopub.status.idle":"2022-01-02T13:12:27.50968Z","shell.execute_reply.started":"2022-01-02T13:12:27.504985Z","shell.execute_reply":"2022-01-02T13:12:27.508776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p {IMAGE_DIR}\n!mkdir -p {LABEL_DIR}","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:12:32.081041Z","iopub.execute_input":"2022-01-02T13:12:32.081792Z","iopub.status.idle":"2022-01-02T13:12:33.650418Z","shell.execute_reply.started":"2022-01-02T13:12:32.081751Z","shell.execute_reply":"2022-01-02T13:12:33.649217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_path(row):\n    row['old_image_path'] = f'{ROOT_DIR}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    row['image_path'] = f'{IMAGE_DIR}/video_{row.video_id}_{row.video_frame}.jpg'\n    row['label_path'] = f'{LABEL_DIR}/video_{row.video_id}_{row.video_frame}.txt'\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:12:33.652245Z","iopub.execute_input":"2022-01-02T13:12:33.652602Z","iopub.status.idle":"2022-01-02T13:12:33.657674Z","shell.execute_reply.started":"2022-01-02T13:12:33.652564Z","shell.execute_reply":"2022-01-02T13:12:33.656794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Data\ndf = pd.read_csv(f'{ROOT_DIR}/train.csv')\ndf = df.progress_apply(get_path, axis=1)\ndf['annotations'] = df['annotations'].progress_apply(lambda x: ast.literal_eval(x))\ndisplay(df.head(2))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:12:35.232722Z","iopub.execute_input":"2022-01-02T13:12:35.233125Z","iopub.status.idle":"2022-01-02T13:13:16.27282Z","shell.execute_reply.started":"2022-01-02T13:12:35.233094Z","shell.execute_reply":"2022-01-02T13:13:16.271914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['num_bbox'] = df['annotations'].progress_apply(lambda x: len(x))\ndata = (df.num_bbox>0).value_counts(normalize=True)*100\nprint(f\"No BBox: {data[0]:0.2f}% | With BBox: {data[1]:0.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:13:19.720148Z","iopub.execute_input":"2022-01-02T13:13:19.720406Z","iopub.status.idle":"2022-01-02T13:13:19.796172Z","shell.execute_reply.started":"2022-01-02T13:13:19.72038Z","shell.execute_reply":"2022-01-02T13:13:19.795632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if REMOVE_NOBBOX:\n    df = df.query(\"num_bbox>0\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:13:22.331932Z","iopub.execute_input":"2022-01-02T13:13:22.332215Z","iopub.status.idle":"2022-01-02T13:13:22.357788Z","shell.execute_reply.started":"2022-01-02T13:13:22.332184Z","shell.execute_reply":"2022-01-02T13:13:22.357163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_copy(path):\n    data = path.split('/')\n    filename = data[-1]\n    video_id = data[-2]\n    new_path = os.path.join(IMAGE_DIR,f'{video_id}_{filename}')\n    shutil.copy(path, new_path)\n    return","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:13:24.448291Z","iopub.execute_input":"2022-01-02T13:13:24.448683Z","iopub.status.idle":"2022-01-02T13:13:24.453963Z","shell.execute_reply.started":"2022-01-02T13:13:24.448655Z","shell.execute_reply":"2022-01-02T13:13:24.453126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = df.old_image_path.tolist()\n_ = Parallel(n_jobs=-1, backend='threading')(delayed(make_copy)(path) for path in tqdm(image_paths))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:13:27.188394Z","iopub.execute_input":"2022-01-02T13:13:27.188676Z","iopub.status.idle":"2022-01-02T13:13:44.572467Z","shell.execute_reply.started":"2022-01-02T13:13:27.188642Z","shell.execute_reply":"2022-01-02T13:13:44.571843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def voc2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    voc  => [x1, y1, x2, y1]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n    \n    w = bboxes[..., 2] - bboxes[..., 0]\n    h = bboxes[..., 3] - bboxes[..., 1]\n    \n    bboxes[..., 0] = bboxes[..., 0] + w/2\n    bboxes[..., 1] = bboxes[..., 1] + h/2\n    bboxes[..., 2] = w\n    bboxes[..., 3] = h\n    \n    return bboxes\n\ndef yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes\n\ndef coco2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normolizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef yolo2coco(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\n\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None):\n    # Plots one bounding box on image img\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n     \n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n    \n    if bbox_format == 'yolo':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:\n            \n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n                h  = round(float(bbox[3])*image.shape[0]/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness)\n            \n    elif bbox_format == 'coco':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:            \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                w  = int(round(bbox[2]))\n                h  = int(round(bbox[3]))\n\n                voc_bbox = (x1, y1, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n\n    elif bbox_format == 'voc_pascal':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes: \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                x2 = int(round(bbox[2]))\n                y2 = int(round(bbox[3]))\n                voc_bbox = (x1, y1, x2, y2)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row['image_path'])\n    return row\n\n\n# https://www.kaggle.com/diegoalejogm/great-barrier-reefs-eda-with-animations\ndef create_animation(ims):\n    fig = plt.figure(figsize=(16, 12))\n    plt.axis('off')\n    im = plt.imshow(ims[0])\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//12)\n\nnp.random.seed(32)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:13:48.203996Z","iopub.execute_input":"2022-01-02T13:13:48.20458Z","iopub.status.idle":"2022-01-02T13:13:48.23764Z","shell.execute_reply.started":"2022-01-02T13:13:48.20454Z","shell.execute_reply":"2022-01-02T13:13:48.236984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['bboxes'] = df.annotations.progress_apply(get_bbox)\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:13:55.800909Z","iopub.execute_input":"2022-01-02T13:13:55.801296Z","iopub.status.idle":"2022-01-02T13:13:55.864769Z","shell.execute_reply.started":"2022-01-02T13:13:55.801266Z","shell.execute_reply":"2022-01-02T13:13:55.863589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['width']  = 1280\ndf['height'] = 720\ndisplay(df.head(2))","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:43:21.894874Z","iopub.execute_input":"2021-12-31T15:43:21.895325Z","iopub.status.idle":"2021-12-31T15:43:21.914339Z","shell.execute_reply.started":"2021-12-31T15:43:21.895285Z","shell.execute_reply":"2021-12-31T15:43:21.913515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = 0\nall_bboxes = []\nfor row_idx in tqdm(range(df.shape[0])):\n    row = df.iloc[row_idx]\n    image_height = row.height\n    image_width  = row.width\n    bboxes_coco  = np.array(row.bboxes).astype(np.float32).copy()\n    num_bbox     = len(bboxes_coco)\n    names        = ['cots']*num_bbox\n    labels       = [0]*num_bbox\n    ## Create Annotation(YOLO)\n    with open(row.label_path, 'w') as f:\n        if num_bbox<1:\n            annot = ''\n            f.write(annot)\n            cnt+=1\n            continue\n        bboxes_yolo  = coco2yolo(image_height, image_width, bboxes_coco)\n        bboxes_yolo  = np.clip(bboxes_yolo, 0, 1)\n        all_bboxes.extend(bboxes_yolo)\n        for bbox_idx in range(len(bboxes_yolo)):\n            annot = [str(labels[bbox_idx])]+ list(bboxes_yolo[bbox_idx].astype(str))+(['\\n'] if num_bbox!=(bbox_idx+1) else [''])\n            annot = ' '.join(annot)\n            annot = annot.strip(' ')\n            f.write(annot)\nprint('Missing:',cnt)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:43:24.155176Z","iopub.execute_input":"2021-12-31T15:43:24.155437Z","iopub.status.idle":"2021-12-31T15:43:26.532428Z","shell.execute_reply.started":"2021-12-31T15:43:24.155407Z","shell.execute_reply":"2021-12-31T15:43:26.531715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:43:30.685997Z","iopub.execute_input":"2021-12-31T15:43:30.686566Z","iopub.status.idle":"2021-12-31T15:43:31.422324Z","shell.execute_reply.started":"2021-12-31T15:43:30.686526Z","shell.execute_reply":"2021-12-31T15:43:31.421454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/AlexeyAB/darknet.git\n\n%cd darknet\n\n!cp '../../input/libcuda/libcuda.so' .\n\n!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n!sed -i 's/GPU=0/GPU=1/g' Makefile\n!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/g' Makefile\n!sed -i 's/LIBSO=0/LIBSO=1/' Makefile\n!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n\n!sed -i 's/LDFLAGS+= -L\\/usr\\/local\\/cuda\\/lib64 -lcuda -lcudart -lcublas -lcurand/LDFLAGS+= -L\\/usr\\/local\\/cuda\\/lib64 -lcudart -lcublas -lcurand -L\\/kaggle\\/working\\/darknet -lcuda/' Makefile\n!make &> compile.log","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:43:33.498592Z","iopub.execute_input":"2021-12-31T15:43:33.499185Z","iopub.status.idle":"2021-12-31T15:45:27.909661Z","shell.execute_reply.started":"2021-12-31T15:43:33.499146Z","shell.execute_reply":"2021-12-31T15:45:27.908554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tail compile.log","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:45:30.953306Z","iopub.execute_input":"2021-12-31T15:45:30.954099Z","iopub.status.idle":"2021-12-31T15:45:31.638269Z","shell.execute_reply.started":"2021-12-31T15:45:30.954052Z","shell.execute_reply":"2021-12-31T15:45:31.637436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/images/* /kaggle/working/darknet/data\n!cp /kaggle/labels/* /kaggle/working/darknet/data","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:45:35.117974Z","iopub.execute_input":"2021-12-31T15:45:35.118661Z","iopub.status.idle":"2021-12-31T15:45:42.136145Z","shell.execute_reply.started":"2021-12-31T15:45:35.118621Z","shell.execute_reply":"2021-12-31T15:45:42.135027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob, os\n\n\ncurrent_dir = '/kaggle/working/darknet/data/'\n\n# Percentage of images to be used for the test set\npercentage_test = 10;\n\n# Create and/or truncate train.txt and test.txt\nfile_train = open('/kaggle/working/darknet/data/train.txt', 'w')\nfile_test = open('/kaggle/working/darknet/data/test.txt', 'w')\n\n# Populate train.txt and test.txt\ncounter = 1\nindex_test = round(100 / percentage_test)\nfor pathAndFilename in glob.iglob(os.path.join(current_dir, \"*.jpg\")):\n    title, ext = os.path.splitext(os.path.basename(pathAndFilename))\n    if counter == index_test:\n        counter = 1\n        file_test.write(\"/kaggle/working/darknet/data/\"  + title + '.jpg' + \"\\n\")\n    else:\n        file_train.write(\"/kaggle/working/darknet/data/\" + title + '.jpg' + \"\\n\")\n        counter = counter + 1","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:45:45.600679Z","iopub.execute_input":"2021-12-31T15:45:45.601329Z","iopub.status.idle":"2021-12-31T15:45:45.657685Z","shell.execute_reply.started":"2021-12-31T15:45:45.601285Z","shell.execute_reply":"2021-12-31T15:45:45.656934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/input/gbrprivateconfig/obj.data /kaggle/working/darknet/data\n!cp /kaggle/input/gbrprivateconfig/obj.names /kaggle/working/darknet/data\n!cp /kaggle/input/gbrprivateconfig/trial.cfg /kaggle/working/darknet/cfg","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:52:42.437609Z","iopub.execute_input":"2021-12-31T15:52:42.437882Z","iopub.status.idle":"2021-12-31T15:52:44.459823Z","shell.execute_reply.started":"2021-12-31T15:52:42.437851Z","shell.execute_reply":"2021-12-31T15:52:44.458864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/darknet\n!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p6.conv.289","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:46:04.028013Z","iopub.execute_input":"2021-12-31T15:46:04.028315Z","iopub.status.idle":"2021-12-31T15:46:12.084274Z","shell.execute_reply.started":"2021-12-31T15:46:04.028276Z","shell.execute_reply":"2021-12-31T15:46:12.083471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n!mkdir edisgreat","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/darknet\n!./darknet detector train data/obj.data cfg/trial.cfg yolov4-p6.conv.289 -dont_show -map","metadata":{"execution":{"iopub.status.busy":"2021-12-31T15:52:48.025395Z","iopub.execute_input":"2021-12-31T15:52:48.025928Z","iopub.status.idle":"2021-12-31T15:54:11.301504Z","shell.execute_reply.started":"2021-12-31T15:52:48.025886Z","shell.execute_reply":"2021-12-31T15:54:11.300691Z"},"trusted":true},"execution_count":null,"outputs":[]}]}