{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{"_uuid":"cbd4fa9d-9d07-4773-92d9-dfb962ba890b","_cell_guid":"3bdf8f72-1d3f-4c74-baf9-ebd3e704ca22","trusted":true}},{"cell_type":"markdown","source":"<a href=\"./a.py\"> Download File </a>","metadata":{"_uuid":"9b532717-6815-4837-b077-e89559c61483","_cell_guid":"953ea798-f4f4-4ae5-9851-34fbba9e7b7d","trusted":true}},{"cell_type":"code","source":"!pip install -q ../input/flex-yolo-pack/torch-1.7.1+cu110-cp37-cp37m-linux_x86_64.whl\n!pip install -q ../input/flex-yolo-pack/torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl\n!pip install -q ../input/flex-yolo-pack/torchvision-0.8.2+cu110-cp37-cp37m-linux_x86_64.whl\n# !pip install  --user ../input/flex-yolo-pack/pycocotools-2.0.4/pycocotools-2.0.4.tar\n# !pip install -q ../input/flex-yolo-pack/coremltools-5.1.0-cp37-none-manylinux1_x86_64.whl\n!pip install -q ../input/flex-yolo-pack/addict-2.4.0-py3-none-any.whl\n# !pip install -q ../input/flex-yolo-pack/onnx-1.10.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n# !pip install -q ../input/flex-yolo-pack/scikit_learn-0.19.2-cp37-cp37m-manylinux1_x86_64.whl\n# !pip install -q ../input/flex-yolo-pack/thop-0.0.31.post2005241907-py3-none-any.whl\n!pip install -q ../input/timm-model/timm-0.3.2-py3-none-any.whl","metadata":{"_uuid":"80c4f2c8-1082-40b9-8d03-e0519d3aebe6","_cell_guid":"1589d069-9c6e-4c86-9d83-4bf046d9b176","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:32:54.215918Z","iopub.execute_input":"2022-02-14T02:32:54.216537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.core.display import HTML\n# HTML(\"<script>flexible_yolo_with_attention_mechnism.notebook.kernel.restart()</script>\")","metadata":{"_uuid":"26bc3e3f-a408-4c82-aa1b-d9f8f2d0f9b5","_cell_guid":"d9f98e57-d05b-41cc-b435-a21a3dc233c9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# import cv2\n# import matplotlib.pyplot as plt\n# tmp=np.load('../input/tensorflow-great-barrier-reef/example_test.npy')\n# from PIL import Image\n# # print(tmp[0].shape)\n# # print(tmp[0])\n\n# # im = Image.fromarray(tmp[0])\n# # imt=cv2.imread(im)\n\n# # print(tmp.shape)\n# # im.show()\n# t=cv2.imread('../input/test-img/1_5296-1-0.jpg')\n# print(t.shape)\n# print(t)\n# # plt.imshow(tmp[0], cmap='gray')\n# # plt.imshow(t)\n# # # print(t.shape)\n# # plt.imshow(rgb, cmap='gray')\n# # plt.show()","metadata":{"_uuid":"cf2d9558-2043-4449-acb3-ec25b702bae3","_cell_guid":"d03e18fd-cccb-48eb-9f35-20e273e211ac","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob\nimport shutil\nimport sys\nsys.path.append('../input/tensorflow-great-barrier-reef')\nsys.path.append('../input/flexible-yolov5/flexible-yolov5/scripts')\nsys.path.append('../input/flexible-yolov5/flexible-yolov5')\nimport torch\nfrom PIL import Image\nimport ast","metadata":{"_uuid":"6d6ca290-fc60-477d-ac01-b273f8f6ccd5","_cell_guid":"314ad46f-f678-4b16-8a14-609566b6e946","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = '''\nstarfish\n'''\nwith open('./class.txt', 'w') as fp:\n    fp.write(data)","metadata":{"_uuid":"f3cbc37e-9ae1-4581-893d-03e64e52c4e5","_cell_guid":"6c5c36f1-d7ce-4bea-8fdc-8547ccf982da","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# def predict(model, img):\n#     height, width = img.shape[:2]\n#     results = model(img)  # custom inference size\n#     preds   = results.pandas().xyxy[0]\n#     bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n#     if len(bboxes):\n#         bboxes  = voc2coco(bboxes,height,width).astype(int)\n#         confs   = preds.confidence.values\n#         return bboxes, confs\n#     else:\n#         return [],[]\n    \ndef format_prediction(bboxes, confs):\n    annot = ''\n    if len(bboxes)>0:\n        for idx in range(len(bboxes)):\n            xmin, ymin, w, h = bboxes[idx]\n            \n            xmin, ymin, w, h=int(xmin), int(ymin), int(w), int(h)\n            conf             = confs[idx]\n            annot +='{:.2f} {} {} {} {}'.format(conf, xmin, ymin, w, h)\n\n#             annot += f'{conf} {xmin} {ymin} {w} {h}'\n            annot +=' '\n        annot = annot.strip(' ')\n    return annot\n\ndef show_img(img, bboxes, bbox_format='yolo'):\n    names  = ['starfish']*len(bboxes)\n    labels = [0]*len(bboxes)\n    img    = draw_bboxes(img = img,\n                           bboxes = bboxes, \n                           classes = names,\n                           class_ids = labels,\n                           class_name = True, \n                           colors = colors, \n                           bbox_format = bbox_format,\n                           line_thickness = 2)\n    return Image.fromarray(img).resize((800, 400))","metadata":{"_uuid":"613280af-d299-4c8d-b76c-25a5d6b9b41c","_cell_guid":"4b5e79d2-8ecb-4806-aa12-429b95c81ca4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img.shape","metadata":{"_uuid":"29fb59f5-243d-4958-b121-56e094d23bed","_cell_guid":"a18e9aac-23be-45c1-adbc-79d76f90f42e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detector import *\nfrom glob import glob\npt_path = '../input/yolo-flex-model/yolo_flex.pt'\nimgs = ['../input/test-img/1_5296-1-0.jpg']\n# img='../input/test-img/1_5296-1-0.jpg'\n# imgs=glob('../input/tensorflow-great-barrier-reef/train_images/video_1/*.jpg')\nclass_pth = './class.txt'\ntmp=np.load('../input/tensorflow-great-barrier-reef/example_test.npy')\ninter = Detector(pt_path=pt_path,namesfile=class_pth, img_size=1280,classes=0, conf_thres=0.3)\n# img = cv2.imread(img)\n# img=img.astype('float64')\nfor img_tmp in imgs:\n    img = cv2.imread(img_tmp)\n#     [:, :, ::-1][:, :, ::-1].transpose(2, 0, 1)\n    result = inter.detect_image(img)\n    bboxes, confs,_=result\n#     if len(bboxes)!=0:\n#         bboxes=bboxes.astype('int64')\n    annot          = format_prediction(bboxes, confs)\n    print(result)\nprint(annot)\n# print(tmp.shape)\n","metadata":{"_uuid":"b1acdab8-44d6-45cd-8aaf-70ba090ed23a","_cell_guid":"c45db0e7-cb7a-4df4-aa23-66ef5e86a2e8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(annot)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# t1=np.load('../input/tensorflow-great-barrier-reef/example_test.npy')[0]\n# t2=cv2.imread('../input/tensorflow-great-barrier-reef/train_images/video_1/5296.jpg')\n# # [:, :, ::-1]\n# # plt.imshow(t, cmap='gray')\n# # plt.imshow(t1)\n# print(t2)","metadata":{"_uuid":"a1f28a86-9b4c-4000-99d1-ad3032525259","_cell_guid":"6c69e6bf-af3f-4b51-855b-055e8fc91ddf","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()# initialize the environment\niter_test = env.iter_test()      # an iterator which loops over the test set and sample submission\nCONF= 0.15\nIOU= 0.50\n# im = cv2.imread(img)\n# inter = Detector(pt_path=pt_path,namesfile=class_pth, img_size=1280,classes=0)\n# result = inter.detect_image(im)\n# print(result)\n# model = load_model(Best_Model, conf=CONF, iou=IOU)\nfor idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n#     im = cv2.imread(img)\n#     print(img.shape)\n#     bboxes, confs  = predict(model, img, size=IMG_SIZE, augment=True)\n#     img=img.astype('float64')\n#     img /= 255.0\n    img_tmp=img\n#     print(img_tmp)\n    bboxes, confs,_=inter.detect_image(img_tmp)\n#     if len(bboxes)!=0:\n#         bboxes=bboxes.astype('int64')\n    annot          = format_prediction(bboxes, confs)\n    pred_df['annotations'] = annot\n    env.predict(pred_df)","metadata":{"_uuid":"9cadd769-cd50-4532-bc7a-c5e54f5f5d67","_cell_guid":"15397b60-be00-44cb-af8e-069c88b4f1ca","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('submission.csv')\nsub_df.head()","metadata":{"_uuid":"5884ac23-38f3-45e0-8e03-172a1ad961ac","_cell_guid":"f7655674-5df3-487d-81c7-25686cdce6f7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"fd1ed6d0-1f6e-46c0-be18-5ae13ad4708b","_cell_guid":"d12769a0-0e27-429c-9056-35f953721adb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"ba006de7-92ec-4f3d-a3b4-d20b2ca216bf","_cell_guid":"1d67909b-6a46-4345-bc75-d2fd1c840ad7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}