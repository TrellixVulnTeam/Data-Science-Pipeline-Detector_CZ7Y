{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Barrier Reef YOLOX_Inference_Parameters","metadata":{"papermill":{"duration":0.015663,"end_time":"2021-11-29T14:02:56.270401","exception":false,"start_time":"2021-11-29T14:02:56.254738","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#### this Notebook based on Barrier Reef YOLOX [Inference]\nhttps://www.kaggle.com/remekkinas/yolox-inference-on-kaggle-for-cots-lb-0-507","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport torch\nimport importlib\nimport cv2 \nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\nfrom PIL import Image\nfrom IPython.display import display","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.628665,"end_time":"2021-11-29T14:02:57.977972","exception":false,"start_time":"2021-11-29T14:02:56.349307","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-10T19:27:43.752826Z","iopub.execute_input":"2021-12-10T19:27:43.753226Z","iopub.status.idle":"2021-12-10T19:27:45.384636Z","shell.execute_reply.started":"2021-12-10T19:27:43.753117Z","shell.execute_reply":"2021-12-10T19:27:45.383896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cp -r /kaggle/input/yolox-cots-models /kaggle/working/\n%cd /kaggle/working/yolox-cots-models/yolox-dep\n\n!pip install pip-21.3.1-py3-none-any.whl -f ./ --no-index\n!pip install loguru-0.5.3-py3-none-any.whl -f ./ --no-index\n!pip install ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl -f ./ --no-index\n!pip install onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl -f ./ --no-index\n!pip install onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl -f ./ --no-index\n!pip install onnxoptimizer-0.2.6-cp37-cp37m-manylinux2014_x86_64.whl -f ./ --no-index\n!pip install thop-0.0.31.post2005241907-py3-none-any.whl -f ./ --no-index\n!pip install tabulate-0.8.9-py3-none-any.whl -f ./ --no-index\n%cd /kaggle/working/yolox-cots-models/YOLOX\n!pip install -r requirements.txt\n!pip install -v -e . \n%cd /kaggle/working/yolox-cots-models/yolox-dep/cocoapi/PythonAPI\n\n!make\n!make install\n!python setup.py install\n\nimport pycocotools\n\n#%cp -r /kaggle/input/barrier-reef-yolox/best_ckpt.pth /kaggle/working/yolox-cots-models","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-10T19:27:45.386412Z","iopub.execute_input":"2021-12-10T19:27:45.386732Z","iopub.status.idle":"2021-12-10T19:28:08.249742Z","shell.execute_reply.started":"2021-12-10T19:27:45.386693Z","shell.execute_reply":"2021-12-10T19:28:08.248883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# YOLO Functions","metadata":{"papermill":{"duration":0.010076,"end_time":"2021-11-29T14:02:57.998601","exception":false,"start_time":"2021-11-29T14:02:57.988525","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def yolox_inference(img, model, test_size): \n    bboxes = []\n    bbclasses = []\n    scores = []\n    \n    preproc = ValTransform(legacy = False)\n\n    tensor_img, _ = preproc(img, None, test_size)\n    tensor_img = torch.from_numpy(tensor_img).unsqueeze(0)\n    tensor_img = tensor_img.float()\n    tensor_img = tensor_img.cuda()\n\n    with torch.no_grad():\n        outputs = model(tensor_img)\n        outputs = postprocess(\n                    outputs, num_classes, confthre,\n                    nmsthre, class_agnostic=True\n                )\n\n    if outputs[0] is None:\n        return [], [], []\n    \n    outputs = outputs[0].cpu()\n    bboxes = outputs[:, 0:4]\n\n    bboxes /= min(test_size[0] / img.shape[0], test_size[1] / img.shape[1])\n    bbclasses = outputs[:, 6]\n    scores = outputs[:, 4] * outputs[:, 5]\n    \n    return bboxes, bbclasses, scores\n\n\ndef draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, classes_dict):\n    for i in range(len(bboxes)):\n            box = bboxes[i]\n            cls_id = int(bbclasses[i])\n            score = scores[i]\n            if score < confthre:\n                continue\n            x0 = int(box[0])\n            y0 = int(box[1])\n            x1 = int(box[2])\n            y1 = int(box[3])\n            \n            cv2.rectangle(img, (x0, y0), (x1, y1), (255, 0, 255), 1)\n            cv2.putText(img, '{}:{:.1f}%'.format(classes_dict[cls_id], score * 100), (x0, y0 - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(255,0,255), thickness = 2)\n    return img\n\ndef format_prediction(bboxes, confs,confthre):\n    annot = ''\n    if len(bboxes)>0:\n        for idx in range(len(bboxes)):\n            box = bboxes[idx]\n            x_min = int(box[0])\n            y_min = int(box[1])\n            x_max = int(box[2])\n            y_max = int(box[3])\n\n            w=x_max-x_min\n            h=y_max-y_min\n            \n            conf = confs[idx]\n            if conf < confthre:\n                continue\n            annot += '{:.3f} {} {} {} {}'.format(conf, x_min, y_min, w, h)\n            annot +=' '\n        annot = annot.strip(' ')\n    return annot","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:30:56.03469Z","iopub.execute_input":"2021-12-10T19:30:56.034965Z","iopub.status.idle":"2021-12-10T19:30:56.043736Z","shell.execute_reply.started":"2021-12-10T19:30:56.034927Z","shell.execute_reply":"2021-12-10T19:30:56.043048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Model","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/yolox-cots-models/YOLOX\nCHECKPOINT_FILE = '/kaggle/working/yolox-cots-models/yx_l_003.pth'","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:30:56.083358Z","iopub.execute_input":"2021-12-10T19:30:56.083601Z","iopub.status.idle":"2021-12-10T19:30:56.092528Z","shell.execute_reply.started":"2021-12-10T19:30:56.083568Z","shell.execute_reply":"2021-12-10T19:30:56.091693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_file_template = '''\n\n#!/usr/bin/env python3\n# -*- coding:utf-8 -*-\n# Copyright (c) Megvii, Inc. and its affiliates.\n\nimport os\n\nfrom yolox.exp import Exp as MyExp\n\n\nclass Exp(MyExp):\n    def __init__(self):\n        super(Exp, self).__init__()\n        self.depth = 1\n        self.width = 1\n        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n        self.num_classes = 1\n\n'''\n\nwith open('cots_config.py', 'w') as f:\n    f.write(config_file_template)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:30:56.094309Z","iopub.execute_input":"2021-12-10T19:30:56.094633Z","iopub.status.idle":"2021-12-10T19:30:56.105035Z","shell.execute_reply.started":"2021-12-10T19:30:56.094597Z","shell.execute_reply":"2021-12-10T19:30:56.10412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from yolox.utils import postprocess\nfrom yolox.data.data_augment import ValTransform\n\nCOCO_CLASSES = (\n  \"starfish\",\n)\n\n# get YOLOX experiment\ncurrent_exp = importlib.import_module('cots_config')\nexp = current_exp.Exp()\n\n# set inference parameters\ntest_size = (800, 1280)\nnum_classes = 1\nconfthre = 0.09 # 0.091 ,0.09\nnmsthre = 0.41 #0.411,0.41\n\n\n# get YOLOX model\nmodel = exp.get_model()\nmodel.cuda()\nmodel.eval()\n\n# get custom trained checkpoint\nckpt_file = CHECKPOINT_FILE\nckpt = torch.load(ckpt_file, map_location=\"cpu\")\nmodel.load_state_dict(ckpt[\"model\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:41:08.772861Z","iopub.execute_input":"2021-12-10T19:41:08.773111Z","iopub.status.idle":"2021-12-10T19:41:09.569441Z","shell.execute_reply.started":"2021-12-10T19:41:08.773082Z","shell.execute_reply":"2021-12-10T19:41:09.568586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference on a image from the Validation set","metadata":{}},{"cell_type":"code","source":"TEST_IMAGE_PATH = \"/kaggle/input/tensorflow-great-barrier-reef/train_images/video_2/5745.jpg\"\nimg = cv2.imread(TEST_IMAGE_PATH)\n\n# Get predictions\nbboxes, bbclasses, scores = yolox_inference(img, model, test_size)\n\n# Draw predictions\nout_image = draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, COCO_CLASSES)\n\n# Since we load image using OpenCV we have to convert it \nout_image = cv2.cvtColor(out_image, cv2.COLOR_BGR2RGB)\ndisplay(Image.fromarray(out_image))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:42:32.696172Z","iopub.execute_input":"2021-12-10T19:42:32.696493Z","iopub.status.idle":"2021-12-10T19:42:33.157249Z","shell.execute_reply.started":"2021-12-10T19:42:32.696458Z","shell.execute_reply":"2021-12-10T19:42:33.156416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Inference","metadata":{"papermill":{"duration":0.010203,"end_time":"2021-11-29T14:02:59.611726","exception":false,"start_time":"2021-11-29T14:02:59.601523","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:31:05.773506Z","iopub.execute_input":"2021-12-10T19:31:05.773846Z","iopub.status.idle":"2021-12-10T19:31:05.780436Z","shell.execute_reply.started":"2021-12-10T19:31:05.773809Z","shell.execute_reply":"2021-12-10T19:31:05.779492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()# initialize the environment\niter_test = env.iter_test()      # an iterator which loops over the test set and sample submission","metadata":{"papermill":{"duration":0.03697,"end_time":"2021-11-29T14:02:59.658924","exception":false,"start_time":"2021-11-29T14:02:59.621954","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-10T19:31:05.784088Z","iopub.execute_input":"2021-12-10T19:31:05.78454Z","iopub.status.idle":"2021-12-10T19:31:05.822347Z","shell.execute_reply.started":"2021-12-10T19:31:05.784507Z","shell.execute_reply":"2021-12-10T19:31:05.821594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n    bboxes, bbclasses, scores = yolox_inference(img[:,:,::-1], model, test_size)\n    annot = format_prediction(bboxes, scores,confthre)\n    pred_df['annotations'] = annot\n    env.predict(pred_df)\n    if idx<3:\n        out_image = draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, COCO_CLASSES)\n        display(Image.fromarray(out_image))    ","metadata":{"execution":{"iopub.status.busy":"2021-12-10T19:42:51.447349Z","iopub.execute_input":"2021-12-10T19:42:51.447896Z","iopub.status.idle":"2021-12-10T19:42:51.494836Z","shell.execute_reply.started":"2021-12-10T19:42:51.447849Z","shell.execute_reply":"2021-12-10T19:42:51.494248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('submission.csv')\nsub_df.head()","metadata":{"papermill":{"duration":0.082754,"end_time":"2021-11-29T14:03:11.459195","exception":false,"start_time":"2021-11-29T14:03:11.376441","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-10T19:42:54.283728Z","iopub.execute_input":"2021-12-10T19:42:54.284406Z","iopub.status.idle":"2021-12-10T19:42:54.295004Z","shell.execute_reply.started":"2021-12-10T19:42:54.284365Z","shell.execute_reply":"2021-12-10T19:42:54.294189Z"},"trusted":true},"execution_count":null,"outputs":[]}]}