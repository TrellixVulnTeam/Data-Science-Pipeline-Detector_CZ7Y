{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\nSome parts of this notebook is copied from [this notebook](https://www.kaggle.com/andradaolteanu/greatbarrierreef-yolo-full-guide-train-infer)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T15:57:45.045364Z","iopub.execute_input":"2022-02-05T15:57:45.04569Z","iopub.status.idle":"2022-02-05T15:57:45.357482Z","shell.execute_reply.started":"2022-02-05T15:57:45.04559Z","shell.execute_reply":"2022-02-05T15:57:45.356709Z"}}},{"cell_type":"markdown","source":"# **Data Preperation**","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport sys\nimport cv2 as cv\nimport os\nfrom tqdm import tqdm\nimport shutil \nimport yaml","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:35.024654Z","iopub.execute_input":"2022-02-05T17:02:35.025246Z","iopub.status.idle":"2022-02-05T17:02:35.35348Z","shell.execute_reply.started":"2022-02-05T17:02:35.025137Z","shell.execute_reply":"2022-02-05T17:02:35.352759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the train.csv file which is holding some important information related to the images.\ntrain= pd.read_csv(\"/kaggle/input/tensorflow-great-barrier-reef/train.csv\")\n\n# Drop all the rows which are not having any annotations\ntrain=train.loc[train[\"annotations\"].astype(str) != \"[]\"]\ntrain['annotations'] = train['annotations'].apply(eval)\n\n# Adding the column with full image path\ntrain['image_path'] = \"/kaggle/input/tensorflow-great-barrier-reef/train_images/video_\" + train['video_id'].astype(str) + \"/\" + train['video_frame'].astype(str) + \".jpg\"\n\n# Single annotation per row\ntrain=train.explode('annotations') \ntrain.reset_index(inplace=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:35.35536Z","iopub.execute_input":"2022-02-05T17:02:35.355623Z","iopub.status.idle":"2022-02-05T17:02:35.697597Z","shell.execute_reply.started":"2022-02-05T17:02:35.355587Z","shell.execute_reply":"2022-02-05T17:02:35.696887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert data from json to flat tables\ndf=pd.DataFrame(pd.json_normalize(train['annotations']), columns=['x', 'y', 'width', 'height']).join(train)\ndf['class']='Fish'\ndf=df[['image_path','x','y','width','height','class','video_id','video_frame']]\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:35.698768Z","iopub.execute_input":"2022-02-05T17:02:35.6991Z","iopub.status.idle":"2022-02-05T17:02:35.785819Z","shell.execute_reply.started":"2022-02-05T17:02:35.69906Z","shell.execute_reply":"2022-02-05T17:02:35.785039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating two new columns path_images and path_labels pointing towards the two new directories images and labels\ndf[\"path_images\"] = \"/kaggle/images/video_\" + df[\"video_id\"].astype(str) + \"_\" + \\\n                                                df[\"video_frame\"].astype(str) + \".jpg\"\ndf[\"path_labels\"] = \"/kaggle/labels/video_\" + df[\"video_id\"].astype(str) + \"_\" + \\\n                                                df[\"video_frame\"].astype(str) + \".txt\"","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:35.787876Z","iopub.execute_input":"2022-02-05T17:02:35.788141Z","iopub.status.idle":"2022-02-05T17:02:35.861723Z","shell.execute_reply.started":"2022-02-05T17:02:35.788105Z","shell.execute_reply":"2022-02-05T17:02:35.860682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:35.863225Z","iopub.execute_input":"2022-02-05T17:02:35.863473Z","iopub.status.idle":"2022-02-05T17:02:35.886128Z","shell.execute_reply.started":"2022-02-05T17:02:35.863439Z","shell.execute_reply":"2022-02-05T17:02:35.88525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an array of x, y, width, height columns\nlabels = df.loc[:, ['x', 'y', 'width', 'height']].values\n\n#Add the labels array into new column bbox in dataframe\ndf['bboxes'] = list(labels)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:35.887608Z","iopub.execute_input":"2022-02-05T17:02:35.890822Z","iopub.status.idle":"2022-02-05T17:02:35.930924Z","shell.execute_reply.started":"2022-02-05T17:02:35.890767Z","shell.execute_reply":"2022-02-05T17:02:35.92965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1 = df.groupby('image_path')['bboxes'].apply(list).reset_index(name='bboxes')\ndata2 = df.groupby('image_path')['path_images', 'path_labels'].agg(\n    width=('path_images', 'max'), height=('path_labels', 'max'))\ntrain_df = pd.merge(data1, data2, on='image_path')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:35.932335Z","iopub.execute_input":"2022-02-05T17:02:35.932729Z","iopub.status.idle":"2022-02-05T17:02:37.022895Z","shell.execute_reply.started":"2022-02-05T17:02:35.932691Z","shell.execute_reply":"2022-02-05T17:02:37.022066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:37.024334Z","iopub.execute_input":"2022-02-05T17:02:37.024886Z","iopub.status.idle":"2022-02-05T17:02:37.055554Z","shell.execute_reply.started":"2022-02-05T17:02:37.024847Z","shell.execute_reply":"2022-02-05T17:02:37.054854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['image_height']=720\ntrain_df['image_width']=1280","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:37.057096Z","iopub.execute_input":"2022-02-05T17:02:37.057581Z","iopub.status.idle":"2022-02-05T17:02:37.063811Z","shell.execute_reply.started":"2022-02-05T17:02:37.057544Z","shell.execute_reply":"2022-02-05T17:02:37.062775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:37.07175Z","iopub.execute_input":"2022-02-05T17:02:37.073427Z","iopub.status.idle":"2022-02-05T17:02:37.102916Z","shell.execute_reply.started":"2022-02-05T17:02:37.073386Z","shell.execute_reply":"2022-02-05T17:02:37.102237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir \"../images\"\n!mkdir \"../labels\"","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:37.106543Z","iopub.execute_input":"2022-02-05T17:02:37.108401Z","iopub.status.idle":"2022-02-05T17:02:38.77574Z","shell.execute_reply.started":"2022-02-05T17:02:37.108363Z","shell.execute_reply":"2022-02-05T17:02:38.774788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path in tqdm(train_df[\"image_path\"].tolist()):\n    split_path = path.split(\"/\")\n\n    # Retrieve the video id (0, 1, 2) and its frame number\n    video_id = split_path[-2]\n    video_frame = split_path[-1]\n\n    # Create new image path\n    path_image = f\"../images/{video_id}_{video_frame}\"\n    \n    # Copy file from source (competition data) to destination (our new folder)\n    shutil.copy(src=path, dst=path_image)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:02:38.777167Z","iopub.execute_input":"2022-02-05T17:02:38.777454Z","iopub.status.idle":"2022-02-05T17:03:32.447835Z","shell.execute_reply.started":"2022-02-05T17:02:38.777413Z","shell.execute_reply":"2022-02-05T17:03:32.447119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def coco2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    Converts a coco annotation format [xmin, ymin, w, h] to \n    the corresponding yolo format [xmid, ymid, w, h]\n    \n    image_height: height of the original image\n    image_width: width of the original image\n    bboxes: coco boxes to be converted\n    return :: \n    \n    inspo: https://www.kaggle.com/awsaf49/great-barrier-reef-yolov5-train\n    \"\"\"\n    \n    bboxes = np.array(bboxes).astype(float)\n    \n    # Normalize xmin, w\n    bboxes[:, [0, 2]]= bboxes[:, [0, 2]]/ image_width\n    # Normalize ymin, h\n    bboxes[:, [1, 3]]= bboxes[:, [1, 3]]/ image_height\n    \n    # Converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[:, [0, 1]] = bboxes[:, [0, 1]] + bboxes[:, [2, 3]]/2\n    \n    # Clip values (between 0 and 1)\n    bboxes = np.clip(bboxes, a_min=0, a_max=1)\n    \n    return bboxes","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:32.448991Z","iopub.execute_input":"2022-02-05T17:03:32.449451Z","iopub.status.idle":"2022-02-05T17:03:32.457026Z","shell.execute_reply.started":"2022-02-05T17:03:32.44941Z","shell.execute_reply":"2022-02-05T17:03:32.456354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo_bbox = []\nfor i in range(len(train_df)):\n    yolo_bbox.append(coco2yolo(train_df['image_height'][i], train_df['image_width'][i], train_df['bboxes'][i]))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:32.458233Z","iopub.execute_input":"2022-02-05T17:03:32.458598Z","iopub.status.idle":"2022-02-05T17:03:32.928563Z","shell.execute_reply.started":"2022-02-05T17:03:32.458565Z","shell.execute_reply":"2022-02-05T17:03:32.922573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['yolo_bbox'] = yolo_bbox","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:32.929674Z","iopub.execute_input":"2022-02-05T17:03:32.929966Z","iopub.status.idle":"2022-02-05T17:03:32.940921Z","shell.execute_reply.started":"2022-02-05T17:03:32.929927Z","shell.execute_reply":"2022-02-05T17:03:32.940123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:32.942278Z","iopub.execute_input":"2022-02-05T17:03:32.942861Z","iopub.status.idle":"2022-02-05T17:03:32.971847Z","shell.execute_reply.started":"2022-02-05T17:03:32.94282Z","shell.execute_reply":"2022-02-05T17:03:32.97056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['num_bbox']=train_df['bboxes'].apply(lambda x: len(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:32.975399Z","iopub.execute_input":"2022-02-05T17:03:32.976263Z","iopub.status.idle":"2022-02-05T17:03:32.996073Z","shell.execute_reply.started":"2022-02-05T17:03:32.976196Z","shell.execute_reply":"2022-02-05T17:03:32.995278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:33.00046Z","iopub.execute_input":"2022-02-05T17:03:33.002548Z","iopub.status.idle":"2022-02-05T17:03:33.033683Z","shell.execute_reply.started":"2022-02-05T17:03:33.002505Z","shell.execute_reply":"2022-02-05T17:03:33.032897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n    #image_name = row['file_name']\n    bounding_boxes = row['yolo_bbox']\n    #labels = row['labels']\n    num_bbox=row['num_bbox']\n    yolo_data=[]\n    for bbox in bounding_boxes:\n        x_center = bbox[0]\n        y_center = bbox[1]\n        width = bbox[2]\n        height = bbox[3]\n        yolo_data.append([x_center,y_center,width,height])\n    yolo_data_array=np.array(yolo_data)\n    with open(row['height'],'w') as file:\n        for i in range(num_bbox):\n            annot = [\"0\"] + yolo_data_array[i].astype(str).tolist()\n            annot = \" \".join(annot).strip()\n            file.write(annot)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:33.036955Z","iopub.execute_input":"2022-02-05T17:03:33.038461Z","iopub.status.idle":"2022-02-05T17:03:34.924052Z","shell.execute_reply.started":"2022-02-05T17:03:33.03842Z","shell.execute_reply":"2022-02-05T17:03:34.923211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1 = open('../labels/video_1_4238.txt', 'r')\nf2 = open('../labels/video_1_5315.txt', 'r')\nf3 = open('../labels/video_0_1006.txt', 'r')\nprint(f1.read())\nprint(f2.read())\nprint(f3.read())","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:34.925454Z","iopub.execute_input":"2022-02-05T17:03:34.926092Z","iopub.status.idle":"2022-02-05T17:03:34.941201Z","shell.execute_reply.started":"2022-02-05T17:03:34.926023Z","shell.execute_reply":"2022-02-05T17:03:34.940089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train,df_valid=train_test_split(train_df,test_size=0.2,random_state=42,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:34.942704Z","iopub.execute_input":"2022-02-05T17:03:34.943135Z","iopub.status.idle":"2022-02-05T17:03:37.329818Z","shell.execute_reply.started":"2022-02-05T17:03:34.9431Z","shell.execute_reply":"2022-02-05T17:03:37.329051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_images=list(df_train['width'])\ndf_train_labels=list(df_train['height'])\n\ndf_test_images=list(df_valid['width'])\ndf_test_labels=list(df_valid['height'])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:37.331037Z","iopub.execute_input":"2022-02-05T17:03:37.331316Z","iopub.status.idle":"2022-02-05T17:03:37.339412Z","shell.execute_reply.started":"2022-02-05T17:03:37.331281Z","shell.execute_reply":"2022-02-05T17:03:37.338392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"./working BEFORE:\",os.listdir(\"../working\"))\n\n# Create train and test path data\nwith open(\"../working/train_images.txt\", \"w\") as file:\n    for path in df_train_images:\n        file.write(path + \"\\n\")\n        \nwith open(\"../working/test_images.txt\", \"w\") as file:\n    for path in df_test_images:\n        file.write(path + \"\\n\")\n\n\n# Create configuration\nconfig = {'path': '/kaggle/working',\n          'train': '/kaggle/working/train_images.txt',\n          'val': '/kaggle/working/test_images.txt',\n          'nc': 1,\n          'names': ['cots']}\n\nwith open(\"../working/cots.yaml\", \"w\") as file:\n    yaml.dump(config, file, default_flow_style=False)\n\n        \nprint(\"../working AFTER:\", os.listdir(\"../working\"))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:37.340907Z","iopub.execute_input":"2022-02-05T17:03:37.341367Z","iopub.status.idle":"2022-02-05T17:03:37.356681Z","shell.execute_reply.started":"2022-02-05T17:03:37.341326Z","shell.execute_reply":"2022-02-05T17:03:37.355701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n!git clone https://github.com/ultralytics/yolov5.git   \n%cd yolov5     \n%pip install -qr requirements.txt   \n\nfrom yolov5 import utils\ndisplay = utils.notebook_init()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:37.358117Z","iopub.execute_input":"2022-02-05T17:03:37.358832Z","iopub.status.idle":"2022-02-05T17:03:51.945942Z","shell.execute_reply.started":"2022-02-05T17:03:37.358791Z","shell.execute_reply":"2022-02-05T17:03:51.945089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 500\nBATCH_SIZE = 4\nEPOCHS = 1\nMODEL = \"yolov5s\"\nWORKERS = 0\nPROJECT = \"GreatBarrierReef\"\nRUN_NAME = f\"{MODEL}_size{SIZE}_epochs{EPOCHS}_batch{BATCH_SIZE}_simple\"","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:51.94806Z","iopub.execute_input":"2022-02-05T17:03:51.948541Z","iopub.status.idle":"2022-02-05T17:03:51.954168Z","shell.execute_reply.started":"2022-02-05T17:03:51.948495Z","shell.execute_reply":"2022-02-05T17:03:51.953218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\n!python train.py --img {SIZE}\\\n                --batch {BATCH_SIZE}\\\n                --epochs {EPOCHS}\\\n                --data /kaggle/working/cots.yaml\\\n                --weights {MODEL}.pt\\\n                --workers {WORKERS}\\\n                --project {PROJECT}\\\n                --name {RUN_NAME}\\\n                --exist-ok","metadata":{"execution":{"iopub.status.busy":"2022-02-05T17:03:51.955669Z","iopub.execute_input":"2022-02-05T17:03:51.956012Z","iopub.status.idle":"2022-02-05T17:14:03.247564Z","shell.execute_reply.started":"2022-02-05T17:03:51.955972Z","shell.execute_reply":"2022-02-05T17:14:03.246559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Work in Progress**","metadata":{}}]}