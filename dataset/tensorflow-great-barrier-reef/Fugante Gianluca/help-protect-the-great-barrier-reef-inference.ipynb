{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# norfair dependencies\n%cd /kaggle/input/norfair031py3/\n!pip install commonmark-0.9.1-py2.py3-none-any.whl -f ./ --no-index\n!pip install rich-9.13.0-py3-none-any.whl\n\n!mkdir /kaggle/working/tmp\n!cp -r /kaggle/input/norfair031py3/filterpy-1.4.5/filterpy-1.4.5/ /kaggle/working/tmp/\n%cd /kaggle/working/tmp/filterpy-1.4.5/\n!pip install .\n!rm -rf /kaggle/working/tmp\n\n# norfair\n%cd /kaggle/input/norfair031py3/\n!pip install norfair-0.3.1-py3-none-any.whl -f ./ --no-index\n%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:28:53.007846Z","iopub.execute_input":"2022-02-01T15:28:53.008182Z","iopub.status.idle":"2022-02-01T15:30:17.384238Z","shell.execute_reply.started":"2022-02-01T15:28:53.008099Z","shell.execute_reply":"2022-02-01T15:30:17.383005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /root/.config/Ultralytics\n!cp /kaggle/input/yolov5-font/Arial.ttf /root/.config/Ultralytics/","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:17.388474Z","iopub.execute_input":"2022-02-01T15:30:17.388771Z","iopub.status.idle":"2022-02-01T15:30:18.905917Z","shell.execute_reply.started":"2022-02-01T15:30:17.388709Z","shell.execute_reply":"2022-02-01T15:30:18.904706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\n\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n#from bbox.utils import voc2coco, draw_bboxes\n\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T15:30:18.909973Z","iopub.execute_input":"2022-02-01T15:30:18.910236Z","iopub.status.idle":"2022-02-01T15:30:20.691218Z","shell.execute_reply.started":"2022-02-01T15:30:18.910205Z","shell.execute_reply":"2022-02-01T15:30:20.69001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def voc2coco(bboxes, height=720, width=1280):\n    \"\"\"\n    voc  => [xmin, ymin, xmax, ymax]\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n#     bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # converstion (xmax, ymax) => (w, h) \n    bboxes[..., 2:4] -= bboxes[..., 0:2]\n    \n    return bboxes","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:20.693017Z","iopub.execute_input":"2022-02-01T15:30:20.693303Z","iopub.status.idle":"2022-02-01T15:30:20.699106Z","shell.execute_reply.started":"2022-02-01T15:30:20.693262Z","shell.execute_reply":"2022-02-01T15:30:20.698083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tracking helpers\n\nimport numpy as np\nfrom norfair import Detection, Tracker\n\n# Helper to convert bbox in format [x_min, y_min, x_max, y_max, score] to norfair.Detection class\ndef to_norfair(detects, frame_id):\n    result = []\n    for x_min, y_min, x_max, y_max, score in detects:\n        xc, yc = (x_min + x_max) / 2, (y_min + y_max) / 2\n        w, h = x_max - x_min, y_max - y_min\n        result.append(Detection(points=np.array([xc, yc]), scores=np.array([score]), data=np.array([w, h, frame_id])))\n        \n    return result\n\n# Euclidean distance function to match detections on this frame with tracked_objects from previous frames\ndef euclidean_distance(detection, tracked_object):\n    return np.linalg.norm(detection.points - tracked_object.estimate)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:20.702829Z","iopub.execute_input":"2022-02-01T15:30:20.703408Z","iopub.status.idle":"2022-02-01T15:30:21.68682Z","shell.execute_reply.started":"2022-02-01T15:30:20.703365Z","shell.execute_reply":"2022-02-01T15:30:21.685878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE  = 11000\nCONF      = 0.28\nIOU       = 0.40\nAUGMENT   = True\n\n#np.random.seed(32)\ncolors = [(255, 0, 0)]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:21.688235Z","iopub.execute_input":"2022-02-01T15:30:21.689271Z","iopub.status.idle":"2022-02-01T15:30:21.696927Z","shell.execute_reply.started":"2022-02-01T15:30:21.689236Z","shell.execute_reply":"2022-02-01T15:30:21.695813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, img, size=768, augment=False):\n    height, width = img.shape[:2]\n    results = model(img, size=size, augment=augment)  # custom inference size\n    preds   = results.pandas().xyxy[0]\n    bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n    if len(bboxes):\n        bboxes  = voc2coco(bboxes,height,width).astype(int)\n        confs   = preds.confidence.values\n        return bboxes, confs\n    else:\n        return [],[]\n    \ndef format_prediction(bboxes, confs):\n    annot = ''\n    if len(bboxes)>0:\n        for idx in range(len(bboxes)):\n            xmin, ymin, w, h = bboxes[idx]\n            conf             = confs[idx]\n            annot += f'{conf} {xmin} {ymin} {w} {h}'\n            annot +=' '\n        annot = annot.strip(' ')\n    return annot\n\ndef load_model(ckpt_path, conf=0.25, iou=0.50):\n    model = torch.hub.load('/kaggle/input/yolov5-lib-ds',\n                           'custom',\n                           path=ckpt_path,\n                           source='local',\n                           force_reload=True)  # local repo\n    model.conf = conf  # NMS confidence threshold\n    model.iou  = iou  # NMS IoU threshold\n    model.classes = None   # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n    model.multi_label = False  # NMS multiple labels per box\n    model.max_det = 20  # maximum number of detections per image\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:21.698457Z","iopub.execute_input":"2022-02-01T15:30:21.699438Z","iopub.status.idle":"2022-02-01T15:30:21.713956Z","shell.execute_reply.started":"2022-02-01T15:30:21.699393Z","shell.execute_reply":"2022-02-01T15:30:21.712679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tracking_function(tracker, frame_id, bboxes, scores):\n    \n    detects = []\n    predictions = []\n    \n    if len(scores)>0:\n        for i in range(len(bboxes)):\n            box = bboxes[i]\n            score = scores[i]\n            x_min = int(box[0])\n            y_min = int(box[1])\n            bbox_width = int(box[2])\n            bbox_height = int(box[3])\n            detects.append([x_min, y_min, x_min+bbox_width, y_min+bbox_height, score])\n            predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n#             print(predictions[:-1])\n    # Update tracks using detects from current frame\n    tracked_objects = tracker.update(detections=to_norfair(detects, frame_id))\n    for tobj in tracked_objects:\n        bbox_width, bbox_height, last_detected_frame_id = tobj.last_detection.data\n        if last_detected_frame_id == frame_id:  # Skip objects that were detected on current frame\n            continue\n        # Add objects that have no detections on current frame to predictions\n        xc, yc = tobj.estimate[0]\n        x_min, y_min = int(round(xc - bbox_width / 2)), int(round(yc - bbox_height / 2))\n        score = tobj.last_detection.scores[0]\n\n        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n        \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:21.71564Z","iopub.execute_input":"2022-02-01T15:30:21.716139Z","iopub.status.idle":"2022-02-01T15:30:21.731702Z","shell.execute_reply.started":"2022-02-01T15:30:21.716079Z","shell.execute_reply":"2022-02-01T15:30:21.730566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()# initialize the environment\niter_test = env.iter_test()      # an iterator which loops over the test set and sample submission","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:21.735793Z","iopub.execute_input":"2022-02-01T15:30:21.736693Z","iopub.status.idle":"2022-02-01T15:30:21.767731Z","shell.execute_reply.started":"2022-02-01T15:30:21.736648Z","shell.execute_reply":"2022-02-01T15:30:21.766739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tracker = Tracker(\n    distance_function=euclidean_distance, \n    distance_threshold=30,\n    hit_inertia_min=3,\n    hit_inertia_max=6,\n    initialization_delay=1,\n)\nframe_id = 0","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:21.769143Z","iopub.execute_input":"2022-02-01T15:30:21.769481Z","iopub.status.idle":"2022-02-01T15:30:21.775449Z","shell.execute_reply.started":"2022-02-01T15:30:21.769423Z","shell.execute_reply":"2022-02-01T15:30:21.774331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('/kaggle/input/reef-baseline-fold12/l6_3600_uflip_vm5_f12_up/f1/best.pt', conf=CONF, iou=IOU)\nfor idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n    \n    bboxes, confs  = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n    #annot          = format_prediction(bboxes, confs)\n    \n    predictions = tracking_function(tracker, frame_id, bboxes, confs)\n    prediction_str = ' '.join(predictions)    \n    \n    pred_df['annotations'] = prediction_str\n    env.predict(pred_df)\n    frame_id += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:21.777578Z","iopub.execute_input":"2022-02-01T15:30:21.778507Z","iopub.status.idle":"2022-02-01T15:30:37.09236Z","shell.execute_reply.started":"2022-02-01T15:30:21.778349Z","shell.execute_reply":"2022-02-01T15:30:37.091193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = load_model('/kaggle/input/best-states/yolov5m_best_v2.pt', conf=CONF, iou=IOU)\n#for idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n#    bboxes, confs  = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n#    annot          = format_prediction(bboxes, confs)\n#    pred_df['annotations'] = annot\n#    env.predict(pred_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:37.094634Z","iopub.execute_input":"2022-02-01T15:30:37.095005Z","iopub.status.idle":"2022-02-01T15:30:37.100283Z","shell.execute_reply.started":"2022-02-01T15:30:37.094949Z","shell.execute_reply":"2022-02-01T15:30:37.099053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('submission.csv')\nsub_df","metadata":{"execution":{"iopub.status.busy":"2022-02-01T15:30:37.102366Z","iopub.execute_input":"2022-02-01T15:30:37.103532Z","iopub.status.idle":"2022-02-01T15:30:37.127079Z","shell.execute_reply.started":"2022-02-01T15:30:37.103474Z","shell.execute_reply":"2022-02-01T15:30:37.125942Z"},"trusted":true},"execution_count":null,"outputs":[]}]}