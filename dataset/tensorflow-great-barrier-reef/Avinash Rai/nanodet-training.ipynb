{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom tqdm import tqdm\nimport os, ast, json\nfrom sklearn.model_selection import train_test_split\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"1300fd60-9205-46fe-ad06-5b272a1e3ea8","_cell_guid":"9c184110-0570-475c-875b-331fb1ac903f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:15:46.761753Z","iopub.execute_input":"2022-01-02T05:15:46.762129Z","iopub.status.idle":"2022-01-02T05:15:47.606688Z","shell.execute_reply.started":"2022-01-02T05:15:46.762042Z","shell.execute_reply":"2022-01-02T05:15:47.605845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tensorflow-great-barrier-reef/train.csv\")\ntrain_df, test_df = train_test_split(df, test_size=0.1)\n\ntrain_df[\"annotations\"] = train_df[\"annotations\"].map(lambda x: ast.literal_eval(x))\ntest_df[\"annotations\"] = test_df[\"annotations\"].map(lambda x: ast.literal_eval(x))\ntrain_df.head()","metadata":{"_uuid":"9f22d0ca-27ce-4113-a174-89bec354c5e3","_cell_guid":"ac7cef0f-3cfa-4017-abca-d04801096e0d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:15:47.60997Z","iopub.execute_input":"2022-01-02T05:15:47.610367Z","iopub.status.idle":"2022-01-02T05:15:48.055256Z","shell.execute_reply.started":"2022-01-02T05:15:47.610334Z","shell.execute_reply":"2022-01-02T05:15:48.054466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape, test_df.shape","metadata":{"_uuid":"9f16b896-1054-4519-a6dd-0443cbe6a3c4","_cell_guid":"aeeef005-cda1-4642-bfac-efd8d9781e63","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:15:48.05653Z","iopub.execute_input":"2022-01-02T05:15:48.056943Z","iopub.status.idle":"2022-01-02T05:15:48.065263Z","shell.execute_reply.started":"2022-01-02T05:15:48.056905Z","shell.execute_reply":"2022-01-02T05:15:48.064463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_coco(df):\n    coco_data = {\n        \"info\":\"kaaggle competition https://www.kaggle.com/c/tensorflow-great-barrier-reef\",\n        \"licenses\" : [{\"id\" : 1, \"name\":\"kaggle\", \"url\":\"https://www.kaggle.com/c/tensorflow-great-barrier-reef\"}],\n        \"categories\" : [{\"id\" : 1, \"name\":\"starfish\"}],\n        \"images\" : [],\n        \"annotations\" : []\n    }\n    a_id = 0\n    for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n        image_path = \"/kaggle/input/tensorflow-great-barrier-reef/train_images/video_{}/{}.jpg\".format(row[\"video_id\"], row[\"video_frame\"])\n        coco_data[\"images\"].append({\n            \"id\" : idx,\n            \"width\" : 1280,\n            \"height\" : 720,\n            \"file_name\" : image_path,\n            \"license\" : 1\n        })\n        annotations = row[\"annotations\"]\n        for i, annotation in enumerate(annotations):\n            coco_data[\"annotations\"].append({\n                \"id\" : a_id,#\"{}_{}_{}\".format(row[\"video_id\"], row[\"video_frame\"], i),\n                \"image_id\" : idx,\n                \"area\" : annotation[\"width\"] * annotation[\"height\"],\n                \"category_id\" : 1,\n                \"iscrowd\" : 1,\n                \"bbox\" : [annotation[\"x\"], annotation[\"y\"], annotation[\"width\"], annotation[\"height\"]]\n            })\n            a_id += 1\n    return coco_data","metadata":{"_uuid":"ee655c74-80e2-4434-a4cb-e17d686c3cd5","_cell_guid":"11afd665-9ad9-4c28-ba44-fcd4f20e5cd9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:15:48.067398Z","iopub.execute_input":"2022-01-02T05:15:48.068302Z","iopub.status.idle":"2022-01-02T05:15:48.078253Z","shell.execute_reply.started":"2022-01-02T05:15:48.068157Z","shell.execute_reply":"2022-01-02T05:15:48.077421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_coco = to_coco(train_df)\ntest_coco = to_coco(test_df)\n#     break\n# print(coco_data)\n# train_df.shape, test_df.shape","metadata":{"_uuid":"ffc867f9-6c0c-41e0-aaf5-49c4cd7ba510","_cell_guid":"67ea7af3-d853-4da0-9109-212d3a34d72d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:15:48.079359Z","iopub.execute_input":"2022-01-02T05:15:48.079797Z","iopub.status.idle":"2022-01-02T05:15:49.586334Z","shell.execute_reply.started":"2022-01-02T05:15:48.079759Z","shell.execute_reply":"2022-01-02T05:15:49.585662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"json.dump(train_coco, open(\"annotations_train.json\", \"w\"))\njson.dump(test_coco, open(\"annotations_val.json\", \"w\"))","metadata":{"_uuid":"2431065e-b8be-4eab-bd5a-355ba109d413","_cell_guid":"f2faca74-5ea1-407f-b157-240060beb5ad","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:15:49.587631Z","iopub.execute_input":"2022-01-02T05:15:49.588031Z","iopub.status.idle":"2022-01-02T05:15:50.178052Z","shell.execute_reply.started":"2022-01-02T05:15:49.587993Z","shell.execute_reply":"2022-01-02T05:15:50.177266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data = json.load(open(\"annotations_coco.json\", \"r\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T05:15:50.179369Z","iopub.execute_input":"2022-01-02T05:15:50.179647Z","iopub.status.idle":"2022-01-02T05:15:50.184096Z","shell.execute_reply.started":"2022-01-02T05:15:50.179591Z","shell.execute_reply":"2022-01-02T05:15:50.183388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imgs ={}\n# for img in data['images']:\n#     imgs[img['id']] = img\n# print(len(imgs.keys()))","metadata":{"execution":{"iopub.status.busy":"2022-01-02T05:15:50.18538Z","iopub.execute_input":"2022-01-02T05:15:50.186016Z","iopub.status.idle":"2022-01-02T05:15:50.193742Z","shell.execute_reply.started":"2022-01-02T05:15:50.185976Z","shell.execute_reply":"2022-01-02T05:15:50.192939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install Cython termcolor numpy tensorboard pycocotools matplotlib pyaml opencv-python tqdm pytorch-lightning torchmetrics","metadata":{"_uuid":"d67fabfb-855d-4cb0-a808-33a7c17da99a","_cell_guid":"3faeba03-e3fc-4f64-9b10-24b05504f444","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:15:50.195527Z","iopub.execute_input":"2022-01-02T05:15:50.195893Z","iopub.status.idle":"2022-01-02T05:16:07.140624Z","shell.execute_reply.started":"2022-01-02T05:15:50.195844Z","shell.execute_reply":"2022-01-02T05:16:07.139804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\ngit clone https://github.com/RangiLyu/nanodet.git\ncd nanodet\npython setup.py develop","metadata":{"_uuid":"825270f3-bd80-4a24-954b-7627e3a93995","_cell_guid":"51fb5015-443a-4926-a5dd-7f98b8fea049","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:16:07.14357Z","iopub.execute_input":"2022-01-02T05:16:07.143859Z","iopub.status.idle":"2022-01-02T05:16:10.003297Z","shell.execute_reply.started":"2022-01-02T05:16:07.14382Z","shell.execute_reply":"2022-01-02T05:16:10.002505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = '# nanodet-plus-m-1.5x_416 \\n \\\n# COCO mAP(0.5:0.95) = 0.341 \\n \\\n#             AP_50  = 0.506 \\n \\\n#             AP_75  = 0.357 \\n \\\n#           AP_small = 0.143 \\n \\\n#               AP_m = 0.363 \\n \\\n#               AP_l = 0.539 \\n \\\nsave_dir: nanodet-plus-m-1.5x_416 \\n \\\nmodel: \\n \\\n  weight_averager: \\n \\\n    name: ExpMovingAverager \\n \\\n    decay: 0.9998 \\n \\\n  arch: \\n \\\n    name: NanoDetPlus \\n \\\n    detach_epoch: 10 \\n \\\n    backbone: \\n \\\n      name: ShuffleNetV2 \\n \\\n      model_size: 1.5x \\n \\\n      out_stages: [2,3,4] \\n \\\n      activation: LeakyReLU \\n \\\n    fpn: \\n \\\n      name: GhostPAN \\n \\\n      in_channels: [176, 352, 704] \\n \\\n      out_channels: 128 \\n \\\n      kernel_size: 5 \\n \\\n      num_extra_level: 1 \\n \\\n      use_depthwise: True \\n \\\n      activation: LeakyReLU \\n \\\n    head: \\n \\\n      name: NanoDetPlusHead \\n \\\n      num_classes: 1 \\n \\\n      input_channel: 128 \\n \\\n      feat_channels: 128 \\n \\\n      stacked_convs: 2 \\n \\\n      kernel_size: 5 \\n \\\n      strides: [8, 16, 32, 64] \\n \\\n      activation: LeakyReLU \\n \\\n      reg_max: 7 \\n \\\n      norm_cfg: \\n \\\n        type: BN \\n \\\n      loss: \\n \\\n        loss_qfl: \\n \\\n          name: QualityFocalLoss \\n \\\n          use_sigmoid: True \\n \\\n          beta: 2.0 \\n \\\n          loss_weight: 1.0 \\n \\\n        loss_dfl: \\n \\\n          name: DistributionFocalLoss \\n \\\n          loss_weight: 0.25 \\n \\\n        loss_bbox: \\n \\\n          name: GIoULoss \\n \\\n          loss_weight: 2.0 \\n \\\n    # Auxiliary head, only use in training time. \\n \\\n    aux_head: \\n \\\n      name: SimpleConvHead \\n \\\n      num_classes: 1 \\n \\\n      input_channel: 256 \\n \\\n      feat_channels: 256 \\n \\\n      stacked_convs: 4 \\n \\\n      strides: [8, 16, 32, 64] \\n \\\n      activation: LeakyReLU \\n \\\n      reg_max: 7 \\n \\\ndata: \\n \\\n  train: \\n \\\n    name: CocoDataset \\n \\\n    img_path: \"\" \\n \\\n    ann_path: /kaggle/working/annotations_train.json \\n \\\n    input_size: [416,416] #[w,h] \\n \\\n    keep_ratio: False \\n \\\n    pipeline: \\n \\\n      perspective: 0.0 \\n \\\n      scale: [0.6, 1.4] \\n \\\n      stretch: [[0.8, 1.2], [0.8, 1.2]] \\n \\\n      rotation: 0 \\n \\\n      shear: 0 \\n \\\n      translate: 0.2 \\n \\\n      flip: 0.5 \\n \\\n      brightness: 0.2 \\n \\\n      contrast: [0.6, 1.4] \\n \\\n      saturation: [0.5, 1.2] \\n \\\n      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]] \\n \\\n  val: \\n \\\n    name: CocoDataset \\n \\\n    img_path: \"\" \\n \\\n    ann_path: /kaggle/working/annotations_val.json \\n \\\n    input_size: [416,416] #[w,h] \\n \\\n    keep_ratio: False \\n \\\n    pipeline: \\n \\\n      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]] \\n \\\ndevice: \\n \\\n  gpu_ids: [0] \\n \\\n  workers_per_gpu: 2 \\n \\\n  batchsize_per_gpu: 4 \\n \\\nschedule: \\n \\\n#  resume: \\n \\\n#  load_model: \\n \\\n  optimizer: \\n \\\n    name: AdamW \\n \\\n    lr: 0.001 \\n \\\n    weight_decay: 0.05 \\n \\\n  warmup: \\n \\\n    name: linear \\n \\\n    steps: 500 \\n \\\n    ratio: 0.0001 \\n \\\n  total_epochs: 300 \\n \\\n  lr_schedule: \\n \\\n    name: CosineAnnealingLR \\n \\\n    T_max: 300 \\n \\\n    eta_min: 0.00005 \\n \\\n  val_intervals: 10 \\n \\\ngrad_clip: 35 \\n \\\nevaluator: \\n \\\n  name: CocoDetectionEvaluator \\n \\\n  save_key: mAP \\n \\\nlog: \\n \\\n  interval: 50 \\n \\\n \\n \\\nclass_names: [\"starfish\"] \\n '\n\nwith open(\"custom_config.yml\", \"w\") as f:\n    f.write(config)","metadata":{"_uuid":"b66d74cd-2741-41a2-9f18-ae2e5f1510cf","_cell_guid":"7694d521-906c-45a0-85cc-8ddba78ca9e5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:16:10.005222Z","iopub.execute_input":"2022-01-02T05:16:10.005507Z","iopub.status.idle":"2022-01-02T05:16:10.012834Z","shell.execute_reply.started":"2022-01-02T05:16:10.005468Z","shell.execute_reply":"2022-01-02T05:16:10.01212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%bash\n# # !cat custom_config.yml\n# cd nanodet\n!python nanodet/tools/train.py custom_config.yml","metadata":{"_uuid":"9e3233c4-76fb-4cd3-a53f-e04d4305429a","_cell_guid":"9ddaaf25-4e18-42b6-9023-f7051c65b9d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-02T05:16:10.014079Z","iopub.execute_input":"2022-01-02T05:16:10.014523Z","iopub.status.idle":"2022-01-02T05:19:59.13504Z","shell.execute_reply.started":"2022-01-02T05:16:10.014486Z","shell.execute_reply":"2022-01-02T05:19:59.134208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"8edc7b79-e663-47fe-bfe4-9cf3df05eefa","_cell_guid":"12ea0dd7-ae79-4f72-98d3-b8143e22edb3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}