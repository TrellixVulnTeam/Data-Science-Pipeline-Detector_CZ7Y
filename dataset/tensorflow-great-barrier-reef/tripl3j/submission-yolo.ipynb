{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport cv2\nimport sys\nfrom PIL import Image,ImageDraw\nfrom torchvision import transforms\nfrom matplotlib import pyplot as plt\nimport os\nfrom tqdm.notebook import tqdm\nsys.path.insert(1, '../input/lanetmodelzip/LANet')\n\nDEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:25.043925Z","iopub.execute_input":"2022-01-23T16:23:25.044698Z","iopub.status.idle":"2022-01-23T16:23:27.500398Z","shell.execute_reply.started":"2022-01-23T16:23:25.044591Z","shell.execute_reply":"2022-01-23T16:23:27.499234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /root/.config/Ultralytics\n!cp ../input/yolov5-font/Arial.ttf /root/.config/Ultralytics/\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:27.50641Z","iopub.execute_input":"2022-01-23T16:23:27.506964Z","iopub.status.idle":"2022-01-23T16:23:29.304675Z","shell.execute_reply.started":"2022-01-23T16:23:27.506919Z","shell.execute_reply":"2022-01-23T16:23:29.303394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LANet Utils","metadata":{}},{"cell_type":"code","source":"transform_list = [transforms.Resize((180, 1280)), transforms.ToTensor()]\ntsfm = transforms.Compose(transform_list)\n\ndef predict_LANet(LANet,img_original):    \n    #proccess images\n    y_blocks = 4\n    H = 720\n    W = 1280\n    \n    crp_img = []\n    for y in range(y_blocks):\n        left = 0\n        top = int(y * (H/y_blocks))\n        right = W\n        bottom = int((y+1) * (H/y_blocks))\n        \n        # Cropped image of above dimension\n        # (It will not change original image)\n        img_crop = img_original.crop((left, top, right, bottom))\n\n        image = tsfm(img_crop)\n        tensor_image = image.unsqueeze(0).to(DEVICE)\n        \n        result = LANet(tensor_image)[0].cpu().detach().numpy()[0].swapaxes(0,2)\n\n        result = cv2.flip(result, 1)\n        result = cv2.rotate(result, cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n        crp_img.append(result)\n\n    #concat the images on the y axis to restore the orginal size\n    final = cv2.vconcat([crp_img[i] for i in range(y_blocks)])\n    \n    #fig = plt.subplot()\n    #plt.imshow(final)\n    #plt.show()\n    \n    final_normalized = ((final - final.min())/(final.max()-final.min()) * 255).astype('uint8')\n    \n    #fig = plt.subplot()\n    #plt.imshow(final_normalized)\n    #plt.show()\n    \n    #print(final_normalized.min(),final_normalized.max())\n    \n    #final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB)\n    \n    return final_normalized","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:29.306788Z","iopub.execute_input":"2022-01-23T16:23:29.307119Z","iopub.status.idle":"2022-01-23T16:23:29.324246Z","shell.execute_reply.started":"2022-01-23T16:23:29.307072Z","shell.execute_reply":"2022-01-23T16:23:29.322851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Yolo Utils","metadata":{}},{"cell_type":"code","source":"def predict_yolo(model, img, size=1280, augment=False):\n    height, width = img.shape[:2]\n    results = model(img)#, size=size, augment=augment)  # custom inference size\n    preds   = results.pandas().xyxy[0]\n    if len(preds):\n        predictions=preds.apply(lambda p:(p['confidence'],[p[\"xmin\"],p[\"ymin\"],p[\"xmax\"]-p[\"xmin\"],p[\"ymax\"]-p[\"ymin\"]]),axis=1)\n        return predictions.tolist()\n    else:\n        return []\n\ndef load_yolo(ckpt_path, conf=0.15, iou=0.50):\n    model = torch.hub.load('../input/yolov5',\n                           'custom',\n                           path=ckpt_path,\n                           source='local',\n                           force_reload=True)  # local repo\n    model.conf = conf  # NMS confidence threshold\n    model.iou  = iou  # NMS IoU threshold\n    model.classes = None   # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n    model.multi_label = False  # NMS multiple labels per box\n    model.max_det = 1000  # maximum number of detections per image\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:29.328855Z","iopub.execute_input":"2022-01-23T16:23:29.32933Z","iopub.status.idle":"2022-01-23T16:23:29.340795Z","shell.execute_reply.started":"2022-01-23T16:23:29.329222Z","shell.execute_reply":"2022-01-23T16:23:29.339152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(img,LANet,YOLO):\n    img = predict_LANet(LANet,img)\n    \n    predictions = predict_yolo(YOLO, img, size=1280, augment=False)\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:29.343032Z","iopub.execute_input":"2022-01-23T16:23:29.343614Z","iopub.status.idle":"2022-01-23T16:23:29.355144Z","shell.execute_reply.started":"2022-01-23T16:23:29.343378Z","shell.execute_reply":"2022-01-23T16:23:29.353837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test with train images","metadata":{}},{"cell_type":"code","source":"LANet = torch.load(\"../input/lanetmodelzip/LANet/checkpoints/model_epoch_40.pk\")[\"model\"].to(DEVICE)\n_=LANet.eval()\n\nYOLO = load_yolo(\"../input/yolov5s6/best.pt\").to(DEVICE)\n_=YOLO.eval()","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:29.35836Z","iopub.execute_input":"2022-01-23T16:23:29.358743Z","iopub.status.idle":"2022-01-23T16:23:37.101642Z","shell.execute_reply.started":"2022-01-23T16:23:29.3587Z","shell.execute_reply":"2022-01-23T16:23:37.100588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\")\ndf = df[(df[\"annotations\"].astype(str)!='[]') & (df[\"video_id\"]==2)]\n\nfolder_path = \"../input/tensorflow-great-barrier-reef/train_images/video_2/\"\n\nfor frame_id in tqdm(df[\"video_frame\"]):\n    print(predict(Image.open(f'{folder_path}{frame_id}.jpg'),LANet,YOLO))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:37.104108Z","iopub.execute_input":"2022-01-23T16:23:37.104504Z","iopub.status.idle":"2022-01-23T16:23:44.419521Z","shell.execute_reply.started":"2022-01-23T16:23:37.104452Z","shell.execute_reply":"2022-01-23T16:23:44.418448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Infer","metadata":{}},{"cell_type":"code","source":"def format_prediction(predictions):\n    annot = ''\n    \n    for conf,bbox in predictions:\n        annot += f'{conf} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]} '\n        \n    return annot.strip()\n\ndef show_img(img, predictions):\n    draw = ImageDraw.Draw(img)\n    \n    for p in predictions:\n        anot,bboxes = p\n        draw.rectangle([(bb[0],bb[1]),(bb[0]+bb[2],bb[1]+bb[3]),],outline = \"red\")\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:44.421619Z","iopub.execute_input":"2022-01-23T16:23:44.4223Z","iopub.status.idle":"2022-01-23T16:23:44.432548Z","shell.execute_reply.started":"2022-01-23T16:23:44.42225Z","shell.execute_reply":"2022-01-23T16:23:44.431506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()# initialize the environment\niter_test = env.iter_test()      # an iterator which loops over the test set and sample submission","metadata":{"execution":{"iopub.status.busy":"2022-01-23T16:23:44.435177Z","iopub.execute_input":"2022-01-23T16:23:44.435871Z","iopub.status.idle":"2022-01-23T16:23:44.471827Z","shell.execute_reply.started":"2022-01-23T16:23:44.435823Z","shell.execute_reply":"2022-01-23T16:23:44.470794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n    img = Image.fromarray(img)\n    predictions = predict(img,LANet,YOLO)\n    annot          = format_prediction(predictions)\n    print(annot)\n    pred_df['annotations'] = annot\n    env.predict(pred_df)\n    #if idx<3:\n        #display(show_img(img, predictions))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-23T16:23:44.475447Z","iopub.execute_input":"2022-01-23T16:23:44.475808Z","iopub.status.idle":"2022-01-23T16:23:51.887347Z","shell.execute_reply.started":"2022-01-23T16:23:44.475763Z","shell.execute_reply":"2022-01-23T16:23:51.886521Z"},"trusted":true},"execution_count":null,"outputs":[]}]}