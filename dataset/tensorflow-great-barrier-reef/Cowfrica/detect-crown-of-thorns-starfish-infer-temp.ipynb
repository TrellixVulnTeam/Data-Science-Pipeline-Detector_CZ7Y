{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob\nimport shutil\nimport sys\nsys.path.append('../input/tensorflow-great-barrier-reef')\nimport torch\nfrom PIL import Image\nimport ast","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:53:03.73244Z","iopub.execute_input":"2021-12-26T05:53:03.733071Z","iopub.status.idle":"2021-12-26T05:53:05.165073Z","shell.execute_reply.started":"2021-12-26T05:53:03.732961Z","shell.execute_reply":"2021-12-26T05:53:05.164215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR  = '/kaggle/input/tensorflow-great-barrier-reef/'\nCKPT_PATH = '../input/starfish/best.pt'\nIMG_SIZE  = 1280\nCONF      = 0.15\nIOU       = 0.50\nAUGMENT   = False","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:53:05.166675Z","iopub.execute_input":"2021-12-26T05:53:05.166906Z","iopub.status.idle":"2021-12-26T05:53:05.171468Z","shell.execute_reply.started":"2021-12-26T05:53:05.166857Z","shell.execute_reply":"2021-12-26T05:53:05.170616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_path(row):\n    row['image_path'] = f'{ROOT_DIR}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    return row","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /root/.config/Ultralytics\n!cp /kaggle/input/yolov5-font/Arial.ttf /root/.config/Ultralytics/","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:53:05.173193Z","iopub.execute_input":"2021-12-26T05:53:05.173498Z","iopub.status.idle":"2021-12-26T05:53:06.780021Z","shell.execute_reply.started":"2021-12-26T05:53:05.173458Z","shell.execute_reply":"2021-12-26T05:53:06.779126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(ckpt_path, conf=0.25, iou=0.50):\n    model = torch.hub.load('/kaggle/input/yolov5-lib-ds',\n                           'custom',\n                           path=ckpt_path,\n                           source='local',\n                           force_reload=True)  # local repo\n    model.conf = conf  # NMS confidence threshold\n    model.iou  = iou  # NMS IoU threshold\n    model.classes = None   # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n    model.multi_label = False  # NMS multiple labels per box\n    model.max_det = 1000  # maximum number of detections per image\n    return model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-26T05:53:06.782351Z","iopub.execute_input":"2021-12-26T05:53:06.78301Z","iopub.status.idle":"2021-12-26T05:53:06.78928Z","shell.execute_reply.started":"2021-12-26T05:53:06.782968Z","shell.execute_reply":"2021-12-26T05:53:06.788661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, img, size=768, augment=False):\n    height, width = img.shape[:2]\n    results = model(img, size=size, augment=augment)  # custom inference size\n    preds   = results.pandas().xyxy[0]\n    bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n    if len(bboxes):\n        bboxes  = voc2coco(bboxes,height,width).astype(int)\n        confs   = preds.confidence.values\n        return bboxes, confs\n    else:\n        return [],[]\n    \ndef format_prediction(bboxes, confs):\n    annot = ''\n    if len(bboxes)>0:\n        for idx in range(len(bboxes)):\n            xmin, ymin, w, h = bboxes[idx]\n            conf             = confs[idx]\n            annot += f'{conf} {xmin} {ymin} {w} {h}'\n            annot +=' '\n        annot = annot.strip(' ')\n    return annot","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:53:06.790182Z","iopub.execute_input":"2021-12-26T05:53:06.790754Z","iopub.status.idle":"2021-12-26T05:53:06.802185Z","shell.execute_reply.started":"2021-12-26T05:53:06.790723Z","shell.execute_reply":"2021-12-26T05:53:06.80143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()# initialize the environment\niter_test = env.iter_test()      # an iterator which loops over the test set and sample submission","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:53:06.803503Z","iopub.execute_input":"2021-12-26T05:53:06.803965Z","iopub.status.idle":"2021-12-26T05:53:06.835234Z","shell.execute_reply.started":"2021-12-26T05:53:06.803931Z","shell.execute_reply":"2021-12-26T05:53:06.834434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model(CKPT_PATH, conf=CONF, iou=IOU)\nfor idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n    bboxes, confs  = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n    annot          = format_prediction(bboxes, confs)\n    pred_df['annotations'] = annot\n    env.predict(pred_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:53:06.83664Z","iopub.execute_input":"2021-12-26T05:53:06.837073Z","iopub.status.idle":"2021-12-26T05:53:14.279326Z","shell.execute_reply.started":"2021-12-26T05:53:06.836997Z","shell.execute_reply":"2021-12-26T05:53:14.27858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('submission.csv')\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-26T05:53:14.281162Z","iopub.execute_input":"2021-12-26T05:53:14.281997Z","iopub.status.idle":"2021-12-26T05:53:14.29952Z","shell.execute_reply.started":"2021-12-26T05:53:14.281945Z","shell.execute_reply":"2021-12-26T05:53:14.298583Z"},"trusted":true},"execution_count":null,"outputs":[]}]}