{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"このコンペはアノテーションのついたデータが意外に少ない。\nGANで新たな画像を水増しすることで、Recallをあげられないか？という取り組み。\n論文を見るとdetectionの精度はあまり変わっていないに見えるが、[1] で「GANのモデルをPre Trainすることで学習時間を短縮した」とあるので、[1]のモデルに流用することができるかもしれない。\n\nここでは、歩行者の擬似画像生成に使われた Pedestrian-Syntheis-GAN [2]というモデルを使う。\nBBoxとターゲットをノイズで置き換えた画像を用意すれば学習してくれるようなので、コンペの一部のデータセット（256x256のクリップ1000枚くらい）を使って学習を試みる。\n\n[1] https://arxiv.org/abs/1910.07169\n[2] https://github.com/yueruchen/Pedestrian-Synthesis-GAN\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:35.912355Z","iopub.execute_input":"2021-12-12T00:49:35.912636Z","iopub.status.idle":"2021-12-12T00:49:37.060045Z","shell.execute_reply.started":"2021-12-12T00:49:35.912609Z","shell.execute_reply":"2021-12-12T00:49:37.059057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tensorflow-great-barrier-reef/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:37.061121Z","iopub.execute_input":"2021-12-12T00:49:37.061257Z","iopub.status.idle":"2021-12-12T00:49:37.106313Z","shell.execute_reply.started":"2021-12-12T00:49:37.061239Z","shell.execute_reply":"2021-12-12T00:49:37.105637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['n_annot'] = train['annotations'].apply(lambda x: len(eval(x)))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:37.107677Z","iopub.execute_input":"2021-12-12T00:49:37.107999Z","iopub.status.idle":"2021-12-12T00:49:37.324131Z","shell.execute_reply.started":"2021-12-12T00:49:37.107977Z","shell.execute_reply":"2021-12-12T00:49:37.32294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_annot = train.query('n_annot > 0')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:37.326677Z","iopub.execute_input":"2021-12-12T00:49:37.326945Z","iopub.status.idle":"2021-12-12T00:49:37.338937Z","shell.execute_reply.started":"2021-12-12T00:49:37.326915Z","shell.execute_reply":"2021-12-12T00:49:37.337803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bboxes = {\n    'x': [], 'y': [], 'width': [], 'height': [], 'video_id': [], 'sequence': [], 'video_frame': [],\n}\n\nfor item in train_annot.itertuples():\n    annots = eval(item.annotations)\n    for annot in annots:\n        for k in annot.keys():\n            bboxes[k].append(annot[k])\n        bboxes['video_id'].append(item.video_id)\n        bboxes['sequence'].append(item.sequence)\n        bboxes['video_frame'].append(item.video_frame)\n    \nbboxes = pd.DataFrame(bboxes)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:37.340292Z","iopub.execute_input":"2021-12-12T00:49:37.340507Z","iopub.status.idle":"2021-12-12T00:49:37.524122Z","shell.execute_reply.started":"2021-12-12T00:49:37.340481Z","shell.execute_reply":"2021-12-12T00:49:37.523043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bboxes.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:37.525382Z","iopub.execute_input":"2021-12-12T00:49:37.526034Z","iopub.status.idle":"2021-12-12T00:49:37.566164Z","shell.execute_reply.started":"2021-12-12T00:49:37.525995Z","shell.execute_reply":"2021-12-12T00:49:37.565601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize BBox Distribution","metadata":{}},{"cell_type":"code","source":"df = bboxes[['x', 'y', 'width', 'height']]\nsample_df = df.copy()\ng = sns.PairGrid(sample_df)\ng.map_upper(sns.histplot)\ng.map_lower(sns.histplot)\ng.map_diag(sns.histplot, kde=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:37.567153Z","iopub.execute_input":"2021-12-12T00:49:37.567427Z","iopub.status.idle":"2021-12-12T00:49:41.176843Z","shell.execute_reply.started":"2021-12-12T00:49:37.567402Z","shell.execute_reply":"2021-12-12T00:49:41.176297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Sampled Clips\n\n1. extract bounding BBox of specific size range\n2. crop 256x256 background image around the BBox","metadata":{}},{"cell_type":"code","source":"BBOX_SELECT_QUERY = 'width >= 40 and height >= 40 and width <= 128 and height <= 128'","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:41.17761Z","iopub.execute_input":"2021-12-12T00:49:41.177781Z","iopub.status.idle":"2021-12-12T00:49:41.183062Z","shell.execute_reply.started":"2021-12-12T00:49:41.177755Z","shell.execute_reply":"2021-12-12T00:49:41.181885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = bboxes.query(BBOX_SELECT_QUERY)\n\nplt.style.use('ggplot')\nfig, axs = plt.subplots(3, 1, figsize=(15, 10))\nfor i, d in df.groupby('sequence'):\n    video_id = d['video_id'].values[0]\n    ax = axs[video_id]\n    dd = d.groupby('video_frame').agg(sum_cots=('video_id', 'count'), video_frame=('video_frame', 'min'))\n    ax.plot(dd['video_frame'], dd['sum_cots'])\n    ax.set_title(f'Video: {video_id}')\nplt.suptitle(f'BBox: {BBOX_SELECT_QUERY}', fontsize=16)\nplt.tight_layout()\nprint(f'Rate: {len(df) / len(bboxes):.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:41.18392Z","iopub.execute_input":"2021-12-12T00:49:41.184065Z","iopub.status.idle":"2021-12-12T00:49:41.853086Z","shell.execute_reply.started":"2021-12-12T00:49:41.184045Z","shell.execute_reply":"2021-12-12T00:49:41.852375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_cache = {}\n\ndef _clear_cache():\n    image_cache = {}\n    \n\ndef load_image(bbox_df, index, image_dir=\"../input/tensorflow-great-barrier-reef/train_images/\"):\n    '''\n    load one image wich include specific bounding box\n    '''\n    df = bbox_df.copy()\n    item = df.loc[index]\n    video = item[\"video_id\"]\n    frame = item[\"video_frame\"]\n    if (video, frame) in image_cache:\n        img = image_cache[(video, frame)]\n    else:\n        img = plt.imread(f\"{image_dir}video_{video}/{frame}.jpg\")\n        image_cache[(video, frame)] = img\n    \n    return img, (item.x, item.y, item.width, item.height)\n\n\ndef clip_bbox_image(img, label, clip_width=128, clip_height=128, image_width=1280, image_height=720):\n    '''\n    load image & clip region including a bounding box\n    return:\n      - img: clipped image array\n      - label: new bounding box label\n    '''\n    x, y, width, height = label\n    \n    # bbox が画像内に収まるように width, height を修正\n    width -= max(x + width - image_width, 0)\n    height -= max(y + height - image_height, 0)\n    \n    xs = min(max(0, x + (width // 2) - (clip_width // 2)), image_width - clip_width)\n    ys = min(max(0, y + (height // 2) - (clip_height // 2)), image_height - clip_height)\n    xe = xs + clip_width\n    ye = ys + clip_height\n    img_clip = img[ys:ye, xs:xe, :]\n\n    # set new clipped cordinate\n    offset_x = min(0, (x + width // 2) - clip_width // 2)\n    offset_y = min(0, (y + height // 2) - clip_height // 2)\n    offset_x_2 = max(0, x + width // 2 + clip_width // 2 - 1280)\n    offset_y_2 = max(0, y + height // 2 + clip_height // 2 - 720)\n    x = max(0, clip_width // 2 - width // 2) + offset_x + offset_x_2\n    y = max(0, clip_height // 2 - height // 2) + offset_y + offset_y_2\n    \n    return img_clip, (x, y, width, height)\n\n\ndef add_noise(img, label):\n    x, y, width, height = label\n    img_noise = img.copy()\n    img_noise[y:y + height, x:x + width, :] = np.random.randint(0, 255, (height, width, 1))\n    return img_noise\n\n\ndef create_psgan_input(df, index):\n    img, label = load_image(df, index)\n    img_clip, label = clip_bbox_image(img, label)\n    img_noise = add_noise(img_clip, label)\n    img_double = np.concatenate((img_clip, img_noise), axis=1)\n    \n    return img_double, label","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-12T00:49:41.855032Z","iopub.execute_input":"2021-12-12T00:49:41.855207Z","iopub.status.idle":"2021-12-12T00:49:41.867529Z","shell.execute_reply.started":"2021-12-12T00:49:41.855179Z","shell.execute_reply":"2021-12-12T00:49:41.866922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_clipped_bbox(\n    df,\n    index,\n    ax=None,\n    figsize=(30, 5),\n):\n    \"\"\"\n    Plot reef image. If `show_annotations` is True, create boxes\n    with the annotations for starfish.\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n        \n    img_double, label = create_psgan_input(df, index)\n    im = ax.imshow(img_double, vmin=0, vmax=255)\n    ax.axis(\"off\")\n    \n    return ax","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-12T00:49:41.868488Z","iopub.execute_input":"2021-12-12T00:49:41.868821Z","iopub.status.idle":"2021-12-12T00:49:41.88873Z","shell.execute_reply.started":"2021-12-12T00:49:41.86879Z","shell.execute_reply":"2021-12-12T00:49:41.887826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_figs = 12\nn_cols = 3\nn_rows = (n_figs - 1) // n_cols + 1\nfig, axs = plt.subplots(n_rows, n_cols, figsize=(8 * n_cols, 4 * n_rows))\naxs = axs.ravel()\n\ndf = bboxes.copy()\ndf = df.query(BBOX_SELECT_QUERY) # only extract sufficient large bbox\n\nindexes = [idx for idx in df.sample(n_figs).index.values]\n\nfor ax, index in zip(axs, indexes):\n    plot_clipped_bbox(df, index, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:41.889968Z","iopub.execute_input":"2021-12-12T00:49:41.890275Z","iopub.status.idle":"2021-12-12T00:49:43.497969Z","shell.execute_reply.started":"2021-12-12T00:49:41.890247Z","shell.execute_reply":"2021-12-12T00:49:43.497341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Write Pedestrian-Synthesize GAN Input Data","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport shutil\n\n\nout_dir = Path('/kaggle/working/psgan_datasets')\nif os.path.isdir(out_dir):\n    shutil.rmtree(out_dir)\n\n# create directory\nout_dir.mkdir(parents=True, exist_ok=True)\nimage_dir = out_dir / 'images' / 'train'\nlabel_dir = out_dir / 'bbox' / 'train'\nimage_dir.mkdir(parents=True, exist_ok=True)\nlabel_dir.mkdir(parents=True, exist_ok=True)\n! tree psgan_datasets","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:43.499049Z","iopub.execute_input":"2021-12-12T00:49:43.499314Z","iopub.status.idle":"2021-12-12T00:49:43.777285Z","shell.execute_reply.started":"2021-12-12T00:49:43.499286Z","shell.execute_reply":"2021-12-12T00:49:43.77667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import listdir\n\ndef show_one_image(root_dir):\n    plt.style.use('default')\n\n    image_path = os.path.join(root_dir, listdir(root_dir)[0])\n    im = plt.imread(image_path)\n    plt.imshow(im)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:43.778429Z","iopub.execute_input":"2021-12-12T00:49:43.778628Z","iopub.status.idle":"2021-12-12T00:49:43.784235Z","shell.execute_reply.started":"2021-12-12T00:49:43.778605Z","shell.execute_reply":"2021-12-12T00:49:43.783293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nfrom PIL import Image\nfrom tqdm import tqdm\nimport cv2\n\n\ndf = bboxes.copy()\ndf = df.query(BBOX_SELECT_QUERY)\ndf = df.sample(1200, random_state=0) # only use 1200 sample for test\n\nfor item in tqdm(df.itertuples(), total=len(df)):\n    img, label = create_psgan_input(bboxes, item.Index)\n    label = [int(x) for x in label]\n    x, y, width, height = label\n    label = {\n        'x': x * 2,\n        'y': y * 2,\n        'w': (x + width) * 2,\n        'h': (y + height) * 2,\n    }\n    \n    # write file\n    label_file_name = f'{item.Index}.json'\n    with open(label_dir / label_file_name, 'w') as f:\n        json.dump(label, f)\n        \n    # resize image\n    img = cv2.resize(img, dsize=(512, 256), interpolation=cv2.INTER_CUBIC)\n    im = Image.fromarray(img)\n    im.save(image_dir / f'{item.Index}.png')\n    \nprint('done!')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:43.78524Z","iopub.execute_input":"2021-12-12T00:49:43.786243Z","iopub.status.idle":"2021-12-12T00:49:50.725348Z","shell.execute_reply.started":"2021-12-12T00:49:43.786128Z","shell.execute_reply":"2021-12-12T00:49:50.724226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_one_image('psgan_datasets/images/train')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:50.726119Z","iopub.status.idle":"2021-12-12T00:49:50.726419Z","shell.execute_reply.started":"2021-12-12T00:49:50.726285Z","shell.execute_reply":"2021-12-12T00:49:50.726298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Varidation Data\n\n* find parameter of train distribution\n* sample from multi-valiate Gaussian distribution\n* adding sampled BBoxes into non-annotated frames","metadata":{}},{"cell_type":"markdown","source":"## Train BBox Distribution","metadata":{}},{"cell_type":"code","source":"NUM_VALID_SAMPLE = 100","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:54.869002Z","iopub.execute_input":"2021-12-12T00:49:54.869241Z","iopub.status.idle":"2021-12-12T00:49:54.873847Z","shell.execute_reply.started":"2021-12-12T00:49:54.869217Z","shell.execute_reply":"2021-12-12T00:49:54.872876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = bboxes[['x', 'y', 'width', 'height']]\nsample_df = df.query(BBOX_SELECT_QUERY)\ng = sns.PairGrid(sample_df)\ng.map_upper(sns.histplot)\ng.map_lower(sns.histplot)\ng.map_diag(sns.histplot, kde=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:55.030292Z","iopub.execute_input":"2021-12-12T00:49:55.030586Z","iopub.status.idle":"2021-12-12T00:49:57.649334Z","shell.execute_reply.started":"2021-12-12T00:49:55.030559Z","shell.execute_reply":"2021-12-12T00:49:57.648614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.cov()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:57.652359Z","iopub.execute_input":"2021-12-12T00:49:57.65272Z","iopub.status.idle":"2021-12-12T00:49:57.670144Z","shell.execute_reply.started":"2021-12-12T00:49:57.652681Z","shell.execute_reply":"2021-12-12T00:49:57.668771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample From Multi-Variate Distribution","metadata":{}},{"cell_type":"code","source":"mean = sample_df.mean().values\ncov = sample_df.cov().values","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:57.671261Z","iopub.execute_input":"2021-12-12T00:49:57.672182Z","iopub.status.idle":"2021-12-12T00:49:57.678189Z","shell.execute_reply.started":"2021-12-12T00:49:57.672103Z","shell.execute_reply":"2021-12-12T00:49:57.677724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.random.multivariate_normal(mean, cov, size=(NUM_VALID_SAMPLE)).astype(int)\nsample = pd.DataFrame(data, columns=['x', 'y', 'width', 'height'])\nsample['x'].clip(0, 1280 - 40, inplace=True)\nsample['y'].clip(0, 720 - 40, inplace=True)\nsample['width'].clip(40, inplace=True)\nsample['height'].clip(40, inplace=True)\n\n\ng = sns.PairGrid(sample)\ng.map_upper(sns.histplot)\ng.map_lower(sns.histplot)\ng.map_diag(sns.histplot, kde=False)\nsample","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:57.679582Z","iopub.execute_input":"2021-12-12T00:49:57.679825Z","iopub.status.idle":"2021-12-12T00:50:00.262024Z","shell.execute_reply.started":"2021-12-12T00:49:57.679803Z","shell.execute_reply":"2021-12-12T00:50:00.261633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add BBox into Non-Annotated Frames","metadata":{}},{"cell_type":"code","source":"image_cache = {}\ndef load_image_by_id(image_id, image_dir=\"../input/tensorflow-great-barrier-reef/train_images/\"):\n    if image_id in image_cache:\n        img = image_cache[image_id]\n    else:\n        video, frame = image_id.split('-')\n        img = plt.imread(f\"{image_dir}video_{video}/{frame}.jpg\")\n        image_cache[image_id] = img\n    \n    return img\n\ndef create_psgan_input_for_valid(df, index, label):\n    df = df.copy()\n    item = df.loc[index]\n    image_id = f'{item.video_id}-{item.video_frame}'\n    \n    img = load_image_by_id(image_id)\n    img_clip, label = clip_bbox_image(img, label)\n    img_noise = add_noise(img_clip, label)\n    img_double = np.concatenate((img_clip, img_noise), axis=1)\n    \n    return img_double, label","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:50:00.262905Z","iopub.execute_input":"2021-12-12T00:50:00.263134Z","iopub.status.idle":"2021-12-12T00:50:00.269357Z","shell.execute_reply.started":"2021-12-12T00:50:00.263113Z","shell.execute_reply":"2021-12-12T00:50:00.2686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_clipped_bbox2(\n    df,\n    index,\n    ax=None,\n    figsize=(30, 5),\n):\n    \"\"\"\n    Plot reef image. If `show_annotations` is True, create boxes\n    with the annotations for starfish.\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n        \n    img_double, label = create_psgan_input(df, index, label)\n    im = ax.imshow(img_double, vmin=0, vmax=255)\n    ax.axis(\"off\")\n    \n    return ax","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:50:00.270617Z","iopub.execute_input":"2021-12-12T00:50:00.271149Z","iopub.status.idle":"2021-12-12T00:50:00.291243Z","shell.execute_reply.started":"2021-12-12T00:50:00.271112Z","shell.execute_reply":"2021-12-12T00:50:00.290323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train.query('n_annot == 0').sample(NUM_VALID_SAMPLE).reset_index(drop=True)\n\nn_figs = 12\nn_cols = 3\nn_rows = (n_figs - 1) // n_cols + 1\nfig, axs = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 3 * n_rows))\naxs = axs.ravel()\n\nfor i, frame, label in zip(range(n_figs), df.itertuples(), sample.itertuples()):\n    label = label._asdict()\n    del label['Index']\n    label = label.values()\n    \n    img, label = create_psgan_input_for_valid(df, i, label)\n    ax = axs[i]\n    im = ax.imshow(img, vmin=0, vmax=255)\n    ax.axis(\"off\")\n    \nplt.suptitle('Validation Set Sample', fontsize=16)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:50:00.292629Z","iopub.execute_input":"2021-12-12T00:50:00.293659Z","iopub.status.idle":"2021-12-12T00:50:02.086432Z","shell.execute_reply.started":"2021-12-12T00:50:00.293607Z","shell.execute_reply":"2021-12-12T00:50:02.085446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport shutil\n\n\nout_dir = Path('/kaggle/working/psgan_datasets_val')\nif os.path.isdir(out_dir):\n    shutil.rmtree(out_dir)\n\n# create directory\nout_dir.mkdir(parents=True, exist_ok=True)\nimage_dir = out_dir / 'images' / 'test'\nlabel_dir = out_dir / 'bbox' / 'test'\nimage_dir.mkdir(parents=True, exist_ok=True)\nlabel_dir.mkdir(parents=True, exist_ok=True)\n! tree psgan_datasets_val","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:50:02.087948Z","iopub.execute_input":"2021-12-12T00:50:02.088174Z","iopub.status.idle":"2021-12-12T00:50:02.369246Z","shell.execute_reply.started":"2021-12-12T00:50:02.088145Z","shell.execute_reply":"2021-12-12T00:50:02.368609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nfrom PIL import Image\nfrom tqdm import tqdm\nimport cv2\n\n\ndf = train.query('n_annot == 0').sample(NUM_VALID_SAMPLE).reset_index(drop=True)\n\nfor i, (frame, label) in enumerate(tqdm(zip(df.itertuples(), sample.itertuples()), total=NUM_VALID_SAMPLE)):\n    label = label._asdict()\n    del label['Index']\n    label = label.values()\n    img, label = create_psgan_input_for_valid(df, i, label)\n    \n    label = [int(x) for x in label]\n    x, y, width, height = label\n    label = {\n        'x': x * 2,\n        'y': y * 2,\n        'w': (x + width) * 2,\n        'h': (y + height) * 2,\n    }\n    \n    # write file\n    label_file_name = f'{i}.json'\n    with open(label_dir / label_file_name, 'w') as f:\n        json.dump(label, f)\n        \n    # resize image\n    img = cv2.resize(img, dsize=(512, 256), interpolation=cv2.INTER_CUBIC)\n    im = Image.fromarray(img)\n    im.save(image_dir / f'{i}.png')\n    \nprint('done!')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:50:02.370441Z","iopub.execute_input":"2021-12-12T00:50:02.370991Z","iopub.status.idle":"2021-12-12T00:50:09.910373Z","shell.execute_reply.started":"2021-12-12T00:50:02.370959Z","shell.execute_reply":"2021-12-12T00:50:09.909536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_one_image('psgan_datasets_val/images/test')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T00:49:50.744518Z","iopub.status.idle":"2021-12-12T00:49:50.744831Z","shell.execute_reply.started":"2021-12-12T00:49:50.744668Z","shell.execute_reply":"2021-12-12T00:49:50.744684Z"},"trusted":true},"execution_count":null,"outputs":[]}]}