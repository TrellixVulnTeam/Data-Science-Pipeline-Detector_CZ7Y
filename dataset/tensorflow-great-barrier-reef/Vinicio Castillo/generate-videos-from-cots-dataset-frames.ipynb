{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generate videos from COTS dataset frames\nI hope you find this notebook useful!\n\nSpecial thanks to **CASFRANCO**, much of this code is from his notebook:\n* https://www.kaggle.com/casfranco/eda-let-s-understand-the-data-protect-the-reef","metadata":{}},{"cell_type":"code","source":"import ast\nimport os\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:45:14.497274Z","iopub.execute_input":"2022-01-01T23:45:14.497596Z","iopub.status.idle":"2022-01-01T23:45:14.50367Z","shell.execute_reply.started":"2022-01-01T23:45:14.497566Z","shell.execute_reply":"2022-01-01T23:45:14.502651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = '/kaggle/input/tensorflow-great-barrier-reef'\ndf_train = pd.read_csv(os.path.join(TRAIN_PATH,'train.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:44:50.462333Z","iopub.execute_input":"2022-01-01T23:44:50.463192Z","iopub.status.idle":"2022-01-01T23:44:50.523953Z","shell.execute_reply.started":"2022-01-01T23:44:50.463153Z","shell.execute_reply":"2022-01-01T23:44:50.523305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_path(row):\n    row['image_path'] = f'{TRAIN_PATH}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:44:52.044965Z","iopub.execute_input":"2022-01-01T23:44:52.04546Z","iopub.status.idle":"2022-01-01T23:44:52.050459Z","shell.execute_reply.started":"2022-01-01T23:44:52.045393Z","shell.execute_reply":"2022-01-01T23:44:52.04989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_yolox_predictions(img, bboxes, color=(45,45,252)):\n    for i in range(len(bboxes)):\n            box = bboxes[i]\n            x0 = int(box[0])\n            y0 = int(box[1])\n            x1 = int(box[2])\n            y1 = int(box[3])\n\n            cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n    return img\n\ndef xywh2xyxy(bboxes):\n    \n    output = []\n    \n    for box in bboxes:   \n        box[0] = box[0] #x0\n        box[1] = box[1] #y0\n        box[2] = box[0] + box[2] #x1\n        box[3] = box[1] + box[3] #y1  \n        output.append(box)\n    \n    return output","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:44:53.758031Z","iopub.execute_input":"2022-01-01T23:44:53.758373Z","iopub.status.idle":"2022-01-01T23:44:53.766521Z","shell.execute_reply.started":"2022-01-01T23:44:53.75832Z","shell.execute_reply":"2022-01-01T23:44:53.765908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taken only annotated photos\ndf_train[\"num_bbox\"] = df_train['annotations'].apply(lambda x: str.count(x, 'x'))\n\n#Annotations \ndf_train['annotations'] = df_train['annotations'].progress_apply(lambda x: ast.literal_eval(x))\ndf_train['bboxes'] = df_train.annotations.progress_apply(get_bbox)\n\n#Path of images\ndf_train = df_train.progress_apply(get_path, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:45:18.616866Z","iopub.execute_input":"2022-01-01T23:45:18.617145Z","iopub.status.idle":"2022-01-01T23:45:36.539024Z","shell.execute_reply.started":"2022-01-01T23:45:18.617117Z","shell.execute_reply":"2022-01-01T23:45:36.538012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"videos_df = []\nfor video_id in range(3):\n    video_id_df = df_train.query(\"video_id==\" + str(video_id))\n    print(\"Bboxes on video \" + str(video_id) + \" per frame: \" + str(video_id_df.count()[0]))\n    print(\"Qty of Bboxes on video \" + str(video_id) + \": \" + str(video_id_df['num_bbox'].sum()))\n    videos_df.append(video_id_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:45:54.818226Z","iopub.execute_input":"2022-01-01T23:45:54.818593Z","iopub.status.idle":"2022-01-01T23:45:54.865847Z","shell.execute_reply.started":"2022-01-01T23:45:54.818558Z","shell.execute_reply":"2022-01-01T23:45:54.865188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGES_PATHS = \"/kaggle/input/tensorflow-great-barrier-reef/train_images/\"\n%cd /kaggle/working\n\nvideos_qty = df_train['video_id'].unique().tolist()\n\nfor video_id in videos_qty:\n    #Choose a video and get its df\n    video_df = df_train[df_train.video_id==video_id]\n    \n    print(\"Exporting video \" + str(video_id) + \"...\")\n    out = cv2.VideoWriter('video_' + str(video_id) + '.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 15, (1280,720))\n    \n    #Get all the sequences of that video\n    video_sequences = video_df['sequence'].unique().tolist()\n    \n    for video_sequence in video_sequences:\n        #Choose a sequence and go thru each of the video frames\n        sequence_frames = df_train[df_train.sequence==video_sequence]['video_frame'].tolist()\n        \n        print(\"Writing sequence: \" + str(video_sequence) + \" to video \" + str(video_id))\n        for video_frame in tqdm(sequence_frames):\n            #use that video frame to load the image\n            filename = IMAGES_PATHS + 'video_' + str(video_id) + '/' + str(video_frame) +'.jpg'\n            img = cv2.imread(filename)\n            \n            #Draw annotations to img\n            img_row = df_train[df_train.image_path==filename]\n            bboxes = img_row['bboxes'].values[0]\n            bboxes = xywh2xyxy(bboxes)\n\n            img = draw_yolox_predictions(img, bboxes)\n\n            height, width, layers = img.shape\n            size = (width,height)\n            out.write(img)\n            \n    out.release()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:45:57.510237Z","iopub.execute_input":"2022-01-01T23:45:57.510537Z","iopub.status.idle":"2022-01-01T23:46:27.797327Z","shell.execute_reply.started":"2022-01-01T23:45:57.510503Z","shell.execute_reply":"2022-01-01T23:46:27.79627Z"},"trusted":true},"execution_count":null,"outputs":[]}]}