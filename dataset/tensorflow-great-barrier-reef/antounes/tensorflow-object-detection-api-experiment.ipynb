{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TensorFlow Object Detection API Experiment","metadata":{}},{"cell_type":"markdown","source":"**Objectives**\n\n1. ETL on competition data for TensorFlow Object Detection API\n2. Train and evaluate a model with competition data\n3. Make a first submission (if everything goes well)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T14:39:36.611813Z","iopub.execute_input":"2021-12-17T14:39:36.612812Z","iopub.status.idle":"2021-12-17T14:39:36.640316Z","shell.execute_reply.started":"2021-12-17T14:39:36.612659Z","shell.execute_reply":"2021-12-17T14:39:36.639242Z"}}},{"cell_type":"code","source":"import os\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\ntf.get_logger().setLevel(\"ERROR\")","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:54:10.946121Z","iopub.execute_input":"2021-12-17T16:54:10.946442Z","iopub.status.idle":"2021-12-17T16:54:10.952626Z","shell.execute_reply.started":"2021-12-17T16:54:10.946404Z","shell.execute_reply":"2021-12-17T16:54:10.951731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{"execution":{"iopub.status.busy":"2021-12-17T15:52:43.437304Z","iopub.execute_input":"2021-12-17T15:52:43.437673Z","iopub.status.idle":"2021-12-17T15:52:43.441461Z","shell.execute_reply.started":"2021-12-17T15:52:43.437631Z","shell.execute_reply":"2021-12-17T15:52:43.440851Z"}}},{"cell_type":"code","source":"# Helper method to load an image\n\ndef load_image_into_numpy_array(path):\n    image = None\n    image_data = tf.io.gfile.GFile(path, \"rb\").read()\n    image = Image.open(BytesIO(image_data))\n    (im_width, im_height) = image.size\n    \n    return np.array(image.getdata()).reshape(\n        (1, im_height, im_width, 3)).astype(np.uint8)\n\n# Map of all models in TFHub\n\nALL_MODELS = {\n'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1', 'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1', 'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1', 'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1', 'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1', 'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1', 'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1', 'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1', 'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1', 'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1', 'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1', 'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1', 'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1', 'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1', 'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1', 'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1', 'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1', 'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1', 'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1', 'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n}\n\n# List of tuples with Human Keypoints needed for models with keypoints\n\nCOCO17_HUMAN_POSE_KEYPOINTS = [\n    (0, 1), (0, 2), (1, 3), (2, 4), (0, 5), (0, 6), (5, 7), (7, 9), (6, 8), (8, 10), (5, 6), \n    (5, 11), (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)\n]","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:54:24.703738Z","iopub.execute_input":"2021-12-17T16:54:24.704077Z","iopub.status.idle":"2021-12-17T16:54:24.718035Z","shell.execute_reply.started":"2021-12-17T16:54:24.704042Z","shell.execute_reply":"2021-12-17T16:54:24.717334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualisation Tools","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:05:47.524355Z","iopub.execute_input":"2021-12-17T16:05:47.524705Z","iopub.status.idle":"2021-12-17T16:05:47.529361Z","shell.execute_reply.started":"2021-12-17T16:05:47.524667Z","shell.execute_reply":"2021-12-17T16:05:47.528495Z"}}},{"cell_type":"code","source":"# Use TensorFlow Object Detection API\n\n# Clone the TensorFlow models repository\n\n!git clone --depth 1 https://github.com/tensorflow/models","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:07:18.759932Z","iopub.execute_input":"2021-12-17T16:07:18.760216Z","iopub.status.idle":"2021-12-17T16:07:23.377966Z","shell.execute_reply.started":"2021-12-17T16:07:18.76019Z","shell.execute_reply":"2021-12-17T16:07:23.377047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install the TensorFlow Object Detection API","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:08:02.408411Z","iopub.execute_input":"2021-12-17T16:08:02.408787Z","iopub.status.idle":"2021-12-17T16:08:02.41342Z","shell.execute_reply.started":"2021-12-17T16:08:02.408748Z","shell.execute_reply":"2021-12-17T16:08:02.412704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\nsudo apt install -y protobuf-compiler\ncd models/research/\nprotoc object_detection/protos/*.proto --python_out=.\ncp object_detection/packages/tf2/setup.py .\npython -m pip install .","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:09:06.725826Z","iopub.execute_input":"2021-12-17T16:09:06.726153Z","iopub.status.idle":"2021-12-17T16:10:52.07141Z","shell.execute_reply.started":"2021-12-17T16:09:06.726114Z","shell.execute_reply":"2021-12-17T16:10:52.069915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import dependencies for object detection\n\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils\nfrom object_detection.utils import ops\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:16:29.561305Z","iopub.execute_input":"2021-12-17T16:16:29.561948Z","iopub.status.idle":"2021-12-17T16:16:30.79424Z","shell.execute_reply.started":"2021-12-17T16:16:29.561899Z","shell.execute_reply":"2021-12-17T16:16:30.793359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build an Object Detection Model","metadata":{}},{"cell_type":"code","source":"# Let's try a version of RetinaNet: SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)\n\nmodel_name = \"SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)\"\nmodel_handle = ALL_MODELS[model_name]\n\n# Load the model from TensorFlow Hub\n\nprint(\"loading model...\")\nhub_model = hub.load(model_handle)\nprint(\"model loaded !\")","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:23:09.42378Z","iopub.execute_input":"2021-12-17T16:23:09.424942Z","iopub.status.idle":"2021-12-17T16:23:30.053408Z","shell.execute_reply.started":"2021-12-17T16:23:09.424882Z","shell.execute_reply":"2021-12-17T16:23:30.052238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model trials on training images","metadata":{}},{"cell_type":"code","source":"# Get the data\n\npath = \"../input/tensorflow-great-barrier-reef/\"\ntrain = pd.read_csv(path+\"train.csv\")\ntest = pd.read_csv(path+\"test.csv\")\n\n# Add images path to data\n\ntrain[\"image_path\"] = \"../input/tensorflow-great-barrier-reef/train_images/video_\"+train[\"video_id\"].astype(str)+\"/\"+train[\"image_id\"].apply(lambda x: x.split(\"-\")[1])+\".jpg\"\n\n# Reorganise columns\n\ncols = train.columns[:-2].tolist()+[\"image_path\"]+[train.columns[-2]]\ntrain = train[cols]\n\nprint(\"First rows of training data:\\n\")\nprint(train.head(), \"\\n\")\n\nprint(\"Training data types:\\n\")\nprint(train.dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:26:46.950608Z","iopub.execute_input":"2021-12-17T16:26:46.951225Z","iopub.status.idle":"2021-12-17T16:26:47.124583Z","shell.execute_reply.started":"2021-12-17T16:26:46.951179Z","shell.execute_reply":"2021-12-17T16:26:47.123634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pick an image randomly from the training set\n\nimage_path = pd.DataFrame.sample(train[\"image_path\"], n=1).tolist()[0]\nimage_np = load_image_into_numpy_array(image_path)\n\nplt.figure(figsize=(10, 8))\nplt.imshow(image_np[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:42:41.779324Z","iopub.execute_input":"2021-12-17T16:42:41.779784Z","iopub.status.idle":"2021-12-17T16:42:44.547688Z","shell.execute_reply.started":"2021-12-17T16:42:41.779749Z","shell.execute_reply":"2021-12-17T16:42:44.546684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run inference with our model\nresult = hub_model(image_np)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:50:44.022417Z","iopub.execute_input":"2021-12-17T16:50:44.022715Z","iopub.status.idle":"2021-12-17T16:50:48.864496Z","shell.execute_reply.started":"2021-12-17T16:50:44.022686Z","shell.execute_reply":"2021-12-17T16:50:48.863621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n\nlabel_id_offset = 0\nimage_np_with_detections = image_np.copy()\n\n# Use keypoints if available in detections\nkeypoints, keypoint_scores = None, None\nif 'detection_keypoints' in results:\n    keypoints = result['detection_keypoints'][0]\n    keypoint_scores = result['detection_keypoint_scores'][0]\n\nvisualization_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_detections[0],\n      result['detection_boxes'][0],\n      (result['detection_classes'][0] + label_id_offset),\n      result['detection_scores'][0],\n      category_index,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=200,\n      min_score_thresh=.1,\n      agnostic_mode=False,\n      keypoints=keypoints,\n      keypoint_scores=keypoint_scores,\n      keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np_with_detections[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:55:11.057761Z","iopub.execute_input":"2021-12-17T16:55:11.058605Z","iopub.status.idle":"2021-12-17T16:55:12.312512Z","shell.execute_reply.started":"2021-12-17T16:55:11.058548Z","shell.execute_reply":"2021-12-17T16:55:12.310861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}