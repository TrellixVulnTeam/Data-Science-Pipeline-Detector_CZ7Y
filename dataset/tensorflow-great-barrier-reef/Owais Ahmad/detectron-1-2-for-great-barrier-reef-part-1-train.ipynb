{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Detectron Half For Great Barrier Reef**","metadata":{}},{"cell_type":"markdown","source":"#### One of the most challenges now a days in Kaggle Competetion is that no Internet is provided while submission of the Notebook. To handle complex models such as Detectron2 it might be tricky without internet access as it requires lots of dependencies and we also have to register out dataset. In this Notebook I utilized Detectron2 version 0.5. Hope you like this Notebook.","metadata":{}},{"cell_type":"markdown","source":" ## A little about Detectron2\n Detectron2 is Facebook AI Research's next generation software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, Detectron, and it originates from maskrcnn-benchmark","metadata":{}},{"cell_type":"markdown","source":"### Starting this Notebook with some Basic Imports. As we move on I will be importing other Modules.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport ast\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nfrom sklearn.model_selection import GroupKFold\nfrom PIL import Image\nfrom string import Template\nfrom IPython.display import display\nfrom shutil import *\n# common libraries\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-21T17:47:22.761404Z","iopub.execute_input":"2022-01-21T17:47:22.761719Z","iopub.status.idle":"2022-01-21T17:47:23.84231Z","shell.execute_reply.started":"2022-01-21T17:47:22.761636Z","shell.execute_reply":"2022-01-21T17:47:23.841565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_path(row):\n    \n    row['image_path'] = f'../input/tensorflow-great-barrier-reef/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    return row\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:47:23.844129Z","iopub.execute_input":"2022-01-21T17:47:23.844451Z","iopub.status.idle":"2022-01-21T17:47:23.850287Z","shell.execute_reply.started":"2022-01-21T17:47:23.844415Z","shell.execute_reply":"2022-01-21T17:47:23.849649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\")\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:47:23.851517Z","iopub.execute_input":"2022-01-21T17:47:23.851947Z","iopub.status.idle":"2022-01-21T17:47:23.924154Z","shell.execute_reply.started":"2022-01-21T17:47:23.851908Z","shell.execute_reply":"2022-01-21T17:47:23.923494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"num_bbox\"] = df['annotations'].progress_apply(lambda x: str.count(x, 'x'))\ndf_train = df[df[\"num_bbox\"]>0]\n\n\ndf_train['annotations'] = df_train['annotations'].progress_apply(lambda x: ast.literal_eval(x))\ndf_train['bboxes'] = df_train.annotations.progress_apply(get_bbox)\n\n\ndf_train[\"width\"] = 1280\ndf_train[\"height\"] = 720\n\n\ndf_train = df_train.progress_apply(get_path, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:47:23.925259Z","iopub.execute_input":"2022-01-21T17:47:23.925496Z","iopub.status.idle":"2022-01-21T17:47:27.600818Z","shell.execute_reply.started":"2022-01-21T17:47:23.925462Z","shell.execute_reply":"2022-01-21T17:47:27.60011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.reset_index(drop=True,inplace=True)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:47:27.602931Z","iopub.execute_input":"2022-01-21T17:47:27.603583Z","iopub.status.idle":"2022-01-21T17:47:27.635397Z","shell.execute_reply.started":"2022-01-21T17:47:27.603545Z","shell.execute_reply":"2022-01-21T17:47:27.634617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = GroupKFold(n_splits = 5) \ndf_train['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(kf.split(df_train, y = df_train.video_id.tolist(), groups=df_train.sequence)):\n    df_train.loc[val_idx, 'fold'] = fold\n\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:47:27.636821Z","iopub.execute_input":"2022-01-21T17:47:27.637121Z","iopub.status.idle":"2022-01-21T17:47:27.66501Z","shell.execute_reply.started":"2022-01-21T17:47:27.637075Z","shell.execute_reply":"2022-01-21T17:47:27.664421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir dataset\n!mkdir dataset/images\n!mkdir dataset/images/train\n!mkdir dataset/images/val\n!mkdir dataset/annotations","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:47:27.666032Z","iopub.execute_input":"2022-01-21T17:47:27.666683Z","iopub.status.idle":"2022-01-21T17:47:31.076371Z","shell.execute_reply.started":"2022-01-21T17:47:27.666646Z","shell.execute_reply":"2022-01-21T17:47:31.075433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SELECTED_FOLD = 4\n\nannotion_id=0\nfor i in tqdm(range(len(df_train))):\n    row = df_train.loc[i]\n    if row.fold != SELECTED_FOLD:\n        copyfile(f'{row.image_path}', f'dataset/images/train/{row.image_id}.jpg')\n    else:\n        copyfile(f'{row.image_path}', f'dataset/images/val/{row.image_id}.jpg') ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:47:31.077938Z","iopub.execute_input":"2022-01-21T17:47:31.078194Z","iopub.status.idle":"2022-01-21T17:48:33.304297Z","shell.execute_reply.started":"2022-01-21T17:47:31.078156Z","shell.execute_reply":"2022-01-21T17:48:33.303077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of training files:', len(os.listdir(f\"dataset/images/train/\")))\nprint(f'Number of validation files:', len(os.listdir(f\"dataset/images/val/\")))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:33.30682Z","iopub.execute_input":"2022-01-21T17:48:33.307104Z","iopub.status.idle":"2022-01-21T17:48:33.317427Z","shell.execute_reply.started":"2022-01-21T17:48:33.307074Z","shell.execute_reply":"2022-01-21T17:48:33.316758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_annot_json(json_annotation, filename):\n    with open(filename, 'w') as f:\n        output_json = json.dumps(json_annotation)\n        f.write(output_json)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:33.318579Z","iopub.execute_input":"2022-01-21T17:48:33.318921Z","iopub.status.idle":"2022-01-21T17:48:33.618717Z","shell.execute_reply.started":"2022-01-21T17:48:33.318882Z","shell.execute_reply":"2022-01-21T17:48:33.617916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset2coco(df, dest_path):\n    \n    global annotion_id\n    \n    annotations_json = {\n        \"info\": [],\n        \"licenses\": [],\n        \"categories\": [],\n        \"images\": [],\n        \"annotations\": []\n    }\n    \n    info = {\n        \"year\": \"2022\",\n        \"version\": \"1\",\n        \"description\": \"COTS dataset - COCO format\",\n        \"contributor\": \"Owais Ahmad\",\n        \"url\": \"https://kaggle.com\",\n        \"date_created\": \"2022-01-18T16:40:06+00:00\"\n    }\n    annotations_json[\"info\"].append(info)\n    \n    lic = {\n            \"id\": 1,\n            \"url\": \"\",\n            \"name\": \"Unknown\"\n        }\n    annotations_json[\"licenses\"].append(lic)\n\n    classes = {\"id\": 0, \"name\": \"starfish\", \"supercategory\": \"none\"}\n\n    annotations_json[\"categories\"].append(classes)\n\n    \n    for ann_row in df.itertuples():\n            \n        images = {\n            \"id\": ann_row[0],\n            \"license\": 1,\n            \"file_name\": ann_row.image_id + '.jpg',\n            \"height\": ann_row.height,\n            \"width\": ann_row.width,\n            \"date_captured\": \"2022-01-18T16:43:26+00:00\"\n        }\n        \n        annotations_json[\"images\"].append(images)\n        \n        bbox_list = ann_row.bboxes\n        \n        for bbox in bbox_list:\n            b_width = bbox[2]\n            b_height = bbox[3]\n            \n            # some boxes in COTS are outside the image height and width\n            if (bbox[0] + bbox[2] > 1280):\n                b_width = bbox[0] - 1280 \n            if (bbox[1] + bbox[3] > 720):\n                b_height = bbox[1] - 720 \n                \n            image_annotations = {\n                \"id\": annotion_id,\n                \"image_id\": ann_row[0],\n                \"category_id\": 0,\n                \"bbox\": [bbox[0], bbox[1], b_width, b_height],\n                \"area\": bbox[2] * bbox[3],\n                \"segmentation\": [],\n                \"iscrowd\": 0\n            }\n            \n            annotion_id += 1\n            annotations_json[\"annotations\"].append(image_annotations)\n        \n        \n    print(f\"Dataset COTS annotation to COCO json format completed! Files: {len(df)}\")\n    return annotations_json","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:33.620059Z","iopub.execute_input":"2022-01-21T17:48:33.620791Z","iopub.status.idle":"2022-01-21T17:48:33.865245Z","shell.execute_reply.started":"2022-01-21T17:48:33.620745Z","shell.execute_reply":"2022-01-21T17:48:33.864336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_annot_json = dataset2coco(df_train[df_train.fold != SELECTED_FOLD], f\"dataset/images/train/\")","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:33.868029Z","iopub.execute_input":"2022-01-21T17:48:33.868248Z","iopub.status.idle":"2022-01-21T17:48:34.031485Z","shell.execute_reply.started":"2022-01-21T17:48:33.8682Z","shell.execute_reply":"2022-01-21T17:48:34.030005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Json files for annotation is saved in seprate annotations folder which I will use further while register our dataset into Detectron2","metadata":{}},{"cell_type":"code","source":"train_annot_json = dataset2coco(df_train[df_train.fold != SELECTED_FOLD], f\"dataset/images/train/\")\nval_annot_json = dataset2coco(df_train[df_train.fold == SELECTED_FOLD], f\"dataset/images/valid\")\n\n\nsave_annot_json(train_annot_json, f\"dataset/annotations/train.json\")\nsave_annot_json(val_annot_json, f\"dataset/annotations/valid.json\")","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:34.032869Z","iopub.execute_input":"2022-01-21T17:48:34.033112Z","iopub.status.idle":"2022-01-21T17:48:34.149698Z","shell.execute_reply.started":"2022-01-21T17:48:34.033079Z","shell.execute_reply":"2022-01-21T17:48:34.148805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions, used these for debugging purposes\n### Detector2 build only succeeds if CUDA version is correct","metadata":{}},{"cell_type":"code","source":"!nvidia-smi\n!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:34.157412Z","iopub.execute_input":"2022-01-21T17:48:34.160173Z","iopub.status.idle":"2022-01-21T17:48:35.775107Z","shell.execute_reply.started":"2022-01-21T17:48:34.160134Z","shell.execute_reply":"2022-01-21T17:48:35.774185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:35.778551Z","iopub.execute_input":"2022-01-21T17:48:35.778804Z","iopub.status.idle":"2022-01-21T17:48:37.585136Z","shell.execute_reply.started":"2022-01-21T17:48:35.778773Z","shell.execute_reply":"2022-01-21T17:48:37.584293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ### The submission notebooks don't have access to the internet, in order to install detectron2 we need to download dependecies with pip download, copy them into Output Directory and Install them as followed it in this notebook","metadata":{}},{"cell_type":"code","source":"!cp  -r ../input/detectron-05/ ./detectron-05/","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:37.586731Z","iopub.execute_input":"2022-01-21T17:48:37.58704Z","iopub.status.idle":"2022-01-21T17:48:46.036242Z","shell.execute_reply.started":"2022-01-21T17:48:37.586994Z","shell.execute_reply":"2022-01-21T17:48:46.035314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Standard procedure to install Detectron2. Install with this if you are facing Issue with the Offline Version","metadata":{}},{"cell_type":"code","source":"#!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' #\n#!git clone https://github.com/facebookresearch/detectron2.git #","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:46.039075Z","iopub.execute_input":"2022-01-21T17:48:46.039353Z","iopub.status.idle":"2022-01-21T17:48:46.043315Z","shell.execute_reply.started":"2022-01-21T17:48:46.039313Z","shell.execute_reply":"2022-01-21T17:48:46.04241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/working/detectron-05/whls/pycocotools-2.0.2/dist/pycocotools-2.0.2.tar --no-index --find-links ../input/detectron-05/whls \n!pip install /kaggle/working/detectron-05/whls/fvcore-0.1.5.post20211019/fvcore-0.1.5.post20211019 --no-index --find-links ../input/detectron-05/whls \n!pip install /kaggle/working/detectron-05/whls/antlr4-python3-runtime-4.8/antlr4-python3-runtime-4.8 --no-index --find-links ../input/detectron-05/whls \n!pip install /kaggle/working/detectron-05/whls/detectron2-0.5/detectron2 --no-index --find-links ../input/detectron-05/whls ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:48:46.044992Z","iopub.execute_input":"2022-01-21T17:48:46.045633Z","iopub.status.idle":"2022-01-21T17:52:03.899075Z","shell.execute_reply.started":"2022-01-21T17:48:46.045579Z","shell.execute_reply":"2022-01-21T17:52:03.897995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Base setup For Detectron2 Training","metadata":{}},{"cell_type":"code","source":"# detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.structures import BoxMode\nfrom detectron2.data.datasets import register_coco_instances\n#import shutil\n#shutil.rmtree('detectron_clone')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:52:03.900836Z","iopub.execute_input":"2022-01-21T17:52:03.901106Z","iopub.status.idle":"2022-01-21T17:52:04.334516Z","shell.execute_reply.started":"2022-01-21T17:52:03.901065Z","shell.execute_reply":"2022-01-21T17:52:04.333789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m detectron2.utils.collect_env","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:52:04.337929Z","iopub.execute_input":"2022-01-21T17:52:04.33843Z","iopub.status.idle":"2022-01-21T17:52:10.199119Z","shell.execute_reply.started":"2022-01-21T17:52:04.338392Z","shell.execute_reply":"2022-01-21T17:52:10.198207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In order to Use Detectron2 We need to Register Out Dataset to Detectron2. While Processing the Dataset I generated corresponding Train.json and Valid.json which I will utilize Now.","metadata":{}},{"cell_type":"code","source":"register_coco_instances( 'Train_Great_Barrier',{},'/kaggle/working/dataset/annotations/train.json','/kaggle/working/dataset/images/train/')# os.path.join(dataset_dir,train_dir))\nregister_coco_instances( 'Valid_Great_Barrier',{},'/kaggle/working/dataset/annotations/valid.json','/kaggle/working/dataset/images/val/')# os.path.join(dataset_dir,train_dir))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:52:10.200644Z","iopub.execute_input":"2022-01-21T17:52:10.200936Z","iopub.status.idle":"2022-01-21T17:52:10.209212Z","shell.execute_reply.started":"2022-01-21T17:52:10.200897Z","shell.execute_reply":"2022-01-21T17:52:10.208416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_dicts = DatasetCatalog.get(\"Train_Great_Barrier\")\nmetadata_dicts = MetadataCatalog.get(\"Train_Great_Barrier\")","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:52:10.21053Z","iopub.execute_input":"2022-01-21T17:52:10.211068Z","iopub.status.idle":"2022-01-21T17:52:10.484883Z","shell.execute_reply.started":"2022-01-21T17:52:10.211031Z","shell.execute_reply":"2022-01-21T17:52:10.484111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.utils.visualizer import ColorMode\nfrom detectron2.engine import DefaultTrainer","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:52:10.486343Z","iopub.execute_input":"2022-01-21T17:52:10.486674Z","iopub.status.idle":"2022-01-21T17:52:10.492186Z","shell.execute_reply.started":"2022-01-21T17:52:10.486638Z","shell.execute_reply":"2022-01-21T17:52:10.491279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 2, figsize =(30,20))\nindices=[ax[0][0],ax[1][0],ax[0][1],ax[1][1] ]\ni=-1\nfor d in random.sample(dataset_dicts, 4):\n    i=i+1    \n    img = cv2.imread(d[\"file_name\"])\n    v = Visualizer(img[:, :, :],\n                   metadata=metadata_dicts, \n                   scale=0.8, instance_mode=ColorMode.IMAGE_BW \n    )\n    out = v.draw_dataset_dict(d)\n    indices[i].grid(False)\n    indices[i].axis('off')\n    indices[i].imshow(out.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:52:10.493711Z","iopub.execute_input":"2022-01-21T17:52:10.494294Z","iopub.status.idle":"2022-01-21T17:52:12.471455Z","shell.execute_reply.started":"2022-01-21T17:52:10.494251Z","shell.execute_reply":"2022-01-21T17:52:12.470673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augumentation","metadata":{}},{"cell_type":"code","source":"from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\nimport detectron2.data.transforms as T\n\ndef custom_mapper(dataset_dict):\n    \n    dataset_dict = copy.deepcopy(dataset_dict)\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n    transform_list = [\n                      T.RandomBrightness(0.5, 2.1),\n                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n                      #T.RandomCrop(\"absolute\", (640, 640))\n                      ]\n    image, transforms = T.apply_transform_gens(transform_list, image)\n    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n\n    annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n        if obj.get(\"iscrowd\", 0) == 0\n    ]\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n    return dataset_dict\nclass AugTrainer(DefaultTrainer):\n    \n    @classmethod\n    def build_train_loader(cls, cfg):\n        return build_detection_train_loader(cfg, mapper=custom_mapper)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:52:12.472882Z","iopub.execute_input":"2022-01-21T17:52:12.473156Z","iopub.status.idle":"2022-01-21T17:52:12.486058Z","shell.execute_reply.started":"2022-01-21T17:52:12.473117Z","shell.execute_reply":"2022-01-21T17:52:12.485161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = get_cfg()\nconfig_name = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\" \n#config_name = \"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"\ncfg.merge_from_file(model_zoo.get_config_file(config_name))\n\ncfg.DATASETS.TRAIN = (\"Train_Great_Barrier\",)\ncfg.DATASETS.TEST = (\"Valid_Great_Barrier\",)\n\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\n\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR = 0.0008\n\ncfg.SOLVER.WARMUP_ITERS = 200\ncfg.SOLVER.MAX_ITER = 2500 #adjust up if val mAP is still rising, adjust down if overfit\ncfg.SOLVER.STEPS = (11, 50) # must be less than  MAX_ITER \ncfg.SOLVER.GAMMA = 0.5\n\n\ncfg.SOLVER.CHECKPOINT_PERIOD = 700  # Small value=Frequent save need a lot of storage.\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 16\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n\n\n#Training using custom trainer defined above\ntrainer = AugTrainer(cfg) \ntrainer = DefaultTrainer(cfg) \n#trainer.resume_or_load(resume=False)\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T17:52:12.487397Z","iopub.execute_input":"2022-01-21T17:52:12.487908Z","iopub.status.idle":"2022-01-21T19:05:01.88281Z","shell.execute_reply.started":"2022-01-21T17:52:12.487875Z","shell.execute_reply":"2022-01-21T19:05:01.881963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dumping config files variables as we may need them while Inferencing ","metadata":{}},{"cell_type":"code","source":"metrics_df = pd.read_json(\"./output/metrics.json\", orient=\"records\", lines=True)\nmdf = metrics_df.sort_values(\"iteration\")\nmdf.T","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:05:01.885259Z","iopub.execute_input":"2022-01-21T19:05:01.885557Z","iopub.status.idle":"2022-01-21T19:05:01.949558Z","shell.execute_reply.started":"2022-01-21T19:05:01.885506Z","shell.execute_reply":"2022-01-21T19:05:01.948757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Loss curve\nfig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"total_loss\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\nif \"validation_loss\" in mdf.columns:\n    mdf2 = mdf[~mdf[\"validation_loss\"].isna()]\n    ax.plot(mdf2[\"iteration\"], mdf2[\"validation_loss\"], c=\"C1\", label=\"validation\")\n\n#ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"Loss curve\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:05:01.951041Z","iopub.execute_input":"2022-01-21T19:05:01.951328Z","iopub.status.idle":"2022-01-21T19:05:02.147149Z","shell.execute_reply.started":"2022-01-21T19:05:01.951294Z","shell.execute_reply":"2022-01-21T19:05:02.146423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Loss curve\nfig, ax = plt.subplots()\n\nmdf1 = mdf[~mdf[\"fast_rcnn/cls_accuracy\"].isna()]\nax.plot(mdf1[\"iteration\"], mdf1[\"fast_rcnn/cls_accuracy\"], c=\"C0\", label=\"train\")\n# ax.set_ylim([0, 0.5])\nax.legend()\nax.set_title(\"cls_accuracy\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:05:02.148403Z","iopub.execute_input":"2022-01-21T19:05:02.148655Z","iopub.status.idle":"2022-01-21T19:05:02.330486Z","shell.execute_reply.started":"2022-01-21T19:05:02.148622Z","shell.execute_reply":"2022-01-21T19:05:02.329807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  If this Notebook helps you a bit,as I have worked very Hard for this so Please up-vote to keep me motivated and Enthusiastic 😁 Thanks!\n- Follow me on Linkedin [Link](https://www.linkedin.com/in/owaiskhan9654/)\n- Also see my Portfolio [Link](https://owaiskhan9654.github.io/)","metadata":{}},{"cell_type":"markdown","source":"## I might be overfitting Detectron2 in this Notebook but their is a hidden reason for that which I will explain. Also See you in Part2 with more explanations","metadata":{}},{"cell_type":"markdown","source":"# Predictor\nA predictor is defined with 0.5 threshold score which gives bounding box and label for the test images","metadata":{}},{"cell_type":"code","source":"!zip -r  output.zip output  ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:05:02.331763Z","iopub.execute_input":"2022-01-21T19:05:02.332159Z","iopub.status.idle":"2022-01-21T19:06:31.609734Z","shell.execute_reply.started":"2022-01-21T19:05:02.332121Z","shell.execute_reply":"2022-01-21T19:06:31.608919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(\"cfg.pkl\", \"wb\") as f:\n    pickle.dump(cfg, f)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:06:31.61178Z","iopub.execute_input":"2022-01-21T19:06:31.612545Z","iopub.status.idle":"2022-01-21T19:06:31.61938Z","shell.execute_reply.started":"2022-01-21T19:06:31.612498Z","shell.execute_reply":"2022-01-21T19:06:31.618651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n#cfg.DATASETS.TEST = (\"Test_Great_Barrier\", )\npredictor = DefaultPredictor(cfg)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:06:31.620921Z","iopub.execute_input":"2022-01-21T19:06:31.621539Z","iopub.status.idle":"2022-01-21T19:06:34.304903Z","shell.execute_reply.started":"2022-01-21T19:06:31.621501Z","shell.execute_reply":"2022-01-21T19:06:34.304131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.evaluation.evaluator import DatasetEvaluator\nimport pycocotools.mask as mask_util\nfrom detectron2.engine import BestCheckpointer\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:34:45.681469Z","iopub.execute_input":"2022-01-21T19:34:45.682035Z","iopub.status.idle":"2022-01-21T19:34:45.686633Z","shell.execute_reply.started":"2022-01-21T19:34:45.681996Z","shell.execute_reply":"2022-01-21T19:34:45.685661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class F2ScoreEvaluator(DatasetEvaluator):\n    def __init__(self, dataset_name):\n        dataset_dicts = DatasetCatalog.get(dataset_name)\n        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:13:30.789161Z","iopub.execute_input":"2022-01-21T19:13:30.789706Z","iopub.status.idle":"2022-01-21T19:13:30.794273Z","shell.execute_reply.started":"2022-01-21T19:13:30.789667Z","shell.execute_reply":"2022-01-21T19:13:30.793617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('################################################################')\nprint('################### test the best model: F2 Score ##################')\nprint('################################################################')\n#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_best.pth\")  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n#predictor = DefaultPredictor(cfg)\nevaluator = F2ScoreEvaluator(\"Valid_Great_Barrier\")\nval_loader = build_detection_test_loader(cfg, \"Valid_Great_Barrier\")\nFS_bm=inference_on_dataset(predictor.model, val_loader, evaluator)['F2 Score']\nprint(\"F2 Score for best model=\",FS_bm)\n\nprint('################################################################')\nprint('################### test the best model : AP@50-95 ##################')\nprint('################################################################')\nevaluator = COCOEvaluator(Data_Resister_valid, output_dir=\"./output\")\nval_loader = build_detection_test_loader(cfg, \"Valid_Great_Barrier\")\nAP_bm=inference_on_dataset(predictor.model, val_loader, evaluator)['bbox']['AP']\nprint(\"AP for best model=\",AP_bm)\n\nprint('################################################################')\nprint('################## test the final model: F2 Score ##################')\nprint('################################################################')\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)\nevaluator = F2ScoreEvaluator(\"Valid_Great_Barrier\")\nval_loader = build_detection_test_loader(cfg, \"Valid_Great_Barrier\")\nFS_fm=inference_on_dataset(predictor.model, val_loader, evaluator)['F2 Score']\nprint(\"F2 Score for the final model=\",FS_fm)\nprint('################################################################')\nprint('################## test final model: AP@50-95 ##################')\nprint('################################################################')\nevaluator = COCOEvaluator(\"Valid_Great_Barrier\", output_dir=\"./output\")\nval_loader = build_detection_test_loader(cfg, \"Valid_Great_Barrier\")\nAP_fm=inference_on_dataset(predictor.model, val_loader, evaluator)['bbox']['AP']\nprint(\"AP for the final model=\",AP_fm)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T19:34:51.354659Z","iopub.execute_input":"2022-01-21T19:34:51.355104Z","iopub.status.idle":"2022-01-21T19:41:43.709363Z","shell.execute_reply.started":"2022-01-21T19:34:51.35507Z","shell.execute_reply":"2022-01-21T19:41:43.708442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}