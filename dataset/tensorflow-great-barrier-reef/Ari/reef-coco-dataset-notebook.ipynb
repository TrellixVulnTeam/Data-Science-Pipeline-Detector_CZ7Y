{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **References**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/julian3833/reef-starter-torch-fasterrcnn-train-lb-0-361\n\nhttps://www.kaggle.com/rhythmcam/ast-basic-string-expression\n\nhttps://www.kaggle.com/vexxingbanana/sartorius-coco-dataset-notebook","metadata":{}},{"cell_type":"markdown","source":"# **Install Pycocotools**","metadata":{}},{"cell_type":"code","source":"!pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-24T02:43:47.352444Z","iopub.execute_input":"2021-11-24T02:43:47.353303Z","iopub.status.idle":"2021-11-24T02:44:08.297271Z","shell.execute_reply.started":"2021-11-24T02:43:47.353161Z","shell.execute_reply":"2021-11-24T02:44:08.296207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Libraries**","metadata":{}},{"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport json\nimport glob\nimport pycocotools\nfrom pycocotools import mask\nimport random\nimport cv2\nimport re\nimport ast","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:06:27.037736Z","iopub.execute_input":"2021-11-24T03:06:27.038667Z","iopub.status.idle":"2021-11-24T03:06:27.045061Z","shell.execute_reply.started":"2021-11-24T03:06:27.038613Z","shell.execute_reply":"2021-11-24T03:06:27.043958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create Coco Json File**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:44:09.425449Z","iopub.execute_input":"2021-11-24T02:44:09.426053Z","iopub.status.idle":"2021-11-24T02:44:09.491168Z","shell.execute_reply.started":"2021-11-24T02:44:09.426019Z","shell.execute_reply":"2021-11-24T02:44:09.490135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-11-24T02:56:40.7167Z","iopub.execute_input":"2021-11-24T02:56:40.717462Z","iopub.status.idle":"2021-11-24T02:56:40.740191Z","shell.execute_reply.started":"2021-11-24T02:56:40.717423Z","shell.execute_reply":"2021-11-24T02:56:40.739305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_json_dict = {\n    \"images\": [],\n    \"annotations\": [],\n    \"categories\": []\n}\ncategory_dict = {\"id\": 1, \"name\": \"starfish\", \"supercategory\": \"none\"}\noutput_json_dict[\"categories\"].append(category_dict)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:07:36.029346Z","iopub.execute_input":"2021-11-24T03:07:36.030002Z","iopub.status.idle":"2021-11-24T03:07:36.034729Z","shell.execute_reply.started":"2021-11-24T03:07:36.029958Z","shell.execute_reply":"2021-11-24T03:07:36.033847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annot_id = 0","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:07:36.165973Z","iopub.execute_input":"2021-11-24T03:07:36.166623Z","iopub.status.idle":"2021-11-24T03:07:36.170231Z","shell.execute_reply.started":"2021-11-24T03:07:36.166582Z","shell.execute_reply":"2021-11-24T03:07:36.169438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_boxes(row):\n    \"\"\"Return the bboxes for a given row as a 3D matrix \"\"\"\n    #if len(row['annotations']) == 0:\n    #    row['annotations'] = [{'x': -1, 'y': -1, 'width': -1, 'height': -1}]\n    return pd.DataFrame(row['annotations'], columns=['x', 'y', 'width', 'height']).astype(float).values","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:07:36.30639Z","iopub.execute_input":"2021-11-24T03:07:36.307023Z","iopub.status.idle":"2021-11-24T03:07:36.311836Z","shell.execute_reply.started":"2021-11-24T03:07:36.306979Z","shell.execute_reply":"2021-11-24T03:07:36.310795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for f in train_df.itertuples():\n    img_path = '../input/tensorflow-great-barrier-reef/train_images/video_' + str(f[1]) + '/' + f[5].split('-')[1] + '.jpg'\n    img = cv2.imread(img_path)\n    height, width, channels = img.shape\n\n    img_info = {\n        \"id\": f[0],\n        \"width\": width,\n        \"height\": height,\n        \"file_name\": img_path\n    }\n    output_json_dict[\"images\"].append(img_info)\n    if f[6] != '[]':\n#         print(train_df.iloc[f[0]]['annotations'])\n        bbox_list = ast.literal_eval(f[6])\n        for bbox in bbox_list:\n#             bbox = ast.literal_eval(bbox)\n            if bbox['height'] + bbox['y'] > 720:\n                bbox['height'] = 720 - bbox['y']\n            annot = {\n                \"category_id\": 1,\n                \"bbox\": [bbox['x'], bbox['y'], bbox['width'], bbox['height']],\n                \"id\": annot_id,\n                \"image_id\": f[0],\n                \"area\": bbox['width'] * bbox['height'],\n                \"segmentation\": [],\n                \"iscrowd\": 0\n            }\n            output_json_dict[\"annotations\"].append(annot)\n            annot_id += 1","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:07:52.010837Z","iopub.execute_input":"2021-11-24T03:07:52.011783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_json_dict['annotations'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('train_dataset.json', 'w') as f:\n    output_json = json.dumps(output_json_dict)\n    f.write(output_json)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}