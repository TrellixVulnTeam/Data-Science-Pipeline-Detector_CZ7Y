{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport torch\nimport importlib\nimport cv2 \nimport pandas as pd\n\nfrom PIL import Image\nfrom IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:10:23.570772Z","iopub.execute_input":"2021-12-25T02:10:23.5712Z","iopub.status.idle":"2021-12-25T02:10:25.52873Z","shell.execute_reply.started":"2021-12-25T02:10:23.571097Z","shell.execute_reply":"2021-12-25T02:10:25.527748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSTALL YOLOX \n<div class=\"alert alert-warning\" role=\"alert\"><strong>It unfortunately requires a lot of Kaggle enviroment hacking :) due to competition limitation - no internet access during submission.</strong></div>","metadata":{}},{"cell_type":"code","source":"# download required packages - first time when I created database (https://www.kaggle.com/remekkinas/yolox-cots-models) with required moduls for YOLOX\n# don't use this section of code until Kaggle doesn't change something in the environment (!!)\n\n\n#%mkdir /kaggle/working/yolox-dep\n#!pip download pip -d \"/kaggle/working/yolox-dep\"\n#!pip download loguru -d \"/kaggle/working/yolox-dep\"\n#!pip download ninja -d \"/kaggle/working/yolox-dep\"\n#!pip download onnx==\"1.8.1\" -d \"/kaggle/working/yolox-dep\"\n#!pip download onnxruntime==\"1.8.0\" -d \"/kaggle/working/yolox-dep\"\n#!pip download onnxoptimizer>=\"0.2.5\" -d \"/kaggle/working/yolox-dep\"\n#!pip download thop -d \"/kaggle/working/yolox-dep\"\n#!pip download tabulate -d \"/kaggle/working/yolox-dep\"\n#!pip download onnx-simplifier==0.3.5 -d \"/kaggle/working/yolox-dep\"","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-25T02:10:25.531081Z","iopub.execute_input":"2021-12-25T02:10:25.531434Z","iopub.status.idle":"2021-12-25T02:10:25.536471Z","shell.execute_reply.started":"2021-12-25T02:10:25.53139Z","shell.execute_reply":"2021-12-25T02:10:25.535233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy YOLOX and required modules from local repository (Kaggle dataset -> https://www.kaggle.com/remekkinas/yolox-cots-models)\n%cp -r /kaggle/input/yolox-cots-models /kaggle/working/\n%cp -r /kaggle/input/reff-model/best_ckpt.pth /kaggle/working/yolox-cots-models/YOLOX\n%cd /kaggle/working/yolox-cots-models/yolox-dep","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:10:25.538131Z","iopub.execute_input":"2021-12-25T02:10:25.53873Z","iopub.status.idle":"2021-12-25T02:10:48.128035Z","shell.execute_reply.started":"2021-12-25T02:10:25.538687Z","shell.execute_reply":"2021-12-25T02:10:48.126853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install YOLOX required modules\n\n!pip install pip-21.3.1-py3-none-any.whl -f ./ --no-index\n!pip install loguru-0.5.3-py3-none-any.whl -f ./ --no-index\n!pip install ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl -f ./ --no-index\n!pip install onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl -f ./ --no-index\n!pip install onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl -f ./ --no-index\n!pip install onnxoptimizer-0.2.6-cp37-cp37m-manylinux2014_x86_64.whl -f ./ --no-index\n!pip install thop-0.0.31.post2005241907-py3-none-any.whl -f ./ --no-index\n!pip install tabulate-0.8.9-py3-none-any.whl -f ./ --no-index\n#!pip install onnx-simplifier-0.3.6.tar.gz -f ./ --no-index","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-25T02:10:48.132846Z","iopub.execute_input":"2021-12-25T02:10:48.133166Z","iopub.status.idle":"2021-12-25T02:12:21.439415Z","shell.execute_reply.started":"2021-12-25T02:10:48.133131Z","shell.execute_reply":"2021-12-25T02:12:21.438366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install YOLOX\n%cd /kaggle/working/yolox-cots-models/YOLOX\n!pip install -r requirements.txt\n!pip install -v -e . ","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-25T02:12:21.442964Z","iopub.execute_input":"2021-12-25T02:12:21.443282Z","iopub.status.idle":"2021-12-25T02:13:43.29017Z","shell.execute_reply.started":"2021-12-25T02:12:21.443249Z","shell.execute_reply":"2021-12-25T02:13:43.289158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install CocoAPI tool\n%cd /kaggle/working/yolox-cots-models/yolox-dep/cocoapi/PythonAPI\n\n!make\n!make install\n!python setup.py install","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-25T02:13:43.292323Z","iopub.execute_input":"2021-12-25T02:13:43.292645Z","iopub.status.idle":"2021-12-25T02:14:05.864379Z","shell.execute_reply.started":"2021-12-25T02:13:43.292582Z","shell.execute_reply":"2021-12-25T02:14:05.863107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pycocotools","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:05.866831Z","iopub.execute_input":"2021-12-25T02:14:05.867178Z","iopub.status.idle":"2021-12-25T02:14:05.875887Z","shell.execute_reply.started":"2021-12-25T02:14:05.867133Z","shell.execute_reply":"2021-12-25T02:14:05.874673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TEST MODEL - MAKE INFERENCE ON SAMPLE DATA\n","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/yolox-cots-models/YOLOX\n\nCHECKPOINT_FILE = 'best_ckpt.pth'","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:05.87755Z","iopub.execute_input":"2021-12-25T02:14:05.877913Z","iopub.status.idle":"2021-12-25T02:14:05.89768Z","shell.execute_reply.started":"2021-12-25T02:14:05.877873Z","shell.execute_reply":"2021-12-25T02:14:05.896348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config_file_template = '''\n\n# #!/usr/bin/env python3\n# # -*- coding:utf-8 -*-\n# # Copyright (c) Megvii, Inc. and its affiliates.\n\n# import os\n\n# from yolox.exp import Exp as MyExp\n\n\n# class Exp(MyExp):\n#     def __init__(self):\n#         super(Exp, self).__init__()\n#         self.depth = 1\n#         self.width = 1\n#         self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n#         self.num_classes = 1\n\n# '''\n\nconfig_file_template = '''\n\n#!/usr/bin/env python3\n# -*- coding:utf-8 -*-\n# Copyright (c) Megvii, Inc. and its affiliates.\n\nimport os\n\nfrom yolox.exp import Exp as MyExp\n\n\nclass Exp(MyExp):\n    def __init__(self):\n        super(Exp, self).__init__()\n        self.depth = 1\n        self.width = 1\n        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n        \n        # Define yourself dataset path\n        self.data_dir = \"dataset/images\"\n        self.train_ann = \"train.json\"\n        self.val_ann = \"valid.json\"\n\n        self.num_classes = 1\n\n        self.max_epoch = 20\n        self.data_num_workers = 2\n        self.eval_interval = 1\n        \n        self.mosaic_prob = 1.0\n        self.mixup_prob = 1.0\n        self.hsv_prob = 1.0\n        self.flip_prob = 0.5\n        self.no_aug_epochs = 2\n        \n        self.input_size = (800, 1280)\n        self.mosaic_scale = (0.5, 1.5)\n        self.random_size = (10, 20)\n        self.test_size = (800, 1280)\n\n'''\n\nwith open('cots_config5.py', 'w') as f:\n    f.write(config_file_template)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:05.899949Z","iopub.execute_input":"2021-12-25T02:14:05.900526Z","iopub.status.idle":"2021-12-25T02:14:05.909629Z","shell.execute_reply.started":"2021-12-25T02:14:05.90048Z","shell.execute_reply":"2021-12-25T02:14:05.908499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from yolox.utils import postprocess\nfrom yolox.data.data_augment import ValTransform\n\nCOCO_CLASSES = (\n  \"starfish\",\n)\n\n# get YOLOX experiment\ncurrent_exp = importlib.import_module('cots_config5')\nexp = current_exp.Exp()\nprint(exp)\n# set inference parameters\ntest_size = (800, 1280)\nnum_classes = 1\nconfthre = 0.1\nnmsthre = 0.45\n\n\n# get YOLOX model\nmodel = exp.get_model()\nmodel.cuda()\nmodel.eval()\n\n# get custom trained checkpoint\nckpt_file = \"best_ckpt.pth\"\nckpt = torch.load(ckpt_file, map_location=\"cpu\")\nmodel.load_state_dict(ckpt[\"model\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:05.915216Z","iopub.execute_input":"2021-12-25T02:14:05.915923Z","iopub.status.idle":"2021-12-25T02:14:10.925421Z","shell.execute_reply.started":"2021-12-25T02:14:05.915873Z","shell.execute_reply":"2021-12-25T02:14:10.924454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def yolox_inference(img, model, test_size): \n    bboxes = []\n    bbclasses = []\n    scores = []\n    \n    preproc = ValTransform(legacy = False)\n\n    tensor_img, _ = preproc(img, None, test_size)\n    tensor_img = torch.from_numpy(tensor_img).unsqueeze(0)\n    tensor_img = tensor_img.float()\n    tensor_img = tensor_img.cuda()\n\n    with torch.no_grad():\n        outputs = model(tensor_img)\n        outputs = postprocess(\n                    outputs, num_classes, confthre,\n                    nmsthre, class_agnostic=True\n                )\n\n    if outputs[0] is None:\n        return [], [], []\n    \n    outputs = outputs[0].cpu()\n    bboxes = outputs[:, 0:4]\n\n    bboxes /= min(test_size[0] / img.shape[0], test_size[1] / img.shape[1])\n    bbclasses = outputs[:, 6]\n    scores = outputs[:, 4] * outputs[:, 5]\n    \n    return bboxes, bbclasses, scores","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:10.927051Z","iopub.execute_input":"2021-12-25T02:14:10.927566Z","iopub.status.idle":"2021-12-25T02:14:10.940231Z","shell.execute_reply.started":"2021-12-25T02:14:10.92752Z","shell.execute_reply":"2021-12-25T02:14:10.939077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, classes_dict):\n    for i in range(len(bboxes)):\n            box = bboxes[i]\n            cls_id = int(bbclasses[i])\n            score = scores[i]\n            if score < confthre:\n                continue\n            x0 = int(box[0])\n            y0 = int(box[1])\n            x1 = int(box[2])\n            y1 = int(box[3])\n\n            cv2.rectangle(img, (x0, y0), (x1, y1), (0, 255, 0), 2)\n            cv2.putText(img, '{}:{:.1f}%'.format(classes_dict[cls_id], score * 100), (x0, y0 - 3), cv2.FONT_HERSHEY_PLAIN, 0.8, (0,255,0), thickness = 1)\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:10.941667Z","iopub.execute_input":"2021-12-25T02:14:10.942753Z","iopub.status.idle":"2021-12-25T02:14:10.954251Z","shell.execute_reply.started":"2021-12-25T02:14:10.94271Z","shell.execute_reply":"2021-12-25T02:14:10.95321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_IMAGE_PATH = \"/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/9674.jpg\"\nimg = cv2.imread(TEST_IMAGE_PATH)\ndef RecoverHE(sceneRadiance):\n    for i in range(3):\n        sceneRadiance[:, :, i] =  cv2.equalizeHist(sceneRadiance[:, :, i])\n    return sceneRadiance\nimg=RecoverHE(img)\n# Get predictions\nbboxes, bbclasses, scores = yolox_inference(img, model, test_size)\n\n# Draw predictions\nout_image = draw_yolox_predictions(img, bboxes, scores, bbclasses, confthre, COCO_CLASSES)\n\n# Since we load image using OpenCV we have to convert it \nout_image = cv2.cvtColor(out_image, cv2.COLOR_BGR2RGB)\ndisplay(Image.fromarray(out_image))","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:10.955935Z","iopub.execute_input":"2021-12-25T02:14:10.95637Z","iopub.status.idle":"2021-12-25T02:14:16.551851Z","shell.execute_reply.started":"2021-12-25T02:14:10.956324Z","shell.execute_reply":"2021-12-25T02:14:16.550702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SUBMIT PREDICTION TO COMPETITION","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:16.55315Z","iopub.execute_input":"2021-12-25T02:14:16.553487Z","iopub.status.idle":"2021-12-25T02:14:16.562903Z","shell.execute_reply.started":"2021-12-25T02:14:16.553441Z","shell.execute_reply":"2021-12-25T02:14:16.561827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\n\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()  ","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:16.564847Z","iopub.execute_input":"2021-12-25T02:14:16.565519Z","iopub.status.idle":"2021-12-25T02:14:16.596673Z","shell.execute_reply.started":"2021-12-25T02:14:16.565474Z","shell.execute_reply":"2021-12-25T02:14:16.595623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_dict = {\n    'id': [],\n    'prediction_string': [],\n}\n\nfor (image_np, sample_prediction_df) in iter_test:\n    image_np=RecoverHE(image_np[:,:,::-1])\n    bboxes, bbclasses, scores = yolox_inference(image_np, model, test_size)\n    \n    predictions = []\n    for i in range(len(bboxes)):\n        box = bboxes[i]\n        cls_id = int(bbclasses[i])\n        score = scores[i]\n        if score < confthre:\n            continue\n        x_min = int(box[0])\n        y_min = int(box[1])\n        x_max = int(box[2])\n        y_max = int(box[3])\n        \n        bbox_width = x_max - x_min\n        bbox_height = y_max - y_min\n        \n        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n    \n    prediction_str = ' '.join(predictions)\n    sample_prediction_df['annotations'] = prediction_str\n    env.predict(sample_prediction_df)\n\n    print('Prediction:', prediction_str)","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:16.598199Z","iopub.execute_input":"2021-12-25T02:14:16.598888Z","iopub.status.idle":"2021-12-25T02:14:17.229248Z","shell.execute_reply.started":"2021-12-25T02:14:16.59885Z","shell.execute_reply":"2021-12-25T02:14:17.228181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('submission.csv')\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-25T02:14:17.231105Z","iopub.execute_input":"2021-12-25T02:14:17.231441Z","iopub.status.idle":"2021-12-25T02:14:17.253603Z","shell.execute_reply.started":"2021-12-25T02:14:17.231398Z","shell.execute_reply":"2021-12-25T02:14:17.252658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\" role=\"alert\">\n    Find this notebook helpful? :) Please give me a vote ;) Thank you\n </div>","metadata":{}}]}