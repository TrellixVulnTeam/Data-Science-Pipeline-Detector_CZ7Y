{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-23T18:31:40.104008Z","iopub.execute_input":"2022-01-23T18:31:40.104642Z","iopub.status.idle":"2022-01-23T18:31:48.472313Z","shell.execute_reply.started":"2022-01-23T18:31:40.104538Z","shell.execute_reply":"2022-01-23T18:31:48.468185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train MetaData**","metadata":{}},{"cell_type":"markdown","source":"**Exploring**","metadata":{}},{"cell_type":"code","source":"train_csv_path = '/kaggle/input/tensorflow-great-barrier-reef/train.csv'\ntrain_df = pd.read_csv(train_csv_path)\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.474333Z","iopub.execute_input":"2022-01-23T18:31:48.474685Z","iopub.status.idle":"2022-01-23T18:31:48.542742Z","shell.execute_reply.started":"2022-01-23T18:31:48.474646Z","shell.execute_reply":"2022-01-23T18:31:48.542199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Video frames in sequence wrt each video\n#Creating df of each video\n\nvideo0 = train_df[train_df['video_id']==0]\nvideo1 = train_df[train_df['video_id'] ==1]\nvideo2 = train_df[train_df['video_id'] == 2]","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.543752Z","iopub.execute_input":"2022-01-23T18:31:48.544266Z","iopub.status.idle":"2022-01-23T18:31:48.556234Z","shell.execute_reply.started":"2022-01-23T18:31:48.544234Z","shell.execute_reply":"2022-01-23T18:31:48.555426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Each video has frames in sequence\nvideo0 = video0.sort_values(by=['video_frame'])\nvideo1 = video1.sort_values(by=['video_frame'])\nvideo2 = video2.sort_values(by=['video_frame'])","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.558421Z","iopub.execute_input":"2022-01-23T18:31:48.558944Z","iopub.status.idle":"2022-01-23T18:31:48.565775Z","shell.execute_reply.started":"2022-01-23T18:31:48.558909Z","shell.execute_reply":"2022-01-23T18:31:48.565163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video0","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.566979Z","iopub.execute_input":"2022-01-23T18:31:48.567591Z","iopub.status.idle":"2022-01-23T18:31:48.584929Z","shell.execute_reply.started":"2022-01-23T18:31:48.567549Z","shell.execute_reply":"2022-01-23T18:31:48.583987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video1","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.586014Z","iopub.execute_input":"2022-01-23T18:31:48.586308Z","iopub.status.idle":"2022-01-23T18:31:48.598765Z","shell.execute_reply.started":"2022-01-23T18:31:48.586283Z","shell.execute_reply":"2022-01-23T18:31:48.598193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video2","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.599741Z","iopub.execute_input":"2022-01-23T18:31:48.600204Z","iopub.status.idle":"2022-01-23T18:31:48.611122Z","shell.execute_reply.started":"2022-01-23T18:31:48.600176Z","shell.execute_reply":"2022-01-23T18:31:48.610379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Annotations**","metadata":{}},{"cell_type":"code","source":"#Percentage of no annotations in video\ndef no_annot_perc(df):\n    no_annot = sum(df['annotations'] == '[]')\n    total = len(df)\n    \n    percentage = (no_annot/total)*100\n    print(f\"Percentage of no annotations in video {df.iloc[0,0]}: {round(percentage,2)} \")","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.612255Z","iopub.execute_input":"2022-01-23T18:31:48.612454Z","iopub.status.idle":"2022-01-23T18:31:48.622898Z","shell.execute_reply.started":"2022-01-23T18:31:48.61243Z","shell.execute_reply":"2022-01-23T18:31:48.622251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_annot_perc(video0)\nno_annot_perc(video1)\nno_annot_perc(video2)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.62505Z","iopub.execute_input":"2022-01-23T18:31:48.625283Z","iopub.status.idle":"2022-01-23T18:31:48.640316Z","shell.execute_reply.started":"2022-01-23T18:31:48.625255Z","shell.execute_reply":"2022-01-23T18:31:48.639479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Majority of frames of each video contains no annotations","metadata":{}},{"cell_type":"markdown","source":"**Individual Frames with annotations**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport ast\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image,ImageDraw\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.642505Z","iopub.execute_input":"2022-01-23T18:31:48.642956Z","iopub.status.idle":"2022-01-23T18:31:48.852963Z","shell.execute_reply.started":"2022-01-23T18:31:48.642923Z","shell.execute_reply":"2022-01-23T18:31:48.852214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot single image from Df\ndef plot_image(df,im_id):\n    #video_id\n    vid_id = df.iloc[im_id,0]\n    frame_number = df.iloc[im_id,2]\n    \n    vid_path = f\"/kaggle/input/tensorflow-great-barrier-reef/train_images/video_{vid_id}\"\n    img_file = f\"{frame_number}.jpg\"\n    \n    img_path = os.path.join(vid_path,img_file)\n    \n    annotations = df.iloc[im_id,5]\n    \n    if annotations == \"[]\":\n        #img = cv2.imread(img_path)\n        #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        img = Image.open(img_path)\n        \n    else:\n        annotations = ast.literal_eval(annotations)\n        img = Image.open(img_path)\n        #img = cv2.imread(img_path)\n        #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        \n        length = len(annotations)\n        for i in range(len(annotations)):\n            obj = annotations[i]\n            x1 = obj['x']\n            y1 = obj['y']\n            x2 = x1 + obj['width']\n            y2 = y1 + obj['height']\n            \n            #cv2.rectangle(img,(x1,x2),(x2,y2),color=(255,0,0),thickness=2)\n            \n            img1 = ImageDraw.Draw(img)\n            img1.rectangle([x1,y1,x2,y2],outline=\"red\",width=2)\n            \n            print(f\"Height: {obj['height']}, Width: {obj['width']}\")\n            print(f\"Number of Detections: {length}\")\n            print(f\"X1,y1: {(x1,y1)} X2,y2: {(x2,y2)}\")\n            \n        \n            \n    \n    #pil_img = Image.fromarray(img)\n    \n    #plt.figure(figsize=(16,10))\n    #plt.imshow(img)\n    return img\n    \n            \n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.854288Z","iopub.execute_input":"2022-01-23T18:31:48.854489Z","iopub.status.idle":"2022-01-23T18:31:48.862574Z","shell.execute_reply.started":"2022-01-23T18:31:48.854466Z","shell.execute_reply":"2022-01-23T18:31:48.861654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = plot_image(video0,70)\nimg","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:48.863958Z","iopub.execute_input":"2022-01-23T18:31:48.864763Z","iopub.status.idle":"2022-01-23T18:31:49.373542Z","shell.execute_reply.started":"2022-01-23T18:31:48.864723Z","shell.execute_reply":"2022-01-23T18:31:49.372572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = plot_image(video0,106)\nimg","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:49.374871Z","iopub.execute_input":"2022-01-23T18:31:49.375094Z","iopub.status.idle":"2022-01-23T18:31:49.748145Z","shell.execute_reply.started":"2022-01-23T18:31:49.375067Z","shell.execute_reply":"2022-01-23T18:31:49.74728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Creating VideoStream**","metadata":{}},{"cell_type":"code","source":"!mkdir \"/kaggle/working/videos\"","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:49.749225Z","iopub.execute_input":"2022-01-23T18:31:49.749441Z","iopub.status.idle":"2022-01-23T18:31:50.542341Z","shell.execute_reply.started":"2022-01-23T18:31:49.749414Z","shell.execute_reply":"2022-01-23T18:31:50.541257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:50.544049Z","iopub.execute_input":"2022-01-23T18:31:50.544354Z","iopub.status.idle":"2022-01-23T18:31:50.549069Z","shell.execute_reply.started":"2022-01-23T18:31:50.544315Z","shell.execute_reply":"2022-01-23T18:31:50.548247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = f\"/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/0.jpg\"\nimg = cv2.imread(image_path)\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:31:50.550238Z","iopub.execute_input":"2022-01-23T18:31:50.5507Z","iopub.status.idle":"2022-01-23T18:31:50.611425Z","shell.execute_reply.started":"2022-01-23T18:31:50.55067Z","shell.execute_reply":"2022-01-23T18:31:50.61085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def videostream(df):\n    video_id = df.iloc[0,0]\n    \n    images_path = f\"/kaggle/input/tensorflow-great-barrier-reef/train_images/video_{video_id}/*.jpg\"\n    video_dest = f\"/kaggle/working/videos/video_{video_id}.avi\"\n    \n    #Video frames\n    images = glob(images_path)\n    images.sort()\n    frame_height,  frame_width, channels = cv2.imread(images[0]).shape\n    fps = 24\n    \n    #Creating Video Writer\n    fourcc = cv2.VideoWriter_fourcc(*'MPEG')\n    vid_writer = cv2.VideoWriter(video_dest,fourcc,fps,(frame_width,frame_height))\n    \n    ##Draw annotations on frames\n    for i in range(len(images)):\n        img_path = images[i]\n        annotations = df.iloc[i,5]\n        \n        if annotations == \"[]\":\n            img  = Image.open(img_path)\n            img = np.array(img)\n            \n        else:\n            annotations = ast.literal_eval(annotations)\n            img = Image.open(img_path)\n            \n            \n            length = len(annotations)\n            for j in range(length):\n                obj = annotations[j]\n                x1 = obj['x']\n                y1 = obj['y']\n                x2 = x1 + obj['width']\n                y2 = y1 + obj['height']\n                \n                img1 = ImageDraw.Draw(img)\n                img1.rectangle([x1,y1,x2,y2],outline=\"red\",width=2)\n                \n            img = np.array(img)\n            \n        vid_writer.write(img)\n        \n    vid_writer.release()\n                \n                ","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:33:03.960958Z","iopub.execute_input":"2022-01-23T18:33:03.961497Z","iopub.status.idle":"2022-01-23T18:33:03.970644Z","shell.execute_reply.started":"2022-01-23T18:33:03.961455Z","shell.execute_reply":"2022-01-23T18:33:03.969922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"videostream(video0)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T18:33:06.901485Z","iopub.execute_input":"2022-01-23T18:33:06.902084Z","iopub.status.idle":"2022-01-23T18:39:26.446314Z","shell.execute_reply.started":"2022-01-23T18:33:06.90204Z","shell.execute_reply":"2022-01-23T18:39:26.44485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install ffmpeg for video compression\n%cd /kaggle/working\n\n! tar xvf ../input/ffmpegstaticbuild/ffmpeg-git-amd64-static.tar.xz\n\nimport subprocess\n\nFFMPEG_BIN = \"./ffmpeg-git-20220108-amd64-static/ffmpeg\"","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:05:30.572274Z","iopub.execute_input":"2022-01-23T19:05:30.572605Z","iopub.status.idle":"2022-01-23T19:05:35.716707Z","shell.execute_reply.started":"2022-01-23T19:05:30.572571Z","shell.execute_reply":"2022-01-23T19:05:35.715893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\nAVI2MP4 = \"-ac 2 -b:v 2000k -c:a aac -c:v libx264 -b:a 160k -vprofile high -bf 0 -strict experimental -f mp4\"\n\ncommand = f\"{FFMPEG_BIN} -i /kaggle/working/videos/video_0.avi {AVI2MP4} /kaggle/working/videos/videos_0.mp4\"\nsubprocess.call(command, shell=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:06:06.631909Z","iopub.execute_input":"2022-01-23T19:06:06.632203Z","iopub.status.idle":"2022-01-23T19:08:36.564757Z","shell.execute_reply.started":"2022-01-23T19:06:06.632174Z","shell.execute_reply":"2022-01-23T19:08:36.563745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\nfrom base64 import b64encode\n\ndef play(filename):\n    html = ''\n    video = open(filename,'rb').read()\n    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n    return HTML(html)\n\nplay(\"/kaggle/working/videos/videos_0.mp4\")","metadata":{"execution":{"iopub.status.busy":"2022-01-23T19:15:57.31186Z","iopub.execute_input":"2022-01-23T19:15:57.31303Z","iopub.status.idle":"2022-01-23T19:15:59.664663Z","shell.execute_reply.started":"2022-01-23T19:15:57.312981Z","shell.execute_reply":"2022-01-23T19:15:59.663937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notebook Incomplete.\n\nCV2 seems to write video in BGR(Not certain)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}