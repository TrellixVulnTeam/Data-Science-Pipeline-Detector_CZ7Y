{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\n\nIn this problem we need find COTS starfish in the great barrier reef,\nbut we don't need implementate an object detection model like YOLO\nwhere the user can see the object in a bounding box, otherwise we only\nneed show the scientics if in these place there are COTS starfish. For\nthis reason, I believe that is better show a canvas where appear the\nstarfish.\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:19.103846Z","iopub.execute_input":"2021-12-12T10:44:19.104201Z","iopub.status.idle":"2021-12-12T10:44:19.131985Z","shell.execute_reply.started":"2021-12-12T10:44:19.104096Z","shell.execute_reply":"2021-12-12T10:44:19.131304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# REQUIRED\n\nfrom IPython.display import display, clear_output\nfrom PIL import Image, ImageDraw, ImageEnhance\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport ast\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:19.735298Z","iopub.execute_input":"2021-12-12T10:44:19.735658Z","iopub.status.idle":"2021-12-12T10:44:23.738675Z","shell.execute_reply.started":"2021-12-12T10:44:19.735612Z","shell.execute_reply":"2021-12-12T10:44:23.737885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONSTANTS\n\nINPUT_PATH = str('../input/tensorflow-great-barrier-reef')\nIMAGE_SIZE = tuple((int(1280), int(720))) # width x height","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:23.740426Z","iopub.execute_input":"2021-12-12T10:44:23.740765Z","iopub.status.idle":"2021-12-12T10:44:23.745387Z","shell.execute_reply.started":"2021-12-12T10:44:23.740724Z","shell.execute_reply":"2021-12-12T10:44:23.744464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GET THE DATA AND DISPLAY ITS STRUCTURE\n\ntrain_dataset = pd.read_csv(INPUT_PATH + '/train.csv')\nprint(train_dataset)\nprint(\"\\n\")\nprint(train_dataset.info())","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:23.746733Z","iopub.execute_input":"2021-12-12T10:44:23.747484Z","iopub.status.idle":"2021-12-12T10:44:23.827997Z","shell.execute_reply.started":"2021-12-12T10:44:23.747445Z","shell.execute_reply":"2021-12-12T10:44:23.82727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DISPLAY THE DATA\n\nfor video_id in train_dataset['video_id'].unique():\n    print(f'Image ID: {video_id}')\n    print(f'Number of images withou COTS:  {sum(train_dataset[train_dataset[\"video_id\"]==video_id][\"annotations\"] == \"[]\")}')\n    print(f'Number of images with COTS:  {sum(train_dataset[train_dataset[\"video_id\"]==video_id][\"annotations\"] != \"[]\")}')\n    if video_id != 2:\n        print(f'----------------------------------')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:23.829196Z","iopub.execute_input":"2021-12-12T10:44:23.829963Z","iopub.status.idle":"2021-12-12T10:44:23.858372Z","shell.execute_reply.started":"2021-12-12T10:44:23.829923Z","shell.execute_reply":"2021-12-12T10:44:23.857681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT DATA ANNOTATIONS STR to LIST\n\ntrain_dataset['annotations'] = train_dataset['annotations'].apply(ast.literal_eval)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:23.860524Z","iopub.execute_input":"2021-12-12T10:44:23.861116Z","iopub.status.idle":"2021-12-12T10:44:24.316897Z","shell.execute_reply.started":"2021-12-12T10:44:23.861062Z","shell.execute_reply":"2021-12-12T10:44:24.316143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ADD A COLUMN WITH THE IMAGE PATH\n\ntrain_dataset['image_path'] = INPUT_PATH + '/train_images/video_' + train_dataset['video_id'].astype(str) + '/' + train_dataset['video_frame'].astype(str) + \".jpg\"","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:24.318449Z","iopub.execute_input":"2021-12-12T10:44:24.318724Z","iopub.status.idle":"2021-12-12T10:44:24.390914Z","shell.execute_reply.started":"2021-12-12T10:44:24.318688Z","shell.execute_reply":"2021-12-12T10:44:24.390143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ADD A COLUMN WITH THE NUMBER OF BOXES PER IMAGE\n\ntrain_dataset['num_bboxes'] = train_dataset['annotations'].apply(lambda x: len(x))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:24.393415Z","iopub.execute_input":"2021-12-12T10:44:24.393888Z","iopub.status.idle":"2021-12-12T10:44:24.411368Z","shell.execute_reply.started":"2021-12-12T10:44:24.393856Z","shell.execute_reply":"2021-12-12T10:44:24.410533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DISPLAY THE NEW STRUCTURE\n\ntrain_dataset.head(18)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:24.412982Z","iopub.execute_input":"2021-12-12T10:44:24.4137Z","iopub.status.idle":"2021-12-12T10:44:24.43607Z","shell.execute_reply.started":"2021-12-12T10:44:24.413659Z","shell.execute_reply":"2021-12-12T10:44:24.435465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_grid(draw, strides=8):\n    x_lines = int(IMAGE_SIZE[0] // strides)\n    y_lines = int(IMAGE_SIZE[1] // strides)\n    \n    for line in range(x_lines):\n        shape = tuple((((IMAGE_SIZE[0] // x_lines) * line, 0), ((IMAGE_SIZE[0] // x_lines) * line, IMAGE_SIZE[1])))\n        draw.line(shape, fill=\"black\", width=1)\n        \n    for line in range(y_lines):\n        shape = tuple(((0, (IMAGE_SIZE[1] // y_lines) * line), (IMAGE_SIZE[0], (IMAGE_SIZE[1] // y_lines) * line)))\n        draw.line(shape, fill=\"black\", width=1)\n        \ndef draw_bbox(draw, bbox):\n    x, y, width, height = bbox['x'], bbox['y'], bbox['width'], bbox['height']\n    draw.rectangle([x, y, x + width, y + height], width=2, outline='salmon')\n    draw.text([x, y - 10], 'COTS', width=7, fill='salmon')\n    \ndef draw_bboxes(image_path, bboxes, grid=False):\n    image = Image.open(image_path)\n    image = image.resize(IMAGE_SIZE)\n    draw  = ImageDraw.Draw(image)\n    \n    if grid:\n        draw_grid(draw)\n            \n    for bbox in bboxes:\n        draw_bbox(draw, bbox)\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:24.437425Z","iopub.execute_input":"2021-12-12T10:44:24.437853Z","iopub.status.idle":"2021-12-12T10:44:24.449029Z","shell.execute_reply.started":"2021-12-12T10:44:24.437816Z","shell.execute_reply":"2021-12-12T10:44:24.448333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DISPLAY AN IMAGE\n\nIMAGE_TEST_ID = int(19668)\ndisplay(draw_bboxes(train_dataset['image_path'][IMAGE_TEST_ID], train_dataset['annotations'][IMAGE_TEST_ID]))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:24.45047Z","iopub.execute_input":"2021-12-12T10:44:24.450927Z","iopub.status.idle":"2021-12-12T10:44:24.799507Z","shell.execute_reply.started":"2021-12-12T10:44:24.45089Z","shell.execute_reply":"2021-12-12T10:44:24.798542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(draw_bboxes(train_dataset['image_path'][IMAGE_TEST_ID], train_dataset['annotations'][IMAGE_TEST_ID], grid=True))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:24.800582Z","iopub.execute_input":"2021-12-12T10:44:24.800792Z","iopub.status.idle":"2021-12-12T10:44:25.134723Z","shell.execute_reply.started":"2021-12-12T10:44:24.800767Z","shell.execute_reply":"2021-12-12T10:44:25.134071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image)\n    image = tf.cast(image, tf.float32)[..., :3]\n    return ((image.numpy() / 127.5) - 1) # [-1, 1] (height, width, channels)\n\ndef label_image(labels):\n    label_map = np.zeros((IMAGE_SIZE[1] // 8, IMAGE_SIZE[0] // 8, 1))\n    for label in labels:\n        x1, y1, x2, y2 = label['x'] // 8, label['y'] // 8, (label['x'] // 8) + (label['width'] // 8), (label['y'] // 8) + (label['height'] // 8)\n        for y in range((IMAGE_SIZE[1] // 8)):\n            for x in range((IMAGE_SIZE[0] // 8)):\n                if x >= x1 and x <= x2 and y >= y1 and y <= y2:\n                    label_map[y][x][0] = 1.0\n\n    return label_map # [0, 1] (height, width, channels)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:25.136031Z","iopub.execute_input":"2021-12-12T10:44:25.136456Z","iopub.status.idle":"2021-12-12T10:44:25.146356Z","shell.execute_reply.started":"2021-12-12T10:44:25.136421Z","shell.execute_reply":"2021-12-12T10:44:25.145733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(32, 18))\nplt.imshow(label_image(train_dataset['annotations'][IMAGE_TEST_ID]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:25.147662Z","iopub.execute_input":"2021-12-12T10:44:25.148086Z","iopub.status.idle":"2021-12-12T10:44:25.622616Z","shell.execute_reply.started":"2021-12-12T10:44:25.14805Z","shell.execute_reply":"2021-12-12T10:44:25.621948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATASET MAKER\n\n\"\"\"\n\n    In this case, since there is only one possibility (COTS),the tiles\n    in the grid where there a COTS will be activated with a 1 value.\n    \n    Example in a 5x5 matrix where in the rigth side there's a COTS:\n    0 0 0 1 1\n    0 0 0 1 1\n    0 0 1 1 1\n    0 0 0 1 1\n    0 0 0 0 1\n\n\"\"\"\n\ndata = list([])\nfor i, image in enumerate(train_dataset['image_path'][:18]):\n    data.append([load_image(image), label_image(train_dataset['annotations'][i])])\n    \nprint(tf.shape(data[0][0]))\nprint(data[0][1].shape)\nplt.subplots(figsize=(32, 18))\nplt.imshow(data[17][1])\nplt.show()\nplt.subplots(figsize=(32, 18))\nplt.imshow(data[17][0] * 0.5 + 0.5)\nplt.show()\ndisplay(draw_bboxes(train_dataset['image_path'][17], train_dataset['annotations'][17]))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:25.625839Z","iopub.execute_input":"2021-12-12T10:44:25.626591Z","iopub.status.idle":"2021-12-12T10:44:30.960133Z","shell.execute_reply.started":"2021-12-12T10:44:25.62655Z","shell.execute_reply":"2021-12-12T10:44:30.959341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetLoader():\n    def __init__(self, data):\n        self.data = list([])\n        \n        for row in data:\n            self.data.append(row)\n            \n    def shuffle(self):\n        self.data = np.random.shuffle(self.data)\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, i):\n        x = tf.cast(tf.reshape(load_image(self.data['image_path'][i]), (1, IMAGE_SIZE[1], IMAGE_SIZE[0], 3)), tf.float32)\n        y = tf.cast(tf.reshape(label_image(self.data['annotations'][i]), (1, IMAGE_SIZE[1] // 8, IMAGE_SIZE[0] // 8, 1)), tf.float32)\n        b = self.data['num_bboxes'][i]\n        return x, y, b","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNBlock(tf.keras.layers.Layer):\n    def __init__(self, features, **kwargs):\n        super(CNNBlock, self).__init__()\n        self.conv = tf.keras.layers.Conv2D(features, padding='same', kernel_initializer=tf.keras.initializers.Ones(), use_bias=False, **kwargs)\n        self.bn = tf.keras.layers.BatchNormalization()\n        self.leaky = tf.keras.layers.LeakyReLU(0.1)\n\n    def call(self, x):\n        return self.leaky(self.bn(self.conv(x)))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:30.961465Z","iopub.execute_input":"2021-12-12T10:44:30.961841Z","iopub.status.idle":"2021-12-12T10:44:31.871597Z","shell.execute_reply.started":"2021-12-12T10:44:30.961807Z","shell.execute_reply":"2021-12-12T10:44:31.870692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(tf.keras.layers.Layer):\n    def __init__(self, features, num_repeats=1):\n        super(ResidualBlock, self).__init__()\n        self.layers = list([])\n        for repeat in range(num_repeats):\n            self.layers.append(list([\n                CNNBlock(features // 2, kernel_size=1),\n                CNNBlock(features, kernel_size=3),\n            ]))\n\n    def call(self, x):\n        r = x\n        for layer in self.layers:\n            x = layer[0](x)\n            x = layer[1](x)\n\n        return tf.keras.layers.Add()([r, x])","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:31.874848Z","iopub.execute_input":"2021-12-12T10:44:31.8755Z","iopub.status.idle":"2021-12-12T10:44:31.886393Z","shell.execute_reply.started":"2021-12-12T10:44:31.875458Z","shell.execute_reply":"2021-12-12T10:44:31.883352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feture_extractor(**kwargs):\n    inputs = tf.keras.layers.Input((IMAGE_SIZE[1], IMAGE_SIZE[0], 3)) # (height, width, channels)\n\n    x = CNNBlock(features=64, kernel_size=3)(inputs)\n    x = CNNBlock(features=128, kernel_size=3, strides=2)(x)\n    s = x\n    x = ResidualBlock(features=128, num_repeats=2)(x)\n    x = tf.keras.layers.Concatenate()([s, x])\n    x = CNNBlock(features=256, kernel_size=3, strides=2)(x)\n    s = x\n    x = ResidualBlock(features=256, num_repeats=4)(x)\n    x = tf.keras.layers.Concatenate()([s, x])\n    x = CNNBlock(features=512, kernel_size=3, strides=2)(x)\n    s = x\n    x = ResidualBlock(features=512, num_repeats=8)(x)\n    x = tf.keras.layers.Concatenate()([s, x])\n    x = ResidualBlock(features=1024, num_repeats=1)(x)\n\n    outputs = tf.keras.layers.Conv2D(1, kernel_size=2, padding='same', activation='sigmoid', kernel_initializer=tf.keras.initializers.Ones())(x)\n    \n    return tf.keras.models.Model(inputs=inputs, outputs=outputs, **kwargs)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:31.88997Z","iopub.execute_input":"2021-12-12T10:44:31.890259Z","iopub.status.idle":"2021-12-12T10:44:31.907009Z","shell.execute_reply.started":"2021-12-12T10:44:31.890223Z","shell.execute_reply":"2021-12-12T10:44:31.906255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = feture_extractor(name='feature_extractor_model')\nmodel.summary(120)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:31.908503Z","iopub.execute_input":"2021-12-12T10:44:31.908977Z","iopub.status.idle":"2021-12-12T10:44:32.526537Z","shell.execute_reply.started":"2021-12-12T10:44:31.908931Z","shell.execute_reply":"2021-12-12T10:44:32.525785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:32.52786Z","iopub.execute_input":"2021-12-12T10:44:32.528128Z","iopub.status.idle":"2021-12-12T10:44:33.28774Z","shell.execute_reply.started":"2021-12-12T10:44:32.528076Z","shell.execute_reply":"2021-12-12T10:44:33.286972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(1e-4)\nbce = tf.keras.losses.BinaryCrossentropy()\nmse = tf.keras.losses.MeanSquaredError()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:33.289512Z","iopub.execute_input":"2021-12-12T10:44:33.290266Z","iopub.status.idle":"2021-12-12T10:44:33.295816Z","shell.execute_reply.started":"2021-12-12T10:44:33.290222Z","shell.execute_reply":"2021-12-12T10:44:33.295159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(x, y):\n    with tf.GradientTape() as tape:\n        pred = model(x, training=True)\n        _pos = tf.math.reduce_sum((pred + 1e-8) - (y + 1e-8) * tf.math.log((pred + 1e-8)))\n        _bce = bce(y, pred)\n        _mse = mse(y, pred)\n        loss = (1e-4 * _pos) + _bce + _mse\n        grad = tape.gradient(loss, model.trainable_weights)\n        opt.apply_gradients(zip(grad, model.trainable_weights))\n        \n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:33.297873Z","iopub.execute_input":"2021-12-12T10:44:33.298472Z","iopub.status.idle":"2021-12-12T10:44:33.308627Z","shell.execute_reply.started":"2021-12-12T10:44:33.298428Z","shell.execute_reply":"2021-12-12T10:44:33.307698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CHECKPOINT = './'\n\ncheckpoint_prefix = os.path.join(CHECKPOINT, \"ckpt\")\ncheckpoint        = tf.train.Checkpoint(\n    LAST_EPOCH    = tf.Variable(0),\n    model         = model,\n    opt           = opt,\n)\n\nmanager = tf.train.CheckpointManager(checkpoint=checkpoint, directory=CHECKPOINT, max_to_keep=5)\nif manager.latest_checkpoint:\n    checkpoint.restore(manager.latest_checkpoint)\n    print(\"Restaurado de {}\".format(manager.latest_checkpoint))\nelse:\n    print(\"Inicializando desde cero\")\n\ndef update_checkpoint():\n    print(\"Updating checkpoint...\")\n    manager = tf.train.CheckpointManager(checkpoint=checkpoint, directory=CHECKPOINT, max_to_keep=5)\n    checkpoint.save(file_prefix=checkpoint_prefix)\n    if manager.latest_checkpoint:\n        os.remove(manager.latest_checkpoint + '.data-00000-of-00001')\n        os.remove(manager.latest_checkpoint + '.index')\n    print(\"===============================================\\nCheckpoint updated\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:33.310682Z","iopub.execute_input":"2021-12-12T10:44:33.311241Z","iopub.status.idle":"2021-12-12T10:44:33.325995Z","shell.execute_reply.started":"2021-12-12T10:44:33.311205Z","shell.execute_reply":"2021-12-12T10:44:33.324962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Last epoch: {checkpoint.LAST_EPOCH.numpy()}')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:33.327976Z","iopub.execute_input":"2021-12-12T10:44:33.32829Z","iopub.status.idle":"2021-12-12T10:44:33.335114Z","shell.execute_reply.started":"2021-12-12T10:44:33.328253Z","shell.execute_reply":"2021-12-12T10:44:33.334258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decayed_learning_rate(lr, step, ds_len):\n    return lr * 0.875 ** (step / ds_len)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:33.337165Z","iopub.execute_input":"2021-12-12T10:44:33.337776Z","iopub.status.idle":"2021-12-12T10:44:33.342851Z","shell.execute_reply.started":"2021-12-12T10:44:33.337738Z","shell.execute_reply":"2021-12-12T10:44:33.341828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = int(10)\nLOSSES = list([])\n\ndataset_length = int(len(train_dataset['image_path']))\nfor epoch in range(EPOCHS):\n    for i, image_path in enumerate(train_dataset['image_path']):\n        b = train_dataset['num_bboxes'][i]\n        x = tf.cast(tf.reshape(load_image(train_dataset['image_path'][i]), (1, IMAGE_SIZE[1], IMAGE_SIZE[0], 3)), tf.float32)\n        y = tf.cast(tf.reshape(label_image(train_dataset['annotations'][i]), (1, IMAGE_SIZE[1] // 8, IMAGE_SIZE[0] // 8, 1)), tf.float32)\n\n        loss = train_step(x, y)\n\n        clear_output(wait=True)\n        print(f'Epoch: [{(epoch + 1)}/{EPOCHS}] - Step: [{(i + 1)}/{dataset_length}] - Nº bboxes: {b} - Loss: {loss.numpy()}')\n#         opt.lr = decayed_learning_rate(opt.lr.numpy(), i, dataset_length)\n#         print(f'LR: {opt.lr.numpy()}')\n#         LOSSES.append([i, loss.numpy()])\n        \n    update_checkpoint()\n#     break","metadata":{"execution":{"iopub.status.busy":"2021-12-12T10:44:33.344649Z","iopub.execute_input":"2021-12-12T10:44:33.345224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.subplots(figsize=(36, 6))\n# plt.plot([i for i, l in LOSSES], [l for i, l in LOSSES])\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs  = load_image(train_dataset['image_path'][35])\noutputs = model(tf.reshape(inputs, (1, IMAGE_SIZE[1], IMAGE_SIZE[0], 3)))\ninputs  = draw_bboxes(train_dataset['image_path'][35], train_dataset['annotations'][35])\ntarget  = label_image(train_dataset['annotations'][35])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Input')\ndisplay(inputs)\nprint('Predicted')\nplt.subplots(figsize=(32, 18))\nplt.imshow(outputs[0])\nplt.show()\nprint('Target')\nplt.subplots(figsize=(32, 18))\nplt.imshow(target)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}