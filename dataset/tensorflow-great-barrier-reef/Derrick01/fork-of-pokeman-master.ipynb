{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# import libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport ast\nimport os\nimport json\nimport pandas as pd\nimport torch\nimport importlib\nimport cv2 \n\nfrom shutil import copyfile\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nfrom sklearn.model_selection import GroupKFold\nfrom PIL import Image\nfrom string import Template\nfrom IPython.display import display\n\nTRAIN_PATH = '/kaggle/input/tensorflow-great-barrier-reef'","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:43:05.902341Z","iopub.execute_input":"2022-01-26T11:43:05.90272Z","iopub.status.idle":"2022-01-26T11:43:09.735909Z","shell.execute_reply.started":"2022-01-26T11:43:05.902595Z","shell.execute_reply":"2022-01-26T11:43:09.734929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# install YOLOX","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/Megvii-BaseDetection/YOLOX -q\n\n%cd YOLOX\n!pip install -U pip && pip install -r requirements.txt\n!pip install -v -e . \n!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:43:09.737994Z","iopub.execute_input":"2022-01-26T11:43:09.738309Z","iopub.status.idle":"2022-01-26T11:45:15.357703Z","shell.execute_reply.started":"2022-01-26T11:43:09.738257Z","shell.execute_reply":"2022-01-26T11:45:15.356537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare dataset for YOLOX to train\nThis section is taken from  notebook created by Awsaf [Great-Barrier-Reef: YOLOv5 train](https://www.kaggle.com/awsaf49/great-barrier-reef-yolov5-train)","metadata":{}},{"cell_type":"code","source":"def get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_path(row):\n    row['image_path'] = f'{TRAIN_PATH}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    return row\ndf = pd.read_csv(\"/kaggle/input/tensorflow-great-barrier-reef/train.csv\")\ndf.head(5)\n# Taken only annotated photos\ndf[\"num_bbox\"] = df['annotations'].apply(lambda x: str.count(x, 'x'))\ndf_train = df[df[\"num_bbox\"]>0]\n\n#Annotations \ndf_train['annotations'] = df_train['annotations'].progress_apply(lambda x: ast.literal_eval(x))\ndf_train['bboxes'] = df_train.annotations.progress_apply(get_bbox)\n\n#Images resolution\ndf_train[\"width\"] = 1280\ndf_train[\"height\"] = 720\n\n#Path of images\ndf_train = df_train.progress_apply(get_path, axis=1)\n\nkf = GroupKFold(n_splits = 5) \ndf_train = df_train.reset_index(drop=True)\ndf_train['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(kf.split(df_train, y = df_train.video_id.tolist(), groups=df_train.sequence)):\n    df_train.loc[val_idx, 'fold'] = fold\n\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:45:15.36011Z","iopub.execute_input":"2022-01-26T11:45:15.360488Z","iopub.status.idle":"2022-01-26T11:45:20.761592Z","shell.execute_reply.started":"2022-01-26T11:45:15.360439Z","shell.execute_reply":"2022-01-26T11:45:20.760379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create directory for storage ","metadata":{}},{"cell_type":"code","source":"HOME_DIR = '/kaggle/working/' \nDATASET_PATH = 'dataset/images'\n\n!mkdir {HOME_DIR}dataset\n!mkdir {HOME_DIR}{DATASET_PATH}\n!mkdir {HOME_DIR}{DATASET_PATH}/train2017\n!mkdir {HOME_DIR}{DATASET_PATH}/val2017\n!mkdir {HOME_DIR}{DATASET_PATH}/annotations","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:45:20.764604Z","iopub.execute_input":"2022-01-26T11:45:20.765057Z","iopub.status.idle":"2022-01-26T11:45:24.600149Z","shell.execute_reply.started":"2022-01-26T11:45:20.764995Z","shell.execute_reply":"2022-01-26T11:45:24.598845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SELECTED_FOLD = 4\n\nfor i in tqdm(range(len(df_train))):\n    row = df_train.loc[i]\n    if row.fold != SELECTED_FOLD:\n        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/train2017/{row.image_id}.jpg')\n    else:\n        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/val2017/{row.image_id}.jpg') \nprint(f'Number of training files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}/train2017/\"))}')\nprint(f'Number of validation files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}/val2017/\"))}')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:45:24.602404Z","iopub.execute_input":"2022-01-26T11:45:24.602792Z","iopub.status.idle":"2022-01-26T11:46:31.949962Z","shell.execute_reply.started":"2022-01-26T11:45:24.602725Z","shell.execute_reply":"2022-01-26T11:46:31.94885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  CREATE COCO ANNOTATION FILES","metadata":{}},{"cell_type":"code","source":"def save_annot_json(json_annotation, filename):\n    with open(filename, 'w') as f:\n        output_json = json.dumps(json_annotation)\n        f.write(output_json)\nannotion_id = 0","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:46:31.951988Z","iopub.execute_input":"2022-01-26T11:46:31.952649Z","iopub.status.idle":"2022-01-26T11:46:31.959352Z","shell.execute_reply.started":"2022-01-26T11:46:31.952578Z","shell.execute_reply":"2022-01-26T11:46:31.95821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset2coco(df, dest_path):\n    \n    global annotion_id\n    \n    annotations_json = {\n        \"info\": [],\n        \"licenses\": [],\n        \"categories\": [],\n        \"images\": [],\n        \"annotations\": []\n    }\n    \n    info = {\n        \"year\": \"2021\",\n        \"version\": \"1\",\n        \"description\": \"COTS dataset - COCO format\",\n        \"contributor\": \"\",\n        \"url\": \"https://kaggle.com\",\n        \"date_created\": \"2021-1-24\"\n    }\n    annotations_json[\"info\"].append(info)\n    \n    lic = {\n            \"id\": 1,\n            \"url\": \"\",\n            \"name\": \"Unknown\"\n        }\n    annotations_json[\"licenses\"].append(lic)\n\n    classes = {\"id\": 0, \"name\": \"starfish\", \"supercategory\": \"none\"}\n\n    annotations_json[\"categories\"].append(classes)\n\n    \n    for ann_row in df.itertuples():\n            \n        images = {\n            \"id\": ann_row[0],\n            \"license\": 1,\n            \"file_name\": ann_row.image_id + '.jpg',\n            \"height\": ann_row.height,\n            \"width\": ann_row.width,\n            \"date_captured\": \"2021-1-24T15:01:26+00:00\"\n        }\n        \n        annotations_json[\"images\"].append(images)\n        \n        bbox_list = ann_row.bboxes\n        \n        for bbox in bbox_list:\n            b_width = bbox[2]\n            b_height = bbox[3]\n            \n            # some boxes in COTS are outside the image height and width\n            if (bbox[0] + bbox[2] > 1280):\n                b_width = bbox[0] - 1280 \n            if (bbox[1] + bbox[3] > 720):\n                b_height = bbox[1] - 720 \n                \n            image_annotations = {\n                \"id\": annotion_id,\n                \"image_id\": ann_row[0],\n                \"category_id\": 0,\n                \"bbox\": [bbox[0], bbox[1], b_width, b_height],\n                \"area\": bbox[2] * bbox[3],\n                \"segmentation\": [],\n                \"iscrowd\": 0\n            }\n            \n            annotion_id += 1\n            annotations_json[\"annotations\"].append(image_annotations)\n        \n        \n    print(f\"Dataset COTS annotation to COCO json format completed! Files: {len(df)}\")\n    return annotations_json\n\n# Convert COTS dataset to JSON COCO\ntrain_annot_json = dataset2coco(df_train[df_train.fold != SELECTED_FOLD], f\"{HOME_DIR}{DATASET_PATH}/train2017/\")\nval_annot_json = dataset2coco(df_train[df_train.fold == SELECTED_FOLD], f\"{HOME_DIR}{DATASET_PATH}/val2017/\")\n\n# Save converted annotations\nsave_annot_json(train_annot_json, f\"{HOME_DIR}{DATASET_PATH}/annotations/train.json\")\nsave_annot_json(val_annot_json, f\"{HOME_DIR}{DATASET_PATH}/annotations/valid.json\")","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:46:31.960522Z","iopub.execute_input":"2022-01-26T11:46:31.960786Z","iopub.status.idle":"2022-01-26T11:46:32.094742Z","shell.execute_reply.started":"2022-01-26T11:46:31.960755Z","shell.execute_reply":"2022-01-26T11:46:32.093686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download a pretrain model","metadata":{"execution":{"iopub.status.busy":"2022-01-24T12:47:01.625794Z","iopub.execute_input":"2022-01-24T12:47:01.626311Z","iopub.status.idle":"2022-01-24T12:47:02.400524Z","shell.execute_reply.started":"2022-01-24T12:47:01.626264Z","shell.execute_reply":"2022-01-24T12:47:02.399234Z"}}},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:46:32.096481Z","iopub.execute_input":"2022-01-26T11:46:32.097059Z","iopub.status.idle":"2022-01-26T11:46:32.870027Z","shell.execute_reply.started":"2022-01-26T11:46:32.097011Z","shell.execute_reply":"2022-01-26T11:46:32.868935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sh = 'wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth'\nMODEL_FILE = 'yolox_s.pth'\nwith open('script.sh', 'w') as file:\n    file.write(sh)\n\n!bash script.sh","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:46:32.873128Z","iopub.execute_input":"2022-01-26T11:46:32.873949Z","iopub.status.idle":"2022-01-26T11:46:56.397749Z","shell.execute_reply.started":"2022-01-26T11:46:32.873894Z","shell.execute_reply":"2022-01-26T11:46:56.396408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find a configuration file","metadata":{}},{"cell_type":"code","source":"config_file_template = '''\n#!/usr/bin/env python3\n# -*- coding:utf-8 -*-\n# Copyright (c) Megvii, Inc. and its affiliates.\n\nimport os\n\nfrom yolox.exp import Exp as MyExp\n\n\nclass Exp(MyExp):\n    def __init__(self):\n        super(Exp, self).__init__()\n        self.depth = 1.0\n        self.width = 1.0\n        self.exp_name = os.path.split(os.path.realpath(__file__))[1].split(\".\")[0]\n        \n        # Define yourself dataset path\n        self.data_dir = \"/kaggle/working/dataset/images\"\n        self.train_ann = \"train.json\"\n        self.val_ann = \"valid.json\"\n\n        self.num_classes = 1\n\n        self.max_epoch = $max_epoch\n        self.data_num_workers = 4\n        self.eval_interval = 20  \n        \n        self.mosaic_prob = 1.0\n        self.mixup_prob = 1.0\n        self.hsv_prob = 1.0\n        self.flip_prob = 0.5\n        self.no_aug_epochs = 2\n        \n        self.input_size = (960, 960)\n        #self.mosaic_scale = (0.5, 1.5)\n        self.random_size = (10, 20)\n        self.test_size = (960, 960)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:46:56.401988Z","iopub.execute_input":"2022-01-26T11:46:56.402368Z","iopub.status.idle":"2022-01-26T11:46:56.410812Z","shell.execute_reply.started":"2022-01-26T11:46:56.402336Z","shell.execute_reply":"2022-01-26T11:46:56.409678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PIPELINE_CONFIG_PATH='cots_config.py'\n\npipeline = Template(config_file_template).substitute(max_epoch = 20)\n\nwith open(PIPELINE_CONFIG_PATH, 'w') as f:\n    f.write(pipeline)\n    \n# ./yolox/data/datasets/voc_classes.py\n\nvoc_cls = '''\nVOC_CLASSES = (\n  \"starfish\",\n)\n'''\nwith open('./yolox/data/datasets/voc_classes.py', 'w') as f:\n    f.write(voc_cls)\n\n# ./yolox/data/datasets/coco_classes.py\n\ncoco_cls = '''\nCOCO_CLASSES = (\n  \"starfish\",\n)\n'''\nwith open('./yolox/data/datasets/coco_classes.py', 'w') as f:\n    f.write(coco_cls)\n\n# check if everything is ok    \n!more ./yolox/data/datasets/coco_classes.py","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:46:56.413459Z","iopub.execute_input":"2022-01-26T11:46:56.416335Z","iopub.status.idle":"2022-01-26T11:46:57.180265Z","shell.execute_reply.started":"2022-01-26T11:46:56.416299Z","shell.execute_reply":"2022-01-26T11:46:57.179068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train","metadata":{}},{"cell_type":"markdown","source":"# install pytorch","metadata":{}},{"cell_type":"code","source":"!pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:46:57.182151Z","iopub.execute_input":"2022-01-26T11:46:57.182456Z","iopub.status.idle":"2022-01-26T11:50:15.036996Z","shell.execute_reply.started":"2022-01-26T11:46:57.182406Z","shell.execute_reply":"2022-01-26T11:50:15.035885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:54:03.152646Z","iopub.execute_input":"2022-01-26T11:54:03.153624Z","iopub.status.idle":"2022-01-26T11:54:03.979175Z","shell.execute_reply.started":"2022-01-26T11:54:03.153527Z","shell.execute_reply":"2022-01-26T11:54:03.977874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo kill -9 <pid>","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:54:19.997085Z","iopub.execute_input":"2022-01-26T11:54:19.997418Z","iopub.status.idle":"2022-01-26T11:54:20.761778Z","shell.execute_reply.started":"2022-01-26T11:54:19.997383Z","shell.execute_reply":"2022-01-26T11:54:20.760666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp ./tools/train.py ./\n!python train.py \\\n    -f cots_config.py \\\n    -d 1 \\\n    -b 32 \\\n    --fp16 \\\n    -o \\\n    -c {MODEL_FILE}   ","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:54:27.788047Z","iopub.execute_input":"2022-01-26T11:54:27.788364Z","iopub.status.idle":"2022-01-26T11:56:28.194152Z","shell.execute_reply.started":"2022-01-26T11:54:27.78833Z","shell.execute_reply":"2022-01-26T11:56:28.192827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r YOLOX_outputs /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-01-26T11:52:22.686929Z","iopub.execute_input":"2022-01-26T11:52:22.687306Z","iopub.status.idle":"2022-01-26T11:52:23.526023Z","shell.execute_reply.started":"2022-01-26T11:52:22.687255Z","shell.execute_reply":"2022-01-26T11:52:23.524612Z"},"trusted":true},"execution_count":null,"outputs":[]}]}