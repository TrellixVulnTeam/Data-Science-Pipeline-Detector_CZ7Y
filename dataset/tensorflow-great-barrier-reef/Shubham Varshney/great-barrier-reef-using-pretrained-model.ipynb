{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport sys\nimport tensorflow as tf\nimport time\n\n# Import the library that is used to submit the prediction result.\nINPUT_DIR = '../input/tensorflow-great-barrier-reef/'\nsys.path.insert(0, INPUT_DIR)\nimport greatbarrierreef","metadata":{"execution":{"iopub.status.busy":"2021-11-25T11:01:17.744933Z","iopub.execute_input":"2021-11-25T11:01:17.745262Z","iopub.status.idle":"2021-11-25T11:01:17.751379Z","shell.execute_reply.started":"2021-11-25T11:01:17.745222Z","shell.execute_reply":"2021-11-25T11:01:17.750184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the TensorFlow COTS detection model into memory and define some util functions for running inference.","metadata":{"execution":{"iopub.status.busy":"2021-11-23T03:32:24.29052Z","iopub.execute_input":"2021-11-23T03:32:24.290814Z","iopub.status.idle":"2021-11-23T03:32:24.295257Z","shell.execute_reply.started":"2021-11-23T03:32:24.290785Z","shell.execute_reply":"2021-11-23T03:32:24.294012Z"}}},{"cell_type":"code","source":"MODEL_DIR = '../input/cots-detection-w-tensorflow-object-detection-api/cots_efficientdet_d0'\nstart_time = time.time()\ntf.keras.backend.clear_session()\ndetect_fn_tf_odt = tf.saved_model.load(os.path.join(os.path.join(MODEL_DIR, 'output'), 'saved_model'))\nend_time = time.time()\nelapsed_time = end_time - start_time\nprint('Elapsed time: ' + str(elapsed_time) + 's')","metadata":{"execution":{"iopub.status.busy":"2021-11-25T11:01:21.633098Z","iopub.execute_input":"2021-11-25T11:01:21.633353Z","iopub.status.idle":"2021-11-25T11:01:48.754724Z","shell.execute_reply.started":"2021-11-25T11:01:21.633323Z","shell.execute_reply":"2021-11-25T11:01:48.753889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image_into_numpy_array(path):\n    \"\"\"Load an image from file into a numpy array.\n\n    Puts image into numpy array to feed into tensorflow graph.\n    Note that by convention we put it into a numpy array with shape\n    (height, width, channels), where channels=3 for RGB.\n\n    Args:\n    path: a file path (this can be local or on colossus)\n\n    Returns:\n    uint8 numpy array with shape (img_height, img_width, 3)\n    \"\"\"\n    img_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(io.BytesIO(img_data))\n    (im_width, im_height) = image.size\n    \n    return np.array(image.getdata()).reshape(\n      (im_height, im_width, 3)).astype(np.uint8)\n\ndef detect(image_np):\n    \"\"\"Detect COTS from a given numpy image.\"\"\"\n\n    input_tensor = np.expand_dims(image_np, 0)\n    start_time = time.time()\n    detections = detect_fn_tf_odt(input_tensor)\n    return detections","metadata":{"execution":{"iopub.status.busy":"2021-11-25T11:01:48.770971Z","iopub.execute_input":"2021-11-25T11:01:48.771201Z","iopub.status.idle":"2021-11-25T11:01:48.787348Z","shell.execute_reply.started":"2021-11-25T11:01:48.771167Z","shell.execute_reply":"2021-11-25T11:01:48.786541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run inference and create the submission data","metadata":{}},{"cell_type":"code","source":"env = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","metadata":{"execution":{"iopub.status.busy":"2021-11-25T11:01:57.893116Z","iopub.execute_input":"2021-11-25T11:01:57.893789Z","iopub.status.idle":"2021-11-25T11:01:57.924093Z","shell.execute_reply.started":"2021-11-25T11:01:57.893741Z","shell.execute_reply":"2021-11-25T11:01:57.922936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DETECTION_THRESHOLD = 0.17\n\nsubmission_dict = {\n    'id': [],\n    'prediction_string': [],\n}\n\nfor (image_np, sample_prediction_df) in iter_test:\n    print(\"=============================================\")\n    height, width, _ = image_np.shape\n    \n    # Run object detection using the TensorFlow model.\n    detections = detect(image_np)\n    \n    # Parse the detection result and generate a prediction string.\n    num_detections = detections['num_detections'][0].numpy().astype(np.int32)\n    print(num_detections)\n    predictions = []\n    for index in range(num_detections):\n        score = detections['detection_scores'][0][index].numpy()\n        print(\"score \" , score)\n        if score < DETECTION_THRESHOLD:\n            continue\n\n        bbox = detections['detection_boxes'][0][index].numpy()\n        print(\"bbox \")\n        y_min = int(bbox[0] * height)\n        x_min = int(bbox[1] * width)\n        y_max = int(bbox[2] * height)\n        x_max = int(bbox[3] * width)\n        \n        bbox_width = x_max - x_min\n        bbox_height = y_max - y_min\n        \n        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n    \n    # Generate the submission data.\n    prediction_str = ' '.join(predictions)\n    sample_prediction_df['annotations'] = prediction_str\n    print(sample_prediction_df)\n    env.predict(sample_prediction_df)\n\n    print('Prediction:', prediction_str)","metadata":{"execution":{"iopub.status.busy":"2021-11-25T11:01:59.16346Z","iopub.execute_input":"2021-11-25T11:01:59.164024Z","iopub.status.idle":"2021-11-25T11:01:59.173687Z","shell.execute_reply.started":"2021-11-25T11:01:59.163984Z","shell.execute_reply":"2021-11-25T11:01:59.172814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"REFFERENCE NOTEBOOK - https://www.kaggle.com/lonnieqin/inference-using-efficientdet-d0-model-tensorflow","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}