{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:40:46.909991Z","iopub.execute_input":"2021-11-29T06:40:46.910343Z","iopub.status.idle":"2021-11-29T06:40:46.91636Z","shell.execute_reply.started":"2021-11-29T06:40:46.910299Z","shell.execute_reply":"2021-11-29T06:40:46.915546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\ntest = pd.read_csv('../input/tensorflow-great-barrier-reef/test.csv')\nss = pd.read_csv('../input/tensorflow-great-barrier-reef/example_sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:40:49.104561Z","iopub.execute_input":"2021-11-29T06:40:49.104846Z","iopub.status.idle":"2021-11-29T06:40:49.183787Z","shell.execute_reply.started":"2021-11-29T06:40:49.104817Z","shell.execute_reply":"2021-11-29T06:40:49.18237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:40:51.285151Z","iopub.execute_input":"2021-11-29T06:40:51.285447Z","iopub.status.idle":"2021-11-29T06:40:51.296136Z","shell.execute_reply.started":"2021-11-29T06:40:51.285419Z","shell.execute_reply":"2021-11-29T06:40:51.294995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Example of using the submission package.","metadata":{}},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (pixel_array, sample_prediction_df) in iter_test:\n    break\n    sample_prediction_df['annotations'] = '0.5 0 0 100 100'  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions\n\nfig, ax = plt.subplots(figsize=(15, 10))\nplt.imshow(pixel_array)\nplt.show()\n\n(train['image_id'] == train['video_id'].astype('str') + '-' + train['video_frame'].astype('str')).mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:41:05.643886Z","iopub.execute_input":"2021-11-29T06:41:05.644496Z","iopub.status.idle":"2021-11-29T06:41:06.907349Z","shell.execute_reply.started":"2021-11-29T06:41:05.644445Z","shell.execute_reply":"2021-11-29T06:41:06.906552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('ggplot')\nfig, ax = plt.subplots(figsize=(15, 5))\nfor sequence, d in train.query('video_id == 0').groupby('sequence'):\n    d['sequence_frame'].plot(ax=ax, label=f'Sequence {sequence}')\nax.set_title('Video 0: Sequence Frame vs Video Frame')\nax.set_xlabel('Video Frame')\nax.set_ylabel('Sequence Frame')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:41:19.094726Z","iopub.execute_input":"2021-11-29T06:41:19.095009Z","iopub.status.idle":"2021-11-29T06:41:19.55561Z","shell.execute_reply.started":"2021-11-29T06:41:19.09498Z","shell.execute_reply":"2021-11-29T06:41:19.554233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:41:50.566899Z","iopub.execute_input":"2021-11-29T06:41:50.567194Z","iopub.status.idle":"2021-11-29T06:41:50.586744Z","shell.execute_reply.started":"2021-11-29T06:41:50.567162Z","shell.execute_reply":"2021-11-29T06:41:50.585379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How many Annotations per Frame?\nIs it different in each video?\nIs it different in each sequence within a video?","metadata":{}},{"cell_type":"code","source":"train['n_annotations'] = train['annotations'].apply(lambda x: len(eval(x)))\n\ntrain.groupby(['video_id','sequence'])['sequence_frame'].max() \\\n    .sort_values().plot(kind='barh', figsize=(12, 5),\n                        title='Length of Sequences')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T06:42:14.316319Z","iopub.execute_input":"2021-11-29T06:42:14.31696Z","iopub.status.idle":"2021-11-29T06:42:14.988111Z","shell.execute_reply.started":"2021-11-29T06:42:14.316923Z","shell.execute_reply":"2021-11-29T06:42:14.987103Z"},"trusted":true},"execution_count":null,"outputs":[]}]}