{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport gc\nimport glob\nimport io\nimport IPython\nimport json\nimport numpy as np\nimport pathlib\nimport pandas as pd\nimport sys\nimport cv2\nimport math\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nimport tensorflow as tf\n\nINPUT_DIR = '/kaggle/input/tensorflow-great-barrier-reef/'\nsys.path.insert(0, INPUT_DIR)\nimport greatbarrierreef","metadata":{"papermill":{"duration":1.526137,"end_time":"2021-11-19T08:39:54.022253","exception":false,"start_time":"2021-11-19T08:39:52.496116","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-20T10:09:37.955664Z","iopub.execute_input":"2021-12-20T10:09:37.956067Z","iopub.status.idle":"2021-12-20T10:09:37.974194Z","shell.execute_reply.started":"2021-12-20T10:09:37.956008Z","shell.execute_reply":"2021-12-20T10:09:37.972666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\nprint(tf.test.is_gpu_available())\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:37.977745Z","iopub.execute_input":"2021-12-20T10:09:37.978777Z","iopub.status.idle":"2021-12-20T10:09:37.998288Z","shell.execute_reply.started":"2021-12-20T10:09:37.978727Z","shell.execute_reply":"2021-12-20T10:09:37.997215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install TF Object Detection API & Download Pre-Trained Model","metadata":{"papermill":{"duration":0.021045,"end_time":"2021-11-19T08:38:07.403389","exception":false,"start_time":"2021-11-19T08:38:07.382344","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Created folders:\n1. **api**: for storing tensorflow object detection model api files\n2. **pre-trained-models**: for storing downloaded pretrained models including checkpoints and config\n3. **my_models**: for storing trained model and new config\n4. **data**: for storing tfrecords files and `label_map.pbtxt` file","metadata":{}},{"cell_type":"markdown","source":"## Create Configs and Folders ","metadata":{}},{"cell_type":"code","source":"CUSTOM_MODEL_NAME = 'my_efficientdet_d2' \nPRETRAINED_MODEL_NAME = 'efficientdet_d2_coco17_tpu-32'\nPRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz'\nLABEL_MAP_NAME = 'label_map.pbtxt'","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:38.000493Z","iopub.execute_input":"2021-12-20T10:09:38.00158Z","iopub.status.idle":"2021-12-20T10:09:38.008018Z","shell.execute_reply.started":"2021-12-20T10:09:38.001532Z","shell.execute_reply":"2021-12-20T10:09:38.00679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folders = {\n    'APIMODEL_PATH': 'api',\n    'DATA_PATH': 'data',\n    'MODEL_PATH': 'my_models',\n    'PRETRAINED_MODEL_PATH': 'pre-trained-models',\n    'CHECKPOINT_PATH': os.path.join('my_models',CUSTOM_MODEL_NAME), \n    'OUTPUT_PATH': os.path.join('my_models',CUSTOM_MODEL_NAME, 'export')\n}\n\nfiles = {\n    'PIPELINE_CONFIG':os.path.join(folders['MODEL_PATH'], CUSTOM_MODEL_NAME, 'pipeline.config'),\n    'LABELMAP': os.path.join(folders['DATA_PATH'], LABEL_MAP_NAME),\n    'VERIFICATION_SCRIPT': os.path.join(folders['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py'),\n    'TRAINING_SCRIPT': os.path.join(folders['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py'),\n    'EXPORTER_SCRIPT': os.path.join(folders['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py')\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:38.010849Z","iopub.execute_input":"2021-12-20T10:09:38.012411Z","iopub.status.idle":"2021-12-20T10:09:38.025228Z","shell.execute_reply.started":"2021-12-20T10:09:38.012362Z","shell.execute_reply":"2021-12-20T10:09:38.023699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for path in folders.values():\n    if not os.path.exists(path):\n        !mkdir -p {path}","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:38.029452Z","iopub.execute_input":"2021-12-20T10:09:38.03118Z","iopub.status.idle":"2021-12-20T10:09:39.723107Z","shell.execute_reply.started":"2021-12-20T10:09:38.03089Z","shell.execute_reply":"2021-12-20T10:09:39.721771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download Pre-Trained Model","metadata":{}},{"cell_type":"code","source":"!wget {PRETRAINED_MODEL_URL} -P {folders['PRETRAINED_MODEL_PATH']}\n!cd {folders['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:39.725526Z","iopub.execute_input":"2021-12-20T10:09:39.725893Z","iopub.status.idle":"2021-12-20T10:09:43.639283Z","shell.execute_reply.started":"2021-12-20T10:09:39.725855Z","shell.execute_reply":"2021-12-20T10:09:43.638098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download TFODT API","metadata":{}},{"cell_type":"code","source":"if not os.path.exists(os.path.join(folders['APIMODEL_PATH'], 'research', 'object_detection')):\n    !git clone https://github.com/tensorflow/models {folders['APIMODEL_PATH']}","metadata":{"execution":{"iopub.status.busy":"2021-12-20T10:09:43.641362Z","iopub.execute_input":"2021-12-20T10:09:43.642119Z","iopub.status.idle":"2021-12-20T10:09:43.650602Z","shell.execute_reply.started":"2021-12-20T10:09:43.642067Z","shell.execute_reply":"2021-12-20T10:09:43.649163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install TFODT API","metadata":{}},{"cell_type":"code","source":"%%bash\ncd api/research\n\nprotoc object_detection/protos/*.proto --python_out=.\n\n# cp object_detection/packages/tf2/setup.py .\nwget https://storage.googleapis.com/odml-dataset/others/setup.py\npip install -q --user .\n\npip install -q imagesize","metadata":{"papermill":{"duration":79.154739,"end_time":"2021-11-19T08:39:52.448588","exception":false,"start_time":"2021-11-19T08:38:33.293849","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-20T10:09:43.652389Z","iopub.execute_input":"2021-12-20T10:09:43.653565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! python {files['VERIFICATION_SCRIPT']}","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import TFODT API","metadata":{}},{"cell_type":"code","source":"from object_detection.utils import dataset_util, label_map_util, config_util\n\nfrom object_detection.utils import visualization_utils as viz_utils\nfrom object_detection.builders import model_builder\nfrom object_detection.protos import pipeline_pb2\nfrom google.protobuf import text_format\nimport imagesize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data","metadata":{"papermill":{"duration":0.04958,"end_time":"2021-11-19T08:39:54.895616","exception":false,"start_time":"2021-11-19T08:39:54.846036","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Split Dataset","metadata":{}},{"cell_type":"code","source":"TRAINING_RATIO = 0.8\ndata_df = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'))","metadata":{"papermill":{"duration":1.175804,"end_time":"2021-11-19T08:40:48.461269","exception":false,"start_time":"2021-11-19T08:40:47.285465","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_index = int(TRAINING_RATIO * len(data_df))\n\nwhile data_df.iloc[split_index - 1].sequence == data_df.iloc[split_index].sequence:\n    split_index += 1\n\ntrain_data_df = data_df.iloc[:split_index].sample(frac=1).reset_index(drop=True)\nval_data_df = data_df.iloc[split_index:].sample(frac=1).reset_index(drop=True)\n\ntrain_positive_count = len(train_data_df[train_data_df.annotations != '[]'])\nval_positive_count = len(val_data_df[val_data_df.annotations != '[]'])\n\nprint('Training ratio (all samples):', f\"{(float(len(train_data_df)) / (len(train_data_df) + len(val_data_df))):.2f}\")\nprint('Training ratio (positive samples):', f\"{(float(train_positive_count) / (train_positive_count + val_positive_count)):.2f}\")","metadata":{"papermill":{"duration":1.175804,"end_time":"2021-11-19T08:40:48.461269","exception":false,"start_time":"2021-11-19T08:40:47.285465","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df = train_data_df[train_data_df.annotations != '[]'].reset_index()\nprint('Number of positive images used for training:', len(train_data_df))\nval_data_df = val_data_df[val_data_df.annotations != '[]'].reset_index()\nprint('Number of positive images used for validation:', len(val_data_df))","metadata":{"papermill":{"duration":0.240932,"end_time":"2021-11-19T08:40:48.926677","exception":false,"start_time":"2021-11-19T08:40:48.685745","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"code","source":"def load_image_into_np(path):\n    img_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(io.BytesIO(img_data))\n    (im_width, im_height) = image.size\n    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n\ndef plot_detections(image_np, boxes, classes, scores, category_index, unc=True):\n    image_np_with_annotations = image_np.copy()\n    viz_utils.visualize_boxes_and_labels_on_image_array(image_np_with_annotations,\n                                                       boxes,\n                                                       classes,\n                                                       scores,\n                                                       category_index,\n                                                       use_normalized_coordinates=unc,\n                                                       min_score_thresh=0.05)\n    return image_np_with_annotations\n\ndef get_image_with_annotation(df, idx):\n    row = df.iloc[idx]\n    img = load_image_into_np(row.image_path)\n    boxes = np.asarray(row.bboxes)\n    num_boxes = len(boxes)\n    classes = np.ones(num_boxes, dtype='int32')\n    scores = np.ones(num_boxes)\n    category_index = {1: {'id': 1, 'name': 'COTS'}}\n    unc = True\n    \n    img = plot_detections(img, boxes, classes, scores, category_index, unc)\n    return img\n\n\ndef get_bbox(row):\n    bboxes = []\n    annotations = json.loads(row.annotations.replace(\"'\", '\"'))\n    for annotation in annotations:\n            bboxes.append([annotation['y'] / row.height, \n                           annotation['x'] / row.width,\n                           (annotation['y'] + annotation['height']) / row.height, \n                           (annotation['x'] + annotation['width']) / row.width])\n    row[\"bboxes\"] = bboxes\n    return row\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row[\"image_path\"])\n    return row\n\ndef get_path(row):\n    row[\"image_path\"] = os.path.join(INPUT_DIR, \"train_images\", f'video_{row.video_id}', f'{row.video_frame}.jpg')\n    return row","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add Some Useful Columns","metadata":{}},{"cell_type":"code","source":"train_data_df = train_data_df.progress_apply(get_path,axis=1)\nval_data_df = val_data_df.progress_apply(get_path,axis=1)\n\ntrain_data_df = train_data_df.progress_apply(get_imgsize,axis=1)\nval_data_df = val_data_df.progress_apply(get_imgsize,axis=1)\n\ntrain_data_df = train_data_df.progress_apply(get_bbox,axis=1)\nval_data_df = val_data_df.progress_apply(get_bbox,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize One Sample","metadata":{"papermill":{"duration":0.196154,"end_time":"2021-11-19T08:40:49.387603","exception":false,"start_time":"2021-11-19T08:40:49.191449","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%matplotlib inline\nidx = np.random.randint(0,train_data_df.shape[0]) \nimg = get_image_with_annotation(train_data_df, idx)\nplt.figure(figsize=(20,10))\nplt.imshow(img)\nplt.title(f\"Image Index {idx}\")\nplt.show()","metadata":{"papermill":{"duration":0.694191,"end_time":"2021-11-19T08:40:50.258113","exception":false,"start_time":"2021-11-19T08:40:49.563922","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create TFRecord Files","metadata":{"papermill":{"duration":0.115403,"end_time":"2021-11-19T08:40:50.494003","exception":false,"start_time":"2021-11-19T08:40:50.3786","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def create_tf_example(row):\n    with tf.io.gfile.GFile(row[\"image_path\"], 'rb') as fid:\n        encoded_jpg = fid.read()\n\n    height = row[\"height\"]\n    width = row[\"width\"]\n    filename = f'{row[\"video_id\"]}:{row[\"video_frame\"]}'.encode('utf8') \n    image_format = 'jpeg'.encode() \n\n    bb = row[\"bboxes\"]\n    \n    xmins = [i[1] for i in bb]\n    xmaxs = [i[3] for i in bb]     \n    ymins = [i[0] for i in bb] \n    ymaxs = [i[2] for i in bb] \n            \n    classes_text = ['COTS'.encode() for i in bb]\n    classes_id = [1 for i in bb] \n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n      'image/height': dataset_util.int64_feature(height),\n      'image/width': dataset_util.int64_feature(width),\n      'image/filename': dataset_util.bytes_feature(filename),\n      'image/source_id': dataset_util.bytes_feature(filename),\n      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n      'image/format': dataset_util.bytes_feature(image_format),\n      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n      'image/object/class/label': dataset_util.int64_list_feature(classes_id),\n    }))\n    \n    return tf_example.SerializeToString()\n\n\ndef convert_to_tfrecord(data_df, filename):\n    with tf.io.TFRecordWriter(os.path.join(folders[\"DATA_PATH\"],filename)) as writer:\n        for _, row in tqdm(data_df.iterrows()):\n            tf_example = create_tf_example(row)\n            writer.write(tf_example)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convert_to_tfrecord(train_data_df, 'train.tfrec')\nconvert_to_tfrecord(val_data_df, 'valid.tfrec')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Label Map","metadata":{}},{"cell_type":"code","source":"labels = [{'name':'COTS', 'id':1}]\n\nwith open(files['LABELMAP'], 'w') as f:\n    for label in labels:\n        f.write('item { \\n')\n        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n        f.write('\\tid:{}\\n'.format(label['id']))\n        f.write('}\\n')\n        \ncategory_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test TFRecords","metadata":{}},{"cell_type":"code","source":"# def deserialize_example(serialized_string):\n#     feature={\n#       'image/height': tf.io.FixedLenFeature([], tf.int64),\n#       'image/width': tf.io.FixedLenFeature([], tf.int64),\n#       'image/filename': tf.io.FixedLenFeature([], tf.string),\n#       'image/source_id': tf.io.FixedLenFeature([], tf.string),\n#       'image/encoded': tf.io.FixedLenFeature([], tf.string),\n#       'image/format': tf.io.FixedLenFeature([], tf.string),\n#       'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n#       'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n#       'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n#       'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n#       'image/object/class/text': tf.io.VarLenFeature(tf.string),\n#       'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n#     }\n\n    \n#     parsed_record = tf.io.parse_single_example(serialized_string, feature)\n#     image = tf.io.decode_jpeg(parsed_record['image/encoded'])\n#     xmins = tf.sparse.to_dense(parsed_record['image/object/bbox/xmin']).numpy()\n#     xmaxs = tf.sparse.to_dense(parsed_record['image/object/bbox/xmax']).numpy()\n#     ymins = tf.sparse.to_dense(parsed_record['image/object/bbox/ymin']).numpy()\n#     ymaxs = tf.sparse.to_dense(parsed_record['image/object/bbox/ymax']).numpy()\n    \n#     bb = [[ymins[i], xmins[i], ymaxs[i], xmaxs[i]] for i in range(len(xmins))]\n\n#     return image, bb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_set = tf.data.TFRecordDataset(os.path.join(folders[\"DATA_PATH\"],\"train.tfrec\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ds = train_set.take(1)\n# for sample in ds:\n#     image, bb = deserialize_example(sample)\n    \n# boxes = np.asarray(bb)\n# num_boxes = len(boxes)\n\n# img = plot_detections(np.array(image), boxes, np.ones(num_boxes, dtype='int32'), np.ones(num_boxes), category_index)\n# plt.figure(figsize=(20,10))\n# plt.imshow(img)\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del train_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config Model","metadata":{}},{"cell_type":"code","source":"!cp {os.path.join(folders['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(folders['CHECKPOINT_PATH'])}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\nconfig","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\nwith tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n    proto_str = f.read()                                                                                                                                                                                                                                          \n    text_format.Merge(proto_str, pipeline_config)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline_config.model.ssd.num_classes = len(labels)\npipeline_config.model.ssd.image_resizer.keep_aspect_ratio_resizer.min_dimension = 1280\npipeline_config.model.ssd.image_resizer.keep_aspect_ratio_resizer.max_dimension = 1280\npipeline_config.train_config.data_augmentation_options[1].random_scale_crop_and_pad_to_square.output_size = 1280\npipeline_config.model.ssd.box_coder.faster_rcnn_box_coder.y_scale = 10.0\npipeline_config.model.ssd.box_coder.faster_rcnn_box_coder.x_scale = 10.0\npipeline_config.model.ssd.box_coder.faster_rcnn_box_coder.height_scale = 5.0\npipeline_config.model.ssd.box_coder.faster_rcnn_box_coder.width_scale = 5.0\npipeline_config.train_config.batch_size = 2\n# pipeline_config.train_config.fine_tune_checkpoint = os.path.join(folders['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\npipeline_config.train_config.fine_tune_checkpoint = \"../input/tfodtoutput/export7-D2-Plus10_000/export/checkpoint/ckpt-0\"\npipeline_config.train_config.use_bfloat16 = False\npipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\npipeline_config.train_config.sync_replicas = False\npipeline_config.train_config.replicas_to_aggregate = 1\npipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.learning_rate_base = 1e-3\npipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.warmup_learning_rate = 1e-4\npipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.total_steps = 10000\npipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.warmup_steps = 2000\npipeline_config.model.ssd.post_processing.batch_non_max_suppression.score_threshold = 1e-8\npipeline_config.model.ssd.post_processing.batch_non_max_suppression.iou_threshold = 0.5\npipeline_config.train_config.num_steps = 10000\npipeline_config.train_input_reader.label_map_path= files['LABELMAP']\npipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(folders['DATA_PATH'], 'train.tfrec')]\npipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\npipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(folders['DATA_PATH'], 'valid.tfrec')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \nwith tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n    f.write(config_text)   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat {files[\"PIPELINE_CONFIG\"]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"!python {files['TRAINING_SCRIPT']}\\\n    --model_dir={folders['CHECKPOINT_PATH']}\\\n    --pipeline_config_path={files['PIPELINE_CONFIG']}\\\n    --num_train_steps=10000","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate Model","metadata":{}},{"cell_type":"code","source":"!python {files['TRAINING_SCRIPT']}\\\n    --model_dir={folders['CHECKPOINT_PATH']}\\\n    --pipeline_config_path={files['PIPELINE_CONFIG']}\\\n    --checkpoint_dir={folders['CHECKPOINT_PATH']}\\\n    --eval_timeout=0 ","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Export Model","metadata":{}},{"cell_type":"code","source":"!python {files['EXPORTER_SCRIPT']}\\\n    --input_type image_tensor \\\n    --pipeline_config_path={files['PIPELINE_CONFIG']} \\\n    --trained_checkpoint_dir={folders['CHECKPOINT_PATH']} \\\n    --output_directory={folders['OUTPUT_PATH']}","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model from Checkpoints","metadata":{}},{"cell_type":"code","source":"!ls {folders[\"CHECKPOINT_PATH\"]}/ckpt-*.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\ndetection_model = model_builder.build(model_config=configs['model'], is_training=False)\n\nckps = glob.glob(folders[\"CHECKPOINT_PATH\"]+\"/ckpt-*.index\")\nckps.sort(key=os.path.getmtime)\n\nckp_file = ckps[-1][:-6]\nprint(ckp_file)\nckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\nckpt.restore(ckp_file).expect_partial()\n\ndef detect_fn(image):\n    image, shapes = detection_model.preprocess(image)\n    prediction_dict = detection_model.predict(image, shapes)\n    detections = detection_model.postprocess(prediction_dict, shapes)\n    return detections","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{"papermill":{"duration":0.24428,"end_time":"2021-11-19T13:57:07.485159","exception":false,"start_time":"2021-11-19T13:57:07.240879","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_image_pred(df, idx):\n\n    image_np = load_image_into_np(df.iloc[idx].image_path)\n    \n    height, width, _ = image_np.shape\n    input_tensor = tf.cast(np.expand_dims(image_np, 0), tf.float32)\n    detections = detect_fn(input_tensor)\n\n    num_detections = detections['num_detections'][0].numpy().astype(np.int32) \n    bboxes = []\n    scores = []\n    classes = []\n    DETECTION_THRESHOLD = 0.15\n    \n    for i in range(num_detections):\n        score = detections['detection_scores'][0][i].numpy()\n        \n        if score < DETECTION_THRESHOLD:\n            continue\n\n        bboxes.append(list(detections['detection_boxes'][0][i].numpy()))\n        scores.append(score)\n        classes.append(1)\n    img = plot_detections(image_np, np.array(bboxes), np.array(classes), np.array(scores), category_index, unc=True)\n    return img\n\ncnt = 10\nfig, ax = plt.subplots(cnt, 2, figsize = (20,40))\nfor row in range(cnt):\n    idx = np.random.randint(0,val_data_df.shape[0])\n    gt = get_image_with_annotation(val_data_df, idx)\n    pred = get_image_pred(val_data_df, idx)\n    \n    ax[row][0].imshow(gt)\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f\"GT_{idx}\")\n    \n    ax[row][1].imshow(pred)\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f\"PR_{idx}\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip ./my_model.zip -r {folders[\"OUTPUT_PATH\"]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./my_models.zip\"> Download File my_model.zip </a>","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"env = greatbarrierreef.make_env()  \niter_test = env.iter_test() ","metadata":{"papermill":{"duration":0.354385,"end_time":"2021-11-19T13:57:37.442493","exception":false,"start_time":"2021-11-19T13:57:37.088108","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DETECTION_THRESHOLD = 0.15\n\nfor (image_np, df) in iter_test:\n    height, width, _ = image_np.shape\n    \n    input_tensor = tf.cast(np.expand_dims(image_np, 0), tf.float32)\n    detections = detect_fn(input_tensor)\n    \n    num_detections = detections['num_detections'][0].numpy().astype(np.int32)\n    predictions = []\n    \n    for index in range(num_detections):\n        score = detections['detection_scores'][0][index].numpy()\n\n        if score < DETECTION_THRESHOLD:\n            continue\n\n        bbox = detections['detection_boxes'][0][index].numpy()\n        y_min = int(bbox[0] * height)\n        x_min = int(bbox[1] * width)\n        y_max = int(bbox[2] * height)\n        x_max = int(bbox[3] * width)\n\n        bbox_width = x_max - x_min\n        bbox_height = y_max - y_min\n\n        predictions.append(f'{score:.2f} {x_min} {y_min} {bbox_width} {bbox_height}')\n        \n        \n    prediction_str = ' '.join(predictions)\n    df['annotations'] = prediction_str\n    env.predict(df)\n\nsub_df = pd.read_csv('submission.csv')\nsub_df.head()","metadata":{"papermill":{"duration":4.526271,"end_time":"2021-11-19T13:57:42.213925","exception":false,"start_time":"2021-11-19T13:57:37.687654","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf ./api\n!rm -rf ./data\n!rm -rf ./pre-trained-models","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}