{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# # for dirname, _, filenames in os.walk('/kaggle/input'):\n# #     for filename in filenames:\n# #         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-02T04:47:08.708566Z","iopub.execute_input":"2022-02-02T04:47:08.70878Z","iopub.status.idle":"2022-02-02T04:47:08.712488Z","shell.execute_reply.started":"2022-02-02T04:47:08.708756Z","shell.execute_reply":"2022-02-02T04:47:08.711778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt update\n!apt install --yes python-opencv\n!apt install --yes libopencv-dev\n!/bin/bash -c 'echo \"/opt/conda/lib/\" > /etc/ld.so.conf.d/opencv.conf'\n!ldconfig\n!pip install imagesize","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:47:16.195606Z","iopub.execute_input":"2022-02-02T04:47:16.195915Z","iopub.status.idle":"2022-02-02T04:55:13.602592Z","shell.execute_reply.started":"2022-02-02T04:47:16.195881Z","shell.execute_reply":"2022-02-02T04:55:13.601749Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-30T11:07:33.449844Z","iopub.execute_input":"2022-01-30T11:07:33.450348Z","iopub.status.idle":"2022-01-30T11:07:42.176365Z","shell.execute_reply.started":"2022-01-30T11:07:33.450299Z","shell.execute_reply":"2022-01-30T11:07:42.175559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport pickle\nimport matplotlib.pyplot as plt\nimport ast\nimport glob\nimport shutil\nimport sys\nimport numpy as np\nimport imagesize\nimport cv2\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:55:13.605562Z","iopub.execute_input":"2022-02-02T04:55:13.605858Z","iopub.status.idle":"2022-02-02T04:55:13.840872Z","shell.execute_reply.started":"2022-02-02T04:55:13.605816Z","shell.execute_reply":"2022-02-02T04:55:13.840182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Install Darknet\n!git clone https://github.com/AlexeyAB/darknet.git","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:55:13.842099Z","iopub.execute_input":"2022-02-02T04:55:13.842381Z","iopub.status.idle":"2022-02-02T04:55:16.836473Z","shell.execute_reply.started":"2022-02-02T04:55:13.842345Z","shell.execute_reply":"2022-02-02T04:55:16.835658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build Darknet with GPU enable settings\n%cd darknet\n\n!cp '../../input/libcuda/libcuda.so' .\n\n!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n!sed -i 's/GPU=0/GPU=1/g' Makefile\n!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/g' Makefile\n!sed -i 's/LIBSO=0/LIBSO=1/' Makefile\n!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n\n!sed -i 's/LDFLAGS+= -L\\/usr\\/local\\/cuda\\/lib64 -lcuda -lcudart -lcublas -lcurand/LDFLAGS+= -L\\/usr\\/local\\/cuda\\/lib64 -lcudart -lcublas -lcurand -L\\/kaggle\\/working\\/darknet -lcuda/' Makefile\n!make &> compile.log","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:55:16.83906Z","iopub.execute_input":"2022-02-02T04:55:16.839344Z","iopub.status.idle":"2022-02-02T04:57:03.909814Z","shell.execute_reply.started":"2022-02-02T04:55:16.839303Z","shell.execute_reply":"2022-02-02T04:57:03.908877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verify build\n!./darknet detector train","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:57:03.911712Z","iopub.execute_input":"2022-02-02T04:57:03.911982Z","iopub.status.idle":"2022-02-02T04:57:07.477981Z","shell.execute_reply.started":"2022-02-02T04:57:03.911947Z","shell.execute_reply":"2022-02-02T04:57:07.477176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define image/label path\nROOT_DIR  = '/kaggle/input'\nWORKING_DIR  = '/kaggle/working'\ndef get_path(row):\n    row['image_path'] = f'{ROOT_DIR}/tensorflow-great-barrier-reef/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    row['label_path'] = f'{WORKING_DIR}/darknet/data/obj/video_{row.video_id}_{row.video_frame}.txt'\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:57:07.479559Z","iopub.execute_input":"2022-02-02T04:57:07.479841Z","iopub.status.idle":"2022-02-02T04:57:07.487632Z","shell.execute_reply.started":"2022-02-02T04:57:07.479805Z","shell.execute_reply":"2022-02-02T04:57:07.486688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load annotations in dataframe\ndf = pd.read_csv(f'{ROOT_DIR}/tensorflow-great-barrier-reef/train.csv')\ndf = df.apply(get_path, axis=1)\ndf['annotations'] = df['annotations'].apply(lambda x: ast.literal_eval(x))\ndisplay(df.head(2))","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:57:07.488923Z","iopub.execute_input":"2022-02-02T04:57:07.490142Z","iopub.status.idle":"2022-02-02T04:57:32.889412Z","shell.execute_reply.started":"2022-02-02T04:57:07.490101Z","shell.execute_reply":"2022-02-02T04:57:32.888724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check negative samples also\ndf['num_bbox'] = df['annotations'].apply(lambda x: len(x))\ndata = (df.num_bbox>0).value_counts()/len(df)*100\nprint('% images without annotations: {}'.format(data[0]))\nprint('% images with annotations: {} '.format(data[1]))","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:57:32.890796Z","iopub.execute_input":"2022-02-02T04:57:32.891066Z","iopub.status.idle":"2022-02-02T04:57:32.911967Z","shell.execute_reply.started":"2022-02-02T04:57:32.891032Z","shell.execute_reply":"2022-02-02T04:57:32.911258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filter out negative samples\ndf = df.query(\"num_bbox>0\")","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:57:32.913105Z","iopub.execute_input":"2022-02-02T04:57:32.913722Z","iopub.status.idle":"2022-02-02T04:57:32.942946Z","shell.execute_reply.started":"2022-02-02T04:57:32.913684Z","shell.execute_reply":"2022-02-02T04:57:32.942233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-30T11:08:03.374428Z","iopub.execute_input":"2022-01-30T11:08:03.37538Z","iopub.status.idle":"2022-01-30T11:08:03.535012Z","shell.execute_reply.started":"2022-01-30T11:08:03.375332Z","shell.execute_reply":"2022-01-30T11:08:03.534168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert given annotations to YOLO format\ndef coco2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normalizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef yolo2coco(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None):\n    # Plots one bounding box on image\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n     \n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n    \n    if bbox_format == 'yolo':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:\n            \n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n                h  = round(float(bbox[3])*image.shape[0]/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row['image_path'])\n    return row\n\n\ndf['bboxes'] = df.annotations.apply(get_bbox)\ndf = df.apply(get_imgsize,axis=1)\ndisplay(df.width.unique(), df.height.unique())\ndisplay(df.head(2))","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:57:32.945529Z","iopub.execute_input":"2022-02-02T04:57:32.945788Z","iopub.status.idle":"2022-02-02T04:58:26.388867Z","shell.execute_reply.started":"2022-02-02T04:57:32.945753Z","shell.execute_reply":"2022-02-02T04:58:26.388163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Maintain the Darknet's YOLO required directory structure\n%cd data/\n!mkdir obj test\n\ncnt = 0\nfor row_idx in tqdm(range(df.shape[0])):\n    row = df.iloc[row_idx]\n    image_height = row.height\n    image_width = row.width\n    bboxes_coco = np.asarray(row.bboxes).astype(np.float32).copy()\n    num_bbox = len(bboxes_coco)\n    labels = [0]*num_bbox\n  \n    f = open(row.label_path, 'w')\n\n    if num_bbox < 1:\n        annot = ''\n        f.write(annot)\n        f.close()\n        cnt += 1\n        continue\n  \n    bboxes_yolo  = coco2yolo(image_height, image_width, bboxes_coco)\n\n    for i in range(len(bboxes_yolo)):\n        annot = [str(labels[i])] + list(bboxes_yolo[i].astype(str)) + (['\\n'] if num_bbox!=(i+1) else [''])\n        annot = ' '.join(annot)\n        annot = annot.strip(' ')\n        f.write(annot)\n    f.close()\n\nprint('Missing boxes ', cnt)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:26.390052Z","iopub.execute_input":"2022-02-02T04:58:26.390458Z","iopub.status.idle":"2022-02-02T04:58:29.065838Z","shell.execute_reply.started":"2022-02-02T04:58:26.390419Z","shell.execute_reply":"2022-02-02T04:58:29.064963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat obj/video_0_1000.txt","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:29.067386Z","iopub.execute_input":"2022-02-02T04:58:29.068221Z","iopub.status.idle":"2022-02-02T04:58:29.725833Z","shell.execute_reply.started":"2022-02-02T04:58:29.06818Z","shell.execute_reply":"2022-02-02T04:58:29.725066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:02:40.492528Z","iopub.execute_input":"2022-02-02T05:02:40.492842Z","iopub.status.idle":"2022-02-02T05:02:40.506092Z","shell.execute_reply.started":"2022-02-02T05:02:40.492809Z","shell.execute_reply":"2022-02-02T05:02:40.505176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:04:06.873529Z","iopub.execute_input":"2022-02-02T05:04:06.873783Z","iopub.status.idle":"2022-02-02T05:04:06.902522Z","shell.execute_reply.started":"2022-02-02T05:04:06.873754Z","shell.execute_reply":"2022-02-02T05:04:06.901866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Split the dataset into train-val\n# from sklearn.model_selection import GroupKFold\n# kf = GroupKFold(n_splits = 10) \n# df = df.reset_index(drop=True)\n# df['fold'] = -1\n# for fold, (train_idx, val_idx) in enumerate(kf.split(df, y = df.video_id.tolist(), groups=df.sequence)):\n#     df.loc[val_idx, 'fold'] = fold\n# display(df.fold.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-02-01T21:35:25.264727Z","iopub.execute_input":"2022-02-01T21:35:25.265063Z","iopub.status.idle":"2022-02-01T21:35:26.129217Z","shell.execute_reply.started":"2022-02-01T21:35:25.26502Z","shell.execute_reply":"2022-02-01T21:35:26.128552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"val_df = df[df[\"video_id\"].isin([2])]\ntrain_df = df[df[\"video_id\"].isin([0, 1])]\nprint(train_df.shape)\nprint(val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:03:36.304345Z","iopub.execute_input":"2022-02-02T05:03:36.305047Z","iopub.status.idle":"2022-02-02T05:03:36.314342Z","shell.execute_reply.started":"2022-02-02T05:03:36.304992Z","shell.execute_reply":"2022-02-02T05:03:36.313526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move labels from obj to test directory\ndef mv_labels (row):\n    old_path = row.label_path\n    filename = row.label_path.split('/')[-1]\n    new_path = '/'.join(row.label_path.split('/')[:-2]) + '/test/' + filename\n    row['label_path'] = new_path\n    shutil.move(old_path, new_path)\n    return row\n\nval_df = val_df.apply(lambda x: mv_labels(x), axis=1)\nval_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:04:28.50845Z","iopub.execute_input":"2022-02-02T05:04:28.508719Z","iopub.status.idle":"2022-02-02T05:04:28.612072Z","shell.execute_reply.started":"2022-02-02T05:04:28.508687Z","shell.execute_reply":"2022-02-02T05:04:28.611373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy images to working directory\n'''\nLabels and images must have the same name:\nImages: obj/image_XX.jpg\nLabels: obj/image_XX.txt\n'''\ndef copy_images (row):\n    old_path = row.image_path\n    filename = row.label_path.split('/')[-1][:-4] + '.jpg'\n    new_path = '/'.join(row.label_path.split('/')[:-1]) + '/' + filename\n    shutil.copy(old_path, new_path)\nval_df.apply(lambda x: copy_images(x), axis=1)\ntrain_df.apply(lambda x: copy_images(x), axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:04:34.122037Z","iopub.execute_input":"2022-02-02T05:04:34.122529Z","iopub.status.idle":"2022-02-02T05:04:43.219516Z","shell.execute_reply.started":"2022-02-02T05:04:34.122489Z","shell.execute_reply":"2022-02-02T05:04:43.218708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verify\n!ls obj/*.jpg | wc -l\n!ls obj/*.txt | wc -l\n!ls test/*.jpg | wc -l\n!ls test/*.txt | wc -l","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:04:43.224136Z","iopub.execute_input":"2022-02-02T05:04:43.22635Z","iopub.status.idle":"2022-02-02T05:04:46.360905Z","shell.execute_reply.started":"2022-02-02T05:04:43.226293Z","shell.execute_reply":"2022-02-02T05:04:46.360059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate train.txt and test.txt files\n%cd ../\ntrain_images = glob.glob('data/obj/*.jpg')\nf = open('./data/train.txt', 'w')\nannot = [os.path.join(os.getcwd(),t) + ('\\n' if i<len(train_images)-1 else '') for i, t in enumerate(train_images)]\nannot = ''.join(annot)\nannot = annot.strip()\nf.write(annot)\n\nval_images = glob.glob('data/test/*.jpg')\nf = open('./data/test.txt', 'w')  \nannot = [os.path.join(os.getcwd(),t) + ('\\n' if i<len(val_images)-1 else '') for i, t in enumerate(val_images)]\nannot = ''.join(annot)\nannot = annot.strip()\nf.write(annot)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:04:48.943906Z","iopub.execute_input":"2022-02-02T05:04:48.944529Z","iopub.status.idle":"2022-02-02T05:04:49.001122Z","shell.execute_reply.started":"2022-02-02T05:04:48.944483Z","shell.execute_reply":"2022-02-02T05:04:49.000289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verify\n!cat data/train.txt | wc -l\n!cat data/test.txt | wc -l","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:04:54.144113Z","iopub.execute_input":"2022-02-02T05:04:54.144719Z","iopub.status.idle":"2022-02-02T05:04:55.500112Z","shell.execute_reply.started":"2022-02-02T05:04:54.144681Z","shell.execute_reply":"2022-02-02T05:04:55.499291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualization\nnp.random.seed(1)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]\n\ndf2 = train_df[(train_df.num_bbox>0)].sample(100) # takes samples with bbox\n\nfor idx in range(10):\n    row = df2.iloc[idx]\n    img           = load_image(row.image_path)\n    image_height  = row.height\n    image_width   = row.width\n    f = open(row.label_path)\n    bboxes_yolo = np.asarray([[float(a) for a in l[1:].strip().split(' ')] for l in f.readlines()])\n\n    names         = ['starfish']*len(bboxes_yolo)\n    labels        = [0]*len(bboxes_yolo)\n\n    plt.figure(figsize = (12, 8))\n    plt.imshow(draw_bboxes(img = img,\n                           bboxes = bboxes_yolo, \n                           classes = names,\n                           class_ids = labels,\n                           class_name = True, \n                           colors = colors, \n                           bbox_format = 'yolo',\n                           line_thickness = 2))\n    plt.axis('OFF')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:05:00.483204Z","iopub.execute_input":"2022-02-02T05:05:00.483816Z","iopub.status.idle":"2022-02-02T05:05:05.330462Z","shell.execute_reply.started":"2022-02-02T05:05:00.483777Z","shell.execute_reply":"2022-02-02T05:05:05.329851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Modify YOLO's configuration file as per our data\n# !sed -i 's/subdivisions=8/subdivisions=64/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/max_batches = 500500/max_batches = 8000/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/steps=400000,450000/steps=6400,7200/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/classes=80/classes=1/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/filters=255/filters=18/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/objectness_smooth=1/objectness_smooth=0/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/scale_x_y=2.0/scale_x_y=1.05/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/activation=logistic/activation=linear/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/iou_thresh=0.2/iou_thresh=1.0/g' ./cfg/yolov4x-mish.cfg\n# !sed 'iou_loss=ciou d' ./cfg/yolov4x-mish.cfg\n# !sed 'iou_normalizer=0.05 d' ./cfg/yolov4x-mish.cfg\n# !sed 'new_coords=1 d' ./cfg/yolov4x-mish.cfg","metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:44:00.774979Z","iopub.execute_input":"2022-01-28T16:44:00.775202Z","iopub.status.idle":"2022-01-28T16:44:03.4331Z","shell.execute_reply.started":"2022-01-28T16:44:00.775174Z","shell.execute_reply":"2022-01-28T16:44:03.43214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !sed -i 's/subdivisions=64/subdivisions=32/g' ./cfg/yolov4-custom.cfg \n# !sed -i 's/width=1024/width=832/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/height=1024/height=832/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/max_batches = 12000/max_batches = 5000/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/steps=9600,10800/steps=4000,4500/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/classes=80/classes=1/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/filters=255/filters=18/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/angle = 0/angle= 30/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/filters=255/filters=18/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/layers = 23/layers = 54/g' ./cfg/yolov4-custom.cfg\n# !sed -i 's/stride = 4/stride= 2/g' ./cfg/yolov4-custom.cfg\n# !sed 'random=1 d' ./cfg/yolov4-custom.cfg","metadata":{"execution":{"iopub.status.busy":"2022-02-01T22:01:52.110628Z","iopub.execute_input":"2022-02-01T22:01:52.111409Z","iopub.status.idle":"2022-02-01T22:02:00.603535Z","shell.execute_reply.started":"2022-02-01T22:01:52.111362Z","shell.execute_reply":"2022-02-01T22:02:00.602637Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sed -i 's/subdivisions=16/subdivisions=32/g' ./cfg/yolov4-custom.cfg \n!sed -i 's/width=608/width=608/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/height=608/height=608/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/max_batches = 500500/max_batches = 5000/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/steps=400000,450000/steps=4000,4500/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/classes=80/classes=1/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/filters=255/filters=18/g' ./cfg/yolov4-custom.cfg\n!sed 'random=1 d' ./cfg/yolov4-custom.cfg\n!sed -i 's/angle = 0/angle= 30/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/exposure= 1.5/exposure= 2.5/g' ./cfg/yolov4-custom.cfg\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:19:18.774175Z","iopub.execute_input":"2022-02-02T05:19:18.774833Z","iopub.status.idle":"2022-02-02T05:19:25.332298Z","shell.execute_reply.started":"2022-02-02T05:19:18.774792Z","shell.execute_reply":"2022-02-02T05:19:25.331343Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Build obj.data and obj.names files \nf = open('./data/obj.data', 'w')\nf.write('classes = 1\\ntrain = data/train.txt\\nvalid = data/test.txt\\nnames = data/obj.names\\nbackup = backup\\n')\nf.close()\nf = open('./data/obj.names', 'w')\nf.write('starfish')\nf.close()","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:15:52.46778Z","iopub.execute_input":"2022-02-02T05:15:52.468082Z","iopub.status.idle":"2022-02-02T05:15:52.474392Z","shell.execute_reply.started":"2022-02-02T05:15:52.468046Z","shell.execute_reply":"2022-02-02T05:15:52.473596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Download YOLOv4x-MISH pre-trained model\n# !wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4x-mish.conv.166","metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:44:09.239692Z","iopub.execute_input":"2022-01-28T16:44:09.240614Z","iopub.status.idle":"2022-01-28T16:44:09.248849Z","shell.execute_reply.started":"2022-01-28T16:44:09.240566Z","shell.execute_reply":"2022-01-28T16:44:09.248238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137","metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:44:09.25042Z","iopub.execute_input":"2022-01-28T16:44:09.250714Z","iopub.status.idle":"2022-01-28T16:44:20.949827Z","shell.execute_reply.started":"2022-01-28T16:44:09.250672Z","shell.execute_reply":"2022-01-28T16:44:20.949004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Start the training\n# !./darknet detector train data/obj.data cfg/yolov4x-mish.cfg yolov4x-mish.conv.166 -dont_show -map","metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:44:20.955035Z","iopub.execute_input":"2022-01-28T16:44:20.955357Z","iopub.status.idle":"2022-01-28T16:44:20.960037Z","shell.execute_reply.started":"2022-01-28T16:44:20.955322Z","shell.execute_reply":"2022-01-28T16:44:20.958979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from distutils.dir_util import copy_tree\n# #copy_tree('../input/cots-last-weight-yolo','/kaggle/working/darknet/backup')\n# import shutil\n# src='../input/cots-last-weight-yolo/yolov4-custom_last.weights'\n# dst = '/kaggle/working/darknet/yolov4-custom_last.weights'\n# try:\n#     #if path already exists, remove it before copying with copytree()\n#     if os.path.exists(dst):\n#         shutil.rmtree(dst)\n#         shutil.copyfile(src, dst)\n#         print(\"Copy File 1\")\n#     elif not os.path.isdir('/kaggle/working/darknet/backup'):\n#         os.makedirs('/kaggle/working/darknet/backup')\n#         print(\"folder is created!\")\n#     else:\n#         shutil.copyfile(src, dst)\n#         print(\"Copy File 2\")\n# except OSError as e:\n#         #shutil.copy(source_dir_prompt, destination_dir_prompt)\n#         print(\"No Copy due to: \", e)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:44:20.961494Z","iopub.execute_input":"2022-01-28T16:44:20.961731Z","iopub.status.idle":"2022-01-28T16:44:20.97514Z","shell.execute_reply.started":"2022-01-28T16:44:20.961701Z","shell.execute_reply":"2022-01-28T16:44:20.974105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!./darknet detector test data/obj.data cfg/yolov4-custom.cfg {ROOT_DIR}/-dont_show -map\n#resume training\n#!./darknet detector train data/obj.data cfg/yolov4-custom.cfg  -map\n!./darknet detector train data/obj.data cfg/yolov4-custom.cfg -dont_show -map","metadata":{"execution":{"iopub.status.busy":"2022-02-02T05:19:48.338137Z","iopub.execute_input":"2022-02-02T05:19:48.338762Z","iopub.status.idle":"2022-02-02T05:20:51.044193Z","shell.execute_reply.started":"2022-02-02T05:19:48.338722Z","shell.execute_reply":"2022-02-02T05:20:51.043364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.listdir('../../working/darknet/results')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:44:21.752263Z","iopub.execute_input":"2022-01-28T16:44:21.752643Z","iopub.status.idle":"2022-01-28T16:44:21.759182Z","shell.execute_reply.started":"2022-01-28T16:44:21.75261Z","shell.execute_reply":"2022-01-28T16:44:21.7583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def imShow(path):\n#   import cv2\n#   import matplotlib.pyplot as plt\n#   %matplotlib inline\n\n#   image = cv2.imread(path)\n#   height, width = image.shape[:2]\n#   resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n\n#   fig = plt.gcf()\n#   fig.set_size_inches(18, 10)\n#   plt.axis(\"off\")\n#   plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n#   plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T08:47:06.523587Z","iopub.execute_input":"2022-01-29T08:47:06.523876Z","iopub.status.idle":"2022-01-29T08:47:06.534491Z","shell.execute_reply.started":"2022-01-29T08:47:06.523844Z","shell.execute_reply":"2022-01-29T08:47:06.533792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# imShow('predictions.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-01-29T08:47:09.540758Z","iopub.execute_input":"2022-01-29T08:47:09.541089Z","iopub.status.idle":"2022-01-29T08:47:10.903218Z","shell.execute_reply.started":"2022-01-29T08:47:09.541055Z","shell.execute_reply":"2022-01-29T08:47:10.902536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cd /kaggle/working/darknet","metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:44:21.910431Z","iopub.status.idle":"2022-01-28T16:44:21.911563Z","shell.execute_reply.started":"2022-01-28T16:44:21.911272Z","shell.execute_reply":"2022-01-28T16:44:21.911302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bboxes=[335,91,27,27]","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:09:48.862813Z","iopub.execute_input":"2022-01-30T10:09:48.86313Z","iopub.status.idle":"2022-01-30T10:09:48.867862Z","shell.execute_reply.started":"2022-01-30T10:09:48.863097Z","shell.execute_reply":"2022-01-30T10:09:48.866925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2 as cv","metadata":{"execution":{"iopub.status.busy":"2022-01-30T11:58:30.988569Z","iopub.execute_input":"2022-01-30T11:58:30.989195Z","iopub.status.idle":"2022-01-30T11:58:31.228232Z","shell.execute_reply.started":"2022-01-30T11:58:30.989099Z","shell.execute_reply":"2022-01-30T11:58:31.227255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def load_model(conf=0.25, iou=0.50):\n#     net = cv.dnn.readNet(f'/kaggle/input/cots-yolov4-final/cots_yolov4_final_weights/yolov4-custom.cfg',\n#                             f'/kaggle/input/yolocotsbest/yolov4-custom_best.weights')\n#     net = cv.dnn_DetectionModel(net)\n#     net.setInputParams(size=(416, 416), scale=1/255, swapRB=True)\n#     return net","metadata":{"execution":{"iopub.status.busy":"2022-01-30T11:58:31.229887Z","iopub.execute_input":"2022-01-30T11:58:31.23038Z","iopub.status.idle":"2022-01-30T11:58:31.235559Z","shell.execute_reply.started":"2022-01-30T11:58:31.230345Z","shell.execute_reply":"2022-01-30T11:58:31.234754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# net = load_model(conf=0.25, iou=0.40)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T11:58:31.23645Z","iopub.execute_input":"2022-01-30T11:58:31.236644Z","iopub.status.idle":"2022-01-30T11:58:36.21989Z","shell.execute_reply.started":"2022-01-30T11:58:31.236613Z","shell.execute_reply":"2022-01-30T11:58:36.219013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confThreshold = 0.25\n# confthre = 0.25\n# IMG_SIZE=416\n# with open('/kaggle/input/objdata/obj.names', 'rt') as f:\n#     names = f.read().rstrip('\\n').split('\\n')\n\n# def predict(net, img, size=IMG_SIZE):\n#     confs = []\n#     bboxes = []\n#     height, width = img.shape[:2]\n#     bbclasses, scores, bboxes = net.detect(img, confThreshold=confThreshold, nmsThreshold=0.4)\n#     print( scores, bboxes)\n#     if type(bbclasses) is not tuple:\n#         for classId, confidence, box in zip(bbclasses.flatten(), scores.flatten(), bboxes):\n#     #         confs = '%.2f' % confidence\n#     #         label = '%s: %s' % (names[classId], label)\n#             left, top, width, height = box\n#             if len(box):\n#                 bboxes  = yolo2coco(box,height,width).astype(int)\n#                 confs = '%.2f' % confidence\n#             else:\n#                 bboxes = []\n#                 confs = []\n#                 print(\"COCO conversion Issue!\")\n#         return bboxes,confs\n#     else:\n#         for classId, confidence, box in zip(bbclasses, scores, bboxes):\n#     #         confs = '%.2f' % confidence\n#     #         label = '%s: %s' % (names[classId], label)\n#             left, top, width, height = box\n#             if len(box):\n#                 bboxes  = voc2coco(box,height,width).astype(int)\n#                 print(\"bboxes::\", bboxes)\n#                 confs = '%.2f' % confidence\n#             else:\n#                 bboxes = []\n#                 confs = []\n#                 print(\"COCO conversion Issue!\")\n#         return bboxes,confs\n# #     for i in range(len(bboxes)):\n# #         box = bboxes[i]\n# #         cls_id = int(bbclasses[i])\n# #         score = scores[i]\n# #     if len(bboxes):\n# #         bboxes  = yolo2coco(bboxes,height,width).astype(int)\n# #         confs   = score\n# #         print(\"confs:\", confs)\n# #         return bboxes, confs\n# #     else:\n# #         return [],[]\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:04:35.005443Z","iopub.execute_input":"2022-01-30T12:04:35.0065Z","iopub.status.idle":"2022-01-30T12:04:35.023611Z","shell.execute_reply.started":"2022-01-30T12:04:35.006445Z","shell.execute_reply":"2022-01-30T12:04:35.022794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def voc2yolo(bboxes, image_height=720, image_width=1280):\n#     \"\"\"\n#     voc  => [x1, y1, x2, y1]\n#     yolo => [xmid, ymid, w, h] (normalized)\n#     \"\"\"\n    \n#     bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n#     bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n#     bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n    \n#     w = bboxes[..., 2] - bboxes[..., 0]\n#     h = bboxes[..., 3] - bboxes[..., 1]\n    \n#     bboxes[..., 0] = bboxes[..., 0] + w/2\n#     bboxes[..., 1] = bboxes[..., 1] + h/2\n#     bboxes[..., 2] = w\n#     bboxes[..., 3] = h\n    \n#     return bboxes\n# def yolo2voc(bboxes, image_height=720, image_width=1280):\n#     \"\"\"\n#     yolo => [xmid, ymid, w, h] (normalized)\n#     voc  => [x1, y1, x2, y1]\n    \n#     \"\"\" \n#     bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n#     bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n#     bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n#     bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n#     bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n#     return bboxes\n# def coco2yolo(bboxes, image_height=720, image_width=1280):\n#     \"\"\"\n#     coco => [xmin, ymin, w, h]\n#     yolo => [xmid, ymid, w, h] (normalized)\n#     \"\"\"\n    \n#     bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n#     # normolizinig\n#     bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n#     bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n#     # converstion (xmin, ymin) => (xmid, ymid)\n#     bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n#     return bboxes\n# def yolo2coco(bboxes, image_height=416, image_width=416):\n#     \"\"\"\n#     yolo => [xmid, ymid, w, h] (normalized)\n#     coco => [xmin, ymin, w, h]\n    \n#     \"\"\" \n#     bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n#     # denormalizing\n#     bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n#     bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n#     # converstion (xmid, ymid) => (xmin, ymin) \n#     bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n#     return bboxes\n\n# def voc2coco(bboxes, image_height=720, image_width=1280):\n#     bboxes  = voc2yolo(bboxes, image_height, image_width)\n#     bboxes  = yolo2coco(bboxes, image_height, image_width)\n#     return bboxes","metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:03:59.845441Z","iopub.execute_input":"2022-01-30T12:03:59.846395Z","iopub.status.idle":"2022-01-30T12:03:59.868315Z","shell.execute_reply.started":"2022-01-30T12:03:59.846316Z","shell.execute_reply":"2022-01-30T12:03:59.86735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -q /kaggle/input/bbox-lib-ds","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:56:16.539664Z","iopub.execute_input":"2022-01-30T10:56:16.540046Z","iopub.status.idle":"2022-01-30T10:56:29.676459Z","shell.execute_reply.started":"2022-01-30T10:56:16.539947Z","shell.execute_reply":"2022-01-30T10:56:29.675453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from PIL import Image\n# from numpy import asarray\n  \n  \n\n# img = Image.open('/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/1910.jpg')\n  \n# # asarray() class is used to convert\n# # PIL images into NumPy arrays\n# numpydata = asarray(img)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:26:15.042045Z","iopub.execute_input":"2022-01-30T12:26:15.042405Z","iopub.status.idle":"2022-01-30T12:26:15.079643Z","shell.execute_reply.started":"2022-01-30T12:26:15.042368Z","shell.execute_reply":"2022-01-30T12:26:15.078709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# bboxes, confs  = predict(net, numpydata, size=IMG_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:26:17.772928Z","iopub.execute_input":"2022-01-30T12:26:17.773254Z","iopub.status.idle":"2022-01-30T12:26:18.579833Z","shell.execute_reply.started":"2022-01-30T12:26:17.773216Z","shell.execute_reply":"2022-01-30T12:26:18.57898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(bboxes,confs)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:04:51.519326Z","iopub.execute_input":"2022-01-30T12:04:51.519618Z","iopub.status.idle":"2022-01-30T12:04:51.527174Z","shell.execute_reply.started":"2022-01-30T12:04:51.519589Z","shell.execute_reply":"2022-01-30T12:04:51.526204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def format_prediction(bboxes, confs):\n#     annot = ''\n#     if len(bboxes)>0:\n#         for idx in range(len(bboxes)):\n#             xmin, ymin, w, h = bboxes[idx]\n#             conf             = confs\n#             annot += f'{conf} {xmin} {ymin} {w} {h}'\n#             annot +=' '\n#         annot = annot.strip(' ')\n#     return annot","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:02:10.211838Z","iopub.execute_input":"2022-01-30T10:02:10.212172Z","iopub.status.idle":"2022-01-30T10:02:10.218721Z","shell.execute_reply.started":"2022-01-30T10:02:10.212137Z","shell.execute_reply":"2022-01-30T10:02:10.21779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  annot= format_prediction(bboxes, confs)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:02:12.941691Z","iopub.execute_input":"2022-01-30T10:02:12.942337Z","iopub.status.idle":"2022-01-30T10:02:12.94719Z","shell.execute_reply.started":"2022-01-30T10:02:12.942296Z","shell.execute_reply":"2022-01-30T10:02:12.946103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# annot","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:02:18.963982Z","iopub.execute_input":"2022-01-30T10:02:18.964374Z","iopub.status.idle":"2022-01-30T10:02:18.970282Z","shell.execute_reply.started":"2022-01-30T10:02:18.964341Z","shell.execute_reply":"2022-01-30T10:02:18.969265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(bboxes,confs)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T09:47:03.275005Z","iopub.execute_input":"2022-01-30T09:47:03.275398Z","iopub.status.idle":"2022-01-30T09:47:03.282177Z","shell.execute_reply.started":"2022-01-30T09:47:03.275362Z","shell.execute_reply":"2022-01-30T09:47:03.28108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n#           for idx in range(1)]\n# print(colors)\n\n# #df2 = train_df[(train_df.num_bbox>0)].sample(100) # takes samples with bbox\n\n    \n# img = load_image('/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/1875.jpg')\n# image_height  = 720\n# image_width   = 1280\n    \n# bboxes_yolo = [[ 35,216 ,46 , 44],[681,602 ,50 ,86]]\n\n# names         = ['starfish']*len(bboxes_yolo)\n# labels        = [0]*len(bboxes_yolo)\n\n# plt.figure(figsize = (12, 8))\n# plt.imshow(draw_bboxes(img = img,\n#                            bboxes = bboxes_yolo, \n#                            classes = names,\n#                            class_ids = labels,\n#                            class_name = True, \n#                            colors = colors, \n#                            bbox_format = 'yolo',\n#                            line_thickness = 2))\n# plt.axis('OFF')\n# plt.show()\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T11:21:48.762237Z","iopub.execute_input":"2022-01-30T11:21:48.762529Z","iopub.status.idle":"2022-01-30T11:21:49.239284Z","shell.execute_reply.started":"2022-01-30T11:21:48.762497Z","shell.execute_reply":"2022-01-30T11:21:49.238211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img","metadata":{"execution":{"iopub.status.busy":"2022-01-30T11:13:49.46514Z","iopub.execute_input":"2022-01-30T11:13:49.465867Z","iopub.status.idle":"2022-01-30T11:13:49.485365Z","shell.execute_reply.started":"2022-01-30T11:13:49.465831Z","shell.execute_reply":"2022-01-30T11:13:49.484552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# k","metadata":{"execution":{"iopub.status.busy":"2022-01-30T09:47:15.335644Z","iopub.execute_input":"2022-01-30T09:47:15.336662Z","iopub.status.idle":"2022-01-30T09:47:15.344142Z","shell.execute_reply.started":"2022-01-30T09:47:15.336617Z","shell.execute_reply":"2022-01-30T09:47:15.343099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install darknetpy\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T07:15:13.655261Z","iopub.execute_input":"2022-01-30T07:15:13.655556Z","iopub.status.idle":"2022-01-30T07:16:18.089908Z","shell.execute_reply.started":"2022-01-30T07:15:13.655525Z","shell.execute_reply":"2022-01-30T07:16:18.088669Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# det=load_model()","metadata":{"execution":{"iopub.status.busy":"2022-01-29T13:18:39.406163Z","iopub.execute_input":"2022-01-29T13:18:39.406453Z","iopub.status.idle":"2022-01-29T13:18:39.611453Z","shell.execute_reply.started":"2022-01-29T13:18:39.406403Z","shell.execute_reply":"2022-01-29T13:18:39.610701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GPU=1 pip install darknetpy","metadata":{"execution":{"iopub.status.busy":"2022-01-30T07:13:35.738668Z","iopub.execute_input":"2022-01-30T07:13:35.738995Z","iopub.status.idle":"2022-01-30T07:13:35.74542Z","shell.execute_reply.started":"2022-01-30T07:13:35.738961Z","shell.execute_reply":"2022-01-30T07:13:35.744105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install https://github.com/sicara/tf2-yolov4/archive/master.zip","metadata":{"execution":{"iopub.status.busy":"2022-01-29T13:03:14.91992Z","iopub.execute_input":"2022-01-29T13:03:14.920264Z","iopub.status.idle":"2022-01-29T13:03:26.439815Z","shell.execute_reply.started":"2022-01-29T13:03:14.920179Z","shell.execute_reply":"2022-01-29T13:03:26.438977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !convert-darknet-weights /kaggle/input/yolocotsbest/yolov4-custom_best.weights -o yolov4.h5","metadata":{"execution":{"iopub.status.busy":"2022-01-29T13:10:01.898362Z","iopub.execute_input":"2022-01-29T13:10:01.898965Z","iopub.status.idle":"2022-01-29T13:10:33.19243Z","shell.execute_reply.started":"2022-01-29T13:10:01.898928Z","shell.execute_reply":"2022-01-29T13:10:33.191666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2022-01-30T07:12:26.43581Z","iopub.execute_input":"2022-01-30T07:12:26.436173Z","iopub.status.idle":"2022-01-30T07:12:35.952212Z","shell.execute_reply.started":"2022-01-30T07:12:26.436129Z","shell.execute_reply":"2022-01-30T07:12:35.951136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"/kaggle/working/darknet/backup\"> Download File </a>\n","metadata":{}}]}