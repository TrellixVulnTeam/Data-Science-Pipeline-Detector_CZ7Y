{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ref: https://www.kaggle.com/remekkinas/yolox-training-pipeline-cots-dataset-lb-0-507","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport ast\nimport os\nimport json\nimport pandas as pd\nimport torch\nimport importlib\nimport cv2 \n\nfrom shutil import copyfile\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nfrom sklearn.model_selection import GroupKFold\n\nTRAIN_PATH = '/kaggle/input/tensorflow-great-barrier-reef'","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:27:26.601212Z","iopub.execute_input":"2022-01-08T12:27:26.601744Z","iopub.status.idle":"2022-01-08T12:27:29.010144Z","shell.execute_reply.started":"2022-01-08T12:27:26.601652Z","shell.execute_reply":"2022-01-08T12:27:29.009241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tensorflow-great-barrier-reef/train.csv\")\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:27:29.01168Z","iopub.execute_input":"2022-01-08T12:27:29.011917Z","iopub.status.idle":"2022-01-08T12:27:29.085612Z","shell.execute_reply.started":"2022-01-08T12:27:29.011888Z","shell.execute_reply":"2022-01-08T12:27:29.084747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add no of bbox, bbox values, image resolution and image path in new dataframe","metadata":{}},{"cell_type":"code","source":"def get_bbox(annots):\n    # get bbox corrdinates only by using anno.values() in annotations dict\n    # since the values are string type, we need to convert to list\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_img_path(row):\n    # /kaggle/input/tensorflow-great-barrier-reef/train_images/video_2/16.jpg\n    row['image_path'] = f'{TRAIN_PATH}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    return row ","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:27:31.668539Z","iopub.execute_input":"2022-01-08T12:27:31.669468Z","iopub.status.idle":"2022-01-08T12:27:31.675974Z","shell.execute_reply.started":"2022-01-08T12:27:31.669414Z","shell.execute_reply":"2022-01-08T12:27:31.67513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taken only annotated photos and add in num_bbox column in df\ndf[\"num_bbox\"] = df['annotations'].apply(lambda x: str.count(x, 'x'))\n\n# to make sure num_bbox in each row is greater than 0 and greate df_train\ndf_train = df[df[\"num_bbox\"]>0]\n\n# change annotations str type to list and add bboxes values in df \ndf_train['annotations'] = df_train['annotations'].progress_apply(lambda x: ast.literal_eval(x))\ndf_train['bboxes'] = df_train.annotations.progress_apply(get_bbox)\n\n# add image resoultuion column in dataframe\ndf_train[\"width\"] = 1280\ndf_train[\"height\"] = 720\n\n# add image path in dataframe\ndf_train = df_train.progress_apply(get_img_path, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:27:32.045136Z","iopub.execute_input":"2022-01-08T12:27:32.045545Z","iopub.status.idle":"2022-01-08T12:27:35.973986Z","shell.execute_reply.started":"2022-01-08T12:27:32.045507Z","shell.execute_reply":"2022-01-08T12:27:35.973148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GroupK Folding (5 folds)","metadata":{}},{"cell_type":"code","source":"kf = GroupKFold(n_splits = 5)\ndf_train = df_train.reset_index(drop=True)\ndf_train['fold'] = -1\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(df_train, y=df_train.video_id.tolist(), groups=df_train.sequence)):\n    df_train.loc[val_idx, 'fold'] = fold\n    \ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:27:35.975462Z","iopub.execute_input":"2022-01-08T12:27:35.975773Z","iopub.status.idle":"2022-01-08T12:27:36.009096Z","shell.execute_reply.started":"2022-01-08T12:27:35.975732Z","shell.execute_reply":"2022-01-08T12:27:36.008431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOME_DIR = '/kaggle/working/'\nDATASET_PATH = 'dataset/COTS-COCO'\n\n!mkdir {HOME_DIR}dataset\n!mkdir {HOME_DIR}{DATASET_PATH}\n!mkdir {HOME_DIR}{DATASET_PATH}/images\n!mkdir {HOME_DIR}{DATASET_PATH}/images/train2017\n!mkdir {HOME_DIR}{DATASET_PATH}/images/val2017\n!mkdir {HOME_DIR}{DATASET_PATH}/annotations","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:29:27.662288Z","iopub.execute_input":"2022-01-08T12:29:27.662621Z","iopub.status.idle":"2022-01-08T12:29:31.422917Z","shell.execute_reply.started":"2022-01-08T12:29:27.662587Z","shell.execute_reply":"2022-01-08T12:29:31.421906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split train and val depending on fold id","metadata":{}},{"cell_type":"code","source":"SELECTED_FOLD = 4\n# fold 1,2,3,5 --> train\n# fold 4 --> val\n\nfor i in tqdm(range(len(df_train))):\n    \n    row = df_train.loc[i]\n    \n    if row.fold != SELECTED_FOLD: # train\n        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/images/train2017/{row.image_id}.jpg')\n    \n    elif row.fold == SELECTED_FOLD: # val\n        copyfile(f'{row.image_path}', f'{HOME_DIR}{DATASET_PATH}/images/val2017/{row.image_id}.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:29:40.179326Z","iopub.execute_input":"2022-01-08T12:29:40.180233Z","iopub.status.idle":"2022-01-08T12:30:28.731898Z","shell.execute_reply.started":"2022-01-08T12:29:40.180193Z","shell.execute_reply":"2022-01-08T12:30:28.730734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of training files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}/images/train2017/\"))}')\nprint(f'Number of validation files: {len(os.listdir(f\"{HOME_DIR}{DATASET_PATH}/images/val2017/\"))}')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T14:58:44.493345Z","iopub.execute_input":"2021-12-29T14:58:44.493742Z","iopub.status.idle":"2021-12-29T14:58:44.503053Z","shell.execute_reply.started":"2021-12-29T14:58:44.493706Z","shell.execute_reply":"2021-12-29T14:58:44.502344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert to COCO Json for annotations","metadata":{}},{"cell_type":"code","source":"def save_annot_json(annotation_dict, fname):\n    with open(fname, 'w') as f:\n        output_json = json.dumps(annotation_dict)\n        f.write(output_json)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T14:58:44.504405Z","iopub.execute_input":"2021-12-29T14:58:44.504813Z","iopub.status.idle":"2021-12-29T14:58:44.509376Z","shell.execute_reply.started":"2021-12-29T14:58:44.504774Z","shell.execute_reply":"2021-12-29T14:58:44.508705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotation_id = 0\nfrom datetime import datetime\n\ndef dataset_to_coco(df):\n        \n    global annotation_id\n    \n    annotations_json = {\n        \"info\": [],\n        \"licenses\": [],\n        \"categories\": [],\n        \"images\": [],\n        \"annotations\": []\n    }\n    \n    info = {\n        \"year\": \"2021\",\n        \"version\": \"1\",\n        \"description\": \"COTS dataset - COCO format\",\n        \"contributor\": \"\",\n        \"url\": \"https://www.kaggle.com/c/tensorflow-great-barrier-reef/overview\",\n        \"date_created\": str(datetime.now())\n    }\n    annotations_json[\"info\"].append(info)\n    \n    lic = {\n            \"id\": 1,\n            \"url\": \"https://www.kaggle.com/c/tensorflow-great-barrier-reef/rules\",\n            \"name\": \"Unknown\"\n        }\n    annotations_json[\"licenses\"].append(lic)\n\n    classes = {\"id\": 0, \"name\": \"starfish\", \"supercategory\": \"none\"}\n\n    annotations_json[\"categories\"].append(classes)\n\n    \n    for ann_row in df.itertuples():\n            \n        images = {\n            \"id\": ann_row[0],\n            \"license\": 1,\n            \"file_name\": ann_row.image_id + '.jpg',\n            \"height\": ann_row.height,\n            \"width\": ann_row.width,\n            \"date_captured\": str(datetime.now())\n        }\n        \n        annotations_json[\"images\"].append(images)\n        \n        bbox_list = ann_row.bboxes\n        \n        for bbox in bbox_list:\n            b_width = bbox[2]\n            b_height = bbox[3]\n            \n            # some boxes in COTS are outside the image height and width\n            if (bbox[0] + bbox[2] > 1280):\n                b_width = bbox[0] - 1280 \n            if (bbox[1] + bbox[3] > 720):\n                b_height = bbox[1] - 720 \n                \n            image_annotations = {\n                \"id\": annotation_id,\n                \"image_id\": ann_row[0],\n                \"category_id\": 0,\n                \"bbox\": [bbox[0], bbox[1], b_width, b_height],\n                \"area\": bbox[2] * bbox[3],\n                \"segmentation\": [],\n                \"iscrowd\": 0\n            }\n            \n            annotation_id += 1\n            annotations_json[\"annotations\"].append(image_annotations)\n        \n        \n    print(f\"Dataset COTS annotation to COCO json format completed! Files: {len(df)}\")\n    return annotations_json","metadata":{"execution":{"iopub.status.busy":"2021-12-29T14:59:46.562466Z","iopub.execute_input":"2021-12-29T14:59:46.562954Z","iopub.status.idle":"2021-12-29T14:59:46.590926Z","shell.execute_reply.started":"2021-12-29T14:59:46.562891Z","shell.execute_reply":"2021-12-29T14:59:46.589668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save coco json annotation file","metadata":{}},{"cell_type":"code","source":"# fold 1,2,3,5\ntrain_df = df_train[df_train.fold != SELECTED_FOLD]\ntrain_coco_dict = dataset_to_coco(df=train_df)\ntrain_json_path = f'{HOME_DIR}{DATASET_PATH}/annotations/train.json'\nsave_annot_json(annotation_dict=train_coco_dict, fname=train_json_path)\n\n\n# fold 4\nval_df = df_train[df_train.fold == SELECTED_FOLD]\nval_coco_dict = dataset_to_coco(df=val_df)\nval_json_path = f'{HOME_DIR}{DATASET_PATH}/annotations/val.json'\nsave_annot_json(annotation_dict=val_coco_dict, fname=val_json_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T14:59:51.087015Z","iopub.execute_input":"2021-12-29T14:59:51.087297Z","iopub.status.idle":"2021-12-29T14:59:51.324579Z","shell.execute_reply.started":"2021-12-29T14:59:51.087263Z","shell.execute_reply":"2021-12-29T14:59:51.323823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}