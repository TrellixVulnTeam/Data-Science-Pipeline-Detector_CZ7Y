{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import party!!","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np \nimport wandb\nimport pytorch_lightning as pl\nimport torchvision\nfrom torchvision.utils  import draw_bounding_boxes\nimport matplotlib.pyplot as plt\nimport torchvision.transforms.functional as F","metadata":{"_uuid":"f42bee71-9b03-412b-bff2-108c7b7136d2","_cell_guid":"865f6024-5d20-47a6-bff4-02a7933dd5fb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-25T01:34:33.30844Z","iopub.execute_input":"2022-03-25T01:34:33.308718Z","iopub.status.idle":"2022-03-25T01:34:33.315258Z","shell.execute_reply.started":"2022-03-25T01:34:33.308687Z","shell.execute_reply":"2022-03-25T01:34:33.31376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helpers\n","metadata":{}},{"cell_type":"code","source":"\n# anotations format may vary depending on the model we choose\n# pseudo helper defs\n\n# remember to chang the annotation values if you change size of each image\n\ndef convert_annotations(info):\n    boxes_min_max=[]\n    if len(info)==0: return torch.tensor([])\n    for information in info:\n        x,y,W,H=information.values()\n        boxes_min_max.append([x,y,x+W,y+H])\n    return torch.tensor(boxes_min_max)\n\ndef display_(path,base_dir):\n    df=pd.read_csv(path)\n    df.annotations=df.annotations.apply(eval)\n    df['annotation_min_max']=df.annotations.apply(convert_annotations)\n    df['path']=base_dir+'/video_'+df.video_id.astype(str)+'/'+df.video_frame.astype(str)+'.jpg'\n#     display(df)\n    return df\n\ndef read_img(path):\n    img=torchvision.io.read_image(path)\n    return img\n\ndef get_annotations(path):\n    annotations=1\n    return annotations\n\ndef plot_with_annotations(df,r=8,c=8,figsize=(20,20)):\n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    for n, ax in enumerate(axs):\n        img=read_img(df.path[n])\n        boxes=df.annotation_min_max[n]\n        img=draw_bounding_boxes(img,boxes)\n        ax.imshow(F.to_pil_image(img))\n        ax.axis('off')\n        \n        \n    plt.tight_layout()\n    plt.show()\n    return\n\ndef main():\n    train_df_path='../input/tensorflow-great-barrier-reef/train.csv'\n    test_df_path='../input/tensorflow-great-barrier-reef/test.csv'\n    train_base_dir='../input/tensorflow-great-barrier-reef/train_images'\n    train_df=display_(train_df_path,train_base_dir)\n    plot_with_annotations(train_df)\n    \n    \nmain()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-25T01:41:25.013111Z","iopub.execute_input":"2022-03-25T01:41:25.013775Z","iopub.status.idle":"2022-03-25T01:41:36.651259Z","shell.execute_reply.started":"2022-03-25T01:41:25.013687Z","shell.execute_reply":"2022-03-25T01:41:36.638919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}