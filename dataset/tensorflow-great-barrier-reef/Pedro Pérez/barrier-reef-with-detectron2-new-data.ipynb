{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl -L https://app.roboflow.com/ds/YCm3CoNdC7?key=2EBYxipTM6 > roboflow.zip; unzip roboflow.zip; rm roboflow.zip","metadata":{"execution":{"iopub.status.busy":"2022-01-31T22:28:02.002058Z","iopub.execute_input":"2022-01-31T22:28:02.003022Z","iopub.status.idle":"2022-01-31T22:28:03.888454Z","shell.execute_reply.started":"2022-01-31T22:28:02.002924Z","shell.execute_reply":"2022-01-31T22:28:03.887664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html","metadata":{"id":"DYJQLvpbg-2w","outputId":"f8b32918-b1e7-4938-fcbc-b1432e38760b","execution":{"iopub.status.busy":"2022-01-31T22:28:03.890348Z","iopub.execute_input":"2022-01-31T22:28:03.890649Z","iopub.status.idle":"2022-01-31T22:30:30.961908Z","shell.execute_reply.started":"2022-01-31T22:28:03.890611Z","shell.execute_reply":"2022-01-31T22:30:30.961067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# install detectron2:\n!pip install detectron2 -f \\\n  https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html","metadata":{"id":"Dr_6MJaHmQ_F","outputId":"b2da3e73-3941-4f4e-f71f-f9bd96a6ac6a","execution":{"iopub.status.busy":"2022-01-31T22:30:30.96385Z","iopub.execute_input":"2022-01-31T22:30:30.964116Z","iopub.status.idle":"2022-01-31T22:31:18.685471Z","shell.execute_reply.started":"2022-01-31T22:30:30.964078Z","shell.execute_reply":"2022-01-31T22:31:18.684624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some basic setup:\n# Setup detectron2 logger\nimport torch, torchvision\n\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n\n\n# import some common detectron2 utilities\nfrom detectron2.data import detection_utils as utils\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data.catalog import DatasetCatalog\nfrom detectron2.data.datasets import load_coco_json\nimport detectron2.data.transforms as T\n\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","metadata":{"id":"qlhpgaIXmWOA","outputId":"8136b24b-115d-4889-c85c-d1fed31d4353","execution":{"iopub.status.busy":"2022-01-31T22:31:18.688575Z","iopub.execute_input":"2022-01-31T22:31:18.689108Z","iopub.status.idle":"2022-01-31T22:31:20.054569Z","shell.execute_reply.started":"2022-01-31T22:31:18.68907Z","shell.execute_reply":"2022-01-31T22:31:20.053664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import some common libraries\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport random\nimport copy\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport ast\nimport seaborn as sns","metadata":{"id":"VpX5ZrCBmZVs","execution":{"iopub.status.busy":"2022-01-31T22:31:20.056017Z","iopub.execute_input":"2022-01-31T22:31:20.056286Z","iopub.status.idle":"2022-01-31T22:31:20.729336Z","shell.execute_reply.started":"2022-01-31T22:31:20.056249Z","shell.execute_reply":"2022-01-31T22:31:20.728648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- Read data ---\n# TRAIN_PATH = '/kaggle/input/tensorflow-great-barrier-reef'\n# Read in the data CSV files\ndf = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\")\ndf.head(5)","metadata":{"id":"2OAi-12emdhL","execution":{"iopub.status.busy":"2022-01-31T22:31:20.730577Z","iopub.execute_input":"2022-01-31T22:31:20.73085Z","iopub.status.idle":"2022-01-31T22:31:20.812877Z","shell.execute_reply.started":"2022-01-31T22:31:20.730817Z","shell.execute_reply":"2022-01-31T22:31:20.812235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !curl -L https://app.roboflow.com/ds/nLiiHYKSAX?key=89k9yeQp9G > roboflow.zip; unzip roboflow.zip; rm roboflow.zip","metadata":{"execution":{"iopub.status.busy":"2022-01-31T22:44:07.904288Z","iopub.execute_input":"2022-01-31T22:44:07.90487Z","iopub.status.idle":"2022-01-31T22:44:07.908636Z","shell.execute_reply.started":"2022-01-31T22:44:07.904829Z","shell.execute_reply":"2022-01-31T22:44:07.907848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.data.datasets import register_coco_instances\nDatasetCatalog.clear()\n\nregister_coco_instances(\"coco_train_dataset\", {}, \"./train/_annotations.coco.json\" ,   \"./train\")\nregister_coco_instances(\"coco_test_dataset\", {}, \"./valid/_annotations.coco.json\" ,   \"./valid\")\n","metadata":{"id":"5j9HjWn0qZo1","execution":{"iopub.status.busy":"2022-01-31T22:31:39.506582Z","iopub.execute_input":"2022-01-31T22:31:39.507136Z","iopub.status.idle":"2022-01-31T22:31:39.513206Z","shell.execute_reply.started":"2022-01-31T22:31:39.507095Z","shell.execute_reply":"2022-01-31T22:31:39.512515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train_metadata = MetadataCatalog.get(\"coco_train_dataset\")\ndataset_train = DatasetCatalog.get(\"coco_train_dataset\")","metadata":{"id":"gne99tfRqr1e","execution":{"iopub.status.busy":"2022-01-31T22:31:39.516137Z","iopub.execute_input":"2022-01-31T22:31:39.51638Z","iopub.status.idle":"2022-01-31T22:31:40.100501Z","shell.execute_reply.started":"2022-01-31T22:31:39.516349Z","shell.execute_reply":"2022-01-31T22:31:40.099745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test_metadata = MetadataCatalog.get(\"coco_test_dataset\")\ndataset_test = DatasetCatalog.get(\"coco_test_dataset\")","metadata":{"id":"42WLN5TVq0Yd","execution":{"iopub.status.busy":"2022-01-31T22:31:40.10195Z","iopub.execute_input":"2022-01-31T22:31:40.102186Z","iopub.status.idle":"2022-01-31T22:31:40.124302Z","shell.execute_reply.started":"2022-01-31T22:31:40.102152Z","shell.execute_reply":"2022-01-31T22:31:40.123445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nfrom detectron2.utils.visualizer import Visualizer\n\nfig, ax = plt.subplots(3, 1, figsize =(20,20))\ni=0\n\nfor d in random.sample(dataset_train, 3):\n    img = cv2.imread(d[\"file_name\"])\n    \n    #print(d)\n    print(\"Nombre y ruta del archivo:\", d.get('file_name'))\n    print(\"Id de la imagen:\", d.get('image_id'))\n    print(\"\")\n    print(\"Información de la primera máscara:\")\n    #print(d['annotations'][0].keys())\n    print(\"Formato del BBox: \",d['annotations'][0].get('bbox_mode'))\n    print(\"Ubicación xy, y dimensiones WH: \",d['annotations'][0].get('bbox'))\n    print(\"Categoría:\",d['annotations'][0].get('category_id')+1)\n    #print(d['annotations'][0].get('iscrowd'))\n    \n    visualizer = Visualizer(img[:, :, ::-1], metadata=dataset_train_metadata, scale=0.5)\n    vis = visualizer.draw_dataset_dict(d)\n    \n    ax[i].grid(False)\n    ax[i].axis('off')\n    ax[i].imshow(cv2.cvtColor(vis.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n    i += 1\n","metadata":{"id":"WyvKOxIpq7Wk","execution":{"iopub.status.busy":"2022-01-31T22:31:40.125687Z","iopub.execute_input":"2022-01-31T22:31:40.126288Z","iopub.status.idle":"2022-01-31T22:31:40.953818Z","shell.execute_reply.started":"2022-01-31T22:31:40.126251Z","shell.execute_reply":"2022-01-31T22:31:40.953122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_mapper (dataset_dict):\n    # Implement a mapper, similar to the default DatasetMapper, but with your own customizations\n    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n\n    image, transforms = T.apply_transform_gens([\n        T.RandomFlip(prob=0.20, horizontal=True, vertical=False),\n        T.RandomFlip(prob=0.20, horizontal=False, vertical=True),\n        T.RandomApply(T.RandomBrightness(intensity_min=0.75, intensity_max=1.25),\n                      prob=0.20),\n        T.RandomApply(T.RandomContrast(intensity_min=0.76, intensity_max=1.25),\n                      prob=0.20),\n        T.RandomApply(T.RandomCrop(crop_type=\"relative_range\", crop_size=(0.8, 0.8)), \n                      prob=0.20),\n        T.RandomApply(T.RandomSaturation(intensity_min=0.75, intensity_max=1.25), \n                      prob=0.20),\n#         T.Resize(shape=(1024, 1024)),\n        T.RandomApply(T.RandomRotation(angle=[-30,30], expand=True, center=None, sample_style=\"range\", interp=None), \n                      prob=0.20)\n\n    ], image)\n    \n    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n\n    annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n        if obj.get(\"iscrowd\", 0) == 0\n    ]\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n    return dataset_dict","metadata":{"id":"HWf2rCjerPhw","execution":{"iopub.status.busy":"2022-01-31T22:31:40.954816Z","iopub.execute_input":"2022-01-31T22:31:40.95514Z","iopub.status.idle":"2022-01-31T22:31:40.969394Z","shell.execute_reply.started":"2022-01-31T22:31:40.955106Z","shell.execute_reply":"2022-01-31T22:31:40.968667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\nfrom detectron2.evaluation import COCOEvaluator\n\nclass MyTrainer(DefaultTrainer):\n    @classmethod\n    def build_train_loader(cls, cfg):\n        return build_detection_train_loader(cfg)\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n        return COCOEvaluator(dataset_name, cfg, True, output_folder)","metadata":{"id":"8Cm_HS2msdcE","execution":{"iopub.status.busy":"2022-01-31T22:32:48.628331Z","iopub.execute_input":"2022-01-31T22:32:48.62861Z","iopub.status.idle":"2022-01-31T22:32:48.634336Z","shell.execute_reply.started":"2022-01-31T22:32:48.628564Z","shell.execute_reply":"2022-01-31T22:32:48.633673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = get_cfg() # initialize cfg object\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))  # load default parameters for Mask R-CNN\ncfg.DATASETS.TRAIN = (\"coco_train_dataset\",)  # dataset used for training model\ncfg.DATASETS.TEST = (\"coco_test_dataset\", )  # we will look at the predictions on both sets after training\n\ncfg.SOLVER.CHECKPOINT_PERIOD = 1000  # number of iterations after which to save model checkpoints\ncfg.MODEL.DEVICE='cuda'  # 'cpu' to force model to run on cpu, 'cuda' if you have a compatible gpu\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.SOLVER.IMS_PER_BATCH = 2 # number of images per batch (across all machines)\ncfg.TEST.EVAL_PERIOD = 1000\ncfg.SOLVER.BASE_LR = 0.0025\ncfg.SOLVER.MAX_ITER = 8000\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n\n\n\n\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.OUTPUT_DIR = \"./\"\n  \n\ntrainer = MyTrainer(cfg)\n","metadata":{"id":"y1y6kKjwsfrs","execution":{"iopub.status.busy":"2022-01-31T22:32:49.6535Z","iopub.execute_input":"2022-01-31T22:32:49.654181Z","iopub.status.idle":"2022-01-31T22:32:54.815472Z","shell.execute_reply.started":"2022-01-31T22:32:49.654141Z","shell.execute_reply":"2022-01-31T22:32:54.81481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_loader = trainer.build_train_loader(cfg)\ndata_iter = iter(train_data_loader)\nbatch = next(data_iter)","metadata":{"id":"e3DFuyQ1siOD","execution":{"iopub.status.busy":"2022-01-31T22:33:22.515471Z","iopub.execute_input":"2022-01-31T22:33:22.516801Z","iopub.status.idle":"2022-01-31T22:33:24.151574Z","shell.execute_reply.started":"2022-01-31T22:33:22.516754Z","shell.execute_reply":"2022-01-31T22:33:24.150059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize =(40,20))\n\nper_image = batch[:1555][0]\n\nimg = cv2.imread(per_image[\"file_name\"])\n\n\n\nax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nax[0].set_title(\"Original image\")\n\n\nimg = per_image[\"image\"].permute(1, 2, 0).cpu().detach().numpy()\nimg = utils.convert_image_to_rgb(img, cfg.INPUT.FORMAT)\n\nvisualizer = Visualizer(img, scale=0.5)\ntarget_fields = per_image[\"instances\"].get_fields()\nlabels = None\nvis = visualizer.overlay_instances(\n        labels=labels,\n        boxes=target_fields.get(\"gt_boxes\", None),\n        masks=target_fields.get(\"gt_masks\", None),\n        keypoints=target_fields.get(\"gt_keypoints\", None),\n    )\nax[1].imshow(cv2.cvtColor(vis.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\nax[1].set_title(\"Augmentated\")\n\nplt.show()","metadata":{"id":"j3HGYOFDt7CC","execution":{"iopub.status.busy":"2022-01-31T22:33:24.164502Z","iopub.execute_input":"2022-01-31T22:33:24.164967Z","iopub.status.idle":"2022-01-31T22:33:25.373143Z","shell.execute_reply.started":"2022-01-31T22:33:24.164915Z","shell.execute_reply":"2022-01-31T22:33:25.372323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set trainer:\ntrainer.resume_or_load(resume=True)\n\n# Perform training:\ntrainer.train()","metadata":{"id":"Mk2ubepGCyfL","execution":{"iopub.status.busy":"2022-01-31T22:49:44.817387Z","iopub.execute_input":"2022-01-31T22:49:44.818097Z","iopub.status.idle":"2022-01-31T22:49:44.821764Z","shell.execute_reply.started":"2022-01-31T22:49:44.818056Z","shell.execute_reply":"2022-01-31T22:49:44.820804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = get_cfg() # initialize cfg object\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))  # load default parameters for Mask R-CNN\ncfg.MODEL.DEVICE='cuda'  # 'cpu' to force model to run on cpu, 'cuda' if you have a compatible gpu\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\ncfg.MODEL.WEIGHTS = '../input/model-31-01/model_0003999.pth'\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\npredictor = DefaultPredictor(cfg)","metadata":{"id":"oWcnifYgSoDC","execution":{"iopub.status.busy":"2022-01-31T22:42:34.718406Z","iopub.execute_input":"2022-01-31T22:42:34.718732Z","iopub.status.idle":"2022-01-31T22:42:42.184172Z","shell.execute_reply.started":"2022-01-31T22:42:34.718701Z","shell.execute_reply":"2022-01-31T22:42:42.183424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_testing = random.sample(dataset_test, 20)","metadata":{"execution":{"iopub.status.busy":"2022-01-31T22:51:44.820115Z","iopub.execute_input":"2022-01-31T22:51:44.820783Z","iopub.status.idle":"2022-01-31T22:51:44.825076Z","shell.execute_reply.started":"2022-01-31T22:51:44.820741Z","shell.execute_reply":"2022-01-31T22:51:44.824357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(20):\n    print(i)\n    fig, ax = plt.subplots(2, 1, figsize =(15,15))\n    img = cv2.imread(random_testing[i]['file_name'])\n\n    visualizer = Visualizer(img[:, :, ::-1],\n                          metadata=dataset_test_metadata,\n                          scale=0.5)\n    out = visualizer.draw_dataset_dict(random_testing[i])\n    ax[0].imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n    ax[0].set_title(\"Imagen original\")\n    outputs = predictor(img)\n    visualizer_pred = Visualizer(img[:, :, ::-1],\n                              metadata=dataset_test_metadata,\n                              scale=0.5)\n    pred = visualizer_pred.draw_instance_predictions(outputs['instances'].to('cpu'))\n  \n    ax[1].imshow(cv2.cvtColor(pred.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n    ax[1].set_title(\"Predicción\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-31T22:51:45.876882Z","iopub.execute_input":"2022-01-31T22:51:45.877396Z","iopub.status.idle":"2022-01-31T22:52:11.047977Z","shell.execute_reply.started":"2022-01-31T22:51:45.877356Z","shell.execute_reply":"2022-01-31T22:52:11.046902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}