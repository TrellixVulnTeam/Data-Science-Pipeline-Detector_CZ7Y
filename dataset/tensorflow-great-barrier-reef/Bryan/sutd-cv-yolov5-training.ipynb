{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom shutil import copyfile","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-18T09:32:57.241373Z","iopub.execute_input":"2022-04-18T09:32:57.242046Z","iopub.status.idle":"2022-04-18T09:32:57.275388Z","shell.execute_reply.started":"2022-04-18T09:32:57.241955Z","shell.execute_reply":"2022-04-18T09:32:57.274534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\ntrain['pos'] = train.annotations != '[]'","metadata":{"execution":{"iopub.status.busy":"2022-04-18T09:32:59.807306Z","iopub.execute_input":"2022-04-18T09:32:59.80789Z","iopub.status.idle":"2022-04-18T09:32:59.875398Z","shell.execute_reply.started":"2022-04-18T09:32:59.807856Z","shell.execute_reply":"2022-04-18T09:32:59.874591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./yolo_data/fold1/images/val\n!mkdir -p ./yolo_data/fold1/images/train\n\n!mkdir -p ./yolo_data/fold1/labels/val\n!mkdir -p ./yolo_data/fold1/labels/train","metadata":{"execution":{"iopub.status.busy":"2022-04-18T09:33:02.34371Z","iopub.execute_input":"2022-04-18T09:33:02.344019Z","iopub.status.idle":"2022-04-18T09:33:05.26685Z","shell.execute_reply.started":"2022-04-18T09:33:02.343989Z","shell.execute_reply":"2022-04-18T09:33:05.265664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 1\n\nannos = []\nfor i, x in train.iterrows():\n    if x.video_id == fold:\n        mode = 'val'\n    else:\n        # train\n        mode = 'train'\n        if not x.pos: continue\n        # val\n    copyfile(f'../input/tensorflow-great-barrier-reef/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n                f'./yolo_data/fold{fold}/images/{mode}/{x.image_id}.jpg')\n    if not x.pos:\n        continue\n    r = ''\n    anno = eval(x.annotations)\n    for an in anno:\n#            annos.append(an)\n        r += '0 {} {} {} {}\\n'.format((an['x'] + an['width'] / 2) / 1280,\n                                        (an['y'] + an['height'] / 2) / 720,\n                                        an['width'] / 1280, an['height'] / 720)\n    with open(f'./yolo_data/fold{fold}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n        fp.write(r)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T09:33:08.020218Z","iopub.execute_input":"2022-04-18T09:33:08.020725Z","iopub.status.idle":"2022-04-18T09:34:11.553187Z","shell.execute_reply.started":"2022-04-18T09:33:08.020692Z","shell.execute_reply":"2022-04-18T09:34:11.549977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyps = '''\n# YOLOv5 by Ultralytics, GPL-3.0 license\n# Hyperparameters for COCO training from scratch\n# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n\nlr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937  # SGD momentum/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 3.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # image HSV-Value augmentation (fraction)\ndegrees: 0.0  # image rotation (+/- deg)\ntranslate: 0.1  # image translation (+/- fraction)\nscale: 0.5  # image scale (+/- gain)\nshear: 0.0  # image shear (+/- deg)\nperspective: 0.0  # image perspective (+/- fraction), range 0-0.001\nflipud: 0.5  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 1.0  # image mosaic (probability)\nmixup: 0.5  # image mixup (probability)\ncopy_paste: 0.0  # segment copy-paste (probability)\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = '''\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\npath: ../yolo_data/fold1/  # dataset root dir\ntrain: images/train  # train images (relative to 'path') 128 images\nval: images/val  # val images (relative to 'path') 128 images\ntest:  # test images (optional)\n\n# Classes\nnc: 1  # number of classes\nnames: ['reef']  # class names\n\n\n# Download script/URL (optional)\n# download: https://ultralytics.com/assets/coco128.zip\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5.git","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./yolov5/data/reef_f1_naive.yaml', 'w') as fp:\n    fp.write(data)\nwith open('./yolov5/data/hyps/hyp.heavy.2.yaml', 'w') as fp:\n    fp.write(hyps)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd yolov5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls data/","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --img 3000 --batch 4 --epochs 5 --data reef_f1_naive.yaml --weights yolov5s6.pt --name l6_3600_uflip_vm5_f1 --hyp data/hyps/hyp.heavy.2.yaml","metadata":{},"execution_count":null,"outputs":[]}]}