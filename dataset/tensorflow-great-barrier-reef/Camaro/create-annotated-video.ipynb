{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport os\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = 30, 30","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-23T03:39:28.956807Z","iopub.execute_input":"2021-11-23T03:39:28.957875Z","iopub.status.idle":"2021-11-23T03:39:29.218968Z","shell.execute_reply.started":"2021-11-23T03:39:28.957731Z","shell.execute_reply":"2021-11-23T03:39:29.217843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/tensorflow-great-barrier-reef/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T03:39:29.220843Z","iopub.execute_input":"2021-11-23T03:39:29.221108Z","iopub.status.idle":"2021-11-23T03:39:29.304148Z","shell.execute_reply.started":"2021-11-23T03:39:29.221077Z","shell.execute_reply":"2021-11-23T03:39:29.303112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ast import literal_eval\n\n\ndef load_image(video_id, video_frame, image_dir):\n    img_path = f'{image_dir}/video_{video_id}/{video_frame}.jpg'\n    assert os.path.exists(img_path), f'{img_path} does not exist.'\n    img = cv2.imread(img_path)\n    return img\n\n\ndef decode_annotations(annotaitons_str):\n    \"\"\"decode annotations in string to list of dict\"\"\"\n    return literal_eval(annotaitons_str)\n\ndef load_image_with_annotations(video_id, video_frame, image_dir, annotaitons_str):\n    img = load_image(video_id, video_frame, image_dir)\n    annotations = decode_annotations(annotaitons_str)\n    if len(annotations) > 0:\n        for ann in annotations:\n            cv2.rectangle(img, (ann['x'], ann['y']),\n                (ann['x'] + ann['width'], ann['y'] + ann['height']),\n                (0, 255, 255), thickness=2,)\n    return img\n\n#test\nindex = 16\nrow = df.iloc[index]\nvideo_id = row.video_id\nvideo_frame = row.video_frame\nannotations_str = row.annotations\nimage_dir = '../input/tensorflow-great-barrier-reef/train_images'\nimg = load_image_with_annotations(video_id, video_frame, image_dir, annotations_str)\nplt.imshow(img[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T03:39:29.305733Z","iopub.execute_input":"2021-11-23T03:39:29.30611Z","iopub.status.idle":"2021-11-23T03:39:31.249366Z","shell.execute_reply.started":"2021-11-23T03:39:29.306063Z","shell.execute_reply":"2021-11-23T03:39:31.248535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport subprocess\n\ndef make_video(df, video_id, image_dir):\n    # partly borrowed from https://github.com/RobMulla/helmet-assignment/blob/main/helmet_assignment/video.py\n    fps = 15 # don't know exact value\n    width = 1280\n    height = 720\n    save_path = f'video{video_id}.mp4'\n    tmp_path = \"tmp_\" + save_path\n    output_video = cv2.VideoWriter(tmp_path, cv2.VideoWriter_fourcc(*\"MP4V\"), fps, (width, height))\n    \n    video_df = df.query('video_id == @video_id')\n    for _, row in tqdm(video_df.iterrows(), total=len(video_df)):\n        video_id = row.video_id\n        video_frame = row.video_frame\n        annotations_str = row.annotations\n        img = load_image_with_annotations(video_id, video_frame, image_dir, annotations_str)\n        output_video.write(img)\n    \n    output_video.release()\n    # Not all browsers support the codec, we will re-load the file at tmp_output_path\n    # and convert to a codec that is more broadly readable using ffmpeg\n    if os.path.exists(save_path):\n        os.remove(save_path)\n    subprocess.run(\n        [\"ffmpeg\", \"-i\", tmp_path, \"-crf\", \"18\", \"-preset\", \"veryfast\", \"-vcodec\", \"libx264\", save_path]\n    )\n    os.remove(tmp_path)\n\nfor video_id in list(df['video_id'].unique()):\n    make_video(df, video_id, image_dir)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T03:39:31.251116Z","iopub.execute_input":"2021-11-23T03:39:31.251503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Video, display\nVideo('video0.mp4')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}