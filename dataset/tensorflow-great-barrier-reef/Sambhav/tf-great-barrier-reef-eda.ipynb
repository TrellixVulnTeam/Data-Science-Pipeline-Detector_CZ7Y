{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport ast\nimport tqdm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-14T00:54:58.366563Z","iopub.execute_input":"2022-01-14T00:54:58.366953Z","iopub.status.idle":"2022-01-14T00:54:58.486008Z","shell.execute_reply.started":"2022-01-14T00:54:58.366843Z","shell.execute_reply":"2022-01-14T00:54:58.485125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get all dirs and paths","metadata":{}},{"cell_type":"code","source":"dataset_path = Path('../input/tensorflow-great-barrier-reef/') \ntrain_root_path = dataset_path / 'train_images'\ntrain_paths = list(train_root_path.rglob('*.jpg'))\n\ntrain_csv_path = dataset_path / \"train.csv\"\ntest_csv_path = dataset_path / \"test.csv\"\n\nrgb2bgr = lambda x : cv2.cvtColor(x, cv2.COLOR_RGB2BGR)\nbgr2rgb = lambda x : cv2.cvtColor(x, cv2.COLOR_BGR2RGB)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:54:58.487313Z","iopub.execute_input":"2022-01-14T00:54:58.488021Z","iopub.status.idle":"2022-01-14T00:55:15.681046Z","shell.execute_reply.started":"2022-01-14T00:54:58.487983Z","shell.execute_reply":"2022-01-14T00:55:15.679999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (f\"dirs in dataset root: {os.listdir(dataset_path)}\")\nprint (f\"sample train paths: {train_paths[:2]}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:15.682363Z","iopub.execute_input":"2022-01-14T00:55:15.682652Z","iopub.status.idle":"2022-01-14T00:55:15.687991Z","shell.execute_reply.started":"2022-01-14T00:55:15.682618Z","shell.execute_reply":"2022-01-14T00:55:15.68739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### lets see what the csv's contain","metadata":{}},{"cell_type":"code","source":"# train_df = pd.read_csv(train_csv_path)\n# test_df = pd.read_csv(test_csv_path)\n\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:15.68992Z","iopub.execute_input":"2022-01-14T00:55:15.690176Z","iopub.status.idle":"2022-01-14T00:55:15.754016Z","shell.execute_reply.started":"2022-01-14T00:55:15.690145Z","shell.execute_reply":"2022-01-14T00:55:15.753267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add image paths according to video name and frame number\ntrain_df['path'] = train_df.apply(lambda row: '../input/tensorflow-great-barrier-reef/train_images/video_' \n                                  + str(row['video_id'])  + f\"/{row['video_frame']}.jpg\", axis = 1)\ntrain_df['annotations'] = train_df['annotations'].apply(ast.literal_eval)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:15.755166Z","iopub.execute_input":"2022-01-14T00:55:15.755571Z","iopub.status.idle":"2022-01-14T00:55:16.408774Z","shell.execute_reply.started":"2022-01-14T00:55:15.755541Z","shell.execute_reply":"2022-01-14T00:55:16.407779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_valid_annots = train_df[train_df.apply(lambda x: len(x['annotations']) > 0, axis=1)]\ntrain_df_valid_annots.reset_index(inplace = True, drop = True)\ntrain_df_valid_annots","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:16.410343Z","iopub.execute_input":"2022-01-14T00:55:16.410699Z","iopub.status.idle":"2022-01-14T00:55:16.649696Z","shell.execute_reply.started":"2022-01-14T00:55:16.410646Z","shell.execute_reply":"2022-01-14T00:55:16.648836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:16.651264Z","iopub.execute_input":"2022-01-14T00:55:16.651728Z","iopub.status.idle":"2022-01-14T00:55:16.663249Z","shell.execute_reply.started":"2022-01-14T00:55:16.651685Z","shell.execute_reply":"2022-01-14T00:55:16.662611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### lets load a sample image ","metadata":{}},{"cell_type":"code","source":"img = cv2.imread(train_df['path'][0])\nprint (f'image shape is {img.shape}')\n\nplt.figure(figsize = (10, 10))\nplt.imshow(bgr2rgb(img))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:16.664344Z","iopub.execute_input":"2022-01-14T00:55:16.66462Z","iopub.status.idle":"2022-01-14T00:55:17.227929Z","shell.execute_reply.started":"2022-01-14T00:55:16.664591Z","shell.execute_reply":"2022-01-14T00:55:17.227112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets plot a bounding box for a single sample","metadata":{}},{"cell_type":"code","source":"idx = 42\nimg = cv2.imread(train_df_valid_annots['path'][idx])\nbboxs = train_df_valid_annots['annotations'][idx]\n\nfor bbox in bboxs:\n    x1 = bbox['x']\n    y1 = bbox['y']\n    x2 = bbox['x'] + bbox['width']\n    y2 = bbox['y'] + bbox['height']\n    img = cv2.rectangle(img, [x1, y1], [x2, y2], [0, 0, 255], 10)\n    \n    \nprint (f'image shape is {img.shape}')\n\nplt.figure(figsize = (10, 10))\nplt.imshow(bgr2rgb(img))","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:17.229371Z","iopub.execute_input":"2022-01-14T00:55:17.230115Z","iopub.status.idle":"2022-01-14T00:55:17.876324Z","shell.execute_reply.started":"2022-01-14T00:55:17.230068Z","shell.execute_reply":"2022-01-14T00:55:17.875603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### plotting bounding box stats","metadata":{}},{"cell_type":"code","source":"train_df['num_bboxs'] = train_df['annotations'].apply(lambda x : len(x))\n\nnum_with_annots = np.count_nonzero(train_df['num_bboxs'])\nnum_without_annots = len(train_df) - num_with_annots\n\ny_lbl = (num_with_annots, num_without_annots)\nx_lbl = ['ANNOTATED IMAGES', 'NON-ANNOTATED IMAGES']\n\nfig = plt.figure(figsize = (10, 5))\nplt.bar(x_lbl, y_lbl)\n\nplt.xticks(fontsize = 13)\nplt.yticks(fontsize = 13)\nplt.ylim(0, max(y_lbl) + 2000)\n\nfor i in range(len(y_lbl)):\n    plt.annotate(str(y_lbl[i]), xy=(x_lbl[i],y_lbl[i]), ha='center', va='bottom', fontsize = 13)\n    \nplt.title('Annotated v/s Non Annotated Images', fontsize = 20);","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:17.87741Z","iopub.execute_input":"2022-01-14T00:55:17.878076Z","iopub.status.idle":"2022-01-14T00:55:18.103067Z","shell.execute_reply.started":"2022-01-14T00:55:17.878029Z","shell.execute_reply":"2022-01-14T00:55:18.102131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**A lot of the images in the train dataframe seem to be unannotated, maybe we can use pseudo-labelling or similar techniques for the training dataset**","metadata":{}},{"cell_type":"code","source":"bbox_list = []\n\nfor bboxs in train_df_valid_annots['annotations']:\n    for bbox in bboxs:\n        bbox_list.append(bbox)\n        \nbbox_df = pd.DataFrame(bbox_list)\nbbox_df['aspect_ratio'] = bbox_df['width'] / bbox_df['height']\nbbox_df['area'] = bbox_df['width'] * bbox_df['height']","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:18.104454Z","iopub.execute_input":"2022-01-14T00:55:18.104734Z","iopub.status.idle":"2022-01-14T00:55:18.135282Z","shell.execute_reply.started":"2022-01-14T00:55:18.104702Z","shell.execute_reply":"2022-01-14T00:55:18.134355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10, 5))\nbbox_df['aspect_ratio'].hist(bins = 200)\nplt.title('distribution of bbox aspect ratios', fontsize = 20)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:18.136448Z","iopub.execute_input":"2022-01-14T00:55:18.136685Z","iopub.status.idle":"2022-01-14T00:55:18.71221Z","shell.execute_reply.started":"2022-01-14T00:55:18.136656Z","shell.execute_reply":"2022-01-14T00:55:18.711311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the bboxs seem to have a slightly greater width than height, but the bounding boxes in most cases don't seem to be thin/skewed","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize = (10, 5))\nbbox_df['area'].hist(bins = 200)\nplt.title('distribution of bbox areas', fontsize = 20)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:55:18.715342Z","iopub.execute_input":"2022-01-14T00:55:18.715739Z","iopub.status.idle":"2022-01-14T00:55:19.3039Z","shell.execute_reply.started":"2022-01-14T00:55:18.715702Z","shell.execute_reply":"2022-01-14T00:55:19.302935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generating annotated videos","metadata":{}},{"cell_type":"code","source":"os.makedirs('videos', exist_ok = True)\n\nfor video_id in tqdm.tqdm_notebook(set(train_df['video_id'])):\n    temp_df = train_df[train_df['video_id'] == video_id]\n    temp_df.reset_index(inplace = True)\n    \n    print (f'writing video {video_id}')\n    \n    sample_img = cv2.imread(temp_df['path'][0])\n    \n    frame_width = int(sample_img.shape[1])\n    frame_height = int(sample_img.shape[0])\n    frame_size = (frame_width,frame_height)\n    fps = 10.\n    \n    output = cv2.VideoWriter(f'videos/video{video_id}.mp4', cv2.VideoWriter_fourcc(*'MP4V'), fps, frame_size)\n\n    for i, row in tqdm.tqdm_notebook(temp_df.iterrows(), leave = False, total = len(temp_df)):\n        img = cv2.imread(row['path'])\n        bboxs = row['annotations']\n        \n        for bbox in bboxs:\n            x1 = bbox['x']\n            y1 = bbox['y']\n            x2 = bbox['x'] + bbox['width']\n            y2 = bbox['y'] + bbox['height']\n            \n            img = cv2.rectangle(img, [x1, y1], [x2, y2], [0, 0, 255], 10)\n        \n        \n        output.write(img)\n        \n    output.release()","metadata":{"execution":{"iopub.status.busy":"2022-01-14T00:56:57.192015Z","iopub.execute_input":"2022-01-14T00:56:57.192543Z","iopub.status.idle":"2022-01-14T01:01:07.893917Z","shell.execute_reply.started":"2022-01-14T00:56:57.192488Z","shell.execute_reply":"2022-01-14T01:01:07.8925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}