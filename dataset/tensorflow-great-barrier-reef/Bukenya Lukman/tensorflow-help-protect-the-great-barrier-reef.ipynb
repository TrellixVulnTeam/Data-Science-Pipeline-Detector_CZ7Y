{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport os\nos.chdir('/kaggle/input/tensorflow-great-barrier-reef')\nos.listdir()\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-29T08:07:50.461891Z","iopub.execute_input":"2021-11-29T08:07:50.462855Z","iopub.status.idle":"2021-11-29T08:07:50.472378Z","shell.execute_reply.started":"2021-11-29T08:07:50.462817Z","shell.execute_reply":"2021-11-29T08:07:50.471343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_df = pd.read_csv(\"train.csv\")\ndf_train_df","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:08:22.866823Z","iopub.execute_input":"2021-11-29T08:08:22.867117Z","iopub.status.idle":"2021-11-29T08:08:22.948521Z","shell.execute_reply.started":"2021-11-29T08:08:22.867087Z","shell.execute_reply":"2021-11-29T08:08:22.947542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Checking for duplicates\ndf_train_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:09:28.54632Z","iopub.execute_input":"2021-11-29T08:09:28.547349Z","iopub.status.idle":"2021-11-29T08:09:28.566091Z","shell.execute_reply.started":"2021-11-29T08:09:28.547305Z","shell.execute_reply":"2021-11-29T08:09:28.565315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###checking frames with annotations\ndf_train_df[df_train_df.annotations.str.len() > 2]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:11:01.64348Z","iopub.execute_input":"2021-11-29T08:11:01.64398Z","iopub.status.idle":"2021-11-29T08:11:01.680858Z","shell.execute_reply.started":"2021-11-29T08:11:01.643947Z","shell.execute_reply":"2021-11-29T08:11:01.680279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Visualizing the annotations\nimport ast\nast.literal_eval(df_train_df.iloc[16].annotations)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:12:53.500953Z","iopub.execute_input":"2021-11-29T08:12:53.501266Z","iopub.status.idle":"2021-11-29T08:12:53.508873Z","shell.execute_reply.started":"2021-11-29T08:12:53.501236Z","shell.execute_reply":"2021-11-29T08:12:53.50818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Videos","metadata":{}},{"cell_type":"code","source":"## Verify in there is corrupted data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import listdir\nfrom PIL import Image\ndef validate_images(video_id):\n    path = 'train_images/video_{}/'.format(video_id) \n    print(\"Verifying that video {} frames are valid...\".format(video_id))\n    for filename in listdir(path):\n        if filename.endswith('.jpg'):\n            try:\n                img = Image.open(path+filename)\n                img.verify() \n            except (IOError, SyntaxError) as e:\n                print('Bad file:', filename) # Print out the names of corrupt files\n    print(\"Verified! Video {} has all valid images\".format(video_id))\n\nfor video_id in range(3):\n    validate_images(video_id)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:18:50.335514Z","iopub.execute_input":"2021-11-29T08:18:50.336531Z","iopub.status.idle":"2021-11-29T08:22:56.66688Z","shell.execute_reply.started":"2021-11-29T08:18:50.336462Z","shell.execute_reply":"2021-11-29T08:22:56.665889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Loading Sequences of images with annotations\nfrom PIL import Image, ImageDraw\n\ndef fetch_image_list(df_tmp, video_id, num_images, start_frame_idx):\n    def fetch_image(frame_id):\n        path_base = 'train_images/video_{}/{}.jpg'\n        raw_img = Image.open(path_base.format(video_id, frame_id))\n\n        row_frame = df_tmp[(df_tmp.video_id == video_id) & (df_tmp.video_frame == frame_id)].iloc[0]\n        bounding_boxes = ast.literal_eval(row_frame.annotations)\n\n        for box in bounding_boxes:\n            draw = ImageDraw.Draw(raw_img)\n            x0, y0, x1, y1 = (box['x'], box['y'], box['x']+box['width'], box['y']+box['height'])\n            draw.rectangle( (x0, y0, x1, y1), outline=180, width=3)\n        return raw_img\n\n    return [np.array(fetch_image(start_frame_idx + index)) for index in range(num_images)]\n\nimages = fetch_image_list(df_train_df, video_id = 0, num_images = 80, start_frame_idx = 25)\n\nprint(\"Num images: \", len(images))\nplt.imshow(images[0], interpolation='nearest')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:24:36.095853Z","iopub.execute_input":"2021-11-29T08:24:36.096752Z","iopub.status.idle":"2021-11-29T08:24:38.729977Z","shell.execute_reply.started":"2021-11-29T08:24:36.096704Z","shell.execute_reply":"2021-11-29T08:24:38.728868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##visualizing list of images as animations\nfrom matplotlib import animation, rc\nrc('animation', html='jshtml')\n\n\ndef create_animation(ims):\n    fig = plt.figure(figsize=(9, 9))\n    plt.axis('off')\n    im = plt.imshow(ims[0])\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//12)\n\ncreate_animation(images)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:16.370997Z","iopub.execute_input":"2021-11-29T08:26:16.371335Z","iopub.status.idle":"2021-11-29T08:26:28.074033Z","shell.execute_reply.started":"2021-11-29T08:26:16.371297Z","shell.execute_reply":"2021-11-29T08:26:28.072194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}