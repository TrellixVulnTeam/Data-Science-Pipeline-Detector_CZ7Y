{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/tfcots-ext')\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom yolox.models import *\nfrom yolox.my_yolox_head import *\nfrom yolox.models.boxes import postprocess\n\n#https://www.kaggle.com/remekkinas/yolox-training-pipeline-cots-dataset-lb-0-507\nimport greatbarrierreef\n\nis_cuda = True","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-02T09:31:50.998115Z","iopub.execute_input":"2022-01-02T09:31:50.998437Z","iopub.status.idle":"2022-01-02T09:31:53.53303Z","shell.execute_reply.started":"2022-01-02T09:31:50.998356Z","shell.execute_reply":"2022-01-02T09:31:53.532271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model definition\nconfigure={\n    'yolo-s': {\n        'depth' : 0.33,\n        'width' : 0.50,\n        'in_channels': [256, 512, 1024],\n        #'pretrain_file': root_dir + '/code/reference-00/YOLOX-main/weights/yolox_s.pth'\n    },\n    'yolo-x': {\n        'depth' : 1.33,\n        'width' : 1.25,\n        'in_channels': [256, 512, 1024],\n        #'pretrain_file': root_dir + '/code/reference-00/YOLOX-main/weights/yolox_x.pth'\n    },\n}\narch = 'yolo-s'\n\n\nclass Net(nn.Module):\n    def __init__(self,arch=arch):\n        super().__init__()\n        depth = configure[arch]['depth']\n        width = configure[arch]['width']\n        in_channels = configure[arch]['in_channels']\n        self.output_mode = 'none'\n\n        self.backbone = YOLOPAFPN(\n            depth=depth,\n            width=width,\n            in_features=('dark3', 'dark4', 'dark5'),\n            in_channels=in_channels,\n            depthwise=False,\n            act='silu',\n        )\n        self.head = MyYOLOXHead(\n            num_class=1,\n            width=width,\n            in_channel=in_channels,\n            act='silu',\n        )\n\n        if 1:\n            for m in self.modules():\n                if isinstance(m, nn.BatchNorm2d):\n                    m.eps = 1e-3\n                    m.momentum = 0.03\n\n        if 0:\n            pretrain_file =  configure[arch]['pretrain_file'] #root_dir + '/code/reference-00/YOLOX-main/weights/yolox_s.pth'\n            state_dict = torch.load(pretrain_file, map_location=lambda storage, loc: storage)['model']\n            for k in list(state_dict.keys()):\n                if any(i in k for i in ['head.cls_preds', ]): del state_dict[k]\n            self.load_state_dict(state_dict, strict=False)\n\n\n    def forward(self, x, target=None):\n        # fpn output content features of [dark3, dark4, dark5]\n        feature = self.backbone(x)\n        predict = self.head(feature)\n\n        if  self.output_mode == 'none':\n            return predict\n\n        if  self.output_mode == 'loss':\n            loss = self.head.predict_to_loss(predict, target)\n            return loss\n\n        if  self.output_mode == 'inference':\n            predict = self.head.predict_to_inference(predict)\n            return predict\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-02T09:31:53.534994Z","iopub.execute_input":"2022-01-02T09:31:53.535262Z","iopub.status.idle":"2022-01-02T09:31:53.549339Z","shell.execute_reply.started":"2022-01-02T09:31:53.535227Z","shell.execute_reply":"2022-01-02T09:31:53.548406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = '../input/tfcots-ext/yolox-s-1440x2560-aug3-fold0-00005250.model.pth'\n\nnet = Net(arch)\nf = torch.load(checkpoint, map_location=lambda storage, loc: storage)\nnet.load_state_dict(f['state_dict'], strict=True)\nnet = net.eval() \nif is_cuda: net = net.cuda() ","metadata":{"execution":{"iopub.status.busy":"2022-01-02T09:31:53.551547Z","iopub.execute_input":"2022-01-02T09:31:53.552214Z","iopub.status.idle":"2022-01-02T09:31:58.482364Z","shell.execute_reply.started":"2022-01-02T09:31:53.552176Z","shell.execute_reply":"2022-01-02T09:31:58.481617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inference_size =  (1440,2560)\nconfthre    = 0.40\nnmsthre     = 0.45\n\ndef resize_with_pad(image, size=inference_size):\n    height,width = image.shape[:2]\n    h,w = size\n\n    if h==height and w==width:\n        pad_image = image\n    else:\n        pad_image = np.full((h,w, 3), fill_value=0, dtype=np.uint8)\n        r = min(h/height, w/width)\n        h,w =int(height * r), int(width * r)\n        if r==1:\n            small = image\n        else:\n            small = cv2.resize( image, (w, h), interpolation=cv2.INTER_LINEAR,)\n        pad_image[:h, :w] = small\n\n    return pad_image\n\ndef image_to_tensor(image):\n    image = resize_with_pad(image)\n    image = np.ascontiguousarray(image.transpose(2,0,1))\n    x = torch.from_numpy(image).unsqueeze(0)\n    x = x.float() #/255\n    return x\n\ndef yolox_inference(image, net):\n    x = image_to_tensor(image) \n    if is_cuda: x = x.cuda() \n    \n    net.eval()\n    net.output_mode = 'inference'\n    with torch.no_grad():\n        #predict = net(x)\n        #predict = net.head.predict_to_inference(predict)\n        predict = net(x)\n        predict = postprocess( predict, 1, confthre, nmsthre, class_agnostic=True )\n\n    if predict[0] is None:\n        p_score  = np.zeros((0), np.float32)\n        p_label  = np.zeros((0), np.int32)\n        p_bbox   = np.zeros((0, 4), np.int32)\n        \n    else: \n        predict = predict[0].data.cpu().numpy() \n        bbox  = predict[:, 0:4]\n        score = predict[:, 4] * predict[:, 5]\n        label = predict[:, 5]\n\n        bbox /= min(x.shape[2] / image.shape[0], x.shape[3] / image.shape[1])\n        bbox[:, 2:] = bbox[:, 2:] - bbox[:, :2]  # x,y,w,h format\n        \n        p_bbox  = np.round(bbox).astype(np.int32)\n        p_score = score\n        p_label = label.astype(np.int32)\n        \n    return p_bbox, p_score, p_label\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-02T09:31:58.486079Z","iopub.execute_input":"2022-01-02T09:31:58.48776Z","iopub.status.idle":"2022-01-02T09:31:58.502587Z","shell.execute_reply.started":"2022-01-02T09:31:58.486694Z","shell.execute_reply":"2022-01-02T09:31:58.501871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if 1:\n    env = greatbarrierreef.make_env()   # initialize the environment\n    iter_test = env.iter_test()  \n\n    for (image, sample_df) in iter_test:\n\n        # change to opencv BGR\n        image = np.ascontiguousarray(image[:,:,::-1])\n\n        if 0:\n            print(image.shape)\n            print(sample_df)\n\n            fig = plt.figure(figsize=(24, 24))\n            plt.imshow(image[:,:,::-1])\n            #break\n\n\n        if 1:  \n            p_bbox, p_score, p_label = yolox_inference(image, net)\n\n            prediction = ''\n            for i in range(len(p_bbox)):\n                x, y, w, h = p_bbox[i] \n                score = p_score[i]\n                if score < confthre:\n                    continue\n\n                prediction += ' %0.8f %d %d %d %d'%(score, x, y, w, h)  \n            sample_df['annotations'] = prediction\n\n        env.predict(sample_df) \n        print('prediction:', sample_df)\n\n\n    #submit_df = pd.read_csv('submission.csv')\n    #submit_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T09:31:58.504418Z","iopub.execute_input":"2022-01-02T09:31:58.505337Z","iopub.status.idle":"2022-01-02T09:31:58.517338Z","shell.execute_reply.started":"2022-01-02T09:31:58.505298Z","shell.execute_reply":"2022-01-02T09:31:58.516572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check function\n\ndef run_check_net():\n    batch_size = 4\n    C, H, W = 3, 736, 1280\n    image = torch.randn(batch_size, C, H, W)\n\n    net = Net()\n    net.output_mode = 'inference'\n    predict = net(image)\n\n    print('image ', image.shape)\n    print('predict ', predict.shape)\n    \n\ndef run_check_detect_one():\n    #ground truth\n    annotation = [{'x': 515, 'y': 511, 'width': 71, 'height': 68}, {'x': 613, 'y': 364, 'width': 55, 'height': 51}, {'x': 666, 'y': 300, 'width': 57, 'height': 50}]\n    t_bbox = [list(a.values()) for a in annotation]\n    \n    image_file = '../input/tensorflow-great-barrier-reef/train_images/video_1/6876.jpg'\n    image = cv2.imread(image_file, cv2.IMREAD_COLOR)\n    \n    \n   \n    p_bbox, p_score, p_label = yolox_inference(image, net) \n    \n    for i, (x, y, w, h) in enumerate(t_bbox):\n        x = int(round(x))\n        y = int(round(y))\n        w = int(round(w))\n        h = int(round(h))  \n        cv2.rectangle(image, (x, y), (x + w, y + h), (225, 225, 225), 6)\n        \n    for i, (x, y, w, h) in enumerate(p_bbox):\n        x = int(round(x))\n        y = int(round(y))\n        w = int(round(w))\n        h = int(round(h)) \n        s = int(p_score[i]*255)\n        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, s), 3)\n        \n    \n    fig = plt.figure(figsize=(24, 24))\n    plt.imshow(image[:,:,::-1])\n    \n    print(p_bbox)\n    print(p_score)\n    \n    \n    \n    \n#-------------------------------------------\n#run_check_net()\n#run_check_detect_one()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T09:35:11.960232Z","iopub.execute_input":"2022-01-02T09:35:11.960496Z","iopub.status.idle":"2022-01-02T09:35:13.183033Z","shell.execute_reply.started":"2022-01-02T09:35:11.960467Z","shell.execute_reply":"2022-01-02T09:35:13.180798Z"},"trusted":true},"execution_count":null,"outputs":[]}]}