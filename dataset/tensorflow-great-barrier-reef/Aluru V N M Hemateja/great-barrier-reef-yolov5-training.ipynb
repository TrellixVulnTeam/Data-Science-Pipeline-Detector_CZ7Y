{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone repo\n%cd yolov5\n\n# Install dependencies\n%pip install -qr requirements.txt  \n\n# change directory\n%cd ../\nimport torch\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:04.127033Z","iopub.execute_input":"2021-12-09T11:44:04.12731Z","iopub.status.idle":"2021-12-09T11:44:12.688095Z","shell.execute_reply.started":"2021-12-09T11:44:04.12727Z","shell.execute_reply":"2021-12-09T11:44:12.687191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Install W&B \n# !pip install -q --upgrade wandb\n\n# # Login \n# import wandb\n\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient() \n\n# personal_key_for_api = user_secrets.get_secret(\"ke\")\n# ! wandb login $personal_key_for_api","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom itertools import groupby\nimport numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\nimport os\nimport pickle\nimport cv2\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\n# import cupy as cp\nimport ast\nimport glob\nfrom os import listdir\nfrom os.path import isfile, join\nfrom glob import glob\nimport yaml\n\nimport shutil\nfrom shutil import copyfile\nimport sys\n\nfrom joblib import Parallel, delayed\n\n# --- Read data ---\nTRAIN_PATH = '/kaggle/input/tensorflow-great-barrier-reef'","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:12.689957Z","iopub.execute_input":"2021-12-09T11:44:12.690235Z","iopub.status.idle":"2021-12-09T11:44:12.752141Z","shell.execute_reply.started":"2021-12-09T11:44:12.690197Z","shell.execute_reply":"2021-12-09T11:44:12.751347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\ndef get_path(row):\n    row['image_path'] = f'{TRAIN_PATH}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    return row\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\ndef coco2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normolizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef yolo2coco(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n    return bboxes\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None):\n    # Plots one bounding box on image img\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [0, 0, 255], thickness=tf, lineType=cv2.LINE_AA)\n\n\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n    \n    if bbox_format == 'yolo':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:\n            \n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n                h  = round(float(bbox[3])*image.shape[0]/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness)\n            \n    elif bbox_format == 'coco':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:            \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                w  = int(round(bbox[2]))\n                h  = int(round(bbox[3]))\n\n                voc_bbox = (x1, y1, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n\n    elif bbox_format == 'voc_pascal':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes: \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                x2 = int(round(bbox[2]))\n                y2 = int(round(bbox[3]))\n                voc_bbox = (x1, y1, x2, y2)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\nnp.random.seed(8)\ncolors = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\ncolors=(255,0,0)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:12.753807Z","iopub.execute_input":"2021-12-09T11:44:12.754063Z","iopub.status.idle":"2021-12-09T11:44:12.783972Z","shell.execute_reply.started":"2021-12-09T11:44:12.754029Z","shell.execute_reply":"2021-12-09T11:44:12.783045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# Read in the data CSV files\ndf = pd.read_csv(\"/kaggle/input/tensorflow-great-barrier-reef/train.csv\")\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:17.463822Z","iopub.execute_input":"2021-12-09T11:44:17.464318Z","iopub.status.idle":"2021-12-09T11:44:17.507946Z","shell.execute_reply.started":"2021-12-09T11:44:17.46428Z","shell.execute_reply":"2021-12-09T11:44:17.507243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"NumBBox\"]=df['annotations'].apply(lambda x: str.count(x, 'x'))\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:18.638012Z","iopub.execute_input":"2021-12-09T11:44:18.638271Z","iopub.status.idle":"2021-12-09T11:44:18.668437Z","shell.execute_reply.started":"2021-12-09T11:44:18.638243Z","shell.execute_reply":"2021-12-09T11:44:18.667744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=df[df[\"NumBBox\"]>0]\ndf_train.sample(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:19.166693Z","iopub.execute_input":"2021-12-09T11:44:19.167478Z","iopub.status.idle":"2021-12-09T11:44:19.181702Z","shell.execute_reply.started":"2021-12-09T11:44:19.16743Z","shell.execute_reply":"2021-12-09T11:44:19.180992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['annotations'] = df_train['annotations'].progress_apply(lambda x: ast.literal_eval(x))\ndf_train['bboxes'] = df_train.annotations.progress_apply(get_bbox)\ndf_train.sample(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:20.70163Z","iopub.execute_input":"2021-12-09T11:44:20.702185Z","iopub.status.idle":"2021-12-09T11:44:21.029912Z","shell.execute_reply.started":"2021-12-09T11:44:20.702146Z","shell.execute_reply":"2021-12-09T11:44:21.029197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"Width\"]=1280\ndf_train[\"Height\"]=720\ndf_train.sample(2)\n\ndf_train = df_train.progress_apply(get_path, axis=1)\ndf_train.sample(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:21.03154Z","iopub.execute_input":"2021-12-09T11:44:21.031969Z","iopub.status.idle":"2021-12-09T11:44:24.923476Z","shell.execute_reply.started":"2021-12-09T11:44:21.031929Z","shell.execute_reply":"2021-12-09T11:44:24.922696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_v = df_train[(df_train.NumBBox==13)].sample(2) \nfig,ax = plt.subplots(1,2,figsize=(30,20))\ni=0;\nfor index, row in df_v.iterrows():\n    img           = load_image(row.image_path)\n    image_height  = row.Height\n    image_width   = row.Width\n    bboxes_coco   = np.array(row.bboxes)\n    bboxes_yolo   = coco2yolo(image_height, image_width, bboxes_coco)\n    names         = ['COTS']*len(bboxes_coco)\n    labels        = [0]*len(bboxes_coco)\n    im=draw_bboxes(img = img,\n                           bboxes = bboxes_yolo, \n                           classes = names,\n                           class_ids = labels,\n                           class_name = True, \n                           colors = colors, \n                           bbox_format = 'yolo',\n                           line_thickness = 2)\n    ax[i].imshow(im)\n    ax[i].axis('OFF')\n    i=i+1","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:24.925551Z","iopub.execute_input":"2021-12-09T11:44:24.926059Z","iopub.status.idle":"2021-12-09T11:44:25.834994Z","shell.execute_reply.started":"2021-12-09T11:44:24.926019Z","shell.execute_reply":"2021-12-09T11:44:25.834326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nEPOCHS = 30\nIMG_SIZE=1280\nSelected_Fold=4  #0..4","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:25.835903Z","iopub.execute_input":"2021-12-09T11:44:25.836119Z","iopub.status.idle":"2021-12-09T11:44:25.840082Z","shell.execute_reply.started":"2021-12-09T11:44:25.836091Z","shell.execute_reply":"2021-12-09T11:44:25.839526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\nkf = GroupKFold(n_splits = 5) \ndf_train = df_train.reset_index(drop=True)\ndf_train['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(kf.split(df_train, y = df_train.video_id.tolist(), groups=df_train.sequence)):\n    df_train.loc[val_idx, 'fold'] = fold\ndisplay(df_train.fold.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:25.842117Z","iopub.execute_input":"2021-12-09T11:44:25.842614Z","iopub.status.idle":"2021-12-09T11:44:26.204407Z","shell.execute_reply.started":"2021-12-09T11:44:25.84258Z","shell.execute_reply":"2021-12-09T11:44:26.203545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"/Kaggle/working\n    /COTS\n         /images\n             /train/img0.jpg\n             /val\n         /labels\n             /train/img0.txt\n             /val\n    /yolov5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('COTS/images/train', exist_ok=True)\nos.makedirs('COTS/images/valid', exist_ok=True)\nos.makedirs('COTS/labels/train', exist_ok=True)\nos.makedirs('COTS/labels/valid', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:26.557868Z","iopub.execute_input":"2021-12-09T11:44:26.558109Z","iopub.status.idle":"2021-12-09T11:44:26.563973Z","shell.execute_reply.started":"2021-12-09T11:44:26.558079Z","shell.execute_reply":"2021-12-09T11:44:26.563028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(len(df_train))):\n    row = df_train.loc[i]\n    if row.fold != Selected_Fold:\n        copyfile(f'{row.image_path}', f'COTS/images/train/{row.image_id}.jpg')\n    else:\n        copyfile(f'{row.image_path}', f'COTS/images/valid/{row.image_id}.jpg') ","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:27.961378Z","iopub.execute_input":"2021-12-09T11:44:27.962379Z","iopub.status.idle":"2021-12-09T11:44:51.241344Z","shell.execute_reply.started":"2021-12-09T11:44:27.962336Z","shell.execute_reply":"2021-12-09T11:44:51.240515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list1 = os.listdir('/kaggle/working/COTS/images/train') # dir is your directory path\nnumber_files1 = len(list1)\nprint(\"Number of images in ./COTS/images/train folder\",number_files1)\nlist2 = os.listdir('/kaggle/working/COTS/images/valid') # dir is your directory path\nnumber_files2 = len(list2)\nprint(\"Number of images in ./COTS/images/valid folder\",number_files2)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:51.243302Z","iopub.execute_input":"2021-12-09T11:44:51.243673Z","iopub.status.idle":"2021-12-09T11:44:51.254753Z","shell.execute_reply.started":"2021-12-09T11:44:51.243631Z","shell.execute_reply":"2021-12-09T11:44:51.253865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yaml\nwith open('/kaggle/working/train.txt', 'w') as f:\n    for path in glob('/kaggle/working/train/*'):\n        f.write(path+'\\n')\n            \nwith open('/kaggle/working/val.txt', 'w') as f:\n    for path in glob('/kaggle/working/val/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train = '/kaggle/working/COTS/images/train',\n    val = '/kaggle/working/COTS/images/valid',\n    \n    nc    = 1, # number of classes\n    names =  ['cots'] # classes\n    )\n\nwith open('/kaggle/working/yolov5/data/data.yaml', 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\n%cat /kaggle/working/yolov5/data/data.yaml","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:44:51.256214Z","iopub.execute_input":"2021-12-09T11:44:51.256481Z","iopub.status.idle":"2021-12-09T11:45:01.625563Z","shell.execute_reply.started":"2021-12-09T11:44:51.256447Z","shell.execute_reply":"2021-12-09T11:45:01.62463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls '/kaggle/working/yolov5/data'","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:45:01.627549Z","iopub.execute_input":"2021-12-09T11:45:01.627785Z","iopub.status.idle":"2021-12-09T11:45:02.293791Z","shell.execute_reply.started":"2021-12-09T11:45:01.62775Z","shell.execute_reply":"2021-12-09T11:45:02.29297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_bboxes = []\nfor row_idx in tqdm(range(df_train.shape[0])):\n    row = df_train.iloc[row_idx]\n    # Get image\n    image_name = row.image_id\n    image_height = row.Height\n    image_width  = row.Width\n    bboxes_coco  = np.array(row.bboxes).astype(np.float32).copy()\n    num_bbox     = len(bboxes_coco)\n    names        = ['cots']*num_bbox\n    labels       = [0]*num_bbox\n    if row.fold != Selected_Fold:\n        file_name = f'/kaggle/working/COTS/labels/train/{image_name}.txt'\n    else:\n        file_name = f'/kaggle/working/COTS/labels/valid/{image_name}.txt'\n\n    with open(file_name, 'w') as f:\n        bboxes_yolo  = coco2yolo(image_height, image_width, bboxes_coco)\n        bboxes_yolo  = np.clip(bboxes_yolo, 0, 1)\n        all_bboxes.extend(bboxes_yolo)\n        for bbox_idx in range(len(bboxes_yolo)):\n            bb=str(bboxes_yolo[bbox_idx])\n            bb=bb[1:-1]\n            #annot = [str(labels[bbox_idx])]+ list(bboxes_yolo[bbox_idx].astype(str))+(['\\n'] if num_bbox!=(bbox_idx+1) else [''])\n            annot = str(str(labels[bbox_idx])) + ' ' + bb + '\\n'\n            annot = ''.join(annot)\n            annot = annot.strip('')\n            f.write(annot)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:45:02.295636Z","iopub.execute_input":"2021-12-09T11:45:02.295924Z","iopub.status.idle":"2021-12-09T11:45:06.65093Z","shell.execute_reply.started":"2021-12-09T11:45:02.295882Z","shell.execute_reply":"2021-12-09T11:45:06.650181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list1 = os.listdir('/kaggle/working/COTS/labels/train') # dir is your directory path\nnumber_files1 = len(list1)\nprint(\"Number of txt file in ./COTS/labels/train folder\",number_files1)\nlist2 = os.listdir('/kaggle/working/COTS/labels/valid') # dir is your directory path\nnumber_files2 = len(list2)\nprint(\"Number of txt file in ./COTS/labels/valid folder\",number_files2)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:45:06.652205Z","iopub.execute_input":"2021-12-09T11:45:06.653805Z","iopub.status.idle":"2021-12-09T11:45:06.664301Z","shell.execute_reply.started":"2021-12-09T11:45:06.653758Z","shell.execute_reply":"2021-12-09T11:45:06.663553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cat '/kaggle/working/COTS/labels/train/{list1[10]}'","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:45:06.665677Z","iopub.execute_input":"2021-12-09T11:45:06.666271Z","iopub.status.idle":"2021-12-09T11:45:07.331837Z","shell.execute_reply.started":"2021-12-09T11:45:06.666231Z","shell.execute_reply":"2021-12-09T11:45:07.331006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd yolov5/","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:45:07.333427Z","iopub.execute_input":"2021-12-09T11:45:07.333721Z","iopub.status.idle":"2021-12-09T11:45:07.341149Z","shell.execute_reply.started":"2021-12-09T11:45:07.333682Z","shell.execute_reply":"2021-12-09T11:45:07.340237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best_weights = '/kaggle/input/nfl-weights/yolov5/kaggle-reef/exp/weights/best.pt' --weights {best_weights} \\\n!python train.py --img {IMG_SIZE} \\\n                 --batch {BATCH_SIZE} \\\n                 --epochs {EPOCHS} \\\n                 --data data.yaml \\\n                 --weights yolov5s.pt \\\n                 --project kaggle-Reef ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!ls /kaggle/working/yolov5/kaggle-NFL/exp\nplt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(plt.imread('/kaggle/working/yolov5/kaggle-Reef/exp/P_curve.png'));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(plt.imread('/kaggle/working/yolov5/kaggle-Reef/exp/PR_curve.png'));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(plt.imread('/kaggle/working/yolov5/kaggle-Reef/exp/F1_curve.png'));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(plt.imread('/kaggle/working/yolov5/kaggle-Reef/exp/R_curve.png'));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ig, ax = plt.subplots(3, 2, figsize = (2*5,3*5), constrained_layout = True)\nfor row in range(3):\n    ax[row][0].imshow(plt.imread(f'/kaggle/working/yolov5/kaggle-Reef/exp/val_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'/kaggle/working/yolov5/kaggle-Reef/exp/val_batch{row}_labels.jpg', fontsize = 12)\n    \n    ax[row][1].imshow(plt.imread(f'/kaggle/working/yolov5/kaggle-Reef/exp/val_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'/kaggle/working/yolov5/runs/kaggle-Reef/val_batch{row}_pred.jpg', fontsize = 12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.axis('off')\nplt.imshow(plt.imread('/kaggle/working/yolov5/kaggle-Reef/exp/results.png'));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%!\nzip -r /kaggle/working/FinalTrainedYOLO5s.zip ./working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./FinalTrainedYOLO5s.zip\"> Download File </a>","metadata":{}},{"cell_type":"code","source":"cd working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"while(True):\n    pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd yolov5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py --source /kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/1000.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Model\n# model = torch.hub.load('/kaggle/working/yolov5/kaggle-Reef/exp/weights/best', 'yolov5s')\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', path='/kaggle/working/yolov5/kaggle-Reef/exp/weights/best.pt')  # local model\n\n# Image\nimg = 'https://ultralytics.com/images/zidane.jpg'\n\n# Inference\nresults = model(img)\n\nresults.pandas().xyxy[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport torch\nfrom PIL import Image\n\n# Model\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', path='/kaggle/input/trainedyolo5-on-cor/yolov5/kaggle-Reef/exp/weights/best.pt')  # local model\n\n# Images\n# for f in ['0.jpg', '10.jpg']:\n#     torch.hub.download_url_to_file('../input/tensorflow-great-barrier-reef/train_images/video_0' + f, f)  # download 2 images\nimg1 = cv2.imread('/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/1002.jpg')[..., ::-1]  # PIL image\nimg2 = cv2.imread('/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/100.jpg')[..., ::-1]  # OpenCV image (BGR to RGB)\nimgs = [img1, img2]  # batch of images\n\n# Inference\nresults = model(imgs)  # includes NMS\n\n# Results\nresults.print()  \nresults.save(\"/kaggle/working/\")  # or .show()\n\nresults.xyxy[0]  # img1 predictions (tensor)\nresults.pandas().xyxy[0]  # img1 predictions (pandas)\n#      xmin    ymin    xmax   ymax  confidence  class    name\n# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:45:07.343078Z","iopub.execute_input":"2021-12-09T11:45:07.34372Z","iopub.status.idle":"2021-12-09T11:45:10.71351Z","shell.execute_reply.started":"2021-12-09T11:45:07.343684Z","shell.execute_reply":"2021-12-09T11:45:10.712765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n# Read in the data CSV files\ndf = pd.read_csv(\"/kaggle/input/tensorflow-great-barrier-reef/test.csv\")\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:45:10.71643Z","iopub.execute_input":"2021-12-09T11:45:10.716681Z","iopub.status.idle":"2021-12-09T11:45:10.730129Z","shell.execute_reply.started":"2021-12-09T11:45:10.716646Z","shell.execute_reply":"2021-12-09T11:45:10.729379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"def load_model(Best_Model, conf=0.25, iou=0.50):\n    model = torch.hub.load('ultralytics/yolov5',\n                           'custom',\n                           path='/kaggle/input/trainedyolo5-on-cor/yolov5/kaggle-Reef/exp/weights/best.pt',\n                           force_reload=True)  # local repo\n    model.conf = conf  # NMS confidence threshold\n    model.iou  = iou  # NMS IoU threshold\n    model.classes = None   # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n    model.multi_label = False  # NMS multiple labels per box\n    model.max_det = 1000  # maximum number of detections per image\n    return model\n\n\ndef predict(model, img, size=768, augment=False):\n    height, width = img.shape[:2]\n    results = model(img, size=size, augment=augment)  # custom inference size\n    preds   = results.pandas().xyxy[0]\n    bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n    if len(bboxes):\n        bboxes  = voc2coco(bboxes,height,width).astype(int)\n        confs   = preds.confidence.values\n        return bboxes, confs\n    else:\n        return [],[]\n    \ndef format_prediction(bboxes, confs):\n    annot = ''\n    if len(bboxes)>0:\n        for idx in range(len(bboxes)):\n            xmin, ymin, w, h = bboxes[idx]\n            conf             = confs[idx]\n            limited_float = \"{:.2f}\".format(conf)\n            annot += f'{limited_float} {xmin} {ymin} {w} {h}'\n            annot +=' '\n        annot = annot.strip(' ')\n    return annot\n\ndef show_img(img, bboxes, bbox_format='yolo'):\n    names  = ['starfish']*len(bboxes)\n    labels = [0]*len(bboxes)\n    img    = draw_bboxes(img = img,\n                           bboxes = bboxes, \n                           classes = names,\n                           class_ids = labels,\n                           class_name = True, \n                           colors = colors, \n                           bbox_format = bbox_format,\n                           line_thickness = 2)\n    return Image.fromarray(img).resize((800, 400))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:46:09.179195Z","iopub.execute_input":"2021-12-09T11:46:09.179478Z","iopub.status.idle":"2021-12-09T11:46:09.192663Z","shell.execute_reply.started":"2021-12-09T11:46:09.179445Z","shell.execute_reply":"2021-12-09T11:46:09.191852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def voc2yolo(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    voc  => [x1, y1, x2, y1]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n    \n    w = bboxes[..., 2] - bboxes[..., 0]\n    h = bboxes[..., 3] - bboxes[..., 1]\n    \n    bboxes[..., 0] = bboxes[..., 0] + w/2\n    bboxes[..., 1] = bboxes[..., 1] + h/2\n    bboxes[..., 2] = w\n    bboxes[..., 3] = h\n    \n    return bboxes\n\ndef yolo2voc(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes\n\ndef coco2yolo(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normolizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef yolo2coco(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef voc2coco(bboxes, image_height=720, image_width=1280):\n    bboxes  = voc2yolo(bboxes, image_height, image_width)\n    bboxes  = yolo2coco(bboxes, image_height, image_width)\n    return bboxes\n\n\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None):\n    # Plots one bounding box on image img\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n     \n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n    \n    if bbox_format == 'yolo':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:\n            \n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n                h  = round(float(bbox[3])*image.shape[0]/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness)\n            \n    elif bbox_format == 'coco':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:            \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                w  = int(round(bbox[2]))\n                h  = int(round(bbox[3]))\n\n                voc_bbox = (x1, y1, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n\n    elif bbox_format == 'voc_pascal':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes: \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                x2 = int(round(bbox[2]))\n                y2 = int(round(bbox[3]))\n                voc_bbox = (x1, y1, x2, y2)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row['image_path'])\n    return row\n\n\nnp.random.seed(8)\ncolors = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\ncolors=(255,0,0)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:46:11.698233Z","iopub.execute_input":"2021-12-09T11:46:11.698598Z","iopub.status.idle":"2021-12-09T11:46:11.752765Z","shell.execute_reply.started":"2021-12-09T11:46:11.698559Z","shell.execute_reply":"2021-12-09T11:46:11.75197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()   # initialize the environment\n   # an iterator which loops over the test set and sample submission","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:46:13.64342Z","iopub.execute_input":"2021-12-09T11:46:13.644179Z","iopub.status.idle":"2021-12-09T11:46:13.744516Z","shell.execute_reply.started":"2021-12-09T11:46:13.644139Z","shell.execute_reply":"2021-12-09T11:46:13.743375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iter_test = env.iter_test() ","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:46:16.590338Z","iopub.execute_input":"2021-12-09T11:46:16.590949Z","iopub.status.idle":"2021-12-09T11:46:16.594956Z","shell.execute_reply.started":"2021-12-09T11:46:16.590908Z","shell.execute_reply":"2021-12-09T11:46:16.59413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DETECTION_THRESHOLD = 0.19\n\nsubmission_dict = {\n    'id': [],\n    'prediction_string': [],\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:46:18.606895Z","iopub.execute_input":"2021-12-09T11:46:18.607385Z","iopub.status.idle":"2021-12-09T11:46:18.611741Z","shell.execute_reply.started":"2021-12-09T11:46:18.60735Z","shell.execute_reply":"2021-12-09T11:46:18.610665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONF= 0.15\nIOU= 0.50\n#model = load_model(Best_Model, conf=CONF, iou=IOU)\nfor (img, pred_df) in enumerate(tqdm(iter_test)):\n    bboxes, confs  = predict(model, img, size=IMG_SIZE, augment=True)\n    annot          = format_prediction(bboxes, confs)\n    #print(annot)\n    pred_df['annotations'] = annot\n    env.predict(pred_df)\n    if idx<3:\n        display(show_img(img, bboxes, bbox_format='coco'))","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:46:40.420879Z","iopub.execute_input":"2021-12-09T11:46:40.421145Z","iopub.status.idle":"2021-12-09T11:46:40.453181Z","shell.execute_reply.started":"2021-12-09T11:46:40.421114Z","shell.execute_reply":"2021-12-09T11:46:40.452514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env.predict()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T11:47:20.044389Z","iopub.execute_input":"2021-12-09T11:47:20.044689Z","iopub.status.idle":"2021-12-09T11:47:20.073121Z","shell.execute_reply.started":"2021-12-09T11:47:20.044656Z","shell.execute_reply":"2021-12-09T11:47:20.072262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bboxes, confs  = predict(model,img1,IMG_SIZE)\nannot          = format_prediction(bboxes, confs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('submission.csv')\nsub_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model('https://ultralytics.com/images/zidane.jpg').pandas().xyxy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}