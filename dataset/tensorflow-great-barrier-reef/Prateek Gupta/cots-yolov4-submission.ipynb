{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# https://www.kaggle.com/eshaandeshpande/cots-detection-with-yolov4-darknet\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport greatbarrierreef\nimport sys\nimport cv2 as cv\nimport os\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-31T04:48:15.628821Z","iopub.execute_input":"2021-12-31T04:48:15.629076Z","iopub.status.idle":"2021-12-31T04:48:15.634255Z","shell.execute_reply.started":"2021-12-31T04:48:15.629047Z","shell.execute_reply":"2021-12-31T04:48:15.633557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cp -R /kaggle/input/darknet-run-environment/darknet /kaggle/working","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cp '/kaggle/input/cots-yolov4-final/cots_yolov4_final_weights/yolov4-custom_final.weights' '/kaggle/working/darknet'\n#%cp '/kaggle/input/predconf/run.py' '/kaggle/working/darknet'\n%cp '/kaggle/input/cots-yolov4-obj/obj.data' '/kaggle/working/darknet/data'\n%cp '/kaggle/input/cots-yolov4-final/cots_yolov4_final_weights/yolov4-custom.cfg' '/kaggle/working/darknet/cfg'\n%cp '/kaggle/input/cots-yolov4-obj/obj.names' '/kaggle/working/darknet/data'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/darknet\n\n!cp '../../input/libcuda/libcuda.so' .\n\n!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n!sed -i 's/GPU=0/GPU=1/g' Makefile\n!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/g' Makefile\n!sed -i 's/LIBSO=0/LIBSO=1/' Makefile\n!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n\n!sed -i 's/LDFLAGS+= -L\\/usr\\/local\\/cuda\\/lib64 -lcuda -lcudart -lcublas -lcurand/LDFLAGS+= -L\\/usr\\/local\\/cuda\\/lib64 -lcudart -lcublas -lcurand -L\\/kaggle\\/working\\/darknet -lcuda/' Makefile\n!make &> compile.log","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport darknet\nimport cv2\n\nnetwork, class_names, class_colors = darknet.load_network(\n        '/kaggle/working/darknet/cfg/yolov4-custom.cfg',\n        '/kaggle/working/darknet/data/obj.data',\n        '/kaggle/working/darknet/yolov4-custom_final.weights',\n        1\n    )\n\n\nfor (pixel_array, sample_prediction_df) in iter_test:\n    ip_image = pixel_array[:,:,::-1]   #cv2.imread('/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/9674.jpg')\n    darknet_image = darknet.make_image(416, 416, 3)\n    ip_rgb = cv2.cvtColor(ip_image, cv2.COLOR_BGR2RGB)\n    img_resized = cv2.resize(ip_rgb,(416,416) ,cv2.INTER_AREA)\n    img_resized[416:416, 0:416] = (0,0,0)\n    darknet.copy_image_from_bytes(darknet_image, img_resized.tobytes())\n    detections = darknet.detect_image(network, class_names, darknet_image, 0.35)\n    darknet.free_image(darknet_image)\n    preds = []\n    for label, confidence, bbox in detections:\n        x1, y1, w1, h1 = bbox\n        if y1 < 416:    \n            xmin, ymin, xmax, ymax = darknet.bbox2points(bbox)\n            preds.append(f'0.{confidence[0]} {int(xmin*2)} {int(ymin*2)} {int(w1*2)} {int(h1*2)}')\n    prediction_str = ' '.join(preds)\n    print(prediction_str)\n    sample_prediction_df['annotations'] = prediction_str\n    env.predict(sample_prediction_df)   # register your predictions\n#     ifinal = darknet.draw_boxes(detections, img_resized, class_colors)\n#     figure(figsize=(12.8, 12.8))\n#     plt.imshow(ifinal)\n#     plt.show()\n#     cv2.imwrite('/kaggle/working/a.jpg', ifinal)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nsub_df = pd.read_csv('/kaggle/working/darknet/submission.csv')\nsub_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/working/darknet/submission.csv /kaggle/working\n!rm -r /kaggle/working/darknet","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR  = '/kaggle/input'\nsys.path.append(f'{ROOT_DIR}/tensorflow-great-barrier-reef')\nconfThreshold = 0.015\nconfthre = 0.015\n\n# try:\n#     net = cv.dnn_DetectionModel(f'{ROOT_DIR}/cots-yolov4-final/cots_yolov4_final_weights/yolov4-custom.cfg',\n#                                 f'{ROOT_DIR}/cots-yolov4-final/cots_yolov4_final_weights/yolov4-custom_final.weights')\n#     net.setInputSize(416, 416)\n#     net.setInputScale(1.0 / 255)\n#     net.setInputSwapRB(True)\n\n\n#     env = greatbarrierreef.make_env()   # initialize the environment\n#     iter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\n#     #print(\"iter_test:\", iter_test)\n    \n#     submission_dict = {\n#         'id': [],\n#         'prediction_string': [],\n#     }\n\n#     with open(f'{ROOT_DIR}/cots-yolov4-names/coco.names', 'rt') as f:\n#         names = f.read().rstrip('\\n').split('\\n')\n\n\n#     for (image_np, sample_prediction_df) in iter_test:\n#         bbclasses, scores, bboxes = net.detect(image_np[:,:,::-1], confThreshold=confThreshold, nmsThreshold=0.4)\n# #         print('bbclasses:', bbclasses)\n# #         print('scores:', scores)\n# #         print('bboxes:', bboxes)\n#         predictions = []\n#         for i in range(len(bboxes)):\n#             box = bboxes[i]\n#             cls_id = int(bbclasses[i])\n#             score = scores[i]\n#             if score < confThreshold:\n#                 continue\n#             x_min = int(box[0])\n#             y_min = int(box[1])\n#             x_max = int(box[2])\n#             y_max = int(box[3])\n\n#             bbox_width = x_max - x_min\n#             bbox_height = y_max - y_min\n\n#             predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n\n#         prediction_str = ' '.join(predictions)\n#         print('Prediction:', prediction_str)\n#         sample_prediction_df['annotations'] = prediction_str\n#         env.predict(sample_prediction_df)\n        \n# except Exception as exc:\n#     print(\"Following error:: \", exc)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T04:48:15.639891Z","iopub.execute_input":"2021-12-31T04:48:15.640309Z","iopub.status.idle":"2021-12-31T04:48:15.648303Z","shell.execute_reply.started":"2021-12-31T04:48:15.640281Z","shell.execute_reply":"2021-12-31T04:48:15.647402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(conf=0.015, iou=0.40):\n    net = cv.dnn.readNet(f'{ROOT_DIR}/cots-yolov4-final/cots_yolov4_final_weights/yolov4-custom.cfg',\n                            f'{ROOT_DIR}/cots-yolov4-final/cots_yolov4_final_weights/yolov4-custom_final.weights')\n    net = cv.dnn_DetectionModel(net)\n    net.setInputParams(size=(416, 416), scale=1/255, swapRB=True)\n    return net","metadata":{"execution":{"iopub.status.busy":"2021-12-31T04:48:15.650364Z","iopub.execute_input":"2021-12-31T04:48:15.650609Z","iopub.status.idle":"2021-12-31T04:48:15.6603Z","shell.execute_reply.started":"2021-12-31T04:48:15.650578Z","shell.execute_reply":"2021-12-31T04:48:15.659518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def voc2yolo(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    voc  => [x1, y1, x2, y1]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n    \n    w = bboxes[..., 2] - bboxes[..., 0]\n    h = bboxes[..., 3] - bboxes[..., 1]\n    \n    bboxes[..., 0] = bboxes[..., 0] + w/2\n    bboxes[..., 1] = bboxes[..., 1] + h/2\n    bboxes[..., 2] = w\n    bboxes[..., 3] = h\n    \n    return bboxes\ndef yolo2voc(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes\ndef coco2yolo(bboxes, image_height=720, image_width=1280):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normolizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n    return bboxes\ndef yolo2coco(bboxes, image_height=416, image_width=416):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef voc2coco(bboxes, image_height=720, image_width=1280):\n    bboxes  = voc2yolo(bboxes, image_height, image_width)\n    bboxes  = yolo2coco(bboxes, image_height, image_width)\n    return bboxes","metadata":{"execution":{"iopub.status.busy":"2021-12-31T04:48:15.661804Z","iopub.execute_input":"2021-12-31T04:48:15.662059Z","iopub.status.idle":"2021-12-31T04:48:15.681082Z","shell.execute_reply.started":"2021-12-31T04:48:15.662027Z","shell.execute_reply":"2021-12-31T04:48:15.680364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE=416\n\nwith open('/kaggle/input/cots-yolov4-names/coco.names', 'rt') as f:\n    names = f.read().rstrip('\\n').split('\\n')\n    \ndef predict(net, img, size=IMG_SIZE):\n    confs = []\n    bboxes = []\n    height, width = img.shape[:2]\n    bbclasses, scores, bboxes = net.detect(img, confThreshold=confThreshold, nmsThreshold=0.4)\n    if len(bboxes):\n        confs=[]\n        for i in scores:\n            confs.append('{:.2f}'.format(i))\n        score=np.array(confs,dtype=float)  \n        return bboxes, score\n    else:\n        return [],[]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T04:48:15.684115Z","iopub.execute_input":"2021-12-31T04:48:15.684387Z","iopub.status.idle":"2021-12-31T04:48:15.694077Z","shell.execute_reply.started":"2021-12-31T04:48:15.68436Z","shell.execute_reply":"2021-12-31T04:48:15.693299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_prediction(bboxes, confs):\n    annot = ''\n    if len(bboxes)>0:\n        for idx in range(len(bboxes)):\n            xmin, ymin, w, h = bboxes[idx]\n            conf             = confs[idx]\n            annot += f'{conf} {xmin} {ymin} {w} {h}'\n            annot +=' '\n        annot = annot.strip(' ')\n    return annot","metadata":{"execution":{"iopub.status.busy":"2021-12-31T04:48:15.695849Z","iopub.execute_input":"2021-12-31T04:48:15.69651Z","iopub.status.idle":"2021-12-31T04:48:15.703313Z","shell.execute_reply.started":"2021-12-31T04:48:15.696476Z","shell.execute_reply":"2021-12-31T04:48:15.702588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom numpy import asarray\n\nimg = Image.open('/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/1875.jpg')\n  \nnumpydata = asarray(img)\n\nnet = load_model(conf=0.015, iou=0.40)\n\nbboxes, confs  = predict(net, numpydata, size=IMG_SIZE)\n\nprint(bboxes, confs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = greatbarrierreef.make_env()# initialize the environment\niter_test = env.iter_test()\nnet = load_model(conf=0.015, iou=0.40)\nfor idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n    bboxes, confs  = predict(net, img, size=IMG_SIZE)\n    annot          = format_prediction(bboxes, confs)\n    pred_df['annotations'] = annot\n    env.predict(pred_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T04:48:17.767509Z","iopub.execute_input":"2021-12-31T04:48:17.768409Z","iopub.status.idle":"2021-12-31T04:48:17.772256Z","shell.execute_reply.started":"2021-12-31T04:48:17.767959Z","shell.execute_reply":"2021-12-31T04:48:17.771324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('submission.csv')\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T04:48:17.773578Z","iopub.execute_input":"2021-12-31T04:48:17.773994Z","iopub.status.idle":"2021-12-31T04:48:17.782603Z","shell.execute_reply.started":"2021-12-31T04:48:17.773957Z","shell.execute_reply":"2021-12-31T04:48:17.781832Z"},"trusted":true},"execution_count":null,"outputs":[]}]}