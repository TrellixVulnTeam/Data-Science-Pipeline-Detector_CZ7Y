{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# # for dirname, _, filenames in os.walk('/kaggle/input'):\n# #     for filename in filenames:\n# #         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T09:25:44.72273Z","iopub.execute_input":"2021-12-22T09:25:44.723406Z","iopub.status.idle":"2021-12-22T09:25:44.749388Z","shell.execute_reply.started":"2021-12-22T09:25:44.723293Z","shell.execute_reply":"2021-12-22T09:25:44.748529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt update\n!apt install --yes python-opencv\n!apt install --yes libopencv-dev\n!/bin/bash -c 'echo \"/opt/conda/lib/\" > /etc/ld.so.conf.d/opencv.conf'\n!ldconfig\n!pip install imagesize","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:25:44.751373Z","iopub.execute_input":"2021-12-22T09:25:44.751883Z","iopub.status.idle":"2021-12-22T09:27:01.938929Z","shell.execute_reply.started":"2021-12-22T09:25:44.751835Z","shell.execute_reply":"2021-12-22T09:27:01.937731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport pickle\nimport matplotlib.pyplot as plt\nimport ast\nimport glob\nimport shutil\nimport sys\nimport numpy as np\nimport imagesize\nimport cv2\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:27:01.941165Z","iopub.execute_input":"2021-12-22T09:27:01.941483Z","iopub.status.idle":"2021-12-22T09:27:02.188805Z","shell.execute_reply.started":"2021-12-22T09:27:01.941442Z","shell.execute_reply":"2021-12-22T09:27:02.187947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Install Darknet\n!git clone https://github.com/AlexeyAB/darknet.git","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:27:02.192871Z","iopub.execute_input":"2021-12-22T09:27:02.193103Z","iopub.status.idle":"2021-12-22T09:27:06.059031Z","shell.execute_reply.started":"2021-12-22T09:27:02.193074Z","shell.execute_reply":"2021-12-22T09:27:06.058102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build Darknet with GPU enable settings\n%cd darknet\n\n!cp '../../input/libcuda/libcuda.so' .\n\n!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n!sed -i 's/GPU=0/GPU=1/g' Makefile\n!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/g' Makefile\n!sed -i 's/LIBSO=0/LIBSO=1/' Makefile\n!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n\n!sed -i 's/LDFLAGS+= -L\\/usr\\/local\\/cuda\\/lib64 -lcuda -lcudart -lcublas -lcurand/LDFLAGS+= -L\\/usr\\/local\\/cuda\\/lib64 -lcudart -lcublas -lcurand -L\\/kaggle\\/working\\/darknet -lcuda/' Makefile\n!make &> compile.log","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:27:06.060596Z","iopub.execute_input":"2021-12-22T09:27:06.060888Z","iopub.status.idle":"2021-12-22T09:29:09.835129Z","shell.execute_reply.started":"2021-12-22T09:27:06.060848Z","shell.execute_reply":"2021-12-22T09:29:09.834138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verify build\n!./darknet detector train","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:29:09.838237Z","iopub.execute_input":"2021-12-22T09:29:09.838558Z","iopub.status.idle":"2021-12-22T09:29:13.504364Z","shell.execute_reply.started":"2021-12-22T09:29:09.838505Z","shell.execute_reply":"2021-12-22T09:29:13.503474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define image/label path\nROOT_DIR  = '/kaggle/input'\nWORKING_DIR  = '/kaggle/working'\ndef get_path(row):\n    row['image_path'] = f'{ROOT_DIR}/tensorflow-great-barrier-reef/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    row['label_path'] = f'{WORKING_DIR}/darknet/data/obj/video_{row.video_id}_{row.video_frame}.txt'\n    return row","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:29:13.506358Z","iopub.execute_input":"2021-12-22T09:29:13.506658Z","iopub.status.idle":"2021-12-22T09:29:13.512903Z","shell.execute_reply.started":"2021-12-22T09:29:13.506603Z","shell.execute_reply":"2021-12-22T09:29:13.512154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load annotations in dataframe\ndf = pd.read_csv(f'{ROOT_DIR}/tensorflow-great-barrier-reef/train.csv')\ndf = df.apply(get_path, axis=1)\ndf['annotations'] = df['annotations'].apply(lambda x: ast.literal_eval(x))\ndisplay(df.head(2))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:29:13.514355Z","iopub.execute_input":"2021-12-22T09:29:13.514929Z","iopub.status.idle":"2021-12-22T09:29:42.868298Z","shell.execute_reply.started":"2021-12-22T09:29:13.51489Z","shell.execute_reply":"2021-12-22T09:29:42.867527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check negative samples also\ndf['num_bbox'] = df['annotations'].apply(lambda x: len(x))\ndata = (df.num_bbox>0).value_counts()/len(df)*100\nprint('% images without annotations: {}'.format(data[0]))\nprint('% images with annotations: {} '.format(data[1]))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:29:42.869686Z","iopub.execute_input":"2021-12-22T09:29:42.869965Z","iopub.status.idle":"2021-12-22T09:29:42.897175Z","shell.execute_reply.started":"2021-12-22T09:29:42.869928Z","shell.execute_reply":"2021-12-22T09:29:42.895927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filter out negative samples\ndf = df.query(\"num_bbox>0\")","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:29:42.901459Z","iopub.execute_input":"2021-12-22T09:29:42.901717Z","iopub.status.idle":"2021-12-22T09:29:42.926219Z","shell.execute_reply.started":"2021-12-22T09:29:42.901685Z","shell.execute_reply":"2021-12-22T09:29:42.925396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert given annotations to YOLO format\ndef coco2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normalizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef yolo2coco(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None):\n    # Plots one bounding box on image\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n     \n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n    \n    if bbox_format == 'yolo':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:\n            \n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n                h  = round(float(bbox[3])*image.shape[0]/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row['image_path'])\n    return row\n\n\ndf['bboxes'] = df.annotations.apply(get_bbox)\ndf = df.apply(get_imgsize,axis=1)\ndisplay(df.width.unique(), df.height.unique())\ndisplay(df.head(2))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:29:42.928347Z","iopub.execute_input":"2021-12-22T09:29:42.928818Z","iopub.status.idle":"2021-12-22T09:30:41.289745Z","shell.execute_reply.started":"2021-12-22T09:29:42.92878Z","shell.execute_reply":"2021-12-22T09:30:41.288903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Maintain the Darknet's YOLO required directory structure\n%cd data/\n!mkdir obj test\n\ncnt = 0\nfor row_idx in tqdm(range(df.shape[0])):\n    row = df.iloc[row_idx]\n    image_height = row.height\n    image_width = row.width\n    bboxes_coco = np.asarray(row.bboxes).astype(np.float32).copy()\n    num_bbox = len(bboxes_coco)\n    labels = [0]*num_bbox\n  \n    f = open(row.label_path, 'w')\n\n    if num_bbox < 1:\n        annot = ''\n        f.write(annot)\n        f.close()\n        cnt += 1\n        continue\n  \n    bboxes_yolo  = coco2yolo(image_height, image_width, bboxes_coco)\n\n    for i in range(len(bboxes_yolo)):\n        annot = [str(labels[i])] + list(bboxes_yolo[i].astype(str)) + (['\\n'] if num_bbox!=(i+1) else [''])\n        annot = ' '.join(annot)\n        annot = annot.strip(' ')\n        f.write(annot)\n    f.close()\n\nprint('Missing boxes ', cnt)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:41.291345Z","iopub.execute_input":"2021-12-22T09:30:41.291626Z","iopub.status.idle":"2021-12-22T09:30:44.357302Z","shell.execute_reply.started":"2021-12-22T09:30:41.291589Z","shell.execute_reply":"2021-12-22T09:30:44.35636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat obj/video_0_1000.txt","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:44.359217Z","iopub.execute_input":"2021-12-22T09:30:44.359703Z","iopub.status.idle":"2021-12-22T09:30:45.182263Z","shell.execute_reply.started":"2021-12-22T09:30:44.359656Z","shell.execute_reply":"2021-12-22T09:30:45.181213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the dataset into train-val\nfrom sklearn.model_selection import GroupKFold\nkf = GroupKFold(n_splits = 5) \ndf = df.reset_index(drop=True)\ndf['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(kf.split(df, y = df.video_id.tolist(), groups=df.sequence)):\n    df.loc[val_idx, 'fold'] = fold\ndisplay(df.fold.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:45.187408Z","iopub.execute_input":"2021-12-22T09:30:45.18775Z","iopub.status.idle":"2021-12-22T09:30:46.187328Z","shell.execute_reply.started":"2021-12-22T09:30:45.187707Z","shell.execute_reply":"2021-12-22T09:30:46.186488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = df[df['fold']==2]\ntrain_df = df[df['fold']!=2]\nprint(train_df.shape)\nprint(val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:46.188708Z","iopub.execute_input":"2021-12-22T09:30:46.189142Z","iopub.status.idle":"2021-12-22T09:30:46.198335Z","shell.execute_reply.started":"2021-12-22T09:30:46.189098Z","shell.execute_reply":"2021-12-22T09:30:46.197334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move labels from obj to test directory\ndef mv_labels (row):\n    old_path = row.label_path\n    filename = row.label_path.split('/')[-1]\n    new_path = '/'.join(row.label_path.split('/')[:-2]) + '/test/' + filename\n    row['label_path'] = new_path\n    shutil.move(old_path, new_path)\n    return row\n\nval_df = val_df.apply(lambda x: mv_labels(x), axis=1)\nval_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:46.199967Z","iopub.execute_input":"2021-12-22T09:30:46.200599Z","iopub.status.idle":"2021-12-22T09:30:46.362408Z","shell.execute_reply.started":"2021-12-22T09:30:46.200559Z","shell.execute_reply":"2021-12-22T09:30:46.361543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy images to working directory\n'''\nLabels and images must have the same name:\nImages: obj/image_XX.jpg\nLabels: obj/image_XX.txt\n'''\ndef copy_images (row):\n    old_path = row.image_path\n    filename = row.label_path.split('/')[-1][:-4] + '.jpg'\n    new_path = '/'.join(row.label_path.split('/')[:-1]) + '/' + filename\n    shutil.copy(old_path, new_path)\nval_df.apply(lambda x: copy_images(x), axis=1)\ntrain_df.apply(lambda x: copy_images(x), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:46.36388Z","iopub.execute_input":"2021-12-22T09:30:46.36415Z","iopub.status.idle":"2021-12-22T09:30:55.036937Z","shell.execute_reply.started":"2021-12-22T09:30:46.364112Z","shell.execute_reply":"2021-12-22T09:30:55.034324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verify\n!ls obj/*.jpg | wc -l\n!ls obj/*.txt | wc -l\n!ls test/*.jpg | wc -l\n!ls test/*.txt | wc -l","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:55.038166Z","iopub.execute_input":"2021-12-22T09:30:55.038579Z","iopub.status.idle":"2021-12-22T09:30:59.611533Z","shell.execute_reply.started":"2021-12-22T09:30:55.038541Z","shell.execute_reply":"2021-12-22T09:30:59.610378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate train.txt and test.txt files\n%cd ../\ntrain_images = glob.glob('data/obj/*.jpg')\nf = open('./data/train.txt', 'w')\nannot = [os.path.join(os.getcwd(),t) + ('\\n' if i<len(train_images)-1 else '') for i, t in enumerate(train_images)]\nannot = ''.join(annot)\nannot = annot.strip()\nf.write(annot)\n\nval_images = glob.glob('data/test/*.jpg')\nf = open('./data/test.txt', 'w')  \nannot = [os.path.join(os.getcwd(),t) + ('\\n' if i<len(val_images)-1 else '') for i, t in enumerate(val_images)]\nannot = ''.join(annot)\nannot = annot.strip()\nf.write(annot)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:59.615157Z","iopub.execute_input":"2021-12-22T09:30:59.615867Z","iopub.status.idle":"2021-12-22T09:30:59.681035Z","shell.execute_reply.started":"2021-12-22T09:30:59.615823Z","shell.execute_reply":"2021-12-22T09:30:59.680031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verify\n!cat data/train.txt | wc -l\n!cat data/test.txt | wc -l","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:30:59.682561Z","iopub.execute_input":"2021-12-22T09:30:59.682961Z","iopub.status.idle":"2021-12-22T09:31:06.636423Z","shell.execute_reply.started":"2021-12-22T09:30:59.682905Z","shell.execute_reply":"2021-12-22T09:31:06.635408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualization\nnp.random.seed(1)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]\n\ndf2 = train_df[(train_df.num_bbox>0)].sample(100) # takes samples with bbox\n\nfor idx in range(10):\n    row = df2.iloc[idx]\n    img           = load_image(row.image_path)\n    image_height  = row.height\n    image_width   = row.width\n    f = open(row.label_path)\n    bboxes_yolo = np.asarray([[float(a) for a in l[1:].strip().split(' ')] for l in f.readlines()])\n\n    names         = ['starfish']*len(bboxes_yolo)\n    labels        = [0]*len(bboxes_yolo)\n\n    plt.figure(figsize = (12, 8))\n    plt.imshow(draw_bboxes(img = img,\n                           bboxes = bboxes_yolo, \n                           classes = names,\n                           class_ids = labels,\n                           class_name = True, \n                           colors = colors, \n                           bbox_format = 'yolo',\n                           line_thickness = 2))\n    plt.axis('OFF')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:06.638631Z","iopub.execute_input":"2021-12-22T09:31:06.638903Z","iopub.status.idle":"2021-12-22T09:31:16.072789Z","shell.execute_reply.started":"2021-12-22T09:31:06.638871Z","shell.execute_reply":"2021-12-22T09:31:16.071756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Modify YOLO's configuration file as per our data\n# !sed -i 's/subdivisions=8/subdivisions=64/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/max_batches = 500500/max_batches = 8000/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/steps=400000,450000/steps=6400,7200/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/classes=80/classes=1/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/filters=255/filters=18/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/objectness_smooth=1/objectness_smooth=0/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/scale_x_y=2.0/scale_x_y=1.05/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/activation=logistic/activation=linear/g' ./cfg/yolov4x-mish.cfg\n# !sed -i 's/iou_thresh=0.2/iou_thresh=1.0/g' ./cfg/yolov4x-mish.cfg\n# !sed 'iou_loss=ciou d' ./cfg/yolov4x-mish.cfg\n# !sed 'iou_normalizer=0.05 d' ./cfg/yolov4x-mish.cfg\n# !sed 'new_coords=1 d' ./cfg/yolov4x-mish.cfg","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:16.074552Z","iopub.execute_input":"2021-12-22T09:31:16.074844Z","iopub.status.idle":"2021-12-22T09:31:16.173154Z","shell.execute_reply.started":"2021-12-22T09:31:16.074808Z","shell.execute_reply":"2021-12-22T09:31:16.172081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sed -i 's/subdivisions=16/subdivisions=64/g' ./cfg/yolov4-custom.cfg \n!sed -i 's/width=608/width=416/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/height=608/height=416/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/max_batches = 500500/max_batches = 12000/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/steps=400000,450000/steps=9600,10800/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/classes=80/classes=1/g' ./cfg/yolov4-custom.cfg\n!sed -i 's/filters=255/filters=18/g' ./cfg/yolov4-custom.cfg","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:16.174975Z","iopub.execute_input":"2021-12-22T09:31:16.175566Z","iopub.status.idle":"2021-12-22T09:31:21.146162Z","shell.execute_reply.started":"2021-12-22T09:31:16.175519Z","shell.execute_reply":"2021-12-22T09:31:21.145182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build obj.data and obj.names files\nf = open('./data/obj.data', 'w')\nf.write('classes = 1\\ntrain = data/train.txt\\nvalid = data/test.txt\\nnames = data/obj.names\\nbackup = backup\\n')\nf.close()\nf = open('./data/obj.names', 'w')\nf.write('starfish')\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:21.14834Z","iopub.execute_input":"2021-12-22T09:31:21.148642Z","iopub.status.idle":"2021-12-22T09:31:21.154835Z","shell.execute_reply.started":"2021-12-22T09:31:21.148605Z","shell.execute_reply":"2021-12-22T09:31:21.153988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Download YOLOv4x-MISH pre-trained model\n# !wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4x-mish.conv.166","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:21.156141Z","iopub.execute_input":"2021-12-22T09:31:21.157158Z","iopub.status.idle":"2021-12-22T09:31:21.16578Z","shell.execute_reply.started":"2021-12-22T09:31:21.157044Z","shell.execute_reply":"2021-12-22T09:31:21.164976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:21.16721Z","iopub.execute_input":"2021-12-22T09:31:21.168139Z","iopub.status.idle":"2021-12-22T09:31:21.175819Z","shell.execute_reply.started":"2021-12-22T09:31:21.168097Z","shell.execute_reply":"2021-12-22T09:31:21.17492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Start the training\n# !./darknet detector train data/obj.data cfg/yolov4x-mish.cfg yolov4x-mish.conv.166 -dont_show -map","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:21.177253Z","iopub.execute_input":"2021-12-22T09:31:21.177834Z","iopub.status.idle":"2021-12-22T09:31:21.185244Z","shell.execute_reply.started":"2021-12-22T09:31:21.17779Z","shell.execute_reply":"2021-12-22T09:31:21.184306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # # from distutils.dir_util import copy_tree\n# # #copy_tree('../input/cots-last-weight-yolo','/kaggle/working/darknet/backup')\n# import shutil\n# src='../input/cots-last-weight-yolo/yolov4-custom_last.weights'\n# dst = '/kaggle/working/darknet/yolov4-custom_last.weights'\n# try:\n#     #if path already exists, remove it before copying with copytree()\n#     if os.path.exists(dst):\n#         shutil.rmtree(dst)\n#         shutil.copyfile(src, dst)\n#         print(\"Copy File 1\")\n#     elif not os.path.isdir('/kaggle/working/darknet/backup'):\n#         os.makedirs('/kaggle/working/darknet/backup')\n#         print(\"folder is created!\")\n#     else:\n#         shutil.copyfile(src, dst)\n#         print(\"Copy File 2\")\n# except OSError as e:\n#         #shutil.copy(source_dir_prompt, destination_dir_prompt)\n#         print(\"No Copy due to: \", e)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:21.190315Z","iopub.execute_input":"2021-12-22T09:31:21.191864Z","iopub.status.idle":"2021-12-22T09:31:21.201615Z","shell.execute_reply.started":"2021-12-22T09:31:21.191815Z","shell.execute_reply":"2021-12-22T09:31:21.200312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !./darknet detector train data/obj.data cfg/yolov4-custom.cfg yolov4.conv.137 -dont_show -map\n#resume training\n!./darknet detector train data/obj.data cfg/yolov4-custom.cfg {ROOT_DIR}/cots-yolov4-last-weight/yolov4-custom_last.weights -dont_show -map","metadata":{"execution":{"iopub.status.busy":"2021-12-22T09:31:21.206208Z","iopub.execute_input":"2021-12-22T09:31:21.206502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}