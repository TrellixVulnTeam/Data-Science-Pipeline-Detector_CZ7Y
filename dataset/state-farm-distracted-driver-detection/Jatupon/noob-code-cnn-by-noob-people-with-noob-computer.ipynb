{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np \nimport pandas as pd \nimport os\nfrom keras.utils.np_utils import to_categorical \nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom glob import glob\nfrom tensorflow.keras.applications import VGG16,EfficientNetB3\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2021-11-16T09:50:02.501389Z","iopub.execute_input":"2021-11-16T09:50:02.501907Z","iopub.status.idle":"2021-11-16T09:50:08.534735Z","shell.execute_reply.started":"2021-11-16T09:50:02.501796Z","shell.execute_reply":"2021-11-16T09:50:08.533978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUMBER_CLASSES=10\n\ndef get_image(path, img_rows, img_cols, color_type=3): #get image\n    img = cv2.imread(path,1)\n    resized = cv2.resize(img, (img_rows, img_cols)) # Reduce size\n    return resized\n#------------------------------------------------train------------------------------------------------------------------------------\ndef load_train(img_rows, img_cols, color_type=3): #train images and train labels\n    train_images = [] \n    train_labels = []\n    for classed in range(NUMBER_CLASSES):\n        print('Loading directory c{}'.format(classed))\n        files = glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/train/c' + str(classed), '*.jpg'))\n        for file in files:\n            img = get_image(file, img_rows, img_cols, color_type)\n            train_images.append(img)\n            train_labels.append(classed)\n    return train_images, train_labels \n\ndef read_and_normalize_train_data(img_rows, img_cols, color_type):\n    X, labels = load_train(img_rows, img_cols, color_type)\n    enc = LabelEncoder()                        \n    P = enc.fit_transform(labels)                ## convert string labels to numbers \n    y = to_categorical(P)                        ## convert number to one-hot-encode form \n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # split into train and test\n    x_train = np.array(x_train).reshape(-1,img_rows,img_cols,color_type)\n    x_test = np.array(x_test).reshape(-1,img_rows,img_cols,color_type)\n    return x_train, x_test, y_train, y_test\n#----------------------------------------------------------------------------------------------------------------------------------------------\n\n#-------------------------------------------------------test------------------------------------------------------------------------------------\ndef load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n    path = os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg')\n    files = sorted(glob(path))\n    X_test, X_test_id = [], []\n    total = 0\n    files_size = len(files)\n    for file in files:\n        if total >= size or total >= files_size:\n            break\n        file_base = file.split(os.path.sep)[-1]\n        img = get_image(file, img_rows, img_cols, color_type)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id\n\ndef read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)   \n    test_data = np.array(test_data)\n    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n    return test_data, test_ids\n#-------------------------------------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2021-11-16T09:50:08.536544Z","iopub.execute_input":"2021-11-16T09:50:08.536783Z","iopub.status.idle":"2021-11-16T09:50:08.694267Z","shell.execute_reply.started":"2021-11-16T09:50:08.53675Z","shell.execute_reply":"2021-11-16T09:50:08.692984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv')\ntest_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-16T09:50:08.699468Z","iopub.execute_input":"2021-11-16T09:50:08.700196Z","iopub.status.idle":"2021-11-16T09:50:08.865526Z","shell.execute_reply.started":"2021-11-16T09:50:08.700141Z","shell.execute_reply":"2021-11-16T09:50:08.864812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_rows = 64 # dimension of images\nimg_cols = 64\ncolor_type = 3\ntest_samples = test_data.shape[0]\n\n# loading train images\nx_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-16T09:50:08.868232Z","iopub.execute_input":"2021-11-16T09:50:08.868651Z","iopub.status.idle":"2021-11-16T09:53:46.697042Z","shell.execute_reply.started":"2021-11-16T09:50:08.86861Z","shell.execute_reply":"2021-11-16T09:53:46.696105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading validation images\ntest_files, test_targets = read_and_normalize_sampled_test_data(test_samples, img_rows, img_cols, color_type)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T09:53:46.698433Z","iopub.execute_input":"2021-11-16T09:53:46.698992Z","iopub.status.idle":"2021-11-16T10:07:54.724226Z","shell.execute_reply.started":"2021-11-16T09:53:46.698948Z","shell.execute_reply":"2021-11-16T10:07:54.723349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = {'c0': 'Safe driving', \n            'c1': 'Texting - right', \n            'c2': 'Talking on the phone - right', \n            'c3': 'Texting - left', \n            'c4': 'Talking on the phone - left', \n            'c5': 'Operating the radio', \n            'c6': 'Drinking', \n            'c7': 'Reaching behind', \n            'c8': 'Hair and makeup', \n            'c9': 'Talking to passenger'}","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:07:54.725824Z","iopub.execute_input":"2021-11-16T10:07:54.726098Z","iopub.status.idle":"2021-11-16T10:07:54.731406Z","shell.execute_reply.started":"2021-11-16T10:07:54.726064Z","shell.execute_reply":"2021-11-16T10:07:54.730659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Create_model2():\n    model = Sequential()\n\n    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))\n    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dense(10,activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:15:22.27475Z","iopub.execute_input":"2021-11-16T10:15:22.275328Z","iopub.status.idle":"2021-11-16T10:15:22.286668Z","shell.execute_reply.started":"2021-11-16T10:15:22.275285Z","shell.execute_reply":"2021-11-16T10:15:22.285856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Create_model2()\n\nmodel.summary()\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:15:25.777025Z","iopub.execute_input":"2021-11-16T10:15:25.777736Z","iopub.status.idle":"2021-11-16T10:15:25.878985Z","shell.execute_reply.started":"2021-11-16T10:15:25.777684Z","shell.execute_reply":"2021-11-16T10:15:25.878304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20,batch_size=40, verbose=1)\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:15:40.900699Z","iopub.execute_input":"2021-11-16T10:15:40.900978Z","iopub.status.idle":"2021-11-16T10:17:19.772537Z","shell.execute_reply.started":"2021-11-16T10:15:40.900947Z","shell.execute_reply":"2021-11-16T10:17:19.771764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score1 = model.evaluate(x_test, y_test, verbose=1)\nprint('Loss: ', score1[0])\nprint('Accuracy: ', score1[1]*100, ' %')","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:17:24.982527Z","iopub.execute_input":"2021-11-16T10:17:24.982786Z","iopub.status.idle":"2021-11-16T10:17:26.324871Z","shell.execute_reply.started":"2021-11-16T10:17:24.982757Z","shell.execute_reply":"2021-11-16T10:17:26.324114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_files, batch_size=40, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:17:33.507604Z","iopub.execute_input":"2021-11-16T10:17:33.507855Z","iopub.status.idle":"2021-11-16T10:17:40.471595Z","shell.execute_reply.started":"2021-11-16T10:17:33.507825Z","shell.execute_reply":"2021-11-16T10:17:40.470806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    img = test_files[i]\n    plt.imshow(img, cmap='gray')\n\n    print('Y prediction: {}'.format(predictions[i]))\n    print('Predicted: {}'.format(classes.get('c{}'.format(np.argmax(predictions[i])))))\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:20:40.565428Z","iopub.execute_input":"2021-11-16T10:20:40.566276Z","iopub.status.idle":"2021-11-16T10:20:42.630509Z","shell.execute_reply.started":"2021-11-16T10:20:40.566213Z","shell.execute_reply":"2021-11-16T10:20:42.629785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nresult = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\nresult.loc[:, 'img'] = pd.Series(test_targets, index=result.index)\n    \nsub_file = os.path.join('submission' + '.csv')\n    \nresult.to_csv(sub_file, index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:20:59.031109Z","iopub.execute_input":"2021-11-16T10:20:59.031409Z","iopub.status.idle":"2021-11-16T10:21:00.214312Z","shell.execute_reply.started":"2021-11-16T10:20:59.031374Z","shell.execute_reply":"2021-11-16T10:21:00.213392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv = pd.read_csv('./submission.csv')\ntest_csv","metadata":{"execution":{"iopub.status.busy":"2021-11-16T10:21:02.573065Z","iopub.execute_input":"2021-11-16T10:21:02.573333Z","iopub.status.idle":"2021-11-16T10:21:02.745537Z","shell.execute_reply.started":"2021-11-16T10:21:02.573302Z","shell.execute_reply":"2021-11-16T10:21:02.74477Z"},"trusted":true},"execution_count":null,"outputs":[]}]}