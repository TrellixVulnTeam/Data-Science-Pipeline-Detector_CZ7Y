{"cells":[{"metadata":{"trusted":true,"_uuid":"a38e0415cf6157f5256111713ea22df12e300e85"},"cell_type":"code","source":"# initiating gpu using tensorflow.\nimport tensorflow as tf\nfrom keras.backend.tensorflow_backend import set_session\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.log_device_placement = True\nsess = tf.Session(config=config)\nset_session(sess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f183d4222c35eeb6f27a6902bd9bfc03fc1cf3c"},"cell_type":"code","source":"#importing libraries for the data processing and model.\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport random\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.datasets import cifar10\nfrom keras.utils import np_utils\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import EarlyStopping\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import misc\nfrom keras.models import load_model\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10daaf4364643a394c6c6de74f3339bc0b495838"},"cell_type":"code","source":"# defining the path and classes.\ndirectory = '../input/state-farm-distracted-driver-detection/imgs/train'\ntest_directory = '../input/state-farm-distracted-driver-detection/imgs/test/'\nrandom_test = '../input/driver/'\nclasses = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d20802e11a6dca5957c0953938cda4ca36316d9"},"cell_type":"code","source":"# defining a shape to be used for our models.\nimg_size1 = 240\nimg_size2 = 240","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"97af3191ca2124c52b95a1908e10ddeb15972450"},"cell_type":"code","source":"# Train class image for display.\nfor i in classes:\n    path = os.path.join(directory,i)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n        plt.imshow(img_array, cmap='gray')\n        plt.show()\n        break\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8957088584e3963c5894a5a5e83e904cb400c09a"},"cell_type":"code","source":"# Test class image for display.\ntest_array = []\nfor img in os.listdir(test_directory):\n    img_array = cv2.imread(os.path.join(test_directory,img),cv2.IMREAD_GRAYSCALE)\n    test_array = img_array\n    plt.imshow(img_array, cmap='gray')\n    plt.show()\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf0389eba76508a37e2e59199b68b7bc68d2dbb6"},"cell_type":"code","source":"# checkking image size using shape.\nprint(img_array.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cde5b7b8563342386733fd5171ca2ad903686eb1"},"cell_type":"code","source":"# trying out the resize image functionality\nnew_img = cv2.resize(test_array,(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b7785807547398a91f21ec9eae18c9ba2d6560c"},"cell_type":"code","source":"# creating a training dataset.\ntraining_data = []\ni = 0\ndef create_training_data():\n    for category in classes:\n        path = os.path.join(directory,category)\n        class_num = classes.index(category)\n        \n        for img in os.listdir(path):\n            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n            new_img = cv2.resize(img_array,(img_size2,img_size1))\n            training_data.append([\n                new_img,class_num])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d725070faf9221489e69f2ee5f684ccd8dba3fa"},"cell_type":"code","source":"# Creating a test dataset.\ntesting_data = []\ni = 0\ndef create_testing_data():        \n    for img in os.listdir(test_directory):\n        img_array = cv2.imread(os.path.join(test_directory,img),cv2.IMREAD_GRAYSCALE)\n        new_img = cv2.resize(img_array,(img_size2,img_size1))\n        testing_data.append([img,\n            new_img])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"085cb49d3aecd1dbfdbf5d6feda7d0e00a4cc40d"},"cell_type":"code","source":"create_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4587210a240b295a82411050e3089d7234ed9ad3"},"cell_type":"code","source":"create_testing_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d19095cd158d3c0cc746ce63b246bafcf0969a08"},"cell_type":"code","source":"print(len(training_data))\nprint(len(testing_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42d170f71ede5c10cb6408e5cadbf0c7ce89d385"},"cell_type":"code","source":"random.shuffle(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be6c02d41af9db7002677020a218c97e4aa4c504"},"cell_type":"code","source":"x = []\ny = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe474ac6b78d3f29eb5893f0226e5c2d791744af"},"cell_type":"code","source":"for features, label in training_data:\n    x.append(features)\n    y.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0b85a24b6bc096afdfa7a8fa7e36710db06e95e"},"cell_type":"code","source":"x[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16829d76be4a2fb85fbde9f9035f5fa89bf81148"},"cell_type":"code","source":"len(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceef0d99e7056373f312f65230b2d0da5abdd691"},"cell_type":"code","source":"#X  = np.array(x[1]).reshape(-1,img_size2,img_size1,1)\n#i = 1\n#for i in range(len(x)):\nX = np.array(x).reshape(-1,img_size2,img_size1,1)\n#    X = np.append(X,Y,axis = 0)\nX.shape,X[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c00ed3190d82666854084971c1ecd7e46979d86d"},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d24e0c5cec21c8fd3962eca1572b6d07a748479"},"cell_type":"code","source":"Y_train = np_utils.to_categorical(y_train,num_classes=10)\nY_test = np_utils.to_categorical(y_test,num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0017519227728612f472e15e0cf51426c3a8c9e6"},"cell_type":"code","source":"model = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fadb2ea572a31ba1ad4b2e7633e9ea4e21cb1ce"},"cell_type":"code","source":"model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(240,240,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a902674c93077ed686497fd4bc3f9688a403d2b"},"cell_type":"code","source":"model.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01faae36470bd2393c4bff4ded807bdf0558e479"},"cell_type":"code","source":"model.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1d5e63583c00a0c8c080ba47f2633eb6e6feff9"},"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(units = 512,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units = 128,activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10,activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06a1778de01f27f551c0834b859aa86eeb8dade4"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2ecad4639865a6cb8ea83b8e7e7d7e3047be7a0"},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d3fdd979e6eb2b2f7b98e25a24a66cc400cd764"},"cell_type":"code","source":"callbacks = [EarlyStopping(monitor='val_acc',patience=5)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2608623a78b85d27a883fdff98d7ea4cef48bfa4"},"cell_type":"code","source":"batch_size = 50\nn_epochs = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3dd276eea82c94e440eba4eb4285f99f4cbe71c"},"cell_type":"code","source":"results = model.fit(x_train,Y_train,batch_size=batch_size,epochs=n_epochs,verbose=1,validation_data=(x_test,Y_test),callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27c64d2b278e17e674406e26ace6b3a5d60bd422"},"cell_type":"code","source":"# Plot training & validation accuracy values\nplt.plot(results.history['acc'])\nplt.plot(results.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(results.history['loss'])\nplt.plot(results.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3247e955ac3dc0cfeff0d4f1524bd24e40e3e8b1"},"cell_type":"code","source":"preds = model.predict(np.array(testing_data[0][1]).reshape(-1,img_size2,img_size1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2af8354dcbcb1035f51900c73d1c1ddc0c2488a"},"cell_type":"code","source":"model.save_weights('./driverdistraction_lr_weights.h5', overwrite=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"839040cdbfe37d98628057cb885d159bd8223010"},"cell_type":"code","source":"model.save('./driverdistraction_lr_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c788f090372555f48f840c95ed36e4c0acd4777"},"cell_type":"code","source":"loaded_model = load_model('../input/driver-distraction/driverdistraction_lr_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f325c9a80fec49bbe2540142e4a1f21ddfc2daa"},"cell_type":"code","source":"test_data = np.array(testing_data[1001][1]).reshape(-1,img_size2,img_size1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61941ace45641ad802732221254e5920db787831"},"cell_type":"code","source":"preds = model.predict(test_data)\npreds= np.argmax(preds)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nclasses = {0: \"safe driving\",\n1: \"texting - right\",\n2: \"talking on the phone - right\",\n3: \"texting - left\",\n4: \"talking on the phone - left\",\n5: \"operating the radio\",\n6: \"drinking\",\n7: \"reaching behind\",\n8: \"hair and makeup\",\n9: \"talking to passenger\",\n}\n\n\nfor key,value in classes.items():\n    if preds==key:\n        predicted = value\n\npredicted     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e984677839f33f3d99afbc4944b7e3828ea2849"},"cell_type":"code","source":"print(predicted)\nnew_img = cv2.resize(testing_data[1001][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbd73f2d1aa8f1e5e83de7dfe08d92d38604ccd7"},"cell_type":"markdown","source":"\n    c0: safe driving\n    c1: texting - right\n    c2: talking on the phone - right\n    c3: texting - left\n    c4: talking on the phone - left\n    c5: operating the radio\n    c6: drinking\n    c7: reaching behind\n    c8: hair and makeup\n    c9: talking to passenger\n","execution_count":null},{"metadata":{"trusted":true,"_uuid":"eff0351213c0d61f988020326e2b1d30434ccaa9"},"cell_type":"code","source":"def create_submission(predictions, test_id, info):\n    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n    now = datetime.datetime.now()\n    if not os.path.isdir('subm'):\n        os.mkdir('subm')\n    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n    result1.to_csv(sub_file, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}