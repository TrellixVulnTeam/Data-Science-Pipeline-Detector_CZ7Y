{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install opencv-python==4.5.5.62\n!pip install opencv-contrib-python==4.5.5.62\n!pip install tf-explain","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:24.578628Z","iopub.execute_input":"2022-06-05T16:27:24.579398Z","iopub.status.idle":"2022-06-05T16:27:49.157638Z","shell.execute_reply.started":"2022-06-05T16:27:24.579352Z","shell.execute_reply":"2022-06-05T16:27:49.156425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport sys\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport skimage\nfrom skimage.feature import hog, canny\nfrom skimage.filters import sobel\nfrom skimage import color\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom keras import layers\nimport keras.backend as K\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing import image\nfrom keras.layers import Input, Dense, Activation, Dropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D \nfrom keras.applications.imagenet_utils import preprocess_input\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications import ResNet50\nfrom tf_explain.core.activations import ExtractActivations\nfrom tf_explain.core.grad_cam import GradCAM\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.data_utils import get_file\n\nfrom PIL import Image\nfrom tqdm import tqdm\nimport random as rnd\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom numpy import expand_dims\n\n!pip install livelossplot\nfrom livelossplot import PlotLossesKeras\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:49.16046Z","iopub.execute_input":"2022-06-05T16:27:49.160844Z","iopub.status.idle":"2022-06-05T16:27:57.243509Z","shell.execute_reply.started":"2022-06-05T16:27:49.160793Z","shell.execute_reply":"2022-06-05T16:27:57.242483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Dataset\nWe'll use here the Pandas to load the dataset into memory","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ntrain_df['path'] = '../input/state-farm-distracted-driver-detection/imgs/train/' + train_df['classname']+ '/' +train_df['img']\npred_df = pd.read_csv('../input/state-farm-distracted-driver-detection/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.245086Z","iopub.execute_input":"2022-06-05T16:27:57.245377Z","iopub.status.idle":"2022-06-05T16:27:57.417424Z","shell.execute_reply.started":"2022-06-05T16:27:57.245345Z","shell.execute_reply":"2022-06-05T16:27:57.416111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = {'c0': 'normal driving',\n'c1': 'texting - right',\n'c2': 'talking on the phone - right',\n'c3': 'texting - left',\n'c4': 'talking on the phone - left',\n'c5': 'operating the radio',\n'c6': 'drinking',\n'c7': 'reaching behind',\n'c8': 'hair and makeup',\n'c9': 'talking to passenger',}","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.422121Z","iopub.execute_input":"2022-06-05T16:27:57.422455Z","iopub.status.idle":"2022-06-05T16:27:57.428974Z","shell.execute_reply.started":"2022-06-05T16:27:57.422418Z","shell.execute_reply":"2022-06-05T16:27:57.427827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.430748Z","iopub.execute_input":"2022-06-05T16:27:57.431032Z","iopub.status.idle":"2022-06-05T16:27:57.454905Z","shell.execute_reply.started":"2022-06-05T16:27:57.430997Z","shell.execute_reply":"2022-06-05T16:27:57.453933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.456639Z","iopub.execute_input":"2022-06-05T16:27:57.457384Z","iopub.status.idle":"2022-06-05T16:27:57.489023Z","shell.execute_reply.started":"2022-06-05T16:27:57.457331Z","shell.execute_reply":"2022-06-05T16:27:57.488027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.count()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.490688Z","iopub.execute_input":"2022-06-05T16:27:57.490945Z","iopub.status.idle":"2022-06-05T16:27:57.514983Z","shell.execute_reply.started":"2022-06-05T16:27:57.490916Z","shell.execute_reply":"2022-06-05T16:27:57.514251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train samples count: ', len(train_df))\ntrain_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.516739Z","iopub.execute_input":"2022-06-05T16:27:57.517071Z","iopub.status.idle":"2022-06-05T16:27:57.536908Z","shell.execute_reply.started":"2022-06-05T16:27:57.517028Z","shell.execute_reply":"2022-06-05T16:27:57.535809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Class Count: ',len(train_df['classname'].value_counts()))\ntrain_df['classname'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.539167Z","iopub.execute_input":"2022-06-05T16:27:57.539537Z","iopub.status.idle":"2022-06-05T16:27:57.55898Z","shell.execute_reply.started":"2022-06-05T16:27:57.539487Z","shell.execute_reply":"2022-06-05T16:27:57.557888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking missing data\nLets check if there is any missing values in our dataset","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.562388Z","iopub.execute_input":"2022-06-05T16:27:57.562723Z","iopub.status.idle":"2022-06-05T16:27:57.582958Z","shell.execute_reply.started":"2022-06-05T16:27:57.562687Z","shell.execute_reply":"2022-06-05T16:27:57.581875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization\nLooking at some random beauties\nIt's a great deal of fun to explore the data and play around with matplotlib","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15,12))\nfor idx,i in enumerate(train_df.classname.unique()):\n    plt.subplot(4,7,idx+1)\n    df = train_df[train_df['classname'] ==i].reset_index(drop = True)\n    image_path = df.loc[rnd.randint(0, len(df))-1,'path']\n    img = Image.open(image_path)\n    img = img.resize((224,224))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(classes[i])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:27:57.584821Z","iopub.execute_input":"2022-06-05T16:27:57.585188Z","iopub.status.idle":"2022-06-05T16:27:59.148364Z","shell.execute_reply.started":"2022-06-05T16:27:57.58514Z","shell.execute_reply":"2022-06-05T16:27:59.147277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_species(df,class_name):\n    plt.figure(figsize = (12,12))\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    plt.suptitle(classes[class_name])\n    for idx,i in enumerate(np.random.choice(classes_df['path'],32)):\n        plt.subplot(8,8,idx+1)\n        image_path = i\n        img = Image.open(image_path)\n        img = img.resize((224,224))\n        plt.imshow(img)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:28:13.432052Z","iopub.execute_input":"2022-06-05T16:28:13.432447Z","iopub.status.idle":"2022-06-05T16:28:13.43978Z","shell.execute_reply.started":"2022-06-05T16:28:13.432409Z","shell.execute_reply":"2022-06-05T16:28:13.43886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_ in train_df['classname'].unique():\n    #print('\\n\\n')\n    plot_species(train_df , class_)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:28:13.958853Z","iopub.execute_input":"2022-06-05T16:28:13.959195Z","iopub.status.idle":"2022-06-05T16:28:49.716106Z","shell.execute_reply.started":"2022-06-05T16:28:13.959162Z","shell.execute_reply":"2022-06-05T16:28:49.715032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Distribution AnalysisÂ¶\nIn this section we will be analyzing the number of training and test samples in each class. It will give us a better understanding of our dataset and provide us the necessary information to preprocess our dataset before the training phase.","metadata":{}},{"cell_type":"code","source":"plot = sns.countplot(x = train_df['classname'], color = '#2596be')\nsns.set(rc={'figure.figsize':(30,25)})\nsns.despine()\nplot.set_title('Class Distribution\\n', font = 'serif', x = 0.1, y=1, fontsize = 18);\nplot.set_ylabel(\"Count\", x = 0.02, font = 'serif', fontsize = 12)\nplot.set_xlabel(\"Driver classes\", fontsize = 15, font = 'serif')\n\nfor p in plot.patches:\n    plot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2, p.get_height()), \n       ha = 'center', va = 'center', xytext = (0, -20),font = 'serif', textcoords = 'offset points', size = 15)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:28:49.718182Z","iopub.execute_input":"2022-06-05T16:28:49.718493Z","iopub.status.idle":"2022-06-05T16:28:50.05192Z","shell.execute_reply.started":"2022-06-05T16:28:49.718457Z","shell.execute_reply":"2022-06-05T16:28:50.050894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nclass_cnt = train_df.groupby(['classname']).size().reset_index(name = 'counts')\ncolors = sns.color_palette('Paired')[0:9]\nplt.pie(class_cnt['counts'], labels=class_cnt['classname'], colors=colors, autopct='%1.1f%%')\nplt.legend(loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:28:50.05378Z","iopub.execute_input":"2022-06-05T16:28:50.054053Z","iopub.status.idle":"2022-06-05T16:28:50.337668Z","shell.execute_reply.started":"2022-06-05T16:28:50.05402Z","shell.execute_reply":"2022-06-05T16:28:50.336675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Resolutions","metadata":{}},{"cell_type":"code","source":"widths, heights = [], []\n\nfor path in tqdm(train_df[\"path\"]):\n    width, height = Image.open(path).size\n    widths.append(width)\n    heights.append(height)\n    \ntrain_df[\"width\"] = widths\ntrain_df[\"height\"] = heights\ntrain_df[\"dimension\"] = train_df[\"width\"] * train_df[\"height\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:28:50.339955Z","iopub.execute_input":"2022-06-05T16:28:50.340225Z","iopub.status.idle":"2022-06-05T16:29:13.418745Z","shell.execute_reply.started":"2022-06-05T16:28:50.340191Z","shell.execute_reply":"2022-06-05T16:29:13.417826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets see some small images**","metadata":{}},{"cell_type":"code","source":"train_df.sort_values('width').head(84)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:29:13.420248Z","iopub.execute_input":"2022-06-05T16:29:13.420463Z","iopub.status.idle":"2022-06-05T16:29:13.441407Z","shell.execute_reply.started":"2022-06-05T16:29:13.420437Z","shell.execute_reply":"2022-06-05T16:29:13.440432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Color Analysis\nWe need to do some color analysis to get an ida about the augmentation technique needed for this problem","metadata":{}},{"cell_type":"code","source":"def is_grey_scale(givenImage):\n    w,h = givenImage.size\n    for i in range(w):\n        for j in range(h):\n            r,g,b = givenImage.getpixel((i,j))\n            if r != g != b: return False\n    return True","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:29:13.443167Z","iopub.execute_input":"2022-06-05T16:29:13.443477Z","iopub.status.idle":"2022-06-05T16:29:13.454211Z","shell.execute_reply.started":"2022-06-05T16:29:13.443435Z","shell.execute_reply":"2022-06-05T16:29:13.452928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check color scale of Train images**","metadata":{}},{"cell_type":"code","source":"sampleFrac = 0.5\n#get our sampled images\nisGreyList = []\nfor imageName in train_df['path'].sample(frac=sampleFrac):\n    val = Image.open(imageName).convert('RGB')\n    isGreyList.append(is_grey_scale(val))\nprint(np.sum(isGreyList) / len(isGreyList))\ndel isGreyList","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:29:13.456148Z","iopub.execute_input":"2022-06-05T16:29:13.45642Z","iopub.status.idle":"2022-06-05T16:30:21.721595Z","shell.execute_reply.started":"2022-06-05T16:29:13.456391Z","shell.execute_reply":"2022-06-05T16:30:21.720366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get mean intensity for each channel RGB**","metadata":{}},{"cell_type":"code","source":"def get_rgb_men(row):\n    img = cv2.imread(row['path'])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return np.sum(img[:,:,0]), np.sum(img[:,:,1]), np.sum(img[:,:,2])\n\ntqdm.pandas()\ntrain_df['R'], train_df['G'], train_df['B'] = zip(*train_df.progress_apply(lambda row: get_rgb_men(row), axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:30:21.723798Z","iopub.execute_input":"2022-06-05T16:30:21.724132Z","iopub.status.idle":"2022-06-05T16:33:25.001979Z","shell.execute_reply.started":"2022-06-05T16:30:21.724087Z","shell.execute_reply":"2022-06-05T16:33:25.00062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_color_dist(df, count):\n    fig, axr = plt.subplots(count,2,figsize=(15,15))\n    if df.empty:\n        print(\"Image internsity of selected color is weak\")\n        return\n    for idx, i in enumerate(np.random.choice(df['path'], count)):\n        img = cv2.imread(i)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axr[idx,0].imshow(img)\n        axr[idx,0].axis('off')\n        axr[idx,1].set_title('R={:.0f}, G={:.0f}, B={:.0f} '.format(np.mean(img[:,:,0]), np.mean(img[:,:,1]), np.mean(img[:,:,2]))) \n        x, y = np.histogram(img[:,:,0], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='R', alpha=0.8, color='red')\n        x, y = np.histogram(img[:,:,1], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='G', alpha=0.8, color='green')\n        x, y = np.histogram(img[:,:,2], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='B', alpha=0.8, color='blue')\n        axr[idx,1].legend()\n        axr[idx,1].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:33:25.003935Z","iopub.execute_input":"2022-06-05T16:33:25.004243Z","iopub.status.idle":"2022-06-05T16:33:25.017805Z","shell.execute_reply.started":"2022-06-05T16:33:25.00421Z","shell.execute_reply":"2022-06-05T16:33:25.016642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Red images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[((train_df['B']) < train_df['R']) & ((train_df['G']) < train_df['R'])]\nif df.size != 0:\n    show_color_dist(df, 8)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:33:25.020382Z","iopub.execute_input":"2022-06-05T16:33:25.020636Z","iopub.status.idle":"2022-06-05T16:33:25.040511Z","shell.execute_reply.started":"2022-06-05T16:33:25.020607Z","shell.execute_reply":"2022-06-05T16:33:25.039481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Green images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[(train_df['G'] > train_df['R']) & (train_df['G'] > train_df['B'])]\nif df.size != 0:\n    show_color_dist(df, 8)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:33:25.042168Z","iopub.execute_input":"2022-06-05T16:33:25.042457Z","iopub.status.idle":"2022-06-05T16:33:43.069476Z","shell.execute_reply.started":"2022-06-05T16:33:25.042428Z","shell.execute_reply":"2022-06-05T16:33:43.068043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Blue images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[(train_df['B'] > train_df['R']) & (train_df['B'] > train_df['G'])]\nif df.size != 0:\n    show_color_dist(df, 8)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:33:43.071652Z","iopub.execute_input":"2022-06-05T16:33:43.071957Z","iopub.status.idle":"2022-06-05T16:34:02.515423Z","shell.execute_reply.started":"2022-06-05T16:33:43.071921Z","shell.execute_reply":"2022-06-05T16:34:02.51442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"markdown","source":"## Analyzing Edges\nA Sobel filter is one means of getting a basic edge magnitude/gradient image. Can be useful to threshold and find prominent linear features, etc. Several other similar filters in skimage.filters are also good edge detectors: roberts, scharr, etc. and you can control direction, i.e. use an anisotropic version.","metadata":{}},{"cell_type":"code","source":"def edges_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],2)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        edges = sobel(image)\n        gray_edges=sobel(gray)\n        dimension = edges.shape\n        fig = plt.figure(figsize=(8, 8))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(gray_edges)\n        plt.subplot(2,2,2)\n        plt.imshow(edges[:dimension[0],:dimension[1],0], cmap=\"gray\")\n        plt.subplot(2,2,3)\n        plt.imshow(edges[:dimension[0],:dimension[1],1], cmap='gray')\n        plt.subplot(2,2,4)\n        plt.imshow(edges[:dimension[0],:dimension[1],2], cmap='gray')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:34:02.517022Z","iopub.execute_input":"2022-06-05T16:34:02.517416Z","iopub.status.idle":"2022-06-05T16:34:02.530332Z","shell.execute_reply.started":"2022-06-05T16:34:02.51737Z","shell.execute_reply":"2022-06-05T16:34:02.528918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    edges_images_gray(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:34:02.532375Z","iopub.execute_input":"2022-06-05T16:34:02.532743Z","iopub.status.idle":"2022-06-05T16:34:21.650609Z","shell.execute_reply.started":"2022-06-05T16:34:02.532695Z","shell.execute_reply":"2022-06-05T16:34:21.649628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HSV Transform\nSince this contest is about time series ordering, I think it's possible there may be useful information in a transform to HSV color space. HSV is useful for identifying shadows and illumination, as well as giving us a means to identify similar objects that are distinct by color between scenes (hue), though there's no guarantee the hue will be stable.","metadata":{}},{"cell_type":"code","source":"def hsv_images(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(train_df['path'],2)):  \n        image = cv2.imread(i)\n        hsv = color.rgb2hsv(image)\n        dimension = hsv.shape\n        fig = plt.figure(figsize=(8, 8))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(image)\n        plt.subplot(2,2,2)\n        plt.imshow(hsv[:dimension[0],:dimension[1],0], cmap=\"PuBuGn\")\n        plt.subplot(2,2,3)\n        plt.imshow(hsv[:dimension[0],:dimension[1],1], cmap='PuBuGn')\n        plt.subplot(2,2,4)\n        plt.imshow(hsv[:dimension[0],:dimension[1],2], cmap='PuBuGn')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:36:05.397945Z","iopub.execute_input":"2022-06-05T16:36:05.398324Z","iopub.status.idle":"2022-06-05T16:36:05.406714Z","shell.execute_reply.started":"2022-06-05T16:36:05.398287Z","shell.execute_reply":"2022-06-05T16:36:05.405773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    hsv_images(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:36:05.700498Z","iopub.execute_input":"2022-06-05T16:36:05.700989Z","iopub.status.idle":"2022-06-05T16:36:25.169405Z","shell.execute_reply.started":"2022-06-05T16:36:05.700956Z","shell.execute_reply":"2022-06-05T16:36:25.168703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Corners","metadata":{}},{"cell_type":"code","source":"def corners_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        corners_gray = cv2.goodFeaturesToTrack(gray, maxCorners=50, qualityLevel=0.02, minDistance=20)\n        corners_gray = np.float32(corners_gray)\n        for item in corners_gray:\n            x, y = item[0]\n            cv2.circle(image, (int(x), int(y)), 6, (0, 255, 0), -1)\n        fig = plt.figure(figsize=(16, 16))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(image, cmap=\"BuGn\")\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:37:06.407817Z","iopub.execute_input":"2022-06-05T16:37:06.408868Z","iopub.status.idle":"2022-06-05T16:37:06.418225Z","shell.execute_reply.started":"2022-06-05T16:37:06.408814Z","shell.execute_reply":"2022-06-05T16:37:06.417173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    corners_images_gray(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:37:24.526085Z","iopub.execute_input":"2022-06-05T16:37:24.526402Z","iopub.status.idle":"2022-06-05T16:37:40.975419Z","shell.execute_reply.started":"2022-06-05T16:37:24.526373Z","shell.execute_reply":"2022-06-05T16:37:40.974407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sift Features","metadata":{}},{"cell_type":"code","source":"def sift_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        sift = cv2.SIFT_create()\n        kp, des = sift.detectAndCompute(gray, None)\n        kp_img = cv2.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n        fig = plt.figure(figsize=(16, 16))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(kp_img, cmap=\"viridis\")\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:38:50.724707Z","iopub.execute_input":"2022-06-05T16:38:50.725044Z","iopub.status.idle":"2022-06-05T16:38:50.733083Z","shell.execute_reply.started":"2022-06-05T16:38:50.725007Z","shell.execute_reply":"2022-06-05T16:38:50.732182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    sift_images_gray(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:38:51.474297Z","iopub.execute_input":"2022-06-05T16:38:51.47534Z","iopub.status.idle":"2022-06-05T16:39:10.449545Z","shell.execute_reply.started":"2022-06-05T16:38:51.47509Z","shell.execute_reply":"2022-06-05T16:39:10.44811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Augmentations","metadata":{}},{"cell_type":"code","source":"def plot_augimages(paths, datagen):\n    plt.figure(figsize = (14,28))\n    plt.suptitle('Augmented Images')\n    \n    midx = 0\n    for path in paths:\n        data = Image.open(path)\n        data = data.resize((224,224))\n        samples = expand_dims(data, 0)\n        it = datagen.flow(samples, batch_size=1)\n    \n        # Show Original Image\n        plt.subplot(10,5, midx+1)\n        plt.imshow(data)\n        plt.axis('off')\n    \n        # Show Augmented Images\n        for idx, i in enumerate(range(4)):\n            midx += 1\n            plt.subplot(10,5, midx+1)\n            \n            batch = it.next()\n            image = batch[0].astype('uint8')\n            plt.imshow(image)\n            plt.axis('off')\n        midx += 1\n    \n    plt.tight_layout()\n    plt.show()\n\n    \ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest'\n) \nplot_augimages(np.random.choice(train_df['path'],10), datagen)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:29.947585Z","iopub.execute_input":"2022-06-05T16:39:29.948236Z","iopub.status.idle":"2022-06-05T16:39:36.905568Z","shell.execute_reply.started":"2022-06-05T16:39:29.948157Z","shell.execute_reply":"2022-06-05T16:39:36.90429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"y_count=len(train_df['classname'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:36.907911Z","iopub.execute_input":"2022-06-05T16:39:36.908356Z","iopub.status.idle":"2022-06-05T16:39:36.91568Z","shell.execute_reply.started":"2022-06-05T16:39:36.908314Z","shell.execute_reply":"2022-06-05T16:39:36.914078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG19","metadata":{}},{"cell_type":"code","source":"# include_top = False means that we doesnt include fully connected top layer we will add them accordingly\nvgg19 = VGG19(include_top = False, input_shape = (560,560,3), weights = 'imagenet')\n\n# training of all the convolution is set to false\nfor layer in vgg19.layers:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(vgg19.output)\npredictions = Dense(y_count, activation='softmax')(x)\n\nmodel_vgg19 = Model(inputs = vgg19.input, outputs = predictions)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:38.627248Z","iopub.execute_input":"2022-06-05T16:39:38.627523Z","iopub.status.idle":"2022-06-05T16:39:39.200958Z","shell.execute_reply.started":"2022-06-05T16:39:38.627495Z","shell.execute_reply":"2022-06-05T16:39:39.200171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet50","metadata":{}},{"cell_type":"code","source":"# include_top = False means that we doesnt include fully connected top layer we will add them accordingly\nresNet50 = ResNet50(include_top = False, input_shape = (560,560,3), weights = 'imagenet')\n\n# training of all the convolution is set to false\nfor layer in resNet50.layers:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(resNet50.output)\npredictions = Dense(y_count, activation='softmax')(x)\n\nmodel_resNet50 = Model(inputs = resNet50.input, outputs = predictions)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:40.56723Z","iopub.execute_input":"2022-06-05T16:39:40.567509Z","iopub.status.idle":"2022-06-05T16:39:42.266333Z","shell.execute_reply.started":"2022-06-05T16:39:40.56748Z","shell.execute_reply":"2022-06-05T16:39:42.265271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Own Proposed Model","metadata":{}},{"cell_type":"code","source":"def create_model():\n    model = Sequential()\n\n    ## CNN 1\n    model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64, 64, 3)))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(32,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 2\n    model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 3\n    model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.5))\n\n    ## Output\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(10,activation='softmax'))\n\n    return model\n\n\ncustom_model = create_model()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:42.711056Z","iopub.execute_input":"2022-06-05T16:39:42.711363Z","iopub.status.idle":"2022-06-05T16:39:42.949768Z","shell.execute_reply.started":"2022-06-05T16:39:42.711332Z","shell.execute_reply":"2022-06-05T16:39:42.948691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile Model","metadata":{}},{"cell_type":"markdown","source":"### Vgg19","metadata":{}},{"cell_type":"code","source":"model_vgg19.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nrlrp_vgg19 = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.01,patience=2,verbose=2,mode=\"auto\",min_delta=0.0001,cooldown=0,min_lr=0)\nmodel_vgg19.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:45.908802Z","iopub.execute_input":"2022-06-05T16:39:45.909075Z","iopub.status.idle":"2022-06-05T16:39:45.937785Z","shell.execute_reply.started":"2022-06-05T16:39:45.909048Z","shell.execute_reply":"2022-06-05T16:39:45.935778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet50","metadata":{}},{"cell_type":"code","source":"model_resNet50.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nrlrp_resNet50 = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.01,patience=2,verbose=2,mode=\"auto\",min_delta=0.0001,cooldown=0,min_lr=0)\nmodel_resNet50.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Model\n\n","metadata":{}},{"cell_type":"code","source":"custom_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\ncustom_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:50.29116Z","iopub.execute_input":"2022-06-05T16:39:50.291446Z","iopub.status.idle":"2022-06-05T16:39:50.312853Z","shell.execute_reply.started":"2022-06-05T16:39:50.291417Z","shell.execute_reply":"2022-06-05T16:39:50.312004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Test Split","metadata":{}},{"cell_type":"code","source":"X, y = train_df[['path', 'classname']], train_df['classname']","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:54.291826Z","iopub.execute_input":"2022-06-05T16:39:54.292156Z","iopub.status.idle":"2022-06-05T16:39:54.304869Z","shell.execute_reply.started":"2022-06-05T16:39:54.292115Z","shell.execute_reply":"2022-06-05T16:39:54.303411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:54.947714Z","iopub.execute_input":"2022-06-05T16:39:54.948004Z","iopub.status.idle":"2022-06-05T16:39:54.960435Z","shell.execute_reply.started":"2022-06-05T16:39:54.947975Z","shell.execute_reply":"2022-06-05T16:39:54.959384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Generators","metadata":{}},{"cell_type":"markdown","source":"### VGG19","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg19 import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:57.367722Z","iopub.execute_input":"2022-06-05T16:39:57.368551Z","iopub.status.idle":"2022-06-05T16:39:57.372692Z","shell.execute_reply.started":"2022-06-05T16:39:57.368516Z","shell.execute_reply":"2022-06-05T16:39:57.371763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_vgg_19 = datagen.flow_from_dataframe(\n        X_train,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(560, 560),  # All images will be resized to 150x150\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n        preprocessing_function=preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:39:58.059719Z","iopub.execute_input":"2022-06-05T16:39:58.060045Z","iopub.status.idle":"2022-06-05T16:40:06.88032Z","shell.execute_reply.started":"2022-06-05T16:39:58.059993Z","shell.execute_reply":"2022-06-05T16:40:06.877033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator_vgg_19 = datagen.flow_from_dataframe(\n        X_test,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(560, 560),  # All images will be resized to 150x150\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n        preprocessing_function=preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:40:06.885245Z","iopub.execute_input":"2022-06-05T16:40:06.886173Z","iopub.status.idle":"2022-06-05T16:40:09.22004Z","shell.execute_reply.started":"2022-06-05T16:40:06.886038Z","shell.execute_reply":"2022-06-05T16:40:09.217762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet50","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:40:09.222583Z","iopub.execute_input":"2022-06-05T16:40:09.224535Z","iopub.status.idle":"2022-06-05T16:40:09.232243Z","shell.execute_reply.started":"2022-06-05T16:40:09.224055Z","shell.execute_reply":"2022-06-05T16:40:09.231352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_resnet50 = datagen.flow_from_dataframe(\n        X_train,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(560, 560),  # All images will be resized to 150x150\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n        preprocessing_function=preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:40:09.234071Z","iopub.execute_input":"2022-06-05T16:40:09.236222Z","iopub.status.idle":"2022-06-05T16:40:09.551234Z","shell.execute_reply.started":"2022-06-05T16:40:09.235985Z","shell.execute_reply":"2022-06-05T16:40:09.550158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator_resnet50 = datagen.flow_from_dataframe(\n        X_test,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(560, 560),  # All images will be resized to 150x150\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n        preprocessing_function=preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:41:56.990871Z","iopub.execute_input":"2022-06-05T16:41:56.991241Z","iopub.status.idle":"2022-06-05T16:41:57.049922Z","shell.execute_reply.started":"2022-06-05T16:41:56.991198Z","shell.execute_reply":"2022-06-05T16:41:57.048997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"train_generator_custom_model = datagen.flow_from_dataframe(\n        X_train,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(64, 64),  # All images will be resized to 150x150\n        batch_size=40,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:41:57.051627Z","iopub.execute_input":"2022-06-05T16:41:57.051946Z","iopub.status.idle":"2022-06-05T16:41:57.251665Z","shell.execute_reply.started":"2022-06-05T16:41:57.051893Z","shell.execute_reply":"2022-06-05T16:41:57.250171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator_custom_model = datagen.flow_from_dataframe(\n        X_test,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(64, 64),  # All images will be resized to 150x150\n        batch_size=40,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:41:57.253718Z","iopub.execute_input":"2022-06-05T16:41:57.254063Z","iopub.status.idle":"2022-06-05T16:41:57.31215Z","shell.execute_reply.started":"2022-06-05T16:41:57.254018Z","shell.execute_reply":"2022-06-05T16:41:57.311369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Fitting","metadata":{}},{"cell_type":"markdown","source":"### Vgg19","metadata":{}},{"cell_type":"code","source":"history_vgg19 = model_vgg19.fit(\n      train_generator_vgg_19,\n     validation_data=val_generator_vgg_19,\n      epochs=2,\n      callbacks = [rlrp_vgg19],\n      verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Resnet50","metadata":{}},{"cell_type":"code","source":"history_resNet50 = model_resNet50.fit(\n      train_generator_resnet50,\n     validation_data=val_generator_resnet50,\n      epochs=10,\n       callbacks = [rlrp_resNet50], \n      verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"history_custom_model = custom_model.fit(\n      train_generator_custom_model,\n     validation_data=val_generator_custom_model,\n      steps_per_epoch=100,\n      epochs=70,\n      verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Loss","metadata":{}},{"cell_type":"markdown","source":"### Vgg19","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_vgg19.history['loss'])\nplt.plot(history_vgg19.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:09.711787Z","iopub.execute_input":"2022-06-05T16:42:09.712066Z","iopub.status.idle":"2022-06-05T16:42:09.783236Z","shell.execute_reply.started":"2022-06-05T16:42:09.712039Z","shell.execute_reply":"2022-06-05T16:42:09.782008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet50","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_resNet50.history['loss'])\nplt.plot(history_resNet50.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:12.019404Z","iopub.execute_input":"2022-06-05T16:42:12.020266Z","iopub.status.idle":"2022-06-05T16:42:12.050246Z","shell.execute_reply.started":"2022-06-05T16:42:12.020218Z","shell.execute_reply":"2022-06-05T16:42:12.049234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_custom_model.history['loss'])\nplt.plot(history_custom_model.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:13.939301Z","iopub.execute_input":"2022-06-05T16:42:13.939612Z","iopub.status.idle":"2022-06-05T16:42:13.973475Z","shell.execute_reply.started":"2022-06-05T16:42:13.939581Z","shell.execute_reply":"2022-06-05T16:42:13.972193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Accuracy","metadata":{}},{"cell_type":"markdown","source":"### Vgg19","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_vgg19.history['accuracy'])\nplt.plot(history_vgg19.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:19.8442Z","iopub.execute_input":"2022-06-05T16:42:19.844502Z","iopub.status.idle":"2022-06-05T16:42:19.881679Z","shell.execute_reply.started":"2022-06-05T16:42:19.844471Z","shell.execute_reply":"2022-06-05T16:42:19.879944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet50","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_resNet50.history['accuracy'])\nplt.plot(history_resNet50.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:20.423397Z","iopub.execute_input":"2022-06-05T16:42:20.423806Z","iopub.status.idle":"2022-06-05T16:42:20.454263Z","shell.execute_reply.started":"2022-06-05T16:42:20.423777Z","shell.execute_reply":"2022-06-05T16:42:20.453121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_custom_model.history['accuracy'])\nplt.plot(history_custom_model.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:24.20871Z","iopub.execute_input":"2022-06-05T16:42:24.209552Z","iopub.status.idle":"2022-06-05T16:42:24.241382Z","shell.execute_reply.started":"2022-06-05T16:42:24.209506Z","shell.execute_reply":"2022-06-05T16:42:24.240258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explaniable AI","metadata":{}},{"cell_type":"markdown","source":"## Methods and utils","metadata":{}},{"cell_type":"code","source":"dict_class = {'c0':0, 'c1':1, 'c2': 2, 'c3': 3, 'c4': 4, 'c5':5, 'c6': 6, 'c7':7, 'c8':8, 'c9':9}","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:25.129503Z","iopub.execute_input":"2022-06-05T16:42:25.129773Z","iopub.status.idle":"2022-06-05T16:42:25.135806Z","shell.execute_reply.started":"2022-06-05T16:42:25.129745Z","shell.execute_reply":"2022-06-05T16:42:25.134536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gradcam_visualise(data, model, class_index):\n    explainer = GradCAM()\n    output = explainer.explain(data, model, class_index=class_index)\n    return output\n\ndef activation_visualise(image, model, layers):\n    explainer = ExtractActivations()\n    output = explainer.explain([image], model, layers_name=layers)\n    return output","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:25.465234Z","iopub.execute_input":"2022-06-05T16:42:25.465655Z","iopub.status.idle":"2022-06-05T16:42:25.473481Z","shell.execute_reply.started":"2022-06-05T16:42:25.465608Z","shell.execute_reply":"2022-06-05T16:42:25.47202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_data_four(class_name, outputs):\n    fig = plt.figure(figsize=(16, 16))\n    plt.suptitle(classes[class_name])\n    plt.subplot(2,2,1)\n    plt.imshow(outputs[0])\n    plt.subplot(2,2,2)\n    plt.imshow(outputs[1])\n    plt.subplot(2,2,3)\n    plt.imshow(outputs[2])\n    plt.subplot(2,2,4)\n    plt.imshow(outputs[3])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:26.922509Z","iopub.execute_input":"2022-06-05T16:42:26.922767Z","iopub.status.idle":"2022-06-05T16:42:26.929516Z","shell.execute_reply.started":"2022-06-05T16:42:26.922741Z","shell.execute_reply":"2022-06-05T16:42:26.928032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grad_cam(model, df_exp, class_name, class_index, image_size):\n    output_data = []\n    classes_df = df_exp[df_exp['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        image = cv2.resize(image, image_size)\n        data = ([image], None)\n        output = gradcam_visualise(data, model, class_index)\n        output_data.append(output)\n    plot_data_four(class_name, output_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:27.545294Z","iopub.execute_input":"2022-06-05T16:42:27.54555Z","iopub.status.idle":"2022-06-05T16:42:27.552333Z","shell.execute_reply.started":"2022-06-05T16:42:27.545522Z","shell.execute_reply":"2022-06-05T16:42:27.551084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def activations_model(model, df_exp, class_name, layers, image_size):\n    output_data = []\n    classes_df = df_exp[df_exp['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        image = cv2.resize(image, image_size)\n        image = tf.expand_dims(image, axis=0)\n        output = activation_visualise([image], model, layers)\n        output_data.append(output)\n    plot_data_four(class_name, output_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T16:42:29.001253Z","iopub.execute_input":"2022-06-05T16:42:29.001511Z","iopub.status.idle":"2022-06-05T16:42:29.008248Z","shell.execute_reply.started":"2022-06-05T16:42:29.001484Z","shell.execute_reply":"2022-06-05T16:42:29.006951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Resnet50","metadata":{}},{"cell_type":"code","source":"for class_name in X_test['classname'].unique():\n    grad_cam(model_resNet50, X_test, class_name, dict_class[class_name], (560,560))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in X_test['classname'].unique():\n    activations_model(model_resNet50, X_test, class_name, [model_resNet50.layers[-3].name], (560,560))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG19","metadata":{}},{"cell_type":"code","source":"for class_name in X_test['classname'].unique():\n    grad_cam(model_vgg19, X_test, class_name, dict_class[class_name], (560,560))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in X_test['classname'].unique():\n    activations_model(model_vgg19, X_test, class_name, [model_vgg19.layers[-3].name], (560,560))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Custom Model","metadata":{}},{"cell_type":"code","source":"for class_name in X_test['classname'].unique():\n    grad_cam(custom_model, X_test, class_name, dict_class[class_name], (64,64))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in X_test['classname'].unique():\n    activations_model(custom_model, X_test, class_name, [custom_model.layers[-9].name], (64,64))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Save","metadata":{}},{"cell_type":"code","source":"model_vgg19.save('./model_vgg19.h5')\nmodel_resNet50.save('./model_resNet50.h5')\ncustom_model.save('./custom_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}