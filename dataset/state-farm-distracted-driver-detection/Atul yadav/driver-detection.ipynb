{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport keras\nimport matplotlib.pyplot as plt\nfrom keras import Sequential\nfrom keras.layers import Convolution2D, Conv2D , MaxPooling2D , Flatten , Dropout , BatchNormalization , Dense\nfrom keras.activations import relu\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dir = os.listdir(\"../input/train/\")\nprint(train_dir)\ndata_folder = ['c0' , 'c1' , 'c2' , 'c3' , 'c4' , 'c5' ,'c6' , 'c7' , 'c8' , 'c9']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab04612daa6df8e0fb1c896c00fecfda126c57eb"},"cell_type":"code","source":"training_data = []\nindex_label = 0\nfor folder in data_folder:\n    path = os.path.join(\"../input/train/\" + folder)\n    img = os.listdir(path)\n    index_label = data_folder.index(folder)\n    for i in range(len(img)):\n        read_img = cv2.imread(os.path.join(path + \"/\" + img[i]) , cv2.IMREAD_GRAYSCALE)\n        #reshape_img = cv2.resize(read_img , (240*240 , 1))\n        reshape_img = cv2.resize(read_img , (1 , 240*240))\n        training_data.append([\n                reshape_img,index_label])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6679dc3839081a7b43c541d2eff18acbdee63f00"},"cell_type":"code","source":"X = []\ny = []\nfor features , label in training_data:\n    X.append(features)\n    y.append(label)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"197a9aefe81f38312eadfe78f91fa65f75827df5"},"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)\ny = y.reshape([X.shape[0] , 1])\nprint(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9da1475db3c00bf08d8fa960aa44eb84250856c9"},"cell_type":"code","source":"# dimesnions of images are a row vector we need to convert it into 240 ,240 , 1 to pass into cnn\nX = X.reshape(-1 , 240 , 240 ,1)\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e97a424afad01078269d16beb41e1b50a0543db"},"cell_type":"code","source":"# one hot encoded\ny = to_categorical(y)\n\n# split the data into train and test\nX_train , X_val , y_train , y_val  = train_test_split(X , y , test_size = 0.25)\nprint(\"Train Data Shape {} , Train Label Shape {} \".format(X_train.shape , y_train.shape))\nprint(\"Test Data Shape {} , Test Label Shape {} \".format(X_val.shape , y_val.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20c78b4589fe4ef9c7993762cdbdf341abf3c69c"},"cell_type":"code","source":"# define model\ndef cnn():\n    model = Sequential([\n        \n        Convolution2D(32,kernel_size = (3,3), strides = (1,1), activation='relu' , input_shape=(240,240,1)),\n        BatchNormalization(),\n        Convolution2D(32 , kernel_size=(3,3) , strides = (1,1), activation='relu' , padding = 'SAME'),\n        BatchNormalization(),\n        MaxPooling2D(pool_size = (2,2) , strides = (2,2) , padding = 'SAME'),\n        Dropout(0.3), \n        \n        Convolution2D(64 , kernel_size=(3,3) , strides = (1,1), activation='relu' , padding = 'SAME'),\n        BatchNormalization(),\n        Convolution2D(64 , kernel_size = (3,3) , strides = (1,1) , activation = 'relu' , padding = 'SAME'),\n        BatchNormalization(),\n        MaxPooling2D(pool_size = (2,2) , strides = (2,2) , padding = 'SAME'),\n        Dropout(0.3),\n        \n        Convolution2D(128 ,kernel_size=(3,3), strides = (1,1),activation='relu', padding = 'SAME'),\n        BatchNormalization(),\n        Convolution2D(128 , kernel_size = (3,3) , strides = (1,1) , activation = 'relu' , padding = 'SAME'),\n        BatchNormalization(),\n        MaxPooling2D(pool_size = (2,2) , strides = (2,2) , padding = 'SAME'),\n        Dropout(0.5),\n        \n        Flatten(),\n        \n        Dense(512 , activation = 'relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(128 ,activation = 'relu'),\n        Dropout(0.25),\n        Dense(10 , activation = 'softmax')\n        \n    ])\n    \n    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"256200ffa46a0f0fbc27d88af2685c8e7eb3af77"},"cell_type":"code","source":"classifier = cnn()\nprint(classifier.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b39c06ca13699131490177bff45cee098552d034"},"cell_type":"code","source":"history = classifier.fit(X_train , y_train , batch_size = 50 , epochs = 20 , validation_data = (X_val , y_val) , verbose = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1043c2975750b9a44dd08dfe6472cbd4ed60d19f"},"cell_type":"code","source":"plt.plot(history.history['loss'] , 'green' , label = 'Training loss')\nplt.plot(history.history['val_loss'] , 'red' , label = \"Validation loss\")\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ca5552de0cc01f0cb215a7ccb43f408a92e73a5"},"cell_type":"code","source":"plt.plot(history.history['acc'] , 'blue' , label = \"Training Accuracy\")\nplt.plot(history.history['val_acc'] , 'orange' , label = \"Validation Accuracy\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"959dbde7b18d591ade8ee057050d0c0a0ac1af80"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}