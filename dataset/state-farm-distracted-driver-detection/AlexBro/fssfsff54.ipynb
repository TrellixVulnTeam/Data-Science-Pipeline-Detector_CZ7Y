{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nimport os, glob\n\ndrivers = pd.read_csv('../input/driver_imgs_list.csv')\ntrain_files = [f for f in glob.glob(\"../input/train/*/*.jpg\")]\ntest_files = [\"../input/test/\" + f for f in os.listdir(\"../input/test/\")]\nprint(train_files[:10])\nprint(test_files[:10])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"-"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"i_ = 0\nplt.rcParams['figure.figsize'] = (11.0, 21.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor c in c_files:\n    im2 = im.copy()\n    gr_im = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n    fc = cv2.CascadeClassifier(c[0])\n    fr = fc.detectMultiScale(gr_im, scaleFactor=1.1, minNeighbors=2, minSize=(20, 20), flags = cv2.CASCADE_SCALE_IMAGE)\n    if len(fr)>0:\n        for (x, y, w, h) in fr:\n            cv2.rectangle(im2, (x, y), (x+w, y+h), (0, 0, 255), 2)\n        cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n    plt.subplot(7, 3, i_+1).set_title(c[1])\n    plt.imshow(cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"lbl = {'c0' : 'safe driving', \n'c1' : 'texting - right', \n'c2' : 'talking on the phone - right', \n'c3' : 'texting - left', \n'c4' : 'talking on the phone - left', \n'c5' : 'operating the radio', \n'c6' : 'drinking', \n'c7' : 'reaching behind', \n'c8' : 'hair and makeup', \n'c9' : 'talking to passenger'}\n\nplt.rcParams['figure.figsize'] = (8.0, 20.0)\nplt.subplots_adjust(wspace=0, hspace=0)\ni_ = 0\nfor l in lbl:\n    tf = [\"../input/train/\" + l + \"/\" + f for f in os.listdir(\"../input/train/\" + l + \"/\")]\n    fi = random.choice(tf)\n    print(fi)\n    im = cv2.imread(fi)\n    plt.subplot(5, 2, i_+1).set_title(lbl[l])\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import time; start_time = time.time()\nimport warnings; warnings.filterwarnings('ignore');\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom PIL import ImageFilter\nfrom sklearn import ensemble\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn import pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.decomposition import MiniBatchDictionaryLearning\nfrom sklearn.feature_extraction.image import extract_patches_2d\n#from sklearn.feature_extraction.image import img_to_graph\n#from sklearn.metrics import f1_score\nfrom sklearn import preprocessing\nimport multiprocessing\nimport random; random.seed(2016);\nimport cv2\nimport os\nimport re\n\ntrain_drivers = pd.read_csv('../input/driver_imgs_list.csv')\ntrain_drivers[\"path\"] = \"../input/train/\" + train_drivers.classname + \"/\" + train_drivers.img\nX_train = train_drivers[[\"path\",\"img\"]]\ny_train = train_drivers['classname'].str.get_dummies()\nid_test = os.listdir(\"../input/test/\")\nX_test = [\"../input/test/\" + f for f in id_test]\nprint(\"full set:\",len(X_train), len(y_train), len(train_drivers), len(X_test), len(id_test))\n\n#remove limit for outside kaggle run - every 1000th row to sample image categories\ntrain_drivers = train_drivers.iloc[::1000, :]\ntrain_drivers = train_drivers.reset_index(drop=True)\nX_train = X_train.iloc[::1000, :]\nX_train = X_train.reset_index(drop=True)\ny_train = y_train.iloc[::1000, :]\ny_train = y_train.reset_index(drop=True)\nid_test = id_test[::1000]\nX_test = X_test[::1000]\n#end limit\nprint(\"limited:\", len(X_train), len(y_train), len(train_drivers), len(X_test), len(id_test))\n\nprint(\"Start Feature Extraction: \", round(((time.time() - start_time)/60),2))\n\nclass cust_img_features(BaseEstimator, TransformerMixin):\n    def fit(self, x, y=None):\n        return self\n    def transform(self, img_features):\n        d_col_drops=['photo_id','tt','subject','classname','path']\n        img_features = img_features.drop(d_col_drops,axis=1).values\n        return img_features\n\ndef image_features(path, tt, photo_id):\n    #to do - add more features [OpenCV haarcascade / placement stats / counts] [image filters edges, color isolations, closing kernels, blob, etc.] [Add differnt image size patches, patch stats]\n    s=[tt, photo_id]\n    im = Image.open(path)\n    xheight, xwidth = [20,20]\n    im = im.resize((xheight, xwidth), Image.ANTIALIAS)\n    im = im.convert('1') #binarize\n    im_data = list(im.getdata())\n    im_data = np.array([r if r == 0 else 1 for r in im_data]).reshape((20, 20))\n    patches = extract_patches_2d(im_data, (4, 4))\n    #print(patches.shape)\n    for p in patches:\n        p1 = re.sub('[\\[\\]\\n ]', '', np.array_str(p))\n        s.append(float(p1[:8] + \".\" + p1[8:]))\n    f = open(\"data.csv\",\"a\")\n    f.write((',').join(map(str, s)) + '\\n')\n    f.close()\n    return\n\nf = open(\"data.csv\",\"w\");\ncol = ['tt', 'photo_id']\nfor i in range(289):\n     col.append(\"patch\"+str(i))\nf.write((',').join(map(str,col)) + '\\n')\nf.close()\n\nif __name__ == '__main__':\n    j = []\n    cpu = multiprocessing.cpu_count(); #print (cpu);\n    \n    for s_ in range(0,len(X_train),cpu):     #train\n        for i in range(cpu):\n            i_=s_+i\n            if (i_)<len(X_train):\n                if i_ % 10000 == 0:\n                    print(\"train \", i_)\n                filename = X_train.path[i_]\n                p = multiprocessing.Process(target=image_features, args=(filename,'train', X_train.img[i_],))\n                j.append(p)\n                p.start()\n    j = []\n    for s_ in range(0,len(X_test),cpu):     #test\n        for i in range(cpu):\n            i_=s_+i\n            if (i_)<len(X_test):\n                if i_ % 10000 == 0:\n                    print(\"test \", i_)\n                filename = X_test[i_]\n                p = multiprocessing.Process(target=image_features, args=(filename,'test', id_test[i_],))\n                j.append(p)\n                p.start()\n    \n    while len(j) > 0: #end all jobs\n        j = [x for x in j if x.is_alive()]\n        time.sleep(1)\n \n    print(\"Start Training/Predictions: \", round(((time.time() - start_time)/60),2))\n    df_all = pd.read_csv('data.csv', index_col=None)\n    df_all = df_all.reset_index(drop=True)\n    train_drivers.columns = ['subject','classname','photo_id','path']\n    df_all = pd.merge(df_all, train_drivers, how='left', on='photo_id')\n    df_all = df_all.reset_index(drop=True)\n    X_train = df_all[df_all['tt'] == 'train']\n    X_train = X_train.reset_index(drop=True)\n    y_train = X_train['classname'].str.get_dummies()\n    X_test = df_all[df_all['tt'] == 'test']\n    X_test.fillna(0, inplace=True)\n    X_test = X_test.reset_index(drop=True)\n    id_test = X_test[\"photo_id\"].values\n\n    rfr = ensemble.RandomForestClassifier(random_state=2016, n_jobs=-1)\n    ovr = OneVsRestClassifier(rfr, n_jobs=-1)\n    clf = pipeline.Pipeline([\n            ('union', FeatureUnion(\n                    transformer_list = [\n                        ('cst',  cust_img_features()),  \n                        ],\n                    transformer_weights = {\n                        'cst': 1.0,\n                        },\n                n_jobs = -1\n                )), \n        ('ovr', ovr)])\n    model = clf.fit(X_train, y_train)\n    y_pred = model.predict_proba(X_test)\n    df = pd.concat((pd.DataFrame(id_test), pd.DataFrame(y_pred)), axis=1)\n    df.columns = ['img','c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\n    df = df.replace(0.0, 0.1)\n    df.to_csv('submission2.csv',index=False)\n    print(\"Ready to submit: \", round(((time.time() - start_time)/60),2))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}