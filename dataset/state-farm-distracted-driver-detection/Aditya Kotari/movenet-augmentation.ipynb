{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport cv2\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageEnhance","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:34:34.408822Z","iopub.execute_input":"2021-07-19T15:34:34.409225Z","iopub.status.idle":"2021-07-19T15:34:41.284107Z","shell.execute_reply.started":"2021-07-19T15:34:34.409192Z","shell.execute_reply":"2021-07-19T15:34:41.282958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:34:46.878458Z","iopub.execute_input":"2021-07-19T15:34:46.878933Z","iopub.status.idle":"2021-07-19T15:34:46.886305Z","shell.execute_reply.started":"2021-07-19T15:34:46.878895Z","shell.execute_reply":"2021-07-19T15:34:46.885267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n  except RuntimeError as e:\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:34:48.684417Z","iopub.execute_input":"2021-07-19T15:34:48.685045Z","iopub.status.idle":"2021-07-19T15:34:48.695193Z","shell.execute_reply.started":"2021-07-19T15:34:48.684995Z","shell.execute_reply":"2021-07-19T15:34:48.693928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_path = \"/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv\"\nimgs_list_path = \"/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\"\ntrain_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:34:54.394074Z","iopub.execute_input":"2021-07-19T15:34:54.394477Z","iopub.status.idle":"2021-07-19T15:34:54.399862Z","shell.execute_reply.started":"2021-07-19T15:34:54.394444Z","shell.execute_reply":"2021-07-19T15:34:54.398473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.Check data distribution","metadata":{}},{"cell_type":"code","source":"driver_imgs_list = pd.read_csv(imgs_list_path)\ndriver_imgs_list.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:34:57.433837Z","iopub.execute_input":"2021-07-19T15:34:57.434467Z","iopub.status.idle":"2021-07-19T15:34:57.500917Z","shell.execute_reply.started":"2021-07-19T15:34:57.434425Z","shell.execute_reply":"2021-07-19T15:34:57.499485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(train_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:34:59.625381Z","iopub.execute_input":"2021-07-19T15:34:59.625823Z","iopub.status.idle":"2021-07-19T15:34:59.642367Z","shell.execute_reply.started":"2021-07-19T15:34:59.625784Z","shell.execute_reply":"2021-07-19T15:34:59.64073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pair_sort(className,values):\n    for j in range(0,len(className)-1):\n        for i in range(0,len(className)-1):\n            if values[i] > values[i+1]:\n                temp =  values[i+1]\n                values[i+1] = values[i]\n                values[i] = temp\n\n                N_temp =  className[i+1]\n                className[i+1] = className[i]\n                className[i] = N_temp\n    \n    return className,values","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:35:01.620477Z","iopub.execute_input":"2021-07-19T15:35:01.621031Z","iopub.status.idle":"2021-07-19T15:35:01.63405Z","shell.execute_reply.started":"2021-07-19T15:35:01.620993Z","shell.execute_reply":"2021-07-19T15:35:01.632903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import figure\nfigure(num=None, figsize=(15, 5), dpi=80, facecolor='w', edgecolor='k')\n\nclass_names = np.unique(driver_imgs_list['classname'])\nclass_image_list = [len(driver_imgs_list[driver_imgs_list['classname'] == current_class]) for current_class in class_names]\n\nclass_names,class_image_list=  pair_sort(class_names,class_image_list)\n\n#plt.figure()\nplt.suptitle('Number of images per Class')\nplt.bar(class_names,class_image_list,color=(0.2, 0.3, 0.6, 0.6))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:35:03.910224Z","iopub.execute_input":"2021-07-19T15:35:03.911013Z","iopub.status.idle":"2021-07-19T15:35:04.207383Z","shell.execute_reply.started":"2021-07-19T15:35:03.910951Z","shell.execute_reply":"2021-07-19T15:35:04.206482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import figure\nsub_names = np.unique(driver_imgs_list['subject'])\nsub_image_list = [len(driver_imgs_list[driver_imgs_list['subject'] == current_sub]) for current_sub in sub_names]\nsub_names,sub_image_list=  pair_sort(sub_names,sub_image_list)\n\nfigure(num=None, figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n\ny_pos = np.arange(len(sub_names))\n# Create horizontal bars\nplt.barh(y_pos, sub_image_list,color=(0.2, 0.4, 0.6, 0.6))\n \n# Create names on the y-axis\nplt.yticks(y_pos,sub_names )\nplt.suptitle('Number of images per subject')\n\n# Show graphic\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:35:07.124457Z","iopub.execute_input":"2021-07-19T15:35:07.125996Z","iopub.status.idle":"2021-07-19T15:35:07.539237Z","shell.execute_reply.started":"2021-07-19T15:35:07.125924Z","shell.execute_reply":"2021-07-19T15:35:07.538192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Changing load function to augment images with movenet","metadata":{}},{"cell_type":"code","source":"def make_square_test(im):\n    \"\"\"\n    Adds black pixel padding to an image to make it a square.\n    \n    Args:\n        im: A PIL Image\n    \"\"\"\n    x, y = im.size\n    size = max(x, y)\n    new_im = Image.new('RGB', (size, size))\n    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n    return new_im","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:35:12.129484Z","iopub.execute_input":"2021-07-19T15:35:12.129949Z","iopub.status.idle":"2021-07-19T15:35:12.137962Z","shell.execute_reply.started":"2021-07-19T15:35:12.12991Z","shell.execute_reply":"2021-07-19T15:35:12.13643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/3\")\ninput_size = 256\n    \ndef movenet(input_image):\n    \"\"\"Runs detection on an input image.\n\n    Args:\n      input_image: A [1, height, width, 3] tensor represents the input image\n        pixels. Note that the height/width should already be resized and match the\n        expected input resolution of the model before passing into this function.\n\n    Returns:\n      A [1, 1, 17, 3] float numpy array representing the predicted keypoint\n      coordinates and scores.\n    \"\"\"\n    model = module.signatures['serving_default']\n\n    # SavedModel format expects tensor type of int32.\n    input_image = tf.cast(input_image, dtype=tf.int32)\n    # Run model inference.\n    outputs = model(input_image)\n    # Output is a [1, 1, 17, 3] tensor.\n    keypoint_with_scores = outputs['output_0'].numpy()\n    return keypoint_with_scores","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-19T15:35:14.61632Z","iopub.execute_input":"2021-07-19T15:35:14.616739Z","iopub.status.idle":"2021-07-19T15:35:32.564312Z","shell.execute_reply.started":"2021-07-19T15:35:14.616701Z","shell.execute_reply":"2021-07-19T15:35:32.563274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The movenet model can be used to take input images of 256x256 pixels\nimg_width,img_height = (256,256)\nmodel_input_shape = (img_width,img_height,3)\nbatch_size = 16\ninput_image = (img_width, img_height)\n\n\ndef load_image(path):\n    read_path = train_path+\"/\"+path\n    \n    # getting movenet coordinates\n    movenet_image = tf.io.read_file(read_path)\n    movenet_image = tf.image.decode_jpeg(movenet_image)\n    movenet_image = tf.expand_dims(movenet_image, axis=0)\n    movenet_image = tf.image.resize_with_pad(movenet_image, 256, 256)\n    \n    movenet_coordinates = movenet(movenet_image)\n    movenet_coordinates = tf.reshape(movenet_coordinates, [17, 3]).numpy()\n    \n    # Finding the least and most x, y coordinates in which a limb is detected\n    min_x = 1\n    min_y = 1\n    max_x = 0\n    max_y = 0\n    \n    for coord in movenet_coordinates[:11]:\n        if coord[1] < min_x:\n            min_x = coord[1]\n        if coord[0] < min_y:\n            min_y = coord[0]\n        if coord[1] > max_x: \n            max_x = coord[1]\n        if coord[0] > max_y: \n            max_y = coord[0]\n    \n    # loading the image again\n    image = Image.open(read_path)\n    image = make_square_test(image)  \n    \n    width, height = image.size\n    \n    # Uses the extreme end coordinates found earlier to crop the images\n    min_x = min_x - (min_x)*0.2\n    max_x = 1\n    min_y = min_y - (min_y)*0.5\n    max_y = max_y + (1-max_y)*0.1\n    \n    # cropping dimensions\n    left = math.floor(min_x*width)\n    right = math.ceil(max_x*width)\n    top = math.floor(min_y*height)\n    bottom = math.ceil(max_y*height)\n    \n    image = image.crop((left, top, right, bottom))\n    \n    image = make_square_test(image)\n    image = image.resize(input_image)\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:39:18.499444Z","iopub.execute_input":"2021-07-19T15:39:18.499847Z","iopub.status.idle":"2021-07-19T15:39:18.517221Z","shell.execute_reply.started":"2021-07-19T15:39:18.499816Z","shell.execute_reply":"2021-07-19T15:39:18.516174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(image_ids,class_names):\n    pixels = [load_image(path) for path in image_ids]\n    \n    num_of_images = len(image_ids)\n    \n    fig, axes = plt.subplots(\n        1, \n        num_of_images, \n        figsize=(5 * num_of_images, 5 * num_of_images),\n        \n    )\n   \n    \n    for i, image_pixels in enumerate(pixels):\n        axes[i].imshow(image_pixels)\n        axes[i].axis(\"off\")\n        axes[i].set_title(class_names[i])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:35:40.877046Z","iopub.execute_input":"2021-07-19T15:35:40.877483Z","iopub.status.idle":"2021-07-19T15:35:40.885433Z","shell.execute_reply.started":"2021-07-19T15:35:40.877441Z","shell.execute_reply":"2021-07-19T15:35:40.884469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.Plot class (images after augmentation)","metadata":{}},{"cell_type":"code","source":"sub_names_imgs = [ current_class+\"/\"+driver_imgs_list[driver_imgs_list['classname'] == current_class]['img'].values[0] for current_class in class_names]\n\nshow_images(sub_names_imgs[:5],class_names[:5])\nshow_images(sub_names_imgs[5:],class_names[5:])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:39:21.520361Z","iopub.execute_input":"2021-07-19T15:39:21.520724Z","iopub.status.idle":"2021-07-19T15:39:23.147517Z","shell.execute_reply.started":"2021-07-19T15:39:21.520693Z","shell.execute_reply":"2021-07-19T15:39:23.146417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## 3. Loads the labelled images, crops, and saves them as outputs","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"\ntest_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test\"\noutput_path = \"/kaggle/working/imgs/train\"","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:33:53.191365Z","iopub.execute_input":"2021-07-14T05:33:53.191685Z","iopub.status.idle":"2021-07-14T05:33:53.196763Z","shell.execute_reply.started":"2021-07-14T05:33:53.191655Z","shell.execute_reply":"2021-07-14T05:33:53.195861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for current_class in class_names:\n    select_df = driver_imgs_list[driver_imgs_list['classname'] == current_class ]\n    image_list = select_df['img'].values\n    if not os.path.exists(output_path+\"/\"+current_class):\n        os.makedirs(output_path+\"/\"+current_class)\n    for filename in image_list:\n        # load_image(current_class+\"/\"+filename)\n        im = load_image(current_class+\"/\"+filename)\n        im.save(output_path+\"/\"+current_class+\"/\"+filename)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:33:53.197735Z","iopub.execute_input":"2021-07-14T05:33:53.197981Z","iopub.status.idle":"2021-07-14T06:04:04.425129Z","shell.execute_reply.started":"2021-07-14T05:33:53.197956Z","shell.execute_reply":"2021-07-14T06:04:04.422966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r /kaggle/working/output.zip /kaggle/working/imgs","metadata":{"execution":{"iopub.status.busy":"2021-07-14T06:15:30.46842Z","iopub.execute_input":"2021-07-14T06:15:30.468859Z","iopub.status.idle":"2021-07-14T06:15:41.532873Z","shell.execute_reply.started":"2021-07-14T06:15:30.46882Z","shell.execute_reply":"2021-07-14T06:15:41.531491Z"},"_kg_hide-output":false,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/imgs/*\n!rm -r /kaggle/working/imgs","metadata":{"execution":{"iopub.status.busy":"2021-07-14T06:16:23.578046Z","iopub.execute_input":"2021-07-14T06:16:23.578472Z","iopub.status.idle":"2021-07-14T06:16:25.8174Z","shell.execute_reply.started":"2021-07-14T06:16:23.578406Z","shell.execute_reply":"2021-07-14T06:16:25.816241Z"},"trusted":true},"execution_count":null,"outputs":[]}]}