{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#modules\nimport os\nimport numpy as np\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nfrom keras.utils.vis_utils import plot_model\nimport math\nfrom collections import OrderedDict\nimport re\nfrom PIL import Image\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import init\nfrom torchvision import models, transforms, datasets\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.utils.model_zoo as model_zoo\nimport torch.nn.functional as F\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyper-parameter\nBATCH_size = 64\nIMG_size = 256\nLR=1e-4 \nWEIGHT_decay=5e-4\nMODEL_name = 'RESNET_50_SAM_SCHEDULER_AUG' #to stroe the hyperparameter\nJITTER_strength = 0.2 #(0.8 to 1.2) 합리적임. 사람 옷들도 다르니까 ㅇㅇ\nCROP_size = 224","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defininng loader\ndef one_image_loader(path):\n    return Image.open(path).convert('RGB')\n\nclass Loader(torch.utils.data.Dataset):\n    def __init__(self, rootdir, split_type, ids=None, transform=None):\n        self.impath = rootdir\n        self.transform = transform\n        self.loader = one_image_loader\n            \n\n        imnames = []\n        imclasses = []\n        \n        for i in range(10):\n            if(split_type == 'train'):\n                for j in train_ids[i]:\n                    imclasses.append(i)\n                    imnames.append(j)\n            else :\n                for j in val_ids[i]:\n                    imclasses.append(i)\n                    imnames.append(j)\n\n        self.imnames = imnames\n        self.imclasses = imclasses\n    \n    def __getitem__(self, index):\n        original_img = self.loader(os.path.join(self.impath, self.imnames[index]))\n        img = self.transform(original_img)\n        label = self.imclasses[index]\n        return img, label\n        \n    def __len__(self):\n        return len(self.imnames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test loader\nclass TestLoader(torch.utils.data.Dataset):\n    def __init__(self, rootdir, transform=None):\n        self.impath = rootdir\n        self.transform = transform\n        self.loader = one_image_loader\n        self.imnames = os.listdir(rootdir)\n\n    \n    def __getitem__(self, index):\n        original_img = self.loader(os.path.join(self.impath, self.imnames[index]))\n        img = self.transform(original_img)\n\n        return self.imnames[index],img\n        \n    def __len__(self):\n        return len(self.imnames)\n    \n#loading the test data\ntest_path = \"../input/state-farm-distracted-driver-detection/imgs/test\"\ntest_loader = torch.utils.data.DataLoader(\n             TestLoader(test_path,\n                    transform=transforms.Compose([\n                                   transforms.Resize((IMG_size,IMG_size)),\n                                   transforms.ToTensor(),\n                                   transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])),\n                               batch_size=BATCH_size, shuffle=False, num_workers=0, pin_memory=True, drop_last=False)\nprint('test_loader done')\nprint('loaded {} test images'.format(len(test_loader.dataset)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#implement 3 models, RESNET 18, RESNET 50, DENSNET121\n__all__ = ['resnet18', 'resnet50', 'densenet121']\n\nmodel_urls = {\n    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#weight initialization functions\ndef weights_init_kaiming(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n        if m.bias is not None:\n            init.constant_(m.bias.data, 0.0)        \n    elif classname.find('Linear') != -1:\n        init.kaiming_normal_(m.weight.data, a=0, mode='fan_out')\n        if m.bias is not None:\n            init.constant_(m.bias.data, 0.0)\n    elif classname.find('BatchNorm1d') != -1:\n        init.normal_(m.weight.data, 1.0, 0.02)\n        if m.bias is not None:        \n            init.constant_(m.bias.data, 0.0)\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal_(m.weight.data, 1.0, 0.02)\n        if m.bias is not None:        \n            init.constant_(m.bias.data, 0.0)\n    elif classname.find('BatchNorm') != -1:\n        if m.affine is not None:\n            init.constant_(m.weight.data, 1.0)\n            init.constant_(m.bias.data, 0.0)        \n\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('Linear') != -1:\n        init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        init.normal_(m.weight.data, 1.0, 0.02)\n        init.constant_(m.bias.data, 0.0)\n\ndef weights_init_xavier(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.xavier_normal_(m.weight.data, gain=1)\n    elif classname.find('Linear') != -1:\n        init.xavier_normal_(m.weight.data, gain=1)\n    elif classname.find('BatchNorm') != -1:\n        init.normal_(m.weight.data, 1.0, 0.02)\n        init.constant_(m.bias.data, 0.0)\n\ndef weights_init_classifier(m):\n    classname = m.__class__.__name__\n    if classname.find('Linear') != -1:\n        init.normal_(m.weight.data, std=0.001)\n        init.constant_(m.bias.data, 0.0)     \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#blocks implementation\nclass ClassBlock(nn.Module):\n    def __init__(self, input_dim, class_num, dropout=True, relu=True, num_bottleneck=512): \n        super(ClassBlock, self).__init__()\n        add_block = []\n        add_block += [nn.Linear(input_dim, num_bottleneck)] \n        add_block += [nn.BatchNorm1d(num_bottleneck)]\n        if relu: \n            add_block += [nn.ReLU()]\n        if dropout: \n            add_block += [nn.Dropout(p=0.5)] \n        add_block = nn.Sequential(*add_block)\n        add_block.apply(weights_init_kaiming)\n        classifier = []\n        classifier += [nn.Linear(num_bottleneck, class_num)]\n        classifier = nn.Sequential(*classifier)\n        classifier.apply(weights_init_classifier)\n        self.add_block = add_block\n        self.classifier = classifier\n    def forward(self, x):\n        x = self.add_block(x)\n        x = self.classifier(x)\n        return x    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#models\nclass Res18_basic(nn.Module):\n    def __init__(self, class_num):\n        super(Res18_basic, self).__init__()\n        fea_dim = IMG_size\n        model_ft = models.resnet18(pretrained=False)\n        model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        model_ft.fc = nn.Sequential()\n        self.model = model_ft\n        self.fc_embed = nn.Linear(512, fea_dim)\n        self.fc_embed.apply(weights_init_classifier)\n        self.classifier = ClassBlock(512, class_num)\n        self.classifier.apply(weights_init_classifier)\n        \n    def forward(self, x):\n        x = self.model.conv1(x)\n        x = self.model.bn1(x)\n        x = self.model.relu(x)\n        x = self.model.maxpool(x)\n        x = self.model.layer1(x)\n        x = self.model.layer2(x)\n        x = self.model.layer3(x)\n        x = self.model.layer4(x)\n        x = self.model.avgpool(x)\n        fea =  x.view(x.size(0), -1)\n        #embed_fea = self.fc_embed(fea)\n        pred = self.classifier(fea)\n        #return embed_fea, pred \n        return pred\n\n# Define the ResNet18-based Model\nclass Res18(nn.Module):\n    def __init__(self, class_num):\n        super(Res18, self).__init__()\n        fea_dim = IMG_size\n        model_ft = models.resnet18(pretrained=False)\n        model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        model_ft.fc = nn.Sequential()\n        self.model = model_ft\n        self.fc_embed = nn.Linear(512, fea_dim)\n        self.fc_embed.apply(weights_init_classifier)\n        self.classifier = ClassBlock(512, class_num)\n        self.classifier.apply(weights_init_classifier)\n        \n    def forward(self, x):\n        x = self.model.conv1(x)\n        x = self.model.bn1(x)\n        x = self.model.relu(x)\n        x = self.model.maxpool(x)\n        x = self.model.layer1(x)\n        x = self.model.layer2(x)\n        x = self.model.layer3(x)\n        x = self.model.layer4(x)\n        x = self.model.avgpool(x)\n        fea =  x.view(x.size(0), -1)\n        #embed_fea = self.fc_embed(fea)\n        pred = self.classifier(fea)\n        #return embed_fea, pred \n        return pred\n\n        \nclass Res50(nn.Module):\n    def __init__(self, class_num):\n        super(Res50, self).__init__()\n        fea_dim = IMG_size       \n        model_ft = models.resnet50(pretrained=False)\n        model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        model_ft.fc = nn.Sequential()        \n        self.model = model_ft\n        self.fc_embed = nn.Linear(2048, fea_dim)\n        self.fc_embed.apply(weights_init_classifier)\n        self.classifier = ClassBlock(2048, class_num)\n        self.classifier.apply(weights_init_classifier)        \n        \n    def forward(self, x):\n        x = self.model.conv1(x)\n        x = self.model.bn1(x)\n        x = self.model.relu(x)\n        x = self.model.maxpool(x)\n        x = self.model.layer1(x)\n        x = self.model.layer2(x)\n        x = self.model.layer3(x)\n        x = self.model.layer4(x)\n        x = self.model.avgpool(x)\n        fea =  x.view(x.size(0), -1)\n        #embed_fea = self.fc_embed(fea)\n        pred = self.classifier(fea)\n        #return embed_fea, pred    \n        return pred\n        \nclass Dense121(nn.Module):\n    def __init__(self, class_num):\n        super(Dense121, self).__init__()\n        fea_dim = IMG_size      \n        model_ft = models.densenet121(pretrained=False)\n        model_ft.features.classifier = nn.Sequential()\n        model_ft.features.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        model_ft.features.fc_embed = nn.Linear(1024, fea_dim)\n        model_ft.features.fc_embed.apply(weights_init_classifier)  \n        model_ft.classifier = ClassBlock(2048, class_num)\n        model_ft.classifier.apply(weights_init_classifier)  \n        self.model = model_ft\n        \n    def forward(self, x):\n        x = self.model.features.conv0(x)\n        x = self.model.features.norm0(x)\n        x = self.model.features.relu0(x)\n        x = self.model.features.pool0(x)\n        x = self.model.features.denseblock1(x)\n        x = self.model.features.transition1(x)\n        x = self.model.features.denseblock2(x)\n        x = self.model.features.transition2(x)\n        x = self.model.features.denseblock3(x)\n        x = self.model.features.transition3(x)\n        x = self.model.features.denseblock4(x)\n        x = self.model.features.norm5(x)\n        x = self.model.features.avgpool(x)\n        fea =  x.view(x.size(0), -1)\n        #embed_fea = self.model.features.fc_embed(fea)\n        pred = self.model.classifier(fea)        \n        #return embed_fea, pred  \n        return pred\n        \nclass Res101(nn.Module):\n    def __init__(self, class_num):\n        super(Res101, self).__init__()\n        fea_dim = IMG_size     \n        model_ft = models.resnet101(pretrained=False)\n        model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        model_ft.fc = nn.Sequential()        \n        self.model = model_ft\n        self.fc_embed = nn.Linear(2048, fea_dim)\n        self.fc_embed.apply(weights_init_classifier)\n        self.classifier = ClassBlock(2048, class_num)\n        self.classifier.apply(weights_init_classifier)        \n        \n    def forward(self, x):\n        x = self.model.conv1(x)\n        x = self.model.bn1(x)\n        x = self.model.relu(x)\n        x = self.model.maxpool(x)\n        x = self.model.layer1(x)\n        x = self.model.layer2(x)\n        x = self.model.layer3(x)\n        x = self.model.layer4(x)\n        x = self.model.avgpool(x)\n        fea =  x.view(x.size(0), -1)\n        #embed_fea = self.fc_embed(fea)\n        pred = self.classifier(fea)\n        #return embed_fea, pred    \n        return pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.hub import load_state_dict_from_url\nfrom torchvision.models import ResNet\n\nfrom torch import nn\n\n\nclass SELayer(nn.Module):\n    def __init__(self, channel, reduction=16):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, channel // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channel // reduction, channel, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y.expand_as(x)\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n\nclass SEBasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None,\n                 *, reduction=16):\n        super(SEBasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes, 1)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.se = SELayer(planes, reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.se(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass SEBottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None,\n                 *, reduction=16):\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se = SELayer(planes * 4, reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        out = self.se(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\ndef se_resnet18(num_classes=1_000):\n    \"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet34(num_classes=1_000):\n    \"\"\"Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet50(num_classes=1_000, pretrained=False):\n    \"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    if pretrained:\n        model.load_state_dict(load_state_dict_from_url(\n            \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\"))\n    return model\n\n\ndef se_resnet101(num_classes=1_000):\n    \"\"\"Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 4, 23, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet152(num_classes=1_000):\n    \"\"\"Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 8, 36, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\nclass CifarSEBasicBlock(nn.Module):\n    def __init__(self, inplanes, planes, stride=1, reduction=16):\n        super(CifarSEBasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.se = SELayer(planes, reduction)\n        if inplanes != planes:\n            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n                                            nn.BatchNorm2d(planes))\n        else:\n            self.downsample = lambda x: x\n        self.stride = stride\n\n    def forward(self, x):\n        residual = self.downsample(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.se(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass CifarSEResNet(nn.Module):\n    def __init__(self, block, n_size, num_classes=10, reduction=16):\n        super(CifarSEResNet, self).__init__()\n        self.inplane = 16\n        self.conv1 = nn.Conv2d(\n            3, self.inplane, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.inplane)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(\n            block, 16, blocks=n_size, stride=1, reduction=reduction)\n        self.layer2 = self._make_layer(\n            block, 32, blocks=n_size, stride=2, reduction=reduction)\n        self.layer3 = self._make_layer(\n            block, 64, blocks=n_size, stride=2, reduction=reduction)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(64, num_classes)\n        self.initialize()\n\n    def initialize(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride, reduction):\n        strides = [stride] + [1] * (blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.inplane, planes, stride, reduction))\n            self.inplane = planes\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\nclass CifarSEPreActResNet(CifarSEResNet):\n    def __init__(self, block, n_size, num_classes=10, reduction=16):\n        super(CifarSEPreActResNet, self).__init__(\n            block, n_size, num_classes, reduction)\n        self.bn1 = nn.BatchNorm2d(self.inplane)\n        self.initialize()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n\ndef se_resnet20(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = CifarSEResNet(CifarSEBasicBlock, 3, **kwargs)\n    return model\n\n\ndef se_resnet32(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = CifarSEResNet(CifarSEBasicBlock, 5, **kwargs)\n    return model\n\n\ndef se_resnet56(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = CifarSEResNet(CifarSEBasicBlock, 9, **kwargs)\n    return model\n\n\ndef se_preactresnet20(**kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    \"\"\"\n    model = CifarSEPreActResNet(CifarSEBasicBlock, 3, **kwargs)\n    return model\n\n\ndef se_preactresnet32(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = CifarSEPreActResNet(CifarSEBasicBlock, 5, **kwargs)\n    return model\n\n\ndef se_preactresnet56(**kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n    \"\"\"\n    model = CifarSEPreActResNet(CifarSEBasicBlock, 9, **kwargs)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SAM(torch.optim.Optimizer): # SAM optimizer from https://github.com/davda54/sam\n    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n\n        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n        super(SAM, self).__init__(params, defaults)\n\n        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n        self.param_groups = self.base_optimizer.param_groups\n\n    @torch.no_grad()\n    def first_step(self, zero_grad=False):\n        grad_norm = self._grad_norm()\n        for group in self.param_groups:\n            scale = group[\"rho\"] / (grad_norm + 1e-12)\n\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n                self.state[p][\"e_w\"] = e_w\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def second_step(self, zero_grad=False):\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n\n        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def step(self, closure=None):\n        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n\n        self.first_step(zero_grad=True)\n        closure()\n        self.second_step()\n\n    def _grad_norm(self):\n        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n        norm = torch.norm(\n                    torch.stack([\n                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n                        for group in self.param_groups for p in group[\"params\"]\n                        if p.grad is not None\n                    ]),\n                    p=2\n               )\n        return norm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom torch.optim.lr_scheduler import _LRScheduler\n\nclass CosineAnnealingWarmUpRestarts(_LRScheduler):\n    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n        if T_0 <= 0 or not isinstance(T_0, int):\n            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n        if T_mult < 1 or not isinstance(T_mult, int):\n            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n        if T_up < 0 or not isinstance(T_up, int):\n            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n        self.T_0 = T_0\n        self.T_mult = T_mult\n        self.base_eta_max = eta_max\n        self.eta_max = eta_max\n        self.T_up = T_up\n        self.T_i = T_0\n        self.gamma = gamma\n        self.cycle = 0\n        self.T_cur = last_epoch\n        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n\n    \n    def get_lr(self):\n        if self.T_cur == -1:\n            return self.base_lrs\n        elif self.T_cur < self.T_up:\n            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n        else:\n            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n                    for base_lr in self.base_lrs]\n\n    def step(self, epoch=None):\n        if epoch is None:\n            epoch = self.last_epoch + 1\n            self.T_cur = self.T_cur + 1\n            if self.T_cur >= self.T_i:\n                self.cycle += 1\n                self.T_cur = self.T_cur - self.T_i\n                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n        else:\n            if epoch >= self.T_0:\n                if self.T_mult == 1:\n                    self.T_cur = epoch % self.T_0\n                    self.cycle = epoch // self.T_0\n                else:\n                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n                    self.cycle = n\n                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n                    self.T_i = self.T_0 * self.T_mult ** (n)\n            else:\n                self.T_i = self.T_0\n                self.T_cur = epoch\n                \n        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n        self.last_epoch = math.floor(epoch)\n        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n            param_group['lr'] = lr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Res50(10) #num classes : 10, Resnet50\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = filter(lambda p: p.requires_grad, model.parameters())\nn_parameters = sum([p.data.nelement() for p in model.parameters()])\nprint('  + Number of params: {}'.format(n_parameters))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.cuda()\ncriterion = nn.CrossEntropyLoss()\nbase_optimizer = optim.Adam\noptimizer = SAM(model.parameters(), base_optimizer, lr=0, weight_decay=WEIGHT_decay)\nscheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=8, T_mult=2, eta_max=LR,  T_up=2, gamma=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n2021-06-15 15:28:28.381337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n\n2021-06-15 15:28:28.481444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n\nfound 1992 train, 497 validation images for class 0\n\nfound 1814 train, 453 validation images for class 1\n\nfound 1854 train, 463 validation images for class 2\n\nfound 1877 train, 469 validation images for class 3\n\nfound 1861 train, 465 validation images for class 4\n\nfound 1850 train, 462 validation images for class 5\n\nfound 1860 train, 465 validation images for class 6\n\nfound 1602 train, 400 validation images for class 7\n\nfound 1529 train, 382 validation images for class 8\n\nfound 1704 train, 425 validation images for class 9\n\ntrain_loader done\n\nloaded 17943 train images\n\nvalidation_loader done\n\nloaded 4481 validation images\n\ntest_loader done\n\nloaded 79726 test images\n\n  + Number of params: 25087818\n\nEpoch 1/50\n\n----------\n\ntrain loss: 2.2997, acc: 10.0318\n\nmodel achieved the best accuracy (10.0424%) - saving best checkpoint...\n\nvalidation loss: 2.3025, acc: 10.0424\n\nEpoch 2/50\n\n----------\n\ntrain loss: 2.2973, acc: 10.7228\n\nmodel achieved the best accuracy (11.8500%) - saving best checkpoint...\n\nvalidation loss: 2.2990, acc: 11.8500\n\nEpoch 3/50\n\n----------\n\ntrain loss: 2.2874, acc: 11.5923\n\nmodel achieved the best accuracy (12.2517%) - saving best checkpoint...\n\nvalidation loss: 2.2358, acc: 12.2517\n\nEpoch 4/50\n\n----------\n\ntrain loss: 1.9627, acc: 28.3119\n\nmodel achieved the best accuracy (48.5606%) - saving best checkpoint...\n\nvalidation loss: 1.3652, acc: 48.5606\n\nEpoch 5/50\n\n----------\n\ntrain loss: 1.3514, acc: 54.3722\n\nmodel achieved the best accuracy (77.8621%) - saving best checkpoint...\n\nvalidation loss: 0.7525, acc: 77.8621\n\nEpoch 6/50\n\n----------\n\ntrain loss: 0.9214, acc: 69.8824\n\nmodel achieved the best accuracy (84.1776%) - saving best checkpoint...\n\nvalidation loss: 0.5334, acc: 84.1776\n\nEpoch 7/50\n\n----------\n\ntrain loss: 0.7593, acc: 75.6340\n\nmodel achieved the best accuracy (90.9618%) - saving best checkpoint...\n\nvalidation loss: 0.4483, acc: 90.9618\n\nEpoch 8/50\n\n----------\n\ntrain loss: 0.6809, acc: 78.5933\n\nmodel achieved the best accuracy (92.4794%) - saving best checkpoint...\n\nvalidation loss: 0.3702, acc: 92.4794\n\nEpoch 9/50\n\n----------\n\ntrain loss: 0.6632, acc: 79.6132\n\nmodel achieved the best accuracy (92.7695%) - saving best checkpoint...\n\nvalidation loss: 0.3719, acc: 92.7695\n\nEpoch 10/50\n\n----------\n\ntrain loss: 0.6586, acc: 79.5129\n\nmodel achieved the best accuracy (94.8003%) - saving best checkpoint...\n\nvalidation loss: 0.3137, acc: 94.8003\n\nEpoch 11/50\n\n----------\n\ntrain loss: 0.6214, acc: 80.2932\n\nvalidation loss: 0.3307, acc: 92.7025\n\nEpoch 12/50\n\n----------\n\ntrain loss: 0.5647, acc: 82.4054\n\nmodel achieved the best accuracy (95.9830%) - saving best checkpoint...\n\nvalidation loss: 0.2079, acc: 95.9830\n\nEpoch 13/50\n\n----------\n\ntrain loss: 0.5079, acc: 83.9269\n\nmodel achieved the best accuracy (96.3624%) - saving best checkpoint...\n\nvalidation loss: 0.1932, acc: 96.3624\n\nEpoch 14/50\n\n----------\n\ntrain loss: 0.4563, acc: 85.5765\n\nmodel achieved the best accuracy (97.4559%) - saving best checkpoint...\n\nvalidation loss: 0.1484, acc: 97.4559\n\nEpoch 15/50\n\n----------\n\ntrain loss: 0.4268, acc: 86.2453\n\nvalidation loss: 0.1412, acc: 97.3890\n\nEpoch 16/50\n\n----------\n\ntrain loss: 0.3965, acc: 87.4714\n\nmodel achieved the best accuracy (97.9023%) - saving best checkpoint...\n\nvalidation loss: 0.1141, acc: 97.9023\n\nEpoch 17/50\n\n----------\n\ntrain loss: 0.3607, acc: 88.6251\n\nmodel achieved the best accuracy (98.3932%) - saving best checkpoint...\n\nvalidation loss: 0.0928, acc: 98.3932\n\nEpoch 18/50\n\n----------\n\ntrain loss: 0.3541, acc: 88.6920\n\nvalidation loss: 0.1026, acc: 98.1477\n\nEpoch 19/50\n\n----------\n\ntrain loss: 0.3352, acc: 89.5001\n\nmodel achieved the best accuracy (98.7280%) - saving best checkpoint...\n\nvalidation loss: 0.0836, acc: 98.7280\n\nEpoch 20/50\n\n----------\n\ntrain loss: 0.3080, acc: 90.5701\n\nmodel achieved the best accuracy (98.9065%) - saving best checkpoint...\n\nvalidation loss: 0.0765, acc: 98.9065\n\nEpoch 21/50\n\n----------\n\ntrain loss: 0.3031, acc: 90.5534\n\nvalidation loss: 0.0774, acc: 98.8842\n\nEpoch 22/50\n\n----------\n\ntrain loss: 0.3074, acc: 90.5534\n\nmodel achieved the best accuracy (98.9511%) - saving best checkpoint...\n\nvalidation loss: 0.0757, acc: 98.9511\n\nEpoch 23/50\n\n----------\n\ntrain loss: 0.2997, acc: 90.5757\n\nmodel achieved the best accuracy (98.9734%) - saving best checkpoint...\n\nvalidation loss: 0.0753, acc: 98.9734\n\nEpoch 24/50\n\n----------\n\ntrain loss: 0.3230, acc: 89.7565\n\nvalidation loss: 0.0721, acc: 98.8172\n\nEpoch 25/50\n\n----------\n\ntrain loss: 0.3200, acc: 89.9348\n\nvalidation loss: 0.0834, acc: 98.2370\n\nEpoch 26/50\n\n----------\n\ntrain loss: 0.3272, acc: 89.4834\n\nvalidation loss: 0.0884, acc: 98.3932\n\nEpoch 27/50\n\n----------\n\ntrain loss: 0.3133, acc: 89.8679\n\nvalidation loss: 0.0793, acc: 98.5494\n\nEpoch 28/50\n\n----------\n\ntrain loss: 0.3066, acc: 90.3138\n\nmodel achieved the best accuracy (99.0181%) - saving best checkpoint...\n\nvalidation loss: 0.0619, acc: 99.0181\n\nEpoch 29/50\n\n----------\n\ntrain loss: 0.2858, acc: 90.9324\n\nmodel achieved the best accuracy (99.1297%) - saving best checkpoint...\n\nvalidation loss: 0.0713, acc: 99.1297\n\nEpoch 30/50\n\n----------\n\ntrain loss: 0.2928, acc: 90.5869\n\nvalidation loss: 0.0636, acc: 98.9065\n\nEpoch 31/50\n\n----------\n\ntrain loss: 0.2843, acc: 90.9491\n\nvalidation loss: 0.0585, acc: 99.0850\n\nEpoch 32/50\n\n----------\n\ntrain loss: 0.2762, acc: 91.2111\n\nmodel achieved the best accuracy (99.1520%) - saving best checkpoint...\n\nvalidation loss: 0.0586, acc: 99.1520\n\nEpoch 33/50\n\n----------\n\ntrain loss: 0.2710, acc: 91.4228\n\nvalidation loss: 0.0524, acc: 99.1073\n\nEpoch 34/50\n\n----------\n\ntrain loss: 0.2651, acc: 91.7349\n\nvalidation loss: 0.0547, acc: 99.1520\n\nEpoch 35/50\n\n----------\n\ntrain loss: 0.2607, acc: 91.8018\n\nmodel achieved the best accuracy (99.2412%) - saving best checkpoint...\n\nvalidation loss: 0.0505, acc: 99.2412\n\nEpoch 36/50\n\n----------\n\ntrain loss: 0.2418, acc: 92.4093\n\nmodel achieved the best accuracy (99.3528%) - saving best checkpoint...\n\nvalidation loss: 0.0489, acc: 99.3528\n\nEpoch 37/50\n\n----------\n\ntrain loss: 0.2470, acc: 92.2087\n\nvalidation loss: 0.0430, acc: 99.3528\n\nEpoch 38/50\n\n----------\n\ntrain loss: 0.2329, acc: 92.6545\n\nmodel achieved the best accuracy (99.4421%) - saving best checkpoint...\n\nvalidation loss: 0.0417, acc: 99.4421\n\nEpoch 39/50\n\n----------\n\ntrain loss: 0.2330, acc: 92.7716\n\nvalidation loss: 0.0407, acc: 99.3305\n\nEpoch 40/50\n\n----------\n\ntrain loss: 0.2262, acc: 92.9053\n\nvalidation loss: 0.0426, acc: 99.3975\n\nEpoch 41/50\n\n----------\n\ntrain loss: 0.2246, acc: 92.8496\n\nvalidation loss: 0.0434, acc: 99.3975\n\nEpoch 42/50\n\n----------\n\ntrain loss: 0.2257, acc: 92.9778\n\nvalidation loss: 0.0384, acc: 99.4198\n\nEpoch 43/50\n\n----------\n\ntrain loss: 0.2166, acc: 93.3512\n\nvalidation loss: 0.0381, acc: 99.3082\n\nEpoch 44/50\n\n----------\n\ntrain loss: 0.2172, acc: 93.3233\n\nvalidation loss: 0.0392, acc: 99.3751\n\nEpoch 45/50\n\n----------\n\ntrain loss: 0.2171, acc: 93.2453\n\nmodel achieved the best accuracy (99.4867%) - saving best checkpoint...\n\nvalidation loss: 0.0402, acc: 99.4867\n\nEpoch 46/50\n\n----------\n\ntrain loss: 0.2100, acc: 93.6410\n\nvalidation loss: 0.0394, acc: 99.3975\n\nEpoch 47/50\n\n----------\n\ntrain loss: 0.2123, acc: 93.2731\n\nvalidation loss: 0.0394, acc: 99.3528\n\nEpoch 48/50\n\n----------\n\ntrain loss: 0.2132, acc: 93.2620\n\nvalidation loss: 0.0384, acc: 99.4644\n\nEpoch 49/50\n\n----------\n\ntrain loss: 0.2163, acc: 93.2063\n\nvalidation loss: 0.0378, acc: 99.4644\n\nEpoch 50/50\n\n----------\n\ntrain loss: 0.2161, acc: 93.2564\n\nvalidation loss: 0.0382, acc: 99.3975\n\ncheckpoint is loaded !\n\nloaded models best accuracy : 99.4867\n\ntesting the loaded model\n\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analyze the results\nckpt = torch.load('../input/exp-15-1/exp_15_1')\n\n#1. load the trained model\nmodel.load_state_dict(ckpt['classifier'])\noptimizer.load_state_dict(ckpt['optimizer'])\nbest_acc = ckpt['best_acc']\nprint('checkpoint is loaded !')\nprint('loaded model''s best accuracy : %.4f' % best_acc)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission\nimport pandas as pd\n\nmodel.eval()\nnp.set_printoptions(precision=10, suppress=True)\n\n# (1) eval & write the test set's result\nprint('Writing start..')\n\nf = open('/kaggle/working/submission.csv', 'w')\nf.write('img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n')\n\nwith torch.no_grad():\n    for i, data in enumerate(test_loader):\n        if not i%100 :\n            print(i*100.0/len(test_loader), \"% done.\")\n        name, img_data = data\n    \n        img_data = img_data.cuda()\n        img_data = model(img_data)\n\n        img_data = F.softmax(img_data, dim=1)\n        img_data = img_data.detach().cpu().numpy()\n\n        for j in range(img_data.shape[0]):\n            f.write(name[j])\n            for k in img_data[j]:\n                f.write(',')\n                f.write(str(k))\n            f.write('\\n')\nf.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}