{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv\n#/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\n#/kaggle/input/state-farm-distracted-driver-detection/imgs/train/c4/img_16261.jpg\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw, ImageEnhance\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_path = \"/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv\"\nimgs_list_path = \"/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\"\ntrain_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.Check data distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"driver_imgs_list = pd.read_csv(imgs_list_path)\ndriver_imgs_list.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pair_sort(className,values):\n    for j in range(0,len(className)-1):\n        for i in range(0,len(className)-1):\n            if values[i] > values[i+1]:\n                temp =  values[i+1]\n                values[i+1] = values[i]\n                values[i] = temp\n\n                N_temp =  className[i+1]\n                className[i+1] = className[i]\n                className[i] = N_temp\n    \n    return className,values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pyplot import figure\nfigure(num=None, figsize=(15, 5), dpi=80, facecolor='w', edgecolor='k')\n\nclass_names = np.unique(driver_imgs_list['classname'])\nclass_image_list = [len(driver_imgs_list[driver_imgs_list['classname'] == current_class]) for current_class in class_names]\n\nclass_names,class_image_list=  pair_sort(class_names,class_image_list)\n\n#plt.figure()\nplt.suptitle('Number of images per Class')\nplt.bar(class_names,class_image_list,color=(0.2, 0.4, 0.6, 0.6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pyplot import figure\nsub_names = np.unique(driver_imgs_list['subject'])\nsub_image_list = [len(driver_imgs_list[driver_imgs_list['subject'] == current_sub]) for current_sub in sub_names]\nsub_names,sub_image_list=  pair_sort(sub_names,sub_image_list)\n\nfigure(num=None, figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n\ny_pos = np.arange(len(sub_names))\n# Create horizontal bars\nplt.barh(y_pos, sub_image_list,color=(0.2, 0.4, 0.6, 0.6))\n \n# Create names on the y-axis\nplt.yticks(y_pos,sub_names )\nplt.suptitle('Number of images per subject')\n\n# Show graphic\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width,img_height = (128,128)\nmodel_input_shape = (img_width,img_height,3)\nbatch_size = 16\ninput_image = (img_width,img_height)\n\ndef load_image(path):\n    read_path = train_path+\"/\"+path\n    image = Image.open(read_path)\n    image = image.resize(input_image)\n    \n    return np.asarray(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(image_ids,class_names):\n    pixels = [load_image(path) for path in image_ids]\n    \n    num_of_images = len(image_ids)\n    \n    fig, axes = plt.subplots(\n        1, \n        num_of_images, \n        figsize=(5 * num_of_images, 5 * num_of_images),\n        \n    )\n   \n    \n    for i, image_pixels in enumerate(pixels):\n        axes[i].imshow(image_pixels)\n        axes[i].axis(\"off\")\n        axes[i].set_title(class_names[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.Plot class images"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_names_imgs = [ current_class+\"/\"+driver_imgs_list[driver_imgs_list['classname'] == current_class]['img'].values[0] for current_class in class_names]\n\nshow_images(sub_names_imgs[:5],class_names[:5])\nshow_images(sub_names_imgs[5:],class_names[5:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## 3. Split and load Train/Validation "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"\ntest_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\n\nsplit_rate = 0.8\nfor current_class in class_names:\n    select_df = driver_imgs_list[driver_imgs_list['classname'] == current_class ]\n    image_list = (select_df['img'].values)\n    train_amount = int( len(image_list)*split_rate)\n    train_list = image_list[:train_amount]\n    val_list = image_list[train_amount:]\n    \n\n    \n    \n    for filename in train_list:\n        x_train.append(load_image(current_class+\"/\"+filename))\n        y_train.append(current_class.replace('c',''))\n\n    for filename in val_list:\n        x_val.append(load_image(current_class+\"/\"+filename))\n        y_val.append(current_class.replace('c',''))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Encode Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.asarray(x_train)\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\nx_val = np.asarray(x_val)\ny_val =tf.keras.utils.to_categorical(y_val, num_classes=10)\nprint(\"Train x Shape: \",x_train.shape)\nprint(\"Test x Shape: \",x_val.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train y Shape: \",y_train.shape)\nprint(\"Test y Shape: \",y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagenerator = ImageDataGenerator(\n    rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.2, # Randomly zoom image \n    width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n     horizontal_flip = True\n    \n)\ndatagenerator.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Create Model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model  = tf.keras.applications.resnet.ResNet50(include_top = False,\n                                                  weights = 'imagenet',\n                                                  input_shape = model_input_shape)\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = base_model.output\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dropout(0.5)(x)\n\noutput =tf.keras.layers.Dense(units = len(class_names),activation = tf.nn.softmax)(x)\nmodel = tf.keras.models.Model(inputs=base_model.inputs, outputs=output)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False),\n              metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 2\nbatchSize = 8\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n     datagenerator.flow(x_train,y_train, batch_size=batchSize),\n      validation_data=(x_val,y_val),\n      steps_per_epoch=int(len(x_train)/batchSize),\n      epochs=num_epochs,\n    callbacks = [learning_rate_reduction],\n      verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n\nax[0].set_title('Accuracy')\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\n\nax[1].set_title('Loss')\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"test_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = os.path.join('', 'test_model.h5')\nmodel = tf.keras.models.load_model(\"test_model.h5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = []\ntest_ids = []\ntest_path = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test\"\nread_path = (os.listdir(test_path))\ntest_ids =  read_path[:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor file in read_path[:]:\n    read_path = test_path+\"/\"+file\n    image = Image.open(read_path)\n    image = image.resize(input_image)\n    x_train.append(np.asarray(image))\n    print(file)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.array(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_submission(predictions, test_id):\n    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n   \n    if not os.path.isdir('subm'):\n        os.mkdir('subm')\n    suffix = \"test_result\"\n    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n    result1.to_csv(sub_file, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result = model.predict(x_train, batch_size=128, verbose=1)\ncreate_submission(test_result,test_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(sample_path)\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result_path = os.path.join('subm', 'submission_test_result.csv')\nsample = pd.read_csv(test_result_path)\nsample.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}