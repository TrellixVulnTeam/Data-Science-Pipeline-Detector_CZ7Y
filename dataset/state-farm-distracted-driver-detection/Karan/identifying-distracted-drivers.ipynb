{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Identifying distracted drivers\n\nIn this notebook, I'll use the dataset which includes images of drivers while performing a number of tasks including .... The aim is to correctly identify if the driver is distracted from driving. We might also like to check what activity is the person performing."},{"metadata":{},"cell_type":"markdown","source":"# Import libraries\n\nI'll use Keras and Tensorflow libraries to create a **Convolutional Neural Network**. So, I'll import the necessary libraries to do the same."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport tensorflow\nos.environ['KERAS_BACKEND'] = 'tensorflow'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import the dataset\n\nI'll import the .csv file to read the labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/driver_imgs_list.csv')\ndataset.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the csv file, I'll use the `classname` as the labels for the images and use the image names to match the labels with the correct images."},{"metadata":{},"cell_type":"markdown","source":"# Images overview\n\nLet's take a look at the various images in the dataset. I'll plot an image for each of the 10 classes. As the directory names are not descriptive, I'll use a map to define the title for each image that is more descriptive."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom IPython.display import display, Image\nimport matplotlib.image as mpimg\n\nactivity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}\n\nplt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = '../input/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building the model\n\nI'll develop the model with a total of 3 Convolutional layers, then a Flatten layer and then 3 Dense layers. I'll use the optimizer as `adam`, and loss as `categorical_crossentropy`."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"classifier = Sequential()\nclassifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (240, 240, 3), data_format = 'channels_last'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Flatten())\nclassifier.add(Dense(units = 1024, activation = 'relu'))\nclassifier.add(Dense(units = 256, activation = 'relu'))\nclassifier.add(Dense(units = 10, activation = 'sigmoid'))\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nclassifier.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating training data\n\nOnce the model is ready, I'll use the data on which I want to train the model. The folder `train` includes the images I need. I'll generate more images using **ImageDataGenerator** and split the training data into 80% train and 20% validation split."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1.0/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True, \n                                   validation_split = 0.2)\n\ntraining_set = train_datagen.flow_from_directory('../input/train', \n                                                 target_size = (240, 240), \n                                                 batch_size = 32,\n                                                 subset = 'training')\n\nvalidation_set = train_datagen.flow_from_directory('../input/train', \n                                                   target_size = (240, 240), \n                                                   batch_size = 32,\n                                                   subset = 'validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the model\n\nUsing `fit_generator`, I'll train the model. I'll also save the model to the file, `safeDriving.h5`."},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit_generator(training_set,\n                         steps_per_epoch = 17943/32,\n                         epochs = 10,\n                         validation_data = validation_set,\n                         validation_steps = 4481/32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n\ndef get_data(image_path):\n    img = Image.open(image_path)\n    img = img.resize((240, 240), Image.ANTIALIAS) # resizes image in-place\n    return np.asarray(img)/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_file = pd.read_csv('../input/sample_submission.csv')\ntest_file.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, file in enumerate(test_file['img']):\n    image = get_data('../input/test/' + file)\n    image = np.reshape(image, (1, image.shape[0], image.shape[1], image.shape[2]))\n    result = classifier.predict(image)\n    test_file.iloc[i, 1:] = result[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_file.to_csv('results.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}