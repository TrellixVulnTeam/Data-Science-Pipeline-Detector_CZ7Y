{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input/state-farm-distracted-driver-detection/imgs'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nimport os, glob, math, cv2, time\nimport numpy as np\nfrom joblib import Parallel, delayed\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_image(img_file):\n    img = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img,(img_size,img_size))\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\n\nX_data = []\nY_data = []\n\nfor j in range(10):\n    print('Load folder c{}'.format(j))\n    path = os.path.join('../input/state-farm-distracted-driver-detection/imgs/train', 'c' + str(j), '*.jpg')\n    files = glob.glob(path)\n    for fl in files:\n            flbase = os.path.basename(fl)\n            img = process_image(fl)\n            X_data.append(img)\n            Y_data.append(j)\n    \nend = time.time() - start\nprint(\"Time: %.2f seconds\" % end)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data = np.array(X_data)\nY_data = np.array(Y_data)\n\n# np.random.shuffle(X_data)\n# np.random.shuffle(Y_data)\n\n# X_data = X_data[0:2000]\n# Y_data = Y_data[0:2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_data[0],cmap= 'gray')\nplt.show()\nprint(Y_data[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_data = torch.Tensor(X_data)\n# X_data = X_data.flatten(start_dim = 1)\n# X_data = X_data.numpy()\n\nX_data = np.reshape(X_data, (X_data.shape[0], -1))\nY_data = np.reshape(Y_data, (-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Drivers_dataset(Dataset):\n    def __init__(self, df):\n        rows = df.shape[0]\n        self.imgnp = df.iloc[:rows, 0:img_size*img_size].values\n        self.labels = df.iloc[:rows, img_size*img_size].values\n        self.rows = rows\n    \n    def __len__(self):\n        return self.rows\n    \n    def __getitem__(self, idx):\n        image = torch.tensor(self.imgnp[idx], dtype=torch.float) / 255  # Normalize\n        image = image.view(1, img_size, img_size)  # (channel, height, width)\n        label = self.labels[idx]\n        return (image, label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, random_state = 0, test_size = 1/5 )\ndel X_data, Y_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset = np.append(X_train, np.reshape(Y_train, (-1, 1)), axis = 1)\ntestset = np.append(X_test, np.reshape(Y_test, (-1, 1)), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset = pd.DataFrame(data = testset)\ntrainset = pd.DataFrame(data = trainset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset = Drivers_dataset(trainset)\ntestset = Drivers_dataset(testset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                          shuffle=True, num_workers=2)\ntrain_data_iter = iter(trainloader)\ntest_data_iter = iter(testloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\nplt.imshow(images.numpy()[0,0,::],cmap= 'gray')\nplt.show()\n\nimages.size(), labels.size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in trainloader:\n  inputs, labels = data\n  print(inputs.shape)\n  print(labels.shape)\n  print(labels.data)\n  break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\nfrom torch.nn.functional import relu, elu, relu6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n\n# Parameters:\n# in_channels (int) – Number of channels in the input image\n# out_channels (int) – Number of channels produced by the convolution\n# kernel_size (int or tuple) – Size of the convolving kernel (Filter size)\n# stride (int or tuple, optional) – Stride of the convolution. (Default: 1)\n# padding (int or tuple, optional) – Zero-padding added to both sides of the input (Default: 0)\n# padding_mode (string, optional) – zeros\n# dilation (int or tuple, optional) – Spacing between kernel elements. (Default: 1)\n# groups (int, optional) – Number of blocked connections from input to output channels. (Default: 1)\n# bias (bool, optional) – If True, adds a learnable bias to the output. (Default: True)\nclass Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n\n        # Define hidden convolutional layers\n        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 4)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Define hidden linear layers\n        self.fc1 = nn.Linear(128 * 6 * 6, 120)\n#         self.fc1_drop = nn.Dropout(p = 0.1)\n        self.fc2 = nn.Linear(120, 84)\n#         self.fc2_drop = nn.Dropout(p = 0.1)\n        self.fc3 = nn.Linear(84, 10)\n        \n    def forward(self, x):\n        \n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(-1, 128 * 6 * 6)\n        \n        x = F.relu(self.fc1(x))\n#         x = self.fc1_drop(x)\n\n        x = F.softmax(self.fc2(x), dim = 1)\n#         x = self.fc2_drop(x)\n\n        x = self.fc3(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nimport torch.backends.cudnn as cudnn\n\ncriterion = nn.CrossEntropyLoss()\n# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\noptimizer = optim.Adam(net.parameters(), lr=0.0001)\n# optimizer = optim.Adam(net.parameters(), lr=0.01, betas=(0.1, 0.4), eps=1e-08, weight_decay=0, amsgrad=False)\n\nif torch.cuda.is_available():\n    net = net.cuda()\n    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n    cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epoch = 10\n\nfor epoch in range(num_epoch):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs\n        inputs, labels = data\n\n        # wrap them in Variable\n        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n        # inputs, labels = Variable(inputs), Variable(labels)\n        \n        labels = labels.type(torch.LongTensor)\n        \n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs.cuda())\n        loss = criterion(outputs.cuda(), labels.cuda())\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 1000 == 999:    # print every 1000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 1000))\n            running_loss = 0.0\n\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\n\n# for data in testloader:\nfor i, data in enumerate(testloader, 0):\n    images, labels = data\n    outputs = net(Variable(images))\n    _, predicted = torch.max(outputs.data, 1)\n    total += labels.size(0)\n    correct += (predicted == labels.cuda()).sum()\n\nprint('Accuracy of the network on the {} test images: {:4.2f} %'.format(\n    X_test.shape[0], 100 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}