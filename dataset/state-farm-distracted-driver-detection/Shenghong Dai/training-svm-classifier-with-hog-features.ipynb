{"cells":[{"metadata":{"_uuid":"339988d2ae05e7ceb5217db4675fa6d0de373c4a","_cell_guid":"2ccf17df-b189-43fe-b01b-9e46a918a55b"},"cell_type":"markdown","source":"**Introduction**\n\n\nIn this analysis  Support Vector Machines (SVM) are used to train a model to classify if an image contains a ship or not. The  feature representation method Histogram of Oriented Gradients (HOG) are used as the feature representation. Although deep learning approaches have proven there superiority in similar image recognition/classification problem, given the small size of the data set it is interesting to find out how a traditional computer vision approach performs in a situation like this."},{"metadata":{"_uuid":"6df37a27fc458ba5bc6ea1859368e0e6837ddbff","_cell_guid":"7cce4402-c8ec-4f5e-9d0d-b9b64353c133","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd \nimport json\nfrom matplotlib import pyplot as plt\nfrom skimage import color\nfrom skimage.feature import hog\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report,accuracy_score\n\nimport matplotlib.pyplot as plt # plt 用于显示图片\nimport matplotlib.image as mpimg # mpimg 用于读取图片\n\nimport keras\nfrom keras.utils import to_categorical\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT_DIR = '../input/state-farm-distracted-driver-detection/'\nTRAIN_DIR = ROOT_DIR + 'imgs/train/'\nTEST_DIR = ROOT_DIR + 'imgs/test/'\ndriver_imgs_list = pd.read_csv(ROOT_DIR + \"driver_imgs_list.csv\")\nsample_submission = pd.read_csv(ROOT_DIR + \"sample_submission.csv\")\nrandom_list = np.random.permutation(len(driver_imgs_list))[:1250]\ndf_copy = driver_imgs_list.iloc[random_list]\nimage_paths = [TRAIN_DIR+row.classname+'/'+row.img \n                   for (index, row) in df_copy.iterrows()]\nlabel_list = [int(row.classname[1]) for (index, row) in df_copy.iterrows()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot vector representation of labels\n# y_labels_one_hot = to_categorical(label_list, dtype=np.int8)\nx_img_path = np.array(image_paths)\n\ndataset = []\nfor i in range(len(x_img_path)): # len(x_img_path)\n    # load\n    img = mpimg.imread(x_img_path[i]) \n    # 此时 img 就已经是一个 np.array 了，可以对它进行任意处理\n    dataset.append([img,label_list[i]])\ndataset = np.transpose(dataset)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba525ff7e714c9cc1a28cb9370b9986afcfea4bf","_cell_guid":"a101f220-46ca-41fc-a091-7491917b71a1"},"cell_type":"markdown","source":"Load the data and see check how an image looks like"},{"metadata":{"_uuid":"543c9aea8f366f988fea7073102991c408ef4fcf","_cell_guid":"71e24327-1562-4664-b73e-38b9b3ae5146","trusted":true},"cell_type":"code","source":"data = np.array(dataset[:][0])\nIMG_HEIGHT = 240\nIMG_WIDTH = 320\n\n# data = data.reshape(-1,3,IMG_HEIGHT,IMG_WIDTH).transpose([0,2,3,1])\nplt.imshow(data[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bb330dd7cd3d9a46ac019dd88e0481c796efade","_cell_guid":"3d87c788-f145-41d5-928f-ff7d81d96f6b"},"cell_type":"markdown","source":"Convert the images to grayscale colorspace before calculating the HOG features for each image"},{"metadata":{"_uuid":"4c8de1455b2d1c63bf0b823c35d5371eb82c8b90","_cell_guid":"7907cd4f-d7f0-464f-84ca-0f6b3da6d01e","trusted":true},"cell_type":"code","source":"data_gray = [ color.rgb2gray(i) for i in data]\nplt.imshow(data_gray[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3205c2a33a3a34d0eefdc51ad15339d5d44ba496","_cell_guid":"0f983630-1e7f-411a-a48d-01be7a1d6533","trusted":true},"cell_type":"code","source":"ppc = 16\nhog_images = []\nhog_features = []\nfor image in data_gray:\n    fd,hog_image = hog(image, orientations=8, pixels_per_cell=(ppc,ppc),cells_per_block=(4, 4),block_norm= 'L2',visualize=True)\n    hog_images.append(hog_image)\n    hog_features.append(fd)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0dc767c5f42c33ce23d517e5a3fb4ba862c8f469","_cell_guid":"c5fb9482-68dd-49ed-a696-a918caab2a0e"},"cell_type":"markdown","source":"The hog function of skimage returns a matrix that can be used to visualize the gradients"},{"metadata":{"_uuid":"e242d313fc8101d26e83996cd0567461cea60555","_cell_guid":"1d99eebf-84d6-4bbc-8698-0bee54dc7bb9","trusted":true},"cell_type":"code","source":"plt.imshow(hog_images[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4d43456af03dcfcf0587b7a4ca1b7d7fbe466d8","_cell_guid":"2e73c2eb-d6b9-4c02-9149-2515b44fa7f8","trusted":true},"cell_type":"code","source":"# labels =  np.array(dataset['labels']).reshape(len(dataset['labels']),1)\nlabels = np.array(dataset[:][1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03422c5af98cc84ca1c6428ac8bfa3ae9e4cca6c","_cell_guid":"a49b7994-cda6-4160-8c08-db0271ad0b35"},"cell_type":"markdown","source":"Fit a simple SVM classifier to the data . Make sure to shuffle the data before fitting it to the model"},{"metadata":{"_uuid":"6ea82e9e469efbb52e15a1b9eb1f13f411cf44bb","_cell_guid":"3963fce6-6f74-45f8-b4b1-d6df7741c40a","trusted":true},"cell_type":"code","source":"clf = svm.SVC()\nhog_features = np.array(hog_features)\ndata_frame = []\nfor i in range(len(hog_features)):\n    data_frame.append(np.hstack((hog_features[i],labels[i]))) \n\nnp.random.shuffle(data_frame)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8940f9e316bb736a14f4f6bdfaa854a9aae43e5d","_cell_guid":"36381116-f599-41f6-a78d-ea2054d57156","trusted":true},"cell_type":"code","source":"#What percentage of data you want to keep for training\npercentage = 80\npartition = int(len(hog_features)*percentage/100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12befca6c78e5a651cf5a2caf728d840579fcddb","_cell_guid":"0589e60c-ad50-4510-bd29-a0a7e5957589","trusted":true},"cell_type":"code","source":"data_frame = np.array(data_frame)\nx_train, x_test = data_frame[:partition,:-1],  data_frame[partition:,:-1]\ny_train, y_test = data_frame[:partition,-1:].ravel() , data_frame[partition:,-1:].ravel()\nclf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"169573ca753acae6cedde8e50213cea5b2f9c07b","_cell_guid":"6a23f296-ef7c-4434-8670-7da458cb7083","trusted":true},"cell_type":"code","source":"y_pred = clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c34aeca6ac1adcbe3160bfbfd0ac5cb6ea68cc4f","_cell_guid":"91ab6668-92c9-40f8-9432-8de008021a34","trusted":true},"cell_type":"code","source":"print(\"Accuracy: \"+str(accuracy_score(y_test, y_pred)))\nprint('\\n')\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3919c5130cb6b2e0e86c3d4b3e0c91a8ce2651c9","_cell_guid":"f96ff658-ea0a-4510-bb40-fd732b48dab4"},"cell_type":"markdown","source":"This shows that we can gain considerably good results with computer vision approaches alone. "},{"metadata":{"_uuid":"6369a9db086f94305d81cf016299f54790dc282f","_cell_guid":"2e84dcd4-b554-41f0-8559-df4d67782242","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}