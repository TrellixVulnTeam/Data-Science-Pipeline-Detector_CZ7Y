{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# State Farm Distracted Driver Detection","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2 #opencv library\nimport random\nimport h5py\n\nimport matplotlib.pyplot as plt  #plotting library\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom PIL import Image\nfrom IPython.display import Image, SVG\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport tensorflow\nfrom keras import layers, models, optimizers\nfrom keras.utils import np_utils\nfrom keras.utils.vis_utils import plot_model, model_to_dot\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nprint(os.listdir(\"../input\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Constant Values\nnum_train = 1000\nnum_test = 1000\nimg_width = 240\nimg_height = 240\nbatch_size = 64\nnb_epochs = 12","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Analysis","metadata":{}},{"cell_type":"code","source":"# Define paths\ntrain_path = '../input/state-farm-distracted-driver-detection/imgs/train'\ntest_path = '../input/state-farm-distracted-driver-detection/imgs/test/'\nclasses = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\ndriver_img_list = '../input/state-farm-distracted-driver-detection/driver_imgs_list.csv'\n# read image csv file\nimg_list = pd.read_csv(driver_img_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for category in classes:\n    i=0\n    path = os.path.join(train_path,category)\n    for img in os.listdir(path):\n           i+=1\n    print('Numer of instances of class {} in Train: {}'.format(category, i))\n\ni=0\nfor img in os.listdir(test_path):\n    i+=1\nprint('\\nTotal number of images in Test: ', i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nf = img_list['classname'].value_counts(sort=False)\nlabels = img_list['classname'].value_counts(sort=False).index.tolist()\ny = np.array(nf)\nwidth = 1/1.5\nN = len(y)\nx = range(N)\n\nfig = plt.figure(figsize=(20,15))\nay = fig.add_subplot(211)\nplt.xticks(x, labels, size=15)\nplt.yticks(size=15)\nay.bar(x, y, width, color=\"blue\")\nplt.title('Class Distribution',size=25)\nplt.xlabel('Class Name',size=15)\nplt.ylabel('Count',size=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explanation for each of the classes\nclass_dict = {\n    'c0': 'hands on the wheel',\n    'c1': 'mobile in right hand',\n    'c2': 'talking on the phone with right hand',\n    'c3': \"mobile in left hand\",\n    'c4': 'talking on the phone with left hand',\n    'c5': 'touching at the dash',\n    'c6': 'drinking',\n    'c7': 'reaching behind',\n    'c8': 'touching the head',\n    'c9': 'looking to the side'\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample Image for each class\nfor i in classes:\n    path = os.path.join(train_path, i)\n    print(\"Class \", i, ': ', class_dict[i])\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n        plt.imshow(img_array, cmap='gray')\n        plt.show()\n        print('\\n')\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Training and Testing Data","metadata":{}},{"cell_type":"code","source":"def create_training_data():\n    training_data = []\n    for category in classes:\n        i=0\n        path = os.path.join(train_path,category)\n        class_num = classes.index(category)\n        for img in os.listdir(path):\n            # return num_train instances of each class\n            if i < num_train:\n                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n                # resize image\n                new_img = cv2.resize(img_array,(img_width,img_height))\n                # get image and class type\n                training_data.append([new_img, class_num])\n                i+=1\n    return training_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_testing_data():\n    testing_data = []\n    i=0\n    for img in os.listdir(test_path):\n        # return num_test test images\n        if i < num_test:\n            img_array = cv2.imread(os.path.join(test_path,img), cv2.IMREAD_GRAYSCALE)\n            new_img = cv2.resize(img_array,(img_width,img_height))\n            testing_data.append([img, new_img])\n            i+=1\n    return testing_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data = create_training_data()\ntesting_data = create_testing_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffling data\nrandom.shuffle(training_data)\nx, y = list(), list()\nfor features, label in training_data:\n    x.append(features)\n    y.append(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Convert y to dummy variables","metadata":{}},{"cell_type":"code","source":"y[0:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = np_utils.to_categorical(y, num_classes=10)\nY[0:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Reshape","metadata":{}},{"cell_type":"code","source":"# Reshaping the image to fit the batch size (batch count,w,h,c)\nX = np.array(x).reshape(-1,img_width,img_height,1)\nX[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split into Train/test sets using train_test_split","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X, Y,test_size=0.2,random_state=123)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of train images is:\", X_train.shape)\nprint(\"Shape of validation images is:\", X_test.shape)\nprint(\"Shape of labels is:\", y_train.shape)\nprint(\"Shape of labels is:\", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating model architecture","metadata":{}},{"cell_type":"code","source":"# build the model\nmodel = Sequential()\n\n## CNN 1\nmodel.add(Conv2D(64,(3,3),activation='relu',input_shape=(img_width,img_height,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.2))\n\n## CNN 2\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.1))\n\n## CNN 3\nmodel.add(Conv2D(256,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.1))\n\n## CNN 3\nmodel.add(Conv2D(512,(5,5),activation='relu',padding='same'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(MaxPooling2D(pool_size=(2,2),padding='same'))\nmodel.add(Dropout(0.1))\n\n## Dense & Output\nmodel.add(Flatten())\nmodel.add(Dense(units = 256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\nmodel.add(Dense(units = 128,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model,show_shapes=True)\nImage(filename = 'model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compile and fit model","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [EarlyStopping(monitor='val_acc',patience=5), ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True, verbose=0, mode='auto'),]\nhistory = model.fit(X_train,y_train,batch_size=batch_size,epochs=nb_epochs,verbose=1,validation_data=(X_test,y_test),callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\n\n\nplt.figure(figsize=(7, 5))\nplt.plot(loss)\nplt.plot(val_loss)\nplt.xlabel('Epochs')\nplt.title('Training and validation loss')\nplt.legend(['Train Loss','Test Loss'], loc='best')\nplt.savefig('losses.png')\n\nplt.figure(figsize=(7, 5))\nplt.plot(accuracy)\nplt.plot(val_accuracy)\nplt.xlabel('Epochs')\nplt.title('Training and validation Accuracy')\nplt.legend(['Train Acc','Test Acc'], loc='best')\nplt.savefig('accuracy.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict and Evaluate Model","metadata":{}},{"cell_type":"markdown","source":"#### Predict on Validation Data","metadata":{}},{"cell_type":"code","source":"y_val_pred = []\ny_val_actual = []\nfor n in range(len(X_test)):\n    preds = model.predict(np.array([X_test[n]]))\n    y_val_pred.append(np.argmax(preds[0]))\n    y_val_actual.append(np.nonzero(y_test[n])[0][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\ndata = {'y_Actual':    y_val_actual,\n        'y_Predicted': y_val_pred}\ndf = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\nconfusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n\nplt.figure(figsize=(10,10))\nsns.heatmap(confusion_matrix, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_val_actual, y_val_pred, target_names=class_dict.keys()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict on Testing Data","metadata":{}},{"cell_type":"code","source":"y_pred = []\nfor n in range(num_test):\n    test_img = np.array(testing_data[n][1]).reshape(-1,img_width,img_height,1)\n    preds = model.predict(test_img)\n    class_idx = np.argmax(preds[0])\n    y_pred.append(class_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample Predictions\nfor n in range(120,130):\n    img_array = cv2.imread(os.path.join(test_path, testing_data[n][0]), cv2.IMREAD_COLOR)\n    plt.imshow(img_array, cmap='gray')\n    title_val = y_pred[n]\n    plt.title('Predicted c{}: {}'.format(title_val, class_dict['c{}'.format(title_val)]))\n    plt.show()\n    print('\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}