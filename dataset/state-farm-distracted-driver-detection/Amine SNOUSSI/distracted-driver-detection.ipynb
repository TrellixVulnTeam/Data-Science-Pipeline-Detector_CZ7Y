{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1 style=\"color:#1a1a1a;\n                    font-size:3em\">\n        Distracted Driver Detection\n        </h1> \n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Can computer vision spot distracted drivers?\n        </h2>\n</center>","metadata":{}},{"cell_type":"markdown","source":"## Realised by:\n * ### Mohammed JAWHAR\n * ### Amine SNOUSSI \n","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:1.5em\">üìú Table of Contents:</p>\n<div style=\"font-size:1.3em\">    \n    <ul>\n       <li><a href=\"#Intro-section\">Part 1: Loading Dataset üìñ</a></li>   \n       <li>\n          <a href=\"#Analysis-section\">Part 2: EDA üîé</a>\n       </li>\n       <li>\n          <a href=\"#Forcasting-section\">Part 3: CNN Model üßø</a>\n        </li>\n        <li>\n          <a href=\"#Forcasting-section\">Part 4 : Data Augmentation üñºÔ∏è</a>\n        </li>\n        \n    ","metadata":{}},{"cell_type":"markdown","source":"<div id=\"overview\">\n        <h1 style=\"color:#1a1a1a\">\n         ‚Æû  Part 1 : Loading Dataset \n        </h1>\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom glob import glob\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T16:14:53.810269Z","iopub.execute_input":"2022-04-16T16:14:53.811337Z","iopub.status.idle":"2022-04-16T16:14:53.819159Z","shell.execute_reply.started":"2022-04-16T16:14:53.811294Z","shell.execute_reply":"2022-04-16T16:14:53.817968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:33:12.180769Z","iopub.execute_input":"2022-04-16T14:33:12.181034Z","iopub.status.idle":"2022-04-16T14:33:12.24177Z","shell.execute_reply.started":"2022-04-16T14:33:12.181002Z","shell.execute_reply":"2022-04-16T14:33:12.240765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Groupby subjects\nby_drivers = df.groupby('subject') \n#Group unique drivers\nunique_drivers = by_drivers.groups.keys() # drivers id\n\nprint('There are : ',len(unique_drivers), ' unique drivers')\nprint('There is a mean of ',round(df.groupby('subject').count()['classname'].mean()), ' images by driver.')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:33:12.244969Z","iopub.execute_input":"2022-04-16T14:33:12.24522Z","iopub.status.idle":"2022-04-16T14:33:12.277349Z","shell.execute_reply.started":"2022-04-16T14:33:12.245192Z","shell.execute_reply":"2022-04-16T14:33:12.276644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 10","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:33:12.279479Z","iopub.execute_input":"2022-04-16T14:33:12.279744Z","iopub.status.idle":"2022-04-16T14:33:12.284137Z","shell.execute_reply.started":"2022-04-16T14:33:12.279712Z","shell.execute_reply":"2022-04-16T14:33:12.283216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read with opencv\ndef get_image(path, img_rows, img_cols, color_type=3):\n    \n    if color_type == 1:\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    elif color_type == 3:\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = cv2.resize(img, (img_rows, img_cols)) # Reduce size\n    return img\n\n#Loading training dataset\ndef train_data_load(img_rows=64, img_cols=64, color_type=3):\n    train_images=[]\n    train_labels=[]\n    \n    #Loop over the training folder\n    for classes in tqdm(range(num_classes)):\n        print('Loading directory c{}'.format(classes))\n        files = glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/train/c' + str(classes), '*.jpg'))\n        for file in files:\n            img = get_image(file, img_rows, img_cols, color_type)\n            train_images.append(img)\n            train_labels.append(classes)\n    return train_images, train_labels\n\ndef read_and_normalize_train_data(img_rows, img_cols, color_type):\n    X, labels = train_data_load(img_rows, img_cols, color_type)\n    y = np_utils.to_categorical(labels, 10)\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    \n    return x_train, x_test, y_train, y_test\n\n#Loading validation dataset\ndef load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n    \"\"\"\n    Same as above but for validation dataset\n    \"\"\"\n    path = os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg')\n    files = sorted(glob(path))\n    X_test, X_test_id = [], []\n    total = 0\n    files_size = len(files)\n    for file in tqdm(files):\n        if total >= size or total >= files_size:\n            break\n        file_base = os.path.basename(file)\n        img = get_image(file, img_rows, img_cols, color_type)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id\n\ndef read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)   \n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n    return test_data, test_ids\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:33:12.285493Z","iopub.execute_input":"2022-04-16T14:33:12.285749Z","iopub.status.idle":"2022-04-16T14:33:12.304737Z","shell.execute_reply.started":"2022-04-16T14:33:12.285719Z","shell.execute_reply":"2022-04-16T14:33:12.303756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install np_utils\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:33:12.305874Z","iopub.execute_input":"2022-04-16T14:33:12.306167Z","iopub.status.idle":"2022-04-16T14:33:26.855638Z","shell.execute_reply.started":"2022-04-16T14:33:12.306134Z","shell.execute_reply":"2022-04-16T14:33:26.854622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_rows = 64\nimg_cols = 64\ncolor_type = 1\nnb_test_samples = 200\n\n#Loading train images \nx_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\n\n#Loading validation images \ntest_files, test_targets = read_and_normalize_sampled_test_data(nb_test_samples, img_rows, img_cols, color_type)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:33:26.85733Z","iopub.execute_input":"2022-04-16T14:33:26.857608Z","iopub.status.idle":"2022-04-16T14:38:04.289148Z","shell.execute_reply.started":"2022-04-16T14:33:26.857578Z","shell.execute_reply":"2022-04-16T14:38:04.287576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"overview\">\n        <h1 style=\"color:#1a1a1a\">\n         ‚Æû  Part 2 : EDA \n        </h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Data visualisation\n ","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\npx.histogram(df, x=\"classname\", color=\"classname\", title=\"Number of images by categories \")\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:38:04.2996Z","iopub.execute_input":"2022-04-16T14:38:04.299856Z","iopub.status.idle":"2022-04-16T14:38:07.622734Z","shell.execute_reply.started":"2022-04-16T14:38:04.299827Z","shell.execute_reply":"2022-04-16T14:38:07.622098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the frequency of images per driver\ndrivers_id = pd.DataFrame((df['subject'].value_counts()).reset_index())\ndrivers_id.columns = ['driver_id', 'Counts']\npx.histogram(drivers_id, x=\"driver_id\",y=\"Counts\" ,color=\"driver_id\", title=\"Number of images by subjects \")","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:38:07.625036Z","iopub.execute_input":"2022-04-16T14:38:07.625274Z","iopub.status.idle":"2022-04-16T14:38:07.833805Z","shell.execute_reply.started":"2022-04-16T14:38:07.625246Z","shell.execute_reply":"2022-04-16T14:38:07.832975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Images overview\n","metadata":{}},{"cell_type":"code","source":"activity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}\n\n\nplt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:38:07.835284Z","iopub.execute_input":"2022-04-16T14:38:07.835866Z","iopub.status.idle":"2022-04-16T14:38:10.129171Z","shell.execute_reply.started":"2022-04-16T14:38:07.835827Z","shell.execute_reply":"2022-04-16T14:38:10.128018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"overview\">\n        <h1 style=\"color:#1a1a1a\">\n         ‚Æû  Part 3 : CNN Model \n        </h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Architecture :\n\n* 3 Convolutionnal layers (with Relu, Maxpooling and dropout)\n* A flatten layer\n* 2 Dense layers with Relu and Dropouts\n* 1 Dense layer with softmax for the classification","metadata":{}},{"cell_type":"code","source":"batch_size = 40\nn_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:38:10.130338Z","iopub.execute_input":"2022-04-16T14:38:10.130601Z","iopub.status.idle":"2022-04-16T14:38:10.135217Z","shell.execute_reply.started":"2022-04-16T14:38:10.13057Z","shell.execute_reply":"2022-04-16T14:38:10.133932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    \n    model = Sequential()\n    \n    #CNN1\n    model.add(Conv2D(32, (3,3), activation='relu', input_shape=(img_rows, img_cols, color_type)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,(3,3), activation='relu', padding='same'))\n    model.add(BatchNormalization(axis=3))\n    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n    model.add(Dropout(0.3))\n    \n    #CNN2\n    model.add(Conv2D(64, (3,3), activation='relu', input_shape=(img_rows, img_cols, color_type)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,(3,3), activation='relu', padding='same'))\n    model.add(BatchNormalization(axis=3))\n    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n    model.add(Dropout(0.3))\n    \n    #CNN3\n    model.add(Conv2D(128, (3,3), activation='relu', input_shape=(img_rows, img_cols, color_type)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3), activation='relu', padding='same'))\n    model.add(BatchNormalization(axis=3))\n    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n    model.add(Dropout(0.3))\n    \n    \n    #Output\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n    model.add(Dense(10,activation='softmax'))\n    \n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:38:10.136979Z","iopub.execute_input":"2022-04-16T14:38:10.137299Z","iopub.status.idle":"2022-04-16T14:38:10.156506Z","shell.execute_reply.started":"2022-04-16T14:38:10.13726Z","shell.execute_reply":"2022-04-16T14:38:10.155379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\n\n#Details about the model\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:38:10.158402Z","iopub.execute_input":"2022-04-16T14:38:10.158853Z","iopub.status.idle":"2022-04-16T14:38:10.550742Z","shell.execute_reply.started":"2022-04-16T14:38:10.158809Z","shell.execute_reply":"2022-04-16T14:38:10.549746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training model","metadata":{}},{"cell_type":"code","source":"history = model.fit(x_train, y_train,\n                   validation_data=(x_test, y_test),\n                   epochs=n_epochs, batch_size=batch_size, verbose=1)\n\nprint('History of the training',history.history)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:38:10.552547Z","iopub.execute_input":"2022-04-16T14:38:10.552928Z","iopub.status.idle":"2022-04-16T15:07:53.686816Z","shell.execute_reply.started":"2022-04-16T14:38:10.552859Z","shell.execute_reply":"2022-04-16T15:07:53.685678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_train_history(history):\n    \"\"\"\n    Plot the validation accuracy and validation loss over epochs\n    \"\"\"\n    # Summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    # Summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \nplot_train_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:07:53.688353Z","iopub.execute_input":"2022-04-16T15:07:53.688696Z","iopub.status.idle":"2022-04-16T15:07:54.119205Z","shell.execute_reply.started":"2022-04-16T15:07:53.688654Z","shell.execute_reply":"2022-04-16T15:07:54.118235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction on test set","metadata":{}},{"cell_type":"code","source":"def plot_test_class(model, test_files, image_number, color_type=1):\n    \"\"\"\n    Function that tests or model on test images and show the results\n    \"\"\"\n    img_brute = test_files[image_number]\n    img_brute = cv2.resize(img_brute,(img_rows,img_cols))\n    plt.imshow(img_brute, cmap='gray')\n\n    new_img = img_brute.reshape(-1,img_rows,img_cols,color_type)\n\n    y_prediction = model.predict(new_img, batch_size=batch_size, verbose=1)\n    print('Y prediction: {}'.format(y_prediction))\n    print('Predicted: {}'.format(activity_map.get('c{}'.format(np.argmax(y_prediction)))))\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:07:54.120556Z","iopub.execute_input":"2022-04-16T15:07:54.120989Z","iopub.status.idle":"2022-04-16T15:07:54.129575Z","shell.execute_reply.started":"2022-04-16T15:07:54.120949Z","shell.execute_reply":"2022-04-16T15:07:54.12856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score1 = model.evaluate(x_test, y_test, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:07:54.131044Z","iopub.execute_input":"2022-04-16T15:07:54.131742Z","iopub.status.idle":"2022-04-16T15:08:11.24997Z","shell.execute_reply.started":"2022-04-16T15:07:54.131695Z","shell.execute_reply":"2022-04-16T15:08:11.24899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Loss: ', score1[0])\nprint('Accuracy: ', score1[1]*100, ' %')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:08:11.251257Z","iopub.execute_input":"2022-04-16T15:08:11.251563Z","iopub.status.idle":"2022-04-16T15:08:11.258444Z","shell.execute_reply.started":"2022-04-16T15:08:11.251523Z","shell.execute_reply":"2022-04-16T15:08:11.257576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    plot_test_class(model, test_files, i)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:08:11.260165Z","iopub.execute_input":"2022-04-16T15:08:11.260821Z","iopub.status.idle":"2022-04-16T15:08:14.508676Z","shell.execute_reply.started":"2022-04-16T15:08:11.260775Z","shell.execute_reply":"2022-04-16T15:08:14.507974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"overview\">\n        <h1 style=\"color:#1a1a1a\">\n         ‚Æû  Part 4 : Data Augmentation\n        </h1>\n</div>","metadata":{}},{"cell_type":"code","source":"# Using ImageDataGenerator from keras\ntrain_datagen = ImageDataGenerator(rescale = 1.0/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True, \n                                   validation_split = 0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1.0/ 255, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:16:05.187431Z","iopub.execute_input":"2022-04-16T15:16:05.187709Z","iopub.status.idle":"2022-04-16T15:16:05.19523Z","shell.execute_reply.started":"2022-04-16T15:16:05.18768Z","shell.execute_reply":"2022-04-16T15:16:05.193963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_train_samples = x_train.shape[0]\nnb_validation_samples = x_test.shape[0]\ntraining_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\nvalidation_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:16:09.011627Z","iopub.execute_input":"2022-04-16T15:16:09.011946Z","iopub.status.idle":"2022-04-16T15:16:09.725604Z","shell.execute_reply.started":"2022-04-16T15:16:09.011899Z","shell.execute_reply":"2022-04-16T15:16:09.724656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training with data augmentation","metadata":{}},{"cell_type":"code","source":"history_v2 = model.fit_generator(training_generator,\n                         steps_per_epoch = nb_train_samples // batch_size,\n                         epochs = n_epochs, \n                         verbose = 1,\n                         validation_data = validation_generator,\n                         validation_steps = nb_validation_samples // batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:16:48.468374Z","iopub.execute_input":"2022-04-16T15:16:48.468667Z","iopub.status.idle":"2022-04-16T15:49:12.792139Z","shell.execute_reply.started":"2022-04-16T15:16:48.468639Z","shell.execute_reply":"2022-04-16T15:49:12.791009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_history(history_v2)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:51:44.076955Z","iopub.execute_input":"2022-04-16T15:51:44.077347Z","iopub.status.idle":"2022-04-16T15:51:44.502137Z","shell.execute_reply.started":"2022-04-16T15:51:44.077315Z","shell.execute_reply":"2022-04-16T15:51:44.501003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate and compare the performance of the new model\nscore2 = model.evaluate_generator(validation_generator, nb_validation_samples // batch_size)\nprint(\"Loss for model 1\",score1[0])\nprint(\"Loss for model 2 (data augmentation):\", score2[0])\n\nprint(\"Test accuracy for model 1\",score1[1])\nprint(\"Test accuracy for model 2 (data augmentation):\", score2[1])","metadata":{"execution":{"iopub.status.busy":"2022-04-16T15:51:53.891199Z","iopub.execute_input":"2022-04-16T15:51:53.891493Z","iopub.status.idle":"2022-04-16T15:52:04.47785Z","shell.execute_reply.started":"2022-04-16T15:51:53.891464Z","shell.execute_reply":"2022-04-16T15:52:04.476995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion for Data Augmentation\n### Data augmentation makes our model more robust.","metadata":{}}]}