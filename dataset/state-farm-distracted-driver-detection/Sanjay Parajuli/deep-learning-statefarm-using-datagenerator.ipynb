{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Outline\n1. Import Dependencies\n2. Prepare Training DataGenerator\n2. Build Model\n4. Train Model\n5. Make Predictions\n"},{"metadata":{},"cell_type":"markdown","source":"## Import Dependencies:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\n# visulization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom keras.models import Sequential, Model\nfrom keras.models import load_model\nfrom keras.layers import Input, Dense, Conv2D, MaxPool2D ,AveragePooling2D, Flatten, Add\nfrom keras.layers import Dropout, BatchNormalization, Activation\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks.callbacks import ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = '../input/state-farm-distracted-driver-detection/imgs/train/'\nTEST_DIR = '../input/state-farm-distracted-driver-detection/imgs/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_HEIGHT = 240\nIMG_WIDTH = 320","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Training Data Generator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS=10\nBATCH_SIZE=32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                color_mode='grayscale', classes=None, class_mode='categorical',\n                                batch_size=BATCH_SIZE, shuffle=True, subset='training')\n\nvalid_generator = train_datagen.flow_from_directory(TRAIN_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                color_mode='grayscale', classes=None, class_mode='categorical',\n                                batch_size=BATCH_SIZE, shuffle=True, subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Model:"},{"metadata":{},"cell_type":"markdown","source":"Things to consider  in keras model building:\n- No Dropout after Conv layer\n- Use dropout after dense layer (use mostly at the end of arch to not loose data)\n- Use BatchNorm before any activation function\n\n### Regularizers:\n- Dropout\n- Weigth Decay (L2) i.e. weights should be smaller. Penalizes model complexity.\n- BatchNorm (is a most)\n- Data Augmentation: e.g. fix lightning in images\n"},{"metadata":{},"cell_type":"markdown","source":"## Basic CNN\nconv > batch_norm > relu\n"},{"metadata":{},"cell_type":"markdown","source":"Room for improvement:\n- Progressive Resizing\n- Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"MODELS_DIR = \"saved_models\"\nif not os.path.exists(MODELS_DIR):\n    os.makedirs(MODELS_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setup Callbacks:"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = MODELS_DIR+'/epoch{epoch:02d}-loss{loss:.2f}-val_loss{val_loss:.2f}.hdf5'\n# checkpoint\nmodel_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n                                   save_best_only=True, save_weights_only=False, mode='min', period=1)\n\n# early stopping: patience = epochs\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1,\n                               mode='min', baseline=None, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_model_loss(history):\n    plt.plot(history['loss'])\n    plt.plot(history['val_loss'])\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'valid'], loc='upper left')\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use stride 2 in the middle to reduce size and increase no. of filters\n# use avgpool at the end (not maxpool)\ndef seq_conv_block(model, filters=32):\n    model.add(Conv2D(filters=filters, kernel_size=(3,3), strides=2, padding=\"same\"))\n    model.add(BatchNormalization(axis=-1))\n    model.add(Activation(\"relu\"))\n    return model\n\n# all conv layers  with strides=1\nmodel = Sequential(name=\"seq_conv_rmsprop\")\n\nmodel.add(Conv2D(input_shape=(IMG_HEIGHT,IMG_WIDTH,1), filters=16, kernel_size=(3,3), padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation(\"relu\"))\n\nmodel = seq_conv_block(model, filters=32)\nmodel = seq_conv_block(model, filters=64)\nmodel = seq_conv_block(model, filters=128)\n\nmodel.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(500))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation(\"relu\"))\n\nmodel.add(Dense(10, activation=\"softmax\"))\n\n# sgd = optimizers.SGD(lr=0.01, clipvalue=0.5)\n# optimizer = RMSprop(learning_rate=0.001)\n# adad = Adam(learning_rate=0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"history_v1 = model.fit_generator(train_generator,\n                         steps_per_epoch = train_generator.samples // BATCH_SIZE,\n                         epochs = EPOCHS, \n                         callbacks=[early_stopping, model_checkpoint],\n                         verbose = 1,\n                         validation_data = valid_generator,\n                         validation_steps = valid_generator.samples // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load saved model\n# model = load_model('saved_models/epoch03-loss0.10-val_loss0.07.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model_loss(history_v1.history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate_generator(valid_generator, steps=valid_generator.samples // BATCH_SIZE)\nprint(\"Loss:\",loss)\nprint(\"Accuracy:\", accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Prediction:"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs('test/all_files')\n!cp -r $TEST_DIR test/all_files/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_DIR = 'test'\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_directory(TEST_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                color_mode='grayscale', classes=None, class_mode=None,\n                                batch_size=BATCH_SIZE, shuffle=False)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()\n# test_generator.filenames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_submission_df(predictions, ids):\n    result_df = pd.DataFrame(predictions, columns=[\"c0\",\"c1\",\"c2\",\"c3\",\"c4\",\"c5\",\"c6\",\"c7\",\"c8\",\"c9\"])\n    result_df['img'] = ids\n    return result_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_generator(test_generator, steps=len(test_generator.filenames)/BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = [os.path.basename(p) for p in test_generator.filenames]\nfinal_df = prepare_submission_df(predictions, ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install kaggle\n# !kaggle competitions submit -c state-farm-distracted-driver-detection -f submission.csv -m \"First Submission.\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resnet like model"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def conv_layer(inputs, filters=16, num_strides=1):\n    return Conv2D(filters=filters, kernel_size=(3,3), strides=num_strides, padding='same')(inputs)\n\ndef conv_block(inputs, filters=16, num_strides=1):\n    x = conv_layer(inputs, filters, num_strides)\n    x = BatchNormalization(axis=-1)(x)\n    x = Activation('relu')(x)\n    return x\n    \ndef resnet_block(inputs, filters=16):\n    x_shortcut = inputs\n    x = conv_block(inputs, filters)\n    x = BatchNormalization(axis=-1)(x)\n    x = Add()([x,x_shortcut]) # skip connection\n    x = Activation('relu')(x)\n    return x\n    \n\ninputs = Input(shape=(IMG_HEIGHT,IMG_WIDTH,1))\n\noutput_0 = conv_block(inputs=inputs, filters=16)\n\noutput_1 = conv_block(output_0, filters=32, num_strides=2)\noutput_1 = resnet_block(output_1, filters=32)\n\noutput_2 = conv_block(output_1, filters=64, num_strides=2)\noutput_2 = resnet_block(output_2, filters=64)\n\noutput_3 = conv_block(output_2, filters=128, num_strides=2)\noutput_3 = resnet_block(output_3, filters=128)\n\noutput_3 = AveragePooling2D(pool_size=(2,2), strides=(2,2))(output_3)\n\noutput_4 = Flatten()(output_3)\noutput_4 = Dropout(0.5)(output_4)\n\noutput_5 = Dense(500)(output_4)\noutput_5 = Dropout(0.5)(output_5)\noutput_5 = BatchNormalization(axis=-1)(output_5)\noutput_5 = Activation('relu')(output_5)\n\noutput_6 = Dense(10, activation='softmax')(output_5)\n\nres_model = Model(inputs=inputs, outputs=output_6, name=\"res_model\")\n\nres_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\nres_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history_v2 = res_model.fit_generator(train_generator,\n#                          steps_per_epoch = train_generator.samples // BATCH_SIZE,\n#                          epochs = EPOCHS, \n#                          callbacks=[early_stopping, model_checkpoint],\n#                          verbose = 1,\n#                          validation_data = valid_generator,\n#                          validation_steps = valid_generator.samples // BATCH_SIZE)\n# model_v2 = res_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_model_loss(history_v2.history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}