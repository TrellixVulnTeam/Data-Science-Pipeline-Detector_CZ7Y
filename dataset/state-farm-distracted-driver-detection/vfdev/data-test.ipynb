{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##\n## Adapted from https://www.kaggle.com/sunlchk/state-farm-distracted-driver-detection/object-expression-farmer\n##\n\n# -*- coding: utf-8 -*-\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport os\nimport random\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"labels = {'c0' : 'safe driving', \n'c1' : 'texting - right', \n'c2' : 'talking on the phone - right', \n'c3' : 'texting - left', \n'c4' : 'talking on the phone - left', \n'c5' : 'operating the radio', \n'c6' : 'drinking', \n'c7' : 'reaching behind', \n'c8' : 'hair and makeup', \n'c9' : 'talking to passenger'}\n\nplt.rcParams['figure.figsize'] = (8.0, 20.0)\nplt.subplots_adjust(wspace=0, hspace=0)\ncount = 0\nfor c in labels:\n    train_files = [\"../input/train/\" + c + \"/\" + f for f in os.listdir(\"../input/train/\" + c + \"/\")]\n    random_file = random.choice(train_files)\n    im = cv2.imread(random_file)\n    print(\"{} : {}\".format(random_file, im.shape))\n    plt.subplot(5, 2, count+1).set_title(labels[c])\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    count += 1"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def proc_func(img):\n    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    gray = cv2.blur(gray, (3, 3))\n    t1 = 70\n    t2 = 200\n    gray = cv2.Canny(gray, t1, t2)\n    return gray"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def proc_func(img):\n    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    gray = cv2.equalizeHist(gray)\n    return gray"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"count = 0\nplt.rcParams['image.cmap'] = 'gray'\nfor c in labels:\n    train_files = [\"../input/train/\" + c + \"/\" + f for f in os.listdir(\"../input/train/\" + c + \"/\")]\n    random_file = random.choice(train_files)\n    im = cv2.imread(random_file)\n    \n    im = proc_func(im)\n    \n    plt.subplot(5, 2, count+1).set_title(labels[c])\n    plt.imshow(im)\n    plt.axis('off')\n    count += 1"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}