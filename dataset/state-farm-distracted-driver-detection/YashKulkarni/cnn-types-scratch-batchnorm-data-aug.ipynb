{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom tensorflow import keras\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggleDir = '/kaggle/input/state-farm-distracted-driver-detection/'\ntrain_img_dir = 'train/'\ntest_img_dir = 'test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(kaggleDir + 'driver_imgs_list.csv', low_memory=True)\nprint('Number of Samples in trainset : {}'.format(df_train.shape[0]))\nprint('Number Of districted Classes : {}'.format(len((df_train.classname).unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_freq_count = df_train.classname.value_counts()\n\nclass_freq_count.plot(kind='bar', label='index')\nplt.title('Sample Per Class');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASSES = {\"c0\": \"safe driving\", \"c1\": \"texting - right\", \"c2\": \"talking on the phone - right\", \"c3\": \"texting - left\",\n           \"c4\": \"talking on the phone - left\", \"c5\": \"operating the radio\", \"c6\": \"drinking\", \"c7\": \"reaching behind\",\n           \"c8\": \"hair and makeup\", \"c9\": \" talking to passenger\"}\nplt.pie(class_freq_count, autopct='%1.1f%%', shadow=True, labels=CLASSES.values())\nplt.title('Sample % per class');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ndataset.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot figure size\nplt.figure(figsize = (4,4))\n# Count the number of images per category\nsns.countplot(x = 'classname', data = dataset)\n# Change the Axis names\nplt.ylabel('Count')\nplt.title('Categories Distribution')\n# Show plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['class_type'] = dataset['classname'].str.extract('(\\d)',expand=False).astype(np.float)\nplt.figure(figsize = (10,10))\ndataset.hist('class_type', alpha=0.5, layout=(1,1), bins=10)\nplt.title('Class distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import image\nfrom matplotlib import pyplot\n\n#load image as pixel array\ndata=image.imread(r\"../input/state-farm-distracted-driver-detection/imgs/train/c1/img_448.jpg\")\n#summarize shape of the pixel array\nprint(data.dtype)\nprint(data.shape)\n#display the arrays of pixels as an image\npyplot.imshow(data)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import image\nfrom matplotlib import pyplot\n\n#load image as pixel array\ndata=cv2.imread(r\"../input/state-farm-distracted-driver-detection/imgs/train/c1/img_448.jpg\",cv2.IMREAD_GRAYSCALE)\n#summarize shape of the pixel array\ndata=cv2.resize(data,(240,240))\nprint(data.dtype)\nprint(data.shape)\n#display the arrays of pixels as an image\npyplot.imshow(data)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import image\nfrom matplotlib import pyplot\n\n#load image as pixel array\ndata=cv2.imread(r\"../input/state-farm-distracted-driver-detection/imgs/train/c2/img_100029.jpg\",cv2.IMREAD_GRAYSCALE)\n#summarize shape of the pixel array\ndata=cv2.resize(data,(240,240))\nprint(data.dtype)\nprint(data.shape)\n#display the arrays of pixels as an image\npyplot.imshow(data)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import image\nfrom matplotlib import pyplot\n\n#load image as pixel array\ndata=cv2.imread(r\"../input/state-farm-distracted-driver-detection/imgs/train/c3/img_100041.jpg\",cv2.IMREAD_GRAYSCALE)\n#summarize shape of the pixel array\ndata=cv2.resize(data,(240,240))\nprint(data.dtype)\nprint(data.shape)\n#display the arrays of pixels as an image\npyplot.imshow(data)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import image\nfrom matplotlib import pyplot\n\n#load image as pixel array\ndata=cv2.imread(r\"../input/state-farm-distracted-driver-detection/imgs/train/c5/img_100027.jpg\",cv2.IMREAD_GRAYSCALE)\n#summarize shape of the pixel array\ndata=cv2.resize(data,(240,240))\nprint(data.dtype)\nprint(data.shape)\n#display the arrays of pixels as an image\npyplot.imshow(data)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files=os.listdir(r\"../input/state-farm-distracted-driver-detection/imgs/train\")\nprint(\"Number of files in train:\",len(files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c0=os.listdir(r\"../input/state-farm-distracted-driver-detection/imgs/train/c0\")\nprint(\"Number of images in C0 class:\",len(c0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c1=os.listdir(r\"../input/state-farm-distracted-driver-detection/imgs/train/c1\")\nprint(\"Number of images in C1 class:\",len(c1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_im=os.listdir(r\"../input/state-farm-distracted-driver-detection/imgs/test\")\nprint(\"Number of images in Test:\",len(test_im))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nactivity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}\n\n\nplt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = r'../input/state-farm-distracted-driver-detection/imgs/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_directory = r\"../input/state-farm-distracted-driver-detection/imgs/train\"\ntest_directory =r\"../input/state-farm-distracted-driver-detection/imgs/test\"\nclasses = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size1 = 240\nimg_size2 = 240","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\n#TRAINING DATA\n\ntraining_data = []\ni = 0\ndef create_training_data():\n    for category in classes:\n        path = os.path.join(train_directory,category)\n        class_num = classes.index(category)\n        \n        for img in os.listdir(path):\n            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n            new_img = cv2.resize(img_array,(img_size2,img_size1))\n            training_data.append([new_img,class_num])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data = []\ni = 0\ndef create_testing_data():        \n    for img in os.listdir(test_directory):\n        img_array = cv2.imread(os.path.join(test_directory,img),cv2.IMREAD_GRAYSCALE)\n        new_img = cv2.resize(img_array,(img_size2,img_size1))\n        testing_data.append([img,new_img])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_testing_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.shuffle(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = []\ny = []\nfor features, label in training_data:\n    x.append(features)\n    y.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nX = np.array(x).reshape(-1,img_size2,img_size1,1)\nX[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=np.array(y).reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\nY_train = np_utils.to_categorical(y_train,num_classes=10)\nY_test = np_utils.to_categorical(y_test,num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nmodel = keras.models.Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nmodels_dir = \"saved_models\"\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_v1():\n    # Vanilla CNN model\n    model = Sequential()\n\n    model.add(Conv2D(filters = 64, kernel_size = 3, padding='same', activation = 'relu', input_shape=(240,240,1)))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 128, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 256, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 512, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Flatten())\n\n    model.add(Dense(500, activation = 'relu'))\n    model.add(Dense(10, activation = 'softmax'))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v1 = create_model_v1()\n\n# More details about the layers\nmodel_v1.summary()\n\n# Compiling the model\nmodel_v1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the Vanilla Model \nhistory_v1 = model_v1.fit(x_train, Y_train, epochs=10,batch_size=40,validation_data=(x_test , Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_train_history(history):\n    # Summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    # Summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_history(history_v1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model_v1.evaluate(x_test, Y_test, verbose=1)\nprint('Score of V1 model: ', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v1.predict(np.array(testing_data[100][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[100][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v1.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[100][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v1.predict(np.array(testing_data[200][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[200][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v1.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[200][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v1.predict(np.array(testing_data[300][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[300][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v1.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted : {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[300][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v1.predict(np.array(testing_data[400][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[400][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v1.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[400][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v1.predict(np.array(testing_data[500][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[500][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v1.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[500][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_v2():\n    # Optimised Vanilla CNN model\n    model = Sequential()\n\n    ## CNN 1\n    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(240,240,1)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 2\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 3\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.5))\n\n    ## Output\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(10,activation='softmax'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v2 = create_model_v2()\n\n# More details about the layers\nmodel_v2.summary()\n\n# Compiling the model\nmodel_v2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_cb=keras.callbacks.ModelCheckpoint(\"saved_models/cnn_vanilla.hdf5\",save_best_only=True)\nhistory_v2 = model_v2.fit(x_train, Y_train, epochs=10,batch_size=40,validation_data=(x_test , Y_test),callbacks=[checkpoint_cb])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -f saved_models/cnn_vanilla.hdf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_train_history(history):\n    # Summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    # Summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_history(history_v2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model_v2.evaluate(x_test, Y_test, verbose=1)\nprint('Score: ', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v2.predict(np.array(testing_data[101][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[101][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v2.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[101][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v2.predict(np.array(testing_data[201][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[201][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v2.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[201][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v2.predict(np.array(testing_data[301][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[301][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v2.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[301][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v2.predict(np.array(testing_data[401][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[401][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v2.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[401][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model_v2.predict(np.array(testing_data[501][1]).reshape(-1,img_size2,img_size1,1))\ntest_data = np.array(testing_data[501][1]).reshape(-1,img_size2,img_size1,1)\n\npreds = model_v2.predict(test_data)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint('Predicted: {}'.format(np.argmax(preds)))\n\nnew_img = cv2.resize(testing_data[501][1],(img_size2,img_size1))\nplt.imshow(new_img,cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_v3():\n    model = Sequential()\n    \n    model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (240, 240, 3), data_format = 'channels_last'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    \n    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    \n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    \n    model.add(Flatten())\n    model.add(Dense(units = 1024, activation = 'relu'))\n    \n    model.add(Dense(units = 256, activation = 'relu'))\n    model.add(Dense(units = 10, activation = 'sigmoid'))\n\n\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v3 = create_model_v3()\n\n# More details about the layers\nmodel_v3.summary()\n\n# Compiling the model\nmodel_v3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1.0/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True, \n                                   validation_split = 0.2)\n\ntraining_set = train_datagen.flow_from_directory('../input/state-farm-distracted-driver-detection/imgs/train', \n                                                 target_size = (240, 240), \n                                                 batch_size = 32,\n                                                 subset = 'training')\n\nvalidation_set = train_datagen.flow_from_directory('../input/state-farm-distracted-driver-detection/imgs/train', \n                                                   target_size = (240, 240), \n                                                   batch_size = 32,\n                                                   subset = 'validation')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_cb=keras.callbacks.ModelCheckpoint(\"./cnn_vanilla.hdf5\",save_best_only=True)\nhistory = model_v3.fit_generator(training_set,\n                         steps_per_epoch = 17943/32,\n                         epochs = 10,\n                         validation_data = validation_set,\n                         validation_steps = 4481/32,\n                         callbacks=[checkpoint_cb])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v3.save_weights('./cnn_vanilla.hdf5', overwrite=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v3.save('./cnn_vanilla.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=keras.models.load_model(\"cnn_vanilla.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nloaded_model = load_model('saved_models/cnn_vanilla.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_train_history(history):\n    # Summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    # Summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nimport os\nimport numpy as np\nfrom keras.preprocessing import image\nimport cv2\nimport matplotlib.pyplot as plt\n\nmodel = load_model('cnn_vanilla.hdf5')\n\ntest_data_dir = r'../input/state-farm-distracted-driver-detection/imgs/test/'\n\n\nclass_labels = [\n    \"normal driving\",\n    \"texting - right\",\n    \"talking on the phone - right\",\n    \"texting - left\",\n    \"talking on the phone - left\",\n    \"operating the radio\",\n    \"drinking\",\n    \"reaching behind\",\n    \"hair and makeup\",\n    \"talking to passenger\"\n]\n\nfile_names = np.random.choice(os.listdir(test_data_dir),550)\n\nimg_arrays = []\n\nfor file_name in file_names:\n    img = image.load_img(os.path.join(test_data_dir, file_name), target_size=(240, 240))\n    img_array = image.img_to_array(img)\n    img_arrays.append(img_array)\n\nimg_arrays = np.array(img_arrays)\nimg_arrays = img_arrays.astype('float32') / 255\n#predictions = model.predict(np.array(img_arrays).reshape(-1,240,240,1))\npredictions = model.predict(img_arrays)\n\n\nlabel_indexes = np.argmax(predictions, axis=1)\nprobabilities = np.max(predictions, axis=1)\n\nfor (file_name, label_index, probability) in zip(file_names, label_indexes, probabilities):\n    if probability < 0.50:\n        continue\n\n    label_with_probability = \"{}: {:.2f}%\".format(class_labels[label_index], probability * 100)\n\n    import cv2\n\n    image = cv2.imread(os.path.join(test_data_dir, file_name))\n    #image = cv2.resize(image, (240,240))\n\n    cv2.putText(image, label_with_probability.upper(), (210, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n\n    c=cv2.imwrite(\"annotated-results/\" + file_name, image)\n    \n    plt.imshow(image)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}