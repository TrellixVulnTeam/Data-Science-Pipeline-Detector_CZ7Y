{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Distraction Driver Detection Project\n\n> In this notebook, I'll use the dataset which includes images of drivers while performing a number of tasks including drinking, texting etc. The aim is to correctly identify if the driver is distracted from driving. We might also like to check what activity the person is performing.\n\nThe notebook will be borken into the following steps:\n\n0. Import the Libraries.\n1. Import the Datasets.\n2. Create a vanilla CNN model.\n3. Create a vanilla CNN model with data augmentation.\n4. Train a CNN with Transfer Learning (VGG16).\n5. Kaggle Results.\n"},{"metadata":{},"cell_type":"markdown","source":"## Import the Libraries\n\nI'll use Keras and Tensorflow libraries to create a **Convolutional Neural Network**. So, I'll import the necessary libraries to do the same."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfrom glob import glob\nimport random\nimport time\nimport tensorflow\nimport datetime\nos.environ['KERAS_BACKEND'] = 'tensorflow'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import FileLink\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns \n%matplotlib inline\nfrom IPython.display import display, Image\nimport matplotlib.image as mpimg\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_files       \nfrom keras.utils import np_utils\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import log_loss\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.applications.vgg16 import VGG16","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import the Datasets\n\nI'll import the `.csv` file to read the labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/driver_imgs_list.csv')\ndataset.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the csv file, I'll use the `classname` as the labels for the images and use the image names to match the labels with the correct images."},{"metadata":{},"cell_type":"markdown","source":"#### Import Driver Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"by_drivers = dataset.groupby('subject')\nunique_drivers = by_drivers.groups.keys()\nprint(unique_drivers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the following, I prepare the code to import the dataset of the driver images. then populate a few variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the dataset previously downloaded from Kaggle\nNUMBER_CLASSES = 10\n# Color type: 1 - grey, 3 - rgb\n\ndef get_cv2_image(path, img_rows, img_cols, color_type=3):\n    # Loading as Grayscale image\n    if color_type == 1:\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    elif color_type == 3:\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n    # Reduce size\n    img = cv2.resize(img, (img_rows, img_cols)) \n    return img\n\n# Training\ndef load_train(img_rows, img_cols, color_type=3):\n    start_time = time.time()\n    train_images = [] \n    train_labels = []\n    # Loop over the training folder \n    for classed in tqdm(range(NUMBER_CLASSES)):\n        print('Loading directory c{}'.format(classed))\n        files = glob(os.path.join('..', 'input', 'train', 'c' + str(classed), '*.jpg'))\n        for file in files:\n            img = get_cv2_image(file, img_rows, img_cols, color_type)\n            train_images.append(img)\n            train_labels.append(classed)\n    print(\"Data Loaded in {} second\".format(time.time() - start_time))\n    return train_images, train_labels \n\ndef read_and_normalize_train_data(img_rows, img_cols, color_type):\n    X, labels = load_train(img_rows, img_cols, color_type)\n    y = np_utils.to_categorical(labels, 10)\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    \n    return x_train, x_test, y_train, y_test\n\n# Validation\ndef load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n    path = os.path.join('..', 'input', 'test', '*.jpg')\n    files = sorted(glob(path))\n    X_test, X_test_id = [], []\n    total = 0\n    files_size = len(files)\n    for file in tqdm(files):\n        if total >= size or total >= files_size:\n            break\n        file_base = os.path.basename(file)\n        img = get_cv2_image(file, img_rows, img_cols, color_type)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id\n\ndef read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)\n    \n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n    \n    return test_data, test_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows = 64\nimg_cols = 64\ncolor_type = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\nprint('Train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_test_samples = 200\ntest_files, test_targets = read_and_normalize_sampled_test_data(nb_test_samples, img_rows, img_cols, color_type)\nprint('Test shape:', test_files.shape)\nprint(test_files.shape[0], 'Test samples')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics\n# Load the list of names\nnames = [item[17:19] for item in sorted(glob(\"../input/train/*/\"))]\ntest_files_size = len(np.array(glob(os.path.join('..', 'input', 'test', '*.jpg'))))\nx_train_size = len(x_train)\ncategories_size = len(names)\nx_test_size = len(x_test)\nprint('There are %s total images.\\n' % (test_files_size + x_train_size + x_test_size))\nprint('There are %d training images.' % x_train_size)\nprint('There are %d total training categories.' % categories_size)\nprint('There are %d validation images.' % x_test_size)\nprint('There are %d test images.'% test_files_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dataset Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot figure size\nplt.figure(figsize = (10,10))\n# Count the number of images per category\nsns.countplot(x = 'classname', data = dataset)\n# Change the Axis names\nplt.ylabel('Count')\nplt.title('Categories Distribution')\n# Show plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the frequency of images per driver\ndrivers_id = pd.DataFrame((dataset['subject'].value_counts()).reset_index())\ndrivers_id.columns = ['driver_id', 'Counts']\ndrivers_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting class distribution\ndataset['class_type'] = dataset['classname'].str.extract('(\\d)',expand=False).astype(np.float)\nplt.figure(figsize = (20,20))\ndataset.hist('class_type', alpha=0.5, layout=(1,1), bins=10)\nplt.title('Class distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Images overview\n\nLet's take a look at the various images in the dataset. I'll plot an image for each of the 10 classes. As the directory names are not descriptive, I'll use a map to define the title for each image that is more descriptive."},{"metadata":{"trusted":true},"cell_type":"code","source":"activity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = '../input/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_submission(predictions, test_id, info):\n    result = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n    result.loc[:, 'img'] = pd.Series(test_id, index=result.index)\n    \n    now = datetime.datetime.now()\n    \n    if not os.path.isdir('kaggle_submissions'):\n        os.mkdir('kaggle_submissions')\n\n    suffix = \"{}_{}\".format(info,str(now.strftime(\"%Y-%m-%d-%H-%M\")))\n    sub_file = os.path.join('kaggle_submissions', 'submission_' + suffix + '.csv')\n    \n    result.to_csv(sub_file, index=False)\n    \n    return sub_file","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a vanilla CNN model"},{"metadata":{},"cell_type":"markdown","source":"#### Building the model\n\nI'll develop the model with a total of 4 Convolutional layers, then a Flatten layer and then 2 Dense layers. I'll use the optimizer as `rmsprop`, and loss as `categorical_crossentropy`."},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 40\nnb_epoch = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -f saved_models/weights_best_vanilla.hdf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_dir = \"saved_models\"\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n    \ncheckpointer = ModelCheckpoint(filepath='saved_models/weights_best_vanilla.hdf5', \n                               monitor='val_loss', mode='min',\n                               verbose=1, save_best_only=True)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\ncallbacks = [checkpointer, es]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model v1\n---"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def create_model_v1():\n    # Vanilla CNN model\n    model = Sequential()\n\n    model.add(Conv2D(filters = 64, kernel_size = 3, padding='same', activation = 'relu', input_shape=(img_rows, img_cols, color_type)))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 128, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 256, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Conv2D(filters = 512, padding='same', kernel_size = 3, activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = 2))\n\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n\n    model.add(Dense(500, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = 'softmax'))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v1 = create_model_v1()\n\n# More details about the layers\nmodel_v1.summary()\n\n# Compiling the model\nmodel_v1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the Vanilla Model version 1\nhistory_v1 = model_v1.fit(x_train, y_train, \n          validation_data=(x_test, y_test),\n          callbacks=callbacks,\n          epochs=nb_epoch, batch_size=batch_size, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the classifier with the best validation loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v1.load_weights('saved_models/weights_best_vanilla.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_train_history(history):\n    # Summarize history for accuracy\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n    # Summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_history(history_v1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_test_class(model, test_files, image_number, color_type=1):\n    img_brute = test_files[image_number]\n    img_brute = cv2.resize(img_brute,(img_rows,img_cols))\n    plt.imshow(img_brute, cmap='gray')\n\n    new_img = img_brute.reshape(-1,img_rows,img_cols,color_type)\n\n    y_prediction = model.predict(new_img, batch_size=batch_size, verbose=1)\n    print('Y prediction: {}'.format(y_prediction))\n    print('Predicted: {}'.format(activity_map.get('c{}'.format(np.argmax(y_prediction)))))\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model_v1.evaluate(x_test, y_test, verbose=1)\nprint('Score: ', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_class(model_v1, test_files, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -f saved_models/weights_best_vanilla.hdf5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Optimised Vanilla CNN Model "},{"metadata":{},"cell_type":"markdown","source":"#### Model v2\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_v2():\n    # Optimised Vanilla CNN model\n    model = Sequential()\n\n    ## CNN 1\n    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 2\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 3\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.5))\n\n    ## Output\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(10,activation='softmax'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v2 = create_model_v2()\n\n# More details about the layers\nmodel_v2.summary()\n\n# Compiling the model\nmodel_v2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the Vanilla Model\nhistory_v2 = model_v2.fit(x_train, y_train, \n          validation_data=(x_test, y_test),\n          callbacks=callbacks,\n          epochs=nb_epoch, batch_size=batch_size, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_history(history_v2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v2.load_weights('saved_models/weights_best_vanilla.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model_v2.evaluate(x_test, y_test, verbose=1)\nprint('Score: ', score)\n\ny_pred = model_v2.predict(x_test, batch_size=batch_size, verbose=1)\nscore = log_loss(y_test, y_pred)\nprint('Score log loss:', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_class(model_v2, test_files, 101) # The model really performs badly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_class(model_v2, test_files, 1) # The model really performs badly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_class(model_v2, test_files, 143) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a vanilla CNN model with data augmentation\n\nHere I'm augmenting the previous model `classifier`, I'll use the data on which I want to train the model. The folder `train` includes the images I need. I'll generate more images using **ImageDataGenerator** and split the training data into 80% train and 20% validation split."},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -f saved_models/weights_best_vanilla.hdf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(rescale = 1.0/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True, \n                                   validation_split = 0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1.0/ 255, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_train_samples = x_train.shape[0]\nnb_validation_samples = x_test.shape[0]\nprint(nb_train_samples)\nprint(nb_validation_samples)\ntraining_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\nvalidation_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train the model with Data Augmentation\n\nUsing `fit_generator`, I'll train the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('saved_models/weights_best_vanilla.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nhistory_v3 = model_v2.fit_generator(training_generator,\n                         steps_per_epoch = nb_train_samples // batch_size,\n                         epochs = 5, \n                         callbacks=[es, checkpoint],\n                         verbose = 1,\n                         validation_data = validation_generator,\n                         validation_steps = nb_validation_samples // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v2.load_weights('saved_models/weights_best_vanilla.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_history(history_v3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the performance of the new model\nscore = model_v2.evaluate_generator(validation_generator, nb_validation_samples // batch_size)\nprint(\"Test Score:\", score[0])\nprint(\"Test Accuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_class(model_v2, test_files, 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_class(model_v2, test_files, 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_class(model_v2, test_files, 145) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_class(model_v2, test_files, 143) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model_v2.predict(test_files, batch_size=batch_size)\nFileLink(create_submission(predictions, test_targets, score[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The trained model achieved a validation accuracy of over 93%."},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -f saved_models/weights_best_vanilla.hdf5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train a CNN with Transfer Learning (VGG, MobileNet)"},{"metadata":{},"cell_type":"markdown","source":"To reduce training time without sacrificing accuracy, I'll train a CNN using **transfer learning**."},{"metadata":{"trusted":true},"cell_type":"code","source":"def vgg_std16_model(img_rows, img_cols, color_type=3):\n    nb_classes = 10\n    # Remove fully connected layer and replace\n    # with softmax for classifying 10 classes\n    vgg16_model = VGG16(weights=\"imagenet\", include_top=False)\n\n    # Freeze all layers of the pre-trained model\n    for layer in vgg16_model.layers:\n        layer.trainable = False\n        \n    x = vgg16_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    predictions = Dense(nb_classes, activation = 'softmax')(x)\n\n    model = Model(input = vgg16_model.input, output = predictions)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the VGG16 network\nprint(\"Loading network...\")\nmodel_vgg16 = vgg_std16_model(img_rows, img_cols)\n\nmodel_vgg16.summary()\n\nmodel_vgg16.compile(loss='categorical_crossentropy',\n                         optimizer='rmsprop',\n                         metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_generator = train_datagen.flow_from_directory('../input/train', \n                                                 target_size = (img_rows, img_cols), \n                                                 batch_size = batch_size,\n                                                 shuffle=True,\n                                                 class_mode='categorical', subset=\"training\")\n\nvalidation_generator = test_datagen.flow_from_directory('../input/train', \n                                                   target_size = (img_rows, img_cols), \n                                                   batch_size = batch_size,\n                                                   shuffle=False,\n                                                   class_mode='categorical', subset=\"validation\")\nnb_train_samples = 17943\nnb_validation_samples = 4481","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -f saved_models/weights_best_vgg16.hdf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the Vanilla Model\ncheckpoint = ModelCheckpoint('saved_models/weights_best_vgg16.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nhistory_v4 = model_vgg16.fit_generator(training_generator,\n                         steps_per_epoch = nb_train_samples // batch_size,\n                         epochs = 5, \n                         callbacks=[es, checkpoint],\n                         verbose = 1,\n                         class_weight='auto',\n                         validation_data = validation_generator,\n                         validation_steps = nb_validation_samples // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_vgg16.load_weights('saved_models/weights_best_vgg16.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_history(history_v4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_vgg16_test_class(model, test_files, image_number):\n    img_brute = test_files[image_number]\n\n    im = cv2.resize(cv2.cvtColor(img_brute, cv2.COLOR_BGR2RGB), (img_rows,img_cols)).astype(np.float32) / 255.0\n    im = np.expand_dims(im, axis =0)\n\n    img_display = cv2.resize(img_brute,(img_rows,img_cols))\n    plt.imshow(img_display, cmap='gray')\n\n    y_preds = model.predict(im, batch_size=batch_size, verbose=1)\n    print(y_preds)\n    y_prediction = np.argmax(y_preds)\n    print('Y Prediction: {}'.format(y_prediction))\n    print('Predicted as: {}'.format(activity_map.get('c{}'.format(y_prediction))))\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_vgg16_test_class(model_vgg16, test_files, 133) # Texting left","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_vgg16_test_class(model_vgg16, test_files, 29) # Texting left","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_vgg16_test_class(model_vgg16, test_files, 82) # Hair","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the performance of the new model\nscore = model_vgg16.evaluate_generator(validation_generator, nb_validation_samples // batch_size, verbose = 1)\nprint(\"Test Score:\", score[0])\nprint(\"Test Accuracy:\", score[1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}