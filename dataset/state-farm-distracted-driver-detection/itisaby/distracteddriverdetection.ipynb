{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing the necessary packages \n\nimport numpy as np\nimport pandas as pd\nimport os \nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport random\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import MaxPooling2D,Conv2D,Dense,Dropout,Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:16.396546Z","iopub.execute_input":"2022-03-11T12:28:16.397349Z","iopub.status.idle":"2022-03-11T12:28:18.130914Z","shell.execute_reply.started":"2022-03-11T12:28:16.397261Z","shell.execute_reply":"2022-03-11T12:28:18.130162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting up the data paths\n\nbase_dir = '../input/state-farm-distracted-driver-detection/' # base directory\nimages_dir = os.path.join(base_dir,'imgs/')                   # images directory\ntest_dir = os.path.join(base_dir,'imgs/test/')                # test directory\ntrain_dir = os.path.join(base_dir,'imgs/train/')              # train directory\n\ndriver_imgs_list = pd.read_csv(os.path.join(base_dir,'driver_imgs_list.csv'))  # images list csv \nsample_sub = pd.read_csv(os.path.join(base_dir,'sample_submission.csv'))       # sample submission","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:18.132112Z","iopub.execute_input":"2022-03-11T12:28:18.132358Z","iopub.status.idle":"2022-03-11T12:28:18.281262Z","shell.execute_reply.started":"2022-03-11T12:28:18.132326Z","shell.execute_reply":"2022-03-11T12:28:18.28057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets look the image details \ndriver_imgs_list.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:18.282785Z","iopub.execute_input":"2022-03-11T12:28:18.283952Z","iopub.status.idle":"2022-03-11T12:28:18.300814Z","shell.execute_reply.started":"2022-03-11T12:28:18.283912Z","shell.execute_reply":"2022-03-11T12:28:18.300138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking n unique classes avaliable \nclasses = driver_imgs_list['classname'].unique()\nclasses","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:18.303735Z","iopub.execute_input":"2022-03-11T12:28:18.304624Z","iopub.status.idle":"2022-03-11T12:28:18.313733Z","shell.execute_reply.started":"2022-03-11T12:28:18.304586Z","shell.execute_reply":"2022-03-11T12:28:18.312932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# keepsing some description for each class based on the driver position to have some clear idea \n\nclass_def = {'c0': 'safe driving',\n'c1': 'texting - right',\n'c2': 'talking on the phone - right',\n'c3': 'texting - left',\n'c4': 'talking on the phone - left',\n'c5': 'operating the radio',\n'c6': 'drinking',\n'c7': 'reaching behind',\n'c8': 'hair and makeup',\n'c9': 'talking to passenger'}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:18.315843Z","iopub.execute_input":"2022-03-11T12:28:18.316723Z","iopub.status.idle":"2022-03-11T12:28:18.322044Z","shell.execute_reply.started":"2022-03-11T12:28:18.316687Z","shell.execute_reply":"2022-03-11T12:28:18.321284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets check the class distribution \n\ndriver_imgs_list.groupby('classname')['img'].count().sort_values().plot(kind='bar')\nplt.ylabel('Images range')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:18.324012Z","iopub.execute_input":"2022-03-11T12:28:18.324945Z","iopub.status.idle":"2022-03-11T12:28:18.57827Z","shell.execute_reply.started":"2022-03-11T12:28:18.324905Z","shell.execute_reply":"2022-03-11T12:28:18.577446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,18)) # image size\ncols,rows = 5,4                   \n\nfor i in range(1,cols*rows+1):\n    pic_indx = random.randint(0,driver_imgs_list.shape[0])\n    img = Image.open(os.path.join(base_dir,'imgs/train/')+str(driver_imgs_list.loc[pic_indx,'classname']+'/')\n                    + str(driver_imgs_list.loc[pic_indx,'img']))\n    fig.add_subplot(rows,cols,i)\n    plt.imshow(img)\n    plt.title('State of Driving :'+ class_def[driver_imgs_list.loc[pic_indx,'classname']])\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:18.580324Z","iopub.execute_input":"2022-03-11T12:28:18.581207Z","iopub.status.idle":"2022-03-11T12:28:20.845757Z","shell.execute_reply.started":"2022-03-11T12:28:18.581163Z","shell.execute_reply":"2022-03-11T12:28:20.844479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# size of each image\n\nimg = Image.open('../input/state-farm-distracted-driver-detection/imgs/test/img_1.jpg')\nprint(img.size)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:20.847457Z","iopub.execute_input":"2022-03-11T12:28:20.853541Z","iopub.status.idle":"2022-03-11T12:28:20.861944Z","shell.execute_reply.started":"2022-03-11T12:28:20.853494Z","shell.execute_reply":"2022-03-11T12:28:20.861122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating the train data generator and test data generator\n \nimage_size = (128,128)  # image shape\nbatch_size = 32\nval_size = 0.2\n\ntrain_data_gen = ImageDataGenerator(rescale=1./127,validation_split= val_size)\ntest_data_gen = ImageDataGenerator(rescale=1./127)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:20.863374Z","iopub.execute_input":"2022-03-11T12:28:20.864473Z","iopub.status.idle":"2022-03-11T12:28:20.873466Z","shell.execute_reply.started":"2022-03-11T12:28:20.864432Z","shell.execute_reply":"2022-03-11T12:28:20.872585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining the training parameters\n\n\ntrain_generator = train_data_gen.flow_from_directory(train_dir,\n                                                     target_size = image_size,\n                                                     batch_size = batch_size,\n                                                     seed=42, \n                                                     shuffle=True,\n                                                     subset='training')\n\nval_generator =  train_data_gen.flow_from_directory(train_dir,\n                                               target_size = image_size,\n                                               batch_size = batch_size,\n                                               seed=42, \n                                               shuffle=True,\n                                               subset='validation')","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:20.875534Z","iopub.execute_input":"2022-03-11T12:28:20.876547Z","iopub.status.idle":"2022-03-11T12:28:26.007841Z","shell.execute_reply.started":"2022-03-11T12:28:20.876508Z","shell.execute_reply":"2022-03-11T12:28:26.007011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the data for one batch\n\nfor data_batch,label_batch in train_generator:\n    print(data_batch.shape)   # train batch\n    print(label_batch.shape)  # label batch\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:26.009461Z","iopub.execute_input":"2022-03-11T12:28:26.010564Z","iopub.status.idle":"2022-03-11T12:28:26.181909Z","shell.execute_reply.started":"2022-03-11T12:28:26.010524Z","shell.execute_reply":"2022-03-11T12:28:26.181055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()                                                  # creating a sequential model\nmodel.add(Conv2D(32,(3,3),activation='relu',input_shape=(128,128,3))) # taking units of 32 and filter of 3x3\nmodel.add(MaxPooling2D(2,2))                                          # maxpool layer with 2x2 filter   \nmodel.add(Conv2D(64,(3,3),activation='relu'))                         # taking units of 64 and filter of 3x3\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(128,(3,3),activation='relu'))                        # taking units of 128 and filter of 3x3\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(256,(3,3),activation='relu'))                        # taking units of 256 and filter of 3x3\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(512,(3,3),activation='relu'))                        # taking units of 512 and filter of 3x3\nmodel.add(MaxPooling2D(2,2))    \nmodel.add(Flatten())                                                  # flattening the data to feed into to Dense layer\nmodel.add(Dense(1024,activation='relu'))                              # taking units of 1024\nmodel.add(Dense(512,activation='relu'))                               # taking units of 512 \nmodel.add(Dense(128,activation='relu'))                               # taking units of 128\nmodel.add(Dense(10,activation='softmax'))                             # output later with units of 10 since 10 labels\n\nmodel.summary() # to print summary of model architecture","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:26.183564Z","iopub.execute_input":"2022-03-11T12:28:26.184725Z","iopub.status.idle":"2022-03-11T12:28:27.280543Z","shell.execute_reply.started":"2022-03-11T12:28:26.184558Z","shell.execute_reply":"2022-03-11T12:28:27.279805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile('adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:27.284492Z","iopub.execute_input":"2022-03-11T12:28:27.285147Z","iopub.status.idle":"2022-03-11T12:28:27.301055Z","shell.execute_reply.started":"2022-03-11T12:28:27.285108Z","shell.execute_reply":"2022-03-11T12:28:27.300358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\n\nhistory = model.fit(train_generator,\n         steps_per_epoch=240,\n         epochs=epochs,\n         validation_data=val_generator,\n         validation_steps=60\n        )","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:28:27.302816Z","iopub.execute_input":"2022-03-11T12:28:27.30381Z","iopub.status.idle":"2022-03-11T12:39:19.348971Z","shell.execute_reply.started":"2022-03-11T12:28:27.303773Z","shell.execute_reply":"2022-03-11T12:39:19.347976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('distracted_driver_acc98.h5')","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:39:19.350488Z","iopub.execute_input":"2022-03-11T12:39:19.351256Z","iopub.status.idle":"2022-03-11T12:39:19.492638Z","shell.execute_reply.started":"2022-03-11T12:39:19.351213Z","shell.execute_reply":"2022-03-11T12:39:19.491859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_loss = history.history['loss']\ntr_accuracy = history.history['accuracy']\n\nval_loss = history.history['val_loss']\nval_accuracy = history.history['val_accuracy']","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:39:19.494161Z","iopub.execute_input":"2022-03-11T12:39:19.494509Z","iopub.status.idle":"2022-03-11T12:39:19.50033Z","shell.execute_reply.started":"2022-03-11T12:39:19.49447Z","shell.execute_reply":"2022-03-11T12:39:19.499409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epchs = list(range(1,len(tr_loss)+1))\nplt.plot(epchs,tr_loss,label='Train')\nplt.plot(epchs,val_loss,label='Test')\nplt.title(\"Training and Validation loss\")\nplt.legend()\nplt.show()\n\n\nplt.plot(epchs,tr_accuracy,label='Train')\nplt.plot(epchs,val_accuracy,label='Test')\nplt.title(\"Training and Validation accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:39:19.502193Z","iopub.execute_input":"2022-03-11T12:39:19.503003Z","iopub.status.idle":"2022-03-11T12:39:19.872604Z","shell.execute_reply.started":"2022-03-11T12:39:19.502966Z","shell.execute_reply":"2022-03-11T12:39:19.871916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntest_data = test_gen.flow_from_directory(\n    images_dir,\n    shuffle = False,\n    target_size = image_size,\n    classes = ['test'],\n    batch_size = 32\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:39:19.873824Z","iopub.execute_input":"2022-03-11T12:39:19.874211Z","iopub.status.idle":"2022-03-11T12:40:15.08832Z","shell.execute_reply.started":"2022-03-11T12:39:19.874176Z","shell.execute_reply":"2022-03-11T12:40:15.087618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T12:51:48.03109Z","iopub.execute_input":"2022-03-11T12:51:48.031661Z","iopub.status.idle":"2022-03-11T12:57:51.534442Z","shell.execute_reply.started":"2022-03-11T12:51:48.031621Z","shell.execute_reply":"2022-03-11T12:57:51.533586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predictions on one batch of images\n\nfor data_batch,label_batch in test_data:\n#     print(data_batch.shape,label_batch.shape)\n    print(model.predict(data_batch).argmax(axis=1))\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-11T13:05:21.164648Z","iopub.execute_input":"2022-03-11T13:05:21.165246Z","iopub.status.idle":"2022-03-11T13:05:21.44986Z","shell.execute_reply.started":"2022-03-11T13:05:21.165211Z","shell.execute_reply":"2022-03-11T13:05:21.44556Z"},"trusted":true},"execution_count":null,"outputs":[]}]}