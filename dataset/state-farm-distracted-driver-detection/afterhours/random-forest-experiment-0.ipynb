{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import os\nimport pandas\nimport random\nimport sklearn\nimport sklearn.ensemble\nimport scipy.ndimage\nimport scipy.misc"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n## Notebook configuration\n\ntrain_dir = '../input/train/'\ntest_dir = '../input/test/'\nchunklen = 500  # Used for sample data and for generator calls\nn_jobs = -1  # Used for multiprocessing in model fitting "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"## Set up the model for learning from examples\n\n# A warm start lets us iterate over parts of the data in memory each time\n# A regressor lets us predict probabilities\nregr = sklearn.ensemble.RandomForestRegressor(n_estimators=100, \n                                             warm_start = True, \n                                             n_jobs=n_jobs)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def build_imagepairs(imagedir):\n    '''\n    Walk a directory structure containing ~/class/[bunch_of_images] and produce\n    a big list of [image_name, class]\n    '''\n\n    imagestruct = os.walk(imagedir)\n    pairs = []\n    classids = []\n\n    for (dirpath, dirnames, filenames) in imagestruct:\n        if dirnames != []:\n            continue\n\n        classid = int(dirpath.split('/')[-1][1:])\n        imagenames = filenames\n        fullnames = [dirpath + '/' + fname for fname in filenames]\n        pairs += [(fn, classid) for fn in fullnames]\n\n        classids.append(classid)\n        # print(classid, end=', ')\n\n    # print(len(pairs))\n    return(pairs, classids)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"## Training data loading, shuffling and class id generation\n\ntrain_pairs, labels = build_imagepairs(train_dir)\nrandom.shuffle(train_pairs)\nX_train, Y_train = zip(*train_pairs)\ntrain_df = pandas.DataFrame({'imagename': X_train, 'label': Y_train})\nlabel_ids = pandas.get_dummies(train_df['label'], prefix=\"class\")\ntrain_df = pandas.concat([train_df, label_ids], axis=1)\nnum_labels = len(label_ids.columns)\nprint(len(train_pairs))\nprint(num_labels)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def chunkify(some_list, chunklen):\n    i = 0\n    maxlen = len(some_list)\n    \n    while i < maxlen:\n        if i + chunklen > maxlen:\n            chunklen = maxlen - i\n\n        yield some_list[i:i+chunklen]\n        i+= chunklen"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def load_data(images):\n    \n    data = [scipy.ndimage.imread(x, flatten=True) for x in images]\n    data = [scipy.misc.imresize(x, (128, 128)) for x in data]\n    data = [x.reshape(-1) for x in data]    \n    return data"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"g = chunkify(train_df, chunklen)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"i = 0\nfor chunk in g:\n    imagedata = load_data(chunk['imagename'])\n    class_probs = chunk[label_ids.columns]\n    regr.fit(imagedata, class_probs)\n    i += chunklen\n    percent = i / len(train_pairs)\n    progress = \"{} {}\".format(i, percent)\n    #print(progress)\n    print('{.2f}'.format(percent), end=', ')\nprint(\"complete\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"X_valid_names = os.listdir(test_dir)\nrandom.shuffle(X_valid_names)\nprint(len(X_valid_names))\nX_valid_names[:3]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"## Break up the test data into chunks and make predictions\n\ng = chunkify(X_valid_names, chunklen)\n\nnum_total = len(X_valid_names)\nall_values = []\ni = 0\nprint(i)\nfor chunk in g:\n\n    if not chunk:\n        print(\"no valid subset...\")\n        continue    \n        \n    fullnames = [test_dir + n for n in chunk]        \n    imagedata = load_data(fullnames)\n    preds = regr.predict(imagedata)\n    \n    values = zip(chunk, preds)\n    all_values += values\n    num_complete = len(all_values)\n    status = \"{} of {} complete, {.2f} percent\".format(num_complete, \n                                                    num_total, \n                                                    num_complete / num_total)\n    print(status, end=', ')\n\nprint(\"complete\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(all_values[:3])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"outfname = 'random_forest_exp_1.csv'\noutfile = open(outfname, 'w')\n\nfirst = ','.join(['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']) + '\\n'\n\noutfile.write(first)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"for imagename, probs in all_values:\n    probs = ','.join([str(p) for p in probs])\n    line = imagename + ',' + probs + '\\n'\n    outfile.write(line)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"outfile.close()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}