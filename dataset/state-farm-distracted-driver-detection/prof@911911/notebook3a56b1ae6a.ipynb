{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nfrom keras.preprocessing.text import one_hot                              #for one_hot encoding labels(not used)\nfrom keras.utils.np_utils import to_categorical                           # for one_hot encoding labels\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential                                        #importing Sequential model\nfrom keras.optimizers import Adam                                          #Importing Adam Optimizer\n\nimport os\nimport cv2                                                                 #Read Image using myCv\nimport glob  \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n\nfrom keras.losses import CategoricalCrossentropy                           #for loss function\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt                                            #for plotting images and to display variations\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing Required Data from Kaggle Kernels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_Train_Images = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train/\"\npath_test_Images =  \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test/\"              #Path for importing train and test imgs\n\ndef prepare_Data(path): \n    imgsList = []\n    labels = []\n    for directory in sorted(glob.glob(os.path.join(path, '*')), key = lambda k: k.split(\"/\")[-1]): #Exploring image directories\n            for imgs in glob.glob(os.path.join(directory,'*.jpg')):                                #provided by kaggle kernel \n                img_cv = cv2.imread(imgs)                                                          #using glob path expansion \n                img_cv_r = cv2.resize(img_cv,(128,128))                                            #Ref Tutorial Points and kaggle\n                imgsList.append(img_cv_r)                                                          #Creating List of resized images\n                labels.append(int(directory.split(\"/\")[-1].replace('c','')))\n    \n    X_Train, X_Test, Y_Train, Y_Test =  train_test_split(imgsList,labels, test_size = 0.2)         #Splitting on 8:2 ratio\n    Y_Train = tf.keras.utils.to_categorical(Y_Train, num_classes=10)                               #one_hot labels with depth=10\n    Y_Test = tf.keras.utils.to_categorical(Y_Test, num_classes=10)\n\n    return np.array(X_Train), np.array(X_Test), Y_Train, Y_Test                                    #Returning Prepared Data\n\n\n\n#List of Images for Train and Test                                                               \nX_Train, X_Test, Y_Train, Y_Test = prepare_Data(path_Train_Images)\n\nprint(\"X_Train: {} ,Y_Train: {}\".format(len(X_Train),len(Y_Train)))\nprint(\"X_Test: {},Y_Test: {}\".format(len(X_Test),len(Y_Test)))                                     #Printing output values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_Train))\nprint(X_Train[100].shape)\nimg = X_Train[100]\n\nRGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #Refr:\"https://note.nkmk.me/en/python-opencv-bgr-rgb-cvtcolor/\"\nplt.imshow(RGB_img)                           #Converting BGR to RBG using cv2 and plotting the image of 100th trainind data\nplt.show()\nprint(\"Class for  {} is :\".format(Y_Train[100]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential()             #Model: Sequential \n\nmodel.add(keras.layers.InputLayer(            #Input Layer with 3 channels\n    input_shape=(128, 128, 3)\n))\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters=32,\n        kernel_size=(5,5),                    #Conv_1 Layer  with 32 units\n        strides = (1,1),\n        padding='same',\n        activation='relu',\n        name='Conv_1'))\n\nmodel.add(\n    keras.layers.MaxPool2D(                   #Refr:\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\"\n        pool_size = (2,2),                    #Pooling Layer 1\n        name = 'Pool_1'))                     #Image: 64*64*32\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 64,\n        kernel_size = (5,5),\n        strides = (1,1),\n        padding = 'same',                     #Conv_2 layer with 64 units\n        activation = 'relu',\n        name = 'Conv_2'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),                    #Pooling Layer 2\n        name = 'Pool_2'))                     #Image_size: 64*32*32(64 filters,image_size 32*32)\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 128,\n        kernel_size = (5,5),\n        strides = (1,1),\n        padding = 'same',                     #Conv_3 Layer\n        activation = 'relu',\n        name = 'Conv_3'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),                    #Pooling Layer 3 \n        name = 'Pool_3'))                     #Image_size:16*16*128\n\nmodel.add(\n    keras.layers.Conv2D(\n        filters = 256,            \n        kernel_size = (5,5),                  #Conv_3 Layer\n        strides = (1,1),\n        padding = 'same',\n        activation = 'relu',\n        name = 'Conv_4'))\n\nmodel.add(\n    keras.layers.MaxPool2D(\n        pool_size = (2,2),\n        name = 'Pool_4'))                     #Image_size: 8*8*256\n\nmodel.add(keras.layers.Flatten())             #Flattening before entering Hidden Layer or # reshape(-1,16,16,256)\n\nmodel.add(keras.layers.Dense(units=1024, activation='relu',name = 'hidden_1'))\n\nmodel.add(keras.layers.Dropout(rate=0.2))     #Refr:\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\"\n                                              #Reduces Noise to prevent overfitting according to tensorflow\n\nmodel.add(keras.layers.Dense(units=512, activation='relu',name = 'hidden_2'))\n\nmodel.add(keras.layers.Dense(units=10,activation='softmax',name = 'hidden_3'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting the model using respective optimizers\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False), metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = model.fit(x = X_Train, y= Y_Train, epochs = 10, batch_size = 500, verbose = 1,validation_split=0.2) #verbose=1 to see how epochcs to run","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss_values, test_data_accuracy = model.evaluate(X_Test, Y_Test, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'image':[],'label_0':[], 'label_1':[],'label_2':[], 'label_3':[], 'label_4':[],'label_5':[], 'label_6':[], 'label_7':[], 'label_8':[], 'label_9':[]})\n\ndef represent_predicted_(path_of_Images,df):\n    \n    for imgs in glob.glob(os.path.join(path_of_Images,'*.jpg')):\n        \n        img_cv = cv2.imread(imgs)\n        img_cv_r = cv2.resize(img_cv,(128,128))\n        \n        img_cv_predict = np.reshape(img_cv_r,[1,128,128,3])\n        arr_predict = model.predict(img_cv_predict,batch_size = 1)         #predicting for each and evry image and one_hot encoding\n        #print(imgs.split('/')[-1])                                        # representation of predictions of labels\n        df = df.append( \n            {\n                'image':imgs.split('/')[-1],\n                'label_0':round(arr_predict[0][0],2), \n                'label_1':round(arr_predict[0][1],2),\n                'label_2':round(arr_predict[0][2],2),                      #values rounding off to 2 decimal points\n                'label_3':round(arr_predict[0][3],2),                      #for better representation (avoiding in exponential form)\n                'label_4':round(arr_predict[0][4],2),\n                'label_5':round(arr_predict[0][5],2),\n                'label_6':round(arr_predict[0][6],2),\n                'label_7':round(arr_predict[0][7],2),\n                'label_8':round(arr_predict[0][8],2),\n                'label_9':round(arr_predict[0][9],2)\n            },\n            ignore_index=True\n        )\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_test_Images =  \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test/\"\ndf = represent_predicted_(path_test_Images,df)    #Dataframe Containing Images and their predicitons","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)\ndf.head(50)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}