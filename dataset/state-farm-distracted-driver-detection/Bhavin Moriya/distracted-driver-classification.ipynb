{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport skimage\nfrom skimage.feature import greycomatrix, greycoprops\nfrom skimage.filters import sobel\nfrom skimage import color\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom keras import layers\nimport keras.backend as K\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing import image\nfrom keras.layers import Input, Dense, Activation, Dropout\nfrom keras.layers import Flatten, BatchNormalization, Conv2D\nfrom keras.layers import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D \nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.applications.vgg19 import VGG19\n\nfrom PIL import Image\nfrom tqdm import tqdm\nimport random as rnd\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom numpy import expand_dims\npd.set_option('display.max_colwidth', -1)\n\n!pip install livelossplot\nfrom livelossplot import PlotLossesKeras\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:36.051394Z","iopub.execute_input":"2022-04-04T13:20:36.051816Z","iopub.status.idle":"2022-04-04T13:20:52.710291Z","shell.execute_reply.started":"2022-04-04T13:20:36.051728Z","shell.execute_reply":"2022-04-04T13:20:52.709482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Dataset\nWe'll use here the Pandas to load the dataset into memory","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ntrain_df['path'] = '../input/state-farm-distracted-driver-detection/imgs/train/' + train_df['classname']+ '/' +train_df['img']\npred_df = pd.read_csv('../input/state-farm-distracted-driver-detection/sample_submission.csv')\npred_df['path'] = '../input/state-farm-distracted-driver-detection/imgs/test/' + pred_df['img']","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:52.71244Z","iopub.execute_input":"2022-04-04T13:20:52.712717Z","iopub.status.idle":"2022-04-04T13:20:52.925689Z","shell.execute_reply.started":"2022-04-04T13:20:52.712684Z","shell.execute_reply":"2022-04-04T13:20:52.924975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:52.927103Z","iopub.execute_input":"2022-04-04T13:20:52.927348Z","iopub.status.idle":"2022-04-04T13:20:52.946279Z","shell.execute_reply.started":"2022-04-04T13:20:52.927314Z","shell.execute_reply":"2022-04-04T13:20:52.945643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.count()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:52.948581Z","iopub.execute_input":"2022-04-04T13:20:52.948994Z","iopub.status.idle":"2022-04-04T13:20:52.96575Z","shell.execute_reply.started":"2022-04-04T13:20:52.948958Z","shell.execute_reply":"2022-04-04T13:20:52.964986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train samples count: ', len(train_df))\ntrain_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:52.967052Z","iopub.execute_input":"2022-04-04T13:20:52.967398Z","iopub.status.idle":"2022-04-04T13:20:52.976671Z","shell.execute_reply.started":"2022-04-04T13:20:52.967362Z","shell.execute_reply":"2022-04-04T13:20:52.975627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Class Count: ',len(train_df['classname'].value_counts()))\ntrain_df['classname'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:52.978095Z","iopub.execute_input":"2022-04-04T13:20:52.978536Z","iopub.status.idle":"2022-04-04T13:20:52.998186Z","shell.execute_reply.started":"2022-04-04T13:20:52.978499Z","shell.execute_reply":"2022-04-04T13:20:52.997482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking missing data\nLets check if there is any missing values in our dataset","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:53.000946Z","iopub.execute_input":"2022-04-04T13:20:53.001178Z","iopub.status.idle":"2022-04-04T13:20:53.018253Z","shell.execute_reply.started":"2022-04-04T13:20:53.001149Z","shell.execute_reply":"2022-04-04T13:20:53.017524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization\nLooking at some random beauties\nIt's a great deal of fun to explore the data and play around with matplotlib","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15,12))\nfor idx,i in enumerate(train_df.classname.unique()):\n    plt.subplot(4,7,idx+1)\n    df = train_df[train_df['classname'] ==i].reset_index(drop = True)\n    image_path = df.loc[rnd.randint(0, len(df))-1,'path']\n    img = Image.open(image_path)\n    img = img.resize((224,224))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(i)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:53.019471Z","iopub.execute_input":"2022-04-04T13:20:53.019709Z","iopub.status.idle":"2022-04-04T13:20:53.844272Z","shell.execute_reply.started":"2022-04-04T13:20:53.019677Z","shell.execute_reply":"2022-04-04T13:20:53.843423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_species(df,class_name):\n    plt.figure(figsize = (12,12))\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    plt.suptitle(class_name)\n    for idx,i in enumerate(np.random.choice(train_df['path'],32)):\n        plt.subplot(8,8,idx+1)\n        image_path = i\n        img = Image.open(image_path)\n        img = img.resize((224,224))\n        plt.imshow(img)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:53.845195Z","iopub.execute_input":"2022-04-04T13:20:53.845413Z","iopub.status.idle":"2022-04-04T13:20:53.854251Z","shell.execute_reply.started":"2022-04-04T13:20:53.845384Z","shell.execute_reply":"2022-04-04T13:20:53.853289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_ in train_df['classname'].unique():\n    #print('\\n\\n')\n    plot_species(train_df , class_)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:20:53.857848Z","iopub.execute_input":"2022-04-04T13:20:53.85833Z","iopub.status.idle":"2022-04-04T13:21:12.58856Z","shell.execute_reply.started":"2022-04-04T13:20:53.858295Z","shell.execute_reply":"2022-04-04T13:21:12.587846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Distribution AnalysisÂ¶\nIn this section we will be analyzing the number of training and test samples in each class. It will give us a better understanding of our dataset and provide us the necessary information to preprocess our dataset before the training phase.","metadata":{}},{"cell_type":"code","source":"plot = sns.countplot(x = train_df['classname'], color = '#2596be')\nsns.set(rc={'figure.figsize':(30,25)})\nsns.despine()\nplot.set_title('Class Distribution\\n', font = 'serif', x = 0.1, y=1, fontsize = 18);\nplot.set_ylabel(\"Count\", x = 0.02, font = 'serif', fontsize = 12)\nplot.set_xlabel(\"Driver classes\", fontsize = 15, font = 'serif')\n\nfor p in plot.patches:\n    plot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2, p.get_height()), \n       ha = 'center', va = 'center', xytext = (0, -20),font = 'serif', textcoords = 'offset points', size = 15)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:21:12.589942Z","iopub.execute_input":"2022-04-04T13:21:12.590382Z","iopub.status.idle":"2022-04-04T13:21:12.882482Z","shell.execute_reply.started":"2022-04-04T13:21:12.590344Z","shell.execute_reply":"2022-04-04T13:21:12.881808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Resolutions","metadata":{}},{"cell_type":"code","source":"widths, heights = [], []\n\nfor path in tqdm(train_df[\"path\"]):\n    width, height = Image.open(path).size\n    widths.append(width)\n    heights.append(height)\n    \ntrain_df[\"width\"] = widths\ntrain_df[\"height\"] = heights\ntrain_df[\"dimension\"] = train_df[\"width\"] * train_df[\"height\"]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:21:12.883568Z","iopub.execute_input":"2022-04-04T13:21:12.885082Z","iopub.status.idle":"2022-04-04T13:23:10.22404Z","shell.execute_reply.started":"2022-04-04T13:21:12.885041Z","shell.execute_reply":"2022-04-04T13:23:10.222821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets see some small images**","metadata":{}},{"cell_type":"code","source":"train_df.sort_values('width').head(84)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:23:10.225412Z","iopub.execute_input":"2022-04-04T13:23:10.22567Z","iopub.status.idle":"2022-04-04T13:23:10.246534Z","shell.execute_reply.started":"2022-04-04T13:23:10.225636Z","shell.execute_reply":"2022-04-04T13:23:10.245836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Color Analysis\nWe need to do some color analysis to get an ida about the augmentation technique needed for this problem","metadata":{}},{"cell_type":"code","source":"def is_grey_scale(givenImage):\n    w,h = givenImage.size\n    for i in range(w):\n        for j in range(h):\n            r,g,b = givenImage.getpixel((i,j))\n            if r != g != b: return False\n    return True","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:23:10.247627Z","iopub.execute_input":"2022-04-04T13:23:10.247951Z","iopub.status.idle":"2022-04-04T13:23:10.255144Z","shell.execute_reply.started":"2022-04-04T13:23:10.247899Z","shell.execute_reply":"2022-04-04T13:23:10.25428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check color scale of Train images**","metadata":{}},{"cell_type":"code","source":"sampleFrac = 0.1\n#get our sampled images\nisGreyList = []\nfor imageName in train_df['path'].sample(frac=sampleFrac):\n    val = Image.open(imageName).convert('RGB')\n    isGreyList.append(is_grey_scale(val))\nprint(np.sum(isGreyList) / len(isGreyList))\ndel isGreyList","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:23:10.256335Z","iopub.execute_input":"2022-04-04T13:23:10.256712Z","iopub.status.idle":"2022-04-04T13:23:20.033914Z","shell.execute_reply.started":"2022-04-04T13:23:10.256619Z","shell.execute_reply":"2022-04-04T13:23:20.033173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check color scale of Test images**","metadata":{}},{"cell_type":"code","source":"sampleFrac = 0.1\n#get our sampled images\nisGreyList_test = []\nfor imageName in pred_df['path'].sample(frac=sampleFrac):\n    val = Image.open(imageName).convert('RGB')\n    isGreyList_test.append(is_grey_scale(val))\nprint(np.sum(isGreyList_test) / len(isGreyList_test))\ndel isGreyList_test","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:23:20.035286Z","iopub.execute_input":"2022-04-04T13:23:20.035759Z","iopub.status.idle":"2022-04-04T13:24:25.590687Z","shell.execute_reply.started":"2022-04-04T13:23:20.035718Z","shell.execute_reply":"2022-04-04T13:24:25.589955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get mean intensity for each channel RGB**","metadata":{}},{"cell_type":"code","source":"def get_rgb_men(row):\n    img = cv2.imread(row['path'])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return np.sum(img[:,:,0]), np.sum(img[:,:,1]), np.sum(img[:,:,2])\n\ntqdm.pandas()\ntrain_df['R'], train_df['G'], train_df['B'] = zip(*train_df.progress_apply(lambda row: get_rgb_men(row), axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:24:25.591968Z","iopub.execute_input":"2022-04-04T13:24:25.592227Z","iopub.status.idle":"2022-04-04T13:26:49.257532Z","shell.execute_reply.started":"2022-04-04T13:24:25.592189Z","shell.execute_reply":"2022-04-04T13:26:49.256734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_color_dist(df, count):\n    fig, axr = plt.subplots(count,2,figsize=(15,15))\n    if df.empty:\n        print(\"Image internsity of selected color is weak\")\n        return\n    for idx, i in enumerate(np.random.choice(df['path'], count)):\n        img = cv2.imread(i)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axr[idx,0].imshow(img)\n        axr[idx,0].axis('off')\n        axr[idx,1].set_title('R={:.0f}, G={:.0f}, B={:.0f} '.format(np.mean(img[:,:,0]), np.mean(img[:,:,1]), np.mean(img[:,:,2]))) \n        x, y = np.histogram(img[:,:,0], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='R', alpha=0.8, color='red')\n        x, y = np.histogram(img[:,:,1], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='G', alpha=0.8, color='green')\n        x, y = np.histogram(img[:,:,2], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='B', alpha=0.8, color='blue')\n        axr[idx,1].legend()\n        axr[idx,1].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:26:49.258747Z","iopub.execute_input":"2022-04-04T13:26:49.260087Z","iopub.status.idle":"2022-04-04T13:26:49.270521Z","shell.execute_reply.started":"2022-04-04T13:26:49.260045Z","shell.execute_reply":"2022-04-04T13:26:49.269756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Red images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[((train_df['B']) < train_df['R']) & ((train_df['G']) < train_df['R'])]\nshow_color_dist(df, 2)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:26:49.271584Z","iopub.execute_input":"2022-04-04T13:26:49.27189Z","iopub.status.idle":"2022-04-04T13:26:49.93902Z","shell.execute_reply.started":"2022-04-04T13:26:49.271854Z","shell.execute_reply":"2022-04-04T13:26:49.938368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Green images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[(train_df['G'] > train_df['R']) & (train_df['G'] > train_df['B'])]\nshow_color_dist(df, 8)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:26:49.940203Z","iopub.execute_input":"2022-04-04T13:26:49.940516Z","iopub.status.idle":"2022-04-04T13:27:07.266338Z","shell.execute_reply.started":"2022-04-04T13:26:49.940479Z","shell.execute_reply":"2022-04-04T13:27:07.263057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Blue images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[(train_df['B'] > train_df['R']) & (train_df['B'] > train_df['G'])]\nshow_color_dist(df, 8)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:27:07.267773Z","iopub.execute_input":"2022-04-04T13:27:07.26826Z","iopub.status.idle":"2022-04-04T13:27:24.598437Z","shell.execute_reply.started":"2022-04-04T13:27:07.268222Z","shell.execute_reply":"2022-04-04T13:27:24.597766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyzing Edges\nA Sobel filter is one means of getting a basic edge magnitude/gradient image. Can be useful to threshold and find prominent linear features, etc. Several other similar filters in skimage.filters are also good edge detectors: roberts, scharr, etc. and you can control direction, i.e. use an anisotropic version.","metadata":{}},{"cell_type":"markdown","source":"### Defective","metadata":{}},{"cell_type":"code","source":"def edges_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(train_df['path'],4)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        edges = sobel(image)\n        gray_edges=sobel(gray)\n        dimension = edges.shape\n        fig = plt.figure(figsize=(8, 8))\n        plt.suptitle(class_name)\n        plt.subplot(2,2,1)\n        plt.imshow(gray_edges)\n        plt.subplot(2,2,2)\n        plt.imshow(edges[:dimension[0],:dimension[1],0], cmap=\"gray\")\n        plt.subplot(2,2,3)\n        plt.imshow(edges[:dimension[0],:dimension[1],1], cmap='gray')\n        plt.subplot(2,2,4)\n        plt.imshow(edges[:dimension[0],:dimension[1],2], cmap='gray')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:27:24.599698Z","iopub.execute_input":"2022-04-04T13:27:24.600149Z","iopub.status.idle":"2022-04-04T13:27:24.610821Z","shell.execute_reply.started":"2022-04-04T13:27:24.600111Z","shell.execute_reply":"2022-04-04T13:27:24.609715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def edges_images_white(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(train_df['path'],4)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        edges = sobel(image)\n        gray_edges=sobel(gray)\n        dimension = edges.shape\n        fig = plt.figure(figsize=(8, 8))\n        plt.suptitle(class_name)\n        plt.subplot(2,2,1)\n        plt.imshow(gray_edges)\n        plt.subplot(2,2,2)\n        plt.imshow(edges[:dimension[0],:dimension[1],0], cmap=\"BuGn\")\n        plt.subplot(2,2,3)\n        plt.imshow(edges[:dimension[0],:dimension[1],1], cmap='BuGn')\n        plt.subplot(2,2,4)\n        plt.imshow(edges[:dimension[0],:dimension[1],2], cmap='BuGn')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:27:24.612172Z","iopub.execute_input":"2022-04-04T13:27:24.612552Z","iopub.status.idle":"2022-04-04T13:27:24.624656Z","shell.execute_reply.started":"2022-04-04T13:27:24.612514Z","shell.execute_reply":"2022-04-04T13:27:24.623969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    edges_images_gray(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:27:24.626184Z","iopub.execute_input":"2022-04-04T13:27:24.626738Z","iopub.status.idle":"2022-04-04T13:27:55.005519Z","shell.execute_reply.started":"2022-04-04T13:27:24.626698Z","shell.execute_reply":"2022-04-04T13:27:55.004787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    edges_images_white(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:27:55.006975Z","iopub.execute_input":"2022-04-04T13:27:55.007433Z","iopub.status.idle":"2022-04-04T13:28:25.277476Z","shell.execute_reply.started":"2022-04-04T13:27:55.00739Z","shell.execute_reply":"2022-04-04T13:28:25.276777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HSV Transform\nSince this contest is about time series ordering, I think it's possible there may be useful information in a transform to HSV color space. HSV is useful for identifying shadows and illumination, as well as giving us a means to identify similar objects that are distinct by color between scenes (hue), though there's no guarantee the hue will be stable.","metadata":{}},{"cell_type":"code","source":"def hsv_images(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(train_df['path'],4)):  \n        image = cv2.imread(i)\n        hsv = color.rgb2hsv(image)\n        dimension = hsv.shape\n        fig = plt.figure(figsize=(8, 8))\n        plt.suptitle(class_name)\n        plt.subplot(2,2,1)\n        plt.imshow(image)\n        plt.subplot(2,2,2)\n        plt.imshow(hsv[:dimension[0],:dimension[1],0], cmap=\"PuBuGn\")\n        plt.subplot(2,2,3)\n        plt.imshow(hsv[:dimension[0],:dimension[1],1], cmap='PuBuGn')\n        plt.subplot(2,2,4)\n        plt.imshow(hsv[:dimension[0],:dimension[1],2], cmap='PuBuGn')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:28:25.278785Z","iopub.execute_input":"2022-04-04T13:28:25.279243Z","iopub.status.idle":"2022-04-04T13:28:25.288816Z","shell.execute_reply.started":"2022-04-04T13:28:25.279207Z","shell.execute_reply":"2022-04-04T13:28:25.287978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    hsv_images(class_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:28:25.289877Z","iopub.execute_input":"2022-04-04T13:28:25.290216Z","iopub.status.idle":"2022-04-04T13:28:56.111887Z","shell.execute_reply.started":"2022-04-04T13:28:25.290179Z","shell.execute_reply":"2022-04-04T13:28:56.111267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Augmentations","metadata":{}},{"cell_type":"code","source":"def plot_augimages(paths, datagen):\n    plt.figure(figsize = (14,28))\n    plt.suptitle('Augmented Images')\n    \n    midx = 0\n    for path in paths:\n        data = Image.open(path)\n        data = data.resize((224,224))\n        samples = expand_dims(data, 0)\n        it = datagen.flow(samples, batch_size=1)\n    \n        # Show Original Image\n        plt.subplot(10,5, midx+1)\n        plt.imshow(data)\n        plt.axis('off')\n    \n        # Show Augmented Images\n        for idx, i in enumerate(range(4)):\n            midx += 1\n            plt.subplot(10,5, midx+1)\n            \n            batch = it.next()\n            image = batch[0].astype('uint8')\n            plt.imshow(image)\n            plt.axis('off')\n        midx += 1\n    \n    plt.tight_layout()\n    plt.show()\n\n    \ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest'\n) \nplot_augimages(np.random.choice(train_df['path'],10), datagen)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:28:56.115835Z","iopub.execute_input":"2022-04-04T13:28:56.117078Z","iopub.status.idle":"2022-04-04T13:29:02.161363Z","shell.execute_reply.started":"2022-04-04T13:28:56.117037Z","shell.execute_reply":"2022-04-04T13:29:02.158003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG19 Model","metadata":{}},{"cell_type":"code","source":"y_count=len(train_df['classname'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:02.162798Z","iopub.execute_input":"2022-04-04T13:29:02.163099Z","iopub.status.idle":"2022-04-04T13:29:02.169599Z","shell.execute_reply.started":"2022-04-04T13:29:02.163055Z","shell.execute_reply":"2022-04-04T13:29:02.168613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# include_top = False means that we doesnt include fully connected top layer we will add them accordingly\nvgg19 = VGG19(include_top = False, input_shape = (224,224,3), weights = 'imagenet')\n\n# training of all the convolution is set to false\nfor layer in vgg19.layers:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(vgg19.output)\npredictions = Dense(y_count, activation='softmax')(x)\n\nmodel = Model(inputs = vgg19.input, outputs = predictions)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:02.170909Z","iopub.execute_input":"2022-04-04T13:29:02.171359Z","iopub.status.idle":"2022-04-04T13:29:05.332417Z","shell.execute_reply.started":"2022-04-04T13:29:02.171325Z","shell.execute_reply":"2022-04-04T13:29:05.331679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile Model","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:05.333534Z","iopub.execute_input":"2022-04-04T13:29:05.334275Z","iopub.status.idle":"2022-04-04T13:29:05.361406Z","shell.execute_reply.started":"2022-04-04T13:29:05.334234Z","shell.execute_reply":"2022-04-04T13:29:05.360738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Test Split","metadata":{}},{"cell_type":"code","source":"X, y = train_df[['path', 'classname']], train_df['classname']","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:05.362658Z","iopub.execute_input":"2022-04-04T13:29:05.362894Z","iopub.status.idle":"2022-04-04T13:29:05.368312Z","shell.execute_reply.started":"2022-04-04T13:29:05.362862Z","shell.execute_reply":"2022-04-04T13:29:05.367356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:05.369977Z","iopub.execute_input":"2022-04-04T13:29:05.370285Z","iopub.status.idle":"2022-04-04T13:29:05.381432Z","shell.execute_reply.started":"2022-04-04T13:29:05.370249Z","shell.execute_reply":"2022-04-04T13:29:05.380627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Generators","metadata":{}},{"cell_type":"code","source":"train_generator = datagen.flow_from_dataframe(\n        X_train,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(224, 224),  # All images will be resized to 150x150\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:05.383899Z","iopub.execute_input":"2022-04-04T13:29:05.384688Z","iopub.status.idle":"2022-04-04T13:29:13.292679Z","shell.execute_reply.started":"2022-04-04T13:29:05.384648Z","shell.execute_reply":"2022-04-04T13:29:13.291972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator = datagen.flow_from_dataframe(\n        X_test,  # This is the source directory for training images\n        x_col='path',\n        y_col='classname',\n        target_size=(224, 224),  # All images will be resized to 150x150\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:13.293972Z","iopub.execute_input":"2022-04-04T13:29:13.294379Z","iopub.status.idle":"2022-04-04T13:29:15.288035Z","shell.execute_reply.started":"2022-04-04T13:29:13.29434Z","shell.execute_reply":"2022-04-04T13:29:15.287269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Fitting","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n      train_generator,\n     validation_data=val_generator,\n      steps_per_epoch=100,\n      epochs=10,\n      verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:29:15.289117Z","iopub.execute_input":"2022-04-04T13:29:15.289959Z","iopub.status.idle":"2022-04-04T13:51:54.938579Z","shell.execute_reply.started":"2022-04-04T13:29:15.289897Z","shell.execute_reply":"2022-04-04T13:51:54.937855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Loss","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history.history['loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:51:54.941482Z","iopub.execute_input":"2022-04-04T13:51:54.941681Z","iopub.status.idle":"2022-04-04T13:51:55.16918Z","shell.execute_reply.started":"2022-04-04T13:51:54.941657Z","shell.execute_reply":"2022-04-04T13:51:55.168519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Accuracy","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history.history['accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:51:55.170237Z","iopub.execute_input":"2022-04-04T13:51:55.171054Z","iopub.status.idle":"2022-04-04T13:51:55.396508Z","shell.execute_reply.started":"2022-04-04T13:51:55.171016Z","shell.execute_reply":"2022-04-04T13:51:55.395774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Save","metadata":{}},{"cell_type":"code","source":"model.save('./last.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T13:51:55.397779Z","iopub.execute_input":"2022-04-04T13:51:55.398054Z","iopub.status.idle":"2022-04-04T13:51:55.551819Z","shell.execute_reply.started":"2022-04-04T13:51:55.398017Z","shell.execute_reply":"2022-04-04T13:51:55.551096Z"},"trusted":true},"execution_count":null,"outputs":[]}]}