{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ndriver_imgs_list = pd.read_csv(\"../input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")\nsample_submission = pd.read_csv(\"../input/state-farm-distracted-driver-detection/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd \nfrom skimage import io\nfrom skimage import color\nfrom PIL import Image\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom dask.array.image import imread\nfrom dask import bag, threaded\nfrom dask.diagnostics import ProgressBar\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense,GlobalAveragePooling2D\nfrom keras.layers import Flatten,Dropout\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image \nfrom keras.layers.normalization import BatchNormalization\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"driver_details = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv',na_values='na')\nprint(driver_details.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image = []\nimage_label = []\n\n\nfor i in range(10):\n    print('now we are in the folder C',i)\n    imgs = os.listdir(\"../input/state-farm-distracted-driver-detection/imgs/train/c\"+str(i))\n    for j in range(1300):\n    #for j in range(100):\n        img_name = \"../input/state-farm-distracted-driver-detection/imgs/train/c\"+str(i)+\"/\"+imgs[j]\n        img = cv2.imread(img_name)\n        #img = color.rgb2gray(img)\n        img = img[50:,120:-50]\n        img = cv2.resize(img,(224,224))\n        label = i\n        driver = driver_details[driver_details['img'] == imgs[j]]['subject'].values[0]\n        train_image.append([img,label,driver])\n        image_label.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.shuffle(train_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"driv_selected = ['p050', 'p015', 'p022', 'p056']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train= []\ny_train = []\nX_test = []\ny_test = []\nD_train = []\nD_test = []\n\nfor features,labels,drivers in train_image:\n    if drivers in driv_selected:\n        X_test.append(features)\n        y_test.append(labels)\n        D_test.append(drivers)\n    \n    else:\n        X_train.append(features)\n        y_train.append(labels)\n        D_train.append(drivers)\n    \nprint (len(X_train),len(X_test))\nprint (len(y_train),len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train).reshape(-1,224,224,3)\nX_test = np.array(X_test).reshape(-1,224,224,3)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n\nprint (X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Defining the input\n\nfrom keras.layers import Input\nxception_input = Input(shape = (224, 224, 3), name = 'Image_input')\n\n## The RESNET model\n\nfrom keras.applications.xception import preprocess_input, decode_predictions\nfrom keras.applications.xception import Xception\n\n\n#Get the RESNET weights and layers\n\nmodel_xception_conv = Xception(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n#model_xception_conv.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use the generated model \nfrom keras.models import Model\n\n\noutput_xception_conv = model_xception_conv(xception_input)\n\n#Add the fully-connected layers \n\nx=GlobalAveragePooling2D()(output_xception_conv)\nx=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\nx = Dropout(0.1)(x) # **reduce dropout \nx=Dense(1024,activation='relu')(x) #dense layer 2\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(512,activation='relu')(x) #dense layer 3\nx = Dense(10, activation='softmax', name='predictions')(x)\n\n\nxception_pretrained = Model(input = xception_input, output = x)\n# for layer in resnet50_pretrained.layers[:2]:\n#     layer.trainable=False\n# for layer in resnet50_pretrained.layers[2:]:\n#     layer.trainable=True\n\n\nxception_pretrained.summary()\n\n\n# Compile CNN model\nadam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0)\nsgd = optimizers.SGD(lr = 0.005)\nxception_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\n\ncheckpointer = ModelCheckpoint('xception_weights_aug_extralayer_alltrained_sgd2_V2.hdf5', verbose=1, save_best_only=True)\nearlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n\n\ndatagen = ImageDataGenerator(\n    height_shift_range=0.5,\n    width_shift_range = 0.5,\n    zoom_range = 0.5,\n    rotation_range=30\n        )\n#datagen.fit(X_train)\ndata_generator = datagen.flow(X_train, y_train, batch_size = 64)\n\n# Fits the model on batches with real-time data augmentation:\nxception_model = xception_pretrained.fit_generator(data_generator,steps_per_epoch = len(X_train) / 64, callbacks=[checkpointer, earlystopper],\n                                                            epochs = 30, verbose = 1, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (10, 5))\naxes[0].plot(range(1, len(xception_pretrained.history.history['accuracy']) + 1), xception_pretrained.history.history['accuracy'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Accuracy')\naxes[0].plot(range(1, len(xception_pretrained.history.history['val_accuracy']) + 1), xception_pretrained.history.history['val_accuracy'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Accuracy')\naxes[0].set_xlabel('Epochs', fontsize = 14)\naxes[0].set_ylabel('Accuracy',fontsize = 14)\naxes[0].set_title('CNN Dropout Accuracy Trainig VS Testing', fontsize = 14)\naxes[0].legend(loc = 'best')\naxes[1].plot(range(1, len(xception_pretrained.history.history['loss']) + 1), xception_pretrained.history.history['loss'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Loss')\naxes[1].plot(range(1, len(xception_pretrained.history.history['val_loss']) + 1), xception_pretrained.history.history['val_loss'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Loss')\naxes[1].set_xlabel('Epochs', fontsize = 14)\naxes[1].set_ylabel('Loss',fontsize = 14)\naxes[1].set_title('CNN Dropout Loss Trainig VS Testing', fontsize = 14)\naxes[1].legend(loc = 'best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels is the image array\ntest_image = []\ni = 0\nfig, ax = plt.subplots(1, 20, figsize = (50,50 ))\n\nfiles = os.listdir(\"../input/state-farm-distracted-driver-detection/imgs/test/\")\nnums = np.random.randint(low=1, high=len(files), size=20)\nfor i in range(20):\n    print ('Image number:',i)\n    img = cv2.imread(\"../input/state-farm-distracted-driver-detection/imgs/test/\"+files[nums[i]])\n    #img = color.rgb2gray(img)\n    img = img[50:,120:-50]\n    img = cv2.resize(img,(224,224))\n    test_image.append(img)\n    ax[i].imshow(img,cmap = 'gray')\n    plt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\n\nfor img in test_image:\n    test.append(img)\n    \nxception_pretrained.load_weights('xception_weights_aug_extralayer_alltrained_sgd2_V2.hdf5')\n\n\ntest = np.array(test).reshape(-1,224,224,3)\nprediction = xception_pretrained.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntags = { \"C0\": \"safe driving\",\n\"C1\": \"texting - right\",\n\"C2\": \"talking on the phone - right\",\n\"C3\": \"texting - left\",\n\"C4\": \"talking on the phone - left\",\n\"C5\": \"operating the radio\",\n\"C6\": \"drinking\",\n\"C7\": \"reaching behind\",\n\"C8\": \"hair and makeup\",\n\"C9\": \"talking to passenger\" }\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels is the image array\ni = 0\nfig, ax = plt.subplots(20, 1, figsize = (100,100))\n\nfor i in range(20):\n    ax[i].imshow(test[i].squeeze())\n    predicted_class = 'C'+str(np.where(prediction[i] == np.amax(prediction[i]))[0][0])\n    ax[i].set_title(tags[predicted_class])\n    plt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}