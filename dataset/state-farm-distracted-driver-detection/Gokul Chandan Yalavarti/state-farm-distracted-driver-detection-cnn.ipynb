{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    if 'test' in dirname:\n        print('yes')\n        print(dirname)\n        break\n#     print(dirname)\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        \n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d1,_,filenames in os.walk('/kaggle/input/state-farm-distracted-driver-detection/imgs/test'):\n#     print(d1)\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n#     print(filenames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import os\nimport pandas as pd \nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n# import pickle\n# import tensorflow.compat.v1 as tf\nimport tensorflow as tf\nimport tensorflow.keras as keras\n# tf.disable_eager_execution()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"df_driver_imglist=pd.read_csv(\"/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")\ndf_driver_imglist.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"df_driver_imglist.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class_names=sorted(df_driver_imglist['classname'].unique())\nclass_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_i=[class_names.index(i) for i in class_names ]\nclass_i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"df_driver_imglist['classname'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"df_driver_imglist['subject'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path='/kaggle/input/state-farm-distracted-driver-detection/imgs/train'\ntest_path='/kaggle/input/state-farm-distracted-driver-detection/imgs/test'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# 224","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator=ImageDataGenerator(rescale=1./255) # ,shear_range=0.2,zoom_range=0.2,horizontal_flip=True\ntrain_gen=generator.flow_from_directory(train_path,target_size=(64,64),batch_size=128,class_mode='categorical',shuffle=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=keras.Sequential([#keras.layers.Input(shape=(None,28,28,1)),\n                        keras.layers.Conv2D(128,(5,5),padding='same',kernel_initializer='he_uniform',input_shape=(64,64,3)),\n                        keras.layers.MaxPooling2D(2),\n                        keras.layers.BatchNormalization(),\n                        keras.layers.Conv2D(64,(5,5),padding='same'),\n                        keras.layers.MaxPooling2D(2),\n                        keras.layers.Dropout(0.4),\n                        keras.layers.Flatten(),\n                        keras.layers.Dense(1024,activation='relu'),\n                        keras.layers.Dropout(0.4),\n                        keras.layers.Dense(10,activation='softmax'),\n                        \n                       ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wsave=model.get_weights()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.set_weights(wsave)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.fit(train_gen,epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x_np=x_train.reshape(-1,64,64,3)\nmodel.fit(train_gen,epochs=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.fit(train_gen,epochs=20)\n# Epoch 1/20\n# 176/176 [==============================] - 560s 3s/step - loss: 4.7924 - accuracy: 0.4134\n# Epoch 2/20\n# 176/176 [==============================] - 566s 3s/step - loss: 0.6814 - accuracy: 0.7651\n# Epoch 3/20\n# 176/176 [==============================] - 544s 3s/step - loss: 0.3770 - accuracy: 0.8730\n# Epoch 4/20\n# 176/176 [==============================] - 551s 3s/step - loss: 0.2498 - accuracy: 0.9166\n# Epoch 5/20\n# 176/176 [==============================] - 537s 3s/step - loss: 0.1995 - accuracy: 0.9344\n# Epoch 6/20\n# 176/176 [==============================] - 543s 3s/step - loss: 0.1550 - accuracy: 0.9473\n# Epoch 7/20\n# 176/176 [==============================] - 588s 3s/step - loss: 0.1314 - accuracy: 0.9559\n# Epoch 8/20\n# 176/176 [==============================] - 591s 3s/step - loss: 0.1127 - accuracy: 0.9637\n# Epoch 9/20\n# 176/176 [==============================] - 589s 3s/step - loss: 0.0896 - accuracy: 0.9686\n# Epoch 10/20\n# 176/176 [==============================] - 582s 3s/step - loss: 0.0777 - accuracy: 0.9726\n# Epoch 11/20\n# 176/176 [==============================] - 583s 3s/step - loss: 0.0734 - accuracy: 0.9750\n# Epoch 12/20\n# 176/176 [==============================] - 576s 3s/step - loss: 0.0690 - accuracy: 0.9755\n# Epoch 13/20\n# 176/176 [==============================] - 578s 3s/step - loss: 0.0708 - accuracy: 0.9759\n# Epoch 14/20\n# 176/176 [==============================] - 569s 3s/step - loss: 0.0825 - accuracy: 0.9719\n# Epoch 15/20\n# 176/176 [==============================] - 582s 3s/step - loss: 0.0817 - accuracy: 0.9735\n# Epoch 16/20\n# 176/176 [==============================] - 572s 3s/step - loss: 0.1041 - accuracy: 0.9708\n# Epoch 17/20\n# 176/176 [==============================] - 575s 3s/step - loss: 0.2228 - accuracy: 0.9351\n# Epoch 18/20\n# 176/176 [==============================] - 557s 3s/step - loss: 0.1069 - accuracy: 0.9681\n# Epoch 19/20\n# 176/176 [==============================] - 556s 3s/step - loss: 0.1081 - accuracy: 0.9686\n# Epoch 20/20\n# 176/176 [==============================] - 556s 3s/step - loss: 0.0943 - accuracy: 0.9755","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.fit_generator(train_img,epochs=15,use_multiprocessing=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.fit_generator(train_img,epochs=15,use_multiprocessing=True)\n# Epoch 1/15\n# 18/18 [==============================] - 20s 1s/step - loss: 1.0998 - accuracy: 0.6480\n# Epoch 2/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.9360 - accuracy: 0.7156\n# Epoch 3/15\n# 18/18 [==============================] - 21s 1s/step - loss: 0.7927 - accuracy: 0.7667\n# Epoch 4/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.6767 - accuracy: 0.8063\n# Epoch 5/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.5600 - accuracy: 0.8502\n# Epoch 6/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.4846 - accuracy: 0.8713\n# Epoch 7/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.4197 - accuracy: 0.8926\n# Epoch 8/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.3482 - accuracy: 0.9148\n# Epoch 9/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.3001 - accuracy: 0.9281\n# Epoch 10/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.2664 - accuracy: 0.9386\n# Epoch 11/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.2311 - accuracy: 0.9471\n# Epoch 12/15\n# 18/18 [==============================] - 19s 1s/step - loss: 0.2076 - accuracy: 0.9533\n# Epoch 13/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.1824 - accuracy: 0.9585\n# Epoch 14/15\n# 18/18 [==============================] - 19s 1s/step - loss: 0.1708 - accuracy: 0.9622\n# Epoch 15/15\n# 18/18 [==============================] - 20s 1s/step - loss: 0.1539 - accuracy: 0.9650","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.fit.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Preditions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil, os, glob\nsrcDir=test_path\ndstDir='/kaggle/working/test/img/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# if os.path.isdir(srcDir) and os.path.isdir(dstDir) :\n#         # Iterate over all the files in source directory\n#         for filePath in glob.glob(srcDir + '\\*'):\n#             # Move each file to destination Directory\n#             shutil.copy(filePath, dstDir);\n# else:\n#     print(\"srcDir & dstDir should be Directories\")\n\nshutil.copytree(srcDir,dstDir)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(dstDir))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngenerator_test=ImageDataGenerator(rescale=1./255)\ntest_gen=generator_test.flow_from_directory('/kaggle/working/test/',target_size=(64,64),batch_size=128,class_mode=None,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_gen.filenames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_gen.image_data_generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict_generator(test_gen,verbose=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission=pd.read_csv('/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.iloc[:,1:]=y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.to_csv('/kaggle/working/submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}