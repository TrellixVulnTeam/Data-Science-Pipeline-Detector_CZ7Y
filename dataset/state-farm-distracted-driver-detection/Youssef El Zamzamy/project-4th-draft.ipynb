{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport random\nimport time\nimport tensorflow\nimport datetime\nos.environ['KERAS_BACKEND'] = 'tensorflow'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import FileLink\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns \n%matplotlib inline\nfrom IPython.display import display, Image\nimport matplotlib.image as mpimg\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_files       \nfrom keras.utils import np_utils\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import log_loss\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.applications.vgg16 import VGG16","metadata":{"execution":{"iopub.status.busy":"2022-01-08T03:21:54.537195Z","iopub.execute_input":"2022-01-08T03:21:54.537785Z","iopub.status.idle":"2022-01-08T03:21:54.555997Z","shell.execute_reply.started":"2022-01-08T03:21:54.537745Z","shell.execute_reply":"2022-01-08T03:21:54.554957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 1:Load & Preprocess Dataset\n","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ndataset.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:55:07.081693Z","iopub.execute_input":"2022-01-08T01:55:07.082823Z","iopub.status.idle":"2022-01-08T01:55:07.1602Z","shell.execute_reply.started":"2022-01-08T01:55:07.082738Z","shell.execute_reply":"2022-01-08T01:55:07.159066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Classes\nNUMBER_CLASSES = 10\n\nactivity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:57:15.233519Z","iopub.execute_input":"2022-01-08T01:57:15.234346Z","iopub.status.idle":"2022-01-08T01:57:15.239561Z","shell.execute_reply.started":"2022-01-08T01:57:15.234304Z","shell.execute_reply":"2022-01-08T01:57:15.238852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Images Sample with classes from dataset\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:56:02.832074Z","iopub.execute_input":"2022-01-08T01:56:02.83296Z","iopub.status.idle":"2022-01-08T01:56:08.312599Z","shell.execute_reply.started":"2022-01-08T01:56:02.832919Z","shell.execute_reply":"2022-01-08T01:56:08.311372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Group Drivers By Subject\nby_drivers = dataset.groupby('subject')\nunique_drivers = by_drivers.groups.keys()\nprint(unique_drivers)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:55:22.625609Z","iopub.execute_input":"2022-01-08T01:55:22.626551Z","iopub.status.idle":"2022-01-08T01:55:22.648528Z","shell.execute_reply.started":"2022-01-08T01:55:22.626499Z","shell.execute_reply":"2022-01-08T01:55:22.647671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Group by Unique drivers\nunique_drivers = by_drivers.groups.keys() # drivers id\nprint('There are : ',len(unique_drivers), ' unique drivers')\nprint('There is a mean of ',round(dataset.groupby('subject').count()['classname'].mean()), ' images by driver.')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:55:34.561219Z","iopub.execute_input":"2022-01-08T01:55:34.562493Z","iopub.status.idle":"2022-01-08T01:55:34.582282Z","shell.execute_reply.started":"2022-01-08T01:55:34.56241Z","shell.execute_reply":"2022-01-08T01:55:34.581655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Resizing images size using cv2\ndef get_cv2_image(path, img_rows, img_cols, color_type=3):\n    if color_type == 1:\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    elif color_type == 3:\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n    img = cv2.resize(img, (img_rows, img_cols)) \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:58:01.819009Z","iopub.execute_input":"2022-01-08T01:58:01.819642Z","iopub.status.idle":"2022-01-08T01:58:01.825781Z","shell.execute_reply.started":"2022-01-08T01:58:01.819573Z","shell.execute_reply":"2022-01-08T01:58:01.824763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train Images\ndef load_train(img_rows, img_cols, color_type=3):\n    start_time = time.time()\n    train_images = [] \n    train_labels = []\n    for classed in tqdm(range(NUMBER_CLASSES)):\n        print('Loading directory c{}'.format(classed))\n        files = glob(os.path.join('../input/state-farm-distracted-driver-detection/imgs/train/c' + str(classed), '*.jpg'))\n        for file in files:\n            img = get_cv2_image(file, img_rows, img_cols, color_type)\n            train_images.append(img)\n            train_labels.append(classed)\n    print(\"Data Loaded in {} second\".format(time.time() - start_time))\n    return train_images, train_labels \n\n#Normalizing Train Images\ndef read_and_normalize_train_data(img_rows, img_cols, color_type):\n    X, labels = load_train(img_rows, img_cols, color_type)\n    y = np_utils.to_categorical(labels, 10)\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)\n    \n    return x_train, x_test, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:59:01.994756Z","iopub.execute_input":"2022-01-08T01:59:01.995084Z","iopub.status.idle":"2022-01-08T01:59:02.007862Z","shell.execute_reply.started":"2022-01-08T01:59:01.995039Z","shell.execute_reply":"2022-01-08T01:59:02.006676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation\ndef load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n    path = os.path.join('../input/state-farm-distracted-driver-detection/imgs/test', '*.jpg')\n    files = sorted(glob(path))\n    X_test, X_test_id = [], []\n    total = 0\n    files_size = len(files)\n    for file in tqdm(files):\n        if total >= size or total >= files_size:\n            break\n        file_base = os.path.basename(file)\n        img = get_cv2_image(file, img_rows, img_cols, color_type)\n        X_test.append(img)\n        X_test_id.append(file_base)\n        total += 1\n    return X_test, X_test_id\n#Normalizing\ndef read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)\n    \n    test_data = np.array(test_data, dtype=np.uint8)\n    test_data = test_data.reshape(-1,img_rows,img_cols,color_type)\n    \n    return test_data, test_ids","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:59:33.227478Z","iopub.execute_input":"2022-01-08T01:59:33.227852Z","iopub.status.idle":"2022-01-08T01:59:33.238112Z","shell.execute_reply.started":"2022-01-08T01:59:33.22781Z","shell.execute_reply":"2022-01-08T01:59:33.237399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_rows = 64\nimg_cols = 64\ncolor_type = 1","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:59:43.638282Z","iopub.execute_input":"2022-01-08T01:59:43.639443Z","iopub.status.idle":"2022-01-08T01:59:43.64498Z","shell.execute_reply.started":"2022-01-08T01:59:43.639385Z","shell.execute_reply":"2022-01-08T01:59:43.643741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\nprint('Train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T01:59:50.925816Z","iopub.execute_input":"2022-01-08T01:59:50.926388Z","iopub.status.idle":"2022-01-08T02:04:18.966037Z","shell.execute_reply.started":"2022-01-08T01:59:50.926348Z","shell.execute_reply":"2022-01-08T02:04:18.964842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_test_samples = 200\ntest_files, test_targets = read_and_normalize_sampled_test_data(nb_test_samples, img_rows, img_cols, color_type)\nprint('Test shape:', test_files.shape)\nprint(test_files.shape[0], 'Test samples')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:57:34.722193Z","iopub.execute_input":"2022-01-08T02:57:34.723321Z","iopub.status.idle":"2022-01-08T02:57:39.705173Z","shell.execute_reply.started":"2022-01-08T02:57:34.723243Z","shell.execute_reply":"2022-01-08T02:57:39.703988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 2:EDA\n","metadata":{}},{"cell_type":"code","source":"#Number of images by category\nimport plotly.express as px\npx.histogram(dataset, x=\"classname\", color=\"classname\", title=\"Number of Images by Categories \")","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:07:12.445824Z","iopub.execute_input":"2022-01-08T02:07:12.446197Z","iopub.status.idle":"2022-01-08T02:07:15.515497Z","shell.execute_reply.started":"2022-01-08T02:07:12.446163Z","shell.execute_reply":"2022-01-08T02:07:15.514772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Classe Distribution\ndriver_details = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')\ndriver_details['class_type'] = driver_details['classname'].str.extract('(\\d)',expand=False).astype(np.float)\nplt.figure()\ndriver_details.hist('class_type',alpha=0.5,layout=(1,1),bins=9)\nplt.title('class distribution')\nplt.draw()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:08:41.486439Z","iopub.execute_input":"2022-01-08T02:08:41.486816Z","iopub.status.idle":"2022-01-08T02:08:41.799661Z","shell.execute_reply.started":"2022-01-08T02:08:41.48678Z","shell.execute_reply":"2022-01-08T02:08:41.798949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Number of images by subjects\ndrivers_id = pd.DataFrame((driver_details['subject'].value_counts()).reset_index())\ndrivers_id.columns = ['driver_id', 'Counts']\npx.histogram(drivers_id, x=\"driver_id\",y=\"Counts\" ,color=\"driver_id\", title=\"Number of images by subjects \")","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:09:07.689477Z","iopub.execute_input":"2022-01-08T02:09:07.690759Z","iopub.status.idle":"2022-01-08T02:09:07.916605Z","shell.execute_reply.started":"2022-01-08T02:09:07.69068Z","shell.execute_reply":"2022-01-08T02:09:07.915672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 3: Vanilla CNN Model\n","metadata":{}},{"cell_type":"code","source":"#batch_size = 32\n#nb_epoch = 10","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:09:42.808821Z","iopub.execute_input":"2022-01-08T02:09:42.809524Z","iopub.status.idle":"2022-01-08T02:09:42.814514Z","shell.execute_reply.started":"2022-01-08T02:09:42.809448Z","shell.execute_reply":"2022-01-08T02:09:42.813642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -f saved_models/weights_best_vanilla.hdf5\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:09:50.802338Z","iopub.execute_input":"2022-01-08T02:09:50.802648Z","iopub.status.idle":"2022-01-08T02:09:51.587035Z","shell.execute_reply.started":"2022-01-08T02:09:50.802613Z","shell.execute_reply":"2022-01-08T02:09:51.585759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_dir = \"saved_models\"\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n    \ncheckpointer = ModelCheckpoint(filepath='saved_models/weights_best_vanilla.hdf5', \n                               monitor='val_loss', mode='min',\n                               verbose=1, save_best_only=True)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\ncallbacks = [checkpointer, es]","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:10:01.695227Z","iopub.execute_input":"2022-01-08T02:10:01.69555Z","iopub.status.idle":"2022-01-08T02:10:01.701899Z","shell.execute_reply.started":"2022-01-08T02:10:01.695515Z","shell.execute_reply":"2022-01-08T02:10:01.701215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#3 Convolutionnal layers (with Relu, Maxpooling and dropout)\n#A flatten layer\n#2 Dense layers with Relu and Dropouts\n#1 Dense layer with softmax for the classification\n#Batch Size: 32\n#Number of Epoch Passes: 10\nbatch_size = 32\nnb_epoch = 10\n\ndef create_model_v1():\n    model = Sequential()\n\n    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n    \n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(10,activation='softmax'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:10:58.542623Z","iopub.execute_input":"2022-01-08T02:10:58.543061Z","iopub.status.idle":"2022-01-08T02:10:58.557535Z","shell.execute_reply.started":"2022-01-08T02:10:58.54303Z","shell.execute_reply":"2022-01-08T02:10:58.556331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the model\nmodel_v1 = create_model_v1()\nmodel_v1.summary()\nmodel_v1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:11:30.939256Z","iopub.execute_input":"2022-01-08T02:11:30.940342Z","iopub.status.idle":"2022-01-08T02:11:31.371144Z","shell.execute_reply.started":"2022-01-08T02:11:30.940293Z","shell.execute_reply":"2022-01-08T02:11:31.369866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training CNN Vanilla Model\nhistory_v1 = model_v1.fit(x_train, y_train, \n          validation_data=(x_test, y_test),\n          callbacks=callbacks,\n          epochs=nb_epoch, batch_size=batch_size, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:11:55.787607Z","iopub.execute_input":"2022-01-08T02:11:55.787909Z","iopub.status.idle":"2022-01-08T02:50:21.129515Z","shell.execute_reply.started":"2022-01-08T02:11:55.787875Z","shell.execute_reply":"2022-01-08T02:50:21.128305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_v1.load_weights('saved_models/weights_best_vanilla.hdf5')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:52:35.384881Z","iopub.execute_input":"2022-01-08T02:52:35.385298Z","iopub.status.idle":"2022-01-08T02:52:35.460252Z","shell.execute_reply.started":"2022-01-08T02:52:35.38526Z","shell.execute_reply":"2022-01-08T02:52:35.4594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy & Loss\ndef plot_train_history(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\n     \n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:52:39.483261Z","iopub.execute_input":"2022-01-08T02:52:39.483874Z","iopub.status.idle":"2022-01-08T02:52:39.493001Z","shell.execute_reply.started":"2022-01-08T02:52:39.483818Z","shell.execute_reply":"2022-01-08T02:52:39.492082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting Acuuracy & Loss\nplot_train_history(history_v1)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:52:42.73511Z","iopub.execute_input":"2022-01-08T02:52:42.735636Z","iopub.status.idle":"2022-01-08T02:52:43.196286Z","shell.execute_reply.started":"2022-01-08T02:52:42.735599Z","shell.execute_reply":"2022-01-08T02:52:43.195544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_v1.load_weights('saved_models/weights_best_vanilla.hdf5')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:53:09.151195Z","iopub.execute_input":"2022-01-08T02:53:09.151497Z","iopub.status.idle":"2022-01-08T02:53:09.215549Z","shell.execute_reply.started":"2022-01-08T02:53:09.151464Z","shell.execute_reply":"2022-01-08T02:53:09.214664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model_v1.evaluate(x_test, y_test, verbose=1)\nprint('Score: ', score)\n\ny_pred = model_v1.predict(x_test, batch_size=batch_size, verbose=1)\nscore = log_loss(y_test, y_pred)\nprint('Score log loss:', score)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:53:13.009026Z","iopub.execute_input":"2022-01-08T02:53:13.009392Z","iopub.status.idle":"2022-01-08T02:53:41.2377Z","shell.execute_reply.started":"2022-01-08T02:53:13.009345Z","shell.execute_reply":"2022-01-08T02:53:41.236726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing CNN Vanilla Model\ndef plot_test_class(model, test_files, image_number, color_type=1):\n    img_brute = test_files[image_number]\n    img_brute = cv2.resize(img_brute,(img_rows,img_cols))\n    plt.imshow(img_brute, cmap='gray')\n\n    new_img = img_brute.reshape(-1,img_rows,img_cols,color_type)\n\n    y_prediction = model.predict(new_img, batch_size=batch_size, verbose=1)\n    print('Y prediction: {}'.format(y_prediction))\n    print('Predicted: {}'.format(activity_map.get('c{}'.format(np.argmax(y_prediction)))))\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:56:01.578336Z","iopub.execute_input":"2022-01-08T02:56:01.578618Z","iopub.status.idle":"2022-01-08T02:56:01.586815Z","shell.execute_reply.started":"2022-01-08T02:56:01.578574Z","shell.execute_reply":"2022-01-08T02:56:01.585702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing on Images\nfor i in range(5):\n    plot_test_class(model_v1, test_files, i)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:58:19.297458Z","iopub.execute_input":"2022-01-08T02:58:19.298538Z","iopub.status.idle":"2022-01-08T02:58:20.664785Z","shell.execute_reply.started":"2022-01-08T02:58:19.298474Z","shell.execute_reply":"2022-01-08T02:58:20.663857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 4:Improving Model Efficiency by using Data Augmentation \n","metadata":{}},{"cell_type":"code","source":"!rm -f saved_models/weights_best_vanilla.hdf5\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:58:32.483295Z","iopub.execute_input":"2022-01-08T02:58:32.483622Z","iopub.status.idle":"2022-01-08T02:58:33.337057Z","shell.execute_reply.started":"2022-01-08T02:58:32.483574Z","shell.execute_reply":"2022-01-08T02:58:33.335562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using data augmentation from keras as ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.0/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True, \n                                   validation_split = 0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1.0/ 255, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:58:35.330041Z","iopub.execute_input":"2022-01-08T02:58:35.331665Z","iopub.status.idle":"2022-01-08T02:58:35.340434Z","shell.execute_reply.started":"2022-01-08T02:58:35.331561Z","shell.execute_reply":"2022-01-08T02:58:35.339225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_train_samples = x_train.shape[0]\nnb_validation_samples = x_test.shape[0]\nprint(nb_train_samples)\nprint(nb_validation_samples)\ntraining_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\nvalidation_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:58:36.967993Z","iopub.execute_input":"2022-01-08T02:58:36.968676Z","iopub.status.idle":"2022-01-08T02:58:37.755968Z","shell.execute_reply.started":"2022-01-08T02:58:36.968634Z","shell.execute_reply":"2022-01-08T02:58:37.75464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train the model with Data Augmentation\ncheckpoint = ModelCheckpoint('saved_models/weights_best_vanilla.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nhistory_v3 = model_v1.fit_generator(training_generator,\n                         steps_per_epoch = nb_train_samples // batch_size,\n                         epochs = 5, \n                         callbacks=[es, checkpoint],\n                         verbose = 1,\n                         validation_data = validation_generator,\n                         validation_steps = nb_validation_samples // batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T02:58:39.610564Z","iopub.execute_input":"2022-01-08T02:58:39.610936Z","iopub.status.idle":"2022-01-08T03:18:01.456425Z","shell.execute_reply.started":"2022-01-08T02:58:39.610899Z","shell.execute_reply":"2022-01-08T03:18:01.455478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_history(history_v3)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-08T03:19:56.009524Z","iopub.execute_input":"2022-01-08T03:19:56.009904Z","iopub.status.idle":"2022-01-08T03:19:56.434659Z","shell.execute_reply.started":"2022-01-08T03:19:56.009866Z","shell.execute_reply":"2022-01-08T03:19:56.433414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the performance with Data Augmentation\nscore = model_v1.evaluate_generator(validation_generator, nb_validation_samples // batch_size)\nprint(\"Test Score:\", score[0])\nprint(\"Test Accuracy:\", score[1])","metadata":{"execution":{"iopub.status.busy":"2022-01-08T03:20:22.12862Z","iopub.execute_input":"2022-01-08T03:20:22.129381Z","iopub.status.idle":"2022-01-08T03:20:35.556313Z","shell.execute_reply.started":"2022-01-08T03:20:22.129303Z","shell.execute_reply":"2022-01-08T03:20:35.55525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing on Images\nfor i in range(2):\n    plot_test_class(model_v1, test_files, i)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T03:20:48.918008Z","iopub.execute_input":"2022-01-08T03:20:48.918495Z","iopub.status.idle":"2022-01-08T03:20:49.454506Z","shell.execute_reply.started":"2022-01-08T03:20:48.918443Z","shell.execute_reply":"2022-01-08T03:20:49.453018Z"},"trusted":true},"execution_count":null,"outputs":[]}]}