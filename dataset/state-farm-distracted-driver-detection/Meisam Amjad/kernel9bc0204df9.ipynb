{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files\n#in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76df2e1cea9cef1978befba62279f0b93582adbd"},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sb  # Importing seaborn for plotting\n\nfrom PIL import Image\n\nimport tqdm  # For ProgressBar\nimport time  # For recording time\n\nfrom torch.utils.data.dataset import Dataset\n\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data import DataLoader\n\nimport torch\nfrom torch import nn # python module\nimport torch.nn.functional as F # Regular function\n\nimport tensorflow as tf\n\nimport skimage.transform\n#from sklearn.model_selection import train_test_split\n\nimport shutil  # For Copying files(checkpoints)\n\nfrom sklearn.metrics import classification_report  # For getting a report from the net","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# First and foremost exploring Data\n"},{"metadata":{"trusted":true,"_uuid":"ddebe769585a6d8cdad85571b205a9e7757eaac4"},"cell_type":"code","source":"train_path = \"../input/train\"\ntest_path = \"../input/test\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0612d435d73a4109f07c0623ebb54aaa415a28f2","scrolled":true},"cell_type":"code","source":"os.listdir(test_path)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2874d1adb5e96b68c5dfdf18ddc273fd5345cdec"},"cell_type":"code","source":"os.listdir(train_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"851b304fdec28ed739c6d005f00fb2a975e2cc73"},"cell_type":"markdown","source":"As you can see above, there are 10 folders, from c0 to c9 (discard .Ds_store, we don't want it) representing 10 different classes that need to be predicted. </p>"},{"metadata":{"_uuid":"27e2198acf1b2433e6ee1bf32cce22936c37fa45"},"cell_type":"markdown","source":"Starting off with looking at data in 'driver_imgs_list.csv': </p>"},{"metadata":{"trusted":true,"_uuid":"78bd045208f06a9cd628b39fee592e860b6c31c3"},"cell_type":"code","source":"driverImgs = pd.read_csv('../input/driver_imgs_list.csv')\nprint(driverImgs.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42cb254343939655b780b508a54d73ae98d3f644"},"cell_type":"code","source":"a = pd.DataFrame({'img':os.listdir(test_path)[:10]})\na.iloc[1, 0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12d8ea9b9a81c9eb75eba2736dc455a0964ce863"},"cell_type":"markdown","source":"Let's explore images inside each folder for each class to see if they are equaly shared in those folder:"},{"metadata":{"trusted":true,"_uuid":"e88ee13f58ec83c5a9950b7d9819765e0120ca57"},"cell_type":"code","source":"# Loading all train image names inside trainImgs list\n# from trainImgs[0..9]\ntrainImgs = []\nfor i in range(10):\n    # making a path i.e. '../input/train/c0' or '../input/train/c9' and checking the path\n    className = \"/c\" + str(i)\n    path = train_path + className \n    assert os.path.exists(path) \n    # reading images from each folder and adding to the list\n    trainImgs.append(os.listdir(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df1673ebb1f3bea50e593646fffbc3e8a98da037"},"cell_type":"code","source":"# Making x, y for plotting\nx = range(10)\ny = []\n\n# clalculating the total number of training images\nnumTrainImgs = 0\nfor i in range(10):\n    y.append(len(trainImgs[i]))\n    numTrainImgs = numTrainImgs + y[i]\n    print(\"Number of images in c%d folder is: %d\" % (i, y[i]))\nprint(\"\\t\\t\\tTotal is: %d\" % numTrainImgs)\n\n# Plotting\nplt.figure(figsize = (13, 8))\ncolors = mpl.cm.rainbow(np.linspace(0, 1, 10))  # Defining rainbow colors\nplt.bar(x, y, color = colors);\nplt.xlabel(\"number of images in each folder from c0..c9\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f12b7bbb23dee9a332b21551b5d72089094992bd"},"cell_type":"markdown","source":"As yo can see above, the number of images for each class are different </p>\nNow, let's see if the total number of train images is matched with the total number of images in 'driver_imgs_list' file. </p>"},{"metadata":{"trusted":true,"_uuid":"e38b6d620a25f96274b0dd1159a3690ef015433b"},"cell_type":"code","source":"print(\"number of imgaes in driver list file is: %d (unique: %d)\" \n      % (driverImgs['img'].count(), driverImgs['img'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a34a3af7197ade91b7e1d50008732b754a72033"},"cell_type":"markdown","source":"Good news both numbers are equal.</p>\nNow I want to figure out how many subjects there are and how many pictures for each subject, and whether or not we have same number of pictures for each subject. </p>"},{"metadata":{"trusted":true,"_uuid":"113e020ca2d85eae944cfb7b05468a994db4266f"},"cell_type":"code","source":"# Plotting a 13 x 8 figure\nplt.figure(figsize = (13, 8))\nsb.countplot(driverImgs['subject'], palette = 'Set3');\n# Changing the label of axis\nplt.xlabel(\"Subjects\")\nplt.ylabel(\"number of existance\")\n# Showing the total number of subject as a title\nplt.title(str(\"Total Number of subjects is:\" + str(driverImgs['subject'].nunique())));","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"340f20b92fd6563118c4cc8c214aff584446e4b2"},"cell_type":"markdown","source":"As you saw, number of images for each subject in different. </p>\nNow, I want to see how many images there are for each class. </p>"},{"metadata":{"trusted":true,"_uuid":"1df40b99d82beafda7a5149fd76a7b07363e7480"},"cell_type":"code","source":"# Plotting a 13 x 8 figure\nplt.figure(figsize = (13, 8))\nsb.countplot(driverImgs['classname'], palette = 'Set3');\n# Changing the label of axis\nplt.xlabel(\"Class Names\")\nplt.ylabel(\"Number\")\n# Showing the total number of subject as a title\nplt.title(\"How many images there are for each class\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f0ad8f4b0955db7e0b401f504e7ac881558c665"},"cell_type":"markdown","source":"The highest number of image is for the case that shows safe driving and the least number belongs to the case where images show hair & makeup.</p>"},{"metadata":{"_uuid":"58a890d8bba7f2a3f084da0c8e0e963bd4a8c34f"},"cell_type":"markdown","source":"** Let's make a DATASET: **"},{"metadata":{"trusted":true,"_uuid":"00abd46a881b65c9ee7929a4a9b4fd9cbf4b2462"},"cell_type":"code","source":"class DriverImageDataset(Dataset):\n    \"\"\"DriverImageDataset.\"\"\"\n\n    def __init__(self, root_dir = '../input', csv_file = 'driver_imgs_list.csv', download = False,\n                 train = True , transform = None, newShape = None,rand_state = 2, limit = None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            download(boolean): Download the data first in active path.\n            train   (boolean): If True (default), returns train data, and test data otherwise.\n            newShape  (tuple): Resize images to the given new shape for instance: (28, 28)\n            transform (callable, optional): Optional transform to be applied on a sample.\n            limit     (tuple): Picking images based on the given tuple \n                               i.e. limit = (starts, ends (not, included))\n            rand_state  (int): int or numpy.random.RandomState, optional Seed for the \n                                random number generator (if int), or numpy RandomState object.\n        \"\"\"\n        if download:\n            !pip install kaggle\n            !kaggle competitions download -c state-farm-distracted-driver-detection\n        \n        self._root_dir_       = root_dir\n        self._transform_      = transform\n        self._newShape_       = newShape\n        self._cvs_file_path_  = os.path.join(root_dir, csv_file)\n        self._isTrain_        = train\n        self._dataPath_       = os.path.join(root_dir, 'train')\n        self.driver_imgs_list = pd.read_csv(self._cvs_file_path_)\n        if not self._isTrain_:\n            self._isTrain_        = False\n            self._dataPath_       = os.path.join(self._root_dir_, 'test')\n            self.driver_imgs_list = pd.DataFrame({'img':os.listdir(self._dataPath_)})\n        # Shuffles the self.driver_imgs_list\n        self.__shuffle__(rand_state, limit)    \n        \n    def __len__(self):\n        return len(self.driver_imgs_list)\n\n    def __getitem__(self, idx):\n        img_name = ''\n        label = 0\n        if self._isTrain_:\n            class_name = self.driver_imgs_list.iloc[idx, 1]\n            img_name = os.path.join(self._dataPath_, class_name, self.driver_imgs_list.iloc[idx, 2])\n            label    = int(class_name[1])\n        else:\n            img_name = os.path.join(self._dataPath_, self.driver_imgs_list.iloc[idx, 0])\n        img = Image.open(img_name)\n        #img = img.convert('RGB')\n        if self._newShape_:\n            img = img.resize(self._newShape_)\n        if self._transform_:\n            img = self._transform_(img)\n        if not self._isTrain_:\n            return img\n        label = torch.from_numpy(np.asarray(label))\n        return img, label\n    \n    def __shuffle__(self, rand_state, limit):\n        self.driver_imgs_list = self.driver_imgs_list.sample(frac = 1, \\\n                                    random_state = rand_state).reset_index(drop = True)\n        if limit:\n            self.driver_imgs_list = self.driver_imgs_list.iloc[limit[0]: limit[1]]. \\\n                                    reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"756fe0847dd47d61dc42f3351b9edc9f5ff05503"},"cell_type":"code","source":"new_shape = (int(640 / 5), int(480 / 5))  # 1/5th of original shape\nnew_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e82ff6f21bc84a733d1db839e4a69fddd77b85a"},"cell_type":"code","source":"trainData = DriverImageDataset(root_dir='../input', train = True, download = False, \n                                newShape = new_shape)\ntestData = DriverImageDataset(root_dir='../input', train = False, download = False, \n                               newShape = new_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"008f0d1793407f6662db95044aa9767b1c40ef24"},"cell_type":"code","source":"# Hyperparameters\nBATCH_SIZE    = 25 #256\nLEARNING_RATE = 0.001\nWORKERS       = 0 #10 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f9a446d519e0548d02cf660ac56a3145a53c641"},"cell_type":"code","source":"def show_batch(images, targets = None, predictions = None):\n    '''This method gets a list of images with their target value\n       and plot them in equal rows and column.\n       Also can get the predictions values and show them with targets.\n       images(list) : List of images\n       targets(list): Labels for each image\n       predictions(list): If not None, is list of predicted values\n                          corresponding with each given image'''\n    plt.figure(figsize = (15, 15))\n    ncols = np.ceil(np.sqrt(len(images)))\n    nrows = np.ceil(len(images) / ncols)\n    for i in range(len(images)):\n        plt.subplot(nrows, ncols, i + 1)\n        plt.imshow(images[i][0].numpy().squeeze())\n        plt.xticks([]); plt.yticks([]); #plt.axis('off');\n        if predictions is not None:\n            plt.xlabel(\"P:{}, T:{}\".format( predictions[i].numpy(), \\\n                                           targets[i].numpy(), fontsize = 'small'))\n        elif targets is not None:\n            plt.xlabel(\"T:{}\".format(targets[i].numpy()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afef0f72a61a2841eecd33a3abf82f4f6ed4c508"},"cell_type":"code","source":"import random\n\nrand_list = random.sample(range(numTrainImgs), 10)\n\nplot_list = []\nplot_labels = []\nfor i in rand_list:\n    im, lab = trainData[i]\n    plot_list.append(im)\n    plot_labels.append(lab)\n    \nshow_batch(plotImgs, plotLables)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b332fbb8a3de9f863c3b2957a101ebd17213ae62"},"cell_type":"markdown","source":"**Now let's make a simple network and train the data **</p>"},{"metadata":{"trusted":true,"_uuid":"1d7da38fa3e4a08ea188d2fe0af56f4bde4512cf"},"cell_type":"code","source":"# Hyperparameters\nBATCH_SIZE    = 64 #256\nLEARNING_RATE = 0.001\nWORKERS       = 2 #10\n\n# For picking 5% of train data as an Evaluation Data\nevalData_length = numTrainImgs - int(numTrainImgs * 0.05)\n\n# Reading Data sets\ntrainData = DriverImageDataset(root_dir='../input', train = True, download = False, \n            transform = ToTensor(), newShape = new_shape , limit = (0, evalData_length))\nevalData  = DriverImageDataset(root_dir='../input', train = True, download = False, \n            transform = ToTensor(), newShape = new_shape , limit = (evalData_length, numTrainImgs))\ntestData  = DriverImageDataset(root_dir='../input', train = False, download = False, \n                               transform = ToTensor(), newShape = new_shape)\n\n# Checking if it picked all train images as evalData + trainData\nassert numTrainImgs == len(evalData) + len(trainData) \n\n# Setting Data Loaders\ntrain_loader = DataLoader(trainData, batch_size = BATCH_SIZE, \n                          num_workers = WORKERS, shuffle = True)\neval_loader  = DataLoader(evalData, batch_size = BATCH_SIZE, \n                          num_workers = WORKERS, shuffle = True)\ntest_loader  = DataLoader(testData, batch_size = BATCH_SIZE, \n                          num_workers = WORKERS, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae44f05630e9b7afe69b2f2b373c5205652afd59"},"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, shape = (3, new_shape[0], new_shape[1]), num_classes = 10):\n        super().__init__()\n        \n        num_inputs = np.product(shape)\n    \n        self.layer1 = nn.Linear(num_inputs, 50)\n        self.layer2 = nn.Linear(50, 100)\n        self.layer3 = nn.Linear(100, num_classes)\n        \n    \n    def forward(self, x):\n        \n        #Conv up here\n        \n        \n        x = x.reshape(x.shape[0], -1)  # Flattening the input\n        h1 = self.layer1(x)            # First layer\n        #!nvidia-smi \n        h1 = F.relu(h1)                # Apply nonlinearity\n        h2 = self.layer2(h1)\n        h2 = F.relu(h2)\n        y = self.layer3(h2)\n        \n        return y  # Will learn to treat 'a' as the natural parameters of a multinomial distr. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56fd3646d9487abc0501708a43d487586d16bf35"},"cell_type":"code","source":"MLPNet = MLP()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f43d2ed017d431daaa8b0d49c319984adce63e60"},"cell_type":"code","source":"print(MLPNet)\nprint(\"----\")\nprint(list(MLPNet.state_dict())) # Assign names to each one of group of tensor parameters\nprint(\"----\")\nprint(MLPNet.parameters)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"993a36953fb90eaf64a3d5ec33199ece8ee7fb99"},"cell_type":"markdown","source":"# GPU (if available)"},{"metadata":{"trusted":true,"_uuid":"3b33ebc7cb75d9d9afa8eb01945f5f61eff74334"},"cell_type":"code","source":"import torch.cuda\ntorch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a741c8c9974ec0b3dffef932000812ecec0c1b8"},"cell_type":"code","source":"if torch.cuda.is_available():\n    def togpu(x):\n        return x.cuda()\n    def tocpu(x):\n        return x.cpu()\nelse:\n    def togpu(x):\n        return x\n    def tocpu(x):\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11e1fb68439ab234843e1b2e9a5e28a4e36574f4"},"cell_type":"code","source":"net = togpu(MLPNet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f462bd41a14af2baa5b8b2e991995ae20175124c"},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params = net.parameters(), lr = LEARNING_RATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9d2002bd167d24b7c0ce380a9f88c59f90f5caa"},"cell_type":"code","source":"def compute_eval_loss(net, criterion, loader):\n    # Evaluate the model\n    with torch.no_grad():\n        eval_loss = 0.0\n        for i, data in tqdm.tqdm(enumerate(loader), desc = 'Evaluating', \n                                 total = len(loader), leave = False):\n            inputs, labels = data\n            inputs, labels = togpu(inputs), togpu(labels)\n            outputs = net(inputs)               # Predict\n            loss = criterion(outputs, labels)   # Grade / Evaluate\n            eval_loss += loss.item()\n    eval_loss /= len(test_loader)\n    return eval_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51efa0a0cda2b1a1f3b2c87bebc284656aeb2b7b"},"cell_type":"code","source":"def run_simpleCNN(net, optimizer, criterion, epoch = 2, best_eval_loss = float('inf')):\n    for epoch in tqdm.tnrange(epoch):\n        running_loss = 0.0\n        tstart = time.time()\n        for _, data in tqdm.tqdm(enumerate(train_loader), total = len(train_loader), leave = False):\n            # get the inputs\n            inputs, labels = data\n        \n            # Move inputs to the GPU\n            inputs, labels = togpu(inputs), togpu(labels)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)               # Predict\n            loss = criterion(outputs, labels)   # Grade / Evaluate\n            loss.backward()                     # Determine how each parameter effected the loss\n            optimizer.step()                    # Update parameters \n\n            # print statistics\n            running_loss += loss.item()\n        tend = time.time()\n    \n        # Save parameters\n        running_loss /= len(train_loader)\n        # This is for where we can stop\n        eval_loss = compute_eval_loss(net, criterion, eval_loader)  \n        torch.save(dict(epoch = epoch, \n                     loss = eval_loss,\n                    parameters = net.state_dict(),\n                    optimizer  = optimizer.state_dict()),\n                   'simplecnn-checkpoint.pth.tar')\n    \n        if eval_loss < best_eval_loss:\n            best_eval_loss = eval_loss\n            best_epoch = epoch\n            shutil.copyfile('simplecnn-checkpoint.pth.tar', 'simplecnn-best.pth.tar')\n        \n        print(\"Epoch {: 4}   loss: {: 2.5f}  Eval_loss: {: 2.5f}  time: {}\".format(epoch, \n                                                          running_loss / len(train_loader),\n                                                          eval_loss,                         \n                                                          tend-tstart))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4bdca6ed0322a67d31bc725ec237089d79df4e2"},"cell_type":"code","source":"!nvidia-smi ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc35050f3299878fc7444fc1660e1ba5d820b3be"},"cell_type":"code","source":"import sys, os\ndef resume(model, optimizer, fn = 'checkpoint.pth.tar'):\n    '''\n        Loads a torch net from the given file.\n    '''\n    if os.path.isfile(fn):\n        print(\"=> loading checkpoint '{}'\".format(fn))\n        checkpoint  = torch.load(fn)\n        model.load_state_dict(checkpoint['parameters'])\n        start_epoch = checkpoint['epoch']\n        best_loss   = checkpoint['loss']\n        ehist       = checkpoint.get('ehist', [])\n        thist       = checkpoint.get('thist', [])\n        optimizer.load_state_dict(checkpoint['optimizer'])\n        print(\"=> Loaded checkpoint '{}' (epoch {})\".format(fn, checkpoint['epoch']))\n    else:\n        start_epoch = 0\n        ehist = []\n        thist = []\n        print (\"=> no checkpoint found at '{}'\".format(fn))\n    return start_epoch, best_loss, ehist, thist\n\n# Qualitative assessment (By Numbers)\ndef report(net, evalData):\n    predictions = np.zeros(len(evalData)) \n    targets = np.zeros(len(evalData))\n\n    for i  in tqdm.tnrange(len(evalData)):\n        x, t = evalData[i]\n        # I have to add one extra axis at the beginning by None\n        p = tocpu(net(togpu(x[None,...]))).argmax(1)[0]  \n        predictions[i] = int(p) # Changing Tensors into integers\n        targets[i] = t \n\n    # Showing classification metrics\n    print(classification_report(targets, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"860c7a3af2ed70e2ae75896bd7739b6fe32adec8"},"cell_type":"code","source":"b_loss = float('inf')  # Assign infinity\nrun_simpleCNN(net, optimizer, criterion, epoch = 2, best_eval_loss = b_loss)\nepoch, b_loss, ehist, thist = resume(net, optimizer, fn = 'simplecnn-best.pth.tar')\nreport(net, evalData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cb04b221a2e245fddcdd005d089e0355babf747"},"cell_type":"markdown","source":"So far, the result was not that bad even with a simple CNN.</p>\nNow, I want to train my network for more epochs.</p>"},{"metadata":{"trusted":true,"_uuid":"8f7f6eee38b7538f556d97f79a0075bdaf5dc12d"},"cell_type":"code","source":"run_simpleCNN(net, optimizer, criterion, epoch = 10, best_eval_loss = b_loss)\nepoch, b_loss, ehist, thist = resume(net, optimizer, fn = 'simplecnn-best.pth.tar')\nreport(net, evalData) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee89294a407ca40f68fafa2381ceb8637a36e9d8","scrolled":true},"cell_type":"code","source":"run_simpleCNN(optimizer, criterion, epoch = 10, best_eval_loss = b_loss)\noptimizer, epoch, b_lost, ehist, thist = resume(net, optimizer, fn = 'simplecnn-best.pth.tar')\nreport(net, evalData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"549a7a7c7f3ce6d69220f57a722ea937ece95b94"},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/sample_submission.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef015bf1fc032157f4cf1c29ac49940dbaaef313"},"cell_type":"code","source":"submission_01 = pd.DataFrame({'img':testData.driver_imgs_list.iloc[:, 0], \n                              'c0':np.zeros(len(testData)),\n                              'c1':np.zeros(len(testData)),\n                              'c2':np.zeros(len(testData)),\n                              'c3':np.zeros(len(testData)),\n                              'c4':np.zeros(len(testData)),\n                              'c5':np.zeros(len(testData)),\n                              'c6':np.zeros(len(testData)),\n                              'c7':np.zeros(len(testData)),\n                              'c8':np.zeros(len(testData)),\n                              'c9':np.zeros(len(testData)) })\n\nfor i  in tqdm.tnrange(len(testData)):\n        x = testData[i]\n        # I have to add one extra axis at the beginning by None\n        submission_01.at[i, 1:] = tocpu(net(togpu(x[None,...])))[0].detach().numpy()\n        \n    \nprint(submission_01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"689beb1b2fe054c433a9832318facb00fdd299c9"},"cell_type":"code","source":"submission_01.to_csv('submission_01_last.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff6ee0474a5b498365753a4b4e86dcd48b4cd937"},"cell_type":"code","source":" ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}