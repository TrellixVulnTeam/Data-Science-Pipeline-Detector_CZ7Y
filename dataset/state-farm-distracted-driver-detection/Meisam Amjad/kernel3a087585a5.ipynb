{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74552152903d8480d29b5c3d58f9bf9fd3e74173"},"cell_type":"code","source":"from os import listdir\n\ntrain_path = '../input/state-farm-distracted-driver-detection/train/'\ntest_path = '../input/state-farm-distracted-driver-detection/test/'\n\ntest_path_array = listdir(test_path)\nmatching = [s for s in test_path_array if \"img_1.jpg\" in s]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed01359619bed3c289f46c38ddfda6a502221b41"},"cell_type":"code","source":"import pandas as pd\n\ndriver_imgs = pd.read_csv('../input/state-farm-distracted-driver-detection/driver_imgs_list.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8928baef9cd9b7ac1679dce145e37f327d74b13c"},"cell_type":"markdown","source":"# Label Preperation"},{"metadata":{"trusted":true,"_uuid":"16e428e5d2350ba6fa9e76c68a9a149a64e514c1"},"cell_type":"code","source":"from tqdm import tqdm\ndef loadBatchImages(path):\n    catList = listdir(path)\n    loadedImages = []\n    loadedLabels = []\n    for cat in catList:\n        if not cat.startswith('.'):\n            deepPath = path+cat+\"/\"\n            imageList = listdir(deepPath)\n            for images in tqdm(imageList):\n                img = deepPath + images\n                loadedLabels.append(int(cat[1:]))\n                loadedImages.append(img)\n            \n    return loadedImages, loadedLabels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4ca9ac98b37fc97549fc2c387ff260954f1ddef"},"cell_type":"code","source":"loadedImages, loadedLabels = loadBatchImages(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3ecbdac1a260c82e473c2517cc80e871166e510"},"cell_type":"code","source":"num_classes = len(np.unique(loadedLabels))\n\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\nlabels_Hot = to_categorical(loadedLabels, num_classes = num_classes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"462ef2dda5199c58f10baf91a1e9ca75b9dee7e5"},"cell_type":"markdown","source":"# Create Data Generator"},{"metadata":{"trusted":true,"_uuid":"03a13bcc5acb7c7c304c457c6ce330f92361e278"},"cell_type":"code","source":"df= pd.DataFrame()\n\ndf['path']=loadedImages\ndf['labels'] = list(labels_Hot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"871fbb2ad804db613a06d051fb75c4b19124b520"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c2b02b0bbc665296fb4083fa80a3df80782fc0e"},"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\n#from keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\n\nimport keras\nfrom keras import backend as K\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model,Sequential, model_from_json\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization,\\\n                            Conv2D, MaxPool2D, MaxPooling2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5820853fee34fcc6e2c3dfe905911cde03a596f0"},"cell_type":"code","source":"train_df = df\n\ntrain_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'labels', \n                            target_size = IMG_SIZE,\n                            batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43e53c03442348122db4855cf04d09142c9ffa0c"},"cell_type":"code","source":"t_x, t_y = next(train_gen)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e37b2fb53310b5b76f53d44f6536bebce09439b5"},"cell_type":"markdown","source":"# VGG16"},{"metadata":{"trusted":true,"_uuid":"ffb75235f8ab1f5d6a75660c38e1c7c24271fb04"},"cell_type":"code","source":"from os.path import join, exists, expanduser\nfrom os import listdir, makedirs\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70f67a9ada0eb8cac36ab6536edf15840f7fc64e"},"cell_type":"code","source":"!cp ../input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5 ~/.keras/models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f97ea5fc5f33fb2e78ef081d2bdc3f37507c5306"},"cell_type":"code","source":"!ls ~/.keras/models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7d716587a3031269217705bdff0d26b30bdf338"},"cell_type":"code","source":"pretrained_model_1 = VGG16(include_top = False, input_shape = t_x.shape[1:])\nbase_model = pretrained_model_1 # Topless\noptimizer1 = keras.optimizers.Adam()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"296aee18736e5122066614cf1bc975de49f17461"},"cell_type":"code","source":"# Add top layer\nx = base_model.output\nx = Conv2D(100, kernel_size = (3,3), padding = 'valid')(x)\nx = Flatten()(x)\nx = Dropout(0.75)(x)\npredictions = Dense(num_classes, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Train top layer\nfor layer in base_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bccebf74dbf371181248eaab8319cb3066d84109"},"cell_type":"code","source":"%%time\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=optimizer1, \n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb30ac1d0666760236201da6fd195f1293d3b5a9"},"cell_type":"code","source":"model.fit_generator(train_gen,steps_per_epoch = 100,epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7dba9b17cc8c6d02690f87ff0f2e7ec8f7f960db"},"cell_type":"code","source":"import glob\nfrom glob import glob\ntest_image_paths = glob('../input/state-farm-distracted-driver-detection/test/*.jpg', recursive=True)\n\nX_test = pd.DataFrame()\nX_test['path'] = test_image_paths\nX_test['labels'] = X_test['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fe8879a0e0254cc03c6f4f112eb69ab3aab4da3"},"cell_type":"code","source":"X_test['labels'] = X_test['labels'] + '.jpg'\nX_test['labels'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b7190d01c2b84abf235132f1d6111f6ab3de426"},"cell_type":"code","source":"test_gen = flow_from_dataframe(core_idg, X_test, \n                             path_col = 'path',\n                            y_col = 'labels', \n                            target_size = IMG_SIZE,\n                            batch_size = 256) # we can use much larger batches for evaluation\nprint(len(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70cf10103dd473309fade66367bceda0f6b70c76"},"cell_type":"code","source":"%%time\npred_Y =  model.predict_generator(test_gen, verbose = 1, steps = 312)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4aa5371f68f88154ec4489ee981ef2a07b8ee8aa"},"cell_type":"code","source":"def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)\n\npred_Y = do_clip(pred_Y,0.93)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78ccb945d28ce882ce1dfe04c5de83a03c266fe7"},"cell_type":"code","source":"submission = pd.DataFrame()\n\nsubmission['img'] = X_test['labels']\n\nsubmission['c0'] = pred_Y[:,0]\nsubmission['c1'] = pred_Y[:,1]\nsubmission['c2'] = pred_Y[:,2]\nsubmission['c3'] = pred_Y[:,3]\nsubmission['c4'] = pred_Y[:,4]\nsubmission['c5'] = pred_Y[:,5]\nsubmission['c6'] = pred_Y[:,6]\nsubmission['c7'] = pred_Y[:,7]\nsubmission['c8'] = pred_Y[:,8]\nsubmission['c9'] = pred_Y[:,9]\n\nsubmission.to_csv(\"submission_05_01.csv\",index = False)\nprint(\"The Submission file has been created!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"378626f824eac494afe99208b79ef04665a068ba"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}