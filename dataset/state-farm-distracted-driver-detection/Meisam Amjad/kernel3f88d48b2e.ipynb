{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sb  # Importing seaborn for plotting\n\nfrom PIL import Image\n\nimport tqdm  # For ProgressBar\nimport time  # For recording time\n\nfrom torch.utils.data.dataset import Dataset\n\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data import DataLoader\n\nimport torch\nfrom torch import nn # python module\nimport torch.nn.functional as F # Regular function\n\nimport tensorflow as tf\n\nimport skimage.transform\n#from sklearn.model_selection import train_test_split\n\nimport shutil  # For Copying files(checkpoints)\n\nfrom sklearn.metrics import classification_report  # For getting a report from the net\n\n# For adding filters\nimport skimage.color  \nimport skimage.filters\nimport skimage.feature\nfrom skimage.transform import warp\n\n# For making interaction plot\nfrom ipywidgets import interact\n\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56f5ad821241f0f1f9c02d9f57681cf2f8d1e095"},"cell_type":"code","source":"class DriverImageDataset(Dataset):\n    \"\"\"DriverImageDataset.\"\"\"\n\n    def __init__(self, root_dir = '../input', csv_file = 'driver_imgs_list.csv', download = False,\n                 train = True , transform = None, newShape = None, evalData = None, \n                 rand_state = 2, limit = None, filter_skin = False):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            download(boolean): Download the data first in active path.\n            train   (boolean): If True (default), returns train data, and test data otherwise.\n            newShape  (tuple): Resize images to the given new shape for instance: (28, 28)\n            transform (callable, optional): Optional transform to be applied on a sample.\n            limit     (tuple): Picking images based on the given tuple \n                               i.e. limit = (starts, ends (not, included))\n            rand_state  (int): int or numpy.random.RandomState, optional Seed for the \n                                random number generator (if int), or numpy RandomState object.\n        \"\"\"\n        if download:\n            !pip install kaggle\n            !kaggle competitions download -c state-farm-distracted-driver-detection\n        \n        self._root_dir_       = root_dir\n        self._transform_      = transform\n        self._newShape_       = newShape\n        self._cvs_file_path_  = os.path.join(root_dir, csv_file)\n        self._isTrain_        = train\n        self._dataPath_       = os.path.join(root_dir, 'train')\n        self.driver_imgs_list = pd.read_csv(self._cvs_file_path_)\n        self._filter_skin     = filter_skin\n        if not self._isTrain_:\n            self._isTrain_        = False\n            self._dataPath_       = os.path.join(self._root_dir_, 'test')\n            self.driver_imgs_list = pd.DataFrame({'img':os.listdir(self._dataPath_)})\n        # Shuffles the self.driver_imgs_list\n        self.__shuffle__(rand_state, limit)\n        \n    def __len__(self):\n        return len(self.driver_imgs_list)\n\n    def __getitem__(self, idx):\n        img_name = ''\n        label = 0\n        if self._isTrain_:\n            class_name = self.driver_imgs_list.iloc[idx, 1]\n            img_name = os.path.join(self._dataPath_, class_name, self.driver_imgs_list.iloc[idx, 2])\n            label    = int(class_name[1])\n        else:\n            img_name = os.path.join(self._dataPath_, self.driver_imgs_list.iloc[idx, 0])\n        img = Image.open(img_name)\n        #img = img.convert('RGB')\n        if self._newShape_:\n            img = img.resize(self._newShape_)\n        if self._filter_skin:\n            img = self.__filter_skin__(img)\n        if self._transform_:\n            img = self._transform_(img)\n        if not self._isTrain_:\n            return img\n        label = torch.from_numpy(np.asarray(label))\n        return img, label\n    \n    def __shuffle__(self, rand_state, limit):\n        self.driver_imgs_list = self.driver_imgs_list.sample(frac = 1, \\\n                                    random_state = rand_state).reset_index(drop = True)\n        if limit:\n            self.driver_imgs_list = self.driver_imgs_list.iloc[limit[0]: limit[1]]. \\\n                                    reset_index(drop = True)\n    def __filter_skin__(im):\n        y_begin, y_end =55,  130\n        Cb_begin, Cb_end =0, 123\n        Cr_begin, Cr_end =128, 256\n        filter1 = np.array([[1., 0., 48.], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n    \n        im = np.asarray(im).copy()\n        im = skimage.color.rgb2ycbcr(im)\n        im = warp(im, filter1)\n        \n        \n        im[((im[:, :, 0] <= y_begin) | (im[:, :, 0] >= y_end))] = 0\n        im[((im[:, :, 1] <= Cb_begin) | (im[:, :, 1] >= Cb_end))] = 0\n        im[((im[:, :, 2] <= Cr_begin) | (im[:, :, 2] >= Cr_end))] = 0\n        \n        im = skimage.color.ycbcr2rgb(im)\n        return im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab251fa16792667ecea03511e5da3efa58d5c27d"},"cell_type":"code","source":"def show_batch(images, targets = None, predictions = None, numpy = True):\n    '''This method gets a list of images with their target value\n       and plot them in equal rows and column.\n       Also can get the predictions values and show them with targets.\n       images(list) : List of images\n       targets(list): Labels for each image\n       predictions(list): If not None, is list of predicted values\n                          corresponding with each given image'''\n    plt.figure(figsize = (15, 15))\n    ncols = np.ceil(np.sqrt(len(images)))\n    nrows = np.ceil(len(images) / ncols)\n    for i in range(len(images)):\n        plt.subplot(nrows, ncols, i + 1)\n        if numpy:\n            im = images[i]\n        else:\n            im = images[i].numpy().squeeze()\n        plt.imshow(im)\n        plt.xticks([]); plt.yticks([]); #plt.axis('off');\n        if predictions is not None:\n            plt.xlabel(\"P:{}, T:{}\".format( predictions[i].numpy(), \\\n                                           targets[i].numpy(), fontsize = 'small'))\n        elif targets is not None:\n            plt.xlabel(\"T:{}\".format(targets[i].numpy()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9f40ff194849602397dd1f59c07b764b2a8011b"},"cell_type":"code","source":"new_shape = (int(640 / 2), int(480 / 2))  # 1/5th of original shape\nnew_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a7ff11a6bb3cca161b995ca4a2384ebe39ed216"},"cell_type":"code","source":"# Hyperparameters\nBATCH_SIZE    = 64 #256\nLEARNING_RATE = 0.001\nWORKERS       = 2 #10\n\nnumTrainImgs = len(pd.read_csv('../input/driver_imgs_list.csv'))\n# For picking 5% of train data as an Evaluation Data\nevalData_start = numTrainImgs - int(numTrainImgs * 0.05)\n\n# Reading Data sets\ntrainData = DriverImageDataset(root_dir='../input', train = True, download = False, \n#            transform = ToTensor(), \n                               newShape = new_shape , limit = (0, evalData_start))\n#evalData  = DriverImageDataset(root_dir='../input', train = True, download = False, \n#            transform = ToTensor(), newShape = new_shape , limit = (evalData_start, numTrainImgs))\n#testData  = DriverImageDataset(root_dir='../input', train = False, download = False, \n#                               transform = ToTensor(), newShape = new_shape)\n\n# Checking if it picked all train images as evalData + trainData\n#assert numTrainImgs == len(evalData) + len(trainData) \n\n# Setting Data Loaders\n#train_loader = DataLoader(trainData, batch_size = BATCH_SIZE, \n#                          num_workers = WORKERS, shuffle = True)\n#eval_loader  = DataLoader(evalData, batch_size = BATCH_SIZE, \n#                          num_workers = WORKERS, shuffle = True)\n#test_loader  = DataLoader(testData, batch_size = BATCH_SIZE, \n#                          num_workers = WORKERS, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31ea2080a9cd0a66fb75ff0c1e9167005787af1d"},"cell_type":"code","source":"trainData = DriverImageDataset(root_dir='../input', train = True, download = False, \n                               newShape = new_shape)\nim, label = trainData[0]\nim = np.asarray(im)\nplt.imshow(im);\nplt.axis(\"off\");\n#im = skimage.color.rgb2gray(im)\nim_origin = skimage.color.rgb2ycbcr(im)\na = im_origin[:, :, 0][None, :, :]\na.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70c591e7dc545e9aa7734c9c9aff2296cc0bbb28"},"cell_type":"code","source":"im = im_origin[:, :, 0]\ndef show_image(data, title, plot_num = 1, axis = 'off'):\n    plt.subplot(plot_num)\n    plt.title(title)\n    plt.imshow(data) \n    plt.axis(axis)\n    \nplt.figure(figsize = (15, 10))\nshow_image(im, \"Origin\", 331);\nshow_image(skimage.filters.sobel_h(im), \"Sobel H\", 332);\nshow_image(skimage.filters.sobel_v(im), \"Sobel V\", 333);\nshow_image(skimage.filters.prewitt(im), \"Prewitt\", 334);\nshow_image(skimage.filters.prewitt_h(im), \"Prewitt H\", 335);\nshow_image(skimage.filters.prewitt_v(im), \"Prewitt V\", 336);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46b08748041385cdb6875f868e955c178ea01db1"},"cell_type":"code","source":"im = im_origin[:, :, 1]\ndef show_image(data, title, plot_num = 1, axis = 'off'):\n    plt.subplot(plot_num)\n    plt.title(title)\n    plt.imshow(data) \n    plt.axis(axis)\n    \nplt.figure(figsize = (15, 10))\nshow_image(im, \"Origin\", 331);\nshow_image(skimage.filters.sobel_h(im), \"Sobel H\", 332);\nshow_image(skimage.filters.sobel_v(im), \"Sobel V\", 333);\nshow_image(skimage.filters.prewitt(im), \"Prewitt\", 334);\nshow_image(skimage.filters.prewitt_h(im), \"Prewitt H\", 335);\nshow_image(skimage.filters.prewitt_v(im), \"Prewitt V\", 336);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d64cc51f5bde1f87c19e6f5ea4e29c3a34709a3"},"cell_type":"code","source":"im = im_origin[:, :, 2]\ndef show_image(data, title, plot_num = 1, axis = 'off'):\n    plt.subplot(plot_num)\n    plt.title(title)\n    plt.imshow(data) \n    plt.axis(axis)\n    \nplt.figure(figsize = (15, 10))\nshow_image(im, \"Origin\", 331);\nshow_image(skimage.filters.sobel_h(im), \"Sobel H\", 332);\nshow_image(skimage.filters.sobel_v(im), \"Sobel V\", 333);\nshow_image(skimage.filters.prewitt(im), \"Prewitt\", 334);\nshow_image(skimage.filters.prewitt_h(im), \"Prewitt H\", 335);\nshow_image(skimage.filters.prewitt_v(im), \"Prewitt V\", 336);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"899e185d9874b3e62a85adcf4e0060bab50b9db4"},"cell_type":"code","source":"im, label = trainData[0]\nim = np.asarray(im)\n\n@interact(ax = (-1, 5, 0.01), ay = (-1, 5, 0.01),\n         bx = (-1, 5, 0.01), by = (-1, 5, 0.01),\n          tx = (0, 360, 1), ty = (0, 360, 1))\ndef plot_img(ax = 1, ay = -0,\n            bx = 0, by = 1, \n            tx = 50, ty = 0):\n    plt.cla()\n    Tm = np.array([[ax, ay, tx], [bx, by, ty], [0, 0, 1]]);\n    plt.imshow(warp(im, Tm));\n    print(Tm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e542b25edabd700701c494ed91044a7e14923d7f"},"cell_type":"code","source":"filter1 = np.array([[1., 0., 48.], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n\nplt.figure(figsize = (20, 15))\nshow_image(im_origin[:, :, 1], \"Origin\", 321);\nshow_image(warp(im_origin, filter1)[:, :, 1], \"Origin\", 322);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c54351154a4db9376f021de1f3eb151ae0210d4"},"cell_type":"code","source":"plot_list = []\nrng = random.sample(range(numTrainImgs - 1), 15)\nfor i in rng:\n    im, label = trainData[i]\n    im = np.asarray(im)\n    im = skimage.color.rgb2ycbcr(im)[:, :, 1]\n    im = warp(im, filter1)\n    plot_list.append(im)\nassert len(plot_list) == 15\nshow_batch(plot_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a66664a24e2d11971d15cd8826bf151c95b8787"},"cell_type":"code","source":"@interact(y_begin = (0, 255, 1), y_end = (0, 255, 1),  \n         Cb_begin = (0, 255, 1), Cb_end = (0, 255, 1),\n         Cr_begin = (0, 255, 1), Cr_end = (0, 255, 1))\ndef plot_img(y_begin = 55, y_end = 130,\n             Cb_begin = 0, Cb_end = 123,\n            Cr_begin = 128, Cr_end = 256):\n    im, label = trainData[200]\n    im = np.asarray(im).copy()\n    \n    plt.cla()\n    plt.figure(figsize = (20, 15))\n    plt.subplot(1, 5, 1)\n    plt.imshow(im)\n    im = skimage.color.rgb2ycbcr(im)\n    \n    \n    plt.subplot(1, 5, 2)\n    plt.title(\"Y\\n [ :, :, 1] >\" + str(y_begin) + \" & [ :, :, 1] < \" + str(y_end))\n    plt.imshow((im[:, :, 0] > y_begin) & (im[:, :, 0] < y_end)) \n    plt.axis('off')\n    \n    plt.subplot(1, 5, 3)\n    plt.title(\"Cb\\n [ :, :, 1] >\" + str(Cb_begin) + \" & [ :, :, 1] < \" + str(Cb_end))\n    plt.imshow((im[:, :, 1] > Cb_begin) & (im[:, :, 1] < Cb_end))\n    plt.axis('off')\n\n    plt.subplot(1, 5, 4)\n    plt.title(\"Cr\\n [ :, :, 1] >\" + str(Cr_begin) + \" & [ :, :, 1] < \" + str(Cr_end))\n    plt.imshow((im[:, :, 2] > Cr_begin) & (im[:, :, 2] < Cr_end));\n    plt.axis('off')\n    \n    im[((im[:, :, 0] <= y_begin) | (im[:, :, 0] >= y_end))] = 0.0\n    im[((im[:, :, 1] <= Cb_begin) | (im[:, :, 1] >= Cb_end))] = 0.0\n    im[((im[:, :, 2] <= Cr_begin) | (im[:, :, 2] >= Cr_end))] = 0.0\n        \n    org_im = skimage.color.ycbcr2rgb(im)\n    plt.subplot(1, 5, 5)\n    plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a835074d6c6390f74d81d52e69d04e36baa515e8"},"cell_type":"code","source":"def filter_skin(im):\n    y_begin, y_end =55,  130\n    Cb_begin, Cb_end =0, 123\n    Cr_begin, Cr_end =128, 256\n    \n    #im = np.asarray(im).copy()\n    im = skimage.color.rgb2ycbcr(im)\n        \n    im[((im[:, :, 0] <= y_begin) | (im[:, :, 0] >= y_end))] = 0\n    im[((im[:, :, 1] <= Cb_begin) | (im[:, :, 1] >= Cb_end))] = 0\n    im[((im[:, :, 2] <= Cr_begin) | (im[:, :, 2] >= Cr_end))] = 0\n        \n    im = skimage.color.ycbcr2rgb(im)\n    return im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"751df5ae3c07c8fb7d0a91af43e328e2ae3dc49b"},"cell_type":"code","source":"plot_list = []\nrng = random.sample(range(numTrainImgs), 4)\nfor i in rng:\n    im, label = trainData[i]\n    im = warp(im, filter1)\n    im = filter_skin(im)\n    plot_list.append(im)\n    \nshow_batch(plot_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31b17e4815d1429d48c795a20234b4e1ff08b0a5"},"cell_type":"code","source":"# Hyperparameters\nBATCH_SIZE    = 64 #256\nLEARNING_RATE = 0.001\nWORKERS       = 0 #10\n\nnumTrainImgs = len(pd.read_csv('../input/driver_imgs_list.csv'))\n# For picking 5% of train data as an Evaluation Data\nevalData_start = numTrainImgs - int(numTrainImgs * 0.05)\n\n# Reading Data sets\ntrainData = DriverImageDataset(root_dir='../input', train = True, download = False, \n            transform = ToTensor(), newShape = new_shape , limit = (0, evalData_start))\nevalData  = DriverImageDataset(root_dir='../input', train = True, download = False, \n            transform = ToTensor(), newShape = new_shape , limit = (evalData_start, numTrainImgs))\ntestData  = DriverImageDataset(root_dir='../input', train = False, download = False, \n                               transform = ToTensor(), newShape = new_shape)\n\n# Checking if it picked all train images as evalData + trainData\nassert numTrainImgs == len(evalData) + len(trainData) \n\n# Setting Data Loaders\ntrain_loader = DataLoader(trainData, batch_size = BATCH_SIZE, \n                          num_workers = WORKERS, shuffle = True)\neval_loader  = DataLoader(evalData, batch_size = BATCH_SIZE, \n                          num_workers = WORKERS, shuffle = True)\ntest_loader  = DataLoader(testData, batch_size = BATCH_SIZE, \n                          num_workers = WORKERS, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88ec64247a0da311734de69801e791e8beae561e"},"cell_type":"code","source":"class simpleCNN(nn.Module):\n    def __init__(self, shape = (3, new_shape[0], new_shape[1]), num_classes = 10):\n        super().__init__()\n        \n        self.layer1 = nn.Conv2d(3, 64, kernel_size = 3, padding = 1)\n        self.layer2 = nn.Conv2d(64, 128, kernel_size = 3, padding = 1)\n        self.layer3 = nn.Conv2d(128, 128, kernel_size = 3, padding = 1)\n        self.layer4 = nn.Linear(40 * 30 * 128, num_classes)\n        \n    \n    def forward(self, x):\n        x = self.layer1(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        \n        x = self.layer2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        \n        x = self.layer3(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        \n        x = x.reshape(-1, 40 * 30 * 128)\n        y = self.layer4(x)\n        \n        return y  # Will learn to treat 'a' as the natural parameters of a multinomial distr. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5248daf92db85745491dfc9b2fcd9a208601cf3"},"cell_type":"code","source":"cNN_net = simpleCNN()\n\nprint(cNN_net)\nprint(\"----\")\nprint(list(cNN_net.state_dict())) # Assign names to each one of group of tensor parameters\nprint(\"----\")\nprint(cNN_net.parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da921d4493703606393d374fd1a7d325dae05291"},"cell_type":"code","source":"import torch.cuda\nprint(torch.cuda.is_available())\n\nif torch.cuda.is_available():\n    def togpu(x):\n        return x.cuda()\n    def tocpu(x):\n        return x.cpu()\nelse:\n    def togpu(x):\n        return x\n    def tocpu(x):\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b498adc44ca76603f6614e93ed37bd777ddd2c2"},"cell_type":"code","source":"net = togpu(cNN_net)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params = net.parameters(), lr = LEARNING_RATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f73536d068f26ac8cbbce103b41d4419ba86f2d4"},"cell_type":"code","source":"def compute_eval_loss(net, criterion, loader):\n    # Evaluate the model\n    with torch.no_grad():\n        eval_loss = 0.0\n        for i, data in tqdm.tqdm(enumerate(loader), desc = 'Evaluating', \n                                 total = len(loader), leave = False):\n            inputs, labels = data\n            \n            inputs, labels = togpu(inputs), togpu(labels)\n            outputs = net(inputs)               # Predict\n            loss = criterion(outputs, labels)   # Grade / Evaluate\n            eval_loss += loss.item()\n    eval_loss /= len(test_loader)\n    return eval_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"652d7ee48770e010b0790df5d60ab9e30237476d"},"cell_type":"code","source":"def run_simpleCNN(net, optimizer, criterion, epoch = 2, best_eval_loss = float('inf')):\n    for epoch in tqdm.tnrange(epoch):\n        running_loss = 0.0\n        tstart = time.time()\n        for _, data in tqdm.tqdm(enumerate(train_loader), total = len(train_loader), leave = False):\n            # get the inputs\n            inputs, labels = data\n        \n            # Move inputs to the GPU\n            inputs, labels = togpu(inputs), togpu(labels)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)               # Predict\n            loss = criterion(outputs, labels)   # Grade / Evaluate\n            loss.backward()                     # Determine how each parameter effected the loss\n            optimizer.step()                    # Update parameters \n\n            # print statistics\n            running_loss += loss.item()\n        tend = time.time()\n    \n        # Save parameters\n        running_loss /= len(train_loader)\n        # This is for where we can stop\n        eval_loss = compute_eval_loss(net, criterion, eval_loader)  \n        torch.save(dict(epoch = epoch, \n                     loss = eval_loss,\n                    parameters = net.state_dict(),\n                    optimizer  = optimizer.state_dict()),\n                   'simpleCNN-checkpoint.pth.tar')\n    \n        if eval_loss < best_eval_loss:\n            best_eval_loss = eval_loss\n            best_epoch = epoch\n            shutil.copyfile('simpleCNN-checkpoint.pth.tar', 'simpleCNN-best.pth.tar')\n        \n        print(\"Epoch {: 4}   loss: {: 2.5f}  Eval_loss: {: 2.5f}  time: {}\".format(epoch, \n                                                          running_loss / len(train_loader),\n                                                          eval_loss,                         \n                                                          tend-tstart))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b54412b421e5ee09a33434edb77a6eaa0d8d9937"},"cell_type":"code","source":"import sys, os\ndef resume(model, optimizer, fn = 'checkpoint.pth.tar'):\n    '''\n        Loads a torch net from the given file.\n    '''\n    if os.path.isfile(fn):\n        print(\"=> loading checkpoint '{}'\".format(fn))\n        checkpoint  = torch.load(fn)\n        model.load_state_dict(checkpoint['parameters'])\n        start_epoch = checkpoint['epoch']\n        best_loss   = checkpoint['loss']\n        ehist       = checkpoint.get('ehist', [])\n        thist       = checkpoint.get('thist', [])\n        optimizer.load_state_dict(checkpoint['optimizer'])\n        print(\"=> Loaded checkpoint '{}' (epoch {})\".format(fn, checkpoint['epoch']))\n    else:\n        start_epoch = 0\n        ehist = []\n        thist = []\n        print (\"=> no checkpoint found at '{}'\".format(fn))\n    return start_epoch, best_loss, ehist, thist\n\n# Qualitative assessment (By Numbers)\ndef report(net, evalData):\n    predictions = np.zeros(len(evalData)) \n    targets = np.zeros(len(evalData))\n\n    for i  in tqdm.tnrange(len(evalData)):\n        x, t = evalData[i]\n        # I have to add one extra axis at the beginning by None\n        p = tocpu(net(togpu(x[None,...]))).argmax(1)[0]  \n        predictions[i] = int(p) # Changing Tensors into integers\n        targets[i] = t \n\n    # Showing classification metrics\n    print(classification_report(targets, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b38e15e18c6ed3d8cdccbe69fd86e7c6936063fa"},"cell_type":"code","source":"%%time\nb_loss = float('inf')  # Assign infinity\nrun_simpleCNN(net, optimizer, criterion, epoch = 1, best_eval_loss = b_loss)\nepoch, b_loss, ehist, thist = resume(net, optimizer, fn = 'simpleCNN-best.pth.tar')\nreport(net, evalData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab6391ab63e35e65f899e86df24efed6de009567"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}