{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport pickle\nimport datetime\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom keras.models import Sequential, Input\nfrom keras import layers\nfrom keras.layers.core import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, \\\n                                       ZeroPadding2D,Conv2D\n\nfrom keras.utils import to_categorical\n\n\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras.models import model_from_json\n# from sklearn.metrics import log_loss\nfrom numpy.random import permutation\n\nimport keras\nimport keras.backend as K \nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Add, Input, BatchNormalization, Activation\nfrom keras.layers import  Conv2D, MaxPooling2D, AveragePooling2D, Flatten\nfrom keras.regularizers import l2\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b048fe573382e8dad5903b8757af5e6fe0689e6"},"cell_type":"code","source":"img_rows = 224\nimg_cols = 224","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/state-farm-distracted-driver-detection/driver_imgs_list.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82a3d23769df1a5a434ec5a210be52ec1a07d6bd"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"304aaf935e89485312d1ea910d97f7e30d421adb"},"cell_type":"code","source":"def load_image(path, rows=None, cols=None, gray=True):\n    if gray:\n        img = cv2.imread(path,0)\n    else:\n        img = cv2.imread(path)\n    if rows != None and cols != None:\n        img = cv2.resize(img,(rows,cols))\n        #img = np.reshape(img, (rows, cols,1))\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16fe1197faf05ab7a36daa7cd8aff768838dc3ef"},"cell_type":"code","source":"def load_data(split=0.33, rows=None, cols=None):\n    paths = glob.glob(os.path.join(\"../input/state-farm-distracted-driver-detection\", \"train\", \"*\",  \"*.jpg\"))\n    labels = [int(x.split('/')[4][1]) for x in paths]\n    if rows != None and cols != None:\n        images = [load_image(x, rows, cols,gray=False) for x in paths]\n    else:\n        images = [load_image(x, gray=False) for x in paths]\n    y = to_categorical(labels)\n    x_train, x_test, y_train, y_test = train_test_split(images, y, test_size=split)\n    \n    return np.array(x_train), np.array(x_test), y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"affa14255e176a7c3489060c6ad0165490e3b439"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = load_data(rows=img_rows, cols=img_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3761b4df825a68228a13a06dbd479aa1ecdccefd"},"cell_type":"code","source":"def vgg_std16_model(img_rows, img_cols, color_type=3):\n    model = Sequential()\n    model.add(ZeroPadding2D((1, 1), input_shape=(img_rows, img_cols,color_type)))\n    model.add(Convolution2D(64, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(64, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(128, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(128, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(256, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1, 1)))\n    model.add(Convolution2D(512, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1000, activation='softmax'))\n\n    #model.load_weights('../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n\n    # Code above loads pre-trained data and\n    model.layers.pop()\n    model.add(Dense(10, activation='softmax'))\n    # Learning rate is changed to 0.001\n    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60e46c24e1a52279c6c499fcbee91370f47155c7"},"cell_type":"code","source":"def main_block(x, filters, n, strides, dropout):\n\t# Normal part\n\tx_res = Conv2D(filters, (3,3), strides=strides, padding=\"same\")(x)# , kernel_regularizer=l2(5e-4)\n\tx_res = BatchNormalization()(x_res)\n\tx_res = Activation('relu')(x_res)\n\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t# Alternative branch\n\tx = Conv2D(filters, (1,1), strides=strides)(x)\n\t# Merge Branches\n\tx = Add()([x_res, x])\n\n\tfor i in range(n-1):\n\t\t# Residual conection\n\t\tx_res = BatchNormalization()(x)\n\t\tx_res = Activation('relu')(x_res)\n\t\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t\t# Apply dropout if given\n\t\tif dropout: x_res = Dropout(dropout)(x)\n\t\t# Second part\n\t\tx_res = BatchNormalization()(x_res)\n\t\tx_res = Activation('relu')(x_res)\n\t\tx_res = Conv2D(filters, (3,3), padding=\"same\")(x_res)\n\t\t# Merge branches\n\t\tx = Add()([x, x_res])\n\n\t# Inter block part\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\treturn x\n\ndef build_model(input_dims, output_dim, n, k, act= \"relu\", dropout=None):\n\t\"\"\" Builds the model. Params:\n\t\t\t- n: number of layers. WRNs are of the form WRN-N-K\n\t\t\t\t It must satisfy that (N-4)%6 = 0\n\t\t\t- k: Widening factor. WRNs are of the form WRN-N-K\n\t\t\t\t It must satisfy that K%2 = 0\n\t\t\t- input_dims: input dimensions for the model\n\t\t\t- output_dim: output dimensions for the model\n\t\t\t- dropout: dropout rate - default=0 (not recomended >0.3)\n\t\t\t- act: activation function - default=relu. Build your custom\n\t\t\t\t   one with keras.backend (ex: swish, e-swish)\n\t\"\"\"\n\t# Ensure n & k are correct\n\tassert (n-4)%6 == 0\n\tassert k%2 == 0\n\tn = (n-4)//6 \n\t# This returns a tensor input to the model\n\tinputs = Input(shape=(input_dims))\n\n\t# Head of the model\n\tx = Conv2D(16, (3,3), padding=\"same\")(inputs)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# 3 Blocks (normal-residual)\n\tx = main_block(x, 16*k, n, (1,1), dropout) # 0\n\tx = main_block(x, 32*k, n, (2,2), dropout) # 1\n\tx = main_block(x, 64*k, n, (2,2), dropout) # 2\n\t\t\t\n\t# Final part of the model\n\tx = AveragePooling2D((8,8))(x)\n\tx = Flatten()(x)\n\toutputs = Dense(output_dim, activation=\"softmax\")(x)\n\n\tmodel = Model(inputs=inputs, outputs=outputs)\n\treturn model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc16f1049131106c4f924c265e76803138f0103f"},"cell_type":"code","source":"x_train[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74d46dd606c4e48c534c26ddba567278502d0257"},"cell_type":"code","source":"#model = vgg_std16_model(img_rows=img_rows, img_cols=img_cols)\nmodel = build_model((224,224,3), 10,16,4)\nmodel.load_weights('../input/weights/weights.h5')\nmodel.compile(\"adam\",\"categorical_crossentropy\", ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97b9ca7536713bae53ef60d18d54593545740212"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cc860e74e53da4c29fe95f50355337e41ae73e6"},"cell_type":"code","source":"model.evaluate(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fee0b9c9deabb847b592944abe3565b23e6ed486"},"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=16, epochs=5, validation_data=(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"617172207258c298d20ecaf5f9799f3b1ba4626e"},"cell_type":"code","source":"model.evaluate(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92d9097fd283c198756f7e5ca4f43cae33b391d6"},"cell_type":"code","source":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"weights.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8633db7c952450b6e725f90feda5e15f06b5ee85"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}