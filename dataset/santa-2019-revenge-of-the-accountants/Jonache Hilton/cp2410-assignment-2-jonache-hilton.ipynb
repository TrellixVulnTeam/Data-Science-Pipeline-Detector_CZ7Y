{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **CP2410 Assignment 2 - Jonache Hilton**\nThis assignment implements two diffrent algorithms; a very fast cost function, which uses Numba JIT from http://numba.pydata.org/ and Stochastic Product search algorithm, which is based off of the Stochastic optimization approach. The assignment also uses two different data structures, lists (Chapter 5.4, page 207 from Data Structures & Algorithms in Python textbook) and Arrays (Chapter 5, page 184 from Data Structures & Algorithms in Python textbook). These algorithms and data structures are used in combination to solve the \"Santa's Workshop Tour 2019\" and \"Santa 2019: Revenge of the Accountants\" competitions.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Structure Analysis\n### Lists\n\nA list is an in-built data structure in Python that is a mutable, or changeable, ordered sequence of elements. Each element or value that is inside of a list is called an item. Lists are great to use when you want to work with many related values. They enable you to keep data together that belongs together, condense your code, and perform the same methods and operations on multiple values at once. The time compexity of a list is great as it is O(N) making it linear.\n\n\n### Arrays\nAn array is a collection of items stored at contiguous memory locations. The idea is to store multiple items of the same type together. This makes it easier to calculate the position of each element by simply adding an offset to a base value, i.e., the memory location of the first element of the array (generally denoted by the name of the array). An array is extremely simple and efficient as the computational complexity for writing to and accessing an array is O(1) because no matter the number of elements in the array, the calculation to find the element in the array is single multiplication and addition. Additionally, the the memory usage of an array is fantastic as it's simply the number of elements in the array multiplied by the size of each element.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Algorithm Analysis\n### Stochastic Product Search (adjusted with revenge of the accountants accounting cost)\n\nIndividuals and organizations such as Santa are often faced with making tradeoffs in order to achieve desirable outcomes. Choosing these tradeoffs in the “best” way is the essence of the Stochastic Product Search Algorithm. Stochastic optimization (SO) methods are optimization methods that generate and use random variables. For stochastic problems, the random variables appear in the formulation of the optimization problem itself, which involves random objective functions or random constraints. Stochastic optimization methods also include methods with random iterates. Some stochastic optimization methods use random iterates to solve stochastic problems, combining both meanings of stochastic optimization. The nested loop in this algorithm leads to a O(n^2) running time in the worst case. As Stochastic search algorithms are designed for problems with inherent random noise the algorithm is a perfect fit for Santa's Workshop Tour problem. This algorithm is defnitley efficient and effective enough to solve the problem.\n\n### Fast cost function using Numba JIT (adjusted with revenge of the accountants accounting cost)\n\nA very fast cost function has been used in this assignment. It uses the Numba JIT package; Numba is an open-source JIT compiler that translates a subset of Python and NumPy into fast machine code using LLVM, via the llvmlite Python package. It offers a range of options for parallelising Python code for CPUs and GPUs, often with only minor code. The nested loop in this algorithm leads to a O(n^2) running time in the worst case. While this algorithm is quadratic in the worst case it is is defnitley efficient and effective enough to solve the problem.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Algorithm 1 - Stochastic Product search\n### Using arrays as data structure","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Retrieved from https://www.kaggle.com/xhlulu/santa-s-2019-stochastic-product-search\n# Retrieved from https://www.kaggle.com/xhlulu/santa-s-2019-faster-cost-function-24-s\nfrom itertools import product\nfrom time import time\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom numba import njit, prange\nimport matplotlib.pyplot as plt\n\nbase_path = '/kaggle/input/santa-2019-revenge-of-the-accountants/'\ndata = pd.read_csv(base_path + 'family_data.csv', index_col='family_id')\nsubmission = pd.read_csv(base_path + 'sample_submission.csv', index_col='family_id')\n\n\ndef _build_choice_array(data, n_days):\n    choice_matrix = data.loc[:, 'choice_0': 'choice_9'].values\n    choice_array_num = np.full((data.shape[0], n_days + 1), -1)\n\n    for i, choice in enumerate(choice_matrix):\n        for d, day in enumerate(choice):\n            choice_array_num[i, day] = d\n    \n    return choice_array_num\n\n\ndef _precompute_accounting(max_day_count, max_diff):\n    accounting_matrix = np.zeros((max_day_count+1, max_diff+1))\n    # Start day count at 1 in order to avoid division by 0\n    for today_count in range(1, max_day_count+1):\n        for diff in range(max_diff+1):\n            #revenge of the accountants adjustment\n            for j in range (1, 6):\n                accounting_cost = (today_count - 125.0) / 400.0 * (today_count**(0.5 + diff / 50.0))/j**2\n                accounting_matrix[today_count, diff] = max(0, accounting_cost)\n    \n    return accounting_matrix\n\n\ndef _precompute_penalties(choice_array_num, family_size):\n    penalties_array = np.array([\n        [\n            0,\n            50,\n            50 + 9 * n,\n            100 + 9 * n,\n            200 + 9 * n,\n            200 + 18 * n,\n            300 + 18 * n,\n            300 + 36 * n,\n            400 + 36 * n,\n            500 + 36 * n + 199 * n,\n            500 + 36 * n + 398 * n\n        ]\n        for n in range(family_size.max() + 1)\n    ])\n    \n    penalty_matrix = np.zeros(choice_array_num.shape)\n    N = family_size.shape[0]\n    for i in range(N):\n        choice = choice_array_num[i]\n        n = family_size[i]\n        \n        for j in range(penalty_matrix.shape[1]):\n            penalty_matrix[i, j] = penalties_array[n, choice[j]]\n    \n    return penalty_matrix\n\n\n@njit\ndef _compute_cost_fast(prediction, family_size, days_array, \n                       penalty_matrix, accounting_matrix, \n                       MAX_OCCUPANCY, MIN_OCCUPANCY, N_DAYS):\n\n    N = family_size.shape[0]\n\n    daily_occupancy = np.zeros(len(days_array)+1, dtype=np.int64)\n    penalty = 0\n    \n    for i in range(N):\n        n = family_size[i]\n        d = prediction[i]\n        \n        daily_occupancy[d] += n\n        penalty += penalty_matrix[i, d]\n\n    relevant_occupancy = daily_occupancy[1:]\n    incorrect_occupancy = np.any(\n        (relevant_occupancy > MAX_OCCUPANCY) | \n        (relevant_occupancy < MIN_OCCUPANCY)\n    )\n    \n    penalty = 100000000\n\n\n    init_occupancy = daily_occupancy[days_array[0]]\n    accounting_cost = (init_occupancy - 125.0) / 400.0 * init_occupancy**(0.5)\n\n    accounting_cost = max(0, accounting_cost)\n    \n\n    yesterday_count = init_occupancy\n    for day in days_array[1:]:\n        today_count = daily_occupancy[day]\n        diff = abs(today_count - yesterday_count)\n        accounting_cost += accounting_matrix[today_count, diff]\n        yesterday_count = today_count\n\n    return penalty, accounting_cost, daily_occupancy\n\n\ndef build_cost_function(data, N_DAYS=100, MAX_OCCUPANCY=300, MIN_OCCUPANCY=125):\n\n    family_size = data.n_people.values\n    days_array = np.arange(N_DAYS, 0, -1)\n\n\n    choice_array_num = _build_choice_array(data, N_DAYS)\n    penalty_matrix = _precompute_penalties(choice_array_num, family_size)\n    accounting_matrix = _precompute_accounting(max_day_count=MAX_OCCUPANCY, max_diff=MAX_OCCUPANCY)\n    \n\n    def cost_function(prediction):\n        penalty, accounting_cost, daily_occupancy = _compute_cost_fast(\n            prediction=prediction,\n            family_size=family_size, \n            days_array=days_array, \n            penalty_matrix=penalty_matrix, \n            accounting_matrix=accounting_matrix,\n            MAX_OCCUPANCY=MAX_OCCUPANCY,\n            MIN_OCCUPANCY=MIN_OCCUPANCY,\n            N_DAYS=N_DAYS\n        )\n        \n        return penalty + accounting_cost\n    \n    return cost_function\n\n# Build your \"cost_function\"\ncost_function = build_cost_function(data)\n\n# Run it on default submission file\noriginal = submission['assigned_day'].values\noriginal_score = cost_function(original)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stochastic_product_search(top_k, fam_size, original, choice_matrix, \n                              disable_tqdm=False, verbose=10000,\n                              n_iter=500, random_state=2019):\n\n    best = original.copy()\n    best_score = cost_function(best)\n    \n    np.random.seed(random_state)\n\n    for i in tqdm(range(n_iter), disable=disable_tqdm):\n        t1 = time()\n        time_array.append(t1 - start_time)\n        fam_indices = np.random.choice(range(choice_matrix.shape[0]), size=fam_size)\n        changes = np.array(list(product(*choice_matrix[fam_indices, :top_k].tolist())))\n\n        for change in changes:\n            new = best.copy()\n            new[fam_indices] = change\n\n            new_score = cost_function(new)\n\n            if new_score < best_score:\n                best_score = new_score\n                best = new\n        \n        if new_score < best_score:\n            best_score = new_score\n            best = new\n    \n        if verbose and i % verbose == 0:\n            print(f\"Iteration #{i}: Best score is {best_score:.2f}\")\n    return best ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"choice_matrix = data.loc[:, 'choice_0': 'choice_9'].values\n\ntime_array = []\nstart_time = time()\n\n\n# Running the algorithm with three rounds\nbest = stochastic_product_search(\n    choice_matrix=choice_matrix, \n    top_k=5,\n    fam_size=5, \n    original=original, \n    n_iter=1,\n    disable_tqdm=False,\n    verbose=2000\n)\n\nend_time = time()\ntotal_time = end_time-start_time\ntime_array.append(total_time)\nprint(f\"Algorithm 1 took\", total_time, \"seconds\")\n\nbars = range(1, len(time_array) + 1)\ny_pos = np.arange(len(bars))\nplt.plot(y_pos, time_array)\n\nplt.title('Stochastic Time Graph')\nplt.xlabel('No. of Iterations')\nplt.ylabel('Time (Sec)')\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Algorithm 1: Efficiency Experiments \n**Score:**\n\n100000200.24\n\n**Actual Running Time:**\n\n0.1721806526184082 seconds\n\n**Worst Case Time Complexity:**\n\nO(N²) = Quadratic Time \n\n**Best Case Time Complexity:**\n\nO(N) = Linear Time \n\n**Time Complexity Graph:**\n\nLooks to be Linear O(N)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Algorithm 2 - Fast cost function using Numba JIT\n### Using lists as data structure","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#retreived from https://www.kaggle.com/nickel/250x-faster-cost-function-with-numba-jit\nprediction = submission['assigned_day'].values\ndesired = data.values[:, :-1]\nfamily_size = data.n_people.values\npenalties = np.asarray([\n    [\n        0,\n        50,\n        50 + 9 * n,\n        100 + 9 * n,\n        200 + 9 * n,\n        200 + 18 * n,\n        300 + 18 * n,\n        300 + 36 * n,\n        400 + 36 * n,\n        500 + 36 * n + 199 * n,\n        500 + 36 * n + 398 * n\n    ] for n in range(family_size.max() + 1)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@njit()\ndef jited_cost(prediction, desired, family_size, penalties):\n    N_DAYS = 100\n    MAX_OCCUPANCY = 300\n    MIN_OCCUPANCY = 125\n    penalty = 0\n    daily_occupancy = np.zeros(N_DAYS + 1, dtype=np.int64)\n    for i in range(len(prediction)):\n        n = family_size[i]\n        pred = prediction[i]\n        n_choice = 0\n        for j in range(len(desired[i])):\n            if desired[i, j] == pred:\n                break\n            else:\n                n_choice += 1\n        \n        daily_occupancy[pred - 1] += n\n        penalty += penalties[n, n_choice]\n\n    accounting_cost = 0\n    n_out_of_range = 0\n    daily_occupancy[-1] = daily_occupancy[-2]\n    for day in range(N_DAYS):\n        n_next = daily_occupancy[day + 1]\n        n = daily_occupancy[day]\n        n_out_of_range += (n > MAX_OCCUPANCY) or (n < MIN_OCCUPANCY)\n        diff = abs(n - n_next)\n        for j in range (1, 6):\n            accounting_cost += max(0, (n-125.0) / 400.0 * n**(0.5 + diff / 50.0))/j**2\n        \n\n    penalty += accounting_cost\n    return penalty\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time()\n\nprint(\"Best Score:\", jited_cost(prediction, desired, family_size, penalties))\n\nend_time = time()\ntotal_time = end_time-start_time\nprint(f\"Algorithm 2 took\", total_time, \"seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Algorithm 2: Efficiency Experiments \n**Score:**\n\n12824467.249055987\n\n**Actual Running Time:**\n\nThe actual running time is 0.00044918060302734375 seconds\n\n**Worst Case Time Complexity:**\n\nO(N²) = Quadratic Time\n\n**Best Case Time Complexity:**\n\nO(N) = Linear Time\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Experiments Discussion\n\nAlgorithm 1 gives a best score of over 100 million, which is horrible for an algorithm that does not split families up. But this score is better and faster than the score when not adjusting for revenge of the accountants. If this algorithm was run over 50,000 + iterations with multiple rounds the score should look somwhere around 70,000. Similarly to Algorithm 2, the time complexity in the worst case is not optimal as it's quadratic time. The actual running time is also very efficient and quick compared to assignment 1; 0.1655 seconds to 0.1595 seconds.\n\nAlgorithm 2 has a best score of over 100 million, which again is not great. This score has been adjusted using revenge of the accountants. It's time complexity in the worst case is not optimal with quadratic time but it's actual running time is very efficient and quick at 0.0004 seconds.\n\nOverall, when adjusting for revenge of the accounts, the scores and actual running time become are more efficient and quicker. Whilst the time complexity remains at Quadratic in worst case and Linear in the best case.\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}