{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Feedback, please\nPlease give me feedback.\n\nI'm especially wondering about my neural network classifier which scores 50% accuracy :**(\n\nThank you very much,\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy import stats\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import StandardScaler  \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score as auc\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import roc_auc_score as auc\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\")\ntrain_data = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\")\n\n\nprint(\"Shape of test_data \"+str(test_data.shape))\n\nprint(\"Shape of train_data \"+str(train_data.shape))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Going to try this person's data engineering: https://www.kaggle.com/asimandia/let-s-try-some-feature-engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_data['target']\ntrain_data_id = train_data['id']\n\ntest_data_id = test_data['id']\n\ntrain_data.drop(['target','id'], axis=1,inplace=True)\ntest_data.drop('id', axis=1,inplace=True)\n\nprint(\"New shape of test_data \"+str(test_data.shape))\n\nprint(\"New shape of train_data \"+str(train_data.shape))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Contents of train_data\\n\")\n\n\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Contents of test_data\\n\")\n\n\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for null items in the data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_val_count_by_col = train_data.isnull().sum()\n\nprint(\"Columns in train_data with missing values, and the number of missing values\")\nprint(missing_val_count_by_col[missing_val_count_by_col > 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fortunately there are none"},{"metadata":{},"cell_type":"markdown","source":"performing train/validation set split here"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_data\n\nprint(\"Shape of y_train before train/validation split is\"+str(y_train.shape))\nprint(\"Shape of X_train before train/validation split is\"+str(X_train.shape))\nprint(\"\\n\")\n#Split training set into a training set and validation set\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.9, test_size=0.1, random_state=0)\n\nprint(\"Shape of y_train is\"+str(y_train.shape))\nprint(\"Shape of X_train is\"+str(X_train.shape))\n\nprint(\"Shape of y_valid is\"+str(y_valid.shape))\nprint(\"Shape of X_valid is\"+str(X_valid.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of unique values for each feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing out the number of unique values for each column in the training data\nfor col_name in X_train.keys():\n    print(\"Column \" + col_name + \" has \" + str( len(X_train[col_name].unique()) ) + \" unique values\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at nominal variables with high unique value counts"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train[\"nom_6\"].value_counts().sort_values(ascending=False))\nprint(X_train[\"nom_7\"].value_counts().sort_values(ascending=False))\nprint(X_train[\"nom_8\"].value_counts().sort_values(ascending=False))\nprint(X_train[\"nom_9\"].value_counts().sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transform ordinal features to numeric labels\nJust going to transform all ordinal features to numeric labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nlabel_X_train = X_train.copy()\nlabel_X_valid = X_valid.copy()\nlabel_test_data = test_data.copy()\n\nsk_label_encoder = LabelEncoder()\n\nfor mycol in [\"ord_0\",\"ord_1\",\"ord_2\",\"ord_2\",\"ord_3\",\"ord_4\",\"ord_5\"]:\n    label_X_train[mycol] = sk_label_encoder.fit_transform(label_X_train[mycol])\n    label_X_valid[mycol] = sk_label_encoder.transform(label_X_valid[mycol])\n    label_test_data[mycol] = sk_label_encoder.transform(label_test_data[mycol])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlabel_X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlabel_X_valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlabel_test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling nominal valued features\n\nFor features that have high cardinality (>=10) will do hashing/frequency encoding\nFor features that have low cardinality (<10) will do one-hot encoding\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"low_cardinality_nom_cols = []\nhigh_cardinality_nom_cols = []\n\n\nfor nom_col in range(10):\n    nom_col_name = \"nom_\"+str(nom_col)\n    if label_X_train[nom_col_name].nunique() < 10:\n        low_cardinality_nom_cols.append(nom_col_name)\n    else:\n        high_cardinality_nom_cols.append(nom_col_name)\n\nprint(\"Nominal columns low cardinality (<=10):\", low_cardinality_nom_cols)\nprint(\"Nominal columns with high cardinality (>10):\", high_cardinality_nom_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert low cardinality nominal variables to one-hot encoded variables\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining everything into a single data frame so as to apply a uniform encoding across train, validation, test data sets\n#If this is not OK please provide your feedback, with references as to why (tyvm)\nlabel_X_train[\"kind\"] = \"train\"\nlabel_X_valid[\"kind\"] = \"valid\"\nlabel_test_data[\"kind\"] = \"test\"\n\nbig_df = pd.concat([label_X_train, label_X_valid, label_test_data], sort=False ).reset_index(drop=True)\n\nprint(\"big_df shape is \"+str(big_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor col in low_cardinality_nom_cols:\n    temp_df_to_concat = pd.get_dummies(big_df[col], prefix=col)\n    big_df = pd.concat([big_df, temp_df_to_concat], axis=1)\n    big_df.drop([col],axis=1, inplace=True)\n\n\nfor col in high_cardinality_nom_cols:\n        big_df[f\"hash_{col}\"] = big_df[col].apply( lambda x: hash(str(x)) % 5000)\n        \n\n#Not sure if I can run this over all of big_df. In the example the coder runs it over df_train only\n\n#Just modify training or validation data set\n\nbig_df_train_valid = big_df.loc[ (big_df[\"kind\"] == \"train\") | (big_df[\"kind\"]==\"valid\") ]\nbig_df_test = big_df.loc[big_df[\"kind\"] == \"test\"]\n\nfor col in high_cardinality_nom_cols:\n    enc_nom_1 =  (big_df_train_valid.groupby(col).size() ) / len(big_df_train_valid)\n    big_df_train_valid[f\"freq_{col}\"] = big_df_train_valid[col].apply( lambda x : enc_nom_1[x])\n\nfor col in high_cardinality_nom_cols:\n    enc_nom_1 =  (big_df_test.groupby(col).size() ) / len(big_df_test)\n    big_df_test[f\"freq_{col}\"] = big_df_test[col].apply( lambda x : enc_nom_1[x])\n    \nlabel_X_train = big_df_train_valid.loc[ big_df[\"kind\"]==\"train\" ]\nlabel_X_valid = big_df_train_valid.loc[ big_df[\"kind\"]==\"valid\" ]\nlabel_test_data = big_df_test.loc[ big_df[\"kind\"]==\"test\" ]\n\nlabel_X_train.drop(\"kind\", axis=1, inplace=True)\nlabel_X_valid.drop(\"kind\", axis=1, inplace=True)\nlabel_test_data.drop(\"kind\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_X_valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"shape of label_test_data \"+str(label_test_data.shape))\nprint(\"shape of label_X_train \"+str(label_X_train.shape))\nprint(\"shape of label_X_valid \"+str(label_X_valid.shape))\n\ndel big_df\ndel big_df_test\ndel big_df_train_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n#More encoding. Borrowed idea from another notebook. Trying other things were too slow\n\nbinary_dict = {\"T\":1, \"F\":0, \"Y\":1, \"N\":0}\n\n\nlabel_X_train[\"bin_3\"] = label_X_train[\"bin_3\"].map(binary_dict)\nlabel_X_train[\"bin_4\"] = label_X_train[\"bin_4\"].map(binary_dict)\n\nlabel_X_valid[\"bin_3\"] = label_X_valid[\"bin_3\"].map(binary_dict)\nlabel_X_valid[\"bin_4\"] = label_X_valid[\"bin_4\"].map(binary_dict)\n\nlabel_test_data[\"bin_3\"] = label_test_data[\"bin_3\"].map(binary_dict)\nlabel_test_data[\"bin_4\"] = label_test_data[\"bin_4\"].map(binary_dict)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now I'm going to drop old features\n\nin label_X_train I will drop these:\n\n* `high_cardinality_nom_cols`\n\nin label_X_valid I will drop these:\n* `high_cardinality_nom_cols`\n\nin label_test_data I will drop these:\n* `high_cardinality_nom_cols`\n\n*Note*: In the cell above I dropped the `low_cardinality_nom_cols` as I one-hot encoded them."},{"metadata":{"trusted":true},"cell_type":"code","source":"label_X_train.drop(high_cardinality_nom_cols, axis=1, inplace=True)\nlabel_X_valid.drop(high_cardinality_nom_cols, axis=1, inplace=True)\nlabel_test_data.drop(high_cardinality_nom_cols, axis=1, inplace=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_X_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So I've massaged the training a validation data\nThere should be an equal number of rows in the y_train and label_X_train pairs and the y_val, label_X_val pairs"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Rows of label_X_train \"+str(label_X_train.shape[0]))\nprint(\"Rows of y_train \"+str(y_train.shape[0]))\nprint(\"Rows of label_X_valid \"+str(label_X_valid.shape[0]))\nprint(\"Rows of y_valid \"+str(y_valid.shape[0]))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build a Model\n[SKLearn AdaBoostClassifier FTW!](https://scikit-learn.org/stable/modules/ensemble.html#adaboost)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_boost_model = AdaBoostClassifier(n_estimators=100, random_state=0, learning_rate=0.05, base_estimator=DecisionTreeClassifier(max_depth=10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trying a [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using a StandardScaler as the sklearn documents suggest scaling the inputs\nneural_model = MLPClassifier(hidden_layer_sizes=(96,96,48,48,24,12,6,3,1), \n                             solver=\"adam\", \n                             batch_size=\"auto\", \n                             #learning_rate=\"adaptive\",\n                             learning_rate_init=0.002,\n                             max_iter=200,\n                             n_iter_no_change=10,\n                             random_state=1,\n                             verbose=True\n                            )\n\nNNPipeline = Pipeline([(\"scaler\",StandardScaler()), (\"NN\",neural_model)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trying a [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient_boost_model = GradientBoostingClassifier(n_estimators=50)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So going to test each one out by doing the following:\n\nGoing to do k-fold cross validation (TODO: add reference) with `n_folds` folds\n\nPer the competition will do ROC AUC scoring.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#I was thinking of doing my own train/valid split\n#but realized with the cross_val_score() function, I need to\n#recombine my train/validation sets and let the internal functionality of cross_val_score()\n#do this splitting for me. So that's why I'm recombining them below :\\\nnew_X_train = pd.concat([label_X_train, label_X_valid], axis=0)\nnew_y_train = pd.concat([y_train, y_valid], axis=0)\nnew_X_train_scaled = pd.DataFrame()\nmy_columns= new_X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nn_folds = 7\n\nkfold = KFold(n_splits=n_folds, shuffle=False, random_state=42)\n\ncv_results = cross_val_score(gradient_boost_model, new_X_train.values, new_y_train,\n                            cv=kfold, scoring='roc_auc', n_jobs=-1)\n\nprint(\"gradient_boost_model average results\",cv_results.mean())\n\ncv_results = cross_val_score(ada_boost_model, new_X_train.values, new_y_train,\n                            cv=kfold, scoring='roc_auc', n_jobs=-1)\n\nprint(\"ada_boost_model average results\",cv_results.mean())\n\n#cv_results = cross_val_score(NNPipeline, new_X_train.values, new_y_train,\n#                            cv=kfold, scoring='roc_auc', n_jobs=-1)\n\n#print(\"NNPipeline average results\",cv_results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ngradient_boost_model.fit(new_X_train, new_y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = gradient_boost_model.predict(label_test_data)\n\nmyscore = gradient_boost_model.score(label_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.hist(y_test_pred, density=True, bins=2)\n#plt.xticks(x+0.5,['0','1'])\nplt.ylabel(\"number of predictions\")\nplt.xlabel(\"values\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id':test_data_id, 'target':y_test_pred})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}