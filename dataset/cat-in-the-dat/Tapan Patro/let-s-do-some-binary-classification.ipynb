{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('../input/cat-in-the-dat/train.csv', nrows=20000)\ntest = pd.read_csv('../input/cat-in-the-dat/test.csv', nrows=200000)\n\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check How many variable we need to predict\ntrain['target'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Its A Binary Classificatoin"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets Drop What not requeired .. In this case Both have id which need to be removed\n\ny_train = train['target']\ntest_id = test['id'] # Future Requirement\ntrain.drop(['id', 'target'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train, y_train, test_size=0.33, stratify=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import LabelEncoder\n\n# #Auto encodes any dataframe column of type category or object.\n# def dummyEncode(df):\n#         columnsToEncode = list(df.select_dtypes(include=['category','object']))\n#         s1 = ['a', 'b', np.nan]\n#         le = LabelEncoder()\n#         for feature in df.columns:\n#             try:\n#                 df[feature] = le.fit_transform(df[feature])\n#             except:\n#                 print('Error encoding '+feature)\n#         return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n#Auto encodes any dataframe column of type category or object.\ndef dummyEncode(df):\n    s1 = [ 'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']\n    \n    for feature in s1:\n        dummy = pd.get_dummies(df['{}'.format(feature)])\n        df = pd.concat([df, dummy], axis=1)\n        \n    return df\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dummy = pd.get_dummies(X_train['nom_1'])\n# # X_train = X_train.drop(['nom_1'], axis=1, inplace=True)\n# X_train = pd.concat([X_train, dummy], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = dummyEncode(X_train)\nX_test = dummyEncode(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# X_train = pd.get_dummies(X_train, columns=X_train.columns, drop_first=True, sparse=True)\n# X_test = pd.get_dummies(X_test, columns=X_test.columns, drop_first=True, sparse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = X_train.sparse.to_coo().tocsr()\n# X_test = X_test.sparse.to_coo().tocsr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TF_Map = { 'T' : 1, 'F' : 0}\nYN_Map = { 'Y' : 1, 'N' : 0}\n\n\nX_train['bin_3_'] =  X_train['bin_3'].map(TF_Map)\nX_train['bin_4_'] = X_train['bin_4'].map(YN_Map)\n\nX_test['bin_3_'] = X_test['bin_3'].map(TF_Map)\nX_test['bin_4_'] = X_test['bin_4'].map(YN_Map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dropExtrafeatures(df):\n    df.drop([ 'bin_4', 'bin_3', 'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5'], axis=1, inplace=True)\n    return df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = dropExtrafeatures(X_train)\nX_test = dropExtrafeatures(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Looks like files are having diff count of feature created."},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = X_train.iloc[:X_train.shape[0], :]\n# X_test = X_test.iloc[:X_train.shape[0], :]\n\n\nX_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get missing columns in the training test\nmissing_cols = set( X_train.columns ) - set( X_test.columns )\n# Add a missing column in test set with default value equal to 0\nfor c in missing_cols:\n    X_test[c] = 0\n# Ensure the order of column in the test set is in the same order than in train set\nX_test = X_test[X_train.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if (str(X_train.dtypes) == 'object'):\n#     print(X_train.columns)\nX_train.bin_4_.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train.bin_4[:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # It Gives us Memory error SO I am going to use PCA overit\n\n# from sklearn.preprocessing import StandardScaler \n# sc = StandardScaler() \n  \n# X_train = sc.fit_transform(X_train) \n# X_test = sc.transform(X_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.decomposition import PCA \n  \n# pca = PCA(n_components = 2) \n  \n# X_train = pca.fit_transform(X_train) \n# X_test = pca.transform(X_test) \n  \n# explained_variance = pca.explained_variance_ratio_ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Parameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = np.array(X_train).tocsr()\n# X_test = np.array(X_test).tocsr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# neigh = LogisticRegression()\n# parameters = {'C':[0.01,0.1,1,10,100]}\n# # clf_search = GridSearchCV(neigh, parameters, cv=3, scoring='roc_auc')\n# clf_search =  RandomizedSearchCV(neigh, param_distributions=parameters, n_iter=10, cv=5, iid=False)\n# clf_search.fit(X_train, y_train)\n\n# print(clf_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotROCCurveGraph(X_train_roc, y_train_roc, X_test_roc, y_test_roc, best_alpha):\n    # for i in tqdm(parameters):\n    neigh = LogisticRegression( C=best_alpha, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l2',\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)\n    neigh.fit(X_train_roc, y_train_roc)\n\n    y_train_pred = neigh.predict_proba(X_train_roc)[:,1]\n    y_test_pred = neigh.predict_proba(X_test_roc)[:,1]\n\n    train_fpr, train_tpr, tr_thresholds = roc_curve(y_train_roc, y_train_pred)\n    test_fpr, test_tpr, te_thresholds = roc_curve(y_test_roc, y_test_pred)\n\n    m_Auc = str(auc(train_fpr, train_tpr))\n\n\n    plt.plot(train_fpr, train_tpr, label=\"train AUC =\"+str(auc(train_fpr, train_tpr)))\n    plt.plot(test_fpr, test_tpr, label=\"test AUC =\"+str(auc(test_fpr, test_tpr)))\n    plt.legend()\n    plt.xlabel(\"FPR\")\n    plt.ylabel(\"TPR\")\n    plt.title(\"ROC Curve\")\n    plt.grid()\n    plt.show()\n    \n    \n    \n    return neigh, m_Auc,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf, m1_Auc, = plotROCCurveGraph(X_train, y_train, X_test, y_test, 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = dummyEncode(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TF_Map = { 'T' : 1, 'F' : 0}\nYN_Map = { 'Y' : 1, 'N' : 0}\n\n\ntest['bin_3_'] =  test['bin_3'].map(TF_Map)\ntest['bin_4_'] = test['bin_4'].map(YN_Map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = dropExtrafeatures(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_cols = set( X_train.columns ) - set( test.columns )\n# Add a missing column in test set with default value equal to 0\nfor c in missing_cols:\n    test[c] = 0\n# Ensure the order of column in the test set is in the same order than in train set\ntest = test[X_train.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_1st = test[:10000]\n# test_2nd = test[10000:20000]\n# test_3rd = test[20000:30000]\n# test_4th = test[30000:40000]\n# test_5th = test[40000:50000]\n\ndef index_marks(nrows, chunk_size):\n    return range(1 * chunk_size, (nrows // chunk_size + 1) * chunk_size, chunk_size)\n\ndef split(dfm, chunk_size):\n    indices = index_marks(dfm.shape[0], chunk_size)\n    return np.split(dfm, indices)\n\nchunks = split(test, 10000)\n\nresult_toSubmit = []\n\nfor c in chunks:\n    if (c.shape[0] != 0):\n        result_toSubmit.extend(clf.predict(c))\n        print(\"Shape: {}; {}\".format(c.shape, c.index))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_toSubmit[:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(result_toSubmit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': test_id, 'target': result_toSubmit})\nsubmission.to_csv('v2_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}