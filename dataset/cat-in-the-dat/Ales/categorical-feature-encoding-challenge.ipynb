{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task\nhttps://www.kaggle.com/c/cat-in-the-dat"},{"metadata":{},"cell_type":"markdown","source":"# Load dependencies and data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer \nfrom sklearn.preprocessing import FunctionTransformer, OneHotEncoder, OrdinalEncoder, LabelBinarizer, MinMaxScaler\nfrom sklearn.model_selection import cross_validate, learning_curve, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\n\nrandom_state = 42\nnp.random.seed(random_state)\ncv = 4\n\nfor dirname, _, filenames in os.walk('input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df = pd.read_csv('/kaggle/input/cat-in-the-dat/train.csv', index_col='id')\nsample_submission_df = pd.read_csv('/kaggle/input/cat-in-the-dat/sample_submission.csv')\ntest_df = pd.read_csv('/kaggle/input/cat-in-the-dat/test.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = shuffle(train_df, random_state=random_state)\ntrain_Y = train_df['target'].copy()\ntrain_X = train_df.drop('target', axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Pipline with Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pipline(estimator):\n    return Pipeline(steps=[\n        ('preproc', ColumnTransformer([\n            ('bin_0_2', 'passthrough', ['bin_0', 'bin_1', 'bin_2']),\n            ('bin_3_4', FunctionTransformer(func=lambda X: X.replace({'F': 0, 'T': 1, 'N': 0, 'Y': 1}), validate=False), [\n                'bin_3', 'bin_4']\n            ),\n            ('nom_0_4', OneHotEncoder(sparse=True, handle_unknown='ignore'), [\n                'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\n            ),\n            ('ord', Pipeline(steps=[\n                ('replace', ColumnTransformer([\n                    ('encoder',  OrdinalEncoder(categories=[\n                        ['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'],\n                        ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot'],\n                        np.sort(train_df['ord_3'].unique()),\n                        np.sort(train_df['ord_4'].unique()),\n                        np.sort(train_df['ord_5'].unique()),\n                    ]), ['ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']),\n                ], remainder='passthrough')),\n                ('mm_scaler', MinMaxScaler())\n            ]), ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day', 'month'] )\n        ])),    \n        ('est', estimator)\n    ])\n\nxgb_pipline = get_pipline(XGBClassifier(objective='binary:logistic', n_estimators=1100, max_depth=6, gamma=5))\nlogit_pipline = get_pipline(LogisticRegression(solver='lbfgs', max_iter=225, C=0.12, random_state=random_state))\n\npipline = VotingClassifier([('xgb', xgb_pipline), ('logit', logit_pipline)], voting='soft', n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'est__solver': ['lbfgs'], 'est__C': [0.11, 0.12, 0.13], 'est__max_iter': [225, 250, 275]}\ngs_cv = GridSearchCV(logit_pipline, params, scoring='roc_auc', cv=cv, n_jobs=-1, return_train_score=True, verbose=1)\n\n#print('Best params {}, score {}'.format(gs_result.best_params_, gs_result.best_score_))\n#Best params {'est__C': 0.12, 'est__max_iter': 225, 'est__solver': 'lbfgs'}, score 0.7998486767216677","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = cross_validate(\n    pipline, train_X, train_Y, scoring='roc_auc', cv=cv, n_jobs=-1, \n    return_train_score=True, return_estimator=True, verbose=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cv_scores['train_score'])\nprint(cv_scores['test_score'])\ncv_scores.keys()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nscores = np.array([est.predict_proba(test_df) for est in cv_scores['estimator']])\nmean_scores = scores.mean(axis=0)[:, 0]\n\nsubmit_df = pd.DataFrame({ 'id': test_df.index, 'target': mean_scores })\nsubmit_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y):\n    plt.figure()\n    plt.title(title)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5), \n        random_state=random_state)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    plt.show()\n\nplot_learning_curve(logit_pipline, 'logit', train_X, train_Y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}