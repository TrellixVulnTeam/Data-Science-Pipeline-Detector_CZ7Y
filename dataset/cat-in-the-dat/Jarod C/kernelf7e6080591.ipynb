{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom collections import Counter\nfrom sklearn.linear_model import LogisticRegression\nimport time\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\ntrain=pd.read_csv('../input/cat-in-the-dat/train.csv', delimiter=',') \ntest = pd.read_csv('../input/cat-in-the-dat/test.csv', delimiter=',') \nid = test['id']\ntest = test.drop(columns=\"id\")\n\nbin3_map = {'T': 1, 'F': -1}\n\nbin4_map = {'Y': 1, 'N': -1}\n\nord1_map = {'Novice': 1, 'Contributor': 2,\n               'Expert': 3, 'Master': 4, 'Grandmaster': 5}\n\nord2_map = {'Freezing': 1, 'Cold': 2,\n               'Warm': 3, 'Hot': 4, 'Boiling Hot': 5, 'Lava Hot': 6}\n\nord3_map = {'a': 1, 'b': 2,\n               'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8,\n               'i': 9, 'j': 10, 'k': 11, 'l': 12,'m': 13, 'n': 14, 'o': 15}\n\nord4_map = {'A': 1, 'B': 2,\n               'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8,\n               'I': 9, 'J': 10, 'K': 11, 'L': 12,'M': 13, 'N': 14, 'O': 15,'P': 16, 'Q': 17,\n               'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23,\n               'X': 24, 'Y': 25, 'Z': 26}\n\ntrain['bin_3'] = train['bin_3'].map(bin3_map)\ntrain['bin_4'] = train['bin_4'].map(bin4_map)\ntrain['ord_1'] = train['ord_1'].map(ord1_map)\ntrain['ord_2'] = train['ord_2'].map(ord2_map)\ntrain['ord_3'] = train['ord_3'].map(ord3_map)\ntrain['ord_4'] = train['ord_4'].map(ord4_map)\n\ntrain['dy_sin'] = np.sin((train['day']-1)*(2.*np.pi/7))\ntrain['dy_cos'] = np.cos((train['day']-1)*(2.*np.pi/7))\ntrain['mnth_sin'] = np.sin((train['month']-1)*(2.*np.pi/12))\ntrain['mnth_cos'] = np.cos((train['month']-1)*(2.*np.pi/12))\n\ntrain = train.drop(columns=\"day\")\ntrain = train.drop(columns=\"month\")\ntrain = train.drop(columns=\"ord_5\")\ntrain = train.drop(columns=\"nom_5\")\ntrain = train.drop(columns=\"nom_6\")\ntrain = train.drop(columns=\"nom_7\")\ntrain = train.drop(columns=\"nom_8\")\ntrain = train.drop(columns=\"nom_9\")\ntrain = train.drop(columns=\"id\")\ntarget=train['target']\ntrain = train.drop(columns=\"target\")\ntrain['target']=target\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['bin_3'] = test['bin_3'].map(bin3_map)\ntest['bin_4'] = test['bin_4'].map(bin4_map)\ntest['ord_1'] = test['ord_1'].map(ord1_map)\ntest['ord_2'] = test['ord_2'].map(ord2_map)\ntest['ord_3'] = test['ord_3'].map(ord3_map)\ntest['ord_4'] = test['ord_4'].map(ord4_map)\n\ntest['dy_sin'] = np.sin((test['day']-1)*(2.*np.pi/7))\ntest['dy_cos'] = np.cos((test['day']-1)*(2.*np.pi/7))\ntest['mnth_sin'] = np.sin((test['month']-1)*(2.*np.pi/12))\ntest['mnth_cos'] = np.cos((test['month']-1)*(2.*np.pi/12))\n\ntest = test.drop(columns=\"day\")\ntest = test.drop(columns=\"month\")\ntest = test.drop(columns=\"ord_5\")\ntest = test.drop(columns=\"nom_5\")\ntest = test.drop(columns=\"nom_6\")\ntest = test.drop(columns=\"nom_7\")\ntest = test.drop(columns=\"nom_8\")\ntest = test.drop(columns=\"nom_9\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohn=OneHotEncoder(sparse=False)\ncolumn_trans=make_column_transformer((OneHotEncoder(),['nom_0','nom_1',\n'nom_2','nom_3','nom_4']),remainder='passthrough')\n\ntest = column_trans.fit_transform(test)\n\ndata=column_trans.fit_transform(train)\nn = data.shape[0]\nm=int(0.8*n)\n\nX_train = data[:,0:39]\ny_train = data[:,39]\n\n\"\"\"\ntrain=data[:m,:]\ntest=data[m:-1,:]\n\nX_train=train[:,0:39]\ny_train=train[:,39]\n\nX_test=test[:,0:39]\ny_test=test[:,39]\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n          \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n          \"Naive Bayes\", \"QDA\"]\n\n\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    SVC(gamma=2, C=1),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1, max_iter=1000),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]\n\n\nnames = [\"Decision Tree\"]\nclassifiers = [ DecisionTreeClassifier]\n\ndepth_range = 9\n\ntuned_parameters_decisiontree = dict(max_depth = depth_range)\nprint(tuned_parameters_decisiontree)\n\n\nclf = GridSearchCV(\n         DecisionTreeClassifier(), tuned_parameters_decisiontree)\n\"\"\"\nclf = DecisionTreeClassifier(max_depth = 9)\nclf.fit(X_train, y_train)\n\"\"\"\nprint(\"Best parameters set found on development set:\")\nprint()\nprint(clf.best_params_)\nprint()\nprint(\"Grid scores on development set:\")\nprint()\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n    print(\"%0.3f (+/-%0.03f) for %r\"\n        % (mean, std * 2, params))\nprint()\nprint(\"Detailed classification report:\")\nprint()\nprint(\"The model is trained on the full development set.\")\nprint(\"The scores are computed on the full evaluation set.\")\nprint()\ny_true, y_pred = y_test, clf.predict(X_test)\nprint(classification_report(y_true, y_pred))\nprint()\n\"\"\"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ntree_range = list(range(9,16))\nfeature_range = list(range(9,16))\ndepth_range_forest = (list(range(9,16)))\ntuned_parameters_randomforest = dict(n_estimators = tree_range, max_depth = depth_range_forest, max_features = feature_range)\n\nclf2 = GridSearchCV(\n         RandomForestClassifier(), tuned_parameters_randomforest)\n\nclf2.fit(X_train, y_train)\n\nprint(\"Best parameters set found on development set:\")\nprint()\nprint(clf2.best_params_)\nprint()\nprint(\"Grid scores on development set:\")\nprint()\nmeans = clf2.cv_results_['mean_test_score']\nstds = clf2.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, clf2.cv_results_['params']):\n    print(\"%0.3f (+/-%0.03f) for %r\"\n        % (mean, std * 2, params))\nprint()\nprint(\"Detailed classification report:\")\nprint()\nprint(\"The model is trained on the full development set.\")\nprint(\"The scores are computed on the full evaluation set.\")\nprint()\ny_true, y_pred = y_test, clf2.predict(X_test)\nprint(classification_report(y_true, y_pred))\nprint()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = clf.predict_proba(test)[:,1]\n\nprint (results)\n\nsubmission = pd.DataFrame({'id': id, 'target': results})\nprint(submission)\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}