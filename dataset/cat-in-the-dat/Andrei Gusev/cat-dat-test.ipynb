{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/cat-in-the-dat/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MeanTargetEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, smoothing_intencity=10):\n        self.smoothing_intencity = smoothing_intencity\n        self.value_means = None\n        self.total_mean = None\n\n    def fit(self, x, y):\n        self.total_mean = y.mean()\n        self.value_means = []\n        for column in x.values.T:\n            column_value_means = {}\n            for value in np.unique(column):\n                value_mask = column == value\n                column_value_means[value] = (y[value_mask].sum() + self.total_mean * self.smoothing_intencity) / \\\n                        (np.sum(value_mask) + self.smoothing_intencity)\n            self.value_means.append(column_value_means)\n        return self\n    \n    def transform(self, x):\n        encoding = []\n        for column, value_mean_dict in zip(x.values.T, self.value_means):\n            column_encoding = np.zeros(column.shape, dtype=np.float64)\n            unseen = np.ones(column.shape, dtype=np.bool)\n            for value, mean_target in value_mean_dict.items():\n                value_mask = column == value\n                column_encoding[value_mask] = mean_target\n                unseen &= ~value_mask\n            column_encoding[unseen] = self.total_mean\n            encoding.append(column_encoding)\n        return np.vstack(encoding).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import chain\n\n\nclass CyclicEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, periods):\n        self.periods = periods\n        \n    def fit(self, *args):\n        return self\n    \n    def transform(self, x):\n        phases = (x.values / self.periods * 2 * np.pi)\n        return np.vstack(list(chain((np.sin(i), np.cos(i)) for i in phases.T))).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BIN_FEATURES = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\nbin_transformer = OneHotEncoder(drop='first')\n# Бинарные факторы кодируются флагами. OneHotEncoder удобно использовать, чтобы выставлять флаги для разных типов входных данных","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NOM_LOW_CARD_FEATURES = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\nnom_low_card_transformer = OneHotEncoder(drop='first')\n# Факторы с небольшим множеством значений можно кодировать one-hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NOM_HIGH_CARD_FEATURES = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nnom_high_card_transformer = MeanTargetEncoder(smoothing_intencity=20)\n# При большом количестве возможных значений фактора по отдельному значению может не быть достаточно примеров. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Постараемся сохранить порядок в порядковых факторах\nORDINAL_ALPHABET_FEATURES = ['ord_0', 'ord_3', 'ord_4', 'ord_5']\nordinal_alphabet_transformer = OrdinalEncoder()\n# Будем считать, что алфавитный порядок, выбираемый OrdinalEncoding по умолчанию, правильный\n\nORDINAL_ENUM_FEATURES = ['ord_1', 'ord_2']\nordibal_enum_transformer = OrdinalEncoder(categories=[\n    ['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster'],\n    ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot']\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CYCLIC_FEATURES = ['day', 'month']\ncyclic_transformer = CyclicEncoder([7, 12])\n# Кодировка синусом и косинусом позволяет сохранить близость не только между последовательными значениями, \n# но и между первыми и последними.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = data.drop('target', axis=1), data['target'].values\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_transformer = ColumnTransformer([\n    ('bin', bin_transformer, BIN_FEATURES), \n    ('nom_low_card', nom_low_card_transformer, NOM_LOW_CARD_FEATURES),\n    ('nom_high_card', nom_high_card_transformer, NOM_HIGH_CARD_FEATURES),\n    ('ord_alphabet', ordinal_alphabet_transformer, ORDINAL_ALPHABET_FEATURES),\n    ('ord_enum', ordibal_enum_transformer, ORDINAL_ENUM_FEATURES),\n    ('cyclic', cyclic_transformer, CYCLIC_FEATURES)\n])\nx_train_preproc = feature_transformer.fit_transform(x_train, y_train)\nx_val_preproc = feature_transformer.transform(x_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_model = LogisticRegression(C=.1).fit(x_train_preproc, y_train)\npred_lr_val = lr_model.predict_proba(x_val_preproc)[:, 1]\nroc_auc_score(y_val, pred_lr_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm_model = SVC(probability=True, C=10).fit(x_train_preproc[:20000], y_train[:20000])\npred_svm_val = svm_model.predict_proba(x_val_preproc)[:, 1]\nroc_auc_score(y_val, pred_svm_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_model = XGBClassifier(min_child_weight=2000, alpha=10).fit(x_train_preproc, y_train)\npred_xgb_val = xgb_model.predict_proba(x_val_preproc)[:, 1]\nroc_auc_score(y_val, pred_xgb_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = pd.read_csv('/kaggle/input/cat-in-the-dat/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_preproc = feature_transformer.transform(x_test)\npred_xgb_test = xgb_model.predict_proba(x_test_preproc)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': x_test['id'], 'target': pred_xgb_test})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}