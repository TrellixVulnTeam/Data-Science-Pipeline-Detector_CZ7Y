{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Categorical Feature Challenge"},{"metadata":{},"cell_type":"markdown","source":"We have been provided with a dataset that only has categorical variables and we are asked to try out different encoding schemes and compare how they perform.The competition is binary classification challenge with only categorical variables to train on."},{"metadata":{},"cell_type":"markdown","source":"### References"},{"metadata":{"trusted":false},"cell_type":"code","source":"#https://www.kaggle.com/cdeotte/high-scoring-lgbm-malware-0-702-0-775\n#https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm\n#https://www.kaggle.com/humananalog/xgboost-lasso\n#https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm\n#https://www.kaggle.com/mlisovyi/modular-good-fun-with-ligthgbm/output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import Necessary libraries:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport gc\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle=1\n\nif kaggle==0:\n    train=pd.read_csv(\"train.csv\")\n    test=pd.read_csv(\"test.csv\")\n    sample_submission=pd.read_csv(\"sample_submission.csv\")\n    \nelse:\n    train=pd.read_csv(\"../input/cat-in-the-dat/train.csv\")\n    test=pd.read_csv(\"../input/cat-in-the-dat/test.csv\")\n    sample_submission=pd.read_csv(\"../input/cat-in-the-dat/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the train dataset has 25 categorical columns with varying degree of cardinality.\n\nLet check the distribution of the target value to understand whether the dataset is balanced or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the target has lot of 0's than 1's.Its an unbalanced problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert all the columns to category datatype:\nfor f in train.columns:\n    if f==\"id\" or f==\"target\": continue\n    print(f'Converting {f} into category datatype\\n')\n    train[f]=train[f].astype('category')\n    test[f]=test[f].astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cardinality of the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"## For binary columns , the cardinality will be 2.Lets separate them out .\nbinary_columns=[c for c in train.columns if train[c].nunique()==2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns=[c for c in train.columns if (c not in binary_columns)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cardinality=[]\nfor c in categorical_columns:\n    if c=='id':continue\n    cardinality.append([c,train[c].nunique()])\ncardinality.sort(key=lambda x:x[1],reverse=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cardinality","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that there are 7 columns with high cardinality.Feature encoding for these columns may include frequency encoding which is based on the ranking of categories based on the frequency of occurence in the group.We check if the cols have same levels in both test and train.We encode only those columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns that can be safely label encoded\ngood_label_cols = [col for col in categorical_columns if \n                   set(train[col]) == set(test[col])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## from https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm\ndef frequency_encoding(variable):\n    t = pd.concat([train[variable], test[variable]]).value_counts().reset_index()\n    t = t.reset_index()\n    t.loc[t[variable] == 1, 'level_0'] = np.nan\n    t.set_index('index', inplace=True)\n    max_label = t['level_0'].max() + 1\n    t.fillna(max_label, inplace=True)\n    return t.to_dict()['level_0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#frequency_encoded_columns=['nom_9','nom_8','nom_7','nom_6','nom_5','ord_5','ord_4']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for variable in tqdm(good_label_cols):\n    freq_encod_dict=frequency_encoding(variable)\n    train[variable+'_FE']=train[variable].map(lambda x:freq_encod_dict.get(x,np.nan))\n    test[variable+'_FE']=test[variable].map(lambda x:freq_encod_dict.get(x,np.nan))\n    categorical_columns.remove(variable)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n\ndef factorize(train, test, features, na_value=-9999, full=False, sort=True):\n    \"\"\"Factorize categorical features.\n    Parameters\n    ----------\n    train : pd.DataFrame\n    test : pd.DataFrame\n    features : list\n           Column names in the DataFrame to be encoded.\n    na_value : int, default -9999\n    full : bool, default False\n        Whether use all columns from train/test or only from train.\n    sort : bool, default True\n        Sort by values.\n    Returns\n    -------\n    train : pd.DataFrame\n    test : pd.DataFrame\n    \"\"\"\n\n    for column in features:\n        if full:\n            vs = pd.concat([train[column], test[column]])\n            labels, indexer = pd.factorize(vs, sort=sort)\n        else:\n            labels, indexer = pd.factorize(train[column], sort=sort)\n\n        train[column+'_LE'] = indexer.get_indexer(train[column])\n        test[column+'_LE'] = indexer.get_indexer(test[column])\n\n        if na_value != -1:\n            train[column] = train[column].replace(-1, na_value)\n            test[column] = test[column].replace(-1, na_value)\n\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexer = {}\n# for col in tqdm(categorical_columns):\n#     if col == 'id': continue\n#     _, indexer[col] = pd.factorize([train[col],test[col]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#categorical_columns.remove('id')\ntrain,test=factorize(train,test,categorical_columns,full=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train,test=factorize(train,test,frequency_encoded_columns,full=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for col in tqdm(categorical_columns):\n#     if col=='id':continue\n#     train[col+'_LE']=indexer[col].get_indexer(train[col])\n#     test[col+'_LE']=indexer[col].get_indexer(test[col])\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we do one hot encoding for all the binary categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat_dum=pd.DataFrame()\ntest_cat_dum=pd.DataFrame()\nfor c_ in binary_columns:\n    if c_=='target':continue\n    train_cat_dum=pd.concat([train_cat_dum,pd.get_dummies(train[c_],prefix=c_).astype(np.uint8)],axis=1)\n    test_cat_dum=pd.concat([test_cat_dum,pd.get_dummies(test[c_],prefix=c_).astype(np.uint8)],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat_dum.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.concat([train,train_cat_dum],axis=1)\ntest=pd.concat([test,test_cat_dum],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now,we have taken care of all the categorical variables.Lets build the model and with 5 fold cross validation .Before this ,lets delete the original categorical columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns,test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_remove=['id', 'bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1',\n       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n       'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day', 'month','id_LE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(cols_to_remove,axis=1)\ntest=test.drop(cols_to_remove,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Importing required libraries:\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train['target']\ndel train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds=5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds=StratifiedKFold(n_splits=5,shuffle=True,random_state=1234)\nfeats=[f for f in train.columns if f not in ['id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_preds = np.zeros(train.shape[0])\nsub_preds = np.zeros(test.shape[0])\n    \nfeature_importance_df = pd.DataFrame()\ncategorical_features=[c for c in train.columns if c not in ['id_LE']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# param = {'num_leaves': 60,\n#          'min_data_in_leaf': 60, \n#          'objective':'binary',\n#          'max_depth': -1,\n#          'learning_rate': 0.1,\n#          \"boosting\": \"gbdt\",\n#          \"feature_fraction\": 0.8,\n#          \"bagging_freq\": 1,\n#          \"bagging_fraction\": 0.8 ,\n#          \"bagging_seed\": 11,\n#          \"metric\": 'auc',\n#          \"lambda_l1\": 0.1,\n#          \"random_state\": 133,\n#          \"verbosity\": -1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#params after bayesian optimisation:\n\nparam = {'num_leaves': 31,\n         'min_data_in_leaf': 69, \n         'objective':'binary',\n         'max_depth': 4,\n         'learning_rate': 0.06,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.33,\n         \"metric\": 'auc',\n         \"lambda_l1\": 0.01,\n         \"random_state\": 133,\n         \"verbosity\": -1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n_folds,(train_idx,valid_idx) in enumerate(folds.split(train.values,y.values)):\n    print(\"fold n°{}\".format(n_folds+1))\n    trn_data = lgb.Dataset(train.iloc[train_idx][feats],\n                           label=y.iloc[train_idx],\n                           categorical_feature=categorical_features\n                          )\n    val_data = lgb.Dataset(train.iloc[valid_idx][feats],\n                           label=y.iloc[valid_idx],categorical_feature=categorical_features\n                          )\n\n    num_round = 10000\n    clf = lgb.train(param,\n                    trn_data,\n                    num_round,\n                    valid_sets = [trn_data, val_data],\n                    verbose_eval=100,\n                    early_stopping_rounds = 200)\n    \n    #clf.fit(train_x,train_y,eval_set=[(train_x,train_y),(valid_x,valid_y)],verbose=500,eval_metric=\"auc\",early_stopping_rounds=100)\n    \n    oof_preds[valid_idx]=clf.predict(train.iloc[valid_idx][feats],num_iteration=clf.best_iteration)\n    sub_preds+=clf.predict(test[feats],num_iteration=clf.best_iteration)/folds.n_splits\n    \n    fold_importance_df=pd.DataFrame()\n    fold_importance_df['features']=feats\n    fold_importance_df['importance']=clf.feature_importance(importance_type='gain')\n    fold_importance_df['folds']=n_folds+1\n    print(f'Fold {n_folds+1}: Most important features are:\\n')\n    for i in np.argsort(fold_importance_df['importance'])[-5:]:\n        print(f'{fold_importance_df.iloc[i,0]}-->{fold_importance_df.iloc[i,1]}')\n    \n    feature_importance_df=pd.concat([feature_importance_df,fold_importance_df],axis=0)\n    \n    print('Fold %2d AUC : %.6f' % (n_folds + 1, roc_auc_score(y.iloc[valid_idx], oof_preds[valid_idx])))\n    del clf\n    gc.collect()\n    \n\n\nprint('Full auc score %.6f' % (roc_auc_score(y,oof_preds)))\n\ntest['target']=sub_preds\n              ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target']=sub_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sample_submission.to_csv(\"sample_submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}