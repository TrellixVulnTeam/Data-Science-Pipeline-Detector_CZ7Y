{"cells":[{"metadata":{},"cell_type":"markdown","source":"I wanted to compare model performance between logistic regression and Xgboost. The logistic regression model uses dummy variables for all catagorical data, whereas the XGB model uses a simple encoder for all catagorical columns. \n\nOverall, I saw a better performance with the Logistic Regression model compared to the XGB"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import SelectFromModel\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Pull data into dataframes\nsubmission = pd.read_csv(\"/kaggle/input/cat-in-the-dat/sample_submission.csv\")\ntrain = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First look at training data\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First look at testing data\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save 'id' for submission and drop it from test data\ntest_id = test[\"id\"]\ntest.drop(['id'],inplace=True, axis = 1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare training data prior to encoding\ny = train['target']\nX = train.drop(['target', 'id'], axis = 1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What are all of the catagorical columns?\ncat_columns = [cols for cols in train.columns if train[cols].dtype == 'object']\nprint(cat_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode catagorical columns\nencoder = LabelEncoder()\nfor col in cat_columns:\n    X[col] = pd.DataFrame(encoder.fit_transform(X[col]))\n    test[col] = pd.DataFrame(encoder.fit_transform(test[col]))   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check data to ensure correct encoding\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create train and test datasets from training data for model validation\nXtrain,Xtest,ytrain,ytest = train_test_split(X,y,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create, train, and test XGB model\nmodel = XGBClassifier(n_estimators=500,scale_pos_weight=2,random_state=1,colsample_bytree=0.5)\nmodel.fit(Xtrain,ytrain)\npred = model.predict_proba(Xtest)[:, 1]\nscore = roc_auc_score(ytest, pred)\n\nprint(\"score: \", score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Can we improve our performance with creating dummy variables and using logistic regression?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reset test and other variables to use for logistic regression\ntest = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\")\ny2 = train['target']\nX2 = train.drop(['target', 'id'], axis = 1)\ntest.drop(['id'],inplace=True, axis = 1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dummies\ntraintest = pd.concat([X2, test])\ndummies = pd.get_dummies(traintest, columns=traintest.columns, sparse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What do dummies look like?\nX2 = dummies.iloc[:X2.shape[0], :]\ntest = dummies.iloc[X2.shape[0]:, :]\n\nprint(X2.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Speed up model\nX2 = X2.sparse.to_coo().tocsr()\ntest = test.sparse.to_coo().tocsr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create training and test data sets\nXtrain,Xtest,ytrain,ytest = train_test_split(X2,y,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create, train, and test Logistic Regression model\nmodel = LogisticRegression(solver='lbfgs', C = 0.1, max_iter=1000)\nmodel.fit(Xtrain,ytrain)\npred = model.predict_proba(Xtest)[:, 1]\nscore = roc_auc_score(ytest, pred)\n\nprint(\"score: \", score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We see a better performance with the logistic regression model + dummy variables, compared to XGB and encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission[\"id\"] = test_id\nsubmission[\"target\"] = model.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}