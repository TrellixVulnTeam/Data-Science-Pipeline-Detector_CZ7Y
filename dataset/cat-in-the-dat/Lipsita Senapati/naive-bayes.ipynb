{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np \nimport os\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/cat-in-the-dat/sample_submission.csv\")\ntrain = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.iloc[:,1:24].values\ny=train.iloc[:,24].values\nX1=test.iloc[:,1:24].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = train.isnull().sum().reset_index()\ntemp_df['Percentage'] = (temp_df[0]/len(train))*100\ntemp_df.columns = ['Column Name', 'Number of null values', 'Null values in percentage']\nprint(f\"The length of dataset is \\t {len(train)}\")\ntemp_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_X_1 = LabelEncoder()\nX[:,3] = labelencoder_X_1.fit_transform(X[:,3])\nX[:,4] = labelencoder_X_1.fit_transform(X[:,4])\nX[:,5] = labelencoder_X_1.fit_transform(X[:,5])\nX[:,6] = labelencoder_X_1.fit_transform(X[:,6])\nX[:,7] = labelencoder_X_1.fit_transform(X[:,7])\nX[:,8] = labelencoder_X_1.fit_transform(X[:,8])\nX[:,9] = labelencoder_X_1.fit_transform(X[:,9])\nX[:,10] = labelencoder_X_1.fit_transform(X[:,10])\nX[:,11] = labelencoder_X_1.fit_transform(X[:,11])\nX[:,12] = labelencoder_X_1.fit_transform(X[:,12])\nX[:,13] = labelencoder_X_1.fit_transform(X[:,13])\nX[:,14] = labelencoder_X_1.fit_transform(X[:,14])\nX[:,16] = labelencoder_X_1.fit_transform(X[:,16])\nX[:,17] = labelencoder_X_1.fit_transform(X[:,17])\nX[:,18] = labelencoder_X_1.fit_transform(X[:,18])\nX[:,19] = labelencoder_X_1.fit_transform(X[:,19])\nX[:,20] = labelencoder_X_1.fit_transform(X[:,20])\n\n\n\ny = labelencoder_X_1.fit_transform(y)\n\nX1[:,3] = labelencoder_X_1.fit_transform(X1[:,3])\nX1[:,4] = labelencoder_X_1.fit_transform(X1[:,4])\nX1[:,5] = labelencoder_X_1.fit_transform(X1[:,5])\nX1[:,6] = labelencoder_X_1.fit_transform(X1[:,6])\nX1[:,7] = labelencoder_X_1.fit_transform(X1[:,7])\n\nX1[:,8] = labelencoder_X_1.fit_transform(X1[:,8])\nX1[:,9] = labelencoder_X_1.fit_transform(X1[:,9])\nX1[:,10] = labelencoder_X_1.fit_transform(X1[:,10])\nX1[:,11] = labelencoder_X_1.fit_transform(X1[:,11])\nX1[:,12] = labelencoder_X_1.fit_transform(X1[:,12])\nX1[:,13] = labelencoder_X_1.fit_transform(X1[:,13])\nX1[:,14] = labelencoder_X_1.fit_transform(X1[:,14])\nX1[:,16] = labelencoder_X_1.fit_transform(X1[:,16])\nX1[:,17] = labelencoder_X_1.fit_transform(X1[:,17])\nX1[:,18] = labelencoder_X_1.fit_transform(X1[:,18])\nX1[:,19] = labelencoder_X_1.fit_transform(X1[:,19])\nX1[:,20] = labelencoder_X_1.fit_transform(X1[:,20])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us Import the Important Libraries  to train our Model for Machine Learning \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split  \nfrom sklearn.model_selection import cross_val_score   \nfrom sklearn.preprocessing import Imputer  \nfrom sklearn.preprocessing import StandardScaler   #","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE, ADASYN\nfrom collections import Counter\nX_resampled, y_resampled = SMOTE().fit_resample(X, y)\n#print(sorted(Counter(y_resampled).items()))\n\nX_resampled.shape,y_resampled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.DataFrame(X)\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nbestfeatures = SelectKBest(score_func=f_classif, k=10)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(10,'Score'))  #print 10 best features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.DataFrame(X)\nX1=pd.DataFrame(X1)\nX4=X.iloc[:,[1]+[4]+[5]+[9]+[15]+[16]+[18]+[19]+[20]+[22]].values\nX5=X1.iloc[:,[1]+[4]+[5]+[9]+[15]+[16]+[18]+[19]+[20]+[22]].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc_X=StandardScaler()\nx_train=sc_X.fit_transform(X4)\n\nx_test = sc_X.fit_transform(X5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=None)\nx_train = pca.fit_transform(x_train)\n\nx_test = pca.fit_transform(x_test)\nexplained_variance = pca.explained_variance_ratio_\nexplained_variance\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=5)\nx_train = pca.fit_transform(x_train)\n\nx_test = pca.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Gaussian Naive Bayes model\nfrom sklearn.naive_bayes import GaussianNB\n\n#Create a Gaussian Classifier\nmodel = GaussianNB()\n\n# Train the model using the training sets\nmodel.fit(x_train, y)\naccuracy = cross_val_score(estimator=model, X=x_train, y=y, cv=25)\nprint(f\"The accuracy of the Gaussian Naive Bayes Model is \\t {accuracy.mean()}\") \nprint(f\"The deviation in the accuracy is \\t {accuracy.std()}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict_proba(x_train)[:, 1]\nscore = roc_auc_score(y, pred)\n\nprint(\"score: \", score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission[\"id\"] = test_id\nsubmission[\"target\"] = model.predict_proba(x_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nsubmission.to_csv('cat.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}