{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Is There a Cat in the Dat ? ( Kernel 2 )\nBy : Hesham Asem\n\n______\n\nafter using LGB Model & gaining only 77% accuracy , let's try using OneHotEncoder method then Logistic Regression \n\nlet's start by importing libraries"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then read the data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/cat-in-the-dat/train.csv')  \ntest = pd.read_csv('../input/cat-in-the-dat/test.csv')  \n\nprint(f'Train data Shape is {train.shape}')\nprint(f'Test data Shape is {test.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"300K sample size for training & 200K for testing , great . \n\nnow to define needed functions"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def Drop(feature) :\n    global data\n    data.drop([feature],axis=1, inplace=True)\n    data.head()\n    \ndef UniqueAll(show_value = True) : \n    global data\n    for col in data.columns : \n        print(f'Length of unique data for   {col}   is    {len(data[col].unique())} ')\n        if show_value == True  : \n            print(f'unique values ae {data[col].unique()}' )\n            print('-----------------------------')\n            \ndef Encoder(feature , new_feature, drop = True) : \n    global data\n    enc  = LabelEncoder()\n    enc.fit(data[feature])\n    data[new_feature] = enc.transform(data[feature])\n    if drop == True : \n        data.drop([feature],axis=1, inplace=True)\n        \ndef CPlot(feature) : \n    global data\n    sns.countplot(x=feature, data=data,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))\n    \ndef Mapp(feature , new_feature ,f_dict, drop_feature = True) : \n    global data\n    data[new_feature] = data[feature].map(f_dict)\n    if drop_feature == True : \n        data.drop([feature],axis=1, inplace=True)\n    else :\n        data.head()\ndef Unique(feature) : \n    global data\n    print(f'Number of unique vaure are {len(list(data[feature].unique()))} which are : \\n {list(data[feature].unique())}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"____\n\nas usual , start with heading data to have a look to it "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"& here is test data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"____\n\n# Forming the Data\n\nsince this example depend on categorical data , we have to slice features (X) from output (y) from training data , then concatenate X from training data to features from text data . \n\n& this step to make same data processing (like label encoder & so ) for all features \n\nso first to slice X_train & X_test"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train = train.drop(['id' , 'target'], axis=1, inplace=False)\nX_test = test.drop(['id'], axis=1, inplace=False)\n\nX_train.shape , X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now to concatenate them together into X"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X = pd.concat([X_train , X_test])\ndel X_train\ndel X_test\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how it looks ? "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"______\n\n# Data Processing\n\n\nno we'll call it data , so it be suitable for all functions we define , which depend on global data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now for plotting some features , to be sure its values are well represented"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_0')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_1')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_2')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_3')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CPlot('nom_0')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('nom_1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CPlot('nom_2')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('nom_3')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('nom_4')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_0')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_1')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_2')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_3')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_4')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so now we are ready for Build the model & train the data \n\n______\n\n# Build the Model\n\nfirst to prepare the data for training by defining trainging & testing data again \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_____\n\n\nnow to use OneHotEncoder to transform the whole data into data_dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"OHE  = OneHotEncoder()\ndata_dummies = OHE.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"what is the shape ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dummies.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"great , now to redefine train_data & test_data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_data = data_dummies[:train.shape[0],:]\ntest_data=  data_dummies[train.shape[0]:,:]\ntrain_data.shape , test_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and now to define X & y "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X = train_data\ny = train['target']\nX.shape , y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then to split it into training & testing data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now we can use Logistic Regression Model to traing our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"LogisticRegressionModel = LogisticRegression(penalty='l2',solver='lbfgs',C=1.0,random_state=33)\nLogisticRegressionModel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how is the accuracy ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LogisticRegressionModel Train Score is : ' , LogisticRegressionModel.score(X_train, y_train))\nprint('LogisticRegressionModel Test Score is : ' , LogisticRegressionModel.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"although ccuracy here is about 76% , but it make a better score at the real test data which is about 80%"},{"metadata":{},"cell_type":"markdown","source":"\n_____\n\nnow to predict test data , but first we have to apply same scaler model to test data"},{"metadata":{},"cell_type":"markdown","source":"ok , now predicting testing data , using predic_proba method , to calculate the probability of having a cat "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_pred = LogisticRegressionModel.predict_proba(test_data)\ny_pred.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how it looks like ? "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_pred[:,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"great , now to open sample_submission , to read id columns from it"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/cat-in-the-dat/sample_submission.csv')  \n\nprint(f'Test data Shape is {data.shape}')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"at last we concatenate id column with the result"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"idd = data['id']\nFinalResults = pd.DataFrame(y_pred[:,1],columns= ['target'])\nFinalResults.insert(0,'id',idd)\nFinalResults.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"& export the result file"},{"metadata":{"trusted":true},"cell_type":"code","source":"FinalResults.to_csv(\"sample_submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_____\n\nhope you find it helpful !"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}