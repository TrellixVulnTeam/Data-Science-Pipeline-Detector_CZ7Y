{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Is There a Cat in the Dat ? \nBy : Hesdham Asem\n\n______\n\na simple clean data , which depend on categorical featurs , & we need to classify it to know whether there will be a cat or not\n\nlet's start by importing libraries"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport lightgbm as lgb\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then read the data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/cat-in-the-dat/train.csv')  \ntest = pd.read_csv('../input/cat-in-the-dat/test.csv')  \n\nprint(f'Train data Shape is {train.shape}')\nprint(f'Test data Shape is {test.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"300K sample size for training & 200K for testing , great . \n\nnow to define needed functions"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def Drop(feature) :\n    global data\n    data.drop([feature],axis=1, inplace=True)\n    data.head()\n    \ndef UniqueAll(show_value = True) : \n    global data\n    for col in data.columns : \n        print(f'Length of unique data for   {col}   is    {len(data[col].unique())} ')\n        if show_value == True  : \n            print(f'unique values ae {data[col].unique()}' )\n            print('-----------------------------')\n            \ndef Encoder(feature , new_feature, drop = True) : \n    global data\n    enc  = LabelEncoder()\n    enc.fit(data[feature])\n    data[new_feature] = enc.transform(data[feature])\n    if drop == True : \n        data.drop([feature],axis=1, inplace=True)\n        \ndef CPlot(feature) : \n    global data\n    sns.countplot(x=feature, data=data,facecolor=(0, 0, 0, 0),linewidth=5,edgecolor=sns.color_palette(\"dark\", 3))\n    \ndef Mapp(feature , new_feature ,f_dict, drop_feature = True) : \n    global data\n    data[new_feature] = data[feature].map(f_dict)\n    if drop_feature == True : \n        data.drop([feature],axis=1, inplace=True)\n    else :\n        data.head()\ndef Unique(feature) : \n    global data\n    print(f'Number of unique vaure are {len(list(data[feature].unique()))} which are : \\n {list(data[feature].unique())}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"____\n\nas usual , start with heading data to have a look to it "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"& here is test data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"____\n\n# Forming the Data\n\nsince this example depend on categorical data , we have to slice features (X) from output (y) from training data , then concatenate X from training data to features from text data . \n\n& this step to make same data processing (like label encoder & so ) for all features \n\nso first to slice X_train & X_test"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train = train.drop(['id' , 'target'], axis=1, inplace=False)\nX_test = test.drop(['id'], axis=1, inplace=False)\n\nX_train.shape , X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now to concatenate them together into X"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X = pd.concat([X_train , X_test])\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how it looks ? "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"______\n\n# Data Processing\n\n\nno we'll call it data , so it be suitable for all functions we define , which depend on global data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now for plotting some features , to be sure its values are well represented"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_0')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_1')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_2')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_3')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_____\n\ngreat . \n\nfor bin 3 , since it got T for True & F for False , let's map it to new feature bin 03, with values 1 , 0"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Mapp('bin_3' , 'bin_03' , {'T':1 , 'F':0} , True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how it looks now"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot it "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_03')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"____\n\nwe'll repeat it for bin 4 , Yes & No will be 1 & 0"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Mapp('bin_4' , 'bin_04' , {'Y':1 , 'N':0} , True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot it"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('bin_04')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_____\n\n& since we use number of unique values for feature on alot of things , let's show them "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"UniqueAll(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"looks fine , may be except few features which got a high number of unique values , so it might not be very helpful in training\n\n_____\n\n# Label Encoding\n\nnow we need to apply label encoding to some categorical features , so it be ready for training \n\nlet's start with features : 'nom_0' , 'nom_1' , 'nom_2' , 'nom_3' , 'nom_4'\n"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for C in ['nom_0' , 'nom_1' , 'nom_2' , 'nom_3' , 'nom_4'] : \n    enc  = LabelEncoder()\n    enc.fit(X[C])\n    X[C] = enc.transform(X[C])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how it looks now"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot them "},{"metadata":{"trusted":true},"cell_type":"code","source":"CPlot('nom_0')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('nom_1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CPlot('nom_2')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('nom_3')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('nom_4')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_____\n\nfor nom_5 & nom_6 , let's have a look to their unique values"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Unique('nom_5')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Unique('nom_6')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ok , we'll continue label encode them"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for C in ['nom_5' , 'nom_6' , 'nom_7' , 'nom_8' , 'nom_9']: \n    enc  = LabelEncoder()\n    enc.fit(X[C])\n    X[C] = enc.transform(X[C])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how it looks"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and it might not be helpful to plot features with very high number of unique values \n\n______\n\nnow to plot other features "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_0')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_1')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_2')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_3')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_4')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CPlot('ord_5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" again to label encode them "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for C in ['ord_0' , 'ord_1' , 'ord_2' , 'ord_3' , 'ord_4' , 'ord_5']: \n    enc  = LabelEncoder()\n    enc.fit(X[C])\n    X[C] = enc.transform(X[C])\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so now we are ready for Build the model & train the data \n\n______\n\n# Build the Model\n\nfirst to prepare the data for training by defining trainging & testing data again \n"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_data = data.iloc[:train.shape[0],:]\ntest_data=  data.iloc[train.shape[0]:,:]\ntrain_data.shape , test_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now to define X & y "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X = train_data\ny = train['target']\nX.shape , y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's apply minmaxscalerfrom sklearn , to make the model faster "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\nX = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"then to split it into training & testing data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now it's time to apply lgb classification model , with round numbers = 25K & shown parameters"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"num_round = 25000\n\nparameters = {'num_leaves': 128,\n             'min_data_in_leaf': 20, \n             'objective':'binary',\n             'max_depth': 8,\n             'learning_rate': 0.001,\n             \"min_child_samples\": 20,\n             \"boosting\": \"gbdt\",\n             \"feature_fraction\": 0.9,\n             \"bagging_freq\": 1,\n             \"bagging_fraction\": 0.9 ,\n             \"bagging_seed\": 44,\n             \"metric\": 'auc',\n             \"verbosity\": -1}\n\n\ntraindata = lgb.Dataset(X_train, label=y_train)\ntestdata = lgb.Dataset(X_test, label=y_test)\n\nLGBModel = lgb.train(parameters, traindata, num_round, valid_sets = [traindata, testdata],\n                     verbose_eval=50, early_stopping_rounds = 600)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"accuracy might be better by using more round numbers \n\n_____\n\nnow to predict test data , but first we have to apply same scaler model to test data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test = scaler.transform(test_data)\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ok , now predicting testing data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_pred = LGBModel.predict(test)\ny_pred.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how it looks like ? "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"great , now to open sample_submission , to read id columns from it"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/cat-in-the-dat/sample_submission.csv')  \n\nprint(f'Test data Shape is {data.shape}')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"at last we concatenate id column with the result"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"idd = data['id']\nFinalResults = pd.DataFrame(y_pred,columns= ['target'])\nFinalResults.insert(0,'id',idd)\nFinalResults.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"& export the result file"},{"metadata":{"trusted":true},"cell_type":"code","source":"FinalResults.to_csv(\"sample_submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}