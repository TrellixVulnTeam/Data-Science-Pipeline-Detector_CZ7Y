{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel basin on the materials from:\n* https://scikit-learn.org/stable/modules/calibration.html\n* https://www.kaggle.com/martin1234567890/logistic-regression"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import (brier_score_loss, precision_score, recall_score,\n                             f1_score, roc_auc_score)\nfrom sklearn.calibration import CalibratedClassifierCV, calibration_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/cat-in-the-dat/sample_submission.csv\")\ntrain = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\")\n\nlabels = train.pop('target')\ntrain_id = train.pop(\"id\")\ntest_id = test.pop(\"id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = labels.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thanks to https://www.kaggle.com/martin1234567890/logistic-regression\ndata = pd.concat([train, test])\ndata[\"ord_5a\"] = data[\"ord_5\"].str[0]\ndata[\"ord_5b\"] = data[\"ord_5\"].str[1]\ndata.drop([\"bin_0\", \"ord_5\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Determination categorical features\nnumerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncategorical_columns = []\nfeatures = data.columns.values.tolist()\nfor col in features:\n    if data[col].dtype in numerics: continue\n    categorical_columns.append(col)\n    \n# Encoding categorical features\nfor col in categorical_columns:\n    if col in data.columns:\n        le = LabelEncoder()\n        le.fit(list(data[col].astype(str).values))\n        data[col] = le.transform(list(data[col].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data.iloc[:train.shape[0], :]\ntest = data.iloc[train.shape[0]:, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.fillna(0)\nX_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.99,\n                                                    random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_pred(clf, X_test):\n    if hasattr(clf, \"predict_proba\"):\n        prob_pos = clf.predict_proba(X_test)[:, 1]\n    else:  # use decision function\n        prob_pos = clf.decision_function(X_test)\n        prob_pos = \\\n        (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n    return prob_pos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thanks to https://scikit-learn.org/stable/modules/calibration.html\ndef plot_calibration_curve(est, name, fig_index):\n    \"\"\"Plot calibration curve for est w/o and with calibration. \"\"\"\n    # Calibrated with isotonic calibration\n    isotonic = CalibratedClassifierCV(est, cv=2, method='isotonic')\n\n    # Calibrated with sigmoid calibration\n    sigmoid = CalibratedClassifierCV(est, cv=2, method='sigmoid')\n\n    # Logistic regression with no calibration as baseline\n    lr = LogisticRegression(C=1., solver='lbfgs')\n\n    fig = plt.figure(fig_index, figsize=(10, 10))\n    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n    ax2 = plt.subplot2grid((3, 1), (2, 0))\n\n    ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n    for clf, name in [(lr, 'Logistic'),\n                      (est, name),\n                      (isotonic, name + ' + Isotonic'),\n                      (sigmoid, name + ' + Sigmoid')]:\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        prob_pos = model_pred(clf, X_test) \n        clf_score = brier_score_loss(y_test, prob_pos, pos_label=1)\n        print(\"%s:\" % name)\n        print(\"\\tBrier: %1.3f\" % (clf_score))\n        print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred))\n        print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred))\n        print(\"\\tF1: %1.3f\\n\" % f1_score(y_test, y_pred))\n\n        fraction_of_positives, mean_predicted_value = \\\n            calibration_curve(y_test, prob_pos, n_bins=10)\n\n        ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n                 label=\"%s (%1.3f)\" % (name, clf_score))\n\n        ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n                 histtype=\"step\", lw=2)\n        if name == \"Naive Bayes + Sigmoid\":\n            test_pred = model_pred(clf, test)\n            submission[\"id\"] = test_id\n            submission[\"target\"] = clf.predict_proba(test)[:, 1]\n            submission.to_csv(\"submission.csv\", index=False)\n\n    ax1.set_ylabel(\"Fraction of positives\")\n    ax1.set_ylim([-0.05, 1.05])\n    ax1.legend(loc=\"lower right\")\n    ax1.set_title('Calibration plots  (reliability curve)')\n\n    ax2.set_xlabel(\"Mean predicted value\")\n    ax2.set_ylabel(\"Count\")\n    ax2.legend(loc=\"upper center\", ncol=2)\n\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot calibration curve for Gaussian Naive Bayes\nplot_calibration_curve(GaussianNB(), \"Naive Bayes\", 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot calibration curve for Linear SVC\nplot_calibration_curve(LinearSVC(max_iter=10000), \"SVC\", 2)\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}