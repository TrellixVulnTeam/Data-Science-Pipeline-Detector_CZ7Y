{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Categorical Feature Encoding Challenge"},{"metadata":{},"cell_type":"markdown","source":"Importing Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nimport scipy\nfrom sklearn import linear_model, datasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\",  index_col='id')\ntest = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\", index_col = 'id')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for any null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum().sum())\nprint(test.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of unique values in each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of the target in Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['target'])\nplt.title(\"Distribution of Target values\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"Encoding binary columns and ordinal columns "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['bin_4'] = train['bin_4'].map({'Y': 1, 'N': 0})\ntrain['bin_3'] = train['bin_3'].map({'T': 1, 'F': 0})\ntrain['ord_1'] = train['ord_1'].map({'Novice': 0, 'Contributor': 1, 'Expert': 2, 'Master': 3,'Grandmaster': 4})\ntrain['ord_2'] = train['ord_2'].map({'Freezing': 0, 'Cold': 1, 'Warm': 2, 'Hot': 3, 'Boiling Hot': 4, 'Lava Hot': 5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['bin_4'] = test['bin_4'].map({'Y': 1, 'N': 0})\ntest['bin_3'] = test['bin_3'].map({'T': 1, 'F': 0})\ntest['ord_1'] = test['ord_1'].map({'Novice': 0, 'Contributor': 1, 'Expert': 2, 'Master': 3,'Grandmaster': 4})\ntest['ord_2'] = test['ord_2'].map({'Freezing': 0, 'Cold': 1, 'Warm': 2, 'Hot': 3, 'Boiling Hot': 4, 'Lava Hot': 5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l3 = train[train['target'] == 1]['ord_3'].value_counts() / train['ord_3'].value_counts() \nl4 = train[train['target'] == 1]['ord_4'].value_counts() / train['ord_4'].value_counts()\nl5 = train[train['target'] == 1]['ord_5'].value_counts() / train['ord_5'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sorting the valuecounts of the ordinal columns - 'ord_3', 'ord_4' and 'ord_5' based on target"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sorted_ord(col_name,ratio):\n    s_ratio = ratio.sort_values()\n    keys = list(s_ratio.keys())\n    train[col_name] = train[col_name].apply(lambda x : keys.index(x))\n    test[col_name] = test[col_name].apply(lambda x : keys.index(x))\n\nsorted_ord('ord_3',l3)\nsorted_ord('ord_4',l4)\nsorted_ord('ord_5',l5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One Hot Encoding the Nominal features along with day and month"},{"metadata":{"trusted":true},"cell_type":"code","source":"nom_col = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4','nom_5','nom_6','nom_7','nom_8','nom_9','day','month']\nnom_train = train[nom_col].astype(str)\nnom_test = test[nom_col].astype(str)\n\nohc_test = pd.get_dummies(nom_test, sparse = True)\nohc_train = pd.get_dummies(nom_train, sparse = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohc_test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ohc_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping feature columns not common in Train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_test = list(set(ohc_test.columns) - set(ohc_train.columns))\nunique_train = list(set(ohc_train.columns) - set(ohc_test.columns))\n\nprint(\"Unique test columns: \", len(unique_test))\nprint(\"Unique Train columns: \",len(unique_train))\n\n#Drop all extra test cols, cant learn anything\nprint(len(ohc_test.columns))\n\nohc_test_final = ohc_test.drop(unique_test, axis = 1)\n\nprint(len(ohc_test_final.columns))\n\n#Drop all extra train cols, doesnt matter for test\nprint(len(ohc_train.columns))\n\nohc_train_final = ohc_train.drop(unique_train, axis = 1)\n\nprint(len(ohc_train_final.columns))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reshaping the dataframe to Sparse matrices for faster processing"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dropped_cols = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4','nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9','day','month','target']\nfinal_df = train.drop(dropped_cols, axis =1)\ntarget_train = train['target']\n\ndropped_cols_test = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4','nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9','day','month']\ntest_df = test.drop(dropped_cols_test, axis=1)\n\nimport scipy\ndf = final_df.to_sparse()\ndf1 = test_df.to_sparse()\n\ndf\ndf=df.to_coo()\ndf=df.tocsr()\n\ndf1\ndf1=df1.to_coo()\ndf1=df1.tocsr()\n\nfinal_dataset = scipy.sparse.hstack([df,ohc_train_final])\nfinal_test = scipy.sparse.hstack([df1,ohc_test_final])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression Model"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Generation of C value taking too long, using the best value of C = 0.12\n# C = np.arange(0.07, 0.13, 0.01)\nC = [0.12]\n\nlr = LogisticRegression()\n\nmax_iter = [10000]\n\nhyperparameters = dict(C=C, max_iter = max_iter)\n\nclf = GridSearchCV(lr, hyperparameters, cv=10, verbose=0)\n\nbest_model = clf.fit(final_dataset,target_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = best_model.predict_proba(final_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samplesub = pd.read_csv(\"/kaggle/input/cat-in-the-dat/sample_submission.csv\", index_col=\"id\")\n\noutput = pd.DataFrame({'Id': samplesub.index, 'target': predictions[:,-1]})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}