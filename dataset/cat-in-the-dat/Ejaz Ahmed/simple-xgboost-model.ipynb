{"cells":[{"metadata":{"_uuid":"680dadfa-f397-4480-ba9b-13f7f7ddf4b5","_cell_guid":"4113ca0e-75d9-4135-a0d0-835923851214","trusted":true},"cell_type":"markdown","source":"## Simple XGboost model\n\nI have used XGBClassifier with simple coding that a beginner can understand easily. If you like it useful, please vote. Your comments are also welcome."},{"metadata":{"_uuid":"25bfecb4-0dd4-47c1-9438-aa57d17ef0ac","_cell_guid":"ccc64035-f607-49be-8ef4-fc356dc99832","trusted":true},"cell_type":"code","source":"# imports\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nimport pandas as pd\nimport numpy as np \nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d363c85a-88ff-49a0-ba18-192b2a53b59d","_cell_guid":"cbbc9bf9-2303-4346-a590-9d97057e04ef","trusted":true},"cell_type":"code","source":"# read files\nsubmission = pd.read_csv(\"/kaggle/input/cat-in-the-dat/sample_submission.csv\",index_col='id')\ndf_train = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\",index_col='id')\ndf_test = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\",index_col='id')\ndf = pd.concat([df_train, df_test],axis=0,ignore_index=True) # combine training and testing data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check submission file first, which gives an idea as what to do, we need to predict probability\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22bb8f9b-d970-4dc6-a5c2-bad757550a6b","_cell_guid":"42a0e1ae-5bb9-42af-b848-72df05f2adad","trusted":true},"cell_type":"code","source":"# function to describe variables\ndef desc(df):\n    summ = pd.DataFrame(df.dtypes,columns=['Data_Types'])\n    summ = summ.reset_index()\n    summ['Columns'] = summ['index']\n    summ = summ[['Columns','Data_Types']]\n    summ['Missing'] = df.isnull().sum().values    \n    summ['Uniques'] = df.nunique().values\n    return summ\n\n# function to analyse missing values\ndef nulls_report(df):\n    nulls = df.isnull().sum()\n    nulls = nulls[df.isnull().sum()>0].sort_values(ascending=False)\n    nulls_report = pd.concat([nulls, nulls / df.shape[0]], axis=1, keys=['Missing_Values','Missing_Ratio'])\n    return nulls_report","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e86b5800-b3ae-4134-8da6-f4c6cf2f5203","_cell_guid":"6849a73b-22b7-4927-a726-1b7ac2057394","trusted":true},"cell_type":"code","source":"# test data, there are no missing values\ndesc(df_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79222e0e-0e95-48be-a57f-c35398984d98","_cell_guid":"48e1b1c3-6713-4506-93e9-7891639e46c7","trusted":true},"cell_type":"code","source":"# distribution of target variable\ndf_train['target'].value_counts(normalize = True).plot(kind='barh',title='Distribution of Target Variable')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"391fab9d-4294-4802-b05d-72250bb60280","_cell_guid":"f3b3bc9b-9eaa-4408-b1d5-7f6d5d5af27b","trusted":true},"cell_type":"code","source":"# Binary Encdoing\n# bin_o and bin_1 need not be converted as these are already converted\n# bin_3and bin_4 are binary variables representing T/F and Y/N. We can convert them to 0 or 1.\ndf['bin_3'] = df['bin_3'].map({'T':1,'F':0})\ndf['bin_4'] = df['bin_4'].map({'Y':1,'N':0})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6809e063-c5ee-4f1c-b78d-8d315f4460ec","_cell_guid":"07854a07-8cf0-4a54-9e3d-f76bd455f5f7","trusted":true},"cell_type":"code","source":"# Ordinal Encoding\n# ord_0 need not to be converted\n# ord_1 and ord_2 has ordinal data. We can manually encode these variables.\n# ( ord_3,ord_4,ord_5 are of hight cardinality)\n\n# ord_1 and ord_2\nd1 = {'Grandmaster': 5, 'Expert': 4 , 'Novice':1 , 'Contributor':2 , 'Master': 3}\nd2 = {'Cold': 2, 'Hot':4, 'Lava Hot': 6, 'Boiling Hot': 5, 'Freezing': 1, 'Warm': 3}\ndf['ord_1'] = df['ord_1'].map(d1)\ndf['ord_2'] = df['ord_2'].map(d2)\n\n# ord_3 and ord_4\ndf['ord_3'] = df['ord_3'].astype('category')\ndf['ord_4'] = df['ord_4'].astype('category')\nd3 = dict(zip(df['ord_3'],df['ord_3'].cat.codes))\nd4 = dict(zip(df['ord_4'],df['ord_4'].cat.codes))\ndf['ord_3'] = df['ord_3'].map(d3)\ndf['ord_4'] = df['ord_4'].map(d4)\n\ndf['ord_3'] = df['ord_3'].astype(int)\ndf['ord_4'] = df['ord_4'].astype(int)\n\n#  ord_5\nli = sorted(list(set(df['ord_5'].values)))\nd5 = dict(zip(li, range(len(li))))  # mapping dict for ord_5\ndf['ord_5'] = df['ord_5'].map(d5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1debb0ef-09d2-4d88-bc06-3d6acae42eb4","_cell_guid":"78d477a4-2636-4110-bbac-f57472215efd","trusted":true},"cell_type":"code","source":"# one hot encoding for column : nom_0 to nom_4\ndf = pd.get_dummies(df, columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4'],\n                        prefix=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4'], \n                        drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80245fca-da3c-4ea3-a16e-5d5f80f0cf18","_cell_guid":"bbc9281e-027b-4d86-92e1-160c18cb2335","trusted":true},"cell_type":"code","source":"# encoding hex feature\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfeatures_hex = ['nom_5','nom_6','nom_7','nom_8','nom_9']\n\nfor col in features_hex:\n    le.fit(df[col])\n    df[col] = le.transform(df[col])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"663c6373-b051-41bb-bf0e-04db231411ba","_cell_guid":"d9a8ee82-d19f-46bf-9714-99decf52217f","trusted":true},"cell_type":"code","source":"# convert cyclical features such as day and month into 2d sin-cos features\ndf['day_sin'] = np.sin(2*np.pi * df['day']/7)\ndf['day_cos'] = np.cos(2*np.pi * df['day']/7)\ndf['month_sin'] = np.sin(2*np.pi * df['month']/12)\ndf['month_cos'] = np.cos(2*np.pi * df['month']/12)\ndf.drop(columns=['day','month'],inplace=True)\n\n# plot features in 2d\ndf.sample(1000).plot.scatter('month_sin','month_cos').set_aspect('equal')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dab21a63-be7f-4fe9-8205-23aaf9f1fbae","_cell_guid":"aa9f2d3c-7961-4353-b3cd-62156c88e659","trusted":true},"cell_type":"code","source":"# get training ,testing, validation and target\nfrom sklearn.model_selection import train_test_split\ny_train = df_train['target']\nX_train = df[:len(df_train)].drop(['target'],axis=1)\nX_test = df[len(df_train):].drop(['target'],axis=1)\n\n# split train and validation data\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.001, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgboost\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(objective= 'binary:logistic',\n                    learning_rate=0.1,\n                    max_depth=3,\n                    n_estimators=200,\n                    scale_pos_weight=2,\n                    random_state=1,\n                    colsample_bytree=0.5)\n\nxgb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.linear_model import LogisticRegression\n#lr=LogisticRegression(C=0.125, solver=\"lbfgs\", max_iter=500) \n#lr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4e9da4e-d193-4261-9017-8e671520b08d","_cell_guid":"fd8d88f6-9091-46c7-9af7-819dae872d40","trusted":true},"cell_type":"code","source":"#submission\ny_pred = xgb.predict_proba(X_test)[:, 1]\nsubmission = pd.DataFrame({'id':df_test.index,'target':y_pred})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}