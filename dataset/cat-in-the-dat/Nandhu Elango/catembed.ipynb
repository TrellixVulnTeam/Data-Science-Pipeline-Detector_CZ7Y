{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport string\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"basepath=\"/kaggle/input/cat-in-the-dat\"\nprint(\"List of files in the directory %s\" %(os.listdir(basepath)))\ntraindata=os.path.join(basepath, 'train.csv')\ntestdata=os.path.join(basepath, 'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(traindata)\ntest=pd.read_csv(testdata)\n\ntrain_X=train.drop(['id','target'],axis=1)\ntrain_y=train['target']\ntest_X=test.drop('id',axis=1)\n\ntrain_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of train and test data is %s %s\" %(train_X.shape, test_X.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's get into cleaning the features for modelling**\n1. Dealing with ordinal features\n2. Dealing with nominal features\n3. Dealing with binary features\n4. Dealing with cyclical features"},{"metadata":{},"cell_type":"markdown","source":"****Dealing with ordinal features****"},{"metadata":{"trusted":true},"cell_type":"code","source":"traintestencode=pd.concat([train_X,test_X])\n\nprint(\"Various ordinal types %s\" %(traintestencode['ord_1'].unique()))\nprint(\"Various ordinal types %s\" %(traintestencode['ord_2'].unique()))\nprint(\"Various ordinal types %s\" %(traintestencode['ord_3'].unique()))\nprint(\"Various ordinal types %s\" %(traintestencode['ord_4'].unique()))\nprint(\"Various ordinal types %s\" %(traintestencode['ord_5'].unique()))\n\nord_1_map = {'Grandmaster': 5, 'Master': 4, 'Expert': 3,'Contributor': 2, 'Novice': 1}\n\nord_2map = {'Lava Hot':6,'Boiling Hot': 5, 'Hot': 4, 'Warm': 3, \n               'Freezing': 2, 'Cold': 1}\n\ntraintestencode['ord_1']=traintestencode['ord_1'].replace(ord_1_map)\ntraintestencode['ord_2']=traintestencode['ord_2'].replace(ord_2map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No of unique categories in the ord_5 ->\" ,traintestencode['ord_5'].nunique())\nprint(\"No of unique categories in the ord_4 ->\" ,traintestencode['ord_4'].nunique())\nprint(\"No of unique categories in the ord_3 ->\" ,traintestencode['ord_3'].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will do the hash encoding for the remaining ordinal variables as the categories are more"},{"metadata":{"trusted":true},"cell_type":"code","source":"ord345=traintestencode[['ord_3','ord_4','ord_5']]\n\nn_orig_features = ord345.shape[1]\nhash_vector_size = 10\nct = ColumnTransformer([(f't_{i}', FeatureHasher(n_features=hash_vector_size, \n                        input_type='string'), i) for i in range(n_orig_features)])\n\nordencoded = ct.fit_transform(ord345)  # n_orig_features * hash_vector_size\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hashedfeatures=pd.DataFrame(data=ordencoded.toarray())\nhashedfeatures.columns=['hash_ord_'+str(f) for f in hashedfeatures.columns]\n\ntraintestencode.reset_index(inplace=True)\n\ntraintestencode=pd.concat([traintestencode,hashedfeatures],axis=1)\ntraintestencode.drop(['ord_3','ord_4','ord_5','index'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traintestencode.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's check for nominal columns**"},{"metadata":{"trusted":true},"cell_type":"code","source":"nominalfeatures=[ feat for feat in traintestencode.columns if feat.split('_')[0]=='nom' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for nominal in nominalfeatures:\n        print(\"No of unique values for the column %s is %s\" %(nominal,traintestencode[nominal].nunique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> For columns having unique value less than 10 we will do one hot encoding for the rest we will do hashing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def nominalohencoding(features):\n    featurelist=[]\n    hashnominallist=[]\n    for feature in features:\n            if traintestencode[feature].nunique()<=10:\n                featurelist.append(feature)\n            else:\n                hashnominallist.append(feature)\n    dummies = pd.get_dummies(traintestencode[featurelist], drop_first=True, sparse=True)\n    return dummies,featurelist,hashnominallist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nominals,nominallist,hashnominallist=nominalohencoding(nominalfeatures)\ntraintestencode=pd.concat([traintestencode,nominals],axis=1)\ntraintestencode.drop(nominallist,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traintestencode.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hashnominal=traintestencode[hashnominallist]\nhash_vector_size=20\n\nct = ColumnTransformer([(f't_{i}', FeatureHasher(n_features=hash_vector_size, \n                        input_type='string'), i) for i in range(len(hashnominallist))])\n\nhashnominalencoded = ct.fit_transform(hashnominal)  # n_orig_features * hash_vector_size\n\nhashedfeatures=pd.DataFrame(data=hashnominalencoded)\nhashedfeatures.columns=['hash_nom_'+str(f) for f in hashedfeatures.columns]\n\n#traintestencode.reset_index(inplace=True)\n\ntraintestencode=pd.concat([traintestencode,hashedfeatures],axis=1)\ntraintestencode.drop(hashnominallist,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Moving to binary features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"traintestencode.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*One hot encode the bin3 and bin4 features*"},{"metadata":{"trusted":true},"cell_type":"code","source":"binlist=['bin_3','bin_4']\nbindummies = pd.get_dummies(traintestencode[binlist], drop_first=True, sparse=True)\ntraintestencode=pd.concat([traintestencode,bindummies],axis=1)\ntraintestencode.drop(binlist,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dealing with cyclical features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode(data, col, max_val):\n    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n    return data\n\ntraintestencode = encode(traintestencode, 'day', 365)\ntraintestencode = encode(traintestencode, 'month', 12)\n\ntraintestencode.drop(['day','month'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**First things first!!**\n> Building logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=traintestencode.loc[:train_X.shape[0]-1,:]\nX_test=traintestencode.loc[train_X.shape[0]:,:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cross validation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\npred_test_full =0\ncv_score =[]\ni=1\n\nfor train_index,test_index in kf.split(X_train,train_y):\n    print('{} of KFold {}'.format(i,kf.n_splits))\n    #print(\"dfdf\",X_train[train_index])\n    xtr,xvl= X_train.loc[train_index],X_train.loc[test_index]\n    ytr,yvl = train_y.loc[train_index],train_y.loc[test_index]\n    \n    #model\n    lr = LogisticRegression()\n    lr.fit(xtr,ytr)\n    score = roc_auc_score(yvl,lr.predict(xvl))\n    print('ROC AUC score:',score)\n    cv_score.append(score)    \n    pred_test = lr.predict_proba(X_test)[:,1]\n    pred_test_full +=pred_test\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make submission\ny_pred = pred_test_full/5\nsubmission = pd.DataFrame({'id': test['id'].values.tolist(), 'target': y_pred})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Work in progress!!!!!!!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}