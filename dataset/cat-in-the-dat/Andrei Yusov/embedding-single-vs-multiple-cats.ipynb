{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is it\n\nThe idea is to try to compare NN performance with one emedding applied to each categorical feature as \nopposed to one embedding applied to all features at once. \nThe hope is that if there are feature interactions using all features at the same time\nmay provide embeddings that give us better predictions in models.\n\nThe results below show that there is no difference. The ROC AUC values from both models are the same.\nThis result may be specific to this data set, though. \nIn artificial data set there may be no feature interactions at all.\n\nStill, there may be other advantages of using one embedding for all. Simpler model, simpler inputs, for example.\n\n## TODO\n\n* Different models, try adding max pooling for example\n* Different data set, same approach applied to different data set may produce different results. But than again, maybe not. Maybe NN learns all interactions it can learn in both cases.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Embedding, MaxPooling1D, Concatenate\nfrom keras.layers import Input\nfrom keras import backend as K \n\nimport tensorflow as tf\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"base_data_dir = '../input/cat-in-the-dat/'\ndtr = pd.read_csv(base_data_dir + \"train.csv\")\ndts = pd.read_csv(base_data_dir + \"test.csv\")\ndts.target = np.NaN\nd = pd.concat([dtr, dts], sort=False)\ntrain_set = dtr.shape[0]\ndel(dtr, dts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = [i for i in d.columns if not i in (\"id\",\"target\")]\nprint(cat_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in cat_features:\n    d[c] = d[c].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Map categorical feature into vectors and matrix"},{"metadata":{},"cell_type":"markdown","source":"First prepare a list of vectors with numeric representation for each categorical value.\nNote that if there is a NA in the category it is mapped into -1 code by pandas.\nIn this case there are no NAs. \nIf there are NAs we should be using code values + 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_vectors = [d[c].cat.codes.to_numpy() for c in cat_features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, make one single merged matrix with all categorical codes.\nEach categorical code must be unique. \nTo achieve that values in each subsequent categorical vector is increased by the number of levels in previous vectors.\nThen all these vectors are merged into a single matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_size = [len(d[c].cat.categories) for c in cat_features]\ncat_offset = np.cumsum([0] + cat_size[:-1])\ncat_vectors2 = [cat_vectors[i] + cat_offset[i] for i in range(len(cat_vectors))]\ncat_matrix = np.concatenate([np.reshape(np.ravel(c),(-1,1)) for c in cat_vectors2], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cat_matrix.shape)\nprint(cat_matrix[0:2,])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare train and test set split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_idx, test_idx = train_test_split(range(train_set), test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Try NN model using emedding across all features"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = cat_matrix[train_idx,:]\nX_test = cat_matrix[test_idx,:]\ny_train = d.target.iloc[train_idx]\ny_test = d.target.iloc[test_idx]\n# X_train, X_test, y_train, y_test = train_test_split(cat_matrix[0:train_set,:], d.target[0:train_set], test_size=0.2)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = np.max(cat_matrix)+1\nmaxlen = cat_matrix.shape[1]\nprint(max_features, maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\ndef auc(y_true, y_pred):\n    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n\nembedding_size = 10\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, embedding_size, input_length=maxlen))\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(X_train, y_train,validation_data=(X_test, y_test),\n          batch_size=100, epochs=3, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look at the model convergence graphs."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(hist.history['auc'])\nplt.plot(hist.history['val_auc'])\nplt.title('model ROC AUC')\nplt.ylabel('AUC')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look at the ROC graph."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\nK.clear_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr)\nplt.xlabel('False positive')\nplt.ylabel('True positive')\nplt.title('ROC auc='+str(auc(fpr, tpr)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Try model with each feature having it's own embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\ndef auc(y_true, y_pred):\n    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n\ndef prepare_one_cat_layer(c):\n    inp = Input(shape=(1,))\n    es = int(round(np.log(np.max(c))))+2 # just a guess\n    emb = Embedding(np.max(c)+1, es, input_length=1)(inp)\n    return (inp,emb)\n\ncat_layers = [prepare_one_cat_layer(c) for c in cat_vectors]\n\nx = Concatenate()([c[1] for c in cat_layers])\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = Dense(10, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(10, activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nfinal_layer = Dense(1, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=[c[0] for c in cat_layers], outputs=[final_layer])\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=[auc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xs_train = [c[train_idx] for c in cat_vectors]\nXs_test = [c[test_idx] for c in cat_vectors]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(Xs_train, y_train, validation_data=(Xs_test, y_test),\n          batch_size=100, epochs=3, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(hist.history['auc'])\nplt.plot(hist.history['val_auc'])\nplt.title('model ROC AUC')\nplt.ylabel('AUC')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(Xs_test)\nK.clear_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr)\nplt.xlabel('False positive')\nplt.ylabel('True positive')\nplt.title('ROC auc='+str(auc(fpr, tpr)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}