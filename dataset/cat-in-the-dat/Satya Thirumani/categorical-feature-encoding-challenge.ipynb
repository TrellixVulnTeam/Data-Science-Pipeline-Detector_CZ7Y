{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Kaggle - Categorical Feature Encoding Challenge\n## Target Prediction Analysis (Cat in the Dat) in Python using sklearn package\n\n## **[https://satya-python.blogspot.com](https://satya-python.blogspot.com)**"},{"metadata":{},"cell_type":"markdown","source":"## **Importing Libraries & Reading Data**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing required packages\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 50)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score,confusion_matrix,roc_curve,auc\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures,LabelEncoder,OneHotEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\")\ntest_ids = test[\"id\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis (EDA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check number of features and data points in train and test\nprint(\"Number of data points in train: %d\" % train.shape[0])\nprint(\"Number of features in train: %d\" % train.shape[1])\n\nprint(\"Number of data points in test: %d\" % test.shape[0])\nprint(\"Number of features in test: %d\" % test.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.tail(10).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique values in each column\nfor col in train.columns:\n    print(\"Unique entries in\",col,\" -\", train[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['bin_3'] = train[\"bin_3\"].apply(lambda x: 0 if x == \"F\" else 1)\ntrain['bin_4'] = train[\"bin_4\"].apply(lambda x: 0 if x == \"N\" else 1)\n\ntest['bin_3'] = test[\"bin_3\"].apply(lambda x: 0 if x == \"F\" else 1)\ntest['bin_4'] = test[\"bin_4\"].apply(lambda x: 0 if x == \"N\" else 1)\n\ntrain['ord_5a'] = train[\"ord_5\"].str[0]\ntrain['ord_5b'] = train[\"ord_5\"].str[1]\n\ntest['ord_5a'] = test[\"ord_5\"].str[0]\ntest['ord_5b'] = test[\"ord_5\"].str[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for NULL/missing values\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for NULL/missing values\ntest.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis\nprint(train['target'].value_counts(),'\\n')\nprint(train['target'].value_counts(normalize=True)*100,'\\n')\nsns.countplot(train[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['ord_1'].str.lower().value_counts().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['ord_2'].str.lower().value_counts().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparding Data for modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"high_card_feats = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nfor col in high_card_feats:\n    train[f'hash_{col}'] = train[col].apply( lambda x: hash(str(x)) % 5000 )\n    test[f'hash_{col}'] = test[col].apply( lambda x: hash(str(x)) % 5000 )\n\ntrain.drop([\"id\",\"nom_5\",\"nom_6\",\"nom_7\",\"nom_8\",\"nom_9\",\"ord_5\"], axis=1, inplace=True)\ntest.drop([\"id\",\"nom_5\",\"nom_6\",\"nom_7\",\"nom_8\",\"nom_9\",\"ord_5\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_new = pd.DataFrame()\n# le = LabelEncoder()\n# for c in train.columns:\n#     if(train[c].dtype == 'object'): train_new[c] = le.fit_transform(train[c])\n#     else:      train_new[c] = train[c]\n\n# train_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_new = pd.DataFrame()\n# for c in test.columns:\n#     if(test[c].dtype == 'object'): test_new[c] = le.transform(test[c])\n#     else:      test_new[c] = test[c]\n\n# test_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding\n\n# str_cols= train.loc[:, train.dtypes=='object'].columns.tolist()\n# str_cols\n\n# train = pd.get_dummies(train, columns=str_cols, drop_first=True)\n# test = pd.get_dummies(test, columns=str_cols, drop_first=True)\n\n# onehot_enc = OneHotEncoder()\n# # train = onehot_enc.fit_transform(train)\n# # test = onehot_enc.transform(test)\n\n# import category_encoders as ce\n# ohe = ce.OneHotEncoder(handle_unknown='ignore', use_cat_names=True)\n# train = ohe.fit_transform(train)\n# test = ohe.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train.pop('target')\ndata = pd.concat([train, test])\ndummies = pd.get_dummies(data, columns=data.columns, drop_first=True, sparse=True)\ntrain = dummies.iloc[:train.shape[0], :]\ntest = dummies.iloc[train.shape[0]:, :]\ntrain = train.sparse.to_coo().tocsr()\ntest = test.sparse.to_coo().tocsr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train2 = train.drop(['target'], axis=1)\n# target = train[\"target\"]\n# train2 = train2.loc[:, test.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Using imblearn for Balancing Data\n# from imblearn.over_sampling import SMOTE\n# sm = SMOTE(random_state=2019)\n\n# from imblearn.over_sampling import ADASYN\n# sm = ADASYN()\n\n# from imblearn.over_sampling import SVMSMOTE\n# sm = SVMSMOTE(random_state=2019)\n\n# from imblearn.combine import SMOTETomek\n# sm = SMOTETomek(ratio='auto')\n\n# from imblearn.combine import SMOTEENN\n# sm = SMOTEENN(random_state=2019)\n\n# train2, target = sm.fit_sample(train2, target.ravel())\n\n# from collections import Counter\n# print('Resampled dataset shape %s' % Counter(target))\n\n# from imblearn.under_sampling import NearMiss\n# nr = NearMiss()\n# train2, target = nr.fit_sample(train2, target.ravel())\n# np.bincount(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Scaling Data\n# #scaler = MinMaxScaler()\n# scaler = StandardScaler()\n# train2 = scaler.fit_transform(train2)\n# test = scaler.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# poly = PolynomialFeatures(degree=1)\n# train2 = poly.fit_transform(train2)\n# test = poly.transform(test)\n# poly\n# print(\"train2 shape:\", train2.shape)\n\n# # # train2 shape: (14272, 44)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pca = PCA(random_state=2019)\n# #pca = PCA(random_state=2019, n_components=200)\n# train2 = pca.fit_transform(train2)\n\n# test = pca.transform(test)\n# pca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train, target, test_size=0.25, random_state=123)\nprint(x_train.shape, x_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning/Neural Networks"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set('talk', 'whitegrid', 'dark', font_scale=1, font='Ricty',rc={\"lines.linewidth\": 2, 'grid.linestyle': '--'})\n\n# Receiver Operating Characteristic\ndef plotAUC(truth, pred, lab):\n    fpr, tpr, _ = roc_curve(truth,pred)\n    roc_auc = auc(fpr, tpr)\n    lw = 2\n    c = (np.random.rand(), np.random.rand(), np.random.rand())\n    plt.plot(fpr, tpr, color= c,lw=lw, label= lab +'(AUC = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve')\n    plt.legend(loc=\"lower right\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #clf_NN = MLPClassifier(random_state=2019, hidden_layer_sizes=(100, 100, 100))\n# clf_NN = MLPClassifier(activation='tanh', alpha=0.0001, max_iter=200, hidden_layer_sizes=(50, 50, 50), random_state=2019, solver='sgd')\n# clf_NN.fit(x_train, y_train)\n# y_val_pred = clf_NN.predict(x_val)\n# predictprob = clf_NN.predict_proba(x_val)[:,1]\n# y_val_pred\n# y_pred = clf_NN.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clf_NN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\n# rf = RandomForestClassifier(n_estimators=800, random_state = 2019).fit(x_train, y_train)\n# rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = LogisticRegression(C=0.1338, solver=\"lbfgs\", tol=0.003, max_iter=4000)\nrf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val_pred = rf.predict(x_val)\npredictprob = rf.predict_proba(x_val)[:,1]\ny_pred = rf.predict(test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy = accuracy_score(y_val, y_val_pred)\nprint(Accuracy)\nplotAUC(y_val, predictprob, 'MLP')\nplt.show()\n\n# ROC 0.745\n# AUC 0.76","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(y_val, y_val_pred).T\ncm = cm.astype('float')/cm.sum(axis=0)\nax = sns.heatmap(cm, annot=True, cmap='Blues');\nax.set_xlabel('True Label',size=12)\nax.set_ylabel('Predicted Label',size=12)\n\n# # TP 0.815 TN 0.44\n# RF # TP 0.96 TN 0.17\n# SMOTE TP 0.96 TN 0.63","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(data = {\"id\":test_ids, \"target\":y_pred})\nprint(submission['target'].value_counts())\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}