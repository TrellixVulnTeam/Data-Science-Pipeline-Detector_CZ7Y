{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"###Reyes, Marcus\n###CoE 197Z Project 1\n###Kaggle-https://www.kaggle.com/c/cat-in-the-dat\n\nimport pandas as pd\nimport keras\nimport numpy as np\nfrom numpy import genfromtxt\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Dropout,BatchNormalization,Conv1D\nfrom keras.optimizers import adam\nfrom sklearn import preprocessing\n\n\n###Data preprocessing\ndata = pd.read_csv(\"train.csv\")\n#For now ignore the data you don't know how to handle\n#drop = ['id', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\n# drop = ['id', 'nom_7','nom_8', 'nom_9']\ndrop = ['id', 'nom_9']\nmynom_9 =  data['nom_9'].astype(str).apply(lambda x: int(x,16))\n\ndata = data.drop(columns = drop)\n\ndata = pd.concat([data,mynom_9],axis = 1)\nprint(data['nom_9'])\n#Categorical to one_hot\n#https://www.datacamp.com/community/tutorials/categorical-data#encoding\none_hot = ['bin_3', 'bin_4','nom_0','nom_1','nom_2','nom_3','nom_4','ord_1', 'ord_2', 'ord_3', 'ord_4','ord_5','day','month', 'nom_5']\n\n#Categorical to labelled\nlabelled = ['nom_6','nom_7', 'nom_8']\n\nfor i,w in enumerate(one_hot):\n   data = pd.get_dummies(data, columns=[w], prefix = [w])\nprint(data.values.shape)\n\nfor i,w in enumerate(labelled):\n    labels = data[w].astype('category').cat.categories.tolist()\n\n    replace_map_comp = {w: {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n\n    data.replace(replace_map_comp, inplace=True)\n    \n    del labels, replace_map_comp\n    \n    print(data[w])\n\ny = data['target'].to_numpy()\ny = keras.utils.to_categorical(y, 2)\n\ndata = data.drop(columns = ['target'])\n\nx = data.to_numpy()\n\n###Normalize data to large to be one-hot-encoded\nmin_max_scaler = preprocessing.MinMaxScaler()\nx = min_max_scaler.fit_transform(x)\n\n# print(x[4,:])\n# print(x[7,:])\nx_train = x[:255000,:]\nx_pretest = x[255000:,:]\n\ny_pretest = y[255000:,:] #note y_train is really y_all here\ny_train = y[:255000,:]\n\n###Model\n\ndropout = 0.7\n(trash, input_dim) = x.shape\n\nhidden = 1024\nmodel = Sequential()\n\n\nmodel.add(Dense(hidden,input_dim = input_dim))\nmodel.add(Dropout(dropout))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(hidden,input_dim = hidden))\nmodel.add(Dropout(dropout))\nmodel.add(Activation('relu'))\n\n\nmodel.add(Dense(hidden,input_dim = hidden))\nmodel.add(Dropout(dropout))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(2,input_dim = hidden))\nmodel.add(Activation('softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\n\n\n###To keep track of validation error\nfor i in range(10):\n    val_ind = np.arange(i*30000,(1+i)*30000)\n    all_ind = np.arange(0,300000)\n    x_pretest = x[val_ind,:]\n    x_train = np.delete(x, val_ind, axis = 0)\n    \n    y_pretest = y[val_ind,:]\n    y_train = np.delete(y, val_ind, axis = 0)\n    \n    \n    print(x_pretest.shape)\n    print(x_train.shape)\n    print(y_pretest.shape)\n    print(y_train.shape)\n    model.fit(x_train, y_train, epochs = 5, batch_size = 4096*16)\n\n    score = model.evaluate(x_pretest, y_pretest, batch_size = 512)\n    print(\"\\nTest accuacy: %.1f%%\" % (100.0 * score[1]))\n    print(\"Iteration: \",i)\n\n\n\n\n\n\n\n\n\n###Testing\ntry:\n    del data\nexcept:\n    pass\n \ndata = pd.read_csv(\"test.csv\")\nmynom_9 =  data['nom_9'].astype(str).apply(lambda x: int(x,16))\ndata = data.drop(columns = drop)\ndata = pd.concat([data,mynom_9],axis = 1)\n\n\nfor i,w in enumerate(one_hot):\n   data = pd.get_dummies(data, columns=[w], prefix = [w])\n\n\nfor i,w in enumerate(labelled):\n    labels = data[w].astype('category').cat.categories.tolist()\n\n    replace_map_comp = {w: {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n\n    data.replace(replace_map_comp, inplace=True)\n    \n    del labels, replace_map_comp\n    \n    print(data[w])\n\n\n\nx_test = data.to_numpy()\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_test = min_max_scaler.fit_transform(x_test)\n \n# print(\"X_testshape\",x_test.shape)\ny_test = model.predict(x_test)\n\n\n\n###Formatting into csv submittable\nid = np.arange(start = 300000, stop = 500000)\nid = np.transpose(id)\nid = id.reshape(200000,1)\ny_temp = y_test[:,1].reshape(200000,1)\ny_pred = np.concatenate((id, y_temp), axis = 1)\nprint(id.shape)\nprint(y_test[:,0].shape)\nprint(y_pred.shape)\npresubmission = pd.DataFrame(y_pred)\n\npresubmission.iloc[:,0] = presubmission.iloc[:,0].astype(int)\npresubmission.iloc[:,1] = presubmission.iloc[:,1].astype(float)\n\n\npresubmission.to_csv(\"submission.csv\",header = [\"id\",\"target\"],index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}