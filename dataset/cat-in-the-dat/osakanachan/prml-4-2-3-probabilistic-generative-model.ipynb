{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Probabilistic generative model to discrete features (feat. PRML 4.2.3)"},{"metadata":{},"cell_type":"markdown","source":"## 0. Outline"},{"metadata":{},"cell_type":"markdown","source":"In probabilistic generative model, we obtain posterior probability for class by Bayes theorem:\n\n$$\n\\begin{align}\np(C_{k}|\\mathbb{x})\n&=\n\\frac{p(\\mathbb{x}|C_{k})p(C_{k})}{p(\\mathbb{x})}\\\\\n&=\n\\frac{p(\\mathbb{x}|C_{k})p(C_{k})}{\\sum_{c}p(\\mathbb{x}|c)p(c)}\n\\end{align}\n$$"},{"metadata":{},"cell_type":"markdown","source":"Since this competition is a 2-class classification task, the posterior probability for class is given as this:\n$$\np(C_{1}|\\mathbb{x}) = \\sigma(a) = \\frac{1}{1+e^{-a}},\n$$\n\nwhere\n$$\na = \\ln\\frac{p(\\mathbb{x}|C_{1})p(C_{1})}{p(\\mathbb{x}|C_{0})p(C_{0})}\n$$"},{"metadata":{},"cell_type":"markdown","source":"Thus, all we need to do is to calculate class-conditional distribution and prior class probability:\n$$\np(\\mathbb{x}|C_{1}), \\;\\;p(\\mathbb{x}|C_{0}), \\;\\;p(C_{1}), \\;\\;p(C_{0})\n$$"},{"metadata":{},"cell_type":"markdown","source":"Let input is a D-dimention vector of discrete components:\n$$ \\mathbb{x}=(x_{1}, ..., x_{D}),\\;\\;x_{i}\\in\\{0,1,...,l_{i}-1\\} $$"},{"metadata":{},"cell_type":"markdown","source":"Under Naive bayes assumption -- if we treat each feature as independent -- , we have this class-conditional distribution form:\n$$ p(\\mathbb{x}|C_{k})=\\prod_{i=1}^{D}\\prod_{j=0}^{l_{i}-1}\\mu_{kij}^{\\delta_{x_{i},j}}$$\n\nwhere\n\n$$\n\\delta_{x_{i},j} = \n\\begin{cases}\n1 \\;\\;\\mathrm{when}\\;\\; x_{i}=j \\\\\n0 \\;\\;\\mathrm{when}\\;\\; x_{i}\\ne j \\\\\n\\end{cases}\n\\;\\;,\\;\\;\n\\sum_{j=0}^{l_{i}-1} \\mu_{kij}=1\n$$"},{"metadata":{},"cell_type":"markdown","source":"Here, parameters to be determined are:\n\n$$\n\\mu_{kij}, \\;\\;p(C_{1}), \\;\\;p(C_{0})\n$$\n\nWith maximum likelihood estimate, they are determined as this:\n\n$$\n\\mu_{\\mathrm{MLE},kij} = \\frac{N(\\mathbb{x}\\in C_{k}, x_{i}=j)}{N(\\mathbb{x}\\in C_{k})} \\\\\np_{\\mathrm{MLE}}(C_{k})=\\frac{N(\\mathbb{x}\\in C_{k})}{N(\\mathbb{x})}\n$$\n\nTo supplement, with MAP estimate, they are determined as this:\n\n$$\n\\mu_{\\mathrm{MAP},kij} =\n\\frac{N(\\mathbb{x}\\in C_{k}, x_{i}=j)\\bigl\\{1+N(\\mathbb{x}\\in C_{k}, x_{i}=j)\\bigr\\}}\n{N(\\mathbb{x}\\in C_{k})\\bigl\\{1+N(\\mathbb{x}\\in C_{k})\\bigr\\}}\n\\\\\np_{\\mathrm{MAP}}(C_{k})\n=\n\\frac{N(\\mathbb{x}\\in C_{k})\\bigl\\{1+N(\\mathbb{x}\\in C_{k})\\bigr\\}}\n{N(\\mathbb{x})\\bigl\\{1+N(\\mathbb{x})\\bigr\\}}\n$$"},{"metadata":{},"cell_type":"markdown","source":"Finally, we obtain posterior probability for class is given as this:\n$$\np(C_{1}|\\mathbb{x}) = \\sigma(a) = \\frac{1}{1+e^{-a}},\n$$\n\nwhere\n\n$$\n\\begin{align}\na &= \\ln\\frac{p(\\mathbb{x}|C_{1})p(C_{1})}{p(\\mathbb{x}|C_{0})p(C_{0})} \\\\\n&=\n\\ln\\prod_{i=1}^{D}\\prod_{j=0}^{l_{i}-1}\\mu_{\\mathrm{MLE},1ij}^{\\delta_{x_{i},j}}\n- \\ln\\prod_{i=1}^{D}\\prod_{j=0}^{l_{i}-1}\\mu_{\\mathrm{MLE},0ij}^{\\delta_{x_{i},j}}\n+ \\ln p_{\\mathrm{MLE}}(C_{1})\n- \\ln p_{\\mathrm{MLE}}(C_{0}) \\\\\n&=\n\\sum_{i=1}^{D}\n\\sum_{j=0}^{l_{i}-1}\n\\delta_{x_{i},j} \\ln \\frac{N(x\\in C_{1}, x_{i}=j)}{N(x\\in C_{0}, x_{i}=j)}\n+ \\ln\\frac{N(x\\in C_{1})}{N(x\\in C_{0})}\n\\end{align}\n$$"},{"metadata":{},"cell_type":"markdown","source":"By this probability, we can predict the class for new inputs with a threshold of 0.5:\n$$\n\\begin{cases}\n\\mathbb{x} \\in C_{1} \\;\\; \\mathrm{when} \\; p(C_{1}|\\mathbb{x}) > 0.5\\\\\n\\mathbb{x} \\in C_{0} \\;\\; \\mathrm{when} \\; p(C_{1}|\\mathbb{x}) < 0.5\n\\end{cases}\n$$"},{"metadata":{},"cell_type":"markdown","source":"For more details, refer to PRML book chapter 4.2.3:\n[https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/)"},{"metadata":{},"cell_type":"markdown","source":"## 1. Coding"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\n        \nimport collections\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_PATH = '../input/cat-in-the-dat/train.csv'\nTEST_PATH = '../input/cat-in-the-dat/test.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_PATH)\ndf_test = pd.read_csv(TEST_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_valid = train_test_split(df_train, train_size=0.8, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1-1. prior class probability"},{"metadata":{},"cell_type":"markdown","source":"With maximum likelihood estimate, we obtain prior class probability:\n$$\np_{\\mathrm{MLE}}(C_{1})=\\frac{N(C_{1})}{N}, \\:\\:\\:\np_{\\mathrm{MLE}}(C_{0})=\\frac{N(C_{0})}{N}\n$$\n\nWith MAP estimate:\n$$\np_{\\mathrm{MAP}}(C_{1})=\\frac{(N(C_{1}))(1+N(C_{1}))}{N(1+N)}, \\:\\:\\:\np_{\\mathrm{MAP}}(C_{0})=\\frac{(N(C_{0}))(1+N(C_{0}))}{N(1+N)}\n$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='target', data=df_train)\nplt.title('target')\nplt.xticks([0,1],[0,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = df_train.shape[0]\nnc1 = df_train.loc[:, 'target'].sum()\nnc0 = n - nc1\n\npc1_mle = nc1 / n\npc0_mle = nc0 / n\npc1_map = nc1 * (1+nc1) / (n * (1+n))\npc0_map = nc0 * (1+nc0) / (n * (1+n))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pc1_mle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pc0_mle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pc1_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pc0_map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1-2. feature encoding"},{"metadata":{},"cell_type":"markdown","source":"We need to convert non-numerical features into numerical features."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### (convert feature to numbers for bin_3, bin_4)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[:, 'bin_3'] = df_train.loc[:, 'bin_3'].replace({'F':0, 'T':1})\ndf_train.loc[:, 'bin_4'] = df_train.loc[:, 'bin_4'].replace({'N':0, 'Y':1})\ndf_train.loc[:, 'bin_0':'bin_4'] = df_train.loc[:, 'bin_0':'bin_4'].astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### (convert feature to numbers for nom_0 to nom_9)"},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_map = {}\n\nfor column in df_train.loc[:, 'nom_0':'nom_9'].columns:\n    replace_map[column] = {}\n    for i, key in enumerate(collections.Counter(df_train.loc[:, column]).keys()):\n        replace_map[column][key] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train.loc[:, 'nom_0':'nom_9'].columns:\n    df_train.loc[:, column] = df_train.loc[:, column].replace(replace_map[column])\ndf_train.loc[:, 'nom_0':'nom_9'] = df_train.loc[:, 'nom_0':'nom_9'].astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[:, 'nom_0':'nom_9']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1-3. naive bayes assumption"},{"metadata":{},"cell_type":"markdown","source":"Little correletion is seen among features bin_0 to nom_9:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(pd.concat([df_train.loc[:, 'bin_0':'nom_9'], df_train.loc[:, 'target']], axis=1).corr(), fmt='.2f', annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Therefore, naive bayes assumption is valid -- we may treat features bin_0 to nom_9 as independent."},{"metadata":{},"cell_type":"markdown","source":"### 1-4. class-conditional distribution"},{"metadata":{},"cell_type":"markdown","source":"As naive bayes assumption is valid, we obtain class-conditional distribution as this:\n$$ \np(\\mathbb{x}|C_{k})=\\prod_{i=1}^{D}\\prod_{j=0}^{l_{i}-1}\\mu_{kij}^{\\delta_{x_{i},j}}$$\n\nwhere\n\n$$\n\\delta_{x_{i},j} = \n\\begin{cases}\n1 \\;\\;\\mathrm{when}\\;\\; x_{i}=j \\\\\n0 \\;\\;\\mathrm{when}\\;\\; x_{i}\\ne j \\\\\n\\end{cases}\n\\;\\;,\\;\\;\n\\sum_{j=0}^{l_{i}-1} \\mu_{kij}=1\n$$\n\nParameters can be determined by maximum likelihood estimation:\n$$\n\\mu_{\\mathrm{MLE},kij} = \\frac{N(\\mathbb{x}\\in C_{k}, x_{i}=j)}{N(\\mathbb{x}\\in C_{k})}\n$$\n\nSimilarly, determined parameters with MAP estimation are:\n$$\n\\mu_{\\mathrm{MAP},kij} =\n\\frac{N(\\mathbb{x}\\in C_{k}, x_{i}=j)\\bigl\\{1+N(\\mathbb{x}\\in C_{k}, x_{i}=j)\\bigr\\}}\n{N(\\mathbb{x}\\in C_{k})\\bigl\\{1+N(\\mathbb{x}\\in C_{k})\\bigr\\}}\n$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_mle = [[], []]\nm_map = [[], []]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train.loc[:, 'bin_0':'bin_4'].columns:\n    class1 = df_train.loc[df_train.loc[:, 'target'] == 1, 'bin_0':'nom_9']\n    class0 = df_train.loc[df_train.loc[:, 'target'] == 0, 'bin_0':'nom_9']\n    mle1j = []\n    mle0j = []\n    map1j = []\n    map0j = []\n    for j in range(2):\n        n1j = np.sum(class1.loc[:, column] == j)\n        n0j = np.sum(class0.loc[:, column] == j)\n        mle1j.append(n1j / class1.shape[0])\n        mle0j.append(n0j / class0.shape[0])\n        map1j.append((n1j * (1+n1j)) / (class1.shape[0] * (1+class1.shape[0])))\n        map0j.append((n0j * (1+n0j)) / (class0.shape[0] * (1+class0.shape[0])))\n    m_mle[1].append(mle1j)\n    m_mle[0].append(mle0j)\n    m_map[1].append(map1j)\n    m_map[0].append(map0j)\n\n\nfor column in df_train.loc[:, 'nom_0':'nom_9'].columns:\n    class1 = df_train.loc[df_train.loc[:, 'target'] == 1, 'bin_0':'nom_9']\n    class0 = df_train.loc[df_train.loc[:, 'target'] == 0, 'bin_0':'nom_9']\n    mle1j = []\n    mle0j = []\n    map1j = []\n    map0j = []\n    for j in range(len(replace_map[column])):\n        n1j = np.sum(class1.loc[:, column] == j)\n        n0j = np.sum(class0.loc[:, column] == j)\n        mle1j.append(n1j / class1.shape[0])\n        mle0j.append(n0j / class0.shape[0])\n        map1j.append((n1j * (1+n1j)) / (class1.shape[0] * (1+class1.shape[0])))\n        map0j.append((n0j * (1+n0j)) / (class0.shape[0] * (1+class0.shape[0])))\n    m_mle[1].append(mle1j)\n    m_mle[0].append(mle0j)\n    m_map[1].append(map1j)\n    m_map[0].append(map0j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1-5. prediction"},{"metadata":{},"cell_type":"markdown","source":"Let us make a prediction!\n\nActivation value of logistic sigmoid is obtained as this:\n\n$$\n\\begin{align}\na &= \\ln\\frac{p(\\mathbb{x}|C_{1})p(C_{1})}{p(\\mathbb{x}|C_{0})p(C_{0})} \\\\\n&=\n\\ln\\prod_{i=1}^{D}\\prod_{j=0}^{l_{i}-1}\\mu_{1ij}^{\\delta_{x_{i},j}}\n- \\ln\\prod_{i=1}^{D}\\prod_{j=0}^{l_{i}-1}\\mu_{0ij}^{\\delta_{x_{i},j}}\n+ \\ln p(C_{1})\n- \\ln p(C_{0})\n\\end{align}\n$$"},{"metadata":{},"cell_type":"markdown","source":"Then we can predict class as this:\n$$\ny_{n} = \\biggl\\{\n\\begin{array}{l}\n1 \\;\\;\\mathrm{when}\\; \\sigma(a)>0.5\\\\\n0 \\;\\;\\mathrm{when}\\; \\sigma(a)<0.5\\\\\n\\end{array}\n$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[:, 'y_mle_pred'] = np.log(pc1_mle) - np.log(pc0_mle)\ndf_train.loc[:, 'y_map_pred'] = np.log(pc1_map) - np.log(pc0_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(df):\n    df.loc[:, 'y_mle_pred'] = np.log(pc1_mle) - np.log(pc0_mle)\n    df.loc[:, 'y_map_pred'] = np.log(pc1_map) - np.log(pc0_map)\n    eps = 1e-8\n    \n    @np.vectorize\n    def sigmoid(x):\n        sigmoid_range = 34.538776394910684\n\n        if x <= -sigmoid_range:\n            return 1e-15\n        if x >= sigmoid_range:\n            return 1.0 - 1e-15\n\n        return 1.0 / (1.0 + np.exp(-x))\n\n\n    for i, column in enumerate(df.loc[:, 'bin_0':'nom_9'].columns):\n        try:\n            df.loc[:, 'y_mle_pred'] += \\\n                df.loc[:, column].apply(\\\n                    lambda j: np.log(max(eps, m_mle[1][i][j])) - np.log(max(eps, m_mle[0][i][j]))\n                )\n        except TypeError:\n            j = random.randrange(0, len(replace_map[column]))\n            df.loc[:, 'y_mle_pred'] += \\\n                np.log(max(eps, m_mle[1][i][j])) - np.log(max(eps, m_mle[0][i][j]))\n        \n    for i, column in enumerate(df.loc[:, 'bin_0':'nom_9'].columns):\n        try:\n            df.loc[:, 'y_map_pred'] += \\\n                df.loc[:, column].apply(\\\n                    lambda j: np.log(max(eps, m_map[1][i][j])) - np.log(max(eps, m_map[0][i][j]))\n                )\n        except TypeError:\n            j = random.randrange(0, len(replace_map[column]))\n            df.loc[:, 'y_map_pred'] += \\\n                np.log(max(eps, m_map[1][i][j])) - np.log(max(eps, m_map[0][i][j]))\n            \n    df.loc[:, 'y_mle_pred'] = sigmoid(df.loc[:, 'y_mle_pred'])\n    df.loc[:, 'y_map_pred'] = sigmoid(df.loc[:, 'y_map_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[:, 'y_mle_pred':'y_map_pred']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(df_train.loc[:, 'target'], df_train.loc[:, 'y_mle_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(df_train.loc[:, 'target'], df_train.loc[:, 'y_map_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_train.loc[:, 'target'], (df_train.loc[:, 'y_mle_pred'] > 0.5) * 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_train.loc[:, 'target'], (df_train.loc[:, 'y_map_pred'] > 0.5) * 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Same procedure to sequential features, day and month"},{"metadata":{},"cell_type":"markdown","source":"For simplicity, we simply apply the same technique to sequential features (ord_0 to ord_5) and cyclic features (day, month).\n\nThat is, here we treat them like categorical features and ignore their sequence."},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train.loc[:, 'ord_0':'ord_5'].columns:\n    replace_map[column] = {}\n    for i, key in enumerate(collections.Counter(df_train.loc[:, column]).keys()):\n        replace_map[column][key] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train.loc[:, 'ord_0':'ord_5'].columns:\n    df_train.loc[:, column] = df_train.loc[:, column].replace(replace_map[column])\ndf_train.loc[:, 'ord_0':'ord_5'] = df_train.loc[:, 'ord_0':'ord_5'].astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train.loc[:, 'day':'month'].columns:\n    replace_map[column] = {}\n    for i, key in enumerate(collections.Counter(df_train.loc[:, column]).keys()):\n        replace_map[column][key] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[:, 'day':'month'] = df_train.loc[:, 'day':'month'] - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in df_train.loc[:, 'ord_0':'month'].columns:\n    class1 = df_train.loc[df_train.loc[:, 'target'] == 1, 'ord_0':'month']\n    class0 = df_train.loc[df_train.loc[:, 'target'] == 0, 'ord_0':'month']\n    mle1j = []\n    mle0j = []\n    map1j = []\n    map0j = []\n    for j in range(len(replace_map[column])):\n        n1j = np.sum(class1.loc[:, column] == j)\n        n0j = np.sum(class0.loc[:, column] == j)\n        mle1j.append(n1j / class1.shape[0])\n        mle0j.append(n0j / class0.shape[0])\n        map1j.append((n1j * (1+n1j)) / (class1.shape[0] * (1+class1.shape[0])))\n        map0j.append((n0j * (1+n0j)) / (class0.shape[0] * (1+class0.shape[0])))\n    m_mle[1].append(mle1j)\n    m_mle[0].append(mle0j)\n    m_map[1].append(map1j)\n    m_map[0].append(map0j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_all(df):\n    df.loc[:, 'y_mle_pred'] = np.log(pc1_mle) - np.log(pc0_mle)\n    df.loc[:, 'y_map_pred'] = np.log(pc1_map) - np.log(pc0_map)\n    eps = 1e-8\n    \n    @np.vectorize\n    def sigmoid(x):\n        sigmoid_range = 34.538776394910684\n\n        if x <= -sigmoid_range:\n            return 1e-15\n        if x >= sigmoid_range:\n            return 1.0 - 1e-15\n\n        return 1.0 / (1.0 + np.exp(-x))\n\n\n    for i, column in enumerate(df.loc[:, 'bin_0':'month'].columns):\n        try:\n            df.loc[:, 'y_mle_pred'] += \\\n                df.loc[:, column].apply(\\\n                    lambda j: np.log(max(eps, m_mle[1][i][j])) - np.log(max(eps, m_mle[0][i][j]))\n                )\n        except TypeError:\n            j = random.randrange(0, len(replace_map[column]))\n            df.loc[:, 'y_mle_pred'] += \\\n                np.log(max(eps, m_mle[1][i][j])) - np.log(max(eps, m_mle[0][i][j]))\n        \n    for i, column in enumerate(df.loc[:, 'bin_0':'month'].columns):\n        try:\n            df.loc[:, 'y_map_pred'] += \\\n                df.loc[:, column].apply(\\\n                    lambda j: np.log(max(eps, m_map[1][i][j])) - np.log(max(eps, m_map[0][i][j]))\n                )\n        except TypeError:\n            j = random.randrange(0, len(replace_map[column]))\n            df.loc[:, 'y_map_pred'] += \\\n                np.log(max(eps, m_map[1][i][j])) - np.log(max(eps, m_map[0][i][j]))\n            \n    df.loc[:, 'y_mle_pred'] = sigmoid(df.loc[:, 'y_mle_pred'])\n    df.loc[:, 'y_map_pred'] = sigmoid(df.loc[:, 'y_map_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_all(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[:, 'y_mle_pred':'y_map_pred']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(df_train.loc[:, 'target'], df_train.loc[:, 'y_mle_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(df_train.loc[:, 'target'], df_train.loc[:, 'y_map_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_train.loc[:, 'target'], (df_train.loc[:, 'y_mle_pred'] > 0.5) * 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_train.loc[:, 'target'], (df_train.loc[:, 'y_map_pred'] > 0.5) * 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df.loc[:, 'bin_3'] = df.loc[:, 'bin_3'].replace({'F':0, 'T':1})\n    df.loc[:, 'bin_4'] = df.loc[:, 'bin_4'].replace({'N':0, 'Y':1})\n    df.loc[:, 'bin_0':'bin_4'] = df.loc[:, 'bin_0':'bin_4'].astype(np.uint8)\n    \n    for column in df.loc[:, 'nom_0':'nom_9'].columns:\n        df.loc[:, column] = df.loc[:, column].replace(replace_map[column])\n        \n    for column in df.loc[:, 'ord_0':'ord_5'].columns:\n        df.loc[:, column] = df.loc[:, column].replace(replace_map[column])\n        \n    df.loc[:, 'day':'month'] = df.loc[:, 'day':'month'] - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess(df_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### validation 1: Probabilistic generative model to discrete features (bin_0 to nom_9)"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict(df_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_valid.loc[:, 'y_mle_pred':'y_map_pred']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(df_valid.loc[:, 'target'], df_valid.loc[:, 'y_mle_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(df_valid.loc[:, 'target'], df_valid.loc[:, 'y_map_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_valid.loc[:, 'target'], (df_valid.loc[:, 'y_mle_pred'] > 0.5) * 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_valid.loc[:, 'target'], (df_valid.loc[:, 'y_map_pred'] > 0.5) * 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### validation 2: Apply one-hot encoding also to sequential features (ord_0 to ord_5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_all(df_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(df_valid.loc[:, 'target'], df_valid.loc[:, 'y_mle_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(df_valid.loc[:, 'target'], df_valid.loc[:, 'y_map_pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_valid.loc[:, 'target'], (df_valid.loc[:, 'y_mle_pred'] > 0.5) * 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_valid.loc[:, 'target'], (df_valid.loc[:, 'y_map_pred'] > 0.5) * 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{},"cell_type":"markdown","source":"The same procedure is available to test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_all(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.loc[:, 'y_mle_pred':'y_map_pred']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.loc[:, 'target'] = df_test.loc[:, 'y_map_pred']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = df_test.loc[:, ['id', 'target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}