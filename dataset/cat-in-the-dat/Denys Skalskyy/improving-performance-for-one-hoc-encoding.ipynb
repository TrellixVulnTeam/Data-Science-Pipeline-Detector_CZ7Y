{"cells":[{"metadata":{},"cell_type":"markdown","source":"I have used [Why Not Logistic Regression](https://www.kaggle.com/peterhurford/why-not-logistic-regression) for experiments with One Hoc Encoding and LogisticRegression model. If you used this notebook you can noticed that step with encoding takes more than 4 minutes. It's too long to play around with features and re-calculate data. So I found way to reduce encoding step time."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load data\ntrain = pd.read_csv('../input/cat-in-the-dat/train.csv')\ntest = pd.read_csv('../input/cat-in-the-dat/test.csv')\n\ntarget = train['target']\ntrain_id = train['id']\ntest_id = test['id']\ntrain.drop(['target', 'id'], axis=1, inplace=True)\ntest.drop('id', axis=1, inplace=True)\n\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The both **STEP 1** and **STEP 2** are an original code from [Why Not Logistic Regression](https://www.kaggle.com/peterhurford/why-not-logistic-regression)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# STEP 1\ntraintest = pd.concat([train, test])\ndummies = pd.get_dummies(traintest, columns=traintest.columns, drop_first=True, sparse=True)\ntrain_ohe = dummies.iloc[:train.shape[0], :]\ntest_ohe = dummies.iloc[train.shape[0]:, :]\n\nprint(train_ohe.shape)\nprint(test_ohe.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# STEP 2\ntrain_ohe = train_ohe.sparse.to_coo().tocsr()\ntest_ohe = test_ohe.sparse.to_coo().tocsr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**STEP 1** duration time is about *4min*.\n\n**STEP 2** duration time is about *4s*.\n\nLet's split **STEP 1** to find part which lasts longer."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# STEP 1.1\ntraintest = pd.concat([train, test])\ndummies = pd.get_dummies(traintest, columns=traintest.columns, drop_first=True, sparse=True)\n\nprint(dummies.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# STEP 1.2\ntrain_ohe = dummies.iloc[:train.shape[0], :]\ntest_ohe = dummies.iloc[train.shape[0]:, :]\n\nprint(train_ohe.shape)\nprint(test_ohe.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we can see that splitting data using *iloc* takes about *4min*.\n\nWhat if we cast *dummies* to cst matrix first? Before splitting on *train* and *test* data?"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntraintest = pd.concat([train, test])\ndummies = pd.get_dummies(traintest, columns=traintest.columns, drop_first=True, sparse=True)\n\ndummies_csr = dummies.sparse.to_coo().tocsr()\n\ntrain_ohe = dummies_csr[:train.shape[0], :]\ntest_ohe = dummies_csr[train.shape[0]:, :]\n\nprint(train_ohe.shape)\nprint(test_ohe.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Result is less then *20s*.\n\nSo we reduced time of running preparation data step more than **4 minutes**.\n\nIn my opinion it's not bad :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}