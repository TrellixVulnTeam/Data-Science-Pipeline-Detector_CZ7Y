{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/cat-in-the-dat/train.csv')\ntest = pd.read_csv('/kaggle/input/cat-in-the-dat/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = [x for x in train.columns if x != 'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='target',data=train)\n#train['target'].value_counts().values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns.tolist():\n    print(f'number of unique values for {col} and column data dype : {train[col].dtype}')\n    print(f'{train[col].nunique()}')\n    print('===========================')\n    if train[col].nunique()<8:\n        print(train[col].unique())\n        print('--------------------------')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_cols = train.select_dtypes('object').columns.tolist()\nobject_df = train[object_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'is there missing data: {np.any(object_df.isnull().sum()>0)}')\nprint(f'is there missing data in test set: {np.any(test.isnull().sum()>0)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def split_dataframe(val_size=0.2):\n    \n#     t_index = len(train.index)\n#     val_index = int(t_index*0.4)\n#     X_train = train[:-val_index]\n#     X_val = train[-val_index:-val_index//2]\n#     X_test = train[-val_index//2:]\n#     return X_train, X_val, X_test\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_value_counts(df):\n    \n    for col in df.columns:\n        print(f'value count for {col} is')\n        print(f'{df[col].value_counts()}')\n    \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=print_value_counts(object_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#object_col_freq = ['nom_5','nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_3', 'ord_4', 'ord_5']\nobject_col_label = ['bin_0','bin_1','bin_2','bin_3','bin_4']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best score 72.**\n# one_hot_encode = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\n# target_encode = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_0' ]\n# cyclic_encode = ['day', 'month']\n# ordinal_encode = ['ord_1','ord_2','ord_3','ord_4', 'ord_5']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encode = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\ntarget_encode = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nweight_encode = target_encode + ['ord_4', 'ord_5' ,'ord_3'] + one_hot_encode + object_col_label\ncyclic_encode = ['day', 'month']\nordinal_encode = ['ord_0','ord_1','ord_2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['bin_4'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def freq_encoding(df, col):\n#     temp_dict = dict(df[col].value_counts())\n#     return df[col].map(temp_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train, X_val, X_test = split_dataframe()\n# for col in object_col_freq:\n#     train[col] = freq_encoding(train,col)\n#     test[col] = freq_encoding(test, col)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Label Encoding\n# Label_train= train[object_col_label]\n# Label_test= test[object_col_label]\n# encoder = LabelEncoder()\n# for col in object_col_label:\n#     Label_train[col] = encoder.fit_transform(Label_train[col])\n#     Label_test[col] = encoder.fit_transform(Label_test[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one_hot = OneHotEncoder(sparse=False)\n# One_hot_train = pd.DataFrame(one_hot.fit_transform(train[one_hot_encode]))\n# One_hot_test = pd.DataFrame(one_hot.fit_transform(test[one_hot_encode]))\n\n# One_hot_train.index = train[one_hot_encode].index\n# One_hot_test.index = test[one_hot_encode].index\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import category_encoders as ce\n\n# # Create the encoder itself\n# target_enc = ce.TargetEncoder(cols=target_encode)\n# # Fit the encoder using the categorical features and target\n# target_enc.fit(train[target_encode], train['target'])\n\n# target_train = target_enc.transform(train[target_encode])\n# target_test = target_enc.transform(test[target_encode])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_enc = ce.woe.WOEEncoder(cols=weight_encode)\n# Fit the encoder using the categorical features and target\nweight_enc.fit(train[weight_encode], train['target'])\n\nweight_train = weight_enc.transform(train[weight_encode])\nweight_test = weight_enc.transform(test[weight_encode])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# backDiff_enc = ce.backward_difference.BackwardDifferenceEncoder(cols=weight_encode)\n# # Fit the encoder using the categorical features and target\n# backDiff_enc.fit(train[weight_encode])\n# backDiff_train = backDiff_enc.transform(train[weight_encode])\n# backDiff_test = backDiff_enc.transform(test[weight_encode])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_train= train[ordinal_encode]\nordinal_test= test[ordinal_encode]\nordinal = OrdinalEncoder()\n\nordinal_train = pd.DataFrame(ordinal.fit_transform(ordinal_train), columns=ordinal_encode)\nordinal_test = pd.DataFrame(ordinal.fit_transform(ordinal_test), columns=ordinal_encode)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[ordinal_encode].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets try scaling here \n# from sklearn.preprocessing import StandardScaler\n# min_max = StandardScaler()\n# cols = ordinal_train.columns\n# min_max.fit(ordinal_train)\n# ordinal_train = pd.DataFrame(min_max.transform(ordinal_train), columns=cols)\n# ordinal_test = pd.DataFrame(min_max.transform(ordinal_test), columns=cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cyclic_df_train = train[cyclic_encode]\ncyclic_df_test = test[cyclic_encode]\nfor col in cyclic_encode:\n#     cyclic_df_train[col] = cyclic_df_train[col].apply(lambda x: np.sin((2*np.pi*x)/max(cyclic_df_train[col])))\n#     cyclic_df_test[col] = cyclic_df_test[col].apply(lambda x: np.sin((2*np.pi*x)/max(cyclic_df_test[col])))\n    cyclic_df_train[col] = np.sin(2*np.pi*cyclic_df_train[col]/max(cyclic_df_train[col]))\n    cyclic_df_test[col] = np.sin(2*np.pi*cyclic_df_test[col]/max(cyclic_df_test[col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_drop = object_col_label+one_hot_encode+target_encode + cyclic_encode + ordinal_encode + ['ord_4','ord_5', 'ord_3']\ntrain.drop(columns=to_drop, inplace=True)\ntest.drop(columns=to_drop, inplace=True)\n# train = pd.concat([train,Label_train,One_hot_train,cyclic_df_train, ordinal_train], axis=1)\n# test = pd.concat([test,Label_test,One_hot_test,cyclic_df_test, ordinal_test], axis=1)\n\ntrain = pd.concat([train,weight_train,cyclic_df_train, ordinal_train], axis=1)\ntest = pd.concat([test,weight_test,cyclic_df_test, ordinal_test], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from imblearn.over_sampling import SMOTE\n# target = train.pop('target')\n# columns = train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sm = SMOTE(sampling_strategy='minority',random_state=42)\n# X, y = sm.fit_sample(train, target)\n# train = pd.concat((pd.DataFrame(X, columns=columns), pd.DataFrame(y,columns=['target'])), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = test['id']\ntest.drop(columns=['id'], inplace=True)\ntrain.drop(columns=['id'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# std_scaler = StandardScaler()\n# std_scaler.fit(train)\n# train = pd.DataFrame(std_scaler.transform(train),columns=train.columns)\n# test = pd.DataFrame(std_scaler.transform(test),columns=test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train=train.pop('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid_param={\n#     'n_estimators':np.arange(10,250,30),\n#     'max_depth': [20,30,10,50]\n# }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rf = RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n#grid_rf = GridSearchCV(rf, param_grid=grid_param, cv=5, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#grid_rf.fit(train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#grid_rf.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr = LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n#                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n#                    max_iter=100, multi_class='warn', n_jobs=-1, penalty='l2',\n#                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n#                    warm_start=False)\n# lr.fit(train, Y_train)\n# lr_pred = lr.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ada_boost = AdaBoostClassifier(n_estimators=100, learning_rate=0.05, random_state=2021)\n# ada_boost.fit(train, Y_train)\n# ada_pred = ada_boost.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ada_pred[1,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# svc = SVC(kernel='rbf')\n# svc.fit(train, Y_train)\n# svc_pred = svc.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# r_forest = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n#                        criterion='gini', max_depth=10, max_features='auto',\n#                        max_leaf_nodes=None, min_impurity_decrease=0.0,\n#                        min_impurity_split=None, min_samples_leaf=1,\n#                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n#                        n_estimators=220, n_jobs=-1, oob_score=False,\n#                        random_state=None, verbose=0, warm_start=False)\n# r_forest.fit(train, Y_train)\n# forest_pred = r_forest.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid_params = {\n#     'learning_rate':np.arange(0.01, 0.9, 0.02),\n#     'n_estimators':np.arange(100,500,100),\n#     'max_depth':np.arange(3,12,3),\n#     'max_features':['sqrt','log2'],\n#     'min_samples_split':np.arange(0.1, 1.0,0.4),\n#     'loss':['exponential']\n# }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gb = GradientBoostingClassifier(validation_fraction=0.2)\n# grid_gb = GridSearchCV(gb, param_grid=grid_params, cv=5, scoring='roc_auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid_gb.fit(train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid_gb.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grd_tree = GradientBoostingClassifier(learning_rate=0.02,\n#                                       n_estimators=350,\n#                                       max_depth=12,\n#                                       max_features='sqrt',\n#                                       validation_fraction=0.2,\n#                                       random_state=2021)\n# grd_tree.fit(train, Y_train)\n# grd_pred = grd_tree.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_params = {\n    'max_depth': 6,\n    'learning_rate':0.03,\n    'n_estimators':400,\n    'booster':'gbtree',\n    'random_state':2021,\n    'subsample':0.5,\n    'objective':'binary:logistic',\n    'colsample_bytree':0.5, 'colsample_bylevel':0.5, 'colsample_bynode':0.5\n#     'sample_type ':'weighted',\n#     'normalize_type':'forest',\n#     'rate_drop':0.2\n}\n#kfold = KFold(n_splits=5, shuffle=True, random_state=2021)\n#for train_index, test_index in kfold.split(train):\nxgb_model = XGBClassifier(**xgb_params)\nxgb_model.fit(train, Y_train)\n#     predictions = xgb_model.predict(train.iloc[test_index])\n#     actuals = Y_train.iloc[test_index]\n#     print('auc_score: ',roc_auc_score(actuals,predictions))\nxgb_pred = xgb_model.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_xgb = pd.read_csv('/kaggle/input/cat-in-the-dat/sample_submission.csv')\nsubmission_xgb['id'] = test_id\nsubmission_xgb['target']= xgb_pred[:,1]\nsubmission_xgb.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_ada = pd.read_csv('/kaggle/input/cat-in-the-dat/sample_submission.csv')\n# submission_ada['id'] = test_id\n# submission_ada['target']= grd_pred[:,1]\n# submission_ada.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_lr = pd.read_csv('/kaggle/input/cat-in-the-dat/sample_submission.csv')\n# submission_lr['id'] = test_id\n# submission_lr['target']= lr_pred[:,1]\n# submission_lr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission_ada.to_csv('sample_submission_grad.csv', index=False)\n#submission_lr.to_csv('sample_submission_lr.csv', index=False)\nsubmission_xgb.to_csv('sample_submission_xgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}