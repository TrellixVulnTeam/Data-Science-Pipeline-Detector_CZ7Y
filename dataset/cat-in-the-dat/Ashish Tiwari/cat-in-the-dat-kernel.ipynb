{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/cat-in-the-dat/train.csv\", index_col='id')\ntest_data = pd.read_csv(\"/kaggle/input/cat-in-the-dat/test.csv\", index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data.pop('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training data shape =\", train_data.shape)\nprint(\"Testing data shape =\", test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"null_val_train = [(x, y) for (x, y) in train_data.isnull().sum().items() if y > 0]\nnull_val_test = [(x, y) for (x, y) in test_data.isnull().sum().items() if y > 0]\nprint(\"Null Values in training data =\", len(null_val_train))\nprint(\"Null Values in testing data =\", len(null_val_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of unique elements per column"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train_data.columns:\n    print(col, train_data[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data = pd.concat([train_data, test_data], axis=0)\ntrain_rows = train_data.shape[0]\ndel train_data\ndel test_data\n\nfull_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data['bin_3'] = full_data['bin_3'].map({'T': 1, 'F': 0})\nfull_data['bin_4'] = full_data['bin_4'].map({'Y': 1, 'N': 0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['ord_1', 'ord_2', 'ord_3', 'ord_4']:\n    print(col, list(np.unique(full_data[col])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data['ord_5_len'] = full_data['ord_5'].map(len)\nfull_data['ord_5_len'] -= 2\nfull_data['ord_5_len'].map(abs).any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Means every value in 'ord_5' is of length 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"m1 = {'Contributor': 1, 'Expert': 2, 'Grandmaster': 4, 'Master': 3, 'Novice': 0}\nfull_data['ord_1'] = full_data['ord_1'].map(m1)\n\nm2 = {'Boiling Hot': 4, 'Cold': 1, 'Freezing': 0, 'Hot': 3, 'Lava Hot': 5, 'Warm': 2}\nfull_data['ord_2'] = full_data['ord_2'].map(m2)\n\nfull_data['ord_3'] = full_data['ord_3'].apply(lambda x: ord(x) - ord('a'))\nfull_data['ord_4'] = full_data['ord_4'].apply(lambda x: ord(x) - ord('A'))\n\nfull_data['ord_5a'] = full_data['ord_5'].str[0]\nfull_data['ord_5b'] = full_data['ord_5'].str[1]\nfull_data['ord_5a'] = full_data['ord_5a'].map({val : idx for idx, val in enumerate(np.unique(full_data['ord_5a']))})\nfull_data['ord_5b'] = full_data['ord_5b'].map({val : idx for idx, val in enumerate(np.unique(full_data['ord_5b']))})\nfull_data.drop(['ord_5', 'ord_5_len'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data[['nom_7', 'nom_8', 'nom_9']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.drop(['nom_7', 'nom_8', 'nom_9'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data['day'] = full_data['day']/7.0\nfull_data['month'] = full_data['month']/12.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data = pd.get_dummies(data=full_data, columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6'], prefix_sep='_', sparse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = full_data[:train_rows]\ntest_data = full_data[train_rows:]\ndel full_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver='sag', class_weight='balanced', random_state=0, max_iter=200, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\nkfold = StratifiedKFold(n_splits=5, random_state=0,)\nparams = {'C': [0.79]}\n\ngrid = GridSearchCV(estimator=lr,\n                  param_grid=params,\n                  cv=kfold\n                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.fit(train_data, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = grid.best_estimator_\nprint(grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict_proba(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = y_pred[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = pd.Series(y_pred)\ntest_df = pd.DataFrame([test_data.index, y_pred]).transpose()\ntest_df.columns = ['id', 'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['id'] = test_df['id'].astype(int)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}