{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"../input/cat-in-the-dat/sample_submission.csv\")\ntest = pd.read_csv(\"../input/cat-in-the-dat/test.csv\")\ntrain = pd.read_csv(\"../input/cat-in-the-dat/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncarrier_count = train['ord_1'].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of Carriers')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('nom_7', fontsize=12)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale_mapper = {'Novice':1, \n                'Contributor':2,\n                'Master':3,\n                'Grandmaster':4,\n                'Expert':5}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale_mapper2 = {'Freezing':1, \n                'Cold':2,\n                'Warm':3,\n                'Hot':4,\n                'Boiling Hot':5,\n                'Lava Hot':6}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale_mapper3 = {'a':1, \n                'b':2,\n                'c':3,\n                'd':4,\n                'e':5,\n                'f':6, \n                'g':7,\n                'h':8,\n                'i':9,\n                'j':10,\n                'k':11, \n                'l':12,\n                'm':13,\n                'n':14,\n                'o':15,\n                }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale_mapper4 = {'A':1, \n                'B':2,\n                'C':3,\n                'D':4,\n                'E':5,\n                'F':6, \n                'G':7,\n                'H':8,\n                'I':9,\n                'J':10,\n                'K':11, \n                'L':12,\n                'M':13,\n                'N':14,\n                'O':15,\n                'P':16, \n                'Q':17,\n                'R':18,\n                'S':19,\n                'T':20,\n                'U':21, \n                'V':22,\n                'W':23,\n                'X':24,\n                'Y':25,\n                'Z':26}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['experience'] = train['ord_1'].replace(scale_mapper)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['experience'] = test['ord_1'].replace(scale_mapper)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temperature'] = train['ord_2'].replace(scale_mapper2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['temperature'] = test['ord_2'].replace(scale_mapper2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['small'] = train['ord_3'].replace(scale_mapper3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['small'] = test['ord_3'].replace(scale_mapper3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['capital'] = train['ord_4'].replace(scale_mapper4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['capital'] = test['ord_4'].replace(scale_mapper4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binaryconverter = {'T':1,\n                   'F':0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binaryconverter2 = {'Y':1,\n                   'N':0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['truefalse'] = train['bin_3'].replace(binaryconverter)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['truefalse'] = test['bin_3'].replace(binaryconverter)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['yesno'] = train['bin_4'].replace(binaryconverter2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['yesno'] = test['bin_4'].replace(binaryconverter2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.rename(columns={'bin_0':'a','bin_1':'b'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.rename(columns={'bin_0':'a','bin_1':'b'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\ntrain['color'] = lb_make.fit_transform(train['nom_0'])\n\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function defined to apply mean encoding technique to nominal features and k-fold to apply regularization andf prevent overfitting\nfrom sklearn import base\nfrom sklearn.model_selection import KFold\nclass KFoldTargetEncoderTrain(base.BaseEstimator, base.TransformerMixin):\n\n    def __init__(self, colnames,targetName,n_fold=5,verbosity=True,discardOriginal_col=False):\n\n        self.colnames = colnames\n        self.targetName = targetName\n        self.n_fold = n_fold\n        self.verbosity = verbosity\n        self.discardOriginal_col = discardOriginal_col\n\n    def fit(self, X, y=None):\n        return self\n\n\n    def transform(self,X):\n\n        assert(type(self.targetName) == str)\n        assert(type(self.colnames) == str)\n        assert(self.colnames in X.columns)\n        assert(self.targetName in X.columns)\n\n        mean_of_target = X[self.targetName].mean()\n        kf = KFold(n_splits = self.n_fold, shuffle = False, random_state=2019)\n\n\n\n        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n        X[col_mean_name] = np.nan\n\n        for tr_ind, val_ind in kf.split(X):\n            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n#             print(tr_ind,val_ind)\n            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n\n        X[col_mean_name].fillna(mean_of_target, inplace = True)\n\n        if self.verbosity:\n\n            encoded_feature = X[col_mean_name].values\n            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,\n                                                                                      self.targetName,\n                                                                                      np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n        if self.discardOriginal_col:\n            X = X.drop(self.targetName, axis=1)\n            \n\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import base\nfrom sklearn.model_selection import KFold\n\ntargetc = KFoldTargetEncoderTrain('nom_1','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.rename(columns={'nom_1_Kfold_Target_Enc':'shape'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mean Encoding categorical variable with K-fold regularization to handle nominal variables\nclass KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n    \n    def __init__(self,train,colNames,encodedName):\n        \n        self.train = train\n        self.colNames = colNames\n        self.encodedName = encodedName\n        \n        \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self,X):\n\n\n        mean = self.train[[self.colNames,self.encodedName]].groupby(self.colNames).mean().reset_index() \n        \n        dd = {}\n        for index, row in mean.iterrows():\n            dd[row[self.colNames]] = row[self.encodedName]\n\n        \n        X[self.encodedName] = X[self.colNames]\n        X = X.replace({self.encodedName: dd})\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shapes ---> test\ntest_targetc = KFoldTargetEncoderTest(train,'nom_1','nom_1_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('nom_2','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Animals ---> test\ntest_targetc = KFoldTargetEncoderTest(train,'nom_2','nom_2_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('nom_3','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Countries\ntest_targetc = KFoldTargetEncoderTest(train,'nom_3','nom_3_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('nom_4','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Instruments\ntest_targetc = KFoldTargetEncoderTest(train,'nom_4','nom_4_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('nom_5','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\ntest_targetc = KFoldTargetEncoderTest(train,'nom_5','nom_5_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('nom_6','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\ntest_targetc = KFoldTargetEncoderTest(train,'nom_6','nom_6_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('nom_7','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\ntest_targetc = KFoldTargetEncoderTest(train,'nom_7','nom_7_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('nom_8','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\ntest_targetc = KFoldTargetEncoderTest(train,'nom_8','nom_8_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('nom_9','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\ntest_targetc = KFoldTargetEncoderTest(train,'nom_9','nom_9_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('ord_5','target',n_fold=5)\ntrain = targetc.fit_transform(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\ntest_targetc = KFoldTargetEncoderTest(train,'ord_5','ord_5_Kfold_Target_Enc')\ntest = test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shapes Animals Countries Instruments\ntrain.rename(columns={'nom_1_Kfold_Target_Enc':'shape','nom_2_Kfold_Target_Enc':'animal','nom_3_Kfold_Target_Enc':'country','nom_4_Kfold_Target_Enc':'instrument','nom_5_Kfold_Target_Enc':'p','nom_6_Kfold_Target_Enc':'q','nom_7_Kfold_Target_Enc':'r','nom_8_Kfold_Target_Enc':'s','nom_9_Kfold_Target_Enc':'t','ord_5_Kfold_Target_Enc':'u'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shapes Animals Countries Instruments\ntest.rename(columns={'nom_1_Kfold_Target_Enc':'shape','nom_2_Kfold_Target_Enc':'animal','nom_3_Kfold_Target_Enc':'country','nom_4_Kfold_Target_Enc':'instrument','nom_5_Kfold_Target_Enc':'p','nom_6_Kfold_Target_Enc':'q','nom_7_Kfold_Target_Enc':'r','nom_8_Kfold_Target_Enc':'s','nom_9_Kfold_Target_Enc':'t','ord_5_Kfold_Target_Enc':'u'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train = train[['a','b','truefalse','yesno','experience','temperature','small','capital','color','shape','animal','country','instrument','p','q','r','s','t','u','day','month','target']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test = train[['a','b','truefalse','yesno','experience','temperature','small','capital','color','shape','animal','country','instrument','p','q','r','s','t','u','day','month']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Handling imbalanced features using SMOTE oversampling technique\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nX = final_train.iloc[:, 0:20]\ny = final_train.iloc[:, 21]\nfrom imblearn.over_sampling import SMOTE\nos = SMOTE(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\ncolumns = X_train.columns\nos_data_X,os_data_y=os.fit_sample(X_train, y_train)\nos_data_X = pd.DataFrame(data=os_data_X,columns=columns )\nos_data_y= pd.DataFrame(data=os_data_y,columns=['target'])\n# we can Check the numbers of our data\nprint(\"length of oversampled data is \",len(os_data_X))\nprint(\"Number of 0 in oversampled data\",len(os_data_y[os_data_y['target']==0]))\nprint(\"Number of subscription\",len(os_data_y[os_data_y['target']==1]))\nprint(\"Proportion of target 0 in oversampled data is \",len(os_data_y[os_data_y['target']==0])/len(os_data_X))\nprint(\"Proportion of target 1 in oversampled data is \",len(os_data_y[os_data_y['target']==1])/len(os_data_X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Applying XGBoost Model\n#Scope for improvement --> hyperparameter grid tuning\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train = pd.concat([os_data_X,os_data_y],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(final_train, test_size=0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.iloc[:,0:19]\ny_train = train.iloc[:,20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test.iloc[:,0:19]\ny_test = test.iloc[:,20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid = final_test.iloc[:,0:20]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier(max_depth=8, objective='reg:logistic',eta=0.3,subsample=0.8,colsample_bytree =0.9,colsample_bylevel=1,min_child_weight=10,num_boost_round=200, \n                  early_stopping_rounds=30, maximize=False, \n                  verbose_eval=10)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain = final_train.iloc[:,0:19]\nYtrain = final_train.iloc[:,20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stratified k-fold cross validation evaluation of xgboost model ------> read more about this!!!\nfrom numpy import loadtxt\nimport xgboost\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\n# CV model\nmodel2 = xgboost.XGBClassifier(max_depth=8, objective='reg:logistic',eta=0.3,subsample=0.8,colsample_bytree =0.9,colsample_bylevel=1,min_child_weight=10)\nkfold = StratifiedKFold(n_splits=10, random_state=7)\nresults = cross_val_score(model2, Xtrain, Ytrain, cv=kfold)\nprint(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.feature_importances_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_importance \nimport matplotlib.pyplot as plt\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nplot_importance(model,ax = axes,height = 0.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n# specify your configurations as a dict\nparams = {'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,        \n    }\n\n\n\nprint('Starting training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=1000,\n                valid_sets=lgb_eval,\n                verbose_eval=50,\n                early_stopping_rounds=5)\n\ny_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n# eval\nprint('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgbm\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgbm.plot_importance(gbm,ax = axes,height = 0.5)\nplt.show();plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Applying regression models\n#Logistic Regression\nfinal_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import roc_auc_score\nlr=LogisticRegression(C=0.125, solver=\"lbfgs\", max_iter=500)  \n\nlr.fit(X_train, y_train)\ny_pred_lr=lr.predict_proba(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_test.values, y_pred_lr[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\ny_pred_proba = lr.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn import linear_model, datasets\nfrom sklearn.model_selection import GridSearchCV\n# Create regularization penalty space\n\npenalty = ['l1', 'l2']\n\n# Create regularization hyperparameter space\nC = np.logspace(0, 4, 10)\n\n# Create hyperparameter options\nhyperparameters = dict(C=C, penalty=penalty)\nlogistic = linear_model.LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create grid search using 5-fold cross validation\nclf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_lr2=clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y_test.values, y_pred_lr2[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\nprint('Best C:', best_model.best_estimator_.get_params()['C'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}