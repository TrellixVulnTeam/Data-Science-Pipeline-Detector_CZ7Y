{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pathlib\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\n# print(f'TF version {tf.__version__}')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input/cat-in-the-dat/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/cat-in-the-dat/train.csv')\ndf_test = pd.read_csv('../input/cat-in-the-dat/test.csv')\n\nprint(f'Train shape {df_train.shape}')\nprint(f'Test shape {df_test.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample = pd.read_csv('../input/cat-in-the-dat/sample_submission.csv')\ndf_sample.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.sample(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train.target.values\ny_train = y_train.ravel().astype(np.float64)\ndf_train.drop(['target'], axis=1, inplace=True)\ndf_train.drop(['id'], axis=1, inplace=True)\n\ndf_id = df_test.id.values\ndf_test.drop(['id'], axis=1, inplace=True)\ndf_all = pd.concat((df_train, df_test), sort=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_na = (df_all.isnull().sum() / len(df_all)) * 100\nall_na = all_na.drop(all_na[all_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_na})\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(df):\n    df = df.replace(np.nan, 0).replace(np.inf, 1e+5).replace(-np.inf, -1e+5)\n    for column in df.columns:\n        if df[column].dtype.name == 'object' and column != 'timestamp':\n            df[column] = pd.Categorical(df[column]).codes\n        if column not in ['site_id', 'building_id', 'timestamp', 'meter', 'meter_reading']:\n            col_stats = df[column].describe()\n            df[column] = (df[column] - col_stats['mean']) / col_stats['std']\n    return df\n\ndf_all = prepare_data(df_all)\ndf_all.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_all[:df_train.shape[0]]\ndf_test = df_all[df_train.shape[0]:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n  model = keras.Sequential([\n    layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001), input_shape=[len(df_train.keys())]),\n    layers.Dropout(0.3),\n    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n    layers.Dropout(0.3),\n    layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n    layers.Dropout(0.3),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(1e-4)\n#   optimizer = tf.keras.optimizers.Adam(1e-4)\n\n#   model.compile(loss='mse',\n#                 optimizer=optimizer,\n#                 metrics=['mae', 'mse'])\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model\n\nmodel = build_model()\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 30\n\nclass MyProgbarLogger(keras.callbacks.Callback):\n  def on_train_begin(self, logs=None):\n    self.seen = 0\n    self.progbar = keras.utils.Progbar(\n        target=EPOCHS,\n        unit_name='epoch')\n\n  def on_epoch_end(self, epoch, logs=None):\n    self.seen += 1\n    self.progbar.update(self.seen)\n    \nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    print('.', end='')\n    \n# progbar = keras.callbacks.ProgbarLogger(params={'verbose': False})\n# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = model.fit(\n  df_train, y_train,\n  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n#   callbacks=[early_stop, MyProgbarLogger()])\n    callbacks=[MyProgbarLogger()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [meter_reading]')\n  plt.plot(hist['epoch'], hist['mae'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mae'],\n           label = 'Val Error')\n  plt.ylim([0,10])\n  plt.legend()\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Square Error [$meter_reading^2$]')\n  plt.plot(hist['epoch'], hist['mse'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mse'],\n           label = 'Val Error')\n  plt.ylim([0,10])\n  plt.legend()\n  plt.show()\n\n\nplot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, mae, mse = model.evaluate(df_train, y_train, verbose=2)\n\nprint(\"Testing set Mean Abs Error: {:5.2f} meter_reading\".format(mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = model.predict(df_train).flatten()\n\nplt.scatter(y_train, test_predictions)\nplt.xlabel('True Values [meter_reading]')\nplt.ylabel('Predictions [meter_reading]')\nplt.axis('equal')\nplt.axis('square')\nplt.xlim([0,plt.xlim()[1]])\nplt.ylim([0,plt.ylim()[1]])\n_ = plt.plot([-100, 100], [-100, 100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(df_test).flatten().ravel()\nsub = pd.DataFrame()\nsub[\"id\"] = df_id\nsub[\"target\"] = y_pred\nprint(sub.head(20))\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}