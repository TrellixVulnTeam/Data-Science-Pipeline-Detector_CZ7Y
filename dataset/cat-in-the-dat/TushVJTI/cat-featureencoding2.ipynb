{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import SVR\nfrom sklearn import *\nimport datetime as dt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Import Dependencies\n%matplotlib inline\n#### Start Python Imports\nimport math, time, random, datetime\n#### Data Manipulation\nimport numpy as np\nimport pandas as pd\n#### Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n#### Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n#### Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\n\n##### Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/cat-in-the-dat/train.csv')\ntest = pd.read_csv('../input/cat-in-the-dat/test.csv')\nprint (\"Data is loaded!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RMSLE(y, pred):\n    return metrics.mean_squared_error(y, pred) ** 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train.copy()\nvalid = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data.nunique()\n#valid.nunique()\n\n# in case needs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get a list of object cat columns \n# Get list of categorical variables\ns = (data.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len (object_cols)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will seperate the object columns that should be one hot encoded (< 12 unique values) and columns that should be label encoded (rest of the object categorical columns)"},{"metadata":{"trusted":true},"cell_type":"code","source":"OH_col = data.loc[:, data.nunique() < 15].columns\n\nnew_OH = []\nfor x in OH_col:\n    if x in object_cols:\n        new_OH.append(x)\n        \n#new_OH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LE_col = data.loc[:, data.nunique() >= 15].columns\nnew_LE = []\nfor x in LE_col:\n    if x in object_cols:\n        new_LE.append(x)\n\n#new_LE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lebel encoding : inplace"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make copy to avoid changing original data \nlabel_X_train = data.copy()\nlabel_X_valid = valid.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in new_LE:\n    label_X_train[col] = label_encoder.fit_transform(data[col])\n    label_X_valid[col] = label_encoder.fit_transform(valid[col])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(label_X_train.shape)\nprint(label_X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_X_valid.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use label_X_train and label_X_valid for next calculations ( One hot encoding )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### * One Hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"#label_X_train[new_OH].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(label_X_train[new_OH]))\nOH_cols_valid = pd.DataFrame(OH_encoder.fit_transform(label_X_valid[new_OH]))\n##  check if fit_transform or just transform should be used.... for valid data set....\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(OH_cols_train.shape)\nprint(OH_cols_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_X_train[new_OH].nunique().sum()\n# means OH_cols_train has no data of rest of columns....\n# so now add the data back","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encoding removed index; put it back\nOH_cols_train.index = label_X_train.index\nOH_cols_valid.index = label_X_valid.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove categorical columns (will replace with one-hot encoding)\n# these are columns which has numerical data and lebel encoding columns that's been processed already.\nnum_X_train = label_X_train.drop(new_OH, axis=1)\nnum_X_valid = label_X_valid.drop(new_OH, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#num_X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#num_X_valid.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OH_X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OH_X_valid.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(OH_X_train.shape)\nprint(OH_X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### * ML Algo"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.utils.testing import ignore_warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier( \n                             n_estimators=200,\n                             n_jobs=-1,\n                             verbose = 2)\n#model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n\nlr1 = LogisticRegression(solver='lbfgs', C=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = OH_X_train.drop(\"target\", axis = 1)\ny_train = OH_X_train[\"target\"]\nX_train = X_train.drop(\"id\", axis=1)\nX_test = OH_X_valid.drop(\"id\",axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaler = MinMaxScaler(feature_range=(0, 1))\n#X_train = scaler.fit_transform(X_train)\n#X_test = scaler.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rf.fit(X_train, y_train)\n#lr1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# alternate cv method\nX, X_hideout, y, y_hideout = model_selection.train_test_split(X_train, y_train, test_size=0.13, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up folds\nK = 4\nkf = model_selection.KFold(n_splits = K, random_state = 1, shuffle = True)\nnp.random.seed(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = SVR(kernel='rbf')\nparams = {'n_estimators': 10, # change to 9000 to obtain 0.505 on LB (longer run time expected)\n        'max_depth': 5,\n        'min_samples_split': 200,\n        'min_samples_leaf': 50,\n        'learning_rate': 0.005,\n        'max_features':  'sqrt',\n        'subsample': 0.8,\n        'loss': 'ls'}\n#model = ensemble.GradientBoostingRegressor(**params)\nmodel = ensemble.RandomForestClassifier(n_jobs = -1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Started CV at \", dt.datetime.now())\nfor i, (train_index, test_index) in enumerate(kf.split(X)):\n    # Create data for this fold\n    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n    #X_test = test[col]\n    print(\"\\nFold \", i)\n    \n    fit_model = model.fit(X_train, y_train)\n    pred = model.predict(X_valid)\n    print('RMSLE GBM Regressor, validation set, fold ', i, ': ', RMSLE(y_valid, pred))\n    \n    pred_hideout = model.predict(X_hideout)\n    print('RMSLE GBM Regressor, hideout set, fold ', i, ': ', RMSLE(y_hideout, pred_hideout))\n    print('Prediction length on validation set, GBM Regressor, fold ', i, ': ', len(pred))\n    # Accumulate test set predictions\n    \n    del  X_train, X_valid, y_train\n    \nprint(\"Finished CV at \", dt.datetime.now())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scores = []\n# best_svr = SVR(kernel='rbf')\n# #random_state=42, shuffle=False\n# cv = KFold(n_splits=10)\n# for train_index, test_index in cv.split(X_train):\n#     print(\"Train Index: \", train_index, \"\\n\")\n#     print(\"Test Index: \", test_index)\n\n#     X_tr = X_train.iloc[train_index,:]\n#     X_tes = X_train.iloc[test_index,:]\n#     y_tr = y_train.iloc[train_index]\n#     y_tes = y_train.iloc[test_index]\n#     print(X_tr.shape)\n#     print(X_tes.shape)\n#     print(y_tr.shape)\n#     print(y_tes.shape)\n    \n    \n#     #best_svr.fit(X_tr, y_tr)\n#     #scores.append(best_svr.score(X_tes, y_tes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train.iloc[[1,3],:]\n#y_train.iloc[30000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions = rf.predict(X_test)\n# predict_lr = lr1.predict_proba(X_test)\n# prediction_svr = best_svr.predict(X_test)\n\n# submission = pd.DataFrame()\n# submission_LR = pd.DataFrame()\n# submission_svr = pd.DataFrame()\n\n# submission[\"id\"] = OH_X_valid[\"id\"]\n# submission_LR[\"id\"] = OH_X_valid[\"id\"]\n# submission_svr['id'] = OH_X_valid[\"id\"]\n\n# submission[\"target\"] = predictions\n# submission_LR[\"target\"] = predict_lr[:, 1]\n# submission_svr[\"target\"] = prediction_svr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(X_test)\nsubmission = pd.DataFrame()\nsubmission['id'] = OH_X_valid[\"id\"]\nsubmission[\"target\"] = prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"cat_submission1.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_lr[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.target.value_counts().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"cat_submission1.csv\", index = False)\nsubmission_LR.to_csv(\"cat_submission_lr.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate\n\nscore=cross_validate(lr1, X_train, y_train, cv=3, scoring=\"roc_auc\")[\"test_score\"].mean()\nprint(f\"{score:.6f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1] Try with all one hot encoding using get dummies once and see the improvements............                                                             2] Try with k - fold CV for training and cs score test "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}