{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Categorical Feature Encoding Challenge Top 1 Solution"},{"metadata":{},"cell_type":"markdown","source":"## This is a simple modeling notebook using Logistic Regression. This model reaches the top 1. If you think it's useful, please upvote ðŸ™‚\n## I also shared [basic EDA notebook for everyone](https://www.kaggle.com/werooring/powerful-and-simple-eda-for-everyone)"},{"metadata":{},"cell_type":"markdown","source":"#### I applied feature encoding, feature scaling to rank 1st place on the private leaderboard"},{"metadata":{},"cell_type":"markdown","source":"- [Competition Link](https://www.kaggle.com/c/cat-in-the-dat/)\n- [Modeling Notebook Reference Link](https://www.kaggle.com/dkomyagin/cat-in-the-dat-0-80285-private-lb-solution)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/cat-in-the-dat/train.csv', index_col='id')\ntest = pd.read_csv('/kaggle/input/cat-in-the-dat/test.csv', index_col='id')\nsubmission = pd.read_csv('/kaggle/input/cat-in-the-dat/sample_submission.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine training data with test data\nall_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop('target', axis=1) # Drop target value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Encoding"},{"metadata":{},"cell_type":"markdown","source":"### Binary Feature Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['bin_3'] = all_data['bin_3'].map({'F':0, 'T':1})\nall_data['bin_4'] = all_data['bin_4'].map({'N':0, 'Y':1})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ordinal Feature Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"ord1dict = {'Novice':0, 'Contributor':1, \n            'Expert':2, 'Master':3, 'Grandmaster':4}\nord2dict = {'Freezing':0, 'Cold':1, 'Warm':2, \n            'Hot':3, 'Boiling Hot':4, 'Lava Hot':5}\n\nall_data['ord_1'] = all_data['ord_1'].map(ord1dict)\nall_data['ord_2'] = all_data['ord_2'].map(ord2dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nord_345 = ['ord_3', 'ord_4', 'ord_5']\n\nord_encoder = OrdinalEncoder() # Create OrdinalEncoder object\n# Apply ordinal encoding\nall_data[ord_345] = ord_encoder.fit_transform(all_data[ord_345])\n\n# Print encoding order by feature\nfor col, categories in zip(ord_345, ord_encoder.categories_):\n    print(col)\n    print(categories)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Nominal Feature Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['nom_5'] = all_data['nom_5'].str[3:]\nall_data['nom_6'] = all_data['nom_6'].str[3:]\nall_data['nom_7'] = all_data['nom_7'].str[3:]\nall_data['nom_8'] = all_data['nom_8'].str[3:]\nall_data['nom_9'] = all_data['nom_9'].str[3:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nom_cols = ['nom_' + str(i) for i in range(10)] # Nominal features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nnom_onehot_encoder = OneHotEncoder(drop='first') # Create OneHotEncoder object\n# Apply one-hot encoding\nencoded_nom_matrix = nom_onehot_encoder.fit_transform(all_data[nom_cols])\n\nall_data = all_data.drop(nom_cols, axis=1) # Drop original nominal features\n\nencoded_nom_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Date Feature Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"date_cols  = ['day', 'month'] # Date features\n\ndate_onehot_encoder = OneHotEncoder() # Create OneHotEncoder object\n# Apply one-hot encoding\nencoded_date_matrix = date_onehot_encoder.fit_transform(all_data[date_cols])\n\nall_data = all_data.drop(date_cols, axis=1) # Drop original date features\n\nencoded_date_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling"},{"metadata":{},"cell_type":"markdown","source":"### Apply scaling to ordinal features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nord_cols = ['ord_' + str(i) for i in range(6)] # ordinal features\n# Min-max normalization\nall_data[ord_cols] = MinMaxScaler().fit_transform(all_data[ord_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Aggregate encoded and feature scaled data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy\n\n# aggregate encoded and feature scaled data \nall_data_sprs = scipy.sparse.hstack([scipy.sparse.csr_matrix(all_data),\n                                     encoded_nom_matrix,\n                                     encoded_date_matrix],\n                                    format='csr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_sprs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Training/Submission"},{"metadata":{},"cell_type":"markdown","source":"### Divide train data and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_train = train.shape[0] # Number of train data\n\n# Divide train data and test data\nX_train = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\n\ny_train = train['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(C=0.125, solver='lbfgs', max_iter=800, verbose=0, n_jobs=-1)\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction and Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = clf.predict_proba(X_test)[:,1]\n\nsubmission['target'] = y_preds\nsubmission.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}