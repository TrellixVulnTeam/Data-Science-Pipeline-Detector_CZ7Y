{"cells":[{"metadata":{},"cell_type":"markdown","source":"This challenge is devoted to binary classification problem, with every feature being categorical.\n\n## **Introduction: categorical variables**\n\nGenerally, there are two types of variable: numerical (continuous) and categorical (discrete). Categorical variable is a discrete variable that has two or more categories. Two major types of categorical variable are defined as nominal and ordinal. Nominal has no intrinsic ordering to the categories. Ordinal has clear intrinsic ordering. \nIn the cosidered dataset the following categorical variable are present: binary (special case of nominal with only two categories), nominal, ordinal, ordinal cyclic (day and month variables). It is important to identify the type of categorical variable since it influences the data preparation and further analysis. Since categorical variables take discrete or often non-numeric values, they have to be properly encoded before using in predictive modeling.\n\n## **Data overview**\nFirst, import the necessary libraries."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt # for plotting\nimport matplotlib.gridspec as gridspec # to do the grid of plots\n# jupyter cell magic for inline visualization\n%matplotlib inline \n\nimport seaborn as sns # for plotting\nsns.set(style='whitegrid') # for plotting style\n\nfrom IPython.display import display\n\nimport gc; gc.enable()\n\n#setting to suppress SettingWithCopy\npd.set_option('mode.chained_assignment', None)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# Any results you write to the current directory are saved as output.\n\n#set random seed\nSEED = 42\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, load the data and calculate some statistics about the available categorical data."},{"metadata":{"trusted":true},"cell_type":"code","source":"##############################\n#######custom  functions######\n##############################\ndef plot_target_dist(df, cols, figsize = (16,10), grid_r=3, grid_c=3):\n    \n    grid = gridspec.GridSpec(grid_r,grid_c) # The grid of chart\n    fig = plt.figure(figsize=figsize) # size of figure\n    total = df.shape[0] # total number of observations\n\n    # loop to get column and the count of plots\n    for n, col in enumerate(df[cols]): \n        ax = plt.subplot(grid[n]) # feeding the figure of grid\n        \n        #for low cardinality data\n        if df[col].nunique() < 14:\n            #count plot\n            sns.countplot(x=col, data=df, hue='target', palette='Paired',\n                          order=df[col].sort_values().unique(),ax=ax) \n            #df.groupby([col,'target'])[col].count().unstack(level=1)\\\n            #  .plot(kind='bar', color = [\"#a6cee3\", \"#1f78b4\"], width=0.8, ax=ax)\n            sizes=[] # Get highest values in y\n            for p in ax.patches: # loop to all objects\n                height = p.get_height()\n                sizes.append(height)\n                ax.text(p.get_x()+p.get_width()/2.,\n                        height * 1.02,\n                        '{:1.1f}%'.format(height/total*100),\n                        ha=\"center\", fontsize=14) \n            ax.set_ylim(0, max(sizes) * 1.15) # set y limit based on highest heights\n\n        #for high cardinality data\n        else:\n            df_col = df.groupby([col,'target'])[col].count()\\\n                       .unstack(level=1).fillna(0).sort_index()\n            #define the plot type \n            if df[col].nunique() < 200:\n                df_col.plot(kind='bar', ax=ax, stacked=True,\n                            color = [\"#a6cee3\", \"#1f78b4\"], width=1)\n            else: \n                df_col.plot(kind='line', ax=ax, \n                            color = [\"#a6cee3\", \"#1f78b4\"])\n                        \n            #force number of xticks to show\n            ax.xaxis.set_major_locator(plt.MaxNLocator(20) )\n            \n            \n        #set labels\n        ax.set_ylabel('Count', fontsize=15) # y axis label\n        ax.set_title(f'{col} distribution by target', fontsize=16) # title label\n        ax.set_xlabel(f'{col} values', fontsize=15) # x axis label\n        _xlim = ax.get_xlim()\n        \n        #calculate pct of class 1\n        d = df.groupby([col,'target'])[col].count()\\\n              .unstack(level=1).fillna(0).sort_index()\n        d['class1_pct'] = d[1] / (d.sum(axis=1))\n        if (d.index.dtype == 'int'):\n            d.index = d.index - d.index.min()\n        elif (d.index.dtype == 'float'):\n            #to fix the scale\n            d.index = d.index * df[col].nunique()\n        \n        #add another y-axis to show the pct of class 1\n        ax2 = ax.twinx()\n        if df[col].nunique() < 200:\n            d.class1_pct.plot(marker='o',markersize=5,ax=ax2,color=[\"#6a3d9a\"])\n        else:\n            d.class1_pct.plot(marker='o',markersize=5,linewidth=0,\n                              ax=ax2,color=[\"#6a3d9a\"])\n            \n        ax2.set_ylabel('class 1 fraction', color=\"#6a3d9a\", fontsize=15)\n        ax2.set_xlim(_xlim)\n        ax2.set_ylim([-0.1,1.1])\n        ax2.grid(False)\n        \n    #!!!!!!!need to fix missing xlabels, problem appears when twinx axis is added\n    plt.tight_layout()\n    plt.show()\n    \n#calculate mean class 1 proporsion and average contrast between values\ndef mean_1_contrast(df,cols):\n    contrast = {}\n    mean_1 = {}\n\n    for col in cols:\n        d = df.groupby([col,'target'])[col].count().unstack(level=1)\n        d['class1_pct'] = d[1] / (d.sum(axis=1))\n        contrast[col] = abs(d['class1_pct'].pct_change().dropna().values).mean()\n        mean_1[col] = d['class1_pct'].mean()\n    \n    return pd.concat([pd.DataFrame(mean_1,index=['mean_class1']),\n          pd.DataFrame(contrast,index=['contrast'])])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"'''Read in train and test data from csv files'''\ndf_train = pd.read_csv('../input/cat-in-the-dat/train.csv',index_col=0)\ndf_test = pd.read_csv('../input/cat-in-the-dat/test.csv',index_col=0)\n\n#From df.info():\nprint('There are no missing values in the dataset.')\n\n#Check the size of the dataset:\nprint(f\"There are {df_train.shape[1]} features and {df_train.shape[0]:,} observation.\")\n\n#Display the statistic for categorical data\nd = df_train.astype('str').describe().T\n#add percentage for most frequently observed value in a given feature\nd['top, %'] = d['freq']/df_train.shape[0]*100\n#display the summary with some columns removed \nd.drop(['count','freq'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the summary table, there are 5 binary variables; 10 nominal, to be exact 5 are low and 5 are high-cardinality; 6 ordinal data where 1 of them is high-cardinality; finally, 2 cyclic variable. The target column is binary which indicates that this is a classification problem. Besides, moderate class imbalance in target values can be noticed: about 70% of class 0 and 30% of class 1. Imbalance can be handled by proper sampling.\n\nNext, to better understand the data, visualization of the feature distribution with respect to target variable, as well as percentage of class 1 are plotted below for different variable types. The goal is to get some insights about the data for preprocessing task."},{"metadata":{"trusted":true},"cell_type":"code","source":"#group columns by type\ntarget = 'target'\nbin_cols = [col for col in df_train.columns if 'bin' in col]\ncyclic_cols = ['day','month']\nord_cols = [col for col in df_train.columns if 'ord' in col]\nnom_cols = [col for col in df_train.columns if 'nom' in col]\nno_target = [col for col in df_train.columns if 'target' not in col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## **Visualization**\n### Binary features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target_dist(df_train, bin_cols, figsize = (16,8), grid_r=2, grid_c=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#target: class 1 fraction\ndf_train.target.value_counts(normalize=True)[1].round(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate contrast and avegare classes 1 proporsion\nmean_1_contrast(df_train,bin_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the plots above and the summary table, binary features have negligible contrast in terms of class 1 fraction: values are close to overall target proportion of 0.305. Clearly bin_1 variable has the highest contrast of ~29 % and bin_4 has some noticeable contrast of ~13% in class 1 fraction between its values. Therefore, original binary features do not contain a lot of information for target predictions.\n\n### Cyclic features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target_dist(df_train,cyclic_cols, figsize = (18,5), grid_r=1, grid_c=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate contrast and avegare classes 1 proporsion\nmean_1_contrast(df_train,cyclic_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cyclic features demonstrate some variability in terms of class 1 fraction although not significant. Day has higher averaged contrast than month variable. There is probably unreliable data at day = 6 and month = 6 due to insufficient amount of observations. \n\n### Ordinal features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target_dist(df_train, ord_cols, figsize = (16,8), grid_r=3, grid_c=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate contrast and avegare classes 1 proporsion\nmean_1_contrast(df_train,ord_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plots ord_1 and ord_2 features are not properly ordered (since ordinal variables imply monotonic behavior of target variable): it needs to be fixed while processing the original data. Noise can be spotted in the data, e.g. in ord_4 there is not anough observation at value 'M'. Moreover, ord_5 definitely has noise probably due to undersampling as well. Here the calculated contrast reflects the averaged slope of the class 1 fraction curve. \n\n### **Nominal features with low-cardinality**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target_dist(df_train, nom_cols[:5], figsize = (16,8), grid_r=3, grid_c=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate contrast and avegare classes 1 proporsion\nmean_1_contrast(df_train,nom_cols[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The low-cardinality nominal variables show the highest level of averaged contrast so far. There are no obviuos outliers or insufficient data issues.\n\n### Nominal features with high-cardinality"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target_dist(df_train, nom_cols[5:], figsize = (16,8), grid_r=3, grid_c=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate contrast and avegare classes 1 proporsion\nmean_1_contrast(df_train,nom_cols[5:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nominal features look very noisy in terms of available data for a given value as well as variation in class 1 fraction. Variable nom_9 is especially noisy, with class fraction jumping between 0 and 1. To confirm this, the distribution of class 1 fraction for nom_9 is shown below. Quite large number of pure class 0 and class 1 observations can be notices, accounting for the fact that each observation value has 21 points or less, these data points are probably unreliable. Further investigations are needed to make high-cardinality data useful, e.g. using appropriate smoothing tecniques to remove unreliable undersampled and \"too confident\" observations."},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of class 1 fraction in nom_9 variable\ncol = 'nom_9'\n\nfig, ax = plt.subplots(1,1,figsize=(6,3))\n\nd = df_train.groupby([col,'target'])[col].count()\\\n            .unstack(level=1).sort_index()\n#calculate the percentage of class 1\nd['class1_pct'] = d[1] / (d.sum(axis=1))\nd.fillna(0, inplace=True)\n#plot a histogram\nd.class1_pct.plot(kind = 'hist')\n\n#label axis\nplt.xlabel('Class 1 fraction', fontsize=15)\nplt.ylabel('Frequency', fontsize=15)\n#add title\nplt.title('Distribution of class 1 fraction for ' + col, fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#how many observation per given value in nom_9?\ndf_train.nom_9.value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Summary**\n\nTo sum up, EDA provides an overview of the cat-in-dat dataset composed purely of categorical features. EDA gives information about noisiness of the data, as well as identifies the undersampled spots, e.g. one value in ord_4, day and month, as well as a few in ord_5. It clearly shown noisiness in high-cardinality nominal features that should be suppressed by proper smoothing tecnique in order to get some valuable infomation from them. Overall, I find this EDA very useful and helpful in gaining better understanding of the problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}