{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os \nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import OneHotEncoder  \nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.preprocessing import StandardScaler  \nfrom sklearn.model_selection import train_test_split\nfrom scipy import sparse  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.listdir(\"../input/cat-in-the-dat\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/cat-in-the-dat/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv(\"../input/cat-in-the-dat/test.csv\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(index=train[~train.nom_7.isin(test.nom_7)].index)\ntrain=train.drop(index=train[~train.nom_8.isin(test.nom_8)].index)\ntrain=train.drop(index=train[~train.nom_9.isin(test.nom_9)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test=test.drop(columns=['id'])\nnew_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\ntrain.target.value_counts().plot(kind='bar',color=['red','plum'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\ncorr = train.corr()\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)\nplt.title(\"correlation plot for train data\",size=28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\ncorr = test.corr()\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns,annot=True)\nplt.title(\"correlation plot for test data\",size=28)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train=train.drop(columns=['id','target'])\nnew_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(5,2,figsize=(15,30))\nj=0\nfor i in new_train.columns[:10]:\n    sns.barplot(y=new_train[i].value_counts()[:10],x=new_train[i].value_counts()[:10].index,ax=ax[int(j/2),round(j%2)])\n    ax[int(j/2),round(j%2)].set_title(\"bar chart for \"+i)\n    ax[int(j/2),round(j%2)].set_ylabel(\"counts\")\n    j+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(5,2,figsize=(30,30))\nj=0\nfor i in new_train.columns[10:20]:\n    sns.barplot(y=new_train[i].value_counts()[:10],x=new_train[i].value_counts()[:10].index,ax=ax[int(j/2),round(j%2)])\n    ax[int(j/2),round(j%2)].set_title(\"bar chart for \"+i)\n    ax[int(j/2),round(j%2)].set_ylabel(\"counts\")\n    j+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(2,2,figsize=(15,15))\nj=0\nfor i in new_train.columns[20:23]:\n    sns.barplot(y=new_train[i].value_counts()[:10],x=new_train[i].value_counts()[:10].index,ax=ax[int(j/2),round(j%2)])\n    ax[int(j/2),round(j%2)].set_title(\"bar chart for \"+i)\n    ax[int(j/2),round(j%2)].set_ylabel(\"counts\")\n    j+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train=new_train.drop(columns=['bin_0'])\nnew_test=new_test.drop(columns=['bin_0'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([new_train, new_test])\n\ndummies = pd.get_dummies(data, columns=data.columns, drop_first=True,sparse=True)\nnew_train = dummies.iloc[:new_train.shape[0], :]\nnew_test = dummies.iloc[new_train.shape[0]:, :]\ndel data\ndel dummies\nnew_train = new_train.sparse.to_coo().tocsr()\nnew_test = new_test.sparse.to_coo().tocsr()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(new_train,train['target'],test_size=0.001,random_state=0)\n\nlr = LogisticRegression(C=0.095,solver='lbfgs',class_weight='balanced')  \nlr.fit(X_train, y_train)  \nproba_test = lr.predict_proba(X_test)[:, 1]\nLR_result=pd.DataFrame({'pred':proba_test,'real':y_test})\nLR_result['pred_0_1']=LR_result.pred.apply(lambda x:1 if x>=0.5 else 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LR_acc: ',sum(LR_result.real==LR_result.pred_0_1)/len(LR_result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.predict_proba(new_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb  \nimport pickle  \n\nX_train=X_train.astype(float)\nX_test=X_test.astype(float)\nlgb_train = lgb.Dataset(X_train, y_train)  \nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train) \nparams = {  \n    'boosting_type': 'gbdt',  \n    'objective': 'binary',  \n    'metric': {'binary_logloss', 'auc'},  \n    'num_leaves':450,  \n    'max_depth': 25,  \n    'min_data_in_leaf': 150,  \n    'learning_rate': 0.1,  \n    'feature_fraction': 0.95,  \n    'bagging_fraction': 0.95,  \n    'bagging_freq': 10,  \n    'lambda_l1': 0,    \n    'lambda_l2': 0, \n    'min_gain_to_split': 0.1,  \n    'verbose': 0,  \n    'is_unbalance': True  \n}  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"gbm = lgb.train(params,  \n                lgb_train,  \n                num_boost_round=10000,  \n                valid_sets=lgb_eval,  \n                early_stopping_rounds=500)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# testdata"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(new_train, train['target'])  \nLR_TEST=lr.predict_proba(new_test)[:, 1]\nnew_test=new_test.astype(float)\nLGBM_TEST= gbm.predict(new_test, num_iteration=gbm.best_iteration) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=pd.DataFrame({'id':test.id,'LR_TEST':LR_TEST,'LGBM_TEST':LGBM_TEST})\nsubmit=pd.DataFrame({'id':test.id,'target':LR_TEST})\nprediction.to_csv('prediction.csv',index=False)\nsubmit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary "},{"metadata":{},"cell_type":"markdown","source":"Here I want to sum up my work from version 1 to version 44.In this data,I have tried to remove variable, set parameters for model,balance the number of sample for target.Actually,most of scores are \nconcentrated on 0.805 to 0.80.\n\nNow I get the highest score is 0.80678,I remove the variable 'bin_0' and use logistic regression.\n\nActually,I could not get the high score from LGBM,even I tried to set the parameter."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}