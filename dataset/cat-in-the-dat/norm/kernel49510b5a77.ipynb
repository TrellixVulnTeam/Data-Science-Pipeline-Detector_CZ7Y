{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.tabular import *\nfrom fastai.callbacks import *\nimport fastai\nfrom fastai.imports import *\nimport string \nfrom fastai.metrics import CMScores\nfrom sklearn.preprocessing import OrdinalEncoder, LabelEncoder\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = Path(\"/kaggle/input/cat-in-the-dat\") #!!!!!!!!!!\npath = Path(\".\") # for saving models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_top(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)\n        \ndef get_infrequent_valuesXX(data, column, threshold):\n    value_counts = data[column].value_counts()\n    return list(value_counts[value_counts < threshold].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    defaults.device = torch.device('cuda') # makes sure the gpu is used\nelse:\n    print(\"not using the gpu\")\n    defaults.device = torch.device('cpu') # makes sure the cpu is used","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# read in test and train data sets\nraw_train_df = pd.read_csv(data_path/\"train.csv\")\nraw_test_df = pd.read_csv(data_path/\"test.csv\")\nsample_sub_df = pd.read_csv(data_path/'sample_submission.csv')\n\ndisplay_top(raw_train_df.tail().transpose())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_train = len(raw_train_df)\nraw_test_df['target'] = -1 #so that both data sets have the same width\n# save for later split \n\n# to simplify recoding - put train and test sets together \nfull_df = pd.concat([raw_train_df, raw_test_df], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split ord 5 into two seperate chars \nfull_df[\"ord_5a\"]=full_df[\"ord_5\"].str[0]\nfull_df[\"ord_5b\"]=full_df[\"ord_5\"].str[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_features = ['ord_0','ord_3','ord_4','ord_5','ord_5a','ord_5b']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ord1_enc = OrdinalEncoder(categories=[np.array(['Novice','Contributor','Expert','Master','Grandmaster'])])\nfull_df.ord_1 = ord1_enc.fit_transform(full_df.ord_1.values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ord2_enc = OrdinalEncoder(categories=[np.array(['Freezing','Cold','Warm','Hot','Boiling Hot','Lava Hot'])])\nfull_df.ord_2 = ord2_enc.fit_transform(full_df.ord_2.values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feat in ordinal_features:\n    enc = OrdinalEncoder()\n    full_df[feat] = enc.fit_transform(full_df[feat].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hex_df = full_df.loc[:,\"nom_5\":\"nom_9\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hex_1 = lambda x: int(bin(int(x,16))[2:].zfill(36)[:9],2)\nhex_2 = lambda x: int(bin(int(x,16))[2:].zfill(36)[9:18],2)\nhex_3 = lambda x: int(bin(int(x,16))[2:].zfill(36)[18:27],2)\nhex_4 = lambda x: int(bin(int(x,16))[2:].zfill(36)[27:],2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_ord_df = pd.DataFrame()\nfor col in hex_df:\n    new_ord_df['%s_1'%col] = hex_df[col].apply(hex_1)\n    new_ord_df['%s_2'%col] = hex_df[col].apply(hex_2)\n    new_ord_df['%s_3'%col] = hex_df[col].apply(hex_3)\n    new_ord_df['%s_4'%col] = hex_df[col].apply(hex_4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.drop(hex_df.columns,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.concat([full_df,new_ord_df],axis=1)\ndisplay_top(full_df.tail().transpose())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_dict = {'Finland':[61.924110,25.748152,'europe',2], \n                'Russia':[61.524010,105.318756,'asia',4], \n                'Canada':[56.130367,-106.346771,'asia',3], \n                'Costa Rica':[9.748917,-83.753426,'sa',1], \n                'China':[35.861660,104.195396,'asia',6], \n                'India':[20.593683,78.962883,'na',5]}\ncountry_df = pd.DataFrame()\ncountry_df['lat'] = full_df.nom_3.apply(lambda x: country_dict[x][0])\ncountry_df['lon'] = full_df.nom_3.apply(lambda x: country_dict[x][1])\ncountry_df['continent'] = full_df.nom_3.apply(lambda x: country_dict[x][2])\n\nfull_df = pd.concat([full_df,country_df],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feat in full_df.columns:\n    if full_df[feat].dtype == 'object':\n        print('Encoding ',feat)\n        le = LabelEncoder()\n        full_df[feat] = le.fit_transform(full_df[feat].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cyclic_days = pd.DataFrame()\ncyclic_days['day_sin'] = np.sin(2 * np.pi * full_df['day']/7)\ncyclic_days['day_cos'] = np.cos(2 * np.pi * full_df['day']/7)\ncyclic_months = pd.DataFrame()\ncyclic_months['month_sin'] = np.sin(2 * np.pi * full_df['month']/12)\ncyclic_months['month_cos'] = np.cos(2 * np.pi * full_df['month']/12)\nfull_df = pd.concat([full_df,cyclic_days,cyclic_months],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['id','bin_0','day','month','nom_3']\nfull_df.drop(drop_cols,axis=1,inplace=True)\n\n\ntrain_df = full_df[:len(raw_train_df)]\ntest_df = full_df[len(raw_train_df)-1:-1]\n\n\ntest_df.drop('target',axis=1,inplace=True)\ndisplay_top(test_df.head().T)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_df), len(test_df))\ndisplay_top(test_df.tail().transpose())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  duplicate the zeros to make the groups about the same size \none = train_df[lambda df: df.target == 1]\nzero = train_df[lambda df: df.target ==0]\ntrain_df = train_df.append(one)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dep_var = 'target'\nnames = set(test_df.columns)\ncat_names = [ 'nom_0', 'nom_1', 'nom_2', 'nom_4',\n       'nom_5_1', 'nom_5_2', 'nom_5_3', 'nom_5_4', 'nom_6_1', 'nom_6_2',\n       'nom_6_3', 'nom_6_4', 'nom_7_1', 'nom_7_2', 'nom_7_3', 'nom_7_4',\n       'nom_8_1', 'nom_8_2', 'nom_8_3', 'nom_8_4', 'nom_9_1', 'nom_9_2',\n       'nom_9_3', 'nom_9_4',  'continent']\ncont_names = list(names - set(cat_names))\n\ncont_names\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for fastai -  need to mark catagoroes and continuous variables\nprint(\"len1\", len(test_df))\n\nprocs = [Categorify, Normalize]\ntest = TabularList.from_df(test_df, path=path, cat_names=cat_names, cont_names=cont_names)\ndata = (TabularList.from_df(train_df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n                           .split_by_rand_pct(.2, seed = 42)\n                           .label_from_df(cols=dep_var)\n                           .add_test(test)\n                           .databunch(bs=2048))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_to_df(d):\n    def cat2num(df):\n        cat_columns = df.select_dtypes(['category']).columns\n        df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n        return df\n    \n    dtrain = cat2num(d.train_ds.x.inner_df)\n    dtrain  = dtrain.drop(['target'], axis=1)\n    dvalid = cat2num(d.valid_ds.x.inner_df)\n    dvalid = dvalid.drop(['target'], axis=1)\n    return dtrain, d.train_ds.y.items, dvalid, d.valid_ds.y.items, cat2num(d.test_ds.x.inner_df)\n\n\nX_train, y_train, X_valid, y_valid,  test_df = convert_to_df(data)\n\n\n\ndisplay_top(X_train.head().T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Myacc(CMScores):\n    def on_epoch_end(self, last_metrics, **kwargs):\n        total = self.cm.sum()\n        wrong = total - self.cm.diag().sum()\n        print(\"total\", total, \"wrong\", wrong)\n        return add_metrics(last_metrics, wrong)\n\nclass FastaiRunner:\n    def emb_sz_rule(n_cat:int)->int: return min(50, (n_cat+5) // 2)\n    def __init__(self, data, X_train, count):\n        self.count = count\n        def emb_sz_rule(n_cat:int)->int: return min(50, (n_cat+5) // 2)\n        self.embedding_dict = {}\n        for column in data.x.cat_names:\n            self.embedding_dict[column] = emb_sz_rule(len(X_train[column].unique()))\n        pre = Myacc()\n        self.learn = tabular_learner(data, layers=[100, 100], metrics=[pre, AUROC()],\n                                     ps =.3,wd = .1, emb_drop = .2, emb_szs= self.embedding_dict)\n        self.path = Path(\".\")\n        \n    def fit(self, _, _1):\n        # shoukld be 32 or more \n        self.learn.fit_one_cycle(self.count, callbacks=[SaveModelCallback(self.learn, monitor=\"myacc\", mode = \"min\", name = \"savedModel\")])\n\n    def predict_proba(self, _):\n        self.learn.load(\"savedModel\")\n        preds, _ = self.learn.get_preds(DatasetType.Test)\n        return  preds\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import RidgeClassifier, LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\n\nclassifiers = [\n    FastaiRunner(data, X_train, 32),\n    RandomForestClassifier(n_estimators=100, oob_score=True),\n    LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=500),\n    LinearDiscriminantAnalysis(),\n    GaussianNB(),\n    BernoulliNB(),\n    DecisionTreeClassifier(),\n    XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', \n                     nrounds = 'min.error.idx', num_class = 3, \n                     maximize = False, eval_metric = 'logloss', eta = .1,\n                     max_depth = 14, colsample_bytree = .4, n_jobs=-1)\n]\n\n\nsubmission_df = sample_sub_df.copy()\nsubmission_df.drop([\"target\"],axis=1,inplace=True)\ncolumns = []\nfor clf in classifiers:\n    name = clf.__class__.__name__\n    columns.append(name)\n    print(\"process\", name)\n    print(X_train.shape)\n    clf.fit(X_train, y_train)\n    preds = clf.predict_proba(test_df)[:,1]\n    print(\"lenpreds \", len(preds), \" len sub\", len(submission_df))\n    submission_df[name] = preds\n    \n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head()\noutput = pd.DataFrame(columns=[\"id\", \"target\"])\noutput.id = submission_df.id\noutput.target = submission_df[columns].mean(axis=1)\n\n\n# each value of preds is a pair with two probs [p0 p1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(output.head())\noutput.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"\n  \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}