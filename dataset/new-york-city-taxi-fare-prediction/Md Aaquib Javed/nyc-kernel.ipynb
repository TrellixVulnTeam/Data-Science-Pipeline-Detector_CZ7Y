{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train =  pd.read_csv('../input/train.csv', nrows = 2_000_000, parse_dates=[\"pickup_datetime\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nThe following things I notice (while using 500k datapoints):\n\n*     The minimal fare_amount is negative. As this does not seem to be realistic I will drop them from the dataset.\n*     Some of the minimum and maximum longitude/lattitude coordinates are way off. These I will also remove from the dataset (I will define a bounding box for the coordinates, see further).\n*     The average fare_amount is about $11.4 USD with a standard deviation of $9.9 USD. When building a predictive model we want to be better than $9.9 USD :)\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Old size : %d\" % len(df_train))\ndf_train = df_train[df_train.fare_amount >= 0]\nprint(\"New Size : %d\" % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train.fare_amount <100].fare_amount.hist(bins = 100, figsize=(14,3))\nplt.xlabel(\"U$D\")\nplt.title(\"Histogram\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()     #Checking for missing data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Old Size : %d' % len(df_train))\ndf_train = df_train.dropna(how = 'any', axis = 'rows')\nprint('New Size : %d' % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/test.csv\")\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below I define a bounding box of interest by [long_min, long_max, latt_min, latt_max] using the minimum and maximum coordinates from the testset. This way, I'm sure to train a model for the full pickup/dropoff coordinate range of the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"#min and max longitude distance\nmin(df_test.pickup_longitude.min(),df_test.dropoff_longitude.min()), \\\nmax(df_test.pickup_longitude.max(),df_test.dropoff_longitude.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#min and max lattitude distance\n\nmin(df_test.pickup_latitude.min(),df_test.dropoff_latitude.min()), \\\nmax(df_test.pickup_latitude.max(),df_test.dropoff_latitude.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n\n\n# load image of NYC map\nBB = (-74.5, -72.8, 40.5, 41.8)\nnyc_map = plt.imread('https://aiblog.nl/download/nyc_-74.5_-72.8_40.5_41.8.png')\n\n# load extra image to zoom in on NYC\nBB_zoom = (-74.3, -73.7, 40.5, 40.9)\nnyc_map_zoom = plt.imread('https://aiblog.nl/download/nyc_-74.3_-73.7_40.5_40.9.png')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Old Size : %d' % len(df_train))\ndf_train = df_train[select_within_boundingbox(df_train, BB)]\nprint('New Size : %d' % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this function will be used more often to plot data on the NYC map\n\ndef plot_on_map(df, BB, nyc_map, s=10, alpha=0.2):\n    fig, axs = plt.subplots(1, 2, figsize=(16,10))\n    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[0].set_xlim((BB[0], BB[1]))\n    axs[0].set_ylim((BB[2], BB[3]))\n    axs[0].set_title('Pickup locations')\n    axs[0].imshow(nyc_map, zorder=0, extent=BB)\n\n    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[1].set_xlim((BB[0], BB[1]))\n    axs[1].set_ylim((BB[2], BB[3]))\n    axs[1].set_title('Dropoff locations')\n    axs[1].imshow(nyc_map, zorder=0, extent=BB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot training data on map\nplot_on_map(df_train, BB, nyc_map, s=1, alpha=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot training data on zoom map\nplot_on_map(df_train, BB_zoom, nyc_map_zoom, s=1, alpha=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ANother Method of visualizing the above scenario\n\ndef plot_hires(df, BB, figsize=(12, 12), ax=None, c=('r', 'b')):\n    if ax == None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    idx = select_within_boundingbox(df, BB)\n    ax.scatter(df[idx].pickup_longitude, df[idx].pickup_latitude, c=c[0], s=0.01, alpha=0.5)\n    ax.scatter(df[idx].dropoff_longitude, df[idx].dropoff_latitude, c=c[1], s=0.01, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nplot_hires(df_train, (-74.1, -73.7, 40.6, 40.9))\nplot_hires(df_train, (-74, -73.95, 40.7, 40.8))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nFrom the training data scatter plot we see that some locations are in the water. Either these are considered as noise, or we drop them from the dataset. I decided to drop them.\n\nAs can be seen from the map + scatter plots above, some datapoints are located in the water. These are obviously noisy datapoints. To remove these datapoints, I create a boolean land/water map from the NYC map. For this I used Photoshop to threshold on the blue color of the water and to cleanup the map"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read nyc mask and turn into boolean map with\n# land = True, water = False\nnyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\nplt.figure(figsize=(8,8))\nplt.imshow(nyc_map, zorder=0)\nplt.imshow(nyc_mask, zorder=1, alpha=0.7); # note: True is show in black, False in white.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing datapoints from water\n\ndef remove_datapoints_from_water(df):\n    def lonlat_to_xy(longitude, latitude, dx, dy, BB):\n        return (dx*(longitude - BB[0])/(BB[1]-BB[0])).astype('int'), \\\n               (dy - dy*(latitude - BB[2])/(BB[3]-BB[2])).astype('int')\n\n    # define bounding box\n    BB = (-74.5, -72.8, 40.5, 41.8)\n    \n    # read nyc mask and turn into boolean map with\n    # land = True, water = False\n    nyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\n    \n    # calculate for each lon,lat coordinate the xy coordinate in the mask map\n    pickup_x, pickup_y = lonlat_to_xy(df.pickup_longitude, df.pickup_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)\n    dropoff_x, dropoff_y = lonlat_to_xy(df.dropoff_longitude, df.dropoff_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)    \n    # calculate boolean index\n    idx = nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x]\n    \n    # return only datapoints on land\n    return df[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Old size: %d' % len(df_train))\ndf_train = remove_datapoints_from_water(df_train)\nprint('New size: %d' % len(df_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplot_on_map(df_train, BB, nyc_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For this plot and further analysis, we need a function to calculate the distance in miles between locations in lon,lat coordinates.\n# This function is based on https://stackoverflow.com/questions/27928/\n# calculate-distance-between-two-latitude-longitude-points-haversine-formula \n# return distance in miles\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...\n\n# First calculate two arrays with datapoint density per sq mile\nn_lon, n_lat = 200, 200 # number of grid bins per longitude, latitude dimension\ndensity_pickup, density_dropoff = np.zeros((n_lat, n_lon)), np.zeros((n_lat, n_lon)) # prepare arrays\n\n# To calculate the number of datapoints in a grid area, the numpy.digitize() function is used. \n# This function needs an array with the (location) bins for counting the number of datapoints\n# per bin.\nbins_lon = np.zeros(n_lon+1) # bin\nbins_lat = np.zeros(n_lat+1) # bin\ndelta_lon = (BB[1]-BB[0]) / n_lon # bin longutide width\ndelta_lat = (BB[3]-BB[2]) / n_lat # bin latitude height\nbin_width_miles = distance(BB[2], BB[1], BB[2], BB[0]) / n_lon # bin width in miles\nbin_height_miles = distance(BB[3], BB[0], BB[2], BB[0]) / n_lat # bin height in miles\nfor i in range(n_lon+1):\n    bins_lon[i] = BB[0] + i * delta_lon\nfor j in range(n_lat+1):\n    bins_lat[j] = BB[2] + j * delta_lat\n    \n# Digitize per longitude, latitude dimension\ninds_pickup_lon = np.digitize(df_train.pickup_longitude, bins_lon)\ninds_pickup_lat = np.digitize(df_train.pickup_latitude, bins_lat)\ninds_dropoff_lon = np.digitize(df_train.dropoff_longitude, bins_lon)\ninds_dropoff_lat = np.digitize(df_train.dropoff_latitude, bins_lat)\n\n# Count per grid bin\n# note: as the density_pickup will be displayed as image, the first index is the y-direction, \n#       the second index is the x-direction. Also, the y-direction needs to be reversed for\n#       properly displaying (therefore the (n_lat-j) term)\ndxdy = bin_width_miles * bin_height_miles\nfor i in range(n_lon):\n    for j in range(n_lat):\n        density_pickup[j, i] = np.sum((inds_pickup_lon==i+1) & (inds_pickup_lat==(n_lat-j))) / dxdy\n        density_dropoff[j, i] = np.sum((inds_dropoff_lon==i+1) & (inds_dropoff_lat==(n_lat-j))) / dxdy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# Plot the density arrays\nfig, axs = plt.subplots(2, 1, figsize=(18, 24))\naxs[0].imshow(nyc_map, zorder=0, extent=BB);\nim = axs[0].imshow(np.log1p(density_pickup), zorder=1, extent=BB, alpha=0.6, cmap='plasma')\naxs[0].set_title('Pickup density [datapoints per sq mile]')\ncbar = fig.colorbar(im, ax=axs[0])\ncbar.set_label('log(1 + #datapoints per sq mile)', rotation=270)\n\naxs[1].imshow(nyc_map, zorder=0, extent=BB);\nim = axs[1].imshow(np.log1p(density_dropoff), zorder=1, extent=BB, alpha=0.6, cmap='plasma')\naxs[1].set_title('Dropoff density [datapoints per sq mile]')\ncbar = fig.colorbar(im, ax=axs[1])\ncbar.set_label('log(1 + #datapoints per sq mile)', rotation=270)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}