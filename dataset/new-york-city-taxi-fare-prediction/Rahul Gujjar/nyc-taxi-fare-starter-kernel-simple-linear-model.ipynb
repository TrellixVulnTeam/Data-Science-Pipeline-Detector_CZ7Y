{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This is a basic Starter Kernel for the New York City Taxi Fare Prediction Playground Competition \nHere we'll use a simple linear model based on the travel vector from the taxi's pickup location to dropoff location which predicts the `fare_amount` of each ride.\n\nThis kernel uses some `pandas` and mostly `numpy` for the critical work.  There are many higher-level libraries you could use instead, for example `sklearn` or `statsmodels`.  ","metadata":{"_uuid":"b4578d48b219735043a4d2102119fb307d2fc83f"}},{"cell_type":"code","source":"# Initial Python environment setup...\nimport numpy as np # linear algebra\nimport pandas as pd # CSV file I/O (e.g. pd.read_csv)\nimport os # reading the input files we have access to\n\nprint(os.listdir('../input'))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-20T16:09:11.80357Z","iopub.execute_input":"2021-06-20T16:09:11.803971Z","iopub.status.idle":"2021-06-20T16:09:11.814479Z","shell.execute_reply.started":"2021-06-20T16:09:11.803907Z","shell.execute_reply":"2021-06-20T16:09:11.813577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setup training data\nFirst let's read in our training data.  Kernels do not yet support enough memory to load the whole dataset at once, at least using `pd.read_csv`.  The entire dataset is about 55M rows, so we're skipping a good portion of the data, but it's certainly possible to build a model using all the data.","metadata":{"_uuid":"fb969a26e52931bcaced3cbb7a36d8d8b1b04556"}},{"cell_type":"code","source":"train_df =  pd.read_csv('../input/train.csv', nrows = 10_000_000)\ntrain_df.dtypes","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-06-20T16:09:11.815729Z","iopub.execute_input":"2021-06-20T16:09:11.816053Z","iopub.status.idle":"2021-06-20T16:09:40.487928Z","shell.execute_reply.started":"2021-06-20T16:09:11.815991Z","shell.execute_reply":"2021-06-20T16:09:40.487222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/test.csv')\ntest_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:09:40.491659Z","iopub.execute_input":"2021-06-20T16:09:40.49357Z","iopub.status.idle":"2021-06-20T16:09:40.536923Z","shell.execute_reply.started":"2021-06-20T16:09:40.493508Z","shell.execute_reply":"2021-06-20T16:09:40.536255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:09:40.5383Z","iopub.execute_input":"2021-06-20T16:09:40.538559Z","iopub.status.idle":"2021-06-20T16:09:40.544952Z","shell.execute_reply.started":"2021-06-20T16:09:40.538515Z","shell.execute_reply":"2021-06-20T16:09:40.544142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create two new features in our training set representing the \"travel vector\" between the start and end points of the taxi ride, in both longitude and latitude coordinates.  We'll take the absolute value since we're only interested in distance traveled. Use a helper function since we'll want to do the same thing for the test set later.","metadata":{"_uuid":"25df18156ed90f583efdbbc028c58a9d2bdfdc7b"}},{"cell_type":"code","source":"# Given a dataframe, add two new features 'abs_diff_longitude' and\n# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n# the pickup location to the dropoff location.\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(train_df)\nadd_travel_vector_features(test_df)","metadata":{"_uuid":"59f0595db44dd60044cfd0404824651a7c2bee87","execution":{"iopub.status.busy":"2021-06-20T16:09:40.546626Z","iopub.execute_input":"2021-06-20T16:09:40.547039Z","iopub.status.idle":"2021-06-20T16:09:40.928939Z","shell.execute_reply.started":"2021-06-20T16:09:40.546968Z","shell.execute_reply":"2021-06-20T16:09:40.928085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore and prune outliers\nFirst let's see if there are any `NaN`s in the dataset.","metadata":{"_uuid":"b1dbc7610bd467f1dfaf9042b5ec638eb2014aaf"}},{"cell_type":"code","source":"print(train_df.isnull().sum())","metadata":{"_uuid":"e808c7e75338b45ca30f9f261dfbc90845700624","execution":{"iopub.status.busy":"2021-06-20T16:09:40.930552Z","iopub.execute_input":"2021-06-20T16:09:40.930909Z","iopub.status.idle":"2021-06-20T16:09:44.951235Z","shell.execute_reply.started":"2021-06-20T16:09:40.930855Z","shell.execute_reply":"2021-06-20T16:09:44.949899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a small amount, so let's remove them from the dataset.","metadata":{"_uuid":"29bc86f2fa8baa37f0c4eb4300f77a8cb69f12aa"}},{"cell_type":"code","source":"print('Old size: %d' % len(train_df))\ntrain_df = train_df.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(train_df))","metadata":{"_uuid":"9d8f28e24f3d4ca55ad93692329680774c341376","execution":{"iopub.status.busy":"2021-06-20T16:09:44.952527Z","iopub.execute_input":"2021-06-20T16:09:44.952838Z","iopub.status.idle":"2021-06-20T16:09:48.874794Z","shell.execute_reply.started":"2021-06-20T16:09:44.952775Z","shell.execute_reply":"2021-06-20T16:09:48.874104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's quickly plot a subset of our travel vector features to see its distribution.","metadata":{"_uuid":"6a045ef14c636ec726a5e8c349ca7e5fbb3a87c1"}},{"cell_type":"code","source":"plot = train_df.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')","metadata":{"_uuid":"97d0aa1deab1c6cf0c97a4a3a12ba7007aada6c5","execution":{"iopub.status.busy":"2021-06-20T16:09:48.876129Z","iopub.execute_input":"2021-06-20T16:09:48.876508Z","iopub.status.idle":"2021-06-20T16:09:49.059497Z","shell.execute_reply.started":"2021-06-20T16:09:48.876425Z","shell.execute_reply":"2021-06-20T16:09:49.058621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We expect most of these values to be very small (likely between 0 and 1) since it should all be differences between GPS coordinates within one city.  For reference, one degree of latitude is about 69 miles.  However, we can see the dataset has extreme values which do not make sense.  Let's remove those values from our training set. Based on the scatterplot, it looks like we can safely exclude values above 5 (though remember the scatterplot is only showing the first 2000 rows...)","metadata":{"_uuid":"22277d77f75e3177a5acaec9b820e0de6e869663"}},{"cell_type":"code","source":"print('Old size: %d' % len(train_df))\ntrain_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\nprint('New size: %d' % len(train_df))","metadata":{"_uuid":"9703895e6c7e67b32c504f843b5ef19be2023964","execution":{"iopub.status.busy":"2021-06-20T16:09:49.060692Z","iopub.execute_input":"2021-06-20T16:09:49.061218Z","iopub.status.idle":"2021-06-20T16:09:49.86344Z","shell.execute_reply.started":"2021-06-20T16:09:49.061055Z","shell.execute_reply":"2021-06-20T16:09:49.862622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let's extract pickup time from date_time column of dataset**","metadata":{}},{"cell_type":"code","source":"ls1 = list(train_df['pickup_datetime'])\nfor i in range(len(ls1)):\n    ls1[i] = ls1[i][11:-7:]\ntrain_df['pickuptime'] = ls1\n\nls1 = list(test_df['pickup_datetime'])\nfor i in range(len(ls1)):\n    ls1[i] = ls1[i][11:-7:]\ntest_df['pickuptime'] = ls1","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:09:49.864674Z","iopub.execute_input":"2021-06-20T16:09:49.86497Z","iopub.status.idle":"2021-06-20T16:09:53.936555Z","shell.execute_reply.started":"2021-06-20T16:09:49.864922Z","shell.execute_reply":"2021-06-20T16:09:53.935907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:09:53.937865Z","iopub.execute_input":"2021-06-20T16:09:53.938161Z","iopub.status.idle":"2021-06-20T16:09:53.956992Z","shell.execute_reply.started":"2021-06-20T16:09:53.938116Z","shell.execute_reply":"2021-06-20T16:09:53.956198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let's slice date & time from pickup_datetime column and convert it into weekdays .Here 0 = monday and 6 = Sunday**** ","metadata":{}},{"cell_type":"code","source":"ls1 = list(train_df['pickup_datetime'])\nfor i in range(len(ls1)):\n    ls1[i] = ls1[i][:-4:]\n    ls1[i] = pd.Timestamp(ls1[i])\n    ls1[i] = ls1[i].weekday()\ntrain_df['weekday'] = ls1\n\n\nls1 = list(test_df['pickup_datetime'])\nfor i in range(len(ls1)):\n    ls1[i] = ls1[i][:-4:]\n    ls1[i] = pd.Timestamp(ls1[i])\n    ls1[i] = ls1[i].weekday()\ntest_df['weekday'] = ls1","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:09:53.95825Z","iopub.execute_input":"2021-06-20T16:09:53.958625Z","iopub.status.idle":"2021-06-20T16:10:27.280752Z","shell.execute_reply.started":"2021-06-20T16:09:53.958561Z","shell.execute_reply":"2021-06-20T16:10:27.280057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:27.281944Z","iopub.execute_input":"2021-06-20T16:10:27.282227Z","iopub.status.idle":"2021-06-20T16:10:27.301703Z","shell.execute_reply.started":"2021-06-20T16:10:27.282183Z","shell.execute_reply":"2021-06-20T16:10:27.300944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now we can drop the pickup_datetime column**","metadata":{}},{"cell_type":"code","source":"train_df.drop('pickup_datetime', inplace = True, axis = 1)\ntest_df.drop('pickup_datetime', inplace = True, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:27.303505Z","iopub.execute_input":"2021-06-20T16:10:27.304159Z","iopub.status.idle":"2021-06-20T16:10:29.735261Z","shell.execute_reply.started":"2021-06-20T16:10:27.304046Z","shell.execute_reply":"2021-06-20T16:10:29.734573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let's replace the weekday value of 0 , 1 , etc with monday , tuesday , etc**","metadata":{}},{"cell_type":"code","source":"train_df['weekday'].replace(to_replace = [i for i in range(0,7)], value = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], inplace=True)\ntest_df['weekday'].replace(to_replace = [i for i in range(0,7)], value = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:29.736615Z","iopub.execute_input":"2021-06-20T16:10:29.736931Z","iopub.status.idle":"2021-06-20T16:10:32.230633Z","shell.execute_reply.started":"2021-06-20T16:10:29.736873Z","shell.execute_reply":"2021-06-20T16:10:32.22997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:32.231849Z","iopub.execute_input":"2021-06-20T16:10:32.232137Z","iopub.status.idle":"2021-06-20T16:10:32.252024Z","shell.execute_reply.started":"2021-06-20T16:10:32.232093Z","shell.execute_reply":"2021-06-20T16:10:32.251275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let's apply One hot Encoding**","metadata":{"execution":{"iopub.status.busy":"2021-06-20T14:10:19.516075Z","iopub.execute_input":"2021-06-20T14:10:19.516378Z","iopub.status.idle":"2021-06-20T14:10:19.52212Z","shell.execute_reply.started":"2021-06-20T14:10:19.516327Z","shell.execute_reply":"2021-06-20T14:10:19.520835Z"}}},{"cell_type":"code","source":"train_one_hot = pd.get_dummies(train_df['weekday'])\ntest_one_hot = pd.get_dummies(test_df['weekday'])\ntrain_df = pd.concat([train_df, train_one_hot], axis = 1)\ntest_df = pd.concat([test_df, test_one_hot], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:32.253273Z","iopub.execute_input":"2021-06-20T16:10:32.25357Z","iopub.status.idle":"2021-06-20T16:10:34.900405Z","shell.execute_reply.started":"2021-06-20T16:10:32.253509Z","shell.execute_reply":"2021-06-20T16:10:34.899617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now as we already use OneHotEncoding in weekday column its time to drop the weekday column**","metadata":{}},{"cell_type":"code","source":"train_df.drop('weekday', inplace=True, axis=1)\ntest_df.drop('weekday', inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:34.901641Z","iopub.execute_input":"2021-06-20T16:10:34.902034Z","iopub.status.idle":"2021-06-20T16:10:37.832542Z","shell.execute_reply.started":"2021-06-20T16:10:34.901968Z","shell.execute_reply":"2021-06-20T16:10:37.831884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:37.833811Z","iopub.execute_input":"2021-06-20T16:10:37.834124Z","iopub.status.idle":"2021-06-20T16:10:37.857721Z","shell.execute_reply.started":"2021-06-20T16:10:37.834081Z","shell.execute_reply":"2021-06-20T16:10:37.856983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let's convert the pickuptime into integer**","metadata":{}},{"cell_type":"code","source":"ls1 = list(train_df['pickuptime'])\nfor i in range(len(ls1)):\n    z = ls1[i].split(':')\n    ls1[i] = int(z[0])*100+int(z[1])\ntrain_df['pickuptime'] = ls1\n    \n    \nls1 = list(test_df['pickuptime'])\nfor i in range(len(ls1)):\n    z = ls1[i].split(':')\n    ls1[i] = int(z[0])*100+int(z[1])\ntest_df['pickuptime'] = ls1","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:37.858863Z","iopub.execute_input":"2021-06-20T16:10:37.859289Z","iopub.status.idle":"2021-06-20T16:10:52.390448Z","shell.execute_reply.started":"2021-06-20T16:10:37.859151Z","shell.execute_reply":"2021-06-20T16:10:52.389804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:52.391576Z","iopub.execute_input":"2021-06-20T16:10:52.391927Z","iopub.status.idle":"2021-06-20T16:10:52.413095Z","shell.execute_reply.started":"2021-06-20T16:10:52.391865Z","shell.execute_reply":"2021-06-20T16:10:52.412372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The below mention code is what I searched in google , actually this code will conervt our given pickup/dropoff longitude/latitude in Kilometer.**","metadata":{}},{"cell_type":"code","source":"R = 6373.0\nlat1 = np.asarray(np.radians(train_df['pickup_latitude']))\nlon1 = np.asarray(np.radians(train_df['pickup_longitude']))\nlat2 = np.asarray(np.radians(train_df['dropoff_latitude']))\nlon2 = np.asarray(np.radians(train_df['dropoff_longitude']))\n\ndlon = lon2 - lon1\ndlat = lat2 - lat1\nls1 = []\n\na = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\nc = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\ndistance = R * c\n\ntrain_df['Distance'] = np.asarray(distance)*0.621\n\n\n\n\nlat1 = np.asarray(np.radians(test_df['pickup_latitude']))\nlon1 = np.asarray(np.radians(test_df['pickup_longitude']))\nlat2 = np.asarray(np.radians(test_df['dropoff_latitude']))\nlon2 = np.asarray(np.radians(test_df['dropoff_longitude']))\n\ndlon = lon2 - lon1\ndlat = lat2 - lat1\nls1 = []\n\na = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\nc = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\ndistance = R * c\n\ntest_df['Distance'] = np.asarray(distance)*0.621","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:52.414358Z","iopub.execute_input":"2021-06-20T16:10:52.414628Z","iopub.status.idle":"2021-06-20T16:10:54.129552Z","shell.execute_reply.started":"2021-06-20T16:10:52.414572Z","shell.execute_reply":"2021-06-20T16:10:54.128891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:54.130797Z","iopub.execute_input":"2021-06-20T16:10:54.131098Z","iopub.status.idle":"2021-06-20T16:10:54.153484Z","shell.execute_reply.started":"2021-06-20T16:10:54.131054Z","shell.execute_reply":"2021-06-20T16:10:54.152795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we all know that the airport cabs have higher price as compare to other cabs .So using same method as above I have added distance of pickup and drop from Airport by using airport longitude and latitude seperately for Airport of John F kennedy\nLatitude: 40.6413111 , Longitude: -73.7781391**","metadata":{}},{"cell_type":"code","source":"R = 6373.0\nlat1 =np.asarray(np.radians(train_df['pickup_latitude']))\nlon1 = np.asarray(np.radians(train_df['pickup_longitude']))\nlat2 = np.asarray(np.radians(train_df['dropoff_latitude']))\nlon2 = np.asarray(np.radians(train_df['dropoff_longitude']))\n\nlat3=np.zeros(len(train_df))+np.radians(40.6413111)\nlon3=np.zeros(len(train_df))+np.radians(-73.7781391)\ndlon_pickup = lon3 - lon1\ndlat_pickup = lat3 - lat1\nd_lon_dropoff=lon3 -lon2\nd_lat_dropoff=lat3-lat2\na1 = np.sin(dlat_pickup/2)**2 + np.cos(lat1) * np.cos(lat3) * np.sin(dlon_pickup/ 2)**2\nc1 = 2 * np.arctan2(np.sqrt(a1), np.sqrt(1 - a1))\ndistance1 = R * c1\ntrain_df['Pickup_Distance_airport']=np.asarray(distance1)*0.621\n\na2=np.sin(d_lat_dropoff/2)**2 + np.cos(lat2) * np.cos(lat3) * np.sin(d_lon_dropoff/ 2)**2\nc2 = 2 * np.arctan2(np.sqrt(a2), np.sqrt(1 - a2))\ndistance2 = R * c2\n\n    \ntrain_df['Dropoff_Distance_airport']=np.asarray(distance2)*0.621\n\n\n\nlat1 =np.asarray(np.radians(test_df['pickup_latitude']))\nlon1 = np.asarray(np.radians(test_df['pickup_longitude']))\nlat2 = np.asarray(np.radians(test_df['dropoff_latitude']))\nlon2 = np.asarray(np.radians(test_df['dropoff_longitude']))\n\nlat3=np.zeros(len(test_df))+np.radians(40.6413111)\nlon3=np.zeros(len(test_df))+np.radians(-73.7781391)\ndlon_pickup = lon3 - lon1\ndlat_pickup = lat3 - lat1\nd_lon_dropoff=lon3 -lon2\nd_lat_dropoff=lat3-lat2\na1 = np.sin(dlat_pickup/2)**2 + np.cos(lat1) * np.cos(lat3) * np.sin(dlon_pickup/ 2)**2\nc1 = 2 * np.arctan2(np.sqrt(a1), np.sqrt(1 - a1))\ndistance1 = R * c1\ntest_df['Pickup_Distance_airport']=np.asarray(distance1)*0.621\n\na2=np.sin(d_lat_dropoff/2)**2 + np.cos(lat2) * np.cos(lat3) * np.sin(d_lon_dropoff/ 2)**2\nc2 = 2 * np.arctan2(np.sqrt(a2), np.sqrt(1 - a2))\ndistance2 = R * c2\n\n    \ntest_df['Dropoff_Distance_airport']=np.asarray(distance2)*0.621\n","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:54.154542Z","iopub.execute_input":"2021-06-20T16:10:54.154914Z","iopub.status.idle":"2021-06-20T16:10:57.730535Z","shell.execute_reply.started":"2021-06-20T16:10:54.154779Z","shell.execute_reply":"2021-06-20T16:10:57.729895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now let's roundup the above derive values upto 2 decimal places**","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:57.731657Z","iopub.execute_input":"2021-06-20T16:10:57.731968Z","iopub.status.idle":"2021-06-20T16:10:57.759041Z","shell.execute_reply.started":"2021-06-20T16:10:57.731914Z","shell.execute_reply":"2021-06-20T16:10:57.758406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Distance'] = np.round(train_df['Distance'],2)\ntrain_df['Pickup_Distance_airport'] = np.round(train_df['Pickup_Distance_airport'],2)\ntrain_df['Dropoff_Distance_airport'] = np.round(train_df['Dropoff_Distance_airport'],2)\n\ntest_df['Distance'] = np.round(test_df['Distance'],2)\ntest_df['Pickup_Distance_airport'] = np.round(test_df['Pickup_Distance_airport'],2)\ntest_df['Dropoff_Distance_airport'] = np.round(test_df['Dropoff_Distance_airport'],2)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:57.760135Z","iopub.execute_input":"2021-06-20T16:10:57.76043Z","iopub.status.idle":"2021-06-20T16:10:58.23717Z","shell.execute_reply.started":"2021-06-20T16:10:57.760372Z","shell.execute_reply":"2021-06-20T16:10:58.236438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)\ntest_df.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:10:58.238458Z","iopub.execute_input":"2021-06-20T16:10:58.239032Z","iopub.status.idle":"2021-06-20T16:11:00.321516Z","shell.execute_reply.started":"2021-06-20T16:10:58.238745Z","shell.execute_reply":"2021-06-20T16:11:00.320901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE**\n* You may delete above mention column/ not , depends on the accuracy you are getting .\n*  Now I am going to subtract the each value of longitude and lattittude with their respective mean\n* Then , I will divide them with there variance","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:11:00.322629Z","iopub.execute_input":"2021-06-20T16:11:00.322943Z","iopub.status.idle":"2021-06-20T16:11:00.342424Z","shell.execute_reply.started":"2021-06-20T16:11:00.322883Z","shell.execute_reply":"2021-06-20T16:11:00.341708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['abs_diff_longitude']=np.abs(train_df['abs_diff_longitude']-np.mean(train_df['abs_diff_longitude']))\ntrain_df['abs_diff_longitude']=train_df['abs_diff_longitude']/np.var(train_df['abs_diff_longitude'])\n\n\ntrain_df['abs_diff_latitude']=np.abs(train_df['abs_diff_latitude']-np.mean(train_df['abs_diff_latitude']))\ntrain_df['abs_diff_latitude']=train_df['abs_diff_latitude']/np.var(train_df['abs_diff_latitude'])","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:11:00.343577Z","iopub.execute_input":"2021-06-20T16:11:00.343933Z","iopub.status.idle":"2021-06-20T16:11:00.983316Z","shell.execute_reply.started":"2021-06-20T16:11:00.343878Z","shell.execute_reply":"2021-06-20T16:11:00.982651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:11:00.984442Z","iopub.execute_input":"2021-06-20T16:11:00.984707Z","iopub.status.idle":"2021-06-20T16:11:01.004346Z","shell.execute_reply.started":"2021-06-20T16:11:00.984665Z","shell.execute_reply":"2021-06-20T16:11:01.003558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:11:01.005549Z","iopub.execute_input":"2021-06-20T16:11:01.00593Z","iopub.status.idle":"2021-06-20T16:11:01.012264Z","shell.execute_reply.started":"2021-06-20T16:11:01.005871Z","shell.execute_reply":"2021-06-20T16:11:01.011583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = train_df.drop(['key','fare_amount'],axis=1)\nY = train_df['fare_amount']\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.01, random_state=80)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:11:01.013461Z","iopub.execute_input":"2021-06-20T16:11:01.014027Z","iopub.status.idle":"2021-06-20T16:11:05.722835Z","shell.execute_reply.started":"2021-06-20T16:11:01.013977Z","shell.execute_reply":"2021-06-20T16:11:05.722012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression(normalize = True)\nlr.fit(X_train,Y_train)\nprint(lr.score(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:11:05.724181Z","iopub.execute_input":"2021-06-20T16:11:05.724621Z","iopub.status.idle":"2021-06-20T16:11:12.979042Z","shell.execute_reply.started":"2021-06-20T16:11:05.724572Z","shell.execute_reply":"2021-06-20T16:11:12.978373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As sample submission is of keys column first and then predict value with 2 decimal places**","metadata":{}},{"cell_type":"code","source":"pred = np.round(lr.predict(test_df.drop('key', axis=1)), 2)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:13:23.687721Z","iopub.execute_input":"2021-06-20T16:13:23.688034Z","iopub.status.idle":"2021-06-20T16:13:23.694562Z","shell.execute_reply.started":"2021-06-20T16:13:23.687975Z","shell.execute_reply":"2021-06-20T16:13:23.693703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(data = pred , columns = ['fare_amount'])\nsubmission['key'] = test_df['key']\nsubmission = submission[['key', 'fare_amount']]          #change order of column header ","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:18:03.137486Z","iopub.execute_input":"2021-06-20T16:18:03.137765Z","iopub.status.idle":"2021-06-20T16:18:03.146879Z","shell.execute_reply.started":"2021-06-20T16:18:03.137714Z","shell.execute_reply":"2021-06-20T16:18:03.146204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.set_index('key', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:18:28.256571Z","iopub.execute_input":"2021-06-20T16:18:28.256901Z","iopub.status.idle":"2021-06-20T16:18:28.266207Z","shell.execute_reply.started":"2021-06-20T16:18:28.256853Z","shell.execute_reply":"2021-06-20T16:18:28.26545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('Submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-20T16:19:16.039209Z","iopub.execute_input":"2021-06-20T16:19:16.039517Z","iopub.status.idle":"2021-06-20T16:19:16.07278Z","shell.execute_reply.started":"2021-06-20T16:19:16.039465Z","shell.execute_reply":"2021-06-20T16:19:16.072198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}