{"cells":[{"metadata":{"_uuid":"b4578d48b219735043a4d2102119fb307d2fc83f"},"cell_type":"markdown","source":"# This is a basic Starter Kernel for the New York City Taxi Fare Prediction Playground Competition \nHere we'll use a simple linear model based on the travel vector from the taxi's pickup location to dropoff location which predicts the `fare_amount` of each ride.\n\nThis kernel uses some `pandas` and mostly `numpy` for the critical work.  There are many higher-level libraries you could use instead, for example `sklearn` or `statsmodels`.  ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Initial Python environment setup...\nimport numpy as np # linear algebra\nimport pandas as pd # CSV file I/O (e.g. pd.read_csv)\nimport os # reading the input files we have access to\n\nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb969a26e52931bcaced3cbb7a36d8d8b1b04556"},"cell_type":"markdown","source":"### Setup training data\nFirst let's read in our training data.  Kernels do not yet support enough memory to load the whole dataset at once, at least using `pd.read_csv`.  The entire dataset is about 55M rows, so we're skipping a good portion of the data, but it's certainly possible to build a model using all the data.","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df =  pd.read_csv('../input/train.csv', nrows = 10_000_000)\ntrain_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25df18156ed90f583efdbbc028c58a9d2bdfdc7b"},"cell_type":"markdown","source":"Let's create two new features in our training set representing the \"travel vector\" between the start and end points of the taxi ride, in both longitude and latitude coordinates.  We'll take the absolute value since we're only interested in distance traveled. Use a helper function since we'll want to do the same thing for the test set later.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"59f0595db44dd60044cfd0404824651a7c2bee87"},"cell_type":"code","source":"# Given a dataframe, add two new features 'abs_diff_longitude' and\n# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n# the pickup location to the dropoff location.\n\n\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n    \n    \n\nadd_travel_vector_features(train_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_travel_vector_features(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1dbc7610bd467f1dfaf9042b5ec638eb2014aaf"},"cell_type":"markdown","source":"### Explore and prune outliers\nFirst let's see if there are any `NaN`s in the dataset.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"e808c7e75338b45ca30f9f261dfbc90845700624"},"cell_type":"code","source":"print(train_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29bc86f2fa8baa37f0c4eb4300f77a8cb69f12aa"},"cell_type":"markdown","source":"There are a small amount, so let's remove them from the dataset.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"9d8f28e24f3d4ca55ad93692329680774c341376"},"cell_type":"code","source":"print('Old size: %d' % len(train_df))\ntrain_df = train_df.dropna(how = 'any', axis = 0)\nprint('New size: %d' % len(train_df))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a045ef14c636ec726a5e8c349ca7e5fbb3a87c1"},"cell_type":"markdown","source":"Now let's quickly plot a subset of our travel vector features to see its distribution.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"97d0aa1deab1c6cf0c97a4a3a12ba7007aada6c5"},"cell_type":"code","source":"plot = train_df.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22277d77f75e3177a5acaec9b820e0de6e869663"},"cell_type":"markdown","source":"We expect most of these values to be very small (likely between 0 and 1) since it should all be differences between GPS coordinates within one city.  For reference, one degree of latitude is about 69 miles.  However, we can see the dataset has extreme values which do not make sense.  Let's remove those values from our training set. Based on the scatterplot, it looks like we can safely exclude values above 5 (though remember the scatterplot is only showing the first 2000 rows...)","execution_count":null},{"metadata":{"trusted":true,"_uuid":"9703895e6c7e67b32c504f843b5ef19be2023964"},"cell_type":"code","source":"print('Old size: %d' % len(train_df))\ntrain_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\nprint('New size: %d' % len(train_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['pickup_datetime'][0][11:19]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list1 = list(train_df['pickup_datetime'])               # Creating an extra col of pickup time,extracting from pickup_datetime\n\nfor i in range(len(list1)):\n    list1[i] = list1[i][11:19]\n\ntrain_df['pickup_time'] = list1\n\n\n\nlist2 = list(test_df['pickup_datetime'])\n\nfor i in range(len(list2)):\n    list2[i] = list2[i][11:19]\n\ntest_df['pickup_time'] = list2\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=pd.Timestamp(train_df['pickup_datetime'][0][:-4]).dayofweek\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating an extra col for day of the week\n\nlist1 = list(train_df['pickup_datetime'])\n\nfor i in range(len(list1)):\n    list1[i] = pd.Timestamp(list1[i][:-4]).dayofweek\n\ntrain_df['weekday'] = list1\n\n\nlist2 = list(test_df['pickup_datetime'])\n\nfor i in range(len(list2)):\n    list2[i] = pd.Timestamp(list2[i][:-4]).dayofweek\n\ntest_df['weekday'] = list2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping \"pickup_datetime\" col\n\ntrain_df.drop(\"pickup_datetime\",axis=1,inplace=True)\ntest_df.drop(\"pickup_datetime\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = test_df.columns.tolist()\ncol = col[:6] + col[8:] +col[6:8]\ncol\n\ntest_df = test_df[col]\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['weekday'].replace(to_replace=[i for i in range(0,7)],\n                           value=[\"monday\",\"tuesday\",'wednesday','thursday','friday','saturday','sunday'],\n                           inplace=True)\n\ntest_df['weekday'].replace(to_replace=[i for i in range(0,7)],\n                           value=[\"monday\",\"tuesday\",'wednesday','thursday','friday','saturday','sunday'],\n                           inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_one_hot = pd.get_dummies(train_df['weekday'])\ntrain_df = pd.concat([train_df,train_one_hot],axis=1)\n\ntest_one_hot = pd.get_dummies(test_df['weekday'])\ntest_df = pd.concat([test_df,test_one_hot],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train_df.drop(\"weekday\",axis=1,inplace=True)\ntest_df.drop(\"weekday\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = train_df['pickup_time'][0].split(\":\")\n(int(a[0])*100) + int(a[1]) + float(a[2])/100\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting pickup_time to float\n\nlist1 = list(train_df['pickup_time'])\nfor i in range(len(list1)):\n    a = list1[i].split(\":\")\n    list1[i] = (int(a[0])*100) + int(a[1]) + float(a[2])/100\n\ntrain_df['pickup_time'] = list1\n\nlist2 = list(test_df['pickup_time'])\nfor i in range(len(list2)):\n    a = list2[i].split(\":\")\n    list2[i] = (int(a[0])*100) + int(a[1]) + float(a[2])/100\n\ntest_df['pickup_time'] = list2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rearranging cols\ntest_df = test_df[train_df.drop('fare_amount',axis=1).columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating distance in kms\n\nR = 6373.0\nlat1 =np.asarray(np.radians(train_df['pickup_latitude']))\nlon1 = np.asarray(np.radians(train_df['pickup_longitude']))\nlat2 = np.asarray(np.radians(train_df['dropoff_latitude']))\nlon2 = np.asarray(np.radians(train_df['dropoff_longitude']))\n\ndlon = lon2 - lon1\ndlat = lat2 - lat1\nls1=[] \na = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/ 2)**2\nc = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\ndistance = R * c\n\n    \ntrain_df['Distance']=np.asarray(distance)*0.621\n\n\n\nlat1 =np.asarray(np.radians(test_df['pickup_latitude']))\nlon1 = np.asarray(np.radians(test_df['pickup_longitude']))\nlat2 = np.asarray(np.radians(test_df['dropoff_latitude']))\nlon2 = np.asarray(np.radians(test_df['dropoff_longitude']))\n\ndlon = lon2 - lon1\ndlat = lat2 - lat1\n \na = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/ 2)**2\nc = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\ndistance = R * c\ntest_df['Distance']=np.asarray(distance)*0.621","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Latitude: 40.6413111 Longitude: -73.7781391 Of John F Kennedy Airport\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculated distances in ref to the airport\n\nR = 6373.0\nlat1 =np.asarray(np.radians(train_df['pickup_latitude']))\nlon1 = np.asarray(np.radians(train_df['pickup_longitude']))\nlat2 = np.asarray(np.radians(train_df['dropoff_latitude']))\nlon2 = np.asarray(np.radians(train_df['dropoff_longitude']))\n\nlat3=np.zeros(len(train_df))+np.radians(40.6413111)\nlon3=np.zeros(len(train_df))+np.radians(-73.7781391)\ndlon_pickup = lon3 - lon1\ndlat_pickup = lat3 - lat1\nd_lon_dropoff=lon3 -lon2\nd_lat_dropoff=lat3-lat2\na1 = np.sin(dlat_pickup/2)**2 + np.cos(lat1) * np.cos(lat3) * np.sin(dlon_pickup/ 2)**2\nc1 = 2 * np.arctan2(np.sqrt(a1), np.sqrt(1 - a1))\ndistance1 = R * c1\ntrain_df['Pickup_Distance_airport']=np.asarray(distance1)*0.621\n\na2=np.sin(d_lat_dropoff/2)**2 + np.cos(lat2) * np.cos(lat3) * np.sin(d_lon_dropoff/ 2)**2\nc2 = 2 * np.arctan2(np.sqrt(a2), np.sqrt(1 - a2))\ndistance2 = R * c2\n\n    \ntrain_df['Dropoff_Distance_airport']=np.asarray(distance2)*0.621\n\n\n\nlat1 =np.asarray(np.radians(test_df['pickup_latitude']))\nlon1 = np.asarray(np.radians(test_df['pickup_longitude']))\nlat2 = np.asarray(np.radians(test_df['dropoff_latitude']))\nlon2 = np.asarray(np.radians(test_df['dropoff_longitude']))\n\nlat3=np.zeros(len(test_df))+np.radians(40.6413111)\nlon3=np.zeros(len(test_df))+np.radians(-73.7781391)\ndlon_pickup = lon3 - lon1\ndlat_pickup = lat3 - lat1\nd_lon_dropoff=lon3 -lon2\nd_lat_dropoff=lat3-lat2\na1 = np.sin(dlat_pickup/2)**2 + np.cos(lat1) * np.cos(lat3) * np.sin(dlon_pickup/ 2)**2\nc1 = 2 * np.arctan2(np.sqrt(a1), np.sqrt(1 - a1))\ndistance1 = R * c1\ntest_df['Pickup_Distance_airport']=np.asarray(distance1)*0.621\n\na2=np.sin(d_lat_dropoff/2)**2 + np.cos(lat2) * np.cos(lat3) * np.sin(d_lon_dropoff/ 2)**2\nc2 = 2 * np.arctan2(np.sqrt(a2), np.sqrt(1 - a2))\ndistance2 = R * c2\n\ntest_df['Dropoff_Distance_airport']=np.asarray(distance2)*0.621\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rounding off data to two decimal places\n\ntrain_df['Distance']=np.round(train_df['Distance'],2)\ntrain_df['Pickup_Distance_airport']=np.round(train_df['Pickup_Distance_airport'],2)\ntrain_df['Dropoff_Distance_airport']=np.round(train_df['Dropoff_Distance_airport'],2)\n\ntest_df['Distance']=np.round(test_df['Distance'],2)\ntest_df['Pickup_Distance_airport']=np.round(test_df['Pickup_Distance_airport'],2)\ntest_df['Dropoff_Distance_airport']=np.round(test_df['Dropoff_Distance_airport'],2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)\ntest_df.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape , test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX=train_df.drop(['key','fare_amount'],axis=1)\ny=train_df['fare_amount']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.01,random_state=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nreg=LinearRegression()\nreg.fit(X_train,y_train)\nreg.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = reg.predict(test_df.drop(\"key\",axis=1))\npredictions = np.round(predictions,2)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission=pd.DataFrame(data=predictions,columns=['fare_amount'])\n\nSubmission['key']=test_df['key']\n\nSubmission=Submission[['key','fare_amount']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.set_index('key',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.reset_index().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.to_csv('Submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}