{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# What did I learnt from this notebook\n1. Always create a outline of the project as it `give us direction`\n2. How to handle **Large dataset**\n\n# What is the main objective of this Notebook\n1. Perform EDA and create a Baseline Model on sample data (20% of training set)\n2. Reduce the size of training set and than train the a model better than this Notebook\n    a. In next notebook use stacking and blending to achieve more respectable result","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.max_columns', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-02T10:59:02.244058Z","iopub.execute_input":"2021-11-02T10:59:02.244532Z","iopub.status.idle":"2021-11-02T10:59:03.196871Z","shell.execute_reply.started":"2021-11-02T10:59:02.24445Z","shell.execute_reply":"2021-11-02T10:59:03.195917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## About the data:\nData fields\nID\n* **key** - Unique string identifying each row in both the training and test sets. Comprised of pickup_datetime plus a unique integer, but this doesn't matter, it should just be used as a unique ID field. Required in your submission CSV. Not necessarily needed in the training set, but could be useful to simulate a 'submission file' while doing cross-validation within the training set.\n### Features**\n* **pickup_datetime** - timestamp value indicating when the taxi ride started.\n* **pickup_longitude** - float for longitude coordinate of where the taxi ride started.\n* **pickup_latitude** - float for latitude coordinate of where the taxi ride started.\n* **dropoff_longitude** - float for longitude coordinate of where the taxi ride ended.\n* **dropoff_latitude** - float for latitude coordinate of where the taxi ride ended.\n* **passenger_count** - integer indicating the number of passengers in the taxi ride.\n### Target\nfare_amount - float dollar amount of the cost of the taxi ride. This value is only in the training set; this is what you are predicting in the test set and it is required in your submission CSV.","metadata":{}},{"cell_type":"code","source":"#%%time\n#sub_df= pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/sample_submission.csv')\n#test_df= pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/test.csv')\n#df= pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv')\n#df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:03.19884Z","iopub.execute_input":"2021-11-02T10:59:03.199666Z","iopub.status.idle":"2021-11-02T10:59:03.204152Z","shell.execute_reply.started":"2021-11-02T10:59:03.199621Z","shell.execute_reply":"2021-11-02T10:59:03.203222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"training data is 5.5GB so it fails to load \nso lets analyse data with shell commands","metadata":{}},{"cell_type":"markdown","source":"## Basic Terminal Navigation Commands: \n\n**ls** : To get the list of all the files or folders.  \n**ls -l**: Optional flags are added to ls to modify default behavior, listing contents in extended form -l is used for “long” output  \n**ls -a**: Lists of all files including the hidden files, add -a  flag   \n**cd**: Used to change the directory.  \n**du**: Show disk usage.  \n**pwd**: Show the present working directory.  \n**man**: Used to show the manual of any command present in Linux.  \n**rmdir**: It is used to delete a directory if it is empty.  \n**ln file1 file2**: Creates a physical link.  \n**ln -s file1 file2**: Creates a symbolic link.  \n**locate**: It is used to locate a file in Linux System  \n**echo**:  This command helps us move some data, usually text into a file.      \n**df**: It is used to see the available disk space in each of the partitions in your system.      \n**tar**: Used to work with tarballs (or files compressed in a tarball archive)       \n\n### [For more details...](https://www.geeksforgeeks.org/basic-shell-commands-in-linux/)","metadata":{}},{"cell_type":"code","source":"data_dir = '../input/new-york-city-taxi-fare-prediction'\n!ls -lh {data_dir}","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:03.206029Z","iopub.execute_input":"2021-11-02T10:59:03.206654Z","iopub.status.idle":"2021-11-02T10:59:03.98852Z","shell.execute_reply.started":"2021-11-02T10:59:03.206612Z","shell.execute_reply":"2021-11-02T10:59:03.987768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!wc -l {data_dir}/train.csv","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:03.990813Z","iopub.execute_input":"2021-11-02T10:59:03.991431Z","iopub.status.idle":"2021-11-02T10:59:50.772291Z","shell.execute_reply.started":"2021-11-02T10:59:03.991385Z","shell.execute_reply":"2021-11-02T10:59:50.771265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!wc -l {data_dir}/test.csv","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:50.775517Z","iopub.execute_input":"2021-11-02T10:59:50.775846Z","iopub.status.idle":"2021-11-02T10:59:51.550483Z","shell.execute_reply.started":"2021-11-02T10:59:50.775803Z","shell.execute_reply":"2021-11-02T10:59:51.549436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!wc -l {data_dir}/sample_submission.csv","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:51.552531Z","iopub.execute_input":"2021-11-02T10:59:51.552887Z","iopub.status.idle":"2021-11-02T10:59:52.322621Z","shell.execute_reply.started":"2021-11-02T10:59:51.552842Z","shell.execute_reply":"2021-11-02T10:59:52.320852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test and Submission have a difference of 1 row... we will look into this but this could me mostly an empty line","metadata":{}},{"cell_type":"markdown","source":"### Lets look at the 1st few lines of each dataset","metadata":{}},{"cell_type":"code","source":"# Training set\n!head {data_dir}/train.csv","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:52.325013Z","iopub.execute_input":"2021-11-02T10:59:52.325371Z","iopub.status.idle":"2021-11-02T10:59:53.07603Z","shell.execute_reply.started":"2021-11-02T10:59:52.325323Z","shell.execute_reply":"2021-11-02T10:59:53.075127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test set\n!head {data_dir}/test.csv","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:53.078378Z","iopub.execute_input":"2021-11-02T10:59:53.078728Z","iopub.status.idle":"2021-11-02T10:59:53.827127Z","shell.execute_reply.started":"2021-11-02T10:59:53.078667Z","shell.execute_reply":"2021-11-02T10:59:53.826102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Sample sub\n!head {data_dir}/sample_submission.csv","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:53.82899Z","iopub.execute_input":"2021-11-02T10:59:53.829253Z","iopub.status.idle":"2021-11-02T10:59:54.575909Z","shell.execute_reply.started":"2021-11-02T10:59:53.829217Z","shell.execute_reply":"2021-11-02T10:59:54.57489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations:\n\n- This is a supervised learning regression problem\n- Training data is 5.5 GB in size\n- Training data has 55 million rows (`55,423,856 rows`) \n- Test set is much smaller (`9,914 rows`)\n- The training set has 8 columns:\n    - `key` (a unique identifier)\n    - `fare_amount` (target column)\n    - `pickup_datetime`\n    - `pickup_longitude`\n    - `pickup_latitude`\n    - `dropoff_longitude`\n    - `dropoff_latitude`\n    - `passenger_count`\n- The test set has all columns except the target column `fare_amount`.\n- The submission file should contain the `key` and `fare_amount` for each test sample.\n- Evaluation is donw with **RMSE**\n","metadata":{}},{"cell_type":"markdown","source":"## Loading data\nSince we can't load training data full \nlets load it in pieces","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(data_dir+'/test.csv',parse_dates=['pickup_datetime'])\ndf_test","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:54.577617Z","iopub.execute_input":"2021-11-02T10:59:54.577894Z","iopub.status.idle":"2021-11-02T10:59:55.057716Z","shell.execute_reply.started":"2021-11-02T10:59:54.577862Z","shell.execute_reply":"2021-11-02T10:59:55.057093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:55.058846Z","iopub.execute_input":"2021-11-02T10:59:55.059576Z","iopub.status.idle":"2021-11-02T10:59:55.080577Z","shell.execute_reply.started":"2021-11-02T10:59:55.059541Z","shell.execute_reply":"2021-11-02T10:59:55.079719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Why key is an object data type to me this these number in the dataframe?`","metadata":{}},{"cell_type":"code","source":"df_test.key.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:55.081805Z","iopub.execute_input":"2021-11-02T10:59:55.082113Z","iopub.status.idle":"2021-11-02T10:59:55.091871Z","shell.execute_reply.started":"2021-11-02T10:59:55.082081Z","shell.execute_reply":"2021-11-02T10:59:55.091125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now lets load training data\nI will avoid key column","metadata":{}},{"cell_type":"code","source":"import random\n## to select random index no from training dataset","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:55.093074Z","iopub.execute_input":"2021-11-02T10:59:55.093808Z","iopub.status.idle":"2021-11-02T10:59:55.098903Z","shell.execute_reply.started":"2021-11-02T10:59:55.093778Z","shell.execute_reply":"2021-11-02T10:59:55.098285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change this\nsample_frac = 0.20\n# we are loading 20% data : Wall time: 28min 35s ; memory usage: 327.6 MB\n# 10% data loading : Wall time: 14min 38s","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:55.102573Z","iopub.execute_input":"2021-11-02T10:59:55.103703Z","iopub.status.idle":"2021-11-02T10:59:55.110452Z","shell.execute_reply.started":"2021-11-02T10:59:55.103649Z","shell.execute_reply":"2021-11-02T10:59:55.109886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* numpy.finfo(numpy.float16).precision **> 3**\n* numpy.finfo(numpy.float32).precision **> 6** (about 8 digit)\n* numpy.finfo(numpy.float64).precision **> 15**\n* numpy.finfo(numpy.float128).precision **> 18**\n* A UINT8 is an **8-bit `unsigned integer` (range: `0 through 255` decimal)** > Generally Taxi can accommodate single digit passangers so 255 is still over kill.","metadata":{}},{"cell_type":"code","source":"%%time\nselected_cols = 'fare_amount,pickup_datetime,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count'.split(',')\ndtypes = {\n    'fare_amount': 'float16',\n    'pickup_longitude': 'float32',\n    'pickup_latitude': 'float32',\n    'dropoff_longitude': 'float32',\n    'passenger_count': 'uint8'\n}\n## this function will return True for (1 -sample_frac) thus these rows will be skipped\ndef skip_row(row_idx):\n    if row_idx == 0:\n        return False\n    return random.random() > sample_frac  ## \n\nrandom.seed(7)\ndf = pd.read_csv(data_dir+\"/train.csv\", \n                 usecols=selected_cols, \n                 dtype=dtypes, \n                 parse_dates=['pickup_datetime'], \n                 skiprows=skip_row)\ndf_original =df.copy()\ndf","metadata":{"execution":{"iopub.status.busy":"2021-11-02T10:59:55.113245Z","iopub.execute_input":"2021-11-02T10:59:55.113951Z","iopub.status.idle":"2021-11-02T11:28:04.726126Z","shell.execute_reply.started":"2021-11-02T10:59:55.113916Z","shell.execute_reply":"2021-11-02T11:28:04.725101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Exporting 20% data to csv for further prediction\ndf.to_csv('20% ofnew-york-city-taxi-fare-predicition.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:28:04.727565Z","iopub.execute_input":"2021-11-02T11:28:04.727945Z","iopub.status.idle":"2021-11-02T11:31:13.801788Z","shell.execute_reply.started":"2021-11-02T11:28:04.7279Z","shell.execute_reply":"2021-11-02T11:31:13.800777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:13.803374Z","iopub.execute_input":"2021-11-02T11:31:13.804317Z","iopub.status.idle":"2021-11-02T11:31:13.82214Z","shell.execute_reply.started":"2021-11-02T11:31:13.804266Z","shell.execute_reply":"2021-11-02T11:31:13.821084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Explore the Dataset\n\n- Basic info about training set\n- Basic info about test set\n- Exploratory data analysis & visualization\n- Ask & answer questions","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:13.823741Z","iopub.execute_input":"2021-11-02T11:31:13.824189Z","iopub.status.idle":"2021-11-02T11:31:14.038758Z","shell.execute_reply.started":"2021-11-02T11:31:13.824143Z","shell.execute_reply":"2021-11-02T11:31:14.037829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset has no missing values","metadata":{}},{"cell_type":"code","source":"%%time\n#### Checking for duplicates\ndf.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:14.040265Z","iopub.execute_input":"2021-11-02T11:31:14.040808Z","iopub.status.idle":"2021-11-02T11:31:26.890319Z","shell.execute_reply.started":"2021-11-02T11:31:14.040763Z","shell.execute_reply":"2021-11-02T11:31:26.88942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# There are 42 duplicates, Lets remove them\ndf.drop_duplicates()  ## dropes duplicates\ndf.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:26.89165Z","iopub.execute_input":"2021-11-02T11:31:26.891905Z","iopub.status.idle":"2021-11-02T11:31:51.670062Z","shell.execute_reply.started":"2021-11-02T11:31:26.891877Z","shell.execute_reply":"2021-11-02T11:31:51.669093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:51.671403Z","iopub.execute_input":"2021-11-02T11:31:51.67162Z","iopub.status.idle":"2021-11-02T11:31:55.111564Z","shell.execute_reply.started":"2021-11-02T11:31:51.671593Z","shell.execute_reply":"2021-11-02T11:31:55.110724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Why fare has min value as -ve and max value = infinite","metadata":{}},{"cell_type":"markdown","source":"# 3. Feature Engineering\nAfter some exploraation I realised I sholud perform **Feature Engineering** to understand the data properly  \nas I saw fare to be -ve in around 463 rows and fare value more than 500 few time and also infinite twice or trice\n1. add a feature for distance between pickup place and drop place\n2. Need to perform feature extraction for time","metadata":{}},{"cell_type":"markdown","source":"### Add Distance Between Pickup and Drop\n\nWe can use the haversine distance: \n- https://en.wikipedia.org/wiki/Haversine_formula\n- https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef haversine_np(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points\n    on the earth (specified in decimal degrees)\n\n    All args must be of equal length.    \n\n    \"\"\"\n    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n\n    c = 2 * np.arcsin(np.sqrt(a))\n    km = 6367 * c\n    return km","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:55.114626Z","iopub.execute_input":"2021-11-02T11:31:55.114854Z","iopub.status.idle":"2021-11-02T11:31:55.123855Z","shell.execute_reply.started":"2021-11-02T11:31:55.114828Z","shell.execute_reply":"2021-11-02T11:31:55.122911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_trip_distance(df):\n    df['trip_distance'] = haversine_np(df['pickup_longitude'], df['pickup_latitude'], df['dropoff_longitude'], df['dropoff_latitude'])","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:55.125252Z","iopub.execute_input":"2021-11-02T11:31:55.125471Z","iopub.status.idle":"2021-11-02T11:31:55.134346Z","shell.execute_reply.started":"2021-11-02T11:31:55.125446Z","shell.execute_reply":"2021-11-02T11:31:55.133623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nadd_trip_distance(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:55.135712Z","iopub.execute_input":"2021-11-02T11:31:55.135913Z","iopub.status.idle":"2021-11-02T11:31:56.547829Z","shell.execute_reply.started":"2021-11-02T11:31:55.135891Z","shell.execute_reply":"2021-11-02T11:31:56.547211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract Parts of Date\n\n- Year\n- Month\n- Day\n- Weekday\n- Hour\n","metadata":{}},{"cell_type":"code","source":"def add_dateparts(df, col):\n    df['year'] = df[col].dt.year\n    df['month'] = df[col].dt.month\n    df['day'] = df[col].dt.day\n    df['weekday'] = df[col].dt.weekday\n    df[col + '_hour'] = df[col].dt.hour","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:56.548773Z","iopub.execute_input":"2021-11-02T11:31:56.549109Z","iopub.status.idle":"2021-11-02T11:31:56.554952Z","shell.execute_reply.started":"2021-11-02T11:31:56.549065Z","shell.execute_reply":"2021-11-02T11:31:56.553732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nadd_dateparts(df, 'pickup_datetime')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:31:56.556039Z","iopub.execute_input":"2021-11-02T11:31:56.556236Z","iopub.status.idle":"2021-11-02T11:32:03.163669Z","shell.execute_reply.started":"2021-11-02T11:31:56.556212Z","shell.execute_reply":"2021-11-02T11:32:03.163047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Add Distance From Popular Landmarks\n\n- JFK Airport\n- LGA Airport\n- EWR Airport\n- Times Square\n- Met Meuseum\n- World Trade Center\n\nWe'll add the distance from drop location. ","metadata":{}},{"cell_type":"code","source":"jfk_lonlat = -73.7781, 40.6413\nlga_lonlat = -73.8740, 40.7769\newr_lonlat = -74.1745, 40.6895\nmet_lonlat = -73.9632, 40.7794\nwtc_lonlat = -74.0099, 40.7126","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:03.165135Z","iopub.execute_input":"2021-11-02T11:32:03.166034Z","iopub.status.idle":"2021-11-02T11:32:03.172462Z","shell.execute_reply.started":"2021-11-02T11:32:03.165989Z","shell.execute_reply":"2021-11-02T11:32:03.171289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_landmark_dropoff_distance(df, landmark_name, landmark_lonlat):\n    lon, lat = landmark_lonlat\n    df[landmark_name + '_drop_distance'] = haversine_np(lon, lat, df['dropoff_longitude'], df['dropoff_latitude'])","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:03.174026Z","iopub.execute_input":"2021-11-02T11:32:03.174285Z","iopub.status.idle":"2021-11-02T11:32:03.18473Z","shell.execute_reply.started":"2021-11-02T11:32:03.174256Z","shell.execute_reply":"2021-11-02T11:32:03.184058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor name, lonlat in [('jfk', jfk_lonlat), ('lga', lga_lonlat), ('ewr', ewr_lonlat), ('met', met_lonlat), ('wtc', wtc_lonlat)]:\n    add_landmark_dropoff_distance(df, name, lonlat)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:03.187731Z","iopub.execute_input":"2021-11-02T11:32:03.188666Z","iopub.status.idle":"2021-11-02T11:32:07.973325Z","shell.execute_reply.started":"2021-11-02T11:32:03.188619Z","shell.execute_reply":"2021-11-02T11:32:07.972406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.1 Removing Outliers\nWe'll use the following ranges:\n\n- `fare_amount`: 1 to 500\n- `longitudes`: -75 to -72\n- `latitudes`: 40 to 42\n- `passenger_count`: 1 to 6","metadata":{}},{"cell_type":"code","source":"def remove_outliers(df):\n    return df[(df['fare_amount'] >= 1.) & \n              (df['fare_amount'] <= 500.) &\n              (df['pickup_longitude'] >= -75) & \n              (df['pickup_longitude'] <= -72) & \n              (df['dropoff_longitude'] >= -75) & \n              (df['dropoff_longitude'] <= -72) & \n              (df['pickup_latitude'] >= 40) & \n              (df['pickup_latitude'] <= 42) & \n              (df['dropoff_latitude'] >=40) & \n              (df['dropoff_latitude'] <= 42) & \n              (df['passenger_count'] >= 1) & \n              (df['passenger_count'] <= 6)]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:07.974743Z","iopub.execute_input":"2021-11-02T11:32:07.975056Z","iopub.status.idle":"2021-11-02T11:32:07.983029Z","shell.execute_reply.started":"2021-11-02T11:32:07.975013Z","shell.execute_reply":"2021-11-02T11:32:07.981945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf = remove_outliers(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:07.984416Z","iopub.execute_input":"2021-11-02T11:32:07.984649Z","iopub.status.idle":"2021-11-02T11:32:10.51512Z","shell.execute_reply.started":"2021-11-02T11:32:07.984623Z","shell.execute_reply":"2021-11-02T11:32:10.514187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. **EDA** cont...","metadata":{}},{"cell_type":"markdown","source":"I wanted to see relationship between -ve fare value with distance thus decided to perform feature engineering before hand ","metadata":{}},{"cell_type":"markdown","source":"### Why fare has min value as -ve and max value = infinite","metadata":{}},{"cell_type":"code","source":"## Checking for fare value to be -ve\ndf[df['fare_amount']<0]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:10.516826Z","iopub.execute_input":"2021-11-02T11:32:10.51715Z","iopub.status.idle":"2021-11-02T11:32:10.618341Z","shell.execute_reply.started":"2021-11-02T11:32:10.517108Z","shell.execute_reply":"2021-11-02T11:32:10.617519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 463 incidents with fare less than 0, I assume they might have used some **coupons** or might carry from past when they paid in surplus... \nBut since we don't have customer i.d. or cab id we can't infer these","metadata":{}},{"cell_type":"code","source":"## Checking for fare value to be greater than 500\ndf[df['fare_amount']>500]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:10.61957Z","iopub.execute_input":"2021-11-02T11:32:10.619875Z","iopub.status.idle":"2021-11-02T11:32:10.662387Z","shell.execute_reply.started":"2021-11-02T11:32:10.619846Z","shell.execute_reply":"2021-11-02T11:32:10.66162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"why there are log and lat with 0,0","metadata":{}},{"cell_type":"code","source":"df[df['pickup_longitude']==0]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:10.6635Z","iopub.execute_input":"2021-11-02T11:32:10.663727Z","iopub.status.idle":"2021-11-02T11:32:10.687628Z","shell.execute_reply.started":"2021-11-02T11:32:10.663701Z","shell.execute_reply":"2021-11-02T11:32:10.686736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 210749 rows with log lat = 0,0","metadata":{}},{"cell_type":"code","source":"## Lets check for distance = 0\ndf[df['trip_distance']==0]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:10.688835Z","iopub.execute_input":"2021-11-02T11:32:10.689052Z","iopub.status.idle":"2021-11-02T11:32:10.712243Z","shell.execute_reply.started":"2021-11-02T11:32:10.689027Z","shell.execute_reply":"2021-11-02T11:32:10.711691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 210749 rows with log lat = 0,0\nand 200326 rows with 0 trip distance ","metadata":{}},{"cell_type":"code","source":"df[df['passenger_count']>6]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:10.71327Z","iopub.execute_input":"2021-11-02T11:32:10.713802Z","iopub.status.idle":"2021-11-02T11:32:10.729633Z","shell.execute_reply.started":"2021-11-02T11:32:10.713767Z","shell.execute_reply":"2021-11-02T11:32:10.728761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.pickup_datetime.min(), df.pickup_datetime.max()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:10.731665Z","iopub.execute_input":"2021-11-02T11:32:10.732929Z","iopub.status.idle":"2021-11-02T11:32:10.811207Z","shell.execute_reply.started":"2021-11-02T11:32:10.73289Z","shell.execute_reply":"2021-11-02T11:32:10.810269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf = df.drop('pickup_datetime', axis=1)\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:10.812613Z","iopub.execute_input":"2021-11-02T11:32:10.812971Z","iopub.status.idle":"2021-11-02T11:32:11.757966Z","shell.execute_reply.started":"2021-11-02T11:32:10.812912Z","shell.execute_reply":"2021-11-02T11:32:11.756967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist(figsize=(22,21), bins=20);","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:11.759479Z","iopub.execute_input":"2021-11-02T11:32:11.760172Z","iopub.status.idle":"2021-11-02T11:32:20.916368Z","shell.execute_reply.started":"2021-11-02T11:32:11.760128Z","shell.execute_reply":"2021-11-02T11:32:20.915388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ask & answer questions about the dataset: \n\n1. What is the busiest day of the week?\n2. What is the busiest time of the day?\n3. In which month are fares the highest?\n4. Which pickup locations have the highest fares?\n5. Which drop locations have the highest fares?\n6. What is the average ride distance?\n\nEDA + asking questions will help you develop a deeper understand of the data and give you ideas for feature engineering.","metadata":{}},{"cell_type":"code","source":"# 1. What is the busiest day of the week?\ndf.weekday.mode()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:20.918152Z","iopub.execute_input":"2021-11-02T11:32:20.918596Z","iopub.status.idle":"2021-11-02T11:32:20.981544Z","shell.execute_reply.started":"2021-11-02T11:32:20.918563Z","shell.execute_reply":"2021-11-02T11:32:20.980187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. What is the busiest time of the day?\ndf.pickup_datetime_hour.mode()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:20.989313Z","iopub.execute_input":"2021-11-02T11:32:20.989963Z","iopub.status.idle":"2021-11-02T11:32:21.055839Z","shell.execute_reply.started":"2021-11-02T11:32:20.989928Z","shell.execute_reply":"2021-11-02T11:32:21.054954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. In which month are fares the highest? >>> winters have high fare and Jan has highest fare\ndf_fare= df.sort_values(ascending=False, by= 'fare_amount').head(50)\ndf_fare.month.hist();","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:21.057159Z","iopub.execute_input":"2021-11-02T11:32:21.057561Z","iopub.status.idle":"2021-11-02T11:32:26.318365Z","shell.execute_reply.started":"2021-11-02T11:32:21.057517Z","shell.execute_reply":"2021-11-02T11:32:26.317216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. Which pickup locations have the highest fares?\nsns.scatterplot(x='pickup_longitude', y= 'pickup_latitude', hue='fare_amount',data=df_fare);","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:26.321595Z","iopub.execute_input":"2021-11-02T11:32:26.321928Z","iopub.status.idle":"2021-11-02T11:32:26.797215Z","shell.execute_reply.started":"2021-11-02T11:32:26.321894Z","shell.execute_reply":"2021-11-02T11:32:26.796396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Which drop locations have the highest fares?\nsns.scatterplot(x='dropoff_longitude', y= 'dropoff_latitude',hue='fare_amount',data=df_fare);","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:26.798565Z","iopub.execute_input":"2021-11-02T11:32:26.799292Z","iopub.status.idle":"2021-11-02T11:32:27.236447Z","shell.execute_reply.started":"2021-11-02T11:32:26.799244Z","shell.execute_reply":"2021-11-02T11:32:27.235603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. What is the average ride distance?\ndf.trip_distance.mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:27.237894Z","iopub.execute_input":"2021-11-02T11:32:27.238131Z","iopub.status.idle":"2021-11-02T11:32:27.261561Z","shell.execute_reply.started":"2021-11-02T11:32:27.238102Z","shell.execute_reply":"2021-11-02T11:32:27.260942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Plotting log , lat for pickup\nsns.scatterplot(x='pickup_longitude', y= 'pickup_latitude', data=df )","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:32:27.263028Z","iopub.execute_input":"2021-11-02T11:32:27.263254Z","iopub.status.idle":"2021-11-02T11:33:05.671566Z","shell.execute_reply.started":"2021-11-02T11:32:27.263229Z","shell.execute_reply":"2021-11-02T11:33:05.670596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Plotting log , lat for pickup\n#sns.scatterplot(x='dropoff_longitude', y= 'dropoff_latitude', data=df , hue='fare_amount')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:05.673283Z","iopub.execute_input":"2021-11-02T11:33:05.674423Z","iopub.status.idle":"2021-11-02T11:33:05.679024Z","shell.execute_reply.started":"2021-11-02T11:33:05.674369Z","shell.execute_reply":"2021-11-02T11:33:05.678089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Just wanna check if this pattern is present in test dataset.","metadata":{}},{"cell_type":"code","source":"df_test.hist(figsize=(8,7), bins=20);","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:05.680849Z","iopub.execute_input":"2021-11-02T11:33:05.682006Z","iopub.status.idle":"2021-11-02T11:33:07.140275Z","shell.execute_reply.started":"2021-11-02T11:33:05.681948Z","shell.execute_reply":"2021-11-02T11:33:07.138763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[df_test['pickup_longitude']==0]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:07.142241Z","iopub.execute_input":"2021-11-02T11:33:07.142575Z","iopub.status.idle":"2021-11-02T11:33:07.157531Z","shell.execute_reply.started":"2021-11-02T11:33:07.14254Z","shell.execute_reply":"2021-11-02T11:33:07.155937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[df_test['passenger_count']>6]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:07.159158Z","iopub.execute_input":"2021-11-02T11:33:07.159475Z","iopub.status.idle":"2021-11-02T11:33:07.185875Z","shell.execute_reply.started":"2021-11-02T11:33:07.159439Z","shell.execute_reply":"2021-11-02T11:33:07.184198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.pickup_datetime.min(), df_test.pickup_datetime.max()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:07.188304Z","iopub.execute_input":"2021-11-02T11:33:07.188827Z","iopub.status.idle":"2021-11-02T11:33:07.19944Z","shell.execute_reply.started":"2021-11-02T11:33:07.188785Z","shell.execute_reply":"2021-11-02T11:33:07.197899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fortunatly this doesn't exit in test dataset so we can **remove** these data from training set","metadata":{}},{"cell_type":"markdown","source":"## 4. Prepare Dataset for Training\n\n- Split Training & Validation Set\n- Fill/Remove Missing Values\n- Extract Inputs & Outputs\n   - Training\n   - Validation\n   - Test","metadata":{}},{"cell_type":"code","source":"%%time\ndf.corr()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:07.202268Z","iopub.execute_input":"2021-11-02T11:33:07.202723Z","iopub.status.idle":"2021-11-02T11:33:18.370386Z","shell.execute_reply.started":"2021-11-02T11:33:07.202656Z","shell.execute_reply":"2021-11-02T11:33:18.368646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* I was curious if distance and log, lat had any correlation between them\n* I also want to check for correlation between extracts of time\n* `Fare` had a correlation of **0.819645** with `trip distance`","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:18.372503Z","iopub.execute_input":"2021-11-02T11:33:18.372872Z","iopub.status.idle":"2021-11-02T11:33:27.388868Z","shell.execute_reply.started":"2021-11-02T11:33:18.372834Z","shell.execute_reply":"2021-11-02T11:33:27.387596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:27.390558Z","iopub.execute_input":"2021-11-02T11:33:27.39124Z","iopub.status.idle":"2021-11-02T11:33:27.396621Z","shell.execute_reply.started":"2021-11-02T11:33:27.391191Z","shell.execute_reply":"2021-11-02T11:33:27.395313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\n#sns.lineplot(y='fare_amount', x='pickup_datetime', data= df_original)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:27.398247Z","iopub.execute_input":"2021-11-02T11:33:27.398846Z","iopub.status.idle":"2021-11-02T11:33:27.41437Z","shell.execute_reply.started":"2021-11-02T11:33:27.398801Z","shell.execute_reply":"2021-11-02T11:33:27.413231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split Training & Validation Set\n\nWe'll set aside 20% of the training data as the validation set, to evaluate the models we train on previously unseen data. \n\nSince the test set and training set have the same date ranges, we can pick a random 20% fraction.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:27.415945Z","iopub.execute_input":"2021-11-02T11:33:27.416513Z","iopub.status.idle":"2021-11-02T11:33:27.739743Z","shell.execute_reply.started":"2021-11-02T11:33:27.416456Z","shell.execute_reply":"2021-11-02T11:33:27.738368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:27.741454Z","iopub.execute_input":"2021-11-02T11:33:27.741847Z","iopub.status.idle":"2021-11-02T11:33:32.279726Z","shell.execute_reply.started":"2021-11-02T11:33:27.741803Z","shell.execute_reply":"2021-11-02T11:33:32.278978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_df), len(val_df)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:32.281355Z","iopub.execute_input":"2021-11-02T11:33:32.282307Z","iopub.status.idle":"2021-11-02T11:33:32.290857Z","shell.execute_reply.started":"2021-11-02T11:33:32.282236Z","shell.execute_reply":"2021-11-02T11:33:32.289858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract Inputs and Outputs","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:32.292155Z","iopub.execute_input":"2021-11-02T11:33:32.293318Z","iopub.status.idle":"2021-11-02T11:33:32.30708Z","shell.execute_reply.started":"2021-11-02T11:33:32.293262Z","shell.execute_reply":"2021-11-02T11:33:32.30619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_cols = ['pickup_longitude', 'pickup_latitude',\n       'dropoff_longitude', 'dropoff_latitude', 'passenger_count',\n       'trip_distance', 'year', 'month', 'day', 'weekday',\n       'pickup_datetime_hour', 'jfk_drop_distance', 'lga_drop_distance',\n       'ewr_drop_distance', 'met_drop_distance', 'wtc_drop_distance']\ntarget_col = 'fare_amount'","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:32.308406Z","iopub.execute_input":"2021-11-02T11:33:32.309268Z","iopub.status.idle":"2021-11-02T11:33:32.32014Z","shell.execute_reply.started":"2021-11-02T11:33:32.30922Z","shell.execute_reply":"2021-11-02T11:33:32.31884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"train_inputs = train_df[input_cols]\ntrain_targets = train_df[target_col]\ntrain_inputs.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:32.322105Z","iopub.execute_input":"2021-11-02T11:33:32.322743Z","iopub.status.idle":"2021-11-02T11:33:32.974392Z","shell.execute_reply.started":"2021-11-02T11:33:32.322669Z","shell.execute_reply":"2021-11-02T11:33:32.973102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_targets.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:32.976404Z","iopub.execute_input":"2021-11-02T11:33:32.977003Z","iopub.status.idle":"2021-11-02T11:33:32.986722Z","shell.execute_reply.started":"2021-11-02T11:33:32.976943Z","shell.execute_reply":"2021-11-02T11:33:32.985816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"code","source":"val_inputs = val_df[input_cols]\nval_targets = val_df[target_col]","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:32.988395Z","iopub.execute_input":"2021-11-02T11:33:32.989166Z","iopub.status.idle":"2021-11-02T11:33:33.256462Z","shell.execute_reply.started":"2021-11-02T11:33:32.989117Z","shell.execute_reply":"2021-11-02T11:33:33.255278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(val_inputs.head(3))\ndisplay(val_targets.head(3))","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:33.258507Z","iopub.execute_input":"2021-11-02T11:33:33.258927Z","iopub.status.idle":"2021-11-02T11:33:33.286205Z","shell.execute_reply.started":"2021-11-02T11:33:33.258889Z","shell.execute_reply":"2021-11-02T11:33:33.284992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"### Feature enigeerning on Test dataset\nadd_dateparts(df_test, 'pickup_datetime')\nadd_trip_distance(df_test)\n\nfor name, lonlat in [('jfk', jfk_lonlat), ('lga', lga_lonlat), ('ewr', ewr_lonlat), ('met', met_lonlat), ('wtc', wtc_lonlat)]:\n    add_landmark_dropoff_distance(df_test, name, lonlat)\ndf_test.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:33.287768Z","iopub.execute_input":"2021-11-02T11:33:33.288419Z","iopub.status.idle":"2021-11-02T11:33:33.351638Z","shell.execute_reply.started":"2021-11-02T11:33:33.28837Z","shell.execute_reply":"2021-11-02T11:33:33.350451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_inputs = df_test[input_cols]\ntest_inputs.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:33.353372Z","iopub.execute_input":"2021-11-02T11:33:33.353866Z","iopub.status.idle":"2021-11-02T11:33:33.382276Z","shell.execute_reply.started":"2021-11-02T11:33:33.353818Z","shell.execute_reply":"2021-11-02T11:33:33.380823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5 Modeling","metadata":{}},{"cell_type":"markdown","source":"## 5.1. Train Hardcoded & Baseline Models\n\n- Hardcoded model: always predict average fare\n- Baseline model: Linear regression \n\nFor evaluation the dataset uses RMSE error: \nhttps://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview/evaluation","metadata":{}},{"cell_type":"markdown","source":"### Train & Evaluate Hardcoded Model\n\ngeneral approach is to create a simple model that always predicts the average.\nBut we will use **linear regression **","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:33.384105Z","iopub.execute_input":"2021-11-02T11:33:33.385029Z","iopub.status.idle":"2021-11-02T11:33:33.502166Z","shell.execute_reply.started":"2021-11-02T11:33:33.384908Z","shell.execute_reply":"2021-11-02T11:33:33.500659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%time\nlinreg_model = LinearRegression()\nlinreg_model.fit(train_inputs, train_targets)\ntrain_preds = linreg_model.predict(train_inputs)\nval_preds = linreg_model.predict(val_inputs)\ntrain_rmse = mean_squared_error(train_targets, train_preds, squared=False)\nval_rmse = mean_squared_error(val_targets, val_preds, squared=False)\nprint('RMSE Score on Validation data',val_rmse)\nprint('RMSE Score on Validation data',train_rmse)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:33.503734Z","iopub.execute_input":"2021-11-02T11:33:33.504871Z","iopub.status.idle":"2021-11-02T11:33:41.243012Z","shell.execute_reply.started":"2021-11-02T11:33:33.504812Z","shell.execute_reply":"2021-11-02T11:33:41.241354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Rmse = 5.15384799403991 mean our prediction is off by 5.153 per prediction which is not good as **fare.median is 8.5**\n* our base model isn't overfitting as validation score is similar to training set","metadata":{}},{"cell_type":"code","source":"df.fare_amount.median()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:41.2475Z","iopub.execute_input":"2021-11-02T11:33:41.247845Z","iopub.status.idle":"2021-11-02T11:33:41.53744Z","shell.execute_reply.started":"2021-11-02T11:33:41.247812Z","shell.execute_reply":"2021-11-02T11:33:41.536041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_train= r2_score(train_targets, train_preds)\nr2_val = r2_score(val_targets, val_preds)\nprint('R2 Score on Validation data',r2_val)\nprint('R2 Score on Validation data',r2_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:41.539868Z","iopub.execute_input":"2021-11-02T11:33:41.540289Z","iopub.status.idle":"2021-11-02T11:33:42.170463Z","shell.execute_reply.started":"2021-11-02T11:33:41.540238Z","shell.execute_reply":"2021-11-02T11:33:42.169267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Train & Evaluate Different Models\n\nWe'll train each of the following & submit predictions to Kaggle:\n\n- Ridge Regression\n- Random Forests\n- Gradient Boosting","metadata":{}},{"cell_type":"code","source":"def evaluate(model):\n    train_preds = model.predict(train_inputs)\n    train_rmse = mean_squared_error(train_targets, train_preds, squared=False)\n    val_preds = model.predict(val_inputs)\n    val_rmse = mean_squared_error(val_targets, val_preds, squared=False)\n    return train_rmse, val_rmse, train_preds, val_preds","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:42.172177Z","iopub.execute_input":"2021-11-02T11:33:42.172488Z","iopub.status.idle":"2021-11-02T11:33:42.18086Z","shell.execute_reply.started":"2021-11-02T11:33:42.172452Z","shell.execute_reply":"2021-11-02T11:33:42.179233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_and_submit(model, fname):\n    test_preds = model.predict(test_inputs)\n    sub_df = pd.read_csv(data_dir+'/sample_submission.csv')\n    sub_df['fare_amount'] = test_preds\n    sub_df.to_csv(fname, index=None)\n    return sub_df","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:42.183055Z","iopub.execute_input":"2021-11-02T11:33:42.184033Z","iopub.status.idle":"2021-11-02T11:33:42.19591Z","shell.execute_reply.started":"2021-11-02T11:33:42.183966Z","shell.execute_reply":"2021-11-02T11:33:42.194812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ridge Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:42.197941Z","iopub.execute_input":"2021-11-02T11:33:42.198432Z","iopub.status.idle":"2021-11-02T11:33:42.213854Z","shell.execute_reply.started":"2021-11-02T11:33:42.198375Z","shell.execute_reply":"2021-11-02T11:33:42.21295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = Ridge(random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:42.215183Z","iopub.execute_input":"2021-11-02T11:33:42.215674Z","iopub.status.idle":"2021-11-02T11:33:42.230308Z","shell.execute_reply.started":"2021-11-02T11:33:42.215529Z","shell.execute_reply":"2021-11-02T11:33:42.229108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel1.fit(train_inputs, train_targets)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:42.232971Z","iopub.execute_input":"2021-11-02T11:33:42.233798Z","iopub.status.idle":"2021-11-02T11:33:44.398694Z","shell.execute_reply.started":"2021-11-02T11:33:42.233745Z","shell.execute_reply":"2021-11-02T11:33:44.397222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model1)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:44.401427Z","iopub.execute_input":"2021-11-02T11:33:44.402498Z","iopub.status.idle":"2021-11-02T11:33:45.534831Z","shell.execute_reply.started":"2021-11-02T11:33:44.402424Z","shell.execute_reply":"2021-11-02T11:33:45.533538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time taken by model : Wall time: 3.18 s\n* Model is not overfitting as both RMSE score is 5.138\n* This mean fare prediction is off by $ 5.138 which is `similar to Linear Regression` \n","metadata":{}},{"cell_type":"code","source":"predict_and_submit(model1, 'ridge_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:45.537304Z","iopub.execute_input":"2021-11-02T11:33:45.538236Z","iopub.status.idle":"2021-11-02T11:33:45.682966Z","shell.execute_reply.started":"2021-11-02T11:33:45.538164Z","shell.execute_reply":"2021-11-02T11:33:45.682113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_and_submit(linreg_model, 'Linear_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:45.684396Z","iopub.execute_input":"2021-11-02T11:33:45.684936Z","iopub.status.idle":"2021-11-02T11:33:45.825388Z","shell.execute_reply.started":"2021-11-02T11:33:45.684895Z","shell.execute_reply":"2021-11-02T11:33:45.824155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### iii) Random Forest\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:45.827481Z","iopub.execute_input":"2021-11-02T11:33:45.82792Z","iopub.status.idle":"2021-11-02T11:33:45.984312Z","shell.execute_reply.started":"2021-11-02T11:33:45.827866Z","shell.execute_reply":"2021-11-02T11:33:45.983023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel2 = RandomForestRegressor(max_depth=10, n_jobs=-1, random_state=7, n_estimators=50)\nmodel2.fit(train_inputs, train_targets)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T11:33:45.985907Z","iopub.execute_input":"2021-11-02T11:33:45.986275Z","iopub.status.idle":"2021-11-02T12:16:49.250232Z","shell.execute_reply.started":"2021-11-02T11:33:45.986222Z","shell.execute_reply":"2021-11-02T12:16:49.2496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model2)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:16:49.251827Z","iopub.execute_input":"2021-11-02T12:16:49.252193Z","iopub.status.idle":"2021-11-02T12:17:08.331355Z","shell.execute_reply.started":"2021-11-02T12:16:49.252158Z","shell.execute_reply":"2021-11-02T12:17:08.330528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RF Model Execution time :: Wall time: 41min 6s   :: CPU times: user 2h 37min 31s  \nWow Random Forest is giving so accurate results with RMSE score of **0.01** and **0.0131** which means prediction is off by few cents and model is not overfitting the data","metadata":{}},{"cell_type":"code","source":"predict_and_submit(model2, 'rf_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:17:08.332708Z","iopub.execute_input":"2021-11-02T12:17:08.332901Z","iopub.status.idle":"2021-11-02T12:17:08.517507Z","shell.execute_reply.started":"2021-11-02T12:17:08.332877Z","shell.execute_reply":"2021-11-02T12:17:08.516741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### iv) XGradient Boosting\n\nhttps://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:17:08.518912Z","iopub.execute_input":"2021-11-02T12:17:08.519216Z","iopub.status.idle":"2021-11-02T12:17:08.637157Z","shell.execute_reply.started":"2021-11-02T12:17:08.519177Z","shell.execute_reply":"2021-11-02T12:17:08.636223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel3 = XGBRegressor(random_state=42, n_jobs=-1, objective='reg:squarederror')\nmodel3.fit(train_inputs, train_targets)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:17:08.638271Z","iopub.execute_input":"2021-11-02T12:17:08.638947Z","iopub.status.idle":"2021-11-02T13:06:26.496619Z","shell.execute_reply.started":"2021-11-02T12:17:08.638913Z","shell.execute_reply":"2021-11-02T13:06:26.495519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model3)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:06:26.498183Z","iopub.execute_input":"2021-11-02T13:06:26.498429Z","iopub.status.idle":"2021-11-02T13:06:38.081993Z","shell.execute_reply.started":"2021-11-02T13:06:26.4984Z","shell.execute_reply":"2021-11-02T13:06:38.081021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time taken to execute XGBoost :: Wall time: 41min 23s :: CPU times: user 2h 28min 42s  \nXGBoost performed worse than Random forest it has a std of 1.2 to 1.35 usd per prediction","metadata":{}},{"cell_type":"code","source":"predict_and_submit(model3, 'xgb_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:06:38.083407Z","iopub.execute_input":"2021-11-02T13:06:38.083641Z","iopub.status.idle":"2021-11-02T13:06:38.168639Z","shell.execute_reply.started":"2021-11-02T13:06:38.083614Z","shell.execute_reply":"2021-11-02T13:06:38.167745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Tune Hyperparmeters\n\nhttps://towardsdatascience.com/mastering-xgboost-2eb6bce6bc76\n\n\nWe'll train parameters for the XGBoost model. Here’s a strategy for tuning hyperparameters:\n\n- Tune the most important/impactful hyperparameter first e.g. n_estimators\n\n- With the best value of the first hyperparameter, tune the next most impactful hyperparameter\n\n- And so on, keep training the next most impactful parameters with the best values for previous parameters...\n\n- Then, go back to the top and further tune each parameter again for further marginal gains\n\n- Hyperparameter tuning is more art than science, unfortunately. Try to get a feel for how the parameters interact with each other based on your understanding of the parameter…\n\nLet's define a helper function for trying different hyperparameters.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef test_params(ModelClass, **params):\n    \"\"\"Trains a model with the given parameters and returns training & validation RMSE\"\"\"\n    model = ModelClass(**params).fit(train_inputs, train_targets)\n    train_rmse = mean_squared_error(model.predict(train_inputs), train_targets, squared=False)\n    val_rmse = mean_squared_error(model.predict(val_inputs), val_targets, squared=False)\n    return train_rmse, val_rmse\n\ndef test_param_and_plot(ModelClass, param_name, param_values, **other_params):\n    \"\"\"Trains multiple models by varying the value of param_name according to param_values\"\"\"\n    train_errors, val_errors = [], [] \n    for value in param_values:\n        params = dict(other_params)\n        params[param_name] = value\n        train_rmse, val_rmse = test_params(ModelClass, **params)\n        train_errors.append(train_rmse)\n        val_errors.append(val_rmse)\n    \n    plt.figure(figsize=(10,6))\n    plt.title('Overfitting curve: ' + param_name)\n    plt.plot(param_values, train_errors, 'b-o')\n    plt.plot(param_values, val_errors, 'r-o')\n    plt.xlabel(param_name)\n    plt.ylabel('RMSE')\n    plt.legend(['Training', 'Validation'])","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:06:38.170022Z","iopub.execute_input":"2021-11-02T13:06:38.170229Z","iopub.status.idle":"2021-11-02T13:06:38.181275Z","shell.execute_reply.started":"2021-11-02T13:06:38.170204Z","shell.execute_reply":"2021-11-02T13:06:38.180271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params = {\n    'random_state': 7,\n    'n_jobs': -1,\n    'objective': 'reg:squarederror'\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:06:38.182904Z","iopub.execute_input":"2021-11-02T13:06:38.183283Z","iopub.status.idle":"2021-11-02T13:06:38.193624Z","shell.execute_reply.started":"2021-11-02T13:06:38.183239Z","shell.execute_reply":"2021-11-02T13:06:38.192794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n### No of trees\ntest_param_and_plot(XGBRegressor, 'n_estimators', [100, 250, 500], **best_params)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T13:06:38.194995Z","iopub.execute_input":"2021-11-02T13:06:38.19571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems like 500 estimators has the lowest validation loss. However, it also takes a long time. Let's stick with 250 for now.","metadata":{}},{"cell_type":"code","source":"best_params['n_estimators'] = 250","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n#### Max Depth\ntest_param_and_plot(XGBRegressor, 'max_depth', [3, 4, 5], **best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params['max_depth'] = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#### Learning Rate\ntest_param_and_plot(XGBRegressor, 'learning_rate', [0.05, 0.1, 0.25], **best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params['learning_rate'] = 0.25","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final Model Creation\nxgb_model_final = XGBRegressor(objective='reg:squarederror', n_jobs=-1, random_state=42,\n                               n_estimators=500, max_depth=5, learning_rate=0.1, \n                               subsample=0.8, colsample_bytree=0.8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nxgb_model_final.fit(train_inputs, train_targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(xgb_model_final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_and_submit(xgb_model_final, 'xgb_tuned_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}