{"cells":[{"metadata":{"_uuid":"dc7d9c3e2cc324ac185321d21781c267e01a5310"},"cell_type":"markdown","source":"# ***This notebook is related to the Kaggle competition \"New York City Taxi Fare Prediction\" by Google Cloud***   \n \n#### The dataset can be found here: https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data"},{"metadata":{"_uuid":"72a7f3af09b574612af17328da39297e31d62dcb"},"cell_type":"markdown","source":"# Before we look into the data, what do we know about taxi fares in NYC?  \n\nWe can get the fare rules from here http://home.nyc.gov/html/tlc/html/passenger/taxicab_rate.shtml  \n\nThere was a change in the fare rules on the 30/09/2012\n\n## Before 05/09/2012 (in USD)\n\n__Normal Trip:__  \nInitial charge: 2  \nSurcharge Improvement:  0.30   \nSurcharge from 8pm to 6am every day: 0.50  \nSurcharge from 4pm to 8pm on weekdays (exc. holidays): 1.00    \nSurcharge for dropoff location (NYC, Nassau, Suffolk, Westchester, Rockland, Dutchess, Orange, Putnam): 0.50  \n\nNo surcharge for extra pasengers or bags.  \nReceipt includes payments for bridges and tunnels.  \n\nMeter: 0.40 per 1/5 mile or 0.40 per 60 seconds when vehicle is stopped.\n\n__Airport Trip:__  \nTo-From La Guardia: Normal Trip  \nTo-From JFK and any location in NYC excluding Manhattan: Normal Trip\nTo/From JFK and any location in Manhattan: 45 + 4.5 if from 4pm to 8pm on weekdays (exc. holidays) + tolls  \nTo Newark: Normal trip + 15  \n\n\n## After 05/09/2012 (in USD)\n\n__Normal Trip:__  \nInitial charge: 2.50  \nSurcharge Improvement:  0.30   \nSurcharge from 8pm to 6am every day: 0.50  \nSurcharge from 4pm to 8pm on weekdays (exc. holidays): 1.00    \nSurcharge for dropoff location (NYC, Nassau, Suffolk, Westchester, Rockland, Dutchess, Orange, Putnam): 0.50  \n\nNo surcharge for extra pasengers or bags.  \nReceipt includes payments for bridges and tunnels.  \n\nMeter: 0.50 per 1/5 mile or 0.50 per 60 seconds when vehicle is stopped.\n\n__Airport Trip:__  \nTo-From La Guardia: Normal Trip  \nTo-From JFK and any location in NYC excluding Manhattan: Normal Trip\nTo/From JFK and any location in Manhattan: 52.8 + 4.5 if from 4pm to 8pm on weekdays (exc. holidays) + tolls  \nTo Newark: Normal trip + 17.5  \n\nIt seems reasonable that we have to categorize the trips on the dataset based on the above rules, and that we should extract features and conditions from the geolocation and datetime of the trips. The hardest part will be to factor in the traffic.\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport itertools\nimport math\nfrom math import radians\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-whitegrid')\nimport plotly.graph_objs as go\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nimport folium\nimport folium.plugins\nfrom folium.plugins import MarkerCluster\nfrom folium.plugins import FastMarkerCluster\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fae3e4b66cb7d1d8a4364bb707efcae4e10ffd10"},"cell_type":"markdown","source":"# Read the Data  \n\nThe first thing to do is to read the training set that contains __55 million rows__ of data! The data contains the datetime of the taxi ride, the pickup location, dropoff location, number of passengers and the fare amount. The are some transformations we want to do with the datetime column that we will do them at the same time that we read the data. \n\nBasically we are going to extract the day of the week, the hour of the day and check if the ride was before or after the fare reform explained before. So first let's define a function that can read csv data and apply those transformations.  "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"def readData(path, types, chunksize, chunks):\n\n    df_list = []\n    counter = 1\n    \n    for df_chunk in tqdm(pd.read_csv(path, usecols=list(types.keys()), dtype=types, chunksize=chunksize)):\n\n        # The counter helps us stop whenever we want instead of reading the entire data\n        if counter == chunks+1:\n            break\n        counter = counter+1\n\n        # Neat trick from https://www.kaggle.com/btyuhas/bayesian-optimization-with-xgboost\n        # Using parse_dates would be much slower!\n        df_chunk['pickup_datetime'] = df_chunk['pickup_datetime'].str.slice(0, 16)\n        df_chunk['pickup_datetime'] = pd.to_datetime(df_chunk['pickup_datetime'])\n\n        # Process the datetime and get hour of day and day of week\n        # After Price Reform - Before Price Reform ('newRate')\n        df_chunk['hour'] = df_chunk['pickup_datetime'].apply(lambda x: x.hour)\n        df_chunk['weekday'] = df_chunk['pickup_datetime'].apply(lambda x: x.weekday())\n        df_chunk['newRate'] = df_chunk['pickup_datetime'].apply(lambda x: True if x > pd.Timestamp(2012, 9, 30, 10) else False)\n        df_chunk.drop(columns=['pickup_datetime'], inplace=True)   \n        \n        # Aappend the chunk to list\n        df_list.append(df_chunk) \n\n    # Merge all dataframes into one dataframe\n    df = pd.concat(df_list)\n\n    # Delete the dataframe list to release memory\n    del df_list\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1278753a24b85e6f2836e673237f947557e8c758"},"cell_type":"markdown","source":"Now we read the training data. We can define how many rows to read using 'chunksize' and 'chunksnumber'"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"1bea35bcbdf212511c2d046e9ea28a74897a3751"},"cell_type":"code","source":" # The path where the Training set is\nTRAIN_PATH = '../input/train.csv'\n\n# The datatypes we want to pass the reading function\ntraintypes = {'fare_amount': 'float32',\n              'pickup_datetime': 'str', \n              'pickup_longitude': 'float32',\n              'pickup_latitude': 'float32',\n              'dropoff_longitude': 'float32',\n              'dropoff_latitude': 'float32',\n              'passenger_count': 'float32'}\n\n# The size of the chunk for each iteration\nchunksizeTrain = 1_000_000\n\n# The number of chunks we want to read\nchunksnumberTrain = 5\n\ndf_train = readData(TRAIN_PATH, traintypes, chunksizeTrain, chunksnumberTrain)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"406a81ff5a0ebb55d633c5369ac65bf3fdbbc305"},"cell_type":"markdown","source":"We also read the test data using the same function"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"f23950333051ad8579d904cf1741c1aa9ffe2328"},"cell_type":"code","source":" # The path where the Test set is\nTEST_PATH = '../input/test.csv'\n\n# The datatypes we want to pass the reading function\ntesttypes = {'key': 'str',\n              'pickup_datetime': 'str', \n              'pickup_longitude': 'float32',\n              'pickup_latitude': 'float32',\n              'dropoff_longitude': 'float32',\n              'dropoff_latitude': 'float32',\n              'passenger_count': 'float32'}\n\n# The size of the chunk for each iteration\nchunksizeTest = 1_000_000\n\n# The number of chunks we want to read\nchunksnumberTest = 1\n\ndf_test = readData(TEST_PATH, testtypes, chunksizeTest, chunksnumberTest)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"845ef73903fbf1801bb3120be2957b10052fddd5"},"cell_type":"markdown","source":"Let's have a look at the imported data (train and test datasets)"},{"metadata":{"trusted":true,"_uuid":"add5365950507de8b5bcda15155cf5f322ddace6","_kg_hide-input":false},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e816b7733b9e6cbd97e54c54db8e26aeda1665b","_kg_hide-input":false},"cell_type":"code","source":"df_train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5666e3cf476f86fe6aabc03c51beffbe85e884df"},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8020f77dd035a1082dbd3dc17b9681d982bb6693"},"cell_type":"code","source":"df_test.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"993d922e247011cd4880d7c6c929387adea7403c"},"cell_type":"markdown","source":"## Clean the Data   \n\nThe next step is to clean the data. We will:  \n\n1) Drop the rows with null values  \n2) Drop rows with fare_amount less than 2.5 USD  \n3) Drop rows with fare_amount above 400 USD  \n4) Drop rows with passenger_count outside the range 1 to 10    \n5) Drop rows with geolocations not close to NYC    "},{"metadata":{"trusted":true,"_uuid":"d1b7aa39cac155e015bbc1feaa60f3b641a53ed1","_kg_hide-input":false},"cell_type":"code","source":"# Function that cleans data\ndef cleanData(df, isTrain):\n\n    # 1) Drop NaN\n    df.dropna(how = 'any', axis = 'rows', inplace = True)\n    \n    # 2) 3) Drop fares below 2.5 USD or above 400 USD in case the dataset is the Training set\n    if isTrain:\n        df = df[df['fare_amount']>=2.5]\n        df = df[df['fare_amount']<400]\n    \n    # 4) Drop passenger count below 1 or above 10\n    df = df[(df['passenger_count']>=1) & (df['passenger_count']<10)] # Drop lines out of bound passenger count   \n    \n    # 5) Drop rides outside NYC\n    minLon = -74.3\n    maxLon = -73.7\n    minLat = 40.5\n    maxLat = 41\n\n    df = df[df['pickup_latitude'] < maxLat]\n    df = df[df['pickup_latitude'] > minLat]\n    df = df[df['pickup_longitude'] < maxLon]\n    df = df[df['pickup_longitude'] > minLon]\n\n    df = df[df['dropoff_latitude'] < maxLat]\n    df = df[df['dropoff_latitude'] > minLat]\n    df = df[df['dropoff_longitude'] < maxLon]\n    df = df[df['dropoff_longitude'] > minLon]\n\n    # Reset Index\n    df.reset_index(inplace=True, drop=True)\n    \n    return df\n\n# Apply cleaning function to both datasets\ndf_train = cleanData(df_train, True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84cfc773f395cea7ac869e08af1711409899dd18"},"cell_type":"markdown","source":"Take a quick look at the dataset after cleaning"},{"metadata":{"trusted":true,"_uuid":"77ec273c03db5dadf3bb604c5995d6f0107455ba","_kg_hide-input":false},"cell_type":"code","source":"df_train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cdaf7daf9488dafab8eba367e646db85df2f822b"},"cell_type":"markdown","source":"Let's have a quick look at how many data we loss while cleaning"},{"metadata":{"trusted":true,"_uuid":"071c45348025339dbe03a683f99b26bf0a92583e","_kg_hide-input":false},"cell_type":"code","source":"trace = go.Pie(values = [df_train.shape[0],chunksizeTrain*chunksnumberTrain - df_train.shape[0]],\n               labels = [\"Useful data\" , \"Data loss due to missing values or other reasons\"],\n               marker = dict(colors = ['skyblue' ,'yellow'], line = dict(color = \"black\", width =  1.5)),\n               rotation  = 60,\n               hoverinfo = 'label+percent',\n              )\n\nlayout = go.Layout(dict(title = 'Data Cleaning (percentage of data loss)',\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        showlegend=False\n                       )\n                  )\n\nfig = go.Figure(data=[trace],layout=layout)\npy.iplot(fig)\nfig = go.Figure(data=[trace],layout=layout)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fb0f59eb279de436651c789bc5847f9d93613ac"},"cell_type":"markdown","source":"# Data Exploration  \n\nWe will begin now the data exploration. Since we are dealing with geolocation data a good place to start is to see our datapoints on a map to get an initial feeling of what we have. Let's have a look at the pickup locations."},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"1497301fc16838c7a6a7b86559f27d9e3bffb9b8"},"cell_type":"code","source":"# Using datashader\n#Import Libraries\nfrom bokeh.models import BoxZoomTool\nfrom bokeh.plotting import figure, output_notebook, show\nimport datashader as ds\nfrom datashader.bokeh_ext import InteractiveImage\nfrom functools import partial\nfrom datashader.utils import export_image\nfrom datashader.colors import colormap_select, Hot, inferno, Elevation\nfrom datashader import transfer_functions as tf\noutput_notebook()\n\n# Define plotting function using Datashader\ndef plot_data_points(longitude,latitude,data_frame) :\n    export  = partial(export_image, export_path=\"export\", background=\"black\")\n    fig = figure(background_fill_color = \"black\")    \n    cvs = ds.Canvas(plot_width=800, \n                    plot_height=600,\n                    x_range=(-74.15,-73.75), \n                    y_range=(40.6,40.9))\n    agg = cvs.points(data_frame,longitude,latitude)\n    #img = tf.shade(agg, cmap=Hot, how='eq_hist')\n    img = tf.shade(agg)   \n    image_xpt = tf.dynspread(img, threshold=0.5, max_px=4)\n    return export(image_xpt,'map')\n\n# Call function and plot\nplot_data_points('pickup_longitude', 'pickup_latitude', df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bbe3814a25b3bd9bde9cbcc8c05929e7d4e6125"},"cell_type":"code","source":"# Let's look at some clusters with Folium (20000 points)\nsamples = df_train.sample(n=min(20000,df_train.shape[0]))\nm = folium.Map(location=[np.mean(samples['pickup_latitude']), np.mean(samples['pickup_longitude'])], zoom_start=11)\nFastMarkerCluster(data=list(zip(samples['pickup_latitude'], samples['pickup_longitude']))).add_to(m)\nfolium.LayerControl().add_to(m)\nm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e5ab5576a481006fbb499a61f9ed6f7527a80d9"},"cell_type":"markdown","source":"# The target variable: the fare\n\nHere we will explore the fares of our training set. We will split the fares in 3 sections based on our intuition and our knowledge related to rides to airports and else:  \n\n1) Up to 40 USD (most of the rides)  \n2) From 40 USD to 70 USD (rides including airports)  \n3) Above 70 USD (expensive rides)  \n\n"},{"metadata":{"trusted":true,"_uuid":"aae571c9cee11f17a5b7b0ffebce1a17e209ebe8","_kg_hide-input":false},"cell_type":"code","source":"# Define how we want to split the data into sections based on 'fare_amount'\na = 40\nb = 70\nc = 400\n\n# Plot normalized histogram for each section\nplt.figure(figsize = (25,7))\nplt.subplot(1,3,1)\nplt.title('Below ' + str(a) + ' USD',color = \"b\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_train[df_train['fare_amount']<=a]['fare_amount'], norm_hist=True, bins=np.arange(0,a))\nplt.subplot(1,3,2)\nplt.title('From ' + str(a) + ' USD to ' + str(b) + ' USD',color = \"b\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_train[(df_train['fare_amount']>a)&(df_train['fare_amount']<=b)]['fare_amount'], norm_hist=True, bins=np.arange(a,b))\nplt.subplot(1,3,3)\nplt.title('From ' + str(b) + ' USD to ' + str(c) + ' USD',color = \"b\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_train[(df_train['fare_amount']>b)&(df_train['fare_amount']<=c)]['fare_amount'], norm_hist=True, bins=np.arange(b,c));","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca4790f4c0932576295518cecff012eac2c73cec"},"cell_type":"markdown","source":"We know that the fare rules changed at some point in 2012, let's plot the data based on this to see if we can appreciate a different behaviour"},{"metadata":{"trusted":true,"_uuid":"fbf40edf9d4843cca710f51b08bfbe40b4e2f57d","_kg_hide-input":false},"cell_type":"code","source":"# Split df_train into a dataset of the rides before the fare rules change and after the fare rules change\ndf_before = df_train[df_train['newRate']==False]\ndf_after = df_train[df_train['newRate']==True]\nprint ('Number of data points from before fare rule change: ' + str(df_before.shape[0]))\nprint ('Number of data points from after fare rule change: ' + str(df_after.shape[0]))\n\n# Plot the sections for the rides before fare rules change\nplt.figure(figsize = (25,14))\nplt.subplot(2,3,1)\nplt.title('Old rate, below ' + str(a) + ' USD',color = \"b\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_before[df_before['fare_amount']<=a]['fare_amount'], norm_hist=True, bins=np.arange(0,a))\nplt.subplot(2,3,2)\nplt.title('Old rate, from ' + str(a) + ' USD to ' + str(b) + ' USD',color = \"b\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_before[(df_before['fare_amount']>a)&(df_before['fare_amount']<=b)]['fare_amount'], norm_hist=True, bins=np.arange(a,b))\nplt.subplot(2,3,3)\nplt.title('Old rate, from ' + str(b) + ' USD to ' + str(c) + ' USD',color = \"b\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_before[(df_before['fare_amount']>b)&(df_before['fare_amount']<=c)]['fare_amount'], norm_hist=True, bins=np.arange(b,c)) \n\n# Plot the sections for the rides after fare rules change\nplt.figure(figsize = (25,14))\nplt.subplot(2,3,4)\nplt.title('New rate, below ' + str(a) + ' USD',color = \"g\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_after[df_after['fare_amount']<=a]['fare_amount'], norm_hist=True, color='green', bins=np.arange(0,a))\nplt.subplot(2,3,5)\nplt.title('New rate, from ' + str(a) + ' USD to ' + str(b) + ' USD',color = \"g\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_after[(df_after['fare_amount']>a)&(df_after['fare_amount']<=b)]['fare_amount'], norm_hist=True, color='green', bins=np.arange(a,b))\nplt.subplot(2,3,6)\nplt.title('New rate, from ' + str(b) + ' USD to ' + str(c) + ' USD',color = \"g\")\nplt.ylabel('Normalized Density')\nsns.distplot(df_after[(df_after['fare_amount']>b)&(df_after['fare_amount']<=c)]['fare_amount'], norm_hist=True, color='green', bins=np.arange(b,c)); ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61ab32a8e514efc3c1adbe92b61f11387d6f75be"},"cell_type":"markdown","source":"We observe a clear change in behavior between the old rates and the new rates. For example in the below 40 USD section we can see a shift in the mean and median values. Also, we can see a change in behavior of the \"cents value\" distribution."},{"metadata":{"trusted":true,"_uuid":"d770fa24985f24df2e3a405ea4417b479827eb57","_kg_hide-input":false},"cell_type":"code","source":"print('Mean fare BEFORE rate change: ' + str(np.around(df_before[df_before['fare_amount']<=a]['fare_amount'].mean(),2)))\nprint('Mean fare AFTER rate change: ' + str(np.around(df_after[df_after['fare_amount']<=a]['fare_amount'].mean(),2)))\nprint('Median fare BEFORE rate change: ' + str(np.around(df_before[df_before['fare_amount']<=a]['fare_amount'].median(),2)))\nprint('Median fare AFTER rate change: ' + str(np.around(df_after[df_after['fare_amount']<=a]['fare_amount'].median(),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37d0b6d2a4d344fd8ffcfd44b5c875bdf4926f23","_kg_hide-input":false},"cell_type":"code","source":"# Using mod function to extract the \"cents value\" of each ride\nplt.figure(figsize = (20,7))\nplt.subplot(1,2,1)\nplt.title('Old Rate, below ' + str(a) + ' USD, \"cents value\"',color = \"b\")\nsns.distplot(np.mod(df_before[df_before['fare_amount']<=a]['fare_amount'],1)) \nplt.subplot(1,2,2)\nplt.title('New Rate, below ' + str(a) + ' USD, \"cents value\"',color = \"g\")\nsns.distplot(np.mod(df_after[df_after['fare_amount']<=a]['fare_amount'],1), color='green'); ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5177c3f675dbd6651b27e936f835850378e5763"},"cell_type":"markdown","source":"We see clearly that before the fare rule change the \"cents value\" of the fare is almost always 0.1, 0.3, 0.5, 0.7 or 0.9, evenly distributed.\nOn the other side after the fare rule change the \"cents value\" of the fare is 0 or 0.5 with almost the same probability.\nWhen trying to predict the fare of new taxi rides we will take this into consideration."},{"metadata":{"_uuid":"128419b43e156edb15f9fe6a51c081fea862fba4"},"cell_type":"markdown","source":"# Rides inside Manhattan  \n\nHere we will analyse the rides that start and end inside Manhattan. Given the streets geometry of this area it makes sense that we can predict the taxi fares with higher precision than other type of rides. The first step is to define a polygon representing Manhattan. Then we can check if a given ride starts and ends inside the polygon."},{"metadata":{"trusted":true,"_uuid":"c471b72aff60fb2a89b4b28d569b0a86e5ed076f","_kg_hide-input":false,"scrolled":false},"cell_type":"code","source":"from shapely.geometry import Point\nfrom shapely.geometry.polygon import Polygon\n\n# Define polygon using coordinates (Just took them from Google Maps by clicking on the map)\nlats_vect = [40.851638, 40.763022, 40.691262, 40.713380, 40.743944, 40.794344, 40.846332]\nlons_vect = [-73.952423, -74.010418, -74.026685, -73.972200, -73.962051, -73.924073, -73.926454]\nlons_lats_vect = np.column_stack((lons_vect, lats_vect))\npolygon = Polygon(lons_lats_vect)\n\n# Plot the polygon using Folium\nman_map = folium.Map(location=[40.7631, -73.9712], zoom_start=12)\nfor i in range(0,6):\n    folium.PolyLine(locations=[[lats_vect[i],lons_vect[i]], [lats_vect[i+1],lons_vect[i+1]]], color='blue').add_to(man_map)\nfolium.PolyLine(locations=[[lats_vect[6],lons_vect[6]], [lats_vect[0],lons_vect[0]]], color='blue').add_to(man_map)\nman_map","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7483dd978413a21dd262793f41e2c49976b43a19"},"cell_type":"markdown","source":"Now that we defined our poligon we can filter our training set and extract only the rides that begin and end inside Manhattan. This may take a little time to compute."},{"metadata":{"trusted":true,"_uuid":"9f6b6bed03ae787cf2d67e6bd953d4c4f688e8a0"},"cell_type":"code","source":"# Check for every point on df_train if it belongs to polygon or not\nmanhattanRides = df_train[df_train[['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']]\n                          .apply(lambda row: ((polygon.contains(Point(row['pickup_longitude'],row['pickup_latitude']))) &\n                                              (polygon.contains(Point(row['dropoff_longitude'],row['dropoff_latitude'])))), axis=1)]\n\n# Plot the remaining dataset 'manhattanRides'\nplot_data_points('pickup_longitude', 'pickup_latitude', manhattanRides)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"722f5ddf78e14ca2b70028cc0b5f527c3f61405f"},"cell_type":"markdown","source":"Our hypothesis is that the distance of the trip is the strongest indicator to predict the price of the ride. Since we are in a very small area, there is not much difference between the Haversine distance and the Euclidean distance. In any case we will use the Manhattan distance since the area streets are like a grid. We should consider that Manhattan is about 29 degrees tilted compared to the north, and we should take that into consideration when calculating the Manhattan distance of the trip. For doing that we need to define some functions that will help us calculate the distance for every ride."},{"metadata":{"trusted":true,"_uuid":"de5f521c12eba53bd784d07a734d33a3e8c61956"},"cell_type":"code","source":"# Simple Euclidean Distance calculator \ndef quickDist(lat1, lng1, lat2, lng2):\n    lng1, lat1, lng2, lat2 = map(radians, [lng1, lat1, lng2, lat2])\n    R = 6371\n    x = (lng2 - lng1) * np.cos(0.5*(lat2+lat1))\n    y = lat2 - lat1\n    d = R * np.sqrt(x*x + y*y)\n    return d\n\n# Longitude distance (use same Euclidean distance function with fixed latitude)\ndef latDist(lat1, lng1, lat2, lng2):\n    uno = quickDist((lat1+lat2)/2, lng1, (lat1+lat2)/2, lng2)\n    return uno\n\n# Calculate real distance (Manhattan distance with 29 degrees to north)\ndef realManDist(lat1, lng1, lat2, lng2):\n    flightDist = quickDist(lat1, lng1, lat2, lng2)\n    latDistance = latDist(lat1, lng1, lat2, lng2)\n    if flightDist == 0:\n        ret = np.nan\n    else:\n        th = np.arccos(latDistance/flightDist)\n        ata = flightDist*np.cos(th-0.506) + flightDist*np.sin(th-0.506)\n        bta = flightDist*np.cos(th+0.506) + flightDist*np.sin(th+0.506)\n        ret = max(ata,bta)\n    return ret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ca96c496bf7a64127d2ea3debf47cae4473f9f7"},"cell_type":"code","source":"# Calculate distance for every ride on manhattanRides\nmanhattanRides['distance'] = manhattanRides.apply(lambda row: realManDist(row['pickup_latitude'], \n                                                                          row['pickup_longitude'], \n                                                                          row['dropoff_latitude'], \n                                                                          row['dropoff_longitude']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6423547e3373dd4d500c31bdc44dafc3d807bc89"},"cell_type":"markdown","source":"Let's check the percentage of the rides that are Manhattan rides. We get that 85% of the trips are Manhattan Rides. Having a good estimator for this kind of trips is extremely important."},{"metadata":{"_uuid":"b997b7d0479801bd1a0999a560fdce35f1dedea6","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"print('Percentage of trips that happen inside Manhattan: ' + str(np.around(100*(manhattanRides.shape[0])/df_train.shape[0],2)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"126125320e3b28fdff47dda7db531a71bba591b8"},"cell_type":"markdown","source":"Now we will focus on building a model to predict the fare. Before we move on, let's split the manhattanRides dataframe into train and test, just so we can train a model using the train section and test the predictions accuracy using the test section. We will do 80% training and 20% testing using sklearn. Then we take a look at the train set by plotting the fare_amount against the distance."},{"metadata":{"trusted":true,"_uuid":"9fdc0c17a06ddd2239c06ed4bb047feb1dd8b9d0"},"cell_type":"code","source":"# Split train/test\nfrom sklearn.model_selection import train_test_split\nmanhattanRides_train, manhattanRides_test = train_test_split(manhattanRides, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16fccd8b7556cd9eba971548b7ea922856a389b0","_kg_hide-input":false},"cell_type":"code","source":"# Plot the 'fare_amount' against the distance of the trip\nplt.figure(figsize = (20,15))\nplt.title('Manhattan Rides', color = \"b\")\nplt.ylabel('Fare in USD')\nplt.xlabel('Distance in Km')\nplt.scatter(manhattanRides_train['distance'], manhattanRides_train['fare_amount'], alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d8a992866210542d6a17e78c5ed501100197699"},"cell_type":"markdown","source":"There are some strange behaviors that we want to exclude from the dataset when building our model. We keep them to further analyse:  \n1) High fare trips with distance close to 0.  \n2) High distance trips with fare below 3 USD.  \n3) Very high value outliers (above 75 USD).  \n4) Fixed price trips around 50 USD no matter the distance.  \n\nLet's filter and plot again:"},{"metadata":{"trusted":true,"_uuid":"3e2746a72a4d2607160d479d30e804f23067f5a8"},"cell_type":"code","source":"manhattanRides_shortDist = manhattanRides_train[manhattanRides_train['distance']<=0.3];\nmanhattanRides_highValue = manhattanRides_train[manhattanRides_train['fare_amount']>75];\nmanhattanRides_lowValue = manhattanRides_train[manhattanRides_train['fare_amount']<=3];\n\nmanhattanRides_train = manhattanRides_train[(manhattanRides_train['distance']>0.3)&(manhattanRides_train['fare_amount']<75)&(manhattanRides_train['fare_amount']>3)];\n\n# Filter fare range\nstraight_lines = manhattanRides_train[(manhattanRides_train['fare_amount']>44)&(manhattanRides_train['fare_amount']<60)]\n# Group by fare and count frequency\nfreq = straight_lines.groupby('fare_amount').count().sort_values('pickup_longitude', ascending=False)\n\n# Keep the fare value of the top 8\nfares_straight_lines = freq.index[0:7].values\n# Extract from training dataframe\nmanhattanRides_straightLines = manhattanRides_train[manhattanRides_train['fare_amount'].isin(fares_straight_lines)]\nmanhattanRides_train = manhattanRides_train[~manhattanRides_train['fare_amount'].isin(fares_straight_lines)]\n# Plot the 'fare_amount' against the distance of the trip\nplt.figure(figsize = (20,15))\nplt.title('Manhattan Rides', color = \"b\")\nplt.ylabel('Fare in USD')\nplt.xlabel('Distance in Km')\nplt.scatter(manhattanRides_train['distance'], manhattanRides_train['fare_amount'], alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17388bbc78047960ba904685256e689983805de1"},"cell_type":"markdown","source":"Now we have a plot that makes more sense. Let's just write down the different datasets that we have now:  \n\n__1) manhattanRides_shortDist:__  Trips with distance below 0.3 km  \n__2) manhattanRides_highValue:__   Trips with fare_amounts above 75 USD  \n__3) manhattanRides_lowValue:__  Trips with fare amounts below 3 USD  \n__4) manhattanRides_straightLines:__  Trips with fixed amount despite distance (usually between 45 and 60 USD)  \n__5) manhattanRides_train:__ Trips that don't belong to any of the above  "},{"metadata":{"_uuid":"faa3d028a2a586adbd5babf08fa1cf6323c8d2f3"},"cell_type":"markdown","source":"What would happen if we tried to fit a linear model to manhattanRides_train? What would the expected error be?   \n\nA MSE of about 2.5 USD is not so good. We need to improve our model."},{"metadata":{"trusted":true,"_uuid":"0901975bf8b6988e9474cf1381462c6ac32bb344"},"cell_type":"code","source":"# Fitting a linear model and measuring the MSE\nimport statsmodels.api as sm\n\n# Define function that makes regression and returns params\ndef measureMSE(df):\n    regression = sm.OLS(df['fare_amount'], sm.add_constant(df['distance'])).fit()\n    farepred = regression.predict(sm.add_constant(df['distance'])) \n    mse = np.around(np.sqrt((((df['fare_amount']-farepred)**2).sum())/(df.shape[0])),4)\n    return [regression.params[1], regression.params[0], mse]\n\n# Apply function on manhattanRides_train\nreg = measureMSE(manhattanRides_train)\n\nprint ('Slope: ' + str(np.around(reg[0],2)))\nprint ('Intercept: ' + str(np.around(reg[1],2)))\nprint ('MSE: ' + str(np.around(reg[2],4)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25e60d36ec46dc012c93b677fd4e64b5e8799f0a"},"cell_type":"markdown","source":"We know about the fare rules change. Let's split the data into before and after the fare rules change, plot the graphs and measure the MSE from a linear model in each case.  \n\nThe MSE for the BEFORE section improved while the MSE for the AFTER section worsen."},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"362e4262f578a6960216be251cef20784ee6ba67"},"cell_type":"code","source":"# Split the train set into before the fare rule change and after the fare rule change\nmanhattanRidesBefore = manhattanRides_train[manhattanRides_train['newRate']==False]\nmanhattanRidesAfter = manhattanRides_train[manhattanRides_train['newRate']==True]\n\n# Fitting a linear model and measuring the MSE\nreg = measureMSE(manhattanRidesBefore)\nprint ('BEFORE - Slope: ' + str(np.around(reg[0],2)))\nprint ('BEFORE - Intercept: ' + str(np.around(reg[1],2)))\nprint ('BEFORE - MSE: ' + str(np.around(reg[2],4)))\n\nreg = measureMSE(manhattanRidesAfter)\nprint ('AFTER - Slope: ' + str(np.around(reg[0],2)))\nprint ('AFTER - Intercept: ' + str(np.around(reg[1],2)))\nprint ('AFTER - MSE: ' + str(np.around(reg[2],4)))\n\n# Plot the 'fare_amount' against the distance of the trip\nplt.figure(figsize = (20,15))\nplt.subplot(2,1,1)\nplt.title('Manhattan Rides before fare change', color = \"b\")\nplt.ylabel('Fare')\nplt.xlabel('Distance in Km')\nplt.scatter(manhattanRidesBefore['distance'], manhattanRidesBefore['fare_amount'], alpha=0.5)\nplt.subplot(2,1,2)\nplt.title('Manhattan Rides after fare change', color = \"g\")\nplt.ylabel('Fare')\nplt.xlabel('Distance in Km')\nplt.scatter(manhattanRidesAfter['distance'], manhattanRidesAfter['fare_amount'], color='green', alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37480b1311126f658a48075c4d1b24fe924abe80"},"cell_type":"markdown","source":"The data above mixes all trips inside Manhattan without any consideration of the day of the week or the hour of the day. Both the day of the week and the hour can have a great impact on traffic and this on the fare. Let's visualize how the plot looks for some specific day/hour combination. Let's also measure the MSE in this case.\n"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"328125c3c3199ec082170b06011c330c3cf09931"},"cell_type":"code","source":"series1 = manhattanRidesBefore[(manhattanRidesBefore['weekday'] == 3) & (manhattanRidesBefore['hour'] == 20)]\nseries2 = manhattanRidesAfter[(manhattanRidesAfter['weekday'] == 3) & (manhattanRidesAfter['hour'] == 20)]\n\n# Fitting a linear model and measuring the MSE\nreg = measureMSE(series1)\nprint ('BEFORE - Specifc daytime - Slope: ' + str(np.around(reg[0],2)))\nprint ('BEFORE - Specifc daytime - Intercept: ' + str(np.around(reg[1],2)))\nprint ('BEFORE - Specifc daytime - MSE: ' + str(np.around(reg[2],4)))\n\nreg = measureMSE(series2)\nprint ('AFTER - Specifc daytime - Slope: ' + str(np.around(reg[0],2)))\nprint ('AFTER - Specifc daytime - Intercept: ' + str(np.around(reg[1],2)))\nprint ('AFTER - Specifc daytime - MSE: ' + str(np.around(reg[2],4)))\n\nplt.figure(figsize = (20,15))\nplt.subplot(2,1,1)\nplt.title('Manhattan Rides before fare change, Tuesday at 14pm', color = \"b\")\nplt.ylabel('Fare')\nplt.xlabel('Distance in Km')\nplt.scatter(series1['distance'], series1['fare_amount'], alpha=0.5)\nplt.subplot(2,1,2)\nplt.title('Manhattan Rides after fare change, Tuesday at 14pm', color = \"g\")\nplt.ylabel('Fare')\nplt.xlabel('Distance in Km')\nplt.scatter(series2['distance'], series2['fare_amount'], color='green', alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c33f5764a1268a6323522c7fc1c2e954d592866"},"cell_type":"markdown","source":"This looks much better, and we could try to fit a linear model on this data and measure the MSE."},{"metadata":{"_uuid":"f72ab678bb69d740cdc5080fd8d0b5d29c9e0cb0"},"cell_type":"markdown","source":"Following this idea we can iterate through the days of the week and the hours of the day and obtain the coefficients for that combination. At the end we get 4 tables:  \n\n1) slopeMatrixBefore  \n2) interMatrixBefore  \n3) mseMatrixBefore\n\n4) slopeMatrixAfter  \n5) interMatrixAfter  \n6) mseMatrixAfter\n"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"8c458572d53379d6144a9cb576e8fac5a805d0d2"},"cell_type":"code","source":"weekdaysOpt = [0,1,2,3,4,5,6]\nhoursOpt = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n\nslopeMatBefore = np.zeros((7, 24))\ninterMatBefore = np.zeros((7, 24))\nmseMatBefore = np.zeros((7, 24))\n\nslopeMatAfter = np.zeros((7, 24))\ninterMatAfter = np.zeros((7, 24))\nmseMatAfter = np.zeros((7, 24))\n\nfor i in weekdaysOpt:\n    for j in hoursOpt:\n        series1 = manhattanRidesBefore[(manhattanRidesBefore['weekday'] == i) & (manhattanRidesBefore['hour'] == j)]\n        reg = measureMSE(series1)\n        slopeMatBefore[i,j] = reg[0]\n        interMatBefore[i,j] = reg[1]        \n        mseMatBefore[i,j] = reg[2] \n        \n        series2 = manhattanRidesAfter[(manhattanRidesAfter['weekday'] == i) & (manhattanRidesAfter['hour'] == j)]\n        reg = measureMSE(series2)\n        slopeMatAfter[i,j] = reg[0]\n        interMatAfter[i,j] = reg[1]        \n        mseMatAfter[i,j] = reg[2] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"722d895a667cbc94dabe2a1960b217e79085b100","_kg_hide-input":false},"cell_type":"code","source":"fig = plt.figure(figsize=(30,13))\nax1 = fig.add_subplot(211)\nax1.set_title('MSE by day and hour: Before Fare Rule Change')\nsns.heatmap(mseMatBefore, xticklabels = hoursOpt, yticklabels = weekdaysOpt, annot = True, ax=ax1, cmap='YlOrRd')\nax2 = fig.add_subplot(212)\nax2.set_title('MSE by day and hour: After Fare Rule Change')\nsns.heatmap(mseMatAfter, xticklabels = hoursOpt, yticklabels = weekdaysOpt, annot = True, ax=ax2, cmap='YlOrRd');\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bce30681aa91229f000804bc09ddbb3d4c125ee9"},"cell_type":"markdown","source":"With the slope and intercept matrices we can build a prediction function"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"f44ecb5641030b819634ee1a4d101c8d4699effb"},"cell_type":"code","source":"def predictManhattan(hour, day, new, distance, slopeMatBefore, interMatBefore, slopeMatAfter, interMatAfter):\n    \n    if new:\n        slope = slopeMatAfter[day, hour]\n        inter = interMatAfter[day, hour]\n    else:\n        slope = slopeMatBefore[day, hour]\n        inter = interMatBefore[day, hour]  \n        \n    fare = inter + slope*distance\n    \n    return fare","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3ece50e9f702b788e4d4ad3843183df337724b4"},"cell_type":"markdown","source":"Let's use this function to see the expected average MSE using the same training_set"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"a2729b9f3c37dfbd42531b7e961ca94c5e028fd8"},"cell_type":"code","source":"predictions = manhattanRides_train.apply(lambda row: predictManhattan(row['hour'], row['weekday'], row['newRate'], row['distance'], slopeMatBefore, interMatBefore, slopeMatAfter, interMatAfter), axis=1)\nprint('The in-sample Average MSE is: ' + str(np.around(np.sqrt((((manhattanRides_train['fare_amount']-predictions)**2).sum())/manhattanRides_train.shape[0]),3)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea384cad4314270f516f1f9373c69083e3a41ee6"},"cell_type":"markdown","source":"Let's repeat using the test_set now"},{"metadata":{"trusted":true,"_uuid":"cf345046cdffe29c5410fdcbb0030de00bd6ac12","_kg_hide-input":false},"cell_type":"code","source":"predictions = manhattanRides_test.apply(lambda row: predictManhattan(row['hour'], row['weekday'], row['newRate'], row['distance'], slopeMatBefore, interMatBefore, slopeMatAfter, interMatAfter), axis=1)\nprint('The out-of-sample average MSE is: ' + str(np.around(np.sqrt((((manhattanRides_test['fare_amount']-predictions)**2).sum())/manhattanRides_test.shape[0]),3)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"a790d22e2c043c3865e218500814a2fa04357943"},"cell_type":"markdown","source":"An out of sample MSE of 2.8 is not bad, but we can make it better if we understand more about the filtered cases (short distance trips, fixed value trips, etc)."},{"metadata":{"_uuid":"c9f41c573efaf95ed0706776b76904d98b41b995"},"cell_type":"markdown","source":"Now we can have a look at the 4 cases that we filtered from the training set, they were:  \n\n__1) manhattanRides_shortDist:__  Trips with distance below 0.3 km  \n__2) manhattanRides_highValue:__   Trips with fare_amounts above 75 USD  \n__3) manhattanRides_lowValue:__  Trips with fare amounts below 3 USD  \n__4) manhattanRides_straightLines:__  Trips with fixed amount despite distance (usually between 45 and 60 USD)  "},{"metadata":{"_uuid":"e851aa51a282044e2abe0d62892489eb0ec4a6b0"},"cell_type":"markdown","source":"Visualize the pickup location and the dropoff location of the different groups:  \n\n1) manhattanRides_shortDist:  __blue__  \n2) manhattanRides_highValue:   __red__    \n3) manhattanRides_lowValue:  __green__  \n4) manhattanRides_straightLines: __yellow__   "},{"metadata":{"_kg_hide-input":false,"trusted":true,"scrolled":false,"_uuid":"d0eee4ccb1f7baf6d650a64cffbaf71ec7f7fba9"},"cell_type":"code","source":"def addMarkerPick(df, color, m1, m2):\n    samples = df.sample(n=min(300,df.shape[0]))\n    for lt, ln in zip(samples['pickup_latitude'], samples['pickup_longitude']):\n            folium.Circle(location = [lt,ln] ,radius = 2, color = color).add_to(m1)\n    for lt, ln in zip(samples['dropoff_latitude'], samples['dropoff_longitude']):\n            folium.Circle(location = [lt,ln] ,radius = 2, color = color).add_to(m2)\n        \nm1 = folium.Map(location=[40.7631, -73.9712], zoom_start=13)\nm2 = folium.Map(location=[40.7631, -73.9712], zoom_start=13)\n\naddMarkerPick(manhattanRides_shortDist, 'blue', m1, m2)\naddMarkerPick(manhattanRides_highValue, 'red', m1, m2)\naddMarkerPick(manhattanRides_lowValue, 'green', m1, m2)\naddMarkerPick(manhattanRides_straightLines, 'yellow', m1, m2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cf1d353b07d92bd8d285e53ae802fda10f55e2d"},"cell_type":"code","source":"m1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a03a6d442c00bf231bcd699fcfc75e08035f4e70"},"cell_type":"code","source":"m2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5c1f7581d23aac5aa5f47826d4980a3a34cddf7"},"cell_type":"markdown","source":"There is not much grographical information or pattern to help us understand why these rides behave so strange."},{"metadata":{"_uuid":"25603ec4abc50e43ad92f34ef71b1b13a4120ea5"},"cell_type":"markdown","source":"# JFK - Manhattan airport rides  \n\nThe next group of rides are rides between JFK and Manhattan. This rides have very specific rules as we've seen at the beggining of the notebook. Let's first get all the rides of this kind."},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"d80946a5400fb3f75b32e1945359285414b18f74"},"cell_type":"code","source":"# One end has to be JFK\njfk_lat_min = 40.626777\njfk_lat_max = 40.665599\njfk_lon_min = -73.823964\njfk_lon_max = -73.743085\n\n# Filter trips originating on JFK\ndf_fromJFK = df_train[(df_train['pickup_latitude']<jfk_lat_max)&\n                      (df_train['pickup_latitude']>jfk_lat_min)&\n                      (df_train['pickup_longitude']<jfk_lon_max)&\n                      (df_train['pickup_longitude']>jfk_lon_min)]\n\n# Filter trips ending on JFK\ndf_toJFK = df_train[(df_train['dropoff_latitude']<jfk_lat_max)&\n                    (df_train['dropoff_latitude']>jfk_lat_min)&\n                    (df_train['dropoff_longitude']<jfk_lon_max)&\n                    (df_train['dropoff_longitude']>jfk_lon_min)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95cb936a1e6994deed106258babf146889b1479d","_kg_hide-input":false},"cell_type":"code","source":"# The other end has to be Manhattan\ndf_fromJFK = df_fromJFK[df_fromJFK[['dropoff_latitude', 'dropoff_longitude']].apply(lambda row: polygon.contains(Point(row['dropoff_longitude'],row['dropoff_latitude'])), axis=1)]\ndf_toJFK = df_toJFK[df_toJFK[['pickup_latitude', 'pickup_longitude']].apply(lambda row: polygon.contains(Point(row['pickup_longitude'],row['pickup_latitude'])), axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f9c58c1defa9507a8885f9cbd8f40709bd53766"},"cell_type":"markdown","source":"Let's check how many of the rides are this type of rides"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"5ea447cc5f72a40579730dc953e2f831ab076d39"},"cell_type":"code","source":"print('Percentage of trips between JFK and Manhattan: ' + str(np.around(100*(df_fromJFK.shape[0] + df_toJFK.shape[0])/df_train.shape[0],2)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2346b7faab632afd58df802c1414cee40f73c34d"},"cell_type":"markdown","source":"Quick look to the exact locations inside JFK for pickups and dropoffs:  \n\nBLUE --> Pickup  \nRED --> Dropoff  "},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6b5ce0f68f8c2a5bffad5ad203fcd118ab664f38"},"cell_type":"code","source":"m1 = folium.Map(location=[40.645580, -73.785115], zoom_start=16)\nsamples = df_fromJFK.sample(n=min(500,df_fromJFK.shape[0]))\nfor lt, ln in zip(samples['pickup_latitude'], samples['pickup_longitude']):\n            folium.Circle(location = [lt,ln] ,radius = 2, color = 'blue').add_to(m1)\n            \nsamples = df_toJFK.sample(n=min(500,df_toJFK.shape[0]))\nfor lt, ln in zip(samples['dropoff_latitude'], samples['dropoff_longitude']):\n            folium.Circle(location = [lt,ln] ,radius = 2, color = 'red').add_to(m1)\n        \nm1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48418bd9bfd6cf9b2802ae895365adc48930338b"},"cell_type":"markdown","source":"As before, we need to split between before the rate change and after the rate change. Let's have a visual look:"},{"metadata":{"trusted":true,"_uuid":"cf439ffdc74ced504cfef6cbf9cfa1e8d3767a61","_kg_hide-input":false},"cell_type":"code","source":"# Plot a histogram of the fares\nplt.figure(figsize = (25,10))\nplt.subplot(2,2,1)\nplt.title('Old rate, from JFK to Manhattan',color = \"b\")\nsns.distplot(df_fromJFK[df_fromJFK['newRate']==False]['fare_amount'], norm_hist=True, bins=np.arange(a,b))\nplt.subplot(2,2,2)\nplt.title('Old rate, from Manhattan to JFK',color = \"b\")\nsns.distplot(df_toJFK[df_toJFK['newRate']==False]['fare_amount'], norm_hist=True, bins=np.arange(a,b))\nplt.subplot(2,2,3)\nplt.title('New rate, from JFK to Manhattan',color = \"b\")\nsns.distplot(df_fromJFK[df_fromJFK['newRate']==True]['fare_amount'], norm_hist=True, bins=np.arange(a,b), color='green')\nplt.subplot(2,2,4)\nplt.title('New rate, from Manhattan to JFK',color = \"b\")\nsns.distplot(df_toJFK[df_toJFK['newRate']==True]['fare_amount'], norm_hist=True, bins=np.arange(a,b), color='green');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68007825e627f3fd3d777c6b1859a25afd2e9000"},"cell_type":"code","source":"# Add a weekend column\ndf_fromJFK['weekend'] = df_fromJFK['weekday'].isin([5,6])==True\ndf_toJFK['weekend'] = df_toJFK['weekday'].isin([5,6])==True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86e6df516f9cd8d77fd913aaf346731f65093506"},"cell_type":"markdown","source":"So far we have a good understanding of the fares between Manhattan and JFK for both before the fare rules change and after the fare rules change. Let's now have a look at how weekday/weekend and the hour of the day plays a role on the fare:"},{"metadata":{"trusted":true,"_uuid":"ad775e1586a62a9e19be2c9fba3e18d090daed5b"},"cell_type":"code","source":" def plotBars(df, newRate, weekend):\n    frfr = df[(df['newRate']==newRate)&(df['weekend']==weekend)]\n    sns.barplot(x='hour',y='fare_amount', data = frfr, edgecolor=\".1\", errcolor = 'red')\n       \n# Plot every combination\nplt.figure(figsize = (23,25))\nplt.subplot(4,2,1)\nplt.title('Old rate, from JFK to Manhattan, not weekend',color = \"b\")\nplotBars(df_fromJFK, False, False)\nplt.subplot(4,2,2)\nplt.title('Old rate, from JFK to Manhattan, weekend',color = \"b\")\nplotBars(df_fromJFK, False, True)\nplt.subplot(4,2,3)\nplt.title('New rate, from JFK to Manhattan, not weekend',color = \"b\")\nplotBars(df_fromJFK, True, False)\nplt.subplot(4,2,4)\nplt.title('New rate, from JFK to Manhattan, weekend',color = \"b\")\nplotBars(df_fromJFK, True, True)\nplt.subplot(4,2,5)\nplt.title('Old rate, from Manhattan to JFK, not weekend',color = \"b\")\nplotBars(df_toJFK, False, False)\nplt.subplot(4,2,6)\nplt.title('Old rate, from Manhattan to JFK, weekend',color = \"b\")\nplotBars(df_toJFK, False, True)\nplt.subplot(4,2,7)\nplt.title('New rate, from Manhattan to JFK, not weekend',color = \"b\")\nplotBars(df_toJFK, True, False)\nplt.subplot(4,2,8)\nplt.title('New rate, from Manhattan to JFK, weekend',color = \"b\")\nplotBars(df_toJFK, True, True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94641365e9e8289df1b3685bb85d35555a4606cc"},"cell_type":"markdown","source":"There is clearly an influence on weekday/weekend and on the time of the day. Specially during the night the fare average decreases and the standar deviation increases considerably. Thinking on doing predictions, we could just check the attributes of the taxi ride (day of week, hour of day, before/after fare rule change) and return the mean for that combination as we see in the figures above. That would give us a fair estimate but not perfect.  \n\nOther option is to keep investigating the reason for the standard deviation on each column. My bet is that it is because of a toll (bridge, tunnel) depending on location inside Manhattan but I won't investigate that. Let's build the resulting matrix that will function as a check table when predicting."},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"f678116baf67330a25037352426667f676b11d25"},"cell_type":"code","source":"# Define options\nweekendOpt = [0, 1]\nhoursOpt = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n\n# Initialize matrices\noldFromJFKtoMAN = np.zeros((2, 24))\nnewFromJFKtoMAN = np.zeros((2, 24))\noldFromMANtoJFK = np.zeros((2, 24))\nnewFromMANtoJFK = np.zeros((2, 24))\n\n# Run combiantions\nfor i in weekendOpt:\n    for j in hoursOpt:\n        \n        mean = df_fromJFK[(df_fromJFK['newRate']==False)&(df_fromJFK['weekend']==i)&(df_fromJFK['hour']==j)]['fare_amount'].mean()\n        oldFromJFKtoMAN[i,j] = mean\n        \n        mean = df_fromJFK[(df_fromJFK['newRate']==True)&(df_fromJFK['weekend']==i)&(df_fromJFK['hour']==j)]['fare_amount'].mean()\n        newFromJFKtoMAN[i,j] = mean\n        \n        mean = df_toJFK[(df_toJFK['newRate']==False)&(df_toJFK['weekend']==i)&(df_toJFK['hour']==j)]['fare_amount'].mean()\n        oldFromMANtoJFK[i,j] = mean\n        \n        mean = df_toJFK[(df_toJFK['newRate']==True)&(df_toJFK['weekend']==i)&(df_toJFK['hour']==j)]['fare_amount'].mean()\n        newFromMANtoJFK[i,j] = mean","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"ce56074e6070430e47508ef91019c679b63c4916"},"cell_type":"code","source":"# This are the prediction matrices\noldFromJFKtoMAN;\nnewFromJFKtoMAN;\noldFromMANtoJFK;\nnewFromMANtoJFK;","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3644e7e1721f056b7b1dfb9479aaa7c21c2f3f68"},"cell_type":"markdown","source":"Let's evaluate our model using the same data:"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"d363b672679d10dd727f97460a3929c591b06d92"},"cell_type":"code","source":"# Prediction function\ndef predictAirport(isfrom, new, weekend, hour, oldFromJFKtoMAN, newFromJFKtoMAN, oldFromMANtoJFK, newFromMANtoJFK):\n    if isfrom:\n        if new:\n            fare = newFromJFKtoMAN[weekend, hour]\n        else:\n            fare = oldFromJFKtoMAN[weekend, hour]\n    else:\n        if new:\n            fare = newFromMANtoJFK[weekend, hour]\n        else:\n            fare = oldFromMANtoJFK[weekend, hour]            \n    return fare","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"f0d956dc0371e9e037e405da7ea025b549318bb4"},"cell_type":"code","source":"# From JFK\npredictions = df_fromJFK.apply(lambda row: predictAirport(True, row['newRate'], row['weekend']*1, row['hour'], oldFromJFKtoMAN, newFromJFKtoMAN, oldFromMANtoJFK, newFromMANtoJFK), axis=1)\nprint('From JFK to Manhattan the MSE is: ' + str(np.around(np.sqrt((((df_fromJFK['fare_amount']-predictions)**2).sum())/df_fromJFK.shape[0]),3)))\n\n# To JFK\npredictions = df_toJFK.apply(lambda row: predictAirport(False, row['newRate'], row['weekend']*1, row['hour'], oldFromJFKtoMAN, newFromJFKtoMAN, oldFromMANtoJFK, newFromMANtoJFK), axis=1)\nprint('From Manhattan to JFK the MSE is: ' + str(np.around(np.sqrt((((df_toJFK['fare_amount']-predictions)**2).sum())/df_toJFK.shape[0]),3)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3ef3d5105462b1688eafc1cb62f5c0f94179890"},"cell_type":"markdown","source":"It is not as good as for trips inside Manhattan but it's good enough for now"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}