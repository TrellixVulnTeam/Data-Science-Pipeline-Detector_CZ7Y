{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#install tensorflowv2\n! pip install tensorflow==2.0.0-rc0 \nimport tensorflow as tf\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#loading dataset\ntrain_iop_path='/kaggle/input/new-york-city-taxi-fare-prediction/train.csv'\ntest_iop_path='/kaggle/input/new-york-city-taxi-fare-prediction/test.csv'\ndataset_train=pd.read_csv(train_iop_path, nrows=10_000, index_col='key')\ndataset_test=pd.read_csv(test_iop_path, nrows=10000, index_col='key')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nprint(\"dataset_train old size\", len(dataset_train))\n\ndataset_train = dataset_train[dataset_train.dropoff_longitude != 0]\nprint(\"new size\", len(dataset_train))\ndataset_train.head(5)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"dataset_test old size\", len(dataset_test))\n\ndataset_test = dataset_test[dataset_test.dropoff_longitude != 0]\nprint(\"new size\", len(dataset_test))\ndataset_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_year(pickup_date):\n  return pickup_date.year\ndef get_month(pickup_date):\n  return pickup_date.month\ndef get_day(pickup_date):\n  return pickup_date.day\ndef get_hour(pickup_date):\n  return pickup_date.hour       \n     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime as dt\nimport warnings\n\ndef preparedataset2(datasetname):\n    warnings.filterwarnings(\"ignore\")\n    datasetname.info()\n    datasetname['pickup_datetime']= pd.to_datetime(datasetname['pickup_datetime']) \n    datasetname['pickup_year'] = datasetname.apply(lambda x: get_year(x['pickup_datetime']),axis=1)\n    datasetname['pickup_month'] = datasetname.apply(lambda x: get_month(x['pickup_datetime']),axis=1)\n    datasetname['pickup_day'] = datasetname.apply(lambda x: get_day(x['pickup_datetime']),axis=1)\n    datasetname['pickup_hour'] = datasetname.apply(lambda x: get_hour(x['pickup_datetime']),axis=1)\n    datasetname['x_dis'] = (datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])  \n    datasetname['y_dis'] = (datasetname['dropoff_latitude'] - datasetname['pickup_latitude']) \n    datasetname['dis'] = ((datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])**2 + (datasetname['dropoff_latitude']-datasetname['pickup_latitude'])**2)**.5 \n    datasetname=datasetname.drop(['pickup_datetime'],axis=1)\n    datasetname=datasetname.drop(['pickup_longitude'],axis=1)\n    datasetname=datasetname.drop(['dropoff_latitude'],axis=1)\n    datasetname=datasetname.drop(['dropoff_longitude'],axis=1)\n    datasetname=datasetname.drop(['pickup_latitude'],axis=1)\n\n   # datasetname.info()\n    return datasetname\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#old preprocesing \nfrom datetime import datetime as dt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndef preparedataset(datasetname):\n    datasetname['pickup_year']=0\n    datasetname['pickup_month']=0\n    datasetname['pickup_day']=0\n    datasetname['pickup_hour']=0\n  #  datasetname['pickup_minute']=0\n #   datasetname['pickup_second']=0\n    datasetname['dis'] =0\n    datasetname['x_dis']=0\n    datasetname['y_dis']=0\n    \n    datasetname.head()\n#print(datetime.strptime(df['pickup_datetime'][0].replace(\"UTC\",''),\"%Y-%m-%d %H:%M:%S \"))\n\n    for k in range(len(datasetname.index)):\n        datetime=dt.strptime(datasetname['pickup_datetime'][k].replace(\"UTC\",''),\"%Y-%m-%d %H:%M:%S \")\n        datasetname['pickup_year'][k]=datetime.year\n        datasetname['pickup_month'][k]=datetime.month\n        datasetname['pickup_day'][k]=datetime.day\n        datasetname['pickup_hour'][k]=datetime.hour\n      # datasetname['pickup_minute'][k]=datetime.minute\n      # datasetname['pickup_second'][k]=datetime.second\n        \n    datasetname['x_dis'] = (datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])  \n    datasetname['y_dis'] = (datasetname['dropoff_latitude'] - datasetname['pickup_latitude']) \n    datasetname['dis'] = ((datasetname['dropoff_longitude'] - datasetname['pickup_longitude'])**2 + (datasetname['dropoff_latitude']-datasetname['pickup_latitude'])**2)**.5 \n    datasetname=datasetname.drop(['pickup_datetime'],axis=1)\n    datasetname=datasetname.drop(['pickup_longitude'],axis=1)\n    datasetname=datasetname.drop(['dropoff_latitude'],axis=1)\n    datasetname=datasetname.drop(['dropoff_longitude'],axis=1)\n    datasetname=datasetname.drop(['pickup_latitude'],axis=1)\n\n    return datasetname\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=preparedataset2(dataset_train)\ndf.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=preparedataset2(dataset_test)\ntest_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#spliting the dataset \nfrom sklearn.model_selection import train_test_split\ny = df.fare_amount\nX=df.drop('fare_amount',axis=1)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying XCbossting \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nresult={}\nbest_istemator=0\nbest_learing_rate=0\nbest_mae=100000000000\nfor lr in [X / 100 for X in range(10,50, 5)]:\n    for ns in range(200,701,50):\n        #print(\"n_estimators\",ns)\n        #print(\"learning_rate\",lr)\n        my_model = XGBRegressor(n_estimators=ns, learning_rate=lr,n_jobs=4)\n        my_model.fit(X_train, y_train)\n\n        predictions = my_model.predict(X_valid)\n\n        mae=mean_absolute_error(predictions, y_valid)\n        if(mae < best_mae):\n            best_mae=mae\n            best_istemator=ns\n            best_learing_rate=lr\n            print(\"better found\")\n            print(ns , lr, mae)\n        result[(ns,lr)]=mae\nmy_model_2 = XGBRegressor(n_estimators=best_istemator, learning_rate=best_learing_rate, n_jobs=4)\nmy_model_2.fit(X_train,y_train)\npredictions_2 = my_model_2.predict(X_valid)\nmae_2 = mean_absolute_error( y_valid, predictions_2) \n# Uncomment to print MAE\nprint(\"best_istemator:\" , best_istemator)\nprint(\"best_learing_rate:\" , best_learing_rate)\nprint(\"Mean Absolute Error:\" , mae_2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"best paramter so far 700 0.25 1.88\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nmy_model_2 = XGBRegressor(n_estimators=700, learning_rate=0.2, n_jobs=4)\nmy_model_2.fit(X_train,y_train)\n\ntest_preds = my_model_2.predict(test_df)\n\noutput = pd.DataFrame({'key': test_df.index,\n                      'fare_amount': test_preds})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}