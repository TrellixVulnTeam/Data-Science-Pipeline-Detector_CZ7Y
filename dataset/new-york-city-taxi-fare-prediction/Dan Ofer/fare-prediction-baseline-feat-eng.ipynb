{"cells":[{"metadata":{"_uuid":"220a611faaf5fde16d3f89b2431679f35af9cb16"},"cell_type":"markdown","source":"#### Modified slightly for a niave baseline\n* Distance wise: we should use Manhattan/cab distance (rectangles, not straight lines, as there's no diagonal in manhattan).\n* I get a sample of data instead of just the head. \n    * Ideally -  downsample randomly + get a temporally stratified sample based on aiming to overfit the test set.  BUT data is randomly sampled anyway, so likely doesn;'t matter\n* ToDo: more distance, speed, geographic clusters, more datetime/clustering features.."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# Data processing\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport random\n# Visualization libaries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\n# check if date is a holiday:\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b535daff430f0377009c289f8133f0526d96bfbc","collapsed":true},"cell_type":"code","source":"# Read data\ntrain = pd.read_csv('../input/train.csv', nrows = 11123456)\n\n#reading in sampled data misses the header row - need to debug\n# n = 55000000 #Approx number of records in file as given in competition description\n# s = 3123456 #desired sample size ~ a few million for now\n# skip = sorted(random.sample(range(n+1),n-s))\n# train = pd.read_csv('../input/train.csv', skiprows=skip,header=0) # sample data. Explicitly note that there's a header, otherwise we can skip it when sampling! \n\ntrain['pickup_datetime'] = pd.to_datetime(train.pickup_datetime,infer_datetime_format=True)\n\ntrain.dropna(how = 'any', axis = 'rows',inplace=True) # drop some outliers/bad data\\\\\n# todo: drop outliers from train based on distances? \nprint(\"train shape:\",train.shape)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1b861f4045510eab2a8a4347bf63eb81b72524c","collapsed":true},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime,infer_datetime_format=True)\nprint(\"test size:\", test.shape)\nprint('Test NaN values ?:')\nprint(test.isnull().sum()) # no nans in the test, unlike the train data\n\ntest.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1804b4fb5493a38776dd8cd4d4136b3bd9b18880","collapsed":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3edc6a0473735fe4042cf3a622414e2409944c9f","collapsed":true},"cell_type":"code","source":"# Remove some potential location outliers:\n## Taken from : https://www.kaggle.com/judesen/fare-prediction\n## Ideally, check if test also has the extreme values or data errors.. \n\n# Latitude and longitude varies from -3116.28 to 2522.27 whereas the mean is around 40 (pickup_latitude, but goes for all the coordinates)\n# This is probably due to a typo when data was gathered. Let's select a more reasonable value (2 times the standard deviation)\n#columns_to_select = ['fare_amount', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n#for column in columns_to_select:\n#    train = train.loc[(train[column] > train[column].mean() - train[column].std() * 2) & (train[column] < train[column].mean() + train[column].std() * 2)]\n\n# Manually picking reasonable levels until I find a smarter way\ntrain = train.loc[(train['fare_amount'] >= 0) & (train['fare_amount'] < 250)]\ntrain = train.loc[(train['pickup_longitude'] > -90) & (train['pickup_longitude'] < 80) & (train['pickup_latitude'] > -80) & (train['pickup_latitude'] < 80)]\ntrain = train.loc[(train['dropoff_longitude'] > -90) & (train['dropoff_longitude'] < 80) & (train['dropoff_latitude'] > -80) & (train['dropoff_latitude'] < 80)]\n\n\n# Let's assume tax's can be mini-busses as well\ntrain = train.loc[train['passenger_count'] <= 7]\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"988f5351897868708b4e84930c85dbcb567babee","collapsed":true},"cell_type":"code","source":"combine = [train, test]\n# test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"for dataset in combine:\n    # Distance is expected to have an impact on the fare\n    dataset['longitude_distance'] = abs(dataset['pickup_longitude'] - dataset['dropoff_longitude'])\n    dataset['latitude_distance'] = abs(dataset['pickup_latitude'] - dataset['dropoff_latitude'])\n    \n    # Straight distance\n    dataset['distance_travelled'] = (dataset['longitude_distance'] ** 2 * dataset['latitude_distance'] ** 2) ** .5\n#     dataset['distance_travelled_sin'] = np.sin((dataset['longitude_distance'] ** 2 * dataset['latitude_distance'] ** 2) ** .5)\n#     dataset['distance_travelled_cos'] = np.cos((dataset['longitude_distance'] ** 2 * dataset['latitude_distance'] ** 2) ** .5)\n    \n#     dataset['distance_travelled_sin_sqrd'] = np.sin((dataset['longitude_distance'] ** 2 * dataset['latitude_distance'] ** 2) ** .5) ** 2\n#     dataset['distance_travelled_cos_sqrd'] = np.cos((dataset['longitude_distance'] ** 2 * dataset['latitude_distance'] ** 2) ** .5) ** 2\n    \n    # Haversine formula for distance\n    # Haversine formula:\ta = sin²(Δφ/2) + cos φ1 ⋅ cos φ2 ⋅ sin²(Δλ/2)\n    # c = 2 ⋅ atan2( √a, √(1−a) )\n    # d = R ⋅ c\n    R = 6371e3 # Metres\n    phi1 = np.radians(dataset['pickup_latitude'])\n    phi2 = np.radians(dataset['dropoff_latitude'])\n    phi_chg = np.radians(dataset['pickup_latitude'] - dataset['dropoff_latitude'])\n    delta_chg = np.radians(dataset['pickup_longitude'] - dataset['dropoff_longitude'])\n    a = np.sin(phi_chg / 2) + np.cos(phi1) * np.cos(phi2) * np.sin(delta_chg / 2)\n    c = 2 * np.arctan2(a ** .5, (1-a) ** .5)\n    d = R * c\n    dataset['haversine'] = d\n    \n    # Bearing\n    # Formula:\tθ = atan2( sin Δλ ⋅ cos φ2 , cos φ1 ⋅ sin φ2 − sin φ1 ⋅ cos φ2 ⋅ cos Δλ )\n    y = np.sin(delta_chg * np.cos(phi2))\n    x = np.cos(phi1) * np.sin(phi2) - np.sin(phi1) * np.cos(phi2) * np.cos(delta_chg)\n    dataset['bearing'] = np.degrees(np.arctan2(y, x))\n    \n#     # Rhumb lines\n    psi_chg = np.log(np.tan(np.pi / 4 + phi2 / 2) / np.tan(np.pi / 4 + phi1 / 2))\n    q = phi_chg / psi_chg\n    d = (phi_chg + q ** 2 * delta_chg ** 2) ** .5 * R\n    dataset['rhumb_lines'] = d\n    \n    # Maybe time of day matters? Obviously duration is a factor, but there is no data for time arrival\n    # Features: hour of day (night vs day), month (some months may be in higher demand) \n    \n#     dataset['pickup_datetime'] = pd.to_datetime(test['pickup_datetime']) # orig, used only test??\n#     dataset['pickup_datetime'] = pd.to_datetime(dataset['pickup_datetime'],infer_datetime_format=True) # new - may be wrong? \n    \n    dataset['hour_of_day'] = dataset.pickup_datetime.dt.hour\n    dataset['day'] = dataset.pickup_datetime.dt.day\n#     dataset['week'] = dataset.pickup_datetime.dt.week\n    dataset['month'] = dataset.pickup_datetime.dt.month\n    dataset[\"dayofweek\"] = dataset.pickup_datetime.dt.dayofweek\n#     dataset['day_of_year'] = dataset.pickup_datetime.dt.dayofyear\n\n#     dataset['week_of_year'] = dataset.pickup_datetime.dt.weekofyear\n    \n    # check if holiday. Can try other calendars: https://stackoverflow.com/questions/29688899/pandas-checking-if-a-date-is-a-holiday-and-assigning-boolean-value\n    cal = calendar()\n    holidays = cal.holidays()\n    dataset[\"usFedHoliday\"] =  dataset.pickup_datetime.dt.date.astype('datetime64').isin(holidays)\n    \n    print(dataset.shape)\n    \ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ddce6cb0e8449a82f74bba090aacf92b230d12a2"},"cell_type":"markdown","source":"### Drop trip distance outliers:"},{"metadata":{"trusted":true,"_uuid":"982d3b1c9971a1038e893e7e555df6d5ef79e88a","collapsed":true},"cell_type":"code","source":"train['distance_travelled'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8e7401171984082bb229f42d56af1ca256a1d0e7","collapsed":true},"cell_type":"code","source":"test['distance_travelled'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9f2d1455c44e4101e102212901d6d86085bb746","collapsed":true},"cell_type":"code","source":"train = train.loc[train['distance_travelled']< 0.6]\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8889da99306cf4111d41341481cc67c210880a8d","collapsed":true},"cell_type":"code","source":"print(test.shape)\nprint(test.dropna().shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31c2b2977a25b5658b487801153bb2256e6504aa","collapsed":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afe593bd294b19ded2414502cb6067e496d6c1b1","collapsed":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2481d03f8eda465b1eddcbfcf97d0e00130fb94f"},"cell_type":"markdown","source":"#### Features correlation plot:"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"39def2ffb283d945d6d1287c91cbe489ef1040d5","collapsed":true},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(20,20))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cec893be34e814522c8945ba0e9959a712536d6","collapsed":true},"cell_type":"code","source":"# Drop irrelevant features\n# We drop the key\n\n# train_features_to_keep = ['haversine', 'fare_amount']\n# train.drop(train.columns.difference(train_features_to_keep), 1, inplace=True)\n\ntrain.drop([\"key\",\"pickup_datetime\"],axis=1,inplace=True)\ntrain.dropna(inplace=True)\n\n# test_features_to_keep = ['key', 'haversine']\n# test.drop(test.columns.difference(test_features_to_keep), 1, inplace=True)\n\ntest.drop([\"pickup_datetime\"],axis=1,inplace=True) # keep key in data for submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5eb984e34364949f052e7a603be5cb428fe2222","scrolled":true,"collapsed":true},"cell_type":"code","source":"# Let's prepare the test set\nx_pred = test.drop('key', axis=1)\n\n# Let's run XGBoost and predict those fares!\nx_train,x_test,y_train,y_test = train_test_split(train.drop('fare_amount',axis=1),train.pop('fare_amount'),random_state=126,test_size=0.16)\n\ndef XGBmodel(x_train,x_test,y_train,y_test):\n    matrix_train = xgb.DMatrix(x_train,label=y_train)\n    matrix_test = xgb.DMatrix(x_test,label=y_test)\n    model=xgb.train(params={'objective':'reg:linear','eval_metric':'rmse'}\n                    ,dtrain=matrix_train,num_boost_round=350, \n                    early_stopping_rounds=15,evals=[(matrix_test,'test')],)\n    return model\n\nmodel=XGBmodel(x_train,x_test,y_train,y_test)\nprediction = model.predict(xgb.DMatrix(x_pred), ntree_limit = model.best_ntree_limit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c9728f5c59bc7a50a93a1d7b2d5e9e17914785d3"},"cell_type":"code","source":"# Add to submission\nsubmission = pd.DataFrame({\n        \"key\": test['key'],\n        \"fare_amount\": prediction.round(3)\n})\n\nsubmission.to_csv('sub_fare.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f375bd4ce358439c382a14594d8f3b79e211140","scrolled":true,"collapsed":true},"cell_type":"code","source":"print(submission.shape)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}