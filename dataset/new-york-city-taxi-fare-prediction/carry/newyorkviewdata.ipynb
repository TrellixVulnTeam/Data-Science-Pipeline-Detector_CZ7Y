{"cells":[{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"acd5a14be284d42d283cb63affcf7ec6bdcff182","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\nimport xgboost as xgb\nfrom sklearn import metrics\nfrom pandas import Series, DataFrame\nfrom sklearn.model_selection import train_test_split,cross_val_predict,cross_val_score, ShuffleSplit\nfrom sklearn.model_selection import GridSearchCV,KFold\nimport matplotlib.pylab as plt\nimport matplotlib.pyplot as plot\nfrom matplotlib.pyplot import savefig\nfrom matplotlib.pylab import rcParams\nimport time\nimport seaborn as sns\nfrom scipy import stats,integrate\nimport datetime","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6db90eb001beafa1e5edbb2969243f31a59e23b3","trusted":true},"cell_type":"code","source":"def rad(d):\n    return d * np.pi / 180.0\ndef GetDistance(lon1,lat1,lon2,lat2):\n    EARTH_RADIUS = 6378137 #赤道半径\n    radLat1 = rad(lat1)\n    radLat2 = rad(lat2)\n    a = radLat1 - radLat2\n    b = rad(lon1) - rad(lon2)\n    s = 2 * np.arcsin(np.sqrt((np.sin(a/2)**2)+np.cos(radLat1)*np.cos(radLat2)*(np.sin(b/2)**2)))\n    s = s * EARTH_RADIUS\n    return s\n\ndef GetDate(date_time):\n    return date_time[:10]\n\ndef GetDate_time(date_time):\n    if(int(date_time[-9:-7]) > 30):\n        return (int(date_time[-12:-10])+1)% 24\n    else:\n        return int(date_time[-12:-10])\ndef GetDate_year(x):\n    return int(x[:4])\ndef GetDate_month(x):\n    return int(x[5:7])\ndef GetDate_day(x):\n    return int(x[8:])\ndef func(x,y):\n    if(x > 0.00 and y > 0.00):\n        return y/x\n    else:\n        return -1\ndef week_get(date):    \n    return int(datetime.datetime(int(date[:4]),int(date[5:7]),int(date[8:])).strftime(\"%w\")) # strftime(\"%a\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5aa8eb4c53d6feaf7ead253ec97eb0e4a96a633","trusted":true},"cell_type":"code","source":"\ndef data_deal(chunk,tag):\n    chunk['distance'] = GetDistance(chunk['pickup_longitude'],chunk['pickup_latitude'],chunk['dropoff_longitude'],chunk['dropoff_latitude'])/1000.0\n    chunk['date'] = chunk['pickup_datetime'].apply(lambda x:GetDate(x))\n    chunk['year'] = chunk['date'].apply(lambda x:GetDate_year(x))\n    chunk['month'] = chunk['date'].apply(lambda x:GetDate_month(x))\n    chunk['day'] = chunk['date'].apply(lambda x:GetDate_day(x))\n    chunk['time'] = chunk['pickup_datetime'].apply(lambda x:GetDate_time(x))\n    chunk['week'] = chunk.apply(lambda x: week_get(x.date), axis = 1)\n    if(tag == True):        \n        chunk['price'] = chunk.apply(lambda x: func(x.distance, x.fare_amount), axis = 1)\n    return chunk\n\ndef getData_train(train_chunks,allow):\n    chunks = []\n    if(allow == False):        \n        count = 0        \n        while(count < 7):               \n            chunk = train_chunks.get_chunk(10000)\n            chunks.append(data_deal(chunk,True))\n            count += 1\n    else:\n        loop = True    \n        while loop:\n            try:\n                chunk = train_chunks.get_chunk(10000)\n                chunks.append(data_deal(chunk,True))\n            except StopIteration:\n                loop = False\n                print(\"Iteration is stopped.\")\n    return chunks","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9cac63d7912922013bffbb0fec6a86b4199d2640","trusted":true},"cell_type":"code","source":"start = time.time()\n# train_chunks = pd.read_csv('./data/train.csv',iterator = True,engine='python')         \ntrain_chunks = pd.read_csv('../input/train.csv',iterator = True,engine='python')\nchunks = getData_train(train_chunks,False)\ndata_train = pd.concat(chunks, ignore_index=True)\ndata_ = data_train[data_train['price'] >= 0]\ndata_.index = range(len(data_))\nprint(data_.head())\nend = time.time()\nprint(end - start)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"423a2db9478115766fcbdb67bce032f09df7084d","trusted":true},"cell_type":"code","source":"plt.title(\"I'm a scatter diagram.\") \nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.xlim(xmax=24,xmin=-1)\nplt.ylim(ymax=50,ymin=0)\nplt.plot(data_.time,data_.price,'ro')\nplt.show()\n# 某个时间的最高价能看出随时间的大致分布","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19d3933ad6ce076f659457b7297edb0e2f13d492","trusted":true},"cell_type":"code","source":"data = data_.loc[:,'price'].values\n# 统计输出信息\npercentile_result = np.percentile(data, [25, 50, 75])\nnum = 0\nfor i in list(data > percentile_result[2] * 1.5):\n    if(i == True):\n        num+=1\nprint('离群点个数：',num,'\\n四分位数Q3：',percentile_result[2])\nprint(num/len(list(data)))\n# 显示图例\nplt.boxplot(x=data,showmeans=True,meanline=True,whis=1.5)\nplt.legend()\n# 显示图形\nplt.show()\nplt.close()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4eb620e265fe67b33c01e2df8cd553865b5aa255","trusted":true},"cell_type":"code","source":"print(data_.shape[0])\nresult = data_[data_['price'] > percentile_result[2] * 1.5].index.tolist()\ndata_.drop(data_.index[result],inplace=True)\ndata_.index = range(len(data_))\nresult = data_[data_['price'] < percentile_result[0] / 1.5].index.tolist()\ndata_.drop(data_.index[result],inplace=True)\ndata_.index = range(len(data_))\nprint(data_.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"deae4b7f2d515ee335e946039cd19dc877cc1390","trusted":true},"cell_type":"code","source":"from pandas import Categorical\nordered_days = data_.week.value_counts().index\nprint(ordered_days)\n# ordered_days = Categorical([\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"])\nordered_days = Categorical([i for i in range(7)])\n# FacetGrid传数据需要是pandas格式\ng = sns.FacetGrid(data_,row='week',row_order=ordered_days,size=2,aspect=3)\ng.map(sns.boxplot,\"price\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25a0a82d66c6b36703f69c40a137a292cfa61bee","trusted":true},"cell_type":"code","source":"days = [ 'Mon','Tue','Wed','Thu','Fri','Sat','Sun']\ndays_ = [i for i in range(0,7)]\n# print(np.unique(list(data_['week'].values)))\npercentile_day1 = []\npercentile_day2 = []\npercentile_day0 = []\npercentile_day = dict().fromkeys([i for i in days_])\npds = []\nfor i in days_:\n    data = data_[data_['week']== i].price\n#     print(data)\n    # 统计输出信息\n    percentile_result = np.percentile(data, [25, 50, 75])\n    percentile_day0.append(percentile_result[0])\n    percentile_day1.append(percentile_result[1])\n    percentile_day2.append(percentile_result[2])\n    percentile_day[i] = percentile_result\n    num = 0\n    for j in list(data > percentile_result[2] * 1.5):\n        if(j == True):\n            num += 1\n    pds.append([i,num,percentile_result[0],percentile_result[1],percentile_result[2],num/len(list(data))])\npas = pd.DataFrame(pds,columns=['week','离群点个数','Q1','Q2','Q3','离群点占比'])\npas\n#     print('离群点个数：',num,'\\n四分位数Q3：',percentile_result[2])    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55c76f3b06bd53e4fa4fe675ebdd71be754815d9","trusted":true},"cell_type":"code","source":"# 一起绘制对比\nweek_days = [i for i in range(1,8)]\nplt.title('Week Analysis')\nmak = ['*','^','v','o','s','<','>']\nplt.plot(week_days, percentile_day0, color='green', label='25%',marker=mak[0])\nplt.plot(week_days, percentile_day1, color='#873018', label='50%',marker=mak[1])\nplt.plot(week_days, percentile_day2,  color='skyblue', label='75%',marker=mak[2])\nplt.xticks(week_days,days)#将数字转换为字符显示\nplt.xlabel('days')\nplt.ylabel('price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5423a3aa7c0bdd3198c5f8ce95eeecaafed62c6a","trusted":true},"cell_type":"code","source":"# 分开来看\ndef draw_point_plt(data):\n    plt.plot(week_days, data, color='green', label='25%',marker=mak[0])\n    plt.xticks(week_days,days)#将数字转换为字符显示\n    plt.xlabel('days')\n    plt.ylabel('price')\n    plt.show()\n    plt.close()\ndraw_point_plt(percentile_day0)\ndraw_point_plt(percentile_day1)\ndraw_point_plt(percentile_day2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7a7d340b21f2e1381dbfedd18b7c7647402f767","scrolled":true,"trusted":true},"cell_type":"code","source":"d = []\nd.append(days_)\nd.append(percentile_day)\nplt.title('Week Analysis')\ncolor_ = ['#587123','#581223','#587199','#327123','#007123','#127453','#918652']\nmak = ['*','^','v','o','s','<','>']\n# print(percentile_day)\n\nplt.xticks(days_,days)#将数字--->字符显示\nfor i in range(7):\n    day = [i,i,i]\n    plt.plot(day, percentile_day[i], color=color_[i], marker=mak[i])\nplt.plot(days_, percentile_day0, color='green', label='25%')\nplt.plot(days_, percentile_day1, color='#873018', label='50%')\nplt.plot(days_, percentile_day2,  color='skyblue', label='75%')\nplt.legend() # 显示图例\nplt.xlabel('days')\nplt.ylabel('price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d919e0e1e903021fd47b076cc6e620c69c8e19e3","trusted":true},"cell_type":"code","source":"data_.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"882e3e74a3dc2063b4415fb20618b404f853784a","trusted":true},"cell_type":"code","source":"year = []\nfor i in range(2009,2016):\n    year.append(i)\npercentile_year = dict().fromkeys([i for i in year])\npercentile_year0 = []\npercentile_year1 = []\npercentile_year2 = []\npds = []\nfor i in year:    \n    data = data_[data_['year']==i].price\n    # 统计输出信息\n    percentile_result = np.percentile(data, [25, 50, 75])\n    percentile_year0.append(percentile_result[0])\n    percentile_year1.append(percentile_result[1])\n    percentile_year2.append(percentile_result[2])\n    percentile_year[i] = percentile_result\n    num = 0\n    for j in list(data > percentile_result[2] * 1.5):\n        if(j == True):\n            num+=1\n    pds.append([i,num,percentile_result[0],percentile_result[1],percentile_result[2],num/len(list(data))])\npas = pd.DataFrame(pds,columns=['year','离群点个数','Q1','Q2','Q3','离群点占比'])\npas\n#     print('离群点个数：',num,'\\n四分位数Q3：',percentile_result[2])    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62a533f6d72f356585e4d654c903ee11b4b9349e","trusted":true},"cell_type":"code","source":"# 一起绘制对比\nyear_ = [i for i in range(7)]\nplt.title('Year Analysis')\nmak = ['*','^','v','o','s','<','>']\nplt.plot(year_, percentile_year0, color='green', label='25%',marker=mak[0])\nplt.plot(year_, percentile_year1, color='#873018', label='50%',marker=mak[1])\nplt.plot(year_, percentile_year2, color='skyblue', label='75%',marker=mak[2])\nplt.xticks(year_,year)#将数字--->字符显示\nplt.xlabel('year')\nplt.ylabel('price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dffd9420571e4fba26329576f39785fed61f2d2","trusted":true},"cell_type":"code","source":"# 分开来看\ndef draw_point_plt(data):\n    plt.plot(year_, data, color='skyblue', label='75%',marker=mak[2])\n    plt.xticks(year_,year)#将数字--->字符显示\n    plt.xlabel('days')\n    plt.ylabel('price')\n    plt.show()\n    plt.close()\ndraw_point_plt(percentile_year0)\ndraw_point_plt(percentile_year1)\ndraw_point_plt(percentile_year2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e02070488c6efe59ac8cf22c5a10dc1d0a1444ed","trusted":true},"cell_type":"code","source":"# 先训练一波\ndef modelfit(alg, data, labels_, cols, target, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n    # 可以返回n_estimates的最佳数目，为什么呢, 哪里返回？\n    if useTrainCV:\n        xgb_param = alg.get_xgb_params()\n        xgtrain = xgb.DMatrix(data, label=labels_)\n        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n            metrics='rmse', early_stopping_rounds=early_stopping_rounds)\n        alg.set_params(n_estimators=cvresult.shape[0])\n    #Fit the algorithm on the data\n    seed = 10\n    # seed=10从0.11升为了0.2566\n    # Model Report\n    # r2_score : 0.2566\n    # MAE:  0.4723899992310908 %\n    test_size = 0.3\n    x_train,x_test,y_train,y_test = train_test_split(data, labels_, test_size=test_size,random_state=seed)    \n    print(x_train.shape[1],y_train.shape[1])    \n    eval_set = [(x_test,y_test)]\n    alg.fit(x_train, y_train, early_stopping_rounds=early_stopping_rounds, eval_metric='rmse',eval_set=eval_set,verbose=True)        \n    #Predict training set:\n    dtrain_predictions = alg.predict(x_test)\n\n    # print(type(dtrain_predictions),type(labels_))\n    y_true = list(y_test)\n    y_pred = list(dtrain_predictions)\n    \n    #Print model report:\n    print(\"\\nModel Report\")\n    print(\"r2_score : %.4g\" % metrics.r2_score(y_true, y_pred))\n    mae_y = 0.00\n#     for i in range(len(y_true)):\n#         mae_y += np.abs(np.float(y_true[i])-y_pred[i])\n#     print(\"MAE: \", (mae_y*4799+6)/len(y_true))\n    # Model Report\n    # r2_score : 0.9673\n    # MAE:  0.636517748270864 %\n    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)   \n\n    # feat_imp.plot(kind='bar', title='Feature Importances')\n    # plt.ylabel('Feature Importance Score')\n    fig, ax = plt.subplots(1, 1, figsize=(8, 13))    \n    plot_importance(alg, max_num_features=25, height=0.5, ax=ax)\n    plt.show()\n    # 重要性筛选\n    feat_sel = list(feat_imp.index)\n    feat_val = list(feat_imp.values)\n    featur = []\n    for i in range(len(feat_sel)):\n        featur.append([cols[int(feat_sel[i][1:])],feat_val[i]])\n    print('所有特征的score:\\n',featur)\n\n    feat_sel2 = list(feat_imp[feat_imp.values > target].index)    \n    featur2 = []\n    for i in range(len(feat_sel2)):\n        featur2.append(cols[int(feat_sel2[i][1:])])    \n    return featur2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1659354e01c00d7eb197f4363e28e03d1228f5b","trusted":true},"cell_type":"code","source":"def MAE_(xgb1,train_x,train_y):\n    y_pre = list(xgb1.predict(train_x))\n    train_y = train_y.as_matrix()    \n    num = 0\n    for i in range(len(y_pre)):        \n        num += np.abs(y_pre[i] - train_y[i])\n    print((num*4799+6)/len(y_pre))\n#     1.9692270331443802 7.559401862892015\ndef RMSE(xgb1,train_x,train_y):\n    y_pre = list(xgb1.predict(train_x))\n#     train_y = train_y.as_matrix()\n    num = 0\n    print(len(y_pre),len(train_y))\n    for i in range(len(y_pre)):\n        num += ((y_pre[i] - train_y[i])*5.5902+1.9692)**2\n    print(np.sqrt(num*5.5902+1.9692)/len(y_pre))\n#     print(np.sqrt(num)/ len(y_pre))\n    \n\ndef xgboost_select_feature(data_, labels_,cols,target):# # 特征选择\n    xgb1 = XGBRegressor(learning_rate =0.1,max_depth=5,min_child_weight=1,n_estimators=1000,\n                    gamma=0,subsample=0.7,colsample_bytree=0.75,objective= 'reg:logistic',\n                        nthread=4,scale_pos_weight=1,seed=27)       \n    feature_ = list(modelfit(xgb1, data_.values,labels_.values,cols,target)) # 特征选择    \n    return feature_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c5db1a4df4fdc96a5b7156dd21aa8115517a176"},"cell_type":"code","source":"# def mini_xgboost_train(train_x, train_y):    \n#     # # 半手动调参-------------------是个过程------调参成功需要注释掉----------------------------------------------------\n#     param_test1 = {\n# #         'n_estimators':[64,65,66,67]\n# #         'max_depth':[i for i in range(3,11)]\n# #         'subsample':[i/100 for i in range(60,100,10)],\n# #         'colsample_bytree':[j/100 for j in range(60,100,10)]\n# #           'subsample':[i/100 for i in range(80,100,5)],\n# #           'colsample_bytree':[j/100 for j in range(80,100,5)]\n#         'learning_rate':[0.1,0.05,0.08,0.07,0.2]\n#     }\n#     gsearch1 = GridSearchCV(estimator = XGBRegressor(learning_rate=0.1,n_estimators=138,max_depth=4,min_child_weight=1,\n#                        colsample_bytree=0.9,subsample=0.9,gamma=0,objective= 'reg:logistic', nthread=4, seed=27), \n#                     param_grid = param_test1,scoring='neg_mean_squared_error',n_jobs=4, iid=False, cv=5)\n#     gsearch1.fit(train_x,train_y)\n#     print(gsearch1.best_params_,gsearch1.best_score_) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df8599d736912e88bdcebf001071c426765efe8f","trusted":true},"cell_type":"code","source":"def xgboost_train(train_x, train_y):\n#     train_x = train_x.as_matrix()\n    xgb1 = XGBRegressor(learning_rate=0.1,n_estimators=138,max_depth=4,min_child_weight=1,\n                       colsample_bytree=0.9,subsample=0.9,gamma=0,objective= 'reg:logistic', nthread=4, seed=27)\n    xgb1.fit(train_x,train_y)\n    RMSE(xgb1,train_x,train_y)\n       \n    return xgb1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef4e97fd8283b768125ac3a8a8ce6b179d1aecc1","trusted":true},"cell_type":"code","source":"colum = ['distance','year','month','day', 'time', 'week','passenger_count','price']\ndata_ = data_[colum].sort_values(by=['year','month','day','time'])\ndata_.index = range(len(data_))\ncolum.remove('price')\ndata = data_[colum]\nlabels_ = data_[['price']]\n# print(data.head())\n# print(labels_.head())\n\n# reg:logistic要求对label归一化\nminn = labels_['price'].min(axis=0)\nmaxx = labels_['price'].max(axis=0)\nprint(minn,maxx)\nlabels_['price_'] = labels_['price'].apply(lambda x: (x - minn)/(maxx - minn))\nlabels_ = labels_.drop('price',axis=1)\n# print(labels_['price'])\ntest_size = 0.3\nseed = 10\ndata = pd.DataFrame(data.values,columns = colum)\nx_train,x_test,y_train,y_test = train_test_split(data, labels_, test_size=test_size,random_state=seed)\n# xgboost_select_feature(data, labels_,colum,100)\n# mini_xgboost_train(x_train.values,y_train.values)\nxgb_ = XGBRegressor()\nxgb_ = xgboost_train(x_train.values,y_train.values)\n\n# -------------------------prediction-------------------------\n# test = pd.read_csv('./data/test.csv')\ntest = pd.read_csv('../input/test.csv')\ntest_data = data_deal(test,False)\ntest_data = test_data[colum_]\ntest_data = pd.DataFrame(test_data.values,columns = colum)\ntest_data = test_data.as_matrix()\n# test_data['week'] = test_data['week'].apply(lambda x: int(x))\n# print(test_data['week'].head())\ny_pre = list(xgb_.predict(test_data))\ntest_pre_ = pd.DataFrame(y_pre).apply(lambda x: (maxx - minn)*x + minn)\nprint(test_pre_.head())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}