{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv', nrows=999999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['fare_amount'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Haversine formula: determining distance between 2 points given their latitude and longtitude","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import radians, cos, sin, arcsin, sqrt\n\ndef haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points \n    on the earth (specified in decimal degrees)\n    \"\"\"\n\n    #Convert decimal degrees to Radians:\n    lon1 = np.radians(lon1.values)\n    lat1 = np.radians(lat1.values)\n    lon2 = np.radians(lon2.values)\n    lat2 = np.radians(lat2.values)\n\n    #Implementing Haversine Formula: \n    dlon = np.subtract(lon2, lon1)\n    dlat = np.subtract(lat2, lat1)\n\n    a = np.add(np.power(np.sin(np.divide(dlat, 2)), 2),  \n                          np.multiply(np.cos(lat1), \n                                      np.multiply(np.cos(lat2), \n                                                  np.power(np.sin(np.divide(dlon, 2)), 2))))\n    c = np.multiply(2, np.arcsin(np.sqrt(a)))\n    r = 6371\n\n    return c*r\ndef distance(s_lat, s_lng, e_lat, e_lng):\n\n   # approximate radius of earth in km\n   R = 6373.0\n\n   s_lat = s_lat*np.pi/180.0                      \n   s_lng = np.deg2rad(s_lng)     \n   e_lat = np.deg2rad(e_lat)                       \n   e_lng = np.deg2rad(e_lng)  \n\n   d = np.sin((e_lat - s_lat)/2)**2 + np.cos(s_lat)*np.cos(e_lat) * np.sin((e_lng - s_lng)/2)**2\n\n   return 2 * R * np.arcsin(np.sqrt(d))\n\n# from haversine import haversine\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['dist_kmm'] = haversine(df['pickup_latitude'], df['pickup_longitude'], df['dropoff_latitude'], df['dropoff_longitude'])\ndf['dist_km'] = distance(df['pickup_latitude'], df['pickup_longitude'], df['dropoff_latitude'], df['dropoff_longitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_on_map(df, BB, nyc_map, s=10, alpha=0.2):\n    fig, axs = plt.subplots(1, 2, figsize=(16,10))\n    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[0].set_xlim((BB[0], BB[1]))\n    axs[0].set_ylim((BB[2], BB[3]))\n    axs[0].set_title('Pickup locations')\n    axs[0].imshow(nyc_map, zorder=0, extent=BB)\n\n    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[1].set_xlim((BB[0], BB[1]))\n    axs[1].set_ylim((BB[2], BB[3]))\n    axs[1].set_title('Dropoff locations')\n    axs[1].imshow(nyc_map, zorder=0, extent=BB)\nBB = (-74.5, -72.8, 40.5, 41.8)\nnyc_map = plt.imread('https://aiblog.nl/download/nyc_-74.5_-72.8_40.5_41.8.png')\nplot_on_map(df, BB, nyc_map, s=1, alpha=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert datetime string to datetime\ndf['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_time = df['pickup_datetime'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_time.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['EDTdate'] = df['pickup_datetime'] - pd.Timedelta(hours=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Hour'] = df['EDTdate'].dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['AMPM'] = np.where(df['Hour']<12, 'am', 'pm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\ndf['DoW'] = df['EDTdate'].dt.dayofweek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['Hour', 'AMPM', 'Weekday', 'DoW']\ncont_cols = ['pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'dist_km']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_col = ['fare_amount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical to numeric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat in cat_cols:\n    df[cat] = df[cat].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Weekday']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['AMPM'].cat.categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['AMPM'].cat.codes.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr = df['Hour'].cat.codes.values\nampm = df['AMPM'].cat.codes.values\nwd = df['Weekday'].cat.codes.values\ndw = df['DoW'].cat.codes.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats = np.stack([hr, ampm, wd, dw], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# category numpy to sensor\ncats = torch.tensor(cats, dtype=torch.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# continous to tensor\nconts = np.stack([df[col].values for col in cont_cols], axis=1)\nconts = torch.tensor(conts, dtype=torch.float)\nconts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label to tensor\ny = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats_size = [len(df[col].cat.categories) for col in cat_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_size = [(size, min(50, (size+1)//2)) for size in cats_size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tabular model - using embedding layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catz = cats[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selfembeds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forward\nembedding_z = []\n\nfor i, e in enumerate(selfembeds):\n    embedding_z.append(e(catz[:,i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = torch.cat(embedding_z, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selfembeddingdrop = nn.Dropout(0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = selfembeddingdrop(z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TabularModel(nn.Module):\n#     u can define the number of layers in this manner of build - flexibility\n    def __init__(self, emb_size, n_cont, out_size, layers, p=0.5):\n        super().__init__()\n        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n        self.emb_drop = nn.Dropout(p)\n        self.bn_cont = nn.BatchNorm1d(n_cont)\n        \n        layer_list = []\n        n_emb = sum([nf for ni, nf in emb_size])\n        n_in = n_emb + n_cont\n        \n        for i  in layers:\n            layer_list.append(nn.Linear(n_in, i))\n            layer_list.append(nn.ReLU(inplace=True))\n            layer_list.append(nn.BatchNorm1d(i))\n            layer_list.append(nn.Dropout(p))\n            n_in = i\n            \n        layer_list.append(nn.Linear(layers[-1], out_size))\n        self.layers = nn.Sequential(*layer_list)\n    \n    def forward(self, x_cat, x_cont):\n        embeddings = []\n        \n        for i, e in enumerate(self.embeds):\n            embeddings.append(e(x_cat[:,i]))\n        \n        x = torch.cat(embeddings, 1)\n        x = self.emb_drop(x)\n        \n        x_cont = self.bn_cont(x_cont)\n        x = torch.cat([x, x_cont], 1)\n        x = self.layers(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(33)\nmodel = TabularModel(embedding_size, conts.shape[1], 1, [200, 100], p=0.4)\n# for classification problem, use class size 2 instead of 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.MSELoss()\n# for classification problem: use nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_test_split\nbatch_size = 60000\ntest_size = int(batch_size*0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shuffled \ncat_train = cats[:batch_size-test_size] \ncat_test = cats[batch_size - test_size:batch_size]\n\ncon_train = conts[:batch_size-test_size]\ncon_test = conts[batch_size - test_size:batch_size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = y[:batch_size-test_size]\ny_test = y[batch_size - test_size:batch_size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cat_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(con_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cat_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nstart_time = time.time()\n\nepochs = 200\n\nlosses = []\n\nfor i in range(epochs):\n    i+=1\n    \n    y_pred = model(cat_train, con_train)\n    loss = torch.sqrt(criterion(y_pred, y_train))\n    losses.append(loss)\n    if i%25 == 1:\n        print(f\"epoch:{i} loss: {loss}\")\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\nduration = time.time() - start_time\nprint(f\"training time: {duration/60}min\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    y_val = model(cat_test, con_test)\n    loss = torch.sqrt(criterion(y_val,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    diff = np.abs(y_val[i].item()-y_test[i].item())\n    print(f\"{i}predicted {y_val[i].item():8.2f} True:{y_test[i].item():8.2f} DIFF: {diff:8.2f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), 'taxi_model_kaggle_pytorch.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading saved model \nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\n\ndef haversine_distance(df, lat1, long1, lat2, long2):\n    r = 6371\n    phi1 = np.radians(df[lat1])\n    phi2 = np.radians(df[lat2])\n    delta_phi = np.radians(df[lat2]-df[lat1])\n    delta_lambda = np.radians(df[long2]-df[long1])\n    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    return r * c\n\nclass TabularModel(nn.Module):\n    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n        super().__init__()\n        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n        self.emb_drop = nn.Dropout(p)\n        self.bn_cont = nn.BatchNorm1d(n_cont)\n        layerlist = []\n        n_emb = sum((nf for ni,nf in emb_szs))\n        n_in = n_emb + n_cont\n        for i in layers:\n            layerlist.append(nn.Linear(n_in,i)) \n            layerlist.append(nn.ReLU(inplace=True))\n            layerlist.append(nn.BatchNorm1d(i))\n            layerlist.append(nn.Dropout(p))\n            n_in = i\n        layerlist.append(nn.Linear(layers[-1],out_sz))\n        self.layers = nn.Sequential(*layerlist)\n    def forward(self, x_cat, x_cont):\n        embeddings = []\n        for i,e in enumerate(self.embeds):\n            embeddings.append(e(x_cat[:,i]))\n        x = torch.cat(embeddings, 1)\n        x = self.emb_drop(x)\n        x_cont = self.bn_cont(x_cont)\n        x = torch.cat([x, x_cont], 1)\n        return self.layers(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_szs = [(24, 12), (2, 1), (7, 4)]\nmodel2 = TabularModel(emb_szs, 6, 1, [200,100], p=0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_data(mdl): # pass in the name of the new model\n    # INPUT NEW DATA\n    plat = float(input('What is the pickup latitude?  '))\n    plong = float(input('What is the pickup longitude? '))\n    dlat = float(input('What is the dropoff latitude?  '))\n    dlong = float(input('What is the dropoff longitude? '))\n    psngr = int(input('How many passengers? '))\n    dt = input('What is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     ')\n    \n    # PREPROCESS THE DATA\n    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n    dfx = pd.DataFrame(dfx_dict, index=[0])\n    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n                                        'dropoff_latitude', 'dropoff_longitude')\n    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n    \n    # We can skip the .astype(category) step since our fields are small,\n    # and encode them right away\n    dfx['Hour'] = dfx['EDTdate'].dt.hour\n    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n                                            [0,1,2,3,4,5,6]).astype('int64')\n    # CREATE CAT AND CONT TENSORS\n    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n                 'dropoff_longitude', 'passenger_count', 'dist_km']\n    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n    xcats = torch.tensor(xcats, dtype=torch.int64)\n    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n    xconts = torch.tensor(xconts, dtype=torch.float)\n    \n    # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n    with torch.no_grad():\n        z = mdl(xcats, xconts)\n    print(f'\\nThe predicted fare amount is ${z.item():.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = test_data(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}