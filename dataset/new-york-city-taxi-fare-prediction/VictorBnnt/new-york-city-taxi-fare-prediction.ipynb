{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"font-size:30pt; font-weight:700;margin-top:50px;margin-bottom:50px;color:royalblue; text-align:center;width:800px;line-height:20pt\">Kaggle New York City Taxi Fare Prediction</div>","metadata":{}},{"cell_type":"markdown","source":"This workbook is the New York City Taxi Fare Prediction dataset analysis to predict the fare of a taxi trip in New York City.\n\nIt is a Kaggle competition available <a href=\"https://www.kaggle.com/c/new-york-city-taxi-fare-prediction\" target=\"_blank\">HERE</a>.\n\n<i><blockquote><b>The Challenge</b></blockquote></i>\n    \n<blockquote>In this playground competition, hosted in partnership with Google Cloud and Coursera, you are tasked with predicting the fare amount (inclusive of tolls) for a taxi ride in New York City given the pickup and dropoff locations. While you can get a basic estimate based on just the distance between the two points, this will result in an RMSE of $5-$8, depending on the model used (see the starter code for an example of this approach in Kernels). Your challenge is to do better than this using Machine Learning techniques!\n\nTo learn how to handle large datasets with ease and solve this problem using TensorFlow, consider taking the Machine Learning with TensorFlow on Google Cloud Platform specialization on Coursera -- the taxi fare problem is one of several real-world problems that are used as case studies in the series of courses. To make this easier, head to Coursera.org/NEXTextended to claim this specialization for free for the first month!</blockquote>\n<figcaption>Kaggle</figcaption>","metadata":{}},{"cell_type":"markdown","source":"# 1. Import","metadata":{}},{"cell_type":"code","source":"#\nfrom scipy import stats\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight');\nplt.rcParams['font.size'] = 14;\nplt.figure(figsize=(12,5));\npalette = sns.color_palette('Paired', 10);\n\n# map\nimport folium\nfrom folium.plugins import HeatMap\nfrom folium.plugins import HeatMapWithTime\n\n# Sci-kit learn\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin \nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn import set_config; set_config(display='diagram')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/new-york-city-taxi-fare-prediction/train.csv\", nrows=1000000)\ndata.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Dropping useless features","metadata":{}},{"cell_type":"code","source":"data = data.drop([\"key\"], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Duplicates","metadata":{}},{"cell_type":"code","source":"size_before = len(data)\ndata = data.drop_duplicates()\nsize_after = len(data)\nprint(str(size_before - size_after) + \" duplicates were removed.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Missing\n<div style=\"font-weight:700\">Droping features that have too many missing values</div>","metadata":{}},{"cell_type":"code","source":"100 * data.isnull().sum().sort_values(ascending=False)/len(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Seems there is nothing to drop.</div>","metadata":{}},{"cell_type":"markdown","source":"# 5. Explore Data","metadata":{}},{"cell_type":"code","source":"def plot_dist(series=data[\"fare_amount\"], title=\"Fare Distribution\"):\n    sns.histplot(series, kde=True, stat='density', discrete=True)\n    sns.despine()\n    plt.title(title);\n    plt.show()\nplot_dist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's drop absurd values.</div>","metadata":{}},{"cell_type":"code","source":"data = data[data.fare_amount.between(0, 60)]\nplot_dist(data.fare_amount)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">We can also visualise binned fare_amount variable:</div>","metadata":{}},{"cell_type":"code","source":"data['fare-bin'] = pd.cut(data['fare_amount'], bins = list(range(0, 50, 5)), include_lowest=True).astype('str')\n\n# Uppermost bin\ndata['fare-bin'] = data['fare-bin'].replace(np.nan, '[45+]')\n\n# apply this to clean up the first bin's label\ndata['fare-bin'] = data['fare-bin'].apply(lambda x: x.replace('-0.001', '0'))\n\n# sort by fare the correct look in the chart\ndata = data.sort_values(by='fare_amount')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x=\"fare-bin\", kind=\"count\", palette=palette, data=data, height=5, aspect=3);\nsns.despine()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's have a closer look at <i style=\"color:royalblue\">passenger_count</i> feature</div>","metadata":{}},{"cell_type":"code","source":"data.passenger_count.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x=\"passenger_count\", kind=\"count\", palette=palette, data=data, height=5, aspect=3);\nsns.despine()\nplt.title('Passenger Count');\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's have a look at <i style=\"color:royalblue\">pickup_datetime</i> feature</div>","metadata":{}},{"cell_type":"code","source":"def extract_time_features(df):\n    timezone_name = 'America/New_York'\n    time_column = \"pickup_datetime\"\n    df.index = pd.to_datetime(df[time_column])\n    df.index = df.index.tz_convert(timezone_name)\n    df[\"dow\"] = df.index.weekday\n    df[\"hour\"] = df.index.hour\n    df[\"month\"] = df.index.month\n    df[\"year\"] = df.index.year\n    return df.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = extract_time_features(data.drop([\"fare-bin\"], axis=1))\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Taxi trip repartition by hour of the day</div>","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"hour\", kind=\"count\", palette=palette, data=data, height=5, aspect=3);\nsns.despine()\nplt.title('Hour of Day');\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Taxi trip repartition by day of week</div>","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"dow\", kind=\"count\", palette=palette, data=data, height=5, aspect=3);\nsns.despine()\nplt.title('Day of Week');\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's have a look at <span style=\"color:royalblue;font-variant:small-caps\">geospatial</span> features</div>\n<br/>\n<div style=\"font-weight:700\">Find boudaries from test set and remove outliers from training set</div>","metadata":{}},{"cell_type":"code","source":"data_test = pd.read_csv(\"/kaggle/input/new-york-city-taxi-fare-prediction/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in [\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\"]:\n    MIN = data_test[col].min()\n    MAX = data_test[col].max()\n    print(col, MIN, MAX)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[data[\"pickup_latitude\"].between(left = 40, right = 42 )]\ndata = data[data[\"pickup_longitude\"].between(left = -74.3, right = -72.9 )]\ndata = data[data[\"dropoff_latitude\"].between(left = 40, right = 42 )]\ndata = data[data[\"dropoff_longitude\"].between(left = -74, right = -72.9 )]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"center_location = [40.758896, -73.985130]\nm = folium.Map(location=center_location, control_scale=True, zoom_start=11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"count\"] =1\nheatmap_data = data.head(10000)[['pickup_latitude', 'pickup_longitude', 'count']].groupby(['pickup_latitude', 'pickup_longitude']).sum().reset_index().values.tolist()\ngradient = {0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 1: 'red'}\nHeatMap(data=heatmap_data, radius=5, gradient=gradient, max_zoom=13).add_to(m)\nm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heatmap_data_by_hour = []\n__data__ = data.head(10000)\nfor hour in data.hour.sort_values().unique():\n    _data = __data__[__data__.hour == hour][['pickup_latitude', 'pickup_longitude', 'count']].groupby(['pickup_latitude', 'pickup_longitude']).sum().reset_index().values.tolist()\n    heatmap_data_by_hour.append(_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m2 = folium.Map(location=center_location, control_scale=True, zoom_start=11)\nHeatMapWithTime(heatmap_data_by_hour, radius=5, \n                gradient=gradient, \n                min_opacity=0.5, max_opacity=0.8, \n                use_local_extrema=False).add_to(m2)\nm2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's have a look at <span style=\"color:royalblue;font-variant:small-caps\">distance</span> features</div>\n<br/>\n<div style=\"font-weight:700\">Here it is a method to compute distance between two point from their geospatial coordinates</div>","metadata":{}},{"cell_type":"code","source":"def haversine_distance(df,\n                       start_lat=\"start_lat\",\n                       start_lon=\"start_lon\",\n                       end_lat=\"end_lat\",\n                       end_lon=\"end_lon\"):\n    \"\"\"\n        Calculate the great circle distance between two points \n        on the earth (specified in decimal degrees).\n        Vectorized version of the haversine distance for pandas df\n        Computes distance in kms\n    \"\"\"\n\n    lat_1_rad, lon_1_rad = np.radians(df[start_lat].astype(float)), np.radians(df[start_lon].astype(float))\n    lat_2_rad, lon_2_rad = np.radians(df[end_lat].astype(float)), np.radians(df[end_lon].astype(float))\n    dlon = lon_2_rad - lon_1_rad\n    dlat = lat_2_rad - lat_1_rad\n\n    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat_1_rad) * np.cos(lat_2_rad) * np.sin(dlon / 2.0) ** 2\n    c = 2 * np.arcsin(np.sqrt(a))\n    haversine_distance = 6371 * c\n    return haversine_distance\n\ndata[\"distance\"] = haversine_distance(data, \n                                      start_lat=\"pickup_latitude\", start_lon=\"pickup_longitude\",\n                                      end_lat=\"dropoff_latitude\", end_lon=\"dropoff_longitude\"\n                                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.distance.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nplot_dist(series=data[data.distance < 50].distance, title='Distance distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's have a look at <i style=\"color:royalblue\">passenger_count</i> feature</div>","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"passenger_count\", y=\"fare_amount\", palette=palette, data=data, kind=\"bar\", aspect=3)\nsns.despine()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's have a look at <i style=\"color:royalblue\">fare_amount</i> feature by hour</div>","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"hour\", y=\"fare_amount\", palette=palette, data=data, kind=\"bar\", aspect=3)\nsns.despine()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's have a look at <i style=\"color:royalblue\">fare_amount</i> feature by day of week</div>","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"dow\", y=\"fare_amount\", palette=palette, data=data, kind=\"bar\", aspect=3)\nsns.despine()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"font-weight:700\">Let's have a look at the corelation between <i style=\"color:royalblue\">fare_amount</i> and <i style=\"color:royalblue\">distance</i> features</div>","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=\"distance\", y=\"fare_amount\", data=data[data.distance < 80].sample(100000))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Training\n<div style=\"font-weight:700\">Starting on a fresh dataset to prepare for training</div>","metadata":{}},{"cell_type":"code","source":"data_train = pd.read_csv(\"/kaggle/input/new-york-city-taxi-fare-prediction/train.csv\", nrows=1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.1. Cleaning dataset","metadata":{}},{"cell_type":"code","source":"def clean_data(df, test=False, predict=False):\n    df = df.drop([\"key\"], axis=1)\n    df = df.dropna(how='any', axis='rows')\n    df = df[(df.dropoff_latitude != 0) | (df.dropoff_longitude != 0)]\n    df = df[(df.pickup_latitude != 0) | (df.pickup_longitude != 0)]\n    if \"fare_amount\" in list(df):\n        df = df[df.fare_amount.between(0, 4000)]\n    df = df[df.passenger_count < 8]\n    df = df[df.passenger_count >= 0]\n    df = df[df[\"pickup_latitude\"].between(left=40, right=42)]\n    df = df[df[\"pickup_longitude\"].between(left=-74.3, right=-72.9)]\n    df = df[df[\"dropoff_latitude\"].between(left=40, right=42)]\n    df = df[df[\"dropoff_longitude\"].between(left=-74, right=-72.9)]\n    return df\ndata_train = clean_data(data_train)\ndata_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2. Preparing model inputs","metadata":{}},{"cell_type":"code","source":"X_train = data_train.drop([\"fare_amount\"], axis=1)\ny_train = data_train[\"fare_amount\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.3. Pipelines","metadata":{}},{"cell_type":"markdown","source":"### 6.3.1. Time features","metadata":{}},{"cell_type":"markdown","source":"#### 6.3.1.1 Class for time features encoding","metadata":{}},{"cell_type":"code","source":"class TimeFeaturesEncoder(BaseEstimator, TransformerMixin):\n    \"\"\"Extract the day of week (dow), the hour, the month and the year from a time column.\"\"\"\n\n    def __init__(self, time_column, time_zone_name='America/New_York'):\n        self.time_column = time_column\n        self.time_zone_name = time_zone_name\n\n    def extract_time_features(self, X):\n        timezone_name = self.time_zone_name\n        time_column = self.time_column\n        df = X.copy()\n        df.index = pd.to_datetime(df[time_column])\n        df.index = df.index.tz_convert(timezone_name)\n        df[\"dow\"] = df.index.weekday\n        df[\"hour\"] = df.index.hour\n        df[\"month\"] = df.index.month\n        df[\"year\"] = df.index.year        \n        return df\n        \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        \"\"\"Returns a copy of the DataFrame X with only four columns: 'dow', 'hour', 'month', 'year'\"\"\"\n        return self.extract_time_features(X)[['dow', 'hour', 'month', 'year']].reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6.3.1.2. Test of the TimeFeaturesEncoder","metadata":{}},{"cell_type":"code","source":"# test the TimeFeaturesEncoder\ntime_enc = TimeFeaturesEncoder('pickup_datetime')\ntime_features = time_enc.fit_transform(X_train, y_train)\ntime_features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6.3.1.3. Pipeline for time features","metadata":{}},{"cell_type":"code","source":"# TIME PIPELINE\npipe_time = Pipeline([\n    ('time_features_create', TimeFeaturesEncoder('pickup_datetime')),\n    ('time_features_ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n])\npipe_time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3.2. Distances","metadata":{}},{"cell_type":"markdown","source":"#### 6.3.2.1 Class for distance encoding","metadata":{}},{"cell_type":"code","source":"def haversine_vectorized(df, \n         start_lat=\"pickup_latitude\",\n         start_lon=\"pickup_longitude\",\n         end_lat=\"dropoff_latitude\",\n         end_lon=\"dropoff_longitude\"):\n\n    \"\"\" \n        Calculate the great circle distance between two points \n        on the earth (specified in decimal degrees).\n        Vectorized version of the haversine distance for pandas df\n        Computes distance in kms\n    \"\"\"\n\n    lat_1_rad, lon_1_rad = np.radians(df[start_lat].astype(float)), np.radians(df[start_lon].astype(float))\n    lat_2_rad, lon_2_rad = np.radians(df[end_lat].astype(float)), np.radians(df[end_lon].astype(float))\n    dlon = lon_2_rad - lon_1_rad\n    dlat = lat_2_rad - lat_1_rad\n\n    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat_1_rad) * np.cos(lat_2_rad) * np.sin(dlon / 2.0) ** 2\n    c = 2 * np.arcsin(np.sqrt(a))\n    return 6371 * c","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DistanceTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"Compute the haversine distance between two GPS points.\"\"\"\n\n    def __init__(self, \n                 start_lat=\"pickup_latitude\",\n                 start_lon=\"pickup_longitude\", \n                 end_lat=\"dropoff_latitude\", \n                 end_lon=\"dropoff_longitude\"):\n        self.start_lat = start_lat\n        self.start_lon = start_lon\n        self.end_lat = end_lat\n        self.end_lon = end_lon\n\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        \"\"\"Returns a copy of the DataFrame X with only one column: 'distance'\"\"\"\n        return pd.DataFrame(haversine_vectorized(X)).rename(columns={0: \"course distance [km]\"}).copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6.3.2.2. Test of the DistanceTransformer","metadata":{}},{"cell_type":"code","source":"dist_trans = DistanceTransformer()\ndistance = dist_trans.fit_transform(X_train, y_train)\ndistance.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3.3. Combination of distance and time features pipeline","metadata":{}},{"cell_type":"code","source":"preprocessor = ColumnTransformer([\n    ('distance', DistanceTransformer(), ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']),\n    ('time', pipe_time, ['pickup_datetime'])\n], remainder='passthrough')\npreprocessor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3.4. Full preprocessor pipeline","metadata":{}},{"cell_type":"code","source":"pipe_prepro = Pipeline([\n    ('dist_and_time', preprocessor),\n    ('scaler', MinMaxScaler())\n])\npipe_prepro","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3.5. Finally, Full pipeline. We choose RandomForestRegressor","metadata":{}},{"cell_type":"code","source":"final_pipe = Pipeline([\n    ('preprocessor', pipe_prepro),\n    ('model', RandomForestRegressor())\n])\nfinal_pipe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.4. Definition of custom score for RMSE","metadata":{}},{"cell_type":"code","source":"def custom_rmse(y_true, y_pred):\n    return np.sqrt(np.mean(np.square(y_true - y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = make_scorer(custom_rmse, greater_is_better=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.5. Baseline RMSE for RandomForestRegressor","metadata":{}},{"cell_type":"code","source":"baseline = cross_validate(final_pipe,\n                          X_train,\n                          y_train,\n                          scoring=rmse,\n                          cv=5)\nbaseline_rmse = -round(baseline[\"test_score\"].mean(), 3)\nbaseline_rmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.6. RandomizedSearchCV for an optimized model","metadata":{}},{"cell_type":"code","source":"grid_RFR = {'model__n_estimators': stats.randint(1, 300),\n            'model__max_depth': stats.randint(1, 300),\n            'model__max_samples': stats.randint(1, 300),\n            \"preprocessor__scaler\": [StandardScaler(), RobustScaler(), MinMaxScaler()]\n            }\n\nsearch_RFR = RandomizedSearchCV(final_pipe,\n                                grid_RFR,\n                                scoring=rmse,\n                                n_iter=100,\n                                cv=5,\n                                n_jobs=-1,\n                                verbose=True)\nsearch_RFR.fit(X_train, y_train);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search_RFR.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Tuned RandomForestRegressor model rmse: \" + str(-round(search_RFR.best_score_, 2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}