{"cells":[{"metadata":{"_uuid":"359708314acbf1afa3bfc0fccaf24e63dce32fcd"},"cell_type":"markdown","source":"# 1) Define Problem"},{"metadata":{"_uuid":"af312c3c71ac783b033681f78e78bf333588bcc6"},"cell_type":"markdown","source":"# New York Taxi Fare Prediction: "},{"metadata":{"_uuid":"33e1f1f294836380df59ce1b527e67fd24732b3c"},"cell_type":"markdown","source":" our  tasked is  predicting the fare amount (inclusive of tolls) for a taxi ride in New York City given the pickup and dropoff locations. While we can get a basic estimate based on just the distance between the two points, this will result in an RMSE of $5-$8, depending on the model used . our  challenge is to do better than this using Machine Learning techniques!\n\n"},{"metadata":{"_uuid":"78c3519df07ec2248754760e643484ea143d5325"},"cell_type":"markdown","source":"# 2) Specify input and output"},{"metadata":{"_uuid":"13f2180fac2a5e9d8fbdc1d65ae7a97ba594260b"},"cell_type":"markdown","source":"# Data Field:"},{"metadata":{"_uuid":"3d8ba6c1b5151add893d9e24d2872b5f919713cc"},"cell_type":"markdown","source":"1)**ID**\nkey - Unique string identifying each row in both the training and test sets. Comprised of pickup_datetime plus a unique integer, but this doesn't matter, it should just be used as a unique ID field. Required in your submission CSV. Not necessarily needed in the training set, but could be useful to simulate a 'submission file' while doing cross-validation within the training set.\n"},{"metadata":{"_uuid":"88bf7bebad5b5462873f0e3740ef3598c4a2e557"},"cell_type":"markdown","source":"# Features\n"},{"metadata":{"_uuid":"be434d4833e1323e85917442a625792b3786692e"},"cell_type":"markdown","source":"**pickup_datetime** - timestamp value indicating when the taxi ride started.\n"},{"metadata":{"_uuid":"ea0b8c9691ee0771af6d7742bf77527c3e355719"},"cell_type":"markdown","source":"**pickup_longitude** - float for longitude coordinate of where the taxi ride started.\n"},{"metadata":{"_uuid":"f4e0684be7e633e73586fa5e601e4db1e21fb758"},"cell_type":"markdown","source":"**pickup_latitude** - float for latitude coordinate of where the taxi ride started.\n"},{"metadata":{"_uuid":"f890bc85ecc768815787555500abafc5f9d4d629"},"cell_type":"markdown","source":"**dropoff_longitude** - float for longitude coordinate of where the taxi ride ended.\n"},{"metadata":{"_uuid":"74262cd65ce88cceb3131c5cdbb6d86ab10e8506"},"cell_type":"markdown","source":"**dropoff_latitude** - float for latitude coordinate of where the taxi ride ended.\n"},{"metadata":{"_uuid":"2ab8debab14bcc46ce66e167d71fe4f05b39f540"},"cell_type":"markdown","source":"**passenger_count** - integer indicating the number of passengers in the taxi ride.\n"},{"metadata":{"_uuid":"5b2fdaaafa0a9164872ecbb0f0a5ef2ab30323b2"},"cell_type":"markdown","source":"# Target\n"},{"metadata":{"_uuid":"044c5d386887cb12dcbb51ae4f1a7dc1e20f7dc1"},"cell_type":"markdown","source":"**fare_amount** - float dollar amount of the cost of the taxi ride. This value is only in the training set; this is what you are predicting in the test set and it is required in your submission CSV."},{"metadata":{"_uuid":"e8f028880a785f11bf30859e32135f8b46c4350b"},"cell_type":"markdown","source":"# 3) Select Framework(libraries)"},{"metadata":{"trusted":true,"_uuid":"356677af33ee98f5eb5bcf99ab9c453c8fca9302"},"cell_type":"code","source":"import os\nimport numpy as np#linear algebra   \nimport pandas as pd #data preprocessing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5f9f18e625d411f5694c4461b451c6b76683985"},"cell_type":"code","source":"train =  pd.read_csv('../input/train.csv', nrows = 100000, parse_dates=[\"pickup_datetime\"])  # 55m rows,but we import 10m rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6137b989dd56209871c63c9a60313bd69616e98d"},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')   #10k rows ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0427168ce5bb0730162e37b0ccb0d67411861cde"},"cell_type":"code","source":"train.head()  # first 5 record of train ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04853bb3c3896ba09cf145d7542d1ef7ece88ad9"},"cell_type":"markdown","source":"# 4) EDA(Exploratery Data Analysis)"},{"metadata":{"_uuid":"7bf0ed4b279a9eab7f7f280be533e553d398c01c"},"cell_type":"markdown","source":"#  Data collection"},{"metadata":{"trusted":true,"_uuid":"4f56f6a9fea2dba42b2a38a792bf4afbe2077570"},"cell_type":"code","source":"train.describe() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64ef511fef9cfb5e6a6dc859a7a603ad16107b01"},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0ed233b9bb01826e1c2ecfb09a358c12103ed27b"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"414ff3806dcbec852805f81f614591539fde5a3a"},"cell_type":"markdown","source":"train  has total 8 column in that   5 float64 values, 1 int value , 1 object ,and 1  datetime64 . "},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing & Data cleaning"},{"metadata":{"trusted":true,"_uuid":"ed8d49bfbb79e93189d4258a3c67cc3a3f087fe2"},"cell_type":"code","source":"print(train.isnull().sum())  # check anu null value is available or not .\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8a90c58e4b818827d1460c363ada6c598dd0a22","scrolled":true},"cell_type":"code","source":"print('Old size: %d' % len(train))\ntrain = train.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(train))\n# if gives 20million data then NaN values comes.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85e5e1423df6ce2391a5f3f42332f246dcd65e39"},"cell_type":"code","source":"print(train.isnull().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"579375b7ac8c020519124963cc1cfbc3c7713a72"},"cell_type":"code","source":"sns.distplot(train['fare_amount']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"in between 0-50 there are 95% 'fare_amount' located."},{"metadata":{"trusted":true,"_uuid":"8b41df1d4e4934db987244846d8ebb1a33402c99"},"cell_type":"code","source":"train.loc[train['fare_amount']<0].shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e09bccf267c8f492318aa90cad3f6c6c7275cd1"},"cell_type":"markdown","source":"There are 9 records with negative fare, we will remove these record from the data."},{"metadata":{"_uuid":"1d2edefad1433a219f488bf0de9d6a87565e589f"},"cell_type":"markdown","source":"there are lots of cases where lat and longitude is 0 , check how many such cases are?"},{"metadata":{"trusted":true,"_uuid":"f04187a6b0e3bdaae0fce324ff39cfd022d1d93e"},"cell_type":"code","source":"train[(train.pickup_latitude==0) | (train.pickup_longitude)==0 | (train.dropoff_latitude==0) | (train.dropoff_longitude==0)].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1918 values are** 0 in train.\nBased on just look at the data, we can see that its not 100% clean and\nsome entries will contribute to higher error rates. "},{"metadata":{"trusted":true,"_uuid":"b206d5e782a4f3fd0f2cba2c26663eca73383530"},"cell_type":"code","source":"sns.distplot(train['passenger_count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8193b4a15c634360ff01f70f86a2b3711b3ed5f2"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81871f6a63801dd2dd1b16f3c10992bcdde424e7"},"cell_type":"code","source":"#clean up the train dataset to eliminate out of range values\ntrain = train[train['fare_amount'] > 0]\ntrain = train[train['pickup_longitude'] < -72]\ntrain = train[(train['pickup_latitude'] > 40) &(train\n                                               ['pickup_latitude'] < 44)]\ntrain = train[train['dropoff_longitude'] < -72]\ntrain = train[(train['dropoff_latitude'] >40) & (train\n                                                ['dropoff_latitude'] < 44)]\ntrain = train[(train['passenger_count']>0) &(train['passenger_count'] < 10)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4ce0b73d807c475074b5ec8fae076536a6663db"},"cell_type":"markdown","source":"Now we can see there are no obvious inconstitencies with the data."},{"metadata":{"_uuid":"c09cc29cbe5bd5f9b81860d4abe8c40a1d189a0f","trusted":true},"cell_type":"code","source":" train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Same operation perform on 'test'"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()  # first 5 record of test ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[(test.pickup_latitude==0) | (test.pickup_longitude)==0 | (test.dropoff_latitude==0) | (test.dropoff_longitude==0)].shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.isnull().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Old size: %d' % len(test))\ntest = test.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clean up the train dataset to eliminate out of range values\ntest = test[test['pickup_longitude'] < -72]\ntest = test[(test['pickup_latitude'] > 40) &(train\n                                               ['pickup_latitude'] < 44)]\ntest = test[test['dropoff_longitude'] < -72]\ntest = test[(test['dropoff_latitude'] >40) & (train\n                                                ['dropoff_latitude'] < 44)]\ntest = test[(test['passenger_count']>0) &(train['passenger_count'] < 10)]\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we clean the dataset."},{"metadata":{},"cell_type":"markdown","source":"#  Transforming Feature"},{"metadata":{"trusted":true,"_uuid":"6c78626deaecf66a34a8bfa166c7e67d73d41c1b"},"cell_type":"code","source":"# Pickup Datetime is in Date format convert it on int\ntrain['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\ntest['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0759098ed85c07b5de8cbf2fa1c779d791d67efe"},"cell_type":"markdown","source":"conver Datetime var into single column as year, month,day_of_week, and hour "},{"metadata":{"trusted":true,"_uuid":"d1062481bd280368c31203d5e94146b3ebd7f13d"},"cell_type":"code","source":"combine = [train,test]\nfor dataset in combine:\n    dataset['pickup_datetime'] = pd.to_datetime(dataset['pickup_datetime'])\n    dataset['hour'] = dataset.pickup_datetime.dt.hour\n    dataset['week'] = dataset.pickup_datetime.dt.week\n    dataset['month'] = dataset.pickup_datetime.dt.month\n    dataset['year'] = dataset.pickup_datetime.dt.year\n\n    \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af1cf2292a03899c6432bf2bfd359b75b8efb879","_kg_hide-input":false},"cell_type":"code","source":"# Given a dataframe, add two new features 'abs_diff_longitude' and\n# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n# the pickup location to the dropoff location.\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(train) \ntrain.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Given a dataframe, add two new features 'abs_diff_longitude' and\n# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n# the pickup location to the dropoff location.\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(test) \ntest.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove unnessary column that not requred for modeling.\ntrain = train.drop(['pickup_datetime', 'key'],axis = 1) \n#train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['pickup_datetime'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's prepare the test set\nx_pred = test.drop('key', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['key'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Feature encoding"},{"metadata":{"trusted":true,"_uuid":"c472d2e5904ec3879cbe959abcf276ebd4c2f15a"},"cell_type":"code","source":"y= train['fare_amount']\nx = train.drop(['fare_amount'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Cross Validation "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXtrain,Xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  i)Linear Regression"},{"metadata":{"trusted":true,"_uuid":"bcc7043899ffe87d62de19526198aa93eef46d48"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error as MSE \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linmodel = LinearRegression()\nlinmodel.fit(Xtrain, ytrain)\nprint(linmodel.score(Xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bc36ddd867e03b476c98d2848f0627265ac3bed"},"cell_type":"code","source":"#Prediction on train data\nlinmodel_pred = linmodel.predict(Xtest)\nr21 = r2_score(ytest, linmodel_pred)\nmse1 = mean_squared_error(ytest,linmodel_pred)\nrmse1 = np.sqrt(MSE(ytest, linmodel_pred)) \nprint(r21)\nprint(mse1)\nprint(\"RMSE : % f\" %(rmse1)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eeb778fec8ecb57770954a4a10d70643d4fb9e9b"},"cell_type":"code","source":"#Prediction on test Data\nlinmodel_pred=linmodel.predict(x_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linmodel_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Ridge Regression\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47cc8513a1a393fd751a84213b35b9aeb9c127e8"},"cell_type":"code","source":"ridge = Ridge(alpha=0.005, normalize=True)\nridge.fit(Xtrain, ytrain)\nprint(ridge.score(Xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction on test Data\nridge_pred=linmodel.predict(x_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lasso Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso= Lasso(alpha=0.0004, normalize=True)\nlasso.fit(Xtrain, ytrain)\nprint(lasso.score(Xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction on test Data\nlasso_pred=linmodel.predict(x_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nsc_y = StandardScaler()\nX_std = sc_x.fit_transform(Xtrain)\ny_std = sc_y.fit_transform(ytrain.values.reshape(-1,1)).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = 0.0001\nw_ = np.zeros(1 + X_std.shape[1])\ncost_ = []\nn_ = 100\n\nfor i in range(n_):\n    y_pred = np.dot(X_std, w_[1:]) + w_[0]\n    errors = (y_std - y_pred)\n    \n    w_[1:] += alpha * X_std.T.dot(errors)\n    w_[0] += alpha * errors.sum()\n    \n    cost = (errors**2).sum() / 2.0\n    cost_.append(cost) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.plot(range(1, n_ + 1), cost_);\nplt.ylabel('SSE');\nplt.xlabel('Epoch');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr = SVR(kernel='linear')\nsvr.fit(Xtrain, ytrain)\nprint(svr.score(Xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction on test Data\nsvr_pred=svr.predict(x_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor()\nrfr.fit(Xtrain, ytrain)\nprint(rfr.score(Xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction on test Data\nrfr_pred=rfr.predict(x_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# iii) XG-BOOST Model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dmatrix = xg.DMatrix(data = Xtrain, label = ytrain) \ntest_dmatrix = xg.DMatrix(data = Xtest, label = ytest)    #For prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DMatrix. It is an optimized data structure that the creators of XGBoost made. It gives the package its performance and efficiency gains."},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"} \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg = xg.train(params = param, dtrain = train_dmatrix, num_boost_round = 10000)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_pred= xg.predict(test_dmatrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(r2_score(ytest, xg_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# parameter Tuning(xgboost cv)"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n      #parameters that we are going to tune\n    'max_depth' :8 ,#result of tuning with cv\n    'eta' :.03, #result of tuning with cv\n    'subsample' : 1, # result of tuning with cv\n    'colsample_bytree' : 0.8, #result of tuning with cv\n    #other parameter\n    'objective': 'reg:linear',\n    'eval_metrics':'rmse',\n    'silent': 1,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Block of code used for hypertuning parameters. Adapt to each round of parameter tuning.\nCV=False\nif CV:\n    dtrain = xgb.DMatrix(train,label=y)\n    gridsearch_params = [\n        (eta)\n        for eta in np.arange(.04, 0.12, .02)\n    ]\n\n    # Define initial best params and RMSE\n    min_rmse = float(\"Inf\")\n    best_params = None\n    for (eta) in gridsearch_params:\n        print(\"CV with eta={} \".format(\n                                 eta))\n\n        # Update our parameters\n        params['eta'] = eta\n\n        # Run CV\n        cv_results = xgb.cv(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            nfold=3,\n            metrics={'rmse'},\n            early_stopping_rounds=10\n        )\n\n        # Update best RMSE\n        mean_rmse = cv_results['test-rmse-mean'].min()\n        boost_rounds = cv_results['test-rmse-mean'].argmin()\n        print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n        if mean_rmse < min_rmse:\n            min_rmse = mean_rmse\n            best_params = (eta)\n\n    print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))\nelse:\n    #Print final params to use for the model\n    params['silent'] = 0 #Turn on output\n    print(params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def XGBmodel(Xtrain,Xtest,ytrain,ytest):\n    matrix_train = xgb.DMatrix(Xtrain,label=ytrain)\n    matrix_test = xgb.DMatrix(Xtest,label=ytest)\n    model=xgb.train(params=params\n                                  ,dtrain=matrix_train,num_boost_round=200, \n                    early_stopping_rounds=20,evals=[(matrix_test,'test')],)\n    return model\n\nmodel=XGBmodel(Xtrain,Xtest,ytrain,ytest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nxgbcv_pred= model.predict(xgb.DMatrix(x_pred), ntree_limit = model.best_ntree_limit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbcv_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linmodel_pred, rfr_pred, xgb_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assigning weights. More precise models gets higher weight.\nlinmodel_weight = 1\nrfr_weight = 3\nxgbcv_weight = 1\nprediction = (linmodel_pred * linmodel_weight + rfr_pred * rfr_weight + xgbcv_pred * xgbcv_weight) / (linmodel_weight + rfr_weight + xgbcv_weight)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6)Submission\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add to submission\nsubmission = pd.DataFrame({\n        \"key\": test['key'],\n        \"fare_amount\": prediction.round(2)\n})\n\nsubmission.to_csv('sub_fare.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7)Conclusion"},{"metadata":{},"cell_type":"markdown","source":"i have tried all the parts related to the proccess of machin learning with a variety of python package and i know there are still some problem then i hope to get your feedback to improve it."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}