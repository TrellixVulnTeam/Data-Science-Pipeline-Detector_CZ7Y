{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom pandas.plotting import scatter_matrix\n\nimport itertools\n\nimport numpy as np \nfrom numpy import loadtxt\n\nfrom scipy.stats import spearmanr\n\nfrom scipy import stats\nfrom scipy.stats import boxcox\nfrom scipy.stats import skew\n\nimport category_encoders as ce\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nimport missingno as msno\n\nfrom sklearn import neighbors\nfrom sklearn import linear_model\n\nfrom sklearn import model_selection, preprocessing\n\nfrom sklearn.preprocessing import StandardScaler, Imputer\n\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression, mutual_info_regression\n\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom bokeh.plotting import figure\nfrom bokeh.io import output_notebook, show\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.transform import factor_cmap\nfrom bokeh.palettes import Viridis\nfrom bokeh.models import ColumnDataSource\noutput_notebook()\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pour l'importation des données, je sélectionne uniquement 1 000 000 d'observations pour réduire le temps de calcul. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/train.csv\", nrows = 1_000_000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"def first_info(data):\n    '''\n    # Affiche un résumé complet du dataset\n    '''\n    print(data.head())\n    print(data.info())\n    print(data.describe())\n    \nfirst_info(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La variable à prédire, \"fare_amount\", est très étendue. Ce sont certainement des valeurs extrêmes. \nLa variable \"passenger_count\", a une faible étendue (faible écart-type), à l'exception peut être d'une ou plusieurs valeurs qui semblent extrêmes. Même constat pour les variables de coordonnées. \n\nIl y a très peu de valeurs manquantes."},{"metadata":{"trusted":true},"cell_type":"code","source":"#************************************************************************************\n#                                                                                   *\n#                               Nettoyer les données                                *\n#                                                                                   *\n#*************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"#************************** TRAITEMENT DES VALEURS MANQUANTES ***********************\n\ndef count_nan_values (data):\n    '''\n    # Affiche un tableau des valeurs manquantes avec les pourcentages\n    '''\n    total = data.isnull().sum().sort_values(ascending=False)\n    percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    print(missing_data.head(20))\n    \nprint(count_nan_values(df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comme prévu, nous observons une part infine de valeurs manquantes 0,0001% pour 2 différentes variables.\n\nNéanmoins nous avons détécté des zéros dans les colonnes relatives aux coordonnées. Ces valeurs peuvent correspondre à des courses annulées par le chauffeur ou par le client. \n\nPour vérifier notre hypothèse nous allons réaliser un nuage de point avec uniquement ces valeurs et le montant des courses associées. \n\nNous créons une nouvelle variable \"distance\" à partir des coordonnées. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def haversine(lon1, lat1, lon2, lat2, earth_radius=6367):\n    \"\"\"\n    Calculer les kilomètres parcourus en fonction des longétudes et lattitudes\n    Tous les arguments doivent être de même longueur.\n    \n    \"\"\"\n    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n\n    c = 2 * np.arcsin(np.sqrt(a))\n    km = earth_radius * c\n    return km\n\ndf['distance'] = df[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude','dropoff_latitude']].apply(lambda x: haversine(x[1], x[0], x[3], x[2]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.distance.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df[df.distance == 0]\nlen(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_test.distance\ny = df_test.fare_amount\nhover = HoverTool(tooltips=[(\"(distance,prix)\", \"(@x, @y)\")])\n\np = figure(plot_width=600, plot_height=400)\np.circle(x,y, size=3, color=\"navy\", alpha=0.5)\np.add_tools(hover)\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Les montants des courses sont étranges pour des distances nuls. Le minimum est négatif (-20$) et de nombreuses observations présentent des prix très élevés. Notre hypothèse semble peu probable. \n\nNous ferons le choix de considérer ces données commes des données manquantes. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Nous remplaçons les observations égales à 0 dans les coordonnées en valeurs manquantes.\ncoord = ['pickup_longitude','pickup_latitude', \n         'dropoff_longitude', 'dropoff_latitude']\n\nfor i in coord :\n    df[i] = df[i].replace(0,np.nan)\n    \nprint(\"\")    \nprint(\"En tenant compte des zéros dans les coordonnées\")\nprint(\"***********************************************\")\nprint(count_nan_values(df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pour visualiser la répartition de nos valeurs manquantes, nous pouvons utiliser une matrice et heatmap. "},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(df)\nmsno.heatmap(df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La matrice nous montre que de nombreuses valeurs manquantes se recoupent sur les mêmes variables. Une hypothèse confirmée par la heatmap. \nUne corrélation de 1 indique que ce sont bien les mêmes valeurs manquantes entre les variables.\nUne corrélation de <1 indique une corrélation presque parfaitement positive : certaines observations sont dans l'une ou l'autre mais pas les deux. \n\n\nLe pourcentage de valeur manquante est tellement faible et nous disposons de très nombreuses observations (55 millions) que nous préférons supprimer ces valeurs plutôt que d'utiliser une méthode d'imputation de données. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)\ncount_nan_values(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#************************************* TRAITEMENT OUTLIERS **************************","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nous avons besoin de visualiser la distribution des variables pour détecter les outliers. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.scatterplot(x=\"distance\", y=\"fare_amount\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il y a un ensemble de valeurs qui ne font pas sens.\nCertaines observations se situent en dessous de 0$, indiquant un prix de course négatif. \nD'autres se situent loin sur l'axe des axcisses et pourtant proche de 0 sur l'axe des ordonnées signifiant que des trajets en taxis très longs (plusieurs miliers de kilomètres) ont été facturés que quelques dollars. \nInversement des observations se situent loin sur l'axe des ordonnées et proche de la valeur 0 en absisse."},{"metadata":{},"cell_type":"markdown","source":"Nous considérons comme outliers : \n\n1. les observations inférieures à 0 dans la variable fare_amount. Une course de taxi ne peut être inférieure à 0$. \n2. les observations des coordonnées qui ne correspondent pas à celles de New York. D'après les informations trouvées sur internet, **la lattitude et longétude de la ville sont respectivement 40.7648 et -73.9808. **. Nous étendons les limites à 5 de part et d'autre. \n3. les observations supérieures à 8 dans la variable passenger_count. Nous considérons qu'un taxi ne peut prendre plus de 8 passagers. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def delete_outlier(data):\n    return data[(data.fare_amount > 0) & \n            (df.pickup_longitude > -78) & (df.pickup_longitude < -68) &\n            (df.pickup_latitude > 35) & (df.pickup_latitude < 45) &\n            (df.dropoff_longitude > -78) & (df.dropoff_longitude < -68) &\n            (df.dropoff_latitude > 35) & (df.dropoff_latitude < 45) &\n            (df.passenger_count > 0) & (df.passenger_count < 8)]\n\ndf_out = delete_outlier(df)\n\nprint(\"Nombre des observations supprimées:\",len(df) - len(df_out))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.distplot(df_out.fare_amount, bins=100);\nplt.xlim(0,100)\nplt.title(\"Histogramme du prix\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.scatterplot(x=\"distance\", y=\"fare_amount\", data=df_out)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Certaines observations semblent encore extrêmes. \nCependant nous manquons d'informations pour réellement déterminer s'il s'agit d'outliers.\nA titre d'exemple nous ignorons **le temps de trajet de la course**. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#************************************************************************************\n#                                                                                   *\n#                               Data Visualization                                  *\n#                                                                                   *\n#************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#*********************************** Times series  **********************************","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"def extract_date (dataset):\n    '''\n    # Transformation de la variable date en datetime et extraction des années, mois, jours\n    '''\n    dataset.loc[:,'pickup_datetime'] = pd.to_datetime(dataset.loc[:,'pickup_datetime'])\n    \n    dataset['month'] = pd.DatetimeIndex(dataset['pickup_datetime']).month\n    dataset['month_name'] = dataset['month'].map({1:\"Janvier\",2:\"Fevrier\",3:\"Mars\",4:\"Avril\",\n                                                 5:\"Mai\",6:\"Juin\",7:\"Juillet\",8:\"Aout\",\n                                                 9:\"Septembre\",10:\"Octobre\",11:\"Novembre\",12:\"Decembre\"})\n    \n    dataset['year']= pd.DatetimeIndex(dataset['pickup_datetime']).year\n    dataset[\"month_year\"] = dataset[\"year\"].astype(str) + \" - \" + dataset[\"month_name\"]\n    \n    dataset['day']=pd.DatetimeIndex(dataset['pickup_datetime']).weekday\n    dataset[\"day_name\"] = dataset[\"day\"].replace([0,1,2,3,4,5,6],\n                                            [\"Lundi\",\"Mardi\",\"Mercredi\",\"Jeudi\",\n                                             \"Vendredi\",\"Samedi\",\"Dimanche\"])\n    \n    dataset['hour']=pd.DatetimeIndex(dataset['pickup_datetime']).hour\n    \n    dataset = dataset.sort_values(by = \"pickup_datetime\", ascending = False)\n\nextract_date(df_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = df_out.groupby('day_name')['distance', 'year'].count()\n\nsource = ColumnDataSource(grouped)\nday = source.data['day_name'].tolist()\n\nd = figure(x_range=day)\npal = Viridis[7]\ncolor_map = factor_cmap(field_name='day_name',palette=pal, factors=day)\n\nd.vbar(x='day_name', top='year', source=source, width=0.70, color=color_map)\nd.add_tools(HoverTool(tooltips= [(\"Total\", \"@distance\")]))\n\nd.title.text ='Nombre de course selon les jours'\nd.xaxis.axis_label = 'Jour de la semaine'\nd.yaxis.axis_label = 'Nombre de course'\n\nshow(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.lineplot(x=\"hour\", y=\"fare_amount\", data=df_out, hue='day_name', \n             hue_order=[\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"], \n             ci=None, marker=\"o\", palette=pal);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trips_hr = df_out[\"hour\"].value_counts().reset_index()\ntrips_hr.columns = [\"hour\",\"count\"]\ntrips_hr = trips_hr.sort_values(by = \"hour\",ascending = True)\nx=trips_hr['hour']\ny=trips_hr['count']\n\n# Instanciation de la figure\np = figure(plot_width= 800, plot_height=500)\np.line(x, y, line_color=\"black\")\n\nr1 = p.circle(x, y, legend='count')\nr1.glyph.size=10\nr1.glyph.fill_alpha=0.2\n\nr2 = p.circle(x,y, size=20, hover_color = 'navy', hover_alpha=0.4, line_color=None, \n              line_width=0, fill_alpha=0.05, legend='count', fill_color='navy')\n\np.add_tools(HoverTool(tooltips= [(\"index\", \"$index\"), (\"(count)\", \"($y)\")], renderers=[r2]))\n\n# Changement des labels de l'axe \np.xaxis.axis_label = \"Heure de la journée\"\np.yaxis.axis_label = \"Nombre de course\"\n\n# Changements de la couleur des axes\np.xaxis.major_label_text_color = \"navy\"\np.yaxis.major_label_text_color = \"navy\"\n\n# Changements sur la grille\np.xgrid.grid_line_color = None\np.ygrid.band_fill_alpha = 0.05\np.ygrid.band_fill_color = \"silver\"\n\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trip_count = df_out.groupby([\"year\",\"month\",\"month_name\"])[\"month_year\"].value_counts().to_frame()\ntrip_count.columns = [\"count\"]\ntrip_count = trip_count.reset_index()\nxi=trip_count['month_year']\nyi=trip_count['count']\n\nfig, ax = plt.subplots(figsize=(40, 20))\nsns.lineplot(xi, yi, marker=\"o\", palette=pal, color=\"navy\")\n\nax.set(xlabel=\"Date\", ylabel=\"Value\", )\nax.set_xticklabels(labels=trip_count[\"month_year\"], rotation=45);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le graphique nous permet de visualiser que des données sont manquantes pour l'année 2015. \nLa récolte des données a dû s'arreter en milieu d'année. \nCela pourrait contribuer à perturber notre modèle. Nous faisons le choix d'exclure les données de 2015, sachant que nous disposons d'un large échantillon de donnée. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_out = df_out[df_out.year != 2015]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.countplot(x=\"day_name\", data=df_out, \n              order=[\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"], hue=\"year\", palette=pal )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.countplot(x=\"passenger_count\", data=df_out, palette=pal)\nplt.title(\"Distribution du nombre de passager\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr_hist2, edges2 = np.histogram(df_out['fare_amount'], \n                               bins = int(64.5/2), \n                               range = [0, 100])\nprix_course = pd.DataFrame({'prix': arr_hist2, \n                       'left': edges2[:-1], \n                       'right': edges2[1:]})\n\nprix_course['f_interval'] = ['%d to %d $' % (left, right) for left, right in zip(prix_course['left'], prix_course['right'])]\nsource_prix = ColumnDataSource(prix_course)\n\ne = figure(plot_height = 800, plot_width = 800, title = 'Histogramme du nombre de course selon les prix', \n           x_axis_label = 'Prix ($)]', \n           y_axis_label = 'Nombre de course')\n\ne.quad(bottom=0, top='prix', left='left', right='right', source=source_prix, fill_color='lightgray', \n       line_color='dimgray', fill_alpha = 0.75, hover_fill_alpha = 1.0, hover_fill_color = 'olive')\n\ne.xaxis.major_label_text_color = \"olive\"\ne.yaxis.major_label_text_color = \"olive\"\n\ne.add_tools(HoverTool(tooltips = [('Interval', '@f_interval'),('(prix,nombre)', '($x, $y)')]))\nshow(e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remarque que la distribution présente une asymétrie à droite (loi de poisson). La très grande majorité des courses se situent entre 0 et 20$. "},{"metadata":{"trusted":true},"cell_type":"code","source":"arr_hist, edges = np.histogram(df_out['distance'], \n                               bins = int(18/0.2), \n                               range = [0, 18])\ncourse = pd.DataFrame({'dist_course': arr_hist, \n                       'left': edges[:-1], \n                       'right': edges[1:]})\n\ncourse['f_interval'] = ['%d to %d km' % (left, right) for left, right in zip(course['left'], course['right'])]\nsrc = ColumnDataSource(course)\n\nh = figure(plot_height = 800, plot_width = 800, title = 'Histogramme du nombre de course selon la distance', \n           x_axis_label = 'Distance (km)]', \n           y_axis_label = 'Nombre de course')\n\nh.quad(bottom=0, top='dist_course', left='left', right='right', source=src, fill_color='aliceblue', \n       line_color='navy', fill_alpha = 0.75, hover_fill_alpha = 1.0, hover_fill_color = 'mediumseagreen')\n\nh.add_tools(HoverTool(tooltips = [('Interval', '@f_interval'),('(distance,nombre)', '($x, $y)')]))\nshow(h)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remarque que la distribution présente une asymétrie à droite également (loi de poisson). La très grande majorité des courses sont des \"petites courses\" : de 0 à 5 km"},{"metadata":{"trusted":true},"cell_type":"code","source":"#************************************************************************************\n#                                                                                   *\n#                               Sélection des variables                             *\n#                                                                                   *\n#************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def list_matrix (data, var='var'):\n    '''\n        # Affiche une liste décroissante des corrélations avec la variable cible. \n        '''\n    corr_matrix = data.corr(method='pearson')\n    print(corr_matrix[var].sort_values(ascending=False))\n\nlist_matrix(df_out, var='fare_amount')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def corr_matrix(data):\n    '''\n        # Affiche une matrice de corrélation de toutes les variables\n        '''\n    corr_data=data.corr(method='pearson')\n    sns.set(style=\"white\")\n    \n    mask = np.zeros_like(corr_data, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n    \n    f, ax = plt.subplots(figsize=(40, 40))\n    \n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n    \n    sns.heatmap(corr_data, mask=mask, cmap=cmap, annot=True, vmax=.3, center=0,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    \ncorr_matrix(df_out)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On peut lire que notre variable distance est très corrélé avec la variable du prix. \nUn modèle simple de régression linéaire pourrait être efficace. \n\nComme nous pouvions le deviner les variables de coordonnées sont très corrélées entre elles et avec notre nouvelle variable \"distance\". \nNous pouvons supprimer les variables de coordonnées, ainsi que la variable de temps. "},{"metadata":{},"cell_type":"markdown","source":"Pour les variables qui ne suivent pas une distribution gaussienne, il peut être utile de vérifier les corrélations avec le coefficient de spearman. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Suppression des variables inutiles \ndf_fare = df_out.drop([\"pickup_longitude\", \"pickup_latitude\",\n                       \"dropoff_longitude\", \"dropoff_latitude\",\n                        \"pickup_datetime\", \"key\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_correlation_test (cols, colors, data, nrows=3, ncols=2, var=\"var\"):\n    plt.rcParams['figure.figsize'] = [25, 15]\n\n    fig, ax = plt.subplots(nrows, ncols)\n\n    ax=ax.flatten()\n\n    j=0\n\n    for i in ax:\n        if j==0:\n            i.set_ylabel(var)\n        i.scatter(data[cols[j]], data[var],  alpha=0.5, color=colors[j])\n        i.set_xlabel(cols[j])\n        i.set_title('Pearson: %s'%data.corr().loc[cols[j]][var].round(2)+' Spearman: %s'%data.corr(method='spearman').loc[cols[j]][var].round(2))\n        j+=1\n\n    plt.show()\n    \ncols = ['distance', 'day', 'month','year',\"passenger_count\",\"hour\"]\ncolors=['#415952', '#f35134', '#243AB5', '#243AB5', 'olive', 'salmon']\n\nplot_correlation_test(cols, colors, df_fare, nrows=3, ncols=2, var=\"fare_amount\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il n'apparaît pas de grosses différenres entres les deux tests statistiques \nLes coefficients de corrélation Pearson et Spearman sont proches. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df_fare.drop([\"fare_amount\", \"month_name\", \"month_year\", \"day_name\"], axis=1)\ntarget = df_fare.fare_amount\n\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = list(df_fare.columns.values)\nsel = SelectKBest(score_func=f_regression, k=4)\nsel.fit(X_train, y_train)\ndf_new = sel.transform(X_train)\nmask = sel.get_support()\nvector_names = list(X_train.columns[sel.get_support()])\nprint(vector_names)\n\nplt.matshow(mask.reshape(1,-1), cmap = 'gray_r')\nplt.xlabel('Axe des features');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Les quatres variables les plus importantes semblent être la distance, le mois, l'année et l'heure. Dans une dynamique d'optimisation des résultats de notre modèle, nous pourrions supprimmer les variables non sélectionnées. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#************************************************************************************\n#                                                                                   *\n#                                Construction des modèles                           *\n#                                                                                   *\n#************************************************************************************","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rappel : La métrique d'évaluation pour ce concours est l'erreur quadratique moyenne ou RMSE. La RMSE mesure la différence entre les prédictions d'un modèle et les vraies valeurs. Une RMSE élevée équivaut à une erreur moyenne importante. \n\nNous testons 3 modèles différents, nous sélectionnerons le modèle qui présente la meilleure RMSE : \n\n* Régression linéaire \n* Gradient Boosting \n* XGBoosting "},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_data (data):\n    '''\n        # Standardisation des données avec le score Z\n        '''\n    data.copy()\n    scaler = preprocessing.StandardScaler().fit(data)\n    data_scaled = scaler.transform(data)\n    columns = data.columns\n    data_scaled = pd.DataFrame(data=data_scaled, columns=columns)\n    \n    return (data_scaled)\n\nX_train_scaled = scale_data(X_train)\nX_test_scaled = scale_data(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#*********************************** Regression Linéaire ****************************\nlr = LinearRegression()\nlr.fit(X_train_scaled, y_train)\n\ndef print_coefs (regression, data):\n    coeffs = list(regression.coef_)\n    coeffs.insert(0, regression.intercept_)\n\n    feats = list(data.columns)\n    feats.insert(0, 'intercept')\n\n    print(pd.DataFrame({'valeur estimée': coeffs}, index = feats))\n\nprint_coefs(lr, data)\nprint(lr.score(X_train_scaled, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse(predictions, targets):\n    return print(\"RMSE:\",np.sqrt(((predictions - targets) ** 2).mean()))\n\npred_test = lr.predict(X_test_scaled)\nrmse(pred_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def QQ_plot (regression, X_train, y_train):\n    pred_train = regression.predict(X_train)\n    residus = pred_train - y_train\n    residus_norm = (residus - residus.mean())/residus.std()\n    stats.probplot(residus_norm, plot=plt)\n    plt.show()\n\nQQ_plot(lr, X_train_scaled, y_train)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Le diagramme Quantile-Quantile ou (Q-Q plot) permet d'évaluer la pertinence de l'ajustement d'une distribution donnée à un modèle théorique. Ainsi la normalité des résidus (une fois centrés réduis) se valide facilement: si les points sont alignés sur la première bissectrice c'est que la distribution des résidus suit probablement une loi gaussienne normalisée. Ce qui n'est pas le cas ici. Cela indique que notre modèle n'est pas forcément le plus approprié. "},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"#*********************************** Gradient Boosting ******************************\n\nparams = { 'n_estimators': 1000,\n          'learning_rate' : 0.01, # Résultat d'une recherche par cadrillage\n          'max_depth' : 2, # Résultat d'une recherche par cadrillage\n          'loss' : 'ls' # Résultat d'une recherche par cadrillage\n         }\n\nmodel_est = GradientBoostingRegressor(**params, random_state=10)\nmodel_est.fit(X_train_scaled, y_train)\n\npred_est = model_est.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_est_train = model_est.predict(X_train_scaled)\nrmse(pred_est, y_test)\nrmse(pred_est_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n\nfor i, pred_est in enumerate(model_est.staged_predict(X_test_scaled)):\n    test_score[i] = model_est.loss_(y_test, pred_est)\n    \ny = model_est.train_score_  \n\np = figure(plot_width= 800, plot_height=500)\np1 = p.line(np.arange(params['n_estimators']) + 1, y, line_color=\"mediumspringgreen\")\np.add_tools(HoverTool(tooltips = [(\"(train_score)\",\"($y)\")], renderers=[p1]))\n\np2 = p.line(np.arange(params['n_estimators']) + 1, test_score, line_color='greenyellow')\np.add_tools(HoverTool(tooltips = [(\"(test_score)\",\"($test_score)\")], renderers=[p2]))\n\n# Changement des labels de l'axe \np.xaxis.axis_label = \"Boosting iterations\"\np.yaxis.axis_label = \"Deviance\"\n\n# Changements de la couleur des axes\np.xaxis.major_label_text_color = \"lightgray\"\np.yaxis.major_label_text_color = \"lightgray\"\n\n# Changements sur la grille\np.xgrid.grid_line_color = None\np.ygrid.band_fill_alpha = 0.05\np.ygrid.band_fill_color = \"silver\"\n\nshow(p)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_features_importances (model, data):\n    \" Fonction pour afficher les variables les plus importantes du modèle. \"\n    feature_importance = model.feature_importances_\n\n    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n    sorted_idx = np.argsort(feature_importance)\n    pos = np.arange(sorted_idx.shape[0]) + .5\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 1, 1)\n    plt.barh(pos, feature_importance[sorted_idx], align='center')\n    plt.yticks(pos, data.columns[sorted_idx])\n    plt.xlabel('Relative Importance')\n    plt.title('Variable Importance')\n    plt.show()\n\nplot_features_importances(model_est, data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#************************************ XGBoost Regressor *****************************\n\nparams_xgb = { 'eta': 0.01, # Résultat d'une recherche par cadrillage \n          'max_depth' : 3, # Résultat d'une recherche par cadrillage \n          'objective' : 'reg:linear'} # Résultat d'une recherche par cadrillage \n\nmodel_xgb = xgboost.XGBRegressor(**params_xgb, random_state=27, n_jobs=-1)\nmodel_xgb.fit(X_train_scaled, y_train)\npred_xgb = model_xgb.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_xgb_train = model_xgb.predict(X_train_scaled)\nrmse(pred_xgb, y_test)\nrmse(pred_xgb_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_features_importances(model_xgb, data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"QQ_plot(model_xgb, X_train_scaled, y_train)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nous obtenons la meilleur RMSE avec le modèle XGBoost. Ce modèle utilise d'avantage les autres variables. \n\nIl est probable que nous puissions améliorer le modèle en nettoyant mieux les données, notamment les valeurs extrêmes. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}