{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Initial Python environment setup...\nimport numpy as np # linear algebra\nimport pandas as pd # CSV file I/O (e.g. pd.read_csv)\nimport os # reading the input files we have access to\n\nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data =  pd.read_csv('../input/train.csv', nrows = 10_000_000)\ntrain_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data=pd.read_csv('../input/test.csv')\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Difference_longitude']=np.abs(np.asarray(train_data['pickup_longitude']-train_data['dropoff_longitude']))\ntrain_data['Difference_latitude']=np.abs(np.asarray(train_data['pickup_latitude']-train_data['dropoff_latitude']))\n\n\ntest_data['Difference_longitude']=np.abs(np.asarray(test_data['pickup_longitude']-test_data['dropoff_longitude']))\ntest_data['Difference_latitude']=np.abs(np.asarray(test_data['pickup_latitude']-test_data['dropoff_latitude']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1dbc7610bd467f1dfaf9042b5ec638eb2014aaf"},"cell_type":"markdown","source":"### Explore and prune outliers\nFirst let's see if there are any `NaN`s in the dataset."},{"metadata":{"trusted":true,"_uuid":"e808c7e75338b45ca30f9f261dfbc90845700624"},"cell_type":"code","source":"print(train_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29bc86f2fa8baa37f0c4eb4300f77a8cb69f12aa"},"cell_type":"markdown","source":"There are a small amount, so let's remove them from the dataset."},{"metadata":{"trusted":true,"_uuid":"9d8f28e24f3d4ca55ad93692329680774c341376"},"cell_type":"code","source":"print('Old size: %d' % len(train_data))\ntrain_data = train_data.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(train_data))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a045ef14c636ec726a5e8c349ca7e5fbb3a87c1"},"cell_type":"markdown","source":"Now let's quickly plot a subset of our travel vector features to see its distribution."},{"metadata":{"trusted":true,"_uuid":"97d0aa1deab1c6cf0c97a4a3a12ba7007aada6c5"},"cell_type":"code","source":"plot = train_data[:2000].plot.scatter('Difference_longitude', 'Difference_latitude')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22277d77f75e3177a5acaec9b820e0de6e869663"},"cell_type":"markdown","source":"We expect most of these values to be very small (likely between 0 and 1) since it should all be differences between GPS coordinates within one city.  For reference, one degree of latitude is about 69 miles.  However, we can see the dataset has extreme values which do not make sense.  Let's remove those values from our training set. Based on the scatterplot, it looks like we can safely exclude values above 5 (though remember the scatterplot is only showing the first 2000 rows...)"},{"metadata":{"trusted":true,"_uuid":"9703895e6c7e67b32c504f843b5ef19be2023964"},"cell_type":"code","source":"print('Old size: %d' % len(train_data))\ntrain_data = train_data[(train_data.Difference_longitude < 5.0) & (train_data.Difference_latitude < 5.0)]\nprint('New size: %d' % len(train_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract pickup time into a separate column using the pickup_datetime column\n\nls1=list(train_data['pickup_datetime'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][11:-7:]\ntrain_data['pickuptime']=ls1    \n\n\n\nls1=list(test_data['pickup_datetime'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][11:-7:]\ntest_data['pickuptime']=ls1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract weekday into a separate column from the pickup_datetime column\n\nls1=list(train_data['pickup_datetime'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][:-4:]\n    ls1[i]=pd.Timestamp(ls1[i])\n    ls1[i]=ls1[i].weekday()\ntrain_data['Weekday']=ls1\n\n\nls1=list(test_data['pickup_datetime'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][:-4:]\n    ls1[i]=pd.Timestamp(ls1[i])\n    ls1[i]=ls1[i].weekday()\ntest_data['Weekday']=ls1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop pickup_datetime as we have extracted info from it above and its not needed anymore\ntrain_data.drop('pickup_datetime',inplace=True,axis=1)\ntest_data.drop('pickup_datetime',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace numeric coded for weekdays by their names in the Weekday column \n\ntrain_data['Weekday'].replace(to_replace=[i for i in range(0,7)],\n                            value=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],\n                              inplace=True)\ntest_data['Weekday'].replace(to_replace=[i for i in range(0,7)],\n                              value=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],\n                              inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#since weekday is categorical we will one hot encode it\ntrain_one_hot=pd.get_dummies(train_data['Weekday'])\ntest_one_hot=pd.get_dummies(test_data['Weekday'])\ntrain_data=pd.concat([train_data,train_one_hot],axis=1)\ntest_data=pd.concat([test_data,test_one_hot],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop weekday column from train and test data as it has been one hot encoded\ntrain_data.drop('Weekday',axis=1,inplace=True)\ntest_data.drop('Weekday',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pickup time conversion to integer\nls1=list(train_data['pickuptime'])\nfor i in range(len(ls1)):\n    z=ls1[i].split(':')\n    ls1[i]=int(z[0])*100+int(z[1])\ntrain_data['pickuptime']=ls1\n\n\nls1=list(test_data['pickuptime'])\nfor i in range(len(ls1)):\n    z=ls1[i].split(':')\n    ls1[i]=int(z[0])*100+int(z[1])\ntest_data['pickuptime']=ls1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate distance between pickup location and dropoff location using the given latitudes and \n#longitudes\n#Formula used : HAVERSINE FORMULA\n\nR = 6373.0 #radius of earth\nlat1 =np.asarray(np.radians(train_data['pickup_latitude']))\nlon1 = np.asarray(np.radians(train_data['pickup_longitude']))\nlat2 = np.asarray(np.radians(train_data['dropoff_latitude']))\nlon2 = np.asarray(np.radians(train_data['dropoff_longitude']))\n\ndlon = lon2 - lon1\ndlat = lat2 - lat1\nls1=[] \na = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/ 2)**2\nc = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\ndistance = R * c\n\n    \ntrain_data['Distance']=np.asarray(distance)*0.621\n\n\n\nlat1 =np.asarray(np.radians(test_data['pickup_latitude']))\nlon1 = np.asarray(np.radians(test_data['pickup_longitude']))\nlat2 = np.asarray(np.radians(test_data['dropoff_latitude']))\nlon2 = np.asarray(np.radians(test_data['dropoff_longitude']))\n\ndlon = lon2 - lon1\ndlat = lat2 - lat1\n \na = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/ 2)**2\nc = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\ndistance = R * c\ntest_data['Distance']=np.asarray(distance)*0.621","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calulate pickup and dropoff distance from airport as fare rates are higher for that\n\nR = 6373.0\nlat1 =np.asarray(np.radians(train_data['pickup_latitude']))\nlon1 = np.asarray(np.radians(train_data['pickup_longitude']))\nlat2 = np.asarray(np.radians(train_data['dropoff_latitude']))\nlon2 = np.asarray(np.radians(train_data['dropoff_longitude']))\n\nlat3=np.zeros(len(train_data))+np.radians(40.6413111) #latitude of jfk airport\nlon3=np.zeros(len(train_data))+np.radians(-73.7781391)#longitude of jfk airport\ndlon_pickup = lon3 - lon1\ndlat_pickup = lat3 - lat1\nd_lon_dropoff=lon3 -lon2\nd_lat_dropoff=lat3-lat2\na1 = np.sin(dlat_pickup/2)**2 + np.cos(lat1) * np.cos(lat3) * np.sin(dlon_pickup/ 2)**2\nc1 = 2 * np.arctan2(np.sqrt(a1), np.sqrt(1 - a1))\ndistance1 = R * c1\ntrain_data['Pickup_Distance_airport']=np.asarray(distance1)*0.621\n\na2=np.sin(d_lat_dropoff/2)**2 + np.cos(lat2) * np.cos(lat3) * np.sin(d_lon_dropoff/ 2)**2\nc2 = 2 * np.arctan2(np.sqrt(a2), np.sqrt(1 - a2))\ndistance2 = R * c2\n\n    \ntrain_data['Dropoff_Distance_airport']=np.asarray(distance2)*0.621\n\n\n\nlat1 =np.asarray(np.radians(test_data['pickup_latitude']))\nlon1 = np.asarray(np.radians(test_data['pickup_longitude']))\nlat2 = np.asarray(np.radians(test_data['dropoff_latitude']))\nlon2 = np.asarray(np.radians(test_data['dropoff_longitude']))\n\nlat3=np.zeros(len(test_data))+np.radians(40.6413111)\nlon3=np.zeros(len(test_data))+np.radians(-73.7781391)\ndlon_pickup = lon3 - lon1\ndlat_pickup = lat3 - lat1\nd_lon_dropoff=lon3 -lon2\nd_lat_dropoff=lat3-lat2\na1 = np.sin(dlat_pickup/2)**2 + np.cos(lat1) * np.cos(lat3) * np.sin(dlon_pickup/ 2)**2\nc1 = 2 * np.arctan2(np.sqrt(a1), np.sqrt(1 - a1))\ndistance1 = R * c1\ntest_data['Pickup_Distance_airport']=np.asarray(distance1)*0.621\n\na2=np.sin(d_lat_dropoff/2)**2 + np.cos(lat2) * np.cos(lat3) * np.sin(d_lon_dropoff/ 2)**2\nc2 = 2 * np.arctan2(np.sqrt(a2), np.sqrt(1 - a2))\ndistance2 = R * c2\n\n    \ntest_data['Dropoff_Distance_airport']=np.asarray(distance2)*0.621","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#round all distances to 2 decimal places\n\ntrain_data['Distance']=np.round(train_data['Distance'],2)\ntrain_data['Pickup_Distance_airport']=np.round(train_data['Pickup_Distance_airport'],2)\ntrain_data['Dropoff_Distance_airport']=np.round(train_data['Dropoff_Distance_airport'],2)\ntest_data['Distance']=np.round(test_data['Distance'],2)\ntest_data['Pickup_Distance_airport']=np.round(test_data['Pickup_Distance_airport'],2)\ntest_data['Dropoff_Distance_airport']=np.round(test_data['Dropoff_Distance_airport'],2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop unecessary columns\ntrain_data.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)\ntest_data.drop(['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Covert to uniform distribution\n\ntrain_data['Difference_longitude']=np.abs(train_data['Difference_longitude']-np.mean(train_data['Difference_longitude']))\ntrain_data['Difference_longitude']=train_data['Difference_longitude']/np.var(train_data['Difference_longitude'])\ntrain_data['Difference_latitude']=np.abs(train_data['Difference_latitude']-np.mean(train_data['Difference_latitude']))\ntrain_data['Difference_latitude']=train_data['Difference_latitude']/np.var(train_data['Difference_latitude'])\ntest_data['Difference_longitude']=np.abs(test_data['Difference_longitude']-np.mean(test_data['Difference_longitude']))\ntest_data['Difference_longitude']=test_data['Difference_longitude']/np.var(test_data['Difference_longitude'])\n\ntest_data['Difference_latitude']=np.abs(test_data['Difference_latitude']-np.mean(test_data['Difference_latitude']))\ntest_data['Difference_latitude']=test_data['Difference_latitude']/np.var(test_data['Difference_latitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=train_data.drop(['key','fare_amount'],axis=1)\ny=train_data['fare_amount']\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.01,random_state=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression(normalize=True)\nlr.fit(X_train,y_train)\nprint(lr.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=np.round(lr.predict(test_data.drop('key',axis=1)),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission=pd.DataFrame(data=pred,columns=['fare_amount'])\nSubmission['key']=test_data['key']\nSubmission=Submission[['key','fare_amount']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission.set_index('key',inplace=True)\nSubmission.to_csv('Submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}