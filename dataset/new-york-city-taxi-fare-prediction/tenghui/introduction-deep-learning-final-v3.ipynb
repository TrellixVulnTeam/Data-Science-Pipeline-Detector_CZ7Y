{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:46:34.003519Z","iopub.execute_input":"2021-06-29T23:46:34.004318Z","iopub.status.idle":"2021-06-29T23:46:34.889703Z","shell.execute_reply.started":"2021-06-29T23:46:34.004159Z","shell.execute_reply":"2021-06-29T23:46:34.888497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ngpus = tf.config.experimental.list_physical_devices('GPU')\n\nif gpus:\n  # Restrict TensorFlow to only use the first GPU\n    try:\n        tf.config.experimental.set_visible_devices(gpus[7], 'GPU')\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n    except RuntimeError as e:\n        # Visible devices must be set before GPUs have been initialized\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:46:34.894027Z","iopub.execute_input":"2021-06-29T23:46:34.894473Z","iopub.status.idle":"2021-06-29T23:46:41.389676Z","shell.execute_reply.started":"2021-06-29T23:46:34.894429Z","shell.execute_reply":"2021-06-29T23:46:41.388723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load data:**","metadata":{}},{"cell_type":"code","source":"train_data= pd.read_csv('../input/taxi-data/taxi_data/train_hire_stats.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:46:41.391877Z","iopub.execute_input":"2021-06-29T23:46:41.392595Z","iopub.status.idle":"2021-06-29T23:46:41.567189Z","shell.execute_reply.started":"2021-06-29T23:46:41.392537Z","shell.execute_reply":"2021-06-29T23:46:41.566232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Preprcessing:**\n#### TURN DATE Training Data int Frequency","metadata":{}},{"cell_type":"code","source":"''' Get Training Data time '''\nholiday=['2016-02-06','2016-02-07','2016-02-08','2016-02-09','2016-02-10','2016-02-11','2016-02-12','2016-02-13','2016-02-14','2016-02-27','2016-02-28','2016-02-29',\n        '2016-04-02','2016-04-03','2016-04-04','2016-04-05','2016-06-09','2016-06-10','2016-06-11','2016-06-12',\n        '2016-09-15','2016-09-16','2016-09-17','2016-09-18',\n         '2016-10-09', '2016-10-10', '2016-10-11','2016-12-31','2017-01-01','2017-01-02',\n         '2017-01-27','2017-01-28','2017-01-29','2017-01-30','2017-01-31',\n         '2017-02-01','2017-02-25','2017-02-26','2017-02-27','2017-02-28'\n        ]\ntrain_time= pd.to_datetime(train_data['Date'], format='%Y-%m-%d')\ntrain_time_df=pd.DataFrame()\n#train_time_df[\"year\"] = time_df_for.dt.year\ntrain_time_df[\"month\"] = train_time.dt.month\ntrain_time_df[\"day\"] = train_time.dt.day\ntrain_time_df[\"weekday\"] = train_time.dt.weekday\ntrain_time_df[\"workday\"] = 0\ntrain_time_df\n'''Train_df Data time'''\n\ntrain_df= pd.DataFrame()\ntrain_time_df[\"workday\"] = 0\nfor i in train_time_df.index: \n     if train_time_df[\"weekday\"][i]==5 or  train_time_df[\"weekday\"][i]==6 or str(train_time.iloc[i]).split()[0] in holiday :\n        train_time_df[\"workday\"][i]=0\n     else:\n        train_time_df[\"workday\"][i]=1\ntrain_df['month_cos']=np.sin(2*np.pi*train_time_df[\"month\"]/12)\ntrain_df['month_sin']=np.cos(2*np.pi*train_time_df[\"month\"]/12)\ntrain_df['day_cos']=np.cos(2*np.pi*train_time_df[\"day\"]/30)\ntrain_df['day_sin']=np.sin(2*np.pi*train_time_df[\"day\"]/31)\ntrain_df['hour_cos']=np.cos(2*np.pi*train_data[\"Hour_slot\"]/24)\ntrain_df['hour_sine']=np.sin(2*np.pi*train_data[\"Hour_slot\"]/24)\ntrain_df['zone_id']=train_data['Zone_ID']\ntrain_df[\"workday\"]=train_time_df[\"workday\"]\ntrain_df['Hire_count']=train_data['Hire_count']\n# train_df['month_cos'][:]\n#fig.subplots_adjust(hspace=0.5, wspace=0.001)\nfig=plt.figure( figsize=(15, 12), facecolor='w', edgecolor='k')\nfig.subplots_adjust(hspace = .5, wspace=.005)\n# ''' Attention remmber   RUNING THE Tensorflow AFFINE TRANSFORM FIRST OTHERWISE WILL POPOUT ERROR'''\nid=1\nrow=3\ncol=1\ndata_all=[train_df['month_cos'][:8786], \n          #train_df['month_sin'][:8786], \n          \n            train_df['day_cos'][:750],\n            #train_df['day_sin'][:750],\n\n            train_df['hour_cos'][:24],\n            #train_df['hour_sine'][:24]\n         ]\ntitle=['Month_sine_cos', 'Day_sine_cos', 'Hour_sine_cos']\ni_=0\n# for i in range(3):\n#     if i==1:\n#         i=2\n#     elif i==2: \n#         i=4\n        \n#     fig.add_subplot(row, col, id)\n    \n#     plt.plot(np.array(data_all[i]), scaley=True, scalex=True)\n#     plt.plot(np.array(data_all[i+1]),scaley=True, scalex=True)\n#     plt.title(title[i_])\n#     i_+=1\n#     id+=1\n#     plt.show()   \n    #plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:46:41.569224Z","iopub.execute_input":"2021-06-29T23:46:41.569975Z","iopub.status.idle":"2021-06-29T23:48:26.782232Z","shell.execute_reply.started":"2021-06-29T23:46:41.569912Z","shell.execute_reply":"2021-06-29T23:48:26.781199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normalize Splitting Data INTO Training and Testing DATA \n**We will using 80% data for training data, 20% for validation**\n\n**1. Ensure that chopping data into windows of consecutive sample is still possible**\n\n**2.Ensure that Training/Validation data will not shuffle because due to the time sereis data --> have time and Position is matter Most**","metadata":{}},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:48:26.783628Z","iopub.execute_input":"2021-06-29T23:48:26.783951Z","iopub.status.idle":"2021-06-29T23:48:26.814747Z","shell.execute_reply.started":"2021-06-29T23:48:26.783917Z","shell.execute_reply":"2021-06-29T23:48:26.813557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"month_cos_min= np.min(train_df['day_cos'])\nmonth_cos_max= np.max(train_df['day_cos'])\nprint(month_cos_min)\nprint(month_cos_max)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:48:26.817414Z","iopub.execute_input":"2021-06-29T23:48:26.818253Z","iopub.status.idle":"2021-06-29T23:48:26.829106Z","shell.execute_reply.started":"2021-06-29T23:48:26.818189Z","shell.execute_reply":"2021-06-29T23:48:26.827872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import minmax_scale\nimport pandas as pd\n##Normalize Data \nfrom sklearn.preprocessing import OneHotEncoder\n# enc = OneHotEncoder()\nenc = OneHotEncoder()\n\n# 2. FIT\nenc.fit(train_df['zone_id'].values)\n\nzone_id=enc.transform(train_df['zone_id']).toarray()\ntrain_df['weekday']= minmax_scale(train_df['weekday'],feature_range=(0, 1))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:48:26.830801Z","iopub.execute_input":"2021-06-29T23:48:26.831582Z","iopub.status.idle":"2021-06-29T23:48:27.399264Z","shell.execute_reply.started":"2021-06-29T23:48:26.831519Z","shell.execute_reply":"2021-06-29T23:48:27.394675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nencoder= LabelEncoder()\n#train_df= train_df.drop(['Hire_count'], axis=1)\ntrain_y=pd.DataFrame()\ntrain_y['Hire_count']=encoder.fit_transform(train_df['Hire_count'].values)\ntrain_y=train_y.astype('float32')\ntrain_y\n# take the Encode label scale into Certain Range values\nscaler=MinMaxScaler(feature_range=(0,1))\ntrain_y_scale=scaler.fit_transform(train_y)## data type pass inn should in the form of (Dataframe)\nprint(np.max(train_y))\nprint(np.max(train_y_scale))\n## Invert Transform back to the orginal value\ntrue_value= scaler.inverse_transform(train_y_scale)\nprint(np.max(true_value))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.183095Z","iopub.execute_input":"2021-06-29T23:57:13.184143Z","iopub.status.idle":"2021-06-29T23:57:13.26418Z","shell.execute_reply.started":"2021-06-29T23:57:13.184036Z","shell.execute_reply":"2021-06-29T23:57:13.263041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Hire_count']= train_y_scale\ntrain_df[['zone_id']]= minmax_scale(train_df[['zone_id']],feature_range=(0, 1))\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.26593Z","iopub.execute_input":"2021-06-29T23:57:13.266274Z","iopub.status.idle":"2021-06-29T23:57:13.382463Z","shell.execute_reply.started":"2021-06-29T23:57:13.266241Z","shell.execute_reply":"2021-06-29T23:57:13.381303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\n## Here shuffle IS good IDEA for Regression Model\n#train_df=sklearn.utils.shuffle(train_df)\nn=len(train_df)\ntraining_df= train_df[0:int(n*0.8)]\nval_df= train_df[int(n*0.8):]\nprint(len(training_df))\nprint(len(val_df))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.385156Z","iopub.execute_input":"2021-06-29T23:57:13.38559Z","iopub.status.idle":"2021-06-29T23:57:13.392773Z","shell.execute_reply.started":"2021-06-29T23:57:13.385544Z","shell.execute_reply":"2021-06-29T23:57:13.391628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalize and Preprocessing for Test data**","metadata":{}},{"cell_type":"code","source":"test_data= pd.read_csv('../input/taxi-data/taxi_data/test_hire_stats.csv')\n\n\n'''Removing the Repeat in Time '''\n\ntime_df=pd.DataFrame()\n\n# test_time_df['date']= test_df['Date']\n# test_time_df['zone_id']=test_df['Zone_ID']\n# # print('Unique values of ZoneID:', time_df.zone_id.unique())\n# test_time_df_rep = test_time_df.groupby(test_time_df.columns.tolist()).size().reset_index().rename(columns={0:'count'})\n# print(test_time_df_rep)\n\n''' Get Training Data time '''\ntest_time= pd.to_datetime(test_data['Date'], format='%Y-%m-%d')\ntest_time_df=pd.DataFrame()\n#train_time_df[\"year\"] = time_df_for.dt.year\ntest_time_df[\"month\"] = test_time.dt.month\ntest_time_df[\"day\"] = test_time.dt.day\ntest_time_df[\"weekday\"] = test_time.dt.weekday\ntest_time_df\n'''Train_df Data time'''\n\ntest_df= pd.DataFrame()\ntest_df['weekday']=test_time_df['weekday']\ntest_df['month_cos']=np.sin(2*np.pi*test_time_df[\"month\"]/12)\ntest_df['month_sin']=np.cos(2*np.pi*test_time_df[\"month\"]/12)\ntest_df['day_cos']=np.cos(2*np.pi*test_time_df[\"day\"]/30)\ntest_df['day_sin']=np.sin(2*np.pi*test_time_df[\"day\"]/31)\ntest_df['hour_cos']=np.cos(2*np.pi*test_data[\"Hour_slot\"]/24)\ntest_df['hour_sine']=np.sin(2*np.pi*test_data[\"Hour_slot\"]/24)\ntest_df['zone_id']=test_data['Zone_ID']\ntest_df['Hire_count']=test_data['Hire_count']\ntest_df","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.395101Z","iopub.execute_input":"2021-06-29T23:57:13.395549Z","iopub.status.idle":"2021-06-29T23:57:13.468542Z","shell.execute_reply.started":"2021-06-29T23:57:13.395504Z","shell.execute_reply":"2021-06-29T23:57:13.467398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zone_id_int=[int(i) for i in (np.linspace(1, 25, 25))]\nprint(zone_id_int)\n# ##Normalize Data \nzone_id= minmax_scale(zone_id_int,feature_range=(0, 1))\nzone_id\ndict_val= zip(zone_id_int, zone_id)\n## GET SCALE FOR zone ID\nlist_val=[]\nfor i in dict_val: \n    list_val.append(i)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.469907Z","iopub.execute_input":"2021-06-29T23:57:13.470225Z","iopub.status.idle":"2021-06-29T23:57:13.478399Z","shell.execute_reply.started":"2021-06-29T23:57:13.470196Z","shell.execute_reply":"2021-06-29T23:57:13.477346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Convert test ZONE_ID the same SCALE\ntest_zone=test_df['zone_id']\ntest_zone_id=[]\nfor i in test_zone: \n    for l in list_val:\n        if i==l[0]: \n            #print(l[1])\n            test_zone_id.append(l[1])\n            \ntest_zone_id=np.array(test_zone_id)\ntest_df['zone_id']=test_zone_id","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.480008Z","iopub.execute_input":"2021-06-29T23:57:13.480444Z","iopub.status.idle":"2021-06-29T23:57:13.513455Z","shell.execute_reply.started":"2021-06-29T23:57:13.480401Z","shell.execute_reply":"2021-06-29T23:57:13.512267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import minmax_scale\nimport pandas as pd\n##Normalize Data \ntest_df['weekday']= minmax_scale(test_df['weekday'],feature_range=(0, 1))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.515017Z","iopub.execute_input":"2021-06-29T23:57:13.515359Z","iopub.status.idle":"2021-06-29T23:57:13.524856Z","shell.execute_reply.started":"2021-06-29T23:57:13.515328Z","shell.execute_reply":"2021-06-29T23:57:13.523945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.526306Z","iopub.execute_input":"2021-06-29T23:57:13.526834Z","iopub.status.idle":"2021-06-29T23:57:13.560038Z","shell.execute_reply.started":"2021-06-29T23:57:13.526788Z","shell.execute_reply":"2021-06-29T23:57:13.558928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model For Time Regression Model**","metadata":{}},{"cell_type":"markdown","source":"**Preparing Data Time Series for Input**","metadata":{}},{"cell_type":"code","source":"train_label=training_df['Hire_count']\ntrain_dff=training_df.drop(['Hire_count'], axis=1)\nval_label=val_df['Hire_count']\nval_dff=val_df.drop(['Hire_count'], axis=1)\ntrain_dff.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.564023Z","iopub.execute_input":"2021-06-29T23:57:13.564354Z","iopub.status.idle":"2021-06-29T23:57:13.593004Z","shell.execute_reply.started":"2021-06-29T23:57:13.564324Z","shell.execute_reply":"2021-06-29T23:57:13.591887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\n\npast = 48 #(48/step= number hour obser) \nfuture = 12 #(12/step = number prediction)\nstep = 6\nsequence_length = int(past / step)\n# the model will be showed data of 4 hours -- predict the next 2 hours\n# Calculate the Number of batch that should go through\nstart=past+future\n#end= start+ 175680\nbatch_size=256\n\n\n\ndataset_train = keras.preprocessing.timeseries_dataset_from_array(\n    train_dff,\n    train_label,\n    sequence_length=sequence_length,\n    sampling_rate=step,\n    batch_size=batch_size,\n    \n)\n\ndataset_val = keras.preprocessing.timeseries_dataset_from_array(\n    val_dff,\n    val_label,\n    sequence_length=sequence_length,\n    sampling_rate=step,\n    batch_size=batch_size,\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.594891Z","iopub.execute_input":"2021-06-29T23:57:13.595207Z","iopub.status.idle":"2021-06-29T23:57:13.807173Z","shell.execute_reply.started":"2021-06-29T23:57:13.595175Z","shell.execute_reply":"2021-06-29T23:57:13.806271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in dataset_train.take(1):\n    inputs, targets = batch\n### Taking 28 step input to predict 1 single output \nprint(\"Input shape:\", inputs.numpy().shape)\nprint(\"Target shape:\", targets.numpy().shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.808484Z","iopub.execute_input":"2021-06-29T23:57:13.808971Z","iopub.status.idle":"2021-06-29T23:57:13.988437Z","shell.execute_reply.started":"2021-06-29T23:57:13.808937Z","shell.execute_reply":"2021-06-29T23:57:13.98739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def callback_list(output_dir, checkpoint): \n    modelckpt_callback = keras.callbacks.ModelCheckpoint(\n        monitor=\"val_loss\",\n        filepath=checkpoint,\n        verbose=2,\n        save_weights_only=True,\n        save_best_only=True,\n    )\n\n    early_stopping= tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n                                                   patience= 50, mode='min')\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                 factor=np.sqrt(.1),\n                                 patience=10,\n                                 verbose=1,\n                                 mode='auto',\n                                 min_delta=0.001,\n                                 cooldown=0,\n                                 min_lr=0.0000001\n                                 )\n    ## Using lr rate schedule to growth Learning rate during the certain number of EPochs\n    lr_schedule = keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-6 * 10**(epoch / 20))\n\n    tensorboard =  tf.keras.callbacks.TensorBoard(\n            log_dir=output_dir,\n            write_graph=False,\n            update_freq='epoch',\n        )\n  \n    callbacks_list=[early_stopping, reducelr, modelckpt_callback, tensorboard]#reducelr, lr_schedule,\n    \n    return callbacks_list\n\n\n\n### Container will store all model Performance \nval_performance = {}","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:13.989699Z","iopub.execute_input":"2021-06-29T23:57:13.989988Z","iopub.status.idle":"2021-06-29T23:57:14.000759Z","shell.execute_reply.started":"2021-06-29T23:57:13.989961Z","shell.execute_reply":"2021-06-29T23:57:13.999594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Desig Normal LSTM Model**","metadata":{}},{"cell_type":"code","source":"# design Simple LSTM model\n\ninputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\nlstm_out = keras.layers.LSTM(256, return_sequences=True)(inputs)\n#lstm_out = keras.layers.LSTM(256, return_sequences=True)(lstm_out)\nlstm_out = keras.layers.LSTM(128, return_sequences=True)(lstm_out)\nlstm_out = keras.layers.LSTM(32, return_sequences=True)(lstm_out)\n#Dense = keras.layers.Dense(64)(lstm_out)\n\noutputs = keras.layers.Dense(1)(lstm_out)\n#outputs1=keras.layers.Lambda(lambda x: x * 200)(outputs)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)\n\n\noptimizer = keras.optimizers.SGD(lr=1e-3, momentum=0.9)\nmodel.compile(loss=tf.losses.MeanSquaredError(),\n                optimizer= tf.optimizers.Adam(lr=5e-3),\n                metrics=[tf.metrics.MeanAbsoluteError()])\nmodel.summary()\n#residual_lstm.compile(loss='mae', optimizer='adam', me)\n#model.load_weights('Method2_Two_lstm_model.h5')\nepochs=200\noutput_dir='./logs_select_lr_v1/multi_LSTM_redu_lr'\ncheck_point=\"muli_LSTM_check_best_lr.h5\"\n\nimport os\n# making directory\ntry:\n    os.mkdir(output_dir)\nexcept:\n    pass\n\ncallbacks_list=callback_list(output_dir, check_point)\n\nhistory=model.fit_generator(\n    dataset_train,\n    epochs=epochs,\n    validation_data=dataset_val,\n    callbacks=callbacks_list,\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T23:57:14.00266Z","iopub.execute_input":"2021-06-29T23:57:14.003139Z","iopub.status.idle":"2021-06-30T02:45:08.977626Z","shell.execute_reply.started":"2021-06-29T23:57:14.003089Z","shell.execute_reply":"2021-06-30T02:45:08.976298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-6, 1e-1, 0, 30])","metadata":{"execution":{"iopub.status.busy":"2021-06-30T02:45:08.979711Z","iopub.execute_input":"2021-06-30T02:45:08.980244Z","iopub.status.idle":"2021-06-30T02:45:09.683946Z","shell.execute_reply.started":"2021-06-30T02:45:08.980208Z","shell.execute_reply":"2021-06-30T02:45:09.682722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bidirectional LSTM Model\n**This allow input Sequence both Forward and Backwards Concatenate Both Interpretation**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ninputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\nlstm_out = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\nlstm_out = layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(lstm_out)\nlstm_out = layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True))(lstm_out)\nlstm_out = layers.Bidirectional(keras.layers.LSTM(32))(lstm_out)\n#Dense = keras.layers.Dense(64)(lstm_out)\noutputs = keras.layers.Dense(1)(lstm_out)\n#outputs1=keras.layers.Lambda(lambda x: x * 200)(outputs)\n\nBi_lstm = keras.Model(inputs=inputs, outputs=outputs)\n\noptimizer = keras.optimizers.SGD(lr=1e-3, momentum=0.9)\nBi_lstm.compile(loss=tf.losses.MeanSquaredError(),\n                optimizer= tf.optimizers.Adam(lr=5e-3),\n                metrics=[tf.metrics.MeanAbsoluteError()])\nBi_lstm.summary()\n#residual_lstm.compile(loss='mae', optimizer='adam', me)\n#model.load_weights('Method2_Two_lstm_model.h5')\nepochs=200\noutput_dir='./logs_select_lr_v1/multi_Bidirect_LSTM_reduce_lr'\ncheck_point=\"muli_Bi_LSTM_check.h5\"\n\nimport os\n# making directory\ntry:\n    os.mkdir(output_dir)\nexcept:\n    pass\n\ncallbacks_list=callback_list(output_dir, check_point)\n\nhistory1=Bi_lstm.fit_generator(\n    dataset_train,\n    epochs=epochs,\n    validation_data=dataset_val,\n    callbacks=callbacks_list,\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T02:45:09.685696Z","iopub.execute_input":"2021-06-30T02:45:09.686185Z","iopub.status.idle":"2021-06-30T06:04:03.626327Z","shell.execute_reply.started":"2021-06-30T02:45:09.686137Z","shell.execute_reply":"2021-06-30T06:04:03.624578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.semilogx(history1.history[\"lr\"], history1.history[\"loss\"])\nplt.axis([1e-6, 1e-1, 0, 30])","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:04:03.630114Z","iopub.execute_input":"2021-06-30T06:04:03.630452Z","iopub.status.idle":"2021-06-30T06:04:05.050898Z","shell.execute_reply.started":"2021-06-30T06:04:03.630399Z","shell.execute_reply":"2021-06-30T06:04:05.049832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Design ConvLSTM model","metadata":{}},{"cell_type":"code","source":"inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\nconv= layers.Conv1D(filters=125, kernel_size=4,  strides=1, \n                    padding=\"causal\", activation=\"relu\")(inputs)\nlstm_out = layers.LSTM(256, return_sequences=True)(conv)\nlstm_out = keras.layers.LSTM(128, return_sequences=True)(lstm_out)\n# lstm_out = keras.layers.LSTM(128, return_sequences=True)(lstm_out)\nlstm_out =keras.layers.LSTM(64, return_sequences=True)(lstm_out)\nlstm_out = keras.layers.LSTM(32)(lstm_out)\n#Dense = keras.layers.Dense(64)(lstm_out)\noutputs = keras.layers.Dense(1)(lstm_out)\n\n#outputs1=keras.layers.Lambda(lambda x: x * 200)(outputs)\n\nconv_lstm = keras.Model(inputs=inputs, outputs=outputs)\n\n\noptimizer = keras.optimizers.SGD(lr=1e-3, momentum=0.9)\nconv_lstm.compile(loss=tf.losses.MeanSquaredError(),\n                optimizer= tf.optimizers.Adam(lr=5e-3),\n                metrics=[tf.metrics.MeanAbsoluteError()])\nconv_lstm.summary()\n\nepochs=200\noutput_dir='./logs_select_lr/multi_Conv_LSTM'\ncheck_point=\"muli_Conv_LSTM_check.h5\"\n\nimport os\n# making directory\ntry:\n    os.mkdir(output_dir)\nexcept:\n    pass\n\ncallbacks_list=callback_list(output_dir, check_point)\n\nhistory2=conv_lstm.fit_generator(\n    dataset_train,\n    epochs=epochs,\n    validation_data=dataset_val,\n    callbacks=callbacks_list,\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T06:04:05.052431Z","iopub.execute_input":"2021-06-30T06:04:05.05271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.semilogx(history2.history[\"lr\"], history2.history[\"loss\"])\nplt.axis([1e-6, 1e-1, 0, 30])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Prediction and Evaluate","metadata":{}},{"cell_type":"code","source":"'''Evaluate model on Validation Dataset'''\nval_perform={}\nmodel.load_weights(\"muli_LSTM_check_best_lr.h5\")\nBi_lstm.load_weights('muli_Bi_LSTM_check.h5'), \nconv_lstm.load_weights('muli_Conv_LSTM_check.h5')\n\n\nval_perform['LSTM'] = model.evaluate(dataset_val)\nval_perform['Conv_LSTM'] = Bi_lstm.evaluate(dataset_val)\nval_perform['Bi_LSTM'] = conv_lstm.evaluate(dataset_val)\n\n\nx = np.arange(len(val_performance))\nwidth = 0.3\n\nmetric_name = 'mean_absolute_error'\nmetric_index = conv_lstm.metrics_names.index('mean_absolute_error')\nval_mae = [v[metric_index] for v in val_perform.values()]\n\nplt.bar(x - 0.17, val_mae, width, label='Validation')\nplt.xticks(ticks=x, labels=val_perform.keys(),\n           rotation=45)\nplt.ylabel(f'MAE (average over all times and outputs)')\n_ = plt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Evaluate for single model","metadata":{}},{"cell_type":"code","source":"'''This custom for single MODEL'''\nconv_lstm.load_weights('muli_Conv_LSTM_check.h5')\nBi_lstm.load_weights('muli_Bi_LSTM_check.h5')\nmodel.load_weights(\"muli_LSTM_check_best_lr.h5\")\nresult=[]\nfor batch in test_df_data:\n    predict=model.predict(batch)\n    result.extend(predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(result))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df=pd.DataFrame(result)\nsns.displot(result_df)\npredict_result = scaler.inverse_transform(result_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(predict_result) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.max(predict_result[100:1000])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Result Evaluate for Multiple Model","metadata":{}},{"cell_type":"code","source":"# model.load_weights(\"muli_LSTM_check.h5\")\n# Bi_lstm.load_weights('muli_Bi_LSTM_check.h5'), \nconv_lstm.load_weights('muli_Conv_LSTM_check.h5')\nall_model=[ model,Bi_lstm, \n           conv_lstm ]\n\nall_prediction=[]\nfor i in range(3): \n    result=[]\n    for batch in test_df_data:\n        predict=all_model[i].predict(batch)\n        result.extend(predict)\n    all_prediction.append(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result=np.array(all_prediction)\nresult1=result[0, :, :]\nresult2=result[1, :, :]\nresult3=result[2, :, :]\n#print(result3[1:50])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncol_name=['lstm', 'bi_lstm', 'conv_lstm']\nresult_df=pd.DataFrame( columns=col_name)\nresult_df['lstm']=result1.reshape(6045,)\nresult_df['bi_lstm']=result2.reshape(6045,)\nresult_df['conv_lstm']=result3.reshape(6045,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(result_df['lstm'])\nsns.displot(result_df['bi_lstm'])\nsns.displot(result_df['conv_lstm'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df=pd.DataFrame(columns=col_name)\nprint(all_df)\n#model_=['lstm', 'bi_lstm','conv_lstm' ]\nfor i in range(3): \n    model_=['lstm', 'bi_lstm','conv_lstm' ]\n    test=result_df[model_[i]]\n    test=np.array(test)\n    \n    predict_result = scaler.inverse_transform(test.reshape(6045, 1))\n    df=pd.DataFrame(predict_result)\n    df.to_csv(model_[i]+\".csv\")\n\n#     test_id=model[i]\n#     all_df[test_id]=DF\n    \n# sns.displot(all_df['lstm']) \n# sns.displot(all_df['bi_lstm']) \n# sns.displot(all_df['conv_lstm']) \n\n# all_df.to_csv('predict9.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_plot(plot_data, delta, title):\n    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n    marker = [\".-\", \"rx\", \"go\"]\n    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n    if delta:\n        future = delta\n    else:\n        future = 0\n\n    plt.title(title)\n    for i, val in enumerate(plot_data):\n        if i:\n            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n        else:\n            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n    plt.legend()\n    plt.xlim([time_steps[0], (future + 5) * 2])\n    plt.xlabel(\"Time-Step\")\n    plt.show()\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor x, y in dataset_val.take(5):\n    print(x.shape)\n    #print(y.shape)\n    result=model.predict(x)[0][0]\n    print(result.shape)\n    \n    show_plot(\n        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0][0]],\n        12,\n        \"Single Step Prediction\",\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}