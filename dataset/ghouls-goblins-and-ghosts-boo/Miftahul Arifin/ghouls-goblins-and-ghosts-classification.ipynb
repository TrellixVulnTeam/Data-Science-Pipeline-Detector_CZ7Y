{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Ghouls, Goblins, and Ghosts Classification with Voting Classifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Outline\n1. Import Libraries\n2. Load and Check Data\n<br>&nbsp;2.1 Load data\n<br>&nbsp;2.2 Outlier detection\n<br>&nbsp;2.3 Join train and test data\n<br>&nbsp;2.4 Check for null and missing values\n3. Feature Analysis\n<br>&nbsp;3.1 Numerical Analysis\n<br>&nbsp;3.2 Categorical Analysis\n4. Feature Engineering\n<br>&nbsp;4.1 Dummies color\n5. Modelling\n<br>&nbsp;5.1 Preparation\n<br>&nbsp;5.2 Cross Validate Model\n<br>&nbsp;5.3 Hyperparameter tuning for best models\n<br>&nbsp;5.4 Learning curves of best models\n<br>&nbsp;5.5 Tree based feature importance\n<br>&nbsp;5.6 Correlation of best models\n6. Prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. Import Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom collections import Counter\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\nsns.set(style='white', context='notebook', palette='deep')\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Load and Check Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2.1 Load data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/data-ghoul/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/data-ghoul/test.csv\")\nIDtest = test[\"id\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2 Outlier detection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Outlier detection \n\ndef detect_outliers(df,n,features):\n    outlier_indices = []\n    \n    for col in features:\n        Q1 = np.percentile(df[col], 25)\n        Q3 = np.percentile(df[col],75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n## Detect outliers from Age, SibSp , Parch and Fare (numerical features)\nOutliers_to_drop = detect_outliers(train,2,[\"bone_length\",\"rotting_flesh\",\"hair_length\",\"has_soul\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the outliers rows\ntrain.loc[Outliers_to_drop]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No outlier found","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"####  2.3 Join train and test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Join train and test data to obtain the same number of features during categorical conversion\ntrain_len = len(train)\ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.4 Check for null and missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Fill empty and NaNs values with NaN\ndataset = dataset.fillna(np.nan)\n\n## Check for Null values\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing value found","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Feature Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Numerical values : bone_length, rotting_flesh, hair_length, has_soul\n- Categorical values : color, type","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 3.1 Numerical Analysis","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## Replace string to int\ntrain[\"type_int\"] = train[\"type\"].replace({\n    \"Ghoul\":1,\n    \"Goblin\":2,\n    \"Ghost\":3\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Correlation matrix\nsns.heatmap(train[[\"type_int\", \"bone_length\", \"rotting_flesh\", \"hair_length\", \"has_soul\"]].corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- feature bone_length","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Distribution plot\ndef f_dist_plot(col):\n    g = sns.FacetGrid(train, col=\"type\")\n    g = g.map(sns.distplot, col)\n    \nf_dist_plot(\"bone_length\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## KDE Plot \ndef f_kde_plot(col):\n    g = sns.kdeplot(train[col][(train[\"type_int\"] == 1) & (train[col].notnull())], color=\"Red\", shade = True)\n    g = sns.kdeplot(train[col][(train[\"type_int\"] == 2) & (train[col].notnull())], ax =g, color=\"Blue\", shade= True)\n    g = sns.kdeplot(train[col][(train[\"type_int\"] == 3) & (train[col].notnull())], ax =g, color=\"Green\", shade= True)\n    g.set_xlabel(col)\n    g.set_ylabel(\"Frequency\")\n    g = g.legend([\"Ghoul\",\"Goblin\",\"Ghost\"])\n\nf_kde_plot(\"bone_length\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- feature rotting_flesh","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Distribution plot\nf_dist_plot(\"rotting_flesh\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## KDE plot\nf_kde_plot(\"rotting_flesh\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- feature hair_length","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Distribution plot\nf_dist_plot(\"hair_length\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## KDE plot\nf_kde_plot(\"hair_length\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- feature has_soul","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Distribution plot\nf_dist_plot(\"has_soul\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## KDE plot\nf_kde_plot(\"has_soul\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Scatter plot has_soul vs hair_length\nsns.scatterplot(x=\"hair_length\", y=\"has_soul\", data=train, hue=\"type\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.2 Categorical Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot color vs type\nfig, axs = plt.subplots(3, 2, figsize=(10,8))\n\ndef plot_color(x, y, color, color_bar):\n    df_color = train[train[\"color\"] == color].groupby([\"type\"]).size()\n    axs[x,y].bar(df_color.index.values, df_color.values, color=color_bar)\n    axs[x,y].set_title(color)\n\nplot_color(0,0,\"clear\", \"beige\")\nplot_color(0,1,\"green\", \"g\")\nplot_color(1,0,\"black\", \"k\")\nplot_color(1,1,\"white\", \"whitesmoke\")\nplot_color(2,0,\"blue\", \"b\")\nplot_color(2,1,\"blood\", \"r\")\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 4.1 Get Dummies Color","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Convert feature color to binary\ndataset = pd.get_dummies(dataset, columns=[\"color\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Convert type from string to int\ndataset[\"type\"] = dataset[\"type\"].replace({\n    \"Ghoul\":1,\n    \"Goblin\":2,\n    \"Ghost\":3\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Modelling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 5.1 Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Separate train dataset and test dataset\ntrain = dataset[:train_len]\ntest = dataset[train_len:]\n\n## Drop type and id label\ntest.drop([\"type\", \"id\"],axis = 1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Separate X and y label\ntrain[\"type\"] = train[\"type\"].astype(int)\n\nY_train = train[\"type\"]\nX_train = train.drop([\"type\", \"id\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.2 Cross validate model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#KFold Stratified cross val\nkfold = StratifiedKFold(n_splits=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Modeling step Test differents algorithms \nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot score of cross validation models\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Hyperparameter Cross Validation Models\nclassifiers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BEST CV MODELS : LinearDiscriminantAnalysis, GradientBoosting, MultipleLayerPerceptron, LogisticRegression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 5.3 Hyperparameter tuning for best models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## LinearDiscriminantAnalysis\nLDA = LinearDiscriminantAnalysis()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\"n_components\": [None, 1, 2, 3, 4]}\n\n\ngsLDA = GridSearchCV(LDA,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsLDA.fit(X_train,Y_train)\n\nLDA_best = gsLDA.best_estimator_\n\n## Best score\ngsLDA.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Gradient boosting tunning\n\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,Y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n## Best score\ngsGBC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## MultipleLayerPerceptron\nMLP = MLPClassifier()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\n    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive'],\n}\n\n\ngsMLP = GridSearchCV(MLP, param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsMLP.fit(X_train,Y_train)\n\nMLP_best = gsMLP.best_estimator_\n\n## Best score\ngsMLP.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## LogisticRegression\nLRC = LogisticRegression()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\n    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n}\n\n\ngsLRC = GridSearchCV(LRC, param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsLRC.fit(X_train,Y_train)\n\nLRC_best = gsLRC.best_estimator_\n\n## Best score\ngsLRC.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.4 Learning curves of best models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot learning curves of best estimators\ng = plot_learning_curve(gsLDA.best_estimator_,\"Linear Discriminant Analysis learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsGBC.best_estimator_,\"Gradient Boosting learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsMLP.best_estimator_,\"MLP learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsLRC.best_estimator_,\"Logistic Regression learning curves\",X_train,Y_train,cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.5 Tree based feature importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot Feature Importance of Gradiect Boosting\n\nplt.figure(figsize=(10,10))\nnames_classifiers = [(\"GBC\",GBC_best)]\nnclassifier = 0\nname = names_classifiers[nclassifier][0]\nclassifier = names_classifiers[nclassifier][1]\nindices = np.argsort(classifier.feature_importances_)[::-1][:40]\ng = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h')\ng.set_xlabel(\"Relative importance\",fontsize=12)\ng.set_ylabel(\"Features\",fontsize=12)\ng.tick_params(labelsize=9)\ng.set_title(name + \" feature importance\")        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.6 Correlation of best models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Corealation between best models\n\ntest_type_LDA = pd.Series(LDA_best.predict(test), name=\"LDA\")\ntest_type_GBC = pd.Series(GBC_best.predict(test), name=\"GBC\")\ntest_type_MLP = pd.Series(MLP_best.predict(test), name=\"MLP\")\ntest_type_LRC = pd.Series(LRC_best.predict(test), name=\"LRC\")\n\nconcatenate_results = pd.concat([test_type_LDA,test_type_GBC,test_type_MLP,test_type_LRC],axis=1)\n\ng= sns.heatmap(concatenate_results.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concatenate_results.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Voting Classifier\nvotingC = VotingClassifier(estimators=[('lda', LDA_best), ('gbc', GBC_best),\n('mlp', MLP_best), ('lrc',LRC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Voting Classifier Model Parameter\nvotingC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Predict test data\ntest_type = pd.Series(votingC.predict(test), name=\"Type\")\ntest_type = test_type.replace({\n    1:\"Ghoul\",\n    2:\"Goblin\",\n    3:\"Ghost\"\n})\nresults = pd.concat([IDtest,test_type],axis=1)\nresults.to_csv(\"voting_prediction.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}