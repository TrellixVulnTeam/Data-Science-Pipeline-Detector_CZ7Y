{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2efbdae-dcab-df4a-5af4-e58c2bd516c2"},"outputs":[],"source":"\ndef xrange(x):\n\n    return iter(range(x))\n\ndef xaver_init(n_inputs, n_outputs, uniform = True):\n    if uniform:\n        init_range = tf.sqrt(6.0/ (n_inputs + n_outputs))\n        return tf.random_uniform_initializer(-init_range, init_range)\n\n    else:\n        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs) /2)\n        return tf.truncated_normal_initializer(stddev=stddev)\n    \n\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd \n\nlearning_rate = 0.01\n\n#reset\ntf.reset_default_graph()\n\n#데이터 셋 준비\ntrain_ori = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\n#y값에 따라 3개 클래스로 분리\ny_train = pd.get_dummies(train_ori[[\"type\"]], prefix=\"\")\n#x-color를 0,1 인코드\ncolor = pd.get_dummies(train_ori[[\"color\"]], prefix=\"\")\n\ntrain_ori.drop('type',inplace=True, axis=1)\ntrain_ori.drop('id',inplace=True, axis=1)\ntrain_ori.drop('color',inplace=True, axis=1)\n\nx_train = pd.concat([train_ori, color], axis=1)\n\n#linear regression multi variable\nx_data = np.array(x_train.values,dtype=np.float32)\ny_data = np.array(y_train.values,dtype=np.float32)\n\nX = tf.placeholder('float', [None, 10])\nY = tf.placeholder('float', [None, 3])\n\nW1 = tf.get_variable(\"W1\", shape=[10, 256], initializer=xaver_init(10, 256))\nW2 = tf.get_variable(\"W2\", shape=[256, 256], initializer=xaver_init(256, 256))\nW3 = tf.get_variable(\"W3\", shape=[256, 3], initializer=xaver_init(256, 3))\n\nB1 = tf.Variable(tf.random_normal([256]))\nB2 = tf.Variable(tf.random_normal([256]))\nB3 = tf.Variable(tf.random_normal([3]))\n\nL1 = tf.nn.relu(tf.add(tf.matmul(X, W1), B1))\nL2 = tf.nn.relu(tf.add(tf.matmul(L1, W2), B2))\n\nhypo = tf.add(tf.matmul(L2, W3), B3)\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypo, labels=Y)) # 구현되어잇는 softmax\noptimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost) # 그라디언트 보다 좀더 좋음\n\n\n\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n    sess.run(init)\n    for step in xrange(4001):\n        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n        if step % 100 == 0:\n            print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n    \n    correct_prediction = tf.equal(tf.argmax(hypo, 1), tf.argmax(Y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n    print (\"Accuracy:\", accuracy.eval({X: x_data, Y: y_data}))\n    \n\n    a = sess.run(hypo, feed_dict={X: [[0.3545121845821541,0.35083902671065004,0.4657608918291205,0.78114166586219,0,0,0,1,0,0]]})\n    print (\"a :\", a, sess.run(tf.arg_max(a, 1)))\n    \n    #테스트셋\n    test_ori = pd.read_csv(\"../input/test.csv\")\n    test_color = pd.get_dummies(test_ori[[\"color\"]], prefix=\"\")\n    id_list = test_ori['id']\n    test_ori.drop('id',inplace=True, axis=1)\n    test_ori.drop('color',inplace=True, axis=1)\n    \n    x_test = pd.concat([test_ori, color], axis=1)\n    test_data = np.array(x_test.values,dtype=np.float32)\n    \n    a = sess.run(hypo, feed_dict={X: x_test})\n    predict_ori = sess.run(tf.arg_max(a, 1))\n    \n\n    def numToName(num):\n        if num == 0:\n            return 'Ghost'\n        elif num == 1:\n            return 'Ghoul'\n        else:\n            return 'Goblin'\n\n    predic = list(map(numToName, predict_ori));\n    \n    type_field = pd.DataFrame(predic, columns = ['type'])\n    \n    result = pd.concat([id_list, type_field], axis=1)\n    print (result)\n    result.to_csv('result.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}