{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-17T16:17:10.765438Z","iopub.execute_input":"2022-03-17T16:17:10.765807Z","iopub.status.idle":"2022-03-17T16:17:11.288794Z","shell.execute_reply.started":"2022-03-17T16:17:10.765721Z","shell.execute_reply":"2022-03-17T16:17:11.288103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/ghouls-goblins-and-ghosts-boo/train.csv.zip\")\ndf_test = pd.read_csv(\"../input/ghouls-goblins-and-ghosts-boo/test.csv.zip\")","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.290172Z","iopub.execute_input":"2022-03-17T16:17:11.290535Z","iopub.status.idle":"2022-03-17T16:17:11.305438Z","shell.execute_reply.started":"2022-03-17T16:17:11.290504Z","shell.execute_reply":"2022-03-17T16:17:11.304501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.309346Z","iopub.execute_input":"2022-03-17T16:17:11.310118Z","iopub.status.idle":"2022-03-17T16:17:11.331216Z","shell.execute_reply.started":"2022-03-17T16:17:11.310075Z","shell.execute_reply":"2022-03-17T16:17:11.330545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.332876Z","iopub.execute_input":"2022-03-17T16:17:11.333551Z","iopub.status.idle":"2022-03-17T16:17:11.363075Z","shell.execute_reply.started":"2022-03-17T16:17:11.333507Z","shell.execute_reply":"2022-03-17T16:17:11.362487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.364201Z","iopub.execute_input":"2022-03-17T16:17:11.364576Z","iopub.status.idle":"2022-03-17T16:17:11.391818Z","shell.execute_reply.started":"2022-03-17T16:17:11.36453Z","shell.execute_reply":"2022-03-17T16:17:11.390906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing for NN","metadata":{}},{"cell_type":"code","source":"# drop noisy 'color' and 'id'\ndf_train.drop(columns = ['id', 'color'], inplace=True)\ndf_test.drop(columns = ['id', 'color'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.393133Z","iopub.execute_input":"2022-03-17T16:17:11.393531Z","iopub.status.idle":"2022-03-17T16:17:11.400701Z","shell.execute_reply.started":"2022-03-17T16:17:11.393483Z","shell.execute_reply":"2022-03-17T16:17:11.399933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OneHotEncode 'type'\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\ny = encoder.fit_transform(df_train['type'].to_numpy().reshape(-1, 1)).A\nX = df_train.drop(columns = ['type'])","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.401901Z","iopub.execute_input":"2022-03-17T16:17:11.402117Z","iopub.status.idle":"2022-03-17T16:17:11.458358Z","shell.execute_reply.started":"2022-03-17T16:17:11.402091Z","shell.execute_reply":"2022-03-17T16:17:11.457378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.459681Z","iopub.execute_input":"2022-03-17T16:17:11.459934Z","iopub.status.idle":"2022-03-17T16:17:11.472626Z","shell.execute_reply.started":"2022-03-17T16:17:11.459902Z","shell.execute_reply":"2022-03-17T16:17:11.471543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Network Initialization","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\nfrom torch import nn  \nfrom torch import optim\nfrom torch.utils.data import DataLoader, TensorDataset  \nfrom tqdm import tqdm  ","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.473957Z","iopub.execute_input":"2022-03-17T16:17:11.474199Z","iopub.status.idle":"2022-03-17T16:17:11.842553Z","shell.execute_reply.started":"2022-03-17T16:17:11.474168Z","shell.execute_reply":"2022-03-17T16:17:11.841529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NN(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(NN, self).__init__()\n        self.fc1 = nn.Linear(input_size, 5)\n        self.fc2 = nn.Linear(5, num_classes)\n        \n        self.dr1 = nn.BatchNorm1d(5)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dr1(x)\n        return self.fc2(x)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.845746Z","iopub.execute_input":"2022-03-17T16:17:11.846084Z","iopub.status.idle":"2022-03-17T16:17:11.853444Z","shell.execute_reply.started":"2022-03-17T16:17:11.846048Z","shell.execute_reply":"2022-03-17T16:17:11.852404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cpu\")\ninput_size = 4\nnum_classes = 3\nlearning_rate = 0.1\nbatch_size = 32\nnum_epochs = 75","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.854871Z","iopub.execute_input":"2022-03-17T16:17:11.855109Z","iopub.status.idle":"2022-03-17T16:17:11.87369Z","shell.execute_reply.started":"2022-03-17T16:17:11.855082Z","shell.execute_reply":"2022-03-17T16:17:11.872852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Utility functions**","metadata":{}},{"cell_type":"code","source":"def check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device).float()\n            _, y = y.to(device=device).max(dim = 1)\n            x = x.reshape(x.shape[0], -1).float()\n\n            scores = model(x)\n            _, predictions = scores.max(dim = 1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n    model.train()\n    return num_correct / num_samples","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.875568Z","iopub.execute_input":"2022-03-17T16:17:11.875835Z","iopub.status.idle":"2022-03-17T16:17:11.888779Z","shell.execute_reply.started":"2022-03-17T16:17:11.875803Z","shell.execute_reply":"2022-03-17T16:17:11.887869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_entropy_one_hot(out, target):\n    _, labels = target.max(dim = 1)\n    return nn.CrossEntropyLoss()(out, labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.890074Z","iopub.execute_input":"2022-03-17T16:17:11.890333Z","iopub.status.idle":"2022-03-17T16:17:11.903968Z","shell.execute_reply.started":"2022-03-17T16:17:11.8903Z","shell.execute_reply":"2022-03-17T16:17:11.902807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_prediction(model, X):\n    with torch.no_grad():\n        X = X.to(device=device)\n        scores = model(X.float())\n        _, predictions = scores.max(dim = 1)\n        predictions = predictions.cpu().numpy()\n    return predictions.T","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.905334Z","iopub.execute_input":"2022-03-17T16:17:11.906483Z","iopub.status.idle":"2022-03-17T16:17:11.917366Z","shell.execute_reply.started":"2022-03-17T16:17:11.906344Z","shell.execute_reply":"2022-03-17T16:17:11.916544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def from_prediction_to_onehot_encoding(Y):\n    preds = list()\n    for y in Y:\n        pred = [0] * num_classes\n        pred[y] = 1\n        preds.append(pred)\n    return np.array(preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.918708Z","iopub.execute_input":"2022-03-17T16:17:11.919347Z","iopub.status.idle":"2022-03-17T16:17:11.931496Z","shell.execute_reply.started":"2022-03-17T16:17:11.919308Z","shell.execute_reply":"2022-03-17T16:17:11.930598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=17)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.934276Z","iopub.execute_input":"2022-03-17T16:17:11.934578Z","iopub.status.idle":"2022-03-17T16:17:11.960176Z","shell.execute_reply.started":"2022-03-17T16:17:11.93454Z","shell.execute_reply":"2022-03-17T16:17:11.959263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_tensor = torch.from_numpy(np.vstack(X_train.to_numpy()[:, :]).astype(np.float64))\nX_test_tensor = torch.from_numpy(np.vstack(X_test.to_numpy()[:, :]).astype(np.float64))\ny_train_tensor = torch.from_numpy(y_train)\ny_test_tensor = torch.from_numpy(y_test)\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.961339Z","iopub.execute_input":"2022-03-17T16:17:11.961635Z","iopub.status.idle":"2022-03-17T16:17:11.970687Z","shell.execute_reply.started":"2022-03-17T16:17:11.961601Z","shell.execute_reply":"2022-03-17T16:17:11.969538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.972165Z","iopub.execute_input":"2022-03-17T16:17:11.973079Z","iopub.status.idle":"2022-03-17T16:17:11.9872Z","shell.execute_reply.started":"2022-03-17T16:17:11.973039Z","shell.execute_reply":"2022-03-17T16:17:11.986258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = NN(input_size=input_size, num_classes=num_classes).to(device)\noptimizer = optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:11.988526Z","iopub.execute_input":"2022-03-17T16:17:11.988937Z","iopub.status.idle":"2022-03-17T16:17:12.001707Z","shell.execute_reply.started":"2022-03-17T16:17:11.988885Z","shell.execute_reply":"2022-03-17T16:17:12.00079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.float()\nlosses = []\nfor epoch in range(num_epochs):\n    local_losses = []\n    for batch_idx, (data, targets) in enumerate(tqdm(train_loader, disable=True)):\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n        data = data.reshape(data.shape[0], -1).float()\n        targets = targets.float()\n\n        scores = model(data)\n        loss = cross_entropy_one_hot(scores, targets)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        local_losses.append(loss.item())\n    losses.append(np.mean(local_losses))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:12.002896Z","iopub.execute_input":"2022-03-17T16:17:12.003129Z","iopub.status.idle":"2022-03-17T16:17:12.844668Z","shell.execute_reply.started":"2022-03-17T16:17:12.003102Z","shell.execute_reply":"2022-03-17T16:17:12.843843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x = range(num_epochs), y = losses)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:12.845795Z","iopub.execute_input":"2022-03-17T16:17:12.846139Z","iopub.status.idle":"2022-03-17T16:17:13.08712Z","shell.execute_reply.started":"2022-03-17T16:17:12.846109Z","shell.execute_reply":"2022-03-17T16:17:13.08621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_score = get_prediction(model, X_test_tensor)\ny_train_score = get_prediction(model, X_train_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:13.088369Z","iopub.execute_input":"2022-03-17T16:17:13.088656Z","iopub.status.idle":"2022-03-17T16:17:13.09434Z","shell.execute_reply.started":"2022-03-17T16:17:13.088623Z","shell.execute_reply":"2022-03-17T16:17:13.093379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\nprint(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:13.09558Z","iopub.execute_input":"2022-03-17T16:17:13.095821Z","iopub.status.idle":"2022-03-17T16:17:13.116289Z","shell.execute_reply.started":"2022-03-17T16:17:13.09579Z","shell.execute_reply":"2022-03-17T16:17:13.11503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create submission","metadata":{}},{"cell_type":"code","source":"X_submission_tensor = torch.from_numpy(np.vstack(df_test.to_numpy()[:, :]).astype(np.float64))\nsubmission = get_prediction(model, X_submission_tensor)\nsubmission = from_prediction_to_onehot_encoding(submission)\nsubmission = encoder.inverse_transform(submission).T[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:13.118023Z","iopub.execute_input":"2022-03-17T16:17:13.119062Z","iopub.status.idle":"2022-03-17T16:17:13.12911Z","shell.execute_reply.started":"2022-03-17T16:17:13.119019Z","shell.execute_reply":"2022-03-17T16:17:13.128091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = pd.read_csv(\"../input/ghouls-goblins-and-ghosts-boo/sample_submission.csv.zip\")['id']\npd.DataFrame({\"id\": ids, \"type\": submission}).set_index(\"id\").to_csv(\"predictions.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-17T16:17:13.131018Z","iopub.execute_input":"2022-03-17T16:17:13.131604Z","iopub.status.idle":"2022-03-17T16:17:13.147383Z","shell.execute_reply.started":"2022-03-17T16:17:13.131565Z","shell.execute_reply":"2022-03-17T16:17:13.146417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}