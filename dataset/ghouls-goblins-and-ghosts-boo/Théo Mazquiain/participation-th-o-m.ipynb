{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:48:55.308193Z","iopub.execute_input":"2022-01-16T14:48:55.308609Z","iopub.status.idle":"2022-01-16T14:48:55.329793Z","shell.execute_reply.started":"2022-01-16T14:48:55.308576Z","shell.execute_reply":"2022-01-16T14:48:55.329069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n#Ce projet porte sur la classificaion de créatures.\n#Il existe trois types de créatures : Ghost (Fantôme), Goblin (Goblin) et Ghoul (Vampire). Chaque créature a des caractéristiques.\n#Les caractéristiques sont : la longueur des os, le pourcentage de chair putréfié, la longueur des cheveux, le pourcentage d'âme et la couleur.\n#Le but de ce projet est de classier des créatures avec des caractéristiques données. ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:49:00.222843Z","iopub.execute_input":"2022-01-16T14:49:00.223145Z","iopub.status.idle":"2022-01-16T14:49:00.229047Z","shell.execute_reply.started":"2022-01-16T14:49:00.22311Z","shell.execute_reply":"2022-01-16T14:49:00.228253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#J'importe mes données qui me serviront de données d'entrainement et de données de test.\ndata=pd.read_csv('/kaggle/input/ghouls-goblins-and-ghosts-boo/train.csv.zip')\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:49:05.121968Z","iopub.execute_input":"2022-01-16T14:49:05.122429Z","iopub.status.idle":"2022-01-16T14:49:05.16165Z","shell.execute_reply.started":"2022-01-16T14:49:05.122376Z","shell.execute_reply":"2022-01-16T14:49:05.160926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Nous avons 371 lignes pour 7 colonnes\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:49:09.552505Z","iopub.execute_input":"2022-01-16T14:49:09.553152Z","iopub.status.idle":"2022-01-16T14:49:09.560437Z","shell.execute_reply.started":"2022-01-16T14:49:09.553118Z","shell.execute_reply":"2022-01-16T14:49:09.55959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Je visualise mes données, pour la sortie nous avons trois types de créatures. 0 pour Goblin, 1 pour fantômes et 2 pour Ghoul\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:49:13.071887Z","iopub.execute_input":"2022-01-16T14:49:13.072168Z","iopub.status.idle":"2022-01-16T14:49:13.08963Z","shell.execute_reply.started":"2022-01-16T14:49:13.072134Z","shell.execute_reply":"2022-01-16T14:49:13.088589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Je regarde mes créatures par rapport à leurs types et à leurs couleurs \n#On remarque que quelque soit le type de créatures, la couleur ne permet pas de les différencier selon les autres paramètres.\ndata.groupby(['type','color']).mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:49:17.829702Z","iopub.execute_input":"2022-01-16T14:49:17.830224Z","iopub.status.idle":"2022-01-16T14:49:17.86287Z","shell.execute_reply.started":"2022-01-16T14:49:17.830189Z","shell.execute_reply":"2022-01-16T14:49:17.862012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On remarque que le paramètre \"Rotting_Flesh\" ne nous sera pas utile pour différencier les créatures\nsns.pairplot(data,hue='type') ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:49:33.883682Z","iopub.execute_input":"2022-01-16T14:49:33.884161Z","iopub.status.idle":"2022-01-16T14:49:41.946389Z","shell.execute_reply.started":"2022-01-16T14:49:33.884123Z","shell.execute_reply":"2022-01-16T14:49:41.945724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Je retire les colonnes \"id\", \"color\" et \"rotting_flesh\" qui ne seront pas utiles pour l'analyse des données. \ndata=data.drop(['id','color', 'rotting_flesh'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:50:48.343733Z","iopub.execute_input":"2022-01-16T14:50:48.344058Z","iopub.status.idle":"2022-01-16T14:50:48.350256Z","shell.execute_reply.started":"2022-01-16T14:50:48.344026Z","shell.execute_reply":"2022-01-16T14:50:48.349086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Je crée maintenant mes données d'entrée et de sortie, en indiquant les colonnes d'entrée et de sortie. \nx=data.iloc[:,0:3]\ny=data.iloc[:,3]\n#Je crée mes données d'entrainement et de test. Les données de test vont représenter 20% des données de base. \nx_train, x_test, y_train, y_test = train_test_split(x,y,random_state=0,test_size=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:50:56.462366Z","iopub.execute_input":"2022-01-16T14:50:56.463331Z","iopub.status.idle":"2022-01-16T14:50:56.474894Z","shell.execute_reply.started":"2022-01-16T14:50:56.463281Z","shell.execute_reply":"2022-01-16T14:50:56.474074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#J'utilise la méthode des KNeighbors pour classifier mes données. \n#Avec mes données d'entrainement, j'entraine mon algorithme. \n#Pour classer une créature, j'utilise, ici, les 5 créatures dont les paramètres se rapprochent le plus de ce dernier pour la classer\nclassifier = KNeighborsClassifier(n_neighbors=5, p=3)\nclassifier.fit(x_train,y_train)\n#Une fois mes données entrainées, je prédis mes données de sortie par rapport à mon jeu de test\ny_pred=classifier.predict(x_test)\n#Ensuite, je compare mes données de sortie de mon jeu de test et les données prédies par ma méthode des KNeighbors.\n#Pour cela, j'utilise la matrice de confusion \ncm = confusion_matrix (y_test, y_pred)\nprint(cm)\n#Je calcule ensuite le score \nprint(accuracy_score(y_test,y_pred))\n#Nous avons un score de 0.746\n#Ce score est plutôt satisfaisant en regardant les graphiques de nos données qui ne montraient pas des caractéristiques spécifiques pour chaque fantôme. ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:51:02.754043Z","iopub.execute_input":"2022-01-16T14:51:02.754491Z","iopub.status.idle":"2022-01-16T14:51:02.775814Z","shell.execute_reply.started":"2022-01-16T14:51:02.754453Z","shell.execute_reply":"2022-01-16T14:51:02.775126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Nous allons utiliser une seconde méthode celle de Naïve Bayésienne\nclassifier2 = GaussianNB()\n#J'entraine mon modèle avec mes données d'entrainement comme précédemment\nclassifier2.fit(x_train, y_train)\n#Je prédis avec mon deuxième modèle des données de sortie \ny_pred2 = classifier2.predict(x_test)\n#J'affiche la matrice de confusion\ncm2 = confusion_matrix(y_test, y_pred2)\nprint(cm2)\n#Je vérifie la précision de mon deuxième modèle\nscore = accuracy_score(y_pred2, y_test)\nprint(score)\n#Nous obtenon sun score de 0.706, ce qui est moins bien qu'avec notre premier modèle.","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:51:16.750091Z","iopub.execute_input":"2022-01-16T14:51:16.750443Z","iopub.status.idle":"2022-01-16T14:51:16.766947Z","shell.execute_reply.started":"2022-01-16T14:51:16.750408Z","shell.execute_reply":"2022-01-16T14:51:16.765809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#La troisème méthode est celle des arbres de décisions qui va déterminer des règles pour classer nos valeurs à partir des données d'apprentisage.\nClassifier3 = DecisionTreeClassifier(max_depth=None)\n#J'entraine mon troisième modèle\nClassifier3.fit(x_train, y_train)\n#Je calcule le score de mon modèle par rapport à mes données de test\nClassifier3.score(x_test, y_test)\n#Le score est de 0.626, ce qui est encore en dessous des deux modèles précédentes. ","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:51:22.248166Z","iopub.execute_input":"2022-01-16T14:51:22.248482Z","iopub.status.idle":"2022-01-16T14:51:22.262501Z","shell.execute_reply.started":"2022-01-16T14:51:22.248449Z","shell.execute_reply":"2022-01-16T14:51:22.26139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#J'importe mes données de test pour compléter le fichier qui sera soumis sur Kaggle \ndata2=pd.read_csv('/kaggle/input/ghouls-goblins-and-ghosts-boo/test.csv.zip')\ndata2=data2.drop(['color', 'rotting_flesh'],axis=1)\nx_test2=data2.iloc[:,1:4]\nY_id=data2.iloc[:,0]\nprint(x_test2)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:51:59.681661Z","iopub.execute_input":"2022-01-16T14:51:59.68255Z","iopub.status.idle":"2022-01-16T14:51:59.712301Z","shell.execute_reply.started":"2022-01-16T14:51:59.68251Z","shell.execute_reply":"2022-01-16T14:51:59.711299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#J'utilise donc la méthode des KNeighbors pour classer mes données. Avec ce modèle, plus de 70% de mes données pourront être déterminées de manière assez fiable.\ny_predit=classifier.predict(x_test2)\nprint(y_predit)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:52:06.791772Z","iopub.execute_input":"2022-01-16T14:52:06.792053Z","iopub.status.idle":"2022-01-16T14:52:06.827029Z","shell.execute_reply.started":"2022-01-16T14:52:06.792024Z","shell.execute_reply":"2022-01-16T14:52:06.826191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Je crée mon tableau avec l'id et la prédiction des créatures\nsubmission=pd.DataFrame({'id':Y_id, 'type': y_predit})\nprint(submission)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:52:15.066138Z","iopub.execute_input":"2022-01-16T14:52:15.066424Z","iopub.status.idle":"2022-01-16T14:52:15.07526Z","shell.execute_reply.started":"2022-01-16T14:52:15.066397Z","shell.execute_reply":"2022-01-16T14:52:15.074612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Je transforme ensuite mon tableau en fichier csv pour l'envoyer sur Kaggle\nsubmission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-16T14:52:28.543947Z","iopub.execute_input":"2022-01-16T14:52:28.54426Z","iopub.status.idle":"2022-01-16T14:52:28.553181Z","shell.execute_reply.started":"2022-01-16T14:52:28.544223Z","shell.execute_reply":"2022-01-16T14:52:28.552484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}