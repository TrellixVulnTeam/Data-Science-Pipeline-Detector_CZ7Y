{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"5e206342-7b57-29ba-5509-7a9c0a764b94"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18da93a1-6526-214c-1ab4-04a38d3e3cde"},"outputs":[],"source":"import pandas\nimport numpy\nimport itertools\n\nfrom sklearn import metrics\nfrom sklearn.preprocessing import (\n    LabelEncoder,\n    StandardScaler,\n    PolynomialFeatures)\nfrom sklearn.feature_selection import RFE\nfrom sklearn.model_selection import (\n    ShuffleSplit,\n    GridSearchCV,\n    cross_val_score)\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.decomposition import KernelPCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.ensemble import (\n    BaggingClassifier,\n    VotingClassifier,\n    RandomForestClassifier)\n\nfrom xgboost import XGBClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6ea994b-8800-94a2-69df-f12557c298ff"},"outputs":[],"source":"train = pandas.read_csv('../input/train.csv')\ntest = pandas.read_csv('../input/test.csv')\n\nfeatures_numerical = [\n    'bone_length',\n    'rotting_flesh',\n    'hair_length',\n    'has_soul'\n]\n\nfeatures_categorical = ['color']\n\ntarget = 'type'\nle_target = LabelEncoder().fit(train[target])\nlabels = le_target.transform(train[target])\nclasses = list(le_target.classes_)\n\ntrain = train.drop([target, 'id'], axis=1)\ntest_ids = test.pop('id')\n\ntrain = train.drop(features_categorical, axis=1)\ntest = test.drop(features_categorical, axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a56fd16c-2c72-74ba-5462-c70e8479dfa2"},"outputs":[],"source":"combined_features = Pipeline([\n    ('feature_set', FeatureUnion([\n        ('f_poly', Pipeline([\n            ('poly', PolynomialFeatures(\n                degree=2,\n                interaction_only=False,\n                include_bias=False\n            )),\n            ('scaler', StandardScaler()),\n        ])),\n        ('f_kpca', Pipeline([\n            ('scaler', StandardScaler()),\n            ('kpca', KernelPCA(\n                n_components=15,\n                kernel=\"rbf\",\n                fit_inverse_transform=True,\n                gamma=1\n            )),\n        ])),\n    ])),\n    ('rfe', RFE(\n        estimator=SVC(kernel='linear', C=1),\n        n_features_to_select=10,\n        step=1\n    )),\n])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dda263eb-d48f-cfe2-6a5f-9fdd09687ae3"},"outputs":[],"source":"classifiers = {\n    'blinky': LogisticRegression(\n        C=1,\n        tol=1e-3,\n        multi_class= 'multinomial',\n        penalty='l2',\n        solver='lbfgs'\n    ),\n    'pinky': RandomForestClassifier(\n        n_estimators=250,\n        criterion='entropy',\n        max_depth=5,\n        min_samples_leaf=8,\n        min_samples_split=3\n    ),\n    'inky': GaussianProcessClassifier(\n        kernel=1.0 * RBF(\n            length_scale=1.0,\n            length_scale_bounds=(1e-1, 10.0)\n        ),\n        warm_start=True\n    ),\n    'clyde': XGBClassifier(\n        n_estimators=250,\n        objective=\"multi:softprob\",\n        max_depth=6,\n        learning_rate=0.1,\n        gamma=0,\n        nthread=6\n    ),\n}"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98790c53-c94c-346f-ad44-96034a8bd54e"},"outputs":[],"source":"clf_acc = []\n\nss = ShuffleSplit(\n    n_splits=10,\n    test_size=0.2,\n    random_state=0\n)\n\nestimators = dict()\n\nprint('\\nResults:')\nfor i, (train_index, val_index) in enumerate(ss.split(train, labels), start=1):\n    X_train, X_val = train.as_matrix()[train_index], train.as_matrix()[val_index]\n    y_train, y_val = labels[train_index], labels[val_index]\n\n    for name, clf in classifiers.items():\n        pipeline = Pipeline([\n            ('features', combined_features),\n            (name, clf),\n        ])\n        estimator = pipeline.fit(X_train, y_train)\n        estimators['%s_%s' % (name, i)] = estimator\n\n        train_predictions = estimator.predict(X_val)\n        acc = metrics.accuracy_score(y_val, train_predictions)\n        print('acc: {:.2%} | [split {}] {}'.format(acc, i, name))\n\n        clf_acc.append([name, i, acc])\n\nclf_acc = pandas.DataFrame(clf_acc, columns=['classifier', 'split', 'acc'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ad1b3d0-92ce-8974-3e9e-eff251a774a2"},"outputs":[],"source":"clf_cv_acc = clf_acc[['classifier', 'acc']] \\\n    .groupby('classifier') \\\n    .mean() \\\n    .sort_values(by='acc', ascending=False\n).reset_index()\n\nprint('\\nMean classifier accuracy:\\n%r' % (clf_cv_acc.head(10)))\n\ntop_estimators_acc = clf_cv_acc.head(3).classifier.values\nvc_estimators = {k: classifiers[k] for k in top_estimators_acc}"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86054dcd-710f-9b61-ba34-b683fdf9457d"},"outputs":[],"source":"ss = ShuffleSplit(\n    n_splits=3,\n    test_size=0.1,\n    random_state=0\n)\n\nmax_w = 3\nweight_scores = []\nw = range(1, max_w + 1)\nfor weights in itertools.product(w, w, w):\n    if (len(set(weights)) != 1) or (int(sum(weights)) == 3):\n        eclf = VotingClassifier(\n            estimators=vc_estimators.items(),\n            voting='soft',\n            weights=weights\n        )\n        \n        # cross_val_score not working in kernels for me, so using below instead...\n        for i, (train_index, val_index) in enumerate(ss.split(train, labels), start=1):\n            X_train, X_val = train.as_matrix()[train_index], train.as_matrix()[val_index]\n            y_train, y_val = labels[train_index], labels[val_index]\n            \n            estimator = eclf.fit(X_train, y_train)\n            acc = metrics.accuracy_score(y_val, estimator.predict(X_val))\n            weight_scores.append([weights, i, acc])\n            print('%s: [split %s] %s' % (weights, i, acc))\n        \n\ncols = ['weights', 'splits', 'acc']\ndf = pandas.DataFrame(weight_scores, columns=cols)\ndf = df[['weights', 'acc']] \\\n    .groupby('weights') \\\n    .mean() \\\n    .sort_values(by='acc', ascending=False\n).reset_index()\n\nprint('\\n\\n%r' % df.head())\nweights, _ = df.as_matrix()[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d82d278-2088-8431-a01d-d2d1a704a7c7"},"outputs":[],"source":"eclf = VotingClassifier(\n    estimators=vc_estimators.items(),\n    voting='soft',\n    weights=weights\n)\neclf.fit(X_train, y_train)\n\ntest_predictions = eclf.predict_proba(test.as_matrix())\ntest_predictions = [le_target.classes_[numpy.argmax(i)] for i in test_predictions]\n\nsubmission = pandas.DataFrame(test_predictions, columns=[target])\nsubmission.insert(0, 'id', test_ids)\n\nsubmission.to_csv('cherries.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}