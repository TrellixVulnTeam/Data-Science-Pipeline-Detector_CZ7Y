{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Ghouls, Goblins, and Ghosts... Boo!"},{"metadata":{},"cell_type":"markdown","source":"This is my first Kaggle competition and first try in machine learning. \n\nLink: https://www.kaggle.com/c/ghouls-goblins-and-ghosts-boo\n\nProblem description: create classification algorithm to distinguish type of monsters by given features."},{"metadata":{},"cell_type":"markdown","source":"## 1 - Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing, ensemble, model_selection\n\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%pylab inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2 - Overview of the Dataset"},{"metadata":{},"cell_type":"markdown","source":"Loading data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/ghouls-goblins-and-ghosts-boo/train.csv.zip', header=0, sep=',')\ntest_data = pd.read_csv('../input/ghouls-goblins-and-ghosts-boo/test.csv.zip', header=0, sep=',')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shape of datasets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of train data: ', train_data.shape)\nprint('Shape of test data: ', test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First 5 rows of datasets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check column names:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Column names:', list(train_data.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove id columns from datasets as it won't be used:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop(['id'], axis=1)\n\ntest_id = test_data['id']\ntest_data = test_data.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualising train dataset as a pairplot. Represents float values of columns 'bone_length', 'rotting_flesh', 'hair_length', 'has_soul'."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train_data.drop('color', axis = 1), hue = 'type', palette = 'muted', diag_kind='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset contains categorical value column 'color'. Let's visualise it."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(x='color', hue='type', data=train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compare general amount of samples to classify for each value."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='type', data=train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we are splitting data to target and features sets. Let's apply label encoding for target values(replace string values by int) in target set and for 'color' column in feature set."},{"metadata":{"trusted":true},"cell_type":"code","source":"color_le = preprocessing.LabelEncoder()\n\ntrain_data_x = train_data\ncolor_le.fit(train_data_x['color'])\ntrain_data_x['color_int'] = color_le.transform(train_data_x['color'])\ntrain_data_x = train_data_x.drop(['color', 'type'], axis=1)\ntrain_data_x = train_data_x.to_numpy()\n\ntype_le = preprocessing.LabelEncoder()\n\ntrain_data_y = train_data['type']\ntype_le.fit(train_data_y)\ntrain_data_y = type_le.transform(train_data_y)\n\nprint('Unique type values:', train_data.type.unique())\nprint()\nprint('Original train_set_y:', np.array(train_data.type[:5]))\nprint('Encoded train_set_y:', train_data_y[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing test data for final prediction is the same as for train_data_x."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data\ncolor_le.fit(test_data['color'])\ntest_data['color_int'] = color_le.transform(test_data['color'])\ntest_data = test_data.drop(['color'], axis=1)\ntest_data = test_data.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessed test data looks like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('test_data:')\nprint(test_data[:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Final train x and y sets look like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train_data_x:')\nprint(train_data_x[:5])\nprint('shape:', train_data_x.shape, 'type:', type(train_data_x))\nprint()\nprint('train_data_y:')\nprint(train_data_y[:5])\nprint('shape:', train_data_y.shape, 'type:', type(train_data_y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3 - Model"},{"metadata":{},"cell_type":"markdown","source":"In this project I am going to use Random Forest Classifier to classify types of creatures. We need to determine hyperparameter - number of trees in forest. Let's look through range of numbers 1, 5, ... 50. We will use cross validation with 3 foldes to find the best parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"n_trees = [1] + list(range(5, 55, 5))\nscoring = []\nfor n_tree in n_trees:\n    estimator = ensemble.RandomForestClassifier(n_estimators = n_tree, min_samples_split=5, random_state=1)\n    score = model_selection.cross_val_score(estimator, train_data_x, train_data_y, \n                                             scoring = 'accuracy', cv = 3)    \n    scoring.append(score)\nscoring = np.asmatrix(scoring)\n\nscoring","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"pylab.plot(n_trees, scoring.mean(axis = 1), marker='.', label='RandomForest')\npylab.grid(True)\npylab.xlabel('n_trees')\npylab.ylabel('score')\npylab.title('Accuracy score')\npylab.legend(loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Alternate way to find best value of hyperparameter is to use GridSearchCV:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparams = {'n_estimators': n_trees}\n\ngrid_search = GridSearchCV(ensemble.RandomForestClassifier(min_samples_split=5, random_state=1), params, cv=3, scoring='accuracy')\n\ngrid_search.fit(train_data_x, train_data_y)\n\nprint('Best n of trees: {}, best accuracy score: {}'.format(grid_search.best_params_['n_estimators'], grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's clearly seen, that both searches have the same results. So, we will use 20 trees for Random Forest Classifier. Now we will divide train data into train and test sets for our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ntrain_set_x, test_set_x, train_set_y, test_set_y = train_test_split(train_data_x, train_data_y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's fit our model and predict y for test set. Then calculate accuracy score for test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_n_tree = grid_search.best_params_['n_estimators']\nmodel = ensemble.RandomForestClassifier(n_estimators = n_tree, min_samples_split=5, random_state=1)\nmodel.fit(train_set_x, train_set_y)\npred_y = model.predict(test_set_x)\n\nscore = accuracy_score(test_set_y, pred_y)\nprint('Accuracy score:', score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, let's predict the 'type' variable for test_data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model.predict(test_data)\nencoded_test_pred = type_le.inverse_transform(test_pred)\nprint('Test predictions:', encoded_test_pred[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': test_id, 'type':encoded_test_pred})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}