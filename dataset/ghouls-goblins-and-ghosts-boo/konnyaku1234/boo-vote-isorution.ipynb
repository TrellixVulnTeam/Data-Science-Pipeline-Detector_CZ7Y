{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#ライブラリのインポート欄\nimport pandas as pd;import numpy as np;import matplotlib.pyplot as plt;import seaborn as sns\nfrom sklearn.pipeline import Pipeline,make_pipeline\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nimport warnings;import seaborn as sns #可視化\nwarnings.filterwarnings('ignore');import zipfile#サンプルがzipなので展開する\nzipfile.ZipFile('/kaggle/input/ghouls-goblins-and-ghosts-boo/train.csv.zip').extractall() \nzipfile.ZipFile('/kaggle/input/ghouls-goblins-and-ghosts-boo/test.csv.zip').extractall()\n#zipfile.ZipFile('/kaggle/input/ghouls-goblins-and-ghosts-boo/sample_submission.csv.zip').extractall()\n\n%matplotlib inline\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split # クロスバリデーション用（テストとトレ分ける）\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics       # 精度検証用\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\n# ニューラルネットワーク\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn import metrics\nimport joblib\n\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\n\n\n# LightGBM#import lightgbm as lgb\nimport optuna\nimport optuna.integration.lightgbm as lgb\n\n\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\n\n\n\n#sklearn モデル　沢山\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\nfrom sklearn.linear_model import PassiveAggressiveRegressor, ARDRegression, RidgeCV\nfrom sklearn.linear_model import TheilSenRegressor, RANSACRegressor, HuberRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cross_decomposition import PLSRegression\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-28T01:56:01.696255Z","iopub.execute_input":"2021-07-28T01:56:01.696642Z","iopub.status.idle":"2021-07-28T01:56:01.730752Z","shell.execute_reply.started":"2021-07-28T01:56:01.696612Z","shell.execute_reply":"2021-07-28T01:56:01.729822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def N_netlog(train, test, target,tartest):\n    # paramate\n    hidden_layer_sizes=(100,)\n    activation = 'relu'\n    solver = 'adam'\n    batch_size = 'auto'\n    alpha = 0.0001\n    random_state = 0\n    max_iter = 10000\n    early_stopping = True\n    # 学習\n    clf = MLPRegressor(\n        hidden_layer_sizes=hidden_layer_sizes,\n        activation=activation,\n        solver=solver,\n        batch_size=batch_size,\n        alpha=alpha,\n        random_state=random_state,\n        max_iter=max_iter,\n    #     early_stopping = early_stopping\n        )\n    clf.fit(train, target)\n    SAVE_TRAINED_DATA_PATH = 'train1.learn'\n    # 学習結果を出力\n    joblib.dump(clf, SAVE_TRAINED_DATA_PATH)\n    # 学習済ファイルのロード\n    clf1 = joblib.load(SAVE_TRAINED_DATA_PATH)\n    # 学習結果の検証\n    #predict_y1 = clf1.predict_proba(test)それぞれの回答確率を出す?\n    #predict = clf1.predict(test)\n    #accs=accuracy_score(train, target)\n    #return  predict,accs\n\n#スコア用\n    if len(tartest) >1:\n        print(tartest)\n        pred = clf1.predict(test)# LightGBM推論]\n        pred_r = np.round(np.round(pred, decimals=1)) # 最尤と判断したクラスの値にする\n        predict = accuracy_score(tartest, pred_r)  # 最尤と判断したクラスの値にする\n    # スコアじゃないとき\n    if len(tartest) ==1:\n        print(test)\n        predict_no = clf1.predict(test)# LightGBM推論\n        predict = np.round(np.round(predict_no, decimals=1)) # 最尤と判断したクラスの値にする\n    return predict\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T01:56:01.732446Z","iopub.execute_input":"2021-07-28T01:56:01.732854Z","iopub.status.idle":"2021-07-28T01:56:01.742495Z","shell.execute_reply.started":"2021-07-28T01:56:01.732811Z","shell.execute_reply":"2021-07-28T01:56:01.741484Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lightgbm(train, test, target,tartest):# データ用意\n    X_train, X_test, Y_train, Y_test = train_test_split(train, target, random_state=0) # random_stateはseed値。\n    # LightGBMのパラメータ設定\n    params = {\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': 'rmse',#クラスは0,1,2,...と与えられる(数字は関係ない)#評価指標：正答率\n        #'num_iterations': 1000,#1000回学習\n        'verbose': -1 #学習情報を非表示\n    }\n    #'metric': 'multi_logress'かえた\n    # LightGBMを利用するのに必要なフォーマットに変換\n    lgb_train = lgb.Dataset(X_train, Y_train)\n    lgb_eval = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n    best_params, history = {}, []\n\n    # LightGBM学習\n    gbm = lgb.train(params,\n                    lgb_train,\n                    valid_sets=[lgb_train, lgb_eval],\n                    verbose_eval=100,\n                    early_stopping_rounds=100\n                   )\n\n    best_params = gbm.params\n    print(\"Best params:\", best_params)\n    params = best_params\n    #ここから推理します\n    #スコア用\n    if len(tartest) >1:\n        print(tartest)\n        pred = gbm.predict(test, num_iteration=gbm.best_iteration)# LightGBM推論]\n        pred_r = np.round(np.round(pred, decimals=1)) # 最尤と判断したクラスの値にする\n        predict = accuracy_score(tartest, pred_r)  # 最尤と判断したクラスの値にする\n    # スコアじゃないとき\n    if len(tartest) ==1:\n        print(test)\n        predict_no = gbm.predict(test, num_iteration=gbm.best_iteration)# LightGBM推論\n        predict = np.round(np.round(predict_no, decimals=1)) # 最尤と判断したクラスの値にする\n    return predict\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T01:56:01.744338Z","iopub.execute_input":"2021-07-28T01:56:01.744627Z","iopub.status.idle":"2021-07-28T01:56:01.762319Z","shell.execute_reply.started":"2021-07-28T01:56:01.744599Z","shell.execute_reply":"2021-07-28T01:56:01.761086Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def def_two(ghost,ghoul,goblin, test, target, accuracy,best_cell_gob,reg_dict):#おかしい。うまく行っていない\n    #HowDoはどの分析方法にするか\n    acc_score_gob=np.zeros((40),dtype = 'float64')#スコアを保存\n    vsnp=np.empty((529),dtype=\"float64\")\n    vsnpp=np.empty((529),dtype=\"float64\")\n    submission=np.empty((529),dtype=\"int\")\n    vote=np.zeros((529,2),dtype=\"int\")#投票によるスコア\n    ones=np.ones((529),dtype=\"int\")#投票によるスコア\n    ghost0=np.zeros(len(ghost));ghost1=np.ones(len(ghost))\n    ghoul0=np.zeros(len(ghoul));ghoul1=np.ones(len(ghoul))\n    goblin0=np.zeros(len(goblin));goblin1=np.ones(len(goblin))#target作成前段階\n    vs = ghost.append(ghoul, ignore_index=True)\n    vst = np.append(ghost1,ghoul0)#target作成\n    #今回はゴーストが1\n    #本番かどうか\n    if accuracy == True:#スコア出す\n        train_r, test_r, target_r, tartest_r = train_test_split(vs, vst, random_state=0) # random_stateはseed値。\n        \n        model = LogisticRegression();model.fit(train_r,target_r);vsnp=model.predict(test_r);acc_score_gob[0]=accuracy_score(tartest_r, vsnp)#LogReg\n        submission = np.round(np.round(vsnp, decimals=1))\n        vote[:len(test_r),0]=vote[:len(test_r),0]+submission[:len(test_r)];vote[:len(test_r),1]=vote[:len(test_r),1]+ones[:len(test_r)]-submission[:len(test_r)]\n        #acc_score_gob[1]=lightgbm(train_r, test_r, target_r, tartest_r)\n        #acc_score_gob[2]=N_netlog(train_r, test_r, target_r, tartest_r)\n        #sklearn沢山\n        n=0\n        for reg_name, reg in reg_dict.items():\n            reg.fit(train_r,target_r);vsnp = reg.predict(test_r);submission = np.round(np.round(vsnp, decimals=1))\n            acc_score_gob[n+3]=accuracy_score(tartest_r, submission);n+=1\n            vote[:len(test_r),0]=vote[:len(test_r),0]+submission[:len(test_r)];vote[:len(test_r),1]=vote[:len(test_r),1]+ones[:len(test_r)]-submission[:len(test_r)]\n        for n in range(len(test_r)):\n            submission[n]= (0 if vote[n,1]>vote[n,0] else 1)\n        #acc_score_gob[39]=accuracy_score(tartest_r, submission)\n        print(acc_score_gob)\n        return acc_score_gob\n    \n    if accuracy == False:#本シミュレーション\n        train_r, test_r, target_r, tartest_r = vs, test, vst, [0]\n        \n        if best_cell_gob==0:#LogReg\n            model = LogisticRegression();model.fit(train_r,target_r);vsnp=model.predict(test_r);vsnpp=vsnp\n        if best_cell_gob==1:#LogReg\n            vsnp=lightgbm(train_r, test_r, target_r, tartest_r);vsnpp=vsnp\n        if best_cell_gob==2:#LogReg\n            vsnp=N_netlog(train_r, test_r, target_r, tartest_r);vsnpp=vsnp\n        if best_cell_gob > 2:#many_sk\n            n=0#n初期化\n            for reg_name, reg in reg_dict.items():\n                #if n == best_cell_gob-3:\n                reg.fit(train_r,target_r);vsnp = reg.predict(test_r)\n                if n == best_cell_gob-3:\n                    vsnpp=vsnp\n                n+=1#特定の数のときだけfit\n                vote[:len(test_r),0]=vote[:len(test_r),0]+submission[:len(test_r)];vote[:len(test_r),1]=vote[:len(test_r),1]+ones[:len(test_r)]-submission[:len(test_r)]\n        if best_cell_gob == 39:\n            for n in range(len(test_r)):\n                vsnp[n]= (0 if vote[n,1]>vote[n,0] else 1)\n            vsnpp=vsnp\n        \n        submission = np.round(np.round(vsnpp, decimals=1)) # 最尤と判断したクラスの値にする\n        \n        return submission","metadata":{"execution":{"iopub.status.busy":"2021-07-28T01:56:01.815167Z","iopub.execute_input":"2021-07-28T01:56:01.815518Z","iopub.status.idle":"2021-07-28T01:56:01.839638Z","shell.execute_reply.started":"2021-07-28T01:56:01.81549Z","shell.execute_reply":"2021-07-28T01:56:01.838752Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def def_gob(ghost,ghoul,goblin, test, target, accuracy,best_cell_gob,reg_dict):#ゴブリンかどうか最初に判別するために、ゴブリンを一番区別できる分別機を選ぶ\n    acc_score_gob=np.zeros((40),dtype = 'float64')#スコアを保存\n    vsnp=np.zeros((529),dtype=\"float64\")\n    vsnpp=np.zeros((529),dtype=\"float64\")\n    submission=np.empty((529),dtype=\"bool\")\n    vote=np.zeros((529,2),dtype=\"int\")#投票によるスコア\n    ones=np.ones((529),dtype=\"bool\")#投票によるスコア\n    ghost0=np.zeros(len(ghost));ghost1=np.ones(len(ghost))\n    ghoul0=np.zeros(len(ghoul));ghoul1=np.ones(len(ghoul))\n    goblin0=np.zeros(len(goblin));goblin1=np.ones(len(goblin))#target作成前段階\n    vs = goblin.append(ghost, ignore_index=True)#train作成\n    vs = vs.append(ghoul, ignore_index=True)#train作成\n    vst = np.append(goblin1,ghost0)#target作成\n    vst = np.append(vst,ghoul0)\n    #本番かどうか\n    if accuracy == True:#スコア出す\n        train_r, test_r, target_r, tartest_r = train_test_split(vs, vst, random_state=0) # random_stateはseed値。\n        #vote[:len(test_r),0]=ones[:len(test_r)]*5\n        model = LogisticRegression();model.fit(train_r,target_r);vsnp=model.predict(test_r);acc_score_gob[0]=accuracy_score(tartest_r, vsnp)#LogReg\n        submission = np.round(np.round(vsnp, decimals=1))\n        vote[:len(test_r),0]=vote[:len(test_r),0]+submission[:len(test_r)];vote[:len(test_r),1]=vote[:len(test_r),1]+ones[:len(test_r)]-submission[:len(test_r)]\n        \n        #acc_score_gob[1]=lightgbm(train_r, test_r, target_r, tartest_r)\n        acc_score_gob[2]=N_netlog(train_r, test_r, target_r, tartest_r)\n        \n        #sklearn沢山\n        n=0\n        for reg_name, reg in reg_dict.items():\n            reg.fit(train_r,target_r)\n            vsnp = reg.predict(test_r);submission = np.round(np.round(vsnp, decimals=1))\n        \n            acc_score_gob[n+3]=accuracy_score(tartest_r, submission);n+=1\n            \n            vote[:len(test_r),0]=vote[:len(test_r),0]+submission[:len(test_r)];vote[:len(test_r),1]=vote[:len(test_r),1]+ones[:len(test_r)]-submission[:len(test_r)]\n        for n in range(len(test_r)):\n            submission[n]= (0 if vote[n,1]>vote[n,0] else 1)\n            \n        #acc_score_gob[39]=accuracy_score(tartest_r, submission)\n        print(acc_score_gob)\n        return acc_score_gob\n    \n    if accuracy == False:#本シミュレーション\n        train_r, test_r, target_r, tartest_r = vs, test,vst, [0]\n        vsnpp_int=np.zeros((529),dtype=\"int\")\n        if best_cell_gob==0:#LogReg\n            model = LogisticRegression();model.fit(train_r,target_r);vsnp=model.predict(test_r);vsnpp=vsnp\n        if best_cell_gob==1:#LogReg\n            vsnp=lightgbm(train_r, test_r, target_r, tartest_r);vsnpp=vsnp\n        if best_cell_gob==2:#LogReg\n            vsnp=N_netlog(train_r, test_r, target_r, tartest_r);vsnpp=vsnp\n        if best_cell_gob > 2:#many_sk\n            n=0#n初期化\n            \n            for reg_name, reg in reg_dict.items():\n               \n                reg.fit(train_r,target_r);vsnp = reg.predict(test_r)\n                vsnpp_int = vsnpp_int +  (np.round(np.round(vsnp, decimals=1))==1)\n                \n                if n == best_cell_gob-3:\n                        vsnpp=vsnp\n                        \n                n+=1#特定の数のときだけfit\n                vote[:len(test_r),0]=vote[:len(test_r),0]+submission[:len(test_r)];vote[:len(test_r),1]=vote[:len(test_r),1]+ones[:len(test_r)]-submission[:len(test_r)]\n        if best_cell_gob == 39:\n            for n in range(len(test_r)):\n                vsnp[n]= (0 if vote[n,1]>vote[n,0] else 1)\n            vsnpp=vsnp\n        submission = np.round(np.round(vsnpp, decimals=1)) # 最尤と判断したクラスの値にする\n        \n        submission = (submission==1) | (vsnpp_int>2)\n        \n        \n        return submission\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-28T01:56:01.84121Z","iopub.execute_input":"2021-07-28T01:56:01.841748Z","iopub.status.idle":"2021-07-28T01:56:01.868546Z","shell.execute_reply.started":"2021-07-28T01:56:01.841696Z","shell.execute_reply":"2021-07-28T01:56:01.867477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main_n():\n    #sklearn沢山用\n    reg_dict = {#\"LinearRegression\": LinearRegression(),\n            #\"Ridge\": Ridge(),\n            #\"Lasso\": Lasso(),\n            #\"ElasticNet\": ElasticNet(), \n   \n            #\"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=3),\n            #\"DecisionTreeRegressor\": DecisionTreeRegressor(),\n            \"RandomForestRegressor\": RandomForestRegressor(),\n            #\"SVR\": SVR(kernel='rbf', C=1e3, gamma=0.1, epsilon=0.1),\n           \n            #\"SGDRegressor\": SGDRegressor(),\n            #\"MLPRegressor\": MLPRegressor(hidden_layer_sizes=(10,10), max_iter=100, early_stopping=True, n_iter_no_change=5),\n            \"ExtraTreesRegressor\": ExtraTreesRegressor(n_estimators=100), \n            \n            #\"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(max_iter=100, tol=1e-3),\n            #\"TheilSenRegressor\": TheilSenRegressor(random_state=0),\n            \n            \"HistGradientBoostingRegressor\": HistGradientBoostingRegressor(),\n            \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0, n_estimators=100),\n            \"BaggingRegressor\": BaggingRegressor(base_estimator=SVR(), n_estimators=2),\n            \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n            \"VotingRegressor\": VotingRegressor([('lr', LinearRegression()), ('rf', RandomForestRegressor(n_estimators=2))]),\n            #\"StackingRegressor\": StackingRegressor(estimators=[('lr', RidgeCV()), ('svr', LinearSVR())], final_estimator=RandomForestRegressor(n_estimators=10)),\n            #\"ARDRegression\": ARDRegression(),\n            #\"HuberRegressor\": HuberRegressor(),\n                    }\n\n    \n    \n   # CSVを読み込む\n    train = pd.read_csv('./train.csv')\n    test = pd.read_csv('./test.csv')\n    \n    submission_no=np.empty((529,3),dtype=\"int\")\n    submission=[\"\"]*529\n    \n    #type_pd = train[\"type\"]\n    type_array = pd.get_dummies(train['type']);  del train['type']#typeをトレインから分離\n    COLOR = pd.get_dummies(train['color']);  del train['color']  ;del train['id']#colorをトレインから分離；idをトレインから分離\n    COLOR2 = pd.get_dummies(test['color']);  del test['color'];  ID = test[\"id\"];  del test['id'] #testも同じようにする\n    vote = np.zeros((3,529),dtype = 'int')\n    target = pd.DataFrame(type_array['Ghost']* 0 + type_array['Ghoul'] * 2 + type_array['Goblin'] * 1)#targetを作成する\n    #怪物のデータが別々にいるプログラム用\n    ghost=train[type_array['Ghost']==1]\n    ghoul=train[type_array['Ghoul']==1]\n    goblin=train[type_array['Goblin']==1]\n    \n    #ここからは色つきでもう一度同じ\n    train_c = train.join(COLOR)\n    test_c = test.join(COLOR2)\n    #怪物のデータが別々にいるプログラム用\n    ghost_c=train_c[type_array['Ghost']==1]\n    ghoul_c=train_c[type_array['Ghoul']==1]\n    goblin_c=train_c[type_array['Goblin']==1]\n    \n    \n    #DAOAのためのスコアで分析\n    #ゴブリンかどうか自動判別\n    best_cell_gob= 0;accuracy=True;gob_c_or_no=True#色付きがいいならTrue出ないならFalse\n    acc_score_gob=def_gob(ghost,ghoul,goblin, test, target, accuracy,best_cell_gob,reg_dict)\n    best_cell_gob=np.argmax(acc_score_gob)#色なし最高スコア\n    print(\"serect\",best_cell_gob)\n    best_cell_gob_c= 0#色あり\n    acc_score_gob_c=def_gob(ghost_c,ghoul_c,goblin_c, test_c, target, accuracy,best_cell_gob_c,reg_dict)\n    best_cell_gob_c=np.argmax(acc_score_gob_c)#追加して\n    print(\"serect\",best_cell_gob)\n    gob_c_or_no = (True if best_cell_gob_c > best_cell_gob else False)#色付き色なしどちらがいい？\n    \n    #ゴブリンか判別本番\n    accuracy=False\n    if gob_c_or_no:\n        submission_no[:,0]=def_gob(ghost_c,ghoul_c,goblin_c, test_c, target, accuracy,best_cell_gob_c,reg_dict)\n    if gob_c_or_no==False:\n        submission_no[:,0]=def_gob(ghost,ghoul,goblin, test, target, accuracy,best_cell_gob,reg_dict)\n    #判別終わり\n    \n    #ID_goblin=np.array(ID[submission_no==1])#ゴブリン該当するIDを取り出し\n    #ID_nogob=np.array(ID[submission_no==0])#ゴブリン該当しないIDを取り出し\n    test_nogob=np.array(test[submission_no[:,0]==0])#ゴブリン該当しないテストを取り出し\n    test_nogob_c=np.array(test_c[submission_no[:,0]==0])#ゴブリン該当しないテストを取り出し色あり\n    #submission[submission_no==1]=\"Goblin\"#ゴブリンを事前に入れておく#いらない\n    #magicno=nonono(ID_nogob)\n    #submission_no_gob=np.zeros((magicno),dtype=\"int\")\n        \n    #ここから、ghoulとghostの判別\n    best_cell_two= 0;accuracy=True;c_or_no=True#色付きがいいならTrue出ないならFalse\n    acc_score_two=def_two(ghost,ghoul,goblin, test_nogob, target, accuracy,best_cell_two,reg_dict)\n    best_cell_two=np.argmax(acc_score_two)#色なし最高スコア\n    best_cell_two_c= 0#色あり\n    acc_score_two_c=def_two(ghost_c,ghoul_c,goblin_c, test_nogob_c, target, accuracy,best_cell_two_c,reg_dict)\n    best_cell_two_c=np.argmax(acc_score_two_c)#追加して\n    c_or_no = (True if best_cell_two_c > best_cell_two else False)#色付き色なしどちらがいい？\n    \n     #２つの判別本番\n    \n    \n    accuracy=False\n   \n    if gob_c_or_no:\n        submission_no[:,1]=def_two(ghost_c,ghoul_c,goblin_c, test_c, target, accuracy,best_cell_two_c,reg_dict)\n    if gob_c_or_no==False:\n        submission_no[:,1]=def_two(ghost,ghoul,goblin, test, target, accuracy,best_cell_two,reg_dict)\n    \n    #ID_ghost=np.array(ID_nogob[submission_no_gob[:len(ID_nogob)]==1])#ghost該当するIDを取り出し\n    #ID_ghoul=np.array(ID_nogob[submission_no_gob[:len(ID_nogob)]==0])#ghoul該当IDを取り出し\n    #print(ID_ghost)\n    #nghost, nghoul, ngoblin = 0,0,0\n    for n in range (len(ID)):\n        if submission_no[n,0]==1:\n            submission[n]=\"Goblin\"\n        if submission_no[n,0]==0:\n            submission[n]= (\"Ghost\" if submission_no[n,1]==1 else \"Ghoul\")\n            \n\n        #if ID[n]==ID_ghost[nghost]:\n       #     submission[n]=\"Ghost\";nghost =(nghost+1 if len(ID_ghost)>nghost+1 else 0 )\n       # if ID[n]==ID_ghoul[nghoul]:\n       #     submission[n]=\"Ghoul\";nghoul = (nghoul+1 if len(ID_ghoul)>nghoul+1 else 0 )\n       # if ID[n]==ID_goblin[ngoblin]:\n       #     submission[n]=\"Ghoblin\";ngoblin = (ngoblin+1 if len(ID_goblin)>ngoblin+1 else 0 )\n    \n    s_c= pd.DataFrame({\"id\": ID, \"type\": submission})\n    \n    return s_c","metadata":{"execution":{"iopub.status.busy":"2021-07-28T01:56:01.870434Z","iopub.execute_input":"2021-07-28T01:56:01.87103Z","iopub.status.idle":"2021-07-28T01:56:01.897127Z","shell.execute_reply.started":"2021-07-28T01:56:01.87098Z","shell.execute_reply":"2021-07-28T01:56:01.896215Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ここでメインを一つずつ実行\nsubmission=main_n()\n\n##ここから推理します\n# Kaggle提出用csvファイルの作成\nsubmission.to_csv(\"submission6.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T01:56:01.898468Z","iopub.execute_input":"2021-07-28T01:56:01.89909Z","iopub.status.idle":"2021-07-28T01:56:08.767167Z","shell.execute_reply.started":"2021-07-28T01:56:01.899026Z","shell.execute_reply":"2021-07-28T01:56:08.765082Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ここから使っていないコード","metadata":{}}]}