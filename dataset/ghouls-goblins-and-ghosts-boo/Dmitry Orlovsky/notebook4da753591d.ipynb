{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bdda0482-582c-a3d1-40c9-8160e7a048a1"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n    \nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34ac58e2-6d12-023a-cd5f-f37db907db1e"},"outputs":[],"source":"import seaborn as sns\n#sns.set()\nfrom sklearn import preprocessing\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction import DictVectorizer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a94855cd-db90-6965-454e-dabfa7ac1f72"},"outputs":[],"source":"df = pd.read_csv(\"../input/train.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43eeed04-05f2-bfad-fbfb-fbedcdcfb8b6"},"outputs":[],"source":"from sklearn import covariance\nNUMERIC_FEATURES = ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul']\nFEATURE_COL = ['bone_length', 'rotting_flesh', 'hair_length', 'has_soul', 'color']\n\ndef AddMahalanobis(df):\n    df2 = df.copy()\n    for t in set(df.type):\n        df_of_a_type = df[df.type == t]\n        mcd = covariance.MinCovDet()\n        mcd.fit(df_of_a_type[NUMERIC_FEATURES])\n        df2[t + '_md'] = mcd.mahalanobis(df[NUMERIC_FEATURES])\n    return df2\n\ndef AddPerColorFeatures(df, feature_cols=NUMERIC_FEATURES, drop_originals=False):\n    df2 = df.copy()\n    for feature_col in feature_cols:\n        for c in set(df['color']):\n            df2[feature_col + '_color_' + c] = df[feature_col] * (df['color'] == c)\n    if drop_originals:\n        df2 = df2.drop(feature_cols, axis=1)\n    return df2\n\ndef GetFeatures(df):\n    df = AddMahalanobis(df)\n    # Does not colorize Malahanobis distances -- should it?\n    df = AddPerColorFeatures(df)\n    #df = AddPerColorFeatures(df, NUMERIC_FEATURES + [t + '_md' for t in set(df.type)], False)\n    df = df.drop(['id', 'type'], axis=1)\n    vec = DictVectorizer(sparse=False)\n    return vec.fit_transform(df.T.to_dict().values()), vec\n\ndef GetFeaturesMahalanobisOnly(df):\n    df = AddMahalanobis(df)\n    df = df[[t + '_md' for t in set(df.type)] + ['color']]\n    vec = DictVectorizer(sparse=False)\n    return vec.fit_transform(df.T.to_dict().values()), vec\n\ndef GetTarget(df):\n    le = preprocessing.LabelEncoder()\n    return le.fit_transform(df.type), le\n\nx_all, vec = GetFeaturesMahalanobisOnly(df)  # GetFeatures(df)\ny_all, le = GetTarget(df)\n\nprint(vec.get_feature_names())\nprint(x_all[0])\nprint(x_all.shape, y_all.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed2322f8-5e69-f8cf-a280-4663fd9bcb51"},"outputs":[],"source":"x_train, x_test, y_train, y_test, id_train, id_test = train_test_split(\n    x_all, y_all, range(len(x_all)), test_size=0.2, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69706227-5242-bcd7-58d4-ac854f9197cd"},"outputs":[],"source":"# RandomForestClassifier example\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=30)\nclf = clf.fit(x_train, y_train)\ny_pred = clf.predict(x_test)\nprint(metrics.confusion_matrix(y_test, y_pred))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9db68d8f-2b24-e635-e724-dacd5696c8b3"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport pylab as pl\nfrom sklearn import metrics\n\nprint(metrics.confusion_matrix(y_all, clf.predict(x_all)))\n\npred = clf.predict(x_test)\nlabels = list(le.classes_)\ncm = metrics.confusion_matrix(y_test, pred)#, labels)\nprint(cm)\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\npl.title('Confusion matrix of the classifier')\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\npl.xlabel('Predicted')\npl.ylabel('True')\npl.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1293aff8-c7b9-1758-4b88-c34efbe8f935"},"outputs":[],"source":"print(x_train.shape, y_train.shape)\nprint(x_all.shape, y_all.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f185596-3128-cadb-26bf-fe69967aff3f"},"outputs":[],"source":"from sklearn import metrics\ntf.logging.set_verbosity(tf.logging.ERROR)\n\ndef TrainLinear(x_train, y_train, x_test, y_test):\n    clf = tf.contrib.learn.LinearClassifier(\n        feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(x_train),\n        n_classes=3,\n        #optimizer=tf.train.FtrlOptimizer(\n        #    learning_rate=0.1,\n        #    l2_regularization_strength=0.001,\n        optimizer=tf.train.AdagradOptimizer(\n            learning_rate=0.5,\n        ))\n    for epoch in range(5):\n        clf.fit(x_train, y_train, steps=500)\n        y_pred = clf.predict(x_test)\n        print('training {}'.format(clf.evaluate(x=x_train, y=y_train)))\n        print('validation {}'.format(clf.evaluate(x=x_test, y=y_test)))\n    #    print('all {}'.format(clf.evaluate(x=x_all, y=y_all)))\n\n    print(metrics.classification_report(y_test, y_pred))\n    print('confusion matrix\\n', metrics.confusion_matrix(y_test, y_pred))\n    return clf\n\n#clf = TrainLinear(x_train, y_train, x_test, y_test)\nclf = TrainLinear(x_all, y_all, x_all, y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19a5d9a1-8908-c143-87e9-44f3b52dce73"},"outputs":[],"source":"clf.get_variable_names()\nclf.get_variable_value('linear/_weight/Adagrad')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe3a1fdc-2674-01cd-696a-a03ebd3b2fce"},"outputs":[],"source":"df_goblin = df[df.type=='Goblin']\nsns.pairplot(df.drop(['id', 'color'], axis=1), hue=\"type\", diag_kind='kde')\nsns.pairplot(df_goblin.drop(['id'], axis=1), hue=\"color\", diag_kind='kde')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56c623ec-8122-2bf0-b5d0-11d891d274b1"},"outputs":[],"source":"sns.pairplot(df_goblin.drop(['id'], axis=1), hue=\"color\", diag_kind='hist')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b161416-9f16-cc7b-4739-4a3ec6c6e397"},"outputs":[],"source":"df3 = AddMahalanobis(df)\ndf3['type'][np.array(id_test)[(y_test == 2) & (y_pred == 1)]] = 'test_Goblin_pred_Ghoul'\ndf3['type'][np.array(id_test)[(y_test == 2) & (y_pred == 0)]] = 'test_Goblin_pred_Ghost'\nsns.pairplot(df3.drop(['id'], axis=1), hue=\"type\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bac31b16-435d-e81a-c75a-8bbf4fbe149e"},"outputs":[],"source":"from sklearn import metrics\ntf.logging.set_verbosity(tf.logging.ERROR)\n\ndef TrainDNN(x_train, y_train, x_test, y_test):\n    clf = tf.contrib.learn.DNNClassifier(\n        feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(x_train),\n        n_classes=3,\n        hidden_units=[9],\n        optimizer=tf.train.ProximalAdagradOptimizer(\n            learning_rate=0.1,\n            l2_regularization_strength=0.001,\n        ))\n    for epoch in range(5):\n        clf.fit(x_train, y_train, steps=500)\n        y_pred = clf.predict(x_test)\n        print('training ', clf.evaluate(x=x_train, y=y_train))\n        print('validation ', clf.evaluate(x=x_test, y=y_test))\n\n    print(metrics.classification_report(y_test, y_pred))\n    print('confusion matrix\\n', metrics.confusion_matrix(y_test, y_pred))\n    return clf\n    \nclf = TrainDNN(x_all, y_all, x_all, y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"297b696a-d4e5-41ed-10df-70bce311f0a7"},"outputs":[],"source":"le.inverse_transform([0,1,2])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98e55835-e6ca-e783-2ece-bbcb5ff17fcf"},"outputs":[],"source":"df_subm = pd.read_csv(\"../input/test.csv\")\nx_subm, _ = GetFeatures(df_subm)\npred_subm = clf.predict(x_subm)\nfdy_subm = pd.DataFrame()\nfdy_subm['id'] = df_subm['id']\nfdy_subm['type'] = le.inverse_transform(pred_subm)\nfdy_subm.to_csv(\"submission.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1a72e46-15b6-db8d-e1cc-ff4b45bda963"},"outputs":[],"source":"print(check_output([\"cat\", \"submission.csv\"]).decode(\"utf8\"))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}