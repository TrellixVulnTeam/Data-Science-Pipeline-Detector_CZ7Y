{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Download SimpleDistributedRL","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/pocokhc/simple_distributed_rl.git\n%mv simple_distributed_rl/srl srl\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:00:59.244543Z","iopub.execute_input":"2022-06-24T06:00:59.245237Z","iopub.status.idle":"2022-06-24T06:01:00.843213Z","shell.execute_reply.started":"2022-06-24T06:00:59.245192Z","shell.execute_reply":"2022-06-24T06:01:00.841761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -V","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:01:00.844979Z","iopub.execute_input":"2022-06-24T06:01:00.845442Z","iopub.status.idle":"2022-06-24T06:01:01.658369Z","shell.execute_reply.started":"2022-06-24T06:01:00.845407Z","shell.execute_reply":"2022-06-24T06:01:01.656631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import srl\nsrl.__version__","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:01:01.660218Z","iopub.execute_input":"2022-06-24T06:01:01.66074Z","iopub.status.idle":"2022-06-24T06:01:01.668663Z","shell.execute_reply.started":"2022-06-24T06:01:01.660696Z","shell.execute_reply":"2022-06-24T06:01:01.667521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create model.py","metadata":{}},{"cell_type":"code","source":"%%writefile model.py\n\nimport json\nimport os\nimport time\nfrom typing import cast\n\nimport numpy as np\n\nimport srl.envs\nimport srl.rl\nfrom srl.base.define import EnvAction\nfrom srl.base.env.base import EnvRun\nfrom srl.base.rl.base import ExtendWorker, WorkerRun\nfrom srl.envs import connectx\nfrom srl.rl.functions.model import ImageLayerType\nfrom srl.runner import sequence\n\n\nclass MyConnectXWorker(ExtendWorker):\n    def __init__(self, *args):\n        super().__init__(*args)\n\n        # rlのconfig\n        self.rl_config = cast(srl.rl.dqn.Config, self.rl_worker.worker.config)\n\n        # 探索数\n        self.max_depth = 4\n\n    def call_on_reset(self, env: EnvRun, worker_run: WorkerRun) -> None:\n        self.is_rl = False\n        self.scores = [0] * env.action_space.n\n        self.minmax_time = 0\n        self.minmax_count = 0\n\n    def call_policy(self, env: EnvRun, worker_run: WorkerRun) -> EnvAction:\n        if env.step_num == 0:\n            # 先行1ターン目\n            self.rl_config.epsilon = 0.5\n            action = self.rl_worker.policy(env)\n            self.is_rl = True\n            return action\n\n        # 2ターン目以降\n        self.rl_config.epsilon = 0.1\n\n        # 元の環境を取得\n        env_org = cast(connectx.ConnectX, env.get_original_env())\n\n        # MinMaxを実施、環境は壊さないようにcopyで渡す\n        self.minmax_count = 0\n        t0 = time.time()\n        self.scores = self._minmax(env_org.copy())\n        self.minmax_time = time.time() - t0\n\n        # 最大スコア\n        max_score = np.max(self.scores)\n        max_count = np.count_nonzero(self.scores == max_score)\n\n        # 最大数が1個ならそのアクションを実施\n        if max_count == 1:\n            self.is_rl = False\n            return int(np.argmax(self.scores))\n\n        # 最大値以外のアクションを選択しないようにする(invalid_actionsに追加)\n        new_invalid_actions = [a for a in range(env.action_space.n) if self.scores[a] != max_score]\n        env.add_invalid_actions(new_invalid_actions, self.player_index)\n\n        # rl実施\n        action = self.rl_worker.policy(env)\n        self.is_rl = True\n\n        return action\n\n    # MinMax\n    def _minmax(self, env: connectx.ConnectX, depth: int = 0):\n        if depth == self.max_depth:\n            return [0] * env.action_space.n\n\n        self.minmax_count += 1\n\n        # 有効なアクションを取得\n        invalid_actions = env.get_invalid_actions()\n        valid_actions = [a for a in range(env.action_space.n) if a not in invalid_actions]\n\n        # env復元用に今の状態を保存\n        env_dat = env.backup()\n\n        if env.player_index == self.player_index:\n            # 自分の番\n            scores = [-9.0 for _ in range(env.action_space.n)]\n            for a in valid_actions:\n                # envを復元\n                env.restore(env_dat)\n\n                # env stepを実施\n                _, r1, r2, done, _ = env.call_step(a)\n                if done:\n                    # 終了状態なら報酬をスコアにする\n                    if self.player_index == 0:\n                        scores[a] = r1\n                    else:\n                        scores[a] = r2\n                else:\n                    # 次のstepに\n                    n_scores = self._minmax(env, depth + 1)\n                    scores[a] = np.min(n_scores)  # 相手の番は最小を選択\n\n        else:\n            # 相手の番\n            scores = [9.0 for _ in range(env.action_space.n)]\n            for a in valid_actions:\n                env.restore(env_dat)\n\n                _, r1, r2, done, _ = env.call_step(a)\n                if done:\n                    if self.player_index == 0:\n                        scores[a] = r1\n                    else:\n                        scores[a] = r2\n                else:\n                    n_scores = self._minmax(env, depth + 1)\n                    scores[a] = np.max(n_scores)  # 自分の番は最大を選択\n\n        return scores\n\n    # 可視化用\n    def call_render(self, env: EnvRun, worker_run: WorkerRun) -> None:\n        print(f\"- MinMax count: {self.minmax_count}, {self.minmax_time:.3f}s -\")\n        print(\"+---+---+---+---+---+---+---+\")\n        s = \"|\"\n        for a in range(env.action_space.n):\n            s += \"{:2d} |\".format(int(self.scores[a]))\n        print(s)\n        print(\"+---+---+---+---+---+---+---+\")\n        if self.is_rl:\n            self.rl_worker.render(env)\n\n\ndef create_config():\n    env_config = srl.envs.Config(\"ConnectX\")\n\n    rl_config = srl.rl.dqn.Config()\n    rl_config.processors = [connectx.LayerProcessor()]\n    rl_config.extend_worker = MyConnectXWorker\n\n    config = sequence.Config(env_config, rl_config)\n    return config\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:01:01.670268Z","iopub.execute_input":"2022-06-24T06:01:01.670635Z","iopub.status.idle":"2022-06-24T06:01:01.687226Z","shell.execute_reply.started":"2022-06-24T06:01:01.670605Z","shell.execute_reply":"2022-06-24T06:01:01.686086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from model import create_config\nfrom srl.runner import sequence\n\nconfig = create_config()\n\n# --- set players\nconfig.players = [None, None]  # self play\n#config.players = [None, \"alphabeta8\"]\n\n# model summary\nconfig.model_summary()\n\n# --- train\nparameter, memory, history = sequence.train(\n    config,\n    timeout=60 * 60 * 10,\n    enable_file_logger=True,\n    enable_validation=False,\n)\n\n# save parameter\nparameter.save(\"parameter.dat\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:01:01.691042Z","iopub.execute_input":"2022-06-24T06:01:01.691401Z","iopub.status.idle":"2022-06-24T06:02:02.000933Z","shell.execute_reply.started":"2022-06-24T06:01:01.691369Z","shell.execute_reply":"2022-06-24T06:02:01.999644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.plot_info(\"train\", \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:02:20.582149Z","iopub.execute_input":"2022-06-24T06:02:20.58257Z","iopub.status.idle":"2022-06-24T06:02:20.900836Z","shell.execute_reply.started":"2022-06-24T06:02:20.582533Z","shell.execute_reply":"2022-06-24T06:02:20.899974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# --- evaluate\nfor players in [\n    [None, None],\n    [None, \"random\"],\n    [\"random\", None],\n    [None, \"alphabeta7\"],\n    [\"alphabeta7\", None],\n]:\n    config.players = players\n    rewards = sequence.evaluate(config, parameter, max_episodes=5)\n    print(f\"{np.mean(rewards, axis=0)}, {players}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:02:26.577399Z","iopub.execute_input":"2022-06-24T06:02:26.578363Z","iopub.status.idle":"2022-06-24T06:03:07.961516Z","shell.execute_reply.started":"2022-06-24T06:02:26.578324Z","shell.execute_reply":"2022-06-24T06:03:07.960361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vs human\n#config.players = [None, \"human\"]\n#sequence.render(config, parameter=parameter)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:53:27.699755Z","iopub.execute_input":"2022-06-23T09:53:27.700788Z","iopub.status.idle":"2022-06-23T09:53:27.706416Z","shell.execute_reply.started":"2022-06-23T09:53:27.700739Z","shell.execute_reply":"2022-06-23T09:53:27.704633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create main.py","metadata":{}},{"cell_type":"code","source":"%%writefile main.py\n\nimport os\nfrom typing import cast\n\nfrom model import create_config\nfrom srl.envs import connectx\n\nKAGGLE_PATH = \"/kaggle_simulations/agent/\"\nif os.path.isdir(KAGGLE_PATH):\n    is_local = False\n    path = os.path.join(KAGGLE_PATH, \"parameter.dat\")\nelse:\n    is_local = True\n    path = os.path.join(os.path.dirname(__file__), \"parameter.dat\")\n\n    \n# -------- config   \nconfig = create_config()\nconfig.set_parameter_path(parameter_path=path)\n\n\n# ------- agent\nenv = config.make_env()\norg_env = cast(connectx.ConnectX, env.get_original_env())\nparameter = config.make_parameter()\nworker = config.make_worker(parameter)\n\n\ndef my_agent(observation, configuration):\n    step = observation.step\n\n    # 1エピソードの最初にresetを呼ぶ必要がある\n    # connectx は先行なら step==0、後攻なら step==1 がエピソードの最初\n    if step == 0 or step == 1:\n        env.direct_reset(observation, configuration)\n        worker.on_reset(env, org_env.player_index)\n\n    env.direct_step(observation, configuration)\n    action = worker.policy(env)\n    return action\n\n\nif is_local:\n    import time\n    import numpy as np\n    import kaggle_environments\n    \n    config.model_summary()\n\n    kaggle_env = kaggle_environments.make(\"connectx\", debug=True)\n    for players in [\n        [my_agent, \"random\"],\n        [\"random\", my_agent],\n        [my_agent, \"negamax\"],\n        [\"negamax\", my_agent],\n    ]:\n        # 10episode実行\n        rewards = []\n        t0 = time.time()\n        for _ in range(10):\n            steps = kaggle_env.run(players)\n            rewards.append([steps[-1][0][\"reward\"], steps[-1][1][\"reward\"]])\n        \n        # 結果\n        rewards = np.mean(rewards, axis=0)\n        print(f\"rewards {rewards}, {time.time() - t0:.3f}s, {players}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:11:08.826939Z","iopub.execute_input":"2022-06-24T06:11:08.827398Z","iopub.status.idle":"2022-06-24T06:11:08.837574Z","shell.execute_reply.started":"2022-06-24T06:11:08.827364Z","shell.execute_reply":"2022-06-24T06:11:08.836264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python main.py","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:11:10.495353Z","iopub.execute_input":"2022-06-24T06:11:10.495792Z","iopub.status.idle":"2022-06-24T06:11:30.60321Z","shell.execute_reply.started":"2022-06-24T06:11:10.495756Z","shell.execute_reply":"2022-06-24T06:11:30.601753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create submission.tar.gz","metadata":{}},{"cell_type":"code","source":"!find . | grep -E \"(__pycache__|\\.pyc|\\.pyo$)\" | xargs rm -rf\n!tar -czvf submission.tar.gz main.py srl model.py parameter.dat","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:54:41.180741Z","iopub.execute_input":"2022-06-23T09:54:41.181071Z","iopub.status.idle":"2022-06-23T09:54:42.76826Z","shell.execute_reply.started":"2022-06-23T09:54:41.181041Z","shell.execute_reply":"2022-06-23T09:54:42.767119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-06-23T09:54:42.770175Z","iopub.execute_input":"2022-06-23T09:54:42.77052Z","iopub.status.idle":"2022-06-23T09:54:43.530771Z","shell.execute_reply.started":"2022-06-23T09:54:42.770487Z","shell.execute_reply":"2022-06-23T09:54:43.52966Z"},"trusted":true},"execution_count":null,"outputs":[]}]}