{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install kaggle-environments"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.6 cannot be found (uncomment if needed). \n# !curl -X PURGE https://pypi.org/simple/kaggle-environments\n\n# ConnectX environment was defined in v0.1.6\n!pip install 'kaggle-environments>=0.1.6'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create ConnectX Environment"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils\n\nenv = make(\"connectx\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute(col, matrix_board, rows, mark, inarow):\n    heuristique = 0.\n    if matrix_board[0][col] != 0:\n        return -10.\n\n    opponent = 2\n    if mark == 2:\n        opponent = 1\n    opp_blocks = find_blocks(matrix_board, opponent, inarow)\n    if opp_blocks[inarow - 1] > 0:\n        return -10.\n\n    new_matrix_board = play(col, matrix_board, rows, mark)\n\n    #print(\"x\"*20)\n    #print(\"xxxxx Calcul heuristique\")\n    #print(new_matrix_board)\n\n    blocks = find_blocks(new_matrix_board, mark, inarow)\n\n    if blocks[inarow - 1] > 0:\n        return 10.\n    else:\n        for i, b in enumerate(blocks):\n            heuristique += b * (i+1) * (i+1)\n\n        heuristique /=  50.\n    #print(\"xx My heuristique : \", heuristique)\n\n    # For the opponent\n    opp_heuristique = 0.\n    for i, b in enumerate(opp_blocks):\n        opp_heuristique += b * (i+1) * (i+1)\n\n    opp_heuristique /=  50.\n\n    #print(\"xx Opp heuristique : \", opp_heuristique)\n    #print(\"Final heurisique : \", heuristique - opp_heuristique)\n    return heuristique - opp_heuristique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def play(col, matrix_board, rows, mark):\n    new_matrix_board = matrix_board.copy()\n    for r in reversed(range(rows)):\n        if new_matrix_board[r][col] == 0:\n            new_matrix_board[r][col] = mark\n            break\n    return new_matrix_board","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def contains(small, big):\n    for i in range(len(big)-len(small)+1):\n        for j in range(len(small)):\n            if big[i+j] != small[j]:\n                break\n        else:\n            return i, i+len(small)\n    return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_blocks(matrix_board, mark, inarow):\n    rows = matrix_board.shape[0]\n    cols = matrix_board.shape[1]\n\n    blocks = [0]*inarow\n\n    # horizontal blocks\n    for r in range(rows):\n        b_size = 0\n\n        if 0 not in matrix_board[r]:\n            # line full\n            victory_list = [mark]*inarow\n            if not contains(victory_list, matrix_board[r]):\n                break\n\n        for c in range(cols):\n            if matrix_board[r][c] == mark:\n                b_size += 1\n                # win\n                if (b_size == inarow):\n                    blocks[b_size - 1] += 1\n                    break\n                if (b_size > 0) and (c == cols - 1):\n                    blocks[b_size - 1] += 1\n            else:\n                if b_size > 0:\n                    blocks[b_size - 1] += 1\n                b_size = 0\n\n    # vertical blocks\n    matrix_board_transp = matrix_board.transpose()\n    rows = matrix_board_transp.shape[0]\n    cols = matrix_board_transp.shape[1]\n    for r in range(rows):\n        b_size = 0\n        for c in range(cols):\n            if matrix_board_transp[r][c] == mark:\n                b_size += 1\n                # win\n                if (b_size == inarow):\n                    blocks[b_size - 1] += 1\n                    break\n                if (b_size > 0) and (c == cols - 1):\n                    blocks[b_size - 1] += 1\n            else:\n                if b_size > 0:\n                    blocks[b_size - 1] += 1\n                # found opponent in column: no more weight for following blocks\n                if matrix_board_transp[r][c] != 0:\n                    break\n                b_size = 0\n\n    # diag blocks\n    # computes only SouthWest to NorthEast direction diagonals: \n    # won't see winning or losing move with other diagonal direction\n    matrix_board_diag = matrix_board.copy()\n    rows = matrix_board_diag.shape[0]\n    cols = matrix_board_diag.shape[1]\n    for k in range(rows + cols -1):\n        diag = []\n        b_size = 0\n        for j in range(k+1):\n            i = k - j;\n            if (i < rows and j < cols):\n                diag.append(matrix_board_diag[i][j])\n        diag.reverse()\n        b_size = 0\n        for i, val in enumerate(diag):              \n            if val == mark:\n                b_size += 1\n                if (b_size > 1 and i == (len(diag) - 1)) or b_size == inarow:\n                    blocks[b_size-1] += 1\n                    break\n            else:\n                if b_size > 1:\n                    blocks[b_size-1] += 1\n                b_size = 0\n\n\n\n    #print(matrix_board)\n    #print(\"Blocks : \", blocks)\n    return blocks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_col_to_play(h_matrix):\n    for d in range(len(h_matrix[0])):\n        for c in range(len(h_matrix)):\n            if h_matrix[c][d].count(10.) > 0:\n                return c\n\n    col_to_play = 66\n    max_found = -100\n    for d in reversed(range(len(h_matrix[0]))):\n        for c in range(len(h_matrix)):\n            max_at_depth_for_col = max(h_matrix[c][d], default=-100)\n            if max_at_depth_for_col > max_found:\n                col_to_play = c\n                max_found = max_at_depth_for_col\n        if max_found > -10.:\n            return col_to_play\n\n    return col_to_play","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def play_one_best_move(columns, new_matrix_board, rows, mark, inarow):\n    import numpy as np\n    h_matrix_opp = np.zeros((columns, 1, 0)).tolist()\n    for c in range(columns):\n        h_opp = compute(c, new_matrix_board, rows, mark, inarow)\n        h_matrix_opp[c][0].append(h_opp)\n    col_opp = get_col_to_play(h_matrix_opp)\n    new_matrix_board = play(col_opp, new_matrix_board, rows, mark)\n    #print(\"New board : {}\".format(new_matrix_board))\n    return new_matrix_board","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def go_trough_moves(h_matrix, matrix_board, cols, rows, mark, inarow, depth, depth_max, h_col):\n    opponent = 1 if mark == 2 else 2\n\n    if depth == depth_max:\n        return\n    else:\n        for col in range(cols):\n            h = compute(col, matrix_board, rows, mark, inarow)\n\n            if depth == 0:\n                h_col = col\n\n            h_matrix[h_col][depth].append(h)\n            if h == -10.:\n                continue\n\n            new_matrix_board = play(col, matrix_board, rows, mark)\n\n            # Opponent may certainly play...\n            new_matrix_board = play_one_best_move(cols, new_matrix_board, rows, opponent, inarow)\n\n            go_trough_moves(h_matrix, new_matrix_board, cols, rows, mark, inarow, depth+1, depth_max, h_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This agent uses a sort of a* algorithm\ndef my_agent(observation, configuration):\n    import numpy as np\n    \n    # Number of Columns on the Board.\n    columns = configuration.columns\n    # Number of Rows on the Board.\n    rows = configuration.rows\n    # Number of Checkers \"in a row\" needed to win.\n    inarow = configuration.inarow\n    # The current serialized Board (rows x columns).\n    board = observation.board[:]\n    # Which player the agent is playing as (1 or 2).\n    mark = observation.mark\n    \n    if np.sum(board) == 0:\n        return int(columns / 2)\n    \n    matrix_board = np.zeros((rows, columns))\n    for row in range(rows):\n        for col in range(columns):\n            matrix_board[row][col] = board[(row*columns) + col]\n    \n    depth = 0\n    max_depth = 3\n    h = 0.01\n    h_matrix = np.zeros((columns, max_depth-1, 0)).tolist()\n    h_matrix = [[ [] for col in range(max_depth)] for row in range(columns)] \n\n    go_trough_moves(h_matrix, matrix_board, columns, rows, mark, inarow, depth, max_depth, 0)\n    #print(\"Final h_matrix : \", h_matrix)\n             \n    return get_col_to_play(h_matrix)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\n\n# Play as the first agent against default \"random\" or negamax agent.\nenv.run([my_agent, my_agent])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Debug/Train your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nwhile not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\n    print(\"Reward: \", reward)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate your Agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) / sum(r[0] + r[1] for r in rewards)\n\n# Run multiple episodes to estimate its performance.\n#print(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\n#print(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Play your Agent\nClick on any column to place a checker there (\"manually select action\")."},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"None\" represents which agent you'll manually play as (first or second player).\nenv.play([my_agent, None], width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Write Submission File\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import inspect\nimport os\n\n# can get function reference through 'globals()[func_name]'\nimport_functions = [\n    compute,\n    play,\n    contains,\n    find_blocks,\n    get_col_to_play,\n    play_one_best_move,\n    go_trough_moves\n]\n\ndef write_agent_to_file(function, file, import_functions=[]):\n    # get source and transform into list of lines\n    function_source = inspect.getsource(function)\n    function_source = function_source.split(\"\\n\")\n\n    for func in import_functions:\n        import_source = inspect.getsource(func)\n        # add tab after every new line\n        import_source = import_source.split(\"\\n\")\n        import_source = [\"    \" + line for line in import_source]\n        # insert new function after function definition\n        function_source.insert(1, \"\\n\".join(import_source))\n    \n    function_source = \"\\n\".join(function_source)\n    \n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(function_source)\n        print(function_source) # print written code\n\nwrite_agent_to_file(my_agent, \"submission.py\", import_functions=import_functions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validate Submission\nPlay your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n\nWhy validate? This roughly verifies that your submission is fully encapsulated and can be run remotely."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: Stdout replacement is a temporary workaround.\nimport sys\nout = sys.stdout\nsubmission = utils.read_file(\"/kaggle/working/submission.py\")\nagent = utils.get_last_callable(submission)\nsys.stdout = out\n\nenv = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}