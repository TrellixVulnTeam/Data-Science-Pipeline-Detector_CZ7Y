{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Minimax with alpha beta pruning\nUses numba for compiling for loops with numpy.  \nFor loops with numpy is usually slower than python lists (due to type conversion)  \nbut numba automatically analyses the byte code and compiles the function statically so it run about 500x faster.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make, utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The following code uses many heuristics.\nThanks to Keith Galli  https://www.youtube.com/watch?v=MMLtza3CZFM for reference implementation and \nhttps://www.youtube.com/watch?v=y7AKtWGOPAE for some heuristics for connect4.\n\n# Here are some heuristics used\n1. Count number 'useful' pieces in rows/columns/diagonals. Useful means u can place additional pieces to win. \n2. Center Column is the best column. As you can connect to both sides of the board.\n3. Even/odd strategy to ensure that you win in the late game.\n4. Lower rows/columns/diagonals are better than higher up the board.\n5. Columns are worth less than rows and diagonals. This is because columns are the easiest to block.\n\n# Value of a board\nThis is the value_of_my_board- factor*value_of_opp_board. This is done using heuristics above.\nNote factor needs to be more than 1 as it's the opponents turn after u place your piece.\n\n# Algorithm\n Minmax search with Alpha Beta Pruning. Not really hard just go wikipedia see pseudocode. But basically the algorithm goes n-steps ahead pick the best board assuming your opponent plays optimally. Alpha Beta pruning so that you can remove branches early and not search them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport numba as nb\n\n@nb.njit\ndef count_nb(arr, value):\n    result = 0\n    for x in arr:\n        if x == value:\n            result += 1\n    return result\n\n@nb.njit\ndef value_fn(board,player):\n    if player == 1:\n        opp_player = 2\n    elif player ==2:\n        opp_player =1\n    return _value_fn(board,player)-5*_value_fn(board,opp_player)\n    \n@nb.njit\ndef _value_fn(board,player):\n    score = 0\n    \n    # Value of center column\n    score+= 101*count_nb(board[:,3],player)\n    \n    # Count score for each row\n    for r in range(6):\n        row_array = board[r,:]\n        for c in range(4):\n            window = row_array[c:c+4]\n            score += evaluate_row(window, player,r)\n    \n    # Count score for each column\n    for c in range(7):\n        col_array = board[:,c]\n        for r in range(3):\n            window = col_array[r:r+4]\n            score += evaluate_column(window, player)\n    \n    # Count score on each diagonal\n    # Forward Diagonal\n    for r in range(3):\n        for c in range(4):\n            window = np.array([board[r+i][c+i] for i in range(4)])\n            score += evaluate_diagonal(window, player,r)\n    \n    # Backward Diagonal\n    for r in range(3):\n        for c in range(4):\n            window = np.array([board[r+3-i][c+i] for i in range(4)])\n            score += evaluate_diagonal(window, player,r)\n            \n    return score\n\n@nb.njit\ndef evaluate_diagonal(window,player,r):\n    score = 0\n    # Lower diagonal is better\n    # Doesnt check if empty place == 0 for given row but will do for now\n    inverse_row = 7-r\n    score += inverse_row #ranges from 1-7\n    if count_nb(window,player) == 4:\n        score += 10000\n    elif count_nb(window,player) == 3 and count_nb(window,0)==1:\n        score += 100\n    elif count_nb(window,player) == 2 and count_nb(window,0)==2:\n        score += 10\n    return score\n\n@nb.njit\ndef evaluate_row(window,player,r):\n    score = 0\n    \n    # Lower row is better\n    inverse_row = 7-r\n    score += inverse_row #ranges from 1-7\n    \n    # Weighs higher on forming rows on odd number rows for player 1\n    # and even rows for player 2 \n    # See connect4 even odd strategy\n    if player == 1 and r%2==0:\n        score +=10\n    if player == 2 and r%2!=0:\n        score +=10\n    \n    if count_nb(window,player) == 4:\n        score += 10000\n    elif count_nb(window,player) == 3 and count_nb(window,0)==1:\n        score += 100\n    elif count_nb(window,player) == 2 and count_nb(window,0)==2:\n        score += 10\n    return score\n\n@nb.njit\ndef evaluate_column(window,player):\n    score = 0\n    if count_nb(window,player) == 4:\n        score += 10000\n    elif count_nb(window,player) == 3 and count_nb(window,0)==1:\n        score += 100\n    elif count_nb(window,player) == 2 and count_nb(window,0)==2:\n        score += 10\n    return 0.5*score\n\n@nb.njit\ndef get_valid_actions(board):\n    \"\"\"\n    get possible valid actions\n    \"\"\"\n    return [c for c in range(0,7) if board[0][c]==0]\n\n@nb.njit\ndef drop_piece(board,col,mark):\n    \"\"\"\n    drop piece at next position\n    \"\"\"\n    board = board.copy()\n    for row in range(6-1, -1, -1):\n        if board[row][col] == 0:\n            break\n    board[row][col] = mark\n    return board\n\n@nb.njit\ndef check_winner(board):\n    \"\"\"\n    Returns player that wins\n    -1 if draws\n    0 if game has not ended\n    \"\"\"\n    # Check rows for winner\n    for row in range(6):\n        for col in range(4):\n            if (board[row][col] == board[row][col + 1] == board[row][col + 2] ==\\\n                board[row][col + 3]) and (board[row][col] != 0):\n                return board[row][col]  #Return Number that match row\n\n    # Check columns for winner\n    for col in range(7):\n        for row in range(3):\n            if (board[row][col] == board[row + 1][col] == board[row + 2][col] ==\\\n                board[row + 3][col]) and (board[row][col] != 0):\n                return board[row][col]  #Return Number that match column\n\n    # Check diagonal (top-left to bottom-right) for winner\n\n    for row in range(3):\n        for col in range(4):\n            if (board[row][col] == board[row + 1][col + 1] == board[row + 2][col + 2] ==\\\n                board[row + 3][col + 3]) and (board[row][col] != 0):\n                return board[row][col] #Return Number that match diagonal\n\n\n    # Check diagonal (bottom-left to top-right) for winner\n\n    for row in range(5, 2, -1):\n        for col in range(4):\n            if (board[row][col] == board[row - 1][col + 1] == board[row - 2][col + 2] ==\\\n                board[row - 3][col + 3]) and (board[row][col] != 0):\n                return board[row][col] #Return Number that match diagonal\n    c = 0\n    for col in range(7):\n        if board[0][col]!=0:\n            c +=1\n    if c == 7:\n        # This is a draw\n        return -1\n    # No winner: return None\n    return 0\n\n@nb.njit\ndef alphabeta(node,depth,alpha,beta,max_player,player,ai_player):\n    winner = check_winner(node)\n    if depth == 0 or winner !=0:\n        if winner == ai_player:\n            return None, 999999999\n        elif winner == player:\n            return None, -999999999\n        elif winner == -1:\n            return None,0\n        else:\n            value = value_fn(node,ai_player)\n            return None,value\n    \n    if max_player:\n        best_value = -9999999999999\n        best_action = 3\n        for action in get_valid_actions(node):\n            child = drop_piece(node,action,ai_player)\n            score = alphabeta(child,depth-1,alpha,beta,False,player,ai_player)[1]\n            if score > best_value:\n                best_value = score\n                best_action = action\n            alpha = max(alpha,best_value)\n            if alpha>=beta:\n                break\n#         print(best_action)\n        return best_action,best_value\n    \n    else:\n        worst_value = 9999999999999\n        worst_action = 3\n        for action in get_valid_actions(node):\n            child = drop_piece(node,action,player)\n            score = alphabeta(child,depth-1,alpha,beta,True,player,ai_player)[1]\n            if score < worst_value:\n                worst_value = score\n                worst_action = action\n            beta = min(beta,worst_value)\n            if beta<=alpha:\n                break\n        return worst_action,worst_value\n\ndef my_agent(observation,config):\n    board = np.array(observation[\"board\"]).reshape(6,7)\n    player = observation[\"mark\"]\n    if player == 1:\n        opp_player =2\n    else:\n        opp_player =1\n    action,value = alphabeta(board,4,-9999999999999,9999999999999,True,opp_player,player)\n    return action\n\n#######################################################\n# call alpha beta once so that numba compiles\narr = np.array([[0,0,0,0,0,0,0],\n                [0,0,0,0,0,0,0],\n                [0,0,2,2,0,0,0],\n                [0,0,1,2,1,0,0],\n                [0,0,1,1,2,0,0],\n                [0,0,1,2,1,0,0]])\n\nalphabeta(arr,2,-9999999999999,9999999999999,True,2,1)\n#######################################################\n\ndef get_minimax_agent(depth=7):\n    def minimax_agent(observation,config):\n        board = np.array(observation[\"board\"]).reshape(6,7)\n        player = observation[\"mark\"]\n        if player == 1:\n            opp_player =2\n        else:\n            opp_player =1\n        action,value = alphabeta(board,depth,-9999999999999,9999999999999,True,opp_player,player)\n        return action\n    return minimax_agent","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Playing first","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"env = make(\"connectx\", debug=True)\nenv.play([None,get_minimax_agent()],width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Playing second","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"env = make(\"connectx\", debug=True)\nenv.play([get_minimax_agent(),None],width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def mean_reward(rewards):\n#     return np.round(rewards.count([1,-1])/len(rewards),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean_reward(evaluate(\"connectx\", [\"negamax\", my_agent], num_episodes=10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean_reward(evaluate(\"connectx\", [my_agent,\"negamax\"], num_episodes=10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}