{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Many thanks to Gordon Henderson for creating [the original notebook](https://www.kaggle.com/code/gordotron85/teaching-an-agent-to-play-connect-4) upon which this workshop is based.","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Introduction to Connect 4 on Kaggle\n\n**What is Kaggle?** So far this semester, we've been using Google Colab for the workshops. Kaggle is like Google Colab, but it also features a community of AI enthusiasts who share code and datasets and compete in AI competitions. I highly recommend checking out Kaggle's competitions page if that sounds interesting to you: https://www.kaggle.com/competitions\n\n*P.S. There is an ongoing [competition specifically for Connect 4](https://www.kaggle.com/competitions/connectx) that you can participate in if you'd like!*\n\n**What is Connect 4?** Most people have probably played Connect 4 before. If not, the rules are simple: Players take turns dropping pieces into a 7x6 grid. The first player to make a line of four pieces in a row wins. The line can be vertical, horizontal, or diagonal. (It's like tic-tac-toe but with gravity that pulls all your pieces to the bottom of the board.)\n\n**What is the ConnectX environment?** Kaggle provides a python package called `kaggle_environments` that provides fun game environments that you can use to practice your programming skills. (It's quite similar to [OpenAI Gym](https://gym.openai.com/envs/#classic_control), if you were here for that workshop.)\n\nThe environment is called ConnectX rather than Connect 4 because it is completely configurable. You can change the size of the board or the number of pieces in a row required (from 4 to something else). But by default, we'll use the standard Connect 4 rules.\n\nLet's create a ConnectX environment now:","metadata":{}},{"cell_type":"code","source":"from kaggle_environments import make\n\n# Create a ConnectX environment with the default Connect 4 board and rules:\nenv = make(\"connectx\", debug=True)\n\n# Display the board on-screen:\nenv.render(mode=\"ipython\")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-04-11T13:16:39.136873Z","iopub.execute_input":"2022-04-11T13:16:39.137249Z","iopub.status.idle":"2022-04-11T13:16:39.157495Z","shell.execute_reply.started":"2022-04-11T13:16:39.137196Z","shell.execute_reply":"2022-04-11T13:16:39.15663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Amazing! You should see a 7x6 board without any pieces placed. To actually *play* the game, we need to create an \"agent\". An \"agent\" is basically a player. Soon we will create an agent that makes smart choices all on its own. But for now, let's create a simple human agent that just asks you, the user, what move to make.\n\nThe agent is just a function that returns an integer from 0-6, where 0 means *place a piece in the far left column* and 6 means *place a piece in the far right column*. This agent will just ask you to type in an integer, and then return that.\n\nRun the following code to define the agent. (It won't actually *do* anything quite yet.)","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n\ndef agent_human(obs, config):\n    # Normally an agent wouldn't do any rendering, but we need the human player to be able to see what's going on\n    clear_output(wait=True)\n    env.render(mode=\"ipython\")\n    \n    # Here's the actual agent code. Rather than making a decision automatically, this agent\n    # just asks the human (you) which move to make, and returns that number.\n    print(\"Please enter your column number (0-6):\")\n    return int(input())","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:16:39.231894Z","iopub.execute_input":"2022-04-11T13:16:39.232279Z","iopub.status.idle":"2022-04-11T13:16:39.238306Z","shell.execute_reply.started":"2022-04-11T13:16:39.232238Z","shell.execute_reply":"2022-04-11T13:16:39.237017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once you've run this, it's time to give the agent a test. Run this code to start a ConnectX game between two copies of `agent_human`:","metadata":{}},{"cell_type":"code","source":"# Create game environment\nenv = make(\"connectx\", debug=True, configuration={ \"actTimeout\": 9999999999 })\n\n# Agents play one game round\nenv.run([agent_human, agent_human])\n\n# Show the game replay\nclear_output(wait=True)\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:16:39.295764Z","iopub.execute_input":"2022-04-11T13:16:39.296337Z","iopub.status.idle":"2022-04-11T13:16:43.46069Z","shell.execute_reply.started":"2022-04-11T13:16:39.296299Z","shell.execute_reply":"2022-04-11T13:16:43.455468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Amazing! Grab a friend, and you'll be able to play Connect 4 against each other. Once you are used to how the column numbers work, let's create our first real agent.","metadata":{}},{"cell_type":"markdown","source":"# Step 2: Random Agent\n\nOur first agent, `agent_human`, just asks the person at the computer what to do. But we want to create agents that think for themselves! Let's begin with an agent that just chooses a random column on every turn.\n\nTo do this, we first need to know how to choose a random column. And the first step there is to get a *list* of all the column numbers. Let's use the `range()` function for this. Check out the code below and edit it as specified.","metadata":{}},{"cell_type":"code","source":"# The following code gets a list of the first 3 numbers, starting from 0.\n# TODO: Can you get the first 20 numbers (0-19) instead?\nnumber_of_columns = 3\nvalid_moves = range(number_of_columns)\n\nprint(list(valid_moves))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:16:48.883534Z","iopub.execute_input":"2022-04-11T13:16:48.883885Z","iopub.status.idle":"2022-04-11T13:16:48.889468Z","shell.execute_reply.started":"2022-04-11T13:16:48.883856Z","shell.execute_reply":"2022-04-11T13:16:48.888441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Awesome. We can use this to get a list of all the valid column numbers. (On the default Connect 4 board, there are seven columns, numbered 0-6.) Then, to choose a random item from that list, we'll use `random.choice()`.","metadata":{}},{"cell_type":"code","source":"import random\nrandom.seed(None) # Make the randomness behave as expected (don't worry about this line too much)\n\nnumber_of_columns = 3\nvalid_moves = range(number_of_columns)\n\n# Choose a random item from the list (0, 1, or 2):\nchosen_move = random.choice(valid_moves)\n\nprint(chosen_move)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:16:50.903012Z","iopub.execute_input":"2022-04-11T13:16:50.903396Z","iopub.status.idle":"2022-04-11T13:16:50.909502Z","shell.execute_reply.started":"2022-04-11T13:16:50.903361Z","shell.execute_reply":"2022-04-11T13:16:50.90831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Amazing! Let's use these tools to create an agent called `agent_random` that picks a random column. (Generally there are 7 columns in a Connect 4 board, but that could change, so `config.columns` will tell us the actual number.)\n\nComplete the code below to choose a random column:","metadata":{}},{"cell_type":"code","source":"import random\n\ndef agent_random(obs, config):\n    # Get the number of columns in the board\n    number_of_columns = config.columns\n\n    # TODO: Create a list of all the valid moves (columns) using `range()`\n    valid_moves = # ???\n    \n    # TODO: Choose a random move (column) from the list\n    chosen_move = # ???\n    \n    # ...and return it\n    return chosen_move","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:16:52.743737Z","iopub.execute_input":"2022-04-11T13:16:52.74432Z","iopub.status.idle":"2022-04-11T13:16:52.751652Z","shell.execute_reply.started":"2022-04-11T13:16:52.744265Z","shell.execute_reply":"2022-04-11T13:16:52.750577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Amazing! If you've created the agent correctly, it should now be able to choose random moves. Let's try playing a game against your agent (`agent_human` vs. `agent_random`):","metadata":{}},{"cell_type":"code","source":"# Create game environment\nenv = make(\"connectx\", debug=True, configuration={ \"actTimeout\": 9999999999 })\n\n# Agents play one game round\nenv.run([agent_human, agent_random])\n\n# Show the game replay\nclear_output(wait=True)\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:16:55.421507Z","iopub.execute_input":"2022-04-11T13:16:55.421888Z","iopub.status.idle":"2022-04-11T13:16:58.600917Z","shell.execute_reply.started":"2022-04-11T13:16:55.421853Z","shell.execute_reply":"2022-04-11T13:16:58.598826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is pretty good! You can even try replacing `agent_human` in the code above with `agent_random` to watch two random agents play against each other.\n\nIn fact, playing random agents against each other is pretty interesting. Let's try having two random agents play 100 games against each other.\n\nThe following code runs a little 100-game contest between two random agents. (You don't need to change anything; it will just work.) Try running it and we'll look at the results.","metadata":{}},{"cell_type":"code","source":"from kaggle_environments import evaluate\nimport numpy as np\n\ndef get_win_percentages(agent1, agent2, n_rounds):\n    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n\n    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n    print(\"Number of invalid plays by Agent 1:\", outcomes.count([None, 0]))\n    print(\"Number of invalid plays by Agent 2:\", outcomes.count([0, None]))\n\n# Play two random agents against each other 100 times\nget_win_percentages(agent_random, agent_random, 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:02.631024Z","iopub.execute_input":"2022-04-11T13:17:02.631395Z","iopub.status.idle":"2022-04-11T13:17:05.436851Z","shell.execute_reply.started":"2022-04-11T13:17:02.631364Z","shell.execute_reply":"2022-04-11T13:17:05.43543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uh oh! There's a problem here. We would expect each agent to win about half the time, but in reality they are winning about a third of the time each. What is happening in the other third of games?\n\nWell, it says that the agents are making invalid plays. What does that mean?\n\nSince `agent_random` just picks a random column from 0-6, it can sometimes try to play in a column that is already full. This is against the rules!\n\nTo fix this, we need to make sure that `valid_moves` only contains the moves that are *actually* valid (i.e. column numbers for columns that are not empty). This means we are going to have to look at the state of the board, which is stored in the variable `obs` (which stands for \"observation\"). Let's print out an example of what `obs` could be, just to understand what it contains...","metadata":{}},{"cell_type":"code","source":"# Reset the environment and manually make a few moves to get an interesting board position\ndata, _ = env.reset()\ndata, _ = env.step([3, 0])\ndata, _ = env.step([0, 2])\ndata, _ = env.step([3, 0])\ndata, _ = env.step([0, 3])\n\n# Get `obs` so we can see what it looks like\nobs = data.observation\n\nprint(obs)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:10.91191Z","iopub.execute_input":"2022-04-11T13:17:10.912475Z","iopub.status.idle":"2022-04-11T13:17:10.9306Z","shell.execute_reply.started":"2022-04-11T13:17:10.912439Z","shell.execute_reply":"2022-04-11T13:17:10.929607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interesting! So `obs` contains `obs.board`, which is a big list of numbers. In a freshly-reset game, as above, all the entries are 0. But each number corresponds to a tile on the board, so as the game progresses, those 0s will be replaced with 1s (for player 1's pieces) and 2s (for player 2's pieces). It also contains `obs.mark`, which is the number of the current player (so in the example above, it is currently player 1's turn).\n\nThe board is given as a list, but it would be much nicer to have it as a rectangle. Let's use `np.reshape()` to turn it into one:","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ngrid = np.asarray(obs.board).reshape(6, 7)\n\nprint(grid)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:13.691658Z","iopub.execute_input":"2022-04-11T13:17:13.692012Z","iopub.status.idle":"2022-04-11T13:17:13.700005Z","shell.execute_reply.started":"2022-04-11T13:17:13.691981Z","shell.execute_reply":"2022-04-11T13:17:13.699085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sweet! Now we can check if a particular column is full or not by just looking at the very top row. The following function should get all the valid moves (i.e. the non-full columns) from a particular board. You just need to make one change to make it correct:","metadata":{}},{"cell_type":"code","source":"def get_valid_moves(obs, config):\n    # Get the board as a rectangle\n    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n\n    first_row = grid[0]\n    \n    # Check each column to find the ones that are not full\n    valid_moves = []\n    for column_index in range(config.columns):\n        if first_row[column_index] == 0:\n            # This `column_index` is not full!\n            # TODO: Add `column_index` to the list `valid_moves`\n            # (Hint: Use `valid_moves.append()`)\n            # ???\n    \n    return valid_moves","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:15.700412Z","iopub.execute_input":"2022-04-11T13:17:15.700922Z","iopub.status.idle":"2022-04-11T13:17:15.708343Z","shell.execute_reply.started":"2022-04-11T13:17:15.700887Z","shell.execute_reply":"2022-04-11T13:17:15.707353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once you have the above function correct, this new version of the agent should always work:","metadata":{}},{"cell_type":"code","source":"import random\n\ndef agent_random(obs, config):\n    valid_moves = get_valid_moves(obs, config)\n    return random.choice(valid_moves)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:19.467545Z","iopub.execute_input":"2022-04-11T13:17:19.468297Z","iopub.status.idle":"2022-04-11T13:17:19.47368Z","shell.execute_reply.started":"2022-04-11T13:17:19.468256Z","shell.execute_reply":"2022-04-11T13:17:19.472492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's give it a try by putting to `agent_random`s against each other. Hopefully they will always make valid moves. Watch and see:","metadata":{}},{"cell_type":"code","source":"# Create game environment\nenv = make(\"connectx\", debug=True)\n\n# Agents play one game round\nenv.run([agent_random, agent_random])\n\n# Show the game replay\nclear_output(wait=True)\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:21.706095Z","iopub.execute_input":"2022-04-11T13:17:21.706699Z","iopub.status.idle":"2022-04-11T13:17:21.770669Z","shell.execute_reply.started":"2022-04-11T13:17:21.706662Z","shell.execute_reply":"2022-04-11T13:17:21.76951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you've written your code correctly, everything should be working. You can even try playing against the random agent yourself by replacing one of the `agent_random`s in the code above with `agent_human`.\n\nNow let's try the 100-game competition again and see what happens:","metadata":{}},{"cell_type":"code","source":"get_win_percentages(agent_random, agent_random, 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:30.744767Z","iopub.execute_input":"2022-04-11T13:17:30.745119Z","iopub.status.idle":"2022-04-11T13:17:33.908233Z","shell.execute_reply.started":"2022-04-11T13:17:30.74509Z","shell.execute_reply":"2022-04-11T13:17:33.907294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hopefully you see zero invalid plays and about a 50% win rate for each agent.","metadata":{}},{"cell_type":"markdown","source":"# Step 3: Smart Agent\n\nLet's try to make an agent that is better than random.\n\nAn obvious first step is to make an agent that makes random choices except when there's something obviously good to do. So if there's a way to win, the agent should take it right away. And if there's a way for the opponent to win on their next turn, the agent should block that move right away. Otherwise, just play randomly.\n\nTo help with this, I am going to provide you with two useful functions that are already correct. The first one, `drop_piece` will simulate dropping a piece so that the agent can see what the board would look like after making a particular move. The second function, `check_winning_grid`, will look at a grid of pieces and decide whether or not a particular player has won the game (i.e. whether a certain player has any 4-in-a-rows).\n\nRun the following code once, and then you will have the functions available when you need them.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\n\n# Gets board at next step if agent drops piece in selected column\ndef drop_piece(grid, config, column, player):\n    next_grid = grid.copy()\n    for row in range(config.rows-1, -1, -1):\n        if next_grid[row][column] == 0:\n            break\n    next_grid[row][column] = player\n    return next_grid\n\n# Check if a particular `player` has won the game on a particular `grid`\ndef check_winning_grid(grid, player, config):\n    # horizontal\n    for row in range(config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[row,col:col+config.inarow])\n            if window.count(player) == config.inarow:\n                return True\n\n    # vertical\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns):\n            window = list(grid[row:row+config.inarow,col])\n            if window.count(player) == config.inarow:\n                return True\n\n    # positive diagonal\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n            if window.count(player) == config.inarow:\n                return True\n\n    # negative diagonal\n    for row in range(config.inarow-1, config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n            if window.count(player) == config.inarow:\n                return True\n\n    return False","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:54.769585Z","iopub.execute_input":"2022-04-11T13:17:54.77025Z","iopub.status.idle":"2022-04-11T13:17:54.788138Z","shell.execute_reply.started":"2022-04-11T13:17:54.770196Z","shell.execute_reply":"2022-04-11T13:17:54.787041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Excellent. Now we're ready to try building `agent_smart`. Let's define a function called `check_winning_move` that will check to see whether placing a piece in a particular column will cause the player to win. (Then we will use this function in the logic for `agent_smart`.)\n\nThe following code is incomplete. Can you finish it?","metadata":{}},{"cell_type":"code","source":"# Returns True if dropping piece in column results in game win\ndef check_winning_move(obs, config, column, player):\n    # Convert the board to a 2D grid\n    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n    \n    # Get the new grid after dropping the player's piece in the column\n    # TODO: Use `drop_piece` to make this work\n    next_grid = # ???\n\n    # TODO: Return whether or not the player has won on `new_grid`\n    # (Hint: Use `check_winning_grid` for this.)\n    return # ???","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:17:57.177987Z","iopub.execute_input":"2022-04-11T13:17:57.178678Z","iopub.status.idle":"2022-04-11T13:17:57.184957Z","shell.execute_reply.started":"2022-04-11T13:17:57.178638Z","shell.execute_reply":"2022-04-11T13:17:57.184021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's test the code to make sure it works. We'll simulate a game and hopefully `check_winning_move` will return `True` when there is a winning move available for player 1 and `False` when there is not a winning move available for player 2. Give it a try:","metadata":{}},{"cell_type":"code","source":"# Start a game and simulate some moves\nenv = make(\"connectx\", debug=True)\ndata, _ = env.step([0, 0])\ndata, _ = env.step([0, 0])\ndata, _ = env.step([1, 0])\ndata, _ = env.step([0, 1])\ndata, _ = env.step([2, 0])\ndata, _ = env.step([0, 2])\nobs = data.observation\n\n# Draw the board\nenv.render(mode=\"ipython\")\n\n# Check if player 1 (blue) could win by playing in the middle column (3)\n# Hopefully this is true\nprint(\"Player 1 can win? (Hopefully True):\", check_winning_move(obs, env.configuration, 3, 1))\n\n# Check if player 2 (white) could win by playing in the middle column (3)\n# Hopefully this is false\nprint(\"Player 2 can win (Hopefully False):\", check_winning_move(obs, env.configuration, 3, 2))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:18:42.783913Z","iopub.execute_input":"2022-04-11T13:18:42.784454Z","iopub.status.idle":"2022-04-11T13:18:42.8216Z","shell.execute_reply.started":"2022-04-11T13:18:42.78441Z","shell.execute_reply":"2022-04-11T13:18:42.820346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Awesome! Once `check_winning_move` is working, we can use it to create `agent_smart`. Recall that `agent_smart` should do three things:\n\n1. If it can find a winning move (i.e. an instant win opportunity) for itself, it plays there.\n2. If it can find a winning move for its oppenent, it plays there in order to block.\n3. Otherwise, it just plays in a random column.\n\nThe following code does most of that. Your job is to finish the code using `check_winning_move`:","metadata":{}},{"cell_type":"code","source":"def agent_smart(obs, config):\n    # Get a list of all the columns that are not full (the valid moves)\n    valid_moves = get_valid_moves(obs, config)\n    \n    # Get the number of the `current_player` and the `other_player`\n    current_player = obs.mark\n    other_player = 2 if current_player == 1 else 1\n    \n    # If there's a winning move for the `current_player`, make it\n    for column in valid_moves:\n        # TODO: Check if this `column` is a winning move for the `current_player`\n        # and return this column as our choice if so. (Hint: Use `check_winning_move`.)\n        if # ???\n            return column\n    \n    # If there's a winning move for the `other_player`, block it\n    # by making the move that the other player wants\n    for column in valid_moves:\n        # TODO: Check if this `column` is a winning move for the `other_player`\n        # and return this column as our choice if so.\n        if # ???\n            return column\n    \n    # Otherwise, choose to play in a random valid column\n    return random.choice(valid_moves)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:18:03.935976Z","iopub.execute_input":"2022-04-11T13:18:03.936363Z","iopub.status.idle":"2022-04-11T13:18:03.944662Z","shell.execute_reply.started":"2022-04-11T13:18:03.936328Z","shell.execute_reply":"2022-04-11T13:18:03.94349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see agent_smart (blue) play against agent_random (white).","metadata":{}},{"cell_type":"code","source":"# Agents play one game round\nenv.reset()\nenv.run([agent_smart, agent_random])\n\n# Show the game\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:19:53.083355Z","iopub.execute_input":"2022-04-11T13:19:53.083983Z","iopub.status.idle":"2022-04-11T13:19:53.182939Z","shell.execute_reply.started":"2022-04-11T13:19:53.083946Z","shell.execute_reply":"2022-04-11T13:19:53.181789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's see how many times agent_smart beats agent_random in 100 games.","metadata":{}},{"cell_type":"code","source":"get_win_percentages(agent_smart, agent_random, 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:19:09.578038Z","iopub.execute_input":"2022-04-11T13:19:09.578436Z","iopub.status.idle":"2022-04-11T13:19:20.677604Z","shell.execute_reply.started":"2022-04-11T13:19:09.578397Z","shell.execute_reply":"2022-04-11T13:19:20.676456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow! `agent_smart` is a *lot* better than `agent_random`. Try playing some games against `agent_smart` yourself:","metadata":{}},{"cell_type":"code","source":"# Agents play one game round\nenv.reset()\nenv.run([agent_smart, agent_human])\n\n# Show the game\nclear_output()\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:22:46.725528Z","iopub.execute_input":"2022-04-11T13:22:46.725905Z","iopub.status.idle":"2022-04-11T13:23:23.061712Z","shell.execute_reply.started":"2022-04-11T13:22:46.725875Z","shell.execute_reply":"2022-04-11T13:23:23.060474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You should notice that this agent is a much smarter oponnent, and you'll have to actively trick it in order to win (for example, by creating two possible winning positions for yourself that are directly on top of each other). But it is still obvious that it is playing randomly most of the time; it doesn't intentionally build good positions for itself.","metadata":{}},{"cell_type":"markdown","source":"# Step 4: Lookahead Agent\n\nLet's replace the random behavior of `agent_smart` with something a little more intentional. We want the agent to build good board positions for itself, so what if we found a way to *score* particular boards based on whether they are good or bad?\n\nWe could count the occurrences of each of the following situations, and assign a score accordingly:\n\n* **A:** The agent has four discs in a row (the agent won),\n* **B:** The agent filled three spots, and the remaining spot is empty (the agent wins if it fills in the empty spot).\n* **C:** The agent filled two spots, and the remaining two spots are empty (the agent wins if it fills in the empty two spots).\n* **D:** The opponent filled two spots, and the remaining two spots are empty (the opponent wins by filling in the empty two spots).\n* **E:** The opponent filled three spots, and the remaining spot is empty (the opponent wins by filling in the empty spot).\n\nThe board is better when A, B, and C are present and worse when D and E are present, so we can calculate the score accordingly. (Each time situation A appears, it's worth 10,000,000,000 points. B is worth 10,000. C is worth 100. D is worth -1. E is worth -1,000,000.)\n\nFor the sake of time (and convenience), the `score_move` function (plus the related helper functions) is created for you. You don't need to change anything, but it might be valuable to take a look at `score_move` and see if it makes sense. (If you have questions, feel free to ask!)\n\nRun the following code to define `score_move`. No need to make any changes.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\n\n# Calculates score if agent drops piece in selected column\ndef score_move(grid, config, column, player):\n    next_grid = drop_piece(grid, config, column, player)\n    score = get_heuristic(next_grid, player, config)\n    return score\n\n# Helper function for score_move: calculates value of heuristic for grid    \ndef get_heuristic(grid, player, config):\n    other_player = 1 if player == 2 else 2\n\n    num_twos = count_windows(grid, 2, player, config)\n    num_threes = count_windows(grid, 3, player, config)\n    num_fours = count_windows(grid, 4, player, config)\n    num_twos_opp = count_windows(grid, 2, other_player, config)\n    num_threes_opp = count_windows(grid, 3, other_player, config)\n\n    score = 1e10*num_fours + 1e4*num_threes + 1e2*num_twos + -1*num_twos_opp + -1e6*num_threes_opp\n    return score\n\n# Helper function for get_heuristic: checks if window satisfies heuristic conditions\ndef check_window(window, num_discs, piece, config):\n    return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n\n# Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\ndef count_windows(grid, num_discs, piece, config):\n    num_windows = 0\n\n    # horizontal\n    for row in range(config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[row, col:col+config.inarow])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n\n    # vertical\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns):\n            window = list(grid[row:row+config.inarow, col])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n\n    # positive diagonal\n    for row in range(config.rows-(config.inarow-1)):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n\n    # negative diagonal\n    for row in range(config.inarow-1, config.rows):\n        for col in range(config.columns-(config.inarow-1)):\n            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n            if check_window(window, num_discs, piece, config):\n                num_windows += 1\n\n    return num_windows","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:59:28.085868Z","iopub.execute_input":"2022-04-11T13:59:28.086348Z","iopub.status.idle":"2022-04-11T13:59:28.1101Z","shell.execute_reply.started":"2022-04-11T13:59:28.086301Z","shell.execute_reply":"2022-04-11T13:59:28.108739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have `score_move`, which gives a score based on how good or bad a move is for the given player, we can use it to create `agent_lookahead`. **The agent should simply search all the `valid_moves` for the one that gives the best score, and then play that.** This time, it's your job to do most of the hard work. Try to fill in the `# ???` in the following code with code that does this. If you need help, feel free to ask!","metadata":{}},{"cell_type":"code","source":"def agent_lookahead(obs, config):\n    # Get list of valid moves\n    valid_moves = get_valid_moves(obs, config)\n\n    # Convert the board to a 2D grid\n    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n\n    # Get the current player\n    player = obs.mark\n    \n    # TODO: Use `score_move` to choose the best move out of all the `valid_moves`\n    # Return the column number that is best!\n    # ???","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:59:31.573934Z","iopub.execute_input":"2022-04-11T13:59:31.574337Z","iopub.status.idle":"2022-04-11T13:59:31.583496Z","shell.execute_reply.started":"2022-04-11T13:59:31.574289Z","shell.execute_reply":"2022-04-11T13:59:31.582218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sweet! Once you have an `agent_lookahead` that you think is correct, try putting `agent_lookahead` and `agent_smart` against each other. Hopefully `agent_lookahead` (blue) will win most of the time:","metadata":{}},{"cell_type":"code","source":"# Agents play one game round\nenv.run([agent_lookahead, agent_smart])\n\n# Show the game\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:48:51.460518Z","iopub.execute_input":"2022-04-11T13:48:51.460877Z","iopub.status.idle":"2022-04-11T13:48:51.893214Z","shell.execute_reply.started":"2022-04-11T13:48:51.460847Z","shell.execute_reply":"2022-04-11T13:48:51.892135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's run a 100-game competition and see the stats:","metadata":{}},{"cell_type":"code","source":"get_win_percentages(agent_lookahead, agent_smart, 100)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:49:02.735483Z","iopub.execute_input":"2022-04-11T13:49:02.735875Z","iopub.status.idle":"2022-04-11T13:49:46.240636Z","shell.execute_reply.started":"2022-04-11T13:49:02.735839Z","shell.execute_reply":"2022-04-11T13:49:46.239476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Amazing! It seems like `agent_lookahead` is genuinely better than `agent_smart`. Finally, take some time to play against `agent_lookahead` yourself. Can you win? Can you win consistently?","metadata":{}},{"cell_type":"code","source":"# Agents play one game round\nenv.reset()\nenv.run([agent_lookahead, agent_human])\n\n# Show the game\nclear_output()\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T13:51:30.798794Z","iopub.execute_input":"2022-04-11T13:51:30.79916Z","iopub.status.idle":"2022-04-11T13:51:33.979432Z","shell.execute_reply.started":"2022-04-11T13:51:30.799129Z","shell.execute_reply":"2022-04-11T13:51:33.978561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5 (Bonus): Minimax Agent\n\nLookahead plays pretty well, but it doesn't really look *that* far head. It is just scoring each possible move based on the board position it would create. A better strategy is to simulate multiple moves into the future and pick the best possible path forward. This is what the minimax algorithm does.\n\nI've provided an example minimax agent here. You can try poking around with the code to see how it works; it's generally a bit better than `agent_lookahead`, but it also takes longer to play.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\n\n# Uses minimax to calculate value of dropping piece in selected column\ndef score_move_minimax(grid, col, mark, config, nsteps):\n    next_grid = drop_piece(grid, config, col, mark)\n    score = minimax(next_grid, nsteps-1, False, mark, config)\n    return score\n\n# Helper function for minimax: checks if game has ended\ndef is_terminal_node(grid, config):\n    # Check for draw \n    if list(grid[0, :]).count(0) == 0:\n        return True\n    \n    # Check for player 1 win\n    if check_winning_grid(grid, 1, config):\n        return True\n\n    # Check for player 2 win\n    if check_winning_grid(grid, 2, config):\n        return True\n    \n    return False\n\n# Minimax implementation\ndef minimax(node, depth, maximizingPlayer, player, config):\n    valid_moves = [c for c in range(config.columns) if node[0][c] == 0]\n\n    if depth == 0 or is_terminal_node(node, config):\n        return get_heuristic(node, player, config)\n    \n    other_player = 1 if player == 2 else 2\n\n    if maximizingPlayer:\n        value = -np.Inf\n        for col in valid_moves:\n            child = drop_piece(node, config, col, player)\n            value = max(value, minimax(child, depth-1, False, player, config))\n        return value\n    else:\n        value = np.Inf\n        for col in valid_moves:\n            child = drop_piece(node, config, col, other_player)\n            value = min(value, minimax(child, depth-1, True, player, config))\n        return value\n\ndef agent_minimax(obs, config):\n    # If agent gets first move, put marker in middle column\n    #if sum(obs.board) == 0:\n        #return 3\n\n    # Get list of valid moves\n    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n\n    # Convert the board to a 2D grid\n    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n\n    # Use the heuristic to assign a score to each possible board in the next step\n    scores = dict(zip(valid_moves, [score_move_minimax(grid, col, obs.mark, config, 3) for col in valid_moves]))\n\n    # Get a list of columns (moves) that maximize the heuristic\n    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n\n    # Select at random from the maximizing columns\n    return random.choice(max_cols)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:10:56.237183Z","iopub.execute_input":"2022-04-11T14:10:56.23754Z","iopub.status.idle":"2022-04-11T14:10:56.257763Z","shell.execute_reply.started":"2022-04-11T14:10:56.237511Z","shell.execute_reply":"2022-04-11T14:10:56.256779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use the following code to play against `agent_minimax`:","metadata":{}},{"cell_type":"code","source":"# Agents play one game round\nenv.reset()\nenv.run([agent_minimax, agent_human])\n\n# Show the game\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T14:10:58.862034Z","iopub.execute_input":"2022-04-11T14:10:58.862513Z","iopub.status.idle":"2022-04-11T14:11:01.36459Z","shell.execute_reply.started":"2022-04-11T14:10:58.862479Z","shell.execute_reply":"2022-04-11T14:11:01.362408Z"},"trusted":true},"execution_count":null,"outputs":[]}]}