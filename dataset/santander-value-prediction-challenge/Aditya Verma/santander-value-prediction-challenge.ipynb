{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#! mkdir ~/.kaggle\n#! cp kaggle.json ~/.kaggle/\n#! chmod 600 ~/.kaggle/kaggle.json\n#! kaggle datasets list\n#!pip install --upgrade --force-reinstall --no-deps kaggle\n#!kaggle competitions download -c santander-value-prediction-challenge\n#! mkdir santander\n#! unzip santander-value-prediction-challenge.zip -d santander","metadata":{"id":"cIJBSS7-JYEa","executionInfo":{"status":"ok","timestamp":1629176896346,"user_tz":-330,"elapsed":10567,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"8ef365d1-7581-4561-8e08-b7b85b96d210","execution":{"iopub.status.busy":"2021-08-19T16:16:26.11185Z","iopub.execute_input":"2021-08-19T16:16:26.112247Z","iopub.status.idle":"2021-08-19T16:16:26.116112Z","shell.execute_reply.started":"2021-08-19T16:16:26.112212Z","shell.execute_reply":"2021-08-19T16:16:26.114983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BUSINESS CONTEXT OF THE PROBLEM**\n\nINTRODUCTION:Santander value prediction challenge is a third competition in a row wherein santander has taken a step further and curated a task to determine the value of transaction with a potential customers and  by having the idea of rough potential transaction  institutions may speculate/predict the type of services a person might need and in turn they can personalise their services for each customer . An amount is a continuous target variable here and problem is a \"**SUPERVISEDD LEARNING REGRESSION TASK**\"\n\n\n#MAPPING BUSINESS PROBLEM TO A MACHINE LEARNING PROBLEM\nFOR A GIVEN DATASET X [n_rows,n_features] predict continuous target variable Y.\nsuch that (Y-Y_hat) is minimised \n\n> ","metadata":{"id":"nc24UeGUifes"}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n! mkdir santander","metadata":{"id":"GHeS5H6oMScB","executionInfo":{"status":"ok","timestamp":1629176904641,"user_tz":-330,"elapsed":1102,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"execution":{"iopub.status.busy":"2021-08-19T16:16:40.132214Z","iopub.execute_input":"2021-08-19T16:16:40.132639Z","iopub.status.idle":"2021-08-19T16:16:41.988658Z","shell.execute_reply.started":"2021-08-19T16:16:40.1326Z","shell.execute_reply":"2021-08-19T16:16:41.987355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('../input/santander-value-prediction-challenge/train.csv')\nprint(\"train\",train.shape)\ntrain.head(2)","metadata":{"id":"namLtrOuNpnf","executionInfo":{"status":"ok","timestamp":1629176910801,"user_tz":-330,"elapsed":4584,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"891d4413-c5ce-4c0b-936f-3b1bcb402de6","execution":{"iopub.status.busy":"2021-08-19T16:16:46.994271Z","iopub.execute_input":"2021-08-19T16:16:46.994652Z","iopub.status.idle":"2021-08-19T16:16:54.386156Z","shell.execute_reply.started":"2021-08-19T16:16:46.994618Z","shell.execute_reply":"2021-08-19T16:16:54.385074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets load the test data\n#test=pd.read_csv('/content/santander/test.csv')\n#print(\"test\",test.shape)\n\n#sample_submission=pd.read_csv('/content/santander/sample_submission.csv')\n#print(\"sample_submission\",sample_submission.shape)","metadata":{"id":"F20kEcXwNt36","executionInfo":{"elapsed":51980,"status":"ok","timestamp":1628908399191,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"},"user_tz":-330},"outputId":"deafc465-0e53-4e97-f73b-edebdcb1d67d","execution":{"iopub.status.busy":"2021-08-19T16:16:54.387686Z","iopub.execute_input":"2021-08-19T16:16:54.388049Z","iopub.status.idle":"2021-08-19T16:16:54.392577Z","shell.execute_reply.started":"2021-08-19T16:16:54.388013Z","shell.execute_reply":"2021-08-19T16:16:54.391234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS","metadata":{"id":"beZUy-w1j7Q4"}},{"cell_type":"code","source":"train.head(2)\n#By looking at the dataset overview it clearly shows that data has sparcity and most of the feature we see there is a huge gap between two values belonging to same features \n#Example  22000000 and 0.0 , 14800000 and 0.0 ","metadata":{"id":"MasoyPDu4IMj","executionInfo":{"status":"ok","timestamp":1629176920779,"user_tz":-330,"elapsed":403,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"6b4872e7-1308-4a4c-def9-686a22a16e2d","execution":{"iopub.status.busy":"2021-08-19T16:16:54.394629Z","iopub.execute_input":"2021-08-19T16:16:54.395032Z","iopub.status.idle":"2021-08-19T16:16:54.432441Z","shell.execute_reply.started":"2021-08-19T16:16:54.394997Z","shell.execute_reply":"2021-08-19T16:16:54.431185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()\n#As we can see train data has most of features are float and int and one object feature","metadata":{"id":"QUSgpU6f6V5e","executionInfo":{"status":"ok","timestamp":1629176923149,"user_tz":-330,"elapsed":469,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"44ede2a5-d854-4fda-d448-fb380f83db9a","execution":{"iopub.status.busy":"2021-08-19T16:16:54.433822Z","iopub.execute_input":"2021-08-19T16:16:54.434099Z","iopub.status.idle":"2021-08-19T16:16:54.802525Z","shell.execute_reply.started":"2021-08-19T16:16:54.434071Z","shell.execute_reply":"2021-08-19T16:16:54.801448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets print the duplicate columns \nprint(len(train.columns))    # total number of columns\nprint(len(set(train.columns)))      # unique number of columns \n# since number of unique features = total columns , hence there is not duplicate column\n","metadata":{"id":"r7M-02NARxyS","executionInfo":{"status":"ok","timestamp":1629176945388,"user_tz":-330,"elapsed":396,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"289ebe67-5f3b-424d-ac4e-da82e8017f39","execution":{"iopub.status.busy":"2021-08-19T16:16:54.803914Z","iopub.execute_input":"2021-08-19T16:16:54.804236Z","iopub.status.idle":"2021-08-19T16:16:54.810866Z","shell.execute_reply.started":"2021-08-19T16:16:54.804203Z","shell.execute_reply":"2021-08-19T16:16:54.809991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now lets explore the number of constant feautres as due to constant values they are not capturing any varience\nfilt=(train.nunique()==1) # feature wise unique value count\ntrain.nunique()[filt]     # number features have single values\nprint(\"constant features:\",train.nunique()[filt].shape[0])","metadata":{"id":"R94b8lOjvI5c","executionInfo":{"status":"ok","timestamp":1629176960756,"user_tz":-330,"elapsed":2303,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"4ff7fe49-b8b6-428c-9300-b9daa254db36","execution":{"iopub.status.busy":"2021-08-19T16:16:58.025025Z","iopub.execute_input":"2021-08-19T16:16:58.025395Z","iopub.status.idle":"2021-08-19T16:17:01.814382Z","shell.execute_reply.started":"2021-08-19T16:16:58.025362Z","shell.execute_reply":"2021-08-19T16:17:01.813568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lests drop the constant features\ncol=list(train.nunique()[filt].reset_index()['index'])\ntrain=train.drop(columns=col)\nprint('train',train.shape)\n","metadata":{"id":"9yUF0GGjXRtS","executionInfo":{"status":"ok","timestamp":1629176979101,"user_tz":-330,"elapsed":1111,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"5f0fa300-0445-4b76-e507-cb253deca67d","execution":{"iopub.status.busy":"2021-08-19T16:17:03.310645Z","iopub.execute_input":"2021-08-19T16:17:03.311012Z","iopub.status.idle":"2021-08-19T16:17:04.64369Z","shell.execute_reply.started":"2021-08-19T16:17:03.310982Z","shell.execute_reply":"2021-08-19T16:17:04.642676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=train.T.drop_duplicates()\n# train.T had (4737 rows × 4459 columns) and after removal of duplicates it has reduced to 4733 rows × 4459 columns ","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:17:05.830261Z","iopub.execute_input":"2021-08-19T16:17:05.830639Z","iopub.status.idle":"2021-08-19T16:17:15.182763Z","shell.execute_reply.started":"2021-08-19T16:17:05.830607Z","shell.execute_reply":"2021-08-19T16:17:15.181399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape\ndf.columns\ntrain=df.T\nprint(\"train after duplicate columns removal\",train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:17:33.713816Z","iopub.execute_input":"2021-08-19T16:17:33.714191Z","iopub.status.idle":"2021-08-19T16:17:35.372304Z","shell.execute_reply.started":"2021-08-19T16:17:33.714159Z","shell.execute_reply":"2021-08-19T16:17:35.371041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets print the duplicate columns \nprint(\"total number of columns\",len(train.columns))    # total number of columns\nprint(\"unique columns\",len(set(train.columns)))      # unique number of columns \n# since number of unique features = total columns , hence there is not duplicate column\n","metadata":{"id":"Tdel39HHZAlE","executionInfo":{"status":"ok","timestamp":1629177095510,"user_tz":-330,"elapsed":392,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"cffa1f85-de95-45c9-a40a-162ff85695d9","execution":{"iopub.status.busy":"2021-08-19T16:17:37.437753Z","iopub.execute_input":"2021-08-19T16:17:37.438119Z","iopub.status.idle":"2021-08-19T16:17:37.445454Z","shell.execute_reply.started":"2021-08-19T16:17:37.438088Z","shell.execute_reply":"2021-08-19T16:17:37.444157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Duplicate features\ndup={}\nfor i,col in enumerate(train.columns):\n  to_remove=[]\n  for j in range(i+1,len(train.columns)):\n    if np.all(train.iloc[:,i].values == train.iloc[:,j].values)==True:\n      to_remove.append(train.columns[j])\n  if len(to_remove)!=0:\n    dup[col]=to_remove\n  else:\n   continue   ","metadata":{"id":"yWPHQL16hvR3","execution":{"iopub.status.busy":"2021-08-19T16:17:39.363386Z","iopub.execute_input":"2021-08-19T16:17:39.363895Z","iopub.status.idle":"2021-08-19T16:17:47.027672Z","shell.execute_reply.started":"2021-08-19T16:17:39.363863Z","shell.execute_reply":"2021-08-19T16:17:47.026403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Duplicates features = ['d60ddde1b','acc5b709d', 'f333a5f60','f8d75792f','912836770','f333a5f60']\n#dup\n#drop duplicate features\n#train=train.drop(columns=['d60ddde1b','acc5b709d', 'f333a5f60','f8d75792f','912836770','f333a5f60'])","metadata":{"id":"6Cl72uFdojja","execution":{"iopub.status.busy":"2021-08-19T16:17:51.002416Z","iopub.execute_input":"2021-08-19T16:17:51.002948Z","iopub.status.idle":"2021-08-19T16:17:51.006308Z","shell.execute_reply.started":"2021-08-19T16:17:51.002915Z","shell.execute_reply":"2021-08-19T16:17:51.005154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets create target variable \ny_train=train['target']\nprint('y_train',y_train.shape)\ntrain.columns[2:]","metadata":{"id":"szvgw7AROSTU","executionInfo":{"status":"ok","timestamp":1629177107943,"user_tz":-330,"elapsed":445,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"4ee3a387-288a-48c3-e251-52b1973a9177","execution":{"iopub.status.busy":"2021-08-19T16:17:52.473576Z","iopub.execute_input":"2021-08-19T16:17:52.474289Z","iopub.status.idle":"2021-08-19T16:17:52.484052Z","shell.execute_reply.started":"2021-08-19T16:17:52.474238Z","shell.execute_reply":"2021-08-19T16:17:52.482584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check for null values\nnull_features=[]\nfor f in train.columns:\n  if np.any(train[f].isnull().values) == True:\n    null_features.append(f)\n  else:\n    continue\nprint(\"number of null values in train :\",null_features) \nprint(train.shape)\n#print(test.shape)","metadata":{"id":"0l6o7nhezuhd","executionInfo":{"status":"ok","timestamp":1629177138798,"user_tz":-330,"elapsed":1081,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"c544094f-7876-4189-8c60-12e36d6713da","execution":{"iopub.status.busy":"2021-08-19T16:17:54.161199Z","iopub.execute_input":"2021-08-19T16:17:54.161798Z","iopub.status.idle":"2021-08-19T16:17:56.780089Z","shell.execute_reply.started":"2021-08-19T16:17:54.161747Z","shell.execute_reply":"2021-08-19T16:17:56.778616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As a part of EDA lets quantify the sparcity of train data \nflat_train=train.iloc[:,1:].to_numpy().flatten() # flatten the train data\nprint(\"Total values:\",flat_train.shape[0])  ## tota non zero values in dataset\n\n# Calculate total number of non zero values\nsparcity = flat_train[flat_train!=0].shape[0]/flat_train.shape[0] * 100\nprint(\"Perentage of non_zero values:\",sparcity,\"%\")\n\n# so from sparcity values we can see that aprox 3.3% values are non zero\n\n#Lets depict it on plot\n\nimport plotly.express as px\n  \n# Random Data\nrandom_x = [flat_train.shape[0],flat_train[flat_train!=0].shape[0]]\nnames = ['Total', 'non_zero']\nfig = px.pie(values=random_x, names=names)\nfig.show()\n# ONLY 3.23% VALUES ARE NON ZERO IN TRAIN DATA REST ARE ZEROS","metadata":{"id":"KQg9_JaVoXEg","executionInfo":{"status":"ok","timestamp":1629177162803,"user_tz":-330,"elapsed":3468,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"a197fc64-eb96-40c6-890a-475847fdcef4","execution":{"iopub.status.busy":"2021-08-19T16:17:58.822144Z","iopub.execute_input":"2021-08-19T16:17:58.822558Z","iopub.status.idle":"2021-08-19T16:18:06.808705Z","shell.execute_reply.started":"2021-08-19T16:17:58.82252Z","shell.execute_reply":"2021-08-19T16:18:06.80786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA(b): FEATURE SELECTION","metadata":{"id":"3L9_N8xCwAxU"}},{"cell_type":"code","source":"from sklearn.preprocessing import minmax_scale\ntrain_scaled = minmax_scale(train.iloc[:,2:], axis = 0)\ntrain_scaled.shape","metadata":{"id":"qq7hln7Hc1qp","executionInfo":{"status":"ok","timestamp":1629177190194,"user_tz":-330,"elapsed":1094,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"7aaa31b7-7243-43ff-fcb0-06dc1cab4933","execution":{"iopub.status.busy":"2021-08-19T16:18:15.133211Z","iopub.execute_input":"2021-08-19T16:18:15.133788Z","iopub.status.idle":"2021-08-19T16:18:16.979983Z","shell.execute_reply.started":"2021-08-19T16:18:15.13374Z","shell.execute_reply":"2021-08-19T16:18:16.978684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train test split ,since we could also use validation_ratio=0.9 but using that aproach in may lead to feeding of test data\n# while training so its better to split it before and define as a validation_data\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_tr, y_ts = train_test_split(train_scaled, y_train, train_size = 0.7, random_state = 42)\nprint(\"x_train\",x_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_tr\",y_tr.shape)\nprint(\"y_ts\",y_ts.shape)\n","metadata":{"id":"vWJ63eUfNk3d","executionInfo":{"status":"ok","timestamp":1629177194000,"user_tz":-330,"elapsed":403,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"0aa9aa37-f4a1-4d5f-bb89-9c24d3ad8eb4","execution":{"iopub.status.busy":"2021-08-19T16:18:18.473645Z","iopub.execute_input":"2021-08-19T16:18:18.474047Z","iopub.status.idle":"2021-08-19T16:18:18.820024Z","shell.execute_reply.started":"2021-08-19T16:18:18.474013Z","shell.execute_reply":"2021-08-19T16:18:18.8189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now lets understand the distribution of target variable\nplt.figure(figsize=(8,8))\nsns.histplot(data=y_tr)\nplt.grid()\nplt.show()\n#since data is right skewed and we know from statistical point of view that data should be normal or close to normal\n#that can be done by box cox transform or in simple term by log normalising the data","metadata":{"id":"3cv0Tucxtk92","executionInfo":{"status":"ok","timestamp":1629177196573,"user_tz":-330,"elapsed":772,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"cfad04d3-efb2-4a00-d18e-5f4e82cdfcd5","execution":{"iopub.status.busy":"2021-08-19T16:18:20.083448Z","iopub.execute_input":"2021-08-19T16:18:20.083922Z","iopub.status.idle":"2021-08-19T16:18:20.418813Z","shell.execute_reply.started":"2021-08-19T16:18:20.083888Z","shell.execute_reply":"2021-08-19T16:18:20.417742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nx=np.arange(len(y_train))\nplt.figure(figsize=(10,10))\nsns.histplot(np.log1p(y_tr.astype(float)),kde=True)\nplt.show()\n#Now we can see that we have normalised data and it is more close to normal distribution\n# which could be an advantage for better generalisation","metadata":{"id":"jYW_pSsC_Or4","executionInfo":{"status":"ok","timestamp":1629177198772,"user_tz":-330,"elapsed":561,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"da2e0d84-4d71-439e-b3ec-5791919e40f7","execution":{"iopub.status.busy":"2021-08-19T16:18:21.621038Z","iopub.execute_input":"2021-08-19T16:18:21.621406Z","iopub.status.idle":"2021-08-19T16:18:22.059188Z","shell.execute_reply.started":"2021-08-19T16:18:21.621377Z","shell.execute_reply":"2021-08-19T16:18:22.058001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#BEFORE DOING FEATURE SELECTION WE NEED TO GET FEATURE IMPORTANCES \n#LETS TRAIN A RANDOM FOREST MODEL TO GET THOSE\nimport pickle\nimport os\n#path=\"/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/CASE STUDY 1/baseline_model\"\npath=\"./santander/baseline_model_after70% split\"\n\nif not os.path.isfile(path):\n  from sklearn.ensemble import RandomForestRegressor\n  regressor=RandomForestRegressor()\n  regressor.fit(x_train,y_tr)\n  pickle.dump(regressor, open(path, 'wb'))\nelse:\n  regressor=pickle.load(open(path, 'rb'))\n\n\nfrom sklearn.metrics import mean_squared_log_error\npred_test=regressor.predict(x_test)\nrmsle_test=np.sqrt(mean_squared_log_error(y_ts,pred_test))  \n\npred_train=regressor.predict(x_train)\nrmsle_train = np.sqrt(mean_squared_log_error(y_tr,pred_train))\nprint(\"rmsle_test\",rmsle_test)\nprint(\"rmsle_train\",rmsle_train)\n\nfrom sklearn.metrics import r2_score\nprint(\"R_square_train\",r2_score(y_tr, pred_train))\nprint(\"R_squared_test\",r2_score(y_ts,pred_test))\n\n#Plots\nresidual_train = (y_tr - pred_train)\nresidual_test = (y_ts - pred_test)\n\nf, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,7))\nax1.scatter(pred_train, residual_train)\nax1.set_title('Target vs Residual plot')\nax2.scatter(pred_test,residual_test )\nax2.set_title('Target vs Residual plot')\n############################################\n\nprint(\"\\nResults after log transformation of target variable\")\n#path1=\"/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/CASE STUDY 1/baseline_model_second_attempt\"\npath1=\"./santander/baseline_model_second_attempt_after70%split\"\n\nif not os.path.isfile(path1):\n  from sklearn.ensemble import RandomForestRegressor\n  regressor2=RandomForestRegressor()\n  regressor2.fit(x_train,np.log1p(y_tr.astype(float)))\n  pickle.dump(regressor, open(path1, 'wb'))\nelse:\n  regressor2=pickle.load(open(path1, 'rb'))\n\n\nfrom sklearn.metrics import mean_squared_log_error\npred_test=regressor2.predict(x_test)\nrmsle_test=np.sqrt(mean_squared_log_error(y_ts,np.exp(pred_test)))  \n\npred_train=regressor2.predict(x_train)\nrmsle_train = np.sqrt(mean_squared_log_error(y_tr,np.exp(pred_train)))\nprint(\"\\nrmsle_test\",rmsle_test)\nprint(\"rmsle_train\",rmsle_train)\n\n\nresidual_train = (y_tr - np.exp(pred_train))\nresidual_test = (y_ts - np.exp(pred_test))\n\nf, (ax3, ax4) = plt.subplots(1, 2,figsize=(15,7))\nax3.scatter(pred_train, residual_train)\nax3.set_title('Target vs Residual plot')\nax4.scatter(pred_test,residual_test )\nax4.set_title('Target vs Residual plot')\n\nfrom sklearn.metrics import r2_score\nprint(\"R_square_train\",r2_score(y_tr, np.exp(pred_train) ))\nprint(\"R_squared_test\",r2_score(y_ts,np.exp(pred_test)))\n\n#Rmsle value for train and test data are far apart i.e model is overfitting but severity of overfit increased on training log transformed data'\n#although test as well as train error has reduces significantly but Rmsle values are also far apart.","metadata":{"id":"AJXByLiB7QoU","executionInfo":{"status":"ok","timestamp":1629177207035,"user_tz":-330,"elapsed":6663,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"992a5a56-f9dd-44e6-9f10-56686ed4a3d9","execution":{"iopub.status.busy":"2021-08-19T16:18:24.175166Z","iopub.execute_input":"2021-08-19T16:18:24.175535Z","iopub.status.idle":"2021-08-19T16:34:14.127262Z","shell.execute_reply.started":"2021-08-19T16:18:24.175504Z","shell.execute_reply":"2021-08-19T16:34:14.126179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"importance=regressor.feature_importances_\nprint(\"feature_importances_\",regressor.feature_importances_)\nprint(\"featues:\",regressor.n_features_)\nargs=importance.argsort()[::-1][:20]\ntop_20=importance[args]\nplt.style.use('dark_background')\nplt.figure(figsize=(40,20))\n#plt.grid()\nplt.barh(y=np.arange(0,20), width=top_20,color='r')\nplt.xlabel(\"Importances\")\nplt.ylabel(\"Features\")\nplt.tight_layout\nplt.title(\"Top 20 Feature importances\")\nfor i in range(0,20):\n  plt.annotate(\"{}\".format(np.round(top_20[i],4)),xy=(top_20[i]+0.001,i),size=20)\nplt.show()\n# top 20 important features along with their importance coefficient\n# for further we will do univeriate as well as bivariate analysis ","metadata":{"id":"AhBYU7qY7mTw","executionInfo":{"status":"ok","timestamp":1629179490811,"user_tz":-330,"elapsed":1497,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"568a2a9b-cf0e-466b-d972-4384c727f842","execution":{"iopub.status.busy":"2021-08-19T16:34:47.283495Z","iopub.execute_input":"2021-08-19T16:34:47.283893Z","iopub.status.idle":"2021-08-19T16:34:47.813338Z","shell.execute_reply.started":"2021-08-19T16:34:47.283857Z","shell.execute_reply":"2021-08-19T16:34:47.812282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args\ndata=train.iloc[:,args]\ndata.columns","metadata":{"id":"9jKDzrhKj5J4","executionInfo":{"status":"ok","timestamp":1629179502666,"user_tz":-330,"elapsed":410,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"d02159a3-ed3f-4b64-edfc-4b2132eacf3a","execution":{"iopub.status.busy":"2021-08-19T16:34:14.623374Z","iopub.execute_input":"2021-08-19T16:34:14.623699Z","iopub.status.idle":"2021-08-19T16:34:14.633959Z","shell.execute_reply.started":"2021-08-19T16:34:14.623669Z","shell.execute_reply":"2021-08-19T16:34:14.632659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation heatmap for imporatant features\ndata=train.iloc[:,args].astype(float)\ndata.corr()\nplt.figure(figsize=(25,15))\nsns.heatmap(data.corr(method='spearman'),vmin=0,vmax=1,annot=True)\nplt.show()\n\n#As we can see there is some correlation between important features but they all are not much significant with respect to\n# statistical standpoint","metadata":{"id":"w43uPAoTKwPG","executionInfo":{"status":"ok","timestamp":1629177218873,"user_tz":-330,"elapsed":3191,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"b14fcf1f-6fc4-4849-f277-1af974966693","execution":{"iopub.status.busy":"2021-08-19T16:34:52.774754Z","iopub.execute_input":"2021-08-19T16:34:52.775141Z","iopub.status.idle":"2021-08-19T16:34:55.245454Z","shell.execute_reply.started":"2021-08-19T16:34:52.775106Z","shell.execute_reply":"2021-08-19T16:34:55.244271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data.columns\n \n#top_20 = ['d401c2b4a', 'e7c0a50e8', 'f6240919f', '268040457', 'dbc48d37c',\n#       '22fbf6997', 'b517115d3', 'd08d1fbe3', '46e10e042', '01005e5de',\n#       '0933930b4', '04b88be38', '413bbe772', '9c502dcd9', 'f52a82e7f',\n#       'e176a204a', 'd79736965', '23c780950', '1bf8c2597', 'ba480f343'] \n\ntop_20 = data.columns\ntop_20","metadata":{"id":"SaZ0JRtd6l2p","executionInfo":{"status":"ok","timestamp":1629179544836,"user_tz":-330,"elapsed":400,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"5a736f49-d42b-4fa6-ef6d-561d295a553e","execution":{"iopub.status.busy":"2021-08-19T16:47:15.352346Z","iopub.execute_input":"2021-08-19T16:47:15.352701Z","iopub.status.idle":"2021-08-19T16:47:15.360314Z","shell.execute_reply.started":"2021-08-19T16:47:15.352672Z","shell.execute_reply":"2021-08-19T16:47:15.359113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data is highly effected by outliers as we can see all the 15 features are facing the issue of outlier on the positive side \nplt.style.use('dark_background')\nplt.figure(figsize=(20,10))\n#data.boxplot(figsize=(15,20),color='r')\nsns.boxplot(data=data,color='b',showfliers=True,orient='vertical').set_ylim(-10e4,10e6)\nplt.xlabel(\"Values\")\nplt.ylabel(\"Features\")\nplt.tight_layout()\nplt.show()  \n# From boxplot we can see that there are lot of outliers in all the top important features.again for all practical using rmse as a loss \n# function is a good choice for this type of data and since features have very diffent scales ,it need feature scaling","metadata":{"id":"1U7nUo0KNswf","executionInfo":{"status":"ok","timestamp":1629179574416,"user_tz":-330,"elapsed":1365,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"1dc14c84-5368-4398-bc63-28b2d096bf69","execution":{"iopub.status.busy":"2021-08-19T16:34:59.506279Z","iopub.execute_input":"2021-08-19T16:34:59.506641Z","iopub.status.idle":"2021-08-19T16:35:00.257761Z","shell.execute_reply.started":"2021-08-19T16:34:59.506611Z","shell.execute_reply":"2021-08-19T16:35:00.256968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,12))\nsns.violinplot(data=data,orient='vertical').set_ylim(-10e6,10e7)\nplt.tight_layout()\nplt.ylabel(\"Values\")\nplt.xlabel(\"Features\")\nplt.title(\"Violin Plot\")\nplt.tight_layout()\nplt.show()\n#Distributions are highly skewed about their means and are symmetric. As we saw in box plot data has outliers same thing is observed here also.","metadata":{"id":"Cxxn_v6KSbKh","executionInfo":{"status":"ok","timestamp":1629179598161,"user_tz":-330,"elapsed":1628,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"4d1005b4-7889-4b6a-b578-3337d8644de7","execution":{"iopub.status.busy":"2021-08-19T16:35:55.658164Z","iopub.execute_input":"2021-08-19T16:35:55.658504Z","iopub.status.idle":"2021-08-19T16:35:56.708665Z","shell.execute_reply.started":"2021-08-19T16:35:55.658474Z","shell.execute_reply":"2021-08-19T16:35:56.707269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train\n#y_tr\n#train.shape\n#args\n#data=train.iloc[:,args]\ndata.shape,data.columns\n#cors=np.array(data.corrwith(np.log1p(y_train.astype(float))))cors\n#cors=np.array(data.corrwith(np.log1p(y_train.astype(float))))\n#cors","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:36:08.10046Z","iopub.execute_input":"2021-08-19T16:36:08.100856Z","iopub.status.idle":"2021-08-19T16:36:08.107102Z","shell.execute_reply.started":"2021-08-19T16:36:08.100821Z","shell.execute_reply":"2021-08-19T16:36:08.106202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Apart from correlation plot lets print the correlation of these importance features with target variable \n\nargs\ndata=train.iloc[:,args].astype(float)\ndata.columns\n\ncors=np.array(data.corrwith(np.log1p(y_train.astype(float))))\n#cors=np.array(data.corrwith(y_train))\ncols=data.columns\nprint(\"Correlation coeff with target variable:\\n\",dict(zip(cols,cors)))\ncols=data.columns\nplt.figure(figsize=(40,15))\nplt.bar(x=cols,height=cors,width=0.5,color='r')\nfor i in range(20):\n  plt.annotate(\"{}\".format(np.round(cors[i],4)),xy=(i,np.round(cors[i],4)),size = 20)\nplt.xlabel(\"Features\")\nplt.ylabel(\"Correlation coeff\")\nplt.title(\"Featues vs Correlation plot\")\nplt.show()  \n\n# Out of 15 ,three shows high positive correlation with the target variable []\n","metadata":{"id":"_-XAkKabPN4Z","executionInfo":{"status":"ok","timestamp":1629179629156,"user_tz":-330,"elapsed":1868,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"a442794b-f953-4596-cd1c-2cd3c08154fb","execution":{"iopub.status.busy":"2021-08-19T16:36:20.413622Z","iopub.execute_input":"2021-08-19T16:36:20.414033Z","iopub.status.idle":"2021-08-19T16:36:20.989596Z","shell.execute_reply.started":"2021-08-19T16:36:20.413997Z","shell.execute_reply":"2021-08-19T16:36:20.988711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns\nplt.figure(figsize=(17,12))\nfor i,col in enumerate(data.columns):\n  plt.subplot(5,4,i+1)\n  sns.scatterplot(x=np.arange(len(data[col])),y=data[col])\n  plt.tight_layout()\nplt.show()\n#most of features are less than 1*1e6 and outlier are there but threse number is less in most of the features and rest of the \n#features there is some uniformity .from this observation we can conclude that seriously need feature scaling ","metadata":{"id":"uTAOKmSPSlq7","executionInfo":{"status":"ok","timestamp":1629179655973,"user_tz":-330,"elapsed":8069,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"37adf237-00a9-4d25-e920-44a4052272a5","execution":{"iopub.status.busy":"2021-08-19T16:36:46.732207Z","iopub.execute_input":"2021-08-19T16:36:46.73271Z","iopub.status.idle":"2021-08-19T16:36:52.824354Z","shell.execute_reply.started":"2021-08-19T16:36:46.732678Z","shell.execute_reply":"2021-08-19T16:36:52.82354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.pairplot(data.iloc[:,:10])\nplt.show()\n#","metadata":{"id":"HW0-SoUTpkTA","outputId":"b198c7bf-9aba-4cb9-e331-bc7dd5f597f5","execution":{"iopub.status.busy":"2021-08-19T16:36:59.26887Z","iopub.execute_input":"2021-08-19T16:36:59.269393Z","iopub.status.idle":"2021-08-19T16:37:21.062858Z","shell.execute_reply.started":"2021-08-19T16:36:59.269359Z","shell.execute_reply":"2021-08-19T16:37:21.061576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import libraries for autoencoders \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Dropout, BatchNormalization\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom imblearn.over_sampling import RandomOverSampler\n\nimport os\nimport gc \n#print(os.listdir(\"../input\"))","metadata":{"id":"TUFKeBB62pWu","executionInfo":{"status":"ok","timestamp":1629179667280,"user_tz":-330,"elapsed":2541,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"3965f5e3-eca6-46b3-d290-598b2de8dc1f","execution":{"iopub.status.busy":"2021-08-19T16:37:21.205854Z","iopub.execute_input":"2021-08-19T16:37:21.206397Z","iopub.status.idle":"2021-08-19T16:37:28.600594Z","shell.execute_reply.started":"2021-08-19T16:37:21.206364Z","shell.execute_reply":"2021-08-19T16:37:28.599385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train\",train.shape)\ntrain.head(2)","metadata":{"id":"jq3VymP-gP9a","executionInfo":{"status":"ok","timestamp":1629179669874,"user_tz":-330,"elapsed":406,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"036033c7-edf2-4e64-af59-0792471289f1","execution":{"iopub.status.busy":"2021-08-19T16:37:28.60218Z","iopub.execute_input":"2021-08-19T16:37:28.602507Z","iopub.status.idle":"2021-08-19T16:37:28.633942Z","shell.execute_reply.started":"2021-08-19T16:37:28.602473Z","shell.execute_reply":"2021-08-19T16:37:28.632831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\"train_scaled\",train_scaled.shape)","metadata":{"id":"3Ex8u4lmpzwa","executionInfo":{"status":"ok","timestamp":1629179697544,"user_tz":-330,"elapsed":406,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"aab43252-af31-4642-8112-433db9d743aa","execution":{"iopub.status.busy":"2021-08-19T16:37:30.015986Z","iopub.execute_input":"2021-08-19T16:37:30.016337Z","iopub.status.idle":"2021-08-19T16:37:30.021995Z","shell.execute_reply.started":"2021-08-19T16:37:30.016306Z","shell.execute_reply":"2021-08-19T16:37:30.021123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-19T16:39:37.485326Z","iopub.execute_input":"2021-08-19T16:39:37.485713Z","iopub.status.idle":"2021-08-19T16:39:37.492528Z","shell.execute_reply.started":"2021-08-19T16:39:37.485681Z","shell.execute_reply":"2021-08-19T16:39:37.491307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lests use Autoencoders to reduce Dimensions and select important features\npath_train = \"./santander/engineered_features_train_third_attempt\"\npath_test  = \"./santander/engineered_features_test_third_attempt\"\n#path = \"/content/drive/MyDrive/APPLIED AI ASSIGNMENTS ipynb/CASE STUDY 1/Encoder_second_attempt\"\n\nif not os.path.isfile(path_test):\n  n_epochs=30\n  input_data = Input(shape=(4730,))\n  encoded = Dense(2048, activation='relu',name='encoded_layer1')(input_data)\n  encoded= Dense(1024, activation='relu',name='encoded_layer2')(encoded)\n  #encoded = BatchNormalization()(encoded)\n\n  encoded= Dense(512, activation='relu',name='encoded_layer3')(encoded)\n  encoded= Dense(256, activation='relu',name='encoded_layer4')(encoded)\n  #encoded = BatchNormalization()(encoded)\n\n  encoded= Dense(128, activation='relu',name='encoded_layer5')(encoded)\n  encoded = BatchNormalization()(encoded)\n\n\n  decoded = Dense(128, activation='relu',name=\"decoder1\")(encoded)\n  decoded = Dense(256, activation='relu',name='decoder2')(decoded)\n  #decoded = BatchNormalization()(decoded)\n\n  decoded = Dense(512, activation='relu')(encoded)\n  #decoded = BatchNormalization()(decoded)\n\n  decoded = Dense(1024, activation='relu')(encoded)\n  #decoded = BatchNormalization()(decoded)\n\n  decoded = Dense(2048, activation='relu')(encoded)\n  #decoded = BatchNormalization()(decoded)\n\n  decoded = Dense(4730, activation='relu')(decoded)\n  #decoded = BatchNormalization()(decoded)\n\n  autoencoder = Model(input_data, decoded)\n  autoencoder.compile(optimizer='adagrad', loss=[\"mean_squared_error\"]) #,\"mean_squared_error\"]) #loss='mean_squared_error')\n\n# Encoding Train Data\n  autoencoder.fit(x_train, x_train, epochs = n_epochs, batch_size = 45, shuffle = True, validation_data= (x_test,x_test)) #,validation_split=0.20)\n  #autoencoder.fit(np.array(train.iloc[:,2:]),np.array(train.iloc[:,2:]), epochs = 15, batch_size = 30, shuffle = False, validation_split=0.2) #,validation_split=0.20)\n  encoder = Model(inputs = input_data, outputs = encoded)\n\n  #pickle.dump(encoder, open(path, 'wb'))\n  encoded_train = pd.DataFrame(encoder.predict(x_train))\n  encoded_train = encoded_train.add_prefix('feature_')\n\n  encoded_test = pd.DataFrame(encoder.predict(x_test))\n  encoded_test = encoded_test.add_prefix('feature_')\n\n  pickle.dump(encoded_train, open(path_train, 'wb'))\n  pickle.dump(encoded_test, open(path_test, 'wb'))\nelse:\n  encoded_train = pickle.load(open(path_train,'rb'))\n  encoded_test = pickle.load(open(path_test,'rb'))\n\n#print(\"encoded_test\",encoded_test.shape)\nprint(\"encoded_train\",encoded_train.shape)  ","metadata":{"id":"eZ6muuz2cpAX","executionInfo":{"status":"ok","timestamp":1629181180642,"user_tz":-330,"elapsed":495,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"b622c0df-e3b0-47ba-97be-d8ffe73e8a3d","execution":{"iopub.status.busy":"2021-08-19T16:39:58.640511Z","iopub.execute_input":"2021-08-19T16:39:58.640966Z","iopub.status.idle":"2021-08-19T16:44:45.265916Z","shell.execute_reply.started":"2021-08-19T16:39:58.640929Z","shell.execute_reply":"2021-08-19T16:44:45.26489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CONCLUSION\n\n#since we have done detailed analysis of high dimensional data\n#1.data is highly sparse as it has only 3.23% non zero rest close to 97% data is zero.\n#2.data feature has lot of scale imbalace which we fixed later by feature scaling\n#3.of the 4993 features 256 were constant feature and 6 duplicate features i.e from PCA(pricipal component analysis) perspective they will capture zero varience hence its better \n#to impute them\n#4.data set has no NA values\n#On applying dimensionality reduction using encoder part of autoencoder sparcity of data is reduced and dimensions are also came down to 129 still after using autoencoders\n# interpretability is a issue as in PCA we were able to capture 99.6% of variance in 2000 features out of aprox 4700 features but here reconstruction error is the only measure we \n# can look at and in our case reconstrucion error was coming consistenly constant during the last phase of training which shows consistent improvement.\n#6.y_train the target variable is right skewed so to make it close to normal we did log transformation.\n","metadata":{"id":"FmX41yPsJtGU","executionInfo":{"status":"ok","timestamp":1629179711825,"user_tz":-330,"elapsed":5,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"-hDXJyVMpCzk","executionInfo":{"status":"ok","timestamp":1629179714598,"user_tz":-330,"elapsed":403,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODELLING AND 'HYPERPARAMETER TUNING'\n","metadata":{"id":"NNzuF9dtpDPV"}},{"cell_type":"code","source":"\ntop_20","metadata":{"id":"dMBoKcMLy_DB","executionInfo":{"status":"ok","timestamp":1629179718530,"user_tz":-330,"elapsed":420,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"136fa4f5-09f0-401d-eda3-42850455d336","execution":{"iopub.status.busy":"2021-08-19T16:47:33.871901Z","iopub.execute_input":"2021-08-19T16:47:33.872289Z","iopub.status.idle":"2021-08-19T16:47:33.879511Z","shell.execute_reply.started":"2021-08-19T16:47:33.872255Z","shell.execute_reply":"2021-08-19T16:47:33.878287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[top_20]","metadata":{"id":"LNx6aDW5pXYS","executionInfo":{"status":"ok","timestamp":1629180087311,"user_tz":-330,"elapsed":429,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"81e70cb8-8e28-4c52-b796-ea970360aa91","execution":{"iopub.status.busy":"2021-08-19T16:47:35.261589Z","iopub.execute_input":"2021-08-19T16:47:35.26199Z","iopub.status.idle":"2021-08-19T16:47:35.293946Z","shell.execute_reply.started":"2021-08-19T16:47:35.261954Z","shell.execute_reply":"2021-08-19T16:47:35.293021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Concatenating top 20 and encoded_test\ncols_test=pd.DataFrame(x_test,columns=train.iloc[:,2:].columns).loc[:,top_20]\nData_imp_test = pd.concat([encoded_test,cols_test],axis=1)\ntest_columns=Data_imp_test.columns\nprint(\"test\",Data_imp_test.shape)\n\ncols_train=pd.DataFrame(x_train,columns=train.iloc[:,2:].columns).loc[:,top_20]\nData_imp_train=pd.concat([encoded_train,cols_train],axis=1)\ntrain_columns= Data_imp_train.columns\nprint(\"train\",Data_imp_train.shape)\nData_imp_train.head(2)\n\n\n#from sklearn.preprocessing import minmax_scale\nData_imp_train = minmax_scale(Data_imp_train, axis = 0)\nData_imp_test = minmax_scale(Data_imp_test, axis = 0)\n\n\nData_imp_train = pd.DataFrame(Data_imp_train,columns=train_columns)\nData_imp_test = pd.DataFrame(Data_imp_test,columns=test_columns)\nprint(\"Data_imp_train\",Data_imp_train.shape)\nprint(\"Data_imp_test\",Data_imp_test.shape)\n\n#print(Data_imp_train.head())\n#print(Data_imp_test.head())","metadata":{"id":"kHxfrxVVWATh","executionInfo":{"status":"ok","timestamp":1629181257371,"user_tz":-330,"elapsed":404,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"3c614182-010e-4f16-800d-662d1ca02da1","execution":{"iopub.status.busy":"2021-08-19T16:47:36.787943Z","iopub.execute_input":"2021-08-19T16:47:36.788303Z","iopub.status.idle":"2021-08-19T16:47:36.822207Z","shell.execute_reply.started":"2021-08-19T16:47:36.788273Z","shell.execute_reply":"2021-08-19T16:47:36.821189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import and train lightGBM model\n\n#import lightgbm as lgb\n#from sklearn.metrics import mean_squared_log_error\n#gbm = lgb.LGBMRegressor()\n\n#model=gbm.fit(Data_imp_train,y_tr.astype(float))\n#model.best_iteration\n#y_pred_train=model.predict(Data_imp_train)\n#print(y_pred_train)\n#rmsle_train = np.sqrt(mean_squared_log_error(y_tr,np.clip(y_pred_train,a_min=0,a_max=None)))\n#print(\"Rmsle on train data\",rmsle_train)\n\n#y_pred_test = model.predict(Data_imp_test)\n#print(\"\\ny_pred_test\",y_pred_test)\n#rmsle_test=np.sqrt(mean_squared_log_error(y_ts,np.clip(y_pred_test,a_min=0,a_max=None)))\n#print(\"\\ny_test\",sample_submission.target.values)\n#print(\"\\nRmsle on test data\",rmsle_test)\n\n#from sklearn.metrics import r2_score\n#print(\"\\nR_square_train\",r2_score(y_tr, y_pred_train))\n#print(\"\\nR_squared_test\",r2_score(y_ts,y_pred_test))\n#print(\"###\"*10)\n\n\n#residual_train = (y_tr - y_pred_train)\n#residual_test = (y_ts - y_pred_test)\n\n#f, (ax3, ax4) = plt.subplots(1, 2,figsize=(15,7))\n#ax3.scatter(pred_train, residual_train)\n#ax3.set_title('Sharing Y axis')\n#ax4.scatter(pred_test,residual_test )\n#ax4.set_title('Sharing Y axis')\n\n###################################################################\n###################################################################\n\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_log_error\ngbm = lgb.LGBMRegressor()\n\nmodel=gbm.fit(Data_imp_train,np.log1p(y_tr.astype(float)))\ny_pred_train=model.predict(Data_imp_train)\nprint(np.expm1(y_pred_train))\nrmsle_train = np.sqrt(mean_squared_log_error(y_tr,np.expm1(y_pred_train)))\nprint(\"Rmsle on train data\",rmsle_train)\n\ny_pred_test = model.predict(Data_imp_test)\nprint(\"\\ny_pred_test\",np.expm1(y_pred_test))\nrmsle_test=np.sqrt(mean_squared_log_error(y_ts,np.expm1(y_pred_test)))\nprint(\"\\nRmsle on test data\",rmsle_test)\n\nfrom sklearn.metrics import r2_score\nprint(\"\\nR_square_train\",r2_score(y_tr, np.expm1(y_pred_train) ))\nprint(\"\\nR_squared_test\",r2_score(y_ts,np.expm1(y_pred_test)))\n\nresidual_train = (y_tr - np.exp(y_pred_train))\nresidual_test = (y_ts - np.exp(y_pred_test))\n\nf, (ax3, ax4) = plt.subplots(1, 2,figsize=(15,7))\nax3.scatter(pred_train, residual_train)\nax3.set_title('train vs residual plot')\nax4.scatter(pred_test,residual_test )\nax4.set_title('Test vs residual plot')\n\n#Baseline Rmsle score train : 0.07089089515547918 and test : 0.07135105539024963","metadata":{"id":"ytf9vlQtybF9","executionInfo":{"status":"ok","timestamp":1629180474059,"user_tz":-330,"elapsed":5900,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"9684577d-c658-4962-d296-4cb7f41a7111","execution":{"iopub.status.busy":"2021-08-19T16:52:42.162353Z","iopub.execute_input":"2021-08-19T16:52:42.162781Z","iopub.status.idle":"2021-08-19T16:52:43.259321Z","shell.execute_reply.started":"2021-08-19T16:52:42.162741Z","shell.execute_reply":"2021-08-19T16:52:43.258474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\ndef light_gbm_model_run(train_x, train_y, validation_x, validation_y, test_x,**kwargs):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        'n_estimator':67,\n        \"num_leaves\" : 45,\n       \"learning_rate\" :0.01,\n        \"max_depth\":5,\n       # \"bagging_fraction\" : 0.5,\n       # \"feature_fraction\" : 0.5,\n       # \"bagging_frequency\" : 6,\n        \"reg_alpha\":5,\n        \"reg_lambda\":64,\n        #\"bagging_seed\" : 42,\n        \"verbosity\" : -1,\n        \"seed\": 42\n    }\n    # Given its a regression case, I am using the RMSE as the metric.\n\n    gbm_train = lgb.Dataset(Data_imp_train, label=np.log1p(y_tr.astype(float)))\n    gbm_val = lgb.Dataset(Data_imp_test, label=np.log1p(y_ts.astype(float)))\n    val_result_lgbm = {}\n\n    model_light_gbm = lgb.train(params,gbm_train,5000,\n                      valid_sets=[gbm_train, gbm_val],**kwargs,\n                      early_stopping_rounds=100,\n                      verbose_eval=20,\n                      evals_result=val_result_lgbm)\n\n    pred_test_light_gbm = np.expm1(model_light_gbm.predict(test_x, num_iteration=model_light_gbm.best_iteration ))\n\n    return pred_test_light_gbm, model_light_gbm, val_result_lgbm,model_light_gbm.best_iteration\n\nn_splits=3\nkf = KFold(n_splits=3, shuffle=True, random_state=45)\npred_test_full = 0\nfor dev_index, val_index in kf.split(Data_imp_train):\n    dev_X, val_X = Data_imp_train.loc[dev_index,:], Data_imp_train.loc[val_index,:]\n    dev_y, val_y = np.log(y_train[dev_index].astype(float)), np.log(y_train[val_index].astype(float))\n    pred_test, model, evals_result,best_iter = light_gbm_model_run(dev_X, dev_y.astype(float), val_X, val_y.astype(float), Data_imp_test)\n    print(\"pred_test\",len(pred_test))\n    print(\"\\nbest parameters after training\",best_iter)\n    pred_test_full += pred_test\npred_test_full /= n_splits\npred_test_full = np.exp(pred_test_full,dtype=np.float128)\n\nfrom sklearn.metrics import r2_score\nprint(\"\\nR_square_train\",r2_score(y_tr, np.exp(y_pred_train.astype(float))))\n#print(\"\\nR_squared_test\",r2_score(np.log1p(sample_submission.target.values),np.expm1(y_pred_test)))\n\nplt.figure(figsize=(8,8))\nplt.grid()\nplt.plot(evals_result['training']['rmse'],label='training')\nplt.plot(evals_result['valid_1']['rmse'],label='test')\nplt.xlabel(\"iterations\")\nplt.ylabel(\"error\")\nplt.legend()\nplt.show()\n\n#validation errors are reducing initially but after crossing 65 - 70 estimators it started overfitting \n# validation  loss has range (1.74,1.59)","metadata":{"id":"tcY2Psd3mrOn","executionInfo":{"status":"ok","timestamp":1629180502187,"user_tz":-330,"elapsed":2345,"user":{"displayName":"Aditya Verma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOGTA563GQR2_tXeSel3x_dRXqLgHMGN_2CcOaLA=s64","userId":"09522989787960602189"}},"outputId":"6b2f6e16-3199-461d-804f-57570446137c","execution":{"iopub.status.busy":"2021-08-19T16:53:03.61706Z","iopub.execute_input":"2021-08-19T16:53:03.61758Z","iopub.status.idle":"2021-08-19T16:53:16.378834Z","shell.execute_reply.started":"2021-08-19T16:53:03.617541Z","shell.execute_reply":"2021-08-19T16:53:16.377785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"3GkLA0D9ySRj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **XGboost model training**","metadata":{"id":"SfbE31G8p5y0"}}]}