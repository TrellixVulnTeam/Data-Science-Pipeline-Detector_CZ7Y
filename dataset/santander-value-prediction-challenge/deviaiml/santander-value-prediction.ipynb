{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filepath=\"/kaggle/input/santander-value-prediction-challenge/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\n\nfrom IPython.display import display\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf = pd.read_csv(filepath+\"train.csv\")\ntestdf = pd.read_csv(filepath+\"test.csv\")\nprint(traindf.head())\nprint(\"-------------------------\")\nprint(testdf.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for Missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.columns[traindf.isnull().sum() != 0].size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdf.columns[testdf.isnull().sum() != 0].size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check and remove constant features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"colstoremove=[]\nfor col in traindf.columns:\n    if col != 'ID' and col != 'target' :\n        if traindf[col].std() == 0:\n            colstoremove.append(col)\n\ntraindf.drop(colstoremove, axis=1, inplace=True)\ntestdf.drop(colstoremove, axis=1, inplace=True)\n\nprint(\"Total constant columns removed : \", len(colstoremove))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove duplicate features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef duplicate_columns(df):\n    groups = df.columns.to_series().groupby(df.dtypes).groups\n    dups=[]\n    \n    i=1\n    for t,v in groups.items():\n        print(\"i=\",i, \"----->\")\n        cs = df[v].columns\n        vs = df[v]\n        lcs = len(cs)\n        #print(vs)\n        i += 1\n        print(\"lcs=\",lcs)    \n        for i in range(lcs):\n            ia = vs.iloc[:,i].values\n            for j in range(i+1, lcs):\n                ja = vs.iloc[:,j].values\n                if np.array_equal(ia, ja):\n                    dups.append(cs[i])\n                    break\n    return dups\n\ndupcols = duplicate_columns(traindf)\nprint(dupcols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.drop(dupcols, axis=1, inplace=True)\ntestdf.drop(dupcols, axis=1, inplace=True)\nprint(\"Removed duplicated columns: \",dupcols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop Sparse Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_sparse(train, test):\n    flist = [x for x in train.columns if not x in ['ID', 'target']]\n    for f in flist:\n        if len(np.unique(train[f]))<2:\n            train.drop(f, axis=1, inplace=True)\n            test.drop(f, axis=1, inplace=True)\n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntraindf , testdf = drop_sparse(traindf, testdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\n\nprint(traindf.shape)\nprint(testdf.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Train and Test data for Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain = traindf.drop(['ID', 'target'] ,  axis=1)\nytrain = np.log1p(traindf['target'].values)\n\nxtest = testdf.drop(['ID'], axis=1)\n\nprint(xtrain.shape, ytrain.shape)\nprint(xtest.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##  split train data into train and validation\n\nxtrain, xval, ytrain, yval = model_selection.train_test_split(xtrain, ytrain, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(xtrain.shape, ytrain.shape)\nprint(xval.shape, yval.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_lgb(xtrain, ytrain, xval, yval, xtest):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        \"num_leaves\" : 40,\n        \"learning_rate\" : 0.004,\n        \"bagging_fraction\" : 0.6,\n        \"feature_fraction\" : 0.6,\n        \"bagging_frequency\" : 6,\n        \"bagging_seed\" : 42,\n        \"verbosity\" : -1,\n        \"seed\" : 42\n    }\n    \n    lgtrain = lgb.Dataset(xtrain, label=ytrain)\n    lgval = lgb.Dataset(xval, label=yval)\n    evals_result={}\n    model = lgb.train(params, lgtrain, 5000, valid_sets = [lgtrain, lgval], early_stopping_rounds=100, \n                     verbose_eval=150, evals_result=evals_result)\n    \n    pred_test_y = np.expm1(model.predict(xtest, num_iteration=model.best_iteration))\n    \n    return pred_test_y, model, evals_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_y , model, evals_result = run_lgb(xtrain, ytrain, xval, yval, xtest)\n\nprint(\"LightGBM model training completed..\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## feature importance\n\nprint(\"Feature Importance : \")\ngain = model.feature_importance('gain')\nprint(\"gain : \", gain)\nfeatureimp = pd.DataFrame({'feature': model.feature_name(), 'split':model.feature_importance('split'), \n                          'gain': 100*gain/gain.sum()}).sort_values(by='gain', ascending=False)\nprint(featureimp[:50])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_xgb(xtrain, ytrain, xval, yval, xtest):\n    params={\n        \"objective\" : \"reg:linear\",\n        \"eval_metric\" : \"rmse\" ,\n        \"eta\" : 0.001,\n        \"max_depth\" : 10,\n        \"subsample\" : 0.6,\n        \"colsample_bytree\" : 0.6,\n        \"alpha\" : 0.001,\n        \"random_state\" : 42,\n        \"silent\" : True\n    }\n    \n    trdata = xgb.DMatrix(xtrain, ytrain)\n    valdata = xgb.DMatrix(xval, yval)\n    \n    watchlist = [(trdata, 'train'), (valdata, 'valid')]\n    \n    model_xgb = xgb.train(params, trdata, 2000, watchlist, maximize=False, early_stopping_rounds=100, \n                         verbose_eval=100)\n    \n    dtest = xgb.DMatrix(xtest)\n    \n    xgb_pred_y = np.expm1(model_xgb.predict(dtest, ntree_limit=model_xgb.best_ntree_limit))\n    \n    return xgb_pred_y, model_xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_pred_y, model_xgb = run_xgb(xtrain, ytrain, xval, yval, xtest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Catboost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cb_model = CatBoostRegressor(iterations = 500,\n                            learning_rate=0.05,\n                            depth=10,\n                            eval_metric='RMSE',\n                            random_seed=42,\n                            bagging_temperature=0.2,\n                            od_type='Iter',\n                            metric_period=50,\n                            od_wait=20\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cb_model.fit(xtrain, ytrain, eval_set=(xval, yval), use_best_model=True, verbose=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_cat = np.expm1(cb_model.predict(xtest))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combine Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_lgb=pd.DataFrame()\nsub_lgb['target']=pred_test_y\n\nsub_xgb=pd.DataFrame()\nsub_xgb['target']=xgb_pred_y\n\nsub_cat = pd.DataFrame()\nsub_cat['target'] = pred_test_cat\n\nsub = pd.read_csv(filepath+'sample_submission.csv')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['target']=sub_lgb['target']*0.5 + sub_xgb['target']*0.3 + sub_cat['target']*0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('/submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}