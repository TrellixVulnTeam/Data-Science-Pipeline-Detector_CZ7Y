{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\ndata = pd.read_csv('/kaggle/input/unimelb/unimelb_training.csv')\n# data = pd.read_csv('/kaggle/input/unimelb/unimelb_test.csv')\n\n# print(data['Role.1'].unique())\n# data.drop(data[\n# (data['RFCDSum'] == 0) &\n# (data['SEOSum'] == 0) &\n# (data['Grant.Status'] == 1)].index)\npercent_missing = data.isnull().sum() * 100 / len(data)\nmissing_value_df = pd.DataFrame({'column_name': data.columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df.sort_values('percent_missing', inplace=True)\nprint(missing_value_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sponsorColunmName = 'Sponsor.Code'\n\n# pt = pd.crosstab([data[sponsorColunmName]], data['Grant.Status'])\n# print(pt)\n# pt.plot(kind='bar', stacked=True)\n\ndata[sponsorColunmName] = data[sponsorColunmName].fillna('0')\n# print(data[sponsorColunmName].isna().sum())\n# data['SponsorSuccessGrants'] = data[sponsorColunmName].map(data.where(lambda row: row['Grant.Status'] == 1).groupby(sponsorColunmName).size() / data.groupby(sponsorColunmName).size())\ndata['SponsorSuccessGrants'] = data[sponsorColunmName].map(data.where(lambda row:\n    row['Grant.Status'] == 1\n).groupby(sponsorColunmName).size())\n\n# print(data[sponsorColunmName])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Grant.Category.Code'] = data['Grant.Category.Code'].fillna('0')\ndata['SuccessfullCategoryGrant'] = data['Grant.Category.Code'].map(data.where(lambda row: row['Grant.Status'] == 1).groupby('Grant.Category.Code').size() / data.groupby('Grant.Category.Code').size())\n# data['SuccessfullCategoryGrant'] = data['Grant.Category.Code'].map(data.where(lambda row: row['Grant.Status'] == 1).groupby('Grant.Category.Code').size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#process grant cost\n# del data['Contract.Value.Band...see.note.A']\ndata.loc[\ndata['Contract.Value.Band...see.note.A'].isnull(),\n    'Contract.Value.Band...see.note.A'] = 'A'\ndata['GrantValueCategory'] = data['Contract.Value.Band...see.note.A'].apply(\n        lambda x: ord(x[0]) - ord('A') + 1\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['StartYear'] = pd.to_datetime(data['Start.date'],\n    infer_datetime_format = True).map(\n        lambda date: date.year\n    )\n\n\n\nfor i in range(1, 16):\n    birthColName = f\"Year.of.Birth.{i}\"\n    data[f\"Age.{i}\"] = data.apply(\n        lambda row: row['StartYear'] - (row['StartYear'] if np.isnan(row[birthColName]) else row[birthColName])\n        , axis = 1\n    )\ndata['GroupAge'] = data.apply(\n    lambda row: row['Age.1'] + row['Age.2'] + row['Age.3'] + row['Age.4'] + row['Age.5']\n              + row['Age.6'] + row['Age.7'] + row['Age.8'] + row['Age.9'] + row['Age.10']\n              + row['Age.11'] + row['Age.12'] + row['Age.13'] + row['Age.14'] + row['Age.15']\n    , axis = 1)\n# minYear = data['StartYear'].min()\n# data['StartYear'] -= minYear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1, 6):\n    rfcdCodeColName = f\"RFCD.Code.{i}\"\n    rfcdPercColName = f\"RFCD.Percentage.{i}\"\n    data[rfcdCodeColName] = data[rfcdCodeColName].fillna(0)\n    \n    seoCodeColName = f\"SEO.Code.{i}\"\n    seoPercColName = f\"SEO.Percentage.{i}\"\n    data[seoCodeColName] = data[seoCodeColName].fillna(0)\n\nrfcdGrants = {}\nrfcdSuccessfullGrants = {}\nseoGrants = {}\nseoSuccessfullGrants = {}\n\ndef codes_sums(row):\n    rfcdCodes = []\n    seoCodes = []\n    for i in range(1, 6):\n        rfcdCodeColName = f\"RFCD.Code.{i}\"\n        rfcdCode = row[rfcdCodeColName]\n        if (not np.isnan(rfcdCode)):\n            rfcdCodes.append(rfcdCode)\n        \n        seoCodeColName = f\"SEO.Code.{i}\"\n        seoCode = row[seoCodeColName]\n        if (not np.isnan(seoCode)):\n            seoCodes.append(seoCode)\n\n    if (row['Grant.Status'] == 1):\n        for code in rfcdCodes:\n            if (rfcdSuccessfullGrants.get(code) == None):\n                rfcdSuccessfullGrants[code] = 1\n            else:\n                rfcdSuccessfullGrants[code] += 1\n        for code in seoCodes:\n            if (seoSuccessfullGrants.get(code) == None):\n                seoSuccessfullGrants[code] = 1\n            else:\n                seoSuccessfullGrants[code] += 1\n                \n    for code in rfcdCodes:\n        if (rfcdGrants.get(code) == None):\n            rfcdGrants[code] = 1\n        else:\n            rfcdGrants[code] += 1\n    for code in seoCodes:\n        if (seoGrants.get(code) == None):\n            seoGrants[code] = 1\n        else:\n            seoGrants[code] += 1\n\nprint('summing...')\n\ndata.apply(codes_sums, axis=1)\n    \nprint('mapping...')\n\nfor i in range(1, 6):\n    rfcdCodeColName = f\"RFCD.Code.{i}\"\n    rfcdPercColName = f\"RFCD.Percentage.{i}\"\n    seoCodeColName = f\"SEO.Code.{i}\"\n    seoPercColName = f\"SEO.Percentage.{i}\"\n    data[f\"RFCDSuccessGrants.{i}\"] = data.apply(lambda row:\n                                                0 if row[rfcdCodeColName] == 0\n                                                else (rfcdSuccessfullGrants.get(row[rfcdCodeColName], 0) / rfcdGrants[row[rfcdCodeColName]]) *  (row[rfcdPercColName] / 100)\n                                    , axis = 1)\n#     data[f\"SEOSuccessGrants.{i}\"] = data[seoCodeColName].map(lambda x: 0 if x == 0 else seoSuccessfullGrants.get(x, 0) / seoGrants[x])\n    data[f\"SEOSuccessGrants.{i}\"] = data.apply(lambda row:\n                                                0 if row[seoCodeColName] == 0\n                                                else (seoSuccessfullGrants.get(row[seoCodeColName], 0) / seoGrants[row[seoCodeColName]]) *  (row[seoPercColName] / 100)\n                                    , axis = 1)\n#     data[rfcdCodeColName] = data[rfcdCodeColName].map(data.where(lambda row: row['Grant.Status'] == 1).groupby(rfcdCodeColName).size() / data.groupby(rfcdCodeColName).size())\n#     data[f\"RFCDSuccessGrants.{i}\"] = data[rfcdCodeColName].map(data.where(lambda row: row['Grant.Status'] == 1).groupby(rfcdCodeColName).size())\n#     data[rfcdCodeColName] = data[rfcdCodeColName].map(lambda x: 0 if np.isnan(x) else x)\n#     data.loc[data[rfcdCodeColName].isnull(), rfcdCodeColName] = 0\n#     data.loc[data[rfcdCodeColName] != 0, rfcdCodeColName] = 1\n    \n#     data[seoCodeColName] = data[seoCodeColName].map(lambda x: 0 if np.isnan(x) else 1)\n    \n#     data[seoCodeColName] = data[seoCodeColName].map(data.where(lambda row: row['Grant.Status'] == 1).groupby(seoCodeColName).size() / data.groupby(seoCodeColName).size())\n#     data[f\"SEOSuccessGrants.{i}\"] = data[seoCodeColName].map(data.where(lambda row: row['Grant.Status'] == 1).groupby(seoCodeColName).size())\n#     data.loc[data[seoCodeColName].isnull(), seoCodeColName] = 0\n#     data.loc[data[seoCodeColName] != 0, seoCodeColName] = 1\n\ndata['RFCDSum'] = data.apply(\n    lambda row: row['RFCDSuccessGrants.1'] + row['RFCDSuccessGrants.2'] + row['RFCDSuccessGrants.3'] + row['RFCDSuccessGrants.4'] + row['RFCDSuccessGrants.5']\n    , axis = 1)\ndata['SEOSum'] = data.apply(\n    lambda row: row['SEOSuccessGrants.1'] + row['SEOSuccessGrants.2'] + row['SEOSuccessGrants.3'] + row['SEOSuccessGrants.4'] + row['SEOSuccessGrants.5']\n    , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1, 16):\n    phdColName = f\"With.PHD.{i}\"\n    data[phdColName] = data[phdColName].map(lambda isPhd: 1 if isPhd == 'Yes ' else 0)\n    \n    pIdColName = f\"Person.ID.{i}\"\n    data[pIdColName] = data[pIdColName].map(lambda pid: 0 if math.isnan(pid) else 1)\n\n    yearsInUnivColName = f\"No..of.Years.in.Uni.at.Time.of.Grant.{i}\"\n    data[yearsInUnivColName] = data[yearsInUnivColName].map(lambda x: (4 if x == 'more than 15' else (3 if x == '>10 to 15' else (2 if x == '>5 to 10' else (1 if x == '>=0 to 5' else 0)))))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"successfullFacs = {}\nallFacs = {}\nsuccessfullDeps = {}\nallDeps = {}\n\ndef univ_codes_sums(row):\n    facsCodes = []\n    deptsCodes = []\n#     if (row['Grant.Application.ID'] % 100 == 0):\n#         print(row['Grant.Application.ID'])\n    for i in range(1, 4):\n        facColName = f\"Faculty.No..{i}\"\n        facCode = row[facColName]\n        if (allFacs.get(facCode) == None):\n            allFacs[facCode] = 1\n        else:\n            allFacs[facCode] += 1\n        facsCodes.append(facCode)\n        \n        deptNoColName = f\"Dept.No..{i}\"\n        deptCode = row[deptNoColName]\n        newDepCode = facCode*deptCode\n        if (allDeps.get(newDepCode) == None):\n            allDeps[newDepCode] = 1\n        else:\n            allDeps[newDepCode] += 1\n        deptsCodes.append(newDepCode)\n        \n    if (row['Grant.Status'] == 1):\n        for facCode in facsCodes:\n            if (successfullFacs.get(facCode) == None):\n                successfullFacs[facCode] = 1\n            else:\n                successfullFacs[facCode] += 1\n        for depCode in deptsCodes:\n            if (successfullDeps.get(depCode) == None):\n                successfullDeps[depCode] = 1\n            else:\n                successfullDeps[depCode] += 1\n\nprint('summing..')\n\ndata.apply(univ_codes_sums, axis=1)\n\nprint('mapping..')\n\nfor i in range(1, 4):\n    facColName = f\"Faculty.No..{i}\"\n    deptNoColName = f\"Dept.No..{i}\"\n    \n    data[facColName] = data[facColName].fillna(0)\n    data[deptNoColName] = data[deptNoColName].fillna(0)\n    \n#     data[f\"FacSuccess.{i}\"] = data[facColName].map(lambda x: successfullFacs.get(x, 0))\n    data[f\"FacSuccess.{i}\"] = data[facColName].map(lambda x: successfullFacs.get(x, 0) / allFacs.get(x, 1))\n#     data[f\"DeptSuccess.{i}\"] = data.apply(lambda row: successfullDeps.get(row[facColName]*row[deptNoColName], 0), axis = 1)\n    data[f\"DeptSuccess.{i}\"] = data.apply(lambda row: successfullDeps.get(row[facColName]*row[deptNoColName], 0) / allDeps.get(row[facColName]*row[deptNoColName], 1), axis = 1)\n\ndata['FacultiesSuccess'] = data.apply(\n    lambda row: row['FacSuccess.1'] + row['FacSuccess.2'] + row['FacSuccess.3']\n    , axis = 1)\ndata['DeptsSuccess'] = data.apply(\n    lambda row: row['DeptSuccess.1'] + row['DeptSuccess.2'] + row['DeptSuccess.3']\n    , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Reseachers'] = data.apply(\n    lambda row: row['Person.ID.1'] + row['Person.ID.2'] + row['Person.ID.3'] + row['Person.ID.4'] + row['Person.ID.5'] + \n        row['Person.ID.6'] + row['Person.ID.7'] + row['Person.ID.8'] + row['Person.ID.9'] + row['Person.ID.10'] + \n        row['Person.ID.11'] + row['Person.ID.12'] + row['Person.ID.13'] + row['Person.ID.14'] + row['Person.ID.15']\n    , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Phds'] = data.apply(\n    lambda row: row['With.PHD.1'] + row['With.PHD.2'] + row['With.PHD.3'] + row['With.PHD.4'] + row['With.PHD.5'] + \n        row['With.PHD.6'] + row['With.PHD.7'] + row['With.PHD.8'] + row['With.PHD.9'] + row['With.PHD.10'] + \n        row['With.PHD.11'] + row['With.PHD.12'] + row['With.PHD.13'] + row['With.PHD.14'] + row['With.PHD.15']\n    , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['PhdsPart'] = data.apply(lambda row: 0 if row['Phds'] == 0 else row['Phds'] / row['Reseachers'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"YearsInUniv\"] = data.apply(\n    lambda row: row['No..of.Years.in.Uni.at.Time.of.Grant.1'] + row['No..of.Years.in.Uni.at.Time.of.Grant.2'] + row['No..of.Years.in.Uni.at.Time.of.Grant.3'] + row['No..of.Years.in.Uni.at.Time.of.Grant.4'] + row['No..of.Years.in.Uni.at.Time.of.Grant.5'] + \n        row['No..of.Years.in.Uni.at.Time.of.Grant.6'] + row['No..of.Years.in.Uni.at.Time.of.Grant.7'] + row['No..of.Years.in.Uni.at.Time.of.Grant.8'] + row['No..of.Years.in.Uni.at.Time.of.Grant.9'] + row['No..of.Years.in.Uni.at.Time.of.Grant.10'] + \n        row['No..of.Years.in.Uni.at.Time.of.Grant.11'] + row['No..of.Years.in.Uni.at.Time.of.Grant.12'] + row['No..of.Years.in.Uni.at.Time.of.Grant.13'] + row['No..of.Years.in.Uni.at.Time.of.Grant.14'] + row['No..of.Years.in.Uni.at.Time.of.Grant.15']\n    , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sum_all_articles(row):\n    res = 0\n    for i in range(1, 16):\n        res += row[f\"A..{i}\"]\n        res += row[f\"A.{i}\"]\n        res += row[f\"B.{i}\"]\n        res += row[f\"C.{i}\"]\n    return res\ndata['Articles'] = data.apply(sum_all_articles, axis = 1)\ndata['A..Sum'] = data.apply(\n    lambda row: row['A..1'] + row['A..2'] + row['A..3'] + row['A..4'] + row['A..5']\n    , axis = 1)\ndata['A.Sum'] = data.apply(\n    lambda row: row['A.1'] + row['A.2'] + row['A.3'] + row['A.4'] + row['A.5']\n    , axis = 1)\ndata['B.Sum'] = data.apply(\n    lambda row: row['B.1'] + row['B.2'] + row['B.3'] + row['B.4'] + row['B.5']\n    , axis = 1)\ndata['C.Sum'] = data.apply(\n    lambda row: row['C.1'] + row['C.2'] + row['C.3'] + row['C.4'] + row['C.5']\n    , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['SuccessfullGrants'] = data.apply(\n    lambda row: row['Number.of.Successful.Grant.1'] + row['Number.of.Successful.Grant.2'] + row['Number.of.Successful.Grant.3'] + row['Number.of.Successful.Grant.4'] + row['Number.of.Successful.Grant.5'] + \n        row['Number.of.Successful.Grant.6'] + row['Number.of.Successful.Grant.7'] + row['Number.of.Successful.Grant.8'] + row['Number.of.Successful.Grant.9'] + row['Number.of.Successful.Grant.10'] + \n        row['Number.of.Successful.Grant.11'] + row['Number.of.Successful.Grant.12'] + row['Number.of.Successful.Grant.13'] + row['Number.of.Successful.Grant.14'] + row['Number.of.Successful.Grant.15']\n    , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['UnsuccessfullGrants'] = data.apply(\n    lambda row: row['Number.of.Unsuccessful.Grant.1'] + row['Number.of.Unsuccessful.Grant.2'] + row['Number.of.Unsuccessful.Grant.3'] + row['Number.of.Unsuccessful.Grant.4'] + row['Number.of.Unsuccessful.Grant.5'] + \n        row['Number.of.Unsuccessful.Grant.6'] + row['Number.of.Unsuccessful.Grant.7'] + row['Number.of.Unsuccessful.Grant.8'] + row['Number.of.Unsuccessful.Grant.9'] + row['Number.of.Unsuccessful.Grant.10'] + \n        row['Number.of.Unsuccessful.Grant.11'] + row['Number.of.Unsuccessful.Grant.12'] + row['Number.of.Unsuccessful.Grant.13'] + row['Number.of.Unsuccessful.Grant.14'] + row['Number.of.Unsuccessful.Grant.15']\n    , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(data[(data['RFCDSum'] == 0) & (data['SEOSum'] == 0) & (data['Grant.Status'] == 1)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(data[(data['Reseachers'] == 0) & (data['Grant.Status'] == 1)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modeldata = data[[\n    'SponsorSuccessGrants'\n    , 'SuccessfullCategoryGrant'\n    , 'GrantValueCategory'\n    , 'StartYear'\n    , 'GroupAge'\n    , 'RFCDSum'\n    , 'SEOSum'\n    , 'Reseachers'\n#     , 'Phds'\n    , 'PhdsPart'\n    , 'YearsInUniv'\n    , 'FacultiesSuccess'\n    , 'DeptsSuccess'\n    , 'A..Sum'\n    , 'A.Sum'\n    , 'B.Sum'\n    , 'C.Sum'\n#     , 'Articles'\n    , 'SuccessfullGrants'\n    , 'UnsuccessfullGrants'\n]].copy()\n\n\n# for i in range(1, 6):\n#     modeldata[f\"RFCDSuccessGrants.{i}\"] = data[f\"RFCDSuccessGrants.{i}\"]\n#     modeldata[f\"SEOSuccessGrants.{i}\"] = data[f\"SEOSuccessGrants.{i}\"]\n\n# for i in range(1, 16):\n#     modeldata[f\"Age.{i}\"] = data[f\"Age.{i}\"]\n#     modeldata[f\"With.PHD.{i}\"] = data[f\"With.PHD.{i}\"]\n#     modeldata[f\"Person.ID.{i}\"] = data[f\"Person.ID.{i}\"]\n#     modeldata[f\"No..of.Years.in.Uni.at.Time.of.Grant.{i}\"] = data[f\"No..of.Years.in.Uni.at.Time.of.Grant.{i}\"]\n\ny = data['Grant.Status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(modeldata.shape)\nprint(modeldata)\n# print(normilized_data)\n# print(scaled_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n# normilized_data = preprocessing.normalize(modeldata.loc[:,:])\nscaled_data = preprocessing.scale(modeldata.loc[:,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_iris\n\nmodel = GradientBoostingClassifier()\nrandom_forest_params  = {\n    'bootstrap': [False],\n    'max_depth': [70],\n    'max_features': ['auto'],\n    'min_samples_leaf': [1],\n    'min_samples_split': [10],\n    'n_estimators': [600, 650, 700]\n}\n\ngradient_boost_parameters = {\n    'n_estimators':[200, 300, 400],\n    'max_depth':[10],\n    'learning_rate':[0.1],\n    'loss' : ['linear', 'square', 'exponential']\n}\n\nmodel_params = gradient_boost_parameters\n\nclassifiers = {\n    DecisionTreeClassifier() : {'max_leaf_nodes': [1,10,30,50,70,90,100], 'min_samples_split': [2, 3, 4]}\n    , svm.SVC(): {'C':[100], 'tol': [0.005], 'kernel':['sigmoid']}\n    , KNeighborsClassifier(): {'n_neighbors':[5], 'weights':['distance'],'leaf_size':[15]}\n    , LogisticRegression(): {'C':[2000], 'tol': [0.0001]}\n    , GradientBoostingClassifier(): {'learning_rate':[0.01],'n_estimators':[100], 'max_depth':[3], 'min_samples_split':[2],'min_samples_leaf': [2]}\n    , AdaBoostClassifier(): {'learning_rate':[0.01], 'n_estimators':[150]}\n}\n\n# X_train, X_test, y_train, y_test = train_test_split(modeldata, y, test_size=0.20, random_state=47)\n# import eli5\n# from eli5.sklearn import PermutationImportance\n# model = RandomForestClassifier()\n# model.fit(X_train, y_train)\n# perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\n# eli5.show_weights(perm, feature_names = X_test.columns.tolist())\n\n# print(classification_report( model.predict(X_test), y_test))\n\nX_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.20, random_state=47)\n# for model in classifiers:\n#     print(f\"{type(model).__name__}\")\n#     model.fit(X_train, y_train)\n#     acc = accuracy_score(y_test, model.predict(X_test))\n#     print(f\"Accuracy: {acc:.4f}\")\n#     print()\n\n#     print(classification_report(res, y_test))\n# clf = GridSearchCV(model, model_params, cv=5, verbose=0, n_jobs=-1, scoring='accuracy')\n# clf.fit(X_train, y_train)\n# print(\"best params: \" + str(clf.best_params_))\n# print(\"best scores: \" + str(clf.best_score_))\n# print(classification_report( clf.predict(X_test), y_test))\n\nbest_params= {\n    'bootstrap': False,\n    'max_depth': 70,\n    'max_features': 'auto',\n    'min_samples_leaf': 1,\n    'min_samples_split': 10,\n    'n_estimators': 900\n}\n\nmodel = RandomForestClassifier(bootstrap = False, max_depth = 70, min_samples_leaf = 1, n_estimators = 900, max_features = 'auto')\nmodel.fit(X_train, y_train)\nres = model.predict(X_test)\nprint(classification_report(res, y_test))\nprint('end')\n# data['class'] = y\n# data.to_csv('data.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}