{"cells":[{"metadata":{},"cell_type":"markdown","source":"## This is the code I used to create the TP & FP datasets\n\nIt needs a little cleaning and simplifying, but this is the code I used to create:\n* https://www.kaggle.com/tpmeli/true-positive-centered-10-second-spectrograms\n* https://www.kaggle.com/tpmeli/false-positive-centered-10-second-spectrograms\n\nThis was done on my local machine so some code is specific to that.\nFor example - I show the specs here, but you can use \"matplotlib.use('Agg')\" to disable showing\nthe outputs for faster processing.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\nimport matplotlib\n# matplotlib.use('Agg')  # Doesn't display plots - Use for on your own computer\n\n# Import and convert\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(\"ignore\")\n\nimport librosa\nimport librosa.display\nimport librosa as lr\nimport os\n\nfrom pathlib import Path\n\nimport pandas as pd\n\nos.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# PUT YOUR OWN PATH HERE.\npath = \"../input/rfcx-species-audio-detection/\"\ntrain_tp = pd.read_csv(path + \"train_tp.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_tp.shape)\ntrain_tp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_tp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read in Files ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = \"../input/rfcx-species-audio-detection/train/\"\n\n# Glob creates a file path list of all of a certain filetype, in this case .flac.\nflac_file_paths = list(glob(base_dir + \"*.flac\"))\n\nprint(\"Sample file paths:\")\nflac_file_paths[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tp[\"song_duration\"] = train_tp[\"t_max\"] - train_tp[\"t_min\"]\ntrain_tp[\"freq_range\"] = train_tp[\"f_max\"] - train_tp[\"f_min\"]\ntrain_tp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tp[\"song_duration\"].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sond duration doesn't go about"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tp[\"freq_range\"].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tp[\"freq_range\"].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tp[\"freq_range\"].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Spectrograms\n\nI used this code on my local machine, so some code is specific to that.\n\nHere I just do 10 specs, but you can do all of them easily by looping over train_tp (using all_iters)"},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nshow_specs = False\nsave_dir = \"\"\n\nskipped = []\n\nall_iters = len(train_tp)\njust_ten = 10\n\nprocess_these = just_ten\n\nprint(f\"processing {process_these} files\")\n\nfor i in tqdm(range(process_these)):\n    \n    try:\n        this_row = train_tp.iloc[i]\n\n        this_filename = base_dir + str(this_row.recording_id) + \".flac\"\n\n        print(\"processing: \", this_row.recording_id)\n\n        # Important information about centering the audio array.\n        song_start = this_row[\"t_min\"]\n        song_end = this_row[\"t_max\"]\n        song_duration = song_end - song_start\n        clip_length = 10\n        empty_space = clip_length - song_duration\n        empty_space_one_side = (empty_space / 2)\n        empty_offset = song_start - empty_space_one_side\n\n        # Read in file\n        audio_array, sampling_rate = lr.load(this_filename, \n                                             duration=10,\n                                             offset = empty_offset)\n\n        # Use this to see when the spectrogram is being extracted.\n        # print(empty_offset, song_start, song_end, song_end + empty_space_one_side)\n\n        # Create the Fourier Transform \n        # (which isolates the amplitude level at each frequency)\n        X_spec = librosa.stft(audio_array,\n                              n_fft = 1024)\n\n        # Converted to Decibels\n        spec_db = librosa.core.amplitude_to_db(X_spec)\n\n        if show_specs:\n            # Display the spectrogram\n            ax = librosa.display.specshow(spec_db)\n            plt.colorbar()\n            plt.show()\n\n        ax = librosa.display.specshow(spec_db)\n        \n        pic_filename = str(this_row.recording_id) + \"_idx_\" + str(i) + \"_.png\"\n        new_save_filename = save_dir + pic_filename\n        \n        # print(new_save_filename)\n        \n        plt.savefig(new_save_filename, pad_inches = 0, bbox_inches = 'tight')\n\n        plt.close(\"all\")\n        librosa.cache.clear()\n\n    except:\n        try:\n            skipped.append(base_filename)\n        except:\n            pass\n    \nprint(\"skipped: \", skipped)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}