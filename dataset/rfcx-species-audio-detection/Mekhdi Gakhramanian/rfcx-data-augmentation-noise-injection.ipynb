{"cells":[{"metadata":{"_uuid":"c9ea3867-14d7-4d67-96f8-5984ac66626c","_cell_guid":"70cd944a-2f4c-4311-9b14-2fb7978ac618","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport random\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport librosa.display\nimport cv2\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\n\n\nfrom tqdm import tqdm\nfrom pydub import AudioSegment\n\nimport albumentations\nfrom albumentations.core.transforms_interface import DualTransform, BasicTransform\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55a97e38-e1f3-40b4-99a4-e75de5a74bed","_cell_guid":"ea34b14c-de38-4619-8776-4ca43019feb2","trusted":true},"cell_type":"code","source":"path = f\"../input/birdsong-resampled-train-audio-03/norhar2/XC143657.wav\"\nsample_rate = 16000\nsound = AudioSegment.from_wav(path)\nsound = sound.set_frame_rate(sample_rate)\n\ndata = np.array(sound.get_array_of_samples(), dtype=np.float32), sample_rate","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eae15764-6f2f-4392-adf7-40fe11495c24","_cell_guid":"fd525b63-752e-42d7-b7ab-4ee7186f5f33","trusted":true},"cell_type":"code","source":"class AudioTransform(BasicTransform):\n    \"\"\"Transform for Audio task\"\"\"\n\n    @property\n    def targets(self):\n        return {\"data\": self.apply}\n    \n    def update_params(self, params, **kwargs):\n        if hasattr(self, \"interpolation\"):\n            params[\"interpolation\"] = self.interpolation\n        if hasattr(self, \"fill_value\"):\n            params[\"fill_value\"] = self.fill_value\n        return params","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c91da57-6252-4173-ad50-fd69a69c29af","_cell_guid":"e4f51778-eb32-4fe8-80bc-c7e4992950a7","trusted":true},"cell_type":"code","source":"    \"\"\"It simply add some random value into data by using numpy\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(NoiseInjection, self).__init__(always_apply, p)\n    \n    def apply(self, data, noise_levels=(0, 0.5), **params):\n        sound, sr = data\n        noise_level = np.random.uniform(*noise_levels)\n        noise = np.random.randn(len(sound))\n        augmented_sound = sound + noise_level * noise\n        # Cast back to same data type\n        augmented_sound = augmented_sound.astype(type(sound[0]))\n\n        return augmented_sound, sr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4662ab11-32ec-4f91-ba53-66a5141b4d10","_cell_guid":"fb936ea7-2821-4947-aee0-e6ee9a6f336b","trusted":true},"cell_type":"code","source":"class NoiseInjection(AudioTransform):\n    \"\"\"It simply add some random value into data by using numpy\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(NoiseInjection, self).__init__(always_apply, p)\n    \n    def apply(self, data, noise_levels=(0, 0.5), **params):\n        sound, sr = data\n        noise_level = np.random.uniform(*noise_levels)\n        noise = np.random.randn(len(sound))\n        augmented_sound = sound + noise_level * noise\n        # Cast back to same data type\n        augmented_sound = augmented_sound.astype(type(sound[0]))\n\n        return augmented_sound, sr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"723762f5-059c-4f3a-9f89-244547b7dc18","_cell_guid":"1ffa501f-e740-41e4-a96a-c4710d9b1357","trusted":true},"cell_type":"code","source":"transform = NoiseInjection(p=1.0)\nsound_aug, sr = transform(data=data)['data']\n\nplt.plot(data[0])\nplt.plot(sound_aug)\nplt.show()\n\ndisplay(ipd.Audio(data[0], rate=sr))\ndisplay(ipd.Audio(sound_aug, rate=sr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9b84f9b-2ca6-4cda-b2d1-a4e2cc262f98","_cell_guid":"292245c8-0a6b-4adc-ab76-5ef9c6b7299c","trusted":true},"cell_type":"code","source":"class ShiftingTime(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(ShiftingTime, self).__init__(always_apply, p)\n    \n    def apply(self, data, **params):\n        sound, sr = data\n\n        shift_max = np.random.randint((len(sound)/sr)/2)\n        shift = np.random.randint(sr * shift_max)\n        direction = np.random.randint(0,2)\n        if direction == 1:\n            shift = -shift\n\n        augmented_sound = np.roll(sound, shift)\n        # Set to silence for heading/ tailing\n        if shift > 0:\n            augmented_sound[:shift] = 0\n        else:\n            augmented_sound[shift:] = 0\n\n        return augmented_sound, sr\n\n    \ntransform = ShiftingTime(p=1.0)\nsound_aug, sr = transform(data=data)['data']\n\nplt.plot(data[0])\nplt.plot(sound_aug)\nplt.show()\n\ndisplay(ipd.Audio(data[0], rate=sr))\ndisplay(ipd.Audio(sound_aug, rate=sr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07d6640b-d9a3-4545-9d1e-f5ccd9ba0186","_cell_guid":"e5e4627c-a144-4c8f-a87d-83e66f641037","trusted":true},"cell_type":"code","source":"class PitchShift(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(PitchShift, self).__init__(always_apply, p)\n    \n    def apply(self, data, **params):\n        sound, sr = data\n\n        n_steps = np.random.randint(-10, 10)\n        augmented_sound = librosa.effects.pitch_shift(sound, sr, n_steps)\n\n        return augmented_sound, sr\n    \ntransform = PitchShift(p=1.0)\nsound_aug, sr = transform(data=data)['data']\n\nplt.plot(data[0])\nplt.plot(sound_aug)\nplt.show()\n\ndisplay(ipd.Audio(data[0], rate=sr))\ndisplay(ipd.Audio(sound_aug, rate=sr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"566ad3bf-fef4-496c-afbf-0eaf085cd073","_cell_guid":"e2c6af1e-f4a4-44eb-bc6c-282c6e9c7d3e","trusted":true},"cell_type":"code","source":"class TimeStretch(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, always_apply=False, p=0.5):\n        super(TimeStretch, self).__init__(always_apply, p)\n    \n    def apply(self, data, **params):\n        sound, sr = data\n\n        rate = np.random.uniform(0, 2)\n        augmented_sound = librosa.effects.time_stretch(sound, rate)\n\n        return augmented_sound, sr\n\ntransform = TimeStretch(p=1.0)\nsound_aug, sr = transform(data=data)['data']\n\nplt.plot(data[0])\nplt.plot(sound_aug)\nplt.show()\n\ndisplay(ipd.Audio(data[0], rate=sr))\ndisplay(ipd.Audio(sound_aug, rate=sr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4cb4c30-7fb1-4084-92d1-5cd64191d5f4","_cell_guid":"69905c4b-1a67-4300-af6b-101895c6ae8b","trusted":true},"cell_type":"code","source":"class MelSpectrogram(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, parameters, always_apply=False, p=0.5):\n        super(MelSpectrogram, self).__init__(always_apply, p)\n\n        self.parameters = parameters\n    \n    def apply(self, data, **params):\n        sound, sr = data\n\n        melspec = librosa.feature.melspectrogram(sound, sr=sr, **self.parameters)\n        melspec = librosa.power_to_db(melspec)\n        melspec = melspec.astype(np.float32)\n\n        return melspec, sr\n    \n    \n    \nmelspectrogram_parameters = {\n        \"n_mels\": 128,\n        \"fmin\": 20,\n        \"fmax\": 16000\n    }\n\ntransform = MelSpectrogram(parameters=melspectrogram_parameters, p=1.0)\n\nmelspec, sr = transform(data=data)['data']\n\nplt.figure(figsize=(20,10))\nplt.imshow(melspec)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2d400e2-933d-4602-a725-fdf7744bdf8e","_cell_guid":"c10be7aa-805c-4b20-ac68-fe2d40c175e3","trusted":true},"cell_type":"code","source":"class SpecAugment(AudioTransform):\n    \"\"\"Shifting time axis\"\"\"\n    def __init__(self, num_mask=2, freq_masking=0.15, time_masking=0.20, always_apply=False, p=0.5):\n        super(SpecAugment, self).__init__(always_apply, p)\n\n        self.num_mask = num_mask\n        self.freq_masking = freq_masking\n        self.time_masking = time_masking\n    \n    def apply(self, data, **params):\n        melspec, sr = data\n\n        spec_aug = self.spec_augment(melspec, \n                                     self.num_mask,\n                                     self.freq_masking,\n                                     self.time_masking,\n                                     melspec.min())\n        \n\n\n        return spec_aug, sr\n    \n\n    def spec_augment(self, \n                    spec: np.ndarray,\n                    num_mask=2,\n                    freq_masking=0.15,\n                    time_masking=0.20,\n                    value=0):\n        spec = spec.copy()\n        num_mask = random.randint(1, num_mask)\n        for i in range(num_mask):\n            all_freqs_num, all_frames_num  = spec.shape\n            freq_percentage = random.uniform(0.0, freq_masking)\n\n            num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n            f0 = int(f0)\n            spec[f0:f0 + num_freqs_to_mask, :] = value\n\n            time_percentage = random.uniform(0.0, time_masking)\n\n            num_frames_to_mask = int(time_percentage * all_frames_num)\n            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n            t0 = int(t0)\n            spec[:, t0:t0 + num_frames_to_mask] = value\n\n        return spec\n    \n    \n    \ntransform = SpecAugment(p=1.0)\ndata = melspec, sr\n\nspecAug, sr = transform(data=data)['data']\n\nplt.figure(figsize=(20,10))\nplt.imshow(specAug)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69b273d3-935f-4410-890c-11909d4a420f","_cell_guid":"8cef8e8d-8c37-4d95-b11d-634026bdaf7a","trusted":true},"cell_type":"code","source":"class SpectToImage(AudioTransform):\n\n    def __init__(self, always_apply=False, p=0.5):\n        super(SpectToImage, self).__init__(always_apply, p)\n    \n    def apply(self, data, **params):\n        image, sr = data\n        delta = librosa.feature.delta(image)\n        accelerate = librosa.feature.delta(image, order=2)\n        image = np.stack([image, delta, accelerate], axis=-1)\n        image = image.astype(np.float32) / 100.0\n\n        return image\n    \n    \ntransform = SpectToImage(p=1.0)\ndata = specAug, sr\n\nimage = transform(data=data)['data']\n\nplt.figure(figsize=(20,10))\nplt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"134a0dcb-110c-4aaf-89d2-21ed4065f05e","_cell_guid":"502018ba-5266-4474-aed3-2052dbb1c506","trusted":true},"cell_type":"markdown","source":"Show All"},{"metadata":{"_uuid":"fb2a4d11-7462-4faa-a171-5e8f73e5d581","_cell_guid":"53b81d43-5b2f-42e9-9fd2-8df7471b2d58","trusted":true},"cell_type":"code","source":"# audio_augmentation = albumentations.Compose([\n#      RandomAudio(always_apply=True),\n#      NoiseInjection(p=1),\n#      MelSpectrogram(parameters=melspectrogram_parameters,always_apply=True),\n#      SpecAugment(p=1),\n#      SpectToImage(always_apply=True)\n# ])\n\n# data = np.array(sound.get_array_of_samples(), dtype=np.float32), sample_rate\n# image = audio_augmentation(data=data)['data']\n\n# plt.imshow(image)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42a43a73-7368-4920-b805-e23c3dd5e6fc","_cell_guid":"2c29bedd-c9d9-4d03-94c9-bebd299fab65","trusted":true},"cell_type":"code","source":"class CutOut(AudioTransform):\n    def __init__(self, always_apply=False, p=0.5 ):\n        super(CutOut, self).__init__(always_apply, p)\n        \n    def apply(self,data,**params):\n        '''\n        data : ndarray of audio timeseries\n        '''\n        start_ = np.random.randint(0,len(data))\n        end_ = np.random.randint(start_,len(data))\n        \n        data[start_:end_] = 0\n        \n        return data\n    \n\n\ny,sr = librosa.load(path,sr=16000)\n\nprint('Audio Intially')\nipd.Audio(y, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90a22da0-aae4-42d1-a727-296420c9ee5e","_cell_guid":"e3442074-e410-4098-9c18-8156d63e1f12","trusted":true},"cell_type":"code","source":"transform = CutOut(p=1.0)\n\nprint('audio after transform')\nipd.Audio(transform(data=y)['data'],rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6f6ba9f-ded7-49b7-8596-0cfb5ba2c60a","_cell_guid":"ef02a7e6-05a0-466a-a6be-0835b806d2e7","trusted":true},"cell_type":"markdown","source":"# Spectrogram Extraction\n\nhttps://github.com/kahst/BirdCLEF-Baseline/blob/master/utils/"},{"metadata":{"_uuid":"60b6db8c-b6d9-4056-bf23-0a9a7caaf1a2","_cell_guid":"a8368dfa-eb38-40c0-b6f3-f5e1dce25d81","trusted":true},"cell_type":"code","source":"def openAudioFile(path, sample_rate=16000, as_mono=True, mean_substract=False):\n    \n    # Open file with librosa (uses ffmpeg or libav)\n    sig, rate = librosa.load(path, sr=sample_rate, mono=as_mono)\n\n    # Noise reduction?\n    if mean_substract:\n        sig -= sig.mean()\n\n    return sig, rate","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23199475-ee42-48d4-b7f8-c34ae2beb274","_cell_guid":"829be1f8-6128-45d7-a758-0ce4eba0da40","trusted":true},"cell_type":"code","source":"def splitSignal(sig, rate, seconds, overlap, minlen):\n\n    # Split signal with overlap\n    sig_splits = []\n    for i in range(0, len(sig), int((seconds - overlap) * rate)):\n        split = sig[i:i + int(seconds * rate)]\n\n        # End of signal?\n        if len(split) < int(minlen * rate):\n            break\n        \n        # Signal chunk too short?\n        if len(split) < int(rate * seconds):\n            split = np.hstack((split, np.zeros((int(rate * seconds) - len(split),))))\n        \n        sig_splits.append(split)\n\n    return sig_splits","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c94bc50-a93a-468d-bd11-3e4a1c3239d8","_cell_guid":"eabaca86-3af0-4a08-8b23-9c943ce58b5c","trusted":true},"cell_type":"code","source":"def melspec(sig, rate, shape=(128, 256), fmin=20, fmax=16000, normalize=True, preemphasis=0.95):\n\n    # shape = (height, width) in pixels\n\n    # Mel-Spec parameters\n    SAMPLE_RATE = rate\n    N_FFT = shape[0] * 8 # = window length\n    N_MELS = shape[0]\n    HOP_LEN = len(sig) // (shape[1] - 1)    \n    FMAX = fmax\n    FMIN = fmin\n\n    # Preemphasis as in python_speech_features by James Lyons\n    if preemphasis:\n        sig = np.append(sig[0], sig[1:] - preemphasis * sig[:-1])\n\n    # Librosa mel-spectrum\n    melspec = librosa.feature.melspectrogram(y=sig, sr=SAMPLE_RATE, hop_length=HOP_LEN, n_fft=N_FFT, n_mels=N_MELS, fmax=FMAX, fmin=FMIN, power=1.0)\n    \n    # Convert power spec to dB scale (compute dB relative to peak power)\n    melspec = librosa.amplitude_to_db(melspec, ref=np.max, top_db=80)\n\n    # Flip spectrum vertically (only for better visialization, low freq. at bottom)\n    melspec = melspec[::-1, ...]\n\n    # Trim to desired shape if too large\n    melspec = melspec[:shape[0], :shape[1]]\n\n    # Normalize values between 0 and 1\n    if normalize:\n        melspec -= melspec.min()\n        if not melspec.max() == 0:\n            melspec /= melspec.max()\n        else:\n            mlspec = np.clip(melspec, 0, 1)\n\n    return melspec.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15dc34d9-cde8-403f-baff-e79c805a0989","_cell_guid":"8c5129a7-671c-4486-b6c7-150153466a55","trusted":true},"cell_type":"code","source":"def stft(sig, rate, shape=(128, 256), fmin=20, fmax=16000, normalize=True):\n\n    # shape = (height, width) in pixels\n\n    # STFT-Spec parameters\n    N_FFT = int((rate * shape[0] * 2) / abs(fmax - fmin)) + 1\n    P_MIN = int(float(N_FFT / 2) / rate * fmin) + 1\n    P_MAX = int(float(N_FFT / 2) / rate * fmax) + 1    \n    HOP_LEN = len(sig) // (shape[1] - 1)\n\n    # Librosa stft-spectrum\n    spec = librosa.core.stft(sig, hop_length=HOP_LEN, n_fft=N_FFT, window='hamm')\n\n    # Convert power spec to dB scale (compute dB relative to peak power)\n    spec = librosa.amplitude_to_db(librosa.core.magphase(spec)[0], ref=np.max, top_db=80)\n\n    # Trim to desired shape using cutoff frequencies\n    spec = spec[P_MIN:P_MAX, :shape[1]]\n\n    # Flip spectrum vertically (only for better visialization, low freq. at bottom)\n    spec = spec[::-1, ...]    \n\n    # Normalize values between 0 and 1\n    if normalize:\n        spec -= spec.min()\n        if not spec.max() == 0:\n            spec /= spec.max()\n        else:\n            spec = np.clip(spec, 0, 1)    \n    \n    return spec.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24496315-ba78-47c7-a77b-ca4981c64764","_cell_guid":"ee700a1c-3f24-46e8-946d-0e8700f5fc8a","trusted":true},"cell_type":"code","source":"def get_spec(sig, rate, shape, spec_type='linear', **kwargs):\n\n    if spec_type.lower()== 'melspec':\n        return melspec(sig, rate, shape, **kwargs)\n    else:\n        return stft(sig, rate, shape, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfbcb6ed-b55c-4ec0-b4ea-ed30c6cd4074","_cell_guid":"7207d28d-c128-4fd5-bc16-7db47d47f7b9","trusted":true},"cell_type":"code","source":"def signal2noise(spec):\n\n    # Get working copy\n    spec = spec.copy()\n\n    # Calculate median for columns and rows\n    col_median = np.median(spec, axis=0, keepdims=True)\n    row_median = np.median(spec, axis=1, keepdims=True)\n\n    # Binary threshold\n    spec[spec < row_median * 1.25] = 0.0\n    spec[spec < col_median * 1.15] = 0.0\n    spec[spec > 0] = 1.0\n\n    # Median blur\n    spec = cv2.medianBlur(spec, 3)\n\n    # Morphology\n    spec = cv2.morphologyEx(spec, cv2.MORPH_CLOSE, np.ones((3, 3), np.float32))\n\n    # Sum of all values\n    spec_sum = spec.sum()\n\n    # Signal to noise ratio (higher is better)\n    try:\n        s2n = spec_sum / (spec.shape[0] * spec.shape[1] * spec.shape[2])\n    except:\n        s2n = spec_sum / (spec.shape[0] * spec.shape[1])\n\n    return s2n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cc14ee9-5a81-41fb-9c18-4c0574c16f4d","_cell_guid":"648a9abd-11a0-4214-99dd-ae085d70f9ea","trusted":true},"cell_type":"code","source":"def specsFromSignal(sig, rate, shape, seconds, overlap, minlen, **kwargs):\n\n    # Split signal in consecutive chunks with overlap\n    sig_splits = splitSignal(sig, rate, seconds, overlap, minlen)\n\n    # Extract specs for every sig split\n    for sig in sig_splits:\n\n        # Get spec for signal chunk\n        spec = get_spec(sig, rate, shape, **kwargs)\n\n        yield spec","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"490ac524-c7e8-4ac3-88c9-6efeb2229614","_cell_guid":"7c94eef3-f8dd-486c-af84-088737b08a2c","trusted":true},"cell_type":"code","source":"def specsFromFile(path, rate, seconds, overlap, minlen, shape, start=-1, end=-1, **kwargs):\n\n    # Open file\n    sig, rate = openAudioFile(path, rate)\n\n    # Trim signal?\n    if start > -1 and end > -1:\n        sig = sig[int(start * rate):int(end * rate)]\n        minlen = 0\n\n    # Yield all specs for file\n    for spec in specsFromSignal(sig, rate, shape, seconds, overlap, minlen, **kwargs):\n        yield spec\n    \nif __name__ == '__main__':\n\n    \n    for spec in specsFromFile('../input/birdsong-resampled-train-audio-03/norwat/XC120655.wav',\n                              rate=44000,\n                              seconds=1,\n                              overlap=0,\n                              minlen=1,\n                              shape=(128, 256),\n                              fmin=20,\n                              fmax=16000,\n                              spec_type='melspec'):\n\n        # Calculate and show noise measure\n        noise = signal2noise(spec)\n        print (noise)\n\n        # Show spec and wait for enter key\n        cv2.imshow('SPEC', spec)\n        cv2.waitKey(-1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}