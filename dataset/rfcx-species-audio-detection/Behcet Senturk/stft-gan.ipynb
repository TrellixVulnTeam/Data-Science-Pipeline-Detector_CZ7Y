{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebre\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll use librosa to read audio and perform some analysis"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import librosa\nimport soundfile as sf\nimport librosa.display as lrd\n\nimport os\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's read both tables to identify true and false positives on the spectrum"},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf = pd.read_csv('/kaggle/input/rfcx-species-audio-detection/train_tp.csv')\nfpdf = pd.read_csv('/kaggle/input/rfcx-species-audio-detection/train_fp.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpdf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number of samples per call type and species"},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf['duration'] = tpdf.t_max-tpdf.t_min\ntpdf['bandwidth'] = tpdf.f_max-tpdf.f_min\n\ntpdf.pivot_table(index='species_id',columns='songtype_id',\n                 values='duration',aggfunc='count').fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metadata per species\n\nNotice how the duration and frequency bands are highly characteristic of each species. \n\nThe trouble will be to establish the event boundaries in new sound files"},{"metadata":{},"cell_type":"markdown","source":"### Call duration\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,figsize=(10,4))\nsns.boxplot(data=tpdf,y='duration',x='species_id',hue='songtype_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lower frequency of call band"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,figsize=(10,4))\nsns.boxplot(data=tpdf,y='f_min',x='species_id',hue='songtype_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Uper frequency of call band"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,figsize=(10,4))\nsns.boxplot(data=tpdf,y='f_max',x='species_id',hue='songtype_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bandwidth"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,figsize=(10,4))\nsns.boxplot(data=tpdf,y='bandwidth',x='species_id',hue='songtype_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Investigate Species 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s0 = tpdf[tpdf['species_id'] == 0]\ns0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r0 = s0[s0['recording_id'] == '00d442df7']\nr0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_min = r0['t_min'].values[0]\nt_max = r0['t_max'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/rfcx-species-audio-detection/train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\nIPython.display.Audio(\"/kaggle/input/rfcx-species-audio-detection/train/00d442df7.flac\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data, samplerate = librosa.load('/kaggle/input/rfcx-species-audio-detection/train/00d442df7.flac', mono=True)\nIPython.display.Audio(data, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samplerate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape[0] / samplerate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_point = int(samplerate * t_min)\nstart_point","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"end_point = int(samplerate * t_max)\nend_point","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r0_cut = data[start_point:end_point]\n\nIPython.display.Audio(r0_cut, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r0_cut.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S0_cut = np.abs(librosa.stft(r0_cut))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S0_cut.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nimg = librosa.display.specshow(librosa.amplitude_to_db(S0_cut, ref=np.max), y_axis='log', x_axis='time', ax=ax)\nax.set_title('Power spectrogram')\nfig.colorbar(img, ax=ax, format=\"%+2.0f dB\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IS0_cut = librosa.istft(S0_cut)\n\nIPython.display.Audio(IS0_cut, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf['species_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0-23 different species\n# species_unique_list = sorted(tpdf['species_id'].unique())\nspecies_unique_list = [0]\nspecies_0 = {}\nfor species in species_unique_list:\n    species_df = tpdf[tpdf['species_id'] == species]\n    \n    for i in species_df.iterrows():\n        record_id = i[1][0]\n        t_min = i[1][3]\n        t_max = i[1][5]\n        \n        data, samplerate = sf.read('/kaggle/input/rfcx-species-audio-detection/train/'+record_id+'.flac')\n        \n        start_point = int(samplerate * t_min)\n        end_point = int(samplerate * t_max)\n    \n        cut = data[start_point:end_point]\n        \n        stft_cut = np.abs(librosa.stft(cut))\n        \n        # Currently we get only same sized sounds\n        if stft_cut.shape[1] != 75:\n            continue\n        \n        species_0[record_id] = stft_cut\n\nspecies_0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GAN Tensorflow2"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport random\nfrom tensorflow import keras\nimport glob\nimport matplotlib.pyplot as plt\nimport time\nfrom tensorflow.keras import layers\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have 40 record for species 0. 10 of them are longer so we dont use them.\ndata = np.array(list(species_0.values()))\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 is for channel\ndata = data.reshape(40, 1025, 75, 1)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 8\nBUFFER_SIZE = 6\ntrain_dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ntrain_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(41*5*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((41, 5, 256)))\n    assert model.output_shape == (None, 41, 5, 256) # Note: None is the batch size\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 41, 5, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(5, 3), padding='same', use_bias=False))\n    assert model.output_shape == (None, 205, 15, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(5, 5), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 1025, 75, 1)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate random stft\ngenerator = make_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_stft = generator(noise, training=False)\n\ngenerated_stft_resized = generated_stft.numpy().reshape(1025, 75)\n\nfig, ax = plt.subplots()\nimg = librosa.display.specshow(librosa.amplitude_to_db(generated_stft_resized, ref=np.max), y_axis='log', x_axis='time', ax=ax)\nax.set_title('Power spectrogram')\nfig.colorbar(img, ax=ax, format=\"%+2.0f dB\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generated_sound = librosa.istft(generated_stft_resized)\n\nIPython.display.Audio(generated_sound, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(5, 5), padding='same', input_shape=[1025, 75, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(5, 3), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_stft)\nprint(decision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 90000\nnoise_dim = 100\nnum_examples_to_generate = 1\n\n# We will reuse this seed overtime (so it's easier)\n# to visualize progress\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Notice the use of `tf.function`\n# This annotation causes the function to be \"compiled\".\n@tf.function\ndef train_step(records):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_records = generator(noise, training=True)\n\n        real_output = discriminator(records, training=True)\n        fake_output = discriminator(generated_records, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n        \n        for image_batch in dataset:\n            train_step(image_batch)\n            \n        # Save the model every 500 epochs\n        if (epoch + 1) % 250 == 0:\n            # Produce records as we go\n            generate_and_save_records(generator, epoch + 1, seed)\n            \n        IPython.display.clear_output(wait=True)\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n    # Generate after the final epoch\n    IPython.display.clear_output(wait=True)\n    generate_and_save_records(generator, epochs, seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_and_save_records(model, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)\n\n    generated_stfts = predictions.numpy().reshape(num_examples_to_generate, 1025, 75)\n    for i in range(generated_stfts.shape[0]):\n        generated_stft = generated_stfts[i]\n        generated_sound = librosa.istft(generated_stft)\n        sf.write('record_at_epoch_{}_{}th.ogg'.format(epoch, i), generated_sound, samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(train_dataset, EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data, samplerate = librosa.load('record_at_epoch_50000_0th.ogg', mono=True)\nIPython.display.Audio(data, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification\n\nWe will use 25(5val+20train) generated and 25(5val+20train) real records for species_0\n\n40(10val+30train) real records for species_1\n\n40(10val+30train) real records for species_2\n\nTotal train size 100 and validation size will be 30"},{"metadata":{},"cell_type":"markdown","source":"#### Species 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use 25(5val+20train) generated and 25(5val+20train) real records for species_0\n# 40(10val+30train) real records for species_1\n# 40(10val+30train) real records for species_2\n\n# Total train size 100 and validation size will be 30\nspecies_0_list = np.array(list(species_0.values()))\nspecies_0_real_train = species_0_list[:20]\nspecies_0_real_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_real_validation = species_0_list[20:25]\nspecies_0_real_validation.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_generated_train = []\nfor i in range(20):\n    noise = tf.random.normal([1, 100])\n    generated_record = generator(noise, training=False)\n\n    generated_record = generated_record.numpy().reshape(-1, 64000)\n    species_0_generated_train.append(generated_record)\n\n    \nspecies_0_generated_train = np.array(species_0_generated_train).squeeze()\nspecies_0_generated_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_generated_validation = []\nfor i in range(5):\n    noise = tf.random.normal([1, 100])\n    generated_record = generator(noise, training=False)\n\n    generated_record = generated_record.numpy().reshape(-1, 64000)\n    species_0_generated_validation.append(generated_record)\n    \nspecies_0_generated_validation = np.array(species_0_generated_validation).squeeze()\nspecies_0_generated_validation.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 40 species_0 record will use as train(20 generated and 20 real)\ntrain_species_0 = np.concatenate((species_0_generated_train, species_0_real_train))\ntrain_species_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\ntrain_species_0_label = np.zeros(len(train_species_0))\ntrain_species_0_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 20 species_0 record will use as train(5 generated and 5 real)\nvalidation_species_0 = np.concatenate((species_0_generated_validation, species_0_real_validation))\nvalidation_species_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_species_0_label = np.zeros(len(validation_species_0))\nvalidation_species_0_label.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Species 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0-23 different species\n# species_unique_list = sorted(tpdf['species_id'].unique())\nspecies_unique_list = [1]\nspecies_1 = {}\nfor species in species_unique_list:\n    species_df = tpdf[tpdf['species_id'] == species]\n    \n    for i in species_df.iterrows():\n        record_id = i[1][0]\n        t_min = i[1][3]\n        t_max = i[1][5]\n        \n        data, samplerate = sf.read('/kaggle/input/rfcx-species-audio-detection/train/'+record_id+'.flac')\n        \n        start_point = int(samplerate * t_min)\n        end_point = int(samplerate * t_max)\n    \n        cut = data[start_point:end_point]\n        \n        species_1[record_id] = cut\n\nspecies_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Padding every record to 64000 samples\n\n'''\nmax_len = -1\nfor record_data in species_0.values():\n    length = len(record_data)\n    if length > max_len:\n        max_len = length\n'''\nmax_len = 64000\n'''\na = [1, 2, 3, 4, 5]\nnp.pad(a, (3), 'constant', constant_values=(6))\n\n>>> array([6, 6, 6, 1, 2, 3, 4, 5, 6, 6, 6])\n'''\nfor record_id in species_1.keys():\n    if len(species_1[record_id]) < max_len:\n        species_1[record_id] = np.pad(species_1[record_id], (0, (max_len - len(species_1[record_id]))), 'constant', constant_values=(0))\n\nspecies_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IPython.display.Audio(species_1['0151b7d20'], rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_1_list = np.array(list(species_1.values()))\ntrain_species_1 = species_1_list[:30]\ntrain_species_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\ntrain_species_1_label = np.ones(len(train_species_1))\ntrain_species_1_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_species_1 = species_1_list[30:40]\nvalidation_species_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\nvalidation_species_1_label = np.ones(len(validation_species_1))\nvalidation_species_1_label.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Species 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0-23 different species\n# species_unique_list = sorted(tpdf['species_id'].unique())\nspecies_unique_list = [3]\nspecies_3 = {}\nfor species in species_unique_list:\n    species_df = tpdf[tpdf['species_id'] == species]\n    \n    for i in species_df.iterrows():\n        record_id = i[1][0]\n        t_min = i[1][3]\n        t_max = i[1][5]\n        \n        data, samplerate = sf.read('/kaggle/input/rfcx-species-audio-detection/train/'+record_id+'.flac')\n        \n        start_point = int(samplerate * t_min)\n        end_point = int(samplerate * t_max)\n    \n        cut = data[start_point:end_point]\n        \n        species_3[record_id] = cut\n\nspecies_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Padding every record to 64000 samples\n\n'''\nmax_len = -1\nfor record_data in species_0.values():\n    length = len(record_data)\n    if length > max_len:\n        max_len = length\n'''\nmax_len = 64000\n'''\na = [1, 2, 3, 4, 5]\nnp.pad(a, (3), 'constant', constant_values=(6))\n\n>>> array([6, 6, 6, 1, 2, 3, 4, 5, 6, 6, 6])\n'''\nfor record_id in species_3.keys():\n    if len(species_3[record_id]) < max_len:\n        species_3[record_id] = np.pad(species_3[record_id], (0, (max_len - len(species_3[record_id]))), 'constant', constant_values=(0))\n\nspecies_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_3_list = np.array(list(species_3.values()))\ntrain_species_3 = species_3_list[:30]\ntrain_species_3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\ntrain_species_3_label = np.ones(len(train_species_3)) * 2\ntrain_species_3_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_species_3 = species_3_list[30:40]\nvalidation_species_3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\nvalidation_species_3_label = np.ones(len(validation_species_3)) * 2\nvalidation_species_3_label.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Concatenate data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate((train_species_0, train_species_1, train_species_3)).reshape(100, 64000, 1)\ny_train = np.concatenate((train_species_0_label, train_species_1_label, train_species_3_label)).reshape(100, 1)\nX_validation = np.concatenate((validation_species_0, validation_species_1, validation_species_3)).reshape(30, 64000, 1)\ny_validation = np.concatenate((validation_species_0_label, validation_species_1_label, validation_species_3_label)).reshape(30, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape,', X_train.shape)\nprint('y_train shape,', y_train.shape)\nprint('X_validation shape,', X_validation.shape)\nprint('y_validation shape,', y_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_validation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ny_validation = enc.fit_transform(y_validation).toarray()\ny_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ny_train = enc.fit_transform(y_train).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_classification_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv1D(32, (25), strides=(4), padding='same',\n                                     input_shape=[64000,1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv1D(32, (25), strides=(4), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv1D(64, (25), strides=(4), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv1D(32, (25), strides=(4), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv1D(32, (25), strides=(4), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    \n    model.add(layers.Dense(32, activation='relu'))\n    model.add(layers.Dense(3, activation='softmax'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model = make_classification_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=150, batch_size=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We never use species_0 records from 25 to 50\nspecies_0_test = species_0_list[25:50]\nspecies_0_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_test = species_0_test.reshape(25, 64000, 1)\nspecies_0_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.predict_classes(species_0_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model.predict_classes(species_0_test), np.zeros(len(species_0_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We never use species_1 records from 40 to 50\nspecies_1_test = species_1_list[40:50]\nspecies_1_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_1_test = species_1_test.reshape(10, 64000, 1)\nspecies_1_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.predict_classes(species_1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model.predict_classes(species_1_test), np.ones(len(species_1_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We never use species_3 records from 40 to 50\nspecies_3_test = species_3_list[40:50]\nspecies_3_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_3_test = species_3_test.reshape(10, 64000, 1)\nspecies_3_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.predict_classes(species_3_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model.predict_classes(species_3_test), np.ones(len(species_3_test))*2 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification 2\n\nWe never use real records for species_0 this time"},{"metadata":{},"cell_type":"markdown","source":"#### Species 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use 40(10val+30train) generated records for species_0\n# 40(10val+30train) real records for species_1\n# 40(10val+30train) real records for species_2\n\n# Total train size 90 and validation size will be 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_generated = []\nfor i in range(40):\n    noise = tf.random.normal([1, 100])\n    generated_record = generator(noise, training=False)\n\n    generated_record = generated_record.numpy().reshape(-1, 64000)\n    species_0_generated.append(generated_record)\n\n    \nspecies_0_generated = np.array(species_0_generated).squeeze()\nspecies_0_generated.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_species_0 = species_0_generated[:30]\ntrain_species_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_species_0 = species_0_generated[30:40]\nvalidation_species_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\ntrain_species_0_label = np.zeros(len(train_species_3))\ntrain_species_0_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\nvalidation_species_0_label = np.zeros(len(validation_species_3))\nvalidation_species_0_label.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Concatenate"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate((train_species_0, train_species_1, train_species_3)).reshape(90, 64000, 1)\ny_train = np.concatenate((train_species_0_label, train_species_1_label, train_species_3_label)).reshape(90, 1)\nX_validation = np.concatenate((validation_species_0, validation_species_1, validation_species_3)).reshape(30, 64000, 1)\ny_validation = np.concatenate((validation_species_0_label, validation_species_1_label, validation_species_3_label)).reshape(30, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape,', X_train.shape)\nprint('y_train shape,', y_train.shape)\nprint('X_validation shape,', X_validation.shape)\nprint('y_validation shape,', y_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preprocces"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ny_validation = enc.fit_transform(y_validation).toarray()\ny_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ny_train = enc.fit_transform(y_train).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create second model"},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2 = make_classification_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=150, batch_size=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We never use real species_0 records\nspecies_0_test = species_0_list[0:50]\nspecies_0_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_test = species_0_test.reshape(50, 64000, 1)\nspecies_0_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2.predict_classes(species_0_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model_2.predict_classes(species_0_test), np.zeros(len(species_0_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We never use last 10 species_1 records\nspecies_1_test = species_1_list[40:50]\nspecies_1_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_1_test = species_1_test.reshape(10, 64000, 1)\nspecies_1_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2.predict_classes(species_1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model_2.predict_classes(species_1_test), np.ones(len(species_1_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We never use last 10 species_3 records\nspecies_3_test = species_3_list[40:50]\nspecies_3_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_3_test = species_3_test.reshape(10, 64000, 1)\nspecies_3_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2.predict_classes(species_3_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model_2.predict_classes(species_3_test), np.ones(len(species_3_test))*2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}