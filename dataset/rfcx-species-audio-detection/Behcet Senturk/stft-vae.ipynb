{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebre\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll use librosa to read audio and perform some analysis"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import librosa\nimport soundfile as sf\nimport librosa.display as lrd\n\nimport os\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's read both tables to identify true and false positives on the spectrum"},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf = pd.read_csv('/kaggle/input/rfcx-species-audio-detection/train_tp.csv')\nfpdf = pd.read_csv('/kaggle/input/rfcx-species-audio-detection/train_fp.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpdf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number of samples per call type and species"},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf['duration'] = tpdf.t_max-tpdf.t_min\ntpdf['bandwidth'] = tpdf.f_max-tpdf.f_min\n\ntpdf.pivot_table(index='species_id',columns='songtype_id',\n                 values='duration',aggfunc='count').fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Metadata per species\n\nNotice how the duration and frequency bands are highly characteristic of each species. \n\nThe trouble will be to establish the event boundaries in new sound files"},{"metadata":{},"cell_type":"markdown","source":"### Call duration\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,figsize=(10,4))\nsns.boxplot(data=tpdf,y='duration',x='species_id',hue='songtype_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lower frequency of call band"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,figsize=(10,4))\nsns.boxplot(data=tpdf,y='f_min',x='species_id',hue='songtype_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Uper frequency of call band"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,figsize=(10,4))\nsns.boxplot(data=tpdf,y='f_max',x='species_id',hue='songtype_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bandwidth"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,figsize=(10,4))\nsns.boxplot(data=tpdf,y='bandwidth',x='species_id',hue='songtype_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Investigate Species 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s0 = tpdf[tpdf['species_id'] == 0]\ns0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r0 = s0[s0['recording_id'] == '00d442df7']\nr0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_min = r0['t_min'].values[0]\nt_max = r0['t_max'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/rfcx-species-audio-detection/train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\nIPython.display.Audio(\"/kaggle/input/rfcx-species-audio-detection/train/00d442df7.flac\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data, samplerate = librosa.load('/kaggle/input/rfcx-species-audio-detection/train/00d442df7.flac', mono=True)\nIPython.display.Audio(data, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samplerate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape[0] / samplerate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_point = int(samplerate * t_min)\nstart_point","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"end_point = int(samplerate * t_max)\nend_point","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r0_cut = data[start_point:end_point]\n\nIPython.display.Audio(r0_cut, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r0_cut.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S0_cut = np.abs(librosa.stft(r0_cut))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S0_cut.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nimg = librosa.display.specshow(librosa.amplitude_to_db(S0_cut, ref=np.max), y_axis='log', x_axis='time', ax=ax)\nax.set_title('Power spectrogram')\nfig.colorbar(img, ax=ax, format=\"%+2.0f dB\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IS0_cut = librosa.istft(S0_cut)\n\nIPython.display.Audio(IS0_cut, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpdf['species_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0-23 different species\n# species_unique_list = sorted(tpdf['species_id'].unique())\nspecies_unique_list = [0]\nspecies_0 = {}\nfor species in species_unique_list:\n    species_df = tpdf[tpdf['species_id'] == species]\n    \n    for i in species_df.iterrows():\n        record_id = i[1][0]\n        t_min = i[1][3]\n        t_max = i[1][5]\n        \n        data, samplerate = sf.read('/kaggle/input/rfcx-species-audio-detection/train/'+record_id+'.flac')\n        \n        start_point = int(samplerate * t_min)\n        end_point = int(samplerate * t_max)\n    \n        cut = data[start_point:end_point]\n        \n        stft_cut = np.abs(librosa.stft(cut))\n        \n        # Currently we get only same sized sounds\n        if stft_cut.shape[1] != 75:\n            continue\n        \n        species_0[record_id] = stft_cut\n\nspecies_0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## VAE Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have 40 record for species 0. 10 of them are longer so we dont use them.\ndata = np.array(list(species_0.values()))\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 is for channel\ndata = data.reshape(40, 1025, 75, 1)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ENCODER\n\nlatent_dim = 2\n\nencoder_inputs = keras.Input(shape=(1025, 75, 1))\nx = layers.Conv2D(32, 3, activation=\"relu\", strides=(5, 5), padding=\"same\")(encoder_inputs)\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=(5, 3), padding=\"same\")(x)\nx = layers.Flatten()(x)\nx = layers.Dense(16, activation=\"relu\")(x)\nz_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\nz_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\nz = Sampling()([z_mean, z_log_var])\nencoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\nencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DECODER\n\nlatent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(41 * 5 * 64, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((41, 5, 64))(x)\nx = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=(5, 3), padding=\"same\")(x)\nx = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=(5, 5), padding=\"same\")(x)\ndecoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def train_step(self, data):\n        if isinstance(data, tuple):\n            data = data[0]\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = encoder(data)\n            reconstruction = decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n                keras.losses.mse(data, reconstruction)\n            )\n            reconstruction_loss *= 1025 * 75\n            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n            kl_loss = tf.reduce_mean(kl_loss)\n            kl_loss *= -0.5\n            total_loss = reconstruction_loss + kl_loss\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        return {\n            \"loss\": total_loss,\n            \"reconstruction_loss\": reconstruction_loss,\n            \"kl_loss\": kl_loss,\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Early Stopping\n# Model Checkpoint\nes = EarlyStopping(monitor='reconstruction_loss', mode='min', patience=50)\nmc = ModelCheckpoint('best_model.h5', monitor='reconstruction_loss', mode='min', save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TRAIN\n\nvae = VAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\nvae.fit(data, epochs=30000, batch_size=128, callbacks=[es, mc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_stft = data[0].reshape(1025, 75)\nexample_sound = librosa.istft(example_stft)\n\nIPython.display.Audio(example_sound, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_stft = example_stft.reshape(1, 1025, 75, 1)\nencoder_outputs = encoder.predict(example_stft)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoded_stft = decoder.predict(encoder_outputs)\ndecoded_stft = decoded_stft.reshape(1025, 75)\ndecoded_sound = librosa.istft(decoded_stft)\n\nIPython.display.Audio(decoded_sound, rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification\n\nWe will use 25(5val+20train) generated and 25(5val+20train) real records for species_0\n\n40(10val+30train) real records for species_1\n\n40(10val+30train) real records for species_2\n\nTotal train size 100 and validation size will be 30"},{"metadata":{},"cell_type":"markdown","source":"#### Species 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use 25(5val+20train) generated and 25(5val+20train) real records for species_0\n# 40(10val+30train) real records for species_1\n# 40(10val+30train) real records for species_2\n\n# Total train size 100 and validation size will be 30\nspecies_0_list = np.array(list(species_0.values()))\nspecies_0_real_train = species_0_list[:20]\nspecies_0_real_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_real_validation = species_0_list[20:25]\nspecies_0_real_validation.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_generated_train = []\nfor i in range(20):\n    noise = tf.random.normal([1, 100])\n    generated_record = generator(noise, training=False)\n\n    generated_record = generated_record.numpy().reshape(-1, 64000)\n    species_0_generated_train.append(generated_record)\n\n    \nspecies_0_generated_train = np.array(species_0_generated_train).squeeze()\nspecies_0_generated_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_generated_validation = []\nfor i in range(5):\n    noise = tf.random.normal([1, 100])\n    generated_record = generator(noise, training=False)\n\n    generated_record = generated_record.numpy().reshape(-1, 64000)\n    species_0_generated_validation.append(generated_record)\n    \nspecies_0_generated_validation = np.array(species_0_generated_validation).squeeze()\nspecies_0_generated_validation.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 40 species_0 record will use as train(20 generated and 20 real)\ntrain_species_0 = np.concatenate((species_0_generated_train, species_0_real_train))\ntrain_species_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\ntrain_species_0_label = np.zeros(len(train_species_0))\ntrain_species_0_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 20 species_0 record will use as train(5 generated and 5 real)\nvalidation_species_0 = np.concatenate((species_0_generated_validation, species_0_real_validation))\nvalidation_species_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_species_0_label = np.zeros(len(validation_species_0))\nvalidation_species_0_label.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Species 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0-23 different species\n# species_unique_list = sorted(tpdf['species_id'].unique())\nspecies_unique_list = [1]\nspecies_1 = {}\nfor species in species_unique_list:\n    species_df = tpdf[tpdf['species_id'] == species]\n    \n    for i in species_df.iterrows():\n        record_id = i[1][0]\n        t_min = i[1][3]\n        t_max = i[1][5]\n        \n        data, samplerate = sf.read('/kaggle/input/rfcx-species-audio-detection/train/'+record_id+'.flac')\n        \n        start_point = int(samplerate * t_min)\n        end_point = int(samplerate * t_max)\n    \n        cut = data[start_point:end_point]\n        \n        species_1[record_id] = cut\n\nspecies_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Padding every record to 64000 samples\n\n'''\nmax_len = -1\nfor record_data in species_0.values():\n    length = len(record_data)\n    if length > max_len:\n        max_len = length\n'''\nmax_len = 64000\n'''\na = [1, 2, 3, 4, 5]\nnp.pad(a, (3), 'constant', constant_values=(6))\n\n>>> array([6, 6, 6, 1, 2, 3, 4, 5, 6, 6, 6])\n'''\nfor record_id in species_1.keys():\n    if len(species_1[record_id]) < max_len:\n        species_1[record_id] = np.pad(species_1[record_id], (0, (max_len - len(species_1[record_id]))), 'constant', constant_values=(0))\n\nspecies_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IPython.display.Audio(species_1['0151b7d20'], rate=samplerate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_1_list = np.array(list(species_1.values()))\ntrain_species_1 = species_1_list[:30]\ntrain_species_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\ntrain_species_1_label = np.ones(len(train_species_1))\ntrain_species_1_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_species_1 = species_1_list[30:40]\nvalidation_species_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\nvalidation_species_1_label = np.ones(len(validation_species_1))\nvalidation_species_1_label.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Species 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0-23 different species\n# species_unique_list = sorted(tpdf['species_id'].unique())\nspecies_unique_list = [3]\nspecies_3 = {}\nfor species in species_unique_list:\n    species_df = tpdf[tpdf['species_id'] == species]\n    \n    for i in species_df.iterrows():\n        record_id = i[1][0]\n        t_min = i[1][3]\n        t_max = i[1][5]\n        \n        data, samplerate = sf.read('/kaggle/input/rfcx-species-audio-detection/train/'+record_id+'.flac')\n        \n        start_point = int(samplerate * t_min)\n        end_point = int(samplerate * t_max)\n    \n        cut = data[start_point:end_point]\n        \n        species_3[record_id] = cut\n\nspecies_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Padding every record to 64000 samples\n\n'''\nmax_len = -1\nfor record_data in species_0.values():\n    length = len(record_data)\n    if length > max_len:\n        max_len = length\n'''\nmax_len = 64000\n'''\na = [1, 2, 3, 4, 5]\nnp.pad(a, (3), 'constant', constant_values=(6))\n\n>>> array([6, 6, 6, 1, 2, 3, 4, 5, 6, 6, 6])\n'''\nfor record_id in species_3.keys():\n    if len(species_3[record_id]) < max_len:\n        species_3[record_id] = np.pad(species_3[record_id], (0, (max_len - len(species_3[record_id]))), 'constant', constant_values=(0))\n\nspecies_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_3_list = np.array(list(species_3.values()))\ntrain_species_3 = species_3_list[:30]\ntrain_species_3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\ntrain_species_3_label = np.ones(len(train_species_3)) * 2\ntrain_species_3_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_species_3 = species_3_list[30:40]\nvalidation_species_3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\nvalidation_species_3_label = np.ones(len(validation_species_3)) * 2\nvalidation_species_3_label.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Concatenate data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate((train_species_0, train_species_1, train_species_3)).reshape(100, 64000, 1)\ny_train = np.concatenate((train_species_0_label, train_species_1_label, train_species_3_label)).reshape(100, 1)\nX_validation = np.concatenate((validation_species_0, validation_species_1, validation_species_3)).reshape(30, 64000, 1)\ny_validation = np.concatenate((validation_species_0_label, validation_species_1_label, validation_species_3_label)).reshape(30, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape,', X_train.shape)\nprint('y_train shape,', y_train.shape)\nprint('X_validation shape,', X_validation.shape)\nprint('y_validation shape,', y_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_validation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ny_validation = enc.fit_transform(y_validation).toarray()\ny_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ny_train = enc.fit_transform(y_train).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_classification_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv1D(32, (25), strides=(4), padding='same',\n                                     input_shape=[64000,1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv1D(32, (25), strides=(4), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv1D(64, (25), strides=(4), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv1D(32, (25), strides=(4), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv1D(32, (25), strides=(4), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    \n    model.add(layers.Dense(32, activation='relu'))\n    model.add(layers.Dense(3, activation='softmax'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model = make_classification_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=150, batch_size=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We never use species_0 records from 25 to 50\nspecies_0_test = species_0_list[25:50]\nspecies_0_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_test = species_0_test.reshape(25, 64000, 1)\nspecies_0_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.predict_classes(species_0_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model.predict_classes(species_0_test), np.zeros(len(species_0_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We never use species_1 records from 40 to 50\nspecies_1_test = species_1_list[40:50]\nspecies_1_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_1_test = species_1_test.reshape(10, 64000, 1)\nspecies_1_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.predict_classes(species_1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model.predict_classes(species_1_test), np.ones(len(species_1_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We never use species_3 records from 40 to 50\nspecies_3_test = species_3_list[40:50]\nspecies_3_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_3_test = species_3_test.reshape(10, 64000, 1)\nspecies_3_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.predict_classes(species_3_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model.predict_classes(species_3_test), np.ones(len(species_3_test))*2 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification 2\n\nWe never use real records for species_0 this time"},{"metadata":{},"cell_type":"markdown","source":"#### Species 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use 40(10val+30train) generated records for species_0\n# 40(10val+30train) real records for species_1\n# 40(10val+30train) real records for species_2\n\n# Total train size 90 and validation size will be 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_generated = []\nfor i in range(40):\n    noise = tf.random.normal([1, 100])\n    generated_record = generator(noise, training=False)\n\n    generated_record = generated_record.numpy().reshape(-1, 64000)\n    species_0_generated.append(generated_record)\n\n    \nspecies_0_generated = np.array(species_0_generated).squeeze()\nspecies_0_generated.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_species_0 = species_0_generated[:30]\ntrain_species_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_species_0 = species_0_generated[30:40]\nvalidation_species_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\ntrain_species_0_label = np.zeros(len(train_species_3))\ntrain_species_0_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create labels species_0 is 0 and species_1 is 1 and species_3 is 2\nvalidation_species_0_label = np.zeros(len(validation_species_3))\nvalidation_species_0_label.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Concatenate"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate((train_species_0, train_species_1, train_species_3)).reshape(90, 64000, 1)\ny_train = np.concatenate((train_species_0_label, train_species_1_label, train_species_3_label)).reshape(90, 1)\nX_validation = np.concatenate((validation_species_0, validation_species_1, validation_species_3)).reshape(30, 64000, 1)\ny_validation = np.concatenate((validation_species_0_label, validation_species_1_label, validation_species_3_label)).reshape(30, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape,', X_train.shape)\nprint('y_train shape,', y_train.shape)\nprint('X_validation shape,', X_validation.shape)\nprint('y_validation shape,', y_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preprocces"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ny_validation = enc.fit_transform(y_validation).toarray()\ny_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ny_train = enc.fit_transform(y_train).toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create second model"},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2 = make_classification_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=150, batch_size=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We never use real species_0 records\nspecies_0_test = species_0_list[0:50]\nspecies_0_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_0_test = species_0_test.reshape(50, 64000, 1)\nspecies_0_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2.predict_classes(species_0_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model_2.predict_classes(species_0_test), np.zeros(len(species_0_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We never use last 10 species_1 records\nspecies_1_test = species_1_list[40:50]\nspecies_1_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_1_test = species_1_test.reshape(10, 64000, 1)\nspecies_1_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2.predict_classes(species_1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model_2.predict_classes(species_1_test), np.ones(len(species_1_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We never use last 10 species_3 records\nspecies_3_test = species_3_list[40:50]\nspecies_3_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species_3_test = species_3_test.reshape(10, 64000, 1)\nspecies_3_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classification_model_2.predict_classes(species_3_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(classification_model_2.predict_classes(species_3_test), np.ones(len(species_3_test))*2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}