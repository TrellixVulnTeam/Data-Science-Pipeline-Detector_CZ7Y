{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is a simple recall method (*recall_simple*), which can be used in [binary-lgb-baseline](https://www.kaggle.com/code/guoyonfan/binary-lgb-baseline-0-834) and [training-data-for-binary-lgb-baseline](https://www.kaggle.com/code/guoyonfan/training-data-for-binary-lgb-baseline-0-834) (by combining with the *recall_knn*).\n\n**In summary**, the *recall_simple* can improve the maximum IoU of the training data of the [training-data-for-binary-lgb-baseline](https://www.kaggle.com/code/guoyonfan/training-data-for-binary-lgb-baseline-0-834) from **0.923** (only generated by *recall_knn*) to **0.928**, and can improve the LB score of the [binary-lgb-baseline](https://www.kaggle.com/code/guoyonfan/binary-lgb-baseline-0-834) from **0.834** to **0.839**.","metadata":{}},{"cell_type":"code","source":"## Imports\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport gc\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nfrom tqdm.auto import tqdm\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.model_selection import GroupKFold","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:26.788506Z","iopub.execute_input":"2022-06-01T03:36:26.789098Z","iopub.status.idle":"2022-06-01T03:36:28.271253Z","shell.execute_reply.started":"2022-06-01T03:36:26.789011Z","shell.execute_reply":"2022-06-01T03:36:28.270155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Parameters\nis_debug = False\nthreshold = 2\nnum_neighbors = 20\nSEED = 2022\nrecall_columns = ['name', 'address', 'categories', 'address', 'phone']","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:28.272896Z","iopub.execute_input":"2022-06-01T03:36:28.273262Z","iopub.status.idle":"2022-06-01T03:36:28.278713Z","shell.execute_reply.started":"2022-06-01T03:36:28.27323Z","shell.execute_reply":"2022-06-01T03:36:28.27722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_simple(df, threshold):\n    val2id_d = {}\n    for col in recall_columns:\n        temp_df = df[['id', col]]\n        temp_df[col] = temp_df[col].str.lower()\n        val2id = temp_df.groupby(col)['id'].apply(set).to_dict()\n        val2id_d[col] = val2id\n        del val2id\n    \n    cus_ids = []\n    match_ids = []\n    for vals in tqdm(df[recall_columns + ['id']].fillna('null').values):\n        cus_id = vals[-1]\n        match_id = []\n        \n        rec_match_count = []\n        for i in range(len(recall_columns)):\n            col = recall_columns[i]\n            \n            if vals[i] != 'null':\n                rec_match_count += list(val2id_d[col][vals[i].lower()])\n        rec_match_count = dict(Counter(rec_match_count))\n        \n        for k, v in rec_match_count.items():\n            if v > threshold:\n                match_id.append(k)\n        \n        cus_ids += [cus_id] * len(match_id)\n        match_ids += match_id\n    \n    train_df = pd.DataFrame()\n    train_df['id'] = cus_ids\n    train_df['match_id'] = match_ids\n    train_df = train_df.drop_duplicates()\n    del cus_ids, match_ids\n    \n    num_data = len(train_df)\n    num_data_per_id = num_data / train_df['id'].nunique()\n    print('Num of data: %s' % num_data)\n    print('Num of data per id: %s' % num_data_per_id)\n    \n    return train_df","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:28.280313Z","iopub.execute_input":"2022-06-01T03:36:28.280988Z","iopub.status.idle":"2022-06-01T03:36:28.295515Z","shell.execute_reply.started":"2022-06-01T03:36:28.28094Z","shell.execute_reply":"2022-06-01T03:36:28.2946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recall_knn(df, Neighbors = 10):\n    print('Start knn grouped by country')\n    train_df_country = []\n    for country, country_df in tqdm(df.groupby('country')):\n        country_df = country_df.reset_index(drop = True)\n\n        neighbors = min(len(country_df), Neighbors)\n        knn = KNeighborsRegressor(n_neighbors = neighbors,\n                                    metric = 'haversine',\n                                    n_jobs = -1)\n        knn.fit(country_df[['latitude','longitude']], country_df.index)\n        dists, nears = knn.kneighbors(country_df[['latitude', 'longitude']], \n                                        return_distance = True)\n\n        for k in range(neighbors):            \n            cur_df = country_df[['id']]\n            cur_df['match_id'] = country_df['id'].values[nears[:, k]]\n            cur_df['kdist_country'] = dists[:, k]\n            cur_df['kneighbors_country'] = k\n            \n            train_df_country.append(cur_df)\n    train_df_country = pd.concat(train_df_country)\n    \n    print('Start knn')\n    train_df = []\n    knn = NearestNeighbors(n_neighbors = Neighbors)\n    knn.fit(df[['latitude','longitude']], df.index)\n    dists, nears = knn.kneighbors(df[['latitude','longitude']])\n    \n    for k in range(Neighbors):            \n        cur_df = df[['id']]\n        cur_df['match_id'] = df['id'].values[nears[:, k]]\n        cur_df['kdist'] = dists[:, k]\n        cur_df['kneighbors'] = k\n        train_df.append(cur_df)\n    \n    train_df = pd.concat(train_df)\n    train_df = train_df.merge(train_df_country,\n                                 on = ['id', 'match_id'],\n                                 how = 'outer')\n    del train_df_country\n    \n    return train_df","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:28.297353Z","iopub.execute_input":"2022-06-01T03:36:28.297905Z","iopub.status.idle":"2022-06-01T03:36:28.31263Z","shell.execute_reply.started":"2022-06-01T03:36:28.297858Z","shell.execute_reply":"2022-06-01T03:36:28.311821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_id2poi(input_df: pd.DataFrame) -> dict:\n    return dict(zip(input_df['id'], input_df['point_of_interest']))\n\ndef get_poi2ids(input_df: pd.DataFrame) -> dict:\n    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n\ndef get_score(input_df: pd.DataFrame):\n    scores = []\n    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n        targets = poi2ids[id2poi[id_str]]\n        preds = set(matches.split())\n        score = len((targets & preds)) / len((targets | preds))\n        scores.append(score)\n    scores = np.array(scores)\n    return scores.mean()\n\ndef analysis(df):\n    print('Num of data: %s' % len(df))\n    print('Num of unique id: %s' % df['id'].nunique())\n    print('Num of unique poi: %s' % df['point_of_interest'].nunique())\n    \n    poi_grouped = df.groupby('point_of_interest')['id'].count().reset_index()\n    print('Mean num of unique poi: %s' % poi_grouped['id'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:28.313741Z","iopub.execute_input":"2022-06-01T03:36:28.314351Z","iopub.status.idle":"2022-06-01T03:36:28.329884Z","shell.execute_reply.started":"2022-06-01T03:36:28.314315Z","shell.execute_reply":"2022-06-01T03:36:28.328714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Data load\ndata_root = '../input/foursquare-location-matching'\ndata = pd.read_csv(os.path.join(data_root, 'train.csv'))\n\nif is_debug:\n    data = data.sample(n = 1000, random_state = SEED)\n    data = data.reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:28.331091Z","iopub.execute_input":"2022-06-01T03:36:28.331863Z","iopub.status.idle":"2022-06-01T03:36:37.788423Z","shell.execute_reply.started":"2022-06-01T03:36:28.331827Z","shell.execute_reply":"2022-06-01T03:36:37.787472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Data split\nkf = GroupKFold(n_splits=2)\nfor i, (trn_idx, val_idx) in enumerate(kf.split(data, \n                                                data['point_of_interest'], \n                                                data['point_of_interest'])):\n    data.loc[val_idx, 'set'] = i\n\nprint('Num of train data: %s' % len(data))\nprint(data['set'].value_counts())\n\nvalid_data = data[data['set'] == 0]\ntrain_data = data[data['set'] == 1]\n\nprint('Train data: ')\nanalysis(train_data)\nprint('Valid data: ')\nanalysis(valid_data)\n\ntrain_poi = train_data['point_of_interest'].unique().tolist()\nvalid_poi = valid_data['point_of_interest'].unique().tolist()\n\nprint(set(train_poi) & set(valid_poi))\n\ntrain_ids = train_data['id'].unique().tolist()\nvalid_ids = valid_data['id'].unique().tolist()\n      \nprint(set(train_ids) & set(valid_ids))\n      \ntv_ids_d = {}\ntv_ids_d['train_ids'] = train_ids\ntv_ids_d['valid_ids'] = valid_ids\n\nnp.save('tv_ids_d.npy', tv_ids_d)\n\ndel train_data, valid_data\ngc.collect()\n\ndata = data.set_index('id')\ndata = data.loc[tv_ids_d['train_ids']]\ndata = data.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:37.789869Z","iopub.execute_input":"2022-06-01T03:36:37.790303Z","iopub.status.idle":"2022-06-01T03:36:37.955437Z","shell.execute_reply.started":"2022-06-01T03:36:37.790262Z","shell.execute_reply":"2022-06-01T03:36:37.954469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Simple recall & knn recall\ntrain_data_simple = recall_simple(data, threshold)\ntrain_data = recall_knn(data, num_neighbors)\n\nprint('train data by knn: %s' % len(train_data))\ntrain_data = train_data.merge(train_data_simple,\n                             on = ['id', 'match_id'],\n                             how = 'outer')\ndel train_data_simple\ngc.collect()\n\ndata = data.set_index('id')\nids = train_data['id'].tolist()\nmatch_ids = train_data['match_id'].tolist()\n\npoi = data.loc[ids]['point_of_interest'].values\nmatch_poi = data.loc[match_ids]['point_of_interest'].values\n\ntrain_data['label'] = np.array(poi == match_poi, dtype = np.int8)\ndel poi, match_poi, ids, match_ids\ngc.collect()\n\nprint('Num of unique id: %s' % train_data['id'].nunique())\nprint('Num of train data: %s' % len(train_data))\nprint('Pos rate: %s' % train_data['label'].mean())\nprint(train_data.sample(5))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:37.956612Z","iopub.execute_input":"2022-06-01T03:36:37.95712Z","iopub.status.idle":"2022-06-01T03:36:44.803375Z","shell.execute_reply.started":"2022-06-01T03:36:37.957083Z","shell.execute_reply":"2022-06-01T03:36:44.802331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Eval\ndata = data.reset_index()\n\nid2poi = get_id2poi(data)\npoi2ids = get_poi2ids(data)\n\neval_df = pd.DataFrame()\neval_df['id'] = data['id'].unique().tolist()\neval_df['match_id'] = eval_df['id']\nprint('Unique id: %s' % len(eval_df))\n\neval_df_ = train_data[train_data['label'] == 1][['id', 'match_id']]\neval_df = pd.concat([eval_df, eval_df_])\n\neval_df = eval_df.groupby('id')['match_id'].\\\n                        apply(list).reset_index()\neval_df['matches'] = eval_df['match_id'].apply(lambda x: ' '.join(set(x)))\nprint('Unique id: %s' % len(eval_df))\n\niou_score = get_score(eval_df)\nprint('IoU score: %s' % iou_score)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:36:44.804791Z","iopub.execute_input":"2022-06-01T03:36:44.805167Z","iopub.status.idle":"2022-06-01T03:36:44.851682Z","shell.execute_reply.started":"2022-06-01T03:36:44.805138Z","shell.execute_reply":"2022-06-01T03:36:44.850622Z"},"trusted":true},"execution_count":null,"outputs":[]}]}