{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook shows how to solve the problem as a multi-class classification by finding candidate points based on geographic location.<br>\nSimilarity as a string, such as edit distance and LCS (Longest Common Subsequence), was used for the features of the candidate points.<br>\n<br>\nInference is made on test data only, but the code for training is left commented out.<br>\n<br>\nIn addition, making the matches bidirectional as a post-processing step improved the score by about 1%.<br>\n<br>","metadata":{}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"pouTaX_llCrb","outputId":"c050ef25-9133-4c86-a9fa-f0b76527faac","execution":{"iopub.status.busy":"2022-04-21T16:21:27.495032Z","iopub.execute_input":"2022-04-21T16:21:27.49541Z","iopub.status.idle":"2022-04-21T16:21:27.515777Z","shell.execute_reply.started":"2022-04-21T16:21:27.495312Z","shell.execute_reply":"2022-04-21T16:21:27.515104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport os\nimport gc\nimport random\nfrom glob import glob\nfrom sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\nimport warnings\nimport seaborn as sns\nimport pickle\nimport json\nimport re\nimport time\nimport sys\nfrom requests import get\nimport multiprocessing\nimport joblib\n\nclass CFG:\n    seed = 46\n    target = \"point_of_interest\"\n    n_neighbors = 10\n    n_splits = 3\n\n    expID = \"\"\n    if \"google.colab\" in sys.modules:\n        expID = get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"].split(\".\")[0]\n\nrandom.seed(CFG.seed)\nos.environ[\"PYTHONHASHSEED\"] = str(CFG.seed)\nnp.random.seed(CFG.seed)\n\nplt.rcParams[\"font.size\"] = 13\nwarnings.filterwarnings('ignore')\n\n# %cd /content/drive/MyDrive/kaggle/foursquare-location-matching/{CFG.expID}","metadata":{"id":"H5QntWoelAkH","outputId":"31efe7df-24ff-40e8-8517-0c7174968413","execution":{"iopub.status.busy":"2022-04-21T16:21:27.517018Z","iopub.execute_input":"2022-04-21T16:21:27.517484Z","iopub.status.idle":"2022-04-21T16:21:28.861521Z","shell.execute_reply.started":"2022-04-21T16:21:27.517451Z","shell.execute_reply":"2022-04-21T16:21:28.86058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/foursquare-location-matching/train.csv\")\ntest = pd.read_csv(\"../input/foursquare-location-matching/test.csv\")\ntest[CFG.target] = \"TEST\"\n\ntrain.head(1)","metadata":{"id":"wz7JepVilAkN","outputId":"0652de28-9bd3-4ab7-c97c-55e6e11935e6","execution":{"iopub.status.busy":"2022-04-21T16:21:28.86311Z","iopub.execute_input":"2022-04-21T16:21:28.86332Z","iopub.status.idle":"2022-04-21T16:21:37.717549Z","shell.execute_reply.started":"2022-04-21T16:21:28.863294Z","shell.execute_reply":"2022-04-21T16:21:37.716669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"WlMa35s33j-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Devide Train Data into about 600KÃ—2","metadata":{"id":"lO9c6tIe3j4B"}},{"cell_type":"code","source":"kf = GroupKFold(n_splits=2)\nfor i, (trn_idx, val_idx) in enumerate(kf.split(train, train[CFG.target], train[CFG.target])):\n    train.loc[val_idx, \"set\"] = i\ntrain[\"set\"].value_counts()","metadata":{"id":"U6PcXKsn3pcK","outputId":"948a4da0-23b5-4716-8a00-1afa3eb5a20b","execution":{"iopub.status.busy":"2022-04-21T16:21:37.718627Z","iopub.execute_input":"2022-04-21T16:21:37.718838Z","iopub.status.idle":"2022-04-21T16:21:44.527354Z","shell.execute_reply.started":"2022-04-21T16:21:37.718813Z","shell.execute_reply":"2022-04-21T16:21:44.526543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Ewfee-Td3pYM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Search Candidates","metadata":{"id":"9yJIRkRD3jr-"}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\n\ndef add_neighbor_features(df):\n    dfs = []\n    columns = ['id', 'name', 'address', 'city', 'state',\n           'zip', 'country', 'url', 'phone', 'categories']\n    for c in columns:\n        if c != \"id\":\n            df[c] = df[c].astype(str).str.lower()\n\n    for country, country_df in tqdm(df.groupby(\"country\")):\n        country_df = country_df.reset_index(drop=True)\n        \n        knn = KNeighborsRegressor(n_neighbors=min(len(country_df), CFG.n_neighbors), \n                                  metric='haversine', n_jobs=-1)\n        knn.fit(country_df[['latitude','longitude']], country_df.index)\n        dists, nears = knn.kneighbors(country_df[['latitude','longitude']], return_distance=True)\n\n        targets = country_df[CFG.target].values\n        for i in range(min(len(country_df), CFG.n_neighbors)):\n            country_df[f\"d_near_{i}\"] = dists[:, i]\n            country_df[f\"near_target_{i}\"] = targets[nears[:, i]]\n            for c in columns:\n                country_df[f\"near_{c}_{i}\"] = country_df[c].values[nears[:, i]]\n\n        for i in range(min(len(country_df), CFG.n_neighbors), CFG.n_neighbors):\n            country_df[f\"d_near_{i}\"] = np.nan\n            country_df[f\"near_target_{i}\"] = np.nan\n            for c in columns:\n                country_df[f\"near_{c}_{i}\"] = np.nan\n\n        dfs.append(country_df)\n    df = pd.concat(dfs).reset_index(drop=True)\n    return df\n\ntrain = pd.concat([\n    add_neighbor_features(train[train[\"set\"]==0]), \n    add_neighbor_features(train[train[\"set\"]==1]), \n])\ntest = add_neighbor_features(test)\n\ntrain.head(1)","metadata":{"id":"rsyHcuGDlAkO","outputId":"67bbd8fb-5f0b-4853-ffc3-3421212c1683","execution":{"iopub.status.busy":"2022-04-21T16:21:44.529239Z","iopub.execute_input":"2022-04-21T16:21:44.529482Z","iopub.status.idle":"2022-04-21T16:27:14.049714Z","shell.execute_reply.started":"2022-04-21T16:21:44.529453Z","shell.execute_reply":"2022-04-21T16:27:14.048826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"yEBSxd5ulAkQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Target","metadata":{"id":"LqqIg-885J3K"}},{"cell_type":"code","source":"for i in range(CFG.n_neighbors):\n    train.loc[train[CFG.target]==train[f\"near_target_{i}\"], \"target\"] = i\ntrain.head()","metadata":{"id":"ftbdH97klAkQ","outputId":"3a49dd42-203b-4117-8312-2e681ec41dd5","execution":{"iopub.status.busy":"2022-04-21T16:27:14.051312Z","iopub.execute_input":"2022-04-21T16:27:14.051942Z","iopub.status.idle":"2022-04-21T16:27:17.299613Z","shell.execute_reply.started":"2022-04-21T16:27:14.051896Z","shell.execute_reply":"2022-04-21T16:27:17.298779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(train[\"target\"], bins=sorted(train[\"target\"].unique()))\nplt.grid()\nplt.xlabel(\"target\")\nplt.show()","metadata":{"id":"-X97ptgolAkR","outputId":"5d2c9c77-d61d-43a3-93cb-baad6f917b01","execution":{"iopub.status.busy":"2022-04-21T16:27:17.300736Z","iopub.execute_input":"2022-04-21T16:27:17.300963Z","iopub.status.idle":"2022-04-21T16:27:17.573118Z","shell.execute_reply.started":"2022-04-21T16:27:17.300934Z","shell.execute_reply":"2022-04-21T16:27:17.572173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Maximum Score","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/columbia2131/foursquare-iou-metrics\ndef get_id2poi(input_df: pd.DataFrame) -> dict:\n    return dict(zip(input_df['id'], input_df['point_of_interest']))\n\ndef get_poi2ids(input_df: pd.DataFrame) -> dict:\n    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n\ndef get_score(input_df: pd.DataFrame):\n    scores = []\n    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n        targets = poi2ids[id2poi[id_str]]\n        preds = set(matches.split())\n        score = len((targets & preds)) / len((targets | preds))\n        scores.append(score)\n    scores = np.array(scores)\n    return scores.mean()\n\nid2poi = get_id2poi(train)\npoi2ids = get_poi2ids(train)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:32:17.073361Z","iopub.execute_input":"2022-04-21T16:32:17.073704Z","iopub.status.idle":"2022-04-21T16:32:38.071914Z","shell.execute_reply.started":"2022-04-21T16:32:17.073669Z","shell.execute_reply":"2022-04-21T16:32:38.070947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = []\n\ntrain[\"matches\"] = \"\"\nfor i in tqdm(range(CFG.n_neighbors)):\n    idx = train[CFG.target]==train[f\"near_target_{i}\"]\n    train.loc[idx, \"matches\"] += \" \" + train.loc[idx, f\"near_id_{i}\"]\n    scores.append(get_score(train))\ntrain[\"mathces\"] = None","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:32:38.073833Z","iopub.execute_input":"2022-04-21T16:32:38.074451Z","iopub.status.idle":"2022-04-21T16:33:15.942126Z","shell.execute_reply.started":"2022-04-21T16:32:38.074413Z","shell.execute_reply":"2022-04-21T16:33:15.941252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(8, 3), facecolor=\"white\")\nplt.plot(range(CFG.n_neighbors), scores, marker=\"o\")\nplt.grid()\nplt.xlabel(\"# of candidates\")\nplt.ylabel(\"Maximum Score\")\nplt.ylim([0.6, 1.0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:34:13.912797Z","iopub.execute_input":"2022-04-21T16:34:13.913117Z","iopub.status.idle":"2022-04-21T16:34:14.0871Z","shell.execute_reply.started":"2022-04-21T16:34:13.913065Z","shell.execute_reply":"2022-04-21T16:34:14.086266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:34:18.857787Z","iopub.execute_input":"2022-04-21T16:34:18.858898Z","iopub.status.idle":"2022-04-21T16:34:19.371699Z","shell.execute_reply.started":"2022-04-21T16:34:18.858839Z","shell.execute_reply":"2022-04-21T16:34:19.370732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"5T4Dky7pbVYD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{"id":"6k59Vk9d5Pmx"}},{"cell_type":"code","source":"if \"google.colab\" in sys.modules:\n    !pip install Levenshtein","metadata":{"id":"R8qeYtT4lAkR","outputId":"91b3848e-29ac-4e04-dff7-f13d4d81c06e","execution":{"iopub.status.busy":"2022-04-21T16:34:24.776701Z","iopub.execute_input":"2022-04-21T16:34:24.776976Z","iopub.status.idle":"2022-04-21T16:34:24.781497Z","shell.execute_reply.started":"2022-04-21T16:34:24.776948Z","shell.execute_reply":"2022-04-21T16:34:24.780697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext Cython","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:34:24.823062Z","iopub.execute_input":"2022-04-21T16:34:24.823916Z","iopub.status.idle":"2022-04-21T16:34:25.527507Z","shell.execute_reply.started":"2022-04-21T16:34:24.823868Z","shell.execute_reply":"2022-04-21T16:34:25.526742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%cython\ndef LCS(str S, str T):\n    cdef int i, j\n    cdef list dp = [[0] * (len(T) + 1) for _ in range(len(S) + 1)]\n    for i in range(len(S)):\n        for j in range(len(T)):\n            dp[i + 1][j + 1] = max(dp[i][j] + (S[i] == T[j]), dp[i + 1][j], dp[i][j + 1], dp[i + 1][j + 1])\n    return dp[len(S)][len(T)]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:34:25.528957Z","iopub.execute_input":"2022-04-21T16:34:25.529194Z","iopub.status.idle":"2022-04-21T16:34:27.023532Z","shell.execute_reply.started":"2022-04-21T16:34:25.529166Z","shell.execute_reply":"2022-04-21T16:34:27.022279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import Levenshtein\nimport difflib\n\ndef _add_distance_features(args):\n    _, df = args\n\n    columns = ['name', 'address', 'city', 'state',\n           'zip', 'country', 'url', 'phone', 'categories']\n\n    for i in tqdm(range(CFG.n_neighbors)):\n        for c in columns:\n            geshs = []\n            levens = []\n            jaros = []\n            lcss = []\n            for str1, str2 in df[[f\"near_{c}_0\", f\"near_{c}_{i}\"]].values.astype(str):\n                if str1==str1 and str2==str2:\n                    geshs.append(difflib.SequenceMatcher(None, str1, str2).ratio())\n                    levens.append(Levenshtein.distance(str1, str2))\n                    jaros.append(Levenshtein.jaro_winkler(str1, str2))\n                    lcss.append(LCS(str(str1), str(str2)))\n                else:\n                    geshs.append(-1)\n                    levens.append(-1)\n                    jaros.append(-1)\n            df[f\"near_{c}_{i}_gesh\"] = geshs\n            df[f\"near_{c}_{i}_leven\"] = levens\n            df[f\"near_{c}_{i}_jaro\"] = jaros\n            df[f\"near_{c}_{i}_lcs\"] = lcss\n            \n            if not c in ['country', \"phone\", \"zip\"]:\n                df[f\"near_{c}_{i}_len\"] = df[f\"near_{c}_{i}\"].astype(str).map(len)\n                df[f\"near_{c}_{i}_nleven\"] = df[f\"near_{c}_{i}_leven\"] / df[[f\"near_{c}_{i}_len\", f\"near_{c}_0_len\"]].max(axis=1)\n                df[f\"near_{c}_{i}_nlcsi\"] = df[f\"near_{c}_{i}_lcs\"] / df[f\"near_{c}_{i}_len\"]\n                df[f\"near_{c}_{i}_nlcs0\"] = df[f\"near_{c}_{i}_lcs\"] / df[f\"near_{c}_0_len\"]\n    return df\n\n\ndef add_distance_features(df):\n    processes = multiprocessing.cpu_count()\n    with multiprocessing.Pool(processes=processes) as pool:\n        dfs = pool.imap_unordered(_add_distance_features, df.groupby('country'))\n        dfs = tqdm(dfs)\n        dfs = list(dfs)\n    df = pd.concat(dfs)\n    return df\n\n# train = add_distance_features(train)\ntest = add_distance_features(test)","metadata":{"id":"elWgtrbalAkS","outputId":"f9e3d5d6-ff3c-4b66-c071-076318eebd59","execution":{"iopub.status.busy":"2022-04-21T16:34:27.027633Z","iopub.execute_input":"2022-04-21T16:34:27.027912Z","iopub.status.idle":"2022-04-21T16:34:28.161213Z","shell.execute_reply.started":"2022-04-21T16:34:27.027878Z","shell.execute_reply":"2022-04-21T16:34:28.160264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"bhspiCyx6sez"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Delete Unusing Columns (just for avoiding OOM)","metadata":{"id":"Q3HV5kfs6saZ"}},{"cell_type":"code","source":"features = []\n\ncolumns = ['name', 'address', 'city', 'state',\n       'zip', 'country', 'url', 'phone', 'categories']\nfor i in tqdm(range(CFG.n_neighbors)):\n    features.append(f\"d_near_{i}\")\n    for c in columns:        \n        features += [f\"near_{c}_{i}_gesh\", f\"near_{c}_{i}_jaro\", f\"near_{c}_{i}_lcs\"]\n        if c in ['country', \"phone\", \"zip\"]:\n            features += [f\"near_{c}_{i}_leven\"]\n        else:\n            features += [f\"near_{c}_{i}_len\", f\"near_{c}_{i}_nleven\", f\"near_{c}_{i}_nlcsi\", f\"near_{c}_{i}_nlcs0\"]\n\nfor f in features:\n#     assert f in train.columns\n    if f not in test.columns:\n        test[f] = np.nan\n\n# print(features)","metadata":{"id":"GHMG8t1UlAkT","outputId":"9c06b154-1276-4069-d21a-7c48907b98dc","execution":{"iopub.status.busy":"2022-04-21T16:34:28.163726Z","iopub.execute_input":"2022-04-21T16:34:28.16396Z","iopub.status.idle":"2022-04-21T16:34:28.204634Z","shell.execute_reply.started":"2022-04-21T16:34:28.163929Z","shell.execute_reply":"2022-04-21T16:34:28.203896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = train[features + [CFG.target, \"target\", \"id\"] + [f\"near_id_{i}\" for i in range(CFG.n_neighbors)]]\ntest = test[features + [\"id\"] + [f\"near_id_{i}\" for i in range(CFG.n_neighbors)]]\n\n# train[features] = train[features].astype(np.float16)\ntest[features] = test[features].astype(np.float16)\n\n# train[\"target\"] = train[\"target\"].fillna(0)\n\n# train.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)\n\nfor _ in range(5):\n    gc.collect()\n\n# train.info()","metadata":{"id":"aKSy9cc3lAkT","outputId":"4d1e8ccb-8d7f-454e-cb15-f1cb8693af74","execution":{"iopub.status.busy":"2022-04-21T16:34:28.205853Z","iopub.execute_input":"2022-04-21T16:34:28.206504Z","iopub.status.idle":"2022-04-21T16:34:30.519348Z","shell.execute_reply.started":"2022-04-21T16:34:28.20647Z","shell.execute_reply":"2022-04-21T16:34:30.518472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YD04E6__6zFx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Folds","metadata":{"id":"yduGPkpC6y4X"}},{"cell_type":"code","source":"# kf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n# for i, (trn_idx, val_idx) in tqdm(enumerate(kf.split(train, train[\"target\"], train[\"target\"]))):\n#     train.loc[val_idx, \"fold\"] = i","metadata":{"id":"7euwk2q7ly5Y","outputId":"1e1f8c10-0523-4a37-d1fc-9d350cc96ec5","execution":{"iopub.status.busy":"2022-04-21T16:34:30.520999Z","iopub.execute_input":"2022-04-21T16:34:30.521404Z","iopub.status.idle":"2022-04-21T16:34:30.525894Z","shell.execute_reply.started":"2022-04-21T16:34:30.521359Z","shell.execute_reply":"2022-04-21T16:34:30.525159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"V2vjM0At63Kn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Learning","metadata":{"id":"qknhwIvndmJ_"}},{"cell_type":"code","source":"import lightgbm as lgbm\n\ndef fit_lgbm(X, y, params=None, es_rounds=20, seed=42, N_SPLITS=5, \n             n_class=None, model_dir=None, folds=None):\n    models = []\n    oof = np.zeros((len(y), n_class), dtype=np.float64)\n    \n    for i in tqdm(range(CFG.n_splits)):\n        print(f\"== fold {i} ==\")\n        trn_idx = folds!=i\n        val_idx = folds==i\n        X_train, y_train = X[trn_idx], y.iloc[trn_idx]\n        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n\n        if model_dir is None:\n            model = lgbm.LGBMClassifier(**params)\n            model.fit(\n                X_train, y_train, \n                eval_set=[(X_valid, y_valid)],  \n                early_stopping_rounds=es_rounds, \n                eval_metric='logloss',  \n    #             verbose=-1)\n                verbose=50)\n        else:\n            with open(f'{model_dir}/lgbm_fold{i}.pkl', 'rb') as f:\n                model = pickle.load(f)\n            \n        pred = model.predict_proba(X_valid)\n        oof[val_idx] = pred\n        models.append(model)\n        \n        file = f'lgbm_fold{i}.pkl'\n        pickle.dump(model, open(file, 'wb'))\n        print()\n\n    cv = (oof.argmax(axis=-1) == y).mean()\n    print(f\"CV-accuracy: {cv}\")\n\n    return oof, models\n\ndef inference_lgbm(models, feat_df):\n    pred = np.array([model.predict_proba(feat_df) for model in models])\n    pred = np.mean(pred, axis=0)\n    return pred","metadata":{"id":"iLKg1PSWlAkU","execution":{"iopub.status.busy":"2022-04-21T16:34:30.527194Z","iopub.execute_input":"2022-04-21T16:34:30.527959Z","iopub.status.idle":"2022-04-21T16:34:31.501818Z","shell.execute_reply.started":"2022-04-21T16:34:30.527913Z","shell.execute_reply":"2022-04-21T16:34:31.500947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'objective': \"logloss\",\n    'learning_rate': 0.2,\n    'reg_alpha': 0.1,\n    'reg_lambda': 0.1,\n    'random_state': 42,\n\n    'max_depth': 7,   \n    'num_leaves': 35, \n    'n_estimators': 1000000, \n    \"colsample_bytree\": 0.9,\n}\n\n# oof, models = fit_lgbm(train[features], train[\"target\"].astype(int), \n#                        params=params, n_class=int(train[\"target\"].max() + 1), \n#                        N_SPLITS=CFG.n_splits, folds=train[\"fold\"].values)\n\nmodels = [joblib.load(f'../input/foursquare-exp009/lgbm_fold{i}.pkl') for i in range(CFG.n_splits)]\npred = inference_lgbm(models, test[features])","metadata":{"id":"y22l2kyLlAkV","outputId":"c284471a-0dd7-4d4b-aa98-82378d2f4b32","execution":{"iopub.status.busy":"2022-04-21T16:34:31.505478Z","iopub.execute_input":"2022-04-21T16:34:31.505731Z","iopub.status.idle":"2022-04-21T16:34:32.804059Z","shell.execute_reply.started":"2022-04-21T16:34:31.505701Z","shell.execute_reply":"2022-04-21T16:34:32.803367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"WmVW8BpjlAkW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check CV","metadata":{}},{"cell_type":"code","source":"# near_ids = train[[f\"near_id_{i}\" for i in range(CFG.n_neighbors)]].values\n\n# matches = []\n# for id, ps, ids in tqdm(zip(train[\"id\"], oof, near_ids)):\n#     idx = np.argmax(ps)\n#     if idx > 0 and ids[idx]==ids[idx]:\n#         matches.append(id + \" \" + ids[idx])\n#     else:\n#         matches.append(id)\n# train[\"matches\"] = matches\n# print(f\"CV: {get_score(train):.6f}\")","metadata":{"id":"yHFNkcnglAkW","outputId":"b886a788-4f08-468b-8050-17e92da005ca","execution":{"iopub.status.busy":"2022-04-21T16:34:32.808211Z","iopub.execute_input":"2022-04-21T16:34:32.808915Z","iopub.status.idle":"2022-04-21T16:34:32.815598Z","shell.execute_reply.started":"2022-04-21T16:34:32.808874Z","shell.execute_reply":"2022-04-21T16:34:32.814801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"near_ids = test[[f\"near_id_{i}\" for i in range(CFG.n_neighbors)]].values\n\nmatches = []\nfor id, ps, ids in tqdm(zip(test[\"id\"], pred, near_ids)):\n    idx = np.argmax(ps)\n    if idx > 0 and ids[idx]==ids[idx]:\n        matches.append(id + \" \" + ids[idx])\n    else:\n        matches.append(id)\ntest[\"matches\"] = matches","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:34:32.820542Z","iopub.execute_input":"2022-04-21T16:34:32.820791Z","iopub.status.idle":"2022-04-21T16:34:32.865216Z","shell.execute_reply.started":"2022-04-21T16:34:32.820762Z","shell.execute_reply":"2022-04-21T16:34:32.864327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Feature Importances","metadata":{}},{"cell_type":"code","source":"def plot_importances(models):\n    importance_df = pd.DataFrame(models[0].feature_importances_, \n                                 index=features, \n                                 columns=['importance'])\\\n                        .sort_values(\"importance\", ascending=False)\n\n    plt.subplots(figsize=(len(features) // 4, 5))\n    plt.bar(importance_df.index, importance_df.importance)\n    plt.grid()\n    plt.xticks(rotation=90)\n    plt.ylabel(\"importance\")\n    plt.tight_layout()\n    plt.show()\n\nplot_importances(models)","metadata":{"id":"o7YqLSXPlAkX","outputId":"11bfa4d9-e19a-4934-f3de-8dacf74f4a18","execution":{"iopub.status.busy":"2022-04-21T16:34:32.866729Z","iopub.execute_input":"2022-04-21T16:34:32.867593Z","iopub.status.idle":"2022-04-21T16:34:42.18874Z","shell.execute_reply.started":"2022-04-21T16:34:32.867549Z","shell.execute_reply":"2022-04-21T16:34:42.188056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple Post-Processing","metadata":{}},{"cell_type":"code","source":"def postprocess(df):\n    id2match = dict(zip(df[\"id\"].values, df[\"matches\"].str.split()))\n\n    for match in tqdm(df[\"matches\"]):\n        match = match.split()\n        if len(match) == 1:        \n            continue\n\n        base = match[0]\n        for m in match[1:]:\n            if not base in id2match[m]:\n                id2match[m].append(base)\n    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n    return df \n\n#train = postprocess(train)\ntest = postprocess(test)\n# print(f\"CV: {get_score(train):.6f}\")","metadata":{"id":"UffaiHGelAkW","execution":{"iopub.status.busy":"2022-04-21T16:34:42.189921Z","iopub.execute_input":"2022-04-21T16:34:42.190301Z","iopub.status.idle":"2022-04-21T16:34:42.235283Z","shell.execute_reply.started":"2022-04-21T16:34:42.19027Z","shell.execute_reply":"2022-04-21T16:34:42.234331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"ssub = pd.read_csv(\"../input/foursquare-location-matching/sample_submission.csv\")\nssub = ssub.drop(columns=\"matches\")\nssub = ssub.merge(test[[\"id\", \"matches\"]], on=\"id\")\nssub.to_csv(\"submission.csv\", index=False)\n\nssub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:34:42.236487Z","iopub.execute_input":"2022-04-21T16:34:42.236829Z","iopub.status.idle":"2022-04-21T16:34:42.272472Z","shell.execute_reply.started":"2022-04-21T16:34:42.236798Z","shell.execute_reply":"2022-04-21T16:34:42.271709Z"},"trusted":true},"execution_count":null,"outputs":[]}]}