{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello Fellow Kagglers,\n\nThis notebook demonstrates the feature engineering, training and inference process, all in one notebook!\n\nTraining takes ~2 hours and inference ~6, expect the submission to take roughly 8 hours.\n\nA binary approach is used, as in many other notebooks, where, for a pair of points, a match confidence is predicted.\n\nThis notebook uses dataset generated in the follow notebooks:\n\n1) [Foursquare 16M Train Pairs Generation](https://www.kaggle.com/code/markwijkhuizen/foursquare-16m-train-pairs-generation)\n2) [Foursquare USE/MPNET Name Embeddings](https://www.kaggle.com/code/markwijkhuizen/foursquare-use-mpnet-name-embeddings)\n\nFeel free to give tips and ask questions!","metadata":{}},{"cell_type":"code","source":"# Install Reverse Geocode Package to deduce Country/City from coordinates\n!pip install /kaggle/input/reversegeocode/reverse_geocode-1.4.1-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:18:03.030039Z","iopub.execute_input":"2022-06-10T12:18:03.030598Z","iopub.status.idle":"2022-06-10T12:18:34.620344Z","shell.execute_reply.started":"2022-06-10T12:18:03.030488Z","shell.execute_reply":"2022-06-10T12:18:34.619311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow_hub as hub\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nfrom tensorflow.keras import backend as K\nfrom Levenshtein import distance as lev\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom scipy.spatial import distance\nfrom sklearn import metrics\nfrom multiprocessing import cpu_count\nfrom sklearn.neighbors import BallTree\nfrom difflib import SequenceMatcher\n\nimport geopy.distance\nimport reverse_geocode\nimport math\nimport scipy\nimport numba\nimport warnings\nimport Levenshtein\nimport itertools\nimport gc\nimport psutil\nimport sys\nimport pickle\n\n# Pandas Apply With Progress Bar\ntqdm.pandas()\n\n# Plot DPI\nimport matplotlib as mpl\nmpl.rcParams['figure.dpi'] = 150\n\n# Tensorflow Version\nprint(f'Tensorflow version {tf.__version__}')\n\n# Ignore Warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:18:34.622732Z","iopub.execute_input":"2022-06-10T12:18:34.62356Z","iopub.status.idle":"2022-06-10T12:18:44.909298Z","shell.execute_reply.started":"2022-06-10T12:18:34.623512Z","shell.execute_reply":"2022-06-10T12:18:44.90819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Global Seed\nSEED = 42\n# Earth Radius in KM to compute Haversine Distance\nEARTH_RADIUS = 6371","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:18:44.910466Z","iopub.execute_input":"2022-06-10T12:18:44.91129Z","iopub.status.idle":"2022-06-10T12:18:44.916388Z","shell.execute_reply.started":"2022-06-10T12:18:44.911255Z","shell.execute_reply":"2022-06-10T12:18:44.915219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Train/Test Data","metadata":{}},{"cell_type":"code","source":"usecols = [\n    'id',\n    'name',\n    'latitude',\n    'longitude',\n    'address',\n    'city',\n    'state',\n    'zip',\n    'country',\n    'url',\n    'phone',\n    'categories',\n]","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:18:44.919424Z","iopub.execute_input":"2022-06-10T12:18:44.920132Z","iopub.status.idle":"2022-06-10T12:18:44.958094Z","shell.execute_reply.started":"2022-06-10T12:18:44.920085Z","shell.execute_reply":"2022-06-10T12:18:44.95712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Train\ntrain_dtype = {\n    'id': 'category',\n    'name': 'category',\n    'address': 'category',\n    'city': 'category',\n    'state': 'category',\n    'zip': 'category',\n    'country': 'category',\n    'url': 'category',\n    'phone': 'category',\n    'categories': 'category',\n    'latitude': np.float32,\n    'longitude': np.float32,\n}\ntrain = pd.read_csv('/kaggle/input/foursquare-location-matching/train.csv', dtype=train_dtype, usecols=usecols)\ntrain['id'] = train.index.values\ndisplay(train.info(memory_usage=True))\ndisplay(train.head())\ndisplay(train.memory_usage(deep=True) / len(train))\n\ntest = pd.read_csv('/kaggle/input/foursquare-location-matching/test.csv', dtype=train_dtype, usecols=usecols)\ndisplay(test.info())\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:18:44.959213Z","iopub.execute_input":"2022-06-10T12:18:44.960285Z","iopub.status.idle":"2022-06-10T12:19:07.000658Z","shell.execute_reply.started":"2022-06-10T12:18:44.960246Z","shell.execute_reply":"2022-06-10T12:19:06.999583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Pairs","metadata":{}},{"cell_type":"code","source":"# Pairs Datype\npairs_dtype = {\n    'id_1': 'category',\n    'id_2': 'category',\n    'name_1': 'category',\n    'name_2': 'category',\n    'address_1': 'category',\n    'address_1': 'category',\n    'city_1': 'category',\n    'city_2': 'category',\n    'state_1': 'category',\n    'state_2': 'category',\n    'zip_1': 'category',\n    'zip_2': 'category',\n    'country_1': 'category',\n    'country_2': 'category',\n    'url_1': 'category',\n    'url_2': 'category',\n    'phone_1': 'category',\n    'phone_2': 'category',\n    'categories_1': 'category',\n    'categories_2': 'category',\n    'latitude_1': np.float32,\n    'longitude_1': np.float32,\n    'latitude_2': np.float32,\n    'longitude_2': np.float32,\n}\npd.options.display.max_rows = 99\npd.options.display.max_columns = 99\n\npairs_sample = pd.read_csv('/kaggle/input/foursquare-location-matching/pairs.csv', dtype=pairs_dtype, skiprows=lambda idx: idx > 5)\ndisplay(pairs_sample.info())\ndisplay(pairs_sample.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:07.002162Z","iopub.execute_input":"2022-06-10T12:19:07.00252Z","iopub.status.idle":"2022-06-10T12:19:10.768564Z","shell.execute_reply.started":"2022-06-10T12:19:07.002487Z","shell.execute_reply":"2022-06-10T12:19:10.767428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Sample Submission","metadata":{}},{"cell_type":"code","source":"# Sample Submission\nsample_submission = pd.read_csv('/kaggle/input/foursquare-location-matching/sample_submission.csv')\ndisplay(sample_submission.info())\ndisplay(sample_submission.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:10.77044Z","iopub.execute_input":"2022-06-10T12:19:10.770786Z","iopub.status.idle":"2022-06-10T12:19:10.797036Z","shell.execute_reply.started":"2022-06-10T12:19:10.770755Z","shell.execute_reply":"2022-06-10T12:19:10.795918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# To Lower","metadata":{}},{"cell_type":"code","source":"# Convert String columns to lower case to make features case agnostic\nto_lower_columns = [\n    'name',\n    'state',\n    'country',\n    'city',\n    'address',\n    'zip',\n    'phone',\n    'url',\n    'categories',\n]\n\ndef to_lower(df):\n    f = lambda v: '' if v == 'NaN' else v.lower()\n    for col in to_lower_columns:\n        if f'{col}_1' in df and f'{col}_2' in df:\n            df[f'{col}_1'] = df[f'{col}_1'].astype(str, copy=False).str.lower().replace('nan', '').astype('category')\n            df[f'{col}_2'] = df[f'{col}_2'].astype(str, copy=False).str.lower().replace('nan', '').astype('category')\n        else:\n            df[col] = df[col].astype(str, copy=False).str.lower().replace('nan', '').astype('category')\n            \nto_lower(train)\nto_lower(pairs_sample)\nto_lower(test)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:10.798163Z","iopub.execute_input":"2022-06-10T12:19:10.798776Z","iopub.status.idle":"2022-06-10T12:19:27.379322Z","shell.execute_reply.started":"2022-06-10T12:19:10.798735Z","shell.execute_reply":"2022-06-10T12:19:27.378251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:27.380542Z","iopub.execute_input":"2022-06-10T12:19:27.381238Z","iopub.status.idle":"2022-06-10T12:19:27.399669Z","shell.execute_reply.started":"2022-06-10T12:19:27.381204Z","shell.execute_reply":"2022-06-10T12:19:27.398654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(pairs_sample.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:27.401878Z","iopub.execute_input":"2022-06-10T12:19:27.40254Z","iopub.status.idle":"2022-06-10T12:19:27.431511Z","shell.execute_reply.started":"2022-06-10T12:19:27.402506Z","shell.execute_reply":"2022-06-10T12:19:27.43058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:27.432803Z","iopub.execute_input":"2022-06-10T12:19:27.433699Z","iopub.status.idle":"2022-06-10T12:19:27.458528Z","shell.execute_reply.started":"2022-06-10T12:19:27.433664Z","shell.execute_reply":"2022-06-10T12:19:27.457391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Pairs generated in other notebook\npairs = pd.read_pickle('/kaggle/input/foursquare-16m-train-pairs-generation-dataset/pairs.pkl')\n\n# Display Memory Usage\ndisplay(pairs.memory_usage(deep=True) / len(pairs))\n\n# Display Pairs Data\ndisplay(pairs.head(25))\ndisplay(pairs.info())\n\n# Display Positive/Negative Sample Ratio's\ndisplay(pairs['match'].value_counts(normalize=True).to_frame())\n\n# Unique Names\ndisplay(pairs[['name_1', 'name_2']].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:27.460052Z","iopub.execute_input":"2022-06-10T12:19:27.460658Z","iopub.status.idle":"2022-06-10T12:19:48.173461Z","shell.execute_reply.started":"2022-06-10T12:19:27.460614Z","shell.execute_reply":"2022-06-10T12:19:48.171946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Explorative Data Analysis","metadata":{}},{"cell_type":"code","source":"# Latitude\ntrain[['latitude', 'longitude']].plot(kind='hist', bins=32, alpha=0.50)\nplt.title('Latitude and Longitude Distribution', size=24)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:48.175295Z","iopub.execute_input":"2022-06-10T12:19:48.175723Z","iopub.status.idle":"2022-06-10T12:19:48.930001Z","shell.execute_reply.started":"2022-06-10T12:19:48.17569Z","shell.execute_reply":"2022-06-10T12:19:48.928936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Most common names are fast food restaurants\nprint(f'Unique Names in Train: {train[\"name\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring Names =====')\ndisplay(train['name'].value_counts(dropna=False, normalize=True).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:48.93141Z","iopub.execute_input":"2022-06-10T12:19:48.931782Z","iopub.status.idle":"2022-06-10T12:19:49.301483Z","shell.execute_reply.started":"2022-06-10T12:19:48.931748Z","shell.execute_reply":"2022-06-10T12:19:49.300377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cities are really all over the world and, most importantly, sometimes spelled in their native language\n# санкт-петербург: Saint Petersburg\nprint(f'Unique Cities in Train: {train[\"city\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring Cities =====')\ndisplay(train['city'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:49.303143Z","iopub.execute_input":"2022-06-10T12:19:49.303577Z","iopub.status.idle":"2022-06-10T12:19:49.350834Z","shell.execute_reply.started":"2022-06-10T12:19:49.303535Z","shell.execute_reply":"2022-06-10T12:19:49.349887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 420K states are empty\nprint(f'Unique States in Train: {train[\"state\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring States =====')\ndisplay(train['state'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:49.352219Z","iopub.execute_input":"2022-06-10T12:19:49.352576Z","iopub.status.idle":"2022-06-10T12:19:49.385149Z","shell.execute_reply.started":"2022-06-10T12:19:49.352545Z","shell.execute_reply":"2022-06-10T12:19:49.384312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Over half of the zip codes are missing\nprint(f'Unique Zip Codes in Train: {train[\"zip\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring Zip Codes =====')\ndisplay(train['zip'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:49.386197Z","iopub.execute_input":"2022-06-10T12:19:49.387224Z","iopub.status.idle":"2022-06-10T12:19:49.450306Z","shell.execute_reply.started":"2022-06-10T12:19:49.387132Z","shell.execute_reply":"2022-06-10T12:19:49.44915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Close to a quarter of the point are located in the US\nprint(f'Unique States in Countries: {train[\"country\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring Countries =====')\ndisplay(train['country'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:49.45188Z","iopub.execute_input":"2022-06-10T12:19:49.452618Z","iopub.status.idle":"2022-06-10T12:19:49.480277Z","shell.execute_reply.started":"2022-06-10T12:19:49.452571Z","shell.execute_reply":"2022-06-10T12:19:49.478902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# URLS are rare, over 75% is missing\nprint(f'Unique URLs in Train: {train[\"url\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring URLs =====')\ndisplay(train['url'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:49.48227Z","iopub.execute_input":"2022-06-10T12:19:49.483106Z","iopub.status.idle":"2022-06-10T12:19:49.573857Z","shell.execute_reply.started":"2022-06-10T12:19:49.483057Z","shell.execute_reply":"2022-06-10T12:19:49.572654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Phone is also missing in ~75% of the cases, not a good feature\nprint(f'Unique Phone Numbers in Train: {train[\"phone\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring Phone Numbers =====')\ndisplay(train['phone'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:49.575363Z","iopub.execute_input":"2022-06-10T12:19:49.575745Z","iopub.status.idle":"2022-06-10T12:19:49.724408Z","shell.execute_reply.started":"2022-06-10T12:19:49.575702Z","shell.execute_reply":"2022-06-10T12:19:49.723241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categories are varying from cafes and hotel to offices and banks\nprint(f'Unique Categories in Train: {train[\"categories\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring Categories =====')\ndisplay(train['categories'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:49.725683Z","iopub.execute_input":"2022-06-10T12:19:49.726097Z","iopub.status.idle":"2022-06-10T12:19:49.775694Z","shell.execute_reply.started":"2022-06-10T12:19:49.726067Z","shell.execute_reply":"2022-06-10T12:19:49.774629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Haversine Distance","metadata":{}},{"cell_type":"code","source":"# Numba optimized haversine distance\n@numba.jit(nopython=True)\ndef haversine_np(args):\n    lon1, lat1, lon2, lat2 = args\n    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n\n    c = 2 * np.arcsin(np.sqrt(a))\n    km = EARTH_RADIUS * c\n    return km","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:49.776628Z","iopub.execute_input":"2022-06-10T12:19:49.777043Z","iopub.status.idle":"2022-06-10T12:19:50.160597Z","shell.execute_reply.started":"2022-06-10T12:19:49.777014Z","shell.execute_reply":"2022-06-10T12:19:50.159639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Country Code\n\n[Reverse Geocode](https://pypi.org/project/reverse-geocode/) package is used to deduce missing country and city based on coordinates","metadata":{}},{"cell_type":"code","source":"def get_country_codes(coords):\n    data = reverse_geocode.search(coords)\n    return [v['country_code'] for v in data]\n\ntrain['country_code'] = get_country_codes(train[['latitude', 'longitude']])\n\npairs['country_code_1'] = get_country_codes(pairs[['latitude_1', 'longitude_1']])\npairs['country_code_2'] = get_country_codes(pairs[['latitude_2', 'longitude_2']])\n\nprint(f'Unique Country Code 1 in Pairs: {pairs[\"country_code_1\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring Country Codes 1 =====')\ndisplay(pairs['country_code_1'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:50.161983Z","iopub.execute_input":"2022-06-10T12:19:50.162929Z","iopub.status.idle":"2022-06-10T12:19:54.438159Z","shell.execute_reply.started":"2022-06-10T12:19:50.162891Z","shell.execute_reply":"2022-06-10T12:19:54.43711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# City","metadata":{}},{"cell_type":"code","source":"def get_cities(coords):\n    data = reverse_geocode.search(coords)\n    return [v['city'] for v in data]\n\ntrain['city_rg'] = get_cities(train[['latitude', 'longitude']])\n    \npairs['city_rg_1'] = get_cities(pairs[['latitude_1', 'longitude_1']])\npairs['city_rg_2'] = get_cities(pairs[['latitude_2', 'longitude_2']])\n\nprint(f'Unique City Reverse Geocode 1 in Pairs: {pairs[\"city_rg_1\"].nunique()}\\n')\nprint('===== Top 10 Most Occuring City Reverse Geocode 1 =====')\ndisplay(pairs['city_rg_1'].value_counts(dropna=False).head(10))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:54.439344Z","iopub.execute_input":"2022-06-10T12:19:54.439708Z","iopub.status.idle":"2022-06-10T12:19:58.051162Z","shell.execute_reply.started":"2022-06-10T12:19:54.439669Z","shell.execute_reply":"2022-06-10T12:19:58.050047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Ordinal Encoding\n\nTo prevent overfitting on categorical columns the ordinal encoding takes the N most common categories and puts all other categories in an \"others\" category. Otherwise there would be many categories with just a handfull of samples, which almost guarantees overfitting.","metadata":{}},{"cell_type":"code","source":"columns_ordinal = [\n    'name',\n    'state',\n    'country',\n    'country_code',\n    'city',\n    'city_rg',\n    'address',\n    'zip',\n    'url',\n]\n\ncat2ord_dict_dicts = dict()\nTOP_K = {\n    'name': 2048,\n    'state': 2048,\n    'country': 1024,\n    'country_code': 1024,\n    'city': 2048,\n    'city_rg': 1024,\n    'address': 1024,\n    'zip': 1024,\n    'phone': 1024,\n    'url': 1024,\n}\nfor col in tqdm(columns_ordinal):\n    n_categories = train[col].nunique()\n    cat_codes = train[col].astype('category').cat.codes\n    if n_categories < TOP_K[col]:\n        train[f'{col}_ordinal'] = cat_codes\n    else:\n        # Ordinal Encoding + 1 for \"Others\" category\n        train[f'{col}_ordinal'] = cat_codes + 1\n    \n        # Category Population Count\n        train[f'{col}_count'] = train[col].apply(train[col].value_counts().get).astype(np.float32)\n        # Set all categories with less than top 1000 population count to 0 \"Others\" category\n        top_k_count = train[col].value_counts()[TOP_K[col] - 1 if cat_codes.max() >= TOP_K[col] else -1]\n        train.loc[train[f'{col}_count'] <= top_k_count, f'{col}_ordinal'] = 0\n        train[f'{col}_ordinal'] = train[f'{col}_ordinal'].astype('category').cat.codes\n    \n    # Make Cateogry to Ordinal Dictionary\n    cat2ord_dict_dicts[col] = train[[col, f'{col}_ordinal']].set_index(col).squeeze().to_dict()\n    n_unique = train[f'{col}_ordinal'].nunique()\n    cat2ord_dict_dicts[f'{col}_count'] = n_unique\n    print(f'{col} has {n_unique} categories, max: {train[col].nunique()}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:19:58.052864Z","iopub.execute_input":"2022-06-10T12:19:58.053641Z","iopub.status.idle":"2022-06-10T12:20:25.203357Z","shell.execute_reply.started":"2022-06-10T12:19:58.05359Z","shell.execute_reply":"2022-06-10T12:20:25.202069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adds ordinal features\ndef add_ordinal_features(df):\n    for col in tqdm(columns_ordinal):\n        df[f'{col}_1_ordinal'] = df[f'{col}_1'].apply(cat2ord_dict_dicts[col].get).astype(np.float32, copy=False).fillna(-1).astype(np.int16, copy=False) + 1\n        df[f'{col}_2_ordinal'] = df[f'{col}_2'].apply(cat2ord_dict_dicts[col].get).astype(np.float32, copy=False).fillna(-1).astype(np.int16, copy=False) + 1","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:20:25.204788Z","iopub.execute_input":"2022-06-10T12:20:25.205255Z","iopub.status.idle":"2022-06-10T12:20:25.214373Z","shell.execute_reply.started":"2022-06-10T12:20:25.20521Z","shell.execute_reply":"2022-06-10T12:20:25.213138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split Categories And Ordinal Encode","metadata":{}},{"cell_type":"code","source":"# Set with all unique categories\nCATEGORIES = set()\n\nfor cats in tqdm(train['categories'].str.split(', ')):\n    if type(cats) is list:\n        for c in cats:\n                CATEGORIES.add(c)\n\nCATEGORIES_LIST_VALID = np.array(list(CATEGORIES))\n# Add the empty category, as some categories are missing\nCATEGORIES_LIST = np.sort(['AAA_empty'] + list(CATEGORIES)).tolist()\nCATEGORIES = pd.Series(index=CATEGORIES_LIST, data=np.arange(len(CATEGORIES_LIST)))\n# Number of Categories, \"+1\" for NaN\nN_CATEGORIES = CATEGORIES.size + 1\nN_CATEGORIES_VALID = CATEGORIES_LIST_VALID.size\nCAT2ORD_DICT = CATEGORIES.to_dict()\nprint(f'N_CATEGORIES: {N_CATEGORIES}, N_CATEGORIES_VALID: {N_CATEGORIES_VALID}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:20:25.215929Z","iopub.execute_input":"2022-06-10T12:20:25.21648Z","iopub.status.idle":"2022-06-10T12:20:26.332364Z","shell.execute_reply.started":"2022-06-10T12:20:25.216435Z","shell.execute_reply":"2022-06-10T12:20:26.331181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_categories_features(df):\n    def get_categories_ordinal(categories, idx):\n        # For missing categories, return 0\n        if type(categories) is not str:\n            return 0\n        else:\n            # Split categories on comma\n            l = np.sort(categories.split(', '))\n            # If index of category is larger than number of categories, return 0\n            if idx >= len(l):\n                return 0\n            else:\n                # Check if category is in categories dictionary, to prevent keyerror for new categories\n                if l[idx] in CAT2ORD_DICT:\n                    return CAT2ORD_DICT.get(l[idx]) + 1\n                # if category is unknown, return 0\n                else:\n                    return 0\n\n    # Ordinal encode first 3 categories\n    for i in tqdm(range(3)):\n        df[f'categories{i}_1_ordinal'] = df[f'categories_1'].apply(get_categories_ordinal, idx=i).astype(np.int16)\n        df[f'categories{i}_2_ordinal'] = df[f'categories_2'].apply(get_categories_ordinal, idx=i).astype(np.int16)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:20:26.370402Z","iopub.execute_input":"2022-06-10T12:20:26.370839Z","iopub.status.idle":"2022-06-10T12:20:26.379173Z","shell.execute_reply.started":"2022-06-10T12:20:26.370788Z","shell.execute_reply":"2022-06-10T12:20:26.37793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stand alone features are computed for a single point and not as relation between pairs\ndef add_stand_alone_features(df):\n    print('===== Ordinal Features =====')\n    add_ordinal_features(df)\n    add_categories_features(df)\n    \n# Add all features to the pairs DataFrame\nadd_stand_alone_features(pairs)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:20:26.381098Z","iopub.execute_input":"2022-06-10T12:20:26.381613Z","iopub.status.idle":"2022-06-10T12:20:31.895031Z","shell.execute_reply.started":"2022-06-10T12:20:26.381569Z","shell.execute_reply":"2022-06-10T12:20:31.89385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show NaN ratio's for categories\nfor i in range(3):\n    nan_ratio_1 = np.mean(pairs[f'categories{i}_1_ordinal'] == 0) * 100\n    nan_ratio_2 = np.mean(pairs[f'categories{i}_2_ordinal'] == 0) * 100\n    print(f'{i} | NaN ratio 1: {nan_ratio_1:.1f}%, NaN ratio 2: {nan_ratio_2:.1f}%')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:20:31.896583Z","iopub.execute_input":"2022-06-10T12:20:31.897124Z","iopub.status.idle":"2022-06-10T12:20:31.912254Z","shell.execute_reply.started":"2022-06-10T12:20:31.897081Z","shell.execute_reply":"2022-06-10T12:20:31.910935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Category Embedding","metadata":{}},{"cell_type":"code","source":"# Universal Sentence Encoder for English words used to embed categories\ndef get_categories_embedding():\n    embed = hub.load('/kaggle/input/universalsentenceencoderlarge/universal-sentence-encoder-large_5')\n    \n    EMBEDDING_SIZE = 512\n    CATEGORIES_EMBEDDING = np.zeros(shape=[N_CATEGORIES_VALID, EMBEDDING_SIZE], dtype=np.float32)\n\n    for cat_idx, cat in enumerate(tqdm(CATEGORIES_LIST_VALID)):\n        CATEGORIES_EMBEDDING[cat_idx] = embed([cat])\n        \n    return CATEGORIES_EMBEDDING","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:20:31.913418Z","iopub.execute_input":"2022-06-10T12:20:31.913735Z","iopub.status.idle":"2022-06-10T12:20:31.922977Z","shell.execute_reply.started":"2022-06-10T12:20:31.913699Z","shell.execute_reply":"2022-06-10T12:20:31.921981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cosine_similarity(a, b):\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:20:31.924556Z","iopub.execute_input":"2022-06-10T12:20:31.925403Z","iopub.status.idle":"2022-06-10T12:20:31.937235Z","shell.execute_reply.started":"2022-06-10T12:20:31.925349Z","shell.execute_reply":"2022-06-10T12:20:31.936206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embeddings of Categories\nCATEGORIES_EMBEDDING = get_categories_embedding()\n\n# Create Cosine Similarity Matrix\nEMBEDDING_DISTANCE = np.full(shape=[N_CATEGORIES, N_CATEGORIES], fill_value=np.nan, dtype=np.float32)\nfor idx_a, cat_emb_a in enumerate(tqdm(CATEGORIES_EMBEDDING)):\n    for idx_b, cat_emb_b in enumerate(CATEGORIES_EMBEDDING):\n        EMBEDDING_DISTANCE[idx_a + 2, idx_b + 2] = cosine_similarity(cat_emb_a, cat_emb_b)\n        \n# Always Save Embedding Distances for Next Time\nprint(f'EMBEDDING_DISTANCE shape: {EMBEDDING_DISTANCE.shape}, EMBEDDING_DISTANCE dtype: {EMBEDDING_DISTANCE.dtype}')\nnp.save('EMBEDDING_DISTANCE.npy', EMBEDDING_DISTANCE)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:20:31.939188Z","iopub.execute_input":"2022-06-10T12:20:31.940109Z","iopub.status.idle":"2022-06-10T12:21:57.811655Z","shell.execute_reply.started":"2022-06-10T12:20:31.940057Z","shell.execute_reply":"2022-06-10T12:21:57.810548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sanity check for embedding distances\ndisplay(pd.Series(EMBEDDING_DISTANCE.flatten()).describe().to_frame(name='Value'))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:21:57.813373Z","iopub.execute_input":"2022-06-10T12:21:57.813704Z","iopub.status.idle":"2022-06-10T12:21:57.867383Z","shell.execute_reply.started":"2022-06-10T12:21:57.813677Z","shell.execute_reply":"2022-06-10T12:21:57.866309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adds distance between a category and the most similar category of the other point\ndef add_categories_distance_features(df):\n    for i in range(3):\n        df[f'categories{i}_distance'] = np.nanmax(\n            np.stack((\n                EMBEDDING_DISTANCE[df[f'categories{i}_1_ordinal'].astype(np.int32), df[f'categories0_2_ordinal'].astype(np.int32)],\n                EMBEDDING_DISTANCE[df[f'categories{i}_1_ordinal'].astype(np.int32), df[f'categories1_2_ordinal'].astype(np.int32)],\n                EMBEDDING_DISTANCE[df[f'categories{i}_1_ordinal'].astype(np.int32), df[f'categories2_2_ordinal'].astype(np.int32)],\n            ))\n        , axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:21:57.868998Z","iopub.execute_input":"2022-06-10T12:21:57.869475Z","iopub.status.idle":"2022-06-10T12:21:57.877768Z","shell.execute_reply.started":"2022-06-10T12:21:57.869432Z","shell.execute_reply":"2022-06-10T12:21:57.876494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Name Embedding\n\nEmbeddings are used from the [Foursquare USE/MPNET Name Embeddings](https://www.kaggle.com/code/markwijkhuizen/foursquare-use-mpnet-name-embeddings/notebook) notebook","metadata":{}},{"cell_type":"code","source":"NAMES_EMBEDDINGS_USE = np.load('/kaggle/input/foursquare-usempnet-name-embeddings-dataset/NAMES_EMBEDDINGS_USE.npy')\nNAMES_EMBEDDINGS_MPNET = np.load('/kaggle/input/foursquare-usempnet-name-embeddings-dataset/NAMES_EMBEDDINGS_MPNET.npy')\n\nprint(f'NAMES_EMBEDDINGS_USE shape: {NAMES_EMBEDDINGS_USE.shape}, dtype: {NAMES_EMBEDDINGS_USE.dtype}')\nprint(f'NAMES_EMBEDDINGS_MPNET shape: {NAMES_EMBEDDINGS_MPNET.shape}, dtype: {NAMES_EMBEDDINGS_MPNET.dtype}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:21:57.879399Z","iopub.execute_input":"2022-06-10T12:21:57.879775Z","iopub.status.idle":"2022-06-10T12:22:29.955336Z","shell.execute_reply.started":"2022-06-10T12:21:57.879744Z","shell.execute_reply":"2022-06-10T12:22:29.954504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/foursquare-usempnet-name-embeddings-dataset/name2names_embedding_idx_dict.pkl', 'rb') as f:\n    name2names_embedding_idx_dict = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:29.95658Z","iopub.execute_input":"2022-06-10T12:22:29.957313Z","iopub.status.idle":"2022-06-10T12:22:31.312494Z","shell.execute_reply.started":"2022-06-10T12:22:29.957268Z","shell.execute_reply":"2022-06-10T12:22:31.309369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Computes the cosine similarity as distance between names\ndef add_name_distance_features(df):\n    idxs_1 = df['name_1'].apply(name2names_embedding_idx_dict.get, args=(-1,)).astype(np.int32)\n    idxs_2 = df['name_2'].apply(name2names_embedding_idx_dict.get, args=(-1,)).astype(np.int32)\n    # Universal Sentence Encoder\n    df['name_distance_use'] = np.array([\n            np.nan if a < 0 or b < 0 else cosine_similarity(NAMES_EMBEDDINGS_USE[a], NAMES_EMBEDDINGS_USE[b])\n                for a, b in zip(idxs_1, idxs_2)\n        ], dtype=np.float32)\n    \n    # MPNET\n    df['name_distance_mpnet'] = np.array([\n            np.nan if a < 0 or b < 0 else cosine_similarity(NAMES_EMBEDDINGS_MPNET[a], NAMES_EMBEDDINGS_MPNET[b])\n                for a, b in zip(idxs_1, idxs_2)\n        ], dtype=np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:31.315199Z","iopub.execute_input":"2022-06-10T12:22:31.315704Z","iopub.status.idle":"2022-06-10T12:22:31.324098Z","shell.execute_reply.started":"2022-06-10T12:22:31.315656Z","shell.execute_reply":"2022-06-10T12:22:31.32289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Haversine Distance","metadata":{}},{"cell_type":"code","source":"# Adds haversine distance between two points\ndef add_haversine_distance(df):\n    df['haversine_distance'] = np.apply_along_axis(\n            haversine_np, 1,\n            df[['longitude_1', 'latitude_1', 'longitude_2', 'latitude_2']].values.astype(np.float32)\n        ).astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:31.326051Z","iopub.execute_input":"2022-06-10T12:22:31.326525Z","iopub.status.idle":"2022-06-10T12:22:31.343279Z","shell.execute_reply.started":"2022-06-10T12:22:31.326483Z","shell.execute_reply":"2022-06-10T12:22:31.342439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Levenstein Distance","metadata":{}},{"cell_type":"code","source":"levenstein_columns = [\n    'name',\n    'address',\n    'categories',\n]\n\n# Adds the levenstein distance for the given columns\ndef add_levenstein_distance(df):\n    def get_levenstein_distance(args):\n        a, b = args\n        if type(a) != str or type(b) != str:\n            return np.nan\n        else:\n            return lev(*args)\n        \n    for col in levenstein_columns:\n        df[f'{col}_ls_distance'] = df[[f'{col}_1', f'{col}_2']].apply(get_levenstein_distance, axis=1, raw=True).astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:31.344965Z","iopub.execute_input":"2022-06-10T12:22:31.345369Z","iopub.status.idle":"2022-06-10T12:22:31.358709Z","shell.execute_reply.started":"2022-06-10T12:22:31.345331Z","shell.execute_reply":"2022-06-10T12:22:31.357235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Equality","metadata":{}},{"cell_type":"code","source":"# Checks whether a category occurs in the other categories\ndef add_equal_features(df):  \n    # Category in other category\n    for i in range(2):\n        df[f'categories{i}_1_isin_2_ordinal'] = (\n            (df[f'categories{i}_1_ordinal'] > 0) &\n            (\n                (df[f'categories{i}_1_ordinal'] == df['categories0_2_ordinal']) |\n                (df[f'categories{i}_1_ordinal'] == df['categories1_2_ordinal']) |\n                (df[f'categories{i}_1_ordinal'] == df['categories2_2_ordinal'])\n            )\n        )","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:31.360984Z","iopub.execute_input":"2022-06-10T12:22:31.361471Z","iopub.status.idle":"2022-06-10T12:22:31.376349Z","shell.execute_reply.started":"2022-06-10T12:22:31.361422Z","shell.execute_reply":"2022-06-10T12:22:31.375243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Longest Substring","metadata":{}},{"cell_type":"code","source":"longest_substring_columns = [\n    'name',\n    'address',\n    'categories',\n]","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:31.377741Z","iopub.execute_input":"2022-06-10T12:22:31.378169Z","iopub.status.idle":"2022-06-10T12:22:31.397095Z","shell.execute_reply.started":"2022-06-10T12:22:31.378128Z","shell.execute_reply":"2022-06-10T12:22:31.395885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source: https://stackoverflow.com/questions/18715688/find-common-substring-between-two-strings\n@numba.jit(nopython=True, nogil=True, cache=True)\ndef longestSubstringFinder(string1: str, string2: str):\n    answer = 0\n    len1, len2 = len(string1), len(string2)\n    \n    for i in range(len1):\n        for j in range(len2):\n            lcs_temp = 0\n            match = 0\n            while ((i+lcs_temp < len1) and (j+lcs_temp<len2) and string1[i+lcs_temp] == string2[j+lcs_temp]):\n                match += 1\n                lcs_temp += 1\n            if match > answer:\n                answer = match\n    return np.uint8(answer)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:31.398599Z","iopub.execute_input":"2022-06-10T12:22:31.400977Z","iopub.status.idle":"2022-06-10T12:22:31.419141Z","shell.execute_reply.started":"2022-06-10T12:22:31.40091Z","shell.execute_reply":"2022-06-10T12:22:31.418006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Longest substring feature\ndef add_longest_substr(df):\n    for col in longest_substring_columns:\n        df[f'{col}_longest_substr'] = df[[f'{col}_1', f'{col}_2']].apply(lambda args: longestSubstringFinder(*args), axis=1, raw=True).astype(np.uint8)\n        df[f'{col}_longest_substr_ratio'] = (\n                (df[f'{col}_longest_substr'] * 2) / (df[f'{col}_1'].apply(len) + df[f'{col}_2'].apply(len)) \n            ).astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:31.420283Z","iopub.execute_input":"2022-06-10T12:22:31.421244Z","iopub.status.idle":"2022-06-10T12:22:31.437165Z","shell.execute_reply.started":"2022-06-10T12:22:31.421201Z","shell.execute_reply":"2022-06-10T12:22:31.436115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop some columns to reduce memory usage\npairs.drop([\n    'city_1',\n    'state_1',\n    'zip_1',\n    'country_1',\n    'url_1',\n    'phone_1',\n    'city_2',\n    'state_2',\n    'zip_2',\n    'country_2',\n    'url_2',\n    'phone_2',\n    'country_code_1',\n    'country_code_2',\n    'city_rg_1',\n    'city_rg_2',\n], axis=1, inplace=True)\n\n# Garbage Collect\nprint(gc.collect())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:31.438487Z","iopub.execute_input":"2022-06-10T12:22:31.439454Z","iopub.status.idle":"2022-06-10T12:22:32.653496Z","shell.execute_reply.started":"2022-06-10T12:22:31.439416Z","shell.execute_reply":"2022-06-10T12:22:32.652362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add Combined Features\n\nThis will take some time, for the complete 16M pairs training set about one and a half hour","metadata":{}},{"cell_type":"code","source":"%%time\ndef add_combined_features(df):\n    add_categories_distance_features(df)\n    add_haversine_distance(df)\n    add_equal_features(df)\n    add_levenstein_distance(df)\n    add_longest_substr(df)\n    add_name_distance_features(df)\n    \nadd_combined_features(pairs)\ndisplay(pairs.head(30))\ndisplay(pairs.info())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:22:32.655662Z","iopub.execute_input":"2022-06-10T12:22:32.656738Z","iopub.status.idle":"2022-06-10T12:24:39.087937Z","shell.execute_reply.started":"2022-06-10T12:22:32.656695Z","shell.execute_reply":"2022-06-10T12:24:39.086607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LightGBM Dataset","metadata":{}},{"cell_type":"code","source":"features_1 = [\n    'latitude_1',\n    'longitude_1',\n    'name_1_ordinal',\n    'state_1_ordinal',\n    'url_1_ordinal',\n    'zip_1_ordinal',\n    'country_1_ordinal',\n    'country_code_1_ordinal',\n    'city_rg_1_ordinal',\n    'city_1_ordinal',\n    'categories0_1_ordinal',\n    'categories1_1_ordinal',\n    'categories2_1_ordinal',\n]\n\nfeatures_2 = [\n    'latitude_2',\n    'longitude_2',\n    'name_2_ordinal',\n    'state_2_ordinal',\n    'url_2_ordinal',\n    'zip_2_ordinal',\n    'country_2_ordinal',\n    'country_code_2_ordinal',\n    'city_rg_2_ordinal',\n    'city_2_ordinal',\n    'categories0_2_ordinal',\n    'categories1_2_ordinal',\n    'categories2_2_ordinal',\n]\n\nfeatures_combined = [\n    'categories0_distance',\n    'categories1_distance',\n\n    \n    'name_distance_use',\n    'name_distance_mpnet',\n    \n    'haversine_distance',\n    \n    'name_ls_distance',\n    'address_ls_distance',\n    'categories_ls_distance',\n    \n    'categories0_1_isin_2_ordinal',\n    'categories1_1_isin_2_ordinal',\n    \n    'name_longest_substr',  \n    'address_longest_substr',  \n    'categories_longest_substr',\n    \n    'name_longest_substr_ratio',\n    'address_longest_substr_ratio',\n    'categories_longest_substr_ratio',\n]\n\nfeatures = features_1 + features_2 + features_combined\n\ncategorical_features_idxs = []\nfor idx, f in enumerate(features):\n    if f.endswith('_ordinal'):\n        categorical_features_idxs.append(idx)\n\ntarget = 'match'\n\nprint(f'categorical_features_idxs: {categorical_features_idxs}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:24:39.090237Z","iopub.execute_input":"2022-06-10T12:24:39.090737Z","iopub.status.idle":"2022-06-10T12:24:39.099857Z","shell.execute_reply.started":"2022-06-10T12:24:39.090679Z","shell.execute_reply":"2022-06-10T12:24:39.098727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Placeholder Matrix for Pairs Features\npairs_features = np.empty(shape=[len(pairs), len(features)], dtype=np.float32)\n\n# Fill up the pairs_features matrix column by column\nfor f_idx, f in enumerate(features):\n    pairs_features[:, f_idx] = pairs[f]\n\npairs_target = pairs[target].values.astype(np.int8)\n\n# Save Pairs Features and Target\nnp.save('pairs_features.npy', pairs_features)\nnp.save('pairs_target.npy', pairs_target)\n\nprint(f'pairs_features shape: {pairs_features.shape}, pairs_target shape: {pairs_target.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:24:39.101607Z","iopub.execute_input":"2022-06-10T12:24:39.102077Z","iopub.status.idle":"2022-06-10T12:24:39.60891Z","shell.execute_reply.started":"2022-06-10T12:24:39.102036Z","shell.execute_reply":"2022-06-10T12:24:39.607727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train/Validation split, use just 5% for validation as that will already create a validation set larger than the test set\ntrain_idxs, val_idxs = train_test_split(np.arange(len(pairs_target), dtype=np.int32), test_size=0.05, random_state=SEED)\nprint(f'train_idxs size: {train_idxs.size}, val_idxs size: {val_idxs.size}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:24:39.610578Z","iopub.execute_input":"2022-06-10T12:24:39.611045Z","iopub.status.idle":"2022-06-10T12:24:39.638877Z","shell.execute_reply.started":"2022-06-10T12:24:39.611003Z","shell.execute_reply":"2022-06-10T12:24:39.637851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clean Up","metadata":{}},{"cell_type":"code","source":"del train, pairs\ngc.collect()\n\nram_usage = psutil.virtual_memory()\nprint(f'RAM memory % used: {ram_usage[2]:.1f}, ({ram_usage[3] / 2**30:.1f}GB)')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:24:39.640251Z","iopub.execute_input":"2022-06-10T12:24:39.640608Z","iopub.status.idle":"2022-06-10T12:24:40.193203Z","shell.execute_reply.started":"2022-06-10T12:24:39.640577Z","shell.execute_reply":"2022-06-10T12:24:40.191712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make LightGBM Dataset","metadata":{}},{"cell_type":"code","source":"# LightGBM Training Dataset\ntrain_data = lgb.Dataset(\n    data = pairs_features[train_idxs],\n    label = pairs_target[train_idxs],\n    categorical_feature = None,\n)\n\n# LightGBM Validation Dataset\nval_data_pairs = lgb.Dataset(\n    data = pairs_features[val_idxs],\n    label = pairs_target[val_idxs],\n    categorical_feature = None,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:24:40.194447Z","iopub.execute_input":"2022-06-10T12:24:40.194974Z","iopub.status.idle":"2022-06-10T12:24:40.264019Z","shell.execute_reply.started":"2022-06-10T12:24:40.194938Z","shell.execute_reply":"2022-06-10T12:24:40.262961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LightGBM Model","metadata":{}},{"cell_type":"code","source":"NUM_BOOST_ROUND = 1000\nMETRICS = ['binary_logloss', 'binary_error']\n\n# Simple LightGBM parameters\nlgbm_params = {\n    'objective': 'binary',\n    'metric': ','.join(METRICS),\n    # Much more than other notebooks, possible due to 16M Training Samples!\n    'num_leaves': 256,\n    'learning_rate': 0.10,\n    'deterministic': True,\n    'seed': SEED,\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:24:40.265416Z","iopub.execute_input":"2022-06-10T12:24:40.265776Z","iopub.status.idle":"2022-06-10T12:24:40.270793Z","shell.execute_reply.started":"2022-06-10T12:24:40.265745Z","shell.execute_reply":"2022-06-10T12:24:40.269891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is all it takes to train a LightGBM Model!\ndef train_f():\n    evals_result = {}\n    model_lgb = lgb.train(\n        params = lgbm_params,\n        train_set = train_data,\n        valid_sets = [train_data, val_data_pairs],\n        num_boost_round = NUM_BOOST_ROUND,\n        verbose_eval = 10,\n        evals_result = evals_result,\n        early_stopping_rounds = 7,\n        categorical_feature = categorical_features_idxs,\n        feature_name = features,\n    )\n\n    # save model\n    model_lgb.save_model(f'model.lgb')\n    \n    return model_lgb, evals_result\n    \nmodel_lgb, evals_result = train_f()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:24:40.272261Z","iopub.execute_input":"2022-06-10T12:24:40.272881Z","iopub.status.idle":"2022-06-10T12:25:06.018174Z","shell.execute_reply.started":"2022-06-10T12:24:40.272809Z","shell.execute_reply":"2022-06-10T12:25:06.017402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean up\ndel train_data, val_data_pairs\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:06.019255Z","iopub.execute_input":"2022-06-10T12:25:06.019738Z","iopub.status.idle":"2022-06-10T12:25:06.303676Z","shell.execute_reply.started":"2022-06-10T12:25:06.019703Z","shell.execute_reply":"2022-06-10T12:25:06.302661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get validation predictions\npred_df = pd.DataFrame({ 'pred': model_lgb.predict(pairs_features[val_idxs]) })\npred_df['pred_correct'] = (pred_df['pred'] > 0.50) == pairs_target[val_idxs]\npred_df['match'] = pairs_target[val_idxs]\n\n# Precision on validation set\ndisplay(pred_df['pred_correct'].value_counts(normalize=True).to_frame('Value'))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:06.304931Z","iopub.execute_input":"2022-06-10T12:25:06.305283Z","iopub.status.idle":"2022-06-10T12:25:06.657643Z","shell.execute_reply.started":"2022-06-10T12:25:06.305252Z","shell.execute_reply":"2022-06-10T12:25:06.656822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check predicted value of positive/negative samples in the validation set\ndisplay(pred_df.groupby('match')['pred'].describe(percentiles=[0.01, 0.05, 0.10, 0.25, 0.75, 0.90, 0.95, 0.99]).T)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:06.658697Z","iopub.execute_input":"2022-06-10T12:25:06.659263Z","iopub.status.idle":"2022-06-10T12:25:06.683417Z","shell.execute_reply.started":"2022-06-10T12:25:06.659228Z","shell.execute_reply":"2022-06-10T12:25:06.682399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Training History","metadata":{}},{"cell_type":"code","source":"# plots the training history\ndef plot_history(evals_result):\n    for metric in METRICS:\n        plt.figure(figsize=(20,8))\n        \n        for key in evals_result.keys():\n            history_len = len(evals_result.get(key)[metric])\n            history = evals_result.get(key)[metric]\n            x_axis = np.arange(1, history_len + 1)\n            plt.plot(x_axis, history, label=key)\n        \n        x_ticks = list(filter(lambda e: (e % (history_len // 100 * 10) == 0) or e == 1, x_axis))\n        plt.xticks(x_ticks, fontsize=12)\n        plt.yticks(fontsize=12)\n\n        plt.title(f'{metric.upper()} History of training', fontsize=18);\n        plt.xlabel('EPOCH', fontsize=16)\n        plt.ylabel(metric.upper(), fontsize=16)\n        \n        if metric in ['auc']:\n            plt.legend(loc='upper left', fontsize=14)\n        else:\n            plt.legend(loc='upper right', fontsize=14)\n        plt.grid()\n        plt.show()\n\nplot_history(evals_result)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:06.685146Z","iopub.execute_input":"2022-06-10T12:25:06.68559Z","iopub.status.idle":"2022-06-10T12:25:07.499709Z","shell.execute_reply.started":"2022-06-10T12:25:06.685547Z","shell.execute_reply":"2022-06-10T12:25:07.499051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"# This is incredibly important to see the performance of features\n# If a feature is not used to split and does not provide much gain, remove it!\ndef show_feature_importances(model, importance_type, max_num_features=10**10):\n    feature_importances = pd.DataFrame()\n    feature_importances['feature'] = features\n    feature_importances['value'] = pd.DataFrame(model.feature_importance(importance_type))\n    feature_importances = feature_importances.sort_values(by='value', ascending=False) # sort feature importance\n    feature_importances.to_csv(f'feature_importances_{importance_type}.csv') # write feature importance to csv\n    feature_importances = feature_importances[:max_num_features] # only show max_num_features\n    \n    plt.figure(figsize=(10, len(features) * 0.25))\n    plt.xlim([0, feature_importances.value.max()*1.1])\n    plt.title(f'Feature {importance_type}', fontsize=18);\n    sns.barplot(data=feature_importances, x='value', y='feature', palette='rocket');\n    for idx, v in enumerate(feature_importances.value):\n        plt.text(v, idx, \"  {:.2e}\".format(v))\n\nshow_feature_importances(model_lgb, 'gain')\nshow_feature_importances(model_lgb, 'split')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:07.500911Z","iopub.execute_input":"2022-06-10T12:25:07.501409Z","iopub.status.idle":"2022-06-10T12:25:09.267472Z","shell.execute_reply.started":"2022-06-10T12:25:07.501372Z","shell.execute_reply":"2022-06-10T12:25:09.266226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Precision/Recall/F1","metadata":{}},{"cell_type":"code","source":"# Predictions and true labels of validation dataset\ny = pairs_target[val_idxs]\ny_pred = model_lgb.predict(pairs_features[val_idxs])\nprint(f'y shape: {y.shape}, y_pred shape: {y_pred.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:09.269407Z","iopub.execute_input":"2022-06-10T12:25:09.269839Z","iopub.status.idle":"2022-06-10T12:25:09.606141Z","shell.execute_reply.started":"2022-06-10T12:25:09.269785Z","shell.execute_reply":"2022-06-10T12:25:09.605253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision, recall, thresholds = metrics.precision_recall_curve(y, y_pred)\nthresholds = np.concatenate(([0], thresholds))\n\nf1 = 2 * (precision * recall) / (precision + recall)\nf1_arg_best = np.argmax(f1)\nf1_best_threshold = thresholds[f1_arg_best]\nf1_best_value = f1.max()\nprint(f'Best F1({f1_best_value:.3f}) at Threshold {f1_best_threshold:.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:09.608697Z","iopub.execute_input":"2022-06-10T12:25:09.609069Z","iopub.status.idle":"2022-06-10T12:25:09.622746Z","shell.execute_reply.started":"2022-06-10T12:25:09.609037Z","shell.execute_reply":"2022-06-10T12:25:09.621598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.plot(precision, recall, color='darkorange', label='Precision/Recall')\nplt.scatter(precision[f1_arg_best], recall[f1_arg_best], color='red', s=100, marker='o', label=f'Best F1({f1_best_value:.3f}) at Threshold {f1_best_threshold:.3f}')\nplt.title('Precision/Recall Curve', size=24)\nplt.xlabel('Precision', size=18)\nplt.ylabel('Recall', size=18)\nplt.xticks(np.arange(0, 1.1, 0.1), size=16)\nplt.yticks(size=16)\nplt.grid()\nplt.legend(prop={'size': 16})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:09.62398Z","iopub.execute_input":"2022-06-10T12:25:09.624751Z","iopub.status.idle":"2022-06-10T12:25:09.991643Z","shell.execute_reply.started":"2022-06-10T12:25:09.624717Z","shell.execute_reply":"2022-06-10T12:25:09.990543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.plot(recall, thresholds,  color='darkorange', label='Recall/Threshold')\nplt.title('Threshold/Recall Curve', size=24)\nplt.xlabel('Threshold', size=18)\nplt.ylabel('Recall', size=18)\nplt.xticks(np.arange(0, 1.1, 0.1), size=16)\nplt.yticks(size=16)\nplt.grid()\nplt.legend(prop={'size': 16})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:09.99328Z","iopub.execute_input":"2022-06-10T12:25:09.994127Z","iopub.status.idle":"2022-06-10T12:25:10.33952Z","shell.execute_reply.started":"2022-06-10T12:25:09.994076Z","shell.execute_reply":"2022-06-10T12:25:10.338355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.plot(thresholds, precision,  color='darkorange', label='Precision/Threshold')\nplt.title('Threshold/Precision Curve', size=24)\nplt.xlabel('Threshold', size=18)\nplt.ylabel('Precision', size=18)\nplt.xticks(np.arange(0, 1.1, 0.1), size=16)\nplt.yticks(np.arange(0, 1.1, 0.1), size=16)\nplt.grid()\nplt.legend(prop={'size': 16})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:10.341115Z","iopub.execute_input":"2022-06-10T12:25:10.341653Z","iopub.status.idle":"2022-06-10T12:25:10.703341Z","shell.execute_reply.started":"2022-06-10T12:25:10.341601Z","shell.execute_reply":"2022-06-10T12:25:10.702328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del pairs_features, pairs_target\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:10.704909Z","iopub.execute_input":"2022-06-10T12:25:10.705532Z","iopub.status.idle":"2022-06-10T12:25:11.044089Z","shell.execute_reply.started":"2022-06-10T12:25:10.705487Z","shell.execute_reply":"2022-06-10T12:25:11.043142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# Let's check how the submission should look like\ndisplay(sample_submission)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.04546Z","iopub.execute_input":"2022-06-10T12:25:11.046244Z","iopub.status.idle":"2022-06-10T12:25:11.05939Z","shell.execute_reply.started":"2022-06-10T12:25:11.046208Z","shell.execute_reply":"2022-06-10T12:25:11.058741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deduce city and country by coordinates\ntest['city_rg'] = get_cities(test[['latitude', 'longitude']])\ntest['country_code'] = get_country_codes(test[['latitude', 'longitude']])\n\n# Make pairs from the test set by simply concatenating the test set with postfix \"_1\"/\"_2\"\ntest_features = pd.concat([test.add_suffix('_1'), test.add_suffix('_2')], axis=1)\nadd_stand_alone_features(test_features)\n\ndisplay(test_features.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.060693Z","iopub.execute_input":"2022-06-10T12:25:11.06162Z","iopub.status.idle":"2022-06-10T12:25:11.202074Z","shell.execute_reply.started":"2022-06-10T12:25:11.061576Z","shell.execute_reply":"2022-06-10T12:25:11.20103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The famous nearest neighbours lookup tree\ntree = BallTree(np.deg2rad(test[['latitude', 'longitude']].values), metric='haversine')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.203307Z","iopub.execute_input":"2022-06-10T12:25:11.203622Z","iopub.status.idle":"2022-06-10T12:25:11.215133Z","shell.execute_reply.started":"2022-06-10T12:25:11.203594Z","shell.execute_reply":"2022-06-10T12:25:11.21407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns to include, because they are needed to compute other features\nsupport_columns_1 = ['name_1', 'address_1', 'categories_1']\nsupport_columns_2 = ['name_2', 'address_2', 'categories_2']","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.216144Z","iopub.execute_input":"2022-06-10T12:25:11.216571Z","iopub.status.idle":"2022-06-10T12:25:11.226536Z","shell.execute_reply.started":"2022-06-10T12:25:11.216537Z","shell.execute_reply":"2022-06-10T12:25:11.225615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features_np_1 = test_features[features_1 + support_columns_1].values.reshape([len(test_features), 1, -1])\ntest_features_np_2 = test_features[features_2 + support_columns_2].values","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.227907Z","iopub.execute_input":"2022-06-10T12:25:11.228591Z","iopub.status.idle":"2022-06-10T12:25:11.246634Z","shell.execute_reply.started":"2022-06-10T12:25:11.22856Z","shell.execute_reply":"2022-06-10T12:25:11.245912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for submission\nIS_DUMMY_TEST = len(test) == 5\n# Only the 15 nearest neighbours are used\nN_NEIGHBOURS = 3 if IS_DUMMY_TEST else 15\n# Threshold to include a point as match\nTHRESHOLD = 0.50\n# Maximum distance to include neighbours from\nMAX_DISTANCE_KM = 10\n# Matrices to save features in, prediction will be done in 1 go\nQUERY_MATRIX = np.zeros(shape=[len(test) * N_NEIGHBOURS, len(features)], dtype=np.float32)\nQUERY_DISTANCES = np.zeros(shape=[len(test), N_NEIGHBOURS], dtype=np.float32)\nQUERY_INDICES = np.zeros(shape=[len(test), N_NEIGHBOURS], dtype=np.int32)\n\n# Inference loop\nfor row_idx, row in tqdm(test.iterrows(), total=len(test)):\n    # Get 15 neaarest neighbours\n    dist, ind = tree.query(np.deg2rad([row['latitude'], row['longitude']]).reshape(1, -1), k=N_NEIGHBOURS)\n    # Distance from degrees to KM\n    dist = dist.squeeze() * EARTH_RADIUS\n    ind = ind.squeeze()\n\n    # Make pairs dataframe\n    df_query = pd.DataFrame(\n        np.concatenate([\n                np.repeat(test_features_np_1[row_idx], N_NEIGHBOURS, 0),\n                test_features_np_2[ind]\n            ]\n        , axis=1)\n    , columns=features_1 + support_columns_1 + features_2 + support_columns_2)\n    \n    # Add Combined Features\n    add_combined_features(df_query)\n\n    # Save query, distances and indices\n    QUERY_MATRIX[row_idx * N_NEIGHBOURS:(row_idx + 1) * N_NEIGHBOURS] = df_query[features].values\n    QUERY_DISTANCES[row_idx] = dist\n    QUERY_INDICES[row_idx] = ind","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.248038Z","iopub.execute_input":"2022-06-10T12:25:11.249071Z","iopub.status.idle":"2022-06-10T12:25:11.41849Z","shell.execute_reply.started":"2022-06-10T12:25:11.249031Z","shell.execute_reply":"2022-06-10T12:25:11.417486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"# Make a single model call, super efficient!\nQUERY_PREDS = model_lgb.predict(QUERY_MATRIX).reshape([len(test), N_NEIGHBOURS])\nQUERY_PREDS_SERIES = pd.Series(QUERY_PREDS.flatten())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.419982Z","iopub.execute_input":"2022-06-10T12:25:11.420317Z","iopub.status.idle":"2022-06-10T12:25:11.429245Z","shell.execute_reply.started":"2022-06-10T12:25:11.420287Z","shell.execute_reply":"2022-06-10T12:25:11.428408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(QUERY_PREDS_SERIES.describe())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.430278Z","iopub.execute_input":"2022-06-10T12:25:11.430703Z","iopub.status.idle":"2022-06-10T12:25:11.446764Z","shell.execute_reply.started":"2022-06-10T12:25:11.43066Z","shell.execute_reply":"2022-06-10T12:25:11.445864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.title('Prediction Distribution', size=24)\nQUERY_PREDS_SERIES.plot(kind='hist')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.447967Z","iopub.execute_input":"2022-06-10T12:25:11.448436Z","iopub.status.idle":"2022-06-10T12:25:11.637298Z","shell.execute_reply.started":"2022-06-10T12:25:11.44839Z","shell.execute_reply":"2022-06-10T12:25:11.636497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Submission DataFrame","metadata":{}},{"cell_type":"code","source":"# Rows of the DataFrame are saved as dictionaries\nsubmission_dict = []\n\nfor row_idx, row in tqdm(test.iterrows(), total=len(test)):\n    ind = QUERY_INDICES[row_idx]\n    dist = QUERY_DISTANCES[row_idx]\n    pred = QUERY_PREDS[row_idx]\n    # Point is included if (mind the brackets):\n    # (the confidence is above the threshold or the point refers to itself) and the distance is below the threshold\n    pred_id_idxs = ind[((pred > THRESHOLD) | (ind == row_idx)) & (dist < MAX_DISTANCE_KM)]\n    pred_ids = ' '.join(test.loc[pred_id_idxs, 'id'].tolist())\n    \n    submission_dict.append({\n        'id': row['id'],\n        'matches': pred_ids,\n    })","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.638597Z","iopub.execute_input":"2022-06-10T12:25:11.638894Z","iopub.status.idle":"2022-06-10T12:25:11.679251Z","shell.execute_reply.started":"2022-06-10T12:25:11.638867Z","shell.execute_reply":"2022-06-10T12:25:11.678371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"pd.options.display.max_colwidth = 200\nsubmission_df = pd.DataFrame(submission_dict)\ndisplay(submission_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.680463Z","iopub.execute_input":"2022-06-10T12:25:11.680778Z","iopub.status.idle":"2022-06-10T12:25:11.691738Z","shell.execute_reply.started":"2022-06-10T12:25:11.680749Z","shell.execute_reply":"2022-06-10T12:25:11.690613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T12:25:11.69342Z","iopub.execute_input":"2022-06-10T12:25:11.693788Z","iopub.status.idle":"2022-06-10T12:25:11.707005Z","shell.execute_reply.started":"2022-06-10T12:25:11.693756Z","shell.execute_reply":"2022-06-10T12:25:11.705986Z"},"trusted":true},"execution_count":null,"outputs":[]}]}