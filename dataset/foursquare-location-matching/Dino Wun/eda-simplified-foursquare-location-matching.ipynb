{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **EDA Simplified: Foursquare Location Matching**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Introduction\nWhen I've entered this competition over locations and matching them with AI, I remembered this:\n\n> *It's a small world after all, It's a small world after all, It's a small world after all, It's a small, small world...*\n\nAnd for sure, I have a challenge. Can you identify the quote mentioned in this introduction quickly within 15 seconds?\n\nIf you incorrectly guessed this quote or you ran out of time, then better luck next time. But if you guess this quote from the beginning correctly, then you're excellent! you've see that it was from the nursery rhyme, **It's a Small World**! Speaking of that, this small world contained possible locations that you may go, since I am a <span style=\"color: #7393B3\">Tsurezure</span> traveller. But when Foursquare released a competition like this, then this may be a great opportunity to explore around the world. But what's this purpose of this competition? The purpose of this competition is that you’ll match POIs together by using a simulated dataset from Foursquare of over one-and-a-half million Place entries. Using this make you produce an algorithm that predicts which Place entries represent the same point-of-interest. Each Place entry includes attributes like the name, street address, and coordinates. Successful submissions will identify matches with the greatest accuracy. And if you've got this done correctly, then you'll make it easier to identify where new stores or businesses would benefit people the most. *Bada-boom, Bada-bing.*","metadata":{}},{"cell_type":"markdown","source":"### Quick Heads-Up: About Foursquare\nBefore let's proceed to our EDA analysis, let's talk about the creator of this competition, Foursquare. Foursquare is the most trusted, independent location data platform for understanding how people move through the real world. With 12+ years of experience perfecting such methods, Foursquare is the first independent provider of global POI data. The leading independent location technology and data cloud platform, Foursquare is dedicated to building meaningful bridges between digital spaces and physical places. Trusted by leading enterprises like Apple, Microsoft, Samsung, and Uber, Foursquare’s tech stack harnesses the power of places and movement to improve customer experiences and drive better business outcomes. With that, let's move in to EDA.","metadata":{}},{"cell_type":"markdown","source":"## Imports\nFor importing modules in this EDA notebook, there's something special to happen. First, we import geopandas, since this competition is based over location. Then, we import the pandas module as pd for data science and the numpy module as np for linear algebra. We also use plotting modules like: matplotlib with the pyplot module as plt, seaborn as sns, and plotly with the graph_objects submodule as go and express submodule as px.","metadata":{}},{"cell_type":"code","source":"import geopandas\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:00:40.578546Z","iopub.execute_input":"2022-06-13T05:00:40.579005Z","iopub.status.idle":"2022-06-13T05:00:43.894228Z","shell.execute_reply.started":"2022-06-13T05:00:40.578919Z","shell.execute_reply":"2022-06-13T05:00:43.893228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataframe Creation\nAfter importing our stuff, then we create two dataframes, out of pairs.csv file and train.csv file by defining two variables: pairs_df and train_df to put the file paths leading to them in the pd module with the read_csv function.","metadata":{}},{"cell_type":"code","source":"pairs_df = pd.read_csv(\"../input/foursquare-location-matching/pairs.csv\")\ntrain_df = pd.read_csv(\"../input/foursquare-location-matching/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:00:43.895889Z","iopub.execute_input":"2022-06-13T05:00:43.896218Z","iopub.status.idle":"2022-06-13T05:01:00.18073Z","shell.execute_reply.started":"2022-06-13T05:00:43.896173Z","shell.execute_reply":"2022-06-13T05:01:00.179646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yet after that, we display the first 5 rows of our newly created two dataframes by plugging the head function into them!","metadata":{}},{"cell_type":"code","source":"pairs_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:00.182174Z","iopub.execute_input":"2022-06-13T05:01:00.182661Z","iopub.status.idle":"2022-06-13T05:01:00.223048Z","shell.execute_reply.started":"2022-06-13T05:01:00.182625Z","shell.execute_reply":"2022-06-13T05:01:00.222085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:00.225521Z","iopub.execute_input":"2022-06-13T05:01:00.225833Z","iopub.status.idle":"2022-06-13T05:01:00.243352Z","shell.execute_reply.started":"2022-06-13T05:01:00.225794Z","shell.execute_reply":"2022-06-13T05:01:00.242198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First Peek in this Data\nNow, after creating our two dataframes, let's take a quick, quick peek! First, we check whether there's any NaN entities in the two dataframes of pairs_df and train_df by plugging to isna function and the sum function (to calculate how many of them is NaN) to each dataframe.","metadata":{}},{"cell_type":"code","source":"pairs_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:00.245152Z","iopub.execute_input":"2022-06-13T05:01:00.245552Z","iopub.status.idle":"2022-06-13T05:01:00.75805Z","shell.execute_reply.started":"2022-06-13T05:01:00.245511Z","shell.execute_reply":"2022-06-13T05:01:00.757083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:00.759705Z","iopub.execute_input":"2022-06-13T05:01:00.76002Z","iopub.status.idle":"2022-06-13T05:01:01.317949Z","shell.execute_reply.started":"2022-06-13T05:01:00.759982Z","shell.execute_reply":"2022-06-13T05:01:01.317087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As for the pairs_df dataframe, we see that the data entities of: \n* address_1 (103,524) \n* city_1 (65,979)\n* state_1 (126,591)\n* zip_1 (219,398)\n* country_1 (8)\n* url_1 (347,101)\n* phone_1 (308,885)\n* categories_1 (16,294)\n* address_2 (266,410)\n* city_2 (211,417)\n* state_2 (269,218)\n* zip_2 (354,080)\n* country_2 (6)\n* url_2 (494,057)\n* phone_2 (459,944)\n* categories_2 (75,976)\n\ncontained some NaN values.","metadata":{}},{"cell_type":"markdown","source":"And on the other hand, the train_df dataframe data entities of:\n* name (1)\n* address (396,621)\n* city (299,189)\n* state (420,586)\n* zip (595,426)\n* country (11)\n* url (871,088)\n* phone (795,957)\n* categories (98,307)\n\nalso contained some NaN values. Now, let's move on to analyzing the number of observations in both dataframes!","metadata":{}},{"cell_type":"markdown","source":"To find the number of observations in our two dataframes, we installed the shape attribute, containing the number 0 enclosed with square brackets to each of our pairs_df and train_df dataframes and print them.","metadata":{}},{"cell_type":"code","source":"print(\"No. of observations in pairs_df:\", pairs_df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:01.319278Z","iopub.execute_input":"2022-06-13T05:01:01.319632Z","iopub.status.idle":"2022-06-13T05:01:01.32546Z","shell.execute_reply.started":"2022-06-13T05:01:01.31959Z","shell.execute_reply":"2022-06-13T05:01:01.32458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No. of observations in train_df:\", train_df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:01.326907Z","iopub.execute_input":"2022-06-13T05:01:01.327158Z","iopub.status.idle":"2022-06-13T05:01:01.342925Z","shell.execute_reply.started":"2022-06-13T05:01:01.327107Z","shell.execute_reply":"2022-06-13T05:01:01.341903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, the number of observations in our pairs_df dataframe is 578,907 entities and the number of observations in our train_df dataframe is 1,138,812 entities. After that, let's use EDA in our Foursquare competition data!","metadata":{}},{"cell_type":"markdown","source":"## EDA\nNow for our EDA analysis, let's analyze our dataframe \"one-at-a-time\" in a chapter so that we can explain it in a clear, clear way. So, let's move on and don't dawdle!","metadata":{}},{"cell_type":"markdown","source":"### Chapter 1: pairs_df\nTo see the most countries in the first pair, we define a sub-dataframe variable called country_1 to our pairs_df with the country_1 data attribute along with the to_frame function (to convert the given series of an object to a dataframe, which is the country_1 data in pairs_df) along with the reset_index function (to reset our data indexes) and the rename function, containing the columns parameter that was set to the dictionary with two keys: index and country_1. \n\nNow, for plotting the countries, it's that simple, if you are using Seaborn. All we need to do is to call the sns module with the displot function, containing the country_1 dataframe with the head function in which it contained the number 20 to indicate the first 20 rows of this dataframe, the x parameter set to country_1, and the y parameter set to count.","metadata":{}},{"cell_type":"code","source":"country_1 = pairs_df.country_1.value_counts().to_frame().reset_index().rename(columns={'index': 'country_1', 'country_1': 'count'})\n\nsns.catplot(data=country_1.head(20), x='country_1', y='count', kind='bar', aspect=2)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:01.344339Z","iopub.execute_input":"2022-06-13T05:01:01.34459Z","iopub.status.idle":"2022-06-13T05:01:01.821787Z","shell.execute_reply.started":"2022-06-13T05:01:01.34456Z","shell.execute_reply":"2022-06-13T05:01:01.820852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When we observed this graph, we see that the most counts of records in country_1 is the United States of America whil the least counts of records in country_2 is Italy. Now, let's move to analyzing the country_2 data index with Matplotlib! ","metadata":{}},{"cell_type":"markdown","source":"Next, let's plot down the data entities of country_2! We continue with Seaborn again, vaguely following of what we did in analyzing country_1 data entities, but we define country_2 variable with displaying out the first 20 rows of this data entity over country_2, thus setting the x parameter in the sns module with the catplot function to country_2.","metadata":{}},{"cell_type":"code","source":"country_2 = pairs_df.country_2.value_counts().to_frame().reset_index().rename(columns={'index': 'country_2', 'country_2': 'count'})\n\nsns.catplot(data=country_2.head(20), x='country_2', y='count', kind='bar', aspect=2)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:01.824596Z","iopub.execute_input":"2022-06-13T05:01:01.824852Z","iopub.status.idle":"2022-06-13T05:01:02.243739Z","shell.execute_reply.started":"2022-06-13T05:01:01.824822Z","shell.execute_reply":"2022-06-13T05:01:02.242683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, when we looked at the two plots, we see that both country_1 and country_2 data entities were almost alike. Now, let's find over the categories!\n\nFor finding over the categories, we use Plotly for sure. But first, we vaguely follow of what we do for the counting the countries in the pairs_df dataframe, but with counting the categories_1 with the definition of the categories_1 variable. Then, we define a variable, fig, to the px module with the bar function, containing the categories_1 variable with the first 20 rows by using the head function, x parameter set to categories_1, y parameter set to count. Finally, we show the fig figure variable by using the show variable on the fig variable.","metadata":{}},{"cell_type":"code","source":"categories_1 = pairs_df.categories_1.value_counts().to_frame().reset_index().rename(columns = {'index':'categories_1', 'categories_1':'count'})\n\nfig = px.bar(categories_1.head(20), x='categories_1', y='count')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:02.244782Z","iopub.execute_input":"2022-06-13T05:01:02.24498Z","iopub.status.idle":"2022-06-13T05:01:03.393018Z","shell.execute_reply.started":"2022-06-13T05:01:02.244956Z","shell.execute_reply":"2022-06-13T05:01:03.392075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's do the same to finding categories_2!","metadata":{}},{"cell_type":"code","source":"categories_2 = pairs_df.categories_2.value_counts().to_frame().reset_index().rename(columns = {'index':'categories_2', 'categories_2':'count'})\n\nfig = px.bar(categories_2.head(20), x='categories_2', y='count')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:03.394529Z","iopub.execute_input":"2022-06-13T05:01:03.394842Z","iopub.status.idle":"2022-06-13T05:01:03.511187Z","shell.execute_reply.started":"2022-06-13T05:01:03.394802Z","shell.execute_reply":"2022-06-13T05:01:03.510369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, in the categories_1 graph, the most values is the shopping malls, with 11,606 entities, while the least values is parks, with 3,513 entities.\n\nMeanwhile, in the categories_2 graph, the most values is Residential Buildings (Apartments/Condos) with counts up to 11,604 data entities and the least values is Pharmacies, with counts up to 3,837 data entities.","metadata":{}},{"cell_type":"markdown","source":"And now, let's plot down the lats and lons of our pairs_df with GeoPandas and Plotly! For finding the lats and lons of the first pair, we convert the pairs_df dataframe into a geo dataframe (gdf) by defining pairs_gdf geo dataframe into the geopandas module with the GeoDataFrame function (to convert a specific dataframe to a geo dataframe), containing the pairs_df dataframe and setting the geometry parameter to the geopandas module with the points_from_xy function (to create geometry points) containing the pairs_df dataframe's longitude_1 and latitude_1 data indexes.","metadata":{}},{"cell_type":"code","source":"pairs_gdf = geopandas.GeoDataFrame(pairs_df, geometry=geopandas.points_from_xy(pairs_df.longitude_1, pairs_df.latitude_1))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:03.512209Z","iopub.execute_input":"2022-06-13T05:01:03.512402Z","iopub.status.idle":"2022-06-13T05:01:03.608824Z","shell.execute_reply.started":"2022-06-13T05:01:03.512378Z","shell.execute_reply":"2022-06-13T05:01:03.60792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's display the first rows of our newly-created pairs_gdf geo dataframe by using the head function!","metadata":{}},{"cell_type":"code","source":"pairs_gdf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:03.609753Z","iopub.execute_input":"2022-06-13T05:01:03.609948Z","iopub.status.idle":"2022-06-13T05:01:03.645693Z","shell.execute_reply.started":"2022-06-13T05:01:03.609925Z","shell.execute_reply":"2022-06-13T05:01:03.644805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's now plot over the first pair of coords over Geopandas' built-in map! We define another variable, world, to the geopandas module with the read_file function to read out the file given, containing the geopandas module again but with the datasets attribute along with the get_path function to get the path directory, containing natural_earth_lowres. Furthermore, we define another variable, ax, to the world variable figure and plug it with the plot function to jot down our geo figure, setting the color parameter to white and the edgecolor set to black. We then use the plot function to the pairs_gdf geo dataframe to plot down the coordinates, setting the ax parameter to ax and color parameter set to green. Finally, we show the figure with the show function to the plt module.","metadata":{}},{"cell_type":"code","source":"world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\nax = world.plot(color=\"white\", edgecolor=\"black\")\npairs_gdf.plot(ax=ax, color='red')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:01:03.647064Z","iopub.execute_input":"2022-06-13T05:01:03.647338Z","iopub.status.idle":"2022-06-13T05:02:28.728158Z","shell.execute_reply.started":"2022-06-13T05:01:03.647308Z","shell.execute_reply":"2022-06-13T05:02:28.7274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When we ran this plot above, we see that the plots clampered together in North America, South America, Europe, and parts of Asia. We also saw some plots of POIs in Antarctica, since we observed four plots in there. So, let's heatmap it with Folium!","metadata":{}},{"cell_type":"markdown","source":"Before we sizzle up plotting the heatmaps, we need to import three important modules: folium, plugins from folium itself, and HeatMap from folium with the plugins module. \n\nAfter that, let's get on to heat up the heatmaps! First, we convert the first pair of latitudes and longitudes of our pairs_df dataframe by redefining them to themself with the astype function, containing the float boolean. \n\nNext, we define another variable, heat_data_one to an array containing another array of the row dataframe with the data indexes of latitude and longitude, since the row dataframe along with the index variable looped in the row iteration in pairs_df dataframe with the iterrows function.\n\nThen, we create another variable, basemap to the folium module with the Map function to create a whole interactive map, setting the location parameter to an array of any two numbers for indicating the current location and the zoom_start parameter to 2 for zooming in to the starting point. We also call out the HeatMap function to apply the heatmaps of the heat_data_one dataframe, setting the radius parameter to 10 and the blur parameter to 5 and apply it with the add_to function, containing the basemap. Finally, we call out the basemap variable.","metadata":{}},{"cell_type":"code","source":"import folium\nfrom folium import plugins\nfrom folium.plugins import HeatMap\n\npairs_df[\"latitude_1\"] = pairs_df[\"latitude_1\"].astype(float)\npairs_df[\"longitude_1\"] = pairs_df[\"longitude_1\"].astype(float)\n\nheat_data = [[row['latitude_1'], row['longitude_1']] for index, row in pairs_df.iterrows()]","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:02:28.729158Z","iopub.execute_input":"2022-06-13T05:02:28.729868Z","iopub.status.idle":"2022-06-13T05:03:34.706496Z","shell.execute_reply.started":"2022-06-13T05:02:28.729824Z","shell.execute_reply":"2022-06-13T05:03:34.70562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basemap = folium.Map(location=[63, -38], zoom_start=2)\nHeatMap(heat_data, radius=10, blur=5).add_to(basemap)\nbasemap","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:03:34.716108Z","iopub.execute_input":"2022-06-13T05:03:34.716979Z","iopub.status.idle":"2022-06-13T05:03:42.402181Z","shell.execute_reply.started":"2022-06-13T05:03:34.71694Z","shell.execute_reply":"2022-06-13T05:03:42.40146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When you zoom out of the interactive \"Leaflet\" map output, you'll see that most heatmaps took place in most of North America, South America, Africa, Europe, and parts of Asia and Oceania. Thus, we see some heatmaps in Antarctica and in the Arctic. It's kinda like the same as Geopandas in our analysis.","metadata":{}},{"cell_type":"markdown","source":"Now let's try plotting and heatmapping again with Folium and Geopandas, but this time, it's for the second pair of lats and lons. It's vaguely based on what we did on plotting the first pair of lats and lons, but the variables and dataframes were defined differently over the pairs_df dataframe with the data indexes of \"latitude_2\" and \"longitude_2\".","metadata":{}},{"cell_type":"code","source":"pairs_gdf_2 = geopandas.GeoDataFrame(pairs_df, geometry=geopandas.points_from_xy(pairs_df.longitude_2, pairs_df.latitude_2))\npairs_gdf_2","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:03:42.403113Z","iopub.execute_input":"2022-06-13T05:03:42.403432Z","iopub.status.idle":"2022-06-13T05:03:43.268107Z","shell.execute_reply.started":"2022-06-13T05:03:42.4034Z","shell.execute_reply":"2022-06-13T05:03:43.267544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\nax = world.plot(color=\"white\", edgecolor=\"black\")\npairs_gdf_2.plot(ax=ax, color='blue')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:03:43.268979Z","iopub.execute_input":"2022-06-13T05:03:43.269561Z","iopub.status.idle":"2022-06-13T05:05:04.062421Z","shell.execute_reply.started":"2022-06-13T05:03:43.269523Z","shell.execute_reply":"2022-06-13T05:05:04.061472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_df[\"latitude_2\"] = pairs_df[\"latitude_2\"].astype(float)\npairs_df[\"longitude_2\"] = pairs_df[\"longitude_2\"].astype(float)\n\nheat_data = [[row['latitude_2'], row['longitude_2']] for index, row in pairs_df.iterrows()]","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:05:04.063574Z","iopub.execute_input":"2022-06-13T05:05:04.063809Z","iopub.status.idle":"2022-06-13T05:06:08.255074Z","shell.execute_reply.started":"2022-06-13T05:05:04.06378Z","shell.execute_reply":"2022-06-13T05:06:08.254152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basemap = folium.Map(location=[63, -38], zoom_start=2)\nHeatMap(heat_data, radius=10, blur=5).add_to(basemap)\nbasemap","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:06:08.256484Z","iopub.execute_input":"2022-06-13T05:06:08.256724Z","iopub.status.idle":"2022-06-13T05:06:14.882723Z","shell.execute_reply.started":"2022-06-13T05:06:08.256697Z","shell.execute_reply":"2022-06-13T05:06:14.881809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After running four sets of code cells, we merely saw a difference that some first pairs of lats and lons aren't the same as the second pairs of lats and lons. Speaking of which, we may find out the number of True and False matches by plotting them, on Seaborn again.","metadata":{}},{"cell_type":"markdown","source":"For counting the true and false matches on Seaborn, we use the sns module with the catplot function to make another categorical plot, setting the data parameter to the pairs_df dataframe, the x parameter set to \"match\", and the kind parameter to set to \"count\".","metadata":{}},{"cell_type":"code","source":"sns.catplot(data=pairs_df, x=\"match\", kind=\"count\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:06:14.883881Z","iopub.execute_input":"2022-06-13T05:06:14.884104Z","iopub.status.idle":"2022-06-13T05:06:52.710229Z","shell.execute_reply.started":"2022-06-13T05:06:14.884077Z","shell.execute_reply":"2022-06-13T05:06:52.709197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As always, there are almost 400K data entities saying that the pairs are True, and 180K of data entities saying that the pairs are False. In that case, there are more True data entities than False data entities.\n\nSince we're done covering the chapter with our EDA of the pairs_df dataframe, let's cover with EDA on the next chapter over the train_df dataframe! ","metadata":{}},{"cell_type":"markdown","source":"### Chapter 2: train_df\nSince we've done analyzing the data in the pairs_df dataframe, let's go on to analyzing the train_df dataframe!","metadata":{}},{"cell_type":"markdown","source":"To see the number of countries specified in the train_df dataframe, we define a variable, country, to what we did for analyzing the pairs_df dataframe but over the train_df dataframe that has the country data attribute.\n\nThen, we use the sns module with the catplot function, setting six parameters inside: x to country, y to count, data to the country dataframe with the head function displaying out the first 20 data entities, kind set to bar, color set to the first letter of the color name, and aspect set to 2.","metadata":{}},{"cell_type":"code","source":"country = train_df.country.value_counts().to_frame().reset_index().rename(columns={'index': 'country', 'country': 'count'})\n\nsns.catplot(x=\"country\", y=\"count\", data=country.head(20), kind=\"bar\", color=\"b\", aspect=2)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:06:52.711421Z","iopub.execute_input":"2022-06-13T05:06:52.711631Z","iopub.status.idle":"2022-06-13T05:06:53.145517Z","shell.execute_reply.started":"2022-06-13T05:06:52.711606Z","shell.execute_reply":"2022-06-13T05:06:53.144705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When we examined the graph carefully, we made a good observation of this graph's difference to the pairs_df country_1 and country_2 data graphs. The most data entries for country data in train_df is the United States, while the least data entries is Saudi Arabia instead of Italy.\n\nNow, let's find out the number of categories in this train_df dataframe we're in!","metadata":{}},{"cell_type":"markdown","source":"First, before plotting down the number of categories with Plotly, we follow the same thing again and again, displaying the top 20 of the categories data index in the train_df dataframe.\n\nWe then define the variable fig again but this time, defining the fig variable to the go module (from the plotly main module with the graph_objects submodule) with the Figure function to create a new Plotly Go figure, setting the data parameter to the go module again with the Bar function to create a bar chart, setting four parameters inside: x set to the categories with the categories data index set to display the first 20 data entities, y set to the categories with the count data index set to display the first 20 data entities, text set to same as what we did to setting up the y parameter, and textposition set to auto. \n\nFurthermore, we can customize the aspect of our bar chart figure by using the update_traces to the fig variable, setting the marker color to any rgb-formatted color, marker_line_color set to any rgb-formatted color, marker_line_width set to 1.5, and opacity set to 0.6. Finally, we show our bar figure by using the show function to the fig variable.","metadata":{}},{"cell_type":"code","source":"categories = train_df.categories.value_counts().to_frame().reset_index().rename(columns = {'index':'categories', 'categories':'count'})\n\nfig = go.Figure(data=[go.Bar(\n            x=categories[\"categories\"].head(20), y=categories[\"count\"].head(20),\n            text=categories[\"count\"].head(20),\n            textposition='auto',\n        )])\n\nfig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.6)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:06:53.146692Z","iopub.execute_input":"2022-06-13T05:06:53.146959Z","iopub.status.idle":"2022-06-13T05:06:53.290991Z","shell.execute_reply.started":"2022-06-13T05:06:53.146931Z","shell.execute_reply":"2022-06-13T05:06:53.290451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unlike the categories_1 and (like) categories_2 data graphs from the pairs_df dataframe analysis, the most data entries is Residential Buildings while the least is Bars.\n\nWithout further ado, let's head on to geo-plotting, with Geopandas and Folium!","metadata":{}},{"cell_type":"markdown","source":"To geo-plot the data from the train_df dataframe with Geopandas, we define a new geodataframe called train_gdf to the geopandas module that has the the GeoDataFrame function to create a new geo-df, applying the train_df dataframe inside, and setting the geometry parameter to the geopandas module that has the points_from_xy function for creating the coordinates, setting the lats and lons with the train_df dataframe that has the longitude and latitude data attributes.","metadata":{}},{"cell_type":"code","source":"train_gdf = geopandas.GeoDataFrame(train_df, geometry=geopandas.points_from_xy(train_df.longitude, train_df.latitude))","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:06:53.291935Z","iopub.execute_input":"2022-06-13T05:06:53.292226Z","iopub.status.idle":"2022-06-13T05:06:53.445978Z","shell.execute_reply.started":"2022-06-13T05:06:53.292202Z","shell.execute_reply":"2022-06-13T05:06:53.445135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's see the train_gdf GeoDataFrame!","metadata":{}},{"cell_type":"code","source":"train_gdf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:06:53.447053Z","iopub.execute_input":"2022-06-13T05:06:53.447338Z","iopub.status.idle":"2022-06-13T05:06:53.46718Z","shell.execute_reply.started":"2022-06-13T05:06:53.447309Z","shell.execute_reply":"2022-06-13T05:06:53.466396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have the geometry data on the train_gdf geodataframe. With that, let's plot the points from it!","metadata":{}},{"cell_type":"markdown","source":"First, we define a variable, world, to the geopandas module with the read_file function to read the file specified, which is the geopandas module again with the datasets attribute along with the get_path function, setting the naturalearth_lowres built-in path file.\n\nNext, we define another variable, ax, to the world variable and apply the plots with the plot function, setting the color parameter to white and the edgecolor parameter to black. We then use the plot function again to the train_gdf dataframe, setting the ax parameter to ax and the color parameter to any color. Finally, we show our geo-plotted figure by using the plt module with the show module.","metadata":{}},{"cell_type":"code","source":"world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\nax = world.plot(color=\"white\", edgecolor=\"black\")\ntrain_gdf.plot(ax=ax, color='purple')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:13:14.497925Z","iopub.execute_input":"2022-06-13T05:13:14.49829Z","iopub.status.idle":"2022-06-13T05:15:54.223876Z","shell.execute_reply.started":"2022-06-13T05:13:14.498244Z","shell.execute_reply":"2022-06-13T05:15:54.223019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Like to our plotting analysis of the first and second lats and lons from the pairs_gdf geodataframe, we see that most points were clamped up together in North America, South America, Europe, and Southeast Asia. However, we merely see some extra points in the East Pacific, and in Anarctica.","metadata":{}},{"cell_type":"markdown","source":"Without a doubt, let's proceed to heatmapping! Before we start heatmapping, we re-define the train_df dataframe that has the latitude and longitude data to itself converting to a float with the astype function, containing the float boolean. Thus, we define another variable, heat_data to an array containing another array that held the row variable that has the latitude and longitude data indexes, and on outside of that, a for loop was made, looping the index and row variables in the train_df dataframe with the iterrows function to iter every row of it.\n\nNow let's create the heat in the maps! First, we define a variable, basemap, to the folium module that has the Map function to create a new map, setting the location parameter to an array with any two numbers and the zoom_start parameter to any less number. \n\nNext, we call the HeatMap function, setting the heat_data inside of it, the radius parameter to 10 and the blur parameter to 5 and then add it to the basemap variable map. Finally, we call out the basemap function.","metadata":{}},{"cell_type":"code","source":"train_df[\"latitude\"] = train_df[\"latitude\"].astype(float)\ntrain_df[\"longitude\"] = train_df[\"longitude\"].astype(float)\nheat_data = [[row[\"latitude\"], row[\"longitude\"]] for index, row in train_df.iterrows()]","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:46:21.635228Z","iopub.execute_input":"2022-06-13T05:46:21.635902Z","iopub.status.idle":"2022-06-13T05:48:33.29948Z","shell.execute_reply.started":"2022-06-13T05:46:21.635867Z","shell.execute_reply":"2022-06-13T05:48:33.298497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basemap = folium.Map(location=[54, -39], zoom_start=1)\nHeatMap(heat_data, radius=10, blur=5).add_to(basemap)\nbasemap","metadata":{"execution":{"iopub.status.busy":"2022-06-13T05:55:37.157148Z","iopub.execute_input":"2022-06-13T05:55:37.157461Z","iopub.status.idle":"2022-06-13T05:55:51.641452Z","shell.execute_reply.started":"2022-06-13T05:55:37.157427Z","shell.execute_reply":"2022-06-13T05:55:51.640489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After analyzing this heatmap above, we made a correlation saying that the heatmap is almost similar to what we plotted out in GeoPandas!\n\nAnd with that, We've done chapter 2 of the train_df dataframe!","metadata":{}},{"cell_type":"markdown","source":"## Conclusion\nWe did it! We used EDA on the Foursquare competition data and travel around the world with that! However, we asked another question, \"Is our world a small world after all?\" We may never know, since our world has a vast majority of a large number of POIs.","metadata":{"execution":{"iopub.status.busy":"2022-06-13T06:05:10.945315Z","iopub.execute_input":"2022-06-13T06:05:10.945964Z","iopub.status.idle":"2022-06-13T06:05:11.252483Z","shell.execute_reply.started":"2022-06-13T06:05:10.945926Z","shell.execute_reply":"2022-06-13T06:05:11.251615Z"}}}]}