{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, let us see how to create additional matched pairs data that can be used for augmenting the `pairs.csv` file","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\ntrain_df = pd.read_csv(\"/kaggle/input/foursquare-location-matching/train.csv\")\ntrain_df.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-15T09:34:09.156737Z","iopub.execute_input":"2022-04-15T09:34:09.157301Z","iopub.status.idle":"2022-04-15T09:34:09.18611Z","shell.execute_reply.started":"2022-04-15T09:34:09.157176Z","shell.execute_reply":"2022-04-15T09:34:09.185277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are given the `point_of_interest` column. If two rows have the same `point_of_interest` value, then it means that both the ids represent the same place and is a match in our context.\n\nLet us look at tha `pairs.csv` file to get an idea about the structure so as to craete matched pairs in same format.","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:34:34.530634Z","iopub.execute_input":"2022-04-15T09:34:34.530914Z","iopub.status.idle":"2022-04-15T09:34:43.563475Z","shell.execute_reply.started":"2022-04-15T09:34:34.530881Z","shell.execute_reply":"2022-04-15T09:34:43.562851Z"}}},{"cell_type":"code","source":"pairs_df = pd.read_csv(\"/kaggle/input/foursquare-location-matching/pairs.csv\")\npairs_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:35:02.529698Z","iopub.execute_input":"2022-04-15T09:35:02.529975Z","iopub.status.idle":"2022-04-15T09:35:09.799816Z","shell.execute_reply.started":"2022-04-15T09:35:02.529942Z","shell.execute_reply":"2022-04-15T09:35:09.798972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:35:42.729285Z","iopub.execute_input":"2022-04-15T09:35:42.729543Z","iopub.status.idle":"2022-04-15T09:35:42.735614Z","shell.execute_reply.started":"2022-04-15T09:35:42.729515Z","shell.execute_reply":"2022-04-15T09:35:42.734835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pairs_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:48:53.763333Z","iopub.execute_input":"2022-04-15T09:48:53.763828Z","iopub.status.idle":"2022-04-15T09:48:53.772122Z","shell.execute_reply.started":"2022-04-15T09:48:53.763786Z","shell.execute_reply":"2022-04-15T09:48:53.771358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the `pairs.csv` file has `id_1` attributes followed by `id_2` attributes and then finally a match column. \n\nSo let us create matched pairs in the same format now.","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:35:48.059119Z","iopub.execute_input":"2022-04-15T09:35:48.059733Z","iopub.status.idle":"2022-04-15T09:35:48.066208Z","shell.execute_reply.started":"2022-04-15T09:35:48.059686Z","shell.execute_reply":"2022-04-15T09:35:48.065439Z"}}},{"cell_type":"code","source":"match_df = pd.merge(train_df, train_df, on=\"point_of_interest\", suffixes=('_1', '_2'))\nmatch_df = match_df[match_df[\"id_1\"]!=match_df[\"id_2\"]]\nmatch_df = match_df.drop([\"point_of_interest\"], axis=1)\nmatch_df[\"match\"] = True\nmatch_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:49:03.978019Z","iopub.execute_input":"2022-04-15T09:49:03.978845Z","iopub.status.idle":"2022-04-15T09:49:17.529631Z","shell.execute_reply.started":"2022-04-15T09:49:03.9788Z","shell.execute_reply":"2022-04-15T09:49:17.528719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"match_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:39:07.740686Z","iopub.execute_input":"2022-04-15T09:39:07.740977Z","iopub.status.idle":"2022-04-15T09:39:07.746928Z","shell.execute_reply.started":"2022-04-15T09:39:07.740948Z","shell.execute_reply":"2022-04-15T09:39:07.745998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"match_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:39:56.850165Z","iopub.execute_input":"2022-04-15T09:39:56.850665Z","iopub.status.idle":"2022-04-15T09:40:02.144848Z","shell.execute_reply.started":"2022-04-15T09:39:56.850621Z","shell.execute_reply":"2022-04-15T09:40:02.143942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Please note that we have only added `match=True` rows in this notebook. We can create some negative samples for non-match and then use that for training in addition to `pairs.csv` dataset.\n\nHappy Kaggling!","metadata":{"execution":{"iopub.status.busy":"2022-04-15T09:42:56.304799Z","iopub.execute_input":"2022-04-15T09:42:56.306168Z","iopub.status.idle":"2022-04-15T09:42:56.345747Z","shell.execute_reply.started":"2022-04-15T09:42:56.306115Z","shell.execute_reply":"2022-04-15T09:42:56.345173Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}