{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T11:26:22.105271Z","iopub.execute_input":"2022-04-26T11:26:22.105667Z","iopub.status.idle":"2022-04-26T11:26:22.12525Z","shell.execute_reply.started":"2022-04-26T11:26:22.105582Z","shell.execute_reply":"2022-04-26T11:26:22.124613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport copy\nfrom collections import deque\nimport random\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:26:22.288497Z","iopub.execute_input":"2022-04-26T11:26:22.28892Z","iopub.status.idle":"2022-04-26T11:26:22.297409Z","shell.execute_reply.started":"2022-04-26T11:26:22.288888Z","shell.execute_reply":"2022-04-26T11:26:22.296399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we start by putting in place the structure of our code","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:26:22.380988Z","iopub.execute_input":"2022-04-26T11:26:22.381289Z","iopub.status.idle":"2022-04-26T11:26:22.384689Z","shell.execute_reply.started":"2022-04-26T11:26:22.38126Z","shell.execute_reply":"2022-04-26T11:26:22.383976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create_folds.py","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:26:22.56828Z","iopub.execute_input":"2022-04-26T11:26:22.568998Z","iopub.status.idle":"2022-04-26T11:26:22.572349Z","shell.execute_reply.started":"2022-04-26T11:26:22.568955Z","shell.execute_reply":"2022-04-26T11:26:22.571476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport copy\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n# import chainer\n# import chainer.functions as F\n# import chainer.links as L","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:26:22.896607Z","iopub.execute_input":"2022-04-26T11:26:22.897276Z","iopub.status.idle":"2022-04-26T11:26:24.269225Z","shell.execute_reply.started":"2022-04-26T11:26:22.897242Z","shell.execute_reply":"2022-04-26T11:26:24.268518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:26:24.271753Z","iopub.execute_input":"2022-04-26T11:26:24.272716Z","iopub.status.idle":"2022-04-26T11:26:24.27641Z","shell.execute_reply.started":"2022-04-26T11:26:24.272675Z","shell.execute_reply":"2022-04-26T11:26:24.275479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_embed = 30\nnum_prod_to_rec = 12 # number of products to recommend to a user at each time step\nbeta = 0.5\nscale = 100\n# episode_length = 128","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:26:24.277789Z","iopub.execute_input":"2022-04-26T11:26:24.278362Z","iopub.status.idle":"2022-04-26T11:26:24.286157Z","shell.execute_reply.started":"2022-04-26T11:26:24.278288Z","shell.execute_reply":"2022-04-26T11:26:24.285476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transactions_train = '../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv'\ndf_transactions = pd.read_csv(transactions_train,\n                             dtype= {\n                                 'customer_id': 'str',\n                                 'article_id': 'str'\n                             })\ndf_transactions['t_dat'] = pd.to_datetime(df_transactions['t_dat'])\ndf_transactions = df_transactions.set_index('t_dat')\nprint(df_transactions.index.min(), df_transactions.index.max())\ndf_transactions.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:26:24.289511Z","iopub.execute_input":"2022-04-26T11:26:24.290058Z","iopub.status.idle":"2022-04-26T11:27:32.594402Z","shell.execute_reply.started":"2022-04-26T11:26:24.290028Z","shell.execute_reply":"2022-04-26T11:27:32.593439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_transactions.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:32.595593Z","iopub.execute_input":"2022-04-26T11:27:32.595931Z","iopub.status.idle":"2022-04-26T11:27:33.085967Z","shell.execute_reply.started":"2022-04-26T11:27:32.595871Z","shell.execute_reply":"2022-04-26T11:27:33.085218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customers = '../input/h-and-m-personalized-fashion-recommendations/customers.csv'\ndf_customers = pd.read_csv(customers,\n                             dtype= {\n                                 'customer_id': 'str'\n                             })","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:33.090391Z","iopub.execute_input":"2022-04-26T11:27:33.090807Z","iopub.status.idle":"2022-04-26T11:27:37.771497Z","shell.execute_reply.started":"2022-04-26T11:27:33.090769Z","shell.execute_reply":"2022-04-26T11:27:37.770761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_customers.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:37.77276Z","iopub.execute_input":"2022-04-26T11:27:37.773089Z","iopub.status.idle":"2022-04-26T11:27:37.787869Z","shell.execute_reply.started":"2022-04-26T11:27:37.773046Z","shell.execute_reply":"2022-04-26T11:27:37.787227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_customers.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:37.789084Z","iopub.execute_input":"2022-04-26T11:27:37.789462Z","iopub.status.idle":"2022-04-26T11:27:38.318579Z","shell.execute_reply.started":"2022-04-26T11:27:37.789427Z","shell.execute_reply":"2022-04-26T11:27:38.317862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"products = '../input/h-and-m-personalized-fashion-recommendations/articles.csv'\ndf_products = pd.read_csv(products,\n                             dtype= {\n                                 'article_id': 'str'\n                             })","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:38.319826Z","iopub.execute_input":"2022-04-26T11:27:38.320086Z","iopub.status.idle":"2022-04-26T11:27:39.105524Z","shell.execute_reply.started":"2022-04-26T11:27:38.320051Z","shell.execute_reply":"2022-04-26T11:27:39.104814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_products.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:39.10873Z","iopub.execute_input":"2022-04-26T11:27:39.108993Z","iopub.status.idle":"2022-04-26T11:27:39.265062Z","shell.execute_reply.started":"2022-04-26T11:27:39.108957Z","shell.execute_reply":"2022-04-26T11:27:39.264053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# embed_prod = nn.Embedding(len(df_products.index), len_embed)\nembed_prod = torch.randn(len(df_products.index), len_embed)\nembed_prod = embed_prod.to(device, dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:39.266441Z","iopub.execute_input":"2022-04-26T11:27:39.266714Z","iopub.status.idle":"2022-04-26T11:27:41.753233Z","shell.execute_reply.started":"2022-04-26T11:27:39.266679Z","shell.execute_reply":"2022-04-26T11:27:41.752097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_prod.get_device()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:41.754472Z","iopub.execute_input":"2022-04-26T11:27:41.754749Z","iopub.status.idle":"2022-04-26T11:27:41.763203Z","shell.execute_reply.started":"2022-04-26T11:27:41.754714Z","shell.execute_reply":"2022-04-26T11:27:41.762519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# embed_prod(torch.LongTensor([3]))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:41.764453Z","iopub.execute_input":"2022-04-26T11:27:41.764871Z","iopub.status.idle":"2022-04-26T11:27:41.770009Z","shell.execute_reply.started":"2022-04-26T11:27:41.764833Z","shell.execute_reply":"2022-04-26T11:27:41.769136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp = embed_prod(torch.LongTensor([3,4])).squeeze()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:41.77132Z","iopub.execute_input":"2022-04-26T11:27:41.771787Z","iopub.status.idle":"2022-04-26T11:27:41.779198Z","shell.execute_reply.started":"2022-04-26T11:27:41.771749Z","shell.execute_reply":"2022-04-26T11:27:41.778467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:41.780481Z","iopub.execute_input":"2022-04-26T11:27:41.780787Z","iopub.status.idle":"2022-04-26T11:27:41.788001Z","shell.execute_reply.started":"2022-04-26T11:27:41.780749Z","shell.execute_reply":"2022-04-26T11:27:41.787083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for elt in temp:\n#     print(elt)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:41.789308Z","iopub.execute_input":"2022-04-26T11:27:41.790108Z","iopub.status.idle":"2022-04-26T11:27:41.796886Z","shell.execute_reply.started":"2022-04-26T11:27:41.790075Z","shell.execute_reply":"2022-04-26T11:27:41.796045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input1 = torch.randn(100, 128)\n# input1","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:41.798196Z","iopub.execute_input":"2022-04-26T11:27:41.798525Z","iopub.status.idle":"2022-04-26T11:27:41.806361Z","shell.execute_reply.started":"2022-04-26T11:27:41.798486Z","shell.execute_reply":"2022-04-26T11:27:41.805626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input2 = torch.randn(100, 128)\n# cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n# output = cos(input1, input2)\n# output","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:41.809347Z","iopub.execute_input":"2022-04-26T11:27:41.810257Z","iopub.status.idle":"2022-04-26T11:27:41.814667Z","shell.execute_reply.started":"2022-04-26T11:27:41.810222Z","shell.execute_reply":"2022-04-26T11:27:41.81361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"date_split = '2020-09-15'\ntrain = df_transactions[:date_split]\ntest = df_transactions[date_split:]\nlen(train), len(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:41.816351Z","iopub.execute_input":"2022-04-26T11:27:41.816928Z","iopub.status.idle":"2022-04-26T11:27:42.272375Z","shell.execute_reply.started":"2022-04-26T11:27:41.816879Z","shell.execute_reply":"2022-04-26T11:27:42.271596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_custom = nn.Embedding(len(df_customers.index), len_embed)\nembed_custom = embed_custom.to(device, dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.273863Z","iopub.execute_input":"2022-04-26T11:27:42.27413Z","iopub.status.idle":"2022-04-26T11:27:42.704285Z","shell.execute_reply.started":"2022-04-26T11:27:42.274096Z","shell.execute_reply":"2022-04-26T11:27:42.703491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# embed_custom(torch.LongTensor([3])).squeeze()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.706334Z","iopub.execute_input":"2022-04-26T11:27:42.70654Z","iopub.status.idle":"2022-04-26T11:27:42.710951Z","shell.execute_reply.started":"2022-04-26T11:27:42.706514Z","shell.execute_reply":"2022-04-26T11:27:42.710267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first = embed_custom(torch.LongTensor([3]))\n# with torch.no_grad():\n#     second = first\n# second","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.712407Z","iopub.execute_input":"2022-04-26T11:27:42.7129Z","iopub.status.idle":"2022-04-26T11:27:42.722391Z","shell.execute_reply.started":"2022-04-26T11:27:42.712863Z","shell.execute_reply":"2022-04-26T11:27:42.721677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# second.detach()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.723853Z","iopub.execute_input":"2022-04-26T11:27:42.724392Z","iopub.status.idle":"2022-04-26T11:27:42.735076Z","shell.execute_reply.started":"2022-04-26T11:27:42.724352Z","shell.execute_reply":"2022-04-26T11:27:42.734113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# second","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.736595Z","iopub.execute_input":"2022-04-26T11:27:42.737119Z","iopub.status.idle":"2022-04-26T11:27:42.744229Z","shell.execute_reply.started":"2022-04-26T11:27:42.737083Z","shell.execute_reply":"2022-04-26T11:27:42.743446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# environment.py\n# in this cell we build the environment class that simulate a RL environment\n\nclass Environment:\n    def __init__(self, data_transactions, emb_customers, emb_products, df_customers, df_products):\n        self.data = data_transactions\n        self.emb_customers = emb_customers\n        self.emb_prod = emb_products\n        self.customers = df_customers\n        self.products = df_products\n        # self.reset()\n        \n    def reset(self):\n        self.done = False\n        self.current_pos = 0\n        # we must return the informations about the current user (and the products bought by him)\n        # let's go first with the current user by getting his id\n        self.userid = self.data.iloc[self.current_pos, 0]\n        # from the userid, we must get its corresponding index  in df_customers\n        self.user_index = self.customers.index[self.customers['customer_id']==self.userid].tolist()[0]\n        # now we can get the user embedding informations from self.emb_customers\n        self.user_embed = self.emb_customers(torch.LongTensor([self.user_index]).to(device, dtype=torch.long))\n        print(self.user_embed.get_device())\n        # in this first version we are not going to consider the last products used by our customer\n        return self.user_embed\n    \n    def step(self, act):\n        # here act is a list of 12 (num_prod_to_rec) products to recommend by their indices.\n        # For example, it could be [1, 2, 3, ..., 11, 12] \n        reward = 0\n        # First, me must find the index of the actual product used by the customer in self.products\n        # let's go first with the current product by getting his id\n        self.product_id = self.data.iloc[self.current_pos, 1]\n        # from the product_id, we must get its corresponding index in df_products\n        self.prod_index = self.products.index[self.products['article_id']==self.product_id].tolist()[0]\n        reward = self.compute_reward(act, self.prod_index)\n        if (self.current_pos < len(self.data.index)):\n#             if ((self.current_pos % episode_length)!=0):\n            self.current_pos += 1\n            if (self.current_pos < len(self.data.index)):\n                self.userid = self.data.iloc[self.current_pos, 0]\n                self.user_index = self.customers.index[self.customers['customer_id']==self.userid].tolist()[0]\n                self.user_embed = self.emb_customers(torch.LongTensor([self.user_index]).to(device, dtype=torch.long))\n                self.done = False\n                return self.user_embed, reward, self.done\n            else:\n                self.done = True\n                return self.user_embed, reward, self.done\n    \n    def compute_reward(self, proposed_products, actual_product):\n        if (actual_product in proposed_products):\n            # take the position where the matching occurs\n            postion = proposed_products.index(actual_product)\n            proposed_products = proposed_products[:position+1]\n        embed_proposed = self.emb_prod[torch.LongTensor(proposed_products).to(device, dtype=torch.long)]\n        embed_actual = self.emb_prod[torch.LongTensor([actual_product]).to(device, dtype=torch.long)]\n        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n        output = cos(embed_proposed, embed_actual)\n        coeffs = [math.pow(beta, t) for t in range(len(proposed_products))]\n        # convert coeffs to tensor\n        coeffs = torch.Tensor(coeffs).to(device, dtype=torch.float)\n        # apply element wise multiplication to output\n        output = torch.mul(output, coeffs)\n        # we sum that and multiply by 100\n        reward = torch.sum(output)\n        reward = torch.mul(reward, scale)\n        reward = reward.item()\n        return reward","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.747157Z","iopub.execute_input":"2022-04-26T11:27:42.747404Z","iopub.status.idle":"2022-04-26T11:27:42.766624Z","shell.execute_reply.started":"2022-04-26T11:27:42.747374Z","shell.execute_reply":"2022-04-26T11:27:42.765684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# models.py\nclass Actor(torch.nn.Module):\n    def __init__(self, n_input, n_weight_out, n_features_out, product_feats):\n        # n_input: number of features that represents a customer\n        # n_weight_out: number of products we want to recommend represent by their features\n        # n_features_out: number of features of each vector of recommend products\n        # product_feats: matrix of vector products. Each line as the same number of\n        # features as n_features_out\n        super(Actor, self).__init__()\n        self.n_input = n_input\n        self.n_weight_out = n_weight_out\n        self.n_features_out = n_features_out\n        self.feats = product_feats\n        l1 = 4 * self.n_input\n        l2 = 2 * l1\n        self.l1 = nn.Linear(self.n_input, l1)\n        self.l2 = nn.Linear(l1, l2)\n        self.l3 = nn.Linear(l2, self.n_weight_out * self.n_features_out)\n    def forward(self, x):\n        x = F.relu(self.l1(x))\n        x = F.relu(self.l2(x))\n        x = F.relu(self.l3(x))\n        the_weights = x.view(-1, self.n_weight_out, self.n_features_out)\n        # take the dot product between the_weights and self.feats\n        product_trans = torch.transpose(self.feats, 0, 1)\n        all_scalar_prods = torch.matmul(the_weights, product_trans)\n        # output shape of previous operation : (1, n_weight_out, num_of_products)\n        # find the indices with the highest scalar products\n        argmax = torch.argmax(all_scalar_prods, dim=2)\n        return argmax\n\nclass Critic(torch.nn.Module):\n    def __init__(self, n_input, n_rec_prod):\n        # n_input: number of features that represents a customer\n        # n_rec_prod: number of products recommend by our actor\n        super(Critic, self).__init__()\n        self.n_input = n_input\n        self.n_rec_prod = n_rec_prod\n        l1 = 4*(self.n_input + self.n_rec_prod)\n        l2 = l1\n        l3 = 1\n        self.l1 = nn.Linear(self.n_input + self.n_rec_prod, l1)\n        self.l2 = nn.Linear(l1, l2)\n        self.l3 = nn.Linear(l2, l3)\n    def forward(self, x, act):\n        x = torch.cat((x, act), -1)\n        x = F.relu(self.l1(x))\n        x = F.relu(self.l2(x))\n        x = self.l3(x)\n        return x\n\nclass Model(torch.nn.Module):\n    def __init__(self, actor, critic):\n        super(Model, self).__init__()\n        self.actor = actor\n        self.critic = critic\n    def forward(self, x):\n        act = self.actor(x)\n        crit = self.critic(x, act)\n        return act, crit","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.768123Z","iopub.execute_input":"2022-04-26T11:27:42.768801Z","iopub.status.idle":"2022-04-26T11:27:42.785983Z","shell.execute_reply.started":"2022-04-26T11:27:42.768765Z","shell.execute_reply":"2022-04-26T11:27:42.7851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Just for testing purpose, we generate product_feats\nprod_feats = torch.rand(105542, 30)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.789223Z","iopub.execute_input":"2022-04-26T11:27:42.789447Z","iopub.status.idle":"2022-04-26T11:27:42.825624Z","shell.execute_reply.started":"2022-04-26T11:27:42.789416Z","shell.execute_reply":"2022-04-26T11:27:42.824855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train.py\nactor_model = Actor(n_input=len_embed, n_weight_out=num_prod_to_rec, n_features_out=30, product_feats=embed_prod)\nactor_model.to(device)\ncritic_model = Critic(n_input=len_embed, n_rec_prod=num_prod_to_rec)\ncritic_model.to(device)\nmodel = Model(actor_model, critic_model)\nmodel.to(device)\nmodel2 = copy.deepcopy(model)\nmodel2.to(device)\nmodel2.load_state_dict(model.state_dict())","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.829866Z","iopub.execute_input":"2022-04-26T11:27:42.830207Z","iopub.status.idle":"2022-04-26T11:27:42.855821Z","shell.execute_reply.started":"2022-04-26T11:27:42.830169Z","shell.execute_reply":"2022-04-26T11:27:42.855076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sync_freq = 50\nloss_fn = torch.nn.MSELoss()\nlearning_rate = 1e-3\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.856941Z","iopub.execute_input":"2022-04-26T11:27:42.857653Z","iopub.status.idle":"2022-04-26T11:27:42.862668Z","shell.execute_reply.started":"2022-04-26T11:27:42.857615Z","shell.execute_reply":"2022-04-26T11:27:42.861629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nlosses = []\nmem_size = 5000\nbatch_size = 256\nreplay = deque(maxlen=mem_size)\nsyn_freq = 500\ngamma = 0.9\nj=0","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.863846Z","iopub.execute_input":"2022-04-26T11:27:42.86427Z","iopub.status.idle":"2022-04-26T11:27:42.872392Z","shell.execute_reply.started":"2022-04-26T11:27:42.864235Z","shell.execute_reply":"2022-04-26T11:27:42.871372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(epochs):\n    # start a new environment\n    env = Environment(df_transactions, embed_custom, embed_prod, df_customers, df_products)\n    state1 = env.reset()\n    status = 1\n    while(status==1):\n        j += 1\n#         print(j)\n        act_, crit_ = model(state1.detach()) # act_ and crit_ are tensors\n        # step the environment\n        act = act_.view(-1).tolist()\n        state2, reward, done = env.step(act)\n        exp = (state1, reward, state2, done)\n        replay.append(exp)\n        state1 = state2\n        \n        if len(replay) > batch_size:\n            minibatch = random.sample(replay, batch_size)\n            state1_batch = torch.cat([s1 for (s1, r, s2, d) in minibatch])\n            reward_batch = torch.Tensor([r for (s1, r, s2, d) in minibatch])\n            reward_batch = reward_batch.to(device, dtype=torch.float)\n            state2_batch = torch.cat([s2 for (s1, r, s2, d) in minibatch])\n            done_batch = torch.Tensor([d for (s1, r, s2, d) in minibatch])\n            done_batch = done_batch.to(device, dtype=torch.float)\n            _, Q1 = model(state1_batch)\n            with torch.no_grad():\n                _, Q2 = model2(state2_batch.detach())\n            Y = reward_batch + gamma * ((1 - done_batch) * Q2)\n            X = Q1\n            loss = loss_fn(X, Y.detach())\n            clear_output(wait=True)\n            optimizer.zero_grad()\n            loss.backward(retain_graph=True)\n            losses.append(loss.item)\n            optimizer.step()\n            \n            if j % syn_freq == 0:\n                print(j)\n                model2.load_state_dict(model.state_dict())\n        if done:\n            status = 0\nlosses = np.array(losses)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:27:42.873679Z","iopub.execute_input":"2022-04-26T11:27:42.877477Z","iopub.status.idle":"2022-04-26T11:35:32.883531Z","shell.execute_reply.started":"2022-04-26T11:27:42.877438Z","shell.execute_reply":"2022-04-26T11:35:32.882176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# inference.py","metadata":{"execution":{"iopub.status.busy":"2022-04-13T08:18:11.554489Z","iopub.execute_input":"2022-04-13T08:18:11.554724Z","iopub.status.idle":"2022-04-13T08:18:11.567531Z","shell.execute_reply.started":"2022-04-13T08:18:11.554696Z","shell.execute_reply":"2022-04-13T08:18:11.566615Z"}}},{"cell_type":"code","source":"# models.py","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:35:32.884619Z","iopub.status.idle":"2022-04-26T11:35:32.885083Z","shell.execute_reply.started":"2022-04-26T11:35:32.884854Z","shell.execute_reply":"2022-04-26T11:35:32.884877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#config.py","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:35:32.886478Z","iopub.status.idle":"2022-04-26T11:35:32.887102Z","shell.execute_reply.started":"2022-04-26T11:35:32.886852Z","shell.execute_reply":"2022-04-26T11:35:32.886878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_dispatcher.py","metadata":{"execution":{"iopub.status.busy":"2022-04-26T11:35:32.888296Z","iopub.status.idle":"2022-04-26T11:35:32.889089Z","shell.execute_reply.started":"2022-04-26T11:35:32.888838Z","shell.execute_reply":"2022-04-26T11:35:32.888867Z"},"trusted":true},"execution_count":null,"outputs":[]}]}