{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Topic Model Tutorial\nWe want to obtain user and item features from users' past purchase information.\nThere are several ways to do this.\n1. Memory-based\n2. Model-based\n3. Hybrid\n4. Deep-Learning\n\nI present the second method(2. Model-based), which uses a topic model.\nWithout going into the details of the topic model, we consider users as sentences and purchase items as words to cluster users.\nFor a detailed explanation of the topic model, please refer to the following paper.\n\n[Latent Dirichlet Allocation](https://web.archive.org/web/20120501152722/http://jmlr.csail.mit.edu/papers/v3/blei03a.html)\nBlei, David M.; Ng, Andrew Y.; Jordan, Michael I. Journal of Machine Learning Research. 3 (4–5): pp. 993–1022.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:36:26.112912Z","iopub.execute_input":"2022-02-10T15:36:26.113259Z","iopub.status.idle":"2022-02-10T15:36:26.142933Z","shell.execute_reply.started":"2022-02-10T15:36:26.113171Z","shell.execute_reply":"2022-02-10T15:36:26.141857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import LdaModel # https://radimrehurek.com/gensim/models/ldamodel.html\nfrom gensim.corpora.dictionary import Dictionary\nimport pyLDAvis.gensim","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:36:26.145015Z","iopub.execute_input":"2022-02-10T15:36:26.145233Z","iopub.status.idle":"2022-02-10T15:36:27.933914Z","shell.execute_reply.started":"2022-02-10T15:36:26.145206Z","shell.execute_reply":"2022-02-10T15:36:27.932977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv',\n                       dtype = {'article_id': 'object'})\narticles_df = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/articles.csv',\n                          dtype = {'article_id': 'object'})","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:36:50.505513Z","iopub.execute_input":"2022-02-10T15:36:50.506383Z","iopub.status.idle":"2022-02-10T15:37:58.519268Z","shell.execute_reply.started":"2022-02-10T15:36:50.506332Z","shell.execute_reply":"2022-02-10T15:37:58.518368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Can someone please tell me a smart way to do this?\ntemp_dict = {}\nfor customer_id, article_id in zip(train_df['customer_id'], train_df['article_id']):\n    if customer_id in temp_dict:\n        temp_dict[customer_id].append(article_id)\n    else:\n        temp_dict[customer_id] = [article_id]\ncustomer_id_list = []\nraw_corpus = []\nfor customer_id in temp_dict:\n    customer_id_list.append(customer_id)\n    raw_corpus.append(temp_dict[customer_id])\ndel temp_dict","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:37:58.521046Z","iopub.execute_input":"2022-02-10T15:37:58.521257Z","iopub.status.idle":"2022-02-10T15:38:27.492816Z","shell.execute_reply.started":"2022-02-10T15:37:58.521231Z","shell.execute_reply":"2022-02-10T15:38:27.491895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary that maps words to word ids\ndictionary = Dictionary(raw_corpus)\n# Convert to BoW format that can be read by LdaModel\ncorpus = [dictionary.doc2bow(article_id) for article_id in raw_corpus]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:38:27.493982Z","iopub.execute_input":"2022-02-10T15:38:27.494279Z","iopub.status.idle":"2022-02-10T15:40:40.906223Z","shell.execute_reply.started":"2022-02-10T15:38:27.494248Z","shell.execute_reply":"2022-02-10T15:40:40.905147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_topics = 15\nlda = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:40:40.908616Z","iopub.execute_input":"2022-02-10T15:40:40.908971Z","iopub.status.idle":"2022-02-10T15:47:53.062951Z","shell.execute_reply.started":"2022-02-10T15:40:40.90894Z","shell.execute_reply":"2022-02-10T15:47:53.061994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda.save('lda_model.pickle')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:47:53.064606Z","iopub.execute_input":"2022-02-10T15:47:53.065748Z","iopub.status.idle":"2022-02-10T15:47:53.175285Z","shell.execute_reply.started":"2022-02-10T15:47:53.065689Z","shell.execute_reply":"2022-02-10T15:47:53.174279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization\nvis = pyLDAvis.gensim.prepare(lda, corpus, dictionary, n_jobs = 1, sort_topics = False)\npyLDAvis.save_html(vis, 'H&M_topic.html')\npyLDAvis.display(vis)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:47:53.176552Z","iopub.execute_input":"2022-02-10T15:47:53.177164Z","iopub.status.idle":"2022-02-10T15:50:36.523673Z","shell.execute_reply.started":"2022-02-10T15:47:53.177134Z","shell.execute_reply":"2022-02-10T15:50:36.522659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_name_dict = dict(zip(articles_df['article_id'], articles_df['index_name']))\ngarment_group_name_dict = dict(zip(articles_df['article_id'], articles_df['garment_group_name']))\ncolor_name_dict = dict(zip(articles_df['article_id'], articles_df['colour_group_name']))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:50:36.52508Z","iopub.execute_input":"2022-02-10T15:50:36.525925Z","iopub.status.idle":"2022-02-10T15:50:36.643611Z","shell.execute_reply.started":"2022-02-10T15:50:36.525885Z","shell.execute_reply":"2022-02-10T15:50:36.642579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for topic in range(num_topics):\n    print(topic)\n    for article_id, prob in lda.show_topic(topic, 30):\n        print(index_name_dict[article_id] + ' : ' + garment_group_name_dict[article_id] + ' : ' + color_name_dict[article_id])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T15:50:36.645375Z","iopub.execute_input":"2022-02-10T15:50:36.645701Z","iopub.status.idle":"2022-02-10T15:50:36.76183Z","shell.execute_reply.started":"2022-02-10T15:50:36.645658Z","shell.execute_reply":"2022-02-10T15:50:36.76102Z"},"trusted":true},"execution_count":null,"outputs":[]}]}