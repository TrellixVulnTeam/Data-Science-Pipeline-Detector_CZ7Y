{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.applications.xception import Xception,preprocess_input\nimport tensorflow as tf\nfrom keras.preprocessing import image\nfrom keras.layers import Input\nfrom keras.backend import reshape\nfrom sklearn.neighbors import NearestNeighbors\nimport matplotlib.pyplot as plt\n\nimages_dir = '../input/h-and-m-personalized-fashion-recommendations/images/'\n\n\n\ndef getImagePaths(path):\n    \"\"\"\n    Function to Combine Directory Path with individual Image Paths\n    \n    parameters: path(string) - Path of directory\n    returns: image_names(string) - Full Image Path\n    \"\"\"\n    image_names = []\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            fullpath = os.path.join(dirname, filename)\n            image_names.append(fullpath)\n    return image_names\n\ndef preprocess_img(img_path):\n    dsize = (225,225)\n    new_image=cv2.imread(img_path)\n    new_image=cv2.resize(new_image,dsize,interpolation=cv2.INTER_NEAREST)  \n    new_image=np.expand_dims(new_image,axis=0)\n    #print (new_image.shape)\n    new_image=preprocess_input(new_image)\n    return new_image\n\ndef load_data():\n    output=[]\n    output=getImagePaths(images_dir)[:10000]\n    return output\n\n\ndef model():\n    model=Xception(weights='imagenet',include_top=False)\n    for layer in model.layers:\n        layer.trainable=False\n        #model.summary()\n    return model\n\ndef feature_extraction(image_data,model):\n    features=model.predict(image_data)    \n    features=np.array(features)\n    features=features.flatten()\n    return features\n\ndef result_vector_cosine(model,feature_vector,new_img):\n    new_feature = model.predict(new_img)\n    new_feature = np.array(new_feature)\n    new_feature = new_feature.flatten()\n    N_result = 12\n    nbrs = NearestNeighbors(n_neighbors=N_result, metric=\"cosine\").fit(feature_vector)\n    distances, indices = nbrs.kneighbors([new_feature])\n    return(indices)\n\ndef input_show(data):\n    plt.title(\"Query Image\")\n    plt.imshow(data)\n  \ndef show_result(data,result):\n    #fig = plt.figure(figsize=(12,8))\n    for i in range(0,12):\n        index_result=result[0][i]\n        plt.subplot(3,4,i+1)\n        plt.imshow(cv2.imread(data[index_result]))\n    plt.show()\n\ndef main():  \n    features=[]\n    output=load_data()\n    print (len(output))\n    main_model=model()\n    #Limiting the data for training\n    for i in output[:999]:\n        new_img=preprocess_img(i)\n        features.append(feature_extraction(new_img,main_model))\n    feature_vec = np.array(features)\n    result=result_vector_cosine(main_model,feature_vec,preprocess_img(output[1000]))\n    input_show(cv2.imread(output[1000]))\n    show_result(output,result)\n  \n\nif __name__=='__main__':\n    main()    ","metadata":{"execution":{"iopub.status.busy":"2022-02-17T06:18:53.400633Z","iopub.execute_input":"2022-02-17T06:18:53.401203Z","iopub.status.idle":"2022-02-17T06:22:15.053044Z","shell.execute_reply.started":"2022-02-17T06:18:53.401177Z","shell.execute_reply":"2022-02-17T06:22:15.051282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}