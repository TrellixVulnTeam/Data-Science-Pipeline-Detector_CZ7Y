{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* **Introduction :**\n\nThis notebook meant for giving a look a bit closer inside the contents of this kind of malls as a high view. I tried to figure out the different type of datasets exist in the competetion, by expaling some relations between different datasets, and attempting to understand the distribution of data and the importance of each branch...etc.\n\nThe explanation will come out in different ways, interpretaion, tables, histograms, images and curves. ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os  # manipulating with directory for uploading data \nimport matplotlib.pyplot as plt  # ploting curves and figures \nfrom matplotlib import style\nimport seaborn as sns # ploting curves and figures \nimport glob\nimport matplotlib.image as mpimg  # images visulizations \nfrom collections import Counter  # counts operations\nimport operator\nfrom PIL import Image\n\nstyle.use('fivethirtyeight')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***# Importing data from articles.csv to handle and deal with the contents***","metadata":{}},{"cell_type":"code","source":"article_id = pd.read_csv ('../input/h-and-m-personalized-fashion-recommendations/articles.csv')\nreal_data= article_id.drop('detail_desc', axis=1).copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:24:08.325128Z","iopub.execute_input":"2022-04-07T15:24:08.325526Z","iopub.status.idle":"2022-04-07T15:24:09.725096Z","shell.execute_reply.started":"2022-04-07T15:24:08.32548Z","shell.execute_reply":"2022-04-07T15:24:09.724187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**# Getting closer look at the contents**","metadata":{}},{"cell_type":"code","source":"article_id.info() \n# this info declare zeros null and no missing data","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:24:11.644757Z","iopub.execute_input":"2022-04-07T15:24:11.645075Z","iopub.status.idle":"2022-04-07T15:24:11.824747Z","shell.execute_reply.started":"2022-04-07T15:24:11.645041Z","shell.execute_reply":"2022-04-07T15:24:11.824099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# real_data.description\nreal_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:24:11.826032Z","iopub.execute_input":"2022-04-07T15:24:11.826737Z","iopub.status.idle":"2022-04-07T15:24:11.910011Z","shell.execute_reply.started":"2022-04-07T15:24:11.826704Z","shell.execute_reply":"2022-04-07T15:24:11.908876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking out the rows duplications\ndupl = real_data.duplicated()\nif dupl.any():\n    print(dupl)\nelse: print('Data not duplicated')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:32:15.375599Z","iopub.execute_input":"2022-04-07T18:32:15.375991Z","iopub.status.idle":"2022-04-07T18:32:15.59485Z","shell.execute_reply.started":"2022-04-07T18:32:15.375956Z","shell.execute_reply":"2022-04-07T18:32:15.593548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we count the amount of each content separatly \ndef data_count():\n    data_counts = {}\n    for col in real_data.columns:\n        difrnt_data = real_data[col].unique()\n        data_counts[col] = difrnt_data, len(difrnt_data) # counting the unique element in each columns\n \n    df = pd.DataFrame([[i, data_counts[i][-1]] for i in data_counts], columns=['items_name','contents_nbrs'])\n    df.set_index('items_name')\n    return df, data_counts\n    # Deppartment_handling\ndf, data_counts= data_count()\ndf","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:50:37.553435Z","iopub.execute_input":"2022-04-07T18:50:37.554062Z","iopub.status.idle":"2022-04-07T18:50:37.715006Z","shell.execute_reply.started":"2022-04-07T18:50:37.554022Z","shell.execute_reply":"2022-04-07T18:50:37.713861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*  *in the next sections we will go ahead and check the distribution of objects within section and departments in general, and make some comparison among departments, section and indexes*","metadata":{}},{"cell_type":"code","source":"def dep_sec_Gr(reference_col, class_1, class_2, items_1=False, items_2=False, department_content=False, products_types=False):\n    \n    rows_list = []\n    for row in real_data[reference_col].unique():\n        # importing data for each class depensding on the referenced column\n        frst_content = real_data[class_1][(real_data[reference_col] == row)] \n        scnd_content = real_data[class_2][real_data[reference_col] == row]\n\n        if items_1:\n            rows_list.append([row,len(frst_content.unique()), len(scnd_content.unique()), frst_content.unique(),\n                                         scnd_content.unique()])\n            department_content = pd.DataFrame(rows_list, columns=[item for item in items_1]) # dataframe for departments data\n\n        if items_2:\n            rows_list.append([row, len(frst_content.unique()), len(scnd_content.unique()), scnd_content.unique()])\n            products_types = pd.DataFrame(rows_list, columns=[item for item in items_2]) # dataframe for sections data\n\n    return department_content, products_types\n\ndep, _ = dep_sec_Gr(reference_col='department_name', class_1='section_name', class_2='index_name',\n           items_1=['departments_name', 'sections_amount', 'index_amount','sections_name', 'index_names', ])\n\n_, sec = dep_sec_Gr(reference_col='section_name', class_1='index_name', class_2='product_group_name',\n               items_2=['section_name', 'index_amount', 'groups_amount', 'groups_name'])","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:24:17.344881Z","iopub.execute_input":"2022-04-07T15:24:17.345212Z","iopub.status.idle":"2022-04-07T15:24:27.482492Z","shell.execute_reply.started":"2022-04-07T15:24:17.345181Z","shell.execute_reply":"2022-04-07T15:24:27.48149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's find out departs with sects and indexs\ndep","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:24:27.484194Z","iopub.execute_input":"2022-04-07T15:24:27.484553Z","iopub.status.idle":"2022-04-07T15:24:27.510275Z","shell.execute_reply.started":"2022-04-07T15:24:27.48452Z","shell.execute_reply":"2022-04-07T15:24:27.509096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's find out sections with indexs and groups\nsec","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:24:29.644989Z","iopub.execute_input":"2022-04-07T15:24:29.645264Z","iopub.status.idle":"2022-04-07T15:24:29.684775Z","shell.execute_reply.started":"2022-04-07T15:24:29.645238Z","shell.execute_reply":"2022-04-07T15:24:29.684001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visulization 10 biggest dapartments by the amount of contents \n\nbgst_depa = Counter(real_data['department_name']) # counting the amount of each element in each dpart\nbgst_depa = Counter(bgst_depa).most_common(10) # choosing the biggest 10 departs\n\n# creating plot\nx = list(map(lambda x: x[0] , (bgst_depa)))\ny = list(map(lambda x: x[1] , (bgst_depa)))\n\nfig = plt.figure(num=None, figsize=(15, 5), dpi=80)\n\nax = sns.barplot(x=x, y=y) \n\nfor cont in ax.containers:\n    ax.bar_label(cont)\n    \nax = ax.set_xticklabels(ax.get_xmajorticklabels(), rotation=70)\nplt.locator_params ('y', nbins = 10)\n\nplt.title('biggest_department_per_content')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:51:40.293577Z","iopub.execute_input":"2022-04-07T18:51:40.293964Z","iopub.status.idle":"2022-04-07T18:51:41.502002Z","shell.execute_reply.started":"2022-04-07T18:51:40.293922Z","shell.execute_reply":"2022-04-07T18:51:41.500858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's see the most 5 product types in each product group\nproduct_group = real_data['product_group_name'].unique()\nmst5_products= list()\nfor i in product_group:\n    product_type = Counter(real_data['product_type_name'][(real_data['product_group_name'] == i)])\n\n    mst5_products.append(product_type.most_common(5)) # choosing the most 5 products types\n\ndf = pd.DataFrame([mst5_products[i] for i in range(len(mst5_products))], index=product_group[:], columns=[1, 2, 3, 4, 5])\nmst5_products_types = df.T\nmst5_products_types","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:54:55.034818Z","iopub.execute_input":"2022-04-07T18:54:55.035922Z","iopub.status.idle":"2022-04-07T18:54:55.418855Z","shell.execute_reply.started":"2022-04-07T18:54:55.035861Z","shell.execute_reply":"2022-04-07T18:54:55.417778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preaparing for importing and printing out the related images to \n# one sample of the previous mst5 list \n\narticle_id=[]\nfor item in df[1]:\n    article_id.append(real_data['article_id'][(real_data['product_type_name'] == item[0])]) # importing the ids of each type to prepare it for visualiztion\n    \n\n# preparing the paths of each image from images file\nimgs=[]  \nexist = False\nfor idx in range(len(article_id)):\n    for value in article_id[idx].values:\n        for items in glob.glob('/kaggle/input/h-and-m-personalized-fashion-recommendations/images/*'):\n            for img in os.listdir(items):\n                item = int(img.split('.')[0])\n                if item == value:\n                    imgs.append(\"{}/{}\".format(items, img))\n                    exist= True\n                    break\n        if exist:\n            exist= False \n            break\n\n# listing the products images names            \ntypes = list(map(lambda x: x[0], df[1]))\n\n# listing the existed iamges\ny = [img for img in imgs]\n\n# starting the plotting\nplt.figure(figsize=(15, 10))\n\nfor i in range(len(imgs)):\n    plt.subplot(5, 5, i+1)\n    image = Image.open(y[i])\n    plt.imshow(image) \n    plt.axis('off')\n    plt.gca().set_title(types[i]) \n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:55:03.83473Z","iopub.execute_input":"2022-04-07T18:55:03.835036Z","iopub.status.idle":"2022-04-07T18:55:12.821847Z","shell.execute_reply.started":"2022-04-07T18:55:03.835005Z","shell.execute_reply":"2022-04-07T18:55:12.821003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We will handle the objects this time according to the transactions that we get\n* The method depends on reading, distributing and visulizing the datasets per **years** *","metadata":{}},{"cell_type":"code","source":"# importing the transactions file\n\ntrans = pd.read_csv('/kaggle/input/h-and-m-personalized-fashion-recommendations/transactions_train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:24:43.839229Z","iopub.execute_input":"2022-04-07T15:24:43.839493Z","iopub.status.idle":"2022-04-07T15:25:34.198523Z","shell.execute_reply.started":"2022-04-07T15:24:43.839463Z","shell.execute_reply":"2022-04-07T15:25:34.197701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trans.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:25:34.200075Z","iopub.execute_input":"2022-04-07T15:25:34.200407Z","iopub.status.idle":"2022-04-07T15:25:34.215097Z","shell.execute_reply.started":"2022-04-07T15:25:34.200365Z","shell.execute_reply":"2022-04-07T15:25:34.213694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cheking out the null and duplication in transactions file\nnull = trans.isnull()\ndup = trans.duplicated()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:25:34.217464Z","iopub.execute_input":"2022-04-07T15:25:34.218026Z","iopub.status.idle":"2022-04-07T15:26:08.041633Z","shell.execute_reply.started":"2022-04-07T15:25:34.217969Z","shell.execute_reply":"2022-04-07T15:26:08.040898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, nl in enumerate(null.any()):\n    if nl:\n        print(nl)\n    else:print('trans row {} witout null'.format(i+1))\nif not dup.any():\n    print(dup)\nelse:print('trans witout duplication')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:58:16.980397Z","iopub.execute_input":"2022-04-07T18:58:16.981285Z","iopub.status.idle":"2022-04-07T18:58:17.011237Z","shell.execute_reply.started":"2022-04-07T18:58:16.981228Z","shell.execute_reply":"2022-04-07T18:58:17.009914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DatetimeIndex(trans['t_dat']).year\ntrans['t_dat'] = pd.to_datetime(trans.t_dat, format='%Y-%m-%d')","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:26:08.082595Z","iopub.execute_input":"2022-04-07T15:26:08.083133Z","iopub.status.idle":"2022-04-07T15:26:26.631061Z","shell.execute_reply.started":"2022-04-07T15:26:08.083084Z","shell.execute_reply":"2022-04-07T15:26:26.629991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extracting the studied years and their months \nyears = trans['t_dat'].dt.year.unique()\nprint(years)\nfor year in years:\n    month = trans['t_dat'][(trans['t_dat'].dt.year==year)].dt.month.unique()\n    print(f'{year}:',month)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:26:26.632707Z","iopub.execute_input":"2022-04-07T15:26:26.633084Z","iopub.status.idle":"2022-04-07T15:26:42.209276Z","shell.execute_reply.started":"2022-04-07T15:26:26.633043Z","shell.execute_reply":"2022-04-07T15:26:42.208045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the amount and prices of sales in each year\n \ndef determine_year(years): # amin function for importing data based on wanted year\n    trans_year = trans[(trans['t_dat'].dt.year==years)].copy()\n    return trans_year\n\ndef price_nbr_count(years): # counting the price and nbr of sales\n    trans_year = determine_year(years)\n    nbr_sales = len(trans_year.article_id)\n    sales_price = sum(trans_year.price)\n    \n    return nbr_sales, np.round(sales_price, 2)\n\nnbr_sales_18, sales_price_18 = price_nbr_count(2018)\nnbr_sales_19, sales_price_19 = price_nbr_count(2019)\nnbr_sales_20, sales_price_20 = price_nbr_count(2020)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:26:42.21074Z","iopub.execute_input":"2022-04-07T15:26:42.21111Z","iopub.status.idle":"2022-04-07T15:26:58.746326Z","shell.execute_reply.started":"2022-04-07T15:26:42.211077Z","shell.execute_reply":"2022-04-07T15:26:58.745304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_nbr_counts = pd.DataFrame([['2018',nbr_sales_18, sales_price_18],['2019',nbr_sales_19,sales_price_19],\n                                 ['2020',nbr_sales_20,sales_price_20]], columns=['years','sales_amount','sales_toatal_price'])\nprice_nbr_counts","metadata":{"execution":{"iopub.status.busy":"2022-04-07T15:26:58.747782Z","iopub.execute_input":"2022-04-07T15:26:58.748037Z","iopub.status.idle":"2022-04-07T15:26:58.765577Z","shell.execute_reply.started":"2022-04-07T15:26:58.74801Z","shell.execute_reply":"2022-04-07T15:26:58.764848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for counting the best sales per how much and how cost \n\ndef most_sales_price(year):\n    trans_year = determine_year(year)\n    \n    # mst_items\n    count_articles = Counter(trans_year.article_id)\n    articles_id_nbr = count_articles.most_common(20)\n    \n    # sum of price\n    articles_price = {}\n    for item in count_articles: \n        article_pr = trans_year['price'][trans_year['article_id']==item]\n        articles_price[item] = sum(article_pr)\n    \n    articles_id_nbr = count_articles.most_common(20)\n    ids_nbr = [real_data.prod_name.values[real_data.article_id==item[0]] for item in articles_id_nbr] # most 20 prod names\n    \n    sorted_bst = sorted(articles_price.items(), key=operator.itemgetter(1))[-20:]\n    ids_bst = [real_data.prod_name.values[real_data.article_id==item[0]] for item in sorted_bst] # sorting the bst prod names by price \n\n    # dataframe for most and best sales \n    articles_bst = pd.DataFrame([[x[0], ids_bst[idx][0], x[1], articles_id_nbr[idx][0], ids_nbr[idx][0], articles_id_nbr[idx][1]]for idx, x in enumerate(sorted_bst)], index=[np.arange(1, len(sorted_bst)+1)], \n                            columns=('bst_artic', 'bst_prod_name','bst_prices','mst_artc', 'mst_prod_name','mst_artc_amount'))\n    articles_bst.sort_index(inplace=True)\n\n    return count_articles, articles_bst\n","metadata":{"execution":{"iopub.status.busy":"2022-04-07T17:36:59.233459Z","iopub.execute_input":"2022-04-07T17:36:59.233875Z","iopub.status.idle":"2022-04-07T17:36:59.246432Z","shell.execute_reply.started":"2022-04-07T17:36:59.233835Z","shell.execute_reply":"2022-04-07T17:36:59.245796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function meant for showing out the iamges of the sales per quantity and prices \ndef img_visu(bst_art, prod_name):\n    imgs=[]  \n    titles = []\n    exist = False\n    for i, value in enumerate(bst_art):\n        for items in glob.glob('/kaggle/input/h-and-m-personalized-fashion-recommendations/images/*'):\n            for img in os.listdir(items):\n                item = int(img.split('.')[0])\n                if item == value:\n                    imgs.append(\"{}/{}\".format(items, img))\n                    titles.append(prod_name[i+1])\n                    exist= True\n                    break\n            if exist:\n                exist = False\n                break\n        \n    # creating plot\n    y = [img for img in imgs]\n\n    plt.figure(figsize=(15, 15))\n    for i in range(len(imgs)):\n        plt.subplot(5, 5, i+1)\n        image = Image.open(y[i])\n        plt.imshow(image) \n        plt.axis('off')\n        plt.gca().set_title(titles[i], size=15) \n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:08:04.094354Z","iopub.execute_input":"2022-04-07T19:08:04.095246Z","iopub.status.idle":"2022-04-07T19:08:04.104987Z","shell.execute_reply.started":"2022-04-07T19:08:04.095205Z","shell.execute_reply":"2022-04-07T19:08:04.104178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function visualizes the the departments with most number of sales and their percentage according to the whole amount of sales \n# we will just show the deprtments as it's the highest levle in malls  \ndef bst_depart_sales(count_articles, year):\n    # preparing best departments per their sales amount\n    dprtmnt = {}\n    for i in count_articles.items():  \n        dep = np.array(real_data.department_name[real_data.article_id==i[0]].values)\n        dep = dep.all()\n        if dep in dprtmnt:\n            dprtmnt[dep] = dprtmnt[dep]+i[1]\n        else:\n            dprtmnt[dep] = i[1]\n    dep_bst = sorted(dprtmnt.items(), key=operator.itemgetter(1))[-20:]\n\n    # Creating plot\n    total = []\n    for item in dprtmnt:\n        total.append(dprtmnt[item])\n\n    x=[item[0] for item in dep_bst]\n    percentage = [np.round(item[1] / sum(total)*100, 2) for item in dep_bst]\n\n    fig = plt.figure(num=None, figsize=(15, 4), dpi=80)\n\n    ax = sns.barplot(x=x, y=percentage) \n    for cont in ax.containers:\n        ax.bar_label(cont, fmt='%.1f%%')\n    ax = ax.set_xticklabels(ax.get_xmajorticklabels(), rotation=70)\n\n    plt.title('best 20_departements per sales amount for {}'.format(year))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:03:47.292615Z","iopub.execute_input":"2022-04-07T19:03:47.293115Z","iopub.status.idle":"2022-04-07T19:03:47.305984Z","shell.execute_reply.started":"2022-04-07T19:03:47.293065Z","shell.execute_reply":"2022-04-07T19:03:47.305199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finally we will see the progress of sales during the years per the sum of prices each week \n\ndef sales_price_progression(year):\n    # distributing sales pries per week \n    weeks = [w for n, w in trans[trans['t_dat'].dt.year==year].groupby(pd.Grouper(key='t_dat',freq='W'))]\n    weekly_prices = [np.sum(weeks[idx]['price']) for idx in range(len(weeks))]\n    \n    # creating plot\n    x = range(len(weeks))\n    y = weekly_prices\n\n    fig = plt.figure(figsize=(15,7))\n\n    plt.plot(x, y, color='r', scalex=y, linewidth=2, marker='*', linestyle=(0, (5, 2, 1, 1)), label='progression line')\n    plt.xlabel('weeks')\n    plt.ylabel('weekly_prices')\n    \n    plt.locator_params ('x', nbins = 30)\n    plt.locator_params ('y', nbins = 20)\n    \n    plt.title('sales movement progression for {}'.format(year))\n    plt.legend()\n\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:03:49.851577Z","iopub.execute_input":"2022-04-07T19:03:49.852126Z","iopub.status.idle":"2022-04-07T19:03:49.862829Z","shell.execute_reply.started":"2022-04-07T19:03:49.852092Z","shell.execute_reply":"2022-04-07T19:03:49.861803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ***2018 year anlysis***","metadata":{}},{"cell_type":"code","source":"# importing the amount of sales and the prices\ncount_articles, articles_price = most_sales_price(2018)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T17:37:15.85219Z","iopub.execute_input":"2022-04-07T17:37:15.852594Z","iopub.status.idle":"2022-04-07T17:41:07.031031Z","shell.execute_reply.started":"2022-04-07T17:37:15.852564Z","shell.execute_reply":"2022-04-07T17:41:07.029869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing images of articles_id with most sales\nimg_visu(articles_price.mst_artc, articles_price.mst_prod_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:08:12.445087Z","iopub.execute_input":"2022-04-07T19:08:12.445401Z","iopub.status.idle":"2022-04-07T19:08:18.894597Z","shell.execute_reply.started":"2022-04-07T19:08:12.44537Z","shell.execute_reply":"2022-04-07T19:08:18.893866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing images of articles_id with most prices\nimg_visu(articles_price.bst_artic, articles_price.bst_prod_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:08:29.386038Z","iopub.execute_input":"2022-04-07T19:08:29.386951Z","iopub.status.idle":"2022-04-07T19:08:36.618457Z","shell.execute_reply.started":"2022-04-07T19:08:29.386903Z","shell.execute_reply":"2022-04-07T19:08:36.617856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing biggest departs per amount of sales\nbst_depart_sales(count_articles, 2018)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T17:43:22.533517Z","iopub.execute_input":"2022-04-07T17:43:22.533852Z","iopub.status.idle":"2022-04-07T17:43:37.445807Z","shell.execute_reply.started":"2022-04-07T17:43:22.533818Z","shell.execute_reply":"2022-04-07T17:43:37.444827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# progression of sales movement during the year\nsales_price_progression(2018)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T17:43:51.753037Z","iopub.execute_input":"2022-04-07T17:43:51.753352Z","iopub.status.idle":"2022-04-07T17:43:55.22631Z","shell.execute_reply.started":"2022-04-07T17:43:51.753312Z","shell.execute_reply":"2022-04-07T17:43:55.225405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ***2019 year anlysis***","metadata":{}},{"cell_type":"code","source":"# importing the amount of sales and the prices\ncount_articles, articles_price = most_sales_price(2019)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T17:44:35.053727Z","iopub.execute_input":"2022-04-07T17:44:35.054332Z","iopub.status.idle":"2022-04-07T18:09:14.454331Z","shell.execute_reply.started":"2022-04-07T17:44:35.054291Z","shell.execute_reply":"2022-04-07T18:09:14.453077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing images of articles_id with most sales\nimg_visu(articles_price.mst_artc, articles_price.mst_prod_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:08:47.304395Z","iopub.execute_input":"2022-04-07T19:08:47.305218Z","iopub.status.idle":"2022-04-07T19:08:53.770757Z","shell.execute_reply.started":"2022-04-07T19:08:47.305171Z","shell.execute_reply":"2022-04-07T19:08:53.769722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing images of articles_id with most prices\nimg_visu(articles_price.bst_artic, articles_price.bst_prod_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:09:02.506148Z","iopub.execute_input":"2022-04-07T19:09:02.506441Z","iopub.status.idle":"2022-04-07T19:09:09.076415Z","shell.execute_reply.started":"2022-04-07T19:09:02.506411Z","shell.execute_reply":"2022-04-07T19:09:09.075189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing biggest departs per amount of sales\nbst_depart_sales(count_articles, 2019)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:09:28.231025Z","iopub.execute_input":"2022-04-07T18:09:28.231396Z","iopub.status.idle":"2022-04-07T18:09:52.767241Z","shell.execute_reply.started":"2022-04-07T18:09:28.231349Z","shell.execute_reply":"2022-04-07T18:09:52.765995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# progression of sales movement during the year\nsales_price_progression(2019)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T02:07:51.936127Z","iopub.execute_input":"2022-04-08T02:07:51.936502Z","iopub.status.idle":"2022-04-08T02:07:52.032608Z","shell.execute_reply.started":"2022-04-08T02:07:51.936412Z","shell.execute_reply":"2022-04-08T02:07:52.031119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ***2020 year anlysis***","metadata":{}},{"cell_type":"code","source":"# importing the amount of sales and the prices\ncount_articles, articles_price = most_sales_price(2020)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:09:56.992004Z","iopub.execute_input":"2022-04-07T18:09:56.992232Z","iopub.status.idle":"2022-04-07T18:24:13.938933Z","shell.execute_reply.started":"2022-04-07T18:09:56.992206Z","shell.execute_reply":"2022-04-07T18:24:13.937867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing images of articles_id with most sales\nimg_visu(articles_price.mst_artc, articles_price.mst_prod_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:09:22.445864Z","iopub.execute_input":"2022-04-07T19:09:22.44686Z","iopub.status.idle":"2022-04-07T19:09:28.748635Z","shell.execute_reply.started":"2022-04-07T19:09:22.446815Z","shell.execute_reply":"2022-04-07T19:09:28.747635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing images of articles_id with most prices\nimg_visu(articles_price.bst_artic, articles_price.bst_prod_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T19:09:45.085417Z","iopub.execute_input":"2022-04-07T19:09:45.085702Z","iopub.status.idle":"2022-04-07T19:09:52.03694Z","shell.execute_reply.started":"2022-04-07T19:09:45.08567Z","shell.execute_reply":"2022-04-07T19:09:52.036085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualizing biggest departs per amount of sales\nbst_depart_sales(count_articles, 2020)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:24:27.022807Z","iopub.execute_input":"2022-04-07T18:24:27.023761Z","iopub.status.idle":"2022-04-07T18:24:48.357737Z","shell.execute_reply.started":"2022-04-07T18:24:27.023716Z","shell.execute_reply":"2022-04-07T18:24:48.356667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# progression of sales movement during the year\nsales_price_progression(2020)","metadata":{"execution":{"iopub.status.busy":"2022-04-07T18:24:48.360827Z","iopub.execute_input":"2022-04-07T18:24:48.361184Z","iopub.status.idle":"2022-04-07T18:24:52.411653Z","shell.execute_reply.started":"2022-04-07T18:24:48.361138Z","shell.execute_reply":"2022-04-07T18:24:52.410426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the ending of analyzing the objects and sales according to the amount of objects and their distributions among the departments and sections, and the movement of sales during the years of transactions.","metadata":{}}]}