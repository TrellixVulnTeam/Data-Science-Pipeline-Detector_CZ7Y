{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This colab was made by Adam Dudek, Aleksandra Tomczak and Jakob Holden Hansen as a group","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Libraries\n\nimport pandas as pd\nimport numpy as np","metadata":{"id":"qRrUUpd2-_Wq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Part 1 - Data preprocessing.","metadata":{"id":"7_mOa9vtA7Ph"}},{"cell_type":"code","source":"# customers = pd.read_csv(\"data/customers.csv\")\n# min(customers['age']) # 16.0\n# max(customers['age']) # 99.0","metadata":{"id":"q01BuK2m_WqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating age groups\n# 16 - 24 : group 1\n# 25 - 34 : group 2\n# 35 - 54 : group 3\n# 55 - 99 : group 4\n# agegroup_1 = customers.loc[customers['age'] <= 24]\n# agegroup_2 = customers.loc[(customers['age'] > 24) & (customers['age'] <= 34)]\n# agegroup_3 = customers.loc[(customers['age'] > 34) & (customers['age'] <= 54)]\n# agegroup_4 = customers.loc[(customers['age'] > 54)]","metadata":{"id":"3DnjsuMy50JM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving customers groups to separate CSV files\n# agegroup_1.to_csv('age_1.csv', index = False)\n# agegroup_2.to_csv('age_2.csv', index = False)\n# agegroup_3.to_csv('age_3.csv', index = False)\n# agegroup_4.to_csv('age_4.csv', index = False)","metadata":{"id":"XahHFLuC536f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading first 10 rows to investigate the data\n# df = pd.read_csv('data/transactions_train.csv', nrows = 10)\n# df","metadata":{"id":"c8IZeHlsDeSR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the type of the date variable\n# type(df['t_dat'][0])\n# Output: str","metadata":{"id":"j9z5ubkMDqQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the transactions for 22.08.2020 - 22.09.2020\n# transactions = pd.read_csv(\"data/transactions_train.csv\")\n# last_month = transactions.loc[transactions['t_dat'] >= '2020-08-22']","metadata":{"id":"PztoafEGI545"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imports\n\nfrom google.colab import files\nuploaded = files.upload()","metadata":{"id":"yyp_MjPd59IA","outputId":"b9cba61d-b7fb-4223-ca58-b515dc2ceab7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# file import\n\nimport io\n\ncustomers = pd.read_csv(io.BytesIO(uploaded['age_1.csv']))\ntransactions = pd.read_csv(io.BytesIO(uploaded['last_month.csv']))","metadata":{"id":"mlaMdpRC6Hg4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customers = pd.read_csv('age_1.csv')\ntransactions = pd.read_csv('last_month.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Part 2 - Non-personalized recommendations.","metadata":{"id":"unw-0F83BAgg"}},{"cell_type":"code","source":"# Creating a list of all customers IDs\ncustomer_list = list(customers['customer_id'])\n\n# Choosing from the transactions records the purchuses of customers from our age group\ntransactions_age = transactions[transactions['customer_id'].isin(customer_list)]\n\n# Reseting an index\ntransactions_age = transactions_age.reset_index()\ntransactions_age = transactions_age.drop(columns = 'index')\n\n# Counting how many times each article was bought\nfrequency = transactions_age['article_id'].value_counts()\n\n# Creating a data frame with top 12 products\ntop_items = pd.DataFrame(frequency[:12]).reset_index()\n\n# Renaming the columns\ntop_items.columns = ['article_id', 'frequency']\n\n# Getting the list of top 12 articles\ntop_items_list = list(top_items['article_id'])","metadata":{"id":"3ku-3ZXUBHKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 12 items\ntop_items_list","metadata":{"id":"yjvxLL6I7V1y","outputId":"89ba66fb-2713-426f-d6b6-c0525da6cbd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting necessary columns\ntransactions_age_ = transactions_age[['customer_id','article_id']]\n\n# Aggregating the data frame\ntransactions_age_agg = transactions_age_.groupby('customer_id').agg(lambda x: list(set(x)))\n\n# Resetting an index so that customer ID is in a separate column\ntransactions_age_agg = transactions_age_agg.reset_index()\n\n# Creating a list of lists of purchased items\npurchased_items = list(transactions_age_agg['article_id'])","metadata":{"id":"r8C1YsYR1I-2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function that calculates association between two products\ndef top_associated_products(df, product, N = 12):\n    d = {}\n    times = 0\n    for l in df:\n        if product in l:\n            times = times + 1\n            for i in l:\n                if i != product: \n                    if(i in d):\n                        d[i] += 1.0\n                    else:\n                        d[i] = 1.0\n\n    for k in d:\n        d[k] =   d[k] / times\n    sorted_list = sorted(d.items(), key=lambda x: x[1],reverse=True)[:N]\n    items_list = []\n    for item in sorted_list:\n        items_list.append(item[0])\n    \n    return items_list","metadata":{"id":"3OIXi_GW1Vyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if the function is working properly\nmost_associated = top_associated_products(purchased_items, 683001028, N = 5)\nprint(most_associated)","metadata":{"id":"kTMCceA969pu","outputId":"5d5dd590-a2cd-4f69-82ba-190cc3f86ae4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Part 3 - Personalized recommendations.","metadata":{"id":"cgcs8W0xBH1C"}},{"cell_type":"code","source":"# Collaborative filtering class\nclass CollaborativeFiltering():\n    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n    \n    def __init__(self,DataFrame):\n        \"\"\" Constructor \"\"\"\n        self.df=DataFrame\n        self.sim_mat = None #for later storage of training similarity matrix\n        self.pivotdata = None #for later storage of pivot datatable\n        \n        \n    #HAVE MADE MY OWN FIT TO MAKE I-I MATRIX\n    def fit(self):\n        \n        \"\"\"\n        using DataFrame as entry and making it to a PivotTable inside class\n        \"\"\"\n        self.df = self.top_k_items()\n        indicator = np.ones(len(self.df)) #creating a rating indicator of 1 for bought items\n        self.df['rating']=indicator #making a column in the dataframe with rating 1 \n        \n        #creating pivot table (U-I table)\n        pivotdata = self.df.pivot_table(values='rating',index='customer_id',columns='article_id').fillna(0.0)\n        self.pivotdata =pivotdata\n        \n        allItems = set(self.pivotdata.columns)\n        similarity = {}\n        \n        for item1 in allItems:\n            similarity.setdefault(item1,{})\n            for item2 in allItems:\n                if item1==item2: continue\n                similarity.setdefault(item2,{})\n                if (item1 in similarity[item2]): continue\n                sim = self.CosineSimilarity(item1,item2)\n        \n                if(sim<0):\n                    similarity[item1][item2]=0\n                    similarity[item2][item1]=0\n                else:\n                    similarity[item1][item2]=sim\n                    similarity[item2][item1]=sim\n            \n        self.sim_mat = pd.DataFrame(similarity)\n        \n    def predict(self, article_ids,customer_id,n_recommendations=12):\n        pred_dict=[]\n        dict_tot = []\n        #finding all the articles for the given customer\n        articles_customer=self.sim_mat[article_ids]\n        #finding number of items bought\n        n_items = articles_customer.shape[1]\n\n        #iterating over all items\n        for i in range(0,n_items):\n            #finding all datasets of similarities for the article_id\n            temp = articles_customer.iloc[:,i]\n            #appending the dataset of similarities for a given item of the user to list\n            dict_tot.append(temp)\n        #transforming the dictionary of all similarities for items to DataFrame\n        #filling all NaN values with zero\n        dict_tot = pd.DataFrame(dict_tot).fillna(0)\n        #Taking the mean of all the articles and sorts from highest to lowest\n        #picks out the 14 top items\n        pred_dict = np.mean(dict_tot,axis=0).sort_values(ascending=False)[:n_recommendations]\n        #DataFrame fix\n        return_df = pred_dict.to_frame().reset_index().copy()\n        #changes columns to article_id and similarity for the output df to easier call\n        return_df.rename(columns={'index':'article_id',0:'similarity'},inplace=True)\n        articles_sorted=return_df['article_id'].to_list()\n        articles_sorted=list(articles_sorted)\n        return articles_sorted\n\n    '''\n        Using Cosine Similarity since we have a unary situation\n    '''\n    \n    #definition of CosineSimilarity between two items\n    def CosineSimilarity(self,Article1, Article2):\n        customers_article1=self.pivotdata[Article1]\n        customers_article2=self.pivotdata[Article2]\n        sim = np.dot(customers_article1, customers_article2) / (np.linalg.norm(customers_article1)*np.linalg.norm(customers_article2))\n\n        return sim\n\n    def top_k_items(self,top_k=100):\n\n        data_grouped_top = self.df.groupby('article_id').size().sort_values(ascending=False).head(top_k)\n        article_numbers = np.array(data_grouped_top.index)\n        art_state = self.df['article_id'].isin(article_numbers)\n        new_df= self.df[art_state]\n        return new_df","metadata":{"id":"zQtEqx30BK8q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the CF on trainingset\ncf = CollaborativeFiltering(transactions_age_)\ncf.fit()","metadata":{"id":"f6ZW4x7OIepb","outputId":"434e52f7-98c5-4668-d0bb-e0b291d56181"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fuction to predict multiple items\ndef prediction_multiple_items(col_fil, customer_id, articles):\n    '''\n    col_fil = the collaborative filter class pre-trained on traininset\n    want to have this an an input in case we test several pre-trained collaborative filters\n    with different number of item inputs\n    '''\n    cf_prediction = col_fil.predict(articles, customer_id)\n    return cf_prediction","metadata":{"id":"gjgkuK8g7u6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating fake \"Testsubject\"\narticle_ids_poo = [827968001, 827968004]\ncustomer_id_poo = '92f038c76d9be61640143b22aa524317059cbc6b97177964e5650b7a9353094c'\njoik = prediction_multiple_items(cf, customer_id_poo, article_ids_poo)\njoik","metadata":{"id":"smO9-FRn7u9V","outputId":"203cf983-3787-476b-9d67-cf4c1cd12f0b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Part 4 - Putting the predictions together.","metadata":{"id":"lR9iRZnl8gLt"}},{"cell_type":"code","source":"# Creating a data frame with only customers IDs\nall_customers = customers.drop(labels = ['FN', 'Active', 'club_member_status', 'fashion_news_frequency', 'age', 'postal_code'], axis = 1)\n\n# Adding a column with an empty value for all customers\nall_customers['article_id'] = ''","metadata":{"id":"1RElMLtKAVsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenating the data frames\nfinal = pd.concat([transactions_age_agg, all_customers], join = \"outer\", ignore_index = True)","metadata":{"id":"bfXMEPxBRjl2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the duplicates, keeping the first occurence by default\n# This way we will drop the rows with 0 values for the customers who actually purchased sth\nfinal = final.drop_duplicates(subset = ['customer_id'], keep = 'first')","metadata":{"id":"C2YD1oZxRjoQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if we have all the customers in our final data frame\nlen(final) == len(customers)","metadata":{"id":"3pkk3LI5RjrP","outputId":"69c98cbe-1638-49b2-9f7a-22a7678d4eef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffling the observations\nfinal = final.sample(frac = 1)\nfinal = final.sample(frac = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resetting an index\nfinal = final.reset_index(drop = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a sample of 10 000 random customers\nsample = final.copy()[:10000]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a flag variable\nsample['flag'] = ''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Flag variable contains the number of items bought by the customer\nfor i in range(0, len(sample)):\n    sample['flag'][i] = len(sample['article_id'][i])","metadata":{"id":"Z2EaF1iKosK7","outputId":"34249e4b-ef30-4cd6-ee20-b113b97fe976"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample['reco'] =''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, len(sample)):\n    if sample['flag'][i] == 0:\n        sample['reco'][i] = top_items_list\n    elif sample['flag'][i] == 1:\n        sample['reco'][i] = top_associated_products(purchased_items, sample['article_id'][i][0], 12)\n    else:\n        print(i)\n        sample['reco'][i] = prediction_multiple_items(cf, sample['customer_id'][i], np.array(sample['article_id'][i]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = sample.to_csv('sample.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}