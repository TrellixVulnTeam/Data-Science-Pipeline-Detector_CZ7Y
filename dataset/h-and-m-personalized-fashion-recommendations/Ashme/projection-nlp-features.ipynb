{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project NLP features with BERT  \nI think if customers bought similar products, products features also are similar. Then I transform 'detail_desc' to distributed representation with BERT and project 2D space after dimension reduction with PCA. \n\nI use euclidean distance to calculates distance between center point and each product features.\n\n$$d(\\mathbf{x}, \\mathbf{y}) = \\sqrt{(x_1 - y_1)^2 + \\cdots + (x_n - y_n)^2}$$\n\n**Result**  \n- I project features that a customer bought product on 2D space but features are not similar. In this notebook, I project all product but it could better to divide product with category before project.  \n- I implemented calculate all customer features center point on local environment to make submission. Maybe it's just my poor implementation took a very long time(about eight hundreds hour...).","metadata":{}},{"cell_type":"markdown","source":"## Import Library  ","metadata":{}},{"cell_type":"code","source":"from typing import List\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.spatial import distance\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport torch\nimport transformers\nfrom transformers import BertTokenizer\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:34:05.321677Z","iopub.execute_input":"2022-03-20T12:34:05.322008Z","iopub.status.idle":"2022-03-20T12:34:07.904095Z","shell.execute_reply.started":"2022-03-20T12:34:05.321934Z","shell.execute_reply":"2022-03-20T12:34:07.903267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load articles data  ","metadata":{}},{"cell_type":"code","source":"articles = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/articles.csv\")\narticles.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:34:07.906854Z","iopub.execute_input":"2022-03-20T12:34:07.907253Z","iopub.status.idle":"2022-03-20T12:34:08.943108Z","shell.execute_reply.started":"2022-03-20T12:34:07.907215Z","shell.execute_reply":"2022-03-20T12:34:08.942455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fill NaN and check max length of 'detail desc' for using BERT.","metadata":{}},{"cell_type":"code","source":"articles['detail_desc'] = articles['detail_desc'].fillna('')\narticles['len_desc'] = articles['detail_desc'].apply(lambda x: len(x.split()))\n\ndisplay(articles['len_desc'])\nprint(f\"max describe length: {articles['len_desc'].max()}\")\nprint(f\"min describe length: {articles['len_desc'].min()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:34:08.944307Z","iopub.execute_input":"2022-03-20T12:34:08.944636Z","iopub.status.idle":"2022-03-20T12:34:09.149035Z","shell.execute_reply.started":"2022-03-20T12:34:08.9446Z","shell.execute_reply":"2022-03-20T12:34:09.148298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions  \nClass of BERT vectorizer refer to this article(japanese).  \nURL: https://zenn.dev/koukyo1994/articles/9b1da2482d8ba1  ","metadata":{}},{"cell_type":"code","source":"class BertSequenceVectorizer:\n    def __init__(self, model_name=\"bert-base-uncased\", max_len=128):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.model_name = model_name\n        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n        self.bert_model = transformers.BertModel.from_pretrained(self.model_name)\n        self.bert_model = self.bert_model.to(self.device)\n        self.max_len = max_len\n\n    def vectorize(self, sentence: str) -> np.array:\n        inp = self.tokenizer.encode(sentence)\n        len_inp = len(inp)\n\n        if len_inp >= self.max_len:\n            inputs = inp[:self.max_len]\n            masks = [1] * self.max_len\n        else:\n            inputs = inp + [0] * (self.max_len - len_inp)\n            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n\n        inputs_tensor = torch.tensor([inputs], dtype=torch.long).to(self.device)\n        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n\n        bert_out = self.bert_model(inputs_tensor, masks_tensor)\n        seq_out, _ = bert_out['last_hidden_state'], bert_out['pooler_output']\n\n        if torch.cuda.is_available():\n            return seq_out[0][0].cpu().detach().numpy()  # 0番目は [CLS] token, 768 dim の文章特徴量\n        else:\n            return seq_out[0][0].detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:34:09.15125Z","iopub.execute_input":"2022-03-20T12:34:09.151786Z","iopub.status.idle":"2022-03-20T12:34:09.162683Z","shell.execute_reply.started":"2022-03-20T12:34:09.151747Z","shell.execute_reply":"2022-03-20T12:34:09.161873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transform 'detail desc' to distributed representation and reduction dimensional with PCA.","metadata":{}},{"cell_type":"code","source":"def tokenize(df: pd.DataFrame, columns: List[str], max_len_list: List[int],\n             model_class=BertSequenceVectorizer, num_component=64):\n    df = df[[\"article_id\"] + columns]\n    token_df = pd.DataFrame({\"article_id\": df[\"article_id\"]})\n\n    for max_len, column in zip(max_len_list, columns):\n        model = model_class(model_name=\"bert-base-cased\", max_len=max_len)\n        pca = PCA(n_components=num_component)\n        feature_columns = [f\"{column}_feature{i}\" for i in range(num_component)]\n        features = np.stack(df[column].apply(lambda x: model.vectorize(x)).values)\n\n        # reduction dimensional with PCA.\n        features = pca.fit_transform(features)\n        token_df[feature_columns] = features\n\n    return token_df","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:34:09.164113Z","iopub.execute_input":"2022-03-20T12:34:09.164452Z","iopub.status.idle":"2022-03-20T12:34:09.17808Z","shell.execute_reply.started":"2022-03-20T12:34:09.164373Z","shell.execute_reply":"2022-03-20T12:34:09.177065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take very long time\ntokenize_df = tokenize(articles, columns=['detail_desc'], max_len_list=[128], num_component=2)\n\narticles = pd.concat((articles, tokenize_df.iloc[:, 1:]), axis=1)\narticles","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-03-20T12:34:09.179286Z","iopub.execute_input":"2022-03-20T12:34:09.180148Z","iopub.status.idle":"2022-03-20T12:53:27.200913Z","shell.execute_reply.started":"2022-03-20T12:34:09.18011Z","shell.execute_reply":"2022-03-20T12:53:27.200181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load transactions data  ","metadata":{}},{"cell_type":"code","source":"transactions = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\")\ntransactions.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:53:27.202341Z","iopub.execute_input":"2022-03-20T12:53:27.202923Z","iopub.status.idle":"2022-03-20T12:54:27.434201Z","shell.execute_reply.started":"2022-03-20T12:53:27.202867Z","shell.execute_reply":"2022-03-20T12:54:27.433503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extract a customer id to plot features that a customer bought product.","metadata":{}},{"cell_type":"code","source":"ex_customer = transactions.loc[0, 'customer_id']\nex_transaction = transactions.query(\"customer_id == @ex_customer\")","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:54:27.43557Z","iopub.execute_input":"2022-03-20T12:54:27.435851Z","iopub.status.idle":"2022-03-20T12:54:29.157786Z","shell.execute_reply.started":"2022-03-20T12:54:27.435817Z","shell.execute_reply":"2022-03-20T12:54:29.157039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\n\narticles['ex_flag'] = 0\n\nfor article_id in ex_transaction['article_id'].values:\n    articles.loc[articles['article_id'] == article_id, 'ex_flag'] = 1\n\nplt.scatter(articles.query(\"ex_flag == 0\")['detail_desc_feature0'],\n            articles.query(\"ex_flag == 0\")['detail_desc_feature1'],\n            label=\"Others\")\nplt.scatter(articles.query(\"ex_flag == 1\")['detail_desc_feature0'],\n            articles.query(\"ex_flag == 1\")['detail_desc_feature1'],\n            label=\"ex customer bought article\")\n\n# 例として得ている客の購入した記事の重心を得る\ncenter_x = articles.query(\"ex_flag == 1\")['detail_desc_feature0'].mean()\ncenter_y = articles.query(\"ex_flag == 1\")['detail_desc_feature1'].mean()\nplt.scatter(center_x, center_y, label=\"center point\")\n\nplt.title(\"article dist\")\nplt.xlabel(\"detail desc feature 0\")\nplt.ylabel(\"detail desc feature 1\")\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:54:29.159072Z","iopub.execute_input":"2022-03-20T12:54:29.15931Z","iopub.status.idle":"2022-03-20T12:54:30.674089Z","shell.execute_reply.started":"2022-03-20T12:54:29.159266Z","shell.execute_reply":"2022-03-20T12:54:30.673391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_customer_dist(ex_customer):\n    plt.figure(figsize=(12, 12))\n\n    ex_transaction = transactions.query(\"customer_id == @ex_customer\")\n    articles['ex_flag'] = 0\n\n    for article_id in ex_transaction['article_id'].values:\n        articles.loc[articles['article_id'] == article_id, 'ex_flag'] = 1\n\n    plt.scatter(articles.query(\"ex_flag == 0\")['detail_desc_feature0'],\n                articles.query(\"ex_flag == 0\")['detail_desc_feature1'],\n                label=\"Others\")\n    plt.scatter(articles.query(\"ex_flag == 1\")['detail_desc_feature0'],\n                articles.query(\"ex_flag == 1\")['detail_desc_feature1'],\n                label=\"ex customer bought article\")\n\n    # calculate features center point\n    center_x = articles.query(\"ex_flag == 1\")['detail_desc_feature0'].mean()\n    center_y = articles.query(\"ex_flag == 1\")['detail_desc_feature1'].mean()\n    plt.scatter(center_x, center_y, label=\"center point\")\n\n    plt.title(f\"article dist {ex_customer}\")\n    plt.xlabel(\"detail desc feature 0\")\n    plt.ylabel(\"detail desc feature 1\")\n    plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:54:30.676422Z","iopub.execute_input":"2022-03-20T12:54:30.67683Z","iopub.status.idle":"2022-03-20T12:54:30.685409Z","shell.execute_reply.started":"2022-03-20T12:54:30.676749Z","shell.execute_reply":"2022-03-20T12:54:30.684503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot features and center point some customers features.  ","metadata":{}},{"cell_type":"code","source":"customer_id_list = transactions['customer_id'].unique()\nfor ex_customer in customer_id_list[:10]:\n    plot_customer_dist(ex_customer)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:54:30.686732Z","iopub.execute_input":"2022-03-20T12:54:30.687635Z","iopub.status.idle":"2022-03-20T12:55:04.112096Z","shell.execute_reply.started":"2022-03-20T12:54:30.6876Z","shell.execute_reply":"2022-03-20T12:55:04.111401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def no_pca_tokenize(df: pd.DataFrame, columns: List[str], max_len_list: List[int],\n                    model_class=BertSequenceVectorizer):\n    df = df[[\"article_id\"] + columns]\n    token_df = pd.DataFrame({\"article_id\": df[\"article_id\"]})\n\n    for max_len, column in zip(max_len_list, columns):\n        model = model_class(model_name=\"bert-base-cased\", max_len=max_len)\n        feature_columns = [f\"{column}_feature{i}\" for i in range(768)]\n        features = np.stack(df[column].apply(lambda x: model.vectorize(x)).values)\n\n        token_df[feature_columns] = features\n\n    return token_df\n\n# take very long time\ntokenize_df = no_pca_tokenize(articles, columns=['detail_desc'], max_len_list=[128])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-03-20T12:55:04.113309Z","iopub.execute_input":"2022-03-20T12:55:04.113758Z","iopub.status.idle":"2022-03-20T12:59:05.344292Z","shell.execute_reply.started":"2022-03-20T12:55:04.113719Z","shell.execute_reply":"2022-03-20T12:59:05.342206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try to make prediction a customer.  ","metadata":{}},{"cell_type":"code","source":"ex_customer = customer_id_list[0]\n\narticles['ex_flag'] = 0\ntokenize_df['ex_flag'] = 0\n\nfor article_id in ex_transaction['article_id'].values:\n    articles.loc[articles['article_id'] == article_id, 'ex_flag'] = 1\n    tokenize_df.loc[articles['article_id'] == article_id, 'ex_flag'] = 1\n\nex_customer_center = tokenize_df.query(\"ex_flag == 1\").iloc[:, 1:-1].values.mean(axis=0)\n\ndistance_df = pd.DataFrame({\"article_id\": articles['article_id'].values})\ndistance_df['distance'] = 0\n\nfor i in range(tokenize_df.shape[0]):\n    features = tokenize_df.iloc[i, 1:-1].values\n    _distance = distance.euclidean(ex_customer_center, features)\n    distance_df.loc[i, 'distance'] = _distance\n\ndistance_df","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:59:05.345511Z","iopub.status.idle":"2022-03-20T12:59:05.345913Z","shell.execute_reply.started":"2022-03-20T12:59:05.345688Z","shell.execute_reply":"2022-03-20T12:59:05.345712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distance_df = distance_df.sort_values(by=\"distance\")\nex_pred = distance_df.head(12)['article_id'].values\n\nprint(ex_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T12:59:05.347282Z","iopub.status.idle":"2022-03-20T12:59:05.347699Z","shell.execute_reply.started":"2022-03-20T12:59:05.347466Z","shell.execute_reply":"2022-03-20T12:59:05.347487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}