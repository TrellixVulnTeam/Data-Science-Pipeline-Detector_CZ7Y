{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport catboost\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.test.is_gpu_available(\n    cuda_only=False,\n    min_cuda_compute_capability=None\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.test.gpu_device_name()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ndf=pd.read_json('../input/whats-cooking-kernels-only/train.json', orient='records', dtype={\"id\":int, \"cuisine\":str,\"ingredients\":list})\ndf_test=pd.read_json('../input/whats-cooking-kernels-only/test.json', orient='records', dtype={\"id\":int, \"ingredients\":list})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Датасет: анализ и подготовка"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['cuisine'].unique(), len(df['cuisine'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y='cuisine', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lists = [df['ingredients'].values[i] for i in range(len(df))]\nunique_ingredients = list(set(list(np.concatenate(lists))))\nd = dict(zip(np.arange(len(unique_ingredients)), unique_ingredients))\ninv_d = dict(zip(unique_ingredients, np.arange(len(unique_ingredients))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(inv_d.items())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(sorted(inv_d.items(), key=lambda item: item[1], reverse=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\ntotal_ingredients_list = []\ntq = tqdm_notebook(total=df.shape[0])\nfor ing in df['ingredients']:\n    total_ingredients_list = total_ingredients_list + ing\n    tq.update(1)\ntq.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chars = re.escape(string.punctuation)\nchars","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# - убираем знаки препинания, цифры, \"oz\", пробелы в начале строки и пишем все строчными буквами\nclean_ingredients_list = [re.sub(r'['+chars+']', '', \n                                 re.sub('[0-9]+','', c.replace(\"oz\",\"\"))).strip(' ').lower()\n                    for c in total_ingredients_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(np.unique(total_ingredients_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(np.unique(clean_ingredients_list))[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(np.unique(clean_ingredients_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nstop_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tq = tqdm_notebook(total=len(clean_ingredients_list))\nfor i, ingredients in enumerate(clean_ingredients_list):\n    cleaned_ingredients = [c for c in ingredients.split(' ') if c not in stop_words]\n    cleaned_ingredients = (' '.join(cleaned_ingredients)).strip(' ')\n    clean_ingredients_list[i] = cleaned_ingredients\n    tq.update(1)\ntq.close()\nclean_unique_ingredients_list = [c for c in list(np.unique(clean_ingredients_list)) if len(c)>0]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(clean_unique_ingredients_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# превращаем список ингридиетов в дамми-переменные","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes_dict = {'greek':0, 'southern_us':1, 'filipino':2, 'indian':3, 'jamaican':4,\n                'spanish':5, 'italian':6, 'mexican':7, 'chinese':8, 'british':9, 'thai':10,\n                'vietnamese':11, 'cajun_creole':12, 'brazilian':13, 'french':14, 'japanese':15,\n                'irish':16, 'korean':17, 'moroccan':18, 'russian':19}\n\ningredients_encoded = np.zeros((df.shape[0], len(clean_unique_ingredients_list)+2), dtype=np.uint8)\ntq = tqdm_notebook(total=df.shape[0])\nfor i in range(df.shape[0]):\n    ingredients_encoded[i,0] = df['id'].values[i]\n    ingredients_encoded[i,1] = classes_dict[df['cuisine'][i]]\n    clean_recipe = [re.sub(r'['+chars+']', '',\n                           re.sub('[0-9]+','', c.replace(\"oz\",\"\"))).strip(' ').lower()\n                    for c in df['ingredients'][i]]\n    for k, ingredients in enumerate(clean_recipe):\n        cleaned_ingredients = [c for c in ingredients.split(' ') if c not in stop_words]\n        cleaned_ingredients = (' '.join(cleaned_ingredients)).strip(' ')\n        clean_recipe[k] = cleaned_ingredients\n        \n    clean_recipe = [c for c in clean_recipe if len(c)>0]\n    for ingredient in clean_recipe:\n        ingredients_encoded[i,clean_unique_ingredients_list.index(ingredient)+2]= 1\n        \n    tq.update(1)\n    \ntq.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ingredients_encoded_test = np.zeros((df_test.shape[0], len(clean_unique_ingredients_list)+2), dtype=np.uint8)\n\ntq = tqdm_notebook(total=df_test.shape[0])\nfor i in range(df_test.shape[0]):\n    ingredients_encoded_test[i,0] = df_test['id'].values[i]\n    ingredients_encoded_test[i,1] = 0\n    clean_recipe = [re.sub(r'['+chars+']', '',\n                           re.sub('[0-9]+','', c.replace(\"oz\",\"\"))).strip(' ').lower()\n                    for c in df_test['ingredients'][i]]\n    for k, ingredients in enumerate(clean_recipe):\n        cleaned_ingredients = [c for c in ingredients.split(' ') if c not in stop_words]\n        cleaned_ingredients = (' '.join(cleaned_ingredients)).strip(' ')\n        clean_recipe[k] = cleaned_ingredients\n    clean_recipe = [c for c in clean_recipe if len(c)>0]\n    for ingredient in clean_recipe:\n        if ingredient not in clean_unique_ingredients_list:\n            continue\n        ingredients_encoded_test[i,clean_unique_ingredients_list.index(ingredient)+2]= 1\n        \n    tq.update(1)\n    \ntq.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = pd.DataFrame(data=ingredients_encoded_test[:,1:])\ndata_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame(data=ingredients_encoded[:,1:])\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gb = data.groupby([0]).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data_gb.loc[:,data_gb.sum(0)>1000], )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gb.sum(0)[data_gb.sum(0)<2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data_test.sum(0)[data_test.sum(0)<2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.loc[:,data.sum(0)>1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Датасет: трейн - тест"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data[data.columns[0]]\nX = data[data.columns[1:]]\nX_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, stratify = y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import timeit\ndef prtime(start, stop):\n    temp = stop - start\n    hours = temp//3600\n    temp = temp - 3600*hours\n    minutes = temp//60\n    seconds = temp - 60*minutes\n    print('%d:%d:%d' %(hours,minutes,seconds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nstart = timeit.default_timer()\nrf_best = RandomForestClassifier(bootstrap=True, \n                                 class_weight='balanced',\n                                 criterion='gini', \n                                 max_depth=100, \n                                 max_features='auto',\n                                 max_leaf_nodes=None, \n                                 min_impurity_decrease=0.0,\n                                 min_impurity_split=None, \n                                 min_samples_leaf=1,\n                                 min_samples_split=2, \n                                 min_weight_fraction_leaf=0.0,\n                                 n_estimators=400, \n                                 n_jobs=8, \n                                 oob_score=False,\n                                 random_state=None, verbose=0, warm_start=False)\n# rf_best.fit(X_train,y_train)\nstop = timeit.default_timer()\nprtime(start, stop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n# y_pred = rf_best.predict(X_test)\n# accuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nstart = timeit.default_timer()\nclf_best = MLPClassifier(solver='adam',\n                         activation='relu',\n                         early_stopping=True, \n                         random_state=3,\n                         max_iter=500,\n                         verbose=True,\n                         alpha=1e-08,\n                         beta_1=0.05, \n                         beta_2=0.4, \n                         epsilon=1e-09)\n\n# clf_best.fit(X, y)\nstop = timeit.default_timer()\nprtime(start, stop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n# y_pred = clf.predict(X_test)\n# accuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\n\n# start = timeit.default_timer()\n# clf_best = LogisticRegression(penalty='elasticnet', \n#                               l1_ratio = 0.8,\n#                               fit_intercept = True,\n#                               class_weight = 'balanced',\n#                               solver = 'saga',\n#                               multi_class = 'multinomial'\n#                              )\n# clf_best.fit(X, y)\n# stop = timeit.default_timer()\n# prtime(start, stop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nstart = timeit.default_timer()\nclf_best = LogisticRegression(penalty='l2', \n                              fit_intercept = True,\n                              class_weight = 'balanced',\n                              solver = 'newton-cg',\n                              multi_class = 'multinomial'\n                             )\nclf_best.fit(X, y)\nstop = timeit.default_timer()\nprtime(start, stop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_pred = clf_best.predict(X_test)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sub = data_test[data_test.columns[1:]]\nX_sub = X_sub.loc[:, X.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_sub = clf_best.predict(X_sub)\ny_pred_str = [list(classes_dict.keys())[list(classes_dict.values()).index(c)] for c in y_sub]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm = pd.DataFrame({'id':df_test['id'], 'cuisine':y_pred_str})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(np.unique(subm['cuisine']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm.to_csv('submission.csv',  index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}