{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\npath ='/kaggle/input/whats-cooking-kernels-only/'\n\nwith open(path + 'train.json','r') as f:\n    train_data = json.load(f)\nwith open(path + 'test.json','r') as f:\n    test_data = json.load(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=pd.DataFrame(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data=pd.DataFrame(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data Exploration\ntrain_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['cuisine'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\ndef random_col(num_col):\n    colors = []\n    for i in range(num_col):        \n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['cuisine'].value_counts().plot.bar(color=random_col(20),figsize=(16,6))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##most commonly used ingredients.\nfrom collections import Counter\nmost_commoning = Counter([item for lists in train_data['ingredients'] for item in lists])\nprint(most_commoning.most_common(20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##plotting a graph on most common ingredients.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ning_df = pd.DataFrame(most_commoning.most_common(20))\ning_df.columns = ['ingredients','tot_count']\nplt.figure(figsize=(7,9))\nsns.barplot(x='tot_count',y='ingredients',data=ing_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom wordcloud import WordCloud\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport xgboost as xgb\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')\nfrom nltk.stem import PorterStemmer\nstop_words = set(stopwords.words('english'))\nstemer = PorterStemmer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport string\npunctuations = string.punctuation\nnltk.download('wordnet')\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport re\n#import unicodedata\nlmz = WordNetLemmatizer()\n \ndef clean(text):\n \n \n txt = str(text).lower()\n txt = \"\".join(c for c in txt if c not in punctuations) \n words = txt.split() \n words = [i for i in words if i.isalpha()] \n pattern = '[0-9]'\n words = [re.sub(pattern, '', i) for i in words]\n words = [re.sub(r'[^a-zA-Z]+$', '', i) for i in words] \n \n clean_txt = \" \".join(words) \n return clean_txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##using stemming in preprocessing\ndef clean_stem(text):\n \n \n txt = str(text).lower()\n txt = \"\".join(c for c in txt if c not in punctuations) \n words = txt.split() \n words = [i for i in words if i.isalpha()] \n pattern = '[0-9]'\n words = [re.sub(pattern, '', i) for i in words]\n words = [re.sub(r'[^a-zA-Z]+$', '', i) for i in words] \n words = \" \".join(words) \n words=[stemer.stem(word) for word in words.split(\" \") if words not in stop_words]\n \n clean_txt = \" \".join(words) \n return clean_txt\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Applying the cleaning function to both test and train datasets\ntrain_data['clean_text'] = train_data['ingredients'].apply(lambda x: clean(x))\ntrain_data['cleanstem_text']=train_data['ingredients'].apply(lambda x:clean_stem(x))\ntest_data['clean_text'] = test_data['ingredients'].apply(lambda x: clean(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvec = CountVectorizer()\ntrain_cv = cvec.fit_transform(train_data['clean_text'])\ntest_cv = cvec.transform(test_data['clean_text'])\nprint(train_cv[0].todense())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(min_df = 2,max_df = 0.5,ngram_range = (1,2))\ntrain_tfidf = tfidf.fit_transform(train_data['clean_text'])\ntest_tfidf = tfidf.transform(test_data['clean_text'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#label encode the target data\nle = LabelEncoder()\ntrain_data['cat_cuisine']=le.fit_transform(train_data['cuisine'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to check the mappings of the target class to its integer value\nle_name_map = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(le_name_map)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_data=le.fit_transform(train_data['cuisine'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx_traintf, x_validtf, y_traintf, y_validtf = train_test_split(train_tfidf ,y_data , test_size=0.2, random_state=42)\nx_traincv,x_validcv,y_traincv,y_validcv=train_test_split(train_cv ,y_data , test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['cat_cuisine'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnb = MultinomialNB(alpha = 2.0)\nmetrics_cv = model_selection.cross_val_score(mnb,train_cv,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score:\",metrics_cv)\nmetric_tfidf = model_selection.cross_val_score(mnb,train_tfidf,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf:\",metric_tfidf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnb.fit(train_cv,train_data['cat_cuisine'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_mnbpreds=mnb.predict(test_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_mnbpreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_mnbpreds=le.inverse_transform(y_mnbpreds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_mnbpreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##will try to balance the dataset and apply the model on balanced dataset\nfrom imblearn.under_sampling import RandomUnderSampler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#undersampling on train countvectirizer data\nundersample =RandomUnderSampler(sampling_strategy='majority')\nx_undercv,y_undercv=undersample.fit_resample(train_cv,train_data['cat_cuisine'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#undersampling on train tfidf data\nx_undertfidf,y_undertfidf=undersample.fit_resample(train_tfidf,train_data['cat_cuisine'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trying multinomial Naive bayes on balanced dataset and without balanced dataset\nmetrics_cv = model_selection.cross_val_score(mnb,train_cv,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"mean_score cv:\",metrics_cv.mean())\nmetric_tfidf = model_selection.cross_val_score(mnb,train_tfidf,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf:\",metric_tfidf.mean())\nmetrics_cvbal = model_selection.cross_val_score(mnb,x_undercv,y_undercv,cv = 10,scoring = 'accuracy')\nprint(\"score of cv balanced:\",metrics_cvbal.mean())\nmetric_tfidfbal = model_selection.cross_val_score(mnb,x_undertfidf,y_undertfidf,cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf balanced:\",metric_tfidfbal.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mnb.fit(x_undercv,y_undercv)\n##since we got high accuracy with CV train test data, therefore we are going with count vectorizer dataset\n#y_mnbpredsbal=mnb.predict(test_cv)\n#y_mnbpredsbal=le.inverse_transform(y_mnbpredsbal)\n#submission = pd.DataFrame({'Id':test_data['id'],'cuisine':y_mnbpredsbal})\n#submission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##we are now aware that undersamping did not give much accuracy therefore, we can try without sampling the dataset\n#now will go for others models, without sampling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn import model_selection","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg=LogisticRegression(random_state=0)\nmetrics_cv = model_selection.cross_val_score(logreg,train_cv,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score of cv:\",metrics_cv.mean())\nmetric_tfidf = model_selection.cross_val_score(logreg,train_tfidf,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf:\",metric_tfidf.mean())\nmetrics_cvbal = model_selection.cross_val_score(logreg,x_undercv,y_undercv,cv = 10,scoring = 'accuracy')\nprint(\"score of cv balanced:\",metrics_cvbal.mean())\nmetric_tfidfbal = model_selection.cross_val_score(logreg,x_undertfidf,y_undertfidf,cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf balanced:\",metric_tfidfbal.mean())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using Support vector machine\nlsvc=LinearSVC()\nmetrics_cv = model_selection.cross_val_score(lsvc,train_cv,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score of cv:\",metrics_cv.mean())\nmetric_tfidf = model_selection.cross_val_score(lsvc,train_tfidf,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf:\",metric_tfidf.mean())\nmetrics_cvbal = model_selection.cross_val_score(lsvc,x_undercv,y_undercv,cv = 10,scoring = 'accuracy')\nprint(\"score of cv balanced:\",metrics_cvbal.mean())\nmetric_tfidfbal = model_selection.cross_val_score(lsvc,x_undertfidf,y_undertfidf,cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf balanced:\",metric_tfidfbal.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#metrics_cv = model_selection.cross_val_score(lsvc,train_cv,train_data['cat_cuisine'],cv = 10,scoring = 'f1_macro')\n#print(\"score of cv:\",metrics_cv.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=10)\nmetrics_cv = model_selection.cross_val_score(knn,train_cv,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score of cv:\",metrics_cv.mean())\nmetric_tfidf = model_selection.cross_val_score(knn,train_tfidf,train_data['cat_cuisine'],cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf:\",metric_tfidf.mean())\nmetrics_cvbal = model_selection.cross_val_score(knn,x_undercv,y_undercv,cv = 10,scoring = 'accuracy')\nprint(\"score of cv balanced:\",metrics_cvbal.mean())\nmetric_tfidfbal = model_selection.cross_val_score(knn,x_undertfidf,y_undertfidf,cv = 10,scoring = 'accuracy')\nprint(\"score of tfidf balanced:\",metric_tfidfbal.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#logreg.fit(train_cv,train_data['cat_cuisine'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_predlogregcv=logreg.predict(test_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_predlogregcv=le.inverse_transform(y_predlogregcv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lsvc.fit(train_tfidf,train_data['cat_cuisine'])\ny_predsvctf=lsvc.predict(test_tfidf)\ny_predsvctf=le.inverse_transform(y_predsvctf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'Id':test_data['id'],'cuisine':y_predsvctf})\nsubmission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## now trying to evaluate the model on train and valid data which we obtained using train and test\n#FOR Naive Bayes\nfrom sklearn.metrics import accuracy_score, confusion_matrix,classification_report\nfrom sklearn.metrics import confusion_matrix\nmnb.fit(x_traintf,y_traintf)\ny_predmnbtf=mnb.predict(x_validtf)\nmnb.fit(x_traincv,y_traincv)\ny_predmnbcv=mnb.predict(x_validcv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predmnb_tf=classification_report(y_validtf, y_predmnbtf)\npredmnb_cv=classification_report(y_validcv, y_predmnbcv)\nprint(\"report of Naivebyes with Tfidf:\\n\",predmnb_tf)\nprint(\"report of Naivebyes with Count Vec:\\n\",predmnb_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#FOR Logistic reg\nlogreg.fit(x_traintf,y_traintf)\ny_predlogregtf=logreg.predict(x_validtf)\nlogreg.fit(x_traincv,y_traincv)\ny_predlogregcv=logreg.predict(x_validcv)\npredlogreg_tf=classification_report(y_validtf, y_predlogregtf)\npredlogreg_cv=classification_report(y_validcv, y_predlogregcv)\nprint(\"report of Logistic Reg with Tfidf:\\n\",predlogreg_tf)\nprint(\"report of Logistic Reg with Count Vec:\\n\",predlogreg_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#FOR Linear SVC\nlsvc.fit(x_traintf,y_traintf)\ny_predlsvctf=lsvc.predict(x_validtf)\nlsvc.fit(x_traincv,y_traincv)\ny_predlsvccv=lsvc.predict(x_validcv)\npredlsvc_tf=classification_report(y_validtf, y_predlsvctf)\npredlsvc_cv=classification_report(y_validcv, y_predlsvccv)\nprint(\"report of Linear SVC with Tfidf:\\n\",predlsvc_tf)\nprint(\"report of  Linear SVC with Count Vec:\\n\",predlsvc_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#FOR Linear knn\nknn.fit(x_traintf,y_traintf)\ny_predknntf=knn.predict(x_validtf)\nknn.fit(x_traincv,y_traincv)\ny_predknncv=knn.predict(x_validcv)\npredknn_tf=classification_report(y_validtf, y_predknntf)\npredknn_cv=classification_report(y_validcv, y_predknncv)\nprint(\"report of knn with Tfidf:\\n\",predknn_tf)\nprint(\"report of  knn with Count Vec:\\n\",predknn_cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}