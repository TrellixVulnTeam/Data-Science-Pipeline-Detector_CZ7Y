{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nimport datetime\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nimport xgboost as xgb\nfrom sklearn import ensemble\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.stats import skew\nimport json\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nimport re\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nwith open('../input/train.json', 'r', encoding='utf-8') as fh: #открываем файл на чтение\n    data_train = json.load(fh) #загружаем из файла данные в словарь data\nwith open('../input//test.json', 'r', encoding='utf-8') as fh1: #открываем файл на чтение\n    data_test = json.load(fh1) #загружаем из файла данные в словарь data\n# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n# функция суммы строковых массивов\ndef arr_str_sum(arr_str):\n    temp = ''\n    temp_ = ' '\n    for i in range(0, len(arr_str)):\n        temp = temp + arr_str[i] + temp_\n    return temp\n# функция суммы строковых массивов\n\n#совпадение целевого вектора\ndef coincidence(y, y_pred):\n    count = 0\n    for i in range(0,len(y_pred)):\n        t = 1 if y[i]==y_pred[i] else 0\n        count = count+t\n    return count/len(y_pred)\n#совпадение целевого вектора\n\n#лемматизация составляющих рецепт\nlemmatizer = WordNetLemmatizer()\ndef preprocess(ingredients):\n    ingredients_text = ' '.join(ingredients)\n    ingredients_text = ingredients_text.lower()\n    ingredients_text = ingredients_text.replace('-', ' ')\n    words = []\n    for word in ingredients_text.split():\n        if re.findall('[0-9]', word): continue\n        if len(word) <= 2: continue\n        if '’' in word: continue\n        word = lemmatizer.lemmatize(word)\n        if len(word) > 0: words.append(word)\n    return ' '.join(words)\n#лемматизация составляющих рецепт\n\n# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n# НАЧИНАЕМ ГЕНЕРАЦИЮ ПРИЗНАКОВ№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№№\n###############################################################################################\n\n\n# добавляем признак количество ингридиентов\nfor i in range(0,len(data_train)):\n    data_train[i].setdefault(\"Amount of ingredients\", len(data_train[i]['ingredients']))\n\nfor i in range(0,len(data_test)):\n    data_test[i].setdefault(\"Amount of ingredients\", len(data_test[i]['ingredients']))\n\n# добавляем признак количество ингридиентов\n\n#одна большая строка-рецепт\nfor i in range(0,len(data_train)):\n    data_train[i].setdefault(\"All ingredients in one string\", preprocess(data_train[i]['ingredients']))\n    \nfor i in range(0,len(data_test)):\n    data_test[i].setdefault(\"All ingredients in one string\", preprocess(data_test[i]['ingredients']))\n#одна большая строка-рецепт\n\n\n# добавляем индикаторы того, что в названии ингридиентов есть название страны\n# некоторые страны убрали, так как их названия практически не встречаются\ncountry = ['italian','mexican','chinese','french',\n           'thai','japanese','greek','spanish','korean','vietnamese' ,'jamaican']\n\nfrom itertools import product\n\nfor i, c in product(range(0,len(data_train)), country):\n        ind = 0 if data_train[i]['All ingredients in one string'].find(c) < 0 else 1\n        data_train[i].setdefault(c, ind)\nfor i, c in product(range(0,len(data_test)), country):\n        ind = 0 if data_test[i]['All ingredients in one string'].find(c) < 0 else 1\n        data_test[i].setdefault(c, ind)\n# добавляем индикаторы того, что в названии ингридиентов есть название страны\nall_recipe = []\nfor i in range(0,len(data_train)):\n    all_recipe.append(data_train[i]['All ingredients in one string'])\nfor i in range(0,len(data_test)):\n    all_recipe.append(data_test[i]['All ingredients in one string'])\n    \n# генерим матрицу TFIDF\nvectorizer = CountVectorizer()\nMat_count = vectorizer.fit_transform(all_recipe)\nmatrix_freq = np.asarray(Mat_count.sum(axis=0)).ravel()\ntransformer = TfidfTransformer()\nMat_count = transformer.fit_transform(Mat_count)\nNames_ingridients = vectorizer.get_feature_names()\n\ndf_train = pd.DataFrame(data_train)\ndf_test = pd.DataFrame(data_test)\ndel(df_train['All ingredients in one string'])\ndel(df_train['ingredients'])\ndel(df_test['All ingredients in one string'])\ndel(df_test['ingredients'])\npdMat = pd.DataFrame(Mat_count.toarray())\ny_train= df_train.cuisine.replace(\n        {'greek': 1, 'southern_us': 2, 'filipino': 3, 'indian': 4, 'jamaican': 5, 'spanish': 6, 'italian': 7,\n 'mexican': 8, 'chinese': 9, 'british': 10, 'thai': 11, 'vietnamese': 12, 'cajun_creole': 13,\n 'brazilian': 14, 'french': 15, 'japanese': 16, 'irish': 17, 'korean': 18, 'moroccan': 19, 'russian': 20})\n\ndf_train = pd.concat([df_train, pdMat[:39774]], axis=1)\ndf_id = df_train['id']\ndel(df_train['id'])\ndel(df_train['cuisine'])\ndf_mat = pdMat[39774:]\ndf_mat.index = range(0,9944)\ndf_test = pd.concat([df_test, df_mat], axis=1)\ndf_id_test =  df_test['id']\ndel(df_test['id'])\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd922c036cf77e001bce601bfcae4c80bcc97f38"},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(df_train)\ndf_train = scaler.transform(df_train)\nscaler.fit(df_test)\ndf_test = scaler.transform(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8952a929f06b671b9992a6ac9024cc8dc527fcb7"},"cell_type":"code","source":"from sklearn.svm import SVC\nestimator = SVC(\n    C=50,\n    kernel='rbf',\n    gamma=1.4,\n    coef0=1,\n    cache_size=500,\n)\ncl = OneVsRestClassifier(estimator, n_jobs=-1)\ncl.fit(df_train, y_train)\ny_pred = cl.predict(df_train)\nprint(coincidence(y_train, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"672bec0b0570c3bc2d782d746d7a4230b821c1bc"},"cell_type":"code","source":"y_pred = cl.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"323603e72bd016b0ef648835c83bb7f833c36d51"},"cell_type":"code","source":"y_pred= pd.DataFrame(y_pred).replace(\n        {1:'greek', 2:'southern_us', 3:'filipino', 4:'indian', 5:'jamaican', 6:'spanish', 7:'italian',\n 8:'mexican', 9:'chinese', 10:'british', 11:'thai', 12:'vietnamese', 13:'cajun_creole',\n 14:'brazilian', 15:'french', 16:'japanese', 17:'irish', 18:'korean', 19:'moroccan', 20:'russian'})\ny_pred.index = df_id_test\ny_pred.columns  = [\"cuisine\"]\ny_pred.to_csv('predict1.csv', header=True, index_label='Id')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}