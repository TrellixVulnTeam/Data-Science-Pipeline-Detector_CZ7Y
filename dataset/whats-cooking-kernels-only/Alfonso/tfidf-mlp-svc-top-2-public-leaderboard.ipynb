{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import the required libraries \nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom tqdm import tqdm_notebook\nimport string\nfrom nltk.corpus import stopwords\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Train Data Preparation\ndata_path = '/kaggle/input/whats-cooking-kernels-only/'\njson_train_path = os.path.join(data_path, 'train.json')\njson_train = pd.read_json(json_train_path)\n\njson_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning and Preparing the data\n\nWe're going to perform the clean in two steps:\n\n* Step 1: Make a list with all unique ingredients without stop words, numbers and commas, semicolons etc.\n* Step 2: Clean each recipe using the step 1 ingredients list."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1: Make a list with all unique ingredients\n\ntotal_ingredients_list = []\nprint('Phase 1 of 2')\ntq = tqdm_notebook(total=json_train.shape[0])\nfor ing in json_train['ingredients']:\n    total_ingredients_list = total_ingredients_list + ing\n    tq.update(1)\ntq.close()\n\nprint('Total number of pre-clean unique ingredients: {}'.format(len(np.unique(total_ingredients_list))))\n\n# Remove a lot of things in the unique ingredients list to clean the data:\n# - Remove (number  oz.)\n# - Remove all spaces in the beggining or in the end\n# - Remove all special characters\n\nimport string\nfrom nltk.corpus import stopwords\n\nchars = re.escape(string.punctuation)\nclean_ingredients_list = [re.sub(r'['+chars+']', '', \n                                 re.sub('[0-9]+','', c.replace(\"oz\",\"\"))).strip(' ').lower()\n                    for c in total_ingredients_list]\n\nstop_words = set(stopwords.words('english'))\nprint('Phase 2 of 2')\ntq = tqdm_notebook(total=len(clean_ingredients_list))\nfor i, ingredients in enumerate(clean_ingredients_list):\n    cleaned_ingredients = [c for c in ingredients.split(' ') if c not in stop_words]\n    cleaned_ingredients = (' '.join(cleaned_ingredients)).strip(' ')\n    clean_ingredients_list[i] = cleaned_ingredients\n    tq.update(1)\ntq.close()\n# See some of the cleaned data\n# BagOfWords\nclean_unique_ingredients_list = [c for c in list(np.unique(clean_ingredients_list)) if len(c)>0]\nprint('Total number of cleaned unique ingredients: ', len(clean_unique_ingredients_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 2: Clean the recipes.\n\ntq = tqdm_notebook(total=json_train.shape[0])\nfor i in range(json_train.shape[0]):\n    recipe = json_train['ingredients'][i]\n    clean_recipe = [re.sub(r'['+chars+']', '',\n                           re.sub('[0-9]+','', c.replace(\"oz\",\"\"))).strip(' ').lower()\n                    for c in recipe]\n    # delete stop words\n    for k, ingredients in enumerate(clean_recipe):\n        cleaned_ingredients = [c for c in ingredients.split(' ') if c not in stop_words]\n        cleaned_ingredients = (' '.join(cleaned_ingredients)).strip(' ')\n        clean_recipe[k] = cleaned_ingredients\n    json_train['ingredients'][i] = ' '.join(clean_recipe)\n    tq.update(1)\n    \ntq.close()\n\njson_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning \n\nWe're going to train two ML algorithms under the same train data (all data):\n\n* MLP: I've calculated the hyperparameters of this algorithm using Cross Validation with 5 folds.\n* SVC: I'm going to use the Hyperparameters founded in https://www.kaggle.com/zeus75/cooking-eda-with-svc#1.-Loading-Packages-and-Data.(Thanks! :))"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Previous Step: Codificate the train data in a sparse matrix to save memory.\n\nvectorizer = TfidfVectorizer(binary=False)\nvectorizer.fit(json_train['ingredients'])\n\nX_train = vectorizer.transform(json_train['ingredients']) \n\nlb = LabelEncoder()\ny_train = lb.fit_transform(json_train['cuisine'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 1: Neuronal Network\n\nclassifier_1 = MLPClassifier(hidden_layer_sizes=300,\n                             early_stopping=True,\n                             random_state=7,\n                             learning_rate_init=0.0001)\n\nfrom sklearn.multiclass import OneVsRestClassifier\nclassifier_1 = OneVsRestClassifier(classifier_1, n_jobs=-1)\n\nmodel_1 = classifier_1.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 2: SVMachine Classifier (This model alone have an 0.78761 score under the test set in Kaggle)\n\nclassifier_2 = SVC(C=100, # penalty parameter\n                 kernel='rbf', # kernel type, rbf working fine here\n                 degree=3, # default value\n                 gamma=1, # kernel coefficient\n                 coef0=1, # change to 1 from default value of 0.0\n                 shrinking=True, # using shrinking heuristics\n                 tol=0.001, # stopping criterion tolerance \n                 probability=True, # no need to enable probability estimates\n                 cache_size=200, # 200 MB cache size\n                 class_weight=None, # all classes are treated equally \n                 verbose=False, # print the logs \n                 max_iter=-1, # no limit, let it run\n                 decision_function_shape=None, # will use one vs rest explicitly \n                 random_state=None)\n\nclassifier_2 = OneVsRestClassifier(classifier_2, n_jobs=1)\n\nmodel_2 = classifier_2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test: \n\nPrepare the test set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"json_test_path = json_train_path = os.path.join(data_path, 'test.json')\njson_test = pd.read_json(os.path.join(json_test_path)\n\n# Clean the recipes using the unique ingredients list calculated before.\n\ntq = tqdm_notebook(total=json_test.shape[0])\nfor i in range(json_test.shape[0]):\n    recipe = json_test['ingredients'][i]\n    clean_recipe = [re.sub(r'['+chars+']', '',\n                           re.sub('[0-9]+','', c.replace(\"oz\",\"\"))).strip(' ').lower()\n                    for c in recipe]\n    # delete stop words\n    for k, ingredients in enumerate(clean_recipe):\n        cleaned_ingredients = [c for c in ingredients.split(' ') if c not in stop_words]\n        cleaned_ingredients = (' '.join(cleaned_ingredients)).strip(' ')\n        clean_recipe[k] = cleaned_ingredients\n    json_test['ingredients'][i] = ' '.join(clean_recipe)\n    tq.update(1)\n    \ntq.close()\n\njson_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = vectorizer.transform(json_test['ingredients'])\n\ny_pred_1 = model_1.predict_proba(X_test)\n\nprint(y_pred_1.shape) #shape=[n_examples, n_classes]\n\ny_pred_2 = model_2.predict_proba(X_test)\n\nprint(y_pred_2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ensembling:\n\ny_pred = (0.3*y_pred_1 + 0.7*y_pred_2)  #0.3*MLP+0.7*SVC = 0.82019\ny_pred = np.argmax(y_pred, axis=1)\ny_pred = lb.inverse_transform(y_pred)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission:\n\nprint (\"Generate Submission File ... \")\ntest_id = json_test['id']\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv('output.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}