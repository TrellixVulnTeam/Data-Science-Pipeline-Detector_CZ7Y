{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['sample_submission.csv', 'test.json', 'train.json']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nfrom pprint import pprint\n\nwith open('../input/train.json') as f:\n    data = json.load(f)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_id = list()\ncuisine = list()\ningre = list()\n\nfor i in range(len(data)):\n    _id.append(data[i]['id'])\n    cuisine.append(data[i]['cuisine'])\n    ingre.append(data[i]['ingredients'])","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_in = list()\n\nfor i in ingre:\n    for j in i:\n        all_in.append(j)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab = set(all_in)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_to_index = dict()\nindex_to_word = dict()\nindex = 1\n\nfor i in vocab:\n    word_to_index[i] = index\n    index_to_word[index] = i\n    index += 1","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq = list()\n\nfor i in ingre:\n    list_ = list()\n    for j in i:\n        x = word_to_index.get(j,-1)\n        if x != -1:\n            list_.append(x)\n    seq.append(list_)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = 0\n\nfor i in range(len(seq)):\n    if m < len(seq[i]):\n        m = len(seq[i])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"65"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nseq = pad_sequences(seq, maxlen=65)","execution_count":11,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq = np.array(seq)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine = pd.get_dummies(cuisine)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine.shape","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"(39774, 20)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/test.json') as f:\n    test_data = json.load(f)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = list()\n# test_cuisine = list()\ntest_ingre = list()\n\nfor i in range(len(test_data)):\n    test_id.append(test_data[i]['id'])\n#     test_cuisine.append(test_data[i]['cuisine'])\n    test_ingre.append(test_data[i]['ingredients'])","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_seq = list()\n\nfor i in test_ingre:\n    list_ = list()\n    for j in i:\n        x = word_to_index.get(j,-1)\n        if x != -1:\n            list_.append(x)\n    test_seq.append(list_)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_seq = pad_sequences(test_seq, maxlen=65)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import Sequential\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nembedding_size=64\nmodel=Sequential()\nmodel.add(Embedding(len(vocab)+1, embedding_size, input_length=65))\nmodel.add(LSTM(128, return_sequences=True))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(128))\nmodel.add(Dense(20, activation='softmax'))\nprint(model.summary())","execution_count":20,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 65, 64)            429760    \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 65, 128)           98816     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 65, 128)           0         \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 128)               131584    \n_________________________________________________________________\ndense_1 (Dense)              (None, 20)                2580      \n=================================================================\nTotal params: 662,740\nTrainable params: 662,740\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\n# checkpoint\nfilepath=\"weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\n\n\nmodel.compile(loss='categorical_crossentropy', \n             optimizer='adam', \n             metrics=['accuracy'])","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(seq, cuisine, batch_size=64, epochs=15)","execution_count":23,"outputs":[{"output_type":"stream","text":"Epoch 1/15\n39774/39774 [==============================] - 111s 3ms/step - loss: 0.5262 - acc: 0.8448\nEpoch 2/15\n39774/39774 [==============================] - 110s 3ms/step - loss: 0.4731 - acc: 0.8595\nEpoch 3/15\n39774/39774 [==============================] - 111s 3ms/step - loss: 0.4446 - acc: 0.8665\nEpoch 4/15\n39774/39774 [==============================] - 111s 3ms/step - loss: 0.4134 - acc: 0.8750\nEpoch 5/15\n39774/39774 [==============================] - 110s 3ms/step - loss: 0.3872 - acc: 0.8825\nEpoch 6/15\n39774/39774 [==============================] - 112s 3ms/step - loss: 0.3607 - acc: 0.8910\nEpoch 7/15\n39774/39774 [==============================] - 111s 3ms/step - loss: 0.3357 - acc: 0.8992\nEpoch 8/15\n39774/39774 [==============================] - 111s 3ms/step - loss: 0.3109 - acc: 0.9047\nEpoch 9/15\n39774/39774 [==============================] - 112s 3ms/step - loss: 0.2941 - acc: 0.9090\nEpoch 10/15\n39774/39774 [==============================] - 111s 3ms/step - loss: 0.2757 - acc: 0.9157\nEpoch 11/15\n39774/39774 [==============================] - 111s 3ms/step - loss: 0.2551 - acc: 0.9219\nEpoch 12/15\n39774/39774 [==============================] - 112s 3ms/step - loss: 0.2379 - acc: 0.9288\nEpoch 13/15\n39774/39774 [==============================] - 110s 3ms/step - loss: 0.2203 - acc: 0.9327\nEpoch 14/15\n39774/39774 [==============================] - 111s 3ms/step - loss: 0.2044 - acc: 0.9376\nEpoch 15/15\n39774/39774 [==============================] - 112s 3ms/step - loss: 0.1970 - acc: 0.9391\n","name":"stdout"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"<keras.callbacks.History at 0x7fb3cc70afd0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(seq[1].reshape(-1,65))","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(pred)","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"16"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisine.head()","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"   brazilian  british  cajun_creole     ...      spanish  thai  vietnamese\n0          0        0             0     ...            0     0           0\n1          0        0             0     ...            0     0           0\n2          0        0             0     ...            0     0           0\n3          0        0             0     ...            0     0           0\n4          0        0             0     ...            0     0           0\n\n[5 rows x 20 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brazilian</th>\n      <th>british</th>\n      <th>cajun_creole</th>\n      <th>chinese</th>\n      <th>filipino</th>\n      <th>french</th>\n      <th>greek</th>\n      <th>indian</th>\n      <th>irish</th>\n      <th>italian</th>\n      <th>jamaican</th>\n      <th>japanese</th>\n      <th>korean</th>\n      <th>mexican</th>\n      <th>moroccan</th>\n      <th>russian</th>\n      <th>southern_us</th>\n      <th>spanish</th>\n      <th>thai</th>\n      <th>vietnamese</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = list(cuisine.keys())\nnames[np.argmax(pred)]","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"'southern_us'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[1]","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"{'id': 25693,\n 'cuisine': 'southern_us',\n 'ingredients': ['plain flour',\n  'ground pepper',\n  'salt',\n  'tomatoes',\n  'ground black pepper',\n  'thyme',\n  'eggs',\n  'green tomatoes',\n  'yellow corn meal',\n  'milk',\n  'vegetable oil']}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = list()\n\nfor i in test_seq:\n    pred = model.predict(i.reshape(-1,65))\n    test_pred.append(names[np.argmax(pred)])","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = np.array(test_pred).reshape(-1,1)\ntest_id = np.array(test_id).reshape(-1,1)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = np.array(np.concatenate((test_id, test_pred),axis=1))","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output[0]","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"array(['18009', 'british'], dtype='<U21')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame(output,columns = [\"id\",\"cuisine\"])","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv('out.csv',index = False)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}