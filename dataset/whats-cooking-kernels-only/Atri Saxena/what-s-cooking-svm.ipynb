{"cells":[{"metadata":{"_uuid":"d7319fcac3bae38898d8969ab251493f1061b7c7"},"cell_type":"markdown","source":"This is the notebook to the What's Cooking competition. \nI have used SVM. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import LabelEncoder\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train_df = pd.read_json('../input/train.json')\ntest_df = pd.read_json('../input/test.json')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bcf03ddaefa465f38cbf71ddd31bad6011194e0a"},"cell_type":"markdown","source":"****Some Feature Engineering****"},{"metadata":{"trusted":true,"_uuid":"2fbe24692ea992fd4d5d10633d51904f142d54cc","collapsed":true},"cell_type":"code","source":"def generate_text(data):\n\ttext_data = [\" \".join(doc).lower() for doc in data.ingredients]\n\treturn text_data \n\ntrain_text = generate_text(train_df)\ntest_text = generate_text(test_df)\ntarget = [doc for doc in train_df.cuisine]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e066f9017e2a1f5b87de1369c4d7624fb9ec2e36","collapsed":true},"cell_type":"code","source":"# Feature Engineering \nprint (\"TF-IDF on text data ... \")\ntfidf = TfidfVectorizer(binary=True)\ndef tfidf_features(txt, flag):\n    if flag == \"train\":\n    \tx = tfidf.fit_transform(txt)\n    else:\n\t    x = tfidf.transform(txt)\n    x = x.astype('float16')\n    return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7834316608254df8b72b1b85b2afcf88ed90c0e9","collapsed":true},"cell_type":"code","source":"X = tfidf_features(train_text, flag=\"train\")\nX_test = tfidf_features(test_text, flag=\"test\")\n\n# Label Encoding - Target \nprint (\"Label Encode the Target Variable ... \")\nlb = LabelEncoder()\ny = lb.fit_transform(target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec8bd504a3f93178de68a9051d231b7c3bf2ff18"},"cell_type":"markdown","source":"**Fitting the Model using SVM**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0166d62e771b5ed6fcd3d156884082820101f2d4","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\nfrom sklearn.svm import SVC\nclassifier = SVC(C=100, # penalty parameter, setting it to a larger value \n                 kernel='rbf', # kernel type, rbf working fine here\n\t \t\t\t degree=3, # default value, not tuned yet\n\t \t\t\t gamma=1, # kernel coefficient, not tuned yet\n\t \t\t\t coef0=1, # change to 1 from default value of 0.0\n\t \t\t\t shrinking=True, # using shrinking heuristics\n\t \t\t\t tol=0.001, # stopping criterion tolerance \n\t      \t\t probability=False, # no need to enable probability estimates\n\t      \t\t cache_size=200, # 200 MB cache size\n\t      \t\t class_weight=None, # all classes are treated equally \n\t      \t\t verbose=False, # print the logs \n\t      \t\t max_iter=-1, # no limit, let it run\n          \t\t decision_function_shape=None, # will use one vs rest explicitly \n          \t\t random_state=None)\n\nmodel = OneVsRestClassifier(classifier, n_jobs=4)\nmodel.fit(X, y)\n# model = xgb.XGBClassifier(max_depth=6, n_estimators=1000, learning_rate=0.1\n#                          ,min_child_weight=5,\n#                          gamma=1,\n#                          subsample=0.8,\n#                          colsample_bytree=0.8,\n#                          nthread=4,\n#                          scale_pos_weight=1,\n#                          )\n# model.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a4cd5f573d9f4d2c85241c712f7364a95f66b2b"},"cell_type":"markdown","source":"**Prediction on Test data**"},{"metadata":{"trusted":true,"_uuid":"54bf063c780a0e180cd74a3f7f4ee003e18e47c1","collapsed":true},"cell_type":"code","source":"\n# Predictions \nprint (\"Predict on test data ... \")\ny_test = model.predict(X_test)\ny_pred = lb.inverse_transform(y_test)\n\n# Submission\nprint (\"Generate Submission File ... \")\ntest_id = [doc for doc in test_df.id]\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv('svm_output.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb5d0da72a3ebf04d12c5b402d2d00d7f1d28033","collapsed":true},"cell_type":"code","source":"sub.head(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}