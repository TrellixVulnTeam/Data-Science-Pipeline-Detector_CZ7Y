{"cells":[{"metadata":{"_uuid":"4a86c63fd446ee61c18b0c80095fd96f4f636423"},"cell_type":"markdown","source":"# What is the best representation for ingredients?\n\nWe need to convert ingredeints to numeric values so that computers can do mathematical operations. My question was what the best representation is for this dataset.\n\nI compared representations below.\n\n-  [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n- [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n- [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) + [SVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)\n- [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html)\n- [fastText](https://github.com/facebookresearch/fastText)\n- TfidfVectorizer + fastText\n- Pre-trained model ([Module google/â€Œnnlm-en-dim128/1](https://www.tensorflow.org/hub/modules/google/nnlm-en-dim128/1))\n\nThere is room for tuning parameters."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ce228f1bdc2d3e67d0bce8e4afcfeae9755d6de9"},"cell_type":"code","source":"import json\nimport time\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom gensim.models import FastText, Word2Vec\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold, cross_validate, train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.preprocessing import FunctionTransformer, LabelEncoder\nfrom sklearn.pipeline import make_pipeline, make_union\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"9759659bb3f381b8ef9762a46b7a1c6872812dfd"},"cell_type":"code","source":"def apply_word2vec(sentences):\n    vectorizer = Word2Vec(\n        sentences,\n        size=500,\n        window=20,\n        min_count=3,\n        sg=1,\n        iter=20\n    )\n\n    def to_vector(sentence):\n        words = [word for word in sentence if word in vectorizer.wv.vocab]\n        if words:\n            return np.mean(vectorizer[words], axis=0)\n        else:\n            return np.zeros(500)\n\n    return np.array([to_vector(sentence) for sentence in sentences])\n\ndef apply_fasttext(sentences):\n    vectorizer = FastText(\n        size=500,\n        window=20,\n        min_count=3,\n        sg=1,\n        iter=20\n    )\n    vectorizer.build_vocab(sentences)\n    vectorizer.train(sentences, total_examples=vectorizer.corpus_count, epochs=vectorizer.iter)\n\n    def to_vector(sentence):\n        words = [word for word in sentence if word in vectorizer.wv.vocab]\n        if words:\n            return np.mean(vectorizer.wv[words], axis=0)\n        else:\n            return np.zeros(500)\n\n    return np.array([to_vector(sentence) for sentence in sentences])\n\ndef train_model(x, y, n_splits=3):\n    model = LogisticRegression(C=10, solver='sag', multi_class='multinomial', max_iter=300, n_jobs=-1)\n    i = 0\n    accuracies = []\n    kfold = KFold(n_splits)\n    for train_index, test_index in kfold.split(x):\n        classifier = LogisticRegression(C=10, solver='sag', multi_class='multinomial', max_iter=300, n_jobs=-1)\n        classifier.fit(x[train_index], y[train_index])\n\n        predictions = classifier.predict(x[test_index])\n        accuracies.append(accuracy_score(predictions, y[test_index]))\n        i += 1\n    average_accuracy = sum(accuracies) / len(accuracies)\n    return average_accuracy\n\ndef run_experiment(preprocessor):\n    train = json.load(open('../input/train.json'))\n\n    target = [doc['cuisine'] for doc in train]\n    lb = LabelEncoder()\n    y = lb.fit_transform(target)\n\n    x = preprocessor.fit_transform(train)\n\n    return train_model(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffe0553680154d7a2a12519d68bec87dfcc4f4a3"},"cell_type":"code","source":"results = []\nfor (name, preprocessor) in [\n    ('CountVectorizer', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        CountVectorizer(),\n    )),\n    ('TfidfVectorizer', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(),\n    )),\n    ('TfidfVectorizer + TruncatedSVD', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(),\n        TruncatedSVD(n_components=500, algorithm='arpack')\n    )),\n    ('Word2Vec', make_pipeline(\n        FunctionTransformer(lambda x: [doc['ingredients'] for doc in x], validate=False),\n        FunctionTransformer(lambda x: apply_word2vec(x), validate=False),\n    )),\n    ('fastText', make_pipeline(\n        FunctionTransformer(lambda x: [doc['ingredients'] for doc in x], validate=False),\n        FunctionTransformer(lambda x: apply_fasttext(x), validate=False),\n    )),\n    ('TfidfVectorizer + fastText', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        make_union(\n            make_pipeline(\n                TfidfVectorizer()\n            ),\n            make_pipeline(\n                FunctionTransformer(lambda x: apply_fasttext(x), validate=False)\n            )\n        )\n    ))\n]:\n    start = time.time()\n    accuracy = run_experiment(preprocessor)\n    execution_time = time.time() - start\n    results.append({\n        'name': name,\n        'accuracy': accuracy,\n        'execution time': f'{round(execution_time, 2)}s'\n    })\npd.DataFrame(results, columns=['name', 'accuracy', 'execution time']).sort_values(by='accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa4eaf2c478ae3ad2cf13871f45300bb3873583a"},"cell_type":"markdown","source":"TF-IDF without SVD was the best. Let's tune parameters."},{"metadata":{"trusted":true,"_uuid":"0894a708b6133eb542cf3c5c9347278b6ee34d21"},"cell_type":"code","source":"results = []\nfor (name, preprocessor) in [\n    ('TfidfVectorizer()', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(),\n    )),\n    ('TfidfVectorizer(binary=True)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(binary=True),\n    )),\n    ('TfidfVectorizer(min_df=3)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(min_df=3),\n    )),\n    ('TfidfVectorizer(min_df=5)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(min_df=5),\n    )),\n    ('TfidfVectorizer(max_df=0.95)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(max_df=0.95),\n    )),\n    ('TfidfVectorizer(max_df=0.9)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(max_df=0.9),\n    )),\n    ('TfidfVectorizer(sublinear_tf=True)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n    )),\n    ('TfidfVectorizer(strip_accents=unicode)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(strip_accents='unicode'),\n    )),\n]:\n    start = time.time()\n    accuracy = run_experiment(preprocessor)\n    execution_time = time.time() - start\n    results.append({\n        'name': name,\n        'accuracy': accuracy,\n        'execution time': f'{round(execution_time, 2)}s'\n    })\npd.DataFrame(results, columns=['name', 'accuracy', 'execution time']).sort_values(by='accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b116f0e6a8ea7fba5ca46b4fde02f177deef220"},"cell_type":"markdown","source":"Just in case, try SVD with different parameters."},{"metadata":{"trusted":true,"_uuid":"82fa4394af6580ed048be3f43f3fe870dac239f4"},"cell_type":"code","source":"results = []\nfor (name, preprocessor) in [\n    ('TruncatedSVD(n_components=100, algorithm=randomized)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n        TruncatedSVD(n_components=100, algorithm='randomized')\n    )),\n    ('TruncatedSVD(n_components=100, algorithm=arpack)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n        TruncatedSVD(n_components=100, algorithm='arpack')\n    )),\n    ('TruncatedSVD(n_components=200, algorithm=randomized)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n        TruncatedSVD(n_components=200, algorithm='randomized')\n    )),\n    ('TruncatedSVD(n_components=200, algorithm=arpack)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n        TruncatedSVD(n_components=200, algorithm='arpack')\n    )),\n    ('TruncatedSVD(n_components=500, algorithm=randomized)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n        TruncatedSVD(n_components=500, algorithm='randomized')\n    )),\n    ('TruncatedSVD(n_components=500, algorithm=arpack)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n        TruncatedSVD(n_components=500, algorithm='arpack')\n    )),\n    ('TruncatedSVD(n_components=1000, algorithm=randomized)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n        TruncatedSVD(n_components=1000, algorithm='randomized')\n    )),\n    ('TruncatedSVD(n_components=1000, algorithm=arpack)', make_pipeline(\n        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n        TfidfVectorizer(sublinear_tf=True),\n        TruncatedSVD(n_components=1000, algorithm='arpack')\n    )),\n]:\n    start = time.time()\n    accuracy = run_experiment(preprocessor)\n    execution_time = time.time() - start\n    results.append({\n        'name': name,\n        'accuracy': accuracy,\n        'execution time': f'{round(execution_time, 2)}s'\n    })\npd.DataFrame(results, columns=['name', 'accuracy', 'execution time']).sort_values(by='accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b17b57d4ee3c9c312d523719fd2055b032da451"},"cell_type":"markdown","source":"# Using pre-trained models\n\n[TensorFlow Hub](https://www.tensorflow.org/hub/) provides pre-trained models for a variety of tasks. For text related tasks, we can use [Text Modules Â |Â  TensorFlow Hub Â |Â  TensorFlow](https://www.tensorflow.org/hub/modules/text).\n\nI tried [Module google/nnlm-en-dim128/1](https://www.tensorflow.org/hub/modules/google/nnlm-en-dim128/1)."},{"metadata":{"trusted":true,"_uuid":"67138fe633362ab8688f601774b3e10a03d821cc"},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n\ntrain = pd.read_json('../input/train.json').set_index('id')\ntrain['ingredients'] = train['ingredients'].apply(lambda x: ' '.join(x))\n\ntrain = train.reset_index()[['ingredients', 'cuisine']]\nlabel_encoder = LabelEncoder()\ntrain['cuisine'] = label_encoder.fit_transform(train['cuisine'])\n\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(train, train['cuisine'], num_epochs=None, shuffle=True)\npredict_train_input_fn = tf.estimator.inputs.pandas_input_fn(train, train['cuisine'], shuffle=False)\n\nembedded_text_feature_column = hub.text_embedding_column(\n    key=\"ingredients\", \n    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\"\n)\n\nclassifier = tf.estimator.DNNClassifier(\n    hidden_units=[500, 100],\n    feature_columns=[embedded_text_feature_column],\n    n_classes=len(train['cuisine'].unique()),\n    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n\nclassifier.train(input_fn=train_input_fn, steps=1000)\n\ntrain_eval_result = classifier.evaluate(input_fn=predict_train_input_fn)\n\n\"Training set accuracy: {accuracy}\".format(**train_eval_result)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10be25dc38c213e01da5c2ff1b831f3d528dbe87"},"cell_type":"markdown","source":"The accuracy is lower than other approaches. I guess the trained model doesn't have enough vocabulary for recipes, and recipes are different from normal sentences.\nAlso, ingredients are not normalized here. The charactaristics of ingredients itself would be discussed in a different kernel."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}