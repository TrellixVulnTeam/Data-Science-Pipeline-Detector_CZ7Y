{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# What are ingredients?\n\nIn the previous kernel (https://www.kaggle.com/rejasupotaro/representations-for-ingredients), I experimented which representation is better for this dataset without looking at what ingredients itself are.\n\nViewing ingredients, I found some interesting things which might help to understand cuisines.\n\n0. Outliers\n1. Special characters\n2. Upper cases\n3. Apostrophes\n4. Hyphens\n5. Numbers\n6. Units\n7. Region names\n8. Accents\n9. Unique ingredients\n10. Language\n11. Misspellings"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import json\nimport langdetect\nimport re\nimport time\nimport unidecode\nimport ipywidgets as widgets\nimport numpy as np\nimport pandas as pd\nfrom ipywidgets import interact\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold, cross_validate, train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import FunctionTransformer, LabelEncoder, MultiLabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8115beba350bfe2477181bf61260fbee1a323306"},"cell_type":"code","source":"train = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d206db027ff40414cfb07357d2e40894718fc31b"},"cell_type":"code","source":"df = pd.concat([train, test], sort=False)\ndf['ingredients_text'] = df['ingredients'].apply(lambda x: ', '.join(x))\ndf['num_ingredients'] = df['ingredients'].apply(lambda x: len(x))\nraw_ingredients = [ingredient for ingredients in df.ingredients.values for ingredient in ingredients]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47b3b0392965191516c61cf259e538b4f3ab935b"},"cell_type":"markdown","source":"## 0. Outliers\n\nI found some recipes which consist of only 1 ingredient like below.\n\n- water => Japanese\n- butter => Indian\n- butter => French\n\nIt could get models confused. Unfortunately, such recipes exist in the test dataset though."},{"metadata":{"trusted":true,"_uuid":"95417e1b18998fc7e059819ebb96aee9487b5bc8"},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(16,4))\nsns.countplot(x='num_ingredients', data=df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25263da5425830b4084c25f2f384f3781165f725"},"cell_type":"markdown","source":"Let's see single-ingredient recipes."},{"metadata":{"trusted":true,"_uuid":"f769bccb78e9345d948eca0cec00b55cdc1e8062"},"cell_type":"code","source":"df[df['num_ingredients'] <= 1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67ef6b6de7e7f6a79bb602db28f35d013b4740d7"},"cell_type":"markdown","source":"Btw, are all ingredients valid? For example, do ingredients consisting of less than 2 characters make sense?"},{"metadata":{"trusted":true,"_uuid":"05231cf02298b149fbc64bccfc75fd0105e50c63"},"cell_type":"code","source":"[ingredient for ingredient in raw_ingredients if len(ingredient) <= 2]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2113ab34d98f391bf049ba0ae65051cdb3731569"},"cell_type":"markdown","source":"## 1. Special characters\n\nSee what special characters are contained.\n\n  - \"Bertolli**®** Alfredo Sauce\"\n  - \"Progresso**™** Chicken Broth\"\n  - \"green bell pepper**,** slice\"\n  - \"half **&** half\"\n  - \"asafetida **\\(**powder**\\)**\"\n  - \"Spring**!** Water\""},{"metadata":{"trusted":true,"_uuid":"754f889128f6ed212666024ebce50be86649e4bc"},"cell_type":"code","source":"' '.join(sorted([char for char in set(' '.join(raw_ingredients)) if re.findall('[^A-Za-z]', char)]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f0502d12f5ffd0964f2ac68930b4e2c07899312"},"cell_type":"markdown","source":"## 2. Upper cases\n\nIt may be a proper noun.\n\n- Company name\n  - \"**Oscar Mayer** Deli Fresh Smoked Ham\"\n- Region name\n  - \"**Shaoxing** wine\"\n  - \"**California** bay leaves\"\n  - \"**Italian** parsley leaves\""},{"metadata":{"trusted":true,"_uuid":"7a2e470e0fe8e28f2e91a505b58f94b41fe83ec3"},"cell_type":"code","source":"list(set([ingredient for ingredient in raw_ingredients if re.findall('[A-Z]+', ingredient)]))[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9c8a65b4f3c0e0c9a9fcefd0b9c87cb9839071d"},"cell_type":"markdown","source":"## 3. Apostrophes\n\n- \"Zatarain’s Jambalaya Mix\"\n- \"Breakstone’s Sour Cream\"\n- \"sheep’s milk cheese\"\n\nIt'd be useful if there are many apostrophes for possession in the dataset but"},{"metadata":{"trusted":true,"_uuid":"fb45a7d714e159e7777b8f65fef92d7886d83ef5"},"cell_type":"code","source":"list(set([ingredient for ingredient in raw_ingredients if '’' in ingredient]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33dceb29fbacc8cbbba57d00d17834361fbe8d5f"},"cell_type":"markdown","source":"## 4. Hyphens ( `-` )\n\nIt might be okay to replace \"-\" with \" \".\n\n- \"chicken-apple sausage\"\n- \"chocolate-hazelnut spread\"\n- \"bone-in chicken breasts\""},{"metadata":{"trusted":true,"_uuid":"9716789cb982819dae51cc88b3a867db9636873d"},"cell_type":"code","source":"list(set([ingredient for ingredient in raw_ingredients if re.findall('-', ingredient)]))[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aaaac9d7493d4e854a11cd4139e8a41602d90d4a"},"cell_type":"markdown","source":"## 5. Numbers\n\nNumbers show quantity or density.\n\n- \"1% low-fat milk\"\n- \"40% less sodium taco seasoning\"\n- \"mexican style 4 cheese blend\"\n\nStrictly speaking, quantities can be a factor of identifying the cuisine but only a few ingredients come with quantity in this dataset."},{"metadata":{"trusted":true,"_uuid":"6dcf676c0900c666bfe750491bb56c27ae8d9508"},"cell_type":"code","source":"list(set([ingredient for ingredient in raw_ingredients if re.findall('[0-9]', ingredient)]))[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9547e5603426d6d5936675dc6a37d636ed70a52d"},"cell_type":"markdown","source":"## 6. Units\n\nUnits come with numbers.\n\n  - \"(15 **oz**.) refried beans\"\n  - \"2 1/2 to 3 **lb**. chicken, cut into serving pieces\"\n  - \"pork chops, 1 **inch** thick\"\n  \nSome units are used only in a specific region. It might be useful for classifiers."},{"metadata":{"trusted":true,"_uuid":"e7da9685a6873d8119ee87f1f80bc998938fac65"},"cell_type":"code","source":"units = ['inch', 'oz', 'lb', 'ounc', '%'] # ounc is a misspelling of ounce?\n\n@interact(unit=units)\ndef f(unit):\n    ingredients_df = pd.DataFrame([ingredient for ingredient in raw_ingredients if unit in ingredient], columns=['ingredient'])\n    return ingredients_df.groupby(['ingredient']).size().reset_index(name='count').sort_values(['count'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82b0be6ea488d763a0c2bb6b83762e11b9151418"},"cell_type":"markdown","source":"## 7. Region names"},{"metadata":{"trusted":true,"_uuid":"79de7e9053b9ee1d49ca7ac9e15fdd1db92d4855"},"cell_type":"code","source":"keywords = [\n    # It indicates the cusine directly\n    'american', 'greek', 'filipino', 'indian', 'jamaican', 'spanish', 'italian', 'mexican', 'chinese', 'thai',\n    'vietnamese', 'cajun', 'creole', 'french', 'japanese', 'irish', 'korean', 'moroccan', 'russian',\n    # Region names I found in the dataset\n    'tokyo', 'shaoxing', 'california'\n]\n\n@interact(keyword=keywords)\ndef f(keyword):\n    ingredients_df = pd.DataFrame([ingredient for ingredient in raw_ingredients if keyword in ingredient], columns=['ingredient'])\n    return ingredients_df.groupby(['ingredient']).size().reset_index(name='count').sort_values(['count'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bb212281ac2cab9ad182b44e3f295ba3d011d8c"},"cell_type":"markdown","source":"## 8. Accents\n\nSome accents are used only in a specific region. Can we use this information?\n\n- \"pumpkin pur**é**e\"\n- \"crème fra**î**che\"\n- \"Ni**ç**oise olives\""},{"metadata":{"trusted":true,"_uuid":"894935a770e0a4e27eb0d520e3d1d7eaaffb63c4"},"cell_type":"code","source":"accents = ['â', 'ç', 'è', 'é', 'í', 'î', 'ú']\n\n@interact(accent=accents)\ndef f(accent):\n    ingredients_df = pd.DataFrame([ingredient for ingredient in raw_ingredients if accent in ingredient], columns=['ingredient'])\n    return ingredients_df.groupby(['ingredient']).size().reset_index(name='count').sort_values(['count'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd2fe4a094668d2b7f309f9937c83a89ce77e028"},"cell_type":"markdown","source":"## 9. Unique ingredients\n\nSome ingredients are used only in a specific region.\n\nI picked some ingredients used in `cuisine == 'japanese'`.\n\n### brown rice => genmai => 玄米\n\n<img src=\"https://kinarino.k-img.com/system/press_eye_catches/000/025/367/aea26213187ab5c5f69ed43c3480e24038c3d06f.jpg?1477883419\" width=\"480\">\n\n### bonito => katsuo => 鰹\n\n<img src=\"http://qoonell.me/wordpress/wp-content/uploads/2015/10/20070412155803000.jpg\" width=\"480\">\n\n### salmon roe => ikura => いくら\n\n<img src=\"https://cdn.macaro-ni.jp/image/summary/33/33186/40f8825cdd5438a6361373fae156a7b5.jpg\" width=\"480\">"},{"metadata":{"trusted":true,"_uuid":"2d2504e0794639b74e17c136e709bbd74f086db3"},"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\ndef preprocess(ingredients):\n    ingredients = ' '.join(ingredients).lower().replace('-', ' ')\n    ingredients = re.sub(\"\\d+\", \"\", ingredients)\n    return [lemmatizer.lemmatize(ingredient) for ingredient in ingredients.split()]\n\ningredients_df = df.groupby(['cuisine'])['ingredients'].sum().apply(lambda ingredients: preprocess(ingredients)).reset_index()\nunique_ingredients = []\nfor cuisine in ingredients_df['cuisine'].unique():\n    target = set(ingredients_df[ingredients_df['cuisine'] == cuisine]['ingredients'].values[0])\n    others = set(ingredients_df[ingredients_df['cuisine'] != cuisine]['ingredients'].sum())\n    unique_ingredients.append({\n        'cuisine': cuisine,\n        'ingredients': target - others\n    })\npd.DataFrame(unique_ingredients, columns=['cuisine', 'ingredients'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64384613bdd24fb61bfefdad7da8f251128a4e9b"},"cell_type":"markdown","source":"## 10. Language\n\nRelated to accents, we can guess which language the ingredient is by looking at the sequence of characters.\n\n- tofu => Japanese\n- purée => French\n\nCan we extract language information from ingredients? In this case, we need to think about how to detect the ingredient language."},{"metadata":{"trusted":true,"_uuid":"44bfd7de12b662b93d4e2d65b728e2c37ac89679"},"cell_type":"code","source":"text_languages = []\nfor text in [\n    'ein, zwei, drei, vier',\n    'purée',\n    'taco',\n    'tofu',\n    'tangzhong',\n    'xuxu',\n]:\n    text_languages.append({\n        'text': text,\n        'detected language': langdetect.detect(text)\n    })\npd.DataFrame(text_languages, columns=['text', 'detected language'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79cb29861ea71322951bdb25c3fe198c4d4c5cc2"},"cell_type":"markdown","source":"## 11. Misspellings\n\nI found that there are some misspellings in the dataset.\n\n- ounc (ounce)\n- wasabe (wasabi)\n- ..."},{"metadata":{"_uuid":"021c0c981a92677559fb8239e926778360fcef1f"},"cell_type":"markdown","source":"# Normalize\n\nI saw some ingredients which contain special characters, misspellings, ... I should probabily normalize ingredients."},{"metadata":{"trusted":true,"_uuid":"0d5f3056ff927312decc52ad7d2afb3aa6c0ce84"},"cell_type":"code","source":"from IPython.display import clear_output\n\ningredients = ['romaine lettuce', 'Eggs', 'Beef demi-glace', 'Sugar 10g', 'Pumpkin purée', 'Kahlúa']\nlabels = [widgets.Label(ingredient) for ingredient in ingredients]\n\nlower_checkbox = widgets.Checkbox(value=False, description='lower', indent=False)\nlemmatize_checkbox = widgets.Checkbox(value=False, description='lemmatize', indent=False)\nremove_hyphens_checkbox = widgets.Checkbox(value=False, description='remove hyphens', indent=False)\nremove_numbers_checkbox = widgets.Checkbox(value=False, description='remove numbers', indent=False)\nstrip_accents_checkbox = widgets.Checkbox(value=False, description='strip accents', indent=False)\n\nlemmatizer = WordNetLemmatizer()\ndef lemmatize(sentence):\n    return ' '.join([lemmatizer.lemmatize(word) for word in sentence.split()])\nassert lemmatize('eggs') == 'egg'\n\ndef remove_numbers(sentence):\n    words = []\n    for word in sentence.split():\n        if re.findall('[0-9]', word): continue\n        if len(word) > 0: words.append(word)\n    return ' '.join(words)\n\ndef update_ingredients(widget):\n    for i, ingredient in enumerate(ingredients):\n        processed = ingredient\n        if lower_checkbox.value: processed = processed.lower()\n        if lemmatize_checkbox.value: processed = lemmatize(processed)\n        if remove_hyphens_checkbox.value: processed = processed.replace('-', ' ')\n        if remove_numbers_checkbox.value: processed = remove_numbers(processed)\n        if strip_accents_checkbox.value: processed = unidecode.unidecode(processed)\n        if processed == ingredient:\n            labels[i].value = ingredient\n        else:\n            labels[i].value = f'{ingredient} => {processed}'\n\nlower_checkbox.observe(update_ingredients)\nlemmatize_checkbox.observe(update_ingredients)\nremove_hyphens_checkbox.observe(update_ingredients)\nremove_numbers_checkbox.observe(update_ingredients)\nstrip_accents_checkbox.observe(update_ingredients)\n\ndisplay(widgets.VBox([\n    widgets.Box([lower_checkbox, lemmatize_checkbox, remove_hyphens_checkbox, remove_numbers_checkbox, strip_accents_checkbox]),\n    widgets.VBox(labels)\n]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}