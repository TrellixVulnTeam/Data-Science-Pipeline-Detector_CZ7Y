{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing all the required libraries\nimport os\nimport numpy as np\nimport pandas as pd\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the filenames from the directory\nfilenames = os.listdir(\"../input/train/train\")\ntest_files = os.listdir(\"../input/test1/test1\")\n\n# Creating a target list which will contain target labels\ntarget = []\nfor name in filenames:\n    if \"cat\" in name:\n        target.append('cat')\n    else:\n        target.append('dog')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dataframe of for both train and test data set \n# Filesnames contains the image name  and target column contains labels i.e cat or dog\ntrain = pd.DataFrame({'filenames' : filenames,\n                     'target' : target})\n\n# test dataset contains only filenames \ntest =  pd.DataFrame({'filenames' : test_files})\n\n# Splitting data for training and validation\nx_train, x_test, y_train, y_test = train_test_split(train['filenames'], \n                                                    train['target'], \n                                                    test_size=0.2,\n                                                    stratify=train['target'])\n\n# Again creating the dataframe of splitted data\ntraining_dataset = pd.DataFrame({'filename' : x_train, \n                       'target' : y_train})\nvalidation_dataset = pd.DataFrame({'filename' : x_test, \n                       'target' : y_test}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the data from data frame files names using Keras Image Data Generator\nBATCH_SIZE = 20\ntrain_generator = ImageDataGenerator(rescale = 1./255)\nvalidation_generator = ImageDataGenerator(rescale = 1./255)\ntest_generator = ImageDataGenerator(rescale=1/.255)\n\ntrain_gen = train_generator.flow_from_dataframe(training_dataset, \n                                                \"../input/train/train/\",\n                                                target_size = (150, 150),\n                                                batch_size = 20,\n                                                x_col = 'filename',\n                                                y_col = 'target',\n                                                class_mode = 'binary',\n                                                shuffle = False)\n\nvalidation_gen = test_generator.flow_from_dataframe(validation_dataset, \n                                                    \"../input/train/train/\",\n                                                    target_size = (150, 150),\n                                                    batch_size = 20,\n                                                    x_col = 'filename',\n                                                    y_col = 'target',\n                                                    class_mode = 'binary',\n                                                    shuffle = False)\n\ntest_gen = test_generator.flow_from_dataframe(test,\n                                              \"../input/test1/test1/\",\n                                              target_size = (150, 150),\n                                              batch_size = 20,\n                                              x_col = 'filenames',\n                                              class_mode = None,\n                                              shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How Generator Works?/\n# Python Generator give lends us values to iterate on,\n# We need to break python generator once all the data or filenames are fetched\n# In one call it will fetch 20 samples = batch size\nfor data_batch, label_batch in train_gen:\n    print(\"Data Shape \", data_batch.shape)\n    print('Target Shape ',label_batch.shape)\n    plt.imshow(data_batch[4])\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keras Deep Learning Model Architecture\nmodel = Sequential()\n# Layer 1\nmodel.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2)))\n\n#Layer 2\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2)))\n\n#Layer 3\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2)))\n\n#Layer 4\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a flatten layer\nmodel.add(layers.Flatten())\n\n# Addling a dense layer\nmodel.add(layers.Dense(512, activation='relu'))\n# Final output layer\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n\n# Compling the model\nmodel.compile(optimizer = optimizers.RMSprop(lr = 1e-4),\n             loss='binary_crossentropy',\n             metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n    train_gen, \n    epochs=20,\n    validation_data=validation_gen,\n    validation_steps=250, # test_dataset.shape[0]//20,\n    steps_per_epoch=1000 # training_dataset.shape[0]//20\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets save the model and print summary\nmodel.save('catsDogsClassification.h5')\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing for the prediction on the validation Data Set\npredicted_value = np.zeros(validation_dataset.shape[0])\ni = 0\ndf = pd.DataFrame(columns = ['predicted_values', \n                             'original_values'])\nfor test_data, test_label in validation_gen:\n    predicted_value = model.predict(test_data)\n    predicted_value = np.reshape(predicted_value, (20,)).tolist()\n    predicted_df = pd.DataFrame({'predicted_values' : predicted_value,\n                                'test_label' : test_label})\n    df = pd.concat([df, predicted_df],\n                   axis = 0,\n                   ignore_index=False,\n                   sort = False)\n    i = i + 1\n    if i*20 >= validation_dataset.shape[0]:\n        break\n        \n# Predicting on the validation dataset\npredicted_df['predicted_values'] = predicted_df['predicted_values'].apply(lambda x : 1 if x > 0.5 else 0)\n\nclass_mapping = train_gen.class_indices\nprint('F1 Score on the validation data set - ', f1_score(predicted_df['predicted_values'] , \n                                                      predicted_df['test_label']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preiction on the test data\n# On Test data\ntest_gen.reset()\nprediction =  model.predict_generator(test_gen,\n                                     steps=test.shape[0]/BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file = pd.DataFrame({'id' : test_gen.filenames,\n                               'label' : np.reshape(prediction, (prediction.shape[0], )).astype(int)})\nsubmission_file['id'] = submission_file['id'].str.replace('.jpg', '')\n\nsubmission_file.to_csv('submission_file_290719.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}