{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Import Stuff and TPU's"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport shutil\nfrom shutil import copyfile\nimport random\nimport os\nimport zipfile\nprint(\"What we've Got\",os.listdir(\"../input/dogs-vs-cats\"))\ninput = \"../input/dogs-vs-cats/train\"\n\n### ADDING TPU's\n# detect and init the TPU\ntpu=\"TPU v3-8\"\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Unzip All\nDataset = \"train\"\nwith zipfile.ZipFile(\"../input/dogs-vs-cats/\"+Dataset+\".zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mk_categories(df,dtype):\n    os.makedirs(dtype+\"/dogs\", exist_ok=True)\n    os.makedirs(dtype+\"/cats\", exist_ok=True)\n    for index, row in df.iterrows():\n        filename= row['filename']\n        category = row['filename'].split('.')[0]\n        if category == 'dog':\n            copyfile(\"train/\"+filename, dtype+\"/dogs/\"+filename)\n        else:\n            copyfile(\"train/\"+filename, dtype+\"/cats/\"+filename)\n\nfilenames = os.listdir(\"train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\n## Make some test data out of training data\ntrain_df, test_df = train_test_split(df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True) \nmk_categories(train_df,\"training\")\nmk_categories(test_df,\"test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['category'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['category'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = random.choice(filenames)\nimage = load_img(\"train/\"+sample)\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PLot a snapshot "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotSnap(who,folder=\"train/\"): \n    # plot first few images\n    for i in range(9):\n         # define subplot\n        plt.subplot(330 + 1 + i)\n        # define filename\n        filename = folder + who +'.' + str(i) + '.jpg'\n        # load image pixels\n        image = load_img(filename)\n        # plot raw pixel data\n        plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets let the dogs out"},{"metadata":{"trusted":true},"cell_type":"code","source":"plotSnap(\"dog\")\n    \n# show the figure\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets see some cat pics"},{"metadata":{"trusted":true},"cell_type":"code","source":"plotSnap(\"cat\")\n    \n# show the figure\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hmm so many different pictures :|"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"folder = 'train/'\nphotos, labels = list(), list()\n# enumerate files in the directory\nfor file in os.listdir(folder):\n    # determine class\n    output = 0.0\n    if file.startswith('cat'):\n        output = 1.0\n    # load image\n    photo = load_img(folder + file, target_size=(200, 200))\n    # convert to numpy array\n    photo = img_to_array(photo)\n    # store\n    photos.append(photo)\n    labels.append(output)\n# convert to a numpy arrays\nphotos = np.asarray(photos)\nlabels = np.asarray(labels)\nprint(photos.shape, labels.shape)\n# save the reshaped photos\nsave('dogs_vs_cats_photos.npy', photos)\nsave('dogs_vs_cats_labels.npy', labels)"},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"check augmenting existing data to generate scenarios"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotPreview(who,folder=\"preview/\"): \n    i=1\n    # plot first few images\n    for file in os.listdir(folder):\n         # define subplot\n        plt.subplot(8,8,i)\n        i=i+1\n        filename = folder + file\n        image = load_img(filename)\n        plt.imshow(image)\n        if i>20:\n            break\n\nif not os.path.exists(\"preview\"):\n    os.mkdir(\"preview\")\n    \ndatagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\nimg = load_img('train/cat.0.jpg')  # this is a PIL image\nx = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\nx = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n\n# the .flow() command below generates batches of randomly transformed images\n# and saves the results to the `preview/` directory\ni = 0\nfor batch in datagen.flow(x, batch_size=1,save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n    i += 1\n    if i > 20:\n        break  # otherwise the generator would loop indefinitely\n        \nplotPreview(\"cat\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers import Activation, Dropout, Flatten, Dense\n# create convnet model\ndef build_model(type=\"covnet\"):\n    with strategy.scope():\n        if type == \"covnet\":\n            model = Sequential()\n            model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Dropout(0.2))\n            model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Dropout(0.2))\n            model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n            model.add(MaxPooling2D((2, 2)))\n            model.add(Dropout(0.2))\n            model.add(Flatten())\n            model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n            model.add(Dropout(0.5))\n            model.add(Dense(1, activation='sigmoid'))\n            opt = SGD(lr=0.001, momentum=0.9)\n            model.compile(loss='binary_crossentropy',\n                          optimizer='rmsprop',\n                          metrics=['accuracy'])\n        if type == \"VGG16\":\n            model = VGG16(include_top=False, input_shape=(224, 224, 3))\n            for layer in model.layers:\n                layer.trainable = False\n            flat1 = Flatten()(model.layers[-1].output)\n            class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n            output = Dense(1, activation='sigmoid')(class1)\n            model = Model(inputs=model.inputs, outputs=output)\n            opt = SGD(lr=0.001, momentum=0.9)\n            model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n\nimport tensorflow as tf\nimport keras.backend.tensorflow_backend as tfback\nprint(\"tf.__version__ is\", tf.__version__)\nprint(\"tf.keras.__version__ is:\", tf.keras.__version__)\n\ndef _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    #global _LOCAL_DEVICES\n    if tfback._LOCAL_DEVICES is None:\n        devices = tf.config.list_logical_devices()\n        tfback._LOCAL_DEVICES = [x.name for x in devices]\n    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n\ntfback._get_available_gpus = _get_available_gpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data prep"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Unzip All test\nDataset = \"test1\"\nwith zipfile.ZipFile(\"../input/dogs-vs-cats/\"+Dataset+\".zip\",\"r\") as z:\n    z.extractall(\".\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_summaries(model):\n    plt.subplot(211)\n    plt.title('Cross Entropy Loss')\n    plt.plot(model.history['loss'], color='blue', label='train')\n    plt.plot(model.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    plt.subplot(212)\n    plt.title('Classification Accuracy')\n    plt.plot(model.history['accuracy'], color='blue', label='train')\n    plt.plot(model.history['val_accuracy'], color='orange', label='test')\n    plt.show()\n \n# Run Train and eval Model \ndef run_train_eval(savepoint=\"savepoint.h5\",type=\"covnet\"):\n    batch_size=16 * strategy.num_replicas_in_sync\n    if type==\"covnet\":\n        size = 200\n    else:\n        size = 224\n    # this is the augmentation configuration we will use for training\n    train_datagen = ImageDataGenerator(\n            rescale=1./255,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True)\n\n    # this is the augmentation configuration we will use for testing:\n    # only rescaling\n    test_datagen = ImageDataGenerator(rescale=1./255)\n\n    # this is a generator that will read pictures found in\n    # subfolers of 'data/train', and indefinitely generate\n    # batches of augmented image data\n    train_generator = train_datagen.flow_from_directory(\n            '/kaggle/working/training/',  # this is the target directory\n            target_size=(size, size),  # all images will be resized to 150x150\n            batch_size=batch_size,\n            class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n\n    # this is a similar generator, for validation data\n    validation_generator = test_datagen.flow_from_directory(\n            '/kaggle/working/test/',\n            target_size=(size, size),\n            batch_size=batch_size,\n            class_mode='binary')\n    model = build_model(type=type)\n    fit = model.fit_generator(\n            train_generator,\n            steps_per_epoch=2000// batch_size,\n            epochs=50,\n            validation_data=validation_generator,\n            validation_steps=800 // batch_size\n    )\n    model.save_weights(savepoint)\n    # evaluate model\n    _, acc = model.evaluate_generator(validation_generator, steps=len(validation_generator), verbose=0)\n    display('> %.3f' % (acc * 100.0))\n    plot_summaries(fit)\n    return (model,fit)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test with covnet"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = run_train_eval()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check with VGG :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelVGG = run_train_eval(savepoint=\"vgg.h5\",type=\"VGG16\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# See if predictions work"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import load_model\n \n# load and prepare the image\ndef load_image(filename,imgSize =224):\n    img = load_img(filename, target_size=(imgSize, imgSize))\n    img = img_to_array(img)\n    img = img.reshape(1, imgSize, imgSize, 3)\n    img = img.astype('float32')\n    img = img - [123.68, 116.779, 103.939]\n    return img\n \n# load an image and predict the class\ndef predict_img(img):\n    # load the image\n    img = load_image(img)\n    # load model\n    model = build_model(type=\"VGG16\")\n    model.load_weights('vgg.h5')\n    # predict the class\n    result = model.predict(img)\n    return result[0]\n\ndef predict_img(img):\n    # load the image\n    img = load_image(img)\n    # load model\n    model = build_model(type=\"VGG16\")\n    model.load_weights('vgg.h5')\n    # predict the class\n    result = model.predict(img)\n    return result[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_img(\"test1/5853.jpg\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = predict_img(\"test1/5853.jpg\") \nprint(val[0])\nif val[0]== 1:\n    print(\"Found A Dog !\")\nelse:\n    print(\"Found A Cat ! \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(\"test1\") \nids =[]\nlabels =[]\ni =1 \nplt.figure(figsize=(12, 24))\nmodel = build_model(type=\"VGG16\")\nmodel.load_weights('vgg.h5')\nfor filename in filenames:\n    id = filename.split('.')[0]\n    ids.append(id)\n    img=\"test1/\"+filename\n    truncImg = load_image(img)\n    lbl = model.predict(truncImg) \n    labels.append(int(round(lbl[0][0])))\n    # Plot few samples\n    if i <= 5:\n        plt.subplot(6, 3, i+1)\n        plt.imshow(load_img(\"test1/\"+filename))\n        plt.xlabel('%s > %f' % (id,int(round(lbl[0][0]))))\n        plt.show()\n        #display('%s > %f' % (id,lbl))\n    i = i+1\n\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## remode dirs\ndef deldir(dirPath):\n    try:\n        print(\"Removing Directory\",dirPath) \n        shutil.rmtree(dirPath)\n    except:\n        print('Error while deleting directory')\ndeldir(\"train\")\ndeldir(\"training\")\ndeldir(\"test1\")\ndeldir(\"test\")\ndeldir(\"preview\")\n\n## create submission file\nsubmission_df = pd.DataFrame({\n    'id': ids,\n    'label': labels\n})\ndisplay(submission_df.head())\nsubmission_df.to_csv('submission.csv', index=False)  ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}