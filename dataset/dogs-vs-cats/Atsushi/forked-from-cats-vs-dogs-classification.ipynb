{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# You may need to install a custom package named *imutils* to run this notebook. \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import cross_val_score\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/train\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9548902205315f78f9d6ea596a7a45d3dd66db4e"},"cell_type":"code","source":"# Adopted (and modified) from https://www.pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.feature_selection import RFE, SelectFromModel\nfrom imutils import paths\nimport numpy as np\nimport imutils # a simple image utility library\nimport cv2 #opencv library\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ba6d6ea34bd8a0f36d2873b6b0960ee8a9b8775"},"cell_type":"code","source":"def image_to_feature_vector(image, size=(32, 32)):\n# resize the image to a fixed size, then flatten the image into\n# a list of raw pixel intensitieb\n    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n    return cv2.resize(ycrcb, size, interpolation=cv2.INTER_AREA).flatten()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9510d8bc95e6f34446413b9a40471caa20c8f15c"},"cell_type":"code","source":"dataset = \"../input/train/train/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"970c37bf80b54b5e186061d0fe39c5a34f4c1995"},"cell_type":"code","source":"# grab the list of images that we'll be describing\nprint(\"[INFO] describing images...\")\nimagePaths = list(paths.list_images(dataset))\nprint(len(imagePaths))\nprint(imagePaths[0])\n# initialize the raw pixel intensities matrix, the features matrix,\n# and labels list\nrawImages = []\nlabels = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c3f13675a86fd1a762649ef52114b5151be16e5"},"cell_type":"code","source":"# loop over the input images\nfor (i, imagePath) in enumerate(imagePaths):\n\t# load the image and extract the class label (assuming that our\n\t# path as the format: /path/to/dataset/{class}.{image_num}.jpg\n\timage = cv2.imread(imagePath)\n\tlabel = 1 if imagePath.split(os.path.sep)[-1].split(\".\")[0] == \"dog\" else 0\n \n\t# extract raw pixel intensity \"features\", followed by a color\n\t# histogram to characterize the color distribution of the pixels\n\t# in the image\n\tpixels = image_to_feature_vector(image)\n\t\n \n\t# update the raw images, features, and labels matricies,\n\t# respectively\n\trawImages.append(pixels)\n\tlabels.append(label)\n \n\t# show an update every 1,000 images\n\tif i > 0 and i % 1000 == 0:\n\t\tprint(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3b2adca6b9b7f83038f0a5d1c3a2118d1afdede"},"cell_type":"code","source":"# show some information on the memory consumed by the raw images\n# matrix and features matrix\nrawImages = np.array(rawImages)\nlabels = np.array(labels)\nprint(\"[INFO] pixels matrix: {:.2f}MB\".format(\n\trawImages.nbytes / (1024 * 1000.0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fab6cded70110b1fc3494799346a6c31793f9c9"},"cell_type":"code","source":"# partition the data into training and testing splits, using 75%\n# of the data for training and the remaining 25% for testing\n(trainRI, trainRL) = (rawImages, labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96f099b5712bfb068bd93211725ff11cfa70b3cf"},"cell_type":"code","source":"# Select a subset of the entire dataset \nrawImages_subset = rawImages[:2000]\nlabels_subset= labels[:2000]\n(trainRI, trainRL) = (rawImages_subset, labels_subset)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70ccd1c8cae68e8af1692316dbfb8fd62355a476"},"cell_type":"code","source":"# train and evaluate a AdaBoost classifer on the raw pixel intensities\nprint(\"[INFO] evaluating raw pixel accuracy...\")\n#neighbors = [1, 3, 5, 7, 13]\n#for k in neighbors:\nmodel = AdaBoostClassifier(n_estimators=300)\nacc = cross_val_score(model, trainRI, trainRL, cv=3)\nprint(\"[INFO] raw pixel accuracy: {}\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68b277b0331fdacd19be062e8539b6280222dae8"},"cell_type":"code","source":"# train and evaluate a XGBoost classifer on the raw pixel intensities\nprint(\"[INFO] evaluating raw pixel accuracy...\")\nmodel = XGBClassifier(learning_rate=0.1, n_estimators=300, max_depth=6, colsample_bytree=0.2, subsample=0.9, objective=\"binary:logistic\")\nacc = cross_val_score(model, trainRI, trainRL, cv=3)\nprint(\"[INFO] raw pixel accuracy: {}\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train and evaluate a Logistic Regression classifer on the raw pixel intensities\nprint(\"[INFO] evaluating raw pixel accuracy...\")\nmodel = LogisticRegression(solver='liblinear', max_iter=300)\nacc = cross_val_score(model, trainRI, trainRL, cv=3)\nprint(\"[INFO] raw pixel accuracy: {}\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(trainRI, trainRL) = (rawImages, labels)\n\nprint(\"[INFO] evaluating raw pixel accuracy...\")\nmodel = XGBClassifier(learning_rate=0.1, n_estimators=300, max_depth=6, colsample_bytree=0.2, subsample=0.9, objective=\"binary:logistic\")\nacc = cross_val_score(model, trainRI, trainRL, cv=3)\nprint(\"[INFO] raw pixel accuracy: {}\".format(acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}