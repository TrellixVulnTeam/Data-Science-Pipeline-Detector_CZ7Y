{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing sShift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import 해야할 것 하기.\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers import Dense, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 디렉토리 안의 파일 확인\nprint(os.listdir(\"../input/dogs-vs-cats/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\nzf = ZipFile('../input/dogs-vs-cats/train.zip', 'r')\nzf.extractall('../kaggle/working/Temp')\nzf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../kaggle/working/Temp/train\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# jpg그림 개와 고양이 분류카테고리 생성\nfilenames = os.listdir(\"../kaggle/working/Temp/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append('dog')\n    else:\n        categories.append('cat')\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimg = image.load_img(\"../kaggle/working/Temp/train/\"+filenames[0])\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이미지 전처리\ntest_image = image.load_img(\"../kaggle/working/Temp/train/\"+filenames[0], \n                            target_size=(128, 128))\ntest_image = image.img_to_array(test_image)\nplt.imshow(test_image[:, :, 2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#교육할 trainset 분리\nfrom sklearn.model_selection import train_test_split\n\ntrain_data, val_data = train_test_split(df, test_size=0.20, random_state=42)\ntrain_data = train_data.reset_index(drop=True)\nval_data   = val_data.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_data['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#모델 구성\nmodel = Sequential([Convolution2D(filters=32, kernel_size=(3, 3), strides=(1, 1), input_shape=(128,128,3),\n                            padding='valid', activation='relu'),\n                         BatchNormalization(),\n                         MaxPooling2D(pool_size=(2, 2)),\n                         Dropout(0.2),\n                         Convolution2D(filters=32, kernel_size=(3, 3), strides=(1, 1),\n                            padding='valid', activation='relu'),\n                         BatchNormalization(),\n                         MaxPooling2D(pool_size=(2, 2)),\n                         Dropout(0.2),\n                         Flatten(),\n                         Dense(512, activation='relu'),\n                         BatchNormalization(),\n                         Dropout(0.25),\n                         Dense(2, activation='softmax')])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 전처리\ntrain_image = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\ntrain_generator = train_image.flow_from_dataframe(\n        train_data,\n        \"../kaggle/working/Temp/train/\",\n        x_col='filename',\n        y_col='category',\n        target_size=(128, 128),\n        batch_size=32,\n        class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_datagen = ImageDataGenerator(rescale=1./255)\n\nval_generator = val_datagen.flow_from_dataframe(\n        val_data,\n        \"../kaggle/working/Temp/train/\",\n        x_col='filename',\n        y_col='category',\n        target_size=(128, 128),\n        batch_size=32,\n        class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 학습이 일정 이상 좋아지지 않으면 중단.\nearly_stopp = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True)\nbest_model =  tf.keras.callbacks.ModelCheckpoint('best_model.h5',moniter='val_accuracy',verbose=1,save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 모델 학습\nhist=model.fit(train_generator,\n                                epochs=10,\n                                validation_data=val_generator,\n                                callbacks=[early_stopp,best_model])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# epoch에 의한 accuracy 변화율\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'], '')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Accuracy')\nplt.title('Change of Accuracy over Epochs')\nplt.legend(['accuracy', 'val_accuracy'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# epoch에 의한 loss변화율\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'], '')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Loss')\nplt.title('Change of Loss over Epochs')\nplt.legend(['loss', 'val_loss'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 예측을 위한 test1 파일을 불러오기.\nfrom zipfile import ZipFile\nzf = ZipFile('../input/dogs-vs-cats/test1.zip', 'r')\nzf.extractall('../kaggle/working/Temp')\nzf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(\"../kaggle/working/Temp/test1\")\n\ntest_data = pd.DataFrame({\n    'filename': filenames\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 아까 model을 불러와서 예측준비.\nfrom keras.models import load_model\n\npred = load_model('best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dog = 1로 예측함.\nimg = image.load_img(\"../kaggle/working/Temp/test1/\"+filenames[29])\n                            \ntest_image = image.load_img(\"../kaggle/working/Temp/test1/\"+filenames[29], \n                            target_size=(128, 128))\ntest_image = image.img_to_array(test_image)\nplt.imshow(img)\ntest_image = np.expand_dims(test_image, axis=0)\nresult = pred.predict(test_image)\nprint(np.argmax(result, axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cat 은 0으로 나와야하나 예측실패.\nimg = image.load_img(\"../kaggle/working/Temp/test1/\"+filenames[55])\n                            \ntest_image = image.load_img(\"../kaggle/working/Temp/test1/\"+filenames[55], \n                            target_size=(128, 128))\ntest_image = image.img_to_array(test_image)\nplt.imshow(img)\ntest_image = np.expand_dims(test_image, axis=0)\nresult = pred.predict(test_image)\nprint(np.argmax(result, axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}