{"cells":[{"metadata":{"_uuid":"fe76d1d1ded592430e7548feacfa38dc42f085d9"},"cell_type":"markdown","source":"# Import Library","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport keras\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Constants","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# assign FAST_RUN=True to train the model with three epochs\nFAST_RUN = False\n\n# input image dimensions\nIMAGE_WIDTH=128\nIMAGE_HEIGHT=128\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n\n# red, green and blue channels\nIMAGE_CHANNELS=3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7335a579cc0268fba5d34d6f7558f33c187eedb3"},"cell_type":"markdown","source":"# Prepare Traning Data","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# get a list of file names from the train folder\nfilenames = os.listdir(\"../input/train/train\")\nfilenames","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# an empty list which will contain all the labels of the train images.\n# for example: for cat.8937.jpg- 0 will be appended to the list. for dog.695.jpg- 1 will be \n# appended to the list\ncategories = []\nfor filename in filenames:\n    \n    # split the filename using delimiter '.'.\n    # for example, 'cat.8937.jpg' will be splitted into 'cat','8937','jpg'. we will take the\n    # first string 'cat' as the category of that image\n    category = filename.split('.')[0]\n    \n    # We will label all the images with dog photos as 1's and cat photos as 0's\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\n# we will create a dataframe which will contain the filenames and the labels of our train set\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"915bb9ba7063ab4d5c07c542419ae119003a5f98","trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72bf69e817f67f5a2eaff8561217e22077248553","trusted":false},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a999484fc35b73373fafe2253ae9db7ff46fdb90"},"cell_type":"markdown","source":"### See Total In count","execution_count":null},{"metadata":{"_uuid":"fa26f0bc7a6d835a24989790b20f3c6f32946f45","trusted":false},"cell_type":"code","source":"# create a barplot showing the amount of cat and dog pictures\ndf['category'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a08da58107777a1dd05c4a4bf5c484484923cac"},"cell_type":"markdown","source":"From our data we have 12000 cats and 12000 dogs","execution_count":null},{"metadata":{"_uuid":"400a293df3c8499059d9175f3915187074efd971"},"cell_type":"markdown","source":"# See sample image","execution_count":null},{"metadata":{"_uuid":"602b40f7353871cb161c60b5237f0da0096b2f47","trusted":false},"cell_type":"code","source":"# randomly choose an image for display\nsample = random.choice(filenames)\nimage = load_img(\"../input/train/train/\"+sample)\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b244e6b7715a04fc6df92dd6dfa3d35c473ca600"},"cell_type":"markdown","source":"# Build Model\n\n<img src=\"https://i.imgur.com/ebkMGGu.jpg\" width=\"100%\"/>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* **Input Layer**: It represent input image data. It will reshape image into single diminsion array. Example your image is 64x64 = 4096, it will convert to (4096,1) array.\n* **Conv Layer**: This layer will extract features from image.\n* **Pooling Layer**: This layerreduce the spatial volume of input image after convolution.\n* **Fully Connected Layer**: It connect the network from a layer to another layer\n* **Output Layer**: It is the predicted values layer. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nmodel = Sequential()\n\n# layer 1\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#layer 2\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#layer 3\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#fully connected layer\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### my understanding on the last layer:\nwe will use a softmax activation on the last layer when we have categorical dependent variable. otherwise, we will use a normal dense layer","execution_count":null},{"metadata":{"_uuid":"8c9f833c1441b657c779844912d0b8028218d454","trusted":false},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### my understanding on loss function:\nwe will use categorical cross entropy for categorical output. we will use mean squared error for non-categorical output.\n##### my understanding on optimizer:\nwe will use Root Mean Square Propogation for categorical output. For non-categorical output, we will use adam optimization.\n##### my understanding on performance metrics:\nwe will use accuracy for categorical output. We will use mean absolute error for non-categorical output","execution_count":null},{"metadata":{"_uuid":"bd496f6c65888a969be3703135b0b03a8a1190c8"},"cell_type":"markdown","source":"# Callbacks","execution_count":null},{"metadata":{"_uuid":"9aa032f0f6da539d23918890d2d131cc3aac8c7a","trusted":false},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76c9ba4fb7f930c96b2c3e0d6b68ed9fa6a4227b"},"cell_type":"markdown","source":"**Early Stop**\n\nTo prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased","execution_count":null},{"metadata":{"_uuid":"3421c5ec428da6c0d8cc1184179a9caff1e01d1c","trusted":false},"cell_type":"code","source":"earlystop = EarlyStopping(patience=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51d3fe52e911286433cedf6e47332948a253361e"},"cell_type":"markdown","source":"**Learning Rate Reduction**\n\nWe will reduce the learning rate when then validation accuracy not increase for 2 steps","execution_count":null},{"metadata":{"_uuid":"8010a5661ad8924d2db24af0f3c00b1593b38901","trusted":false},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a79cc604199469789f183096d863f7248e5f6aab","trusted":false},"cell_type":"code","source":"callbacks = [earlystop, learning_rate_reduction]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Because we will use image genaretor `with class_mode=\"categorical\"`. We need to convert column category into string. Then imagenerator will convert it one-hot encoding which is good for our classification. \n\nSo we will convert 1 to dog and 0 to cat","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4eeb7af8dcf02c4ef5ca744c8305c51a2f5cedef","trusted":false},"cell_type":"code","source":"# do a train-validation split on the whole set.\ntrain_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n\n# drop the indexes of train and validation dataframe\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b84836337441705eda9d2e655665ffa14d9feead","trusted":false},"cell_type":"code","source":"# see the amount of cat and dog photos in the train dataframe\ntrain_df['category'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19cf03f9a3c39532d6e2d06bd30be49a5afd9d57","trusted":false},"cell_type":"code","source":"# see the amount of cat and dog photos in the train dataframe\nvalidate_df['category'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae3dec0361f0443132d0309d3b883ee80070cf9f","trusted":false},"cell_type":"code","source":"# get the total amount of data in train and validation set\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\n\n# set the minibatch size to 15\nbatch_size=15","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff760be9104f7d9492467b8d9d3405011aa77d11"},"cell_type":"markdown","source":"# Traning Generator","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# ImageDataGenerator?","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d1c7818703a8a4bac5c036fdea45972aa9e5e9e","trusted":false},"cell_type":"code","source":"#  Generate batches of tensor image data with real-time data augmentation.\n#  The data will be looped over (in batches)\n\n# Degree range for random rotations is 15\n# rescaling factor is 1/255, meaning that the image pixel values will be multiplied by 1/255\n# Shear angle in counter-clockwise direction in degrees is 0.1\n# Range for random zoom is 0.2\n# Randomly flip inputs horizontally\n# width_shift_range 0.1 fraction of total width\n# height_shift_range 0.1 fraction of total height\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# train_datagen.flow_from_dataframe?","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d1c7818703a8a4bac5c036fdea45972aa9e5e9e","trusted":false},"cell_type":"code","source":"# Takes the dataframe and the path to a directory\n#  and generates batches of augmented/normalized data.\n\n# target_size: The dimensions to which all images found will be resized\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"../input/train/train/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"859c7b2857939c19fd2e3bb32839c9f7deb5aa3f"},"cell_type":"markdown","source":"### Validation Generator","execution_count":null},{"metadata":{"_uuid":"7925e16bcacc89f4484fb6fe47e54d6420af732e","trusted":false},"cell_type":"code","source":"# we will definitely not need to zoom, shear, or any kind of bullshit to increase validation\n# set but we will divide the pixel values by 255\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"../input/train/train/\",\n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e17fc1f002fedd60febb78fee5e81770640b909"},"cell_type":"markdown","source":"# See how our generator work","execution_count":null},{"metadata":{"_uuid":"4252cce168ab65f88e44a8ebc2672607bc852af4","trusted":false},"cell_type":"code","source":"# here we will create a dataframe with one row from the training dataframe for demonstrating\n# how the datagenerator works\nexample_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"../input/train/train/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23d923dba747f8b47dc75569244cecc6f70df321","trusted":false},"cell_type":"code","source":"# we will generate 15 random image from our example data generator and show them using\n# matplotlib\nplt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    #on each iteration of the for loop, the generator returns the same amount of random \n    #images as the original dataframe on which the generator was created\n    for X_batch, Y_batch in example_generator:\n        #get the first image of the generated batch\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"810ddf1373d9db470ed48da4f30ca5a6c1274435"},"cell_type":"markdown","source":"Seem to be nice ","execution_count":null},{"metadata":{"_uuid":"5cd8df64e794ed17de326b613a9819e7da977a0e"},"cell_type":"markdown","source":"# Fit Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Uncomment the following cell to run training","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"if(os.path.isfile('saved_model/history.csv') and pd.read_csv('saved_model/history.csv').shape[0]>0):\n    iteration_to_be_loaded=pd.read_csv('saved_model/history.csv').shape[0]-1\n    model.load_weights(\"saved_model/model_\"+str(iteration_to_be_loaded)+\".h5\")\n    print(\"saved_model/model_\"+str(iteration_to_be_loaded)+\".h5\"+\" loaded!\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0836a4cc8aa0abf603e0f96573c0c4ff383ad56b","trusted":false},"cell_type":"code","source":"epochs=3 if FAST_RUN else 50\nhistory = model.fit(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size,\n    callbacks=callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# assert(False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa1fbc4081ae0de2993188b2bf658a0be5bc0687"},"cell_type":"markdown","source":"# Save Model","execution_count":null},{"metadata":{"_uuid":"67575a4decdaf79a915d23151626b784ffa82642","trusted":false},"cell_type":"code","source":"model.save_weights(\"saved_model/model.h5\")\n\nimport pickle\nwith open('saved_model/history.pickle', 'wb') as f:\n    pickle.dump(history, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.load_weights(\"saved_model/model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import pickle\nwith open('saved_model/history.pickle','rb') as f:\n    history = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b76c0a9040bc0babf0a453e567e41e22f8a1e0e"},"cell_type":"markdown","source":"# Visualize Training","execution_count":null},{"metadata":{"_uuid":"79055f2dc3e2abb47bea758e0464c86ca42ab431","trusted":false},"cell_type":"code","source":"# create a figure with two subplots in 2 rows and one column\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n\n#draw losses on the first subplot\n# plot the training loss\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n#plot the validation loss\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\n#draw accuracy on the second subplot\n# training accuracy\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n# validation accuracy\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"764dc66e4b2bc558f3a0f90b80bb802f5b3d45a8"},"cell_type":"markdown","source":"# Prepare Testing Data","execution_count":null},{"metadata":{"_uuid":"c35e70d3e1e4834dbbf840fa0ea08c049bfcd915","trusted":false},"cell_type":"code","source":"test_filenames = os.listdir(\"../input/test1/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"291bc3996dce8d05e174b27d64f03996d3e8038e"},"cell_type":"markdown","source":"# Create Testing Generator","execution_count":null},{"metadata":{"_uuid":"52249ec1c35fb1be3adef386be245de3794e55aa","trusted":false},"cell_type":"code","source":"test_gen = ImageDataGenerator(rescale=1./255)\n\n#remember to not shuffle the test set\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"../input/test1/test1/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fa580afca2931ec5ce374e732d8c1789d03f2ed"},"cell_type":"markdown","source":"# Predict","execution_count":null},{"metadata":{"_uuid":"4782eb23fa7d003f0e2415d995894017edb2d896","trusted":false},"cell_type":"code","source":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df['category'] = np.argmax(predict, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df['category']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will convert the predict category back into our generator classes by using `train_generator.class_indices`. It is the classes that image generator map while converting data into computer vision","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"label_map = dict((v,k) for k,v in train_generator.class_indices.items())\ntest_df['category'] = test_df['category'].replace(label_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df['category']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From our prepare data part. We map data with `{1: 'dog', 0: 'cat'}`. Now we will map the result back to dog is 1 and cat is 0","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b00add65fe765529e637c3a9904d710bb7eff1d8"},"cell_type":"markdown","source":"### Visualize Result","execution_count":null},{"metadata":{"_uuid":"d0bf6dd5ff344092fa0121f70bdd60fa5a40e29c","trusted":false},"cell_type":"code","source":"test_df['category'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce72a83f80d6e012b12b82c8ee3365d671a3b307"},"cell_type":"markdown","source":"### See predicted result with images","execution_count":null},{"metadata":{"_uuid":"98b41dc83075e6297137fb45bf703c313dd4ae28","trusted":false},"cell_type":"code","source":"sample_test = test_df.head(18)\nsample_test.head(18)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98b41dc83075e6297137fb45bf703c313dd4ae28","trusted":false},"cell_type":"code","source":"plt.figure(figsize=(12, 24))\n\n# iterrows() will return index and each row of a dataframe\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\"../input/test1/test1/\"+filename, target_size=IMAGE_SIZE)\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1ca25943e73aa20a37f9fb8670ee430caeaaf1f"},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{"_uuid":"cce9f3e2ffff0693d79d84590ed71fbbca7c3c7c","trusted":false},"cell_type":"code","source":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\n# I added this line\nsubmission_df=submission_df.astype({'id': 'int32'})\nsubmission_df=submission_df.sort_values('id',ascending=True)\n\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}