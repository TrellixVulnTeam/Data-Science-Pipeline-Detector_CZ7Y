{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport shutil\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats/train.zip',mode='r') as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats/test1.zip',mode='r') as z:\n    z.extractall(\".\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cats,dogs = [],[]\nfile_names = os.listdir(\"./train/\")\nfor i in file_names:\n    if i.split(\".\")[0]=='cat':\n        cats.append(i)\n    else:\n        dogs.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(cats),len(dogs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir my_dataset\n!mkdir my_dataset/training_data\n!mkdir my_dataset/training_data/cats\n!mkdir my_dataset/training_data/dogs\n!mkdir my_dataset/validation_data\n!mkdir my_dataset/validation_data/cats\n!mkdir my_dataset/validation_data/dogs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = int(len(cats)*.8) #80 percentage\n\n\nfor f in cats[:train_size]:\n    shutil.move(\"./train/\"+f, './my_dataset/training_data/cats/')\n\nfor f in cats[train_size:]:\n    shutil.move(\"./train/\"+f, './my_dataset/validation_data/cats/')\n    \nfor f in dogs[:train_size]:\n    shutil.move(\"./train/\"+f, './my_dataset/training_data/dogs/')\n\nfor f in dogs[train_size:]:\n    shutil.move(\"./train/\"+f, './my_dataset/validation_data/dogs/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = './my_dataset/'\n\ntrain_dir = os.path.join(base_dir, 'training_data')\nvalidation_dir = os.path.join(base_dir, 'validation_data')\n\n# Directory with our training cat/dog pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\n# Directory with our validation cat/dog pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cat_fnames = os.listdir( train_cats_dir )\ntrain_dog_fnames = os.listdir( train_dogs_dir )\n\nvalidation_cat_fnames = os.listdir( validation_cats_dir )\nvalidation_dog_fnames = os.listdir( validation_dogs_dir )\n\nprint(train_cat_fnames[:10])\nprint(train_dog_fnames[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('total training cat images :', len(os.listdir(      train_cats_dir ) ))\nprint('total training dog images :', len(os.listdir(      train_dogs_dir ) ))\n\nprint('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\nprint('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nnext_cat_pix = [os.path.join(train_cats_dir, fname) \n                for fname in train_cat_fnames[ pic_index-8:pic_index] \n               ]\n\nnext_dog_pix = [os.path.join(train_dogs_dir, fname) \n                for fname in train_dog_fnames[ pic_index-8:pic_index]\n               ]\n\nfor i, img_path in enumerate(next_cat_pix+next_dog_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tensorflow Model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale= 1.0/255)\nvalid_datagen = ImageDataGenerator(rescale= 1.0/255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                   batch_size=20,\n                                                   class_mode='binary',\n                                                   target_size=(150,150))\n\nvalidation_generator = valid_datagen.flow_from_directory(validation_dir,\n                                                   batch_size=20,\n                                                   class_mode='binary',\n                                                   target_size=(150,150))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,\n                   validation_data=validation_generator,\n                   steps_per_epoch=100,\n                   epochs=15,\n                   validation_steps=50,\n                   verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MODEL hISTORY Plotting","metadata":{}},{"cell_type":"code","source":"def plot_model_history(history):\n    #-----------------------------------------------------------\n    # Retrieve a list of list results on training and test data\n    # sets for each training epoch\n    #-----------------------------------------------------------\n    acc      = history.history[     'accuracy' ]\n    val_acc  = history.history[ 'val_accuracy' ]\n    loss     = history.history[    'loss' ]\n    val_loss = history.history['val_loss' ]\n\n    epochs   = range(len(acc)) # Get number of epochs\n\n    #------------------------------------------------\n    # Plot training and validation accuracy per epoch\n    #------------------------------------------------\n    plt.plot  ( epochs,     acc )\n    plt.plot  ( epochs, val_acc )\n    plt.title ('Training and validation accuracy')\n    plt.figure()\n\n    #------------------------------------------------\n    # Plot training and validation loss per epoch\n    #------------------------------------------------\n    plt.plot  ( epochs,     loss )\n    plt.plot  ( epochs, val_loss )\n    plt.title ('Training and validation loss'   )\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With Augmentation and Dropout","metadata":{}},{"cell_type":"code","source":"model2 = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel2.compile(optimizer=RMSprop(lr=0.001),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])\n\nmodel2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen_aug = ImageDataGenerator(rescale=1/255,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\n# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n# TRAIN GENERATOR.\ntrain_generator_aug = train_datagen_aug.flow_from_directory(train_dir,\n                                                   batch_size=10,\n                                                   class_mode='binary',\n                                                   target_size=(150,150))\n\nvalidation_datagen_aug = ImageDataGenerator(rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\n# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE \n# VALIDATION GENERATOR.\nvalidation_generator_aug = validation_datagen_aug.flow_from_directory(validation_dir,\n                                                              batch_size=100,\n                                                              class_mode='binary',\n                                                              target_size=(150, 150))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history2 = model2.fit(train_generator_aug,\n                   validation_data=validation_generator_aug,\n                   steps_per_epoch=100,\n                   epochs=15,\n                   validation_steps=50,\n                   verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_history(history2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transfer learning","metadata":{}},{"cell_type":"code","source":"!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape=(150,150,3),\n                               include_top=False,\n                               weights=None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n    layer.trainable=False\n    \n# pre_trained_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('Last layer output shape: ',last_layer.output_shape)\nlast_output = last_layer.output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = tf.keras.layers.Flatten()(last_output)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel3 = tf.keras.Model(pre_trained_model.input,x)\nmodel3.compile(optimizer=RMSprop(lr=0.0001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history3 = model.fit(\n                train_generator_aug,\n                validation_data = validation_generator_aug,\n                steps_per_epoch=100,\n                epochs=15,\n                validation_steps=50,\n                verbose=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_history(history_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above model we pick transfer learning as best model","metadata":{}},{"cell_type":"markdown","source":"Test and Submission","metadata":{}},{"cell_type":"code","source":"test_path='./test1'\ntest_file=os.listdir('./test1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=pd.DataFrame({'file':test_file})\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = valid_datagen.flow_from_dataframe(test_df,directory=test_path,\n                                                 x_col='file',\n                                                 y_col=None,\n                                                 class_mode=None,\n                                                 target_size=(150,150),\n                                                 batch_size=32,\n                                                 shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict=model.predict(test_generator)\nsub = np.around(predict).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nmy_random_list = [random.randint(0, len(test_file)) for i in range(8)]\nrandom_list = [os.path.join(test_path,test_file[i]) for i in my_random_list]\n\n\nfor i, img_path in enumerate(next_cat_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n  label = \"Dog\" if sub[my_random_list[i]]==1 else \"Cat\"\n  plt.title('Predicted: '+str(label)+'\\nScore: '+str(predict[my_random_list[i]]))\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_df.copy()\nsubmission['id'] = submission['file'].str.split(\".\").str[0]\nsubmission['label'] = sub\nsubmission.drop(['file'], axis=1, inplace=True)\nsubmission['id'] = submission['id'].astype('int')\nsubmission = submission.sort_values(by=['id'])\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To do:\n\n* Callbacks\n* Tensorboard\n* Augmentation\n* Transfer Learning","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}