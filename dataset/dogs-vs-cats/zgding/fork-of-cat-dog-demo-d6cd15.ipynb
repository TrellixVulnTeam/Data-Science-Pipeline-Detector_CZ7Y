{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#demo\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport random\nimport os,shutil\n\nsrc_path=\"../input\"\n\nprint(os.listdir(src_path))\n\n#constant value\nVALID_SPIT=0.2\nIMAGE_SIZE=64\nBATCH_SIZE=128\nCHANNEL_SIZE=1\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc928b5c9d681fa550231204eb05ad6402ec106a"},"cell_type":"code","source":"label=[]\ndata=[]\ncounter=0\npath=\"../input/train/train\"\nfor file in os.listdir(path):\n    image_data=cv2.imread(os.path.join(path,file), cv2.IMREAD_GRAYSCALE)\n    image_data=cv2.resize(image_data,(IMAGE_SIZE,IMAGE_SIZE))\n    if file.startswith(\"cat\"):\n        label.append(0)\n    elif file.startswith(\"dog\"):\n        label.append(1)\n    try:\n        data.append(image_data/255)\n    except:\n        label=label[:len(label)-1]\n    counter+=1\n    if counter%1000==0:\n        print (counter,\" image data retreived\")\n\ndata=np.array(data)\ndata=data.reshape((data.shape)[0],(data.shape)[1],(data.shape)[2],1)\nlabel=np.array(label)\nprint (data.shape)\nprint (label.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5aaa1607e0757c68ebc6489e216c24359fef4865"},"cell_type":"code","source":"sns.countplot(label)\npd.Series(label).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50433529f32b5c409deaf96721819fe45df10e1e"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_data, valid_data, train_label, valid_label = train_test_split(\n    data, label, test_size=0.2, random_state=42)\nprint(train_data.shape)\nprint(train_label.shape)\nprint(valid_data.shape)\nprint(valid_label.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caf768afb49730f1d0d5de90d7352ad32fb5935a"},"cell_type":"code","source":"sns.countplot(train_label)\npd.Series(train_label).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c68cb2b34a2e7dfcd93fbe0603dc89966fc0af1a"},"cell_type":"code","source":"sns.countplot(valid_label)\npd.Series(valid_label).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae76619d451c5fa6f5fd24afa291d6d605555a47"},"cell_type":"code","source":"from keras import Sequential\nimport keras.optimizers as optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import *\nimport keras.backend as K\nimport tensorflow as tf\nimport keras\nimport keras.layers as KL\nfrom keras.layers  import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c9c14f785071e5bdc82c1ac87c25d13f12f6cfd"},"cell_type":"code","source":"#result: val_acc=0.8346\n#Sequential模型接口 \nmodel=Sequential()\nmodel.add(Conv2D(8, (3, 3), input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNEL_SIZE), activation='relu', padding='same'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100,activation=\"relu\"))\nmodel.add(Dense(1,activation=\"sigmoid\"))\n\nmodel.summary()\n\n\n# training\nmodel.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n\ncallack_saver = ModelCheckpoint(\n            \"model.h5\"\n            , monitor='val_loss'\n            , verbose=0\n            , save_weights_only=True\n            , mode='auto'\n            , save_best_only=True\n        )\n\ntrain_history=model.fit(train_data,train_label,validation_data=(valid_data,valid_label),epochs=15,batch_size=BATCH_SIZE, callbacks=[callack_saver])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a3be3c49cf57fa01140530665da92292fadc49e"},"cell_type":"code","source":"\"\"\"\nnetwork block\n\"\"\"\n\n############################################################\n#  Utility Functions\n############################################################\nclass BatchNorm(KL.BatchNormalization):\n    def call(self, inputs, training=None):\n        return super(self.__class__, self).call(inputs, training=training)\n\n\n############################################################\n#  Resnet Graph\n############################################################\ndef identity_block(input_tensor, kernel_size, filters, stage, block,\n                   use_bias=True, train_bn=True):\n    nb_filter1, nb_filter2, nb_filter3 = filters\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = KL.Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a',\n                  use_bias=use_bias)(input_tensor)\n    x = BatchNorm(name=bn_name_base + '2a')(x, training=train_bn)\n    x = KL.Activation('relu')(x)\n\n    x = KL.Conv2D(nb_filter2, (kernel_size, kernel_size), padding='same',\n                  name=conv_name_base + '2b', use_bias=use_bias)(x)\n    x = BatchNorm(name=bn_name_base + '2b')(x, training=train_bn)\n    x = KL.Activation('relu')(x)\n\n    x = KL.Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c',\n                  use_bias=use_bias)(x)\n    x = BatchNorm(name=bn_name_base + '2c')(x, training=train_bn)\n\n    x = KL.Add()([x, input_tensor])\n    x = KL.Activation('relu', name='res' + str(stage) + block + '_out')(x)\n    return x\n\n\ndef conv_block(input_tensor, kernel_size, filters, stage, block,\n               strides=(2, 2), use_bias=True, train_bn=True):\n    nb_filter1, nb_filter2, nb_filter3 = filters\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = KL.Conv2D(nb_filter1, (1, 1), strides=strides,\n                  name=conv_name_base + '2a', use_bias=use_bias)(input_tensor)\n    x = BatchNorm(name=bn_name_base + '2a')(x, training=train_bn)\n    x = KL.Activation('relu')(x)\n\n    x = KL.Conv2D(nb_filter2, (kernel_size, kernel_size), padding='same',\n                  name=conv_name_base + '2b', use_bias=use_bias)(x)\n    x = BatchNorm(name=bn_name_base + '2b')(x, training=train_bn)\n    x = KL.Activation('relu')(x)\n\n    x = KL.Conv2D(nb_filter3, (1, 1), name=conv_name_base +\n                  '2c', use_bias=use_bias)(x)\n    x = BatchNorm(name=bn_name_base + '2c')(x, training=train_bn)\n\n    shortcut = KL.Conv2D(nb_filter3, (1, 1), strides=strides,\n                         name=conv_name_base + '1', use_bias=use_bias)(input_tensor)\n    shortcut = BatchNorm(name=bn_name_base + '1')(shortcut, training=train_bn)\n\n    x = KL.Add()([x, shortcut])\n    x = KL.Activation('relu', name='res' + str(stage) + block + '_out')(x)\n    return x\n\n\ndef resnet_full(input_image, architecture, stage5=False, train_bn=True):\n    assert architecture in [\"resnet50\", \"resnet101\"]\n    # Stage 1\n    x = KL.ZeroPadding2D((3, 3))(input_image)\n    x = KL.Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=True)(x) #默认padding='valid', 改成'same'，是否可以省略ZeroPadding2D\n    x = BatchNorm(name='bn_conv1')(x, training=train_bn)\n    x = KL.Activation('relu')(x)\n    x = KL.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n    # Stage 2\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), train_bn=train_bn)\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', train_bn=train_bn)\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', train_bn=train_bn)\n    # Stage 3\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', train_bn=train_bn)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', train_bn=train_bn)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', train_bn=train_bn)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', train_bn=train_bn)\n    # Stage 4\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', train_bn=train_bn)\n    block_count = {\"resnet50\": 5, \"resnet101\": 22}[architecture]\n    for i in range(block_count):\n        x = identity_block(x, 3, [256, 256, 1024], stage=4, block=chr(98 + i), train_bn=train_bn)\n    # Stage 5\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', train_bn=train_bn)\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b', train_bn=train_bn)\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c', train_bn=train_bn)\n\n    #cls\n    x = KL.GlobalAveragePooling2D(dim_ordering='default')(x)#globle_avg\n    x = KL.Dense(1000, name=\"output\")(x)\n    return\n\n\n############################################################\n#  Mobilenet V1 Graph\n############################################################\ndef relu6(x):\n    return K.relu(x, max_value=6)\n\n\ndef _conv_block(inputs, filters, alpha, kernel=(3, 3), strides=(1, 1),block_id=1, train_bn=False):\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    filters = int(filters * alpha)\n    x = KL.Conv2D(filters, kernel,\n               padding='same',\n               use_bias=False,\n               strides=strides,\n               name='conv{}'.format(block_id))(inputs)\n    x = BatchNorm(axis=channel_axis, name='conv{}_bn'.format(block_id))(x, training = train_bn)\n    return KL.Activation(relu6, name='conv{}_relu'.format(block_id))(x)\n\n\ndef _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n                          depth_multiplier=1, strides=(1, 1), block_id=1, train_bn=False):\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n    # Depthwise\n    x = KL.DepthwiseConv2D((3, 3),\n                    padding='same',\n                    depth_multiplier=depth_multiplier,\n                    strides=strides,\n                    use_bias=False,\n                    name='conv_dw_{}'.format(block_id))(inputs)\n    x = BatchNorm(axis=channel_axis, name='conv_dw_{}_bn'.format(block_id))(x, training=train_bn)\n    x = KL.Activation(relu6, name='conv_dw_{}_relu'.format(block_id))(x)\n    # Pointwise\n    x = KL.Conv2D(pointwise_conv_filters, (1, 1),\n                    padding='same',\n                    use_bias=False,\n                    strides=(1, 1),\n                    name='conv_pw_{}'.format(block_id))(x)\n    x = BatchNorm(axis=channel_axis, name='conv_pw_{}_bn'.format(block_id))(x, training=train_bn)\n    return KL.Activation(relu6, name='conv_pw_{}_relu'.format(block_id))(x)\n\n\ndef mobilenetv1_full(inputs, alpha=1.0, depth_multiplier=1, train_bn = False):\n    # Stage 1\n    x = _conv_block(inputs, 32, alpha, strides=(2, 2), block_id=0, train_bn=train_bn)              #Input Resolution: 224 x 224\n    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1, train_bn=train_bn)       #Input Resolution: 112 x 112\n\n    # Stage 2\n    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, strides=(2, 2), block_id=2, train_bn=train_bn)\n    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3, train_bn=train_bn)      #Input Resolution: 56 x 56\n\n    # Stage 3\n    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, strides=(2, 2), block_id=4, train_bn=train_bn)\n    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5, train_bn=train_bn)      #Input Resolution: 28 x 28\n\n    # Stage 4\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, strides=(2, 2), block_id=6, train_bn=train_bn)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7, train_bn=train_bn)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8, train_bn=train_bn)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9, train_bn=train_bn)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10, train_bn=train_bn)\n    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11, train_bn=train_bn)     #Input Resolution: 14 x 14\n\n    # Stage 5\n    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, strides=(2, 2), block_id=12, train_bn=train_bn)\n    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13, train_bn=train_bn)    #Input Resolution: 7x7\n\n    #cls\n    x = KL.GlobalAveragePooling2D(dim_ordering='default')(x)#globle_avg\n    x = KL.Dense(1000, name=\"output\")(x)\n    return\n\n\n\n############################################################\n#  MobileNetV2 Graph\n############################################################\n\ndef _bottleneck(inputs, filters, kernel, t, s, r=False, alpha=1.0, block_id=1, train_bn = False):\n    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n    tchannel = K.int_shape(inputs)[channel_axis] * t\n    filters = int(alpha * filters)\n\n    x = _conv_block(inputs, tchannel, alpha, (1, 1), (1, 1),block_id=block_id,train_bn=train_bn)\n\n    x = KL.DepthwiseConv2D(kernel,\n                    strides=(s, s),\n                    depth_multiplier=1,\n                    padding='same',\n                    name='conv_dw_{}'.format(block_id))(x)\n    x = BatchNorm(axis=channel_axis,name='conv_dw_{}_bn'.format(block_id))(x, training=train_bn)\n    x = KL.Activation(relu6, name='conv_dw_{}_relu'.format(block_id))(x)\n\n    x = KL.Conv2D(filters,\n                    (1, 1),\n                    strides=(1, 1),\n                    padding='same',\n                    name='conv_pw_{}'.format(block_id))(x)\n    x = BatchNorm(axis=channel_axis, name='conv_pw_{}_bn'.format(block_id))(x, training=train_bn)\n\n    if r:\n        x = KL.add([x, inputs], name='res{}'.format(block_id))\n    return x\n\n\ndef _inverted_residual_block(inputs, filters, kernel, t, strides, n, alpha, block_id, train_bn):\n    x = _bottleneck(inputs, filters, kernel, t, strides, False, alpha, block_id, train_bn)\n\n    for i in range(1, n):\n        block_id += 1\n        x = _bottleneck(x, filters, kernel, t, 1, True, alpha, block_id, train_bn)\n\n    return x\n\n\ndef mobilenetv2_full(inputs, out_dim, alpha = 1.0, train_bn = False):\n    x = _conv_block(inputs, 32, alpha, (3, 3), strides=(2, 2), block_id=0, train_bn=train_bn)                      # Input Res: 1\n    x = _inverted_residual_block(x, 16,  (3, 3), t=1, strides=1, n=1, alpha=1.0, block_id=1, train_bn=train_bn)\t# Input Res: 1/2\n    x = _inverted_residual_block(x, 24,  (3, 3), t=6, strides=2, n=2, alpha=1.0, block_id=2, train_bn=train_bn)\t# Input Res: 1/2\n    x = _inverted_residual_block(x, 32,  (3, 3), t=6, strides=2, n=3, alpha=1.0, block_id=4, train_bn=train_bn)\t# Input Res: 1/4\n    x = _inverted_residual_block(x, 64,  (3, 3), t=6, strides=2, n=4, alpha=1.0, block_id=7, train_bn=train_bn)\t# Input Res: 1/8\n    x = _inverted_residual_block(x, 96,  (3, 3), t=6, strides=1, n=3, alpha=1.0, block_id=11, train_bn=train_bn)\t# Input Res: 1/8\n    x = _inverted_residual_block(x, 160, (3, 3), t=6, strides=2, n=3, alpha=1.0, block_id=14, train_bn=train_bn)\t# Input Res: 1/16\n    x = _inverted_residual_block(x, 320, (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=17, train_bn=train_bn)\t# Input Res: 1/32\n    x = _conv_block(x, 1280, alpha, (1, 1), strides=(1, 1), block_id=18, train_bn=train_bn)                      # Input Res: 1/32\n    x = KL.GlobalAveragePooling2D(dim_ordering='default')(x)#globle_avg\n    x = KL.Dense(out_dim, name=\"output\")(x)\n    return  x\n######################################################################################################################\n#数据shape：64*64*1\n#64*64 ----> 32*32\n#32*32 ----> 16*16\n#16*16 ----> 8*8\n#8*8 ----> 4*4\n#4*4 ----> 2*2\n#最多降采样5次.(ps:2*2 ----> 1*1意义不大)\n\n\n#resnet design: 注意conv_block默认strides=(2, 2)\ndef resnet_mini_v1(input_image, stage5=False, train_bn=True):\n    # Stage 1\n    x = KL.ZeroPadding2D((3, 3))(input_image)\n    x = KL.Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=True)(x) #默认padding='valid', 改成'same'，是否可以省略ZeroPadding2D\n    x = BatchNorm(name='bn_conv1')(x, training=train_bn)\n    x = KL.Activation('relu')(x)\n    x = KL.MaxPooling2D((3, 3), strides=(2, 2), padding=\"same\")(x)\n    # Stage 2\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), train_bn=train_bn)\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', train_bn=train_bn)\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', train_bn=train_bn)\n    # Stage 3\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', train_bn=train_bn)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', train_bn=train_bn)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', train_bn=train_bn)\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', train_bn=train_bn)\n    # Stage 4\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', train_bn=train_bn)\n    for i in range(5):\n        x = identity_block(x, 3, [256, 256, 1024], stage=4, block=chr(98 + i), train_bn=train_bn)\n    # Stage 5\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', train_bn=train_bn)\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b', train_bn=train_bn)\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c', train_bn=train_bn)\n\n    #cls\n    x = KL.GlobalAveragePooling2D(dim_ordering='default')(x)#globle_avg\n    x = KL.Dense(1,activation=\"sigmoid\", name=\"output\")(x)\n    return x\n\n\n#mobilenetv1 design\n\n\n#mobilenetv2 design\n#pb模型大小:80KB, result: train_acc=0.885, val_acc =0.747\ndef mobilenetv2_mini_v1(inputs, train_bn = True):\n    x = _conv_block(inputs, 8, 1.0, (3, 3), strides=(2, 2), block_id=0, train_bn=train_bn)                      # Input Res: 1\n    x = _inverted_residual_block(x, 12,  (3, 3), t=6, strides=2, n=1, alpha=1.0, block_id=1, train_bn=train_bn)\t# Input Res: 1/2\n    x = _inverted_residual_block(x, 12,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=2, train_bn=train_bn)\t# Input Res: 1/2\n    x = _inverted_residual_block(x, 24,  (3, 3), t=6, strides=2, n=1, alpha=1.0, block_id=4, train_bn=train_bn)\t# Input Res: 1/4\n    x = _inverted_residual_block(x, 24,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=7, train_bn=train_bn)\t# Input Res: 1/8\n    x = _inverted_residual_block(x, 32,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=11, train_bn=train_bn)\t# Input Res: 1/8\n    x = KL.GlobalAveragePooling2D(dim_ordering='default')(x)#globle_avg\n    x = KL.Dense(1, activation=\"sigmoid\", name=\"cls_logits\")(x)\n    return x\n\n#pb模型大小:1.4MB, result: train_acc= 0.90, val_acc = 0.73\ndef mobilenetv2_mini_v2(inputs, train_bn = True):\n    x = _conv_block(inputs, 16, 1.0, (3, 3), strides=(2, 2), block_id=0, train_bn=train_bn)                      # Input Res: 1\n    x = _inverted_residual_block(x, 24,  (3, 3), t=6, strides=2, n=1, alpha=1.0, block_id=1, train_bn=train_bn)\t# Input Res: 1/2\n    x = _inverted_residual_block(x, 24,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=2, train_bn=train_bn)\t# Input Res: 1/2\n    x = _inverted_residual_block(x, 32,  (3, 3), t=6, strides=2, n=1, alpha=1.0, block_id=3, train_bn=train_bn)\t# Input Res: 1/4\n    x = _inverted_residual_block(x, 32,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=4, train_bn=train_bn)\t# Input Res: 1/8\n    x = _inverted_residual_block(x, 64,  (3, 3), t=6, strides=2, n=1, alpha=1.0, block_id=5, train_bn=train_bn)\t# Input Res: 1/8\n    x = _inverted_residual_block(x, 64,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=6, train_bn=train_bn)\n    x = KL.Flatten()(x) #extra layer\n    x = KL.Dense(64, name=\"fc\")(x) #extra layer\n    x = KL.Dropout(0.7)(x) #extra layer\n    #x = KL.GlobalAveragePooling2D(dim_ordering='default')(x)#globle_avg\n    x = KL.Dense(1, activation=\"sigmoid\", name=\"cls_logits\")(x)\n    return x\n\n#pb模型大小:?MB, result: val_acc =0.897\ndef mobilenetv2_mini_v3(inputs, train_bn = True):\n    x = _conv_block(inputs, 32, 1.0, (3, 3), strides=(2, 2), block_id=0, train_bn=train_bn)                      # Input Res: 1\n    x = _inverted_residual_block(x, 64,  (3, 3), t=6, strides=2, n=1, alpha=1.0, block_id=1, train_bn=train_bn)\t# Input Res: 1/2\n    x = _inverted_residual_block(x, 64,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=2, train_bn=train_bn)\t# Input Res: 1/2\n    x = _inverted_residual_block(x, 128,  (3, 3), t=6, strides=2, n=1, alpha=1.0, block_id=3, train_bn=train_bn)\t# Input Res: 1/4\n    x = _inverted_residual_block(x, 128,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=4, train_bn=train_bn)\t# Input Res: 1/8\n    x = _inverted_residual_block(x, 256,  (3, 3), t=6, strides=2, n=1, alpha=1.0, block_id=5, train_bn=train_bn)\t# Input Res: 1/8\n    x = _inverted_residual_block(x, 256,  (3, 3), t=6, strides=1, n=1, alpha=1.0, block_id=6, train_bn=train_bn)\n    x = KL.Flatten()(x) #extra layer\n    x = KL.Dense(512, name=\"fc\")(x) #extra layer\n    x = KL.Dropout(0.5)(x) #extra layer\n    #x = KL.GlobalAveragePooling2D(dim_ordering='default')(x)#globle_avg\n    x = KL.Dense(1, activation=\"sigmoid\", name=\"cls_logits\")(x)\n    return x\n\n\n\n#Keras有两种类型的模型，序贯模型（Sequential）和函数式模型（Model），函数式模型应用更为广泛，序贯模型是函数式模型的一种特殊情况\n#函数式模型接口\nfrom keras.models import Model\n\ninputs = KL.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNEL_SIZE))\n\npredictions = mobilenetv2_mini_v2(inputs, train_bn = True)\n\nmodel = Model(inputs=inputs, outputs=predictions)\n\n# training\nmodel.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n\ncallack_saver = ModelCheckpoint(\n            \"model.h5\"\n            , monitor='val_loss'\n            , verbose=0\n            , save_weights_only=True\n            , mode='auto'\n            , save_best_only=True\n        )\n\ntrain_history=model.fit(train_data,train_label,validation_data=(valid_data,valid_label),epochs=15,batch_size=BATCH_SIZE, callbacks=[callack_saver])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4c49438d53a4ac0650054bd77e6b9cf87b79d47"},"cell_type":"code","source":"def show_train_history(train_history, train, validation):\n    plt.plot(train_history.history[train])\n    plt.plot(train_history.history[validation])\n    plt.title('Train History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"275ee24fffaa7152e4ddb9f66b8bcbedd40a8617","_kg_hide-output":true},"cell_type":"code","source":"show_train_history(train_history, 'loss', 'val_loss')\nshow_train_history(train_history, 'acc', 'val_acc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f8a52c06c9081023bdd8c3ee5ae23d664d7f618"},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7145704147ed2d53c7305deab7a416d1aee3a7ce"},"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(valid_data)\npredicted_label=np.round(Y_pred,decimals=2)\npredicted_label=[1 if value>0.5 else 0 for value in predicted_label]\nconfusion_mtx = confusion_matrix(valid_label, predicted_label) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3454dc2c8b11a242df6803788f8eb103c85dd84a","scrolled":true},"cell_type":"code","source":"image_list=[]\ntest_data=[]\ncount = 0\nfor file in os.listdir(\"../input/test1/test1\"):\n    image_data=cv2.imread(os.path.join(\"../input/test1/test1\",file))\n    image_list.append(image_data)\n    \n    image_data=cv2.imread(os.path.join(\"../input/test1/test1\",file), cv2.IMREAD_GRAYSCALE)\n    image_data=cv2.resize(image_data,(IMAGE_SIZE,IMAGE_SIZE))\n    test_data.append(image_data/255)\n    count +=1\n    if count == 1:\n        break\n        \nfig, ax = plt.subplots(1,2,figsize=(10,5))\nax[0].imshow(image_list[0])\nax[1].imshow(test_data[0])   \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb0a278a74e37af1ea4b43eb28d91380ef0f3fb6"},"cell_type":"code","source":"test_data=np.array(test_data)\ntest_data=test_data.reshape((test_data.shape)[0],(test_data.shape)[1],(test_data.shape)[2],1)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75a431543fbcf6d70ee852d65cb5f5ea1e250457"},"cell_type":"code","source":"predicted_labels=model.predict(test_data)\npredicted_labels=np.round(predicted_labels,decimals=2)\nlabels=[1 if value>0.5 else 0 for value in predicted_labels]\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6367f55ffdbcca3b44c7fac8fe3612d82ecfdbe8"},"cell_type":"code","source":"layer_1 = K.function([model.layers[0].input], [model.layers[1].output])\nf1 = layer_1([test_data])[0]\nprint(f1.shape)\n#第一层卷积后的特征图展示，输出是（1,32,32,8）\nfor _ in range(8):\n        show_img = f1[:, :, :, _]\n        show_img.shape = [32, 32]\n        plt.subplot(1, 8, _ + 1)\n        plt.imshow(show_img, cmap='gray')\n        plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47f134d5b2aeea54385c579cf79516cae66b60d0"},"cell_type":"code","source":"layer_3 = K.function([model.layers[0].input], [model.layers[3].output])\nf1 = layer_3([test_data])[0]#只修改inpu_image\nprint(f1.shape)\nfor _ in range(16):\n        show_img = f1[:, :, :, _]\n        show_img.shape = [16, 16]\n        plt.subplot(2, 8, _ + 1)\n        plt.imshow(show_img, cmap='gray')\n        plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"846a0fb19154ac96ca92b7fd198784c936608dee"},"cell_type":"code","source":"layer_5 = K.function([model.layers[0].input], [model.layers[5].output])\nf1 = layer_5([test_data])[0]#只修改inpu_image\nprint(f1.shape)\nfor _ in range(32):\n        show_img = f1[:, :, :, _]\n        show_img.shape = [8, 8]\n        plt.subplot(4, 8, _ + 1)\n        plt.imshow(show_img, cmap='gray')\n        plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1e43a75827b851f338e7967e576cc18d8898e87"},"cell_type":"code","source":"layer_7 = K.function([model.layers[0].input], [model.layers[7].output])\nf1 = layer_7([test_data])[0]#只修改inpu_image\nprint(f1.shape)\nfor _ in range(64):\n        show_img = f1[:, :, :, _]\n        show_img.shape = [4, 4]\n        plt.subplot(8, 8, _ + 1)\n        plt.imshow(show_img, cmap='gray')\n        plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96215efad4ac864d7c61e065596dcf40a54cdf83"},"cell_type":"code","source":"test_data=[]\nid=[]\ncounter=0\nfor file in os.listdir(\"../input/test1/test1\"):\n    image_data=cv2.imread(os.path.join(\"../input/test1/test1\",file), cv2.IMREAD_GRAYSCALE)\n    try:\n        image_data=cv2.resize(image_data,(IMAGE_SIZE,IMAGE_SIZE))\n        test_data.append(image_data/255)\n        id.append((file.split(\".\"))[0])\n    except:\n        print (\"ek gaya\")\n    counter+=1\n    if counter%1000==0:\n        print (counter,\" image data retreived\")\n\ntest_data=np.array(test_data)\nprint (test_data.shape)\ntest_data=test_data.reshape((test_data.shape)[0],(test_data.shape)[1],(test_data.shape)[2],1)\ndataframe_output=pd.DataFrame({\"id\":id})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d1e188744e90d0cdad53469322375153e75e040"},"cell_type":"code","source":"predicted_labels=model.predict(test_data)\npredicted_labels=np.round(predicted_labels,decimals=2)\nlabels=[1 if value>0.5 else 0 for value in predicted_labels]\n\n#print(len(labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d072c5357840cca7b4846dd2786da2f751766b85"},"cell_type":"code","source":"dataframe_output[\"label\"]=labels\nprint(dataframe_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5be17382af31459070c165811e1e54f87675d18f"},"cell_type":"code","source":"dataframe_output.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}