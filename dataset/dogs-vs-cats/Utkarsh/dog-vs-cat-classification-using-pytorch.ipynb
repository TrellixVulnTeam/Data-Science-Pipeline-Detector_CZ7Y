{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cf897a2116c4eae7bb3dafeeb4405075e848038"},"cell_type":"code","source":"from os import walk\nfor (dirpath, dirnames, filenames) in walk(\"../input/dogs-vs-cats\"):\n    print(\"Directory path: \", dirpath)\n    print(\"Folder name: \", dirnames)\n    print(\"File name: \", filenames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6b13bf258e80d5829434fb23b8db40ca08054d8"},"cell_type":"code","source":"from os import walk\nfor (dirpath, dirnames, filenames) in walk(\"../input/dogs-vs-cats-for-pytorch\"):\n    print(\"Directory path: \", dirpath)\n    print(\"Folder name: \", dirnames)\n    print(\"File name: \", filenames)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Implementation"},{"metadata":{"trusted":true,"_uuid":"cc0c921c2188b10d3c07d46d5f2d75d25f14f16d"},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import datasets ,models,transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim import lr_scheduler\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8402f92bc655b7aead5de0798f5e37a15dd9dd24"},"cell_type":"code","source":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a603f2e3b87e6987245b06b95076f2177adbc27"},"cell_type":"code","source":"PATH=Path('../input/dogs-vs-cats-for-pytorch/cat_dog_data/Cat_Dog_data')\nPATH1=Path('../input/dogs-vs-cats/test1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"456bf7d2535f3c45d3cf22c72077367962fceda2"},"cell_type":"code","source":"TRAIN =Path(PATH/'train')\nVALID = Path(PATH/'test')\nTEST=Path(PATH1)\nprint(TRAIN)\nprint(VALID)\nprint(TEST)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3302f270638ea786d60e5a825efe55dd7ff0774a"},"cell_type":"markdown","source":"No of dog images for training"},{"metadata":{"trusted":true,"_uuid":"8b150cb4173e9b1b67416713d63158f463e57f43"},"cell_type":"code","source":"ls ../input/dogs-vs-cats-for-pytorch/cat_dog_data/Cat_Dog_data/train/dog -1 | wc -l","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08b576f07f8f7cf37cf949e3af11db6c6f2c4d7c"},"cell_type":"markdown","source":"No of Cat images for training"},{"metadata":{"trusted":true,"_uuid":"7de8b754963a1cfbc3695ab12630afd7abf7e0bd"},"cell_type":"code","source":"ls ../input/dogs-vs-cats-for-pytorch/cat_dog_data/Cat_Dog_data/train/cat -1 | wc -l","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"033975937d8d283b90bdf42d42a867b6930cceb8"},"cell_type":"markdown","source":"No of Dog images for validation"},{"metadata":{"trusted":true,"_uuid":"96ba04a79812804f076c0189aaf830b97deb588b"},"cell_type":"code","source":"ls ../input/dogs-vs-cats-for-pytorch/cat_dog_data/Cat_Dog_data/test/dog -1 | wc -l","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d82c1144b6dc797963c2865da07ea5d7ac21da49"},"cell_type":"markdown","source":"No of Cat images for validation"},{"metadata":{"trusted":true,"_uuid":"4a6fd56718fc65612eb5a87afd24a55346c45ec8"},"cell_type":"code","source":"ls ../input/dogs-vs-cats-for-pytorch/cat_dog_data/Cat_Dog_data/test/cat -1 | wc -l","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbb6b9a84e23884a5187b268cb2546ec7db2d03b"},"cell_type":"markdown","source":"No of images to predict"},{"metadata":{"trusted":true,"_uuid":"5bc776186c5fea776e1283456bfa568bf72e81a2"},"cell_type":"code","source":"ls ../input/dogs-vs-cats/test1/test1 -1 | wc -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f460717dbfd51d925e7e5ee348cb74334aa0301c"},"cell_type":"code","source":"# number of subprocesses to use for data loading\nnum_workers = 0\n# how many samples per batch to load\nbatch_size = 32\n\n# convert data to a normalized torch.FloatTensor\ntrain_transforms = transforms.Compose([transforms.Resize((224,224)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\nvalid_transforms = transforms.Compose([transforms.Resize((224,224)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n# choose the training and test datasets\n\ntest_transforms = transforms.Compose([transforms.Resize((224,224)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n# choose the training and test datasets\ntrain_data = datasets.ImageFolder(TRAIN, transform=train_transforms)\nvalid_data=datasets.ImageFolder(VALID,transform=valid_transforms)\ntest_data = datasets.ImageFolder(PATH1, transform=test_transforms)\n\n# obtain training indices that will be used for validation\n#num_train = len(train_data)\n#indices = list(range(num_train))\n#np.random.shuffle(indices)\n#split = int(np.floor(valid_size * num_train))\n#print(\"Split Index\",split)\n#train_idx, valid_idx = indices[split:], indices[:split]\n# define samplers for obtaining training and validation batches\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0cb2a3741f38e633686e711996476324c361bca"},"cell_type":"code","source":"print(train_data.class_to_idx)\nprint(valid_data.class_to_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b747ff806f4e80734cea0daad42918ac1cb00906"},"cell_type":"code","source":"# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,  num_workers=num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b5b83c42b058a9c46d395723ea014791f1d81cb"},"cell_type":"code","source":"images,labels=next(iter(train_loader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4083b460a0eeb10ae81e6e465b59ee0202e2d124"},"cell_type":"code","source":"images.shape,labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec4b972aeedfeca3f931963c0529948bb08b5c62"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nclasses = ['cat','dog']\nmean , std = torch.tensor([0.485, 0.456, 0.406]),torch.tensor([0.229, 0.224, 0.225])\n\n\ndef denormalize(image):\n  image = transforms.Normalize(-mean/std,1/std)(image) #denormalize\n  image = image.permute(1,2,0) #Changing from 3x224x224 to 224x224x3\n  image = torch.clamp(image,0,1)\n  return image\n\n# helper function to un-normalize and display an image\ndef imshow(img):\n    img = denormalize(img) \n    plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a798a576675154c274dba5173db2505396ca9f51"},"cell_type":"code","source":"# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 8))\n# display 20 images\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    ax.set_title(\"{} \".format( classes[labels[idx]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31c1d36f71044ff88382415cf030c8a29c1d47d1"},"cell_type":"markdown","source":"rgb_img = np.squeeze(images[3])\nchannels = ['red channel', 'green channel', 'blue channel']\n\nfig = plt.figure(figsize = (36, 36)) \nfor idx in np.arange(rgb_img.shape[0]):\n    ax = fig.add_subplot(1, 3, idx + 1)\n    img = rgb_img[idx]\n    ax.imshow(img, cmap='gray')\n    ax.set_title(channels[idx])\n    width, height = img.shape\n    thresh = img.max()/2.5\n    for x in range(width):\n        for y in range(height):\n            val = round(img[x][y],2) if img[x][y] !=0 else 0\n            ax.annotate(str(val), xy=(y,x),\n                    horizontalalignment='center',\n                    verticalalignment='center', size=8,\n                    color='white' if img[x][y]<thresh else 'black')"},{"metadata":{"trusted":true,"_uuid":"af3e9af0992a7228e3c4744fe4a95e9898848b33"},"cell_type":"markdown","source":"![](http://)Load the model VGG -19"},{"metadata":{"trusted":true,"_uuid":"4a05bc1f8d54374fbd914011a2f8e0fc85db859d"},"cell_type":"code","source":"vgg_19=models.vgg19_bn(pretrained=True)\nvgg_19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59d8071adab43cafe88ab43b9cbfd278030b6f4e"},"cell_type":"code","source":"# Freeze parameters so we don't backprop through them\nfor param in vgg_19.parameters():\n    param.requires_grad = False\n\nfrom collections import OrderedDict\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(25088, 1028)),\n                          ('relu1', nn.ReLU()),\n                          ('dropout1',nn.Dropout(0.5)),\n                          ('fc2', nn.Linear(1028, 512)),\n                          ('relu2', nn.ReLU()), \n                          ('dropout2',nn.Dropout(0.5)),\n                          ('fc3', nn.Linear(512, 2)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nvgg_19.classifier = classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fe13f9fdc397b4af13443e25c9d7f6f251a8d4d"},"cell_type":"code","source":"vgg_19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30ef92168a98bdb63e7e41ca1214635b8649fe50"},"cell_type":"code","source":"criterion = nn.NLLLoss()\noptimizer=torch.optim.Adam(vgg_19.parameters(),lr=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1daa951c7b757be404d32caa248156d6be907d60"},"cell_type":"code","source":"# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,  num_workers=num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ccc71267ca99ab5895408a89cba964729063233"},"cell_type":"code","source":"if train_on_gpu:\n    vgg_19.cuda()\n# number of epochs to train the model\nn_epochs = 3\n\nvalid_loss_min = np.Inf # track change in validation loss\n\n#train_losses,valid_losses=[],[]\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    vgg_19.train()\n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg_19(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    vgg_19.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg_19(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    #train_losses.append(train_loss/len(train_loader.dataset))\n    #valid_losses.append(valid_loss.item()/len(valid_loader.dataset)\n    train_loss = train_loss/len(train_loader.dataset)\n    valid_loss = valid_loss/len(valid_loader.dataset)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(vgg_19.state_dict(), 'model_vgg19.pth')\n        valid_loss_min = valid_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42f7742549adc8fb0eb34f558ea06d481707182f"},"cell_type":"code","source":"valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\nbatch_size=4\n# track test loss\ntest_loss = 0.0\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\nvgg_19.eval()\n# iterate over valid data\nfor data, target in valid_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = vgg_19(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(batch_size):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss/len(valid_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb6777caef4badba8e3c45b6de56afca5c62cd1a"},"cell_type":"code","source":"batch_size=32\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\nvgg_19.cpu()\n# obtain one batch of test images\ndataiter = iter(valid_loader)\nimages, labels = dataiter.next()\n\n# move model inputs to cuda, if GPU available\n#if train_on_gpu:\n    #images = images.cuda()\n\n# get sample outputs\noutput = vgg_19(images)\n# convert output probabilities to predicted class\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"012bfd6109f073f2656528fba8fecfb17478f68b"},"cell_type":"code","source":"print(\"The state dict keys: \\n\\n\", vgg_19.state_dict().keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f24ddf9aa5ff2a0be93dbbdf3ab2366e0df569c"},"cell_type":"code","source":"torch.save(vgg_19.state_dict(), 'checkpoint_97.pth')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f457e4ae1c1f63969a4c169d417d703af7f181e"},"cell_type":"markdown","source":"vgg_19.load_state_dict(state_dict)"},{"metadata":{"trusted":true,"_uuid":"4135612d5f8f2fa9f3d869a6d027e37dc2a12be2"},"cell_type":"code","source":"# Criteria NLLLoss which is recommended with Softmax final layer\ncriterion = nn.NLLLoss()\n# Observe that all parameters are being optimized\noptimizer = torch.optim.Adam(vgg_19.classifier.parameters(), lr=0.001)\n# Decay LR by a factor of 0.1 every 3 epochs\nscheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n# Number of epochs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb5d786d934781f1868115a1e812e4dc3f6ab34c"},"cell_type":"code","source":"if train_on_gpu:\n    vgg_19.cuda()\n# number of epochs to train the model\nn_epochs = 2\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    vgg_19.train()\n    \n    for data, target in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        scheduler.step()\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg_19(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    vgg_19.eval()\n    for data, target in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg_19(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average losses\n    train_loss = train_loss/len(train_loader.dataset)\n    valid_loss = valid_loss/len(valid_loader.dataset)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(vgg_19.state_dict(), 'model_vgg19_2.pth')\n        valid_loss_min = valid_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d59caceb43c56bee3afb8d96e56438ed9a83137a"},"cell_type":"code","source":"batch_size=4\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size,  num_workers=num_workers,shuffle=True)\n# track test loss\ntest_loss = 0.0\nclass_correct = list(0. for i in range(2))\nclass_total = list(0. for i in range(2))\n\nvgg_19.eval()\n# iterate over test data\nfor data, target in valid_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = vgg_19(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(batch_size):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\ntest_loss = test_loss/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4ed63fd4053efe5ef4110ad05cd913beb1dcdde"},"cell_type":"markdown","source":"References\n<br>\n[Notebook](https://www.kaggle.com/pocahontas1010/cats-dogs-classifier-with-pytorch/notebook)\n<br>\n[Sorting data into subdirectories](https://www.kaggle.com/c/dog-breed-identification/discussion/48908)\n<br>\n[Model evaluation](https://www.kaggle.com/carloalbertobarbano/vgg16-transfer-learning-pytorch)\n<br>\n[Pytorch Models](https://pytorch.org/docs/stable/torchvision/models.html[Pytorch Models])\n<br>\n[Pytorch Augmetation](https://colab.research.google.com/drive/109vu3F1LTzD1gdVV6cho9fKGx7lzbFll)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}