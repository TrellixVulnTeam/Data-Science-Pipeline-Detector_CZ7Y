{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Лабораторная работа 1. Нейронные сети.\n\nРезультатом лабораторной работы является отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: нам — меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n\nМы уверены, что выполнение лабораторных работ занимает значительное время, поэтому не рекомендуем оставлять их на последний вечер перед сдачей.\n\n\n**ВНИМАНИЕ:** В рамках данной лабораторной работы допускается использование PyTorch вместо Keras","metadata":{"id":"Ivr_hqTuwEQu"}},{"cell_type":"markdown","source":"# Часть 1. Свёрточные сети\n\nЗдесь вам предстоит построить и обучить свою первую свёрточную сеть для классификации изображений на данных CIFAR10. ","metadata":{"id":"P36AMza-wEQx"}},{"cell_type":"markdown","source":"## Данные\n\nCIFAR10\n* 60000 RGB изображений размером 32x32x3\n* 10 классов: самолёты, собаки, рыбы и т.п.\n\n<img src=\"https://www.samyzaf.com/ML/cifar10/cifar1.jpg\" style=\"width:60%\">","metadata":{"id":"y1_jJqMpwEQy"}},{"cell_type":"markdown","source":"Загрузите данные, разделите их на обучающую и тестовую выборки. Размер тестовой выборки должен быть 10^4.","metadata":{"id":"WC0ISLJ_wEQz"}},{"cell_type":"code","source":"from torch import nn\nimport torch","metadata":{"id":"h4qgRKuQdyUU","execution":{"iopub.status.busy":"2021-10-31T21:46:22.548555Z","iopub.execute_input":"2021-10-31T21:46:22.548918Z","iopub.status.idle":"2021-10-31T21:46:23.917759Z","shell.execute_reply.started":"2021-10-31T21:46:22.548846Z","shell.execute_reply":"2021-10-31T21:46:23.91701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.datasets import cifar10\nfrom sklearn.model_selection import train_test_split\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10**4, random_state=42)\n\nclass_names = np.array(['airplane','automobile ','bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck'])\n\nprint(X_train.shape, y_train.shape)","metadata":{"id":"TYLDBnlxwEQ0","outputId":"98b3dd0a-d591-4865-bc18-7e3a18e1060f","execution":{"iopub.status.busy":"2021-10-31T21:46:23.920133Z","iopub.execute_input":"2021-10-31T21:46:23.920542Z","iopub.status.idle":"2021-10-31T21:46:37.4967Z","shell.execute_reply.started":"2021-10-31T21:46:23.9205Z","shell.execute_reply":"2021-10-31T21:46:37.495954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Датасет также доступен по ссылке [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). В PyTorch нужно использовать [torchvision.datasets](https://pytorch.org/docs/stable/torchvision/datasets.html) и разбить его на обучающую, валидационную и тестовую выборки.\n\n**Замечание:** По умолчанию данные в PyTorch разбиты на обучающую и тестовую выборки. Для того что бы разбить обучающую выборку на обучающую и валидационную, можно воспользоваться [torch.utils.data.sampler.SubsetRandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.SubsetRandomSampler).","metadata":{"id":"aZ0b7sjYwEQ0"}},{"cell_type":"markdown","source":"Прежде, чем приступать к основной работе, стоит убедиться, что загруженно именно то, что требовалось:","metadata":{"id":"qh2vQzR0wEQ1"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=[12,10])\nfor i in range(12):\n    plt.subplot(3, 4, i + 1)\n    plt.xlabel(class_names[y_train[i, 0]])\n    plt.imshow(X_train[i])","metadata":{"id":"MltYHVXWwEQ1","outputId":"3cf265cd-a72b-483f-c8d9-1ea32307eb68","execution":{"iopub.status.busy":"2021-10-31T21:46:37.49796Z","iopub.execute_input":"2021-10-31T21:46:37.498229Z","iopub.status.idle":"2021-10-31T21:46:39.103394Z","shell.execute_reply.started":"2021-10-31T21:46:37.498191Z","shell.execute_reply":"2021-10-31T21:46:39.102615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка данных\n\nСейчас каждый пиксель изображения закодирован тройкой чисел (RGB) __от 0 до 255__. Однако лучше себя показывает подход, где значения входов нейросети распределены недалеко от 0.\n\nДавайте приведём все данные в диапазон __`[0, 1]`__ — просто разделим на соответствующий коэффициент:","metadata":{"id":"ErAeLWe4wEQ2"}},{"cell_type":"code","source":"X_train = (X_train / 255).astype('float32')\nX_val =  (X_val / 255).astype('float32')\nX_test = (X_test / 255).astype('float32')","metadata":{"id":"qG9k4GcTwEQ2","execution":{"iopub.status.busy":"2021-10-31T21:46:39.10609Z","iopub.execute_input":"2021-10-31T21:46:39.106637Z","iopub.status.idle":"2021-10-31T21:46:39.850556Z","shell.execute_reply.started":"2021-10-31T21:46:39.106593Z","shell.execute_reply":"2021-10-31T21:46:39.849829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Исполните код ниже для проверки, что все выполнено корректно.","metadata":{"id":"Z0sntzfBwEQ2"}},{"cell_type":"code","source":"assert np.shape(X_train) == (40000, 32, 32, 3), \"data shape should not change\"\nassert 0.9 <= max(map(np.max, (X_train, X_val, X_test))) <= 1.05\nassert 0.0 <= min(map(np.min, (X_train, X_val, X_test))) <= 0.1\nassert len(np.unique(X_test / 255.)) > 10, \"make sure you casted data to float type\"","metadata":{"id":"yPNorAzrwEQ2","execution":{"iopub.status.busy":"2021-10-31T21:46:39.8517Z","iopub.execute_input":"2021-10-31T21:46:39.851989Z","iopub.status.idle":"2021-10-31T21:46:41.66611Z","shell.execute_reply.started":"2021-10-31T21:46:39.851956Z","shell.execute_reply":"2021-10-31T21:46:41.665344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Архитектура сети\n\nДля начала реализуйте простую нейросеть:\n1. принимает на вход картинки размера 32 x 32 x 3;\n2. вытягивает их в вектор (`keras.layers.Flatten`, `torch.nn.Flatten`);\n3. пропускает через 1 или 2 полносвязных слоя;\n4. выходной слой отдает вероятности принадлежности к каждому из 10 классов.","metadata":{"id":"sCV4agBvwEQ3"}},{"cell_type":"markdown","source":"Создайте полносвязную сеть:","metadata":{"id":"rfOfGqmWwEQ4"}},{"cell_type":"code","source":"simple_dense_model = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(32*32*3, 2048),\n    nn.ReLU(),\n    nn.Linear(2048, 1024),\n    nn.ReLU(), \n    nn.Linear(1024, 10), \n    nn.Softmax(dim=1)\n    )","metadata":{"id":"uupxIcdYwEQ4","execution":{"iopub.status.busy":"2021-10-31T21:46:41.667564Z","iopub.execute_input":"2021-10-31T21:46:41.667836Z","iopub.status.idle":"2021-10-31T21:46:41.746683Z","shell.execute_reply.started":"2021-10-31T21:46:41.667802Z","shell.execute_reply":"2021-10-31T21:46:41.745893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy_pred = simple_dense_model(torch.from_numpy(X_train[:20])).detach().numpy()\nassert dummy_pred.shape == (20, 10)\nassert np.allclose(dummy_pred.sum(-1), 1)\n\nprint(\"Успех!\")","metadata":{"id":"-D8Fuy9KwEQ4","outputId":"d831f2b6-3094-423b-e940-5b7bb43b0d22","execution":{"iopub.status.busy":"2021-10-31T21:46:41.747877Z","iopub.execute_input":"2021-10-31T21:46:41.748147Z","iopub.status.idle":"2021-10-31T21:46:41.857186Z","shell.execute_reply.started":"2021-10-31T21:46:41.748111Z","shell.execute_reply":"2021-10-31T21:46:41.856212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Создание копии модели:","metadata":{}},{"cell_type":"markdown","source":"## Обучение сети\n\n**Задание 1.1 (1.5 балла).** Будем минимизировать многоклассовую кроссэнтропию с помощью __sgd__. Вам нужно получить сеть, которая достигнет __не менее 45%__ __accuracy__ на тестовых данных.\n\n__Важно:__ поскольку в y_train лежат номера классов, Керасу нужно либо указать sparse функции потерь и метрики оценки качества классификации (`sparse_categorical_crossentropy` и `sparse_categorical_accuracy`), либо конвертировать метки в one-hot формат. PyTorch, напротив, умеет работать с меткаим классов (`torch.nn.CrossEntropyLoss`)\n\n### Полезные советы (keras)\n* `model.compile` позволяет указать, какие метрики вы хотите вычислять.\n* В `model.fit` можно передать валидационную выборку (`validation_data=[X_val, y_val]`), для отслеживания прогресса на ней. Также рекомендуем сохранять результаты в [tensorboard](https://keras.io/callbacks/#tensorboard).\n* По умолчанию сеть учится 1 эпоху. Совсем не факт, что вам этого хватит. Число эпох можно настроить в методе `fit` (`epochs`).\n* Ещё у Кераса есть много [полезных callback-ов](https://keras.io/callbacks/), которые можно попробовать. Например, автоматическая остановка или подбор скорости обучения.\n\n### PyTorch\nВ PyTorch есть модуль [tensorboard](https://pytorch.org/docs/stable/tensorboard.html),  который по сути использует готоывй (установленный вами) TensorBoard, так что в вопросе визуализации PyTorch несколько проигрывает Tensorflow, но, тем не менее, благодаря данному модулю все возможности Tensorboard досутпны и в PyTorch","metadata":{"id":"ipAJV4thwEQ5"}},{"cell_type":"code","source":"import torchvision\nfrom torchvision.transforms import ToTensor\n\n\ndataset = torchvision.datasets.CIFAR10('cifar10/train/', download=True, transform=ToTensor(), train=True)\ntest_data = torchvision.datasets.CIFAR10('cifar10/test', download=True, transform=ToTensor(), train=False)\n\ntrain_data, val_data = train_test_split(dataset, test_size=5000, random_state=42)\n\ntrain_loader = torch.utils.data.DataLoader(train_data,\n                                          batch_size=64,\n                                          shuffle=True,\n                                          num_workers=2)\n\nval_loader = torch.utils.data.DataLoader(val_data,\n                                          batch_size=64,\n                                          shuffle=False,\n                                          num_workers=2)\n\ntest_loader = torch.utils.data.DataLoader(test_data,\n                                          batch_size=64,\n                                          shuffle=False,\n                                          num_workers=2)","metadata":{"id":"L7JINzAopjxG","outputId":"868dbd96-299e-423a-a7fc-e966fe64f03c","execution":{"iopub.status.busy":"2021-10-31T21:46:41.858512Z","iopub.execute_input":"2021-10-31T21:46:41.858838Z","iopub.status.idle":"2021-10-31T21:47:06.222577Z","shell.execute_reply.started":"2021-10-31T21:46:41.8588Z","shell.execute_reply":"2021-10-31T21:47:06.221618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = torch.Tensor(10000, 3, 32, 32)\ny_test = []\nfor i, data in enumerate(test_data):\n    image, label = data\n    X_test[i,:,:,:] = image\n    y_test.append(label)\ny_test = torch.Tensor(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T21:47:06.223956Z","iopub.execute_input":"2021-10-31T21:47:06.224207Z","iopub.status.idle":"2021-10-31T21:47:07.401338Z","shell.execute_reply.started":"2021-10-31T21:47:06.224175Z","shell.execute_reply":"2021-10-31T21:47:07.400573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning.core.lightning import LightningModule\nfrom sklearn.metrics import accuracy_score\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom torch.optim import SGD, Adam\nfrom torch.utils.data import DataLoader\nfrom copy import deepcopy","metadata":{"id":"3nhJWefkERHA","execution":{"iopub.status.busy":"2021-10-31T21:47:07.404521Z","iopub.execute_input":"2021-10-31T21:47:07.405189Z","iopub.status.idle":"2021-10-31T21:47:08.804643Z","shell.execute_reply.started":"2021-10-31T21:47:07.405155Z","shell.execute_reply":"2021-10-31T21:47:08.803584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CifarModel(LightningModule):\n    def __init__(self, model, get_optimizer = None):\n        super().__init__()\n        self.model = model\n        self.loss = nn.CrossEntropyLoss()\n        if get_optimizer:\n            self.optimizer = get_optimizer(self.parameters())\n        else:\n            self.optimizer = SGD(self.parameters(), lr=1e-2, momentum=0.9)\n\n\n    def forward(self, x):\n        return self.model.forward(x)\n      \n    def configure_optimizers(self):\n        return self.optimizer\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.forward(x)\n        loss = self.loss(logits, y)\n        \n        preds = torch.argmax(logits, dim=1)\n        acc = accuracy_score(y.cpu(), preds.cpu())\n        \n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n      \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.forward(x)\n        loss = self.loss(logits, y)\n        \n        preds = torch.argmax(logits, dim=1)\n        acc = accuracy_score(y.cpu(), preds.cpu())\n        \n        self.log('val_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.forward(x)\n        loss = self.loss(logits, y)\n        preds = torch.argmax(logits, dim=1)\n        acc = accuracy_score(y.cpu(), preds.cpu())\n        \n        self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    \n    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = None):\n        x,y = batch\n        return self(x).argmax(axis=1)","metadata":{"id":"zfrUkoDw6LoL","execution":{"iopub.status.busy":"2021-10-31T21:47:08.806437Z","iopub.execute_input":"2021-10-31T21:47:08.806984Z","iopub.status.idle":"2021-10-31T21:47:08.829254Z","shell.execute_reply.started":"2021-10-31T21:47:08.806943Z","shell.execute_reply":"2021-10-31T21:47:08.828642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = TensorBoardLogger(\"logs/task1\")\ndense_model = CifarModel(deepcopy(simple_dense_model))\ntrainer = Trainer(logger=logger, gpus=1, max_epochs=25)\ntrainer.fit(dense_model, train_loader, val_loader)","metadata":{"id":"_B4AVsnUwEQ5","outputId":"ed8b330d-7bf0-4804-fe04-3ecb46882571","execution":{"iopub.status.busy":"2021-10-31T21:47:08.830925Z","iopub.execute_input":"2021-10-31T21:47:08.831511Z","iopub.status.idle":"2021-10-31T21:51:15.181349Z","shell.execute_reply.started":"2021-10-31T21:47:08.831475Z","shell.execute_reply":"2021-10-31T21:51:15.180477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"А теперь можно проверить качество вашей сети, выполнив код ниже:","metadata":{"id":"l4bEz58wwEQ6"}},{"cell_type":"code","source":"y_pred = torch.cat(trainer.predict(dense_model, test_loader, return_predictions=True), dim=0).cpu()\ntest_acc = accuracy_score(y_test, y_pred)\nprint(\"\\n Test_acc =\", test_acc)\nassert test_acc > 0.45, \"Not good enough. Back to the drawing board :)\"\nprint(\" Not bad!\")","metadata":{"id":"CUBsELyYwEQ6","outputId":"54a00b97-0115-4947-8c21-7df69b5a9632","execution":{"iopub.status.busy":"2021-10-31T21:51:15.183297Z","iopub.execute_input":"2021-10-31T21:51:15.183584Z","iopub.status.idle":"2021-10-31T21:51:16.733011Z","shell.execute_reply.started":"2021-10-31T21:51:15.183548Z","shell.execute_reply":"2021-10-31T21:51:16.732049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Примечание:**\n\nЯчейка ниже запускает Tensorboard на кагле.","metadata":{}},{"cell_type":"code","source":"# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\nfrom urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n    \n    # Launch TensorBoard\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # Install ngrok\n    if not isfile('./ngrok'):\n        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n        download_and_unzip(ngrok_url)\n        chmod('./ngrok', 0o755)\n\n    # Create ngrok tunnel and print its public URL\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n        time.sleep(1) # Waiting for ngrok to start the tunnel\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\n\ndef download_and_unzip(url, extract_to='.'):\n    http_response = urlopen(url)\n    zipfile = ZipFile(BytesIO(http_response.read()))\n    zipfile.extractall(path=extract_to)\n\n\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\n\ntb_process, ngrok_process = launch_tensorboard()","metadata":{"id":"ZBiM2kcn-qQU","execution":{"iopub.status.busy":"2021-10-31T21:51:16.735043Z","iopub.execute_input":"2021-10-31T21:51:16.73534Z","iopub.status.idle":"2021-10-31T21:51:19.670149Z","shell.execute_reply.started":"2021-10-31T21:51:16.735302Z","shell.execute_reply":"2021-10-31T21:51:19.668541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %load_ext tensorboard\n# %tensorboard --logdir logs","metadata":{"id":"P4twIV0v5zHe","outputId":"6dba5f83-d443-4694-85e2-8f75b93298ad","execution":{"iopub.status.busy":"2021-10-31T21:51:19.67401Z","iopub.execute_input":"2021-10-31T21:51:19.675271Z","iopub.status.idle":"2021-10-31T21:51:19.684321Z","shell.execute_reply.started":"2021-10-31T21:51:19.675114Z","shell.execute_reply":"2021-10-31T21:51:19.683629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Карманная сверточная сеть\n\n**Задание 1.2 (1.5 балла).** Реализуйте небольшую свёрточную сеть. Совсем небольшую:\n1. Входной слой\n2. Свёртка 3x3 с 10 фильтрами\n3. Нелинейность на ваш вкус\n4. Max-pooling 2x2\n5. Вытягиваем оставшееся в вектор (Flatten)\n6. Полносвязный слой на 100 нейронов\n7. Нелинейность на ваш вкус\n8. Выходной полносвязный слой с softmax\n\nОбучите её так же, как и предыдущую сеть. Если всё хорошо, у вас получится accuracy не меньше __50%__.","metadata":{"id":"U--0i6bkwEQ6"}},{"cell_type":"code","source":"simple_convolutional_model = nn.Sequential(\n    nn.Conv2d(3, 10, 3),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Flatten(),\n    nn.Linear(2250, 100),\n    nn.ReLU(), \n    nn.Linear(100, 10), \n    nn.Softmax(dim=1)\n    )","metadata":{"id":"KjFdDdUqwEQ6","execution":{"iopub.status.busy":"2021-10-31T21:51:19.685781Z","iopub.execute_input":"2021-10-31T21:51:19.687943Z","iopub.status.idle":"2021-10-31T21:51:19.71051Z","shell.execute_reply.started":"2021-10-31T21:51:19.687898Z","shell.execute_reply":"2021-10-31T21:51:19.709786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = TensorBoardLogger(\"logs/task2\")\nconv_model = CifarModel(deepcopy(simple_convolutional_model))\ntrainer = Trainer(logger=logger, gpus=1, max_epochs=20)\ntrainer.fit(conv_model, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T21:51:19.713507Z","iopub.execute_input":"2021-10-31T21:51:19.714249Z","iopub.status.idle":"2021-10-31T21:54:02.695585Z","shell.execute_reply.started":"2021-10-31T21:51:19.714209Z","shell.execute_reply":"2021-10-31T21:54:02.694834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Давайте посмотрим, смогла ли карманная сверточная сеть побить заданный порог по качеству:","metadata":{"id":"P49EFt_EwEQ7"}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_pred = conv_model(X_test).argmax(axis=1).cpu()\ntest_acc = accuracy_score(y_test, y_pred)\nprint(\"\\n Test_acc =\", test_acc)\nassert test_acc > 0.50, \"Not good enough. Back to the drawing board :)\"\nprint(\" Not bad!\")","metadata":{"id":"fpdsZQ6wwEQ7","execution":{"iopub.status.busy":"2021-10-31T21:54:02.697368Z","iopub.execute_input":"2021-10-31T21:54:02.697799Z","iopub.status.idle":"2021-10-31T21:54:04.211103Z","shell.execute_reply.started":"2021-10-31T21:54:02.697762Z","shell.execute_reply":"2021-10-31T21:54:04.210231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Учимся учить\n\nА теперь научимся сравнивать кривые обучения моделей — зависимости значения accuracy от количества итераций. \n\nВам потребуется реализовать _экспериментальный стенд_ — вспомогательный код, в который вы сможете подать несколько архитектур и методов обучения, чтобы он их обучил и вывел графики кривых обучения. Это можно сделать с помощью `keras.callbacks` — `TensorBoard` или `History`.\n\nБудьте морально готовы, что на обучение уйдёт _много времени_. Даже если вы ограничитесь 10 эпохами. Пока идёт обучение, вы можете переключиться на другие задания или заняться чем-нибудь приятным: поспать, например.","metadata":{"id":"U4Q4q56CwEQ7"}},{"cell_type":"code","source":"def train_model_experiment(model, task_name, train_loader, val_loader, test_loader, early_stopping = None, max_epoch=25):\n    logger = TensorBoardLogger(\"logs/\" + task_name)\n    if early_stopping:\n        trainer = Trainer(logger=logger, gpus=1, max_epochs=max_epoch, callbacks=[early_stopping])\n    else:\n        trainer = Trainer(logger=logger, gpus=1, max_epochs=max_epoch)\n    trainer.fit(model, train_loader, val_loader)\n    \n    y_pred = torch.cat(trainer.predict(model, test_loader, return_predictions=True), dim=0).cpu()\n    test_acc = accuracy_score(y_test, y_pred)\n    return test_acc","metadata":{"execution":{"iopub.status.busy":"2021-10-31T21:54:04.212871Z","iopub.execute_input":"2021-10-31T21:54:04.213496Z","iopub.status.idle":"2021-10-31T21:54:04.221815Z","shell.execute_reply.started":"2021-10-31T21:54:04.213452Z","shell.execute_reply":"2021-10-31T21:54:04.221068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Задание 1.3 (1 балл).** Попробуйте использовать различные методы оптимизации (sgd, momentum, adam) с параметрами по умолчанию. Какой из методов работает лучше?","metadata":{"id":"_qwP70M_wEQ7"}},{"cell_type":"code","source":"model_sgd = CifarModel(deepcopy(simple_convolutional_model), lambda model_params: SGD(model_params, lr=2e-3))\nsgd_acc = train_model_experiment(model_sgd, 'task3_sgd', train_loader, val_loader, test_loader)\nsgd_acc","metadata":{"id":"TfywQKcuwEQ8","execution":{"iopub.status.busy":"2021-10-31T21:54:04.22332Z","iopub.execute_input":"2021-10-31T21:54:04.22388Z","iopub.status.idle":"2021-10-31T21:58:27.32619Z","shell.execute_reply.started":"2021-10-31T21:54:04.223839Z","shell.execute_reply":"2021-10-31T21:58:27.325425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_momentum = CifarModel(deepcopy(simple_convolutional_model), lambda model_params: SGD(model_params, momentum=0.9, lr=2e-3))\nmomentum_acc = train_model_experiment(model_momentum, 'task3_momentum', train_loader, val_loader, test_loader)\nmomentum_acc","metadata":{"execution":{"iopub.status.busy":"2021-10-31T21:58:27.327771Z","iopub.execute_input":"2021-10-31T21:58:27.328316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_adam = CifarModel(deepcopy(simple_convolutional_model), lambda model_params: Adam(model_params, lr=2e-3))\nadam_acc = train_model_experiment(model_adam, 'task3_adam', train_loader, val_loader, test_loader)\nadam_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### График **accuracy** на валидационной выборке:\n\n* Коричный - SGD.\n* Голубой - Momentum.\n* Розовый - Adam.\n\n\n<img src=\"https://drive.google.com/uc?export=view&id=1Se1Rll79TvXLxur55iNsz1E7iA98Pihl\" width=\"600\">","metadata":{}},{"cell_type":"markdown","source":"**Задание 1.4 (0.5 балла).** Добавьте нормализацию по батчу (`BatchNormalization`) между свёрткой и активацией. Попробуйте использовать несколько нормализаций — в свёрточных и полносвязных слоях.","metadata":{"id":"xkGa-FVcwEQ8"}},{"cell_type":"code","source":"batch_norm_in_conv_model = nn.Sequential(\n    nn.Conv2d(3, 10, 3),\n    nn.BatchNorm2d(10),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Flatten(),\n    nn.Linear(2250, 100),\n    nn.ReLU(), \n    nn.Linear(100, 10), \n    nn.Softmax(dim=1)\n    )\nmodel_bn_conv = CifarModel(deepcopy(batch_norm_in_conv_model), lambda model_params: Adam(model_params, lr=2e-3))\nbn_conv_acc = train_model_experiment(model_bn_conv, 'task4_batch_norm_conv', train_loader, val_loader, test_loader)\nbn_conv_acc","metadata":{"id":"QosvgalCwEQ8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_norm_in_dense_model = nn.Sequential(\n    nn.Conv2d(3, 10, 3),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Flatten(),\n    nn.Linear(2250, 100),\n    nn.BatchNorm1d(100),\n    nn.ReLU(), \n    nn.Linear(100, 10), \n    nn.Softmax(dim=1)\n    )\nmodel_bn_dense = CifarModel(deepcopy(batch_norm_in_conv_model), lambda model_params: Adam(model_params, lr=2e-3))\nbn_dense_acc = train_model_experiment(model_bn_dense, 'task4_batch_norm_dense', train_loader, val_loader, test_loader)\nbn_dense_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_norm_model = nn.Sequential(\n    nn.Conv2d(3, 10, 3),\n    nn.BatchNorm2d(10),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Flatten(),\n    nn.Linear(2250, 100),\n    nn.BatchNorm1d(100),\n    nn.ReLU(), \n    nn.Linear(100, 10), \n    nn.Softmax(dim=1)\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_bn = CifarModel(deepcopy(batch_norm_model), lambda model_params: Adam(model_params, lr=2e-3))\nbn_acc = train_model_experiment(model_bn, 'task4_batch_norm', train_loader, val_loader, test_loader)\nbn_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### График **accuracy** на валидационной выборке:\n\n* Коричный - Батч-норм на полносвязном слое.\n* Синий - Батч-норм после свертки.\n* Зеленый - Батч-норм после свертки и на полносвязном слое.\n\n<img src=\"https://drive.google.com/uc?export=view&id=14-_V0fd8qFigseAUubFw82BA-GhmsTWA\" width=\"600\">","metadata":{}},{"cell_type":"markdown","source":"**Задание 1.5 (0.5 балла).** Посмотрите на batch_size (параметр model.fit) - при большем батче модель будет быстрее проходить эпохи, но с совсем огромным батчем вам потребуется больше эпох для сходимости (т.к. сеть делает меньше шагов за одну эпоху).\nНайдите такое значение, при котором модель быстрее достигает точности 55%.","metadata":{"id":"QeY4RLr5wEQ8"}},{"cell_type":"code","source":"from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\nbatch_sizes_list = [4, 8, 16, 32, 64, 128]\nearly_stopping = EarlyStopping('val_acc', stopping_threshold=0.55, mode='max')\nfor batch_size in batch_sizes_list:\n    train_loader_batch_task = torch.utils.data.DataLoader(train_data,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          num_workers=2)\n\n    val_loader_batch_task = torch.utils.data.DataLoader(val_data,\n                                          batch_size=batch_size,\n                                          shuffle=False,\n                                          num_workers=2)\n    model = CifarModel(deepcopy(batch_norm_model), lambda model_params: Adam(model_params, lr=2e-3))\n    acc = train_model_experiment(model, 'task5_batch_size' + str(batch_size), train_loader_batch_task, val_loader_batch_task, test_loader, early_stopping)\n    print('Batch size: ' + str(batch_size))\n    print('Accuracy: ' + str(acc))","metadata":{"id":"WQQPJHrqwEQ8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Вывод:\nМодель с размером батча=4 получила требуемый **accuracy** за 9 эпох. Модель с размером батча 8 сделала это за 2 эпохи. Модели с размерами 16,32,64,128 получили требуемое качество за 1 эпоху. При этом, лучшее accuracy на тестовой выборке принадлежит модели с размером батча = 32.","metadata":{}},{"cell_type":"markdown","source":"**Задание 1.6 (0.5 балла).** Попробуйте найти такую комбинацию метода обучения и нормализации, при которой сеть имеет наилучшую кривую обучения. Поясните, что вы понимаете под \"наилучшей\" кривой обучения.","metadata":{"id":"-pDU1QMbwEQ9"}},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_data,\n                                          batch_size=32,\n                                          shuffle=True,\n                                          num_workers=2)\nval_loader = torch.utils.data.DataLoader(val_data,\n                                          batch_size=32,\n                                          shuffle=False,\n                                          num_workers=2)\nmodel = CifarModel(deepcopy(batch_norm_model), lambda model_params: Adam(model_params, lr=2e-3))\nacc = train_model_experiment(model, 'task6_best_comb', train_loader, val_loader, test_loader, max_epoch=20)\nacc","metadata":{"id":"ocPLP7VewEQ9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### График **accuracy** на валидационной выборке:\n\n<img src=\"https://drive.google.com/uc?export=view&id=1a_T0b0ri_9lF77eerHLzTIXqE9aXygLo\" width=\"600\">","metadata":{}},{"cell_type":"markdown","source":"Напишите ваши выводы по проделанным экспериментам: что заработало, что — не очень. Постройте графики кривых обучения разных архитектур.","metadata":{"id":"3ux0qg8OwEQ9"}},{"cell_type":"markdown","source":"## Выводы:\n1. Адам работает лучше чем SGD.\n2. батч-нормализация даёт значительное улучшение. Лучший результат у батч-норма на сверточных и полносвязных слоях.\n3. Наулучший размер батча = 32.","metadata":{}},{"cell_type":"markdown","source":"## Свёрточная нейросеть здорового человека\n\n**Задание 1.7 (5 баллов).** Наигравшись выше, обучим большую свёрточную сеть, которая даст на тестовой выборке __accuracy больше 80%__. В этом задании вам потребуется провести эксперименты, сравнив их между собой в конце. Возможно, будет несколько проще, если писать выводы во время или сразу после каждого эксперимента, после чего сделать общие выводы.\n\nРекомендуем начать с лучшей модели предыдущего задания и постепенно её улучшать. Вы можете использовать всё, что угодно: любые активации, сколь угодно большие свёрточные слои и глубокие сети. Единственное ограничение: __нельзя использовать предобученные сети и дополнительные данные__.\n\n### Полезные советы\n* Для начала неплохо бы научить что-нибудь побольше, чем 10 фильтров 3x3.\n* __Главное правило: одно изменение на эксперимент__. Если у вас есть 2 идеи по улучшению сети, сначала попробуйте их независимо. Может оказаться, что одно из них дало __+10%__ точности, а другое __-7%__. А вы так и будете думать, что сделали 2 полезных изменения, которые в сумме дают __+3%__. Если какая-то идея не работает — даже если она вам нравится - опишите ее и выкидывайте из дальнейших экспериментов.\n* __Be careful or you will dropout__. Дропаут (`keras.layers.Dropout`, `torch.nn.Dropout`) может позволить вам обучить в несколько раз бОльшую сеть без переобучения, выжав несколько процентов качества. Это круто, но не стоит сразу ставить dropout 50%. Во-первых, слишком сильный дропаут только ухудшит сеть (underfitting). Во-вторых, даже если дропаут улучшает качество, он замедляет обучение. Рекомендуем начинать с небольшого дропаута, быстро провести основные эксперименты, а потом жахнуть в 2 раза больше нейронов и дропаута ~~на ночь~~.\n* __Аугментация данных__. Если котика слегка повернуть и подрезать (простите), он всё равно останется котиком. В Керасе есть [удобный класс](https://keras.io/preprocessing/image/), который поставит подрезание котиков на поток. Ещё можно сделать этот трюк в тесте: вертим картинку 10 раз, предсказываем вероятности и усредняем. Только один совет: прежде, чем учить, посмотрите глазами на аугментированные картинки. Если вы сами не можете их различить, то и сеть не сможет. [Аналогичный модуль для аугментации](https://pytorch.org/vision/stable/transforms.html) в Pytorch.\n* __Don't just stack more layers__. Есть более эффективные способы организовать слои, чем простой Sequential. Вот пара идей: [Inception family](https://hacktildawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions](https://arxiv.org/abs/1608.06993). Только не копируйте архитектуру подчистую — вам скорее всего хватит меньшего размера.\n* __Долго != плохо__. Более глубокие архитектуры обычно требуют бОльше эпох до сходимости. Это значит, что в первые несколько эпох они могут быть хуже менее глубоких аналогов. Дайте им время, запаситесь чаем и обмажьтесь batch-norm-ом.","metadata":{}},{"cell_type":"code","source":"big_conv_model = nn.Sequential(\n    nn.Conv2d(3, 128, 3),\n    nn.BatchNorm2d(128),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Dropout(0.2),\n     nn.Conv2d(128, 256, 3),\n    nn.BatchNorm2d(256),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Dropout(0.2),\n    nn.Conv2d(256, 256, 3),\n    nn.BatchNorm2d(256),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    nn.Dropout(0.2),\n    nn.Flatten(),\n    nn.Linear(1024, 1024),\n    nn.BatchNorm1d(1024),\n    nn.ReLU(),\n    nn.Linear(1024, 10), \n    nn.Softmax(dim=1)\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision import transforms as T \n\naug_transforms = T.Compose([\n    T.RandomHorizontalFlip(p=0.5),\n    T.RandomVerticalFlip(p=0.5),\n    T.ToTensor(),\n])\n\ntest_aug_transforms = T.Compose([\n    T.ToTensor()\n])\n\n\ndataset = torchvision.datasets.CIFAR10('cifar10/train/', download=True, transform=T.ToTensor(), train=True)\ntest_data = torchvision.datasets.CIFAR10('cifar10/test', download=True, transform=T.ToTensor(), train=False)\ntrain_data, val_data = train_test_split(dataset, test_size=1000, random_state=42)\n\ntrain_loader = torch.utils.data.DataLoader(train_data,\n                                          batch_size=64,\n                                          shuffle=True,\n                                          num_workers=2)\nval_loader = torch.utils.data.DataLoader(val_data,\n                                          batch_size=64,\n                                          shuffle=False,\n                                          num_workers=2)\ntest_loader = torch.utils.data.DataLoader(test_data,\n                                          batch_size=64,\n                                          shuffle=False,\n                                          num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CifarModel(deepcopy(big_conv_model), lambda model_params: Adam(model_params, lr=1e-3))\nacc = train_model_experiment(model, 'task7_custom_model', train_loader, val_loader, test_loader, max_epoch=35)\nacc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Момент истины: проверьте, какого качества достигла ваша сеть.","metadata":{"id":"1_8OyZ5kwEQ-"}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntrainer = Trainer(gpus=1)\ny_pred = torch.cat(trainer.predict(model, test_loader, return_predictions=True), dim=0).cpu()\nprint(np.array(y_pred))\ntest_acc = accuracy_score(y_test, y_pred)\nprint(\"\\n Test_acc =\", test_acc)\nif test_acc > 0.8:\n    print(\"Это победа!\")","metadata":{"id":"QmVQX-e8wEQ_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### График **accuracy** на валидационной выборке:\n<img src=\"https://drive.google.com/uc?export=view&id=1HbmnEKi4br1wodROP-ng7x5qUWbdpHoT\" width=\"600\">","metadata":{}},{"cell_type":"code","source":"del model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"А теперь, опишите свои <s>ощущения</s> результаты от проведенных экспериментов. ","metadata":{"id":"kL104JJ4wEQ_"}},{"cell_type":"markdown","source":"Увеличив количество сверточных слоев и пуллинга, а также добавив дропаут удалось побить требуемый порог качества.","metadata":{}},{"cell_type":"markdown","source":"# Часть 2. Fine-tuning обученных нейросетей\n\nВ этой части задания вам предстоит поработать с настоящими монстрами: сетями с почти сотней слоёв и десятками миллионов параметров. Например, такими:\n\n![img](https://alexisbcook.github.io/assets/inception.png)\n<center>googlenet inception v3</center>\n\nЕсли внимательно всмотреться в картинку, можно заметить, что синим цветом обозначены свёрточные слои, красным — pooling, зелёным — конкатенация входов и т.п.\n\n__Чем кормить такого монстра?__\n\nОгромные нейросети обучаются на огромных массивах данных. В компьютерном зрении таких несколько, но самый популярный из них [ImageNet](http://image-net.org/). В этой выборке более миллиона изображений.\n\nЗадача этой сети состоит в классификации каждого изображения в один из 1000 классов. Вот они:","metadata":{"id":"d_7BwkwrwEQ_"}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\n\nclasses = pickle.load(open('../input/ml2task1dataset/classes.pkl','rb'))\nprint(classes[::100])","metadata":{"id":"VKxOCsRywERA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Зоопарк нейросетей\n\nВ пуполярных бибилотеках для содания нейросетей, кроме всего прочего, есть зоопарк предобученных нейросетей: [__`keras.applications`__](https://keras.io/applications/) для Keras и [torchvision.models](https://pytorch.org/vision/stable/models.html) для PyTorch. В этом задании мы предлагаем порадотать с моделью `InceptionV3`.\n\n**Внимание!**\nInceptionV3 требует много памяти для работы. Если ваш ПК начинает зависать:\n* закройте всё кроме jupyter и браузера с одной вкладкой;\n* если не помогло, загрузите эту тетрадку в [google colab](https://colab.research.google.com/) и работайте там;\n* замените `InceptionV3` на `MobileNet`. Однако в этом случае вам придётся исправить и предобработку картинок.\n\nВыберите оптимальный для вас вариант, загрузите модель (пример кода можно для каждого из фреймворков Keras и PyTorch можно посмотреть по ссылкам выше) и начнем работу!","metadata":{"id":"gmzKug5bwERA"}},{"cell_type":"code","source":"model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True, aux_logits=False).cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Функция ниже позволяет найти для заданного изображения топ10 классов по мнению InceptionV3.","metadata":{"id":"YKhxVfRQwERB"}},{"cell_type":"markdown","source":"Для Keras:","metadata":{"id":"reEsr2g9B6zB"}},{"cell_type":"code","source":"# import tensorflow as tf\n# preprocess_input = tf.keras.applications.inception_v3.preprocess_input","metadata":{"id":"oQV7Ro14A1z7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для PyTorch:","metadata":{"id":"riWjfUR1B9SZ"}},{"cell_type":"code","source":"import torchvision\nfrom torchvision.transforms import ToTensor, Normalize, Compose\npreprocess_input = Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])","metadata":{"id":"Wyq1kyzlBLkT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.transform import resize\n\n\ndef predict_top10(img, model, preprocess_input):\n    model.eval()\n    img = resize(img, (299, 299), mode='reflect')\n    assert img.min() >= 0.0 and img.max() <= 1.0\n    plt.imshow(img)\n    plt.show()\n    img_preprocessed = preprocess_input(img * 255)[None]\n    probs = torch.nn.functional.softmax(model(img_preprocessed.float().cuda()).detach().cpu()[0], dim=0)\n    labels = reversed(probs.argsort()[-10:])\n\n    print('top-10 classes:')\n    for l in labels:\n        print('%.4f\\t%s' % (probs.ravel()[l], classes[l].split(',')[0]))","metadata":{"id":"Ny37ZV-2wERB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Примечание:** не нужно бояться функции `tf.keras.applications.inception_v3.preprocess_input`: на самом деле это общее преобразование картинки (не привязанное непосредственно к `InceptionV3`), которое преобразует изображение в тензор и масштабирует фичи в отрехое $[-1; 1]$.  В PyTorch все преобрзаования над картинкой производятся при момощи модуля `torchvision.transform`, для преобразования в тензор используется класс `torchvision.transform.ToTensor`. Обратите внимание, что, в отличие от Temsorflow, родной входной формат для PyTorch - это значения в диапазоне $[0; 1]$.\n\n`MobileNet`","metadata":{"id":"lF03ZrD__g9e"}},{"cell_type":"markdown","source":"Проверим, как она работает на близкой к обучающей выборке картинке:","metadata":{"id":"4GxSw1skwERB"}},{"cell_type":"code","source":"# predict_top10(plt.imread('albatross.jpg'))","metadata":{"id":"8pH_uFbMwERB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"А теперь попробуем ее на чем-то неожиданном!","metadata":{"id":"K4RkGhFdwERC"}},{"cell_type":"code","source":"!wget http://cdn.com.do/wp-content/uploads/2017/02/Donal-Trum-Derogar.jpeg -O img.jpg\npredict_top10(plt.imread('img.jpg'), model, preprocess_input)","metadata":{"id":"yxVCA0oYwERC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dogs Vs Cats\n\nА теперь попробуем построить классификатор, который отличает изображение кошки от собаки. \n\n![img](https://dingo.care2.com/pictures/greenliving/1203/1202163.large.jpg)","metadata":{"id":"Gjb3lwVowERC"}},{"cell_type":"markdown","source":"Скачайте данные из [Каггла](https://www.kaggle.com/c/dogs-vs-cats/data)","metadata":{"id":"A4GF7T4AwERD"}},{"cell_type":"code","source":"# Этот ноутбук запускался на кагле, все данные подключались через апи датасетов.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sklearn way\n\n**Задание 2.1 (1.5 балла).** В вашем распоряжении есть предобученная сеть InceptionV3. Ваша задача — обучить классификатор из sklearn (на ваш выбор), который будет отличать котов от собак, используя __активации нейронной сети в качестве признаков__.\n\nДля начала прочитайте данные и сформируйте для вашего классификатора обучающую и тестовую выборки в пропорции 4:1. \n\nВ вашем распоряжении всего 25 000 изображений различного размера, все в формате JPEG. Изображения кошек имеют название вида `./train/cat.*.jpg`, собак — `./train/dog.*.jpg`.\n\nСчитайте данные и для каждой картинки вычислите признаки из промежуточного слоя свёрточной сети. В качестве признаков можно выбрать какой-нибудь слой или несколько слоёв сети. Попробуйте найти комбинацию слоёв, которая работает лучше всего.\n\n[Здесь](https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer) можно почитать, как посчитать активацию промежуточных слоёв.","metadata":{"id":"xF7CS067wERD"}},{"cell_type":"code","source":"!rm -rf train\n!unzip ../input/dogs-vs-cats/train.zip -d train;","metadata":{"id":"BmRTj3NQwERD","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nfilenames = os.listdir(\"./train/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n}) \ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Разделите данные на обучение и тест в отношении 4:1.","metadata":{"id":"tP1yiju3wERE"}},{"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nX_train_filenames, X_test_filenames, y_train, y_test = train_test_split(df['filename'], df['category'], test_size=0.2, random_state=42)","metadata":{"id":"7_FOPd5IwERE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обучите поверх этих признаков классификатор из sklearn (можно попробовать несколько и выбрать лучший). Попробуйте получить ROC-AUC __хотя бы 99%__.","metadata":{"id":"bOflj0mzwERE"}},{"cell_type":"code","source":"# Убираем линейный слой и дропаут перед ним\nmodel.dropout = nn.Identity()\nmodel.fc = nn.Identity()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom skimage import io\nfrom tqdm import tqdm\nimport gc\n    \ndef get_features(root_dir, X_filenames, preprocess_input, feature_extractor):\n    result = []\n    for filename in tqdm(X_filenames):\n        img_name = os.path.join(root_dir, filename)\n        img = io.imread(img_name)\n        img = resize(img, (299, 299), mode='reflect')\n        assert img.min() >= 0.0 and img.max() <= 1.0\n        img_preprocessed = preprocess_input(img * 255)[None].float()\n        features = feature_extractor(img_preprocessed.cuda()).detach().cpu().numpy()\n        result.append(features)\n        del img_preprocessed, img\n    gc.collect()\n    return np.array(result)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_features = get_features('./train/train', X_train_filenames, preprocess_input, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_features = get_features('./train/train', X_test_filenames, preprocess_input, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sklearn.__version__","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:00:26.185001Z","iopub.execute_input":"2021-11-01T12:00:26.18536Z","iopub.status.idle":"2021-11-01T12:00:26.194691Z","shell.execute_reply.started":"2021-11-01T12:00:26.18532Z","shell.execute_reply":"2021-11-01T12:00:26.194003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nrdf =  RandomForestClassifier(n_estimators=500)\nrdf.fit(X_train_features.squeeze(), y_train.to_numpy())","metadata":{"execution":{"iopub.status.busy":"2021-11-01T12:01:49.71792Z","iopub.execute_input":"2021-11-01T12:01:49.718187Z","iopub.status.idle":"2021-11-01T12:01:49.959491Z","shell.execute_reply.started":"2021-11-01T12:01:49.718158Z","shell.execute_reply":"2021-11-01T12:01:49.958399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test.to_numpy(), rdf.predict_proba(X_test_features.squeeze())[:, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Опишите ваши выводы о проделанной работе.","metadata":{"id":"RW_JK74LwERE"}},{"cell_type":"markdown","source":"## Fine-tuning\n\n**Задание 2.2 (3 балла).** Давайте попробуем добиться ещё большего качества через дообучение (fine-tuning) модели. Новая цель — получить качество лучше, чем у классификатора из предыдущего пункта на признаках `InceptionV3`. Цель этого задания: получить значение ROC-AUC __не меньше 99.5%__.","metadata":{"id":"P_rOEdiJwERF"}},{"cell_type":"markdown","source":"__Шаг 1.__  Постройте сеть, в которой InceptionV3 \"без головы\" используется в качестве первого слоя. Поверх неё надстройте новую голову из `keras.layers`/ `torch.nn`— она будет отличать котов от собак. Это можно сделать с помощью [общего интерфейса модели](https://keras.io/models/model/). В PyTorch несеквенциальные модели можно строить, наследуя модель от класса `torch.nn.Module`: [общий интерфейс модели PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)","metadata":{"id":"IQ3_10M3wERF"}},{"cell_type":"code","source":"class InceptionV3Model(nn.Module):\n    def __init__(self, feature_extractor):\n        super().__init__()\n        self.feature_extractor = feature_extractor\n        self.head = nn.Sequential(\n          nn.Dropout(p=0.2),\n          nn.Linear(2048, 1024),\n          nn.ReLU(),\n          nn.Linear(1024, 1)\n        )\n\n    def forward(self, x):\n        features = self.feature_extractor(x)\n        return self.head(features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Шаг 2.__ Обучите \"голову\" на обучающей выборке, не меняя весов изначальной сети. Это называется обучением с замороженными весами. Как это сделать в Keras, можно прочитать [здесь](https://keras.io/getting-started/faq/#how-can-i-freeze-keras-layers), для PyTorch смотрите [статью](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html), подраздел про Finetuning. В PyTorch заморозка весов регулируется параметром `requires_grad = False`.","metadata":{"id":"KyNJr_t7wERF"}},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass CatVSDogDataset(Dataset):\n    def __init__(self, filenames, labels, root_dir, preprocess_input, train, transform=None):\n        self.root_dir = root_dir\n        self.filenames = filenames\n        self.labels = labels\n        self.transform = transform\n        self.preprocess_input = preprocess_input\n        self.train = train\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir,\n                                self.filenames.iloc[idx])\n        image = io.imread(img_name)\n        image = resize(image, (299, 299), mode='reflect')\n        assert image.min() >= 0.0 and image.max() <= 1.0\n        image_preprocessed = preprocess_input(image * 255).float()\n        label = self.labels.iloc[idx]\n\n        if self.transform:\n            image_preprocessed = self.transform(image_preprocessed)\n        if self.train:\n            return (image_preprocessed, label)\n        else: \n            return image_preprocessed","metadata":{"id":"hI9OIH8xwERF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CatVSDogDataset(X_train_filenames, y_train, './train/train', preprocess_input, train=True)\ntest_dataset = CatVSDogDataset(X_test_filenames, y_test, './train/train', preprocess_input, train=False)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                          batch_size=64,\n                                          shuffle=True,\n                                          num_workers=2)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=64,\n                                          shuffle=False,\n                                          num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CatVsDogModel(LightningModule):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n        self.loss = nn.BCEWithLogitsLoss()\n\n    def forward(self, x):\n        return self.model.forward(x)\n      \n    def configure_optimizers(self):\n        return Adam(filter(lambda p: p.requires_grad, self.model.parameters()), lr=2e-3)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.forward(x).squeeze()\n        loss = self.loss(logits, y.float())\n        \n        preds = (logits > 0).float()\n        acc = accuracy_score(y.cpu(), preds.cpu())\n        \n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n      \n    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = None):\n        return (self(batch) > 0).float()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor = deepcopy(model)\nfor param in feature_extractor.parameters():\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = TensorBoardLogger(\"logs/part2_freeze\")\nnet = InceptionV3Model(feature_extractor)\ncvd_model = CatVsDogModel(net)\ntrainer = Trainer(logger=logger, gpus=1, max_epochs=2)\ntrainer.fit(cvd_model, train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ny_pred = torch.cat(trainer.predict(cvd_model, test_loader, return_predictions=True), dim=0).cpu()\nroc_auc_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Sanity check:__ После этого шага ваша модель должна уже быть сравнима по точности с моделями из задания 1.\n\nЕсли всё получилось, самое время [сохранить модель Keras](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model) или [сохранить модель PyTorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html).","metadata":{"id":"JR5w4TIowERG"}},{"cell_type":"code","source":"trainer.save_checkpoint(\"inceptionv3_model.ckpt\")","metadata":{"id":"GBk_zTNawERG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Шаг 3.__ \"Разморозьте\" несколько предыдущих слоёв модели и продолжите обучение. На этом этапе важно не переобучиться: смотрите качество на валидации.\n\nЕсли качество не улучшается, а сразу идёт вниз, попробуйте уменьшить число обучаемых слоёв или воспользуйтесь [аугментацией данных](https://keras.io/preprocessing/image/) ([аугментация](https://pytorch.org/vision/stable/transforms.html) в Pytorch). В общем случае всегда полезно помнить про аугментацию данных, даже если и без неё всё работает — иногда она творит [чудеса](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced).","metadata":{"id":"zSBHk9-CwERG"}},{"cell_type":"code","source":"feature_extractor = deepcopy(model)\nfor param in list(feature_extractor.parameters())[:-3]:\n    param.requires_grad = False\n\nfor param in list(feature_extractor.parameters())[-3:]:\n    param.requires_grad = True","metadata":{"id":"oTwG0FunwERG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = TensorBoardLogger(\"logs/task2_unfreeze\")\nnet = InceptionV3Model(feature_extractor)\ncvd_model = CatVsDogModel(net)\ntrainer = Trainer(logger=logger, gpus=1, max_epochs=2)\ntrainer.fit(cvd_model, train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Шаг 4.__ Вычислите финальное качество.","metadata":{"id":"zvX_-bT0wERG"}},{"cell_type":"code","source":"y_pred = torch.cat(trainer.predict(cvd_model, test_loader, return_predictions=True), dim=0).cpu()\nroc_auc_score(y_test, y_pred)","metadata":{"id":"QiB_oNutwERH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Напишите отчёт и вознаградите себя за старания чем-нибудь.","metadata":{"id":"LwuSz8pNwERH"}},{"cell_type":"markdown","source":"### Вывод:\nRandomForest, обученный на фичах получает **accuracy**~0.75. В то время как полносвязные слои с замороженными свертками получают **accuracy**~0.975. Размораживание 2 последних сверток не даёт улучшений. Возможно нужно разморозить больше слоёв.","metadata":{}},{"cell_type":"markdown","source":"# Всё сделали, но азарт не прошел?\n\nВ таких случаях можно пробовать следующие техники:\n* Ансамбль из нескольких предобученных нейросетей. Bagging? Stacking? Boosting? Всё, что пожелаете.\n* Более честный эксперимент: разделяем данные на train/__dev__/test, все сравнения делаем по dev, а test используем только в самом конце.\n* Аугментировать данные картинками из интернета. Уж чего, а котиков и собачек там хватает.","metadata":{"id":"9RGQTh2VwERH"}},{"cell_type":"code","source":"","metadata":{"id":"NiLCKIK9wERH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Часть 3. Рекуррентные языковые модели\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSj85jp-W-V-Bz8ZBjFJYIkV1TTxQxTMh4iqls_rRt8O-sraL08PA)\n\nВ этой части домашней работы мы создадим языковую модель на рекуррентных нейросетях (RNN) и заставим её придумывать имена.\n\n__Языковая модель__, если вкратце, — это модель, которая умеет предсказывать вероятность некоторого текста. Ее можно использовать также для генерирации нового текста в соответствии с обученными вероятностями. Задание будет заключаться в том, чтобы научить модель генерировать новые имена, скормив ей для этого 8к существующих.\n\nВ данном случае в качестве входных данных мы будет работать со строками, которые можно рассматривать как последовательности _символов_: $\\{x_0, x_1, x_2, ..., x_n\\}$. \n\nНаша основная задача — научиться предсказывать вероятность следующего символа:\n$$ p(x_0, x_1, x_2, ..., x_n) = \\prod_t p(x_t | x_0, ... x_{t - 1}) $$","metadata":{"id":"O9r7JiI-wERI"}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt","metadata":{"id":"Pd32BiVVwERI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Данные\n\nМы будем строить языковую модель по ~8k человеческих имён на латинице. Если когда-нибудь вам нужно будет дать имя своему ребёнку, у вас будет для этого генеративная нейросетевая модель.\n\nДавайте их прочитаем:\n* Считайте все строки из файла `names` в список\n* В начало каждой строки допишите __пробел__\n* В конце сроки не должно быть переноса (`\\n`)","metadata":{"id":"H_j-MQlSwERI"}},{"cell_type":"code","source":"import os\nstart_token = \" \"\n\n# YOUR CODE\nwith open('../input/names-ml2task1/names') as file:\n    lines = file.readlines()\n    lines = [' ' + line[:-1] for line in lines]","metadata":{"id":"T1evly3pwERI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert all(line[0] == start_token for line in lines)\nassert all(line[-1] != '\\n' for line in lines)","metadata":{"id":"74G17ppwwERJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('n samples = ',len(lines))\nfor x in lines[::1000]:\n    print(x)","metadata":{"id":"58kGHFs8wERJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Проверьте, что все корректно:","metadata":{"id":"JbLKbnrgwERJ"}},{"cell_type":"code","source":"MAX_LENGTH = max(map(len, lines))\nprint(\"max length =\", MAX_LENGTH)\nassert MAX_LENGTH == 16 , \"max length (for names) should be 16. remove assert if you work on different dataset\"","metadata":{"id":"Zhe6x7e2wERJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Словари\n\nВ начале нам будет необходимо построить \"словарь\" — упорядоченное множество уникальных символов, которые сеть может породить. Это нужно, чтобы уметь сопоставить каждому символу свой номер. Перед отправкой в сеть все символы будут кодироваться их номерами в словаре.\n\nТакже необходимо добавить в словарь пробельный символ, который будет использоваться в качестве специального токена.","metadata":{"id":"OVmEMAmHwERK"}},{"cell_type":"code","source":"import string\ntokens = string.ascii_letters + ' ' + '-' + '\\''\n\ntokens = sorted(list(tokens))\n\nn_tokens = len(tokens)\nprint ('n_tokens = ', n_tokens)\n\nassert 50 < n_tokens < 60","metadata":{"id":"IsgLJVXCwERK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"А теперь построим обратный словарь: для каждой буквы посчитаем её номер в списке токенов.","metadata":{"id":"U4jNnlVIwERK"}},{"cell_type":"code","source":"token_to_id = { tokens[idx]:idx for idx in range(len(tokens))}","metadata":{"id":"kDcyNAQDwERK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"И проверим, все ли корректно:","metadata":{"id":"a58Vz3TjwERL"}},{"cell_type":"code","source":"assert len(tokens) == len(token_to_id), \"число токенов должно совпадать\"\n\nfor i in range(n_tokens):\n    assert token_to_id[tokens[i]] == i, \"словарь должен указывать на индекс буквы в tokens\"\n\nprint(\"Кажется заработало...\")","metadata":{"id":"iyt4rIFgwERL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Имея построенное соответствие, можно преобразовать батч входных данных в матрицу int32 номеров токенов. Так как в батче все строки должны быть одной длины, слишком короткие строки в батче нужно будет дополнить пробелами (паддинг).","metadata":{"id":"f5vHGreYwERL"}},{"cell_type":"code","source":"def to_matrix(lines, max_len=None, pad=token_to_id[' '], dtype='int32'):\n    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n    max_len = max_len or max(map(len, lines))\n    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n\n    for i in range(len(lines)):\n        line_ix = list(map(token_to_id.get, lines[i]))\n        lines_ix[i, :len(line_ix)] = line_ix\n\n    return lines_ix","metadata":{"id":"qU4rebVBwERL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\n'.join(lines[::2000]))\nprint(to_matrix(lines[::2000]))","metadata":{"id":"5srwIfaywERM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Один шаг RNN\n\nРекуррентная нейронная сеть (RNN) — это такая сеть с <s>блокнотом</s> состоянием $h$, в который она умеет писать то, что видела.\n\nСеть начинает с пустого $h_0 = \\vec 0$, после чего текст обрабатывается по одному символу:\n* $x_t$ — очередной символ, $h_t$ — предыдущее состояние\n* $h_{t+1} = \\text{get_h_next}(h_t, x_t)$ — новое состояние\n* $p(x_{t+1} | h_{t+1}) = \\text{get_probs}(h_{t+1})$ — вероятность следующего символа\n\n\n\n<img src=\"https://i.imgur.com/8l4qFF0.png\" width=480>\n\nПоскольку $x_t$ — это индекс символа в словаре (натуральное число), то ему можно сопоставить некоторый обучаемый вектор (*embedding*).","metadata":{"id":"kHZzCqBpwERM"}},{"cell_type":"markdown","source":"**Задание 3.1 (1 балл)**. Реализуйте вычисление нового состояния *get_h_next* и вероятности следующего символа *get_probs*, после чего напишите код для одного шага рекуррентной сети *rnn_one_step*, как на схеме выше.","metadata":{"id":"AvibL20qwERM"}},{"cell_type":"code","source":"import tensorflow.compat.v1 as tf\nimport keras, keras.layers as L # torch.nn as L\ntf.disable_v2_behavior()  \n\nemb_size, rnn_size = 16, 64","metadata":{"id":"jnUgQeqewERM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создадим слой, который сопоставляет каждому из n_tokens входов свой обучаемый вектор:","metadata":{"id":"3RvlbIGSwERN"}},{"cell_type":"code","source":"embed_x = L.Embedding(n_tokens, emb_size)","metadata":{"id":"8PLGADchwERN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Теперь инициализируем слой, вычисляющий следующее состояния $[emb(x_t), h_t] \\to h_{t+1}$.","metadata":{"id":"zjirocAuwERN"}},{"cell_type":"code","source":"get_h_next = L.Dense(rnn_size, activation=\"tanh\", name=\"layer1_rnn\")","metadata":{"id":"9TppnOm0wERN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"И, наконец, слой предсказывающий вероятности $h_{t+1} \\to P(x_{t+1}|h_{t+1})$.","metadata":{"id":"EQDurpcgwERO"}},{"cell_type":"code","source":"get_probs = L.Dense(n_tokens, activation=\"softmax\", name=\"layer2_rnn\")","metadata":{"id":"iHJGtml3wERO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для реализации одного шага RNN реализуйте следующую последовательность действий:\n1. замените номер символа на его вектор (embedding) (*hint*: возможно, вам потребуется tf.reshape);\n2. сконкатенируйте вектор входа и предыдущее состояние;\n3. вычислите следующее состояние сети;\n4. предскажите вероятности для языковой модели P(x_next | h_next).","metadata":{"id":"US1DMD-1wERO"}},{"cell_type":"code","source":"def rnn_one_step(x_t, h_t):    \n    # YOUR CODE\n    embedding = embed_x(tf.reshape(x_t, (-1,1)))[:,0,:] \n    h_t_reshaped = tf.reshape(h_t, (-1, rnn_size))\n    hidden_x = tf.concat([embedding, h_t_reshaped], 1)\n    hidden_x_reshaped = tf.reshape(hidden_x, (-1, emb_size + rnn_size))\n    h_next = get_h_next(hidden_x_reshaped)\n    output_probs = get_probs(h_next)\n    return h_next, output_probs","metadata":{"id":"xMy7snRqwERO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Проверим, что все работает (для PyTorch проверочный код разрешается изменить):","metadata":{"id":"iSEe0pVIwERO"}},{"cell_type":"code","source":"input_sequence = tf.placeholder('int32', (None, MAX_LENGTH))\nbatch_size = tf.shape(input_sequence)[0]\n\n# начальное состояние из нулей\nh0 = tf.zeros([batch_size, rnn_size])","metadata":{"id":"ibNbSc7QwERP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h1, p_y1 = rnn_one_step(input_sequence[:, 0], h0)\n\ndummy_data = np.arange(MAX_LENGTH * 2).reshape([2, -1])\nsess = tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())\ntest_h1, test_p_y1 = sess.run([h1, p_y1],  {input_sequence: dummy_data})\nassert test_h1.shape == (len(dummy_data), rnn_size)\nassert test_p_y1.shape == (len(dummy_data), n_tokens) and np.allclose(test_p_y1.sum(-1), 1)","metadata":{"id":"xVVfXFIcwERP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Много шагов RNN\n\nПосле того как был реализован один шаг нейросети, самое время сделать этих шагов побольше. Самый простой способ это сделать — написать цикл для фиксированного числа шагов (`MAX_LENGTH`).\n\n**Задание 3.2 (1 балл)**. Реализуйте много шагов рекуррентной сети, на каждом шаге вычисляя следующее состояние RNN, исходя из предыдущего, при этом не забывая про *get_h_next* и *get_probs*.","metadata":{"id":"83_eYl7CwERP"}},{"cell_type":"code","source":"h_prev = h0\npredicted_probs = []\n\nfor t in range(MAX_LENGTH):\n    x_t = input_sequence[:, t]\n    # YOUR CODE\n    h_next, probs_next = rnn_one_step(x_t, h_prev)\n    \n    # END OF YOUR CODE\n    predicted_probs.append(probs_next)\n    h_prev = h_next\n    \npredicted_probs = tf.stack(predicted_probs, axis=1) # torch.stack for PyTorch","metadata":{"id":"AiPk8d3zwERR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert predicted_probs.shape.as_list() == [None, MAX_LENGTH, n_tokens]\nassert h_prev.shape.as_list() == h0.shape.as_list()","metadata":{"id":"jJ8n9VrPwERR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение RNN\n\nКак и любую вероятностную модель, RNN можно обучить методом максимизации log-правдоподобия по всей выборке $D$:\n\n$$ \\theta = \\underset \\theta {argmax} \\log P(D) $$\n\nгде\n$$ \\log P(D) = \\underset {\\vec x \\in D} \\sum \\log P(\\vec x) = \\underset {\\vec x \\in D} \\sum \\underset {x_t \\in \\vec x} \\sum \\log P(x_t | x_0, ..., x_{t+1})$$\n\nC тем же успехом мы можем __минимизировать__ кроссэнтропию — то же самое, но с минусом.","metadata":{"id":"UkWaPiaXwERS"}},{"cell_type":"code","source":"predictions_matrix = predicted_probs[:, :-1]\nanswers_matrix = tf.one_hot(input_sequence[:, 1:], n_tokens)  # torch.nn.functional.one_hot for PyTorch\n\nprint('predictions_matrix:', predictions_matrix.shape)\nprint('answers_matrix:', predictions_matrix.shape)","metadata":{"id":"1LNROifRwERS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Задание 3.3 (2 балла)**. Реализуйте вычисление функции потерь (кроссэнтропия) и шаг градиентного спуска.","metadata":{"id":"BTge6KpCwERS"}},{"cell_type":"code","source":"import tensorflow\nloss = tensorflow.reduce_mean(tensorflow.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\noptimize = tf.train.AdamOptimizer().minimize(loss)","metadata":{"id":"kUJoHwycwERT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Цикл обучения\n\n**Задание 3.4 (1 балл)**. Напишите цикл обучения:\n1. выбираем `batch_size` случайных строчек\n2. преобразуем их в матрицу индексов\n3. вычисляем функцию потерь и делаем шаг обучения\n4. записываем функцию потерь в `history`\n\nДля удобства отладки рекомендуем печатать или рисовать промежуточные результаты раз в несколько итераций.","metadata":{"id":"3Q6QXg-SwERT"}},{"cell_type":"code","source":"batch_size = 32\nhistory = []\n\nsess.run(tf.global_variables_initializer()) # эту строку можно выпилить","metadata":{"id":"vZwc2OdCwERT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_matrix = to_matrix(lines, max_len=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1000):\n    batch = words_matrix[np.random.choice(words_matrix.shape[0], batch_size, replace=False), :]\n    _loss, _ = sess.run((loss, optimize), {input_sequence: batch})\n    history.append(_loss)","metadata":{"id":"94-ezMExwERT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history)\nplt.grid()","metadata":{"id":"rSnE5eI6wERU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Применение RNN\n\nТолько что у нас обучилась модель, которая предсказывает вероятности следующего символа.\nТеперь давайте применим её к строке из одного пробела. Получим вероятности первой буквы имени. После чего:\n* $x_t \\sim P(x_t | h_t)$ — выберем букву пропорционально вероятностям.\n* $h_{t+1} = \\text{get_h_next}(h_t, x_t)$ — присоединим букву к имени и прогоним через RNN","metadata":{"id":"6kpnPrGWwERU"}},{"cell_type":"markdown","source":"Для начала инициализируем необходимые переменные:","metadata":{"id":"AvleSSQowERU"}},{"cell_type":"code","source":"x_t = tf.placeholder('int32', (None, ))\nh_t = tf.Variable(np.zeros([1, rnn_size], 'float32'))\n\nnext_h, next_probs = rnn_one_step(x_t, h_t)","metadata":{"id":"C9RnjUcgwERU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Задание 3.5 (1 балл).** Напишите функцию, генерируюущю новые имена:","metadata":{"id":"Dwtv5yEGwERU"}},{"cell_type":"code","source":"def generate_sample(seed_phrase=' ', max_length=MAX_LENGTH):\n    result = seed_phrase\n    words = to_matrix(seed_phrase)\n\n    sess.run(tf.assign(h_t, h_t.initial_value))\n\n    for word in words[:-1]:\n        sess.run(tf.assign(h_t, next_h), {x_t: word})\n\n    word = words[-1][0]\n    for _ in range(len(seed_phrase), max_length):\n        probs, _ = sess.run([next_probs, tf.assign(h_t, next_h)], {x_t: [word]})\n        word = np.random.choice(n_tokens, p=probs[0])\n        result += tokens[word]\n    return result","metadata":{"id":"U-GbLfpCwERV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим, что же придумала наша модель:","metadata":{"id":"ekVdeShFwERV"}},{"cell_type":"code","source":"for _ in range(10):\n    print(generate_sample())","metadata":{"id":"yqF3IrgqwERV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _ in range(25):\n    print(generate_sample(' Putin'))","metadata":{"id":"xOjqM3SlwERV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Что теперь?\n\nЕсли вам наскучит решать повседневные задачи или вам нужны новые идеи, вы теперь всегда можете воспользоваться RNN, чтобы сгенерировать что-то новое. Вот несколько задач, от которых можно отталкиваться:\n* названия статей по глубинному обучению;\n* названия карт Magic The Gathering;\n* [имена покемонов](https://github.com/cervoise/pentest-scripts/blob/master/password-cracking/wordlists/pokemon-list-en.txt);\n* clickbait заголовки;\n* молекулы в формате [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system);\n* ваша фантазия, с ограничениями которой вы уже должны были понять, как бороться.\n\nЕсли возьмётесь за эту задачу, то вот несколько полезных советов:\n* Сейчас модель обучается на коротких строчках. Если у вас роман, его придётся порезать на кускочки.\n* Если длина строк сильно варьируется, можно поставить параметр MAX_LENGTH так, чтобы он покрывал 90%. Это обычно дает ускорение примерно в 2 раза.\n* Для более сложных задач требуется больше нейронов (rnn_size). Кроме того, можно экспериментировать и со составляющими сети (см. ниже).\n\n### Ещё почитать\n\n* [Подборка советов](https://danijar.com/tips-for-training-recurrent-neural-networks/) по обучению RNN. Чуть более полезная, чем обычно.\n* Отличный блог-пост от Andrej Karpathy про языковые модели на rnn, их применение и визуализацию — [Unreasonable Effectiveness of RNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).\n* Большой список статей, постов, реализаций и прочих полезностей по RNN - [awesome rnn](https://github.com/kjw0612/awesome-rnn).\n* Зоопарк готовых рекуррентных ячеек (LSTM, GRU) в [Керасе](https://keras.io/layers/recurrent/) и [PyTorch](https://pytorch.org/docs/stable/nn.html#recurrent-layers).\n* Сейчас мы настраиваем количество итераций заранее. Если вы хотите определять их динамически, милости просим в [tf.while_loop](https://www.tensorflow.org/api_docs/python/tf/while_loop) или [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan).\n* А ещё рекуррентные сети можно аугментировать механизмом внимания или долговременной памятью. Вот тут есть [хорошая статья](https://distill.pub/2016/augmented-rnns/).","metadata":{"id":"qi_vPDh6wERW"}},{"cell_type":"code","source":"","metadata":{"id":"lFs5wufHwERW"},"execution_count":null,"outputs":[]}]}