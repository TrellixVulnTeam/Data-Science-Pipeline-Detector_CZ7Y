{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Dogs or Cats \n\nFirst Version about VGG-19 (working progress....) \n\n\n<br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. Frameworks ","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os \nimport glob \nimport zipfile\nimport re \nimport time \nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\nimport seaborn as sns \nimport random \n\n%matplotlib inline \nimport warnings \nwarnings.filterwarnings('ignore')\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, InputLayer\nfrom tensorflow.keras.layers import SpatialDropout2D, GlobalMaxPool2D, GlobalMaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seed \ntf.random.set_seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if tf.test.gpu_device_name():\n    print('Default GPU device: {}'.format(tf.test.gpu_device_name()))\nelse: \n    print('Please install GPU for tensorflow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# zipfiles \nzip_files = ['test1', 'train']\n\nfor zip_file in zip_files:\n    with zipfile.ZipFile(\"../input/dogs-vs-cats/{}.zip\".format(zip_file),\"r\") as z:\n        z.extractall(\".\")\n        print(\"{} unzipped\".format(zip_file))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filenames\nprint(os.listdir('../input/dogs-vs-cats'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import files \n\nimage_folder = ('../working/train')\nfilenames = os.listdir(image_folder)\n\n\nclasses=list()\nfull_paths=list()\nfor file in filenames:\n    target=file.split(\".\")[0]\n    full_path=os.path.join(image_folder, file)\n    full_paths.append(full_path)\n    classes.append(target)\n\ndata=pd.DataFrame()\ndata['path']=full_paths\ndata['label']=classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count images\nclasses_count = data['label'].value_counts()\n\nprint('Count dog images: {}'.format(classes_count['dog']))\nprint('Count dog images: {}'.format(classes_count['cat']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classes count \nplt.figure(figsize=(9,5))\nsns.countplot(data['label'], palette='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# spliting images \n\ndogs_list = ['../working/train/dog.11618.jpg', '../working/train/dog.4341.jpg', '../working/train/dog.8119.jpg']\n\nplt.figure(figsize=(14,7))\n\nfor image in range(0,3):\n    plt.subplot(1,3, image +1)\n    image = load_img(dogs_list[image], target_size=(150,150))\n    plt.imshow(image)\n    plt.title('Dog', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats_list = ['../working/train/cat.1654.jpg', '../working/train/cat.4341.jpg', '../working/train/cat.8119.jpg']\n\nplt.figure(figsize=(14,7))\n        \n           \nfor image in range(0,3):\n    plt.subplot(1,3, image +1)\n    image = load_img(cats_list[image], target_size=(150,150))\n    plt.imshow(image)\n    plt.title('Cat', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Images shape  \nimage = load_img('../working/train/dog.1273.jpg', target_size=(150,150))\nimage = img_to_array(image)\nimage.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show image \nimage = array_to_img(image)\nplt.imshow(image, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n<hr>\n<br>\n\n\n### Build Convolutional Neural Network \n\n\n<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNN Archicture \n\n\ndef cnn(input_shape, block1, block2, block3, block4):\n    \n   # sequential and input  \n    model = Sequential()\n    model.add(InputLayer(input_shape=input_shape))\n   \n   # Block 1 | Convolutional\n    model.add(Conv2D(filters=block1[0], kernel_size=block1[1], strides=block1[2], padding=block1[3], activation='relu'))\n    model.add(Conv2D(filters=block1[0], kernel_size=block1[1], strides=block1[2], padding=block1[3], activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n    \n    \n    \n   # Block 2 | Convolutional \n    model.add(Conv2D(filters=block2[0], kernel_size=block2[1], strides=block2[2], padding=block2[3], activation='relu'))\n    model.add(Conv2D(filters=block2[0], kernel_size=block2[1], strides=block2[2], padding=block2[3], activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n    \n    \n              \n    # Block 3 | Convolutional \n    model.add(Conv2D(filters=block3[0], kernel_size=block3[1], strides=block3[2], padding=block3[3], activation='relu'))\n    model.add(Conv2D(filters=block3[0], kernel_size=block3[1], strides=block3[2], padding=block3[3], activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n    \n    \n    # Block 4 | Convolutional \n    model.add(Conv2D(filters=block4[0], kernel_size=block4[1], strides=block4[2], padding=block4[3], activation='relu'))\n    model.add(Conv2D(filters=block4[0], kernel_size=block4[1], strides=block4[2], padding=block4[3], activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n    \n    \n              \n    # Block 5 | GlobalMaxPooling + Fully Connected + Output Layer \n    model.add(GlobalMaxPool2D())\n    model.add(Dense(units=512, activation='relu'))\n    model.add(Dense(units=1, activation='sigmoid'))\n              \n    \n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defines parameters and blocks \n\nimage_size = 150\ninput_shape = (image_size, image_size, 3)\n\n\n\nepochs = 50\nbatch = 160\noptimizer = RMSprop(learning_rate=1e-4)\nmetrics = ['accuracy']\nloss = BinaryCrossentropy()\n\n\nblock1 = [32, (3,3), (1,1), 'same']\nblock2 = [64, (3,3), (1,1), 'same']\nblock3 = [128, (3,3), (1,1), 'same']\nblock4 = [32, (3,3), (1,1), 'same']\n\n\nmodel = cnn(input_shape=input_shape, block1=block1, block2=block2, block3=block3, block4=block4)\n\nmodel.compile(optimizer=optimizer,\n             loss=loss,\n             metrics=metrics)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# spliting dataset \n\ntrain, test = train_test_split(data, test_size=0.30, random_state=42)\n\nprint('train shape: {} | test shape: {}'.format(train.shape, test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n\n\n### Data Augmentation \n\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train generator\n\ngenerator_train = ImageDataGenerator(horizontal_flip=True,\n                             rotation_range=15,\n                             shear_range=0.1,\n                             zoom_range=0.20, \n                             rescale=1./255,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1,                            \n                             )\n\n\n\ntrain_generator = generator_train.flow_from_dataframe(dataframe=train,\n                            x_col='path',\n                            y_col='label',                \n                            target_size=(image_size,image_size),\n                            color_mode='rgb',\n                            class_mode='binary',\n                            batch_size=150\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test generator \ngenerator_test= ImageDataGenerator(rescale=1./255)\n\n\ntest_generator = generator_test.flow_from_dataframe(dataframe=test,\n                            x_col='path',\n                            y_col='label',                \n                            target_size=(image_size,image_size),\n                            color_mode='rgb',\n                            class_mode='binary',\n                            batch_size=150\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n\nhistory = model.fit(train_generator, validation_data=test_generator,\n            epochs=50, \n            validation_steps=test.shape[0]//150,\n            steps_per_epoch=train.shape[0]//150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(test_generator, batch_size=150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation  \n\nepochs = [i for i in range(0,50)]\n\nfig, ax = plt.subplots(1,2, figsize=(14,5))\n\n\n# Loss \nax[0].plot(epochs, history.history['loss'], label='train loss')\nax[0].plot(epochs, history.history['val_loss'], label='train loss')\nax[0].set_xlabel('Epochs', fontsize=13)\nax[0].set_ylabel('Loss', fontsize=13)\nax[0].set_title('Loss CNN', fontsize=14)\n\n\n# Accuracy \nax[1].plot(epochs, history.history['accuracy'], label='train accuracy')\nax[1].plot(epochs, history.history['val_accuracy'], label='test accuracy')\nax[1].set_xlabel('Epochs', fontsize=13)\nax[1].set_ylabel('Loss', fontsize=13)\nax[1].set_title('Accuracy CNN', fontsize=14)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy: {} | Loss: {}'.format(accuracy, loss))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n\n## Transfer learning VGG-19 \n\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg19_model = VGG19(weights='imagenet', include_top=False, input_shape=(150,150,3))\n\n\n    \nfor layer in vgg19_model.layers[:15]:\n    layer.trainable = False\n\nfor layer in vgg19_model.layers[15:]:\n    layer.trainable = True\n    \n    \nlast_layer = vgg19_model.get_layer('block5_pool')\nlast_output = last_layer.output\n    \n\nx = GlobalMaxPooling2D()(last_output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(vgg19_model.input, x)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images, test_images = train_test_split(data, test_size=0.30, random_state=42)\n\ntotal_train = train_images.shape[0]\ntotal_test = test_images.shape[0]\n\nbatch_size=16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\n\n\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_images,  \n    x_col='path',\n    y_col='label',\n    class_mode='binary',\n    target_size=(224, 224),\n    batch_size=batch\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n\n\ntest_generator = test_datagen.flow_from_dataframe(\n    test_images,  \n    x_col='path',\n    y_col='label',\n    class_mode='binary',\n    target_size=(224, 224),\n    batch_size=batch\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n\nmodel.fit(train_generator, validation_data=test_generator,\n            epochs=20,\n            validation_steps=total_train//batch_size,\n            steps_per_epoch=total_test//batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(test_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_samples = test_images.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))\n\nthreshold = 0.5\ntest_images['category'] = np.argmax(predict, axis=-1) #alterar para -1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = test_images.copy()\nsubmission_df['id'] = submission_df['path'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['label']\nsubmission_df.drop(['path', 'label'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}