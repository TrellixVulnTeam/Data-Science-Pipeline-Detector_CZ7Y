{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cats v/s Dogs kernel rewritten for practice","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nimport PIL\nimport zipfile\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:42:59.959132Z","iopub.execute_input":"2021-06-24T14:42:59.959484Z","iopub.status.idle":"2021-06-24T14:42:59.965879Z","shell.execute_reply.started":"2021-06-24T14:42:59.959426Z","shell.execute_reply":"2021-06-24T14:42:59.964737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Global Variables","metadata":{}},{"cell_type":"code","source":"# Path to zip file\n\npath_to_train_zip = '../input/train.zip'\npath_to_test_zip = '../input/test1.zip'\ndirectory_to_extract = '.'\n\nBATCH_SIZE = 256\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nEPOCHS = 1\n\ntrain_imgs_path = './train'\ntest_imgs_path = './test1'\n\nlabel_map = {\n    'dog' : 1,\n    'cat' : 0\n}\n\ninverse_label_map = {\n    1 : 'dog',\n    0 : 'cat'\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:42:59.969985Z","iopub.execute_input":"2021-06-24T14:42:59.970224Z","iopub.status.idle":"2021-06-24T14:42:59.976452Z","shell.execute_reply.started":"2021-06-24T14:42:59.97018Z","shell.execute_reply":"2021-06-24T14:42:59.975654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract the data","metadata":{}},{"cell_type":"code","source":"with zipfile.ZipFile(path_to_train_zip, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract)\n    \nwith zipfile.ZipFile(path_to_test_zip, 'r') as zip_ref:\n    zip_ref.extractall(directory_to_extract)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:42:59.977813Z","iopub.execute_input":"2021-06-24T14:42:59.97852Z","iopub.status.idle":"2021-06-24T14:43:12.794002Z","shell.execute_reply.started":"2021-06-24T14:42:59.978469Z","shell.execute_reply":"2021-06-24T14:43:12.793261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dataLoader","metadata":{}},{"cell_type":"code","source":"class DVCLoader(torch.utils.data.Dataset):\n    def __init__(self, path_to_images, label_map, dim_img):\n        '''\n        Provide link to images directory in path_to_images\n        '''\n        super().__init__()\n        self.all_images = [f\"{path_to_images}/{img}\" for img in os.listdir(path_to_images)]\n        self.labels = [label.split('.')[0] for label in os.listdir(path_to_images)]\n        \n        self.length = len(self.all_images)\n        \n        self.label_map = label_map\n        self.transforms = torchvision.transforms.Compose([\n            torchvision.transforms.Resize((dim_img, dim_img)),\n            torchvision.transforms.ToTensor(),            \n            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n        \n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self, idx):\n        '''\n        Return PIL Image\n        '''\n        label_numeric = torch.tensor(self.label_map[self.labels[idx]], dtype = torch.float32)\n        img_pil = PIL.Image.open(self.all_images[idx])\n        img_final = self.transforms(img_pil)\n        return (img_final, label_numeric)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:43:12.795197Z","iopub.execute_input":"2021-06-24T14:43:12.795453Z","iopub.status.idle":"2021-06-24T14:43:12.805634Z","shell.execute_reply.started":"2021-06-24T14:43:12.79541Z","shell.execute_reply":"2021-06-24T14:43:12.804298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Splitting","metadata":{}},{"cell_type":"code","source":"a = DVCLoader(train_imgs_path, label_map, dim_img = 250)\ntrain_data, val_data = torch.utils.data.random_split(a, [15000, 10000])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:43:12.807373Z","iopub.execute_input":"2021-06-24T14:43:12.808013Z","iopub.status.idle":"2021-06-24T14:43:12.852469Z","shell.execute_reply.started":"2021-06-24T14:43:12.80775Z","shell.execute_reply":"2021-06-24T14:43:12.851697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"train_dl = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True, num_workers = 8, pin_memory=True)\nval_dl = torch.utils.data.DataLoader(val_data, batch_size = BATCH_SIZE, shuffle = True, num_workers = 8, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:43:12.853582Z","iopub.execute_input":"2021-06-24T14:43:12.853958Z","iopub.status.idle":"2021-06-24T14:43:12.85996Z","shell.execute_reply.started":"2021-06-24T14:43:12.853802Z","shell.execute_reply":"2021-06-24T14:43:12.859055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"class CVDClassifier(torch.nn.Module):\n    '''\n    cats v/s dogs\n    '''\n    def __init__(self):\n        super().__init__()\n        self.backbone = torchvision.models.squeezenet1_0(pretrained=True)\n        # outputs 1x1000 dimensional vector\n        self.out = torch.nn.Linear(1000, 1)\n        # just outputs the logits, loss optimizer handled separately\n        \n    def forward(self, img_tensor):\n        return self.out(self.backbone(img_tensor))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:43:12.861497Z","iopub.execute_input":"2021-06-24T14:43:12.861893Z","iopub.status.idle":"2021-06-24T14:43:12.875661Z","shell.execute_reply.started":"2021-06-24T14:43:12.861722Z","shell.execute_reply":"2021-06-24T14:43:12.874798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop Parameters","metadata":{}},{"cell_type":"code","source":"# set optimizer, loss, metric\nmodel = CVDClassifier()\nmodel = model.to(DEVICE)\nloss_function = torch.nn.BCEWithLogitsLoss(reduction = 'mean').cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:43:12.876545Z","iopub.execute_input":"2021-06-24T14:43:12.877604Z","iopub.status.idle":"2021-06-24T14:43:12.935363Z","shell.execute_reply.started":"2021-06-24T14:43:12.877548Z","shell.execute_reply":"2021-06-24T14:43:12.93469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # training loop\n# for epoch in range(EPOCHS):\n#     model.train()\n#     for batch_idx, (img, labels) in enumerate(train_dl):\n        \n#         labels = labels.cuda()\n        \n#         output = model(img.cuda())\n#         loss = loss_function(output, labels.view(-1, 1))\n        \n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n        \n#         # Validation\n#         if epoch % 5 == 0 and batch_idx % 5 == 0:\n#             with torch.no_grad():\n#                 model.eval()\n#                 img, label = next(iter(val_dl))\n#                 output = model(img.cuda())\n#                 loss = loss_function(output, labels.view(-1, 1).float())\n#                 print(f\"Loss EPOCH {epoch} BATCH {batch_idx} {loss.detach()}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:43:12.938196Z","iopub.execute_input":"2021-06-24T14:43:12.938407Z","iopub.status.idle":"2021-06-24T14:51:21.723557Z","shell.execute_reply.started":"2021-06-24T14:43:12.938361Z","shell.execute_reply":"2021-06-24T14:51:21.671001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission file","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame()\nid_col = []\nlabel_col = []\ntfs = torchvision.transforms.Compose([\n            torchvision.transforms.Resize((250, 250)),\n            torchvision.transforms.ToTensor(),            \n            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n\nmodel.eval()\n\nfor _img in os.listdir(test_imgs_path):\n    img_id = int(_img.split('.')[0])\n    img = PIL.Image.open(f\"{test_imgs_path}/{_img}\")\n    img_tensor = tfs(img)\n    with torch.no_grad():\n        pred = int(model(img_tensor.unsqueeze(0).cuda()) > 0.5)\n        \n    id_col.append(img_id)\n    label_col.append(pred)\n    \n    \n\n# Final Submission file\nsubmission['id'] = id_col\nsubmission['label'] = label_col\n\nSUBMISSION_IDENTIFIER = 'run_1_torch_squeezenet'\nsubmission.to_csv(f'submission_{SUBMISSION_IDENTIFIER}.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:52:01.295003Z","iopub.execute_input":"2021-06-24T14:52:01.295334Z","iopub.status.idle":"2021-06-24T14:53:40.780288Z","shell.execute_reply.started":"2021-06-24T14:52:01.295273Z","shell.execute_reply":"2021-06-24T14:53:40.779602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r ./train\n!rm -r ./test1","metadata":{"execution":{"iopub.status.busy":"2021-06-24T14:53:44.846383Z","iopub.execute_input":"2021-06-24T14:53:44.846687Z","iopub.status.idle":"2021-06-24T14:53:47.095765Z","shell.execute_reply.started":"2021-06-24T14:53:44.846636Z","shell.execute_reply":"2021-06-24T14:53:47.094699Z"},"trusted":true},"execution_count":null,"outputs":[]}]}