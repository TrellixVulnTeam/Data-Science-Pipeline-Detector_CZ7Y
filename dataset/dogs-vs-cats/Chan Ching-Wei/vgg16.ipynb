{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras.applications import VGG16\n\nconv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150,150,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_dataset_dir = '../input/train/train'\nbase_dir = '../data'\nif not os.path.isdir(base_dir): os.mkdir(base_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = os.path.join(base_dir,'train')\nif not os.path.isdir(train_dir): os.mkdir(train_dir)\ntest_dir = os.path.join(base_dir,'test')\nif not os.path.isdir(test_dir): os.mkdir(test_dir)\nvalidation_dir = os.path.join(base_dir,'validation')\nif not os.path.isdir(validation_dir): os.mkdir(validation_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats_dir = os.path.join(train_dir,'cats')\nif not os.path.isdir(train_cats_dir): os.mkdir(train_cats_dir)\n\ntrain_dogs_dir = os.path.join(train_dir,'dogs')\nif not os.path.isdir(train_dogs_dir): os.mkdir(train_dogs_dir)\n    \nvalidation_cats_dir = os.path.join(validation_dir,'cats')\nif not os.path.isdir(validation_cats_dir) : os.mkdir(validation_cats_dir)\nvalidation_dogs_dir = os.path.join(validation_dir,'dogs')\nif not os.path.isdir(validation_dogs_dir) : os.mkdir(validation_dogs_dir)\n\ntest_cats_dir = os.path.join(test_dir,'cats')\nif not os.path.isdir(test_cats_dir) : os.mkdir(test_cats_dir)\ntest_dogs_dir = os.path.join(test_dir,'dogs')\nif not os.path.isdir(test_dogs_dir) : os.mkdir(test_dogs_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showdir(path, depth):\n    if depth == 0:\n        print(\"root:[\" + path + \"]\")\n \n    for item in os.listdir(path):\n        if '.git' not in item:\n            print(\"|      \" * depth + \"|--\" + item)\n \n            newitem = os.path.join(path,item)\n            if os.path.isdir(newitem):\n                showdir(newitem, depth +1)\nshowdir(base_dir,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nfnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_cats_dir,fname)\n    shutil.copyfile(src,dst)   \nfnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_cats_dir,fname)\n    shutil.copyfile(src,dst)\nfnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_cats_dir,fname)\n    shutil.copyfile(src,dst)\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_dogs_dir,fname)\n    shutil.copyfile(src,dst)   \nfnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_dogs_dir,fname)\n    shutil.copyfile(src,dst)\nfnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_dogs_dir,fname)\n    shutil.copyfile(src,dst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ncats = pd.Series([len(os.listdir(train_cats_dir)),len(os.listdir(validation_cats_dir)),len(os.listdir(test_cats_dir))])\ndogs = pd.Series([len(os.listdir(train_dogs_dir)),len(os.listdir(validation_dogs_dir)),len(os.listdir(test_dogs_dir))])\ndf = pd.DataFrame({'Cats':cats,'Dogs':dogs})\ndf.index = ['Train','Validation','Test']\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 無法資料擴增的快速特徵提取"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_feature(directory, sample_cout):\n    features = np.zeros(shape=(sample_cout,4,4,512))\n    labels = np.zeros(shape=(sample_cout))\n    generator = datagen.flow_from_directory(directory,target_size=(150,150),batch_size=batch_size,class_mode='binary')\n    i = 0\n    \n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i*batch_size:(i+1)*batch_size] = features_batch\n        labels[i*batch_size:(i+1)*batch_size]   = labels_batch\n        i+=1\n        print(i,end='')\n        if i*batch_size >=sample_cout:\n            break\n    return features, labels\n\ntrain_features, train_labels = extract_feature(train_dir, 2000)\nvalidation_features, validation_labels = extract_feature(validation_dir,1000)\ntest_features, test_labels = extract_feature(test_dir, 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = np.reshape(train_features,(2000,-1))\nvalidation_features = np.reshape(validation_features,(1000,-1))\ntest_features = np.reshape(test_features,(1000,-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.optimizers import RMSprop\n\nmodel = Sequential()\nmodel.add(Dense(256,activation='relu',input_dim=4*4*512))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer=RMSprop(lr=2e-5),loss='binary_crossentropy',metrics=['acc'])\nhistory = model.fit(train_features,train_labels,epochs=30,batch_size=20,validation_data=(validation_features,validation_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef show_all(history):\n    def show(history,acc,val_acc,label):\n        epochs = range(1,31)\n        plt.plot(epochs,history.history[acc],label='Training '+label)\n        plt.plot(epochs,history.history[val_acc],label='Validation '+label)\n        plt.title('Training and Validation '+label)\n        plt.legend()\n    plt.figure(figsize=(15,5))\n    plt.subplot(121)\n    show(history,'acc','val_acc','acc')\n    plt.subplot(122)\n    show(history,'loss','val_loss','loss')\nshow_all(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 仍有Overfitting!\n> 從頭訓練，凍結VGG16層"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Flatten\nconv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150,150,3))\nmodel2 = Sequential()\nmodel2.add(conv_base)\nmodel2.add(Flatten())\nmodel2.add(Dense(256,activation='relu'))\nmodel2.add(Dense(1,activation='sigmoid'))\nmodel2.summary() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Here is the answer of the question why val acc > acc:\n* 這可能是不同 Keras 版本造成的問題 (在某些版本是正確的)，可以參考以下的討論：\n\n* https://github.com/fchollet/deep-learning-with-python-notebooks/issues/21\n\n\n* 這邊提供 2 種解法試試：\n\n1. 將 conv_base.trainable = False  註解掉。\n\n2. 餵給 VGG16 的圖片像素值不要壓到 0-1 之間，將 rescale=1./255 都註解掉，在程式 5.23 中做以下的修改：\n\n\n>from keras.applications.imagenet_utils import preprocess_input  # 新增這行\n\n>train_gen = ImageDataGenerator(\n> #     rescale=1.0/255,      # 註解這行\n    preprocessing_function=preprocess_input, # 新增這行\n    height_shift_range=0.2,\n    width_shift_range=0.2,\n    zoom_range=0.2,\n    shear_range=0.2,\n    rotation_range=40,\n    horizontal_flip=True,\n    fill_mode='nearest'\n )\n\n>#test_datagen = ImageDataGenerator(1./255)      # 註解這行\n>test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) # 新增這行"},{"metadata":{"trusted":true},"cell_type":"code","source":"#conv_base.trainable = False # Very important","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode='binary')\nvalidation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode='binary')\n\nmodel2.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=2e-5),metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_2 = model2.fit_generator(train_generator,\n                                steps_per_epoch=100,\n                                epochs=30,\n                                validation_data=validation_generator,\n                                validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_all(history_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 兩種方法的比較圖"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Quick Feature Extraction:cannot Data Augmentation')\nshow_all(history)\nprint('Quick Feature Extraction:Data Augmentation')\nshow_all(history_2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}