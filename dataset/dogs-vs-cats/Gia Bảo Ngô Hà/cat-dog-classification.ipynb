{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-05T01:41:49.220715Z","iopub.execute_input":"2021-08-05T01:41:49.221158Z","iopub.status.idle":"2021-08-05T01:41:49.237183Z","shell.execute_reply.started":"2021-08-05T01:41:49.221071Z","shell.execute_reply":"2021-08-05T01:41:49.236297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nfrom random import shuffle\nfrom time import time\n# tensorboard --logdir=logs/ --host localhost --port 8088\n\nprint(f'TensorFlow Version - {tf.__version__}')\nprint(f'Keras Version - {tf.keras.__version__}')","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:41:49.238751Z","iopub.execute_input":"2021-08-05T01:41:49.239086Z","iopub.status.idle":"2021-08-05T01:41:55.556745Z","shell.execute_reply.started":"2021-08-05T01:41:49.239057Z","shell.execute_reply":"2021-08-05T01:41:55.555596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile as zf\ntrain_zip = zf('/kaggle/input/dogs-vs-cats/train.zip', 'r')\ntrain_zip.extractall()\ntrain_zip.close()\ntest_zip = zf('/kaggle/input/dogs-vs-cats/test1.zip', 'r')\ntest_zip.extractall()\ntest_zip.close()\nIMG_SIZE = 50\nLR = 0.0003\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:41:55.558843Z","iopub.execute_input":"2021-08-05T01:41:55.55912Z","iopub.status.idle":"2021-08-05T01:42:14.619332Z","shell.execute_reply.started":"2021-08-05T01:41:55.559094Z","shell.execute_reply":"2021-08-05T01:42:14.618549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = 'cat_and_dog_LR-{}_MODEL-{}.h5'.format(LR,'CovNet-128(2)-64(2)-32(2)-512-128-1')\nMODEL_PATH = os.path.join('saved_models',MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:14.620707Z","iopub.execute_input":"2021-08-05T01:42:14.621175Z","iopub.status.idle":"2021-08-05T01:42:14.625097Z","shell.execute_reply.started":"2021-08-05T01:42:14.621118Z","shell.execute_reply":"2021-08-05T01:42:14.624044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = './train/'\nTEST_DIR = './test1/'","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:14.626556Z","iopub.execute_input":"2021-08-05T01:42:14.626954Z","iopub.status.idle":"2021-08-05T01:42:14.638718Z","shell.execute_reply.started":"2021-08-05T01:42:14.626915Z","shell.execute_reply":"2021-08-05T01:42:14.637758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(saved=True):\n    '''\n        Return the model\n    '''\n    if os.path.isfile(MODEL_PATH) and saved :\n        print(\"Loading saved model {}\".format(MODEL_NAME))\n        return load_model(MODEL_PATH)\n    \n    # Declaring model\n    model = Sequential()\n\n    # 1st Block\n    model.add(Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 1),filters=128, kernel_size=5, strides=1,padding='same',name = 'block1_conv1'))\n    model.add(Conv2D(filters=128, kernel_size=5, strides=1,padding='same',name = 'block1_conv2'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'block1_mxPool'))\n\n    # 2nd Block\n    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'block2_conv1'))\n    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'block2_conv2'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'block2_mxPool'))\n    \n    # 3rd Block\n    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv1'))\n    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv2'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'block3_mxPool'))\n\n    # 4th Block - FC Block\n    dr_rate = 0.35\n    model.add(Flatten(name = 'block4_flatten'))\n    model.add(Dropout(dr_rate,name = 'block4_droupout1'))\n    model.add(Dense(512, activation='relu',name = 'block4_dense1'))\n    model.add(Dropout(dr_rate,name = 'block4_droupout2'))\n    model.add(Dense(128, activation='relu',name = 'block4_dense2'))\n    model.add(Dropout(dr_rate,name = 'block4_droupout3'))\n    model.add(Dense(1, activation='sigmoid',name = 'block4_dense3'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:14.639918Z","iopub.execute_input":"2021-08-05T01:42:14.640282Z","iopub.status.idle":"2021-08-05T01:42:14.654793Z","shell.execute_reply.started":"2021-08-05T01:42:14.640253Z","shell.execute_reply":"2021-08-05T01:42:14.653785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label(img):\n    '''\n        Return the label for images\n    '''\n    word = img.split('.')[0]\n    if word == 'cat':\n        return [0]\n    else:\n        return [1]","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:14.656132Z","iopub.execute_input":"2021-08-05T01:42:14.656548Z","iopub.status.idle":"2021-08-05T01:42:14.664914Z","shell.execute_reply.started":"2021-08-05T01:42:14.656517Z","shell.execute_reply":"2021-08-05T01:42:14.663991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_training_data():\n    '''\n        Return training data\n    '''\n    training_data = []\n    if os.path.isfile('training_data_{}.npy'.format(IMG_SIZE)):\n        return np.load('training_data_{}.npy'.format(IMG_SIZE))\n    else:\n        for img in tqdm(os.listdir(TRAIN_DIR)):\n            label = get_label(img)\n            path = os.path.join(TRAIN_DIR,img)\n            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n            img = img/255\n            training_data.append([np.array(img),np.array(label)])\n        shuffle(training_data)\n        np.save('training_data_{}.npy'.format(IMG_SIZE),training_data)\n        return np.array(training_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:14.667449Z","iopub.execute_input":"2021-08-05T01:42:14.667803Z","iopub.status.idle":"2021-08-05T01:42:14.675763Z","shell.execute_reply.started":"2021-08-05T01:42:14.667774Z","shell.execute_reply":"2021-08-05T01:42:14.674867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_testing_data():\n    '''\n        Return testing data\n    '''\n    testing_data = []\n    if os.path.isfile('testing_data_{}.npy'.format(IMG_SIZE)):\n        return np.load('testing_data_{}.npy'.format(IMG_SIZE))\n    else:\n        for img in tqdm(os.listdir(TEST_DIR)):\n            img_id = int(img.split('.')[0])\n            path = os.path.join(TEST_DIR,img)\n            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n            img = img/255\n            testing_data.append([np.array(img),img_id])\n        testing_data.sort(key = lambda x: x[1])\n        np.save('testing_data_{}.npy'.format(IMG_SIZE),testing_data)\n        return np.array(testing_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:14.677218Z","iopub.execute_input":"2021-08-05T01:42:14.677593Z","iopub.status.idle":"2021-08-05T01:42:14.690861Z","shell.execute_reply.started":"2021-08-05T01:42:14.677564Z","shell.execute_reply":"2021-08-05T01:42:14.690046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparation","metadata":{}},{"cell_type":"code","source":"data = get_training_data()\n\npartition = 1000             # Breaking -ve index\ntrain = data[:-partition]    # For Training purpose\ntest= data[-partition:]      # For Validation purpose\n\n# Training set\nX_train = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\ny_train = np.array([i[1] for i in train])\n\n# Validation set\nX_val = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\ny_val = np.array([i[1] for i in test])","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:14.692177Z","iopub.execute_input":"2021-08-05T01:42:14.692573Z","iopub.status.idle":"2021-08-05T01:42:42.515006Z","shell.execute_reply.started":"2021-08-05T01:42:14.692544Z","shell.execute_reply":"2021-08-05T01:42:42.514021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Effects added on image\n    Rotation - ± 50 deegrees,\n    Width Shift - ± 15 %\n    Height Shift - ± 15 %\n    Zoom - 30%\n    Horizontal Flip\n    Vertical Flip\n'''\ndatagen = ImageDataGenerator(rotation_range=20,width_shift_range=0.05,height_shift_range=0.05,\n                            zoom_range=0.05,horizontal_flip=True,vertical_flip=False)\n\n# Calculation of necessary internal data for all images.\ndatagen.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:42.516499Z","iopub.execute_input":"2021-08-05T01:42:42.516881Z","iopub.status.idle":"2021-08-05T01:42:42.754083Z","shell.execute_reply.started":"2021-08-05T01:42:42.516842Z","shell.execute_reply":"2021-08-05T01:42:42.753192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:42.755602Z","iopub.execute_input":"2021-08-05T01:42:42.756029Z","iopub.status.idle":"2021-08-05T01:42:42.969706Z","shell.execute_reply.started":"2021-08-05T01:42:42.755987Z","shell.execute_reply":"2021-08-05T01:42:42.968514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimizer (Adam Optimizer)\nadam = Adam(lr = LR)\n\n# Callbacks Declared\ntensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),batch_size=BATCH_SIZE)\n# Supported in new version of keras ,update_freq='epoch')\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.3,patience=3,verbose=1,\n                              mode='max', min_lr=0.000001)\nearly_stop = EarlyStopping(monitor='val_loss',patience=3,verbose=1,mode='min')\n# Supported in new version of keras ,restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint(filepath=MODEL_PATH,monitor='val_acc',verbose=1,save_best_only=True,\n                                  mode='max',period=3)\n\nmodel.compile(optimizer = adam,loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:42.972867Z","iopub.execute_input":"2021-08-05T01:42:42.973159Z","iopub.status.idle":"2021-08-05T01:42:42.997776Z","shell.execute_reply.started":"2021-08-05T01:42:42.973131Z","shell.execute_reply":"2021-08-05T01:42:42.996639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Toggle if dont want to train using Image Augmentation\ngenerator_train = True\nEPOCHS = 30\ncallbacks=[tensorboard,reduce_lr,early_stop,model_checkpoint]\n\nif generator_train:\n    print(f'Training model {MODEL_NAME} using Image Augmentation')\n    hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=BATCH_SIZE),\n                               steps_per_epoch=len(X_train)//BATCH_SIZE,epochs=EPOCHS,verbose=2,\n                               validation_data=(X_val,y_val),callbacks=callbacks)\nelse:\n    print(f'Training model {MODEL_NAME} using normal image data provided')\n    hist = model.fit(X_train,y_train,epochs=EPOCHS,batch_size=BATCH_SIZE,validation_data=(X_val,y_val),\n                     verbose=2,callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T01:42:42.999004Z","iopub.execute_input":"2021-08-05T01:42:42.99929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"test_data = get_testing_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\nids = [i[1] for i in test_data]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}