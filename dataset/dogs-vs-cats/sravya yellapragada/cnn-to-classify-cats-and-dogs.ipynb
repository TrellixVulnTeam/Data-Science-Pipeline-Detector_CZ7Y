{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-27T15:09:14.329165Z","iopub.execute_input":"2021-06-27T15:09:14.329517Z","iopub.status.idle":"2021-06-27T15:09:14.339053Z","shell.execute_reply.started":"2021-06-27T15:09:14.329482Z","shell.execute_reply":"2021-06-27T15:09:14.337851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:09:18.081156Z","iopub.execute_input":"2021-06-27T15:09:18.081503Z","iopub.status.idle":"2021-06-27T15:09:18.087245Z","shell.execute_reply.started":"2021-06-27T15:09:18.081472Z","shell.execute_reply":"2021-06-27T15:09:18.086127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracting training data\nlocal_zip = '/kaggle/input/dogs-vs-cats/train.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('/kaggle/working/dogs-vs-cats/')\nzip_ref.close()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:09:23.441665Z","iopub.execute_input":"2021-06-27T15:09:23.442049Z","iopub.status.idle":"2021-06-27T15:09:37.694995Z","shell.execute_reply.started":"2021-06-27T15:09:23.441992Z","shell.execute_reply":"2021-06-27T15:09:37.693982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train set has label in image name i.e cat.jpg or dog.jpg\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/working/dogs-vs-cats/train'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:09:50.627168Z","iopub.execute_input":"2021-06-27T15:09:50.627747Z","iopub.status.idle":"2021-06-27T15:09:50.679099Z","shell.execute_reply.started":"2021-06-27T15:09:50.627676Z","shell.execute_reply":"2021-06-27T15:09:50.677933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extracting testing data\nlocal_zip1 = '/kaggle/input/dogs-vs-cats/test1.zip'\nzip_ref1 = zipfile.ZipFile(local_zip1, 'r')\nzip_ref1.extractall('/kaggle/working/dogs-vs-cats/')\nzip_ref1.close()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:09:56.396123Z","iopub.execute_input":"2021-06-27T15:09:56.396846Z","iopub.status.idle":"2021-06-27T15:10:04.029822Z","shell.execute_reply.started":"2021-06-27T15:09:56.396781Z","shell.execute_reply":"2021-06-27T15:10:04.028819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test set didnot have any label in image name i.e cat or dog\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/working/dogs-vs-cats/test1'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:11:05.306728Z","iopub.execute_input":"2021-06-27T15:11:05.307122Z","iopub.status.idle":"2021-06-27T15:11:05.328089Z","shell.execute_reply.started":"2021-06-27T15:11:05.307087Z","shell.execute_reply":"2021-06-27T15:11:05.326965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#length of train set and test set\nprint(len(os.listdir('/kaggle/working/dogs-vs-cats/train')))\nprint(len(os.listdir('/kaggle/working/dogs-vs-cats/test1')))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:11:12.672399Z","iopub.execute_input":"2021-06-27T15:11:12.672768Z","iopub.status.idle":"2021-06-27T15:11:12.699287Z","shell.execute_reply.started":"2021-06-27T15:11:12.672738Z","shell.execute_reply":"2021-06-27T15:11:12.698326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filter out cats and dogs to seperate folders in trainset\ntry:\n    os.mkdir('/kaggle/working/dogs-vs-cats/train/cat')\n    os.mkdir('/kaggle/working/dogs-vs-cats/train/dog')\nexcept OSError:\n    pass\ncat_dir = '/kaggle/working/dogs-vs-cats/train/cat'\ndog_dir = '/kaggle/working/dogs-vs-cats/train/dog'\ncdfilenames = []\nfor dirname, _, filenames in os.walk('/kaggle/working/dogs-vs-cats/train'):\n    for filename in filenames:\n        #print(filename)\n        if(filename not in cdfilenames):\n            if(\"cat\" in filename):\n                #print(((os.path.join(dirname, filename)),(os.path.join(cat_dir,filename))))\n                copyfile((os.path.join(dirname, filename)),(os.path.join(cat_dir,filename)))\n            elif(\"dog\" in filename):\n                #print((os.path.join(dirname, filename)),(os.path.join(dog_dir,filename)))\n                copyfile((os.path.join(dirname, filename)),(os.path.join(dog_dir,filename)))\n            cdfilenames.append(filename)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:11:16.032809Z","iopub.execute_input":"2021-06-27T15:11:16.033159Z","iopub.status.idle":"2021-06-27T15:11:31.48727Z","shell.execute_reply.started":"2021-06-27T15:11:16.033128Z","shell.execute_reply":"2021-06-27T15:11:31.486479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir('/kaggle/working/dogs-vs-cats/train/cat/')))\nprint(len(os.listdir('/kaggle/working/dogs-vs-cats/train/dog/')))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:11:56.307302Z","iopub.execute_input":"2021-06-27T15:11:56.307823Z","iopub.status.idle":"2021-06-27T15:11:56.325906Z","shell.execute_reply.started":"2021-06-27T15:11:56.30779Z","shell.execute_reply":"2021-06-27T15:11:56.324803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dirs = [\n    '/kaggle/working/cats-v-dogs',\n    '/kaggle/working/cats-v-dogs/training',\n    '/kaggle/working/cats-v-dogs/validation',\n    '/kaggle/working/cats-v-dogs/training/cats',\n    '/kaggle/working/cats-v-dogs/training/dogs',\n    '/kaggle/working/cats-v-dogs/validation/cats',\n    '/kaggle/working/cats-v-dogs/validation/dogs'\n]\nfor d in dirs:\n    try:\n        os.mkdir(d)\n        print(\"Created \"+d+\" successfully\")\n        #YOUR CODE GOES HERE\n    except OSError:\n        print(\"Failed to create \" + d)\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:11:59.010095Z","iopub.execute_input":"2021-06-27T15:11:59.010467Z","iopub.status.idle":"2021-06-27T15:11:59.019125Z","shell.execute_reply.started":"2021-06-27T15:11:59.010435Z","shell.execute_reply":"2021-06-27T15:11:59.017947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split some part of traindata into validation set\ndef split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n    all_files = []\n    \n    for file_name in os.listdir(SOURCE):\n        file_path = SOURCE + file_name\n\n        if os.path.getsize(file_path):\n            all_files.append(file_name)\n        else:\n            print('{} is zero length, so ignoring'.format(file_name))\n    \n    n_files = len(all_files)\n    split_point = int(n_files * SPLIT_SIZE)\n    \n    shuffled = random.sample(all_files, n_files)\n    \n    train_set = shuffled[:split_point]\n    test_set = shuffled[split_point:]\n    \n    for file_name in train_set:\n        copyfile(SOURCE + file_name, TRAINING + file_name)\n        \n    for file_name in test_set:\n        copyfile(SOURCE + file_name, TESTING + file_name)\n\n\nCAT_SOURCE_DIR = \"/kaggle/working/dogs-vs-cats/train/cat/\"\nTRAINING_CATS_DIR = \"/kaggle/working/cats-v-dogs/training/cats/\"\nTESTING_CATS_DIR = \"/kaggle/working/cats-v-dogs/validation/cats/\"\nDOG_SOURCE_DIR = \"/kaggle/working/dogs-vs-cats/train/dog/\"\nTRAINING_DOGS_DIR = \"/kaggle/working/cats-v-dogs/training/dogs/\"\nTESTING_DOGS_DIR = \"/kaggle/working/cats-v-dogs/validation/dogs/\"\n\nsplit_size = .9\nsplit_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\nsplit_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:12:07.940254Z","iopub.execute_input":"2021-06-27T15:12:07.940758Z","iopub.status.idle":"2021-06-27T15:12:10.652741Z","shell.execute_reply.started":"2021-06-27T15:12:07.94071Z","shell.execute_reply":"2021-06-27T15:12:10.652034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir('/kaggle/working/cats-v-dogs/training/cats/')))\nprint(len(os.listdir('/kaggle/working/cats-v-dogs/training/dogs/')))\nprint(len(os.listdir('/kaggle/working/cats-v-dogs/validation/cats/')))\nprint(len(os.listdir('/kaggle/working/cats-v-dogs/validation/dogs/')))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:12:15.85591Z","iopub.execute_input":"2021-06-27T15:12:15.856493Z","iopub.status.idle":"2021-06-27T15:12:15.878154Z","shell.execute_reply.started":"2021-06-27T15:12:15.856444Z","shell.execute_reply":"2021-06-27T15:12:15.877155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KERAS MODEL TO CLASSIFY CATS V DOGS\n# 3 CONVOLUTION LAYERS\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(1, activation='sigmoid') \n])\n\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:12:22.546979Z","iopub.execute_input":"2021-06-27T15:12:22.54734Z","iopub.status.idle":"2021-06-27T15:12:22.698143Z","shell.execute_reply.started":"2021-06-27T15:12:22.547311Z","shell.execute_reply":"2021-06-27T15:12:22.697143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAINING_DIR = '/kaggle/working/cats-v-dogs/training/'\ntrain_datagen = ImageDataGenerator( rescale = 1.0/255. )\n\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))\n\nVALIDATION_DIR = '/kaggle/working/cats-v-dogs/validation/'\nvalidation_datagen = ImageDataGenerator( rescale = 1.0/255. )\n\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                         batch_size=20,\n                                                         class_mode  = 'binary',\n                                                         target_size = (150, 150))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:12:29.902165Z","iopub.execute_input":"2021-06-27T15:12:29.902539Z","iopub.status.idle":"2021-06-27T15:12:30.509072Z","shell.execute_reply.started":"2021-06-27T15:12:29.902508Z","shell.execute_reply":"2021-06-27T15:12:30.508171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,\n                    epochs=5,\n                    verbose=1,\n                    validation_data=validation_generator)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:12:36.589111Z","iopub.execute_input":"2021-06-27T15:12:36.589632Z","iopub.status.idle":"2021-06-27T15:41:05.554162Z","shell.execute_reply.started":"2021-06-27T15:12:36.589596Z","shell.execute_reply":"2021-06-27T15:41:05.553086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLOTTING LOSS AND ACCURACY\n%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\n\nplt.title('Training and validation loss')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:41:33.927537Z","iopub.execute_input":"2021-06-27T15:41:33.928074Z","iopub.status.idle":"2021-06-27T15:41:34.217106Z","shell.execute_reply.started":"2021-06-27T15:41:33.928022Z","shell.execute_reply":"2021-06-27T15:41:34.216119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting images in testset\n%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.preprocessing import image\n\ncount = 10\nfor dirname, _, filenames in os.walk('/kaggle/working/dogs-vs-cats/test1'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        # predicting images\n        path = os.path.join(dirname, filename)\n        img = image.load_img(path, target_size=(150, 150))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        img = mpimg.imread(path)\n        plt.imshow(img)\n        plt.show()\n        images = np.vstack([x])\n        classes = model.predict(images, batch_size=10)\n        if classes[0]>0.5:\n            print(filename + \" is a dog\")\n        else:\n            print(filename + \" is a cat\")\n        print(\"--\"*30)\n        count -= 1\n        if(count < 0):\n            break","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:44:42.459797Z","iopub.execute_input":"2021-06-27T15:44:42.460242Z","iopub.status.idle":"2021-06-27T15:44:45.626893Z","shell.execute_reply.started":"2021-06-27T15:44:42.460169Z","shell.execute_reply":"2021-06-27T15:44:45.625694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transfer learning using Inception v3\n# Download the inception v3 weights\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\n# Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Create an instance of the inception model from the local pre-trained weights\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(\n    input_shape=(150, 150, 3),\n    include_top=False,\n    weights=None\n)\n\npre_trained_model.load_weights(local_weights_file)\n\n# Make all the layers in the pre-trained model non-trainable\nfor layer in pre_trained_model.layers:\n    layer.trainable = False\n\n# Print the model summary\npre_trained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:08:37.423988Z","iopub.execute_input":"2021-06-27T15:08:37.424654Z","iopub.status.idle":"2021-06-27T15:08:47.699265Z","shell.execute_reply.started":"2021-06-27T15:08:37.424563Z","shell.execute_reply":"2021-06-27T15:08:47.698434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:45:58.031964Z","iopub.execute_input":"2021-06-27T15:45:58.032359Z","iopub.status.idle":"2021-06-27T15:45:58.039125Z","shell.execute_reply.started":"2021-06-27T15:45:58.032324Z","shell.execute_reply":"2021-06-27T15:45:58.037898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import RMSprop\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1, activation='sigmoid')(x)           \n\nmodel1 = Model(pre_trained_model.input, x) \n\nmodel1.compile(\n    optimizer=RMSprop(lr=0.0001), \n    loss='binary_crossentropy', \n    metrics=['accuracy']\n)\n\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:49:26.225124Z","iopub.execute_input":"2021-06-27T15:49:26.225626Z","iopub.status.idle":"2021-06-27T15:49:26.805838Z","shell.execute_reply.started":"2021-06-27T15:49:26.22559Z","shell.execute_reply":"2021-06-27T15:49:26.804859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAINING_DIR = '/kaggle/working/cats-v-dogs/training/'\nVALIDATION_DIR = '/kaggle/working/cats-v-dogs/validation/'\n\n# ImageDataGenerator to do Image Augmentation\ntrain_datagen1 = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n    )\n\nvalidation_datagen1 = ImageDataGenerator(rescale=1 / 255)\n\ntrain_generator1 = train_datagen1.flow_from_directory(TRAINING_DIR,\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))\n\nvalidation_generator1 = validation_datagen1.flow_from_directory(VALIDATION_DIR,\n                                                         batch_size=20,\n                                                         class_mode  = 'binary',\n                                                         target_size = (150, 150))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:56:23.575791Z","iopub.execute_input":"2021-06-27T15:56:23.576221Z","iopub.status.idle":"2021-06-27T15:56:24.136055Z","shell.execute_reply.started":"2021-06-27T15:56:23.576182Z","shell.execute_reply":"2021-06-27T15:56:24.134968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.999):\n            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n            self.model.stop_training = True\n        \ncallbacks = myCallback()\nhistory1 = model1.fit_generator(\n    train_generator1,\n    epochs=5,\n    validation_data=validation_generator1,\n    callbacks=[callbacks]\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T16:20:37.386156Z","iopub.execute_input":"2021-06-27T16:20:37.386579Z","iopub.status.idle":"2021-06-27T17:32:34.857814Z","shell.execute_reply.started":"2021-06-27T16:20:37.386543Z","shell.execute_reply":"2021-06-27T17:32:34.856594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLOTTING LOSS AND ACCURACY\n%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history1.history['accuracy']\nval_acc=history1.history['val_accuracy']\nloss=history1.history['loss']\nval_loss=history1.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\n\nplt.title('Training and validation loss')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:40:42.155409Z","iopub.execute_input":"2021-06-27T17:40:42.156251Z","iopub.status.idle":"2021-06-27T17:40:42.411559Z","shell.execute_reply.started":"2021-06-27T17:40:42.156178Z","shell.execute_reply":"2021-06-27T17:40:42.410252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting images in testset\n%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.preprocessing import image\n\ncount = 10\nfor dirname, _, filenames in os.walk('/kaggle/working/dogs-vs-cats/test1'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        # predicting images\n        path = os.path.join(dirname, filename)\n        img = image.load_img(path, target_size=(150, 150))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        img = mpimg.imread(path)\n        plt.imshow(img)\n        plt.show()\n        images = np.vstack([x])\n        classes = model1.predict(images, batch_size=10)\n        if classes[0]>0.5:\n            print(filename + \" is a dog\")\n        else:\n            print(filename + \" is a cat\")\n        print(\"--\"*30)\n        count -= 1\n        if(count < 0):\n            break","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:41:49.90949Z","iopub.execute_input":"2021-06-27T17:41:49.909872Z","iopub.status.idle":"2021-06-27T17:41:54.049048Z","shell.execute_reply.started":"2021-06-27T17:41:49.909838Z","shell.execute_reply":"2021-06-27T17:41:54.047413Z"},"trusted":true},"execution_count":null,"outputs":[]}]}