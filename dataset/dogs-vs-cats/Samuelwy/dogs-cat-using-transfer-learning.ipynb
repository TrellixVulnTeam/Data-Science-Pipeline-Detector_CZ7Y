{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nimport zipfile\nfrom shutil import copyfile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to delete files or folder\n'''import shutil\nshutil.rmtree(\"/kaggle/working/test1\")'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list files in input directory\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Unzipped and extract files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract all training images\nwith zipfile.ZipFile(\"../input/dogs-vs-cats/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n\n# extract all testing images\nwith zipfile.ZipFile(\"../input/dogs-vs-cats/test1.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of training images : ',len(os.listdir(\"/kaggle/working/train\")))\nprint('Number of testing images : ',len(os.listdir(\"/kaggle/working/test1\")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"/kaggle/working/train\")[:3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create training and validation directories and its subdirectories","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"/kaggle/working/training/\")\nos.mkdir(\"/kaggle/working/validation/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"/kaggle/working/training/dogs\")\nos.mkdir(\"/kaggle/working/validation/dogs\")\nos.mkdir(\"/kaggle/working/training/cats\")\nos.mkdir(\"/kaggle/working/validation/cats\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/working/training/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/working/validation/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# shuffle -> split into train and validation -> copy into subdirectories","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def shuffle_split(source, split):\n    n = len(os.listdir(source))\n    inputfiles = np.array(os.listdir(source))\n    np.random.shuffle(inputfiles)\n    print(len(inputfiles))\n    split_index = int(n*split)\n    training, validation = inputfiles[:split_index], inputfiles[split_index:]\n    print(len(training), len(validation))\n    return training, validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def copy_file(source,training, validation, split):\n    tr, va = shuffle_split(source, split) # shuffle and split files into training and validation\n    # training\n    for filename in tr:\n        filename_split = filename.split('.')[0]\n        if filename_split == 'cat':\n            copyfile(source+filename, training + 'cats/' + filename)\n        else:\n            copyfile(source+filename, training + 'dogs/' + filename)\n    # validation\n    for filename in va:\n        filename_split = filename.split('.')[0]\n        if filename_split == 'cat':\n            copyfile(source+filename, validation + 'cats/' + filename)\n        else:\n            copyfile(source+filename,validation + 'dogs/' + filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAINING_DIR = '/kaggle/working/training/'\nVALIDATION_DIR = '/kaggle/working/validation/'\nTRAIN_SOURCE = '/kaggle/working/train/'\n\ncopy_file(TRAIN_SOURCE, TRAINING_DIR, VALIDATION_DIR,0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dir in [TRAINING_DIR,VALIDATION_DIR]:\n    for sub in ['cats','dogs']:\n        print(sub,len(os.listdir(dir+sub)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\npretrained_model = InceptionV3(input_shape = (150, 150, 3), include_top = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in pretrained_model.layers:\n    layer.trainable = False # freeze or lock the underlying layers\n\npretrained_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = pretrained_model.get_layer('mixed7')\n\nlast_output = last_layer.output\nprint(last_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n\n# Take the last output layer and pass it through a DNN\nx = layers.Flatten()(last_output)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = Model(pretrained_model.input, x)\nmodel.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# data augmentation for training images\ntrain_datagen = ImageDataGenerator(\trescale=1./255,\n    rotation_range=40, # rotate image\n    width_shift_range=0.2, # move image left or right\n    height_shift_range=0.2, # move image up or down\n    shear_range=0.2, # skew image\n    zoom_range=0.2, # zoom in on image\n    horizontal_flip=True, # flip image on horizontal\n    fill_mode='nearest') # normalize the data\n\ntrain_generator = train_datagen.flow_from_directory( \n    TRAINING_DIR,\n    target_size = (150,150), \n    batch_size = 128, \n    class_mode = 'binary')\n\nvalidation_datagen = ImageDataGenerator(rescale = 1./255)\n\nvalidation_generator = validation_datagen.flow_from_directory( \n    VALIDATION_DIR, \n    target_size = (150,150), \n    batch_size = 32, \n    class_mode = 'binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping\n\nearlystopping = EarlyStopping(patience = 2)\nhistory = model.fit(train_generator, \n          steps_per_epoch= 20000//128, \n          epochs = 3, \n          validation_data=validation_generator, \n          validation_steps=5000//32, \n          callbacks = [earlystopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot the history of our model\n\nimport matplotlib.pyplot as plt\n# Get the different results\nacc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(len(acc))\n\n# Plot the training and validation accuracy per epoch\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title(\"Training and validation accuracy\")\nplt.figure()\n\n# Plot the training and validation loss per epoch\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title(\"Training and validation loss\")\nplt.figure()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate on test images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('/kaggle/working/testing/')\nos.mkdir('/kaggle/working/testing/cats/')\nos.mkdir('/kaggle/working/testing/dogs/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def testfiles(source, output):\n    for filename in os.listdir(source):\n        if filename.split('.')[0] == 'cat':\n            copyfile(source+filename, output+'cats/'+filename)\n        else:\n            copyfile(source+filename, output+'dogs/'+filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testfiles('/kaggle/working/test1/','/kaggle/working/testing/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_datagen = ImageDataGenerator(rescale = 1./255)\n\ntesting_generator = testing_datagen.flow_from_directory( \n    '/kaggle/working/testing/', \n    target_size = (150,150), \n    batch_size = 128, \n    class_mode = 'binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(testing_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save model for future use","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('./model_inceptions1.h5') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}