{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nimport numpy as np \nimport pandas as pd \nimport zipfile\nimport matplotlib.pyplot as plt\nimport os\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:20.594959Z","iopub.execute_input":"2021-06-05T05:20:20.595358Z","iopub.status.idle":"2021-06-05T05:20:25.527315Z","shell.execute_reply.started":"2021-06-05T05:20:20.595275Z","shell.execute_reply":"2021-06-05T05:20:25.526472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.unpack_archive('../input/dogs-vs-cats/train.zip','./')\nshutil.unpack_archive('../input/dogs-vs-cats/test1.zip','./')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:25.528704Z","iopub.execute_input":"2021-06-05T05:20:25.529029Z","iopub.status.idle":"2021-06-05T05:20:42.40303Z","shell.execute_reply.started":"2021-06-05T05:20:25.528992Z","shell.execute_reply":"2021-06-05T05:20:42.402037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another way of unzipping files is :","metadata":{}},{"cell_type":"code","source":"#with zipfile.ZipFile(\"../input/dogs-vs-cats/train.zip\", 'r') as zip_ref:\n                #zip_ref.extractall(\"./\")\n\n#with zipfile.ZipFile(\"../input/dogs-vs-cats/test1.zip\", 'r') as zip_ref:\n                #zip_ref.extractall(\"./\")","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:42.404769Z","iopub.execute_input":"2021-06-05T05:20:42.405272Z","iopub.status.idle":"2021-06-05T05:20:42.409159Z","shell.execute_reply.started":"2021-06-05T05:20:42.405229Z","shell.execute_reply":"2021-06-05T05:20:42.408162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total train images\")\nprint(len([files for files in os.listdir('./train') if os.path.isfile(os.path.join('./train', files))]))\nprint(\"Total test images\")\nprint(len([files for files in os.listdir('./test1') if os.path.isfile(os.path.join('./test1', files))]))","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:42.410667Z","iopub.execute_input":"2021-06-05T05:20:42.411178Z","iopub.status.idle":"2021-06-05T05:20:42.616905Z","shell.execute_reply.started":"2021-06-05T05:20:42.411141Z","shell.execute_reply":"2021-06-05T05:20:42.616129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total no of cat images in train dataset:\")\nprint(len([files for files in os.listdir('./train') if os.path.isfile(os.path.join('./train', files)) and 'cat' in files]))\nprint(\"Total no of dog images in train dataset:\")\nprint(len([files for files in os.listdir('./train') if os.path.isfile(os.path.join('./train', files)) and 'dog' in files]))","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:42.618093Z","iopub.execute_input":"2021-06-05T05:20:42.61858Z","iopub.status.idle":"2021-06-05T05:20:42.885605Z","shell.execute_reply.started":"2021-06-05T05:20:42.618542Z","shell.execute_reply":"2021-06-05T05:20:42.884818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total no of cat images in test dataset:\")\nprint(len([files for files in os.listdir('./test1') if os.path.isfile(os.path.join('./test1', files)) and 'cat' in files]))\nprint(\"Total no of dog images in test dataset:\")\nprint(len([files for files in os.listdir('./test1') if os.path.isfile(os.path.join('./test1', files)) and 'dog' in files]))","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:42.886949Z","iopub.execute_input":"2021-06-05T05:20:42.887309Z","iopub.status.idle":"2021-06-05T05:20:43.025211Z","shell.execute_reply.started":"2021-06-05T05:20:42.88727Z","shell.execute_reply":"2021-06-05T05:20:43.024304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since images in test dataset are unlabelled, hence model can't find any 'cat' and 'dog' images","metadata":{}},{"cell_type":"markdown","source":"**Showing a random image in train dataset**","metadata":{}},{"cell_type":"code","source":"for img in os.listdir('./train'):\n    img_path = os.path.join('./train',img)\n    print(img_path)\n    img_arr = plt.imread(img_path)\n    plt.imshow(img_arr)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:43.026589Z","iopub.execute_input":"2021-06-05T05:20:43.026933Z","iopub.status.idle":"2021-06-05T05:20:43.361613Z","shell.execute_reply.started":"2021-06-05T05:20:43.026896Z","shell.execute_reply":"2021-06-05T05:20:43.360787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Showing a random image from test dataset**","metadata":{}},{"cell_type":"code","source":"for img in os.listdir('./test1'):\n    img_path = os.path.join('./test1',img)\n    print(img_path)\n    img_arr = plt.imread(img_path)\n    plt.imshow(img_arr)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:43.36391Z","iopub.execute_input":"2021-06-05T05:20:43.364264Z","iopub.status.idle":"2021-06-05T05:20:43.622403Z","shell.execute_reply.started":"2021-06-05T05:20:43.364228Z","shell.execute_reply":"2021-06-05T05:20:43.621589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets now prepare the data !\n","metadata":{}},{"cell_type":"markdown","source":"## Image Data Pre-processing","metadata":{}},{"cell_type":"markdown","source":"**Lets create 3 directories each for training, testing and validation**","metadata":{}},{"cell_type":"code","source":" base_dir = './'\n\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\ntest_dir = os.path.join(base_dir, 'test_dir')\nos.mkdir(test_dir)\n\ntrain_cats = os.path.join(train_dir, 'cats')\nos.mkdir(train_cats) \ntrain_dogs = os.path.join(train_dir, 'dogs')\nos.mkdir(train_dogs)\n\nval_cats = os.path.join(val_dir, 'cats')\nos.mkdir(val_cats) \nval_dogs = os.path.join(val_dir, 'dogs')\nos.mkdir(val_dogs)\n\ntest_cats = os.path.join(test_dir, 'cats')\nos.mkdir(test_cats) \ntest_dogs = os.path.join(test_dir, 'dogs')\nos.mkdir(test_dogs)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:43.624026Z","iopub.execute_input":"2021-06-05T05:20:43.624304Z","iopub.status.idle":"2021-06-05T05:20:43.632508Z","shell.execute_reply.started":"2021-06-05T05:20:43.624278Z","shell.execute_reply":"2021-06-05T05:20:43.63151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = ['cat.{}.jpg'.format(i) for i in range(8750)]\nfor filename in files:\n    src = os.path.join('./train', filename)\n    dst = os.path.join(train_cats, filename)\n    shutil.copyfile(src, dst)\n    \nfiles = ['cat.{}.jpg'.format(i) for i in range(8750, 12500)]\nfor filename in files:\n    src = os.path.join('./train', filename)\n    dst = os.path.join(val_cats, filename)\n    shutil.copyfile(src, dst)\n    \n\n    \nfiles = ['dog.{}.jpg'.format(i) for i in range(8750)]\nfor filename in files:\n    src = os.path.join('./train', filename)\n    dst = os.path.join(train_dogs, filename)\n    shutil.copyfile(src, dst)\n\nfiles = ['dog.{}.jpg'.format(i) for i in range(8750, 12500)]\nfor filename in files:\n    src = os.path.join('./train', filename)\n    dst = os.path.join(val_dogs, filename)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:43.634029Z","iopub.execute_input":"2021-06-05T05:20:43.634458Z","iopub.status.idle":"2021-06-05T05:20:45.762373Z","shell.execute_reply.started":"2021-06-05T05:20:43.634419Z","shell.execute_reply":"2021-06-05T05:20:45.7615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n\ntrain_datagen = ImageDataGenerator(\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    rotation_range = 30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2,\n    rescale=1./255)\n\nval_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:45.763675Z","iopub.execute_input":"2021-06-05T05:20:45.764071Z","iopub.status.idle":"2021-06-05T05:20:45.771438Z","shell.execute_reply.started":"2021-06-05T05:20:45.764028Z","shell.execute_reply":"2021-06-05T05:20:45.770627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (120,120)\nBATCH_SIZE = 128\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    class_mode='binary')   \n\n\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:45.772717Z","iopub.execute_input":"2021-06-05T05:20:45.773103Z","iopub.status.idle":"2021-06-05T05:20:47.056035Z","shell.execute_reply.started":"2021-06-05T05:20:45.773065Z","shell.execute_reply":"2021-06-05T05:20:47.055108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data_batch, label_batch in train_generator:\n    print(\"Train data batch shape:\", data_batch.shape)\n    print(\"Train label batch shape:\", label_batch.shape)\n    break;\n    \nfor data_batch, label_batch in val_generator:\n    print(\"Val data batch shape:\", data_batch.shape)\n    print(\"Val label batch shape:\", label_batch.shape)\n    break;","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:47.057465Z","iopub.execute_input":"2021-06-05T05:20:47.057905Z","iopub.status.idle":"2021-06-05T05:20:48.142837Z","shell.execute_reply.started":"2021-06-05T05:20:47.057865Z","shell.execute_reply":"2021-06-05T05:20:48.131331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data_batch, label_batch in train_generator:\n    print(\"Train data batch shape:\", data_batch.shape)\n    print(\"Train label batch shape:\", label_batch.shape)\n    break;","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:48.154542Z","iopub.execute_input":"2021-06-05T05:20:48.159432Z","iopub.status.idle":"2021-06-05T05:20:48.849505Z","shell.execute_reply.started":"2021-06-05T05:20:48.15857Z","shell.execute_reply":"2021-06-05T05:20:48.848074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Data batch shape : No.of batches x Img_size x no.of channels","metadata":{}},{"cell_type":"markdown","source":"# VGG-16 MODEL","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\n\nconv_base = VGG16(weights='imagenet',\n                 include_top=False,\n                 input_shape=(120,120, 3))","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:48.850787Z","iopub.execute_input":"2021-06-05T05:20:48.851136Z","iopub.status.idle":"2021-06-05T05:20:54.250551Z","shell.execute_reply.started":"2021-06-05T05:20:48.851083Z","shell.execute_reply":"2021-06-05T05:20:54.248544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_base.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:54.252032Z","iopub.execute_input":"2021-06-05T05:20:54.252669Z","iopub.status.idle":"2021-06-05T05:20:54.269716Z","shell.execute_reply.started":"2021-06-05T05:20:54.252631Z","shell.execute_reply":"2021-06-05T05:20:54.268784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_base.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:54.273191Z","iopub.execute_input":"2021-06-05T05:20:54.274179Z","iopub.status.idle":"2021-06-05T05:20:54.296859Z","shell.execute_reply.started":"2021-06-05T05:20:54.274141Z","shell.execute_reply":"2021-06-05T05:20:54.285105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\n\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:54.302462Z","iopub.execute_input":"2021-06-05T05:20:54.303025Z","iopub.status.idle":"2021-06-05T05:20:54.506203Z","shell.execute_reply.started":"2021-06-05T05:20:54.302988Z","shell.execute_reply":"2021-06-05T05:20:54.505202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Always use 'sigmoid' in the final layer for binary classification. If we use 'softmax', the loss will become very big and hard to converge.","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:54.510505Z","iopub.execute_input":"2021-06-05T05:20:54.510851Z","iopub.status.idle":"2021-06-05T05:20:54.524227Z","shell.execute_reply.started":"2021-06-05T05:20:54.510816Z","shell.execute_reply":"2021-06-05T05:20:54.523222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n             optimizer = keras.optimizers.Adam(),\n             metrics = ['acc'])","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:54.527865Z","iopub.execute_input":"2021-06-05T05:20:54.529883Z","iopub.status.idle":"2021-06-05T05:20:54.550019Z","shell.execute_reply.started":"2021-06-05T05:20:54.529844Z","shell.execute_reply":"2021-06-05T05:20:54.549171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Adding callbacks","metadata":{}},{"cell_type":"code","source":"callbacks_list = [keras.callbacks.EarlyStopping(\n        monitor = 'acc',\n        patience = 2),\n                  keras.callbacks.ModelCheckpoint(\n        filepath='vgg16_standart.h5',\n        monitor='loss',\n        save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:54.553785Z","iopub.execute_input":"2021-06-05T05:20:54.555913Z","iopub.status.idle":"2021-06-05T05:20:54.562074Z","shell.execute_reply.started":"2021-06-05T05:20:54.555865Z","shell.execute_reply":"2021-06-05T05:20:54.561288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator.n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:54.566178Z","iopub.execute_input":"2021-06-05T05:20:54.568449Z","iopub.status.idle":"2021-06-05T05:20:54.577445Z","shell.execute_reply.started":"2021-06-05T05:20:54.568411Z","shell.execute_reply":"2021-06-05T05:20:54.576547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_training = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.n//BATCH_SIZE,\n    validation_steps=val_generator.n//BATCH_SIZE,\n    epochs = 5,\n    callbacks = callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T05:20:54.584149Z","iopub.execute_input":"2021-06-05T05:20:54.586296Z","iopub.status.idle":"2021-06-05T06:24:25.285977Z","shell.execute_reply.started":"2021-06-05T05:20:54.586259Z","shell.execute_reply":"2021-06-05T06:24:25.285012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our model name is 'model'.\nThe History object gets returned by the fit method of models. Hence I assigned it as different name 'model_training' where the History object gets stored.","metadata":{}},{"cell_type":"markdown","source":"Go to this link to know more about keras.callbacks.History   http://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History","metadata":{}},{"cell_type":"code","source":"acc = model_training.history['acc']\nval_acc=model_training.history['val_acc']\nloss = model_training.history['loss']\nval_loss = model_training.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'o', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo', label='Validation accuracy')\n\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'o', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:24:25.288321Z","iopub.execute_input":"2021-06-05T06:24:25.288726Z","iopub.status.idle":"2021-06-05T06:24:25.591293Z","shell.execute_reply.started":"2021-06-05T06:24:25.288681Z","shell.execute_reply":"2021-06-05T06:24:25.590316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DenseNet201","metadata":{}},{"cell_type":"code","source":"from keras.applications import DenseNet201\n\nconv_base = DenseNet201(weights='imagenet',\n                 include_top=False,\n                 input_shape=(120,120, 3))","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:24:25.592764Z","iopub.execute_input":"2021-06-05T06:24:25.593132Z","iopub.status.idle":"2021-06-05T06:24:31.574128Z","shell.execute_reply.started":"2021-06-05T06:24:25.593078Z","shell.execute_reply":"2021-06-05T06:24:31.573019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_base.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:24:31.576251Z","iopub.execute_input":"2021-06-05T06:24:31.576598Z","iopub.status.idle":"2021-06-05T06:24:31.894281Z","shell.execute_reply.started":"2021-06-05T06:24:31.576562Z","shell.execute_reply":"2021-06-05T06:24:31.892881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_base.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:24:31.897291Z","iopub.execute_input":"2021-06-05T06:24:31.89756Z","iopub.status.idle":"2021-06-05T06:24:31.924317Z","shell.execute_reply.started":"2021-06-05T06:24:31.897533Z","shell.execute_reply":"2021-06-05T06:24:31.923446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\n\nmodel_DN = Sequential()\nmodel_DN.add(conv_base)\nmodel_DN.add(layers.Flatten())\nmodel_DN.add(layers.Dense(256, activation='relu'))\nmodel_DN.add(layers.Dense(1, activation = 'sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:24:31.92574Z","iopub.execute_input":"2021-06-05T06:24:31.926093Z","iopub.status.idle":"2021-06-05T06:24:33.146592Z","shell.execute_reply.started":"2021-06-05T06:24:31.926055Z","shell.execute_reply":"2021-06-05T06:24:33.145773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_DN.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:24:33.147856Z","iopub.execute_input":"2021-06-05T06:24:33.148217Z","iopub.status.idle":"2021-06-05T06:24:33.192059Z","shell.execute_reply.started":"2021-06-05T06:24:33.148182Z","shell.execute_reply":"2021-06-05T06:24:33.191075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_DN.compile(loss='binary_crossentropy',\n             optimizer = keras.optimizers.Adam(),\n             metrics = ['acc'])","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:24:33.193474Z","iopub.execute_input":"2021-06-05T06:24:33.193826Z","iopub.status.idle":"2021-06-05T06:24:33.216422Z","shell.execute_reply.started":"2021-06-05T06:24:33.193784Z","shell.execute_reply":"2021-06-05T06:24:33.215556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks_list = [keras.callbacks.EarlyStopping(\n        monitor = 'acc',\n        patience = 1),\n                  keras.callbacks.ModelCheckpoint(\n        filepath='densenet201.h5',\n        monitor='loss',\n        save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:31:49.491226Z","iopub.execute_input":"2021-06-05T06:31:49.491566Z","iopub.status.idle":"2021-06-05T06:31:49.496163Z","shell.execute_reply.started":"2021-06-05T06:31:49.491537Z","shell.execute_reply":"2021-06-05T06:31:49.495048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator.n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:31:51.32106Z","iopub.execute_input":"2021-06-05T06:31:51.321509Z","iopub.status.idle":"2021-06-05T06:31:51.331821Z","shell.execute_reply.started":"2021-06-05T06:31:51.321469Z","shell.execute_reply":"2021-06-05T06:31:51.330912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_training = model_DN.fit(\n    train_generator,\n    validation_data=val_generator,\n    steps_per_epoch=train_generator.n//BATCH_SIZE,\n    validation_steps=val_generator.n//BATCH_SIZE,\n    epochs = 5,\n    callbacks = callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:31:53.000729Z","iopub.execute_input":"2021-06-05T06:31:53.00104Z","iopub.status.idle":"2021-06-05T06:41:00.876925Z","shell.execute_reply.started":"2021-06-05T06:31:53.00101Z","shell.execute_reply":"2021-06-05T06:41:00.876076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = model_training.history['acc']\nval_acc= model_training.history['val_acc']\nloss =  model_training.history['loss']\nval_loss =  model_training.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'o', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo', label='Validation accuracy')\n\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'o', label='Training loss')\nplt.plot(epochs, val_loss, 'bo', label='Validation loss')\nplt.title('Training loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T06:42:46.886491Z","iopub.execute_input":"2021-06-05T06:42:46.886845Z","iopub.status.idle":"2021-06-05T06:42:47.23451Z","shell.execute_reply.started":"2021-06-05T06:42:46.886814Z","shell.execute_reply":"2021-06-05T06:42:47.233481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Data","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}