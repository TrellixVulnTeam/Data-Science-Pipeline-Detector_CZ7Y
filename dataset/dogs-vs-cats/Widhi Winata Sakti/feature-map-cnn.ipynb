{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport shutil\nfrom  shutil import copyfile\nimport random\nimport zipfile","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T12:57:28.730026Z","iopub.execute_input":"2022-01-21T12:57:28.730341Z","iopub.status.idle":"2022-01-21T12:57:34.136444Z","shell.execute_reply.started":"2022-01-21T12:57:28.730258Z","shell.execute_reply":"2022-01-21T12:57:34.13566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\ninput_path = '/kaggle/input/dogs-vs-cats'\nwork_path = '/kaggle/working/data'\ntrain_path = os.path.join(input_path,'train.zip')\ntest_path = os.path.join(input_path,'test1.zip')\n\nwith zipfile.ZipFile(train_path, 'r') as zip_ref:\n    zip_ref.extractall(work_path)\nwith zipfile.ZipFile(test_path, 'r') as zip_ref:\n    zip_ref.extractall(work_path)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T12:57:34.138189Z","iopub.execute_input":"2022-01-21T12:57:34.138443Z","iopub.status.idle":"2022-01-21T12:57:52.337521Z","shell.execute_reply.started":"2022-01-21T12:57:34.138402Z","shell.execute_reply":"2022-01-21T12:57:52.336748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = work_path\ntrain_dir = data_dir+\"/train\"\ntest_dir = data_dir+\"/test1\"\ntrain_dir","metadata":{"execution":{"iopub.status.busy":"2022-01-21T12:57:52.340345Z","iopub.execute_input":"2022-01-21T12:57:52.340994Z","iopub.status.idle":"2022-01-21T12:57:52.348449Z","shell.execute_reply.started":"2022-01-21T12:57:52.340963Z","shell.execute_reply":"2022-01-21T12:57:52.347538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame()\nfnames = os.listdir(train_dir)\n\nclass_name = []\nfor name in fnames:\n    class_name.append(name.split('.')[0])\n    \ndata = {'filename':fnames,'class':class_name}\ndf = pd.DataFrame(data)\ndf = df.sample(frac=1)\n\ntrain_datagen = ImageDataGenerator(rescale = 1/255,\n                                   rotation_range=20,\n                                   shear_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   horizontal_flip=True,\n                                   zoom_range=0.2)\nvalid_datagen = ImageDataGenerator(rescale = 1/255)\n\nidx = int(0.8*len(df))\ntrain_df = df.iloc[:idx]\nvalid_df = df.iloc[idx:]\n\ntarget = (150,150)\n\ntrain_data_gen = train_datagen.flow_from_dataframe(train_df,\n                                              directory=train_dir,\n                                              shuffle=True,\n                                              target_size = target,\n                                              batch_size = 64,\n                                              class_mode = 'binary')\n\nval_data_gen = valid_datagen.flow_from_dataframe(valid_df,\n                                              directory=train_dir,\n                                              shuffle=False,\n                                              target_size = target,\n                                              batch_size = 32,\n                                              class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T12:57:52.349735Z","iopub.execute_input":"2022-01-21T12:57:52.350458Z","iopub.status.idle":"2022-01-21T12:57:52.643068Z","shell.execute_reply.started":"2022-01-21T12:57:52.350421Z","shell.execute_reply":"2022-01-21T12:57:52.642211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\ndef plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T12:57:52.645447Z","iopub.execute_input":"2022-01-21T12:57:52.645829Z","iopub.status.idle":"2022-01-21T12:57:52.651386Z","shell.execute_reply.started":"2022-01-21T12:57:52.645788Z","shell.execute_reply":"2022-01-21T12:57:52.650637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_images = [train_data_gen[0][0][0] for i in range(5)]\nplotImages(augmented_images)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T12:57:52.652851Z","iopub.execute_input":"2022-01-21T12:57:52.653116Z","iopub.status.idle":"2022-01-21T12:57:55.283686Z","shell.execute_reply.started":"2022-01-21T12:57:52.653073Z","shell.execute_reply":"2022-01-21T12:57:55.276171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_training_images, _ = next(train_data_gen)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T12:57:55.28598Z","iopub.execute_input":"2022-01-21T12:57:55.286181Z","iopub.status.idle":"2022-01-21T12:57:55.775439Z","shell.execute_reply.started":"2022-01-21T12:57:55.286156Z","shell.execute_reply":"2022-01-21T12:57:55.774454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotImages(sample_training_images[:5])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T12:57:55.777554Z","iopub.execute_input":"2022-01-21T12:57:55.778139Z","iopub.status.idle":"2022-01-21T12:57:57.016127Z","shell.execute_reply.started":"2022-01-21T12:57:55.778097Z","shell.execute_reply":"2022-01-21T12:57:57.01541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(16, 3, padding='same', activation='relu', \n           input_shape=(target[0],target[1] ,3)),\n    MaxPooling2D(),\n    Dropout(0.2),\n    Conv2D(32, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Conv2D(64, 3, padding='same', activation='relu'),\n    MaxPooling2D(),\n    Dropout(0.2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(1)\n])\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T12:59:41.733036Z","iopub.execute_input":"2022-01-21T12:59:41.733322Z","iopub.status.idle":"2022-01-21T12:59:42.008961Z","shell.execute_reply.started":"2022-01-21T12:59:41.73329Z","shell.execute_reply":"2022-01-21T12:59:42.008248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 5\nbatch_size=100\nhistory = model.fit_generator(\n    train_data_gen,\n    steps_per_epoch=1000,\n    epochs=epochs,\n    validation_data=val_data_gen,\n    validation_steps=1000\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:00:26.09655Z","iopub.execute_input":"2022-01-21T13:00:26.096839Z","iopub.status.idle":"2022-01-21T13:03:49.065282Z","shell.execute_reply.started":"2022-01-21T13:00:26.096809Z","shell.execute_reply":"2022-01-21T13:03:49.06451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random\nfrom   tensorflow.keras.preprocessing.image import img_to_array, load_img","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T13:07:30.806752Z","iopub.execute_input":"2022-01-21T13:07:30.8076Z","iopub.status.idle":"2022-01-21T13:07:30.813328Z","shell.execute_reply.started":"2022-01-21T13:07:30.807559Z","shell.execute_reply":"2022-01-21T13:07:30.810678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/data/train\")\n!ls","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:12:36.230462Z","iopub.execute_input":"2022-01-21T13:12:36.231056Z","iopub.status.idle":"2022-01-21T13:12:37.044024Z","shell.execute_reply.started":"2022-01-21T13:12:36.231015Z","shell.execute_reply":"2022-01-21T13:12:37.043213Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path='/kaggle/working/data/train/cat.3248.jpg' #dog\n\nimg = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n\nx   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\nx   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n\n# Rescale by 1/255\nx /= 255.0\ny_pred=model.predict(x)\n#_pred =(y_pred>0.5)\nprint(y_pred)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T13:13:12.714367Z","iopub.execute_input":"2022-01-21T13:13:12.714676Z","iopub.status.idle":"2022-01-21T13:13:12.888013Z","shell.execute_reply.started":"2022-01-21T13:13:12.714639Z","shell.execute_reply":"2022-01-21T13:13:12.887269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_gen.class_indices","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T13:13:16.694543Z","iopub.execute_input":"2022-01-21T13:13:16.695156Z","iopub.status.idle":"2022-01-21T13:13:16.700853Z","shell.execute_reply.started":"2022-01-21T13:13:16.695117Z","shell.execute_reply":"2022-01-21T13:13:16.699972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotFilters(conv_filter):\n    fig, axes = plt.subplots(1, 3, figsize=(5,5))\n    axes = axes.flatten()\n    for img, ax in zip( conv_filter, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-01-21T13:13:34.687145Z","iopub.execute_input":"2022-01-21T13:13:34.687409Z","iopub.status.idle":"2022-01-21T13:13:34.692865Z","shell.execute_reply.started":"2022-01-21T13:13:34.687379Z","shell.execute_reply":"2022-01-21T13:13:34.691945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers:\n    if 'conv' in layer.name:\n        filters, bias= layer.get_weights()\n        print(layer.name, filters.shape)\n         #normalize filter values between  0 and 1 for visualization\n        f_min, f_max = filters.min(), filters.max()\n        filters = (filters - f_min) / (f_max - f_min)  \n        print(filters.shape[3])\n        axis_x=1\n        #plotting all the filters\n        for i in range(filters.shape[3]):\n        #for i in range(6):\n            #get the filters\n            filt=filters[:,:,:, i]\n            plotFilters(filt)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:13:37.902575Z","iopub.execute_input":"2022-01-21T13:13:37.903132Z","iopub.status.idle":"2022-01-21T13:13:57.660584Z","shell.execute_reply.started":"2022-01-21T13:13:37.903097Z","shell.execute_reply":"2022-01-21T13:13:57.659863Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing the filters\n#plt.figure(figsize=(5,5))\nfor layer in model.layers:\n    if 'conv' in layer.name:\n        weights, bias= layer.get_weights()\n        print(layer.name, weights.shape)\n         #normalize filter values between  0 and 1 for visualization\n        f_min, f_max = weights.min(), weights.max()\n        filters = (weights - f_min) / (f_max - f_min)  \n        print(weights.shape[3])\n        filter_cnt=1\n        #plotting all the filters\n        for i in range(filters.shape[3]):\n        #for i in range(6):\n            #get the filters\n            filt=filters[:,:,:, i]\n            #plotting ecah channel\n            for j in range(filters.shape[0]):\n                #plt.figure( figsize=(5, 5) )\n                #f = plt.figure(figsize=(10,10))\n                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n                ax.set_xticks([])\n                ax.set_yticks([])\n                plt.imshow(filt[:,:, j])\n                filter_cnt+=1\n        plt.show()\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:14:02.061365Z","iopub.execute_input":"2022-01-21T13:14:02.06167Z","iopub.status.idle":"2022-01-21T13:14:13.174855Z","shell.execute_reply.started":"2022-01-21T13:14:02.061629Z","shell.execute_reply":"2022-01-21T13:14:13.17401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnp.seterr(divide='ignore', invalid='ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:14:13.176687Z","iopub.execute_input":"2022-01-21T13:14:13.176955Z","iopub.status.idle":"2022-01-21T13:14:13.184166Z","shell.execute_reply.started":"2022-01-21T13:14:13.176919Z","shell.execute_reply":"2022-01-21T13:14:13.183484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg_path='/kaggle/working/data/test1/36.jpg' #dog\n# Let's define a new Model that will take an image as input, and will output\n# intermediate representations for all layers in the previous model after\n# the first.\nsuccessive_outputs = [layer.output for layer in model.layers[1:]]\n\n#visualization_model = Model(img_input, successive_outputs)\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n\n# Let's prepare a random input image of a cat or dog from the training set.\n#cat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\n#dog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n\n#img_path = random.choice(cat_img_files + dog_img_files)\n\nimg = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n\nx   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\nx   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n\n# Rescale by 1/255\nx /= 255.0\n\n# Let's run our image through our network, thus obtaining all\n# intermediate representations for this image.\nsuccessive_feature_maps = visualization_model.predict(x)\n\n# These are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\n\n# -----------------------------------------------------------------------\n# Now let's display our representations\n# -----------------------------------------------------------------------\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  print(feature_map.shape)\n  if len(feature_map.shape) == 4:\n    \n    #-------------------------------------------\n    # Just do this for the conv / maxpool layers, not the fully-connected layers\n    #-------------------------------------------\n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    #-------------------------------------------------\n    # Postprocess the feature to be visually palatable\n    #-------------------------------------------------\n    for i in range(n_features):\n      x  = feature_map[0, :, :, i]\n      x -= x.mean()\n      x /= x.std ()\n      x *=  64\n      x += 128\n      x  = np.clip(x, 0, 255).astype('uint8')\n      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n    #-----------------\n    # Display the grid\n    #-----------------\n\n    scale = 20. / n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' ) ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:14:28.044531Z","iopub.execute_input":"2022-01-21T13:14:28.044887Z","iopub.status.idle":"2022-01-21T13:14:29.232826Z","shell.execute_reply.started":"2022-01-21T13:14:28.044851Z","shell.execute_reply":"2022-01-21T13:14:29.23187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path='/kaggle/working/data/test1/137.jpg' #dog\n# Define a new Model, Input= image \n# Output= intermediate representations for all layers in the  \n# previous model after the first.\nsuccessive_outputs = [layer.output for layer in model.layers[1:]]\n#visualization_model = Model(img_input, successive_outputs)\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n#Load the input image\nimg = load_img(img_path, target_size=(150, 150))  \n# Convert ht image to Array of dimension (150,150,3)\nx   = img_to_array(img)                           \nx   = x.reshape((1,) + x.shape)                   \n# Rescale by 1/255\nx /= 255.0\n# Let's run input image through our vislauization network\n# to obtain all intermediate representations for the image.\nsuccessive_feature_maps = visualization_model.predict(x)\n# Retrieve are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  print(feature_map.shape)\n  if len(feature_map.shape) == 4:\n    \n    # Plot Feature maps for the conv / maxpool layers, not the fully-connected layers\n   \n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    # Postprocess the feature to be visually palatable\n    for i in range(n_features):\n      x  = feature_map[0, :, :, i]\n      x -= x.mean()\n      x /= x.std ()\n      x *=  64\n      x += 128\n      x  = np.clip(x, 0, 255).astype('uint8')\n      # Tile each filter into a horizontal grid\n      display_grid[:, i * size : (i + 1) * size] = x \n\n    # Display the grid\n    scale = 20. / n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' )","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:14:42.492584Z","iopub.execute_input":"2022-01-21T13:14:42.493212Z","iopub.status.idle":"2022-01-21T13:14:43.704135Z","shell.execute_reply.started":"2022-01-21T13:14:42.493168Z","shell.execute_reply":"2022-01-21T13:14:43.70345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:15:12.354265Z","iopub.execute_input":"2022-01-21T13:15:12.354537Z","iopub.status.idle":"2022-01-21T13:15:12.360824Z","shell.execute_reply.started":"2022-01-21T13:15:12.354507Z","shell.execute_reply":"2022-01-21T13:15:12.359987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"range(epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:16:56.084427Z","iopub.execute_input":"2022-01-21T13:16:56.085149Z","iopub.status.idle":"2022-01-21T13:16:56.090571Z","shell.execute_reply.started":"2022-01-21T13:16:56.085113Z","shell.execute_reply":"2022-01-21T13:16:56.08977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"scrolled":true},"execution_count":null,"outputs":[]}]}