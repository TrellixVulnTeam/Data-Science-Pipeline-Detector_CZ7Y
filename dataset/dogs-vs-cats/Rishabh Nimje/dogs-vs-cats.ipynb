{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Overview\n\nHere you’ll write an algorithm to classify whether images contain either a dog or a cat. This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## The Asirra data set\n\nWeb services are often protected with a challenge that’s supposed to be easy for people to solve, but difficult for computers. Such a challenge is often called a CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) or HIP (Human Interactive Proof). HIPs are used for many purposes, such as to reduce email and blog spam and prevent brute-force attacks on web site passwords.\n\nAsirra (Animal Species Image Recognition for Restricting Access) is a HIP that works by asking users to identify photographs of cats and dogs. This task is difficult for computers, but studies have shown that people can accomplish it quickly and accurately. Many even think it’s fun! Here is an example of the Asirra interface:\n\nAsirra is unique because of its partnership with Petfinder.com, the world’s largest site devoted to finding homes for homeless pets. They’ve provided Microsoft Research with over three million images of cats and dogs, manually classified by people at thousands of animal shelters across the United States. Kaggle is fortunate to offer a subset of this data for fun and research.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Description\n\nThe training archive contains 25,000 images of dogs and cats. Train your algorithm on these files and predict the labels for test1.zip (1 = dog, 0 = cat).\n\nYou can find the dataset [here](https://www.kaggle.com/c/dogs-vs-cats/data).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Files\n* test1.zip\n* train.zip","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## So let’s begin here…","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\n\nfrom PIL import Image\nimport cv2\nfrom zipfile import ZipFile\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extracting Files from zip file","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"file_train = \"../input/dogs-vs-cats/train.zip\"\nfile_test = \"../input/dogs-vs-cats/test1.zip\"\n\nwith ZipFile(file_train, 'r') as zip:\n    zip.extractall('/train')\n    print('Train Extract Done!') \n    \nwith ZipFile(file_test,'r') as zip:\n    zip.extractall('/test1')\n    print('Test Extract Done!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Number of training data and testing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Data ',len(os.listdir('/train/train/')))\nprint('Test Data ',len(os.listdir('/test1/test1/')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Opening a Train Image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_pic = np.random.randint(0,len(os.listdir('/train/train/')))\ndc_pic = os.listdir('/train/train/')[rand_pic]\n\n# Load the images\ndc_load = Image.open('/train/train/' + dc_pic)\ncategory = dc_pic.split(\".\")[0]\nplt.title(category)\nimg_plot = plt.imshow(dc_load)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '/train/train/'\n\nX_train = []\ny_train = []\n\nconvert = lambda category : int(category == 'dog')\n\ndef create_train_data(path):\n    for p in os.listdir(path):\n        category = p.split(\".\")[0]\n        category = convert(category)\n        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n        X_train.append(new_img_array)\n        y_train.append(category)\n        \ncreate_train_data(train_path)\n\nX_train = np.array(X_train).reshape(-1, 80,80,1)\ny_train = np.array(y_train)\nX_train = X_train/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = \"/test1/test1/\"\n\nX_test = []\ntest_id = []\n\ndef create_test_data(path):\n    for p in os.listdir(path):\n        test_id.append(p.split(\".\")[0])\n        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n        X_test.append(new_img_array)\n\ncreate_test_data(test_path)\n\nX_test = np.array(X_test).reshape(-1,80,80,1)\nX_test = X_test/255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(16,(3,3), activation = 'relu', input_shape = X_train.shape[1:]))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(32,(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(64,(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(128,(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\n\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting Data in Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs = 20, batch_size = 100, validation_split=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)\npredicted_val = [int(round(p[0])) for p in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame({'id':test_id, 'label':predicted_val})\nsubmission_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting Test Images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test = submission_df.head(60)\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['id']\n    category = row['label']\n    img = load_img(\"/test1/test1/\"+filename+\".jpg\", target_size=(128,128))\n    plt.subplot(10, 6, index+1)\n    plt.imshow(img)\n    if(category == 1):\n        plt.title( '(' + \"Dog\"+ ')' )\n    else:\n        plt.title( '(' + \"Cat\"+ ')' )\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}