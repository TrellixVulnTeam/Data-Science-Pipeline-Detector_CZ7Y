{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center>Dog vs Cat classification</center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n%matplotlib inline\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nfrom pickle import dump\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.tree import plot_tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining constants for directories","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST1_DIR = 'test1'\nTRAIN_DIR = 'train'\nINPUT_DIR = '../input/dogs-vs-cats'\nOUTPUT_DIR = '/kaggle/working/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extraction of the images from the zip files.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\nfiles_to_extract = [TEST1_DIR,TRAIN_DIR]\n\nfor Dataset in files_to_extract:\n    with ZipFile('{}/{}.zip'.format(INPUT_DIR, Dataset),'r') as z:\n        z.extractall('.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Listing the current directories in the workspace.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output(['ls', '.']).decode('utf8'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training\n### Data preparation\nCharging the list of image names.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(TRAIN_DIR)\nfilenames[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"creating the list of expected outputs of the image classification (**0 = Cat**, **1 = Dog**).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [1 if filename.startswith('dog') else 0 for filename in filenames]\n\nlabels[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"creating training dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\n    'filename': filenames,\n    'category': labels\n})\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the number of cats and dogs images.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df.category.value_counts().plot.bar(color=['dodgerblue', 'slategray'])\nplt.title('Dogs and Cats images count')\nplt.xlabel('Dog = 1 - Cat = 0')\nplt.ylabel('samples count')\nax.set_xticklabels(['Dog', 'Cat'], rotation=0, fontsize=11)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"charging a random image to see the example.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_filename = '{}/{}'.format(TRAIN_DIR, random.choice(filenames))\nrandom_image = mpimg.imread(random_filename)\n# random_image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"showing the image.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(random_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"method to charge a list of image kind files from a directory and resize them into a resolution of 64x64.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images_from_dir(dir_location, filenames):\n    return [np.array(Image.open('{}/{}'.format(dir_location, filename)).resize((64, 64))) for filename in filenames]\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"charging all the images.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"images = np.array(load_images_from_dir(TRAIN_DIR, filenames))\nimages.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Put the image dimetions into variables and make a dimensionality reduction from four dimentios to two dimentions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"h, w, d = images[0].shape\nimages_resized = np.array([np.reshape(img, (w*h*d)) for img in images])\nimages_resized.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparing classification models.\n### MLP (Multi Layer Perceptron).\ncreating model instance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"training the model using the processed data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp.fit(images_resized, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"score obtained using default configurations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp.score(images_resized, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree\ncreating model instance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"training the model using the processed data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.fit(images_resized, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"score obtained using default configurations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.score(images_resized, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ploting the Decision Tree generated.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_tree(tree)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest\ncreating model instance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"forest = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"training the model using the processed data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"forest.fit(images_resized, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"score obtained using default configurations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"forest.score(images_resized, labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing Models.\n### Data preparation for training with a random example.\nCharging the list of image names.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filenames = os.listdir(TEST1_DIR)\ntest_filenames[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"charging a random image to see the example.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_filename = '{}/{}'.format(TEST1_DIR, random.choice(test_filenames))\nrandom_image = mpimg.imread(random_filename)\nrandom_image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(random_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"resizing the selected image to make the prediction.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_image_resized = np.array(Image.fromarray(random_image).resize((64, 64)))\nrandom_image_resized.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make a dimensionality reduction from tree dimentios to two dimentions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"random_image_resized = np.reshape(random_image_resized, (w*h*d))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MLP prediction output.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp_prediction = mlp.predict([random_image_resized])\nmlp_prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree prediction output.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_prediction = tree.predict([random_image_resized])\ntree_prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest prediction output.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_prediction = forest.predict([random_image_resized])\nforest_prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preparation for training with more examples.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"charging all the images.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = np.array(load_images_from_dir(TEST1_DIR, test_filenames))\ntest_images.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make a dimensionality reduction from four dimentios to two dimentions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images_resized = np.array([np.reshape(img, (w*h*d)) for img in test_images])\ntest_images_resized.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparing the otput of the predictions.\nCreating the list of predictions with the MLP.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp_predictions = mlp.predict(test_images_resized)\nmlp_predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the list of predictions with the Decision Tree.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_predictions = tree.predict(test_images_resized)\ntree_predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the list of predictions with the Random Forest.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_predictions = forest.predict(test_images_resized)\nforest_predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating MLP dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_mlp = pd.DataFrame({\n    'filename': test_filenames,\n    'category': mlp_predictions\n})\n\ndf_test_mlp.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating Decision Tree dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_tree = pd.DataFrame({\n    'filename': test_filenames,\n    'category': tree_predictions\n})\n\ndf_test_tree.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating Random Forest dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_forest = pd.DataFrame({\n    'filename': test_filenames,\n    'category': forest_predictions\n})\n\ndf_test_forest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def autolabel(ax):\n    \"\"\"\n    Attach a text label above each bar displaying its height\n    \"\"\"\n    for p in ax.patches:\n        ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the predictions of the counts.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df_test_mlp.category.value_counts().plot.bar(color=['dodgerblue', 'slategray'])\nplt.title('Dogs and Cats images count MLP')\nplt.xlabel('Dog = 1 - Cat = 0')\nplt.ylabel('samples count')\nax.set_xticklabels(['Dog', 'Cat'], rotation=0, fontsize=11)\nautolabel(ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df_test_tree.category.value_counts().plot.bar(color=['dodgerblue', 'slategray'])\nplt.title('Dogs and Cats images count Desicion Tree')\nplt.xlabel('Dog = 1 - Cat = 0')\nplt.ylabel('samples count')\nax.set_xticklabels(['Dog', 'Cat'], rotation=0, fontsize=11)\nautolabel(ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df_test_forest.category.value_counts().plot.bar(color=['dodgerblue', 'slategray'])\nplt.title('Dogs and Cats images count Random Forest')\nplt.xlabel('Dog = 1 - Cat = 0')\nplt.ylabel('samples count')\nax.set_xticklabels(['Dog', 'Cat'], rotation=0, fontsize=11)\nautolabel(ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the first samples to compare the prediction with the image.\nMLP 13 hits - 5 wrong.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = (w, h)\nsample_test = df_test_mlp.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = mpimg.imread('./test1/{}'.format(filename))\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel('{} ({})'.format(filename, category))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree 8 hits - 10 wrong","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test = df_test_tree.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = mpimg.imread('./test1/{}'.format(filename))\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel('{} ({})'.format(filename, category))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest 14 hits - 4 wrong","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test = df_test_forest.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = mpimg.imread('./test1/{}'.format(filename))\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel('{} ({})'.format(filename, category))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Changing to the working directory to put the output data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(OUTPUT_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saving the best successful model configuration.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"FILE_NAME = 'forest_model.sav'\ndump(forest, open(FILE_NAME, 'wb'))\n# loaded_model = pickle.load(open(filename, 'rb'))\n# result = loaded_model.score(X_test, Y_test)\n# print(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from IPython.display import FileLink\n# FileLink(FILE_NAME)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saving the random forest dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = df_test_forest.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df['label'] = submission_df['category']\nsubmission_df.drop(['filename', 'category'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}