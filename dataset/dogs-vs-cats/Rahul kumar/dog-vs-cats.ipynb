{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing important libraries and modules\nimport cv2\nimport os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.layers import Dropout, Conv2D, Dense, BatchNormalization, AveragePooling2D, MaxPooling2D, Flatten\nfrom keras.models import Sequential, load_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom zipfile import ZipFile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting the training data and test data for prediction from the zip file\n\n# for training data\nwith ZipFile('../input/dogs-vs-cats/train.zip', 'r') as zip: \n    print('Extracting all the files for training data now...') \n    zip.extractall() \n    print('Done!')\n    \n# for test data for prediction   \nwith ZipFile('../input/dogs-vs-cats/test1.zip', 'r') as zip: \n    print('Extracting all the files for test data for prediction now...') \n    zip.extractall() \n    print('Done!')    \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have to read the training data from a file which contains data in the form of image. \n# The folder is named as 'train' and it contains images of dogs and cats\n\n# First of all we will extract the detail of all the data and save all of them in terms of dataframe with foldername, imagename, objectname and labels\ndetail = glob.glob(\"./train/*\")\nfoldername = [str(i.split(\"n/\")[0]) + \"n\" for i in detail]\nimagename = [str(i.split(\"/\")[2]) for i in detail]\nobjectname = [str(i.split(\".\")[0]) for i in imagename]\nlabel = [1 if i == 'dog' else 0 for i in objectname]\n\n# Defining dataframe and saving all the extracted information in that dataframe\ntrain_data_detail = pd.DataFrame() \ntrain_data_detail[\"foldername\"] = foldername\ntrain_data_detail[\"imagename\"] = imagename\ntrain_data_detail[\"objectname\"] = objectname\ntrain_data_detail[\"label\"] = label\n\n# Shuffling of all the classes present in that dataframe\ntrain_data_detail.reset_index(inplace = True, drop = True)  \n\n# Analying the train data detail\nprint(\"\\nNumber of images in training set = \"+str(len(detail)))\nprint(train_data_detail.columns)\ntrain_data_detail.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting training set into initial training set and test set\ntrain_data_detail, test_data_detail = train_test_split(train_data_detail, stratify=train_data_detail[\"label\"], test_size = 0.08)\n\n# Splitting training data into final training set and cross validation set\ntrain_data_detail, cv_data_detail = train_test_split(train_data_detail, stratify=train_data_detail[\"label\"], test_size = 0.086956)\ntrain_data_detail.shape, test_data_detail.shape, cv_data_detail.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resetting index of train, cross validation and test set\ntrain_data_detail.reset_index(inplace = True, drop = True)\ncv_data_detail.reset_index(inplace = True, drop = True)\ntest_data_detail.reset_index(inplace = True, drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting  and printing distribution of each class in all train, cross validation and test set\n\n# for training data.................................................................................................................\nfig = plt.figure(figsize = (10, 6))\nax = fig.add_axes([0,0,1,1])\nax.set_title(\"object in Training Data set\", fontsize = 20)\nsns.countplot(x = \"objectname\", data = train_data_detail)\nfor i in ax.patches:\n    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"black\")\nplt.xlabel(\"\")\nplt.ylabel(\"Count\", fontsize = 13)\nplt.tick_params(labelsize = 15)\nplt.xticks(rotation = 0)\nplt.show()\n\n# for cross validation data............................................................................................................\nfig = plt.figure(figsize = (10, 6))\nax = fig.add_axes([0,0,1,1])\nax.set_title(\"object in cv Data set\", fontsize = 20)\nsns.countplot(x = \"objectname\", data = cv_data_detail)\nfor i in ax.patches:\n    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"black\")\nplt.xlabel(\"\")\nplt.ylabel(\"Count\", fontsize = 13)\nplt.tick_params(labelsize = 15)\nplt.xticks(rotation = 0)\nplt.show()\n\n# for test data............................................................................................................................\nfig = plt.figure(figsize = (10, 6))\nax = fig.add_axes([0,0,1,1])\nax.set_title(\"object in test Data set\", fontsize = 20)\nsns.countplot(x = \"objectname\", data = test_data_detail)\nfor i in ax.patches:\n    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 20, color = \"black\")\nplt.xlabel(\"\")\nplt.ylabel(\"Count\", fontsize = 13)\nplt.tick_params(labelsize = 15)\nplt.xticks(rotation = 0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the data into an array of pixels and labels so that it can be fed into the model expect test which is for prediction only\n# Initially it was in the form of a DataFrame\n\n# for training data\ntrain_x = []\ntrain_y = []\nfor i in range(len(train_data_detail)):\n        path1 = train_data_detail[\"foldername\"][i]\n        path2 = train_data_detail[\"imagename\"][i]\n        image = cv2.imread(os.path.join(path1, path2))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (128, 128))\n        #here, we are normalizing the images\n        norm_image = image/255.0 \n        #Creating and saving each image in the form of numerical data in an array \n        train_x.append(norm_image)\n        #appending corresponding labels \n        train_y.append(train_data_detail['label'][i])  \ntrain_x = np.array(train_x)\ntrain_y = np.array(train_y)\nprint(\" for training data \", train_x.shape, train_y.shape)\n\n# for test data\ncv_x = []\ncv_y = []\nfor i in range(len(cv_data_detail)):\n        path1 = cv_data_detail[\"foldername\"][i]\n        path2 = cv_data_detail[\"imagename\"][i]\n        image = cv2.imread(os.path.join(path1, path2))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (128, 128))\n        #here, we are normalizing the images\n        norm_image = image/255.0 \n        #Creating and saving each image in the form of numerical data in an array \n        cv_x.append(norm_image)\n        #appending corresponding labels \n        cv_y.append(cv_data_detail['label'][i])  \ncv_x = np.array(cv_x)\ncv_y = np.array(cv_y)\nprint(\" for cv data \",cv_x.shape, cv_y.shape)\n\n# for cv data\ntest_x = []\ntest_y = []\nfor i in range(len(test_data_detail)):\n        path1 = test_data_detail[\"foldername\"][i]\n        path2 = test_data_detail[\"imagename\"][i]\n        image = cv2.imread(os.path.join(path1, path2))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (128, 128))\n        #here, we are normalizing the images\n        norm_image = image/255.0 \n        #Creating and saving each image in the form of numerical data in an array \n        test_x.append(norm_image)\n        #appending corresponding labels \n        test_y.append(test_data_detail['label'][i])  \ntest_x = np.array(test_x)\ntest_y = np.array(test_y)\nprint(\" for test data \",test_x.shape, test_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the accuracy after processing\nr = 10000\nplt.imshow(train_x[r])\nprint(train_y[r])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We also need to read the test data for prediction from a file which contains data in the form of image. \n# The folder is named as 'test1' and it contains images of dogs and cats\n\n# First of all we will extract the detail of all the data and save all of them in terms of dataframe with foldername and imagename only\ndetail = glob.glob(\"./test1/*\")\nfoldername = [str(i.split(\"1/\")[0]) + \"1\" for i in detail]\nimagename = [str(i.split(\"/\")[2]) for i in detail]\n\n# Defining dataframe and saving all the extracted information in that dataframe\ntest_data_for_prediction_detail = pd.DataFrame() \ntest_data_for_prediction_detail[\"foldername\"] = foldername\ntest_data_for_prediction_detail[\"imagename\"] = imagename\n\n# Analying the test data set for prediction detail\nprint(\"\\nNumber of images in test data set for prediction  = \"+str(len(detail)))\nprint(test_data_for_prediction_detail.columns)\ntest_data_for_prediction_detail.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the data into an array of pixels and labels so that it can be fed into the model for prediction \n# Initially it was in the form of a DataFrame\n\n# for test data for prediction data\nprediction = []\nfor i in range(len(test_data_for_prediction_detail)):\n        path1 = test_data_for_prediction_detail[\"foldername\"][i]\n        path2 = test_data_for_prediction_detail[\"imagename\"][i]\n        image = cv2.imread(os.path.join(path1, path2))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (128, 128))\n        #here, we are normalizing the images\n        norm_image = image/255.0 \n        #Creating and saving each image in the form of numerical data in an array \n        prediction.append(norm_image) \nprediction = np.array(prediction)\nprint(\" for test data for prediction \", prediction.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To train and predict on the given data we need to covert them into tensor\ntrain_x = train_x.reshape(21000, 128, 128, 1)\ntest_x = test_x.reshape(2000, 128, 128, 1)\ncv_x = cv_x.reshape(2000, 128, 128, 1)\nprediction = prediction.reshape(12500, 128, 128, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a model consisting of convolutional layers, polling layers and fully connected layer\ndef model():\n    model = Sequential()\n    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(128,128,1)))\n    model.add(MaxPooling2D())\n\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D())\n    \n    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D())\n    \n    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D())\n\n    model.add(Flatten())\n    model.add(Dropout(0.7))\n\n    model.add(Dense(units=512, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    return model\nmodel = model()\nmodel.summary()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling and running the model\nmodel.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = [\"accuracy\"])\nhist = model.fit(train_x, train_y, validation_data=(cv_x, cv_y), epochs = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing losses and accuracy with epochs \nepoch_number = []\nfor epoch in range(50):\n    epoch_number.append(epoch + 1)\ntrain_loss = hist.history['loss']\nval_loss   = hist.history['val_loss']\ntrain_acc  = hist.history['accuracy']\nval_acc    = hist.history['val_accuracy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing a table depicting the detail about the trained model\nlog_frame = pd.DataFrame(columns = [\"Epoch\", \"Train_Loss\", \"Train_Accuracy\", \"CV_Loss\", \"CV_Accuracy\"])\nlog_frame[\"Epoch\"] = epoch_number\nlog_frame[\"Train_Loss\"] = train_loss\nlog_frame[\"Train_Accuracy\"] = train_acc\nlog_frame[\"CV_Loss\"] = val_loss\nlog_frame[\"CV_Accuracy\"] = val_acc \nlog_frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting epoch vs loss\ndef plotting(epoch, train_loss, CV_loss, title):\n    fig, axes = plt.subplots(1,1, figsize = (12, 8))\n    axes.plot(epoch, train_loss, color = 'red', label = \"Train\")\n    axes.plot(epoch, CV_loss, color = 'blue', label = \"CV\")\n    axes.set_title(title, fontsize = 25)\n    axes.set_xlabel(\"Epochs\", fontsize = 20)\n    axes.set_ylabel(\"Loss\", fontsize = 20)\n    axes.grid()\n    axes.legend(fontsize = 20)\n\nplotting(list(log_frame[\"Epoch\"]), list(log_frame[\"Train_Loss\"]), list(log_frame[\"CV_Loss\"]), \"EPOCH VS LOSS\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting epoch vs accuracy\ndef plotting(epoch, train_acc, CV_acc, title):\n    fig, axes = plt.subplots(1,1, figsize = (12, 8))\n    axes.plot(epoch, train_acc, color = 'red', label = \"Train_Accuracy\")\n    axes.plot(epoch, CV_acc, color = 'blue', label = \"CV_Accuracy\")\n    axes.set_title(title, fontsize = 25)\n    axes.set_xlabel(\"Epochs\", fontsize = 20)\n    axes.set_ylabel(\"Accuracy\", fontsize = 20)\n    axes.grid()\n    axes.legend(fontsize = 20)\n\nplotting(list(log_frame[\"Epoch\"]), list(log_frame[\"Train_Accuracy\"]), list(log_frame[\"CV_Accuracy\"]), \"EPOCH VS ACCURACY\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting on test data\ntest_predict = model.predict(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since the test_predict is in the form of dummy variable with the value of probability so we will convert it into categorical data\nl = []\nfor i in range(test_predict.shape[0]):\n  if test_predict[i] < 0.5:\n    j = 0\n  else:\n    j = 1\n  l.append(j)\ntest_predict = pd.DataFrame(l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy on test data\nacc = accuracy_score(test_y, l) * 100\nacc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now prediction on data to be predicted\nprediction_predict = model.predict(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since the prediction_predict is in the form of dummy variable with the value of probability so we will convert it into categorical data\nl = []\nfor i in range(prediction_predict.shape[0]):\n  if prediction_predict[i] < 0.5:\n    j = 0\n  else:\n    j = 1\n  l.append(j)\nsubmission2 = pd.DataFrame(l)  \nsubmission2 = submission2.rename(columns = {0 : 'label'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading sample submission file and dropping the falsely labelled column from Sample submission file and clubing it with the predicted file \nsubmission1 = pd.read_csv('../input/dogs-vs-cats/sampleSubmission.csv')\nsubmission1.drop(columns = ['label'], inplace = True)\nsubmission = pd.concat([submission1, submission2], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final submission file\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation by image plotting\nt = prediction.reshape(12500, 128, 128)\nr = 233\nplt.imshow(t[r])\nif submission[\"label\"][r] == 1:\n    print(\"It is a dog\")\nelse:\n    print(\"it is a cat\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete unwanted output files\nimport shutil\nshutil.rmtree('./train')\nshutil.rmtree('./test1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the submission file\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}