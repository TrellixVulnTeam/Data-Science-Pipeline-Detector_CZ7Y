{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-01T21:52:49.575058Z","iopub.execute_input":"2022-01-01T21:52:49.575826Z","iopub.status.idle":"2022-01-01T21:52:49.604856Z","shell.execute_reply.started":"2022-01-01T21:52:49.575715Z","shell.execute_reply":"2022-01-01T21:52:49.603962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras import Sequential\n\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D,Dropout, Flatten, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom PIL import Image \nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:17:33.700846Z","iopub.execute_input":"2022-01-01T22:17:33.701168Z","iopub.status.idle":"2022-01-01T22:17:33.709049Z","shell.execute_reply.started":"2022-01-01T22:17:33.701131Z","shell.execute_reply":"2022-01-01T22:17:33.707957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set = \"dogs-vs-cats\"\n\nimport zipfile \nwith zipfile.ZipFile(\"/kaggle/input/\"+ data_set +\"/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    # save all files to kaggle/files/images\n    destination = '/kaggle/files/images/train'\n    z.extractall(destination)\n    \nwith zipfile.ZipFile(\"/kaggle/input/\"+ data_set +\"/test1.zip\",\"r\") as z:\n    z.extractall(\".\")\n    # save all files to kaggle/files/images\n    destination = '/kaggle/files/images/test'\n    z.extractall(destination)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:53:30.025652Z","iopub.execute_input":"2022-01-01T21:53:30.025954Z","iopub.status.idle":"2022-01-01T21:54:04.206568Z","shell.execute_reply.started":"2022-01-01T21:53:30.025921Z","shell.execute_reply":"2022-01-01T21:54:04.205746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def list_full_paths(directory):\n    return [os.path.join(directory, file) for file in os.listdir(directory)]\n\ntrain = pd.DataFrame({'filepath': list_full_paths('/kaggle/files/images/train/train')})\ntrain['truth_label'] = np.where(train['filepath'].str.contains('dog'), 'dog', 'cat')\n\ntest = pd.DataFrame({'filepath': list_full_paths('/kaggle/files/images/test/test1')})","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:54:06.334966Z","iopub.execute_input":"2022-01-01T21:54:06.335229Z","iopub.status.idle":"2022-01-01T21:54:06.472739Z","shell.execute_reply.started":"2022-01-01T21:54:06.335202Z","shell.execute_reply":"2022-01-01T21:54:06.471749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test = train_test_split(train, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:54:08.851131Z","iopub.execute_input":"2022-01-01T21:54:08.851402Z","iopub.status.idle":"2022-01-01T21:54:08.862748Z","shell.execute_reply.started":"2022-01-01T21:54:08.851374Z","shell.execute_reply":"2022-01-01T21:54:08.862115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n                    rescale = 1./255,\n                    shear_range = 0.2,\n                    zoom_range = 0.2,\n                    rotation_range=40,\n                    width_shift_range=0.2,\n                    height_shift_range=0.2,\n                    horizontal_flip=True,\n                    fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:54:11.438062Z","iopub.execute_input":"2022-01-01T21:54:11.438464Z","iopub.status.idle":"2022-01-01T21:54:11.443565Z","shell.execute_reply.started":"2022-01-01T21:54:11.438434Z","shell.execute_reply":"2022-01-01T21:54:11.442939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set = train_datagen.flow_from_dataframe(dataframe=X_train, x_col='filepath', y_col='truth_label', class_mode='categorical', target_size = (64, 64), batch_size = 128)\ntest_set = test_datagen.flow_from_dataframe(dataframe=X_test, x_col='filepath', y_col='truth_label', class_mode='categorical', target_size = (64, 64), batch_size = 128)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:54:25.412245Z","iopub.execute_input":"2022-01-01T21:54:25.412652Z","iopub.status.idle":"2022-01-01T21:54:25.734975Z","shell.execute_reply.started":"2022-01-01T21:54:25.412621Z","shell.execute_reply":"2022-01-01T21:54:25.734107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\nbatches_augmented = train_datagen.flow_from_directory('/kaggle/files/images/', target_size = (512, 512), batch_size = 16, class_mode = 'categorical', seed=1234)\nbatches_real = test_datagen.flow_from_directory('/kaggle/files/images/', target_size = (512, 512), batch_size = 16, class_mode = 'categorical', seed=1234)\n\nx_batch_augmented, y_batch_augmented = next(batches_augmented)\nx_batch_real, y_batch_real = next(batches_real)\n\nfor i in range(16):\n    image_augmented = x_batch_augmented[i]\n    image_real = x_batch_real[i]\n    \n    title_add_on = \"random image\"\n    if y_batch_augmented[i][1]: title_add_on =  \"dog vs cat\"\n\n    plt.subplot(221)\n    plt.imshow(image_real)\n    plt.title(\"original \" + title_add_on)\n\n        \n    plt.subplot(222)\n    plt.imshow(image_augmented)\n    plt.title(\"augmented \" + title_add_on)\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:54:29.701142Z","iopub.execute_input":"2022-01-01T21:54:29.7021Z","iopub.status.idle":"2022-01-01T21:54:38.62963Z","shell.execute_reply.started":"2022-01-01T21:54:29.702054Z","shell.execute_reply":"2022-01-01T21:54:38.628747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = Sequential()\n\nclassifier.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n                padding=\"valid\", input_shape = (64,64,3)))\n\nclassifier.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n\nclassifier.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n                padding=\"valid\", input_shape = (64,64,3)))\n\nclassifier.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n\nclassifier.add(Flatten())\nclassifier.add(Dense(128,activation=\"relu\")) \nclassifier.add(Dense(2,activation=\"sigmoid\")) ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:54:42.908543Z","iopub.execute_input":"2022-01-01T21:54:42.908867Z","iopub.status.idle":"2022-01-01T21:54:43.067758Z","shell.execute_reply.started":"2022-01-01T21:54:42.908836Z","shell.execute_reply":"2022-01-01T21:54:43.067153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:54:45.614898Z","iopub.execute_input":"2022-01-01T21:54:45.615226Z","iopub.status.idle":"2022-01-01T21:54:45.630662Z","shell.execute_reply.started":"2022-01-01T21:54:45.61519Z","shell.execute_reply":"2022-01-01T21:54:45.629748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = classifier.fit(training_set, validation_data = test_set, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T21:54:47.741751Z","iopub.execute_input":"2022-01-01T21:54:47.742218Z","iopub.status.idle":"2022-01-01T22:15:55.509196Z","shell.execute_reply.started":"2022-01-01T21:54:47.742175Z","shell.execute_reply":"2022-01-01T22:15:55.507912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set2 = test_datagen.flow_from_dataframe(dataframe=test,\n    directory = '/kaggle/files/images/test',\n    x_col = 'filepath',\n    y_col = None,\n    class_mode = None,\n    target_size = (64, 64),\n    batch_size = 32,\n    shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:16:11.961415Z","iopub.execute_input":"2022-01-01T22:16:11.962493Z","iopub.status.idle":"2022-01-01T22:16:12.153697Z","shell.execute_reply.started":"2022-01-01T22:16:11.962432Z","shell.execute_reply":"2022-01-01T22:16:12.152825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = classifier.predict(test_set2, steps = np.ceil(test.shape[0] / 32))\n\ntest[\"test_preds\"] = np.argmax(test_preds, axis = 1)\nlabels = dict((v,k) for k,v in training_set.class_indices.items())\n\ntest['test_preds'] = test['test_preds'].map(labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:16:13.886949Z","iopub.execute_input":"2022-01-01T22:16:13.887258Z","iopub.status.idle":"2022-01-01T22:16:49.26061Z","shell.execute_reply.started":"2022-01-01T22:16:13.887223Z","shell.execute_reply":"2022-01-01T22:16:49.259741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_test = test.sample(64).reset_index(drop = True)\n\nfig = plt.figure(1, figsize = (24, 20))\nfig.suptitle(\"Sample Predictions\")\n\nfor i in range(len(sample_test)):\n    \n    plt.subplot(10, 8, i + 1)\n    image = load_img(sample_test.filepath[i])\n    plt.imshow(image)\n    plt.axis(\"off\")\n    plt.title(f\"Predicted as {sample_test['test_preds'][i]}\")\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:20:53.113768Z","iopub.execute_input":"2022-01-01T22:20:53.114116Z","iopub.status.idle":"2022-01-01T22:20:58.063293Z","shell.execute_reply.started":"2022-01-01T22:20:53.114063Z","shell.execute_reply":"2022-01-01T22:20:58.062321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}