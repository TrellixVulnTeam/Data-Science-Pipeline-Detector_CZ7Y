{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Derin Öğrenme ile Kedi ve Köpek Sınıflandırma","metadata":{}},{"cell_type":"markdown","source":"## İçindekiler\n1. Giriş\n2. Temel Bağımlılıkları Belirleme\n3. Veri Setinde Etiketlerin Okunması\n4. Veri Görselleştirme\n5. Veri bölünmesi ve Veri Dağıtımı\n6. Vanilla CNN ile Sınıflandırma\n7. Veri Setini Büyütmek ve Öğrenme Oranı Çizelgesi (Learning Rate Schedule)\n8. ResNet50 ile Sınıflandırma\n9. Test Verisi ile Son Tahminler\n","metadata":{}},{"cell_type":"markdown","source":"# 1. Giriş:\n\nProblemimiz, kedi ve köpek fotoğraflarını etiketlenmiş görüntü verilerine göre sınıflandırmaktır. Veri setimizde train kısmı için 25.000, test kısmı için 12500 kedi ve köpek fotoğrafı vardır. Köpekler 1, kediler 0 olarak etiketlenmiştir. En yüksek doğruluğa ulaşmak için farklı derin öğrenme teknikleri kullanılmıştır.\n\n# # 1.1 Convolutional Neural Network (CNN)\nCNN resim tanıma için kullanılan çok etkili bir mekanizmadır.\n\n\nCnn verilen görüntüleri ayırt etmek için bir uçağı uçak ya da yılanı yılan haline getiren benzersiz özellikleri kullanır. Aslında bu süreç beynimizde de bilinçsizce oluyor.\n\nÖrneğin, bir uçak resmine baktığımızda, iki kanat, motor, pencere gibi özellikleri birbirinden ayırarak uçağı tanımlayabiliriz. Cnn de aynı şeyi yapar, ancak daha önce eğriler ve kenarlar gibi alt düzey özellikleri tespit ederler ve daha soyut kavramlara kadar bunları oluştururlar.\n\n# # 1.2 Evrişimsel Sinir Ağlarının Yapısı\nKonuştuğumuz işlevselliği elde etmek için, Cnn görüntüyü çeşitli katmanlarla işler. Bu katmanlara ve amaçlarına genel bir bakış yapalım:\n\n**Convolutional Layer** — Özellikleri saptamak için kullanılır\nConvolutional (evrişim katmanı) CNN algoritmalarında görüntüyü ele alan ilk katmandır. Bilindiği üzere görseller aslında içlerinde belirli değerler taşıyan piksellerden oluşan matrislerdir. Evrişim katmanında da orijinal görsel boyutlarından daha küçük bir filtre görselin üzerinde gezer ve bu görsellerden belirli özellikleri yakalamaya çalışır.\n\n\n**Pooling (Downsampling) Layer** — Ağırlık sayısını azaltır ve uygunluğu kontrol eder.\nEvrişimli katman gibi pooling (havuzlama) katmanı da boyutsallığı azaltma amacındadır. Bu sayede hem gereken işlem gücü azalır hem de yakalanan gereksiz özellikler yok sayılarak daha önemli özelliklere odaklanılır.\n\n**Fully-Connected Layer** — Sınıflamada kullanılan Standart Sinir Ağı\nFully Connected katmanda birkaç kez evrişimli katmandan ve pooling katmanından geçen ve matris halinde olan görselimiz düz bir vektör haline getirilir.\n","metadata":{}},{"cell_type":"markdown","source":"# 2.Temel Bağımlılıkları Belirleme","metadata":{}},{"cell_type":"code","source":"\nimport zipfile\nimport glob\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns \n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"ZDKIXSLKKZQA","outputId":"37b1912c-460a-412d-cfca-9a165cb95bb5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Veri Setinde Etiketlerin Okunması\n","metadata":{}},{"cell_type":"code","source":"print('Veriseti zipten çıkarmak')\nzip_files = glob.glob('/kaggle/input/dogs-vs-cats/*.zip')\n\n\nprint('{} tane dosya bulundu'.format(len(zip_files)))\nfor file in zip_files:\n    with zipfile.ZipFile(file, 'r') as Z:\n        Z.extractall('data')\n    print ('{} çıkarma işlemi bitti'.format(file.split('/')[-1]))\n          \n  ","metadata":{"id":"VX8NiXN4Kw16","outputId":"81f2612e-2982-45ac-d046-6fec3c9a7289","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resim sayıları\n\ntrain_dir = '/kaggle/working/data/train/'\ntest_dir  = '/kaggle/working/data/test1/'\n\nprint('Train dosyaları {} adet görsel'.format(len(os.listdir(train_dir))))\nprint('Test dosyaları  {} adet görsel'.format(len(os.listdir(test_dir))))            ","metadata":{"id":"jeiIIza1K3-x","outputId":"caf36cf7-6fd5-49be-8557-a4eb3b2e944f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef category(path): \n    label = []\n    for file in os.listdir(path):\n        lab = file.split('.')[0]\n        label.append(lab)\n    return label\n\n\n\ndef filename(path):\n    fname = []\n    for file in os.listdir(path):\n        fname.append(file)\n    return fname\n","metadata":{"id":"DvBDnsJXKxr9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = filename(train_dir) \ny_train = category(train_dir)\nx_test = filename(test_dir)\n\n\nprint('Dataframeler oluşturuluyor...')\ntotal_df = pd.DataFrame({ 'filename': x_train, 'category': y_train})\nsub_df = pd.DataFrame({'filename': x_test})\n\nprint('Dataframeler oluşturuldu')\n\nprint('Train kısmının içerisindeki tüm resimler total_df dataframe i hazırlanırken kullanılır')\nprint('Test kısmının içerisindeki kısımlar sub_df (submission dataframe) hazırlanırken kullanılır')\n\n","metadata":{"id":"ZkS8Las2KyHK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Veri Görselleştirme","metadata":{}},{"cell_type":"code","source":"print('Bu fonksiyon kategorilerin ID lerini, resimlerin dosya yolunu ve kategorileri verir.')\ndef img_path(directory):\n    paths = []\n    cate = []\n    ID_no = []\n    for file in os.listdir(directory):\n        path = os.path.join(directory, file)\n        paths.append(path)\n        cate.append(file.split('.')[0])\n        ID_no.append(file.split('.')[1])\n    return ID_no, paths, cate\n","metadata":{"id":"taVy1YO0UrXj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ID_no, img_paths, train_images = img_path(train_dir)\n\nprint('Dataframe içerisindeki verilerin görselleştirilmesi')\nvisual_df = pd.DataFrame({'ID_no':ID_no,'Category':train_images, 'img_paths': img_paths})\n\n#dataframe'e bir bakış\nvisual_df.head(10)","metadata":{"id":"wJWxS9aqaoo7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint('showImages fonksiyonu resimlerin galeri şeklinde gözükmesini sağlayan fonksiyondur')\n\nprint('num_row galeri görünümünün satır sayısını verir')\nprint('num_col galeri görünümünün kolon sayısını verir')\ndef showImages(num_row,num_col,data, what ):\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    \n    cat_df = data[data['Category'] == 'cat']\n    dog_df = data[data['Category'] == 'dog']\n\n    if what == 'dog':\n        X = dog_df['img_paths']\n        Y = dog_df['ID_no']\n    elif what == 'cat':\n        X = cat_df['img_paths']\n        Y = cat_df['ID_no']\n    else:\n        X = data['img_paths']\n        Y = data['ID_no']\n\n\n    from sklearn.utils import shuffle\n    (X_rand, Y_rand) = shuffle(X, Y)\n    \n    fig, axes = plt.subplots(num_row,num_col,figsize = (12,12))\n    fig.suptitle(' ',fontsize=10)\n\n    axes = axes.ravel()\n    for i in range(0, num_row*num_col):\n        x = load_img(X_rand.iloc[i],target_size= (150, 150))\n        axes[i].imshow(x)\n        axes[i].set_title(\"{}\".format(Y_rand.iloc[i]))\n        axes[i].axis('off')\n        plt.subplots_adjust(wspace =0)\n    fig.tight_layout()\n    print(\"ID numaralarıyla beraber {} adet {} örneği\".format((num_row * num_col),what))\n    \n    return","metadata":{"id":"JJWkH95iaoSR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImages( 10,10,visual_df, 'dog')","metadata":{"id":"y2OoIdtTaoPX","outputId":"15a528b6-fec1-4fcf-8cee-3108f3e92ad3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImages(10, 10, visual_df, 'cat')","metadata":{"id":"3IEE-WG-A4-g","outputId":"02bbb2de-055a-45c8-f447-b6519a11570f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showImages(10,10,visual_df, 'Dogs and Cat')","metadata":{"id":"yo7z0IwmWtHx","outputId":"65df8ea8-8a82-4788-a9cd-835ae1755229","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Veri Bölünmesi ve Veri Dağıtımı","metadata":{"id":"up4ajfD3Qbky"}},{"cell_type":"code","source":"train_valid_df, test_df = train_test_split(total_df, test_size = 0.04)\ntrain_df, valid_df = train_test_split(train_valid_df, test_size = 0.2)\n\n\ntrain_images = train_df.shape[0]\nvalid_images = valid_df.shape[0]\ntest_images = sub_df.shape[0]\n\nprint('Veri setinden training için ayrılan görsel miktarı {}'.format(train_images))\nprint('Veri setinden validation için ayrılan görsel miktarı {}'.format(valid_images))\nprint('Veri setinden test için ayrılan görsel miktarı {}'.format(test_images))\n","metadata":{"id":"FKcypyT2QYYP","outputId":"93b7bb55-989c-4cbf-fe1c-23a9f5c77b68","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Veri dağılım grafikleri\n\ndata  = [train_df['category'] ,  valid_df['category'], test_df['category']]\n\nfig, axis = plt.subplots(1,2, figsize = (25,6))\naxis = axis.ravel()\nsns.countplot(train_df['category'], ax = axis[0])\naxis[0].set_title('Train verisinin dağılımı')\naxis[0].set_xlabel('Classes')\nsns.countplot(valid_df['category'], ax = axis[1])\naxis[1].set_title('Validation verisinin dağılımı')\naxis[1].set_xlabel('Classes')\nplt.show","metadata":{"id":"Uc_iRxNJQYol","outputId":"32961a5f-d7ed-46ff-8b9a-e723196b8d0f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Vanilla CNN ile Sınıflandırma\n","metadata":{"id":"A8gmnjNu6m9J"}},{"cell_type":"markdown","source":"Veri setimiz eşit olarak dağıtılmıştır. Bu çalışmada ilk olarak önceden eğitilmiş bir model kullanılacaktır. Bu model daha da geliştirilebilir. Çalışmamız [keras applcations](https://keras.io/api/applications/) içerisindeki ImageNet çalışması ile benzerlik gösterdiğinden dolayı 2 etikete göre sınıflandırmak için içerisindeki herhangi bir model kullanılabilir. Sıfırdan özel bir CNN modeli ile daha yüksek bir doğruluk elde etmeye çalışmak o kadar pratik değildir. \n\nÖncelikle ne kadar iyi performans gösterebileceğini görmek için veri artırma işlemleri olmadan basit bir vanilla network'ü ile başlayalım. Daha sonra diğer tekniğe geçeceğiz.","metadata":{}},{"cell_type":"code","source":"img_size = 224\nbatch_size = 128\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataframeiterators without data agumnetation\n\ntrain_map = ImageDataGenerator()\nvalid_map = ImageDataGenerator()\ntest_map =  ImageDataGenerator()\n\n        \n#Creating a dataframe iterators for fitting\nvani_train_data = train_map.flow_from_dataframe(\n            train_df,train_dir,\n            x_col = 'filename',\n            y_col = 'category',\n            target_size = (img_size, img_size),\n            batch_size = batch_size,\n            class_mode = 'categorical')\n\nvani_valid_data = valid_map.flow_from_dataframe(\n             valid_df, train_dir,\n             x_col = 'filename',\n             y_col = 'category',\n             target_size = (img_size, img_size),\n             batch_size = batch_size,\n             class_mode = 'categorical')\n\n\nvani_test_data = test_map.flow_from_dataframe(\n             test_df, train_dir,\n             x_col = 'filename',\n             y_col = None,\n             target_size = (img_size, img_size),\n             batch_size = batch_size,\n             class_mode = None,\n             shuffle = False)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sıralı katmanlardan oluşan Sequential modeli oluşturulur.","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n    \n    \nvani_model = Sequential()\nvani_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same', input_shape = (224,224,3)))\nvani_model.add(Conv2D(16, (3,3), activation = 'relu', padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\nvani_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same', input_shape = (224,224,3)))\nvani_model.add(Conv2D(32, (3,3), activation = 'relu', padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\nvani_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))\nvani_model.add(Conv2D(64, (3,3), activation = 'relu', padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\nvani_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\nvani_model.add(Conv2D(128, (3,3), activation = 'relu', padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\nvani_model.add(Dropout(0.3))\nvani_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\nvani_model.add(Conv2D(256, (3,3), activation = 'relu', padding = 'same'))\nvani_model.add(MaxPooling2D(pool_size = (2,2),strides=(2,2)))\nvani_model.add(Dropout(0.3))\nvani_model.add(Flatten())\nvani_model.add(Dense(512, activation = 'relu'))\nvani_model.add(Dropout(0.5))\nvani_model.add(Dense(2, activation = 'softmax'))\n\nvani_model.summary()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n\nplot_model(vani_model, to_file='vani_model.png')\nSVG(model_to_dot(vani_model).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = 'categorical_crossentropy'\nopt = tf.keras.optimizers.Adam(learning_rate= 0.0001,beta_1=0.9, beta_2=0.999,epsilon=1e-07)\nmetrics = ['accuracy']\n\nvani_model.compile(loss = loss, optimizer = opt, metrics = metrics)\n\nvani_history = vani_model.fit(vani_train_data, epochs = 15,\n                          validation_data = vani_valid_data,\n                          validation_steps= valid_images//batch_size,\n                          steps_per_epoch= train_images//batch_size)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist1 = vani_history.history\nfig = plt.figure(figsize = (15,5))\n\nEpochs =  range(len(hist1['loss']))\n\nfig.add_subplot(1, 2 ,1)\nsns.lineplot(x = Epochs, y = hist1['val_loss'], label = 'Validation Loss')\nsns.lineplot(x = Epochs, y = hist1['loss'], label = 'Training_loss')\n\nfig.add_subplot(1,2,2)\nsns.lineplot(x = Epochs, y = hist1['val_accuracy'], label = 'Validation accuracy')\nsns.lineplot(x = Epochs, y = hist1['accuracy'], label = 'Training_accuracy')\n","metadata":{"id":"S-huJxUoJBDp","outputId":"a642a5ab-628c-4a68-aa0c-8b963cdc43af","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport warnings\nwarnings.filterwarnings('ignore')\n\nvani_pred = vani_model.predict_generator(vani_test_data)\ntest_df['vani_pred'] = np.argmax(vani_pred, axis = -1)\nlabels = dict((v,k) for k,v in vani_train_data.class_indices.items())\n\ntest_df['vani_pred'] = test_df['vani_pred'].map(labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n\n\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    if sum_stats:\n        accuracy  = np.trace(cf) / float(np.sum(cf))\n\n        if len(cf)==2:\n            precision = cf[1,1] / sum(cf[:,1])\n            recall    = cf[1,1] / sum(cf[1,:])\n            f1_score  = 2*precision*recall / (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    if figsize==None:\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        categories=False\n\n\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nvani_cf_matrix = confusion_matrix(test_df['category'],test_df['vani_pred'])\n\n\nlabels = [ 'True Neg','False Pos','False Neg','True Pos']\ncategories = ['Cat', 'Dog']\nmake_confusion_matrix(vani_cf_matrix, \n                      group_names=labels,\n                      categories=categories, \n                      title = 'Vanila CNN comfusion matrix')\n\nvani_matrix = classification_report(test_df['category'],test_df['vani_pred'])\nprint('Classification report : \\n',vani_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Veri Setini Büyütmek ve Öğrenme Oranı Çizelgesi (Learning Rate Schedule)","metadata":{}},{"cell_type":"code","source":"def data_argumentation_show(n, grid_size):\n    sample_aug_map = ImageDataGenerator(\n            zoom_range = 0.1,\n            rotation_range = 25,\n            horizontal_flip = True,\n            height_shift_range =0.2,\n            width_shift_range = 0.2,\n            fill_mode='nearest',\n            rescale = 1/255)\n    sample_data = sample_aug_map.flow_from_dataframe(\n            (train_df.sample(n)),\n            train_dir,\n            x_col = 'filename',\n            y_col = 'category',\n            target_size = (img_size, img_size),\n            class_mode = 'categorical')\n  \n  #subplot grid \n    plt.figure(figsize = (15,15))\n    for i in range(0,grid_size*grid_size):\n        plt.subplot(grid_size,grid_size, i+1)\n        for x,y in sample_data:\n            img = x[0]\n            plt.imshow(img)\n            break\n            plt.tight_layout()\n            plt.show()\n\n    return \n\n","metadata":{"id":"1xh9oi9dQYdu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata_argumentation_show(1, 5)","metadata":{"id":"VXw80kw6QYbi","outputId":"7c0ee447-836a-4198-8687-38d4bfc415f0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_argumentation_show(2, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('öğrenme hızı çizelgesi (learning rate schedule) için bir zayıflama öğrenme oranı (decay learning rate) belirleme')\nepoch = 50\nlearning_rate = 3e-5 \nlr_start = 0.00000001\nlr_min = 0.000001\nlr_max = 3e-5 \nlr_rampup_epochs = 1\nlr_sustain_epochs = 1\nlr_exp_decay = .8\n\ndef lrfn(epoch):\n    if epoch < lr_rampup_epochs:\n        lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n    elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n        lr = lr_max\n    else:\n        lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n    return lr\n    \n\n","metadata":{"id":"Hdjed4u7oYx8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nepochs_range = [i for i in range(50 if epochs<50 else epochs)]\nlearn_rate = [lrfn(x) for x in epochs_range]\n\n\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(learn_rate[0], max(learn_rate), learn_rate[-1]))\n\n\nfig = plt.figure()\nplt.plot(epochs_range, learn_rate, 'sr-') \nplt.xlabel('Range of epochs')\nplt.ylabel('Learning rate in 10^-5')\nplt.title('Learning Rate Schedule')\n\n\nprint('Bu çizelge(schedule), öğrenme hızının maksimum düzenleme periyodunun olmasını ve üssel toplamının azaltmasını sağlar.')","metadata":{"id":"v79OSrS0FWvK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. ResNet50 ile Sınıflandırma","metadata":{"id":"b5wQCvt-njNa"}},{"cell_type":"markdown","source":"ResNet, 2015 yılında He Kaiming, Sun Jian ve Microsoft Research Asia'dan diğerleri tarafından önerilen bir ağ yapısıdır ve ILSVRC-2015 sınıflandırma görevinde birinci olmuştur . Aynı zamanda ImageNet algılama, ImageNet yerelleştirme, COCO algılama ve COCO segmentasyon görevlerinde birinci olmuştur. \n\nAğ modelinin gerçek anlamda derinleşmeye başladığı kendinden önceki modellerden farklı bir mantığı barındıran ResNet; artık değerlerin (residual value) sonraki katmanlara besleyen blokların (residual block) modele eklenmesiyle oluşmaktadır. ResNet bu özelliği ile klasik bir model olmaktan çıkmaktadır ve modelin performansını daha iyi bir hale getirmektedir.\n","metadata":{}},{"cell_type":"code","source":"\n\nfrom keras.applications.resnet50 import preprocess_input\n\ntrain_aug_map = ImageDataGenerator(\n                    rotation_range=10,\n                    zoom_range=0.1,\n                    horizontal_flip=True,\n                    fill_mode='nearest',\n                    width_shift_range=0.1,\n                    height_shift_range=0.1,\n                    preprocessing_function = preprocess_input)\nres_train_data = train_aug_map.flow_from_dataframe(\n            train_df, train_dir,\n            x_col = 'filename',\n            y_col = 'category',\n            target_size = (img_size, img_size),\n            batch_size = batch_size,\n            class_mode = 'categorical')\n\n\nvalid_aug_map = ImageDataGenerator(preprocessing_function = preprocess_input)\n\nres_valid_data = valid_aug_map.flow_from_dataframe(\n             valid_df, train_dir,\n             x_col = 'filename',\n             y_col = 'category',\n             target_size = (img_size, img_size),\n             batch_size = batch_size,\n             class_mode = 'categorical')\n\n\n\n\ntest_aug_map = ImageDataGenerator(preprocessing_function = preprocess_input)\n\nres_test_data = test_aug_map.flow_from_dataframe(\n             test_df, train_dir,\n             x_col = 'filename',\n             y_col = None,\n             class_mode = None,\n             target_size = (img_size, img_size),\n             shuffle = False)\n           \n","metadata":{"id":"YXMZlhOfPQt5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications import resnet\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.layers import  *\nfrom keras.models import Model, Sequential\nfrom keras import optimizers\nfrom keras import regularizers\n\nfrom keras import backend as K\nK.clear_session()\n\n#loading resent \nresNet = resnet.ResNet50(weights = 'imagenet',\n                        include_top = False,\n                        input_shape = (224,224, 3))\n\nresNet.trainable = False # Freeze layers\nresNet_model = Sequential([\n        resNet,\n        Flatten(),\n        Dense(1024, activation = 'relu'),\n        Dropout(0.4),\n        Dense(2, activation = 'softmax')])\n     \n\noptimizer = optimizers.Adam(1e-5)\n\nresNet_model.summary()","metadata":{"id":"vf854PFUPQ0z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(resNet_model, to_file='resNet_model.png')\nSVG(model_to_dot(resNet_model).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Erken durdurma faktörünün ve öğrenme oranı çizelgesinin (learning rate schedule) ayarlanması')\n\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler\n\nearlystop = EarlyStopping(patience= 5)\n    \nlr_callback = LearningRateScheduler(lrfn, verbose = True)\n\ncallbacks = [earlystop, lr_callback]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resNet_model.compile(optimizer = optimizer,\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])\n\n\nresnet_history = resNet_model.fit_generator(res_train_data, epochs = 15,\n                          validation_data = res_valid_data,\n                          validation_steps= valid_images//batch_size,\n                          steps_per_epoch= train_images//batch_size,\n                          callbacks = callbacks)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist2 = resnet_history.history\nfig = plt.figure(figsize = (15,5))\n\nEpochs =  range(len(hist2['loss']))\n\nfig.add_subplot(1, 2 ,1)\nsns.lineplot(x = Epochs, y = hist2['val_loss'], label = 'Validation Loss')\nsns.lineplot(x = Epochs, y = hist2['loss'], label = 'Training_loss')\n\nfig.add_subplot(1,2,2)\nsns.lineplot(x = Epochs, y = hist2['val_accuracy'], label = 'Validation accuracy')\nsns.lineplot(x = Epochs, y = hist2['accuracy'], label = 'Training_accuracy')\n","metadata":{"id":"zNc2CxJwPQpF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_pred = resNet_model.predict_generator(res_test_data)\ntest_df['res_pred'] = np.argmax(res_pred, axis = -1)\nlabels = dict((v,k) for k,v in res_train_data.class_indices.items())\n\ntest_df['res_pred'] = test_df['res_pred'].map(labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nres_cf_matrix = confusion_matrix(test_df['category'],test_df['res_pred'])\n\n\nlabels = [ 'True Neg','False Pos','False Neg','True Pos']\ncategories = ['Cat', 'Dog']\nmake_confusion_matrix(res_cf_matrix, \n                      group_names=labels,\n                      categories=categories, \n                      title = 'ResNet comfusion matrix')\n\nres_matrix = classification_report(test_df['category'],test_df['res_pred'])\nprint('Classification report : \\n',res_matrix)","metadata":{"id":"lA8mVBcAPQkL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Test Verisi ile Son Tahminler","metadata":{}},{"cell_type":"code","source":"# generating an dataframe iterator for test dataset\n\nvani_sub_aug_map = ImageDataGenerator()\nres_sub_aug_map = ImageDataGenerator(preprocessing_function = preprocess_input)\n\nvani_sub_data = vani_sub_aug_map.flow_from_dataframe(\n             sub_df, test_dir,\n             x_col = 'filename',\n             y_col = None,\n             class_mode = None,\n             target_size = (img_size, img_size),\n             shuffle = False)\n\n\nres_sub_data = res_sub_aug_map.flow_from_dataframe(\n             sub_df, test_dir,\n             x_col = 'filename',\n             y_col = None,\n             class_mode = None,\n             target_size = (img_size, img_size),\n             shuffle = False)","metadata":{"id":"-_YrpgMEPQhT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vani_pred_sub = vani_model.predict_generator(vani_sub_data)\nsub_df['vani_pred_sub'] = np.argmax(vani_pred_sub, axis = -1)\nlabels = dict((v,k) for k,v in res_train_data.class_indices.items())\nsub_df['vani_pred_sub'] = sub_df['vani_pred_sub'].map(labels)\n\n\nres_pred_sub = resNet_model.predict_generator(res_sub_data)\nsub_df['res_pred_sub'] = np.argmax(res_pred_sub, axis = -1)\nlabels = dict((v,k) for k,v in res_train_data.class_indices.items())\nsub_df['res_pred_sub'] = sub_df['res_pred_sub'].map(labels)\n\nsub_df.head()","metadata":{"id":"PXXnPlqpPQfQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_sample = sub_df.sample(18)\npred_sample.reset_index(drop = True, inplace = True)\nplt.figure(figsize=(12,24))\nfor index, row in pred_sample.iterrows():\n    filename = row['filename']\n    vani_pred = row['vani_pred_sub']\n    res_pred = row['res_pred_sub']\n    img = load_img( test_dir + filename, target_size= (img_size, img_size))\n    plt.subplot(6,3, index+1)\n    plt.imshow(img)\n    plt.text(130, 175, 'vanila_pred: {}'.format(vani_pred), color='lightgreen',fontsize= 11, bbox=dict(facecolor='black', alpha=0.9))\n    plt.text(130, 200, 'resNet_pred: {}'.format(res_pred), color='red',fontsize= 11, bbox=dict(facecolor='black', alpha=0.9))\n    plt.title(filename.split('.')[0])\nplt.tight_layout()\n#plt.subplots_adjust( wspace=0, hspace= 1)\nplt.show()\n   ","metadata":{"id":"yL1uQEtzPQdP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"id":"49xwDbf1PQWJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading predictions to submission.csv file","metadata":{}},{"cell_type":"code","source":"sub_df['res_pred_sub'].replace({'cat': 0, 'dog': 1},  inplace = True)\nsub_df.rename(columns = {'res_pred_sub': 'label'}, inplace = True)\nsub_df['filename'] = sub_df['filename'].str.split('.').str[0]\nsub_df.rename(columns = {'filename': 'id'}, inplace = True)\nsub_df.drop(['vani_pred_sub'], axis=1, inplace=True)\nsub_df.to_csv('submission.csv', index=False)","metadata":{"id":"MHsnrhaeFV-D","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}