{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# We will build a model that takes an image as input and determines whether the image contains a picture of a dog or a cat.","metadata":{}},{"cell_type":"markdown","source":"![](https://lirp.cdn-website.com/f499246c/dms3rep/multi/opt/Convolutional+Neural+Network-637w.jpg)","metadata":{}},{"cell_type":"markdown","source":"image credits: [Click Here](https://lirp.cdn-website.com/f499246c/dms3rep/multi/opt/Convolutional+Neural+Network-637w.jpg)","metadata":{}},{"cell_type":"markdown","source":"# About Dataset:\n- ### The Asirra (animal species image recognition for restricting access) dataset was introduced in 2013 for a machine learning competition. The dataset includes 25,000 images with equal numbers of labels for cats and dogs.","metadata":{}},{"cell_type":"markdown","source":"# Cats vs Dogs Classification using CNN Tensorflow.Keras \n- A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data. A CNN uses a system much like a multilayer perceptron that has been designed for reduced processing requirements\n\n- image credits: [Click Here](https://media.geeksforgeeks.org/wp-content/uploads/cat-vs-dog.jpp)","metadata":{}},{"cell_type":"markdown","source":"![](https://media.geeksforgeeks.org/wp-content/uploads/cat-vs-dog.jpg)","metadata":{}},{"cell_type":"code","source":"# Import the libraries\nimport os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:20:55.222291Z","iopub.execute_input":"2022-01-11T10:20:55.222834Z","iopub.status.idle":"2022-01-11T10:21:01.753553Z","shell.execute_reply.started":"2022-01-11T10:20:55.222738Z","shell.execute_reply":"2022-01-11T10:21:01.752837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking if gpu is available \nimport tensorflow as tf\ntf.test.is_gpu_available()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:51:31.996808Z","iopub.execute_input":"2022-01-11T10:51:31.997112Z","iopub.status.idle":"2022-01-11T10:51:32.010292Z","shell.execute_reply.started":"2022-01-11T10:51:31.997079Z","shell.execute_reply":"2022-01-11T10:51:32.009243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Picking GPU if available or else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:01.814515Z","iopub.execute_input":"2022-01-11T10:21:01.81496Z","iopub.status.idle":"2022-01-11T10:21:01.827149Z","shell.execute_reply.started":"2022-01-11T10:21:01.814921Z","shell.execute_reply":"2022-01-11T10:21:01.82644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:01.829611Z","iopub.execute_input":"2022-01-11T10:21:01.830072Z","iopub.status.idle":"2022-01-11T10:21:01.837042Z","shell.execute_reply.started":"2022-01-11T10:21:01.830033Z","shell.execute_reply":"2022-01-11T10:21:01.836283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:01.840034Z","iopub.execute_input":"2022-01-11T10:21:01.840243Z","iopub.status.idle":"2022-01-11T10:21:01.845935Z","shell.execute_reply.started":"2022-01-11T10:21:01.840209Z","shell.execute_reply":"2022-01-11T10:21:01.845101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Prepare dataset for training model:","metadata":{}},{"cell_type":"code","source":"data_set = \"dogs-vs-cats\"\n\nimport zipfile \nwith zipfile.ZipFile(\"/kaggle/input/\"+ data_set +\"/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    # save all files to kaggle/files/images\n    destination = '/kaggle/files/images/train'\n    z.extractall(destination)\n    \nwith zipfile.ZipFile(\"/kaggle/input/\"+ data_set +\"/test1.zip\",\"r\") as z:\n    z.extractall(\".\")\n    # save all files to kaggle/files/images\n    destination = '/kaggle/files/images/test'\n    z.extractall(destination)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:01.847467Z","iopub.execute_input":"2022-01-11T10:21:01.847719Z","iopub.status.idle":"2022-01-11T10:21:32.952251Z","shell.execute_reply.started":"2022-01-11T10:21:01.847684Z","shell.execute_reply":"2022-01-11T10:21:32.951492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def list_full_paths(directory):\n    return [os.path.join(directory, file) for file in os.listdir(directory)]\n\ntrain = pd.DataFrame({'filepath': list_full_paths('/kaggle/files/images/train/train')})\ntrain['truth_label'] = np.where(train['filepath'].str.contains('dog'), 'dog', 'cat')\n\ntest = pd.DataFrame({'filepath': list_full_paths('/kaggle/files/images/test/test1')})","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:32.953397Z","iopub.execute_input":"2022-01-11T10:21:32.95367Z","iopub.status.idle":"2022-01-11T10:21:33.069216Z","shell.execute_reply.started":"2022-01-11T10:21:32.953634Z","shell.execute_reply":"2022-01-11T10:21:33.06853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test = train_test_split(train, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.070284Z","iopub.execute_input":"2022-01-11T10:21:33.070543Z","iopub.status.idle":"2022-01-11T10:21:33.083153Z","shell.execute_reply.started":"2022-01-11T10:21:33.07051Z","shell.execute_reply":"2022-01-11T10:21:33.082267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.084964Z","iopub.execute_input":"2022-01-11T10:21:33.085228Z","iopub.status.idle":"2022-01-11T10:21:33.090999Z","shell.execute_reply.started":"2022-01-11T10:21:33.085194Z","shell.execute_reply":"2022-01-11T10:21:33.090262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.095047Z","iopub.execute_input":"2022-01-11T10:21:33.095547Z","iopub.status.idle":"2022-01-11T10:21:33.101236Z","shell.execute_reply.started":"2022-01-11T10:21:33.095511Z","shell.execute_reply":"2022-01-11T10:21:33.100365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.102516Z","iopub.execute_input":"2022-01-11T10:21:33.103263Z","iopub.status.idle":"2022-01-11T10:21:33.11038Z","shell.execute_reply.started":"2022-01-11T10:21:33.103224Z","shell.execute_reply":"2022-01-11T10:21:33.10947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.111701Z","iopub.execute_input":"2022-01-11T10:21:33.112095Z","iopub.status.idle":"2022-01-11T10:21:33.118987Z","shell.execute_reply.started":"2022-01-11T10:21:33.112058Z","shell.execute_reply":"2022-01-11T10:21:33.11801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.12107Z","iopub.execute_input":"2022-01-11T10:21:33.121641Z","iopub.status.idle":"2022-01-11T10:21:33.133578Z","shell.execute_reply.started":"2022-01-11T10:21:33.121604Z","shell.execute_reply":"2022-01-11T10:21:33.132898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n                    rescale = 1./255,\n                    shear_range = 0.2,\n                    zoom_range = 0.2,\n                    rotation_range=40,\n                    width_shift_range=0.2,\n                    height_shift_range=0.2,\n                    horizontal_flip=True,\n                    fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.134611Z","iopub.execute_input":"2022-01-11T10:21:33.135184Z","iopub.status.idle":"2022-01-11T10:21:33.140832Z","shell.execute_reply.started":"2022-01-11T10:21:33.135147Z","shell.execute_reply":"2022-01-11T10:21:33.140097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set = train_datagen.flow_from_dataframe(dataframe=X_train, x_col='filepath', y_col='truth_label', class_mode='categorical', target_size = (64, 64), batch_size = 128)\ntest_set = test_datagen.flow_from_dataframe(dataframe=X_test, x_col='filepath', y_col='truth_label', class_mode='categorical', target_size = (64, 64), batch_size = 128)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.142034Z","iopub.execute_input":"2022-01-11T10:21:33.142526Z","iopub.status.idle":"2022-01-11T10:21:33.392076Z","shell.execute_reply.started":"2022-01-11T10:21:33.142493Z","shell.execute_reply":"2022-01-11T10:21:33.39134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- plotting images from dataset","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n\nbatches_augmented = train_datagen.flow_from_directory('/kaggle/files/images/', target_size = (512, 512), batch_size = 16, class_mode = 'categorical', seed=1234)\nbatches_real = test_datagen.flow_from_directory('/kaggle/files/images/', target_size = (512, 512), batch_size = 16, class_mode = 'categorical', seed=1234)\n\nx_batch_augmented, y_batch_augmented = next(batches_augmented)\nx_batch_real, y_batch_real = next(batches_real)\n\nfor i in range(16):\n    image_augmented = x_batch_augmented[i]\n    image_real = x_batch_real[i]\n    \n    title_add_on = \"random image\"\n    if y_batch_augmented[i][1]: title_add_on =  \"dog vs cat\"\n\n    plt.subplot(221)\n    plt.imshow(image_real)\n    plt.title(\"original \" + title_add_on)\n\n        \n    plt.subplot(222)\n    plt.imshow(image_augmented)\n    plt.title(\"augmented \" + title_add_on)\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:33.393448Z","iopub.execute_input":"2022-01-11T10:21:33.393917Z","iopub.status.idle":"2022-01-11T10:21:42.573617Z","shell.execute_reply.started":"2022-01-11T10:21:33.393876Z","shell.execute_reply":"2022-01-11T10:21:42.572451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Create the neural net model:","metadata":{}},{"cell_type":"code","source":"classifier = Sequential()\n\nclassifier.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n                padding=\"valid\", input_shape = (64,64,3)))\n\nclassifier.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n\nclassifier.add(Conv2D(filters=32,kernel_size=(3,3),activation=\"relu\",\n                padding=\"valid\", input_shape = (64,64,3)))\n\nclassifier.add(MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n\nclassifier.add(Flatten())\nclassifier.add(Dense(128,activation=\"relu\")) \nclassifier.add(Dense(2,activation=\"sigmoid\")) ","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:42.574975Z","iopub.execute_input":"2022-01-11T10:21:42.575619Z","iopub.status.idle":"2022-01-11T10:21:47.715533Z","shell.execute_reply.started":"2022-01-11T10:21:42.575577Z","shell.execute_reply":"2022-01-11T10:21:47.714854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:47.719301Z","iopub.execute_input":"2022-01-11T10:21:47.721325Z","iopub.status.idle":"2022-01-11T10:21:47.733068Z","shell.execute_reply.started":"2022-01-11T10:21:47.721285Z","shell.execute_reply":"2022-01-11T10:21:47.731556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:47.736588Z","iopub.execute_input":"2022-01-11T10:21:47.738555Z","iopub.status.idle":"2022-01-11T10:21:48.19815Z","shell.execute_reply.started":"2022-01-11T10:21:47.738514Z","shell.execute_reply":"2022-01-11T10:21:48.197313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Model Training ","metadata":{}},{"cell_type":"code","source":"history = classifier.fit(training_set, validation_data = test_set, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:21:48.199562Z","iopub.execute_input":"2022-01-11T10:21:48.199838Z","iopub.status.idle":"2022-01-11T10:47:20.942837Z","shell.execute_reply.started":"2022-01-11T10:21:48.199802Z","shell.execute_reply":"2022-01-11T10:47:20.942029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set2 = test_datagen.flow_from_dataframe(dataframe=test,\n    directory = '/kaggle/files/images/test',\n    x_col = 'filepath',\n    y_col = None,\n    class_mode = None,\n    target_size = (64, 64),\n    batch_size = 32,\n    shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:47:20.944289Z","iopub.execute_input":"2022-01-11T10:47:20.945878Z","iopub.status.idle":"2022-01-11T10:47:21.052395Z","shell.execute_reply.started":"2022-01-11T10:47:20.945827Z","shell.execute_reply":"2022-01-11T10:47:21.051672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = classifier.predict(test_set2, steps = np.ceil(test.shape[0] / 32))\n\ntest[\"test_preds\"] = np.argmax(test_preds, axis = 1)\nlabels = dict((v,k) for k,v in training_set.class_indices.items())\n\ntest['test_preds'] = test['test_preds'].map(labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:47:21.053514Z","iopub.execute_input":"2022-01-11T10:47:21.053906Z","iopub.status.idle":"2022-01-11T10:47:48.64004Z","shell.execute_reply.started":"2022-01-11T10:47:21.053867Z","shell.execute_reply":"2022-01-11T10:47:48.639303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_test = test.sample(64).reset_index(drop = True)\n\nfig = plt.figure(1, figsize = (24, 20))\nfig.suptitle(\"Sample Predictions\")\n\nfor i in range(len(sample_test)):\n    \n    plt.subplot(10, 8, i + 1)\n    image = load_img(sample_test.filepath[i])\n    plt.imshow(image)\n    plt.axis(\"off\")\n    plt.title(f\"Predicted as {sample_test['test_preds'][i]}\")\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:47:48.641128Z","iopub.execute_input":"2022-01-11T10:47:48.641378Z","iopub.status.idle":"2022-01-11T10:47:53.293926Z","shell.execute_reply.started":"2022-01-11T10:47:48.641332Z","shell.execute_reply":"2022-01-11T10:47:53.291494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now will be using VGG16\n\n- VGG-16 is a convolutional neural network that is 16 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database [1]. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. \n\n- image credits: [Click Here](https://media.geeksforgeeks.org/wp-content/uploads/20200219152327/conv-layers-vgg16.jpg)","metadata":{}},{"cell_type":"markdown","source":"![](https://media.geeksforgeeks.org/wp-content/uploads/20200219152327/conv-layers-vgg16.jpg)","metadata":{}},{"cell_type":"code","source":"!rm -r ./*","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:47:53.295316Z","iopub.execute_input":"2022-01-11T10:47:53.295734Z","iopub.status.idle":"2022-01-11T10:47:54.980098Z","shell.execute_reply.started":"2022-01-11T10:47:53.295698Z","shell.execute_reply":"2022-01-11T10:47:54.979163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/dogs-vs-cats/train.zip -d ./new_data","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-11T10:47:54.983693Z","iopub.execute_input":"2022-01-11T10:47:54.983915Z","iopub.status.idle":"2022-01-11T10:48:03.669572Z","shell.execute_reply.started":"2022-01-11T10:47:54.983886Z","shell.execute_reply":"2022-01-11T10:48:03.668744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The path to the directory where the original\n# dataset was uncompressed\noriginal_dataset_dir = './new_data/train'","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:03.671068Z","iopub.execute_input":"2022-01-11T10:48:03.671336Z","iopub.status.idle":"2022-01-11T10:48:03.676318Z","shell.execute_reply.started":"2022-01-11T10:48:03.671299Z","shell.execute_reply":"2022-01-11T10:48:03.675665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The directory where we will\n# store our smaller dataset\nbase_dir = './new_data_base'\nos.mkdir(base_dir)\n\n# Directories for our training,\n# validation and test splits\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:03.677532Z","iopub.execute_input":"2022-01-11T10:48:03.67818Z","iopub.status.idle":"2022-01-11T10:48:03.692094Z","shell.execute_reply.started":"2022-01-11T10:48:03.678139Z","shell.execute_reply":"2022-01-11T10:48:03.691458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory with our training cat pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\nos.mkdir(train_cats_dir)\n\n# Directory with our training dog pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nos.mkdir(train_dogs_dir)\n\n# Directory with our validation cat pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nos.mkdir(validation_cats_dir)\n\n# Directory with our validation dog pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nos.mkdir(validation_dogs_dir)\n\n# Directory with our validation cat pictures\ntest_cats_dir = os.path.join(test_dir, 'cats')\nos.mkdir(test_cats_dir)\n\n# Directory with our validation dog pictures\ntest_dogs_dir = os.path.join(test_dir, 'dogs')\nos.mkdir(test_dogs_dir)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:03.697444Z","iopub.execute_input":"2022-01-11T10:48:03.6983Z","iopub.status.idle":"2022-01-11T10:48:03.707371Z","shell.execute_reply.started":"2022-01-11T10:48:03.698263Z","shell.execute_reply":"2022-01-11T10:48:03.706685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n# Copy first 1000 cat images to train_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_cats_dir, fname)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:03.709954Z","iopub.execute_input":"2022-01-11T10:48:03.710171Z","iopub.status.idle":"2022-01-11T10:48:03.811379Z","shell.execute_reply.started":"2022-01-11T10:48:03.710146Z","shell.execute_reply":"2022-01-11T10:48:03.810639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy next 500 cat images to validation_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_cats_dir, fname)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:03.812721Z","iopub.execute_input":"2022-01-11T10:48:03.812989Z","iopub.status.idle":"2022-01-11T10:48:03.867869Z","shell.execute_reply.started":"2022-01-11T10:48:03.812954Z","shell.execute_reply":"2022-01-11T10:48:03.867169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy next 500 cat images to test_cats_dir\nfnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_cats_dir, fname)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:03.869295Z","iopub.execute_input":"2022-01-11T10:48:03.869795Z","iopub.status.idle":"2022-01-11T10:48:03.922237Z","shell.execute_reply.started":"2022-01-11T10:48:03.869753Z","shell.execute_reply":"2022-01-11T10:48:03.921441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy first 1000 dog images to train_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_dogs_dir, fname)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:03.923646Z","iopub.execute_input":"2022-01-11T10:48:03.923928Z","iopub.status.idle":"2022-01-11T10:48:04.04919Z","shell.execute_reply.started":"2022-01-11T10:48:03.92389Z","shell.execute_reply":"2022-01-11T10:48:04.048277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy next 500 dog images to validation_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_dogs_dir, fname)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:04.050655Z","iopub.execute_input":"2022-01-11T10:48:04.050954Z","iopub.status.idle":"2022-01-11T10:48:04.108219Z","shell.execute_reply.started":"2022-01-11T10:48:04.050917Z","shell.execute_reply":"2022-01-11T10:48:04.107516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy next 500 dog images to test_dogs_dir\nfnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_dogs_dir, fname)\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:04.110945Z","iopub.execute_input":"2022-01-11T10:48:04.111141Z","iopub.status.idle":"2022-01-11T10:48:04.176391Z","shell.execute_reply.started":"2022-01-11T10:48:04.111116Z","shell.execute_reply":"2022-01-11T10:48:04.175776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('total training dog images:', len(os.listdir(train_dogs_dir)))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:04.177442Z","iopub.execute_input":"2022-01-11T10:48:04.177889Z","iopub.status.idle":"2022-01-11T10:48:04.185581Z","shell.execute_reply.started":"2022-01-11T10:48:04.177857Z","shell.execute_reply":"2022-01-11T10:48:04.184333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import models","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:04.187114Z","iopub.execute_input":"2022-01-11T10:48:04.187636Z","iopub.status.idle":"2022-01-11T10:48:04.191848Z","shell.execute_reply.started":"2022-01-11T10:48:04.187598Z","shell.execute_reply":"2022-01-11T10:48:04.19107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\n\nconv_base = VGG16(weights='imagenet',\n                  include_top=False, \n                  input_shape=(150, 150, 3))\n\nconv_base.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:04.193366Z","iopub.execute_input":"2022-01-11T10:48:04.193916Z","iopub.status.idle":"2022-01-11T10:48:04.890383Z","shell.execute_reply.started":"2022-01-11T10:48:04.19388Z","shell.execute_reply":"2022-01-11T10:48:04.889662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rescale=1./255)\nbatch_size = 20","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:04.893153Z","iopub.execute_input":"2022-01-11T10:48:04.893357Z","iopub.status.idle":"2022-01-11T10:48:04.899955Z","shell.execute_reply.started":"2022-01-11T10:48:04.893325Z","shell.execute_reply":"2022-01-11T10:48:04.899282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    \n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n    \n    i = 0\n    \n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        \n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        \n        i += 1\n        if i * batch_size >= sample_count:\n            # Note that since generators yield data indefinitely in a loop, \n            # we must `break` after every image has been seen once.\n            break\n    return features, labels\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:04.901655Z","iopub.execute_input":"2022-01-11T10:48:04.90208Z","iopub.status.idle":"2022-01-11T10:48:04.909997Z","shell.execute_reply.started":"2022-01-11T10:48:04.902038Z","shell.execute_reply":"2022-01-11T10:48:04.90926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features, train_labels = extract_features(train_dir, 2000)\nvalidation_features, validation_labels = extract_features(validation_dir, 1000)\ntest_feature, test_labels = extract_features(test_dir, 1000)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:04.911068Z","iopub.execute_input":"2022-01-11T10:48:04.911313Z","iopub.status.idle":"2022-01-11T10:48:32.459041Z","shell.execute_reply.started":"2022-01-11T10:48:04.911276Z","shell.execute_reply":"2022-01-11T10:48:32.458275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flattening our input data for dense layers\ntrain_features = np.reshape(train_features, (2000, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\ntest_feature = np.reshape(test_feature, (1000, 4 * 4 * 512))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:32.46027Z","iopub.execute_input":"2022-01-11T10:48:32.460569Z","iopub.status.idle":"2022-01-11T10:48:32.467217Z","shell.execute_reply.started":"2022-01-11T10:48:32.460531Z","shell.execute_reply":"2022-01-11T10:48:32.465193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Dense(256, activation=\"relu\", input_dim = 4 * 4 * 512))\n\n# adding Dropout layer for regularization\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Dense(1, activation=\"sigmoid\"))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:32.468476Z","iopub.execute_input":"2022-01-11T10:48:32.469035Z","iopub.status.idle":"2022-01-11T10:48:32.501108Z","shell.execute_reply.started":"2022-01-11T10:48:32.468989Z","shell.execute_reply":"2022-01-11T10:48:32.500457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\nmodel.compile(\n    loss=\"binary_crossentropy\", \n    optimizer=optimizers.RMSprop(lr=2e-5), \n    metrics=[\"acc\"])","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:32.502399Z","iopub.execute_input":"2022-01-11T10:48:32.502651Z","iopub.status.idle":"2022-01-11T10:48:32.515211Z","shell.execute_reply.started":"2022-01-11T10:48:32.502618Z","shell.execute_reply":"2022-01-11T10:48:32.51455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_features, train_labels, \n    epochs=30, \n    batch_size=20,\n    validation_data=(validation_features, validation_labels))","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:32.516581Z","iopub.execute_input":"2022-01-11T10:48:32.51707Z","iopub.status.idle":"2022-01-11T10:48:43.279958Z","shell.execute_reply.started":"2022-01-11T10:48:32.517023Z","shell.execute_reply":"2022-01-11T10:48:43.279217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"./cats_and_dogs_vgg16.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:43.281624Z","iopub.execute_input":"2022-01-11T10:48:43.28187Z","iopub.status.idle":"2022-01-11T10:48:43.320453Z","shell.execute_reply.started":"2022-01-11T10:48:43.281836Z","shell.execute_reply":"2022-01-11T10:48:43.319715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:43.321769Z","iopub.execute_input":"2022-01-11T10:48:43.322008Z","iopub.status.idle":"2022-01-11T10:48:43.326911Z","shell.execute_reply.started":"2022-01-11T10:48:43.321974Z","shell.execute_reply":"2022-01-11T10:48:43.326241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc') \nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy') \nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss') \nplt.plot(epochs, val_loss, 'b', label='Validation loss') \nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T10:48:43.328396Z","iopub.execute_input":"2022-01-11T10:48:43.328943Z","iopub.status.idle":"2022-01-11T10:48:43.718956Z","shell.execute_reply.started":"2022-01-11T10:48:43.328901Z","shell.execute_reply":"2022-01-11T10:48:43.718272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion:\n- **Both performed Quite well.**","metadata":{}}]}