{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\nfrom os import makedirs\nfrom os import listdir\nfrom shutil import copyfile\nfrom random import seed\nfrom random import random\nimport shutil\nif(os.path.isdir('/kaggle/working/train/')):\n    shutil.rmtree('/kaggle/working/train/')\n    shutil.rmtree('/kaggle/working/validation/')\n    shutil.rmtree('/kaggle/working/training/')\n    shutil.rmtree('/kaggle/working/test1/')\nelse:\n    # create directories\n    with zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats/train.zip\",\"r\") as z:\n            z.extractall(\".\")\n    dataset_home = '/kaggle/working/'\n    subdirs = ['training/', 'validation/']\n    for subdir in subdirs:\n        labeldirs = ['dogs/', 'cats/']\n        for labldir in labeldirs:\n            newdir = dataset_home + subdir + labldir\n            makedirs(newdir, exist_ok=True)\n    # seed random number generator\n    seed(1)\n    # # define ratio of pictures to use for validation\n    val_ratio = 0.25\n    # # copy training dataset images into subdirectories\n    src_directory = '/kaggle/working/train/'\n    for file in listdir(src_directory):\n        src = src_directory + '/' + file\n        dst_dir = 'training/'\n        if random() < val_ratio:\n            dst_dir = 'validation/'\n        if file.startswith('cat'):\n            dst = dataset_home + dst_dir + 'cats/'  + file\n            copyfile(src, dst)\n        elif file.startswith('dog'):\n            dst = dataset_home + dst_dir + 'dogs/'  + file\n            copyfile(src, dst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot dog photos from the dogs vs cats dataset\nfrom matplotlib import pyplot\nfrom matplotlib.image import imread\nfilename = '/kaggle/working/train/cat.0.jpg'\n# filename = folder + file\nimage = imread(filename)\npyplot.imshow(image)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.test.gpu_device_name())\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# baseline model for the dogs vs cats dataset\nimport sys\nfrom matplotlib import pyplot\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.regularizers import l2\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\n\nclass cnn_arch():\n\tdef __init__(self):\n\t\tself.input_size = (200,200,3)\n\t\tself.kernel_initializer = 'he_uniform'\n\t\tself.activation = 'relu'\n\t\tself.padding = 'same'\n\t\tself.loss = 'binary_crossentropy'\n\t\tself.kernel_regularizer = 'l2'\n    \n\t# define cnn model\n\tdef define_model(self):\n\t\tmodel = Sequential()\n\t\tmodel.add(Conv2D(32, (3, 3), \n                         activation=self.activation, \n                         kernel_initializer=self.kernel_initializer,\n                         kernel_regularizer=l2(0.001),\n                         padding=self.padding, input_shape=self.input_size))\n\t\tmodel.add(MaxPooling2D((2, 2)))\n\t\tmodel.add(Conv2D(64, (3, 3), \n                         activation=self.activation, \n                         kernel_initializer=self.kernel_initializer, \n                         kernel_regularizer=l2(0.001),\n                         padding=self.padding))\n\t\tmodel.add(MaxPooling2D((2, 2)))\n\t\tmodel.add(Conv2D(128, (3, 3), \n                         activation=self.activation, \n                         kernel_initializer=self.kernel_initializer, \n                         kernel_regularizer=l2(0.001),\n                         padding=self.padding))\n\t\tmodel.add(MaxPooling2D((2, 2)))\n\t\tmodel.add(Flatten())\n\t\tmodel.add(Dense(128, \n                        activation=self.activation, \n                        kernel_initializer=self.kernel_initializer,\n                        kernel_regularizer=l2(0.001)))\n\t\tmodel.add(Dense(1, activation='sigmoid'))\n\t\t# compile model\n\t\topt = SGD(lr=0.001, momentum=0.9)\n\t\tmodel.compile(optimizer='adam', loss=self.loss, metrics=['accuracy'])\n\t\treturn model\n\n\t# plot diagnostic learning curves\n\tdef summarize_diagnostics(self, history):\n\t\t# plot loss\n\t\tpyplot.subplot(211)\n\t\tpyplot.title('Cross Entropy Loss')\n\t\tpyplot.plot(history.history['loss'], color='blue', label='train')\n\t\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n\t\t# plot accuracy\n\t\tpyplot.subplot(212)\n\t\tpyplot.title('Classification Accuracy')\n\t\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n\t\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n\t\t# save plot to file\n\t\tfilename = sys.argv[0].split('/')[-1]\n\t\tpyplot.savefig(filename + '_plot.png')\n\t\tpyplot.close()\n\n\t# run the test harness for evaluating a model\n\tdef train(self):\n\t\ttf.debugging.set_log_device_placement(True)\n\t\t# define model\n\t\tmodel = self.define_model()\n\t\t# create data generators\n\t\ttrain_datagen = ImageDataGenerator(rescale=1.0/255.0,\n\t\t\twidth_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n\t\ttest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n\t\t# early stopping\n# \t\tes = EarlyStopping(monitor='val_loss', patience=20, verbose=2)\n\t\t# prepare iterators\n\t\ttrain_it = train_datagen.flow_from_directory('/kaggle/working/training/',\n\t\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n\t\ttest_it = test_datagen.flow_from_directory('/kaggle/working/validation/',\n\t\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n\t\t# fit model\n\t\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n                                      validation_data=test_it, validation_steps=len(test_it), epochs=100, verbose=2)\n\t\t# evaluate model\n\t\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=2)\n\t\tprint('> %.3f' % (acc * 100.0))\n\t\t# model save\n\t\tmodel.save('final_model.h5')\n\t\t# learning curves\n\t\tself.summarize_diagnostics(history)\n\n\n# entry point, run the test harness\ncnn = cnn_arch().train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = imread('/kaggle/working/ipykernel_launcher.py_plot.png')\npyplot.imshow(image)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a prediction for a new image.\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import load_model\nfrom os import listdir\n\nwith zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats/test1.zip\",\"r\") as z:\n            z.extractall(\".\")\n# load and prepare the image\ndef load_image(filename):\n\t# load the image\n\timg = load_img(filename, target_size=(200, 200))\n\t# convert to array\n\timg = img_to_array(img)\n\t# reshape into a single sample with 3 channels\n\timg = img.reshape(1, 200, 200, 3)\n\treturn img\n \n# load an image and predict the class\ndef run_example():\n\tmodel = load_model('final_model.h5')\n\tsubmission_df = pd.DataFrame(columns=['id','label'])\n\t# load the image\n\tsrc_directory = '/kaggle/working/test1/'\n\tfor file in listdir(src_directory):\n\t\timg = load_image(src_directory+file)\n\t\t# predict the class\n\t\tresult = model.predict(img)\n\t\tsubmission_df.loc[len(submission_df)] = [file.split('.')[0], result[0][0]]\n\tsubmission_df.to_csv('submission_070620201.csv', index=False)\n \n# entry point, run the example\nrun_example()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}