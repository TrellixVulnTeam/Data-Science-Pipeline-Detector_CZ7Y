{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nbase=\"../input\"\ntrain_in=\"../input/train/train\"\nfile_names=(os.listdir(\"../input/train/train\"))\n# Any results you write to the current directory are saved as output.","execution_count":39,"outputs":[{"output_type":"stream","text":"['train', 'sampleSubmission.csv', 'test1']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(file_names)\ntargets=list()\nfull_paths=list()\nfor x in file_names:\n    temp=os.path.join(train_in,x)\n    full_paths.append(temp)\n    #temp2=file_names.split(\".\")[0] #NOTERROR: TAKE A SINGLE ITEM INSTEAD OF ENTIRE LIST\n    temp2=x.split(\".\")[0]\n    targets.append(temp2)\n","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(targets[:10])","execution_count":41,"outputs":[{"output_type":"stream","text":"['cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#targets2=list(len(targets))\n#for y in range(len(targets)):\n#    if targets[y] == 'dog':\n#        targets[y]=1\n##    else:\n #       targets[y]=0","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(full_paths[:10])\nprint(targets[:10])","execution_count":43,"outputs":[{"output_type":"stream","text":"['../input/train/train/cat.11679.jpg', '../input/train/train/dog.2811.jpg', '../input/train/train/dog.2578.jpg', '../input/train/train/dog.9238.jpg', '../input/train/train/dog.7504.jpg', '../input/train/train/dog.11302.jpg', '../input/train/train/dog.11743.jpg', '../input/train/train/cat.8233.jpg', '../input/train/train/cat.1653.jpg', '../input/train/train/cat.12144.jpg']\n['cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.DataFrame()\ndataset['Paths']=full_paths\ndataset['Name']=targets","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"                                Paths Name\n0  ../input/train/train/cat.11679.jpg  cat\n1   ../input/train/train/dog.2811.jpg  dog\n2   ../input/train/train/dog.2578.jpg  dog\n3   ../input/train/train/dog.9238.jpg  dog\n4   ../input/train/train/dog.7504.jpg  dog","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Paths</th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/train/train/cat.11679.jpg</td>\n      <td>cat</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/train/train/dog.2811.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/train/train/dog.2578.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/train/train/dog.9238.jpg</td>\n      <td>dog</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/train/train/dog.7504.jpg</td>\n      <td>dog</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import matplotlib.pyplot as plt\n#plt.imshow(dataset.iloc(0))","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn import train_test_split\nimport sklearn\nfrom sklearn.model_selection import train_test_split\ntrain_1230,test_123=sklearn.model_selection.train_test_split(dataset,test_size=0.2,random_state=42)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=tf.keras.Sequential([tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)),\n                          tf.keras.layers.MaxPooling2D(2,2),\n                          tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n                          tf.keras.layers.MaxPooling2D(2,2),\n                          tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n                          tf.keras.layers.MaxPooling2D(2,2),\n                          tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n                          tf.keras.layers.MaxPooling2D(2,2),\n                          tf.keras.layers.Flatten(),\n                          tf.keras.layers.Dense(512,activation='relu'),\n                          tf.keras.layers.Dense(1,activation='sigmoid')])","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":50,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_4 (Conv2D)            (None, 148, 148, 64)      1792      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 74, 74, 64)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 72, 72, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 36, 36, 128)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 34, 34, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 15, 15, 64)        73792     \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 7, 7, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3136)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               1606144   \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 1,903,681\nTrainable params: 1,903,681\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss=\"binary_crossentropy\",metrics=['acc'])\nprint(\"[INFO]: model compiled...\")","execution_count":51,"outputs":[{"output_type":"stream","text":"[INFO]: model compiled...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen=ImageDataGenerator(rescale=1./255)\ntest_datagen=ImageDataGenerator(rescale=1./255)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_generator=train_datagen.flow_from_dataframe(dataframe=train_1230,\n                                                      x_col='Paths',\n                                                      y_col='Name',target_size=(150,150),\n                                                      class_mode=\"binary\",\n                                                      batch_size=150)","execution_count":53,"outputs":[{"output_type":"stream","text":"Found 20000 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data_generator)","execution_count":54,"outputs":[{"output_type":"stream","text":"<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7f9a0dfc4a90>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_generator=test_datagen.flow_from_dataframe(dataframe=test_123,\n                                                      x_col='Paths',\n                                                      y_col='Name',\n                                                      target_size=(150,150),\n                                                      class_mode=\"binary\",\n                                                      batch_size=150)","execution_count":55,"outputs":[{"output_type":"stream","text":"Found 5000 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelHistory=model.fit_generator(train_data_generator,\n                                epochs=10,\n                                validation_data=test_data_generator,\n                                validation_steps=test_123.shape[0]//150,\n                                steps_per_epoch=train_1230.shape[0]//150)","execution_count":56,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n34/34 [==============================] - 19s 557ms/step - loss: 0.6381 - acc: 0.6646\n134/134 [==============================] - 91s 678ms/step - loss: 0.7221 - acc: 0.5430 - val_loss: 0.6381 - val_acc: 0.6646\nEpoch 2/10\n34/34 [==============================] - 19s 556ms/step - loss: 0.5247 - acc: 0.7384\n134/134 [==============================] - 86s 644ms/step - loss: 0.5965 - acc: 0.6826 - val_loss: 0.5247 - val_acc: 0.7384\nEpoch 3/10\n34/34 [==============================] - 19s 570ms/step - loss: 0.4748 - acc: 0.7804\n134/134 [==============================] - 86s 641ms/step - loss: 0.5187 - acc: 0.7438 - val_loss: 0.4748 - val_acc: 0.7804\nEpoch 4/10\n34/34 [==============================] - 19s 555ms/step - loss: 0.4468 - acc: 0.7946\n134/134 [==============================] - 86s 642ms/step - loss: 0.4452 - acc: 0.7915 - val_loss: 0.4468 - val_acc: 0.7946\nEpoch 5/10\n34/34 [==============================] - 19s 554ms/step - loss: 0.4338 - acc: 0.7984\n134/134 [==============================] - 86s 640ms/step - loss: 0.3885 - acc: 0.8241 - val_loss: 0.4338 - val_acc: 0.7984\nEpoch 6/10\n34/34 [==============================] - 19s 564ms/step - loss: 0.3974 - acc: 0.8208\n134/134 [==============================] - 86s 645ms/step - loss: 0.3449 - acc: 0.8482 - val_loss: 0.3974 - val_acc: 0.8208\nEpoch 7/10\n34/34 [==============================] - 19s 558ms/step - loss: 0.3322 - acc: 0.8634\n134/134 [==============================] - 86s 642ms/step - loss: 0.2986 - acc: 0.8709 - val_loss: 0.3322 - val_acc: 0.8634\nEpoch 8/10\n34/34 [==============================] - 19s 550ms/step - loss: 0.4256 - acc: 0.8244\n134/134 [==============================] - 86s 638ms/step - loss: 0.2595 - acc: 0.8882 - val_loss: 0.4256 - val_acc: 0.8244\nEpoch 9/10\n34/34 [==============================] - 19s 558ms/step - loss: 0.3070 - acc: 0.8832\n134/134 [==============================] - 86s 639ms/step - loss: 0.2112 - acc: 0.9112 - val_loss: 0.3070 - val_acc: 0.8832\nEpoch 10/10\n34/34 [==============================] - 19s 551ms/step - loss: 0.2957 - acc: 0.8860\n134/134 [==============================] - 86s 639ms/step - loss: 0.1743 - acc: 0.9283 - val_loss: 0.2957 - val_acc: 0.8860\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#history=model.fit_generator(train_data_generator,validation_data=test_data_generator,\n#                           epochs=1)#,\n#                            #validation_steps=test.shape[0]//150,\n#                            #steps_per_epoch=train.shape[0]//150)\n#                                #steps_per_epoch=200)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"models.h5\")","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base2=\"../input/test1/test1\"\ntest_files_name=os.listdir(\"../input/test1/test1\")\n#print(test_files_name)\n","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_paths2=list()\nfor x in test_files_name:\n    temp=os.path.join(base2,x)\n    full_paths2.append(temp)\n    #temp2=file_names.split(\".\")[0] #NOTERROR: TAKE A SINGLE ITEM INSTEAD OF ENTIRE LIST\n    #temp2=x.split(\".\")[0]\n    #targets.append(temp2)\nfull_paths2[:10]","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"['../input/test1/test1/3090.jpg',\n '../input/test1/test1/8785.jpg',\n '../input/test1/test1/10679.jpg',\n '../input/test1/test1/7247.jpg',\n '../input/test1/test1/8151.jpg',\n '../input/test1/test1/1621.jpg',\n '../input/test1/test1/10255.jpg',\n '../input/test1/test1/7723.jpg',\n '../input/test1/test1/11953.jpg',\n '../input/test1/test1/6162.jpg']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.DataFrame({'filename':full_paths2})\nno_sample=(test_df.shape[0])\nprint(no_sample)\ntest_df.head()","execution_count":61,"outputs":[{"output_type":"stream","text":"12500\n","name":"stdout"},{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"                         filename\n0   ../input/test1/test1/3090.jpg\n1   ../input/test1/test1/8785.jpg\n2  ../input/test1/test1/10679.jpg\n3   ../input/test1/test1/7247.jpg\n4   ../input/test1/test1/8151.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/test1/test1/3090.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/test1/test1/8785.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/test1/test1/10679.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/test1/test1/7247.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/test1/test1/8151.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1gen=ImageDataGenerator(rescale=1./255)\ntest1_image_generator=test1gen.flow_from_dataframe(dataframe=test_df,x_col='filename',y_col=None, class_mode =None, target_size=(150,150),batch_size=15)","execution_count":62,"outputs":[{"output_type":"stream","text":"Found 12500 images.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict_generator(test1_image_generator, steps=np.ceil(no_sample/15))","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predict)","execution_count":64,"outputs":[{"output_type":"stream","text":"[[4.5089096e-02]\n [2.6822090e-06]\n [9.9518681e-01]\n ...\n [9.9999738e-01]\n [4.2100284e-01]\n [9.6232277e-01]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(predict))\nprint(len(test_files_name))","execution_count":65,"outputs":[{"output_type":"stream","text":"12500\n12500\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_name_list=list()\nfor x in test_files_name:\n    t=x.split(\".\")[0]\n    submission_name_list.append(t)\nprint(submission_name_list[:10])","execution_count":66,"outputs":[{"output_type":"stream","text":"['3090', '8785', '10679', '7247', '8151', '1621', '10255', '7723', '11953', '6162']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(predict))\nlist_temp=list()\nlist_temp=predict","execution_count":67,"outputs":[{"output_type":"stream","text":"<class 'numpy.ndarray'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold=0.5\nclass_np=np.where(predict > threshold, 1,0)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_np[:10]","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"array([[0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#threshold = 0.5\n#test_cat=pd.DataFrame()\n#test_cat['id'] = list_temp\n#test_cat['category'] = np.where(test_df['probability'] > threshold, 1,0)\n","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#threshold = 0.5\ntest_cat=pd.DataFrame()\ntest_cat['id'] = submission_name_list\ntest_cat['label'] = class_np","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cat.head()","execution_count":72,"outputs":[{"output_type":"execute_result","execution_count":72,"data":{"text/plain":"      id  label\n0   3090      0\n1   8785      0\n2  10679      1\n3   7247      0\n4   8151      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3090</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8785</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10679</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7247</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8151</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cat['label'].value_counts().plot.bar()","execution_count":73,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f99ad9af1d0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cat.to_csv('submission.csv', index=False)","execution_count":74,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}