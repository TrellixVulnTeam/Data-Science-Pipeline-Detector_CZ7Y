{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget --no-check-certificate \\\n  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n  -O /tmp/cats_and_dogs_filtered.zip","metadata":{"execution":{"iopub.status.busy":"2021-07-26T13:58:04.157288Z","iopub.execute_input":"2021-07-26T13:58:04.157626Z","iopub.status.idle":"2021-07-26T13:58:05.545795Z","shell.execute_reply.started":"2021-07-26T13:58:04.157598Z","shell.execute_reply":"2021-07-26T13:58:05.544865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n\nlocal_zip = '/tmp/cats_and_dogs_filtered.zip'\n\nzip_ref = zipfile.ZipFile(local_zip, 'r')\n\nzip_ref.extractall('/tmp')\nzip_ref.close()\n\nbase_dir = '/tmp/cats_and_dogs_filtered'\n\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'validation')\nprint(train_dir)\nprint(validation_dir)\n\n# Directory with our training cat/dog pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\n# Directory with our validation cat/dog pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\n\n'''for dirname, _, filenames in os.walk(base_dir):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\ntrain_cat_fnames = os.listdir( train_cats_dir )\ntrain_dog_fnames = os.listdir( train_dogs_dir )\n\nprint(train_cat_fnames[:10])\nprint(train_dog_fnames[:10])\n\n\nprint('total training cat images :', len(os.listdir(      train_cats_dir ) ))\nprint('total training dog images :', len(os.listdir(      train_dogs_dir ) ))\n\nprint('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\nprint('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:18:27.854398Z","iopub.execute_input":"2021-07-26T14:18:27.854734Z","iopub.status.idle":"2021-07-26T14:18:28.948273Z","shell.execute_reply.started":"2021-07-26T14:18:27.854706Z","shell.execute_reply":"2021-07-26T14:18:28.946677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:16:11.160118Z","iopub.execute_input":"2021-07-26T14:16:11.160485Z","iopub.status.idle":"2021-07-26T14:16:11.376946Z","shell.execute_reply.started":"2021-07-26T14:16:11.160454Z","shell.execute_reply":"2021-07-26T14:16:11.376048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images\n\n\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nnext_cat_pix = [os.path.join(train_cats_dir, fname) \n                for fname in train_cat_fnames[ pic_index-8:pic_index] \n               ]\n\nnext_dog_pix = [os.path.join(train_dogs_dir, fname) \n                for fname in train_dog_fnames[ pic_index-8:pic_index]\n               ]\n\nfor i, img_path in enumerate(next_cat_pix+next_dog_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:18:31.384257Z","iopub.execute_input":"2021-07-26T14:18:31.384587Z","iopub.status.idle":"2021-07-26T14:18:32.916271Z","shell.execute_reply.started":"2021-07-26T14:18:31.384559Z","shell.execute_reply":"2021-07-26T14:18:32.915295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-07-26T13:58:17.143098Z","iopub.execute_input":"2021-07-26T13:58:17.143458Z","iopub.status.idle":"2021-07-26T13:58:22.279085Z","shell.execute_reply.started":"2021-07-26T13:58:17.143428Z","shell.execute_reply":"2021-07-26T13:58:22.278259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same', input_shape=(150, 150, 3)),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D( pool_size=(2, 2), strides=2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D( pool_size=(2, 2), strides=2), \n    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding='same'), \n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding='same'), \n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])'''\n\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:18:37.773374Z","iopub.execute_input":"2021-07-26T14:18:37.77369Z","iopub.status.idle":"2021-07-26T14:18:37.841925Z","shell.execute_reply.started":"2021-07-26T14:18:37.773662Z","shell.execute_reply":"2021-07-26T14:18:37.841134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:18:41.980932Z","iopub.execute_input":"2021-07-26T14:18:41.981284Z","iopub.status.idle":"2021-07-26T14:18:41.992614Z","shell.execute_reply.started":"2021-07-26T14:18:41.981251Z","shell.execute_reply":"2021-07-26T14:18:41.991808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.optimizers \n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:30:33.091081Z","iopub.execute_input":"2021-07-26T14:30:33.091442Z","iopub.status.idle":"2021-07-26T14:30:33.106348Z","shell.execute_reply.started":"2021-07-26T14:30:33.091413Z","shell.execute_reply":"2021-07-26T14:30:33.105439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1./255.\ntrain_datagen = ImageDataGenerator( rescale = 1.0/255. )\ntest_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))     \n# --------------------\n# Flow validation images in batches of 20 using test_datagen generator\n# --------------------\nvalidation_generator =  test_datagen.flow_from_directory(validation_dir,\n                                                         batch_size=20,\n                                                         class_mode  = 'binary',\n                                                         target_size = (150, 150))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:30:34.173252Z","iopub.execute_input":"2021-07-26T14:30:34.173576Z","iopub.status.idle":"2021-07-26T14:30:34.390197Z","shell.execute_reply.started":"2021-07-26T14:30:34.173549Z","shell.execute_reply":"2021-07-26T14:30:34.389275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n      train_generator,\n      steps_per_epoch=100,  \n      epochs=15,\n      verbose=2,\n      validation_data = validation_generator,\n      validation_steps=50)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:30:35.514034Z","iopub.execute_input":"2021-07-26T14:30:35.514379Z","iopub.status.idle":"2021-07-26T14:32:38.773582Z","shell.execute_reply.started":"2021-07-26T14:30:35.514349Z","shell.execute_reply":"2021-07-26T14:32:38.772738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history.history[     'accuracy' ]\nval_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:11:31.83353Z","iopub.execute_input":"2021-07-26T14:11:31.833881Z","iopub.status.idle":"2021-07-26T14:11:32.174017Z","shell.execute_reply.started":"2021-07-26T14:11:31.83385Z","shell.execute_reply":"2021-07-26T14:11:32.173045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}