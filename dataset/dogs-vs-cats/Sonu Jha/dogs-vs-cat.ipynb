{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"class CNN_NET(nn.Module):\n    def __init__(self) -> None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        x = nn.Softmax(dim=1)(x)\n        return x## Directory Setup","metadata":{}},{"cell_type":"code","source":"!mkdir data","metadata":{"execution":{"iopub.status.busy":"2022-06-30T04:40:33.294224Z","iopub.execute_input":"2022-06-30T04:40:33.294606Z","iopub.status.idle":"2022-06-30T04:40:34.041989Z","shell.execute_reply.started":"2022-06-30T04:40:33.294564Z","shell.execute_reply":"2022-06-30T04:40:34.040854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp ../input/dogs-vs-cats/* data","metadata":{"execution":{"iopub.status.busy":"2022-06-30T04:40:34.046591Z","iopub.execute_input":"2022-06-30T04:40:34.046966Z","iopub.status.idle":"2022-06-30T04:40:43.124038Z","shell.execute_reply.started":"2022-06-30T04:40:34.046928Z","shell.execute_reply":"2022-06-30T04:40:43.122982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd data","metadata":{"execution":{"iopub.status.busy":"2022-06-30T04:40:43.127256Z","iopub.execute_input":"2022-06-30T04:40:43.127702Z","iopub.status.idle":"2022-06-30T04:40:43.135874Z","shell.execute_reply.started":"2022-06-30T04:40:43.127652Z","shell.execute_reply":"2022-06-30T04:40:43.134764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q train.zip ","metadata":{"execution":{"iopub.status.busy":"2022-06-30T04:40:43.1375Z","iopub.execute_input":"2022-06-30T04:40:43.138167Z","iopub.status.idle":"2022-06-30T04:40:50.523345Z","shell.execute_reply.started":"2022-06-30T04:40:43.138119Z","shell.execute_reply":"2022-06-30T04:40:50.52222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q test1.zip ","metadata":{"execution":{"iopub.status.busy":"2022-06-30T04:40:50.528178Z","iopub.execute_input":"2022-06-30T04:40:50.528536Z","iopub.status.idle":"2022-06-30T04:40:55.181394Z","shell.execute_reply.started":"2022-06-30T04:40:50.528499Z","shell.execute_reply":"2022-06-30T04:40:55.18033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd ..","metadata":{"execution":{"iopub.status.busy":"2022-06-30T04:40:55.183399Z","iopub.execute_input":"2022-06-30T04:40:55.183982Z","iopub.status.idle":"2022-06-30T04:40:55.195454Z","shell.execute_reply.started":"2022-06-30T04:40:55.183932Z","shell.execute_reply":"2022-06-30T04:40:55.194047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls data","metadata":{"execution":{"iopub.status.busy":"2022-06-30T04:40:55.197201Z","iopub.execute_input":"2022-06-30T04:40:55.19759Z","iopub.status.idle":"2022-06-30T04:40:55.922067Z","shell.execute_reply.started":"2022-06-30T04:40:55.197559Z","shell.execute_reply":"2022-06-30T04:40:55.920999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms \nimport torch \nfrom glob import glob \nfrom pathlib import Path\nimport random \n\nclass config:\n    p = Path('.')\n    images = list(p.glob('data/train/*.jpg'))\n    random.shuffle(images)\n    train_images, valid_images = images[:int(len(images) * 0.8)], images[int(len(images) * 0.8):]\n\n\n    tfms = transforms.Compose([transforms.ToTensor()])\n\n    INPUT_SIZE = 224*224*3\n    NUM_CLASS = 2\n    EPOCHS = 3\n    BATCH_SIZE = 32\n    LEARNING_RATE = 0.01\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-06-30T04:40:55.92385Z","iopub.execute_input":"2022-06-30T04:40:55.924257Z","iopub.status.idle":"2022-06-30T04:40:58.567078Z","shell.execute_reply.started":"2022-06-30T04:40:55.924221Z","shell.execute_reply":"2022-06-30T04:40:58.566208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Function","metadata":{}},{"cell_type":"code","source":"import torch \nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\n\n\ndef train(model, train_dl, valid_dl, optimizer, loss_fn):\n    model.train() \n    for epoch in range(config.EPOCHS):\n        loop = tqdm(train_dl)\n        train_losses = []\n        train_acc = []\n        val_losses = []\n        val_accuracies = []\n        for xb, yb in loop:\n            xb = xb.to(config.device)\n            yb = yb.to(config.device)\n            out = model(xb)\n            loss = loss_fn(out, yb)\n            loss.backward()\n            train_losses.append(loss.item())\n            optimizer.step()\n            optimizer.zero_grad()\n            prediction = torch.argmax(out, dim=1)\n            acc = accuracy_score(yb.cpu(), prediction.cpu())\n            train_acc.append(acc)           \n        model.eval()\n        with torch.no_grad():\n            for xb, yb in valid_dl:\n                xb = xb.to(config.device)\n                yb = yb.to(config.device)\n                output = model(xb)\n                loss = loss_fn(output, yb)\n                prediction = torch.argmax(output, dim=1)\n                accuracy = accuracy_score(yb.cpu(), prediction.cpu())\n                val_losses.append(loss)\n                val_accuracies.append(accuracy)\n        print(f'epoch={epoch}, train_loss = {sum(train_losses)/len(train_losses)},\\\n            val_loss={sum(val_losses)/len(val_losses)}, train_acc = {sum(train_acc)/len(train_acc)}, \\\n                 val_acc={sum(val_accuracies)/len(val_accuracies)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T06:06:49.975264Z","iopub.execute_input":"2022-06-30T06:06:49.975635Z","iopub.status.idle":"2022-06-30T06:06:49.989797Z","shell.execute_reply.started":"2022-06-30T06:06:49.975587Z","shell.execute_reply":"2022-06-30T06:06:49.988433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport os \nfrom glob import glob \nfrom torchvision import transforms, utils\nimport random \nfrom PIL import Image\nfrom pathlib import Path \nimport torch \n\n\n\n\nclass DogsVsCatsDataset(Dataset):\n    def __init__(self, images, transform=None):\n        self.images = images\n        self.transform = config.tfms\n    \n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).resize((224,224))\n        label = img_path.name.split('.')[0]\n        label = 1 if label == 'cat' else 0\n        if self.transform:\n            image = self.transform(image)\n        return image, torch.tensor(label)\n\nif __name__ == '__main__':\n    train_dataset = DogsVsCatsDataset(config.train_images)\n    valid_dataset = DogsVsCatsDataset(config.valid_images)\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n    print(len(train_loader))\n    print(len(valid_loader))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T06:06:53.920417Z","iopub.execute_input":"2022-06-30T06:06:53.920775Z","iopub.status.idle":"2022-06-30T06:06:53.935064Z","shell.execute_reply.started":"2022-06-30T06:06:53.920741Z","shell.execute_reply":"2022-06-30T06:06:53.933928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn \nimport torch.nn.functional as F\nfrom torchvision import models\n\nclass Net(nn.Module):\n    def __init__(self, input_size, num_class):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(input_size, 512)\n        self.fc2 = nn.Linear(512, 124)\n        self.fc3 = nn.Linear(124, 64)\n        self.fc4 = nn.Linear(64, num_class)\n    \n    def forward(self, xb):\n        xb = xb.view((xb.shape[0], -1))\n        xb = F.relu(self.fc1(xb))\n        xb = F.relu(self.fc2(xb))\n        xb = F.relu(self.fc3(xb))\n        xb = self.fc4(xb)\n        out = nn.Softmax(dim=1)(xb)\n        return xb\n\nclass CNN_NET(nn.Module):\n    def __init__(self) -> None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 64, 3)\n        self.conv2 = nn.Conv2d(64, 128, 3)\n        self.conv3 = nn.Conv2d(128, 256, 3)\n        self.conv4 = nn.Conv2d(256, 512, 3)\n        self.pool = nn.MaxPool2d(kernel_size=3)\n        self.linear = nn.Linear(512, 10)\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        x = self.linear(x.view(x.shape[0], -1))\n        x = nn.Softmax(dim=1)(x)\n        return x\n    \nclass vgg(nn.Module):\n    def __init__(self) -> None:\n        super().__init__()\n        self.features = models.vgg16(pretrained=True)\n        self.last_linear = nn.Linear(1000, 10)\n    def forward(self, x):\n        x = self.features(x)\n        x = self.last_linear(x)\n        x = nn.Softmax(dim=1)(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-06-30T06:21:52.945418Z","iopub.execute_input":"2022-06-30T06:21:52.945836Z","iopub.status.idle":"2022-06-30T06:21:52.970508Z","shell.execute_reply.started":"2022-06-30T06:21:52.945801Z","shell.execute_reply":"2022-06-30T06:21:52.968524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xb, yb = next(iter(train_loader))\nmodel = Net(input_size=config.INPUT_SIZE, num_class = config.NUM_CLASS)\n# # model = CNN_NET()\n# out = model(xb)\n# print(out.shape)\nloss_fn = nn.CrossEntropyLoss()\n\n# loss = loss_fn(out, yb)\n# loss\n# for xb, yb in train_loader:\n#     out = model(xb)\n#     loss = loss_fn(out, yb)\n#     print(loss)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T06:07:20.123272Z","iopub.execute_input":"2022-06-30T06:07:20.123603Z","iopub.status.idle":"2022-06-30T06:07:20.856313Z","shell.execute_reply.started":"2022-06-30T06:07:20.123571Z","shell.execute_reply":"2022-06-30T06:07:20.855479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader \nimport torch \nimport torch.nn as nn \nimport numpy as np \nfrom torch.utils.data import Subset\n\nif __name__==\"__main__\":\n    train_dataset = DogsVsCatsDataset(config.train_images)\n    valid_dataset = DogsVsCatsDataset(config.valid_images)\n    train_dataset = Subset(train_dataset, np.arange(2044))\n    valid_dataset = Subset(valid_dataset, np.arange(512))\n    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n#     model = Net(input_size=config.INPUT_SIZE, num_class = config.NUM_CLASS)\n#     model = CNN_NET()\n    model = vgg()\n    model.to(config.device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n    device = config.device\n    train(model, train_loader,valid_loader, optimizer=optimizer, loss_fn=loss_fn)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T06:21:57.907825Z","iopub.execute_input":"2022-06-30T06:21:57.908207Z","iopub.status.idle":"2022-06-30T06:23:46.659145Z","shell.execute_reply.started":"2022-06-30T06:21:57.908165Z","shell.execute_reply":"2022-06-30T06:23:46.657324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}