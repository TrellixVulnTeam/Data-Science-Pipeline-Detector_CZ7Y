{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14477cdaa5eca7a39b5548a7b37a64f4963acd3d"},"cell_type":"code","source":"!pip install tensornets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8da53e7b53ca3298c1355eb2a1ffae83fd3554b9"},"cell_type":"code","source":"import tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44572da60d945ff1c459a03bf2a3931e9180e889"},"cell_type":"code","source":"data=[]\nlabel=[]\nimages_cat_class=500\nimages_dog_class=500\ncount_cat=0\ncount_dog=0\nfor file in os.listdir(\"../input/train/train\"):\n    if count_cat<images_cat_class or count_dog<images_dog_class:\n        image=cv2.imread(os.path.join(\"../input/train/train\",file))\n        image=cv2.resize(image,(224,224))\n        if file.startswith(\"cat\") and count_cat<images_cat_class:\n            label.append([1,0])\n            data.append(image)\n            count_cat+=1\n        elif file.startswith(\"dog\") and count_dog<images_dog_class:\n            label.append([0,1])\n            data.append(image)\n            count_dog+=1\n    else:\n        break\ndata=np.array(data)\nlabel=np.array(label)\nprint(data.shape)\nprint(label.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8e738409c149bcd4bf9aa4c85caf8a9818c3e67"},"cell_type":"code","source":"import tensornets as nets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15f80b4ec8f89f1e953cd631eca55fcfeb6cb55f"},"cell_type":"code","source":"inputs = tf.placeholder(tf.float32, shape=[None, 224, 224, 3])\noutputs = tf.placeholder(tf.float32, shape=[None, 2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4468dc6bb004015cd3b4f3bf333c09a4821c65e3"},"cell_type":"code","source":"logits = nets.VGG19(inputs, is_training=True, classes=2)\nmodel = tf.identity(logits, name='logits')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30f1ab7dd0980f3f0acd708ba33a1fa3f7168b76"},"cell_type":"code","source":"loss = tf.losses.softmax_cross_entropy(outputs, logits)\ntrain = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b042ce6b4f6dd5dbf20c2c6c8abdc64a71ae40e"},"cell_type":"code","source":"correct_pred = tf.equal(tf.argmax(model, 1), tf.argmax(outputs, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3238f47650e8968be806e1096b06f7f8b7c8408f"},"cell_type":"code","source":"epoch=10\nbatch_size=10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b36998e73575d806f37ecb938eae3c9a39c9074","scrolled":false},"cell_type":"code","source":"# from tqdm import tqdm\n# with tf.Session() as sess:\n#     sess.run(tf.global_variables_initializer())\n#     for iterate in range(epoch):\n#         batch_number_count=data.shape[0]//batch_size\n#         train_loss=0.0\n#         train_accuracy=0.0\n#         for batch in tqdm(range(batch_number_count)):\n#             images_train=data[(batch*batch_size):(batch*batch_size)+batch_size,:,:,:]\n#             label_train=label[(batch*batch_size):(batch*batch_size)+batch_size,:]\n#             print(\"image_shape\",images_train.shape)\n#             print(\"label_shape\",label_train.shape)\n#             print(label_train)\n#             _,train_loss,train_accuracy=sess.run([train,loss,accuracy],feed_dict={inputs:images_train,outputs:label_train})\n#         print(\"epoch\",iterate,\"loss\",train_loss,\"accuracy\",train_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"554296186de52a22df8ca4d48751ab9132e00e7b"},"cell_type":"code","source":"from tqdm import tqdm\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for iterate in range(epoch):\n        batch_count_total=data.shape[0]//batch_size\n        loss_list=[]\n        accuracy_list=[]\n        for batch in tqdm(range(batch_count_total)):\n            _,train_loss,train_accuracy=sess.run([train,loss,accuracy],feed_dict={inputs:data[(batch*batch_size):(batch*batch_size)+batch_size,:,:,:],outputs:label[(batch*batch_size):(batch*batch_size)+batch_size,:]})\n            loss_list.append(train_loss)\n            accuracy_list.append(train_accuracy)\n        print(\"epoch\",iterate,\"loss\",sum(loss_list)/batch_count_total,\"accuracy\",sum(accuracy_list)/batch_count_total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43f0ddca17eb2a36f11907460a00cd997f086caa"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}