{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# We use Preprocessed dataset that have every image in size = 50 *50 "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Preparing convNet model\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import normalize\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.callbacks import TensorBoard\nimport pickle\nimport time\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d3f172cdf08bf9f8f05dc768126b0692b1a5a77"},"cell_type":"code","source":"# set tensorBoard name to realtime tracking \nNAME = \"Cats-vs-dogs-cnn-64x2-{}\".format(int(time.time()))\n\ntensorboard = TensorBoard(log_dir='logs/{}'.format(NAME)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b45152a5e6254cdec656e15f01836410a881592"},"cell_type":"code","source":"# LOad data\n\nX = pickle.load(open('../input/pickled-cats-vs-dogs/x.pickle', \"rb\"))\ny = pickle.load(open('../input/pickled-cats-vs-dogs/y.pickle', \"rb\"))\n\nX = X/255.0 # normalize x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66da968fb2b4d8dd8adaf3822e2171e7c084865c"},"cell_type":"code","source":"y.append(0)\nlen(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e19d2091996dc21689b864e9aef57060497bdd44"},"cell_type":"markdown","source":"### Optimizing our model and find best fitting parameters"},{"metadata":{"trusted":true,"_uuid":"79bece2a91876915ecd5f1fb21b0f81d99c70a5e"},"cell_type":"code","source":"# deine parameters and thier vairance\ndense_layers = [0]\nlayers_sizes = [32]\nconv_layers = [3]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b3372bba2371cdee6fb1a46f9f1ed6fd9915fae"},"cell_type":"code","source":"\nfor dense_layer in dense_layers:\n    for layers_size in layers_sizes:\n        for conv_layer in conv_layers:\n            NAME = \"{}-Conv-{}-nodes-{}-dense-{}\".format(conv_layer, layers_size, dense_layer, int(time.time()))\n            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME)) \n            print(NAME)\n            \n            # define model and layers\n            model = Sequential()\n            \n            model.add(Conv2D(layers_size, (3,3), input_shape= X.shape[1:]))\n            model.add(Activation(\"relu\"))\n            model.add(MaxPool2D(pool_size=(2, 2)))\n\n            for i in range(conv_layer -1):\n                model.add(Conv2D(layers_size, (3,3)))\n                model.add(Activation(\"relu\"))\n                model.add(MaxPool2D(pool_size=(2, 2)))\n\n            model.add(Flatten()) # this is converts our 3D features to 1D vectors\n            \n            for i in range(dense_layer):\n                model.add(Dense(512))\n                model.add(Activation('relu'))\n                model.add(Dropout(0.2))\n\n            model.add(Dense(1))\n            model.add(Activation('sigmoid'))\n\n            model.compile(loss='binary_crossentropy',\n                         optimizer='adam',\n                         metrics=['accuracy'])\n            model.fit(X, y, batch_size=32, epochs =20, validation_split=0.1, callbacks=[tensorboard])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1071bb7ae155693ffee6f25603314f4038273560"},"cell_type":"code","source":"model.save('64x3-CNN.model')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5eb527275e865889cb75fdfc73655dca0cdc4be7"},"cell_type":"markdown","source":"### you can use saved modelto make prediction after comitting and load saved model again"},{"metadata":{"trusted":true,"_uuid":"12957470a7458496b4ab9a7cd3188b5bb9946280"},"cell_type":"code","source":"import cv2\nimport tensorflow as tf\n\nCATEGORIES = [\"Dog\", \"Cat\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c8ab62100f0befc43975b01fedef38c145699db"},"cell_type":"code","source":"# def prepare(filepath):\n#     IMG_SIZE = 50\n#     img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n#     new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n#     return new_array.reshape(-1, IMG_SIZE, IMG_SIZE,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b39b01a1be26c1a67172543baf75cd5402e96bb2"},"cell_type":"code","source":"# load model\n# model = tf.keras.models.load_model('64x3-CNN.model') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"437e6a075fc732d9279d3a8a46524be7ce515544"},"cell_type":"code","source":"# predict\n# prediction = model.predict([prepare('cat1.jpeg')])\n# print(CATEGORIES[int(prediction[0][0])])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}