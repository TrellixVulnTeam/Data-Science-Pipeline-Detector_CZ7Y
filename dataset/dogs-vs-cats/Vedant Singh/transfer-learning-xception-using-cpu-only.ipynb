{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <h2>Importing data: </h2>\nWe begin with importing the essential libraries for our project"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport zipfile\nimport random\nimport tensorflow as tf\nimport shutil\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nfrom os import getcwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_zip = '/kaggle/input/dogs-vs-cats/test1.zip'\ntrain_zip = '/kaggle/input/dogs-vs-cats/train.zip'\nzip_ref = zipfile.ZipFile(test_zip, 'r')\nzip_ref.extractall('/kaggle/temp')\nzip_ref.close()\n\nzip_ref = zipfile.ZipFile(train_zip, 'r')\nzip_ref.extractall('/kaggle/temp')\nzip_ref.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(os.listdir('/kaggle/temp/train')))\nprint(len(os.listdir('/kaggle/temp/test1')))\nos.listdir(\"/kaggle/temp\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check few images:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\n\ncount=0\nplt.figure(figsize=(10,10))\nfor i in np.random.randint(1, 500, size=25):\n    count += 1\n    image_path = '/kaggle/temp/train/dog.'+ str(i) +'.jpg'\n    img = image.load_img(image_path, target_size=(150, 150))\n    x = image.img_to_array(img)\n\n    x = tf.expand_dims(x, axis=0)\n    x = x / 255.0\n    plt.subplot(5, 5, count)\n    plt.axis('off')\n    plt.imshow(x[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Data generation:</h2>\nFirst step is creating folders for data generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"orig_train_data_dir = \"/kaggle/temp/train\"\norig_test_data_dir = \"/kaggle/temp/test1\"\n\ntry:\n    base_dir = \"/kaggle/Cats_vs_Dogs/\"\n    os.mkdir(base_dir)\n\n    train_dir = os.path.join(base_dir, 'train')\n    os.mkdir(train_dir)\n    test_dir = os.path.join(base_dir, 'test')\n    os.mkdir(test_dir)\n\n    train_dogs_dir = os.path.join(train_dir, 'dogs')\n    train_cats_dir = os.path.join(train_dir, 'cats')\n    os.mkdir(train_dogs_dir)\n    os.mkdir(train_cats_dir)\n\n    test_dogs_dir = os.path.join(test_dir, 'dogs')\n    test_cats_dir = os.path.join(test_dir, 'cats')\n    os.mkdir(test_dogs_dir)\n    os.mkdir(test_cats_dir)\n\n    fnames = ['cat.{}.jpg'.format(i) for i in range(6250)] \n    for fname in fnames:\n        src = os.path.join(orig_train_data_dir, fname) \n        dst = os.path.join(train_cats_dir, fname) \n        shutil.copyfile(src, dst)\n        \n    fnames = ['dog.{}.jpg'.format(i) for i in range(6250)] \n    for fname in fnames:\n        src = os.path.join(orig_train_data_dir, fname) \n        dst = os.path.join(train_dogs_dir, fname) \n        shutil.copyfile(src, dst)\nexcept:\n    pass        \nfnames = os.listdir(orig_test_data_dir) \nfor fname in fnames:\n    src = os.path.join(orig_test_data_dir, fname) \n    dst = os.path.join(test_dir, fname) \n    shutil.copyfile(src, dst)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Becuase we are using transfer learning, we need only half of training data to create a model with hight accuracy."},{"metadata":{},"cell_type":"markdown","source":"Creating a validation and training data generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir, \n        target_size=(150, 150),\n        batch_size=250,\n        class_mode = 'binary',\n        subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(150, 150),\n        batch_size=250,\n        class_mode='binary',\n        subset='validation')\n\ntest_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(150, 150),\n        batch_size=250)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data_batch, labels_batch in train_generator:\n    print(data_batch.shape)\n    print(labels_batch.shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Applying transfer learning</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import Callback, LearningRateScheduler\nfrom tensorflow.keras.applications import Xception\n\n\nconv_base = Xception(weights=\"/kaggle/input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\", include_top=False, input_shape=(150, 150, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since this project requires CPU alone, feature extraction will be the most computational task."},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 250\n\ndef extract_features(generator, sample_count):\n    features = np.zeros(shape=(sample_count, 5, 5, 2048))\n    labels = np.zeros(shape=(sample_count))\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i+1) * batch_size] = features_batch\n        labels[i * batch_size : (i+1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size >= sample_count:\n            break\n    return features, labels\n\ntrain_features, train_labels = extract_features(train_generator, 10000) \nvalidation_features, validation_labels = extract_features(validation_generator, 2500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nclass myCallback(Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if (logs.get('accuracy') > 0.999):\n            self.model.stop_training = True\n            \ncallback = myCallback()\n\nmodel = models.Sequential([\n    layers.Flatten(input_shape=(5, 5, 2048)),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-5),metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_features, train_labels, epochs=50, batch_size=batch_size, validation_data=(validation_features, validation_labels),callbacks=[callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\nplt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\nplt.title(\"Training and validation accuracy\")\nplt.legend()\n\nplt.figure()\nplt.plot(epochs, loss, \"bo\", label=\"Training loss\")\nplt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\nplt.title(\"Training and validation loss\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = conv_base.predict(test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans=[]\nfor i in range(pred.shape[0]):\n    if pred[i] > 0.5:\n        ans.append(1)\n    else:\n        ans.append(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}