{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c989ef05-fd88-44ac-ab6f-1d670ecc2e03","_cell_guid":"90b31998-0369-4ef5-8d1c-eae28952631c","trusted":true},"cell_type":"code","source":"# %% [code]\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfrom zipfile import ZipFile\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.endswith('.zip'):\n            print(os.path.join(dirname, filename))\n            zip = ZipFile((os.path.join(dirname, filename)))\n            zip.extractall()\n            zip.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport shutil\nfrom tqdm import tqdm\nimport random\n\ndata_dir = 'train'\ncat_path_name = data_dir + '/cat'\ndog_path_name = data_dir + '/dog'\ntrain_test_indices = list(range(1,25000)) \nrandom.shuffle(train_test_indices)\nnnp = round(len(train_test_indices)*0.8)\ntrain_indices = train_test_indices[:nnp]\n#print(len(train_indices))\ntest_indices = [i for i in train_test_indices if i not in train_indices]\n\ntrain_path_name = data_dir+'/train_classified'\ntest_path_name = data_dir+'/test_classified'\ntrain_cat_path = train_path_name +'/cat'\ntest_cat_path = test_path_name + '/cat'\ntrain_dog_path = train_path_name + '/dog'\ntest_dog_path = test_path_name + '/dog'\nmake_folders = [train_path_name,test_path_name,train_cat_path,test_cat_path,train_dog_path,test_dog_path]\n\nfor path in tqdm(make_folders):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\nall_files = os.listdir(data_dir+'/')\n\ntrain_files = [all_files[i] for i in train_indices]\ntest_files = [all_files[i] for i in test_indices]\n\ndef copy_data(files,destination):\n    for f in tqdm(files):\n        #img = \n        if f.startswith('cat'):\n            shutil.copy(data_dir+'/'+f,destination+'/cat')\n        if f.startswith('dog'):\n            shutil.copy(data_dir+'/'+f,destination+'/dog')\n    return\n\ncopy_data(files=train_files,destination=train_path_name)\ncopy_data(files=test_files,destination=test_path_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # TODO: Define transforms for the training data and testing data\nimport random\nrandom.seed(2)\n\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.Resize((256,256)),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.5], \n                                                            [0.5])\n                                      ])\n\ntest_transforms = transforms.Compose([transforms.Resize((256,256)),\n                                       transforms.ToTensor(),\n                                      transforms.Normalize([0.5], \n                                                            [0.5])\n                                       ])\n\n# # Pass transforms in here, then run the next cell to see how the transforms look\ntrain_data = datasets.ImageFolder(data_dir+'/train_classified', transform=train_transforms)\ntest_data = datasets.ImageFolder(data_dir+'/test_classified', transform=test_transforms)\n\n\ndef sample_data(collection,n_sample):\n    indices = list(range(1,len(collection.samples))) \n    random.shuffle(indices)\n    indices = indices[:n_sample]\n    collection.samples = [collection.samples[idx] for idx in indices]\n    collection.targets = [collection.targets[idx] for idx in indices]\n    return collection\n\n\n\n#train_data = sample_data(train_data,n_sample=1000)\n#test_data = sample_data(test_data,n_sample=200)\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=32,shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=32,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data,test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\n\nmodel = models.densenet121(pretrained=True)\n# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(1024, 512)),\n                          ('relu', nn.ReLU()),\n                          ('fc2', nn.Linear(512,64)),\n                        ('relu', nn.ReLU()),\n    \n        ('fc3', nn.Linear(64, 2)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nmodel.classifier = classifier\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.005)\n\ndevice = 'cuda'\n\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = Classifier()\n\n\nepochs = 3\nsteps = 0\n\n\ntrain_losses, test_losses = [], []\nfor e in range(epochs):\n    #print(e)\n    running_loss = 0\n    for images, labels in trainloader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        log_ps = model(images)\n        loss = criterion(log_ps, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        #print(running_loss)\n        \n    else:\n        test_loss = 0\n        accuracy = 0\n        #print('Validation Starts!')\n        # Turn off gradients for validation, saves memory and computations\n        with torch.no_grad():\n            model.eval()\n            for images, labels in testloader:\n                images, labels = images.to(device), labels.to(device)\n\n                log_ps = model(images)\n                test_loss += criterion(log_ps, labels)\n                \n                ps = torch.exp(log_ps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n        model.train()\n        \n        train_losses.append(running_loss/len(trainloader))\n        test_losses.append(test_loss/len(testloader))\n\n        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n              \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('test'):\n    shutil.copytree('test1','test/test1')\ntest_dir = 'test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data = datasets.ImageFolder(test_dir, transform=test_transforms)\nids = [int(i[0][11:-4]) for i in submission_data.samples]\nsubmission_data.targets = ids\ntestloader = torch.utils.data.DataLoader(submission_data, batch_size=32,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples, _ = iter(testloader).next()\nsamples = samples.to(device)\nfig = plt.figure(figsize=(24, 16))\nfig.tight_layout()\noutput = model(samples[:24])\npred = torch.argmax(output, dim=1)\npred = [p.item() for p in pred]\nad = {0:'cat', 1:'dog'}\nfor num, sample in enumerate(samples[:24]):\n    plt.subplot(4,6,num+1)\n    plt.title(ad[pred[num]])\n    plt.axis('off')\n    sample = sample.cpu().numpy()\n    plt.imshow(np.transpose(sample, (1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Test out your network!\n\nmodel.eval()\nfn_list = []\npred_list = []\n\nfor x, fn in tqdm(testloader):\n    with torch.no_grad():\n        x = x.to(device)\n        logps = model.forward(x)\n        ps = torch.exp(logps)\n        top_p, top_class = ps.topk(1, dim=1)\n        pred_list.extend(top_class)\n        \n        \n#         pred = torch.argmax(output, dim=1)\n#         fn_list += [n[:-4] for n in fn]\n#         pred_list += [p.item() for p in pred]\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred_list = [i.item() for i in pred_list]\nsubmission = pd.DataFrame({\"id\":ids, \"label\":pred_list})\n#submission.to_csv('pytorch_sample.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('pytorch_sample.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}