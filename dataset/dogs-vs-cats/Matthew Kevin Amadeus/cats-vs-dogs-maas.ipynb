{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> In this Notebook we will classify images of dogs and cats using transfer learning from pre-trained network\n\n\n","metadata":{"id":"8CpA7-svcfz8"}},{"cell_type":"markdown","source":"# Genrel workFlow\n\n\n1.   Data Preprocessing\n2.   Create Base model\n3.   Feature Extraction\n4.   Model Evaluation\n\n","metadata":{"id":"ANzIvJ6vkv3K"}},{"cell_type":"markdown","source":"A **pre-trained** model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. You either use the pretrained model as is or use transfer learning to customize this model to a given task. â˜£\n\n\n\n\n\n\n\n\n\n\n\n**The intuition** behind **transfer learning** for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset","metadata":{"id":"7jschsVvfPQi"}},{"cell_type":"code","source":"# Setup\n\nimport os\nimport numpy as np\nimport tensorflow as tf \nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n","metadata":{"id":"roidI4MCdwTd","execution":{"iopub.status.busy":"2022-04-30T10:19:56.516613Z","iopub.execute_input":"2022-04-30T10:19:56.516956Z","iopub.status.idle":"2022-04-30T10:20:00.764564Z","shell.execute_reply.started":"2022-04-30T10:19:56.516879Z","shell.execute_reply":"2022-04-30T10:20:00.763779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"id":"1nSxUbiKfBAj"}},{"cell_type":"markdown","source":"We will download a dataset containing several thousand images of cats and dogs , then extract a zip file and create a training and validation ","metadata":{"id":"IuaABZC-gXOd"}},{"cell_type":"code","source":"_url_ = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip',origin = _url_,extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip),'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH,'train')\nvalidation_dir = os.path.join(PATH,'validation')\n\nBatch_Size = 32\nIMG_SIZE=(160,160)","metadata":{"id":"tl3pho0dhB7E","outputId":"d4c1006c-2406-441f-fba9-5007e6031b08","execution":{"iopub.status.busy":"2022-04-30T10:20:00.766022Z","iopub.execute_input":"2022-04-30T10:20:00.76625Z","iopub.status.idle":"2022-04-30T10:20:03.462629Z","shell.execute_reply.started":"2022-04-30T10:20:00.766217Z","shell.execute_reply":"2022-04-30T10:20:03.461893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"print directories we working wit it","metadata":{"id":"6GKNOed7y750"}},{"cell_type":"code","source":"print(os.path.dirname(path_to_zip))\nprint(train_dir)\nprint(validation_dir)","metadata":{"id":"N1I5ldoPxZFn","outputId":"3df8e3e6-b697-4966-a263-19007fb9a8ef","execution":{"iopub.status.busy":"2022-04-30T10:20:03.466074Z","iopub.execute_input":"2022-04-30T10:20:03.466273Z","iopub.status.idle":"2022-04-30T10:20:03.474605Z","shell.execute_reply.started":"2022-04-30T10:20:03.466247Z","shell.execute_reply":"2022-04-30T10:20:03.473382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"making a train and validation classes from data we extracted above","metadata":{"id":"TiptT1iwwWt4"}},{"cell_type":"code","source":"train_dataset = tf.keras.utils.image_dataset_from_directory(\n    train_dir,\n    shuffle=True,\n    batch_size=Batch_Size,\n    image_size = IMG_SIZE\n)","metadata":{"id":"_8JBYoASwoay","outputId":"002a9573-2163-4c69-bb7c-1ef27674223b","execution":{"iopub.status.busy":"2022-04-30T10:20:03.476452Z","iopub.execute_input":"2022-04-30T10:20:03.476711Z","iopub.status.idle":"2022-04-30T10:20:05.969946Z","shell.execute_reply.started":"2022-04-30T10:20:03.476676Z","shell.execute_reply":"2022-04-30T10:20:05.968584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_dataset = tf.keras.utils.image_dataset_from_directory(\n    validation_dir,\n    shuffle=True,\n    batch_size=Batch_Size,\n    image_size = IMG_SIZE\n)","metadata":{"id":"q-pXbmqnxkik","outputId":"5795de9e-ef1e-43de-af88-143616b66bfd","execution":{"iopub.status.busy":"2022-04-30T10:20:05.971158Z","iopub.execute_input":"2022-04-30T10:20:05.971477Z","iopub.status.idle":"2022-04-30T10:20:06.091544Z","shell.execute_reply.started":"2022-04-30T10:20:05.971437Z","shell.execute_reply":"2022-04-30T10:20:06.090887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**showing the first nine images and labels from the training set**\n\n","metadata":{"id":"CulbHeLoyGDc"}},{"cell_type":"code","source":"class_name = train_dataset.class_names\n","metadata":{"id":"4dTCCE_Mnaq4","execution":{"iopub.status.busy":"2022-04-30T10:20:06.092859Z","iopub.execute_input":"2022-04-30T10:20:06.093091Z","iopub.status.idle":"2022-04-30T10:20:06.096759Z","shell.execute_reply.started":"2022-04-30T10:20:06.093058Z","shell.execute_reply":"2022-04-30T10:20:06.095938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\n\nfor image , labels in train_dataset.take(1):\n  \n  for i in range(9):\n\n    ax = plt.subplot(3,3,i+1)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    plt.imshow(image[i].numpy().astype('uint8'))\n    plt.title(class_name[labels[i]])\n\n","metadata":{"id":"Qw7qyCpd2p5k","outputId":"fd7202bd-ca90-41f8-b97e-175a48fe2796","execution":{"iopub.status.busy":"2022-04-30T10:20:06.098032Z","iopub.execute_input":"2022-04-30T10:20:06.098503Z","iopub.status.idle":"2022-04-30T10:20:07.154914Z","shell.execute_reply.started":"2022-04-30T10:20:06.098465Z","shell.execute_reply":"2022-04-30T10:20:07.154163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the orignal dataset don`t have test set , we will create one.\n**How ?**\n\nDetermine how many batchs of data available in the validation set then move 20% of them to a test set","metadata":{"id":"dqNMw4ZUAOEh"}},{"cell_type":"code","source":"val_batches = tf.data.experimental.cardinality(validation_dataset)\ntest_dataset = validation_dataset.take(val_batches//5)\nvalidation_dataset = validation_dataset.skip(val_batches//5)","metadata":{"id":"c25sEfapAnxp","execution":{"iopub.status.busy":"2022-04-30T10:20:07.155893Z","iopub.execute_input":"2022-04-30T10:20:07.156117Z","iopub.status.idle":"2022-04-30T10:20:07.173742Z","shell.execute_reply.started":"2022-04-30T10:20:07.156087Z","shell.execute_reply":"2022-04-30T10:20:07.172879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'number of validation batches = {tf.data.experimental.cardinality(validation_dataset)}')\nprint(f'number of test batches = {tf.data.experimental.cardinality(test_dataset)}')","metadata":{"id":"e7ZBYNIpFMFL","outputId":"642f8f20-267a-46a4-e8c2-da5280941a90","execution":{"iopub.status.busy":"2022-04-30T10:20:07.175011Z","iopub.execute_input":"2022-04-30T10:20:07.175757Z","iopub.status.idle":"2022-04-30T10:20:07.338728Z","shell.execute_reply.started":"2022-04-30T10:20:07.175713Z","shell.execute_reply":"2022-04-30T10:20:07.337783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**configure the dataset for performance**","metadata":{"id":"evmgBsylG7p3"}},{"cell_type":"markdown","source":"this will be better performance , you can visit [tens_api](https://www.tensorflow.org/guide/data_performance)","metadata":{"id":"orAJkLquR9ab"}},{"cell_type":"code","source":"autotune = tf.data.AUTOTUNE\ntrain_dataset = train_dataset.prefetch(buffer_size = autotune)\nvalidation_dataset = validation_dataset.prefetch(buffer_size = autotune)\ntest_dataset = test_dataset.prefetch(buffer_size = autotune)","metadata":{"id":"SDal8Oj0OLcB","execution":{"iopub.status.busy":"2022-04-30T10:20:07.343005Z","iopub.execute_input":"2022-04-30T10:20:07.343323Z","iopub.status.idle":"2022-04-30T10:20:07.350544Z","shell.execute_reply.started":"2022-04-30T10:20:07.343291Z","shell.execute_reply":"2022-04-30T10:20:07.349644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Use Data Augmentation**","metadata":{"id":"O50F6eQlR1Ke"}},{"cell_type":"markdown","source":"nice trick to reduce overfitting as your data is not large enough","metadata":{"id":"f_v6qpKqSnJz"}},{"cell_type":"code","source":"# data augmentation layers [1]\n\ndata_augmentation = tf.keras.Sequential([              \n          tf.keras.layers.RandomFlip(mode='horizontal'),\n          tf.keras.layers.RandomRotation(factor=.2)\n          ])\n\n\n\n# Note > this layers active only while training \"model.fit\" and inactive when using \"model.evaluate\"","metadata":{"id":"n2cHSTqgSiUH","execution":{"iopub.status.busy":"2022-04-30T10:20:07.351841Z","iopub.execute_input":"2022-04-30T10:20:07.352562Z","iopub.status.idle":"2022-04-30T10:20:07.38664Z","shell.execute_reply.started":"2022-04-30T10:20:07.352514Z","shell.execute_reply":"2022-04-30T10:20:07.385896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**apply these layers to sample image and see the result.**","metadata":{"id":"YrMVO1jWdHYO"}},{"cell_type":"code","source":"for image , _ in train_dataset.take(1):\n\n  plt.figure(figsize = (10,10))\n  sample_image = image[0]\n\n  for i in range(9):\n\n    ax = plt.subplot(3,3,i+1)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    aug_img = data_augmentation(tf.expand_dims(sample_image,0))\n    plt.imshow(aug_img[0]/255)\n    ","metadata":{"id":"e5c-bHaYdfb1","outputId":"b5632fce-c980-4cf2-e0d1-847355efda4b","execution":{"iopub.status.busy":"2022-04-30T10:20:07.388089Z","iopub.execute_input":"2022-04-30T10:20:07.388364Z","iopub.status.idle":"2022-04-30T10:20:08.498083Z","shell.execute_reply.started":"2022-04-30T10:20:07.388326Z","shell.execute_reply":"2022-04-30T10:20:08.497481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**rescale pixels value**\n\nwe will use `tf.keras.applications.MobileNetV2` for use as base model\nbut this model expect pixel value in [1,-1] while pixel value in our images in [0,255]  , so we need to rescaling them","metadata":{"id":"EEatxnpZr7cK"}},{"cell_type":"code","source":"# rescaling layer [2]\n\npreprocess_input =  tf.keras.applications.mobilenet_v2.preprocess_input ","metadata":{"id":"V4teHGOXCWZZ","execution":{"iopub.status.busy":"2022-04-30T10:20:08.499232Z","iopub.execute_input":"2022-04-30T10:20:08.500039Z","iopub.status.idle":"2022-04-30T10:20:08.503866Z","shell.execute_reply.started":"2022-04-30T10:20:08.499994Z","shell.execute_reply":"2022-04-30T10:20:08.503265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the base model from pre-trained ","metadata":{"id":"-cbL4H56Cs3m"}},{"cell_type":"markdown","source":"we will create base model from the **MobileNetV2** please check API [Here](https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2)","metadata":{"id":"QoQWj66KDKjx"}},{"cell_type":"code","source":"IMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape = IMG_SHAPE,\n    include_top = False, # pick which layer will use and top layers not include here\n    weights = 'imagenet'\n)","metadata":{"id":"vNvkXb5tD4ek","outputId":"6b39b973-9c1f-4128-8c11-b5a3ba925824","execution":{"iopub.status.busy":"2022-04-30T10:20:08.504958Z","iopub.execute_input":"2022-04-30T10:20:08.505373Z","iopub.status.idle":"2022-04-30T10:20:10.065139Z","shell.execute_reply.started":"2022-04-30T10:20:08.50533Z","shell.execute_reply":"2022-04-30T10:20:10.064417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base model layers [3]\n\nimage_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch) \nprint(feature_batch.shape)","metadata":{"id":"XxZ1ZglOHE_N","outputId":"6f164929-c45e-4a4b-ce8b-5b97bcd96e8f","execution":{"iopub.status.busy":"2022-04-30T10:20:10.066214Z","iopub.execute_input":"2022-04-30T10:20:10.066444Z","iopub.status.idle":"2022-04-30T10:20:16.381352Z","shell.execute_reply.started":"2022-04-30T10:20:10.066412Z","shell.execute_reply":"2022-04-30T10:20:16.38064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Feature Extraction","metadata":{"id":"J0ClXwH3Hd8S"}},{"cell_type":"markdown","source":"**Note** --\n\nwe use base model from `MobileNetV2` this model has many layers already, we pick some of these layers but need to freeze what we pick , it is Important step","metadata":{"id":"yCVH9KJbHq9p"}},{"cell_type":"code","source":"base_model.trainable = False","metadata":{"id":"9MAlJwNIJQTX","execution":{"iopub.status.busy":"2022-04-30T10:20:16.382404Z","iopub.execute_input":"2022-04-30T10:20:16.382665Z","iopub.status.idle":"2022-04-30T10:20:16.394523Z","shell.execute_reply.started":"2022-04-30T10:20:16.382626Z","shell.execute_reply":"2022-04-30T10:20:16.393786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets take a look about base_model architecture\nbase_model.summary()","metadata":{"id":"wmzfa1LEJmpB","execution":{"iopub.status.busy":"2022-04-30T10:20:16.395883Z","iopub.execute_input":"2022-04-30T10:20:16.396144Z","iopub.status.idle":"2022-04-30T10:20:16.466377Z","shell.execute_reply.started":"2022-04-30T10:20:16.396099Z","shell.execute_reply":"2022-04-30T10:20:16.463298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n> from summary above you can see `BatchNormalization layer`\nyou should see [API](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) for this layer and understand why shoud make `layer.trainable = False` \n\n> you should keep the `BatchNormalization layers` in inference mode by passing `training = False` when calling the base model. Otherwise, the updates applied to the non-trainable weights will **destroy** what the model has learned.\n\n","metadata":{"id":"44YxkNAJJ3SM"}},{"cell_type":"markdown","source":"**Add a classification head** \n","metadata":{"id":"Lgt_ddLmSx-b"}},{"cell_type":"code","source":"# feature extractor layers [4]\n\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_average_layer = global_average_layer(feature_batch)\n\nprediction_layer = tf.keras.layers.Dense(1) # note you don`t need activation here as output will be raw prediction 0 or 1 \npredication_batch = prediction_layer(feature_average_layer)\n\nprint(predication_batch.shape)\n","metadata":{"id":"QAHwdJTqluhA","outputId":"a37ad3a6-8090-4ce0-cc3b-be60eaa1a446","execution":{"iopub.status.busy":"2022-04-30T10:20:16.468205Z","iopub.execute_input":"2022-04-30T10:20:16.46843Z","iopub.status.idle":"2022-04-30T10:20:16.494738Z","shell.execute_reply.started":"2022-04-30T10:20:16.468399Z","shell.execute_reply":"2022-04-30T10:20:16.494003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Building a model by chaining all together**","metadata":{"id":"uEQTV6xTrRhN"}},{"cell_type":"code","source":"inputs = tf.keras.Input(shape = (160,160,3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x,training =False) # note batchnormalization \nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(.2)(x) # reduce overfitting\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs,outputs)\n","metadata":{"id":"k1MmkTG1rwFq","execution":{"iopub.status.busy":"2022-04-30T10:20:16.495936Z","iopub.execute_input":"2022-04-30T10:20:16.496159Z","iopub.status.idle":"2022-04-30T10:20:16.917564Z","shell.execute_reply.started":"2022-04-30T10:20:16.496128Z","shell.execute_reply":"2022-04-30T10:20:16.916856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**compile the model**","metadata":{"id":"tbYMYtAItEl7"}},{"cell_type":"code","source":"learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"id":"F494jUFMuDrE","execution":{"iopub.status.busy":"2022-04-30T10:20:16.918624Z","iopub.execute_input":"2022-04-30T10:20:16.920485Z","iopub.status.idle":"2022-04-30T10:20:16.936495Z","shell.execute_reply.started":"2022-04-30T10:20:16.920455Z","shell.execute_reply":"2022-04-30T10:20:16.935684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#showing model summary\nmodel.summary()","metadata":{"id":"y-o7ixq-uKta","outputId":"398c8ae1-e8db-423c-981b-d148a3ef4634","execution":{"iopub.status.busy":"2022-04-30T10:20:16.937824Z","iopub.execute_input":"2022-04-30T10:20:16.938191Z","iopub.status.idle":"2022-04-30T10:20:16.956411Z","shell.execute_reply.started":"2022-04-30T10:20:16.938153Z","shell.execute_reply":"2022-04-30T10:20:16.955691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finally training the model\ninitial_epochs = 100\nhistory = model.fit(train_dataset,\n                    epochs=initial_epochs,\n                    validation_data = validation_dataset\n                    )","metadata":{"id":"YJahKx_puTw7","outputId":"22b3a121-b653-43be-c8f8-b58eaaf5974a","execution":{"iopub.status.busy":"2022-04-30T10:20:16.957713Z","iopub.execute_input":"2022-04-30T10:20:16.958018Z","iopub.status.idle":"2022-04-30T10:27:31.763497Z","shell.execute_reply.started":"2022-04-30T10:20:16.957979Z","shell.execute_reply":"2022-04-30T10:27:31.762824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation\n\nlook at the learning curves of the training and validation accuracy/loss","metadata":{"id":"WHxSlRLju_lo"}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(test_dataset)\n\nprint(\"Test Model loss: {:.2f}\".format(loss))\nprint(\"Test Model accuracy: {:.2f}\".format(accuracy))","metadata":{"id":"VEyVVbRcwZwX","outputId":"e694e682-6e49-4b1f-c4aa-6fcef73bfd5e","execution":{"iopub.status.busy":"2022-04-30T10:27:31.766332Z","iopub.execute_input":"2022-04-30T10:27:31.7669Z","iopub.status.idle":"2022-04-30T10:27:32.418473Z","shell.execute_reply.started":"2022-04-30T10:27:31.766869Z","shell.execute_reply":"2022-04-30T10:27:32.41767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"id":"PS5V6-auuzmW","outputId":"c2b980c4-5491-4081-f170-f80b752bc185","execution":{"iopub.status.busy":"2022-04-30T10:27:32.419617Z","iopub.execute_input":"2022-04-30T10:27:32.420372Z","iopub.status.idle":"2022-04-30T10:27:32.708242Z","shell.execute_reply.started":"2022-04-30T10:27:32.420331Z","shell.execute_reply":"2022-04-30T10:27:32.707592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"catdog.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-30T10:27:32.709353Z","iopub.execute_input":"2022-04-30T10:27:32.709694Z","iopub.status.idle":"2022-04-30T10:27:33.066652Z","shell.execute_reply.started":"2022-04-30T10:27:32.709639Z","shell.execute_reply":"2022-04-30T10:27:33.065904Z"},"trusted":true},"execution_count":null,"outputs":[]}]}