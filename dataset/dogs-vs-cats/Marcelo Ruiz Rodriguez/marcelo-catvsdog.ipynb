{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport cv2\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip ../input/dogs-vs-cats/train.zip -d train\n!unzip ../input/dogs-vs-cats/test1.zip -d test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = 'train/train/'\nTEST_DIR = 'test/test1/'\n\ntrain_images_filepaths = [TRAIN_DIR + last_file_name for last_file_name in os.listdir(TRAIN_DIR)]\ntest_images_filepaths = [TEST_DIR + last_file_name for last_file_name in os.listdir(TEST_DIR)]\n\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dogs_filepaths = [TRAIN_DIR+ dog_file_name for dog_file_name in os.listdir(TRAIN_DIR) if 'dog' in dog_file_name]\ntrain_cats_filepaths = [TRAIN_DIR+ cat_file_name for cat_file_name in os.listdir(TRAIN_DIR) if 'cat' in cat_file_name]\n\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Seeing a \"color\" image\ntest_img_file_path = train_dogs_filepaths[10]\nimg_array = cv2.imread(test_img_file_path,cv2.IMREAD_COLOR) #The last parameter can be switched with cv2.IMREAD_GRAYSCALE too\nplt.imshow(img_array)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_array_gray = cv2.imread(test_img_file_path,cv2.IMREAD_GRAYSCALE)\n\nplt.imshow(img_array_gray, cmap = \"gray\")\nplt.show()\n\nprint(img_array_gray.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROW_DIMENSION = 150\nCOLUMN_DIMENSION = 150\nCHANNELS = 3 #For greyscale images put it to 1; put it to 3 if you want color image data\n\nnew_array = cv2.resize(img_array_gray,(ROW_DIMENSION,COLUMN_DIMENSION)) #A squarish compression on it's width will take place\nplt.imshow(new_array,cmap = 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def read_converted_img(to_read_img_array):\n    plt.imshow(to_read_img_array,cmap = 'gray')\n    plt.show()\n    \ndef prep_img(single_image_path):\n    img_array_to_resize = cv2.imread(single_image_path,cv2.IMREAD_COLOR)\n    resized = cv2.resize(img_array_to_resize,(ROW_DIMENSION,COLUMN_DIMENSION),interpolation = cv2.INTER_CUBIC)\n    return resized\n\ndef prep_data(list_of_image_paths):\n    \n    size = len(list_of_image_paths)\n    \n    #preped_data = np.ndarray((size, ROW_DIMENSION, COLUMN_DIMENSION,CHANNELS), dtype=np.uint8)\n    preped_data = []\n    \n    '''\n    for i in range(size):\n        list_of_image_paths[i] = prep_img(list_of_image_paths)\n    '''\n    \n    for i, image_file_path in enumerate(list_of_image_paths):\n        '''\n        image = prep_img(image_file_path)\n        #preped_data[i] = image.T\n        preped_data.append(image)\n        '''\n        preped_data.append(cv2.resize(cv2.imread(image_file_path), (ROW_DIMENSION,COLUMN_DIMENSION), interpolation=cv2.INTER_CUBIC))\n        \n        if(i%1000==0):\n            print(\"Processed\",i,\"of\",size)\n        \n        #print(image.shape)\n        #print(preped_data.shape)\n        \n    return preped_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"PREPING TRAINING SET\")\ntrain_data = prep_data(train_images_filepaths)\nprint(\"\\nPREPING TEST SET\")\ntest_data = prep_data(test_images_filepaths)\nprint(\"\\nDone\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(train_data)\n\nprint(X_train.shape)\n#print(train_data.shape)\n#print(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_converted_img(X_train[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_train = []\n\nfor path_name in train_images_filepaths:\n    print(path_name)\n    if('dog' in path_name):\n        y_train.append(1)\n    else:\n        y_train.append(0)\n\nprint(\"Percentage of dogs is\",sum(y_train)/len(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.array(y_train)\nprint(y_train)\nfrom keras.utils.np_utils import to_categorical   \n\ncategorical_labels = to_categorical(y_train)\nprint(categorical_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, Dropout\n\nprint(\"Import Successful\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dvc_classifier = Sequential()\n\ndvc_classifier.add(Conv2D(32,kernel_size = (3,3),\n                         activation = 'relu',\n                         input_shape = (ROW_DIMENSION,COLUMN_DIMENSION,3)))\n\ndvc_classifier.add(Conv2D(32,kernel_size = (3,3),\n                        activation = 'relu'))\n\ndvc_classifier.add(Conv2D(64,kernel_size = (3,3),\n                        activation = 'relu'))\n\ndvc_classifier.add(Flatten())\n\ndvc_classifier.add(Dense(128,activation = 'relu'))\n\ndvc_classifier.add(Dense(2,activation = 'softmax'))\n\ndvc_classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dvc_classifier.compile(loss = \"categorical_crossentropy\",\n                      optimizer = 'adam',\n                      metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dvc_classifier.fit(X_train,categorical_labels,\n               batch_size = 128,\n               epochs = 5,\n               validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trying to save a model\nmodel_json = dvc_classifier.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\ndvc_classifier.save_weights(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n\n# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loaded_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr_test = np.array(test_data)\nprint(np.shape(arr_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_probabilities = dvc_classifier.predict(arr_test, verbose=0)\nprint(prediction_probabilities)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,100):\n    if prediction_probabilities[i, 0] >= prediction_probabilities[i, 1]: \n        print(f'I am {prediction_probabilities[i][0]} sure this is a Cat')\n    else: \n        print(f'I am {prediction_probabilities[i][1]} sure this is a Dog')\n    plt.imshow(arr_test[i])\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}