{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport h5py\nimport scipy.io\nimport sklearn\nimport sklearn.datasets\n\ndef sigmoid(x):\n    \n    s = 1/(1+np.exp(-x))\n    return s\n\ndef relu(x):\n   \n    s = np.maximum(0,x)\n    \n    return s\n\ndef load_params_and_grads(seed=1):\n    np.random.seed(seed)\n    W1 = np.random.randn(2,3)\n    b1 = np.random.randn(2,1)\n    W2 = np.random.randn(3,3)\n    b2 = np.random.randn(3,1)\n\n    dW1 = np.random.randn(2,3)\n    db1 = np.random.randn(2,1)\n    dW2 = np.random.randn(3,3)\n    db2 = np.random.randn(3,1)\n    \n    return W1, b1, W2, b2, dW1, db1, dW2, db2\n\n\ndef initialize_parameters(layer_dims):\n    \n    \n    \n    np.random.seed(3)\n    parameters = {}\n    L = len(layer_dims) # number of layers in the network\n\n    for l in range(1, L):\n        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*  np.sqrt(2 / layer_dims[l-1])\n        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n        \n        assert parameters['W' + str(l)].shape[0] == layer_dims[l], layer_dims[l-1]\n        assert parameters['W' + str(l)].shape[0] == layer_dims[l], 1\n        \n    return parameters\n\n\ndef compute_cost(a3, Y):\n    \n\n    \n    \n    logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n    cost_total =  np.sum(logprobs)\n    \n    return cost_total\n\ndef forward_propagation(X, parameters):\n    \n    \n    # retrieve parameters\n    W1 = parameters[\"W1\"]\n    b1 = parameters[\"b1\"]\n    W2 = parameters[\"W2\"]\n    b2 = parameters[\"b2\"]\n    W3 = parameters[\"W3\"]\n    b3 = parameters[\"b3\"]\n    \n    # LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID\n    z1 = np.dot(W1, X) + b1\n    a1 = relu(z1)\n    z2 = np.dot(W2, a1) + b2\n    a2 = relu(z2)\n    z3 = np.dot(W3, a2) + b3\n    a3 = sigmoid(z3)\n    \n    cache = (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3)\n    \n    return a3, cache\n\ndef backward_propagation(X, Y, cache):\n   \n    m = X.shape[1]\n    (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3) = cache\n    \n    dz3 = 1./m * (a3 - Y)\n    dW3 = np.dot(dz3, a2.T)\n    db3 = np.sum(dz3, axis=1, keepdims = True)\n    \n    da2 = np.dot(W3.T, dz3)\n    dz2 = np.multiply(da2, np.int64(a2 > 0))\n    dW2 = np.dot(dz2, a1.T)\n    db2 = np.sum(dz2, axis=1, keepdims = True)\n    \n    da1 = np.dot(W2.T, dz2)\n    dz1 = np.multiply(da1, np.int64(a1 > 0))\n    dW1 = np.dot(dz1, X.T)\n    db1 = np.sum(dz1, axis=1, keepdims = True)\n    \n    gradients = {\"dz3\": dz3, \"dW3\": dW3, \"db3\": db3,\n                 \"da2\": da2, \"dz2\": dz2, \"dW2\": dW2, \"db2\": db2,\n                 \"da1\": da1, \"dz1\": dz1, \"dW1\": dW1, \"db1\": db1}\n    \n    return gradients\n\ndef predict(X, y, parameters):\n    \n    m = X.shape[1]\n    p = np.zeros((1,m), dtype = np.int)\n    \n    # Forward propagation\n    a3, caches = forward_propagation(X, parameters)\n    \n    # convert probas to 0/1 predictions\n    for i in range(0, a3.shape[1]):\n        if a3[0,i] > 0.5:\n            p[0,i] = 1\n        else:\n            p[0,i] = 0\n\n    # print results\n\n    #print (\"predictions: \" + str(p[0,:]))\n    #print (\"true labels: \" + str(y[0,:]))\n    print(\"Accuracy: \"  + str(np.mean((p[0,:] == y[0,:]))))\n    \n    return p\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport zipfile\n\n#zf = zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats/train.zip\") \ndf = pd.read_csv(\"/kaggle/input/dogs-vs-cats/sampleSubmission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zf = pd.read_csv(\"/kaggle/input/dogs-vs-cats/train.zip\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! unzip /kaggle/input/dogs-vs-cats/train.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! unzip /kaggle/input/dogs-vs-cats/test1.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" k = pd.read_csv(\"/kaggle/working/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/working/train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}