{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport zipfile\nimport shutil\nimport random","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Unzipping Data in to the tmp folder\n\npath = \"/kaggle/input/dogs-vs-cats/train.zip\"\nzip_ref = zipfile.ZipFile(path)\nzip_ref.extractall('/kaggle/tmp/PetImages/')\n\npath = \"/kaggle/input/dogs-vs-cats/test1.zip\"\nzip_ref = zipfile.ZipFile(path)\nzip_ref.extractall('/kaggle/tmp/test_dataset/')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividing Cat and Dogs Images in separate folders\n\ntry:\n    os.mkdir('/kaggle/tmp/PetImages/cats')\n    os.mkdir('/kaggle/tmp/PetImages/dogs')\nexcept OSError:\n    pass\n\nsource = \"/kaggle/tmp/PetImages/train\"\ndest_cats = \"/kaggle/tmp/PetImages/cats\"\ndest_dogs = \"/kaggle/tmp/PetImages/dogs\"\n\nfor filename in os.listdir(source):\n    if 'cat' in filename:\n        shutil.copyfile(os.path.join(source, filename), os.path.join(dest_cats, filename))\n    else:\n        shutil.copyfile(os.path.join(source, filename), os.path.join(dest_dogs, filename))\n\nprint(len(os.listdir('/kaggle/tmp/PetImages/cats')))\nprint(len(os.listdir('/kaggle/tmp/PetImages/dogs')))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Folders for Image Data Generator\n\n# Creating Folders for Training Dataset\ntry:\n    os.mkdir('/kaggle/tmp/cats-v-dogs')\n    os.mkdir('/kaggle/tmp/cats-v-dogs/training_dataset')\n    os.mkdir('/kaggle/tmp/cats-v-dogs/training_dataset/cats')\n    os.mkdir('/kaggle/tmp/cats-v-dogs/training_dataset/dogs')\nexcept OSError:\n    pass\n    \n\n# Creating Folders for Validation Dataset\ntry:\n    os.mkdir('/kaggle/tmp/cats-v-dogs/validation_dataset')\n    os.mkdir('/kaggle/tmp/cats-v-dogs/validation_dataset/cats')\n    os.mkdir('/kaggle/tmp/cats-v-dogs/validation_dataset/dogs')\nexcept OSError:\n    pass\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('/kaggle/tmp/cats-v-dogs/training_dataset'))\nprint(os.listdir('/kaggle/tmp/cats-v-dogs/validation_dataset'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function for Spliting Data in to Training and Validation Datasets\n\ndef split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):\n    files = []\n    for filename in os.listdir(SOURCE):\n        file = os.path.join(SOURCE, filename)\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(filename + \" is zero length, so ignoring.\")\n            \n    training_length = int(len(files) * SPLIT_SIZE)\n    validation_length = int(len(files) - training_length)\n    shuffled_set = random.sample(files, len(files))\n    training_set = shuffled_set[0:training_length]\n    testing_set = shuffled_set[-validation_length:]\n\n    for filename in training_set:\n        this_file = os.path.join(SOURCE, filename)\n        destination = os.path.join(TRAINING, filename)\n        shutil.copyfile(this_file, destination)\n\n    for filename in testing_set:\n        this_file = os.path.join(SOURCE, filename)\n        destination = os.path.join(VALIDATION, filename)\n        shutil.copyfile(this_file, destination)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calling split_data function\n\nCAT_SOURCE = '/kaggle/tmp/PetImages/cats'\nDOG_SOURCE = '/kaggle/tmp/PetImages/dogs'\n\nCAT_TRAINING = \"/kaggle/tmp/cats-v-dogs/training_dataset/cats\"\nDOG_TRAINING = \"/kaggle/tmp/cats-v-dogs/training_dataset/dogs\"\n\nCAT_VALIDATION = \"/kaggle/tmp/cats-v-dogs/validation_dataset/cats\"\nDOG_VALIDATION = \"/kaggle/tmp/cats-v-dogs/validation_dataset/dogs\"\n\nSPLIT_SIZE = 0.9\n\nsplit_data(CAT_SOURCE, CAT_TRAINING, CAT_VALIDATION, SPLIT_SIZE)\nsplit_data(DOG_SOURCE, DOG_TRAINING, DOG_VALIDATION, SPLIT_SIZE)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Listing New Directory\nvalidation_dir = '/kaggle/tmp/cats-v-dogs/training_dataset'\nprint(\"Training Tree\")\nprint(os.listdir(validation_dir))\nprint(\"No. of Training Cats: \", len(os.listdir(CAT_TRAINING)))\nprint(\"No. of Training Dogs: \", len(os.listdir(DOG_TRAINING)))\n\nvalidation_dir = '/kaggle/tmp/cats-v-dogs/validation_dataset'\nprint(\"\\nValidation Tree\")\nprint(os.listdir(validation_dir))\nprint(\"No. of Validation Cats: \", len(os.listdir(CAT_VALIDATION)))\nprint(\"No. of Validation Dogs: \", len(os.listdir(DOG_VALIDATION)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,)\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/tmp/cats-v-dogs/training_dataset',\n    target_size=(150, 150),\n    batch_size=50,\n    class_mode='binary'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_directory(\n    '/kaggle/tmp/cats-v-dogs/validation_dataset',\n    target_size=(150, 150),\n    batch_size=50,\n    class_mode='binary'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Downloading Local Weights File\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\nlocal_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n                               include_top=False,\n                               weights=None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n    layer.trainable=False\n    \npre_trained_model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('mixed7')\nprint(\"Last layer out put shape: \", last_layer.output_shape)\nlast_layer = last_layer.output\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Flatten the output layer to 1 dimention\nx = tf.keras.layers.Flatten()(last_layer)\n\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\n\nx = tf.keras.layers.Dense(512, activation='relu')(x)\n\nx = tf.keras.layers.Dropout(0.2)(x)\n\nx = tf.keras.layers.Dense(1, activation='relu')(x)\n\nmodel = Model(pre_trained_model.input, x)\n\nmodel.compile(optimizer = RMSprop(lr=0.0001),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator,\n                    epochs=20,\n                    verbose=1,\n                    validation_data=validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ploting Training and Accuracy Graph\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n    \nacc = history.history['accuracy']\nloss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\nplt.title('Training and validation loss')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nfrom keras.preprocessing import image\n\ntest_data = '/kaggle/tmp/test_dataset/test1'\ntest_data_images = os.listdir(test_data)\n\n\npredicted_value = []\n\nfor name in test_data_images[:100]:\n    path = os.path.join(test_data, name)\n    img = image.load_img(path, target_size=(150, 150))\n    \n    x=image.img_to_array(img)\n    x=np.expand_dims(x, axis=0)\n    images = np.vstack([x])\n    \n    classes = model.predict(images, batch_size=10)\n    \n    if classes[0]>0:\n        predicted_value.append('dog')\n    else:\n        predicted_value.append('cat')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images\n\n# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=16\n\nnext_test_pix = [os.path.join(test_data, fname) \n                for fname in test_data_images[ pic_index-16:pic_index] \n               ]\n\nfor i, img_path in enumerate(next_test_pix):\n    # Set up subplot; subplot indices start at 1\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n    plt.title(predicted_value[i])\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}