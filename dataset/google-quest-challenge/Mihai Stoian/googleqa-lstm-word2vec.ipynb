{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#!git clone https://github.com/dwyl/english-words  #english words dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport json\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the question_title, question_body and qustion_answer for vectorizing\ndf_questions_answer_title = []\nfor i in range(len(df['question_body'])):\n    df_questions_answer_title.append(df['question_title'][i]+' '+df['question_body'][i]+' '+df['answer'][i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef eliminate_non_char(sample):\n    regex = re.compile(\"\"\"[,\\.!?'\"123456789]\"\"\")\n    sample = regex.sub('',sample )\n    sample = re.sub(r'\\([^)]*\\)', '', sample)\n    sample = sample.replace('\\n','')\n    new_sample = []\n    for word in sample.split():\n            new_sample.append(word)\n    return new_sample\n\n    \n#samples =[eliminate_non_english_words(x.lower()) for x in df_questions_answer_title] # question body + question answer + title\nsamples =[eliminate_non_char(x.lower()) for x in df_questions_answer_title] # question body + question answer + title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_dev, y_train, y_dev = train_test_split(samples, labels, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_train = np.array(y_train)\n#y_test = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec\nw2v_size = 300\nw2v_model = Word2Vec(min_count=50,\n                     window=4,\n                     size=w2v_size,\n                     workers=2)\nw2v_model.build_vocab(X_train)\nw2v_model.train(X_train, total_examples=w2v_model.corpus_count, epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vectorizing train data\npadding= np.zeros(w2v_size)\nX_train_vec = []\nfor sample in X_train:\n    vec = []\n    k = 0\n    for word in sample:\n        if k >= 50:\n            break\n        k += 1\n        try:\n            vec.append(w2v_model.wv[word])\n        except:\n            vec.append(padding)\n    while k < 50:\n        vec.append(padding)\n        k += 1\n    X_train_vec.append(np.array(vec))\nX_train_vec = np.array(X_train_vec)\n\n# vectorizing dev data\npadding= np.zeros(w2v_size)\nX_dev_vec = []\nfor sample in X_dev:\n    vec = []\n    k = 0\n    for word in sample:\n        if k >= 50:\n            break\n        k += 1\n        try:\n            vec.append(w2v_model.wv[word])\n        except:\n            vec.append(padding)\n    while k < 50:\n        vec.append(padding)\n        k += 1\n    X_dev_vec.append(np.array(vec))\nX_dev_vec = np.array(X_dev_vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_dev = X_dev_vec\nX_train = X_train_vec\nprint(X_train.shape)\nprint(X_dev.shape)\nprint(y_train.shape)\nprint(y_dev.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer, LSTM, Bidirectional, GlobalMaxPooling1D, Conv1D, Dropout, MaxPool1D\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(LSTM(32, return_sequences = 'True'))\n    model.add(Dropout(0.5))\n    model.add(LSTM(16))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n    return model\n\ndef train_model(model, X_train, y_train, X_test, y_test):\n    mcp_save = ModelCheckpoint('model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n    model.fit(X_train, y_train,validation_data=[X_test, y_test], batch_size=32, epochs=100,  \n                        callbacks= [\n                              EarlyStopping(patience=10, monitor='val_loss', mode='min'),\n                              mcp_save,\n                              ReduceLROnPlateau(factor=.3)\n                         ])\n    model.load_weights(filepath = 'model.hdf5')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# m = build_model()\n# train_model(m, X_train, np.array(y_train['question_well_written']), X_dev, np.array(y_dev['question_well_written']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes =['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\nsample_subbmision = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_questions_answer_title = []\nfor i in range(len(test_data['question_body'])):\n    df_questions_answer_title.append(df['question_title'][i]+' '+df['question_body'][i]+' '+df['answer'][i])\nprint(len(df_questions_answer_title))\nsamples =[eliminate_non_char(x.lower()) for x in df_questions_answer_title] # question body + question answer + title\nX_test = samples\n# vectorizing test data\npadding= np.zeros(w2v_size)\nX_test_vec = []\nfor sample in X_test:\n    vec = []\n    k = 0\n    for word in sample:\n        if k >= 50:\n            break\n        k += 1\n        try:\n            vec.append(w2v_model.wv[word])\n        except:\n            vec.append(padding)\n    while k < 50:\n        vec.append(padding)\n        k += 1\n    X_test_vec.append(np.array(vec))\nX_test_vec = np.array(X_test_vec)\nX_test = X_test_vec\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#subbmision = pd.DataFrame(columns = ['qa_id']+classes) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = {}\nk = 1\nfor cl in classes:\n    m = build_model()\n    print('Training for '+cl+'\\n')\n    m = train_model(m, X_train, np.array(y_train[cl]), X_dev, np.array(y_dev[cl]))\n    pred = m.predict(X_test)\n    predictions[cl] = pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_columns  = ['qa_id']\ni = 1\nsub_df = pd.DataFrame(columns = df_columns)\nfor cl in classes:\n    pred = []\n    for el in predictions[cl]:\n        #pred.append(el[0])\n        pred.append(\"{:.5f}\".format(el[0]))\n    sub_df.insert(i, cl, pred, True)\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df['qa_id'] = test_data['qa_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}