{"cells":[{"metadata":{},"cell_type":"markdown","source":"If you like this kernel, consider upvoting it and the associated datasets:\n- https://www.kaggle.com/abhishek/bert-base-uncased\n- https://www.kaggle.com/abhishek/tpubert"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nfrom scipy import stats\nimport numpy as np\n\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport joblib\n\nimport transformers\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nimport sys","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class BERTBaseUncased(nn.Module):\n    def __init__(self, bert_path):\n        super(BERTBaseUncased, self).__init__()\n        self.bert_path = bert_path\n        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n        self.bert_drop = nn.Dropout(0.3)\n        self.out = nn.Linear(768, 30)\n\n    def forward(\n            self,\n            ids,\n            mask,\n            token_type_ids\n    ):\n        _, o2 = self.bert(\n            ids,\n            attention_mask=mask,\n            token_type_ids=token_type_ids)\n\n        bo = self.bert_drop(o2)\n        p2 = self.out(bo)\n        return p2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BERTDatasetTest:\n    def __init__(self, qtitle, qbody, answer, tokenizer, max_length):\n        self.qtitle = qtitle\n        self.qbody = qbody\n        self.answer = answer\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.answer)\n\n    def __getitem__(self, item):\n        question_title = str(self.qtitle[item])\n        question_body = str(self.qbody[item])\n        answer_text = str(self.answer[item])\n\n        question_title = \" \".join(question_title.split())\n        question_body = \" \".join(question_body.split())\n        answer_text = \" \".join(answer_text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            question_title + \" \" + question_body,\n            answer_text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n        )\n        ids = inputs[\"input_ids\"]\n        token_type_ids = inputs[\"token_type_ids\"]\n        mask = inputs[\"attention_mask\"]\n        \n        padding_length = self.max_length - len(ids)\n        \n        ids = ids + ([0] * padding_length)\n        mask = mask + ([0] * padding_length)\n        token_type_ids = token_type_ids + ([0] * padding_length)\n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict():\n    DEVICE = torch.device(\"cuda\")\n    TEST_BATCH_SIZE = 8\n    TEST_DATASET = \"../input/google-quest-challenge/test.csv\"\n    df = pd.read_csv(TEST_DATASET).fillna(\"none\")\n\n    qtitle = df.question_title.values.astype(str).tolist()\n    qbody = df.question_body.values.astype(str).tolist()\n    answer = df.answer.values.astype(str).tolist()\n    category = df.category.values.astype(str).tolist()\n\n    tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased/\", \n                                                           do_lower_case=True)\n    maxlen = 512\n    predictions = []\n\n    test_dataset = BERTDatasetTest(\n        qtitle=qtitle,\n        qbody=qbody,\n        answer=answer,\n        tokenizer=tokenizer,\n        max_length=maxlen\n    )\n    test_data_loader = torch.utils.data.DataLoader(\n        test_dataset,\n        batch_size=TEST_BATCH_SIZE,\n        shuffle=False,\n        num_workers=4\n    )\n\n    model = BERTBaseUncased(\"../input/bert-base-uncased/\")\n    model.to(DEVICE)\n    model.load_state_dict(torch.load(\"../input/tpubert/model.bin\"))\n    model.eval()\n\n    tk0 = tqdm(test_data_loader, total=int(len(test_dataset) / test_data_loader.batch_size))\n    for bi, d in enumerate(tk0):\n        ids = d[\"ids\"]\n        mask = d[\"mask\"]\n        token_type_ids = d[\"token_type_ids\"]\n\n        ids = ids.to(DEVICE, dtype=torch.long)\n        mask = mask.to(DEVICE, dtype=torch.long)\n        token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n        \n        with torch.no_grad():\n            outputs = model(\n                ids=ids,\n                mask=mask,\n                token_type_ids=token_type_ids\n            )\n            outputs = torch.sigmoid(outputs).cpu().numpy()\n            predictions.append(outputs)\n\n    return np.vstack(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = predict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SAMPLE_SUBMISSION = \"../input/google-quest-challenge/sample_submission.csv\"\nsample = pd.read_csv(SAMPLE_SUBMISSION)\ntarget_cols = list(sample.drop(\"qa_id\", axis=1).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample[target_cols] = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}