{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/google-quest-challenge/train.csv\", index_col='qa_id')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/google-quest-challenge/test.csv\", index_col='qa_id')\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract target variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = [\n    'question_asker_intent_understanding',\n    'question_body_critical',\n    'question_conversational',\n    'question_expect_short_answer',\n    'question_fact_seeking',\n    'question_has_commonly_accepted_answer',\n    'question_interestingness_others',\n    'question_interestingness_self',\n    'question_multi_intent',\n    'question_not_really_a_question',\n    'question_opinion_seeking',\n    'question_type_choice',\n    'question_type_compare',\n    'question_type_consequence',\n    'question_type_definition',\n    'question_type_entity',\n    'question_type_instructions',\n    'question_type_procedure',\n    'question_type_reason_explanation',\n    'question_type_spelling',\n    'question_well_written',\n    'answer_helpful',\n    'answer_level_of_information',\n    'answer_plausible',\n    'answer_relevance',\n    'answer_satisfaction',\n    'answer_type_instructions',\n    'answer_type_procedure',\n    'answer_type_reason_explanation',\n    'answer_well_written'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train[target_columns].copy()\nx_train = train.drop(target_columns, axis=1)\ndel train\n\nx_test = test.copy()\ndel test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head(1).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow_hub as hub\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://github.com/tensorflow/models/blob/master/official/nlp/bert/tokenization.py\n\n# see https://www.kaggle.com/rtatman/import-functions-from-kaggle-script\n\nfrom shutil import copyfile\n\n\ncopyfile(src = \"../input/tf-bert-tokenization/tokenization.py\", dst = \"../working/tokenization.py\")\n\nfrom tokenization import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\n\nBERT = '../input/bert-model'\n\ntokenizer = FullTokenizer(BERT + '/assets/vocab.txt', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.tokenize('Hello world from BERT FullTokenizer!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from ??? well known code\n\ndef _get_masks(tokens, max_seq_length):\n    \"\"\"Mask for padding\"\"\"\n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n\ndef _get_segments(tokens, max_seq_length):\n    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    segments = []\n    first_sep = True\n    current_segment_id = 0\n    for token in tokens:\n        segments.append(current_segment_id)\n        if token == \"[SEP]\":\n            if first_sep:\n                first_sep = False\n            else:\n                current_segment_id = 1\n    return segments + [0] * (max_seq_length - len(tokens))\n\ndef _get_ids(tokens, tokenizer, max_seq_length):\n    \"\"\"Token ids from Tokenizer vocab\"\"\"\n    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n    return input_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n\n\ndef trim_tokens(t, q, a, max_t, max_q, max_a):\n    if (len(t) + len(q) + len(a)) > (max_t + max_q + max_a):\n        \n        _max_t = max_t\n        _max_q = max_q\n        _max_a = max_a\n        \n        if len(t) > _max_t:\n            t = t[:_max_t]\n        else:\n            x = (_max_t - len(t)) / 2.\n            _max_q += math.ceil(x)\n            _max_a += math.floor(x)\n        \n        if len(q) > _max_q:\n            q = q[:_max_q]\n        else:\n            _max_a += (_max_q - len(q))\n        \n        if len(a) > _max_a:\n            a = a[:_max_a]\n    \n    return t,q,a\n\n\ndef make_bert_input(x, max_question_title_length=24, max_question_body_length=242, max_answer_length=242):\n    \n    max_sequence_length = max_question_title_length + max_question_body_length + max_answer_length + 4\n    print('Calculated max sequence length:', max_sequence_length)\n    \n    input_ids = []\n    input_masks = []\n    input_segments = []\n    \n    for idx, row in x[['question_title', 'question_body', 'answer']].iterrows():\n        \n        # get tokens\n        t,q,a = trim_tokens(tokenizer.tokenize(row.question_title),\n                            tokenizer.tokenize(row.question_body),\n                            tokenizer.tokenize(row.answer),\n                            max_question_title_length,\n                            max_question_body_length,\n                            max_answer_length)\n        \n        tokens = ['[CLS]'] + t + ['[SEP]'] + q + ['[SEP]'] + a + ['[SEP]']\n        # print(tokens)\n        \n        input_ids.append(_get_ids(tokens, tokenizer, max_sequence_length))\n        input_masks.append(_get_masks(tokens, max_sequence_length))\n        input_segments.append(_get_segments(tokens, max_sequence_length))\n    \n    return [\n        np.asarray(input_ids, dtype=np.int32),\n        np.asarray(input_masks, dtype=np.int32),\n        np.asarray(input_segments, dtype=np.int32)\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_sequence_length = 512\n\n# bert_input_train = make_bert_input(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_model():\n    \n    input_word_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,\n                                           name=\"input_word_ids\")\n    input_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,\n                                       name=\"input_mask\")\n    segment_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32,\n                                        name=\"segment_ids\")\n    \n    bert_layer = hub.KerasLayer(BERT, trainable=True)\n    \n    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    \n    tmp = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n    tmp = tf.keras.layers.Dropout(0.2)(tmp)\n    out = tf.keras.layers.Dense(len(target_columns), activation='sigmoid', name='dense_output')(tmp)\n    \n    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    \n    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr\n\n\ndef mean_spearmanr_correlation_score(y_true, y_pred):\n    return np.mean([spearmanr(y_pred[:, idx] + np.random.normal(0, 1e-7, y_pred.shape[0]),\n                              y_true[:, idx]).correlation for idx in range(len(target_columns))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_estimators = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport tensorflow.keras.backend as K\nimport math\n\n\nn_splits = 5\n\nscores = []\n\ncv = KFold(n_splits=n_splits, random_state=42)\nidx = 1\nfor train_idx, valid_idx in cv.split(x_train, y_train, groups=x_train.question_body):\n    \n    x_train_train = x_train.iloc[train_idx]\n    y_train_train = y_train.iloc[train_idx]\n    x_train_valid = x_train.iloc[valid_idx]\n    y_train_valid = y_train.iloc[valid_idx]\n    \n    K.clear_session()\n    \n    estimator = make_model()\n    estimator.fit(make_bert_input(x_train_train), y_train_train, batch_size=8, epochs=5)\n    trained_estimators.append(estimator)\n    \n    oof_part = estimator.predict(make_bert_input(x_train_valid))\n    score = mean_spearmanr_correlation_score(y_train_valid.values, oof_part)\n    print('Score:', score)\n    \n    if not math.isnan(score):\n        # trained_estimators.append(estimator)\n        scores.append(score)\n    \n    # limit number of iterations to complete job within 2 hours\n    idx += 1\n    if idx > 3:\n        break\n\n\nprint('Mean score:', np.mean(scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(trained_estimators)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = []\nfor estimator in trained_estimators:\n    y_pred.append(estimator.predict(make_bert_input(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Blend by ranking"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import rankdata\n\n\ndef blend_by_ranking(data, weights):\n    out = np.zeros(data.shape[0])\n    for idx,column in enumerate(data.columns):\n        out += weights[idx] * rankdata(data[column].values)\n    out /= np.max(out)\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\", index_col='qa_id')\n\nout = pd.DataFrame(index=submission.index)\nfor column_idx,column in enumerate(target_columns):\n    \n    # collect all predictions for one column\n    column_data = pd.DataFrame(index=submission.index)\n    for prediction_idx,prediction in enumerate(y_pred):\n        column_data[str(prediction_idx)] = prediction[:, column_idx]\n    \n    out[column] = blend_by_ranking(column_data, np.ones(column_data.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"out.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}