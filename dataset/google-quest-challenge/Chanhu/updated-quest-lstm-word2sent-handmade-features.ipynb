{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing import text\nimport os\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport pickle\nimport gc\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split, KFold\nimport torch.nn.functional as F\nimport os\nimport random\nimport time\nimport pickle\nimport joblib\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler\nimport operator\nfrom nltk.tokenize.treebank import TreebankWordTokenizer\nimport spacy\nfrom spacy.lang.en import English\nfrom scipy.stats import spearmanr\nimport re\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"CRAWL_EMBEDDING_PATH = '../input/pickled-crawl300d2m-for-kernel-competitions/crawl-300d-2M.pkl'\nGLOVE_EMBEDDING_PATH = '../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'\ntrain_csv_path       = '../input/google-quest-challenge/train.csv'\ntest_csv_path        = '../input/google-quest-challenge/test.csv'\nseed                 = 0\nepochs               = 50\nmax_features         = 100000\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nseed_everything(seed)\nnlp = English()  # just the language with no model\nsentencizer = nlp.create_pipe(\"sentencizer\")\nnlp.add_pipe(sentencizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = pd.read_csv(train_csv_path)\ntest  = pd.read_csv(test_csv_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Useful Function"},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\ndef load_embeddings(path):\n    with open(path,'rb') as f:\n        emb_arr = pickle.load(f)\n    return emb_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tree_tokenizer = TreebankWordTokenizer()\ndef handle_contractions(x):\n    x = tree_tokenizer.tokenize(x)\n    x = ' '.join(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for col in ['question_body', 'question_title', 'answer']:\n    train[col] = train[col].apply(lambda x: handle_contractions(x))\n    test[col] = test[col].apply(lambda x: handle_contractions(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tokenizer = text.Tokenizer(lower=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_question = train['question_body']\nX_train_title    = train['question_title']\nX_train_answer   = train['answer']\n\nX_test_question  = test['question_body']\nX_test_title     = test['question_title']\nX_test_answer    = test['answer']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tokenizer.fit_on_texts(list(X_train_question) + \\\n                       list(X_train_answer) + \\\n                       list(X_train_title) + \\\n                       list(X_test_question) + \\\n                       list(X_test_answer) + \\\n                       list(X_test_title))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def split_document(texts):\n    \n    all_sents = []\n    max_number_sentense = 0.0\n    for text in tqdm(texts):\n        doc  = nlp(text)\n        sents = []\n        for idx, sent in enumerate(doc.sents):\n            sents.append(sent.text)\n        all_sents.append(sents)\n    \n    return all_sents\n\nX_train_question = split_document(X_train_question)\nX_train_answer   = split_document(X_train_answer)\n\nX_test_question  = split_document(X_test_question)\nX_test_answer    = split_document(X_test_answer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def build_matrix(word_index, path):\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((max_features + 1, 300))\n    unknown_words = []\n    \n    for word, i in word_index.items():\n        if i <= max_features:\n            try:\n                embedding_matrix[i] = embedding_index[word]\n            except KeyError:\n                try:\n                    embedding_matrix[i] = embedding_index[word.lower()]\n                except KeyError:\n                    try:\n                        embedding_matrix[i] = embedding_index[word.title()]\n                    except KeyError:\n                        unknown_words.append(word)\n                        \n    return embedding_matrix, unknown_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"crawl_matrix, unknown_words_crawl = build_matrix(tokenizer.word_index, CRAWL_EMBEDDING_PATH)\nprint('n unknown words (crawl): ', len(unknown_words_crawl))\n\nglove_matrix, unknown_words_glove = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\nprint('n unknown words (glove): ', len(unknown_words_glove))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"embedding_matrix = np.concatenate([crawl_matrix, glove_matrix], axis=-1)\nprint(embedding_matrix.shape)\n\ndel crawl_matrix\ndel glove_matrix\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing Train"},{"metadata":{"trusted":false},"cell_type":"code","source":"def add_question_metadata_features(text):\n    doc = nlp(text)\n    indirect = 0\n    question_count = 0\n    reason_explanation_words = 0\n    choice_words = 0\n\n    for sent in doc.sents:\n        if '?' in sent.text and '?' == sent.text[-1]:\n            question_count += 1                  # -> question_multi_intent\n            for token in sent:\n                if token.text.lower() == 'why':  # question_type_reason_explanation e.g index->102\n                    reason_explanation_words += 1\n                elif token.text.lower() == 'or':\n                    choice_words += 1            # question_type_choice\n    if question_count == 0:\n        indirect = 1\n\n    return [indirect, question_count, reason_explanation_words, choice_words]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ans_user_category = train[train[['answer_user_name', 'category']].duplicated()][['answer_user_name', 'category']].values.tolist()\nprint(len(ans_user_category))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def question_answer_author_same(df):\n    \n    q_username = df['question_user_name']\n    a_username = df['answer_user_name'] \n    \n    author_same = []\n    for i in range(len(df)):\n        if q_username[i] == a_username[i]:\n            author_same.append(int(1))\n        else:\n            author_same.append(int(0))\n            \n    return author_same\n\ndef add_external_features(df):\n    \n    #If the question is longer, it may be more clear, which may help users give a more \n    df['question_body']      = df['question_body'].progress_apply(lambda x:str(x))\n    df['question_num_words'] = df.question_body.str.count('\\S+')\n    \n    #The assumption here is that longer answer could bring more useful detail\n    df['answer']            = df['answer'].progress_apply(lambda x:str(x))\n    df['answer_num_words']  = df.answer.str.count('\\S+')\n    \n    #if the question is long and the answer is short, it may be less relevant\n    df[\"question_vs_answer_length\"] = df['question_num_words'] /  df['answer_num_words']\n    \n    #if answer's author is the same as the corresponding question's author,\n    #Why he/she asked question.. :)\n    df[\"q_a_author_same\"] = question_answer_author_same(df)\n    \n    #answers which was posted by users who answer one category more than one times, they may have read more similar questions.\n    #thus, the answers by this type of user will more relevent to question.\n    ans_user_cat = []\n    for x in tqdm(df[['answer_user_name', 'category']].values.tolist()):\n        if x in ans_user_category:\n            ans_user_cat.append(int(1))\n        else:\n            ans_user_cat.append(int(0))\n    df['ans_user_with_cat'] = ans_user_cat\n    \n    handmade_features = []\n\n    for idx, text in enumerate(df['question_body'].values):\n        handmade_features.append(add_question_metadata_features(text))\n        \n\n    return df, np.array(handmade_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train, train_handmade_features = add_external_features(train)\ntest, test_handmade_features   = add_external_features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"num_words_scaler = MinMaxScaler()\nnum_words_scaler.fit(train[['question_num_words', 'answer_num_words']].values)\ntrain[['question_num_words', 'answer_num_words']]= num_words_scaler.transform(train[['question_num_words', 'answer_num_words']].values)\ntest[['question_num_words', 'answer_num_words']] = num_words_scaler.transform(test[['question_num_words', 'answer_num_words']].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_external_features = train[['question_num_words', 'answer_num_words',\n                                 \"question_vs_answer_length\", \"q_a_author_same\",\n                                 \"ans_user_with_cat\"]].values\ntest_external_features  = test[['question_num_words', 'answer_num_words',\n                                \"question_vs_answer_length\", \"q_a_author_same\", \n                                \"ans_user_with_cat\"]].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_external_features = np.hstack((train_external_features, train_handmade_features))\ntest_external_features = np.hstack((test_external_features, test_handmade_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def tokenizer_to_index(texts, max_number_sentence, maxlen):\n    \n    all_seqs = []\n    \n    for text in tqdm(texts):\n        seqs = []\n        for sent in text:\n            sent = tokenizer.texts_to_sequences(pd.Series(sent))\n            sent = pad_sequences(sent, maxlen=maxlen)\n            if len(sent) == 0:\n                seqs.append([0]*maxlen)\n            else:\n                seqs.append(sent[0])\n        if len(seqs) < max_number_sentence:\n            gap = max_number_sentence - len(seqs)\n            pad_zeros = [[0]*maxlen for g in range(gap)]\n            seqs = pad_zeros + seqs # pad -> pre\n        elif len(seqs) > max_number_sentence:\n            seqs = seqs[:max_number_sentence]\n            \n        all_seqs.append(np.array(seqs))\n    return np.stack(all_seqs, 0)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_question = tokenizer_to_index(X_train_question, max_number_sentence=20, maxlen=50)\nX_train_answer   = tokenizer_to_index(X_train_answer, max_number_sentence=20, maxlen=50)\n\n\nX_test_question = tokenizer_to_index(X_test_question, max_number_sentence=20, maxlen=50)\nX_test_answer   = tokenizer_to_index(X_test_answer, max_number_sentence=20, maxlen=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_title    = tokenizer.texts_to_sequences(X_train_title)\nX_train_title    = pad_sequences(X_train_title, maxlen=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test_title    = tokenizer.texts_to_sequences(X_test_title)\nX_test_title    = pad_sequences(X_test_title, maxlen=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# the assumption here is that the question comment relevance might depend on the category of the question\n\nunique_categories = list(set(train['category'].unique().tolist() + test['category'].unique().tolist()))\ncategory_dict = {i + 1: e for i, e in enumerate(unique_categories)}\ncategory_dict_reverse = {v: k for k, v in category_dict.items()}\n\nunique_hosts = list(set(train['host'].unique().tolist() + test['host'].unique().tolist()))\nhost_dict = {i + 1: e for i, e in enumerate(unique_hosts)}\nhost_dict_reverse = {v: k for k, v in host_dict.items()}\n\ntrain_host = train['host'].apply(lambda x: host_dict_reverse[x]).values\ntrain_category = train['category'].apply(lambda x: category_dict_reverse[x]).values\n\ntest_host = test['host'].apply(lambda x: host_dict_reverse[x]).values\ntest_category = test['category'].apply(lambda x: category_dict_reverse[x]).values\n\nn_cat = len(category_dict) + 1\ncat_emb = min(np.ceil((len(category_dict)) / 2), 50)\nn_host = len(host_dict) + 1\nhost_emb = min(np.ceil((len(host_dict)) / 2), 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"class QuestDataset(Dataset):\n\n    def __init__(self, df, questions, answers, titles, hosts, categories, external_features):\n        self.df = df\n        self.questions         = questions\n        self.answers           = answers\n        self.titles            = titles\n        self.hosts             = hosts\n        self.categories        = categories\n        self.external_features = external_features\n\n        self.question_cols = ['question_asker_intent_understanding',\n                              'question_body_critical', 'question_conversational',\n                              'question_expect_short_answer', 'question_fact_seeking',\n                              'question_has_commonly_accepted_answer',\n                              'question_interestingness_others', 'question_interestingness_self',\n                              'question_multi_intent', 'question_not_really_a_question',\n                              'question_opinion_seeking', 'question_type_choice',\n                              'question_type_compare', 'question_type_consequence',\n                              'question_type_definition', 'question_type_entity',\n                              'question_type_instructions', 'question_type_procedure',\n                              'question_type_reason_explanation', 'question_type_spelling',\n                              'question_well_written']\n        self.answer_cols = ['answer_helpful', 'answer_level_of_information',\n                            'answer_plausible', 'answer_relevance',\n                            'answer_satisfaction', 'answer_type_instructions',\n                            'answer_type_procedure', 'answer_type_reason_explanation',\n                            'answer_well_written']\n\n        self.label = self.df[self.question_cols + self.answer_cols].values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        question = self.questions[idx]\n        answer = self.answers[idx]\n        title = self.titles[idx]\n        host = self.hosts[idx]\n        category = self.categories[idx]\n        external_features = self.external_features[idx]\n\n        labels = self.label[idx]\n\n        return [question, answer, title, host, category, external_features], labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class QuestDataset_test(Dataset):\n    \n    def __init__(self, questions, answers, titles, hosts, categories, external_features):\n        \n        self.questions         = questions\n        self.answers           = answers\n        self.titles            = titles\n        self.hosts             = hosts\n        self.categories        = categories\n        self.external_features = external_features\n\n    def __len__(self):\n        return self.questions.shape[0]\n\n    def __getitem__(self, idx):\n        \n        question = self.questions[idx]\n        answer   = self.answers[idx]\n        title    = self.titles[idx]\n        host = self.hosts[idx]\n        category = self.categories[idx]\n        external_features = self.external_features[idx]\n        \n        return [question, answer, title, host, category, external_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class SpatialDropout(nn.Dropout2d):\n    def forward(self, x):\n        x = x.unsqueeze(2)    # (N, T, 1, K)\n        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n        x = x.squeeze(2)  # (N, T, K)\n        return x\n\nclass Attention(nn.Module):\n    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n\n        self.supports_masking = True\n\n        self.bias = bias\n        self.feature_dim = feature_dim\n        self.step_dim = step_dim\n        self.features_dim = 0\n\n        weight = torch.zeros(feature_dim, 1)\n        nn.init.xavier_uniform_(weight)\n        self.weight = nn.Parameter(weight)\n\n        if bias:\n            self.b = nn.Parameter(torch.zeros(step_dim))\n\n    def forward(self, x, mask=None):\n        feature_dim = self.feature_dim\n        step_dim = self.step_dim\n\n        eij = torch.mm(\n            x.contiguous().view(-1, feature_dim),\n            self.weight\n        ).view(-1, step_dim)\n\n        if self.bias:\n            eij = eij + self.b\n\n        eij = torch.tanh(eij)\n        a = torch.exp(eij)\n\n        if mask is not None:\n            a = a * mask\n\n        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n        weighted_input = x * torch.unsqueeze(a, -1)\n        \n        return torch.sum(weighted_input, 1)\n\nclass rnn_Layer(nn.Module):\n    \n    def __init__(self, input_dim, output_dim, max_len):\n        super().__init__()\n        self.lstm_1 = nn.LSTM(input_dim, output_dim, bidirectional=True, batch_first=True)\n        self.atten  = Attention(output_dim * 2, max_len)\n        \n    def forward(self, x):\n        \n        lstm_output, _ = self.lstm_1(x)\n        \n        return self.atten(lstm_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class QuestModel(nn.Module):\n\n    def __init__(self, embedding_matrix, n_cat, cat_emb, n_host, host_emb):\n        super().__init__()\n\n        LSTM_UNITS = 128\n        embed_size = embedding_matrix.shape[1]\n        DENSE_HIDDEN_UNITS = LSTM_UNITS * 4\n        #max_features = config.MAX_FEATURES\n\n        self.embedding = nn.Embedding(max_features, embed_size)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.embedding.weight.requires_grad = False\n        self.embedding_dropout = SpatialDropout(0.3)\n\n        self.category_embedding = nn.Embedding(n_cat, int(cat_emb))\n        self.host_embedding = nn.Embedding(n_host, int(host_emb))\n\n        ##########################################################\n        # LSTM\n        ##########################################################\n        self.lstm_q_1 = rnn_Layer(embed_size, LSTM_UNITS, max_len=50)\n        self.lstm_q_2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n\n        self.lstm_a_1 = rnn_Layer(embed_size, LSTM_UNITS, max_len=50)\n        self.lstm_a_2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n\n        self.lstm_t_1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n\n        self.p_fc1 = nn.Sequential(nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS),\n                                   nn.BatchNorm1d(DENSE_HIDDEN_UNITS),\n                                   nn.ReLU(inplace=True),\n                                   nn.Dropout(0.5))\n        self.a_fc1 = nn.Sequential(nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS),\n                                   nn.BatchNorm1d(DENSE_HIDDEN_UNITS),\n                                   nn.ReLU(inplace=True),\n                                   nn.Dropout(0.5))\n        self.t_fc1 = nn.Sequential(nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS),\n                                   nn.BatchNorm1d(DENSE_HIDDEN_UNITS),\n                                   nn.ReLU(inplace=True),\n                                   nn.Dropout(0.5))\n\n        ######################################\n        # Q-branch\n        ######################################\n        self.q_t_consine = nn.CosineSimilarity(dim=1)\n        self.q_fc1 = nn.Sequential(nn.Linear(DENSE_HIDDEN_UNITS*2 + int(cat_emb) + int(host_emb) + 6, DENSE_HIDDEN_UNITS),\n                                   nn.BatchNorm1d(DENSE_HIDDEN_UNITS),\n                                   nn.ReLU(inplace=True),\n                                   nn.Dropout(0.5))\n        self.q_fc2 = nn.Linear(DENSE_HIDDEN_UNITS, 21)\n\n        ######################################\n        # QA-branch\n        ######################################\n\n        self.aq_bil = nn.Bilinear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n        self.aq_fc1 = nn.Sequential(nn.Linear(DENSE_HIDDEN_UNITS * 4 + 4, DENSE_HIDDEN_UNITS),\n                                    nn.BatchNorm1d(DENSE_HIDDEN_UNITS),\n                                    nn.ReLU(inplace=True),\n                                    nn.Dropout(0.5))\n\n        self.aq_fc2 = nn.Linear(DENSE_HIDDEN_UNITS, 9)\n\n    def forward(self, question, answer, title, host, category, external_features):\n\n        _, q_sentence_num, q_max_len = question.size()\n        _, a_sentence_num, a_max_len = answer.size()\n        category_embed  = self.category_embedding(category)\n        host_embed      = self.host_embedding(host)\n        question_length  = external_features[:, 0].unsqueeze(-1)\n        answer_length    = external_features[:, 1].unsqueeze(-1)\n        q_vs_a           = external_features[:, 2].unsqueeze(-1)\n        qa_same_author   = external_features[:, 3].unsqueeze(-1)\n        a_with_cat       = external_features[:, 4].unsqueeze(-1)\n        \n        indirect         = external_features[:, 5].unsqueeze(-1)\n        num_question     = external_features[:, 6].unsqueeze(-1)\n        reasonal_explain = external_features[:, 7].unsqueeze(-1)\n        choice           = external_features[:, 8].unsqueeze(-1)\n\n        #######################################\n        # Question\n        #######################################\n        q_reps = []\n        for i in range(q_sentence_num):\n            question_sentence = question[:, i, :].long()  # (batch_size, max_len)\n            question_embedding = self.embedding(question_sentence)\n            question_embedding = self.embedding_dropout(question_embedding)  # (batch_size, max_len, embed_size)\n            q_sentence_reps = self.lstm_q_1(question_embedding)  # (batch_size, output_dim*2) #Word-level-attention\n            q_sentence_reps = torch.unsqueeze(q_sentence_reps, dim=1)  # (batch_size, 1, LSTM_UNITS*2)\n            q_reps.append(q_sentence_reps)\n\n        q_reps     = torch.cat(q_reps, dim=1)  #(batch_size, sentence_num, LSTM_UNITS*2)\n        q_lstm2, _ = self.lstm_q_2(q_reps)\n\n        q_avg_pool = torch.mean(q_lstm2, 1)\n        q_max_pool, _ = torch.max(q_lstm2, 1)\n\n        #######################################\n        # answer\n        #######################################\n        a_reps = []\n        for j in range(a_sentence_num):\n            answer_sentence = answer[:, j, :].long()  # (batch_size, max_len)\n            answer_embedding = self.embedding(answer_sentence)\n            answer_embedding = self.embedding_dropout(answer_embedding)  # (batch_size, max_len, embed_size)\n            a_sentence_reps = self.lstm_a_1(answer_embedding)  # (batch_size, LSTM_UNITS*2)\n            a_sentence_reps = torch.unsqueeze(a_sentence_reps, dim=1)  # (batch_size, 1, DENSE_HIDDEN_UNITS)\n            a_reps.append(a_sentence_reps)\n\n        a_reps = torch.cat(a_reps, dim=1)  # (batch_size, sentence_num, DENSE_HIDDEN_UNITS)\n        a_lstm2, _ = self.lstm_a_2(a_reps)\n\n        a_avg_pool = torch.mean(a_lstm2, 1)\n        a_max_pool, _ = torch.max(a_lstm2, 1)\n\n        #######################################\n        # title\n        #######################################\n\n        title_embedding = self.embedding(title.long())\n        title_embedding = self.embedding_dropout(title_embedding)\n\n        t_lstm1, _ = self.lstm_t_1(title_embedding)\n\n        t_avg_pool = torch.mean(t_lstm1, 1)\n        t_max_pool, _ = torch.max(t_lstm1, 1)\n\n        q_features = self.p_fc1(\n            torch.cat((q_max_pool, q_avg_pool), 1))  # (batch_size, LSTM_UNITS*4) -> (batch_size, LSTM_UNITS)\n        a_features = self.a_fc1(\n            torch.cat((a_max_pool, a_avg_pool), 1))  # (batch_size, LSTM_UNITS*4) -> (batch_size, LSTM_UNITS)\n        t_features = self.t_fc1(\n            torch.cat((t_max_pool, t_avg_pool), 1))  # (batch_size, LSTM_UNITS*4) -> (batch_size, LSTM_UNITS)\n        ######################################\n        # Q-branch\n        ######################################\n        cosine_q_t = self.q_t_consine(q_features, t_features).unsqueeze(-1)\n        hidden_q   = self.q_fc1(torch.cat((q_features, t_features, category_embed, host_embed,\n                                           cosine_q_t, question_length, indirect, num_question,\n                                           reasonal_explain, choice), 1))\n        q_result   = self.q_fc2(hidden_q)\n        ######################################\n        # QA-branch\n        ######################################\n        bil_sim   = self.aq_bil(q_features, a_features)\n        hidden_aq = self.aq_fc1(torch.cat((q_features, t_features, a_features, \n                                           bil_sim, answer_length, q_vs_a, \n                                           qa_same_author, a_with_cat), 1))\n        aq_result = self.aq_fc2(hidden_aq)\n\n        return torch.cat((q_result, aq_result), 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_model(train_loader, optimizer, criterion):\n    \n    model.train()\n    avg_loss = 0.\n    \n    for idx, (inputs, labels) in enumerate(train_loader):\n        questions, answers, titles, hosts, categories, external_features = inputs \n        questions, answers, titles, hosts, categories = questions.cuda(), answers.cuda(), titles.cuda(), hosts.long().cuda(), categories.long().cuda()\n        external_features = external_features.float().cuda()\n        labels = labels.float().cuda()\n        \n        optimizer.zero_grad()\n        output_train = model(questions, answers, titles, hosts, categories, external_features)\n        loss = criterion(output_train,labels)\n        loss.backward() \n        optimizer.step()\n        avg_loss += loss.item() / len(train_loader)\n        \n    return avg_loss\n\ndef val_model(val_loader):\n    avg_val_loss = 0.\n    model.eval() #実行モード\n    preds = []\n    original = []\n    with torch.no_grad():\n        for idx, (inputs, labels) in enumerate(val_loader):\n            questions, answers, titles, hosts, categories, external_features = inputs \n            questions, answers, titles, hosts, categories = questions.cuda(), answers.cuda(), titles.cuda(), hosts.long().cuda(), categories.long().cuda()\n            external_features = external_features.float().cuda()\n            labels = labels.float().cuda()\n            \n            \n            output_val = model(questions, answers, titles, hosts, categories, external_features)\n            avg_val_loss += criterion(output_val, labels).item() / len(val_loader)\n            preds.append(output_val.cpu().numpy())\n            original.append(labels.cpu().numpy())\n        \n        score = 0\n        for i in range(30):\n            score += np.nan_to_num(\n                spearmanr(np.concatenate(original)[:, i], np.concatenate(preds)[:, i]).correlation / 30)\n        \n    return avg_val_loss, score\n\n\ndef predict_result(model, test_loader, batch_size=64):\n    \n    output = np.zeros((len(test_set), 30))\n    model.eval()\n    with torch.no_grad():\n        for idx, inputs in enumerate(test_loader):\n            start_index = idx * batch_size\n            end_index   = min(start_index + batch_size, len(test_set))\n            questions, answers, titles, hosts, categories, external_features = inputs \n            questions, answers, titles, hosts, categories = questions.cuda(), answers.cuda(), titles.cuda(), hosts.long().cuda(), categories.long().cuda()\n            external_features = external_features.float().cuda()\n            predictions = model(questions, answers, titles, hosts, categories, external_features)\n            predictions = torch.sigmoid(predictions)\n            output[start_index:end_index, :] = predictions.detach().cpu().numpy()\n            \n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=seed)\ntest_set     = QuestDataset_test(X_test_question,  \n                                 X_test_answer, \n                                 X_test_title,\n                                 test_host,\n                                 test_category,\n                                 test_external_features,\n                                )\ntest_loader  = DataLoader(test_set, batch_size=64, shuffle=False)\nresult = np.zeros((len(test), 30))\n\nfor fold, (train_index, val_index) in enumerate(kf.split(range(len(train)))):\n    print(\"fold:\", fold)\n    train_df = train.iloc[train_index]\n    val_df   = train.iloc[val_index]\n    \n    train_set    = QuestDataset(train_df,\n                                X_train_question[train_index],\n                                X_train_answer[train_index],\n                                X_train_title[train_index],\n                                train_host[train_index],\n                                train_category[train_index],\n                                train_external_features[train_index])\n    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n    \n    val_set      = QuestDataset(val_df,\n                                X_train_question[val_index],\n                                X_train_answer[val_index],\n                                X_train_title[val_index],\n                                train_host[val_index],\n                                train_category[val_index],\n                                train_external_features[val_index])\n    val_loader   = DataLoader(val_set, batch_size=64, shuffle=False)\n    \n\n    model = QuestModel(embedding_matrix, n_cat, cat_emb, n_host, host_emb)\n    model.to(device)\n    \n    best_avg_loss   = 100.0\n    best_score      = 0.0\n    best_param_loss = None\n    best_param_score = None \n    i = 0\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.BCEWithLogitsLoss()\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n\n    \n    for epoch in range(epochs):\n        \n        if i == 5: break\n        start_time   = time.time()\n        avg_loss     = train_model(train_loader, optimizer, criterion)\n        avg_val_loss, score = val_model(val_loader)\n        elapsed_time = time.time() - start_time \n        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t score={:.6f} \\t time={:.2f}s'.format(epoch + 1, epochs, avg_loss, avg_val_loss, score, elapsed_time))\n    \n        if best_avg_loss > avg_val_loss:\n            i = 0\n            best_avg_loss = avg_val_loss \n            best_param_loss = model.state_dict()\n        if best_score < score:\n            best_score = score\n            best_param_score = model.state_dict()\n        else:\n            i += 1\n        scheduler.step(avg_val_loss)\n        \n\n    model.load_state_dict(best_param_score)\n    result += predict_result(model, test_loader)\n    \n    torch.cuda.empty_cache()\n    del train_df\n    del val_df\n    del model\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"result /= 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/google-quest-challenge/sample_submission.csv\")\nsubmission.loc[:, 'question_asker_intent_understanding':] = result\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"02a57be2de5e47d9850c31481bbe8a76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a50d51a2defb4c338a833c94458bf5a7","IPY_MODEL_ded8a22c596a4c50ac1ea230383cabd4"],"layout":"IPY_MODEL_2382facad2a94394843a17c010722ccc"}},"07db061b753d4af08a28a536198b8da2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08798eacc2dc48bea01bde92e441954a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7fed30ec42d4ce7aa67f795c08adcf7","IPY_MODEL_780b0897c14a4daab6aad39881db3f83"],"layout":"IPY_MODEL_07db061b753d4af08a28a536198b8da2"}},"0a7639838df34355a05a9e9d507ac42f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_3b131cad3b654f5583082987a10af1f2","max":6079,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ce6b260a55646ef8599c8e9176d3037","value":6079}},"0b6c0746f4fd4774a675c718818363f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11df7d5d37244c8ba1a1b136411231bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13676254d8df4445b3942c9e36abf6af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16861346e48a4c879ad49cc15f64a568":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2382facad2a94394843a17c010722ccc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2508ee67cc2544378283ed9b79db5b3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0f1eadd62134c12b284521a1148f8a5","placeholder":"​","style":"IPY_MODEL_e7321611888a478cbd62f13a90ac9c69","value":" 476/476 [00:02&lt;00:00, 160.11it/s]"}},"28222c2628934997a53cbbd3ded4eea2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30f3af856d0a44f38391a4db28597355":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3597a57b31ad4d049c27d6b292e91d6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"397f78ddf5e84f378983d7ec7348e326":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db6920208ba041d3a92734b170d98e00","IPY_MODEL_70a54aa20a7c4eaf963dc4a97290dff7"],"layout":"IPY_MODEL_d0470f9bdf2c4e75b3b527bbdce29a1c"}},"3b131cad3b654f5583082987a10af1f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cd69e517b9b40e3915f47ef5efa1cd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"3ce6b260a55646ef8599c8e9176d3037":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"40f1772597a247879ae37cbe5091821f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"436e6ef2b2724d49aff5a84d4995a92e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4454316af40c47e5a1c6f63dc29a669c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a14ec2401bba4213919ef04ebe54739d","IPY_MODEL_7810a5ffca5249c8aeece0b9c3f17f54"],"layout":"IPY_MODEL_ad3f987cdfa04e97ba425471c362a275"}},"498c7fbbd32b4b0eba03ec8e22a528a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"4d865d4114634d819c83dc92b05f3f2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"54b0f7d74a0844a2b496112b134f320e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55bdefae8f234de1a8cc7c44921f77fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ba504cb1ea440c9892c213f8e63d710":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1e3f8678c394bd580db70958af41191","IPY_MODEL_c1325d0ddc364ece9bb167f422bac2fb"],"layout":"IPY_MODEL_6b79d45c93304f0ebeea933e1406f146"}},"5cf657e59a2d44249b9d6cbb4976b1c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b79d45c93304f0ebeea933e1406f146":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e51f5c5d5f149e9a469ffb6d8f4ebba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70a54aa20a7c4eaf963dc4a97290dff7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b42ca8a09f5d48bcab4bd60b5dc44258","placeholder":"​","style":"IPY_MODEL_ab4b54dfef60400ea1138d6c185d8b96","value":" 476/476 [00:03&lt;00:00, 127.46it/s]"}},"73fa51daf374405e92a9653c0e8b0ad8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"780b0897c14a4daab6aad39881db3f83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cf657e59a2d44249b9d6cbb4976b1c2","placeholder":"​","style":"IPY_MODEL_73fa51daf374405e92a9653c0e8b0ad8","value":" 6079/6079 [00:45&lt;00:00, 132.52it/s]"}},"7810a5ffca5249c8aeece0b9c3f17f54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b12ff7d92e9f425c95593eaab5d71a3b","placeholder":"​","style":"IPY_MODEL_8bbb11dfaea540869346034416a487c7","value":" 6079/6079 [00:18&lt;00:00, 324.40it/s]"}},"89a7ba6fb3cd4794a00a554932c261aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bbb11dfaea540869346034416a487c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"963802bcd65a4536b39597c8db306bfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd7c99c4b5bd41d589842a409a7dd94c","IPY_MODEL_2508ee67cc2544378283ed9b79db5b3e"],"layout":"IPY_MODEL_d6091426b89e4e5aa14d320049438661"}},"9aedcfa18498438082c1037f67461aa7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fd6c6d7fe1c44daae7056aab83a0b03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55bdefae8f234de1a8cc7c44921f77fd","placeholder":"​","style":"IPY_MODEL_9aedcfa18498438082c1037f67461aa7","value":" 6079/6079 [00:34&lt;00:00, 176.30it/s]"}},"a14ec2401bba4213919ef04ebe54739d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_dc30d04095ac426db835fbaff32e2487","max":6079,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a81184fcb37a4b6c92694d19ed48c188","value":6079}},"a16f757b3bd24ebaad59c5eca9be95ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b6c0746f4fd4774a675c718818363f3","placeholder":"​","style":"IPY_MODEL_11df7d5d37244c8ba1a1b136411231bd","value":" 476/476 [00:01&lt;00:00, 272.16it/s]"}},"a50d51a2defb4c338a833c94458bf5a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_3597a57b31ad4d049c27d6b292e91d6a","max":6079,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c25e626be5804419b1c324fd3abedf1d","value":6079}},"a81184fcb37a4b6c92694d19ed48c188":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"a9b6e50cd5374262aec968a6e7d362a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_fae074a351574525a4dfe49c06c26036","max":476,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e89a1533c5db4556ada4055283fba7f2","value":476}},"ab4b54dfef60400ea1138d6c185d8b96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad3f987cdfa04e97ba425471c362a275":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b00e9d04c8684eeb9d10ea8143caea2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9b6e50cd5374262aec968a6e7d362a0","IPY_MODEL_a16f757b3bd24ebaad59c5eca9be95ba"],"layout":"IPY_MODEL_6e51f5c5d5f149e9a469ffb6d8f4ebba"}},"b12ff7d92e9f425c95593eaab5d71a3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b42ca8a09f5d48bcab4bd60b5dc44258":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1325d0ddc364ece9bb167f422bac2fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_436e6ef2b2724d49aff5a84d4995a92e","placeholder":"​","style":"IPY_MODEL_30f3af856d0a44f38391a4db28597355","value":" 476/476 [00:02&lt;00:00, 222.55it/s]"}},"c25e626be5804419b1c324fd3abedf1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"c7fed30ec42d4ce7aa67f795c08adcf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_28222c2628934997a53cbbd3ded4eea2","max":6079,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d865d4114634d819c83dc92b05f3f2e","value":6079}},"caae7ee8c4a1403f85fa4e27438feae9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0470f9bdf2c4e75b3b527bbdce29a1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6091426b89e4e5aa14d320049438661":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db6920208ba041d3a92734b170d98e00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_16861346e48a4c879ad49cc15f64a568","max":476,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40f1772597a247879ae37cbe5091821f","value":476}},"dc30d04095ac426db835fbaff32e2487":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd7c99c4b5bd41d589842a409a7dd94c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_caae7ee8c4a1403f85fa4e27438feae9","max":476,"min":0,"orientation":"horizontal","style":"IPY_MODEL_498c7fbbd32b4b0eba03ec8e22a528a4","value":476}},"ded8a22c596a4c50ac1ea230383cabd4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13676254d8df4445b3942c9e36abf6af","placeholder":"​","style":"IPY_MODEL_89a7ba6fb3cd4794a00a554932c261aa","value":" 6079/6079 [01:04&lt;00:00, 94.97it/s]"}},"e0ed6b5602b7406d94d0f94e769b23a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a7639838df34355a05a9e9d507ac42f","IPY_MODEL_9fd6c6d7fe1c44daae7056aab83a0b03"],"layout":"IPY_MODEL_54b0f7d74a0844a2b496112b134f320e"}},"e0f1eadd62134c12b284521a1148f8a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e3f8678c394bd580db70958af41191":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_fdac6ed53ac14deb9b87ff7cab2237e3","max":476,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cd69e517b9b40e3915f47ef5efa1cd2","value":476}},"e7321611888a478cbd62f13a90ac9c69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e89a1533c5db4556ada4055283fba7f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"fae074a351574525a4dfe49c06c26036":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdac6ed53ac14deb9b87ff7cab2237e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":1}