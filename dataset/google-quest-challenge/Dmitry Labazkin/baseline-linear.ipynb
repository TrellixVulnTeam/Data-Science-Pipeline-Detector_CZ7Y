{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from pathlib import Path\n\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"RANDOM_STATE = 42\n\nDATA_PATH = Path('../input/google-quest-challenge')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH/'train.csv')\ntest_df = pd.read_csv(DATA_PATH/'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['question_title_word_len'] = train_df['question_title'].str.split().str.len()\ntest_df['question_title_word_len'] = test_df['question_title'].str.split().str.len()\n\ntrain_df['question_body_word_len'] = train_df['question_body'].str.split().str.len()\ntest_df['question_body_word_len'] = test_df['question_body'].str.split().str.len()\n\ntrain_df['answer_word_len'] = train_df['answer'].str.split().str.len()\ntest_df['answer_word_len'] = test_df['answer'].str.split().str.len()\n\nhost_levels_df = train_df['question_user_page'].str.split('/').str[2].str.rsplit('.').apply(lambda x: pd.Series(reversed(x)))\nhost_cols = ['domain_1', 'domain_2', 'domain_3', 'domain_4']\nhost_levels_df.columns = host_cols\ntrain_df[host_cols] = host_levels_df\ntrain_df['domains_count'] = host_levels_df.notnull().sum(axis=1)\n\nhost_levels_df = test_df['question_user_page'].str.split('/').str[2].str.rsplit('.').apply(lambda x: pd.Series(reversed(x)))\nhost_cols = ['domain_1', 'domain_2', 'domain_3', 'domain_4']\nhost_levels_df.columns = host_cols\ntest_df[host_cols] = host_levels_df\ntest_df['domains_count'] = host_levels_df.notnull().sum(axis=1)\n\ntrain_df['is_question_no_name_user'] = train_df['question_user_name'].str.contains('^user\\d+$')\ntrain_df['is_answer_no_name_user'] = train_df['answer_user_name'].str.contains('^user\\d+$')\n\ntest_df['is_question_no_name_user'] = test_df['question_user_name'].str.contains('^user\\d+$')\ntest_df['is_answer_no_name_user'] = test_df['answer_user_name'].str.contains('^user\\d+$')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding', 'question_body_critical', \n               'question_conversational', 'question_expect_short_answer', \n               'question_fact_seeking', 'question_has_commonly_accepted_answer', \n               'question_interestingness_others', 'question_interestingness_self', \n               'question_multi_intent', 'question_not_really_a_question', \n               'question_opinion_seeking', 'question_type_choice', \n               'question_type_compare', 'question_type_consequence', \n               'question_type_definition', 'question_type_entity', \n               'question_type_instructions', 'question_type_procedure', \n               'question_type_reason_explanation', 'question_type_spelling', \n               'question_well_written', 'answer_helpful', \n               'answer_level_of_information', 'answer_plausible', \n               'answer_relevance', 'answer_satisfaction', \n               'answer_type_instructions', 'answer_type_procedure', \n               'answer_type_reason_explanation', 'answer_well_written']\n\ncols = train_df.loc[:, ~train_df.columns.isin(target_cols)].columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n\nfrom scipy import stats\n\nimport category_encoders as ce\n\nfrom sklearn.base import clone\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer, OneHotEncoder, RobustScaler, KBinsDiscretizer, QuantileTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold, GroupKFold\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import make_scorer\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor, RANSACRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn.experimental import enable_hist_gradient_boosting \nfrom sklearn.ensemble import BaggingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spearman_corr(y_true, y_pred):\n        if np.ndim(y_pred) == 2:\n            corr = np.mean([stats.spearmanr(y_true[:, i], y_pred[:, i])[0] for i in range(y_true.shape[1])])\n        else:\n            corr = stats.spearmanr(y_true, y_pred)[0]\n        return corr\n    \ncustom_scorer = make_scorer(spearman_corr, greater_is_better=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df[cols]\ny = train_df[target_cols].values\n\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title_col = 'question_title'\ntitle_transformer = Pipeline([\n    ('tfidf', TfidfVectorizer())\n])\n\nbody_col = 'question_body'\nbody_transformer = Pipeline([\n    ('tfidf', TfidfVectorizer())\n])\n\nnum_cols = [\n    'question_title_word_len', \n    'question_body_word_len', \n    'domains_count', \n    'answer_word_len', \n]\nnum_transformer = Pipeline([\n    ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n    ('scale', PowerTransformer(method='yeo-johnson'))\n])\n\n\ncat_cols = [\n    'domain_1', \n    'domain_2', \n    'domain_3', \n    'category', \n    'is_question_no_name_user',\n    'is_answer_no_name_user'\n]\ncat_transformer = Pipeline([\n    ('impute', SimpleImputer(strategy='constant', fill_value='')),\n    ('encode', OneHotEncoder(handle_unknown='ignore'))\n])\n\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('title', title_transformer, title_col),\n        ('body', body_transformer, body_col),\n        ('num', num_transformer, num_cols),\n        ('cat', cat_transformer, cat_cols)\n    ]\n)\n\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('estimator', LinearRegression())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor.fit_transform(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n\nparam_grid = {\n    'estimator': [\n        Ridge(random_state=RANDOM_STATE),\n    ],\n    'estimator__alpha': [20],\n    \n    'preprocessor__title__tfidf__lowercase': [False],\n    'preprocessor__title__tfidf__max_df': [0.3],\n    'preprocessor__title__tfidf__min_df': [1],\n    'preprocessor__title__tfidf__binary': [True],\n    'preprocessor__title__tfidf__use_idf': [True],\n    'preprocessor__title__tfidf__smooth_idf': [False],\n    'preprocessor__title__tfidf__sublinear_tf': [False],\n    'preprocessor__title__tfidf__ngram_range': [(1, 1)], # (1, 2)\n    'preprocessor__title__tfidf__stop_words': [None],\n    'preprocessor__title__tfidf__token_pattern': ['(?u)\\\\b\\\\w+\\\\b'],\n    \n    'preprocessor__body__tfidf__lowercase': [False],\n    'preprocessor__body__tfidf__max_df': [0.3],\n    'preprocessor__body__tfidf__min_df': [1],\n    'preprocessor__body__tfidf__binary': [True],\n    'preprocessor__body__tfidf__use_idf': [False],\n    'preprocessor__body__tfidf__smooth_idf': [False],\n    'preprocessor__body__tfidf__sublinear_tf': [False],\n    'preprocessor__body__tfidf__ngram_range': [(1, 1)], # (1, 3)\n    'preprocessor__body__tfidf__stop_words': [None],\n    'preprocessor__body__tfidf__token_pattern': ['(?u)\\\\b\\\\w+\\\\b'],\n\n    'preprocessor__num__impute__strategy': ['constant'],\n    'preprocessor__num__scale': [PowerTransformer()],\n    \n    'preprocessor__cat__impute__strategy': ['constant'],\n    'preprocessor__cat__encode': [ce.BackwardDifferenceEncoder()],\n    \n}\n\ngrid_search = GridSearchCV(pipeline, param_grid, scoring=custom_scorer, \n                           cv=cv, n_jobs=-1, refit=True, return_train_score=True, verbose=2)\n\ngrid_search.fit(X, y)\ngrid_search.best_score_, grid_search.best_params_, grid_search.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"best_estimator = clone(grid_search.best_estimator_)\nbest_estimator.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test = test_df[cols]\n\ny_pred_test = best_estimator.predict(X_test)\ny_pred_test = (y_pred_test - y_pred_test.min(axis=0)) / (y_pred_test.max(axis=0) - y_pred_test.min(axis=0))\ny_pred_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_test.min(axis=0), y_pred_test.max(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission_df = pd.read_csv(DATA_PATH/'sample_submission.csv')\nsubmission_df[target_cols] = y_pred_test\nsubmission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub_file_name = 'submission.csv'\nsubmission_df.to_csv(sub_file_name, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}