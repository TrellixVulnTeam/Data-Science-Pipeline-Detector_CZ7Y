{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Aim of this Challenge:** \n\nCreate intelligent question and answer systems that can reliably predict context without relying on complicated and opaque rating guidelines.","metadata":{}},{"cell_type":"markdown","source":"# The Business Problem:\n\n\nTo create a more human-like question and answering system can answer the provided question having the intuitive understanding of the question. This can attract users and address their question more human-like and this can also increase the number of user participation in the question answering forms and create human-like conversation chat boxes.\n","metadata":{}},{"cell_type":"markdown","source":"# Exploring dataset","metadata":{}},{"cell_type":"code","source":"# importing the required libraries \n\nimport pandas as pd\nimport  numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:03.979938Z","iopub.execute_input":"2022-02-18T06:54:03.980316Z","iopub.status.idle":"2022-02-18T06:54:04.865117Z","shell.execute_reply.started":"2022-02-18T06:54:03.980228Z","shell.execute_reply":"2022-02-18T06:54:04.86437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')\ntest_dataset = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\nsample_submission_dataset = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n\nprint(\"Train shape:\", train_dataset.shape)\nprint(\"Test shape:\", test_dataset.shape)\nprint(\"Sample submission shape:\", sample_submission_dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:04.866795Z","iopub.execute_input":"2022-02-18T06:54:04.867131Z","iopub.status.idle":"2022-02-18T06:54:05.278133Z","shell.execute_reply.started":"2022-02-18T06:54:04.867092Z","shell.execute_reply":"2022-02-18T06:54:05.277399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations:\n* In train dataset we have 41 column and 6079 rows(instances/training points).\n* in test dataset we have only 11 column and 476 rows(instances/test points).\n* in submission dataset we have 31 column and 476 rows.","metadata":{}},{"cell_type":"code","source":"# Check for train data samples\ntrain_dataset.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:05.279476Z","iopub.execute_input":"2022-02-18T06:54:05.279735Z","iopub.status.idle":"2022-02-18T06:54:05.313416Z","shell.execute_reply.started":"2022-02-18T06:54:05.279684Z","shell.execute_reply":"2022-02-18T06:54:05.312676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting basic info from training data\ntrain_dataset.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:05.316189Z","iopub.execute_input":"2022-02-18T06:54:05.316695Z","iopub.status.idle":"2022-02-18T06:54:05.345396Z","shell.execute_reply.started":"2022-02-18T06:54:05.316652Z","shell.execute_reply":"2022-02-18T06:54:05.344681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Observations:** There are 10 features and no null values and 10 are having type as object and 30 labels are having type as float64 \n\n### Features:\n 1   question_title                         \n 2   question_body                           \n 3   question_user_name                      \n 4   question_user_page                     \n 5   answer                                 \n 6   answer_user_name                      \n 7   answer_user_page                        \n 8   url                                     \n 9   category                                \n 10  host      ","metadata":{}},{"cell_type":"code","source":"# Describing the train data\ntrain_dataset.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:05.346616Z","iopub.execute_input":"2022-02-18T06:54:05.346863Z","iopub.status.idle":"2022-02-18T06:54:05.428481Z","shell.execute_reply.started":"2022-02-18T06:54:05.346824Z","shell.execute_reply":"2022-02-18T06:54:05.427727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Observations:** \n* In the above 41 columns, 10 are feature and 30 are the class labels and one column qa_id is the unique ID for every instance.\n* **21 class** labels are for **questions** that is the label  that starts with \"question_...\"\n* **9 class** labels are for **answers** that is the label  which starts with \"answer_...\"\n\n* Total we have **30 Class Lables**","metadata":{}},{"cell_type":"code","source":"# Let's see the list of column names\n\nlist(train_dataset.columns[1:])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:05.429732Z","iopub.execute_input":"2022-02-18T06:54:05.429976Z","iopub.status.idle":"2022-02-18T06:54:05.436389Z","shell.execute_reply.started":"2022-02-18T06:54:05.429943Z","shell.execute_reply":"2022-02-18T06:54:05.435567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:05.437904Z","iopub.execute_input":"2022-02-18T06:54:05.438462Z","iopub.status.idle":"2022-02-18T06:54:05.468416Z","shell.execute_reply.started":"2022-02-18T06:54:05.438421Z","shell.execute_reply":"2022-02-18T06:54:05.467662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking density of words & characters present in the `question_title` feature","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\n\ndef word_count(sentense):\n    sentense = sentense.strip()\n\n    return len(sentense.split(\" \"))\n\n\nfig, ax = plt.subplots(1,2, figsize = ( 20 , 5))\n\n\nquestion_title_lengths_train = train_dataset['question_title'].apply(len)\nquestion_title_lengths_test = test_dataset['question_title'].apply(len)\nquestion_title_lengths_train_words = train_dataset['question_title'].apply(word_count)\nquestion_title_lengths_test_words = test_dataset['question_title'].apply(word_count)\n\n\nsns.histplot(question_title_lengths_train, label=\"Train\", kde=True, stat=\"density\", linewidth=0,  color=\"red\", ax=ax[0])\nsns.histplot(question_title_lengths_test, label=\"Test\", kde=True, stat=\"density\", linewidth=0,  color=\"blue\", ax=ax[0])\nsns.histplot(question_title_lengths_train_words, label=\"Train\", kde=True, stat=\"density\", linewidth=0,  color=\"red\", ax=ax[1])\nsns.histplot(question_title_lengths_test_words, label=\"Test\", kde=True, stat=\"density\", linewidth=0,  color=\"blue\", ax=ax[1])\n\n# Set label for x-axis\nax[0].set_xlabel( \"No. of characters\" , size = 12 )\n  \n# Set label for y-axis\nax[0].set_ylabel( \"Density of character\" , size = 12 )\n  \n# Set title for plot\nax[0].set_title( \"Density of characters in 'question_title' feature\\n\" , size = 15 )\n\nax[0].legend()\n\n\n# Set label for x-axis\nax[1].set_xlabel( \"No. of Words\" , size = 12 )\n  \n# Set label for y-axis\nax[1].set_ylabel( \"Density of Words\" , size = 12 )\n  \n# Set title for plot\nax[1].set_title( \"Density of Words in 'question_title' feature\\n\" , size = 15 )\n\nax[1].legend()\n\n\n\nplt.show();\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:05.469729Z","iopub.execute_input":"2022-02-18T06:54:05.469977Z","iopub.status.idle":"2022-02-18T06:54:06.245457Z","shell.execute_reply.started":"2022-02-18T06:54:05.469944Z","shell.execute_reply":"2022-02-18T06:54:06.24479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation: \n* Both train and test having the same distribution of characters and words. \n* Most of the words lies in range 5-10 both train and test. \n* Most of the characters lies in the range 40-60 train and test. ","metadata":{}},{"cell_type":"markdown","source":"## Checking density of words & characters present in the `question_body` feature","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\n\ndef word_count(sentense):\n    sentense = sentense.strip()\n\n    return len(sentense.split(\" \"))\n\n\nfig, ax = plt.subplots(1,2, figsize = ( 20 , 5))\n\n\nquestion_body_lengths_train = train_dataset['question_body'].apply(len)\nquestion_body_lengths_test = test_dataset['question_body'].apply(len)\nquestion_body_lengths_train_words = train_dataset['question_body'].apply(word_count)\nquestion_body_lengths_test_words = test_dataset['question_body'].apply(word_count)\n\n\nsns.histplot(question_body_lengths_train, label=\"Train\", kde=True, stat=\"density\", linewidth=0,  color=\"red\", ax=ax[0])\nsns.histplot(question_body_lengths_test, label=\"Test\", kde=True, stat=\"density\", linewidth=0,  color=\"blue\", ax=ax[0])\nsns.histplot(question_body_lengths_train_words, label=\"Train\", kde=True, stat=\"density\", linewidth=0,  color=\"red\", ax=ax[1])\nsns.histplot(question_body_lengths_test_words, label=\"Test\", kde=True, stat=\"density\", linewidth=0,  color=\"blue\", ax=ax[1])\n\n# Set label for x-axis\nax[0].set_xlabel( \"No. of characters\" , size = 12 )\n  \n# Set label for y-axis\nax[0].set_ylabel( \"Density of character\" , size = 12 )\n  \n# Set title for plot\nax[0].set_title( \"Density of characters in 'question_body' feature\\n\" , size = 15 )\n\nax[0].legend()\n\n\n# Set label for x-axis\nax[1].set_xlabel( \"No. of Words\" , size = 12 )\n  \n# Set label for y-axis\nax[1].set_ylabel( \"Density of Words\" , size = 12 )\n  \n# Set title for plot\nax[1].set_title( \"Density of Words in 'question_body' feature\\n\" , size = 15 )\n\nax[1].legend()\n\n\n\nplt.show();\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:06.246723Z","iopub.execute_input":"2022-02-18T06:54:06.247067Z","iopub.status.idle":"2022-02-18T06:54:09.332258Z","shell.execute_reply.started":"2022-02-18T06:54:06.247036Z","shell.execute_reply":"2022-02-18T06:54:09.331575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\n* We can observe that the distribution of both words and characters are very much right skewed.\n* Most of the characters in question_body lies below 2500.\n* Most of the words in question_body lies below 1000.","metadata":{}},{"cell_type":"markdown","source":"## Similarly we will check for `answer` feature","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\n\ndef word_count(sentense):\n    sentense = sentense.strip()\n    return len(sentense.split(\" \"))\n\n\nfig, ax = plt.subplots(1,2, figsize = ( 20 , 5))\n\n\nanswer_lengths_train = train_dataset['answer'].apply(len)\nanswer_lengths_test = test_dataset['answer'].apply(len)\nanswer_lengths_train_words = train_dataset['answer'].apply(word_count)\nanswer_lengths_test_words = test_dataset['answer'].apply(word_count)\n\n\nsns.histplot(answer_lengths_train, label=\"Train\", kde=True, stat=\"density\", linewidth=0,  color=\"red\", ax=ax[0])\nsns.histplot(answer_lengths_test, label=\"Test\", kde=True, stat=\"density\", linewidth=0,  color=\"blue\", ax=ax[0])\nsns.histplot(answer_lengths_train_words, label=\"Train\", kde=True, stat=\"density\", linewidth=0,  color=\"red\", ax=ax[1])\nsns.histplot(answer_lengths_test_words, label=\"Test\", kde=True, stat=\"density\", linewidth=0,  color=\"blue\", ax=ax[1])\n\n# Set label for x-axis\nax[0].set_xlabel( \"No. of characters\" , size = 12 )\n  \n# Set label for y-axis\nax[0].set_ylabel( \"Density of character\" , size = 12 )\n  \n# Set title for plot\nax[0].set_title( \"Density of characters in 'answer' feature\\n\" , size = 15 )\n\nax[0].legend()\n\n\n# Set label for x-axis\nax[1].set_xlabel( \"No. of Words\" , size = 12 )\n  \n# Set label for y-axis\nax[1].set_ylabel( \"Density of Words\" , size = 12 )\n  \n# Set title for plot\nax[1].set_title( \"Density of Words in 'answer' feature\\n\" , size = 15 )\n\nax[1].legend()\n\n\n\nplt.show();\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:09.335578Z","iopub.execute_input":"2022-02-18T06:54:09.335785Z","iopub.status.idle":"2022-02-18T06:54:12.591795Z","shell.execute_reply.started":"2022-02-18T06:54:09.33576Z","shell.execute_reply":"2022-02-18T06:54:12.591102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\n* As similar to question_body we can find that answer distribution is also skewed.\n* Their may be some extreme outlier instance that words/char length are very high in both question_body and answer features.","metadata":{}},{"cell_type":"markdown","source":"## Analyzing `question_body` and `answer` features sequence length","metadata":{}},{"cell_type":"code","source":"for i in range(0,101,10):\n    print(f'{i}th percentile of question_body input sequence {np.percentile(question_body_lengths_train_words, i)}')\nprint()\nfor i in range(90,101):\n    print(f'{i}th percentile of question_body input sequence {np.percentile(question_body_lengths_train_words, i)}')\nprint()\nfor i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n    print(f'{i}th percentile of question_body input sequence {np.percentile(question_body_lengths_train_words, i)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:12.593017Z","iopub.execute_input":"2022-02-18T06:54:12.593417Z","iopub.status.idle":"2022-02-18T06:54:12.618222Z","shell.execute_reply.started":"2022-02-18T06:54:12.593357Z","shell.execute_reply":"2022-02-18T06:54:12.616962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Observation:** 99.9% the of words in question body lies below **3220**","metadata":{}},{"cell_type":"code","source":"for i in range(0,101,10):\n    print(f'{i}th percentile of answer input sequence {np.percentile(answer_lengths_train_words, i)}')\nprint()\nfor i in range(90,101):\n    print(f'{i}th percentile of answer input sequence {np.percentile(answer_lengths_train_words, i)}')\nprint()\nfor i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n    print(f'{i}th percentile of answer input sequence {np.percentile(answer_lengths_train_words, i)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:12.61934Z","iopub.execute_input":"2022-02-18T06:54:12.619674Z","iopub.status.idle":"2022-02-18T06:54:12.643375Z","shell.execute_reply.started":"2022-02-18T06:54:12.619637Z","shell.execute_reply":"2022-02-18T06:54:12.642661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Observation:** 99.9% of words in answer feature lies below **2200**","metadata":{}},{"cell_type":"markdown","source":"# Analyzing `category` Feature","metadata":{}},{"cell_type":"code","source":"train_dataset['category'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:12.645505Z","iopub.execute_input":"2022-02-18T06:54:12.645747Z","iopub.status.idle":"2022-02-18T06:54:12.651748Z","shell.execute_reply.started":"2022-02-18T06:54:12.645697Z","shell.execute_reply":"2022-02-18T06:54:12.650986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_category_feature_count = train_dataset['category'].value_counts()\ntest_category_feature_count = test_dataset['category'].value_counts()\n\nprint(\"Train category:\\n\",train_category_feature_count)\nprint()\nprint(\"Test category:\\n\",test_category_feature_count)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:12.653148Z","iopub.execute_input":"2022-02-18T06:54:12.653423Z","iopub.status.idle":"2022-02-18T06:54:12.66497Z","shell.execute_reply.started":"2022-02-18T06:54:12.65337Z","shell.execute_reply":"2022-02-18T06:54:12.664223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure, ax = plt.subplots(1,2, figsize=(12, 6))\n\ntrain_category_feature_count.plot(kind='bar', ax=ax[0])\ntest_category_feature_count.plot(kind='bar', ax=ax[1])\n\nax[0].set_title('Train')\nax[0].set_xlabel( \"unique category\" , size = 12 )\nax[0].set_ylabel( \"count\" , size = 12 )\n\nax[1].set_title('Test')\nax[1].set_xlabel( \"unique category\" , size = 12 )\nax[1].set_ylabel( \"count\" , size = 12 )\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:12.666315Z","iopub.execute_input":"2022-02-18T06:54:12.666533Z","iopub.status.idle":"2022-02-18T06:54:12.976199Z","shell.execute_reply.started":"2022-02-18T06:54:12.666498Z","shell.execute_reply":"2022-02-18T06:54:12.975539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample stack over flow question and answer\ntrain_dataset[train_dataset['category'] == 'STACKOVERFLOW'].values[11]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:12.977598Z","iopub.execute_input":"2022-02-18T06:54:12.978074Z","iopub.status.idle":"2022-02-18T06:54:12.990081Z","shell.execute_reply.started":"2022-02-18T06:54:12.978037Z","shell.execute_reply":"2022-02-18T06:54:12.989361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample science question and answer \ntrain_dataset[train_dataset['category'] == 'SCIENCE'].values[11]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:12.991526Z","iopub.execute_input":"2022-02-18T06:54:12.991823Z","iopub.status.idle":"2022-02-18T06:54:13.001931Z","shell.execute_reply.started":"2022-02-18T06:54:12.991786Z","shell.execute_reply":"2022-02-18T06:54:13.00129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample life art and culture question and answer\ntrain_dataset[train_dataset['category'] == 'LIFE_ARTS'].values[11]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:13.003455Z","iopub.execute_input":"2022-02-18T06:54:13.004035Z","iopub.status.idle":"2022-02-18T06:54:13.014409Z","shell.execute_reply.started":"2022-02-18T06:54:13.003997Z","shell.execute_reply":"2022-02-18T06:54:13.013537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample life art and culture question and answer\ntrain_dataset[train_dataset['category'] == 'CULTURE'].values[11]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:13.016168Z","iopub.execute_input":"2022-02-18T06:54:13.01666Z","iopub.status.idle":"2022-02-18T06:54:13.027309Z","shell.execute_reply.started":"2022-02-18T06:54:13.016622Z","shell.execute_reply":"2022-02-18T06:54:13.026511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\n* Five unique category are present in the category feature.\n* **Technology** and **Stackoverflow** are the highest count and both are related topics.\n* **Life_arts** as the lowest count category.\n* Distribution of train and test category are the same.\n* **Life_arts & culture** follow general english syntax & structure.\n* **Science** utilizes latex with expressions prepended and appended with symbol: $\n* **Technology & stackoverflow** have code snippets & logs.","metadata":{}},{"cell_type":"markdown","source":"# Word cloud","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\n\n\ndef plot_wordcloud(text, ax, title=None):\n    wordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\n    ax.imshow(wordcloud)\n    if title is not None:\n        ax.set_title(title, size = 15)\n    ax.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:13.028885Z","iopub.execute_input":"2022-02-18T06:54:13.029216Z","iopub.status.idle":"2022-02-18T06:54:13.087394Z","shell.execute_reply.started":"2022-02-18T06:54:13.029182Z","shell.execute_reply":"2022-02-18T06:54:13.086753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# word cloud for train data\ntext = ' '.join(train_dataset['question_title'].values)\nplot_wordcloud(text, axes[0][0], 'Train Question title')\n\ntext = ' '.join(train_dataset['question_body'].values)\nplot_wordcloud(text, axes[0][1], 'Train Question body')\n\ntext = ' '.join(train_dataset['answer'].values)\nplot_wordcloud(text, axes[0][2], 'Train Answer')\n\n\n# word cloud for Test data\ntext = ' '.join(test_dataset['question_title'].values)\nplot_wordcloud(text, axes[1][0], 'Test Question title')\n\ntext = ' '.join(test_dataset['question_body'].values)\nplot_wordcloud(text, axes[1][1], 'Test Question body')\n\ntext = ' '.join(test_dataset['answer'].values)\nplot_wordcloud(text, axes[1][2], 'Test Answer')\n\nplt.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:13.088593Z","iopub.execute_input":"2022-02-18T06:54:13.089053Z","iopub.status.idle":"2022-02-18T06:54:35.182076Z","shell.execute_reply.started":"2022-02-18T06:54:13.089018Z","shell.execute_reply":"2022-02-18T06:54:35.179775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\n* We can observe that some of words match between train and test set.\nReference: https://www.kaggle.com/corochann/google-quest-first-data-introduction?scriptVersionId=23910525&cellId=34","metadata":{}},{"cell_type":"markdown","source":"# Analyzing labels ","metadata":{}},{"cell_type":"code","source":"for label in train_dataset.columns[11:]:\n    print(f\"{label:.20}: no. of unique label values: {len(train_dataset[label].unique())}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:35.183042Z","iopub.execute_input":"2022-02-18T06:54:35.183257Z","iopub.status.idle":"2022-02-18T06:54:35.200691Z","shell.execute_reply.started":"2022-02-18T06:54:35.183229Z","shell.execute_reply":"2022-02-18T06:54:35.200114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\n* The output label are regression(real) values but the distribution is not continuous.\n* Except for `answer_satisfaction` label rest every label are having unique values some are with 9 unique values and some are of 5 unique values.\n* Using this insights we can use post pocessing to get better scoring ","metadata":{}},{"cell_type":"code","source":"for label in train_dataset.columns[11:]:\n    sns.histplot(train_dataset[label], label=label, kde=False)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:35.201806Z","iopub.execute_input":"2022-02-18T06:54:35.202217Z","iopub.status.idle":"2022-02-18T06:54:42.271234Z","shell.execute_reply.started":"2022-02-18T06:54:35.202178Z","shell.execute_reply":"2022-02-18T06:54:42.270572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\n* **Label values are imbalance** like for some of the label values are having only one values ex: **question_type_spelling**, **question_not_really_question** etc that is the distribution of label are very dissimilar.","metadata":{}},{"cell_type":"markdown","source":"### correlation between target variables","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,20))   \nsns.heatmap(train_dataset[11:].corr(), linewidths=1, ax=ax, annot_kws={\"fontsize\":40})\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:42.272506Z","iopub.execute_input":"2022-02-18T06:54:42.272755Z","iopub.status.idle":"2022-02-18T06:54:43.541497Z","shell.execute_reply.started":"2022-02-18T06:54:42.272705Z","shell.execute_reply":"2022-02-18T06:54:43.540778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations:\nFrom the above heatmap of correleation we can observe that `answer_helpful`, `answer_level_of_information`, `answer_plausible`, `answer_releveance` and `answer_satification` have some correlation between them.","metadata":{}},{"cell_type":"markdown","source":"## Analyzing `host` feature","metadata":{}},{"cell_type":"code","source":"print(f\"Total unique host present in the dataset {len(train_dataset['host'].unique())}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:43.545225Z","iopub.execute_input":"2022-02-18T06:54:43.546845Z","iopub.status.idle":"2022-02-18T06:54:43.556252Z","shell.execute_reply.started":"2022-02-18T06:54:43.546806Z","shell.execute_reply":"2022-02-18T06:54:43.555346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_host_feature_count = train_dataset['host'].value_counts()\n\n\nfigure, ax = plt.subplots( figsize=(20, 5))\n\ntrain_host_feature_count.plot(kind='bar', ax=ax)\n\nax.set_title('Train dataset - count of Q&A collected from each website', size=20)\nax.set_xlabel( \"Host\" , size = 12 )\nax.set_ylabel( \"Count\" , size = 12 )\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:43.557602Z","iopub.execute_input":"2022-02-18T06:54:43.558091Z","iopub.status.idle":"2022-02-18T06:54:44.921533Z","shell.execute_reply.started":"2022-02-18T06:54:43.558056Z","shell.execute_reply":"2022-02-18T06:54:44.920863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_host_feature_count = test_dataset['host'].value_counts()\nfigure, ax = plt.subplots( figsize=(20, 5))\ntest_host_feature_count.plot(kind='bar', ax=ax)\nax.set_title('Test dataset - count of Q&A collected from each website', size=20)\nax.set_xlabel( \"Host\" , size = 12 )\nax.set_ylabel( \"Count\" , size = 12 )\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:44.922666Z","iopub.execute_input":"2022-02-18T06:54:44.923233Z","iopub.status.idle":"2022-02-18T06:54:45.924413Z","shell.execute_reply.started":"2022-02-18T06:54:44.92319Z","shell.execute_reply":"2022-02-18T06:54:45.923772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\n* All question and answer in the dataset are extracted from **63 websites**.\n* Most of the question and answer are from **stackoverflow.com** as we observe from the  `category` feature analysis that most of the caterogy fall under **technology and stackoverflow**.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Spliting the data in to train and validation","metadata":{}},{"cell_type":"code","source":"y_columns = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']\n\ny = train_dataset[y_columns]\nX = train_dataset.drop(y_columns,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:45.930291Z","iopub.execute_input":"2022-02-18T06:54:45.930859Z","iopub.status.idle":"2022-02-18T06:54:45.938545Z","shell.execute_reply.started":"2022-02-18T06:54:45.930827Z","shell.execute_reply":"2022-02-18T06:54:45.937883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:45.939816Z","iopub.execute_input":"2022-02-18T06:54:45.940451Z","iopub.status.idle":"2022-02-18T06:54:45.959431Z","shell.execute_reply.started":"2022-02-18T06:54:45.940401Z","shell.execute_reply":"2022-02-18T06:54:45.958638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train_dataset, X_valid_dataset, y_train_dataset, y_valid_dataset = train_test_split(X,y, test_size=0.10)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:45.960819Z","iopub.execute_input":"2022-02-18T06:54:45.96111Z","iopub.status.idle":"2022-02-18T06:54:46.113239Z","shell.execute_reply.started":"2022-02-18T06:54:45.961077Z","shell.execute_reply":"2022-02-18T06:54:46.112503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset.shape, X_valid_dataset.shape, y_train_dataset.shape, y_valid_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:46.114591Z","iopub.execute_input":"2022-02-18T06:54:46.114851Z","iopub.status.idle":"2022-02-18T06:54:46.120908Z","shell.execute_reply.started":"2022-02-18T06:54:46.114816Z","shell.execute_reply":"2022-02-18T06:54:46.120133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:46.122412Z","iopub.execute_input":"2022-02-18T06:54:46.122737Z","iopub.status.idle":"2022-02-18T06:54:46.145076Z","shell.execute_reply.started":"2022-02-18T06:54:46.122691Z","shell.execute_reply":"2022-02-18T06:54:46.144219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Preprocessing Text Feature**","metadata":{}},{"cell_type":"code","source":"# https://stackoverflow.com/a/47091490/4084039\nimport re\n\ndef decontracted(phrase):\n    phrase = re.sub(r\"(W|w)on(\\'|\\’)t \", \"will not \", phrase)\n    phrase = re.sub(r\"(C|c)an(\\'|\\’)t \", \"can not \", phrase)\n    phrase = re.sub(r\"(Y|y)(\\'|\\’)all \", \"you all \", phrase)\n    phrase = re.sub(r\"(Y|y)a(\\'|\\’)ll \", \"you all \", phrase)\n    phrase = re.sub(r\"(I|i)(\\'|\\’)m \", \"i am \", phrase)\n    phrase = re.sub(r\"(A|a)isn(\\'|\\’)t \", \"is not \", phrase)\n    phrase = re.sub(r\"n(\\'|\\’)t \", \" not \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)re \", \" are \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)d \", \" would \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)ll \", \" will \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)t \", \" not \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)ve \", \" have \", phrase)\n    \n    return phrase\n\n\ndef clean_text(x):\n\n    x = str(x)\n    for punct in \"/-'\":\n        x = x.replace(punct, ' ')\n    for punct in '&':\n        x = x.replace(punct, f' {punct} ')\n    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n        x = x.replace(punct, '')\n    return x\n\ndef clean_numbers(x):\n\n    x = re.sub('[0-9]{5,}', '12345', x)\n    x = re.sub('[0-9]{4}', '1234', x)\n    x = re.sub('[0-9]{3}', '123', x)\n    x = re.sub('[0-9]{2}', '12', x)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:46.146608Z","iopub.execute_input":"2022-02-18T06:54:46.146942Z","iopub.status.idle":"2022-02-18T06:54:46.158458Z","shell.execute_reply.started":"2022-02-18T06:54:46.146902Z","shell.execute_reply":"2022-02-18T06:54:46.157341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://gist.github.com/sebleier/554280\n# we are removing the words from the stop words list: 'no', 'nor', 'not'\nstopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:46.159514Z","iopub.execute_input":"2022-02-18T06:54:46.160414Z","iopub.status.idle":"2022-02-18T06:54:46.171952Z","shell.execute_reply.started":"2022-02-18T06:54:46.160378Z","shell.execute_reply":"2022-02-18T06:54:46.171244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combining all the above stundents \nfrom tqdm import tqdm\ndef preprocess_text(text_data):\n    preprocessed_text = []\n    # tqdm is for printing the status bar\n    for sentance in tqdm(text_data):\n        sent = decontracted(sentance)\n        sent = clean_text(sentance)\n        sent = clean_numbers(sentance)\n        sent = sent.replace('\\\\r', ' ')\n        sent = sent.replace('\\\\n', ' ')\n        sent = sent.replace('\\\\\"', ' ')\n        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n        # https://gist.github.com/sebleier/554280\n        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n        preprocessed_text.append(sent.lower().strip())\n    return preprocessed_text","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:46.172943Z","iopub.execute_input":"2022-02-18T06:54:46.173307Z","iopub.status.idle":"2022-02-18T06:54:46.18426Z","shell.execute_reply.started":"2022-02-18T06:54:46.173266Z","shell.execute_reply":"2022-02-18T06:54:46.183522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset['preprocessed_question_title'] = preprocess_text(X_train_dataset['question_title'].values)\nX_train_dataset['preprocessed_question_body'] = preprocess_text(X_train_dataset['question_body'].values)\nX_train_dataset['preprocessed_answer'] = preprocess_text(X_train_dataset['answer'].values)\n\n\nX_valid_dataset['preprocessed_question_title'] = preprocess_text(X_valid_dataset['question_title'].values)\nX_valid_dataset['preprocessed_question_body'] = preprocess_text(X_valid_dataset['question_body'].values)\nX_valid_dataset['preprocessed_answer'] = preprocess_text(X_valid_dataset['answer'].values)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:46.185403Z","iopub.execute_input":"2022-02-18T06:54:46.186144Z","iopub.status.idle":"2022-02-18T06:54:54.855758Z","shell.execute_reply.started":"2022-02-18T06:54:46.186102Z","shell.execute_reply":"2022-02-18T06:54:54.854636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset['preprocessed_question_title'] = preprocess_text(test_dataset['question_title'].values)\ntest_dataset['preprocessed_question_body'] = preprocess_text(test_dataset['question_body'].values)\ntest_dataset['preprocessed_answer'] = preprocess_text(test_dataset['answer'].values)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:54.856949Z","iopub.execute_input":"2022-02-18T06:54:54.857431Z","iopub.status.idle":"2022-02-18T06:54:55.561291Z","shell.execute_reply.started":"2022-02-18T06:54:54.857387Z","shell.execute_reply":"2022-02-18T06:54:55.560483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### question_title text after preprocessing","metadata":{}},{"cell_type":"code","source":"# Text before preprocessing\nX_train_dataset['question_title'].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:55.562781Z","iopub.execute_input":"2022-02-18T06:54:55.563056Z","iopub.status.idle":"2022-02-18T06:54:55.568326Z","shell.execute_reply.started":"2022-02-18T06:54:55.56302Z","shell.execute_reply":"2022-02-18T06:54:55.567685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text after preprocessing\nX_train_dataset['preprocessed_question_title'].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:55.56959Z","iopub.execute_input":"2022-02-18T06:54:55.570077Z","iopub.status.idle":"2022-02-18T06:54:55.580341Z","shell.execute_reply.started":"2022-02-18T06:54:55.570041Z","shell.execute_reply":"2022-02-18T06:54:55.579429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### question_body after preprocessing","metadata":{}},{"cell_type":"code","source":"# Text before preprocessing\nX_train_dataset['question_body'].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:55.581705Z","iopub.execute_input":"2022-02-18T06:54:55.581962Z","iopub.status.idle":"2022-02-18T06:54:55.59091Z","shell.execute_reply.started":"2022-02-18T06:54:55.581928Z","shell.execute_reply":"2022-02-18T06:54:55.590015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text after preprocessing\nX_train_dataset['preprocessed_question_body'].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:55.592324Z","iopub.execute_input":"2022-02-18T06:54:55.592901Z","iopub.status.idle":"2022-02-18T06:54:55.602133Z","shell.execute_reply.started":"2022-02-18T06:54:55.592863Z","shell.execute_reply":"2022-02-18T06:54:55.601368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Answer after preprocessing","metadata":{}},{"cell_type":"code","source":"# Text before preprocessing\nX_train_dataset['answer'].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:55.604218Z","iopub.execute_input":"2022-02-18T06:54:55.604767Z","iopub.status.idle":"2022-02-18T06:54:55.610517Z","shell.execute_reply.started":"2022-02-18T06:54:55.604722Z","shell.execute_reply":"2022-02-18T06:54:55.609651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text after preprocessing\nX_train_dataset['preprocessed_answer'].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:55.612094Z","iopub.execute_input":"2022-02-18T06:54:55.61264Z","iopub.status.idle":"2022-02-18T06:54:55.619599Z","shell.execute_reply.started":"2022-02-18T06:54:55.612605Z","shell.execute_reply":"2022-02-18T06:54:55.61883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature engineering:**","metadata":{}},{"cell_type":"markdown","source":"## Text count based features:\n\n1. Number of characters in the **question_title**\n2. Number of characters in the **question_body**\n3. Number of characters in the **answer**\n4. Number of words in the **question_title**\n5. Number of words in the **question_body**\n6. Number of words in the **answer**\n7. Number of unique words in the **question_title**\n8. Number of unique words in the **question_body**\n9. Number of unique words in the **answer**\n","metadata":{}},{"cell_type":"code","source":"def word_count(sentense):\n    sentense = sentense.strip()\n\n    return len(sentense.split(\" \"))\n\ndef unique_word_count(sentense):\n    sentense = sentense.strip()\n\n    return len(set(sentense.split(\" \")))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:55.621065Z","iopub.execute_input":"2022-02-18T06:54:55.621366Z","iopub.status.idle":"2022-02-18T06:54:55.629444Z","shell.execute_reply.started":"2022-02-18T06:54:55.621329Z","shell.execute_reply":"2022-02-18T06:54:55.628754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n# Number of characters in the text\nX_train_dataset[\"question_title_num_chars\"] = X_train_dataset[\"question_title\"].apply(len)\nX_train_dataset[\"question_body_num_chars\"] = X_train_dataset[\"question_body\"].apply(len)\nX_train_dataset[\"answer_num_chars\"] = X_train_dataset[\"answer\"].apply(len)\n\n# Feature engineering for validation dataset\nX_valid_dataset[\"question_title_num_chars\"] = X_valid_dataset[\"question_title\"].apply(len)\nX_valid_dataset[\"question_body_num_chars\"] = X_valid_dataset[\"question_body\"].apply(len)\nX_valid_dataset[\"answer_num_chars\"] = X_valid_dataset[\"answer\"].apply(len)\n\ntest_dataset[\"question_title_num_chars\"] = test_dataset[\"question_title\"].apply(len)\ntest_dataset[\"question_body_num_chars\"] = test_dataset[\"question_body\"].apply(len)\ntest_dataset[\"answer_num_chars\"] = test_dataset[\"answer\"].apply(len)\n\n#########################################################################################################\n# Number of words in the text\nX_train_dataset[\"question_title_num_words\"] = X_train_dataset[\"question_title\"].apply(word_count)\nX_train_dataset[\"question_body_num_words\"] = X_train_dataset[\"question_body\"].apply(word_count)\nX_train_dataset[\"answer_num_words\"] = X_train_dataset[\"answer\"].apply(word_count)\n\n# validation dataset features\nX_valid_dataset[\"question_title_num_words\"] = X_valid_dataset[\"question_title\"].apply(word_count)\nX_valid_dataset[\"question_body_num_words\"] = X_valid_dataset[\"question_body\"].apply(word_count)\nX_valid_dataset[\"answer_num_words\"] = X_valid_dataset[\"answer\"].apply(word_count)\n\ntest_dataset[\"question_title_num_words\"] = test_dataset[\"question_title\"].apply(word_count)\ntest_dataset[\"question_body_num_words\"] = test_dataset[\"question_body\"].apply(word_count)\ntest_dataset[\"answer_num_words\"] = test_dataset[\"answer\"].apply(word_count)\n\n\n#######################################################################################################\n# Number of unique words in the text\nX_train_dataset[\"question_title_num_unique_words\"] = X_train_dataset[\"question_title\"].apply(unique_word_count)\nX_train_dataset[\"question_body_num_unique_words\"] = X_train_dataset[\"question_body\"].apply(unique_word_count)\nX_train_dataset[\"answer_num_unique_words\"] = X_train_dataset[\"answer\"].apply(unique_word_count)\n\n# Validation dataset\nX_valid_dataset[\"question_title_num_unique_words\"] = X_valid_dataset[\"question_title\"].apply(unique_word_count)\nX_valid_dataset[\"question_body_num_unique_words\"] = X_valid_dataset[\"question_body\"].apply(unique_word_count)\nX_valid_dataset[\"answer_num_unique_words\"] = X_valid_dataset[\"answer\"].apply(unique_word_count)\n\ntest_dataset[\"question_title_num_unique_words\"] = test_dataset[\"question_title\"].apply(unique_word_count)\ntest_dataset[\"question_body_num_unique_words\"] = test_dataset[\"question_body\"].apply(unique_word_count)\ntest_dataset[\"answer_num_unique_words\"] = test_dataset[\"answer\"].apply(unique_word_count)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:55.630653Z","iopub.execute_input":"2022-02-18T06:54:55.631332Z","iopub.status.idle":"2022-02-18T06:54:56.022077Z","shell.execute_reply.started":"2022-02-18T06:54:55.631263Z","shell.execute_reply":"2022-02-18T06:54:56.021349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF based features:\n\n* Word Level N-Gram TF-IDF of **question_title**\n* Word Level N-Gram TF-IDF of **question_body**\n* Word Level N-Gram TF-IDF of **answer**","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nvectorizer = TfidfVectorizer(min_df=2)\ntsvd = TruncatedSVD(n_components = 128, n_iter=5)\n\n\nqt_tfidf = vectorizer.fit_transform(X_train_dataset['preprocessed_question_title'].values)\ntfidf_question_title_train = tsvd.fit_transform(qt_tfidf)\n\n\nqb_tfidf = vectorizer.fit_transform(X_train_dataset['preprocessed_question_body'].values)\ntfidf_question_body_train = tsvd.fit_transform(qb_tfidf)\n\n\nans_tfidf = vectorizer.fit_transform(X_train_dataset['preprocessed_answer'].values)\ntfidf_answer_train = tsvd.fit_transform(ans_tfidf)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:54:56.023454Z","iopub.execute_input":"2022-02-18T06:54:56.023833Z","iopub.status.idle":"2022-02-18T06:55:00.615188Z","shell.execute_reply.started":"2022-02-18T06:54:56.023799Z","shell.execute_reply":"2022-02-18T06:55:00.614266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qt_tfidf = vectorizer.fit_transform(X_valid_dataset['preprocessed_question_title'].values)\ntfidf_question_title_valid = tsvd.fit_transform(qt_tfidf)\n\n\nqb_tfidf = vectorizer.fit_transform(X_valid_dataset['preprocessed_question_body'].values)\ntfidf_question_body_valid = tsvd.fit_transform(qb_tfidf)\n\n\nans_tfidf = vectorizer.fit_transform(X_valid_dataset['preprocessed_answer'].values)\ntfidf_answer_valid = tsvd.fit_transform(ans_tfidf)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:00.620251Z","iopub.execute_input":"2022-02-18T06:55:00.622933Z","iopub.status.idle":"2022-02-18T06:55:01.247336Z","shell.execute_reply.started":"2022-02-18T06:55:00.621Z","shell.execute_reply":"2022-02-18T06:55:01.2465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qt_tfidf = vectorizer.fit_transform(test_dataset['preprocessed_question_title'].values)\ntfidf_question_title_test = tsvd.fit_transform(qt_tfidf)\n\n\nqb_tfidf = vectorizer.fit_transform(test_dataset['preprocessed_question_body'].values)\ntfidf_question_body_test = tsvd.fit_transform(qb_tfidf)\n\n\nans_tfidf = vectorizer.fit_transform(test_dataset['preprocessed_answer'].values)\ntfidf_answer_test = tsvd.fit_transform(ans_tfidf)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:01.248879Z","iopub.execute_input":"2022-02-18T06:55:01.249374Z","iopub.status.idle":"2022-02-18T06:55:01.706394Z","shell.execute_reply.started":"2022-02-18T06:55:01.249337Z","shell.execute_reply":"2022-02-18T06:55:01.70556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset[\"tfidf_question_title\"] = list(tfidf_question_title_train)\nX_train_dataset[\"tfidf_question_body\"] = list(tfidf_question_body_train)\nX_train_dataset[\"tfidf_answer\"] = list(tfidf_answer_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:01.707946Z","iopub.execute_input":"2022-02-18T06:55:01.708429Z","iopub.status.idle":"2022-02-18T06:55:01.725219Z","shell.execute_reply.started":"2022-02-18T06:55:01.708392Z","shell.execute_reply":"2022-02-18T06:55:01.724458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid_dataset[\"tfidf_question_title\"] = list(tfidf_question_title_valid)\nX_valid_dataset[\"tfidf_question_body\"] = list(tfidf_question_body_valid)\nX_valid_dataset[\"tfidf_answer\"] = list(tfidf_answer_valid)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:01.72655Z","iopub.execute_input":"2022-02-18T06:55:01.727029Z","iopub.status.idle":"2022-02-18T06:55:01.735319Z","shell.execute_reply.started":"2022-02-18T06:55:01.726992Z","shell.execute_reply":"2022-02-18T06:55:01.734218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset[\"tfidf_question_title\"] = list(tfidf_question_title_test)\ntest_dataset[\"tfidf_question_body\"] = list(tfidf_question_body_test)\ntest_dataset[\"tfidf_answer\"] = list(tfidf_answer_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:01.737206Z","iopub.execute_input":"2022-02-18T06:55:01.737794Z","iopub.status.idle":"2022-02-18T06:55:01.746468Z","shell.execute_reply.started":"2022-02-18T06:55:01.737754Z","shell.execute_reply":"2022-02-18T06:55:01.745625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features using web scraping \n\n\n## `answer_user_page` features:\n","metadata":{}},{"cell_type":"code","source":"!pip install bs4","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:01.74846Z","iopub.execute_input":"2022-02-18T06:55:01.749104Z","iopub.status.idle":"2022-02-18T06:55:12.128094Z","shell.execute_reply.started":"2022-02-18T06:55:01.749063Z","shell.execute_reply":"2022-02-18T06:55:12.127279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tqdm.notebook import tqdm\nfrom bs4 import BeautifulSoup\nfrom urllib import request\n\n\ndef get_user_rating(url):\n    try:\n        get = request.urlopen(url).read()\n        src = BeautifulSoup(get, 'html.parser')\n        #print(src)\n        reputation, gold = [], []\n        silver, bronze = [], []\n        reputation = int(''.join(src.find_all(\"div\", class_ = 'fs-body3 fc-dark')[0].text.strip().split(',')))\n        try:\n            gold = int(''.join(src.find_all('div', class_='fs-title fw-bold fc-black-800')[0].text.strip().split(',')))\n        except:\n            gold = 0\n\n        try:    \n            silver = int(''.join(src.find_all('div', class_='fs-title fw-bold fc-black-800')[1].text.strip().split(',')))\n        except:\n            silver = 0\n\n        try:\n            bronze = int(''.join(src.find_all('div', class_='fs-title fw-bold fc-black-800')[2].text.strip().split(',')))\n        except:\n            bronze = 0\n\n        output = [reputation, gold, silver, bronze]\n    except:\n        output = [0]*4\n\n    return output\n'''\ndata = []\nfor url in tqdm(X_train_dataset['answer_user_page']):\n    #print(url)\n    data.append(get_user_rating(url))\n    columns = ['reputation', 'gold', 'silver', 'bronze']  \nscraped = pd.DataFrame(data, columns=columns)\nscraped.to_csv(f'train_web_scrap_features.csv', index=False)\n\ndata = []\nfor url in tqdm(X_valid_dataset['answer_user_page']):\n    #print(url)\n    data.append(get_user_rating(url))\n    columns = ['reputation', 'gold', 'silver', 'bronze']  \nscraped = pd.DataFrame(data, columns=columns)\nscraped.to_csv(f'valid_web_scrap_features.csv', index=False)\n'''\n\ntrain_web_scraping_feature = pd.read_csv('../input/feature-engineering/train_web_scrap_features.csv')\nvalid_web_scraping_feature = pd.read_csv('../input/feature-engineering/valid_web_scrap_features.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:12.129609Z","iopub.execute_input":"2022-02-18T06:55:12.129889Z","iopub.status.idle":"2022-02-18T06:55:12.349835Z","shell.execute_reply.started":"2022-02-18T06:55:12.129852Z","shell.execute_reply":"2022-02-18T06:55:12.349152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_web_scraping_feature","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:12.352688Z","iopub.execute_input":"2022-02-18T06:55:12.352915Z","iopub.status.idle":"2022-02-18T06:55:12.366373Z","shell.execute_reply.started":"2022-02-18T06:55:12.35289Z","shell.execute_reply":"2022-02-18T06:55:12.365641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_web_scraping_feature","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:12.36784Z","iopub.execute_input":"2022-02-18T06:55:12.36834Z","iopub.status.idle":"2022-02-18T06:55:12.380063Z","shell.execute_reply.started":"2022-02-18T06:55:12.368303Z","shell.execute_reply":"2022-02-18T06:55:12.379389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### References for feature engineering:\n* https://www.kaggle.com/c/google-quest-challenge/discussion/130041 - meta features.\n* https://www.kaggle.com/codename007/start-from-here-quest-complete-eda-fe?scriptVersionId=25618132&cellId=65 - tfidf, count based features.\n* https://towardsdatascience.com/hands-on-transformers-kaggle-google-quest-q-a-labeling-affd3dad7bcb - web scraping features","metadata":{}},{"cell_type":"markdown","source":"# Converting **`question_title`**  Text -> Vector","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nquestion_title_tk = tf.keras.preprocessing.text.Tokenizer(filters = \" \")\nquestion_title_tk.fit_on_texts(X_train_dataset['question_title'].values)\n\nvocab_size_question_title = len(question_title_tk.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:12.381148Z","iopub.execute_input":"2022-02-18T06:55:12.381498Z","iopub.status.idle":"2022-02-18T06:55:17.501826Z","shell.execute_reply.started":"2022-02-18T06:55:12.381461Z","shell.execute_reply":"2022-02-18T06:55:17.500989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting **`question_title`** text feature to tokens ","metadata":{}},{"cell_type":"code","source":"tokenized_question_title_train = question_title_tk.texts_to_sequences(X_train_dataset['question_title'].values)\ntokenized_question_title_valid = question_title_tk.texts_to_sequences(X_valid_dataset['question_title'].values)\ntokenized_question_title_test = question_title_tk.texts_to_sequences(test_dataset['question_title'].values)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:17.50303Z","iopub.execute_input":"2022-02-18T06:55:17.504302Z","iopub.status.idle":"2022-02-18T06:55:17.568955Z","shell.execute_reply.started":"2022-02-18T06:55:17.504261Z","shell.execute_reply":"2022-02-18T06:55:17.568267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"max length in the question title feature\",max([(len(title)) for title in tokenized_question_title_train]))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:17.57019Z","iopub.execute_input":"2022-02-18T06:55:17.570464Z","iopub.status.idle":"2022-02-18T06:55:17.576496Z","shell.execute_reply.started":"2022-02-18T06:55:17.570426Z","shell.execute_reply":"2022-02-18T06:55:17.575563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Padding **`question_title`** tokens to have all question_title in same lenght (i.e: 30)","metadata":{}},{"cell_type":"code","source":"tokenized_question_title_train = tf.keras.preprocessing.sequence.pad_sequences(tokenized_question_title_train, maxlen=30, dtype='int32', padding='post')\ntokenized_question_title_valid = tf.keras.preprocessing.sequence.pad_sequences(tokenized_question_title_valid, maxlen=30, dtype='int32', padding='post')\ntokenized_question_title_test = tf.keras.preprocessing.sequence.pad_sequences(tokenized_question_title_test, maxlen=30, dtype='int32', padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:17.577643Z","iopub.execute_input":"2022-02-18T06:55:17.578888Z","iopub.status.idle":"2022-02-18T06:55:17.637518Z","shell.execute_reply.started":"2022-02-18T06:55:17.578823Z","shell.execute_reply":"2022-02-18T06:55:17.636846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_question_title_train.shape, tokenized_question_title_valid.shape, tokenized_question_title_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:17.640525Z","iopub.execute_input":"2022-02-18T06:55:17.640742Z","iopub.status.idle":"2022-02-18T06:55:17.64806Z","shell.execute_reply.started":"2022-02-18T06:55:17.640696Z","shell.execute_reply":"2022-02-18T06:55:17.647086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting **`question_body`** Feature Text -> Vector","metadata":{}},{"cell_type":"code","source":"question_body_tk = tf.keras.preprocessing.text.Tokenizer(filters = \" \")\nquestion_body_tk.fit_on_texts(X_train_dataset['question_body'].values)\n\nvocab_size_question_body = len(question_body_tk.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:17.649419Z","iopub.execute_input":"2022-02-18T06:55:17.6498Z","iopub.status.idle":"2022-02-18T06:55:18.274928Z","shell.execute_reply.started":"2022-02-18T06:55:17.649763Z","shell.execute_reply":"2022-02-18T06:55:18.274157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Converting **`question_body`** text feature to tokens ","metadata":{}},{"cell_type":"code","source":"tokenized_question_body_train = question_body_tk.texts_to_sequences(X_train_dataset['question_body'].values)\ntokenized_question_body_valid = question_body_tk.texts_to_sequences(X_valid_dataset['question_body'].values)\ntokenized_question_body_test = question_body_tk.texts_to_sequences(test_dataset['question_body'].values)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:18.276232Z","iopub.execute_input":"2022-02-18T06:55:18.276476Z","iopub.status.idle":"2022-02-18T06:55:18.72751Z","shell.execute_reply.started":"2022-02-18T06:55:18.276442Z","shell.execute_reply":"2022-02-18T06:55:18.72665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question_body_max_len = max([(len(body)) for body in tokenized_question_body_train])\nprint(\"max length in the question body feature\",question_body_max_len)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:18.728948Z","iopub.execute_input":"2022-02-18T06:55:18.729285Z","iopub.status.idle":"2022-02-18T06:55:18.73653Z","shell.execute_reply.started":"2022-02-18T06:55:18.729248Z","shell.execute_reply":"2022-02-18T06:55:18.735569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Padding **`question_body`** tokens to have all question_body in same lenght (i.e: 1397)","metadata":{}},{"cell_type":"code","source":"tokenized_question_body_train = tf.keras.preprocessing.sequence.pad_sequences(tokenized_question_body_train, maxlen=question_body_max_len, dtype='int32', padding='post')\ntokenized_question_body_valid = tf.keras.preprocessing.sequence.pad_sequences(tokenized_question_body_valid, maxlen=question_body_max_len, dtype='int32', padding='post')\ntokenized_question_body_test = tf.keras.preprocessing.sequence.pad_sequences(tokenized_question_body_test, maxlen=question_body_max_len, dtype='int32', padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:18.738267Z","iopub.execute_input":"2022-02-18T06:55:18.7387Z","iopub.status.idle":"2022-02-18T06:55:18.959646Z","shell.execute_reply.started":"2022-02-18T06:55:18.738664Z","shell.execute_reply":"2022-02-18T06:55:18.958759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_question_body_train.shape, tokenized_question_body_valid.shape, tokenized_question_body_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:18.961333Z","iopub.execute_input":"2022-02-18T06:55:18.961607Z","iopub.status.idle":"2022-02-18T06:55:18.969696Z","shell.execute_reply.started":"2022-02-18T06:55:18.961574Z","shell.execute_reply":"2022-02-18T06:55:18.968567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Converting **`answer`** Feature Text -> Vector","metadata":{}},{"cell_type":"code","source":"answer_tk = tf.keras.preprocessing.text.Tokenizer(filters = \" \")\nanswer_tk.fit_on_texts(X_train_dataset['answer'].values)\n\nvocab_size_answer = len(answer_tk.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:18.971257Z","iopub.execute_input":"2022-02-18T06:55:18.971655Z","iopub.status.idle":"2022-02-18T06:55:19.669974Z","shell.execute_reply.started":"2022-02-18T06:55:18.971619Z","shell.execute_reply":"2022-02-18T06:55:19.669201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting **`answer`** text feature to tokens ","metadata":{}},{"cell_type":"code","source":"tokenized_answer_train = answer_tk.texts_to_sequences(X_train_dataset['answer'].values)\ntokenized_answer_valid = answer_tk.texts_to_sequences(X_valid_dataset['answer'].values)\ntokenized_answer_test = answer_tk.texts_to_sequences(test_dataset['answer'].values)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:19.671543Z","iopub.execute_input":"2022-02-18T06:55:19.671812Z","iopub.status.idle":"2022-02-18T06:55:20.132211Z","shell.execute_reply.started":"2022-02-18T06:55:19.671777Z","shell.execute_reply":"2022-02-18T06:55:20.131503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer_max_len = max([(len(answer)) for answer in tokenized_answer_train])\nprint(\"max length in the answer feature\",answer_max_len)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:20.133648Z","iopub.execute_input":"2022-02-18T06:55:20.133918Z","iopub.status.idle":"2022-02-18T06:55:20.141347Z","shell.execute_reply.started":"2022-02-18T06:55:20.133876Z","shell.execute_reply":"2022-02-18T06:55:20.140635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Padding **`answer`** tokens to have all answer in same lenght (i.e: 2332)","metadata":{}},{"cell_type":"code","source":"tokenized_answer_train = tf.keras.preprocessing.sequence.pad_sequences(tokenized_answer_train, maxlen=answer_max_len, dtype='int32', padding='post')\ntokenized_answer_valid = tf.keras.preprocessing.sequence.pad_sequences(tokenized_answer_valid, maxlen=answer_max_len, dtype='int32', padding='post')\ntokenized_answer_test = tf.keras.preprocessing.sequence.pad_sequences(tokenized_answer_test, maxlen=answer_max_len, dtype='int32', padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:20.142539Z","iopub.execute_input":"2022-02-18T06:55:20.143017Z","iopub.status.idle":"2022-02-18T06:55:20.351545Z","shell.execute_reply.started":"2022-02-18T06:55:20.14298Z","shell.execute_reply":"2022-02-18T06:55:20.350842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_question_title_train.shape, tokenized_question_body_train.shape, tokenized_answer_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:20.352928Z","iopub.execute_input":"2022-02-18T06:55:20.353165Z","iopub.status.idle":"2022-02-18T06:55:20.359695Z","shell.execute_reply.started":"2022-02-18T06:55:20.353134Z","shell.execute_reply":"2022-02-18T06:55:20.35898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_question_title_valid.shape, tokenized_question_body_valid.shape, tokenized_answer_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:20.361313Z","iopub.execute_input":"2022-02-18T06:55:20.362009Z","iopub.status.idle":"2022-02-18T06:55:20.369284Z","shell.execute_reply.started":"2022-02-18T06:55:20.361973Z","shell.execute_reply":"2022-02-18T06:55:20.368492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_question_title_test.shape, tokenized_question_body_test.shape, tokenized_answer_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:20.370722Z","iopub.execute_input":"2022-02-18T06:55:20.370978Z","iopub.status.idle":"2022-02-18T06:55:20.380639Z","shell.execute_reply.started":"2022-02-18T06:55:20.370946Z","shell.execute_reply":"2022-02-18T06:55:20.379819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:20.382195Z","iopub.execute_input":"2022-02-18T06:55:20.382517Z","iopub.status.idle":"2022-02-18T06:55:20.390156Z","shell.execute_reply.started":"2022-02-18T06:55:20.382483Z","shell.execute_reply":"2022-02-18T06:55:20.389295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid_dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:20.391504Z","iopub.execute_input":"2022-02-18T06:55:20.391827Z","iopub.status.idle":"2022-02-18T06:55:20.39975Z","shell.execute_reply.started":"2022-02-18T06:55:20.391792Z","shell.execute_reply":"2022-02-18T06:55:20.39899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Embedding weights for **question_title**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm\n\nglove_file = open('../input/glove-embeddings/glove.6B.300d.txt', encoding='utf8')\n\nembeddings_index = dict()   \nfor line in tqdm(glove_file):\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nglove_file.close()\nprint('Loaded %s word vectors.' % len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:55:20.401327Z","iopub.execute_input":"2022-02-18T06:55:20.401834Z","iopub.status.idle":"2022-02-18T06:56:06.648445Z","shell.execute_reply.started":"2022-02-18T06:55:20.401798Z","shell.execute_reply":"2022-02-18T06:56:06.647671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a weight matrix for words in training docs\n\nembedding_matrix_question_title = np.zeros((vocab_size_question_title, 300))\nfor word, i in question_title_tk.word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix_question_title[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:06.649837Z","iopub.execute_input":"2022-02-18T06:56:06.650115Z","iopub.status.idle":"2022-02-18T06:56:06.679004Z","shell.execute_reply.started":"2022-02-18T06:56:06.650078Z","shell.execute_reply":"2022-02-18T06:56:06.678336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_question_title.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:06.680308Z","iopub.execute_input":"2022-02-18T06:56:06.680565Z","iopub.status.idle":"2022-02-18T06:56:06.68605Z","shell.execute_reply.started":"2022-02-18T06:56:06.680532Z","shell.execute_reply":"2022-02-18T06:56:06.685221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Embedding weights for **question_body**","metadata":{}},{"cell_type":"code","source":"# create a weight matrix for words in training docs\n\nembedding_matrix_question_body = np.zeros((vocab_size_question_body, 300))\nfor word, i in question_body_tk.word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix_question_body[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:06.687495Z","iopub.execute_input":"2022-02-18T06:56:06.687778Z","iopub.status.idle":"2022-02-18T06:56:06.780636Z","shell.execute_reply.started":"2022-02-18T06:56:06.687745Z","shell.execute_reply":"2022-02-18T06:56:06.779926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_question_body.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:06.782018Z","iopub.execute_input":"2022-02-18T06:56:06.782275Z","iopub.status.idle":"2022-02-18T06:56:06.789396Z","shell.execute_reply.started":"2022-02-18T06:56:06.782241Z","shell.execute_reply":"2022-02-18T06:56:06.787208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Embedding weights for **answer**","metadata":{}},{"cell_type":"code","source":"# create a weight matrix for words in training docs\n\nembedding_matrix_answer = np.zeros((vocab_size_answer, 300))\nfor word, i in question_body_tk.word_index.items():\n    \n    \n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix_answer[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:06.790532Z","iopub.execute_input":"2022-02-18T06:56:06.790746Z","iopub.status.idle":"2022-02-18T06:56:06.881853Z","shell.execute_reply.started":"2022-02-18T06:56:06.790695Z","shell.execute_reply":"2022-02-18T06:56:06.881109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_answer.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:06.883236Z","iopub.execute_input":"2022-02-18T06:56:06.883489Z","iopub.status.idle":"2022-02-18T06:56:06.889507Z","shell.execute_reply.started":"2022-02-18T06:56:06.883454Z","shell.execute_reply":"2022-02-18T06:56:06.888629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLot the history of the model\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:06.899257Z","iopub.execute_input":"2022-02-18T06:56:06.899447Z","iopub.status.idle":"2022-02-18T06:56:06.902496Z","shell.execute_reply.started":"2022-02-18T06:56:06.899424Z","shell.execute_reply":"2022-02-18T06:56:06.90168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Base LSTM Model ","metadata":{}},{"cell_type":"code","source":"############################ INPUT 1 - Question title ############################################################\ninput_1 = tf.keras.layers.Input(shape=(30,))\nembed_1 = tf.keras.layers.Embedding(vocab_size_question_title, \n                                    300, \n                                    weights=[embedding_matrix_question_title],\n                                    input_length=30,\n                                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23), \n                                    trainable=False)(input_1)\nlstm1 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26),\n          return_sequences=True))(embed_1)\nprint(\"lstm_1 :\",lstm1.shape)\nflat_1 = tf.keras.layers.Flatten()(lstm1)\n\n\n############################ INPUT 2 - Question body ##############################################################\ninput_2 = tf.keras.layers.Input(shape=(question_body_max_len,))\nembed_2 = tf.keras.layers.Embedding(vocab_size_question_body,\n                    300, \n                    weights=[embedding_matrix_question_body], \n                    input_length=question_body_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=24), \n                    trainable=False)(input_2)\nlstm2 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=27),\n          return_sequences=True))(embed_2)\nprint(\"lstm_2 :\",lstm2.shape)\nflat_2 = tf.keras.layers.Flatten()(lstm2)\n\n\n############################ INPUT 3 - Answer ################################################################\ninput_3 = tf.keras.layers.Input(shape=(answer_max_len,))\nembed_3 = tf.keras.layers.Embedding(vocab_size_answer, 300, weights=[embedding_matrix_answer], \n                    input_length=answer_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=25), \n                    trainable=False)(input_3)\nlstm3 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=28),\n          return_sequences=True))(embed_3)\nprint(\"lstm_3 :\",lstm3.shape)\nflat_3 = tf.keras.layers.Flatten()(lstm3)\n\n\n\n\nprint(\"Flat_1 shape :\",flat_1.shape)\nprint(\"Flat_2 shape :\",flat_2.shape)\nprint(\"Flat_3 shape :\",flat_3.shape)\n\nconcat = tf.keras.layers.Concatenate()([flat_1,flat_2,flat_3])\nprint(concat.shape)\ndense = tf.keras.layers.Dense(32,activation = 'relu',kernel_initializer=tf.keras.initializers.he_normal(seed=40))(concat)\n\noutput = tf.keras.layers.Dense(30,activation = 'sigmoid',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45))(dense)\n\nmodel = tf.keras.Model(inputs = [input_1, input_2, input_3], outputs = output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:06.903857Z","iopub.execute_input":"2022-02-18T06:56:06.904318Z","iopub.status.idle":"2022-02-18T06:56:11.021104Z","shell.execute_reply.started":"2022-02-18T06:56:06.904279Z","shell.execute_reply":"2022-02-18T06:56:11.020388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:11.022275Z","iopub.execute_input":"2022-02-18T06:56:11.022525Z","iopub.status.idle":"2022-02-18T06:56:11.790457Z","shell.execute_reply.started":"2022-02-18T06:56:11.02249Z","shell.execute_reply":"2022-02-18T06:56:11.789573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import spearmanr\n\nlist_1 = [1,2,3,4,5]\nlist_2 = [2,3,4,5,6]\nspearmanr(list_1, list_2)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:11.792267Z","iopub.execute_input":"2022-02-18T06:56:11.792541Z","iopub.status.idle":"2022-02-18T06:56:11.802998Z","shell.execute_reply.started":"2022-02-18T06:56:11.7925Z","shell.execute_reply":"2022-02-18T06:56:11.802164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import spearmanr\n\nclass SpearmanCallback(tf.keras.callbacks.Callback):\n    def __init__(self, validation_data):\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred_val = self.model.predict(self.x_val)\n        rho_val = np.mean([spearmanr(self.y_val[:, ind], y_pred_val[:, ind] + np.random.normal(0, 1e-7, y_pred_val.shape[0])).correlation for ind in range(y_pred_val.shape[1])])\n        print(rho_val)\n        print('\\nval_spearman-corr: %s' % (str(round(rho_val, 6))), end=100*' '+'\\n')\n        return rho_val","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:11.80457Z","iopub.execute_input":"2022-02-18T06:56:11.805036Z","iopub.status.idle":"2022-02-18T06:56:11.815068Z","shell.execute_reply.started":"2022-02-18T06:56:11.804996Z","shell.execute_reply":"2022-02-18T06:56:11.814357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                   optimizer=tf.keras.optimizers.Adam()\n            )","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:11.816607Z","iopub.execute_input":"2022-02-18T06:56:11.816881Z","iopub.status.idle":"2022-02-18T06:56:11.837519Z","shell.execute_reply.started":"2022-02-18T06:56:11.816848Z","shell.execute_reply":"2022-02-18T06:56:11.836757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid_dataset = np.array(y_valid_dataset)\ny_train_dataset = np.array(y_train_dataset)\ncustom_callback = SpearmanCallback(validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid ], y_valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:11.838904Z","iopub.execute_input":"2022-02-18T06:56:11.839168Z","iopub.status.idle":"2022-02-18T06:56:11.84666Z","shell.execute_reply.started":"2022-02-18T06:56:11.839132Z","shell.execute_reply":"2022-02-18T06:56:11.845738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([tokenized_question_title_train, tokenized_question_body_train, tokenized_answer_train], y_train_dataset, \n           epochs=30,  \n           validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid ], y_valid_dataset), \n           callbacks=[custom_callback])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T06:56:11.847951Z","iopub.execute_input":"2022-02-18T06:56:11.848459Z","iopub.status.idle":"2022-02-18T07:18:39.720575Z","shell.execute_reply.started":"2022-02-18T06:56:11.848413Z","shell.execute_reply":"2022-02-18T07:18:39.719761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot()\nplt.title(\"Base model with 3 features\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:39.722363Z","iopub.execute_input":"2022-02-18T07:18:39.722647Z","iopub.status.idle":"2022-02-18T07:18:39.962314Z","shell.execute_reply.started":"2022-02-18T07:18:39.72261Z","shell.execute_reply":"2022-02-18T07:18:39.961694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Observation:** \nAfter 11 epochs we have acheived an spearman score of **0.27447** with three question_title, question_body, answer features ","metadata":{}},{"cell_type":"markdown","source":"# Base LSTM model applying 18 Feature Engineering features\n\n* **3 text features** - question_title, question_body, answer\n* **9 Feature engineering features (9 dim)** -  question_title_num_chars, question_body_num_chars, answer_num_chars,  question_title_num_words, question_body_num_words, answer_num_words, question_title_num_unique_words, question_body_num_unique_words, answer_num_unique_words\n* **3 TF-IDF features (384 dim)** - TF-IDF quesion_title, TF_IDF quesiton_body, TF-IDF answer.\n* **4 Web scraping features (4 dim)** - reputation, \tgold, \tsilver, \tbronze.","metadata":{}},{"cell_type":"code","source":"feature_engineer_columns = ['question_title_num_chars', 'question_body_num_chars',\n       'answer_num_chars', 'question_title_num_words',\n       'question_body_num_words', 'answer_num_words',\n       'question_title_num_unique_words', 'question_body_num_unique_words',\n       'answer_num_unique_words']\n\n\ntfidf_features = ['tfidf_question_title','tfidf_question_body', 'tfidf_answer']\n\n\ntrain_web_scraping_feature.shape, valid_web_scraping_feature.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:39.963668Z","iopub.execute_input":"2022-02-18T07:18:39.963902Z","iopub.status.idle":"2022-02-18T07:18:39.969531Z","shell.execute_reply.started":"2022-02-18T07:18:39.963871Z","shell.execute_reply":"2022-02-18T07:18:39.968807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_feature_eng = np.array(X_train_dataset[feature_engineer_columns])\nX_valid_feature_eng = np.array(X_valid_dataset[feature_engineer_columns])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:39.970907Z","iopub.execute_input":"2022-02-18T07:18:39.971352Z","iopub.status.idle":"2022-02-18T07:18:39.994156Z","shell.execute_reply.started":"2022-02-18T07:18:39.971314Z","shell.execute_reply":"2022-02-18T07:18:39.99337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_feature_eng.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:39.995467Z","iopub.execute_input":"2022-02-18T07:18:39.995742Z","iopub.status.idle":"2022-02-18T07:18:40.000849Z","shell.execute_reply.started":"2022-02-18T07:18:39.995692Z","shell.execute_reply":"2022-02-18T07:18:40.000151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid_feature_eng.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:40.002075Z","iopub.execute_input":"2022-02-18T07:18:40.002726Z","iopub.status.idle":"2022-02-18T07:18:40.012337Z","shell.execute_reply.started":"2022-02-18T07:18:40.002671Z","shell.execute_reply":"2022-02-18T07:18:40.011606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  TF-IDF Features","metadata":{}},{"cell_type":"code","source":"tfidf_question_title_train.shape, tfidf_question_body_train.shape, tfidf_answer_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:40.01344Z","iopub.execute_input":"2022-02-18T07:18:40.014309Z","iopub.status.idle":"2022-02-18T07:18:40.02107Z","shell.execute_reply.started":"2022-02-18T07:18:40.014268Z","shell.execute_reply":"2022-02-18T07:18:40.020154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_question_title_valid.shape, tfidf_question_body_valid.shape, tfidf_answer_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:40.022517Z","iopub.execute_input":"2022-02-18T07:18:40.023131Z","iopub.status.idle":"2022-02-18T07:18:40.030399Z","shell.execute_reply.started":"2022-02-18T07:18:40.023093Z","shell.execute_reply":"2022-02-18T07:18:40.029659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_train_features = np.hstack((tfidf_question_title_train, tfidf_question_body_train, tfidf_answer_train))\ntfidf_valid_features = np.hstack((tfidf_question_title_valid, tfidf_question_body_valid, tfidf_answer_valid))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:40.031555Z","iopub.execute_input":"2022-02-18T07:18:40.03215Z","iopub.status.idle":"2022-02-18T07:18:40.046255Z","shell.execute_reply.started":"2022-02-18T07:18:40.032115Z","shell.execute_reply":"2022-02-18T07:18:40.04553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_train_features.shape, tfidf_valid_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:40.049333Z","iopub.execute_input":"2022-02-18T07:18:40.050873Z","iopub.status.idle":"2022-02-18T07:18:40.057897Z","shell.execute_reply.started":"2022-02-18T07:18:40.050844Z","shell.execute_reply":"2022-02-18T07:18:40.057228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############################ INPUT 1 - Question title ############################################################\ninput_1 = tf.keras.layers.Input(shape=(30,))\nembed_1 = tf.keras.layers.Embedding(vocab_size_question_title, \n                                    300, \n                                    weights=[embedding_matrix_question_title],\n                                    input_length=30,\n                                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23), \n                                    trainable=False)(input_1)\nlstm1 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26),\n          return_sequences=True))(embed_1)\nprint(\"lstm_1 :\",lstm1.shape)\nflat_1 = tf.keras.layers.Flatten()(lstm1)\n\n\n############################ INPUT 2 - Question body ##############################################################\ninput_2 = tf.keras.layers.Input(shape=(question_body_max_len,))\nembed_2 = tf.keras.layers.Embedding(vocab_size_question_body,\n                    300, \n                    weights=[embedding_matrix_question_body], \n                    input_length=question_body_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=24), \n                    trainable=False)(input_2)\nlstm2 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=27),\n          return_sequences=True))(embed_2)\nprint(\"lstm_2 :\",lstm2.shape)\nflat_2 = tf.keras.layers.Flatten()(lstm2)\n\n\n############################ INPUT 3 - Answer ################################################################\ninput_3 = tf.keras.layers.Input(shape=(answer_max_len,))\nembed_3 = tf.keras.layers.Embedding(vocab_size_answer, 300, weights=[embedding_matrix_answer], \n                    input_length=answer_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=25), \n                    trainable=False)(input_3)\nlstm3 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=28),\n          return_sequences=True))(embed_3)\nprint(\"lstm_3 :\",lstm3.shape)\nflat_3 = tf.keras.layers.Flatten()(lstm3)\n\n#########################  INPUT 4 - Feature Engineering features ############################################\ninput_4 = tf.keras.layers.Input(shape=(9,))\nx = tf.keras.layers.Dense(64, activation='relu')(input_4)\nflat_4 = tf.keras.layers.Dense(32, activation='relu')(x)\n\n\n####################### INPUT 5 - TF-IDF Features ###########################################################\ninput_5 = tf.keras.layers.Input(shape=(384,))\nx = tf.keras.layers.Dense(128, activation='relu')(input_5)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nflat_5 = tf.keras.layers.Dense(32, activation='relu')(x)\n\n\n##################### Input 6 - Web scraping feature ##########################################################\ninput_6 = tf.keras.layers.Input(shape=(4,))\nx = tf.keras.layers.Dense(128, activation='relu')(input_6)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nflat_6 = tf.keras.layers.Dense(32, activation='relu')(x)\n\n\n\n\n\n\nprint(\"Flat_1 shape :\",flat_1.shape)\nprint(\"Flat_2 shape :\",flat_2.shape)\nprint(\"Flat_3 shape :\",flat_3.shape)\nprint(\"Flat_4 shape :\",flat_4.shape)\nprint(\"Flat_5 shape :\",flat_5.shape)\n\n\nconcat = tf.keras.layers.Concatenate()([flat_1,flat_2,flat_3, flat_4, flat_5, flat_6])\nprint(concat.shape)\ndense = tf.keras.layers.Dense(32,activation = 'relu',kernel_initializer=tf.keras.initializers.he_normal(seed=40))(concat)\n\noutput = tf.keras.layers.Dense(30,activation = 'sigmoid',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45))(dense)\n\nmodel = tf.keras.Model(inputs = [input_1, input_2, input_3, input_4, input_5, input_6], outputs = output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:40.061082Z","iopub.execute_input":"2022-02-18T07:18:40.06158Z","iopub.status.idle":"2022-02-18T07:18:41.605318Z","shell.execute_reply.started":"2022-02-18T07:18:40.061553Z","shell.execute_reply":"2022-02-18T07:18:41.604613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:41.606414Z","iopub.execute_input":"2022-02-18T07:18:41.606651Z","iopub.status.idle":"2022-02-18T07:18:41.850468Z","shell.execute_reply.started":"2022-02-18T07:18:41.606618Z","shell.execute_reply":"2022-02-18T07:18:41.84964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import spearmanr\n\nclass SpearmanCallback(tf.keras.callbacks.Callback):\n    def __init__(self, validation_data):\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred_val = self.model.predict(self.x_val)\n        rho_val = np.mean([spearmanr(self.y_val[:, ind], y_pred_val[:, ind] + np.random.normal(0, 1e-7, y_pred_val.shape[0])).correlation for ind in range(y_pred_val.shape[1])])\n        print('\\nval_spearman-corr: %s' % (str(round(rho_val, 6))), end=100*' '+'\\n')\n        return rho_val","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:41.852277Z","iopub.execute_input":"2022-02-18T07:18:41.852749Z","iopub.status.idle":"2022-02-18T07:18:41.862242Z","shell.execute_reply.started":"2022-02-18T07:18:41.85269Z","shell.execute_reply":"2022-02-18T07:18:41.861335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                   optimizer=tf.keras.optimizers.Adam()\n            )","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:41.863653Z","iopub.execute_input":"2022-02-18T07:18:41.863941Z","iopub.status.idle":"2022-02-18T07:18:41.882965Z","shell.execute_reply.started":"2022-02-18T07:18:41.863906Z","shell.execute_reply":"2022-02-18T07:18:41.88224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid_dataset = np.array(y_valid_dataset)\ncustom_callback = SpearmanCallback(validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid, X_valid_feature_eng, tfidf_valid_features, valid_web_scraping_feature ], y_valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:41.884123Z","iopub.execute_input":"2022-02-18T07:18:41.884482Z","iopub.status.idle":"2022-02-18T07:18:41.89073Z","shell.execute_reply.started":"2022-02-18T07:18:41.884448Z","shell.execute_reply":"2022-02-18T07:18:41.889983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([tokenized_question_title_train, tokenized_question_body_train, tokenized_answer_train, X_train_feature_eng, tfidf_train_features, train_web_scraping_feature], y_train_dataset, \n           epochs=30,  \n           validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid, X_valid_feature_eng, tfidf_valid_features, valid_web_scraping_feature], y_valid_dataset), \n           callbacks=[custom_callback])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:18:41.891958Z","iopub.execute_input":"2022-02-18T07:18:41.892434Z","iopub.status.idle":"2022-02-18T07:41:09.18856Z","shell.execute_reply.started":"2022-02-18T07:18:41.892397Z","shell.execute_reply":"2022-02-18T07:41:09.187053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Observation:** \nIn the above model we have trained with all 18 feature engineering features but by using all the features we have observed that performance has decreased a lot comparing to basic three features","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(history.history).plot()\nplt.title(\"Base Model with 18 FE features\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:41:09.190117Z","iopub.execute_input":"2022-02-18T07:41:09.190456Z","iopub.status.idle":"2022-02-18T07:41:09.427449Z","shell.execute_reply.started":"2022-02-18T07:41:09.190411Z","shell.execute_reply":"2022-02-18T07:41:09.426774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Base LSTM model applying 13 Feature Engineering features\n\n> Removing TF-IDF features as in the above model the performance has decreased comparing to the base model with only three features as tf-idf has more dimension \n\n\n* **3 text features** - question_title, question_body, answer\n* **9 Feature engineering features (9 dim)** -  question_title_num_chars, question_body_num_chars, answer_num_chars,  question_title_num_words, question_body_num_words, answer_num_words, question_title_num_unique_words, question_body_num_unique_words, answer_num_unique_words\n* **4 Web scraping features (4 dim)** - reputation, \tgold, \tsilver, \tbronze.","metadata":{}},{"cell_type":"code","source":"############################ INPUT 1 - Question title ############################################################\ninput_1 = tf.keras.layers.Input(shape=(30,))\nembed_1 = tf.keras.layers.Embedding(vocab_size_question_title, \n                                    300, \n                                    weights=[embedding_matrix_question_title],\n                                    input_length=30,\n                                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23), \n                                    trainable=False)(input_1)\nlstm1 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26),\n          return_sequences=True))(embed_1)\nprint(\"lstm_1 :\",lstm1.shape)\nflat_1 = tf.keras.layers.Flatten()(lstm1)\n\n\n############################ INPUT 2 - Question body ##############################################################\ninput_2 = tf.keras.layers.Input(shape=(question_body_max_len,))\nembed_2 = tf.keras.layers.Embedding(vocab_size_question_body,\n                    300, \n                    weights=[embedding_matrix_question_body], \n                    input_length=question_body_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=24), \n                    trainable=False)(input_2)\nlstm2 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=27),\n          return_sequences=True))(embed_2)\nprint(\"lstm_2 :\",lstm2.shape)\nflat_2 = tf.keras.layers.Flatten()(lstm2)\n\n\n############################ INPUT 3 - Answer ################################################################\ninput_3 = tf.keras.layers.Input(shape=(answer_max_len,))\nembed_3 = tf.keras.layers.Embedding(vocab_size_answer, 300, weights=[embedding_matrix_answer], \n                    input_length=answer_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=25), \n                    trainable=False)(input_3)\nlstm3 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=28),\n          return_sequences=True))(embed_3)\nprint(\"lstm_3 :\",lstm3.shape)\nflat_3 = tf.keras.layers.Flatten()(lstm3)\n\n#########################  INPUT 4 - Feature Engineering features ############################################\ninput_4 = tf.keras.layers.Input(shape=(9,))\nx = tf.keras.layers.Dense(64, activation='relu')(input_4)\nflat_4 = tf.keras.layers.Dense(32, activation='relu')(x)\n\n\n##################### Input 6 - Web scraping feature ##########################################################\ninput_5 = tf.keras.layers.Input(shape=(4,))\nx = tf.keras.layers.Dense(128, activation='relu')(input_5)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nflat_5 = tf.keras.layers.Dense(32, activation='relu')(x)\n\nprint(\"Flat_1 shape :\",flat_1.shape)\nprint(\"Flat_2 shape :\",flat_2.shape)\nprint(\"Flat_3 shape :\",flat_3.shape)\nprint(\"Flat_4 shape :\",flat_4.shape)\nprint(\"Flat_5 shape :\",flat_5.shape)\n\n\nconcat = tf.keras.layers.Concatenate()([flat_1,flat_2,flat_3, flat_4, flat_5])\nprint(concat.shape)\ndense = tf.keras.layers.Dense(32,activation = 'relu',kernel_initializer=tf.keras.initializers.he_normal(seed=40))(concat)\n\noutput = tf.keras.layers.Dense(10,activation = 'sigmoid',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45))(dense)\n\nmodel = tf.keras.Model(inputs = [input_1, input_2, input_3, input_4, input_5], outputs = output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:41:09.428827Z","iopub.execute_input":"2022-02-18T07:41:09.429234Z","iopub.status.idle":"2022-02-18T07:41:10.9404Z","shell.execute_reply.started":"2022-02-18T07:41:09.429197Z","shell.execute_reply":"2022-02-18T07:41:10.939627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:41:10.941846Z","iopub.execute_input":"2022-02-18T07:41:10.94209Z","iopub.status.idle":"2022-02-18T07:41:11.214168Z","shell.execute_reply.started":"2022-02-18T07:41:10.942056Z","shell.execute_reply":"2022-02-18T07:41:11.213377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                   optimizer=tf.keras.optimizers.Adam()\n            )","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:41:11.216013Z","iopub.execute_input":"2022-02-18T07:41:11.216288Z","iopub.status.idle":"2022-02-18T07:41:11.228217Z","shell.execute_reply.started":"2022-02-18T07:41:11.216252Z","shell.execute_reply":"2022-02-18T07:41:11.227511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid_dataset = np.array(y_valid_dataset)\ncustom_callback = SpearmanCallback(validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid, X_valid_feature_eng, valid_web_scraping_feature ], y_valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:41:11.229558Z","iopub.execute_input":"2022-02-18T07:41:11.229872Z","iopub.status.idle":"2022-02-18T07:41:11.236261Z","shell.execute_reply.started":"2022-02-18T07:41:11.229836Z","shell.execute_reply":"2022-02-18T07:41:11.235297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([tokenized_question_title_train, tokenized_question_body_train, tokenized_answer_train, X_train_feature_eng, train_web_scraping_feature], y_train_dataset, \n           epochs=10,  \n           validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid, X_valid_feature_eng, valid_web_scraping_feature], y_valid_dataset), \n           callbacks=[custom_callback])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:42:08.402753Z","iopub.execute_input":"2022-02-18T07:42:08.403243Z","iopub.status.idle":"2022-02-18T07:50:30.428187Z","shell.execute_reply.started":"2022-02-18T07:42:08.403206Z","shell.execute_reply":"2022-02-18T07:50:30.427252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot()\nplt.title(\"Base model with 13 FE features\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:50:30.430484Z","iopub.execute_input":"2022-02-18T07:50:30.430802Z","iopub.status.idle":"2022-02-18T07:50:30.649378Z","shell.execute_reply.started":"2022-02-18T07:50:30.430762Z","shell.execute_reply":"2022-02-18T07:50:30.648719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Observation:**\nThe model still not performed better comparing to the model with three basic text feature even after removing the **TF-IDF** features","metadata":{}},{"cell_type":"markdown","source":"# Base LSTM model applying 9 Feature Engineering features\n\n> Removing **TF-IDF features** as in the above model the performance has decreased comparing to the base model with only three features as tf-idf has more dimension.\n\n> Removing **Web scraping features** \n\n\n* **3 text features** - question_title, question_body, answer\n* **9 Feature engineering features (9 dim)** -  question_title_num_chars, question_body_num_chars, answer_num_chars,  question_title_num_words, question_body_num_words, answer_num_words, question_title_num_unique_words, question_body_num_unique_words, answer_num_unique_words\n","metadata":{}},{"cell_type":"code","source":"############################ INPUT 1 - Question title ############################################################\ninput_1 = tf.keras.layers.Input(shape=(30,))\nembed_1 = tf.keras.layers.Embedding(vocab_size_question_title, \n                                    300, \n                                    weights=[embedding_matrix_question_title],\n                                    input_length=30,\n                                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23), \n                                    trainable=False)(input_1)\nlstm1 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26),\n          return_sequences=True))(embed_1)\nprint(\"lstm_1 :\",lstm1.shape)\nflat_1 = tf.keras.layers.Flatten()(lstm1)\n\n\n############################ INPUT 2 - Question body ##############################################################\ninput_2 = tf.keras.layers.Input(shape=(question_body_max_len,))\nembed_2 = tf.keras.layers.Embedding(vocab_size_question_body,\n                    300, \n                    weights=[embedding_matrix_question_body], \n                    input_length=question_body_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=24), \n                    trainable=False)(input_2)\nlstm2 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=27),\n          return_sequences=True))(embed_2)\nprint(\"lstm_2 :\",lstm2.shape)\nflat_2 = tf.keras.layers.Flatten()(lstm2)\n\n\n############################ INPUT 3 - Answer ################################################################\ninput_3 = tf.keras.layers.Input(shape=(answer_max_len,))\nembed_3 = tf.keras.layers.Embedding(vocab_size_answer, 300, weights=[embedding_matrix_answer], \n                    input_length=answer_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=25), \n                    trainable=False)(input_3)\nlstm3 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=28),\n          return_sequences=True))(embed_3)\nprint(\"lstm_3 :\",lstm3.shape)\nflat_3 = tf.keras.layers.Flatten()(lstm3)\n\n#########################  INPUT 4 - Feature Engineering features ############################################\ninput_4 = tf.keras.layers.Input(shape=(9,))\nx = tf.keras.layers.Dense(64, activation='relu')(input_4)\nflat_4 = tf.keras.layers.Dense(32, activation='relu')(x)\n\n\n\n\nprint(\"Flat_1 shape :\",flat_1.shape)\nprint(\"Flat_2 shape :\",flat_2.shape)\nprint(\"Flat_3 shape :\",flat_3.shape)\nprint(\"Flat_4 shape :\",flat_4.shape)\n\n\nconcat = tf.keras.layers.Concatenate()([flat_1,flat_2,flat_3, flat_4])\nprint(concat.shape)\ndense = tf.keras.layers.Dense(32,activation = 'relu',kernel_initializer=tf.keras.initializers.he_normal(seed=40))(concat)\n\noutput = tf.keras.layers.Dense(30,activation = 'sigmoid',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45))(dense)\n\nmodel = tf.keras.Model(inputs = [input_1, input_2, input_3, input_4], outputs = output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:50:30.650761Z","iopub.execute_input":"2022-02-18T07:50:30.651121Z","iopub.status.idle":"2022-02-18T07:50:32.115745Z","shell.execute_reply.started":"2022-02-18T07:50:30.651083Z","shell.execute_reply":"2022-02-18T07:50:32.115048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:50:32.117674Z","iopub.execute_input":"2022-02-18T07:50:32.118013Z","iopub.status.idle":"2022-02-18T07:50:32.359357Z","shell.execute_reply.started":"2022-02-18T07:50:32.117975Z","shell.execute_reply":"2022-02-18T07:50:32.358594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                   optimizer=tf.keras.optimizers.Adam()\n            )","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:50:32.361005Z","iopub.execute_input":"2022-02-18T07:50:32.361501Z","iopub.status.idle":"2022-02-18T07:50:32.374349Z","shell.execute_reply.started":"2022-02-18T07:50:32.361458Z","shell.execute_reply":"2022-02-18T07:50:32.373677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_callback = SpearmanCallback(validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid, X_valid_feature_eng ], y_valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:50:32.376667Z","iopub.execute_input":"2022-02-18T07:50:32.377408Z","iopub.status.idle":"2022-02-18T07:50:32.381719Z","shell.execute_reply.started":"2022-02-18T07:50:32.377369Z","shell.execute_reply":"2022-02-18T07:50:32.381009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([tokenized_question_title_train, tokenized_question_body_train, tokenized_answer_train, X_train_feature_eng], y_train_dataset, \n           epochs=10,  \n           validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid, X_valid_feature_eng], y_valid_dataset), \n           callbacks=[custom_callback])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:50:32.383121Z","iopub.execute_input":"2022-02-18T07:50:32.383485Z","iopub.status.idle":"2022-02-18T07:58:12.036228Z","shell.execute_reply.started":"2022-02-18T07:50:32.383449Z","shell.execute_reply":"2022-02-18T07:58:12.035395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot()\nplt.title(\"Base model with 9 FE features\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T07:58:12.037837Z","iopub.execute_input":"2022-02-18T07:58:12.038037Z","iopub.status.idle":"2022-02-18T07:58:12.271465Z","shell.execute_reply.started":"2022-02-18T07:58:12.038014Z","shell.execute_reply":"2022-02-18T07:58:12.270808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Observation:**\nThe model with meta feature engineering has acheived better performance comparing to the TF-IDF, Web scraping features by acheiving the height spearman value as **0.2871** at 14th epoch and the model started overfitting the train data after 5th epoch as the training loss decrease but validation loss increasing","metadata":{}},{"cell_type":"markdown","source":"# Overall Observations:\n\n* Model with basic three features (question_title, quesiton_body, answer) + Meta features has acheived best performance comparing to the model with TF-IDF and web scraping features.\n* The best base model has acheived an spearman score of **0.2871**.\n* There is no need for training for 30 epochs as after 10 epochs the validation loss is increasing so the model will be overfitting to the training data.\n* TF-IDF and Web scraping feature are not important to get best performance, meta features are the important features.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Base Model with 100 dim glove \n","metadata":{}},{"cell_type":"markdown","source":"# Embedding 100 dim weights for **question_title**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm\n\nglove_file = open('../input/glove-embeddings/glove.6B.100d.txt', encoding='utf8')\n\nembeddings_index_100 = dict()   \nfor line in tqdm(glove_file):\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nglove_file.close()\nprint('Loaded %s word vectors.' % len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:08:48.780924Z","iopub.execute_input":"2022-02-18T08:08:48.7812Z","iopub.status.idle":"2022-02-18T08:09:05.458396Z","shell.execute_reply.started":"2022-02-18T08:08:48.781172Z","shell.execute_reply":"2022-02-18T08:09:05.457681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a weight matrix for words in training docs\n\nembedding_100_matrix_question_title = np.zeros((vocab_size_question_title, 100))\nfor word, i in question_title_tk.word_index.items():\n    embedding_vector = embeddings_index_100.get(word)\n    if embedding_vector is not None:\n        embedding_matrix_question_title[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:09:09.296085Z","iopub.execute_input":"2022-02-18T08:09:09.296508Z","iopub.status.idle":"2022-02-18T08:09:09.317284Z","shell.execute_reply.started":"2022-02-18T08:09:09.296467Z","shell.execute_reply":"2022-02-18T08:09:09.316615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_100_matrix_question_title.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:09:12.137294Z","iopub.execute_input":"2022-02-18T08:09:12.137843Z","iopub.status.idle":"2022-02-18T08:09:12.142696Z","shell.execute_reply.started":"2022-02-18T08:09:12.137805Z","shell.execute_reply":"2022-02-18T08:09:12.142044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Embedding 100 dim weights for **question_body**","metadata":{}},{"cell_type":"code","source":"# create a weight matrix for words in training docs\n\nembedding_100_matrix_question_body = np.zeros((vocab_size_question_body, 100))\nfor word, i in question_body_tk.word_index.items():\n    embedding_vector = embeddings_index_100.get(word)\n    if embedding_vector is not None:\n        embedding_matrix_question_body[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:09:17.902936Z","iopub.execute_input":"2022-02-18T08:09:17.903428Z","iopub.status.idle":"2022-02-18T08:09:17.930823Z","shell.execute_reply.started":"2022-02-18T08:09:17.90339Z","shell.execute_reply":"2022-02-18T08:09:17.930121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_100_matrix_question_body.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:09:21.381235Z","iopub.execute_input":"2022-02-18T08:09:21.381485Z","iopub.status.idle":"2022-02-18T08:09:21.389613Z","shell.execute_reply.started":"2022-02-18T08:09:21.381459Z","shell.execute_reply":"2022-02-18T08:09:21.388767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Embedding 100 dim weights for **answer**","metadata":{}},{"cell_type":"code","source":"# create a weight matrix for words in training docs\n\nembedding_100_matrix_answer = np.zeros((vocab_size_answer, 100))\nfor word, i in question_body_tk.word_index.items():\n    embedding_vector = embeddings_index_100.get(word)\n    if embedding_vector is not None:\n        embedding_matrix_answer[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:13:09.722586Z","iopub.execute_input":"2022-02-18T08:13:09.72299Z","iopub.status.idle":"2022-02-18T08:13:09.761874Z","shell.execute_reply.started":"2022-02-18T08:13:09.722953Z","shell.execute_reply":"2022-02-18T08:13:09.761165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_100_matrix_answer.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:13:10.751439Z","iopub.execute_input":"2022-02-18T08:13:10.75199Z","iopub.status.idle":"2022-02-18T08:13:10.758597Z","shell.execute_reply.started":"2022-02-18T08:13:10.751953Z","shell.execute_reply":"2022-02-18T08:13:10.757775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building base model with 100 dim embeddings\n\n","metadata":{}},{"cell_type":"code","source":"############################ INPUT 1 - Question title ############################################################\ninput_1 = tf.keras.layers.Input(shape=(30,))\nembed_1 = tf.keras.layers.Embedding(vocab_size_question_title, \n                                    100, \n                                    weights=[embedding_100_matrix_question_title],\n                                    input_length=30,\n                                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23), \n                                    trainable=False)(input_1)\nlstm1 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26),\n          return_sequences=True))(embed_1)\nprint(\"lstm_1 :\",lstm1.shape)\nflat_1 = tf.keras.layers.Flatten()(lstm1)\n\n\n############################ INPUT 2 - Question body ##############################################################\ninput_2 = tf.keras.layers.Input(shape=(question_body_max_len,))\nembed_2 = tf.keras.layers.Embedding(vocab_size_question_body,\n                    100, \n                    weights=[embedding_100_matrix_question_body], \n                    input_length=question_body_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=24), \n                    trainable=False)(input_2)\nlstm2 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=27),\n          return_sequences=True))(embed_2)\nprint(\"lstm_2 :\",lstm2.shape)\nflat_2 = tf.keras.layers.Flatten()(lstm2)\n\n\n############################ INPUT 3 - Answer ################################################################\ninput_3 = tf.keras.layers.Input(shape=(answer_max_len,))\nembed_3 = tf.keras.layers.Embedding(vocab_size_answer, 100, weights=[embedding_100_matrix_answer], \n                    input_length=answer_max_len, \n                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=25), \n                    trainable=False)(input_3)\nlstm3 = tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(24,activation='tanh',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=28),\n          return_sequences=True))(embed_3)\nprint(\"lstm_3 :\",lstm3.shape)\nflat_3 = tf.keras.layers.Flatten()(lstm3)\n\n#########################  INPUT 4 - Feature Engineering features ############################################\ninput_4 = tf.keras.layers.Input(shape=(9,))\nx = tf.keras.layers.Dense(64, activation='relu')(input_4)\nx = tf.keras.layers.Dropout(0.2)(x)\nflat_4 = tf.keras.layers.Dense(32, activation='relu')(x)\n\n\n##################### Input 5 - Web scraping feature ##########################################################\ninput_5 = tf.keras.layers.Input(shape=(4,))\nx = tf.keras.layers.Dense(128, activation='relu')(input_5)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nflat_5 = tf.keras.layers.Dense(32, activation='relu')(x)\n\nprint(\"Flat_1 shape :\",flat_1.shape)\nprint(\"Flat_2 shape :\",flat_2.shape)\nprint(\"Flat_3 shape :\",flat_3.shape)\nprint(\"Flat_4 shape :\",flat_4.shape)\nprint(\"Flat_5 shape :\",flat_5.shape)\n\n\nconcat = tf.keras.layers.Concatenate()([flat_1,flat_2,flat_3, flat_4, flat_5])\nprint(concat.shape)\ndense = tf.keras.layers.Dense(32,activation = 'relu',kernel_initializer=tf.keras.initializers.he_normal(seed=40))(concat)\n\noutput = tf.keras.layers.Dense(30,activation = 'sigmoid',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45))(dense)\n\nmodel = tf.keras.Model(inputs = [input_1, input_2, input_3, input_4, input_5], outputs = output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:14:31.63757Z","iopub.execute_input":"2022-02-18T08:14:31.637903Z","iopub.status.idle":"2022-02-18T08:14:32.987155Z","shell.execute_reply.started":"2022-02-18T08:14:31.637864Z","shell.execute_reply":"2022-02-18T08:14:32.986371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:14:35.879574Z","iopub.execute_input":"2022-02-18T08:14:35.880273Z","iopub.status.idle":"2022-02-18T08:14:36.168393Z","shell.execute_reply.started":"2022-02-18T08:14:35.880236Z","shell.execute_reply":"2022-02-18T08:14:36.167603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n                   optimizer=tf.keras.optimizers.Adam()\n            )","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:18:02.541465Z","iopub.execute_input":"2022-02-18T08:18:02.541752Z","iopub.status.idle":"2022-02-18T08:18:02.556853Z","shell.execute_reply.started":"2022-02-18T08:18:02.541718Z","shell.execute_reply":"2022-02-18T08:18:02.556169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid_dataset = np.array(y_valid_dataset)\ncustom_callback = SpearmanCallback(validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid, X_valid_feature_eng, valid_web_scraping_feature ], y_valid_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:18:03.728272Z","iopub.execute_input":"2022-02-18T08:18:03.728855Z","iopub.status.idle":"2022-02-18T08:18:03.733748Z","shell.execute_reply.started":"2022-02-18T08:18:03.728816Z","shell.execute_reply":"2022-02-18T08:18:03.73292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([tokenized_question_title_train, tokenized_question_body_train, tokenized_answer_train, X_train_feature_eng, train_web_scraping_feature], y_train_dataset, \n           epochs=10,  \n           validation_data=([tokenized_question_title_valid, tokenized_question_body_valid, tokenized_answer_valid, X_valid_feature_eng, valid_web_scraping_feature], y_valid_dataset), \n           callbacks=[custom_callback])","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:18:05.329245Z","iopub.execute_input":"2022-02-18T08:18:05.329835Z","iopub.status.idle":"2022-02-18T08:25:34.107763Z","shell.execute_reply.started":"2022-02-18T08:18:05.329796Z","shell.execute_reply":"2022-02-18T08:25:34.106998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot()\nplt.title(\"Base model with 100 dim embeddings\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:25:34.109856Z","iopub.execute_input":"2022-02-18T08:25:34.110144Z","iopub.status.idle":"2022-02-18T08:25:34.363089Z","shell.execute_reply.started":"2022-02-18T08:25:34.110108Z","shell.execute_reply":"2022-02-18T08:25:34.362302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from prettytable import PrettyTable\n\n\nmyTable = PrettyTable([\"Base Model\", \"Features\", \"Spearman scroe\"])\n\n\nmyTable.add_row([\"Bi-LSTM\", \"Three basic features\", \"0.2756\"])\nmyTable.add_row([\"Bi-LSTM\", \"Three basic features + 18 FE Features(meta, TF-IDF, Web scraping)\", \"0.00256\"])\nmyTable.add_row([\"Bi-LSTM\", \"Three basic features + 13 FE Features(meta, Web scraping)\", \"0.012556\"])\nmyTable.add_row([\"Bi-LSTM\", \"Three basic features + 9 FE Features(meta features)\", \"0.2865\"])\nmyTable.add_row([\"Bi-LSTM\", \"Three basic features + 13 FE features with 100 dim embeddings(meta, Web scraping)\", \"-0.004126\"])\n\nprint(myTable)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:30:11.573703Z","iopub.execute_input":"2022-02-18T08:30:11.574307Z","iopub.status.idle":"2022-02-18T08:30:11.581784Z","shell.execute_reply.started":"2022-02-18T08:30:11.574268Z","shell.execute_reply":"2022-02-18T08:30:11.580854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observations:\n\n* From the above we can observe that base model with three basic + meta features provided high score of **0.2865** comparing to all the other model.\n* The model with 100 dim embeddings with meta and web scraping features has also not reached the score of base model with base feature.\n* so, we can conclude that base model with meta features are gives the high score comparing to other models that we have experimented with.\n\n* As the training data is less and for training neural network model we need huge data so we will try with  transfer learning model like bert, albert, XLnet etc..","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}