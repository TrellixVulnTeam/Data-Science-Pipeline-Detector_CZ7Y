{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Aim of this Challenge:** \n\nCreate intelligent question and answer systems that can reliably predict context without relying on complicated and opaque rating guidelines.","metadata":{"editable":false}},{"cell_type":"markdown","source":"# The Business Problem:\n\n\nTo create a more human-like question and answering system can answer the provided question having the intuitive understanding of the question. This can attract users and address their question more human-like and this can also increase the number of user participation in the question answering forms and create human-like conversation chat boxes.\n","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Exploring dataset","metadata":{"editable":false}},{"cell_type":"code","source":"# importing the required libraries \n\nimport pandas as pd\nimport  numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:46.498969Z","iopub.execute_input":"2022-03-02T05:44:46.499415Z","iopub.status.idle":"2022-03-02T05:44:47.360404Z","shell.execute_reply.started":"2022-03-02T05:44:46.499323Z","shell.execute_reply":"2022-03-02T05:44:47.359628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')\ntest_dataset = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\nsample_submission_dataset = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n\nprint(\"Train shape:\", train_dataset.shape)\nprint(\"Test shape:\", test_dataset.shape)\nprint(\"Sample submission shape:\", sample_submission_dataset.shape)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.361999Z","iopub.execute_input":"2022-03-02T05:44:47.362251Z","iopub.status.idle":"2022-03-02T05:44:47.728788Z","shell.execute_reply.started":"2022-03-02T05:44:47.362215Z","shell.execute_reply":"2022-03-02T05:44:47.727025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations:\n* In train dataset we have 41 column and 6079 rows(instances/training points).\n* in test dataset we have only 11 column and 476 rows(instances/test points).\n* in submission dataset we have 31 column and 476 rows.","metadata":{"editable":false}},{"cell_type":"code","source":"# Check for train data samples\ntrain_dataset.head(2)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.730022Z","iopub.execute_input":"2022-03-02T05:44:47.7303Z","iopub.status.idle":"2022-03-02T05:44:47.763978Z","shell.execute_reply.started":"2022-03-02T05:44:47.730264Z","shell.execute_reply":"2022-03-02T05:44:47.763193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spliting the data in to train and validation","metadata":{"editable":false}},{"cell_type":"code","source":"y_columns = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']\n\ny = train_dataset[y_columns]\nX = train_dataset.drop(y_columns,axis=1)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.766071Z","iopub.execute_input":"2022-03-02T05:44:47.766537Z","iopub.status.idle":"2022-03-02T05:44:47.777708Z","shell.execute_reply.started":"2022-03-02T05:44:47.766495Z","shell.execute_reply":"2022-03-02T05:44:47.777016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.778998Z","iopub.execute_input":"2022-03-02T05:44:47.779324Z","iopub.status.idle":"2022-03-02T05:44:47.788263Z","shell.execute_reply.started":"2022-03-02T05:44:47.779279Z","shell.execute_reply":"2022-03-02T05:44:47.787538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train_dataset, X_valid_dataset, y_train_dataset, y_valid_dataset = train_test_split(X,y, test_size=0.10)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.789735Z","iopub.execute_input":"2022-03-02T05:44:47.78994Z","iopub.status.idle":"2022-03-02T05:44:47.945713Z","shell.execute_reply.started":"2022-03-02T05:44:47.789917Z","shell.execute_reply":"2022-03-02T05:44:47.945014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset.shape, X_valid_dataset.shape, y_train_dataset.shape, y_valid_dataset.shape","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.947Z","iopub.execute_input":"2022-03-02T05:44:47.947267Z","iopub.status.idle":"2022-03-02T05:44:47.95316Z","shell.execute_reply.started":"2022-03-02T05:44:47.947233Z","shell.execute_reply":"2022-03-02T05:44:47.952355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.954697Z","iopub.execute_input":"2022-03-02T05:44:47.95496Z","iopub.status.idle":"2022-03-02T05:44:47.978471Z","shell.execute_reply.started":"2022-03-02T05:44:47.954926Z","shell.execute_reply":"2022-03-02T05:44:47.97781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Preprocessing Text Feature**","metadata":{"editable":false}},{"cell_type":"code","source":"# https://stackoverflow.com/a/47091490/4084039\nimport re\n\ndef decontracted(phrase):\n    phrase = re.sub(r\"(W|w)on(\\'|\\’)t \", \"will not \", phrase)\n    phrase = re.sub(r\"(C|c)an(\\'|\\’)t \", \"can not \", phrase)\n    phrase = re.sub(r\"(Y|y)(\\'|\\’)all \", \"you all \", phrase)\n    phrase = re.sub(r\"(Y|y)a(\\'|\\’)ll \", \"you all \", phrase)\n    phrase = re.sub(r\"(I|i)(\\'|\\’)m \", \"i am \", phrase)\n    phrase = re.sub(r\"(A|a)isn(\\'|\\’)t \", \"is not \", phrase)\n    phrase = re.sub(r\"n(\\'|\\’)t \", \" not \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)re \", \" are \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)d \", \" would \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)ll \", \" will \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)t \", \" not \", phrase)\n    phrase = re.sub(r\"(\\'|\\’)ve \", \" have \", phrase)\n    \n    return phrase\n\n\ndef clean_text(x):\n\n    x = str(x)\n    for punct in \"/-'\":\n        x = x.replace(punct, ' ')\n    for punct in '&':\n        x = x.replace(punct, f' {punct} ')\n    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n        x = x.replace(punct, '')\n    return x\n\ndef clean_numbers(x):\n\n    x = re.sub('[0-9]{5,}', '12345', x)\n    x = re.sub('[0-9]{4}', '1234', x)\n    x = re.sub('[0-9]{3}', '123', x)\n    x = re.sub('[0-9]{2}', '12', x)\n    return x","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.979748Z","iopub.execute_input":"2022-03-02T05:44:47.979989Z","iopub.status.idle":"2022-03-02T05:44:47.992302Z","shell.execute_reply.started":"2022-03-02T05:44:47.979957Z","shell.execute_reply":"2022-03-02T05:44:47.991582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://gist.github.com/sebleier/554280\n# we are removing the words from the stop words list: 'no', 'nor', 'not'\nstopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:47.995883Z","iopub.execute_input":"2022-03-02T05:44:47.996124Z","iopub.status.idle":"2022-03-02T05:44:48.007984Z","shell.execute_reply.started":"2022-03-02T05:44:47.996097Z","shell.execute_reply":"2022-03-02T05:44:48.007371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combining all the above stundents \nfrom tqdm import tqdm\ndef preprocess_text(text_data):\n    preprocessed_text = []\n    # tqdm is for printing the status bar\n    for sentance in tqdm(text_data):\n        sent = decontracted(sentance)\n        sent = clean_text(sentance)\n        sent = clean_numbers(sentance)\n        sent = sent.replace('\\\\r', ' ')\n        sent = sent.replace('\\\\n', ' ')\n        sent = sent.replace('\\\\\"', ' ')\n        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n        # https://gist.github.com/sebleier/554280\n        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n        preprocessed_text.append(sent.lower().strip())\n    return preprocessed_text","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:48.009509Z","iopub.execute_input":"2022-03-02T05:44:48.009983Z","iopub.status.idle":"2022-03-02T05:44:48.02149Z","shell.execute_reply.started":"2022-03-02T05:44:48.009918Z","shell.execute_reply":"2022-03-02T05:44:48.020514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset['preprocessed_question_title'] = preprocess_text(X_train_dataset['question_title'].values)\nX_train_dataset['preprocessed_question_body'] = preprocess_text(X_train_dataset['question_body'].values)\nX_train_dataset['preprocessed_answer'] = preprocess_text(X_train_dataset['answer'].values)\n\n\nX_valid_dataset['preprocessed_question_title'] = preprocess_text(X_valid_dataset['question_title'].values)\nX_valid_dataset['preprocessed_question_body'] = preprocess_text(X_valid_dataset['question_body'].values)\nX_valid_dataset['preprocessed_answer'] = preprocess_text(X_valid_dataset['answer'].values)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:48.023187Z","iopub.execute_input":"2022-03-02T05:44:48.023726Z","iopub.status.idle":"2022-03-02T05:44:56.918974Z","shell.execute_reply.started":"2022-03-02T05:44:48.02369Z","shell.execute_reply":"2022-03-02T05:44:56.918269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset['preprocessed_question_title'] = preprocess_text(test_dataset['question_title'].values)\ntest_dataset['preprocessed_question_body'] = preprocess_text(test_dataset['question_body'].values)\ntest_dataset['preprocessed_answer'] = preprocess_text(test_dataset['answer'].values)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:56.920286Z","iopub.execute_input":"2022-03-02T05:44:56.921285Z","iopub.status.idle":"2022-03-02T05:44:57.626393Z","shell.execute_reply.started":"2022-03-02T05:44:56.921244Z","shell.execute_reply":"2022-03-02T05:44:57.6246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### question_title text after preprocessing","metadata":{"editable":false}},{"cell_type":"code","source":"# Text before preprocessing\nX_train_dataset['question_title'].values[0]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:57.627605Z","iopub.execute_input":"2022-03-02T05:44:57.627859Z","iopub.status.idle":"2022-03-02T05:44:57.633404Z","shell.execute_reply.started":"2022-03-02T05:44:57.627821Z","shell.execute_reply":"2022-03-02T05:44:57.632703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text after preprocessing\nX_train_dataset['preprocessed_question_title'].values[0]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:57.634487Z","iopub.execute_input":"2022-03-02T05:44:57.635167Z","iopub.status.idle":"2022-03-02T05:44:57.644495Z","shell.execute_reply.started":"2022-03-02T05:44:57.635099Z","shell.execute_reply":"2022-03-02T05:44:57.643718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### question_body after preprocessing","metadata":{"editable":false}},{"cell_type":"code","source":"# Text before preprocessing\nX_train_dataset['question_body'].values[0]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:57.645661Z","iopub.execute_input":"2022-03-02T05:44:57.645934Z","iopub.status.idle":"2022-03-02T05:44:57.65415Z","shell.execute_reply.started":"2022-03-02T05:44:57.645899Z","shell.execute_reply":"2022-03-02T05:44:57.65341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text after preprocessing\nX_train_dataset['preprocessed_question_body'].values[0]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:57.655543Z","iopub.execute_input":"2022-03-02T05:44:57.656053Z","iopub.status.idle":"2022-03-02T05:44:57.66372Z","shell.execute_reply.started":"2022-03-02T05:44:57.656016Z","shell.execute_reply":"2022-03-02T05:44:57.662879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Answer after preprocessing","metadata":{"editable":false}},{"cell_type":"code","source":"# Text before preprocessing\nX_train_dataset['answer'].values[0]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:57.664888Z","iopub.execute_input":"2022-03-02T05:44:57.665198Z","iopub.status.idle":"2022-03-02T05:44:57.673162Z","shell.execute_reply.started":"2022-03-02T05:44:57.665126Z","shell.execute_reply":"2022-03-02T05:44:57.672368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text after preprocessing\nX_train_dataset['preprocessed_answer'].values[0]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:44:57.67517Z","iopub.execute_input":"2022-03-02T05:44:57.675883Z","iopub.status.idle":"2022-03-02T05:44:57.682386Z","shell.execute_reply.started":"2022-03-02T05:44:57.675845Z","shell.execute_reply":"2022-03-02T05:44:57.681613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nimport tensorflow_hub as hub\nimport tensorflow as tf\nimport bert_tokenization as tokenization\nimport tensorflow.keras.backend as K\nimport gc\nimport os\nfrom scipy.stats import spearmanr\nfrom math import floor, ceil\n\nnp.set_printoptions(suppress=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T05:44:57.683394Z","iopub.execute_input":"2022-03-02T05:44:57.685272Z","iopub.status.idle":"2022-03-02T05:45:02.815925Z","shell.execute_reply.started":"2022-03-02T05:44:57.685242Z","shell.execute_reply":"2022-03-02T05:45:02.815187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hub_url_bert = \"../input/bert-hub/bert_en_uncased_L-12_H-768_A-12\"\nbert_layer = hub.KerasLayer(hub_url_bert, trainable=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-02T05:45:02.817017Z","iopub.execute_input":"2022-03-02T05:45:02.817278Z","iopub.status.idle":"2022-03-02T05:45:14.804003Z","shell.execute_reply.started":"2022-03-02T05:45:02.817243Z","shell.execute_reply":"2022-03-02T05:45:14.803291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n#do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n\n\ntokenizer = tokenization.FullTokenizer('../input/bert-hub/bert_en_uncased_L-12_H-768_A-12/assets/vocab.txt', True)\n\nprint(\"Vocab size:\", len(tokenizer.vocab))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T05:45:14.805328Z","iopub.execute_input":"2022-03-02T05:45:14.805584Z","iopub.status.idle":"2022-03-02T05:45:14.930225Z","shell.execute_reply.started":"2022-03-02T05:45:14.805549Z","shell.execute_reply":"2022-03-02T05:45:14.929355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset.shape, X_valid_dataset.shape, test_dataset.shape","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:45:14.931498Z","iopub.execute_input":"2022-03-02T05:45:14.931974Z","iopub.status.idle":"2022-03-02T05:45:14.939476Z","shell.execute_reply.started":"2022-03-02T05:45:14.931929Z","shell.execute_reply":"2022-03-02T05:45:14.93847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_dataset.columns","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:45:14.941031Z","iopub.execute_input":"2022-03-02T05:45:14.941865Z","iopub.status.idle":"2022-03-02T05:45:14.951226Z","shell.execute_reply.started":"2022-03-02T05:45:14.941821Z","shell.execute_reply":"2022-03-02T05:45:14.950282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Transforming input features for bert model","metadata":{"editable":false}},{"cell_type":"markdown","source":"### Functions to get `Input Ids` , `Input mask`, `Input segment` for bert","metadata":{"editable":false}},{"cell_type":"code","source":"def extract_masks(tokens, max_seq_length):\n    \n    \"\"\"Mask for padding\"\"\"\n    \n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n\n\n\ndef extract_segments(tokens, max_seq_length):\n    \n    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n    \n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    segments = []\n    first_sep = True\n    current_segment_id = 0\n    for token in tokens:\n        segments.append(current_segment_id)\n        if token == \"[SEP]\":\n            if first_sep:\n                first_sep = False \n            else:\n                current_segment_id = 1\n    return segments + [0] * (max_seq_length - len(tokens))\n\n\n\ndef extract_ids(tokens, tokenizer, max_seq_length):\n    \n    \"\"\"Token ids from Tokenizer vocab\"\"\"\n    \n    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n    return input_ids","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:45:14.952837Z","iopub.execute_input":"2022-03-02T05:45:14.953976Z","iopub.status.idle":"2022-03-02T05:45:14.96675Z","shell.execute_reply.started":"2022-03-02T05:45:14.953942Z","shell.execute_reply":"2022-03-02T05:45:14.965921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In the below `_traim_input` function:\n\n* if the input sentence has the number of tokens > 512, the \nsentence is trimmed down to 512. To trim the number of tokens, 256 tokens from \nthe start and 256 tokens from the end are kept and the remaining tokens are dropped.\n\n> **Ex.** suppose an answer has 700 tokens, to trim this down to 512, 256 tokens from the\nbeginning are taken and 256 tokens from the end are taken and concatenated to make \n512 tokens. The remaining [700-(256+256) = 288] tokens that are in the middle of the \nanswer are dropped. \n\n* The logic makes sense because in large texts, the beginning part\nusually describes what the text is all about and the end part describes the conclusion\nof the text. This is also closely related to the target features that we need to predict.","metadata":{"editable":false}},{"cell_type":"code","source":"def _trim_input(title, question, answer, max_sequence_length, \n                t_max_len=30, q_max_len=239, a_max_len=239):\n\n    t = tokenizer.tokenize(title)\n    q = tokenizer.tokenize(question)\n    a = tokenizer.tokenize(answer)\n    \n    t_len = len(t)\n    q_len = len(q)\n    a_len = len(a)\n\n    if (t_len+q_len+a_len+4) > max_sequence_length:\n        \n        if t_max_len > t_len:\n            t_new_len = t_len\n            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n        else:\n            t_new_len = t_max_len\n      \n        if a_max_len > a_len:\n            a_new_len = a_len \n            q_new_len = q_max_len + (a_max_len - a_len)\n        elif q_max_len > q_len:\n            a_new_len = a_max_len + (q_max_len - q_len)\n            q_new_len = q_len\n        else:\n            a_new_len = a_max_len\n            q_new_len = q_max_len\n            \n            \n        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n            raise ValueError(\"New sequence length should be %d, but is %d\" \n                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n        \n        t = t[:t_new_len]\n        q = q[:q_new_len]\n        a = a[:a_new_len]\n    \n    return t, q, a","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:45:14.970156Z","iopub.execute_input":"2022-03-02T05:45:14.970376Z","iopub.status.idle":"2022-03-02T05:45:14.981803Z","shell.execute_reply.started":"2022-03-02T05:45:14.970344Z","shell.execute_reply":"2022-03-02T05:45:14.980831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### In the below `_convert_to_bert_inputs` function\n\n* Concatinate the three text features in to one single features and convert the input to bert compatable inputs","metadata":{"editable":false}},{"cell_type":"code","source":"def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n    \n    text = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n\n    input_ids = extract_ids(text, tokenizer, max_sequence_length)\n    input_masks = extract_masks(text, max_sequence_length)\n    input_segments = extract_segments(text, max_sequence_length)\n\n    return [input_ids, input_masks, input_segments]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:45:14.983379Z","iopub.execute_input":"2022-03-02T05:45:14.983848Z","iopub.status.idle":"2022-03-02T05:45:14.992699Z","shell.execute_reply.started":"2022-03-02T05:45:14.983808Z","shell.execute_reply":"2022-03-02T05:45:14.991681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming bert training dataset to bert compatible input\n\ninput_ids, input_masks, input_segments = [], [], []\nmax_sequence_length = 512\nfor _, instance in tqdm(X_train_dataset.iterrows()):\n    t, q, a = instance.question_title, instance.question_body, instance.answer\n\n    t, q, a = _trim_input(t, q, a, max_sequence_length)\n\n    ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n    input_ids.append(ids)\n    input_masks.append(masks)\n    input_segments.append(segments)\n\nX_train_bert =  [np.asarray(input_ids, dtype=np.int32), \n                np.asarray(input_masks, dtype=np.int32), \n                np.asarray(input_segments, dtype=np.int32)]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:45:14.998262Z","iopub.execute_input":"2022-03-02T05:45:14.998903Z","iopub.status.idle":"2022-03-02T05:45:57.861243Z","shell.execute_reply.started":"2022-03-02T05:45:14.998872Z","shell.execute_reply":"2022-03-02T05:45:57.860471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming bert validation dataset to bert compatible input\n\ninput_ids, input_masks, input_segments = [], [], []\nmax_sequence_length = 512\nfor _, instance in tqdm(X_valid_dataset.iterrows()):\n    t, q, a = instance.question_title, instance.question_body, instance.answer\n\n    t, q, a = _trim_input(t, q, a, max_sequence_length)\n\n    ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n    input_ids.append(ids)\n    input_masks.append(masks)\n    input_segments.append(segments)\n\nX_valid_bert =  [np.asarray(input_ids, dtype=np.int32), \n                np.asarray(input_masks, dtype=np.int32), \n                np.asarray(input_segments, dtype=np.int32)]\n\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:45:57.862546Z","iopub.execute_input":"2022-03-02T05:45:57.862799Z","iopub.status.idle":"2022-03-02T05:46:02.503645Z","shell.execute_reply.started":"2022-03-02T05:45:57.862765Z","shell.execute_reply":"2022-03-02T05:46:02.502787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming bert test dataset to bert compatible input\n\ninput_ids, input_masks, input_segments = [], [], []\nmax_sequence_length = 512\nfor _, instance in tqdm(test_dataset.iterrows()):\n    t, q, a = instance.question_title, instance.question_body, instance.answer\n\n    t, q, a = _trim_input(t, q, a, max_sequence_length)\n\n    ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n    input_ids.append(ids)\n    input_masks.append(masks)\n    input_segments.append(segments)\n\nX_test_bert =  [np.asarray(input_ids, dtype=np.int32), \n                np.asarray(input_masks, dtype=np.int32), \n                np.asarray(input_segments, dtype=np.int32)]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:46:02.505198Z","iopub.execute_input":"2022-03-02T05:46:02.505469Z","iopub.status.idle":"2022-03-02T05:46:06.208375Z","shell.execute_reply.started":"2022-03-02T05:46:02.505432Z","shell.execute_reply":"2022-03-02T05:46:06.207609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train_bert), X_train_bert[0].shape, X_train_bert[1].shape, X_train_bert[2].shape","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:46:06.209532Z","iopub.execute_input":"2022-03-02T05:46:06.210204Z","iopub.status.idle":"2022-03-02T05:46:06.217939Z","shell.execute_reply.started":"2022-03-02T05:46:06.210166Z","shell.execute_reply":"2022-03-02T05:46:06.217081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tuning bert model","metadata":{"editable":false}},{"cell_type":"code","source":"from scipy.stats import spearmanr\n\nclass SpearmanCallback(tf.keras.callbacks.Callback):\n    def __init__(self, validation_data):\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n    def on_epoch_end(self, epoch, logs={}):\n        print(\"y_val :\", self.y_val.shape)\n        y_pred_val = self.model.predict(self.x_val)\n        print(\"y_pred_val :\",y_pred_val.shape )\n        rho_val = np.mean([spearmanr(self.y_val[:, ind], y_pred_val[:, ind] + np.random.normal(0, 1e-7, y_pred_val.shape[0])).correlation for ind in range(y_pred_val.shape[1])])\n        print(rho_val)\n        print('\\nval_spearman-corr: %s' % (str(round(rho_val, 6))), end=100*' '+'\\n')\n        return rho_val","metadata":{"execution":{"iopub.status.busy":"2022-03-02T05:46:06.219247Z","iopub.execute_input":"2022-03-02T05:46:06.219591Z","iopub.status.idle":"2022-03-02T05:46:06.229065Z","shell.execute_reply.started":"2022-03-02T05:46:06.219553Z","shell.execute_reply":"2022-03-02T05:46:06.227916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nmax_seq_length = 512\n\ninput_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n\ninput_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n\nsegment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n\nhub_url_bert = \"../input/bert-hub/bert_en_uncased_L-12_H-768_A-12\"\nbert_layer = hub.KerasLayer(hub_url_bert, trainable=True)\n\npooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n\nbert_model = tf.keras.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=sequence_output)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T05:46:06.230346Z","iopub.execute_input":"2022-03-02T05:46:06.230777Z","iopub.status.idle":"2022-03-02T05:46:13.216579Z","shell.execute_reply.started":"2022-03-02T05:46:06.23074Z","shell.execute_reply":"2022-03-02T05:46:13.215762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninput_word_ids = tf.keras.layers.Input(\n    (512,), dtype=tf.int32, name='input_word_ids')\ninput_masks = tf.keras.layers.Input(\n    (512,), dtype=tf.int32, name='input_masks')\ninput_segments = tf.keras.layers.Input(\n    (512,), dtype=tf.int32, name='input_segments')\n\n\nsequence_output = bert_model([input_word_ids, input_masks, input_segments])\n\nx = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\nx = tf.keras.layers.Dropout(0.2)(x)\nout = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n\nmodel = tf.keras.Model(\n    inputs=[input_word_ids, input_masks, input_segments], outputs=out\n)\n    \nmodel.summary()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:46:13.217886Z","iopub.execute_input":"2022-03-02T05:46:13.218123Z","iopub.status.idle":"2022-03-02T05:46:13.430962Z","shell.execute_reply.started":"2022-03-02T05:46:13.218092Z","shell.execute_reply":"2022-03-02T05:46:13.430198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:46:13.432244Z","iopub.execute_input":"2022-03-02T05:46:13.432497Z","iopub.status.idle":"2022-03-02T05:46:14.235753Z","shell.execute_reply.started":"2022-03-02T05:46:13.432463Z","shell.execute_reply":"2022-03-02T05:46:14.234995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_callback = SpearmanCallback(\n        validation_data=(X_valid_bert, np.array(y_valid_dataset))\n)\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-03-02T05:46:14.237618Z","iopub.execute_input":"2022-03-02T05:46:14.237894Z","iopub.status.idle":"2022-03-02T05:46:14.243232Z","shell.execute_reply.started":"2022-03-02T05:46:14.23785Z","shell.execute_reply":"2022-03-02T05:46:14.242369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_dataset = np.asarray(y_train_dataset)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)) # 3e-5\n\nhistory = model.fit(X_train_bert, y_train_dataset, epochs=3, \n          validation_data=(X_valid_bert, np.array(y_valid_dataset)),\n              batch_size=4, callbacks=[custom_callback])","metadata":{"execution":{"iopub.status.busy":"2022-03-02T05:46:14.245298Z","iopub.execute_input":"2022-03-02T05:46:14.245565Z","iopub.status.idle":"2022-03-02T06:07:20.507501Z","shell.execute_reply.started":"2022-03-02T05:46:14.245532Z","shell.execute_reply":"2022-03-02T06:07:20.505989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = model.predict(X_test_bert)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:07:20.509099Z","iopub.execute_input":"2022-03-02T06:07:20.509586Z","iopub.status.idle":"2022-03-02T06:07:42.165212Z","shell.execute_reply.started":"2022-03-02T06:07:20.509543Z","shell.execute_reply":"2022-03-02T06:07:42.16443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:07:42.166959Z","iopub.execute_input":"2022-03-02T06:07:42.167235Z","iopub.status.idle":"2022-03-02T06:07:42.172081Z","shell.execute_reply.started":"2022-03-02T06:07:42.167201Z","shell.execute_reply":"2022-03-02T06:07:42.171445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_dataset[y_columns] = submission","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:07:42.173487Z","iopub.execute_input":"2022-03-02T06:07:42.173943Z","iopub.status.idle":"2022-03-02T06:07:42.187449Z","shell.execute_reply.started":"2022-03-02T06:07:42.173907Z","shell.execute_reply":"2022-03-02T06:07:42.186697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_dataset.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T06:07:42.188869Z","iopub.execute_input":"2022-03-02T06:07:42.189452Z","iopub.status.idle":"2022-03-02T06:07:42.215664Z","shell.execute_reply.started":"2022-03-02T06:07:42.189415Z","shell.execute_reply":"2022-03-02T06:07:42.215078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}