{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Understanding the Metric: Spearman's Rank Correlation Coefficient (Spearman's Rho)"},{"metadata":{},"cell_type":"markdown","source":"![](http://i.hurimg.com/i/hdn/75/0x0/59c9a5f845d2a027e83ddaf9.jpg)"},{"metadata":{},"cell_type":"markdown","source":"In this kernel we explore the competition metric for the [Google QUEST Q&A Labeling 2019 competition](https://www.kaggle.com/c/google-quest-challenge). The competition metric is called [Spearman's Rank Correlation Coefficient (or Spearman's Rho)](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient). This metric is similar to Pearson correlation, but used the ranks of the data instead of the raw data."},{"metadata":{},"cell_type":"markdown","source":"P.S. This kernel is the third in a series of kernels on metrics. Feel free to check out the previous ones on [Root Mean Square Logirithmic Error (RMSLE)](https://www.kaggle.com/carlolepelaars/understanding-the-metric-rmsle) and [Quadratic Weighted Kappa (QWK)](https://www.kaggle.com/carlolepelaars/understanding-the-metric-quadratic-weighted-kappa)."},{"metadata":{},"cell_type":"markdown","source":"## Table of Contents"},{"metadata":{},"cell_type":"markdown","source":"- [Dependencies](#1)\n- [Preparation](#2)\n- [The Metric](#3)\n- [Speed Comparison](#4)\n- [Naive Baselines](#5)\n- [Optimizing Spearman's Rho](#6)\n- [Submission](#7)"},{"metadata":{},"cell_type":"markdown","source":"## Dependencies <a id=\"1\"></a>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Standard dependencies\nimport os\nimport numpy as np\nimport random as rn\nimport pandas as pd\nfrom numba import jit\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import Callback\n\n# Scipy's implementation of Spearman's Rho \nfrom scipy.stats import spearmanr\n\n# Set seed for reproducability\nseed = 1234\nrn.seed(seed)\nnp.random.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\n\n# Paths for easy data access\nBASE_PATH = \"../input/google-quest-challenge/\"\nTRAIN_PATH = BASE_PATH + \"train.csv\"\nTEST_PATH = BASE_PATH + \"test.csv\"\nSUB_PATH = BASE_PATH + \"sample_submission.csv\"","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# File sizes and specifications\nprint('\\n# Files and file sizes')\nfor file in os.listdir(BASE_PATH):\n    print('{}| {} MB'.format(file.ljust(30), \n                             str(round(os.path.getsize(BASE_PATH + file) / 1000000, 2))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparation <a id=\"2\"></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# All 30 targets\ntarget_cols = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read in training data\ndf = pd.read_csv(TRAIN_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Target variables:\")\ndf[target_cols].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Metric <a id=\"3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"[Spearman's Rho](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) is one of the most popular ways to evaluate the correlation between variables. It is an appropriate metric for both continuous and discrete ordinal variables. The Spearman's Rho score will always be between -1 (perfect negative correlation) and 1 (Perfect correlation). The original formula can look quite daunting but for completeness we present it here:\n\n![](https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2015/01/tied-ranks-1.png)\n\nR(x) and R(y) are the ranks.\n\nR(x)bar and R(y)bar are the mean ranks.\n\n[Image Source](https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2015/01/tied-ranks-1.png)\n\nWe can clean up the formula a bit if you are familiar with how covariance and the standard deviation are calculated. We define Spearman's Rho as the Covariance of the ranks of the variables divided by the multiplied standard deviations of the ranks:\n\n![](https://wikimedia.org/api/rest_v1/media/math/render/svg/a8dda555d22080d721679401fa13181cad3863f6) \n\nIf all ranks are distinct integers we can use a popular simplified formula to calculate Spearman's Rho:\n\n![](https://wikimedia.org/api/rest_v1/media/math/render/svg/b69578f3203ecf1b85b1a0929772b376ae07a3ce)\n\n"},{"metadata":{},"cell_type":"markdown","source":"We can use an optimized implementation from Scipy that uses [Cython](https://cython.org/) and can already calculate Spearman's Rho pretty efficiently. It will also provide the p-value for the calculation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def spearmans_rho(y_true, y_pred, axis=0):\n    \"\"\"\n        Calculates the Spearman's Rho Correlation between ground truth labels and predictions \n    \"\"\"\n    return spearmanr(y_true, y_pred, axis=axis)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's implement Spearman's R using only NumPy to get better insight in the structure of the formula and see how you can implement it yourself in Python."},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_ranks(arr: np.ndarray) -> np.ndarray:\n    \"\"\"\n        Efficiently calculates the ranks of the data.\n        Only sorts once to get the ranked data.\n        \n        :param arr: A 1D NumPy Array\n        :return: A 1D NumPy Array containing the ranks of the data\n    \"\"\"\n    temp = arr.argsort(kind='stable')\n    ranks = np.empty_like(temp)\n    ranks[temp] = np.arange(len(arr))\n    return ranks\n\ndef spearmans_rho_custom(y_true: np.ndarray, y_pred: np.ndarray) -> np.float32:\n    \"\"\"\n        Efficiently calculates the Spearman's Rho correlation using only NumPy\n        \n        :param y_true: The ground truth labels\n        :param y_pred: The predicted labels\n    \"\"\"\n    # Get ranked data\n    true_rank = _get_ranks(y_true)\n    pred_rank = _get_ranks(y_pred)\n    \n    return np.corrcoef(true_rank, pred_rank)[1][0] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, [Abhishek Thakur](https://www.kaggle.com/abhishek) provided us with a nice implementation of Spearman's Rho as a callback compatible with Tensorflow/Keras. Use this callback if you are training a Tensorflow/Keras model and want to keep score on Spearman's Rho.\n\n[The implementation was copied from this Kaggle kernel](https://www.kaggle.com/abhishek/distilbert-use-features-oof)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SpearmanRhoCallback(Callback):\n    def __init__(self, training_data, validation_data, patience, model_name):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n        \n        self.patience = patience\n        self.value = -1\n        self.bad_epochs = 0\n        self.model_name = model_name\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred_val = self.model.predict(self.x_val)\n        rho_val = np.mean([spearmanr(self.y_val[:, ind], y_pred_val[:, ind] + np.random.normal(0, 1e-7, y_pred_val.shape[0])).correlation for ind in range(y_pred_val.shape[1])])\n        if rho_val >= self.value:\n            self.value = rho_val\n        else:\n            self.bad_epochs += 1\n        if self.bad_epochs >= self.patience:\n            print(\"Epoch %05d: early stopping Threshold\" % epoch)\n            self.model.stop_training = True\n            #self.model.save_weights(self.model_name)\n        print('\\rval_spearman-rho: %s' % (str(round(rho_val, 4))), end=100*' '+'\\n')\n        return rho_val\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Speed Comparison <a id=\"4\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Our custom implementation only needs to sort once, but it still takes advantage of the optimized function from NumPy. It also calculates only the correlation without p-values. This is probably why it runs a little faster than Scipy's version. We will show this with an example using sampled linear data with noise."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample two times from distributions that are highly correlated\nsamp_size = 1000000\nnorm_num = np.arange(samp_size) + np.random.normal(0, 10, samp_size)\nnorm_num2 = np.arange(samp_size) + np.random.normal(0, 100000, samp_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Speed Test Scipy's Implementation"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%timeit\nspearmanr(norm_num, norm_num2)[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Speed Test Custom Implementation"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%timeit\nspearmans_rho_custom(norm_num, norm_num2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Baselines <a id=\"5\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 1. Predict using random uniform predictions"},{"metadata":{},"cell_type":"markdown","source":"The most basic benchmark is to sample from a random uniform distribution ([0,1]). This will give us a score that is close to 0."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"corrs = []\n# Make random predictions\nfor col in target_cols:\n    naive_preds = np.random.rand(len(df))\n    corr = spearmans_rho_custom(naive_preds, df[col])\n    corrs.append(corr)\nrand_baseline = np.mean(corrs)\nprint(f\"Spearman's Rho Score for random uniform predictions: {round(rand_baseline, 6)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Predict mean rank with noise"},{"metadata":{},"cell_type":"markdown","source":"A second way to formulate a naive baseline is to predict the mean of the column. However, we have to add a little noise to avoid a division by zero error. Remember that in order to calculate Spearman's Rho we have to divide by standard deviation of the first column multiplied by the standard deviation of the second column. If our prediction is completely constant than the standard deviation will be zero and hence we will get an error.\n\nUnfortunately, this will not improve compared to the random predictions."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"corrs = []\n# Predict the mean and a small amount of noise to avoid division by zero\nfor col in target_cols:\n    probs = df[col].value_counts().values / len(df)\n    vals = list(df[col].value_counts().index)\n    naive_preds = df[col].mean() + np.random.normal(0, 1e-15, len(df))\n    corr = spearmans_rho_custom(naive_preds, df[col])\n    corrs.append(corr)\nmean_baseline = np.mean(corrs)\nprint(f\"Spearman's Rho Score for predicting the mean with some noise: {round(mean_baseline, 6)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Predict using distribution based on the data"},{"metadata":{},"cell_type":"markdown","source":"Thirdly, we can create a naive baseline using the probability that a value occurs and use these probabilities to create a new distribution to sample from. Unfortunately, there will be no increase in score compared to the random baseline."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"corrs = []\n# Calculate probability of some prediction and sample according to those probabilities\nfor col in target_cols:\n    probs = df[col].value_counts().values / len(df)\n    vals = list(df[col].value_counts().index)\n    naive_preds = np.random.choice(vals, len(df), p=probs)\n    corr = spearmanr(naive_preds, df[col])[0]\n    corrs.append(corr)\ndist_baseline = np.mean(corrs)\nprint(f\"Spearman's Rho Score for sampling from calculated distribution: {round(dist_baseline, 6)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optimizing Spearman's Rho <a id=\"6\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In essence there are two choices to optimize for the Spearman's Rho score (in this competition):\n\n1. Use binary_crossentropy since it is essentially a binary classification problem.\n2. Implement a custom loss function to optimize Spearman's Rho directly."},{"metadata":{},"cell_type":"markdown","source":"### 1. Use binary_crossentropy"},{"metadata":{},"cell_type":"markdown","source":"Binary Crossentropy is a common loss function that is already implemented in most libraries. Just select \"binary_crossentropy\" as a loss function in the Machine Learning library of your choice. ;)"},{"metadata":{},"cell_type":"markdown","source":"### 2. Optimize Spearman's Rho directly"},{"metadata":{},"cell_type":"markdown","source":"Spearman's Rho can be formulated as a loss function, so it can be used to directly optimize a Machine Learning model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO Spearman Correlation loss function for Tensorflow 2.0+","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission <a id=\"7\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in sample submission file\nsub_df = pd.read_csv(SUB_PATH)\n\n# Make random predictions\nfor col in target_cols:\n    naive_preds = np.random.rand(len(sub_df))\n    sub_df[col] = naive_preds.round(6)\n    \nsub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Final predictions:')\nsub_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unfortunately I have not found a way to get a naive baseline that performs better than random uniform. Please let me know in the comments if there is a way to do better than random. I will implement it in this kernel."},{"metadata":{},"cell_type":"markdown","source":"**That's it! If you like this Kaggle kernel, feel free to give an upvote and leave a comment! Your feedback is also very welcome! I will try to implement your suggestions in this kernel!**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}