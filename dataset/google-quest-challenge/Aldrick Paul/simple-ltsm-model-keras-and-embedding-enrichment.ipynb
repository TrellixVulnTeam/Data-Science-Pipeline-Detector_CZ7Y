{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from datetime import datetime\nstartTime = datetime.now()\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nfrom numpy import array\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers.core import Activation, Dropout, Dense\nfrom keras.layers import Flatten, LSTM\nfrom keras.layers import GlobalMaxPooling1D\nfrom keras.models import Model\nfrom keras.layers.embeddings import Embedding\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Input\nfrom keras.layers.merge import Concatenate\nimport os\nimport pandas as pd\nimport numpy as np\nimport re\nimport gc\n\nimport json\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom numpy import array\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers.core import Activation, Dropout, Dense\nfrom keras.layers import Flatten, LSTM\nfrom keras.layers import GlobalMaxPooling1D\nfrom keras.models import Model\nfrom keras.layers.embeddings import Embedding\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Input\nfrom keras.layers.merge import Concatenate\n\nimport pandas as pd\nimport numpy as np\nimport re\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom numpy import array\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers.core import Activation, Dropout, Dense\nfrom keras.layers import Flatten, LSTM\nfrom keras.layers import GlobalMaxPooling1D\nfrom keras.models import Model\nfrom keras.layers.embeddings import Embedding\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Input\nfrom keras.layers.merge import Concatenate\nimport os\nimport pandas as pd\nimport numpy as np\nimport re\nimport gc\nimport numpy as np\nfrom tqdm import tqdm\nfrom numpy import array\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers.core import Activation, Dropout, Dense\nfrom keras.layers import Flatten, LSTM\nfrom keras.layers import GlobalMaxPooling1D\nfrom keras.models import Model\nfrom keras.layers.embeddings import Embedding\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Input\nfrom keras.layers.merge import Concatenate\nimport os\nimport pandas as pd\nimport numpy as np\nimport re\nimport gc\n\nimport json\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom numpy import array\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers.core import Activation, Dropout, Dense\nfrom keras.layers import Flatten, LSTM\nfrom keras.layers import GlobalMaxPooling1D\nfrom keras.models import Model\nfrom keras.layers.embeddings import Embedding\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Input\nfrom keras.layers.merge import Concatenate\n\nimport pandas as pd\nimport numpy as np\nimport re\n\nimport matplotlib.pyplot as plt\n\nfrom keras.layers import Input, Embedding, LSTM, Dense , concatenate, Bidirectional,CuDNNLSTM\nfrom keras.models import Model\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.preprocessing import text, sequence\nfrom gensim.models import KeyedVectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(x):\n\n    x = str(x)\n    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^`{|}~' + '“”’':\n        x = x.replace(punct, f' {punct} ')\n   \n    for punct in '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—_':\n        x = x.replace(punct, f' {punct} ')\n \n    return x\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\n\nmispell_dict = {\"usepackage\" : \"use package\",\n                'instrumentsettingsid':'instrumental settings id',\n                'RippleShaderProgram' : 'ripple shader program',\n                'ShaderProgramConstants':'shader program constants',\n                'storedElements':'stored elements',\n                'stackSize' : 'stack size',\n                '_':' '\n\n                }\nmispellings, mispellings_re = _get_mispell(mispell_dict)\n\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')\ntest_df = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"question_body\"] = train_df[\"question_body\"].apply(lambda x: clean_text(x))\ntrain_df[\"question_body\"] = train_df[\"question_body\"].apply(lambda x: replace_typical_misspell(x))\n\ntrain_df[\"question_title\"] = train_df[\"question_title\"].apply(lambda x: clean_text(x))\ntrain_df[\"question_title\"] = train_df[\"question_title\"].apply(lambda x: replace_typical_misspell(x))\n\ntrain_df[\"category\"] = train_df[\"category\"].apply(lambda x: clean_text(x))\ntrain_df[\"category\"] = train_df[\"category\"].apply(lambda x: replace_typical_misspell(x))\n\ntrain_df[\"answer\"] = train_df[\"answer\"].apply(lambda x: clean_text(x))\ntrain_df[\"answer\"] = train_df[\"answer\"].apply(lambda x: replace_typical_misspell(x))\n\ntest_df[\"question_body\"] = test_df[\"question_body\"].apply(lambda x: clean_text(x))\ntest_df[\"question_body\"] = test_df[\"question_body\"].apply(lambda x: replace_typical_misspell(x))\n\ntest_df[\"question_title\"] = test_df[\"question_title\"].apply(lambda x: clean_text(x))\ntest_df[\"question_title\"] = test_df[\"question_title\"].apply(lambda x: replace_typical_misspell(x))\n\ntest_df[\"category\"] = test_df[\"category\"].apply(lambda x: clean_text(x))\ntest_df[\"category\"] = test_df[\"category\"].apply(lambda x: replace_typical_misspell(x))\n\ntest_df[\"answer\"] = test_df[\"answer\"].apply(lambda x: clean_text(x))\ntest_df[\"answer\"] = test_df[\"answer\"].apply(lambda x: replace_typical_misspell(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_body = train_df['question_body']\nanswer = train_df['answer']\nquestion_title = train_df[\"question_title\"]\ncategory = train_df[\"category\"]\n\nquestion_body_test = test_df['question_body']\nanswer_test = test_df['answer']\nquestion_title_test = test_df[\"question_title\"]\ncategory_test = test_df[\"category\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train_df[train_df.columns[-30:]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_text = pd.concat([train_df['question_body'],train_df['answer'],test_df['question_body'],test_df['answer'],train_df[\"question_title\"],train_df[\"category\"],test_df[\"question_title\"],test_df[\"category\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=1000000, lower=False,filters='')\n\ntokenizer.fit_on_texts(all_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_body = tokenizer.texts_to_sequences(question_body)\nanswer = tokenizer.texts_to_sequences(answer)\nquestion_title = tokenizer.texts_to_sequences(question_title)\ncategory = tokenizer.texts_to_sequences(category)\n\nquestion_body_test = tokenizer.texts_to_sequences(question_body_test)\nanswer_test = tokenizer.texts_to_sequences(answer_test)\nquestion_title_test = tokenizer.texts_to_sequences(question_title_test)\ncategory_test = tokenizer.texts_to_sequences(category_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens = []\nfor i in question_body:\n    lens.append(len(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\n\nmaxlen = 245\n\nquestion_body = pad_sequences(question_body, padding='post', maxlen=maxlen)\nanswer = pad_sequences(answer, padding='post', maxlen=maxlen)\nquestion_title = pad_sequences(question_title, padding='post', maxlen=maxlen)\ncategory = pad_sequences(category, padding='post', maxlen=maxlen)\n\n\nquestion_body_test = pad_sequences(question_body_test, padding='post', maxlen=maxlen)\nanswer_test = pad_sequences(answer_test, padding='post', maxlen=maxlen)\nquestion_title_test = pad_sequences(question_title_test, padding='post', maxlen=maxlen)\ncategory_test = pad_sequences(category_test, padding='post', maxlen=maxlen)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Embedding, LSTM, Dense , concatenate, Bidirectional,CuDNNLSTM\nfrom keras.models import Model\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.preprocessing import text, sequence\nfrom gensim.models import KeyedVectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_matrix(word_index, path):\n    embedding_index = KeyedVectors.load(path, mmap='r')\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    for word, i in word_index.items():\n        for candidate in [word, word.lower()]:\n            if candidate in embedding_index:\n                embedding_matrix[i] = embedding_index[candidate]\n                break\n    return embedding_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EMBEDDING_FILES = [\n    '../input/gensim-embeddings-dataset/crawl-300d-2M.gensim',\n    '../input/gensim-embeddings-dataset/glove.840B.300d.gensim'\n]\nNUM_MODELS = 3\nBATCH_SIZE = 128\nLSTM_UNITS = 64\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\nEPOCHS = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = np.concatenate(\n    [build_matrix(tokenizer.word_index, f) for f in EMBEDDING_FILES], axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(embedding_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp1 = Input(shape=(None,))\ninp2 = Input(shape=(None,))\ninp3 = Input(shape=(None,))\ninp4 = Input(shape=(None,))\nwords = concatenate([inp1,inp2,inp3,inp4])\nx = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\nx = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\nx = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n\nhidden = concatenate([\n        GlobalMaxPooling1D()(x),\n        GlobalAveragePooling1D()(x),\n    ])\nhidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\nhidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\nresult = Dense(30, activation='sigmoid')(hidden)\nmodel = Model(inputs=[inp1,inp2,inp3,inp4], outputs=[result])\nmodel.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(datetime.now() - startTime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n           [question_body,question_title,category,answer], [target],\n            batch_size=128,\n            epochs=10,\n            verbose=1,\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict([question_body_test,question_title_test,category_test,answer_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/google-quest-challenge/sample_submission.csv\")\n\nfor col_index, col in enumerate(target_cols):\n    sub[col] = predictions[:, col_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}