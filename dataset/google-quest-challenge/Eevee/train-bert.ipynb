{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport gc\nimport random\nimport re\nfrom tqdm.notebook import tqdm\nimport numpy as np\nfrom collections import deque\n\nsys.path.extend(['../input/transformer/', '../input/sacremoses/sacremoses-master/'])\n\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom scipy.stats import spearmanr\n    \nimport torch\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, Dataset\nfrom torch import nn\nfrom torch.nn import Module\n\nimport transformers\nfrom transformers import BertTokenizer, BertConfig, BertPreTrainedModel, BertModel\nfrom transformers import AlbertTokenizer, AlbertConfig, AlbertModel, AlbertPreTrainedModel\nfrom transformers.tokenization_bert import BasicTokenizer, whitespace_tokenize\nfrom transformers.optimization import AdamW, get_linear_schedule_with_warmup\n\nfrom nltk.corpus import stopwords\n\nstop_word = set(stopwords.words('english'))\nprint(len(stop_word))\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean text"},{"metadata":{"trusted":true},"cell_type":"code","source":"#clean data\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\xa0', '\\t',\n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\nmispell_dict = {\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"couldnt\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"doesnt\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"havent\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"shouldnt\" : \"should not\",\n\"that's\" : \"that is\",\n\"thats\" : \"that is\",\n\"there's\" : \"there is\",\n\"theres\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"theyre\":  \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"}\n\n\ndef clean_text(x):\n    x = str(x).replace(\"\\n\",\"\")\n    for punct in puncts:\n        x = x.replace(punct, ' '+punct+' ')\n    return x\n\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x\n\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\n\ndef replace_typical_misspell(text):\n    mispellings, mispellings_re = _get_mispell(mispell_dict)\n\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)\n\ndef remove_space(string):\n    string = BeautifulSoup(string).text.strip().lower()\n    string = re.sub(r'\\s+', ' ', string)\n    string = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' url ', string)\n    return string\n\n\ndef clean_data(df, columns: list):\n    \n    for col in columns:\n        df[col] = df[col].apply(lambda x: remove_space(x).lower())        \n        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n        df[col] = df[col].apply(lambda x: clean_text(x))\n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/google-quest-challenge/'\ntrain_path = path + 'train.csv'\ntest_path = path + 'test.csv'\nsubmission_path = path + 'sample_submission.csv'\n\npath_model = '../input/pretrained-bert-models-for-pytorch/'\npath_albert = '../input/albert-large/albert-large-pytorch_model.bin'\nconfig_albert = '../input/albert-large/albert-large-config.json'\n\nmodel_file = path_model + 'bert-base-uncased/pytorch_model.bin'\nconfig_file = path_model + 'bert-base-uncased/bert_config.json'\nvocab_file = path_model + 'bert-base-uncased-vocab.txt'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train file"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(train_path)\nprint(train.columns)\ntrain.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test file"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(test_path)\nprint(test.columns)\ntest.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(submission_path)\ntarget = submission.columns[1:].to_list()\nprint(len(target))\n\ninput_columns = ['question_title', 'question_body', 'answer']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train dev split"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain = clean_data(train, input_columns)\ntest = clean_data(test, input_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of query and answer"},{"metadata":{"trusted":true},"cell_type":"code","source":"question_title = train.question_title.apply(lambda x:len(x.split(' ')))\nprint(max(question_title))\nplt.figure(figsize=(10, 8))\nsns.distplot(question_title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_body = train.question_body.apply(lambda x:len(x.split(' ')))\n\nplt.figure(figsize=(10, 8))\nsns.distplot(question_body)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = train.answer.apply(lambda x:len(x.split(' ')))\n\nplt.figure(figsize=(10, 8))\nsns.distplot(answer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class QueryDataset(Dataset):\n    \n    def __init__(self, data, is_train=True, max_query_title = 46, max_length=512):\n        \n        super(QueryDataset, self).__init__()\n        \n        self.max_length = max_length\n        self.max_query_title = max_query_title\n        self.data = data\n        self.is_train = is_train\n        self.tokenizer = BertTokenizer.from_pretrained(vocab_file, do_lower_case=True, do_basic_tokenize=True)\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        token_ids, segment_ids = self.get_token_ids(idx)\n        \n        if self.is_train:\n            label = torch.tensor(self.data.loc[idx, target], dtype=torch.float32)\n            return token_ids, segment_ids, label\n        else:\n            return token_ids, segment_ids\n        \n    \n    def get_token_ids(self, idx):\n        \n        t = self.tokenizer.tokenize(self.data.loc[idx, input_columns[0]])\n        b = self.tokenizer.tokenize(self.data.loc[idx, input_columns[1]])\n        a = self.tokenizer.tokenize(self.data.loc[idx, input_columns[2]])\n        \n        t_len, b_len, a_len = len(t), len(b), len(a)\n        all_len = t_len + b_len + a_len + 4\n        max_query_body = (self.max_length - self.max_query_title - 4)//2\n        max_seq_length = self.max_length - 4 - self.max_query_title - max_query_body\n        \n        if all_len > self.max_length:            \n            if t_len < self.max_query_title:\n                t_new_len = t_len\n                max_query_body = (self.max_length - t_len - 4)//2\n                max_seq_length = self.max_length - 4 - t_new_len - max_query_body\n            else:\n                t_new_len = self.max_query_title\n                \n            if a_len < max_seq_length:\n                a_new_len = a_len\n                b_new_len = max_query_body + (max_seq_length - a_len)\n            elif b_len < max_query_body:                \n                a_new_len = max_seq_length + (max_query_body - b_len)\n                b_new_len = b_len\n            else:\n                a_new_len = max_seq_length\n                b_new_len = max_query_body\n        else:\n            t_new_len, b_new_len, a_new_len = t_len, b_len, a_len\n                                                 \n                                                         \n        token = ['[CLS]'] + t[:t_new_len] + ['[SEP]'] + b[:b_new_len] + ['[SEP]'] + a[:a_new_len] + ['[SEP]']\n        token_ids_org = self.tokenizer.convert_tokens_to_ids(token)\n       \n        if len(token_ids_org) < self.max_length:\n            token_ids = token_ids_org + [0]*(self.max_length - len(token_ids_org))\n        else:\n            token_ids = token_ids_org[:self.max_length]\n            \n        token_ids = torch.tensor(token_ids)\n        segment_ids = [1]*len(token_ids_org)        \n        \n        sep_one = True\n        for index, tk in enumerate(token_ids_org): \n            segment_ids[index] = 0\n            if tk == 102:\n                if sep_one:\n                    sep_one = False\n                else:\n                    break                    \n        \n        segment_ids += [0]*(self.max_length - len(token_ids_org))\n        segment_ids = torch.tensor(segment_ids)\n        del token_ids_org\n        \n        return token_ids, segment_ids\n                \n    def collate_fn(self, batch):\n        \n        token_ids = torch.stack([x[0] for x in batch])\n        segment_ids = torch.stack([x[1] for x in batch])\n        \n        if self.is_train:\n            label = torch.stack([x[2] for x in batch])\n            return token_ids, segment_ids, label\n        else:\n            return token_ids, segment_ids","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"config = BertConfig.from_json_file(config_file)\nconfig","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spearmanr"},{"metadata":{"trusted":true},"cell_type":"code","source":"def spearmanr_score(expected, pred):\n    score = deque()\n    expected, pred = expected.cpu().detach().numpy(), pred.cpu().detach().numpy()\n    for i in range(pred.shape[1]):\n        score.append(np.nan_to_num(spearmanr(expected[:, i], pred[:, i]).correlation))\n    \n    return np.mean(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertLinear(BertPreTrainedModel):\n    \n    def __init__(self, config, num_class):\n        super(BertLinear, self).__init__(config)\n        \n        self.bert = BertModel.from_pretrained(model_file, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.fc = nn.Linear(config.hidden_size, num_class)\n    \n    def forward(self, input_ids, segment_ids=None):\n        attention_mask = (input_ids > 1).float()\n        layer, pooler = self.bert(input_ids=input_ids,\n                                  attention_mask=attention_mask,\n                                  token_type_ids=segment_ids)\n        output = self.dropout(pooler)  \n        logits = self.fc(output)\n        \n        return logits\n    \n\ndef load_model(load_weight=True):\n    \n    models = []\n    config = BertConfig.from_json_file(config_file)\n    model = BertLinear(config, len(target)).to(device)\n    model = nn.DataParallel(model)\n    \n    if load_weight:\n        for weight in sorted(os.listdir('../input/train-bert')):\n            if 'pth' in weight:\n                weight_path = os.path.join('../input/train-bert', weight)\n                state = torch.load(weight_path, map_location=lambda storage, loc: storage)\n                models.append(state)\n    else:\n        model.to(device)\n        for i in range(5):            \n            models.append(model.state_dict())\n        \n    return models\n\nbase_model = load_model(True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train process"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Trainer(object):\n    \n    def __init__(self, config, base_model,\n                 weight_decay=0.1, learning_rate=2e-5):\n        \n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        \n        self.config = config\n        self.base_model = base_model\n        self.cretion = nn.MSELoss()\n        self.score = spearmanr_score\n    \n    def train(self, folds, epochs, train, check_number=5):\n        \n        model = BertLinear(config, len(target)).to(device)\n        model = nn.DataParallel(model)\n        \n        for fold, (train_index, val_index) in enumerate(KFold(n_splits=folds, shuffle=True).split(train)):\n            print(f'fold: {fold}')\n            val_score_max = 0\n        \n            train_df = train.iloc[train_index]\n            train_df.reset_index(inplace=True, drop=True)\n            \n            val_df = train.iloc[val_index]\n            val_df.reset_index(inplace=True, drop=True)\n            \n            model.load_state_dict(self.base_model[fold])\n            \n            optimizer = AdamW(model.parameters(),\n                              lr=self.learning_rate,\n                              weight_decay=self.weight_decay,\n                              correct_bias=False)\n        \n            \n            \n            train_dataset = QueryDataset(train_df)\n            train_ld = DataLoader(train_dataset, batch_size=8, shuffle=True,\n                                  num_workers=0, collate_fn=train_dataset.collate_fn)\n            \n            val_dataset = QueryDataset(val_df)\n            val_ld = DataLoader(val_dataset, batch_size=8, shuffle=True,\n                                num_workers=0, collate_fn=val_dataset.collate_fn)\n            \n            schedule = get_linear_schedule_with_warmup(optimizer,\n                                                       num_warmup_steps=0.05,\n                                                       num_training_steps=epochs*len(train_ld))\n            \n            del val_dataset, train_dataset, val_df, train_df\n            model.zero_grad()\n            check_score = 0\n            for epoch in range(epochs):\n                print(f'Epoch: {epoch}')\n                train_loss = 0\n                val_loss = 0\n\n                model.train()\n                for token_ids, segment_ids, label in tqdm(train_ld):\n\n                    optimizer.zero_grad()\n                    token_ids, segment_ids, label = token_ids.to(device), segment_ids.to(device), label.to(device)\n                    output = torch.sigmoid(model(token_ids, segment_ids))\n                    \n                    loss = self.cretion(output, label)\n                    loss.backward()\n                    train_loss += loss.item()\n                    \n                    optimizer.step()\n                    schedule.step()\n                    del token_ids, segment_ids, label\n                    \n                train_loss = train_loss/len(train_ld)\n                torch.cuda.empty_cache()\n                gc.collect()\n                \n                # evaluate process\n                model.eval()\n                score_val = 0\n                with torch.no_grad():\n                    for token_ids, segment_ids, label in tqdm(val_ld):\n                        token_ids, segment_ids, label = token_ids.to(device), segment_ids.to(device), label.to(device)\n\n                        output = torch.sigmoid(model(token_ids, segment_ids))\n                        loss = self.cretion(output, label)\n                        score_val += self.score(output, label)\n                        val_loss += loss.item()\n                    \n                    score_val = score_val/len(val_ld)\n                    val_loss = val_loss/len(val_ld)             \n                    \n                    \n                print(f'train_loss: {train_loss:.4f}, valid_loss: {val_loss:.4f}, valid_score: {score_val:.4f}')\n                schedule.step(val_loss)\n\n                if score_val >= val_score_max:\n                    check_score+=1\n                    print(f'Validation score increased ({val_score_max:.4f} --> {score_val:.4f}). Saving model...')\n                    val_score_max = score_val\n                    check_score = 0\n                    torch.save(model.state_dict(), f'model_fold_{str(fold)}.pth')\n                else:\n                    check_score += 1\n                    print(f'{check_score} epochs of decreasing val_score')\n\n                    if check_score > check_number:\n                        print('Stopping trainning!')                    \n                        break\n                        \n            del optimizer, schedule, train_ld, val_ld\n            torch.cuda.empty_cache()\n            \n            gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_process = Trainer(config, base_model)\n\ntrain_process.train(folds=5,\n                    epochs=5,\n                    train=train,\n                    check_number=5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}