{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import modules"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport time\nimport torch\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom math import floor, ceil\nfrom datetime import datetime\nfrom scipy.stats import spearmanr\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import GroupKFold\nfrom catalyst.utils import get_device, set_global_seed\nfrom transformers import BertModel, BertPreTrainedModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utils for loading data and calculating score"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data(BASE_PATH):\n    print('Reading train.csv file....')\n    train = pd.read_csv(BASE_PATH + 'train.csv')\n    print('Training.csv file have {} rows and {} columns'.format(\n        train.shape[0], train.shape[1]))\n\n    print('Reading test.csv file....')\n    test = pd.read_csv(BASE_PATH + 'test.csv')\n    print('Test.csv file have {} rows and {} columns'.format(\n        test.shape[0], test.shape[1]))\n\n    print('Reading sample_submission.csv file....')\n    sample_submission = pd.read_csv(BASE_PATH + 'sample_submission.csv')\n    print('Sample_submission.csv file have {} rows and {} columns'.format(\n        sample_submission.shape[0], sample_submission.shape[1]))\n    return train, test, sample_submission\n\nimport numpy as np\nfrom scipy.stats import spearmanr\n\n\ndef mean_spearmanr_correlation_score(y_true, y_pred):\n    num_labels = y_pred.shape[1]\n    score = np.nanmean([spearmanr(y_pred[:, col], y_true[:, col]).correlation\n                        for col in range(num_labels)])\n    return score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utils for preprocessing dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def compute_input_arrays(df, columns, tokenizer, max_sequence_length,\n                         t_max_len=30, q_max_len=239, a_max_len=239, head_tail=True):\n    input_ids, input_masks, input_segments = [], [], []\n    for _, instance in df[columns].iterrows():\n        # TODO: you will customize this stoken on each competition\n        t, q, a = instance.question_title, instance.question_body, instance.answer\n        t, q, a = _trim_input(t, q, a, tokenizer, max_sequence_length, t_max_len, q_max_len, a_max_len, head_tail)\n        stoken = [\"[CLS]\"] + t + [\"[SEP]\"] + q + [\"[SEP]\"] + a + [\"[SEP]\"]\n        ids, masks, segments = _convert_to_bert_inputs(stoken, tokenizer, max_sequence_length)\n        input_ids.append(ids)\n        input_masks.append(masks)\n        input_segments.append(segments)\n    return [\n        torch.from_numpy(np.asarray(input_ids, dtype=np.int32)).long(),\n        torch.from_numpy(np.asarray(input_masks, dtype=np.int32)).long(),\n        torch.from_numpy(np.asarray(input_segments, dtype=np.int32)).long(),\n    ]\n\n\ndef compute_output_arrays(df, columns):\n    # TODO: if label is int, dtype is torch.long\n    return torch.tensor(np.asarray(df[columns]), dtype=torch.float32)\n            \n\ndef _trim_input(title, question, answer, tokenizer, max_sequence_length,\n                t_max_len=30, q_max_len=239, a_max_len=239, head_tail=False):\n    # 239 + 239 + 30 = 508 + 4 = 512\n    t = tokenizer.tokenize(title)\n    q = tokenizer.tokenize(question)\n    a = tokenizer.tokenize(answer)\n\n    t_len = len(t)\n    q_len = len(q)\n    a_len = len(a)\n\n    if (t_len + q_len + a_len + 4) > max_sequence_length:\n\n        if t_max_len > t_len:\n            t_new_len = t_len\n            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n        else:\n            t_new_len = t_max_len\n\n        if a_max_len > a_len:\n            a_new_len = a_len\n            q_new_len = q_max_len + (a_max_len - a_len)\n        elif q_max_len > q_len:\n            a_new_len = a_max_len + (q_max_len - q_len)\n            q_new_len = q_len\n        else:\n            a_new_len = a_max_len\n            q_new_len = q_max_len\n\n        if t_new_len + a_new_len + q_new_len + 4 != max_sequence_length:\n            raise ValueError(\"New sequence length should be %d, but is %d\"\n                             % (max_sequence_length, (t_new_len + a_new_len + q_new_len + 4)))\n\n        # Head only\n        t = t[:t_new_len]\n        q = q[:q_new_len]\n        a = a[:a_new_len]\n\n        # Head + Tail\n        # https://arxiv.org/pdf/1905.05583.pdf\n        if head_tail:\n            q_len_head = q_new_len // 2\n            q_len_tail = - (q_new_len - q_len_head)\n            a_len_head = a_new_len // 2\n            a_len_tail = - (a_new_len - a_len_head)\n            q = q[:q_len_head] + q[q_len_tail:]\n            a = a[:a_len_head] + a[a_len_tail:]\n\n    return t, q, a\n\n\ndef _get_masks(tokens, max_seq_length):\n    \"\"\"Mask for padding\"\"\"\n    if len(tokens) > max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    return [1] * len(tokens) + [0] * (max_seq_length - len(tokens))\n\n\ndef _get_segments(tokens, max_seq_length):\n    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n\n    if len(tokens) > max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n\n    segments = []\n    first_sep = True\n    current_segment_id = 0\n\n    for token in tokens:\n        segments.append(current_segment_id)\n        if token == \"[SEP]\":\n            if first_sep:\n                first_sep = False\n            else:\n                current_segment_id = 1\n    return segments + [0] * (max_seq_length - len(tokens))\n\n\ndef _get_ids(tokens, tokenizer, max_seq_length):\n    \"\"\"Token ids from Tokenizer vocab\"\"\"\n    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n    input_ids = token_ids + [0] * (max_seq_length - len(token_ids))\n    return input_ids\n\n\ndef _convert_to_bert_inputs(stoken, tokenizer, max_sequence_length):\n    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n    input_masks = _get_masks(stoken, max_sequence_length)\n    input_segments = _get_segments(stoken, max_sequence_length)\n    return [input_ids, input_masks, input_segments]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset and model class"},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuestDataset(torch.utils.data.Dataset):\n    def __init__(self, inputs, lengths, labels=None):\n        self.inputs = inputs\n        self.lengths = lengths\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        input_ids = self.inputs[0][idx]\n        input_masks = self.inputs[1][idx]\n        input_segments = self.inputs[2][idx]\n        lengths = self.lengths[idx]\n        # for no target\n        if self.labels is None:\n            return input_ids, input_masks, input_segments, lengths\n\n        labels = self.labels[idx]\n        return input_ids, input_masks, input_segments, labels, lengths\n\n    def __len__(self):\n        return len(self.inputs[0])\n\n\nclass CustomBertForSequenceClassification(BertPreTrainedModel):\n    def __init__(self, config):\n        super(CustomBertForSequenceClassification, self).__init__(config)\n        self.n_use_layer = 4\n        self.bert = BertModel(config)\n        self.dense = nn.Linear(768*self.n_use_layer, 768*self.n_use_layer)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(768*self.n_use_layer, config.num_labels)\n        self.init_weights()\n\n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None,\n        labels=None,\n    ):\n\n        # outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]\n        # https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel.forward\n        outputs = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=inputs_embeds,\n        )\n\n        # gererally, we pool outputs[0] using GlobalAveragePooling\n        # outputs[0] : all output of last layer\n        # outputs[1] : [CLS] output of last layer\n        # outputs[2] : input embedding + 12 hidden layer output\n        pooled_output = torch.cat([\n            outputs[2][-1*i][:, 0] for i in range(1, self.n_use_layer+1)\n        ], dim=1)\n        pooled_output = self.dense(pooled_output)\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        # add hidden states and attention if they are here\n        outputs = (logits,) + outputs[2:]\n        return outputs  # (loss), logits, (hidden_states), (attentions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## My original pytorch runner"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertRunner:\n    def __init__(self, device='cpu'):\n        self.device = device\n\n    def train(self, model, criterion, optimizer, loaders, scheduler=None, logdir=None,\n              num_epochs=5, score_func=None):\n        model = model.to(self.device)\n        train_loader = loaders['train']\n        valid_loader = loaders['valid']\n        best_score = -1.0\n        best_avg_val_loss = 100\n        for epoch in range(num_epochs):\n            start_time = time.time()\n            # release memory\n            torch.cuda.empty_cache()\n            gc.collect()\n            # train for one epoch\n            avg_loss = self._train_model(model, criterion, optimizer, train_loader, scheduler)\n            # evaluate on validation set\n            avg_val_loss, score = self._validate_model(model, criterion, valid_loader, score_func)\n\n            # log\n            elapsed_time = time.time() - start_time\n            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t score={:.6f} \\t time={:.2f}s'.format(\n                epoch + 1, num_epochs, avg_loss, avg_val_loss, score, elapsed_time))\n\n            # save best params\n            save_path = 'best_model.pth'\n            if logdir is not None:\n                save_path = os.path.join(logdir, save_path)\n\n            if score is None:\n                if best_avg_val_loss > avg_val_loss:\n                    best_avg_val_loss = avg_val_loss\n                    best_param_loss = model.state_dict()\n                    torch.save(best_param_loss, save_path)\n                    print('Save the best model on Epoch {}'.format(epoch + 1))\n            else:\n                if best_score < score:\n                    best_score = score\n                    best_param_score = model.state_dict()\n                    torch.save(best_param_score, save_path)\n                    print('Save the best model on Epoch {}'.format(epoch + 1))\n\n        return True\n\n    def predict_loader(self, model, loader, resume='best_model.pth'):\n        model = model.to(self.device)\n        # load best model\n        model.load_state_dict(torch.load(resume))\n        model.eval()\n        preds = []\n        # prediction\n        with torch.no_grad():\n            for idx, batch in tqdm(enumerate(loader), total=len(loader)):\n                input_ids, input_masks, input_segments, labels, _ = batch\n                input_ids = input_ids.to(self.device)\n                input_masks = input_masks.to(self.device)\n                input_segments = input_segments.to(self.device)\n                labels = labels.to(self.device)\n\n                # output\n                output_valid = model(\n                    input_ids=input_ids,\n                    labels=None,\n                    attention_mask=input_masks,\n                    token_type_ids=input_segments,\n                )\n                logits = output_valid[0]  # output preds\n                preds.extend(logits.detach().cpu().squeeze().numpy())\n\n            # TODO : you should write your process\n            preds = np.array(preds)\n            preds = torch.sigmoid(torch.tensor(preds)).numpy()\n\n        return preds\n\n    def _train_model(self, model, criterion, optimizer, train_loader, scheduler=None):\n        # switch to train mode\n        model.train()\n        avg_loss = 0.0\n        for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n            input_ids, input_masks, input_segments, labels, _ = batch\n            input_ids = input_ids.to(self.device)\n            input_masks = input_masks.to(self.device)\n            input_segments = input_segments.to(self.device)\n            labels = labels.to(self.device)\n\n            # bert training\n            output_train = model(\n                input_ids=input_ids,\n                labels=None,\n                attention_mask=input_masks,\n                token_type_ids=input_segments,\n            )\n            logits = output_train[0]  # output preds\n            loss = criterion(logits, labels)\n\n            # update params\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            # the position of this depends on the scheduler you use\n            if scheduler is not None:\n                scheduler.step()\n\n            # calc loss\n            avg_loss += loss.item() / len(train_loader)\n\n        return avg_loss\n\n    def _validate_model(self, model, criterion, valid_loader, score_func=None):\n        # switch to eval mode\n        model.eval()\n        avg_val_loss = 0.\n        valid_preds = []\n        original = []\n        with torch.no_grad():\n            for idx, batch in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n                input_ids, input_masks, input_segments, labels, _ = batch\n                input_ids = input_ids.to(self.device)\n                input_masks = input_masks.to(self.device)\n                input_segments = input_segments.to(self.device)\n                labels = labels.to(self.device)\n\n                # output\n                output_valid = model(\n                    input_ids=input_ids,\n                    labels=None,\n                    attention_mask=input_masks,\n                    token_type_ids=input_segments,\n                )\n                logits = output_valid[0]  # output preds\n\n                # calc score\n                avg_val_loss += criterion(logits, labels).item() / len(valid_loader)\n                valid_preds.extend(logits.detach().cpu().squeeze().numpy())\n                original.extend(labels.detach().cpu().squeeze().numpy())\n\n            score = None\n            if score_func is not None:\n                # TODO : you should write valid score calculation\n                # In this case, we pass sigmoid function\n                valid_preds = np.array(valid_preds)\n                original = np.array(original)\n                preds = torch.sigmoid(torch.tensor(valid_preds)).numpy()\n                score = score_func(original, preds)\n\n        return avg_val_loss, score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train setting\nnum_folds = 5\nseed = 1234\nbase_dataset_path = '../input/google-quest-challenge/'\nbatch_size = 4\nnum_epochs = 3\nbert_model = 'bert-base-uncased'\nbase_logdir = './'\n\n# fix seed\nset_global_seed(seed)\ndevice = get_device()\n\n# set up logdir\nnow = datetime.now()\nbase_logdir = os.path.join(base_logdir, now.strftime(\"%Y_%m_%d\"))\nos.makedirs(base_logdir, exist_ok=True)\n\n# load dataset\n# TODO: set your dataset\ntrain, test, sample_submission = read_data(base_dataset_path)\ninput_cols = list(train.columns[[1, 2, 5]])\ntarget_cols = list(train.columns[11:])\nnum_labels = len(target_cols)\n\n# init Bert\ntokenizer = BertTokenizer.from_pretrained(bert_model)\n\n# execute CV\n# TODO: set your CV method\nkf = GroupKFold(n_splits=num_folds)\nids = kf.split(train['question_body'], groups=train['question_body'])\nfold_scores = []\nfor fold, (train_idx, valid_idx) in enumerate(ids):\n    print(\"Current Fold: \", fold + 1)\n    logdir = os.path.join(base_logdir, 'fold_{}'.format(fold + 1))\n    os.makedirs(logdir, exist_ok=True)\n\n    # create dataloader\n    train_df, val_df = train.iloc[train_idx], train.iloc[valid_idx]\n    print(\"Train and Valid Shapes are\", train_df.shape, val_df.shape)\n\n    print(\"Preparing train datasets....\")\n    inputs_train = compute_input_arrays(train_df, input_cols, tokenizer, max_sequence_length=512)\n    outputs_train = compute_output_arrays(train_df, columns=target_cols)\n    lengths_train = np.argmax(inputs_train[0] == 0, axis=1)\n    lengths_train[lengths_train == 0] = inputs_train[0].shape[1]\n\n    print(\"Preparing valid datasets....\")\n    inputs_valid = compute_input_arrays(val_df, input_cols, tokenizer, max_sequence_length=512)\n    outputs_valid = compute_output_arrays(val_df, columns=target_cols)\n    lengths_valid = np.argmax(inputs_valid[0] == 0, axis=1)\n    lengths_valid[lengths_valid == 0] = inputs_valid[0].shape[1]\n\n    print(\"Preparing dataloaders datasets....\")\n    train_set = QuestDataset(inputs=inputs_train, lengths=lengths_train, labels=outputs_train)\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n    valid_set = QuestDataset(inputs=inputs_valid, lengths=lengths_valid, labels=outputs_valid)\n    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n\n    # init models\n    model = CustomBertForSequenceClassification.from_pretrained(\n        bert_model, num_labels=num_labels, output_hidden_states=True)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=0.05, num_training_steps=num_epochs * len(train_loader)\n    )\n\n    # model training\n    runner = BertRunner(device=device)\n    loaders = {'train': train_loader, 'valid': valid_loader}\n    print(\"Model Training....\")\n    runner.train(model=model, criterion=criterion, optimizer=optimizer, scheduler=scheduler,\n                 loaders=loaders, logdir=logdir, num_epochs=num_epochs,\n                 score_func=mean_spearmanr_correlation_score)\n\n    # calc valid score\n    best_model_path = os.path.join(logdir, 'best_model.pth')\n    val_preds = runner.predict_loader(model, loaders['valid'], resume=best_model_path)\n    val_truth = train[target_cols].iloc[valid_idx].values\n    # TODO: set your score function\n    cv_score = mean_spearmanr_correlation_score(val_truth, val_preds)\n    print('Fold {} CV score : {}'.format(fold + 1, cv_score))\n    fold_scores.append(cv_score)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}