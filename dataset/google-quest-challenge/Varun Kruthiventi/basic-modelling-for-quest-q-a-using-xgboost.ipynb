{"cells":[{"metadata":{},"cell_type":"markdown","source":"Objective of this kernel is to present a base line modelling using XGBoost. \nFor the sake of simplicity, I am only considering the Question related text and answer of modelling and ignoring all other features"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\n\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"INPUT_PATH = \"/kaggle/input/google-quest-challenge/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(INPUT_PATH + \"train.csv\")\ntest = pd.read_csv(INPUT_PATH + \"test.csv\")\nsample_submission = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} observations, {} columns\".format(train.shape[0], train.shape[1]))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} observations, {} columns\".format(test.shape[0], test.shape[1]))\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} observations, {} columns\".format(sample_submission.shape[0], sample_submission.shape[1]))\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = train.columns\ncolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_features = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For initial modelling, I am considering 'question_title', 'question_body', 'answer' as training features which need to be vectorized"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_features = ['question_title', 'question_body', 'answer']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Pre-processing and Vectorizing"},{"metadata":{},"cell_type":"markdown","source":"Source:\n[https://www.kaggle.com/enzoamp/nb-svm-strong-linear-baseline-w-category-dummies](https://www.kaggle.com/enzoamp/nb-svm-strong-linear-baseline-w-category-dummies)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re, string\nre_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\n\ntsvd = TruncatedSVD(n_components = 50)\n\ntrain_question_title_doc = vec.fit_transform(train['question_title'].values)\ntest_question_title_doc = vec.transform(test['question_title'].values)\n\ntrain_question_title_doc = tsvd.fit_transform(train_question_title_doc)\ntest_question_title_doc = tsvd.transform(test_question_title_doc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec_qbody = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\n\ntsvd = TruncatedSVD(n_components = 50)\n\ntrain_question_body_doc = vec_qbody.fit_transform(train['question_body'].values)\ntest_question_body_doc = vec_qbody.transform(test['question_body'].values)\n\ntrain_question_body_doc = tsvd.fit_transform(train_question_body_doc)\ntest_question_body_doc = tsvd.transform(test_question_body_doc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec_answer = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\n\ntsvd = TruncatedSVD(n_components = 50)\n\ntrain_answer_doc = vec_answer.fit_transform(train['answer'].values)\ntest_answer_doc = vec_answer.transform(test['answer'].values)\n\ntrain_answer_doc = tsvd.fit_transform(train_answer_doc)\ntest_answer_doc = tsvd.transform(test_answer_doc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate([train_question_title_doc, train_question_body_doc, train_answer_doc], axis=1)\nX_test = np.concatenate([test_question_title_doc, test_question_body_doc, test_answer_doc], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"printt(X_train.shape)\nprintt(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_xbg_model(target_feature):\n    xgb_model = xgb.XGBRegressor(learning_rate = 0.1, n_estimators=1000,\n                           max_depth=5, min_child_weight=1,\n                           gamma=0, subsample=0.8,\n                           colsample_bytree=0.8, objective= \"binary:logistic\",  \n                           nthread=-1, scale_pos_weight=1, random_state=2019, seed=2019)\n    xgb_model.fit(X_train, train[target_feature])\n    y_pred = xgb_model.predict(X_test)\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in target_features:\n    print(\"------------------------------\")\n    print(f\"Traning for {feature}\")\n    sample_submission[feature] = train_xbg_model(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}