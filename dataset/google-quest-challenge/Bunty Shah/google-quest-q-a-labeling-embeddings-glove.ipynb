{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, Dropout, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import LearningRateScheduler\nimport time\nimport pickle\nimport re\nfrom tqdm._tqdm_notebook import tqdm_notebook as tqdm\ntqdm.pandas()\nfrom pathlib import Path\nfrom scipy.stats import spearmanr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"GLOVE_EMBEDDING_PATH = '../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndatadir = Path('/kaggle/input/google-quest-challenge')\n\n# Read in the data CSV files\ntrain = pd.read_csv(datadir/'train.csv')\ntest = pd.read_csv(datadir/'test.csv')\nsample_submission = pd.read_csv(datadir/'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")\ntest = pd.read_csv(\"../input/google-quest-challenge/test.csv\")\ntrain = pd.read_csv(\"../input/google-quest-challenge/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = [col for col in train.columns if col not in sample_submission.columns]\nprint(\"Feature columns are \" , feature_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can use other columns later\ncol_to_use = ['question_title', 'question_body', 'answer', 'category']\ntrain[col_to_use].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nlbl = preprocessing.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl.fit(list(train['category'].values))\ntrain['category'] = lbl.transform(list(train['category'].values))\nlbl.fit(list(test['category'].values))\ntest['category'] = lbl.transform(list(test['category'].values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing for embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adjusting the load_embeddings function, to now handle the pickled dict.\n\ndef get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\n\ndef load_embeddings(path):\n    with open(path,'rb') as f:\n        emb_arr = pickle.load(f)\n    return emb_arr\n\ndef build_matrix(word_index, path):\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    unknown_words = []\n    \n    for word, i in word_index.items():\n        try:\n            embedding_matrix[i] = embedding_index[word]\n        except KeyError:\n            unknown_words.append(word)\n    return embedding_matrix, unknown_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import operator \n\ndef check_coverage(vocab,embeddings_index):\n    a = {}\n    oov = {}\n    k = 0\n    i = 0\n    for word in tqdm(vocab):\n        try:\n            a[word] = embeddings_index[word]\n            k += vocab[word]\n        except:\n\n            oov[word] = vocab[word]\n            i += vocab[word]\n            pass\n\n    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n\n    return sorted_x\n\ndef build_vocab(sentences, verbose =  True):\n    \"\"\"\n    :param sentences: list of list of words\n    :return: dictionary of words and their count\n    \"\"\"\n    vocab = {}\n    for sentence in tqdm(sentences, disable = (not verbose)):\n        for word in sentence:\n            try:\n                vocab[word] += 1\n            except KeyError:\n                vocab[word] = 1\n    return vocab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets load GLOVE Embb question_title"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets load the embeddings \ntic = time.time()\nglove_embeddings = load_embeddings(GLOVE_EMBEDDING_PATH)\nprint(f'loaded {len(glove_embeddings)} word vectors in {time.time()-tic}s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check how many words we got covered \nvocab = build_vocab(list(train['question_title'].apply(lambda x:x.split())))\noov = check_coverage(vocab,glove_embeddings)\noov[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nlatin_similar = \"’'‘ÆÐƎƏƐƔĲŊŒẞÞǷȜæðǝəɛɣĳŋœĸſßþƿȝĄƁÇĐƊĘĦĮƘŁØƠŞȘŢȚŦŲƯY̨Ƴąɓçđɗęħįƙłøơşșţțŧųưy̨ƴÁÀÂÄǍĂĀÃÅǺĄÆǼǢƁĆĊĈČÇĎḌĐƊÐÉÈĖÊËĚĔĒĘẸƎƏƐĠĜǦĞĢƔáàâäǎăāãåǻąæǽǣɓćċĉčçďḍđɗðéèėêëěĕēęẹǝəɛġĝǧğģɣĤḤĦIÍÌİÎÏǏĬĪĨĮỊĲĴĶƘĹĻŁĽĿʼNŃN̈ŇÑŅŊÓÒÔÖǑŎŌÕŐỌØǾƠŒĥḥħıíìiîïǐĭīĩįịĳĵķƙĸĺļłľŀŉńn̈ňñņŋóòôöǒŏōõőọøǿơœŔŘŖŚŜŠŞȘṢẞŤŢṬŦÞÚÙÛÜǓŬŪŨŰŮŲỤƯẂẀŴẄǷÝỲŶŸȲỸƳŹŻŽẒŕřŗſśŝšşșṣßťţṭŧþúùûüǔŭūũűůųụưẃẁŵẅƿýỳŷÿȳỹƴźżžẓ\"\nwhite_list = string.ascii_letters + string.digits + latin_similar + ' '\nwhite_list += \"'\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_chars = ''.join([c for c in tqdm(glove_embeddings) if len(c) == 1])\nglove_symbols = ''.join([c for c in glove_chars if not c in white_list])\nglove_symbols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jigsaw_chars = build_vocab(list(train[\"question_title\"]))\njigsaw_symbols = ''.join([c for c in jigsaw_chars if not c in white_list])\njigsaw_symbols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"symbols_to_delete = ''.join([c for c in jigsaw_symbols if not c in glove_symbols])\nsymbols_to_delete","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"symbols_to_isolate = ''.join([c for c in jigsaw_symbols if c in glove_symbols])\nsymbols_to_isolate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"isolate_dict = {ord(c):f' {c} ' for c in symbols_to_isolate}\nremove_dict = {ord(c):f'' for c in symbols_to_delete}\n\ndef handle_punctuation(x):\n    x = x.translate(remove_dict)\n    x = x.translate(isolate_dict)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['question_title'] = train['question_title'].progress_apply(lambda x:handle_punctuation(x))\ntest['question_title'] = test['question_title'].progress_apply(lambda x:handle_punctuation(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize.treebank import TreebankWordTokenizer\ntokenizer = TreebankWordTokenizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def handle_contractions(x):\n    x = tokenizer.tokenize(x)\n    x = ' '.join(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['question_title'] = train['question_title'].progress_apply(lambda x:handle_contractions(x))\ntest['question_title'] = test['question_title'].progress_apply(lambda x:handle_contractions(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_quote(x):\n    x = [x_[1:] if x_.startswith(\"'\") else x_ for x_ in x]\n    x = ' '.join(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['question_title'] = train['question_title'].progress_apply(lambda x:fix_quote(x.split()))\ntest['question_title'] = test['question_title'].progress_apply(lambda x:fix_quote(x.split()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question Body\n\n1. Use SPL char Embeddings\n2. Tokenize \n3. Fix quote"},{"metadata":{"trusted":true},"cell_type":"code","source":"question_body_chars = build_vocab(list(train[\"question_body\"]))\nquestion_body_symbols = ''.join([c for c in question_body_chars if not c in white_list])\nquestion_body_symbols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"symbols_to_delete = ''.join([c for c in question_body_symbols if not c in glove_symbols])\nsymbols_to_delete","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"symbols_to_isolate = ''.join([c for c in question_body_symbols if c in glove_symbols])\nsymbols_to_isolate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['question_body'] = train['question_body'].progress_apply(lambda x:handle_punctuation(x))\ntest['question_body'] = test['question_body'].progress_apply(lambda x:handle_punctuation(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenize\n\ntrain['question_body'] = train['question_body'].progress_apply(lambda x:handle_contractions(x))\ntest['question_body'] = test['question_body'].progress_apply(lambda x:handle_contractions(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['question_body'] = train['question_body'].progress_apply(lambda x:fix_quote(x.split()))\ntest['question_body'] = test['question_body'].progress_apply(lambda x:fix_quote(x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Coverage\n# Lets check how many words we got covered \nvocab = build_vocab(list(train['question_body'].apply(lambda x:x.split())))\noov = check_coverage(vocab,glove_embeddings)\noov[:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Answer"},{"metadata":{"trusted":true},"cell_type":"code","source":"answer_body_chars = build_vocab(list(train[\"answer\"]))\nanswer_body_symbols = ''.join([c for c in answer_body_chars if not c in white_list])\nanswer_body_symbols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"symbols_to_delete = ''.join([c for c in answer_body_symbols if not c in glove_symbols])\nsymbols_to_delete","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"symbols_to_isolate = ''.join([c for c in answer_body_symbols if c in glove_symbols])\nsymbols_to_isolate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['answer'] = train['answer'].progress_apply(lambda x:handle_punctuation(x))\ntest['answer'] = test['answer'].progress_apply(lambda x:handle_punctuation(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenize\n\ntrain['answer'] = train['answer'].progress_apply(lambda x:handle_contractions(x))\ntest['answer'] = test['answer'].progress_apply(lambda x:handle_contractions(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['answer'] = train['answer'].progress_apply(lambda x:fix_quote(x.split()))\ntest['answer'] = test['answer'].progress_apply(lambda x:fix_quote(x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Coverage\n# Lets check how many words we got covered \nvocab = build_vocab(list(train['answer'].apply(lambda x:x.split())))\noov = check_coverage(vocab,glove_embeddings)\noov[:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train[col_to_use]\ny = train[target_cols]\ntest_pred = test[col_to_use]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_MODELS = 1\nLSTM_UNITS = 200\nDENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\nMAX_LEN = 300 #220\nmax_features = 6000\n\nBATCH_SIZE = 8\nEPOCHS = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words = max_features, filters='',lower=False)\ntokenizer.fit_on_texts(list(X['question_title']) + list(X['question_body'])+list(X['answer'])+ list(test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_matrix, unknown_words_glove = build_matrix(tokenizer.word_index, GLOVE_EMBEDDING_PATH)\nprint('n unknown words (glove): ', len(unknown_words_glove))\n\nmax_features = max_features or len(tokenizer.word_index) + 1\nprint(max_features)\n\nembedding_matrix = np.concatenate([glove_matrix], axis=-1)\nprint( embedding_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel glove_matrix\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = tokenizer.texts_to_sequences(X['question_title'])\nX2 = tokenizer.texts_to_sequences(X['question_body'])\nX3 = tokenizer.texts_to_sequences(X['answer'])\nX_cat = X['category']\ntest_pred1 = tokenizer.texts_to_sequences(test_pred['question_title'])\ntest_pred2 = tokenizer.texts_to_sequences(test_pred['question_body'])\ntest_pred3 = tokenizer.texts_to_sequences(test_pred['answer'])\ntest_cat = test_pred['category']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cat.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = sequence.pad_sequences(X1, maxlen=MAX_LEN)\nX2 = sequence.pad_sequences(X2, maxlen=MAX_LEN)\nX3 = sequence.pad_sequences(X3, maxlen=MAX_LEN)\n\ntest_pred1 = sequence.pad_sequences(test_pred1, maxlen=MAX_LEN)\ntest_pred2 = sequence.pad_sequences(test_pred2, maxlen=MAX_LEN)\ntest_pred3 = sequence.pad_sequences(test_pred3, maxlen=MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_predictions = []\nweights = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_spearmanr(trues, preds):\n    rhos = []\n    for col_trues, col_pred in zip(trues.T, preds.T):\n        rhos.append(\n            spearmanr(col_trues, col_pred))\n    return(np.mean(rhos))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomCallback(tf.keras.callbacks.Callback):\n    \n    def __init__(self, valid_data,batch_size=16, fold=None):\n        \n        self.X1_val = valid_data[0][0]\n        self.X2_val = valid_data[0][1]\n        self.X3_val = valid_data[0][2]\n        self.X_cat_val = valid_data[0][3]\n        self.valid_outputs = valid_data[1]\n        \n        self.batch_size = batch_size\n        self.fold = fold\n        \n    def on_train_begin(self, logs={}):\n        self.valid_predictions = []\n        self.test_predictions = []\n        \n    def on_epoch_end(self, epoch, logs={}):\n        self.valid_predictions.append(\n            self.model.predict(([self.X1_val,self.X2_val,self.X3_val,self.X_cat_val],self.valid_outputs), batch_size=self.batch_size))\n        \n        rho_val = compute_spearmanr(\n            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n        \n        print(\"\\nvalidation rho: %.4f\" % rho_val)\n        \n        if self.fold is not None:\n            self.model.save_weights(f'bert-base-{fold}-{epoch}.h5py')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, Dropout, add, concatenate,Flatten,Lambda\nfrom keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D,PReLU,LSTM\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.models import Sequential\nfrom keras.preprocessing import text, sequence\nfrom keras import regularizers\nimport keras.backend as K\nfrom sklearn.model_selection import train_test_split\nfrom keras.engine.topology import Layer\nimport tensorflow_hub as hub\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Concatenate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1_train , X1_val,X2_train, X2_val,X3_train, X3_val,X_cat_train,X_cat_val ,y_train  , y_val = train_test_split(X1 , X2,X3,X_cat,\n                                                     y , \n                                                     train_size = 0.8,\n                                                     random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X1_train.shape)\nprint(X2_train.shape)\nprint(X3_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X1_val.shape)\nprint(X2_val.shape)\nprint(X3_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping \nes = EarlyStopping(monitor='val_loss', mode ='min' ,verbose =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(embedding_matrix, num_aux_targets):\n    title = Input(shape=(MAX_LEN,))\n    question_body = Input(shape=(MAX_LEN,))\n    answer = Input(shape=(MAX_LEN,))\n    category = Input(shape=(1,))\n    \n    title_embb = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False )(title)\n    question_body_embb = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(question_body)\n    answer_embb = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(answer)\n    concat = Concatenate(axis=1)\n    embb_final = concat([title_embb,question_body_embb,answer_embb])\n    \n    x1 = SpatialDropout1D(0.3)(embb_final)\n    x1 = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x1)\n    x1 = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x1)\n    hidden1 = concatenate([\n        GlobalMaxPooling1D()(x1), \n        GlobalAveragePooling1D()(x1),#layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input \n        #of variable length in the simplest way possible.\n    ])\n    hidden1 = add([hidden1, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden1)])\n    hidden1 = Dense(30, activation='sigmoid')(hidden1)\n    category1 = Dense(30, activation='sigmoid')(category)\n    \n    final = add([hidden1,category1])\n    \n    result = Dense(30, activation='sigmoid')(final)\n    model = Model(inputs=[title,question_body,answer,category], outputs= result)\n    model._name = 'mymodel'\n    model.compile(loss='binary_crossentropy',metrics = ['accuracy'], optimizer='adam')\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model_idx in range(NUM_MODELS):\n    model = build_model(embedding_matrix,1)\n    for global_epoch in range(EPOCHS):      \n        model.fit(\n            [X1_train,X2_train,X3_train,X_cat_train],\n            y_train,\n            validation_data = ([X1_val,X2_val,X3_val,X_cat_val], y_val),\n            batch_size=BATCH_SIZE,\n            epochs=4,\n            verbose=2,\n            callbacks=[\n                LearningRateScheduler(lambda epoch: 0.4 * (0.1 ** global_epoch))\n            ]\n        )\n        checkpoint_predictions.append(model.predict([test_pred1,test_pred2,test_pred3,test_cat]).flatten())\n        weights.append(2 ** global_epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict([test_pred1,test_pred2,test_pred3,test_cat])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.iloc[:, 1:] = predictions\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}