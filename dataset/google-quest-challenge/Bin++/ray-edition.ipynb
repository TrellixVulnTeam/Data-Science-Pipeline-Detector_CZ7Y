{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport re\nfrom math import floor, ceil\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.utils import shuffle\nimport numpy as np\nfrom torch.utils import data\nfrom transformers import BertForMultipleChoice, BertTokenizer\nimport torch\n\n\nRANDOM_SEED = 49662\nSPLIT_NUM = 5\n\n\nclass QuestDataset(data.Dataset):\n\n    def __init__(self, df, train_mode=True, labeled=True):\n        \"\"\"\n        Load data file in `google-quest-challenge` folder, and set data into Pandas dataframe\n\n        :param load: default 'train'\n        train: Load `train.csv`\n        test: Load `test.csv`\n        \"\"\"\n\n        self.MAX_LEN = 512\n        self.SEP_TOKEN_ID = 102\n        self.input_cols = ['question_title', 'question_body', 'answer']\n        self.target_cols = ['question_asker_intent_understanding', 'question_body_critical',\n                            'question_conversational', 'question_expect_short_answer',\n                            'question_fact_seeking', 'question_has_commonly_accepted_answer',\n                            'question_interestingness_others', 'question_interestingness_self',\n                            'question_multi_intent', 'question_not_really_a_question',\n                            'question_opinion_seeking', 'question_type_choice',\n                            'question_type_compare', 'question_type_consequence',\n                            'question_type_definition', 'question_type_entity',\n                            'question_type_instructions', 'question_type_procedure',\n                            'question_type_reason_explanation', 'question_type_spelling',\n                            'question_well_written', 'answer_helpful',\n                            'answer_level_of_information', 'answer_plausible',\n                            'answer_relevance', 'answer_satisfaction',\n                            'answer_type_instructions', 'answer_type_procedure',\n                            'answer_type_reason_explanation', 'answer_well_written']\n        self.train_mode = train_mode\n        self.labeled = labeled\n        self.data = df\n        self.tokenizer = BertTokenizer.from_pretrained('../input/pretrained-bert-models-for-pytorch/bert-base-uncased-vocab.txt')\n\n    def __getitem__(self, index):\n        row = self.data.iloc[index]\n        token_ids, seg_ids = self.get_token_ids(row)\n        if self.labeled:\n            labels = self.get_label(row)\n            return token_ids, seg_ids, labels\n        else:\n            return token_ids, seg_ids\n\n    def __len__(self):\n        return len(self.data)\n\n    def cut_words(self, sentence, punc=True, entity=True):\n        \"\"\"\n        Convert a string sentence into the list containing words and punctuations\n        :param sentence:\n        string sentence\n\n        :param punc:\n        preserve the punctuations in the sentence.\n        True: preserve, False: not preserve\n\n        :param entity:\n        identify the entity e.g <formu> <url> <numb> ...\n        True: open entity mode, False: close entity mode\n\n        :return: list with words and punctuations\n        \"\"\"\n        punc_regex = '\\s[\\(\\):,\\.\\?/\\'\\\";\\[\\]\\{\\}\\-\\=\\+\\_|\\!@#%\\^\\&\\*]+|[\\(\\):,\\.\\?/\\'\\\";\\[\\]\\{\\}\\-\\=\\+\\_|\\!@#%\\^\\&\\*]+\\s'\n        formula_regex = '(?<!\\w)~*\\\\\\\\*\\${2}.+?\\${2}(?!\\w|\\(|\\{|\\[|\\\\\\\\|!)|(?<!\\w)~*\\\\\\\\*\\${1}.+?\\${1}(?!\\w|\\(|\\{|\\[|\\\\\\\\|!)|(?<!\\w)~*\\\\\\\\*\\${2}\\n*(^.+?\\n)+\\n*\\${2}(?!\\w|\\(|\\{|\\[|\\\\\\\\|!)'\n        url_regex = '(https?|ftp|file)://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|](?=\\s|$|\\. |\\.\\n|\\]|\\))'\n        js_regex = '(&lt; *script.*?&gt;)[\\s\\S]*?(&lt;/ *script *&gt;)'\n        css_regex = '(&lt; *style.*?&gt;)[\\s\\S]*?(&lt;/ *style *&gt;)'\n        php_regex = '&lt;\\s*\\?php([\\w\\W]+?)(\\?&gt;|\\n\\n\\n(?=[A-Z]))'\n        html_regex = '&lt;\\?{0,1}/{0,1}%{0,1}([a-zA-Z]+\\s+)+([a-zA-Z,:%-\\.]+\\s*=(\\\\|\\s){0,1}(\\\").*?(\\\")\\s*)*\\?{0,1}/{0,1}%{0,1}\\s*[a-zA-Z]*\\s*&gt;'\n        html1_regex = '(?<!#include\\s)(?<!#include\\s\\s)&lt;.*?&gt;'\n        html2_regex = '\\n *(&lt;([a-z]+) *[^/]*?&gt;) *\\n'\n        html3_regex = '&lt;\\!\\-\\-[\\w\\W]*?\\-\\-&gt;'\n        latex_regex = '\\\\\\\\document[\\s\\S]*?\\\\\\\\end\\{document\\}'\n        formula1_regex = '\\${2}[\\s\\S]+?\\${2}'\n        latex1_regex = '\\\\\\\\begin[\\s\\S]*?(\\\\\\\\end\\{[a-zA-Z\\*]+\\}|\\<latex\\>)'\n        latex2_regex = '[ \\t%]*(\\\\\\\\[a-zA-Z\\*]+)+(\\[[a-zA-Z\\d=,\\n]*?\\])*(\\\\{.*?\\\\}) *(?=\\n|%).*'\n        java_regex = '\\n{1,6}((import .*?;)|(package .*?;))\\n((( {4}){0,5}.*?(;|\\{|\\})\\n)|(( {4}){0,5}//.*?\\n)|(( {4}){0,5}/\\**.*?\\n)|(( {4}){0,5} \\**.*?\\n)|(( {4}){0,5}(public|@|class|if).*?\\n)|\\n)+'\n        # c_regex = '\\n{1,6}(( {2}){0,5}//.*?\\n)*#include (&lt;|\\\").*?(&gt;|\\\")\\n(#include (&lt;|\\\").*?(&gt;|\\\")\\n)*\\n*((( {2}){0,20}(int|void|double|bool|float|short|long|double|char) [a-zA-Z]+\\(.*?\\)(\\s*\\{|;)\\s*)|(( {2}){0,20}.*?\\{\\s*)|(( {2}){0,20}.*?(\\\\|\\)|/|;|,))\\s*\\n|(( {2}){0,20}[a-zA-Z]+.*?(;|\\s*\\{)(\\s*//.*){0,1}\\n)|(?<=\\n)\\s*\\{\\s*(?=\\n)|(\\#.*?\\n)|\\n|((( {2}){0,5})//.*?\\n)|(( {2}){0,5}\\}\\s*\\n))+'\n        c_regex = '\\n{1,6}(( {2}){0,5}//.*?\\n)*#include (&lt;|\\\").*?(&gt;|\\\")\\n(#include (&lt;|\\\").*?(&gt;|\\\")\\n)*(using .*?;\\n)*\\n*[\\d\\D]*?\\n{3}'\n        c2_regex = '(#include (&lt;|\\\").*?(&gt;|\\\")\\n)+[\\s\\S]*'\n        java2_regex = '(((?<=\\s)(public ){0,1}class .*?\\{)|(using .*?;)|((?<=\\s)(public ){0,1}class .*?\\s+\\{))\\n((( {4}){0,5}.*?(;|\\{|\\})\\n)|(( {4}){0,5}//.*?\\n)|(( {4}){0,5}/\\**.*?\\n)|(( {4}){0,5} \\**.*?\\n)|(( {4}){0,5}(public|@|class|if).*?\\n)|(( {4}){0,5}.*?\\\",\\n)|\\n)+'\n        java3_regex = '(((?<=\\s)(public |private |protected){0,1}.*?class .*?\\s*\\{)|((?<=\\n)using .*?;))\\n*((( {4}){0,5}.*?(;|\\{|\\})\\s*\\n)|(( {4}){0,5}//.*?\\n)|(( {4}){0,5}/\\**.*?\\n)|(( {4}){0,5} \\**.*?\\n)|(( {4}){0,5}(public|@|class|if).*?\\n)|(( {4}){0,5}.*?\\\",\\n)|\\n)+'\n        java4_regex = '((?<=\\n)(public |private |protected ){0,1}class .*?\\s*(\\{|extends))\\n*((( {4}){0,5}.*?(;|\\{|\\})\\s*\\n)|(( {4}){0,5}//.*?\\n)|(( {4}){0,5}/\\**.*?\\n)|(( {4}){0,5} \\**.*?\\n)|(( {4}){0,5}(public|@|class|if).*?\\n)|(( {4}){0,5}.*?\\\",\\n)|\\n)+'\n        java5_regex = '(\\s*(private|public|protected) ((void|static) ){0,2}[a-zA-Z]+.*(\\)|\\}|;|\\(|\\s*\\{)(?=\\n)\\n)+\\n*((( {4}){0,5}.*?(;|\\{|\\})\\s*\\n)|(( {4}){0,5}//.*?\\n)|(( {4}){0,5}/\\**.*?\\n)|(( {4}){0,5} \\**.*?\\n)|(( {4}){0,5}(public|@|class|if).*?\\n)|(( {4}){0,5}.*?\\\",\\n)|\\n)+'\n        python_regex = '(?<=\\n) *((class [a-zA-Z_]+?\\(.*?\\))|(for [^\\s]+ in .*?\\:)|(if _{0,2}name_{0,2} \\=\\= \\'_{0,2}main_{0,2}\\'\\:)|(def [^\\s]+?\\(.*?\\))|((from [^\\s]*? +){0,1}import.*))[\\s\\S]*?((\\n\\n(?=([A-Z][a-z]+|[a-z]+ ){2}([A-Z][a-z]+|[a-z]+ )+(?!\\=)))|(\\n\\n(?=\\n))|\\n+$)'\n        sql_regex = '(?<=\\n)\\n*(Connecting: host|SELECT|select| *CREATE|create|/\\*{1}\\*+)[\\s\\S]*?(?<!,)(\\n\\n)(?!( *[A-Z][A-Z]+)| *\\-{2})'\n        # (\\s*(private|public|protected) ((void|static) ){0,1}[A-Z][a-zA-Z]+.*(\\)|\\}|;|\\(|\\s*\\{)(?=\\n)\\n)+\n        version_regex = '[A-Z]+[A-Za-z]{4,10} (\\d+\\.)+\\d*'\n        # | ( *([ ^\\s]+ +){0, 1}[^ \\s]+? {0, 4}\\= {0, 4}.*)\n        # (for )|(if *\\(.*?\\))|(//.*)\n        refine_sentence = sentence\n\n        if entity:\n            formula_pattern = re.compile(formula_regex)\n            url_pattern = re.compile(url_regex)\n            js_pattern = re.compile(js_regex)\n            css_pattern = re.compile(css_regex)\n            php_pattern = re.compile(php_regex)\n            html_pattern = re.compile(html_regex)\n            html1_pattern = re.compile(html1_regex)\n            html2_pattern = re.compile(html2_regex)\n            html3_pattern = re.compile(html3_regex)\n            latex_pattern = re.compile(latex_regex)\n            formula1_pattern = re.compile(formula1_regex)\n            latex1_pattern = re.compile(latex1_regex)\n            latex2_pattern = re.compile(latex2_regex)\n            java_pattern = re.compile(java_regex)\n            java2_pattern = re.compile(java2_regex)\n            java3_pattern = re.compile(java3_regex)\n            java4_pattern = re.compile(java4_regex)\n            java5_pattern = re.compile(java5_regex)\n            c_pattern = re.compile(c_regex)\n            c2_pattern = re.compile(c2_regex)\n            python_pattern = re.compile(python_regex)\n            sql_pattern = re.compile(sql_regex)\n            # print(refine_sentence)\n            refine_sentence = re.sub(pattern=formula_pattern, repl='<formu>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=url_pattern, repl='<url>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=css_pattern, repl='<css>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=js_pattern, repl='<js>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=php_pattern, repl='<php>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=html_pattern, repl='<html>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=html1_pattern, repl='<html>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=html2_pattern, repl='<html>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=html3_pattern, repl='<html>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=latex_pattern, repl='<latex>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=formula1_pattern, repl='<formu>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=latex1_pattern, repl='<latex>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=latex2_pattern, repl='<latex>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=java_pattern, repl='<java>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=c_pattern, repl='<c>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=c2_pattern, repl='<c>', string=refine_sentence)\n            # print(refine_sentence)\n            refine_sentence = re.sub(pattern=java2_pattern, repl='<java>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=java3_pattern, repl='<java>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=java4_pattern, repl='<java>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=java5_pattern, repl='<java>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=python_pattern, repl='<python>', string=refine_sentence)\n            refine_sentence = re.sub(pattern=sql_pattern, repl='<sql>', string=refine_sentence)\n\n        print(refine_sentence)\n        print('---------------------------------------------')\n        # print(re.sub(pattern='', repl='', string=refine_sentence))\n\n        if punc:\n            punc_regex = '(' + punc_regex + ')'\n\n        pattern = re.compile(punc_regex)\n\n        if entity:\n            refine_sentence = ' '.join(\n                re.split(pattern=re.compile('(<.*?>)'), string=refine_sentence))  # split entity\n\n        refine_sentence = ' '.join(re.split(pattern=re.compile('([A-z]\\.\\.+([A-z]|\\(|\\[|\\{))'), string=refine_sentence))  # split ...\n        refine_sentence = ' ' + refine_sentence.strip().replace('\\n', ' ').replace(' ', '  ') + ' '\n        phrase = list(re.split(pattern=pattern, string=refine_sentence))\n        words = []\n        for index in range(len(phrase) - 1):\n            words += re.split(pattern=re.compile('\\s|/'), string=phrase[index].strip())\n\n        while '' in words:\n            words.remove('')\n\n        return words\n\n    def trim_input(self, title, question, answer, t_max_len=30, q_max_len=239, a_max_len=239):\n        max_sequence_length = self.MAX_LEN\n\n        t = self.tokenizer.tokenize(title)\n        q = self.tokenizer.tokenize(question)\n        a = self.tokenizer.tokenize(answer)\n\n        t_len = len(t)\n        q_len = len(q)\n        a_len = len(a)\n\n        if (t_len + q_len + a_len + 4) > max_sequence_length:\n\n            if t_max_len > t_len:\n                t_new_len = t_len\n                a_max_len = a_max_len + floor((t_max_len - t_len) / 2)\n                q_max_len = q_max_len + ceil((t_max_len - t_len) / 2)\n            else:\n                t_new_len = t_max_len\n\n            if a_max_len > a_len:\n                a_new_len = a_len\n                q_new_len = q_max_len + (a_max_len - a_len)\n            elif q_max_len > q_len:\n                a_new_len = a_max_len + (q_max_len - q_len)\n                q_new_len = q_len\n            else:\n                a_new_len = a_max_len\n                q_new_len = q_max_len\n\n            if t_new_len + a_new_len + q_new_len + 4 != max_sequence_length:\n                raise ValueError(\"New sequence length should be %d, but is %d\"\n                                 % (max_sequence_length, (t_new_len + a_new_len + q_new_len + 4)))\n\n            t = t[:t_new_len]\n            q = q[:q_new_len]\n            a = a[:a_new_len]\n\n        return t, q, a\n\n    def get_token_ids(self, row):\n        t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer)\n\n        tokens = ['[CLS]'] + t_tokens + ['[SEP]'] + q_tokens + ['[SEP]'] + a_tokens + ['[SEP]']\n        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        if len(token_ids) < self.MAX_LEN:\n            token_ids += [0] * (self.MAX_LEN - len(token_ids))\n        ids = torch.tensor(token_ids)\n        seg_ids = self.get_seg_ids(ids)\n        return ids, seg_ids\n\n    def get_seg_ids(self, ids):\n        seg_ids = torch.zeros_like(ids)\n        seg_idx = 0\n        first_sep = True\n        for i, e in enumerate(ids):\n            seg_ids[i] = seg_idx\n            if e == self.SEP_TOKEN_ID:\n                if first_sep:\n                    first_sep = False\n                else:\n                    seg_idx = 1\n        pad_idx = torch.nonzero(ids == 0)\n        seg_ids[pad_idx] = 0\n\n        return seg_ids\n\n    def get_label(self, row):\n        return torch.tensor(row[self.target_cols].values.astype(np.float32))\n\n    def collate_fn(self, batch):\n        token_ids = torch.stack([x[0] for x in batch])\n        seg_ids = torch.stack([x[1] for x in batch])\n\n        if self.labeled:\n            labels = torch.stack([x[2] for x in batch])\n            return token_ids, seg_ids, labels\n        else:\n            return token_ids, seg_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_loader(batch_size=4):\n    df = pd.read_csv(filepath_or_buffer='../input/google-quest-challenge/test.csv', header=0)\n    ds_test = QuestDataset(df, train_mode=False, labeled=False)\n    loader = data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=0,\n                                         collate_fn=ds_test.collate_fn, drop_last=False)\n    loader.num = len(df)\n\n    return loader\n\n\ndef get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0):\n    df = pd.read_csv(filepath_or_buffer='../input/google-quest-challenge/train.csv', header=0)\n    df = shuffle(df, random_state=RANDOM_SEED)\n\n    df_train = None\n    df_val = None\n\n    # split_index = int(len(df) * (1-val_percent))\n    gkf = GroupKFold(n_splits=SPLIT_NUM).split(X=df.question_body, groups=df.question_body)\n    for fold, (train_idx, valid_idx) in enumerate(gkf):\n        # print(str(fold), str((train_idx.shape, valid_idx.shape)))\n        if fold == ifold:\n            df_train = df.iloc[train_idx]\n            df_val = df.iloc[valid_idx]\n            break\n\n    ds_train = QuestDataset(df_train)\n    train_loader = data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=ds_train.collate_fn, drop_last=True)\n    train_loader.num = len(df_train)\n\n    ds_val = QuestDataset(df_val, train_mode=False)\n    val_loader = data.DataLoader(ds_val, batch_size=val_batch_size, shuffle=False, num_workers=0, collate_fn=ds_val.collate_fn, drop_last=False)\n    val_loader.num = len(df_val)\n    val_loader.df = df_val\n\n    return train_loader, val_loader\n\n\ndef test_train_loader():\n    loader, _ = get_train_val_loaders(4, 4, 1)\n    for ids, seg_ids, labels in loader:\n        print(ids)\n        print(ids.dtype)\n        print(seg_ids)\n        print(seg_ids.dtype)\n        print(labels.dtype)\n        break\n\n\ndef test_test_loader():\n    loader = get_test_loader(4)\n    for ids, seg_ids in loader:\n        print(ids.dtype)\n        print(seg_ids.dtype)\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 在运行了`test_train_loader()` 要**重启kernal**，`test_train_loader()` 内部的数据会占用显存，正式训练时不要运行`test_train_loader()`"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_train_loader()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertModel, AdamW, BertConfig, get_linear_schedule_with_warmup, BertPreTrainedModel, BertConfig\nimport torch.nn as nn\nimport random\nimport time\nimport datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import spearmanr\nimport os\n\nbert_model_config = '../input/pretrained-bert-models-for-pytorch/bert-base-uncased/bert_config.json'\nbert_config = BertConfig.from_json_file(bert_model_config)\nbert_config.num_labels = 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuestModel(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        config.output_hidden_states = True\n        self.num_labels = config.num_labels\n\n        self.bert = BertModel(config)\n        self.dropout = nn.Dropout(0.2)\n        self.high_dropout = nn.Dropout(p=0.5)\n        \n        n_weights = config.num_hidden_layers + 1\n        weights_init = torch.zeros(n_weights).float()\n        weights_init.data[:-1] = -3\n        self.layer_weights = torch.nn.Parameter(weights_init)\n        \n        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n\n        self.init_weights()\n\n    def forward(self, ids, seg_ids, mask, target=None):\n        outputs = self.bert(\n            input_ids=ids,\n            token_type_ids=seg_ids,\n            attention_mask=mask,\n        )\n        \n        hidden_layers = outputs[2]\n        last_hidden = outputs[0]\n\n        cls_outputs = torch.stack(\n            [self.dropout(layer[:, 0, :]) for layer in hidden_layers], dim=2\n        )\n        cls_output = (torch.softmax(self.layer_weights, dim=0) * cls_outputs).sum(-1)\n\n        # multisample dropout (wut): https://arxiv.org/abs/1905.09788\n        logits = torch.mean(\n            torch.stack(\n                [self.classifier(self.high_dropout(cls_output)) for _ in range(5)],\n                dim=0,\n            ),\n            dim=0,\n        )\n\n        outputs = logits\n        \n# #         pooled_output = outputs[1]\n#         #hidden_state = outputs[0]\n#         #pooled_output = hidden_state[:, 0]\n#         #pooled_output = self.pre_classifier(pooled_output)\n#         #pooled_output = nn.SELU()(pooled_output)\n#         pooled_output = torch.mean(outputs[0], 1)\n\n#         pooled_output = self.dropout(pooled_output)\n#         logits = self.classifier(pooled_output)\n# #         logits = torch.sigmoid(logits)\n\n#         outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n\n        if target is not None:\n            loss_fct = nn.BCEWithLogitsLoss()\n            loss = loss_fct(logits.view(-1, self.num_labels), target.view(-1, self.num_labels))\n            outputs = (loss, outputs)\n\n        return outputs  # (loss), logits, (hidden_states), (attentions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model():\n    x = torch.tensor([[1, 2, 3, 4, 5, 0, 0], [1, 2, 3, 4, 5, 0, 0]])\n    seg_ids = torch.tensor([[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]])\n    model = QuestModel.from_pretrained(\n        \"../input/pretrained-bert-models-for-pytorch/bert-base-uncased/\",  # Use the 12-layer BERT model, with an uncased vocab.\n        config=bert_config\n    )\n    model.cuda()\n    y = model(ids=x.cuda(), seg_ids=seg_ids.cuda(), mask=(x > 0).long().cuda())\n\n    output_dir = 'test_model_save'\n\n    # Create output directory if needed\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    print(\"Saving model to %s\" % output_dir)\n\n    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n    # They can then be reloaded using `from_pretrained()`\n    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n    model_to_save.save_pretrained(output_dir)\n\n    print(y[0])\n    print(y)\n    \n    model.cpu()\n    torch.cuda.empty_cache()\n    \n    del model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 在运行了 `test_model()` 要**重启kernal**，因为test会生成一个model，这个model会占用大量内存导致下列`train()`无法运行"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"torch清空显存的例子"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))\n\n\n# Function to calculate the accuracy of our predictions vs labels\ndef spearmanr_accuracy(preds, target):\n    total_acc = 0\n    for i in range(preds.shape[0]):\n        accruacy, _ = spearmanr(preds[i], target[i], axis=0, nan_policy='propagate')\n        total_acc += accruacy\n\n    return total_acc/preds.shape[0]\n\n\ndef train(device):\n\n    batch_size = 16\n\n    for ifold in range(SPLIT_NUM):\n        train_loader, val_loader = get_train_val_loaders(batch_size=batch_size, val_batch_size=batch_size, ifold=ifold)\n        \n        model = QuestModel.from_pretrained(\n            \"../input/pretrained-bert-models-for-pytorch/bert-base-uncased/\",\n            config=bert_config\n        )\n    \n        model.to(device)\n\n        params = list(model.named_parameters())\n\n        print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n\n        print('==== Embedding Layer ====\\n')\n\n        for p in params[0:5]:\n            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\n        print('\\n==== First Transformer ====\\n')\n\n        for p in params[5:21]:\n            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\n        print('\\n==== Output Layer ====\\n')\n\n        for p in params[-4:]:\n            print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\n        # Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n        # I believe the 'W' stands for 'Weight Decay fix\"\n        optimizer = AdamW(model.parameters(),\n                          lr=2e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n                          # Candidate 5e-5, 3e-5, 2e-5\n                          eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n                          )\n\n        # Number of training epochs (authors recommend between 2 and 4)\n        epochs = 8\n\n        # Total number of training steps is number of batches * number of epochs.\n        total_steps = len(train_loader) * epochs\n\n        # Create the learning rate scheduler.\n        scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                    num_warmup_steps=0,  # Default value in run_glue.py\n                                                    num_training_steps=total_steps)\n\n        # Store the average loss after each epoch so we can plot them.\n        train_loss_values = []\n        train_acc_values = []\n        val_loss_values = []\n        val_acc_values = []\n\n        # Set the seed value all over the place to make this reproducible.\n        seed_val = 42\n\n        random.seed(seed_val)\n        np.random.seed(seed_val)\n        torch.manual_seed(seed_val)\n        torch.cuda.manual_seed_all(seed_val)\n\n        for epoch_i in range(0, epochs):\n\n            # ========================================\n            #               Training\n            # ========================================\n\n            # Perform one full pass over the training set.\n\n            print(\"\")\n            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n            print('Training...')\n\n            # Measure how long the training epoch takes.\n            t0 = time.time()\n\n            # Reset the total loss for this epoch.\n            total_loss = 0\n            train_preds = None\n            train_targets = None\n\n            # For each batch of training data...\n            for step, batch in enumerate(train_loader):\n\n                # Progress update every 40 batches.\n                if step % 40 == 0 and not step == 0:\n                    # Calculate elapsed time in minutes.\n                    elapsed = format_time(time.time() - t0)\n\n                    # Report progress.\n                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n\n                input_ids = batch[0]\n                input_seg = batch[1]\n                input_mask = (input_ids > 0)\n                target = batch[2]\n\n                # Always clear any previously calculated gradients before performing a\n                # backward pass. PyTorch doesn't do this automatically because\n                # accumulating the gradients is \"convenient while training RNNs\".\n                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n                # model.zero_grad()\n\n                outputs = model(\n                    ids=input_ids.to(device),\n                    seg_ids=input_seg.to(device),\n                    mask=input_mask.to(device),\n                    target=target.to(device),\n                )\n\n                # The call to `model` always returns a tuple, so we need to pull the\n                # loss value out of the tuple.\n                loss, logits = outputs[:2]\n                \n                optimizer.zero_grad()\n\n                # Accumulate the training loss over all of the batches so that we can\n                # calculate the average loss at the end. `loss` is a Tensor containing a\n                # single value; the `.item()` function just returns the Python value\n                # from the tensor.\n                total_loss += loss.item()\n\n                # Perform a backward pass to calculate the gradients.\n                loss.backward()\n\n                # Clip the norm of the gradients to 1.0.\n                # This is to help prevent the \"exploding gradients\" problem.\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n                # Update parameters and take a step using the computed gradient.\n                # The optimizer dictates the \"update rule\"--how the parameters are\n                # modified based on their gradients, the learning rate, etc.\n                optimizer.step()\n\n                # Update the learning rate.\n                scheduler.step()\n\n                # Move logits and labels to CPU\n                logits = logits.detach().cpu().numpy()\n                target_ids = target.to('cpu').numpy()\n\n                if train_preds is None:\n                    train_preds = logits\n                    train_targets = target_ids\n                else:\n                    train_preds = np.append(train_preds, logits, axis=0)\n                    train_targets = np.append(train_targets, target_ids, axis=0)\n\n                # if step > 10:\n                #     break\n\n            # Calculate the average loss over the training data.\n            avg_train_loss = total_loss / len(train_loader)\n\n            # Store the loss value for plotting the learning curve.\n            train_loss_values.append(avg_train_loss)\n\n            # Report the final accuracy for this validation run.\n            train_accuracy = spearmanr_accuracy(train_preds, train_targets)\n            train_acc_values.append(train_accuracy)\n\n            print(\"\")\n            print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n            print(\"  Average training acc: {0:.2f}\".format(train_accuracy))\n            print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n\n            # ========================================\n            #               Validation\n            # ========================================\n            # After the completion of each training epoch, measure our performance on\n            # our validation set.\n\n            print(\"\")\n            print(\"Running Validation...\")\n\n            t0 = time.time()\n\n            # Put the model in evaluation mode--the dropout layers behave differently\n            # during evaluation.\n            model.eval()\n\n            # Tracking variables\n            eval_loss, eval_accuracy = 0, 0\n            nb_eval_steps, nb_eval_examples = 0, 0\n            val_preds = None\n            val_targets = None\n\n            eval_total_loss = 0\n\n            # Evaluate data for one epoch\n            for batch in val_loader:\n                # Unpack the inputs from our dataloader\n                input_ids = batch[0]\n                input_seg = batch[1]\n                input_mask = (input_ids > 0)\n                target = batch[2]\n\n                # Telling the model not to compute or store gradients, saving memory and\n                # speeding up validation\n                with torch.no_grad():\n                    outputs = model(\n                        ids=input_ids.to(device),\n                        seg_ids=input_seg.to(device),\n                        mask=input_mask.to(device),\n                        target=target.to(device),\n                    )\n\n                # Get the \"logits\" output by the model. The \"logits\" are the output\n                # values prior to applying an activation function like the softmax.\n                loss, logits = outputs[:2]\n\n                eval_total_loss += loss.item()\n\n                # Move logits and labels to CPU\n                logits = logits.detach().cpu().numpy()\n                target_ids = target.to('cpu').numpy()\n\n                nb_eval_steps += 1\n\n                if val_preds is None:\n                    val_preds = logits\n                    val_targets = target_ids\n                else:\n                    val_preds = np.append(val_preds, logits, axis=0)\n                    val_targets = np.append(val_targets, target_ids, axis=0)\n\n                # if nb_eval_steps > 10:\n                #     break\n\n            # Calculate the average loss over the training data.\n            avg_val_loss = total_loss / len(val_loader)\n\n            # Store the loss value for plotting the learning curve.\n            val_loss_values.append(avg_val_loss)\n\n            # Report the final accuracy for this validation run.\n            eval_accuracy = spearmanr_accuracy(val_preds, val_targets)\n            val_acc_values.append(eval_accuracy)\n\n            print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n            print(\"Validation Accuracy: {0:.2f}\".format(eval_accuracy))\n            print(\"Validation took: {:}\".format(format_time(time.time() - t0)))\n\n        print(\"\")\n        print(\"Training complete!\")\n\n        output_dir = 'model_fold{0}.pt'.format(ifold+1)\n\n        torch.save(model.state_dict(), output_dir)\n        model.cpu()\n        torch.cuda.empty_cache()\n\n\ndef predict(device):\n    batch_size = 16\n    test_loader = get_test_loader(batch_size=batch_size)\n\n    prediction = None\n\n    for ifold in range(SPLIT_NUM):\n        # Prediction on test set\n\n        print('Predicting labels for {:,} test sentences...'.format(test_loader.num))\n        model = QuestModel(bert_config)\n        model.load_state_dict(torch.load('../input/custombert/model_fold{0}.pt'.format(ifold+1)))\n\n        # Put model in evaluation mode\n        model.eval()\n        model.to(device)\n\n        # Tracking variables\n        preds = None\n\n        # Predict\n        for batch in test_loader:\n            # Unpack the inputs from our dataloader\n            input_ids = batch[0]\n            input_seg = batch[1]\n            input_mask = (input_ids > 0)\n            # target = batch[2].float().detach().cpu().numpy()\n\n            # Telling the model not to compute or store gradients, saving memory and\n            # speeding up validation\n            with torch.no_grad():\n                outputs = model(\n                    ids=input_ids.to(device),\n                    seg_ids=input_seg.to(device),\n                    mask=input_mask.to(device),\n                )\n\n            logits = outputs\n            logits = logits.sigmoid()\n\n            # Move logits and labels to CPU\n            logits = logits.detach().cpu().numpy()\n\n            # Store predictions and true labels\n            if preds is None:\n                preds = logits\n            else:\n                preds = np.append(preds, logits, axis=0)\n\n        if prediction is None:\n            prediction = preds\n        else:\n            prediction += preds\n\n        print('Goup {0}\\tDONE.'.format(ifold))\n\n    return prediction/SPLIT_NUM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The torch version is ' + str(torch.__version__))\n\n# If there's a GPU available...\nif torch.cuda.is_available():\n\n    # Tell PyTorch to use the GPU.\n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = predict(device)\n\ntest_df = pd.read_csv('../input/google-quest-challenge/test.csv')\nsubmission_df = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')\n\npreds_df = pd.DataFrame(data=preds, columns=submission_df.columns[-30:])\nsubmission_df = pd.concat([test_df['qa_id'], preds_df], axis=1)\n\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}