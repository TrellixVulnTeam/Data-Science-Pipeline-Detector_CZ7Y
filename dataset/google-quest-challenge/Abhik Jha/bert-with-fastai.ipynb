{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import data and Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai import *\nfrom fastai.text import *\nfrom fastai.tabular import *\n\nfrom pathlib import Path\nfrom typing import *\n\nimport torch\nimport torch.optim as optim\n\nimport gc\ngc.collect()\n\nimport re\nimport os\nimport re\nimport gc\nimport pickle  \nimport random\nimport keras\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport keras.backend as K\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Dropout, Lambda\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback\nfrom scipy.stats import spearmanr, rankdata\nfrom os.path import join as path_join\nfrom numpy.random import seed\nfrom urllib.parse import urlparse\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom bayes_opt import BayesianOptimization\nfrom lightgbm import LGBMRegressor\nfrom nltk.tokenize import wordpunct_tokenize\nfrom nltk.stem.snowball import EnglishStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom functools import lru_cache\nfrom tqdm import tqdm as tqdm\nfrom fastai.text import *\nfrom fastai.metrics import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 42\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/google-quest-challenge/train.csv\")\ntest = pd.read_csv(\"../input/google-quest-challenge/test.csv\")\nsub = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape, sub.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '\\n', '\\xa0', '\\t',\n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '\\u3000', '\\u202f',\n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\nmispell_dict = {\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"couldnt\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"doesnt\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"havent\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"shouldnt\" : \"should not\",\n\"that's\" : \"that is\",\n\"thats\" : \"that is\",\n\"there's\" : \"there is\",\n\"theres\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"theyre\":  \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"}\n\n\ndef clean_text(x):\n    x = str(x)\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x\n\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\n\ndef replace_typical_misspell(text):\n    mispellings, mispellings_re = _get_mispell(mispell_dict)\n\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)\n\n\ndef clean_data(df, columns: list):\n    for col in columns:\n        df[col] = df[col].apply(lambda x: clean_numbers(x))\n        df[col] = df[col].apply(lambda x: clean_text(x.lower()))\n        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols_questions = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written']\n\ntarget_cols_answers = ['answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']\n\ntargets = target_cols_questions + target_cols_answers\n\ninput_columns = ['question_title', 'question_body', 'answer']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = clean_data(train, ['answer', 'question_body', 'question_title'])\ntest = clean_data(test, ['answer', 'question_body', 'question_title'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find = re.compile(r\"^[^.]*\")\n\ntrain['netloc_1'] = train['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\ntest['netloc_1'] = test['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n\ntrain['netloc_2'] = train['question_user_page'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\ntest['netloc_2'] = test['question_user_page'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n\ntrain['netloc_3'] = train['answer_user_page'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\ntest['netloc_3'] = test['answer_user_page'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train-val-test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[input_columns + targets]\ntest = test[input_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, val = train_test_split(train, test_size=0.2, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, val.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transformers"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install ../input/sacremoses/sacremoses-master/\n!pip install ../input/transformers/transformers-master/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/pretrained-bert-models-for-pytorch/bert-base-uncased","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom dataclasses import dataclass\nimport functools\nimport gc\nimport itertools\nimport json\nfrom multiprocessing import Pool\nimport os\nfrom pathlib import Path\nimport random\nimport re\nimport shutil\nimport subprocess\nimport time\nfrom typing import Callable, Dict, List, Generator, Tuple\nfrom os.path import join as path_join\n\nimport numpy as np\nimport pandas as pd\nfrom pandas.io.json._json import JsonReader\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm._tqdm_notebook import tqdm_notebook as tqdm\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, Subset, DataLoader\n\nfrom transformers import BertTokenizer, AdamW, BertModel, BertPreTrainedModel, BertConfig\nfrom transformers.optimization import get_linear_schedule_with_warmup","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Forward Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a config object to store task specific information\nclass Config(dict):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n    \n    def set(self, key, val):\n        self[key] = val\n        setattr(self, key, val)\n        \nconfig = Config(\n    testing=False,\n    seed = 42,\n    roberta_model_name='bert-base-uncased', # can also be exchnaged with roberta-large \n    use_fp16=False,\n    bs=16, \n    max_seq_len=128, \n    hidden_dropout_prob=.25,\n    hidden_size=768, # 1024 for roberta-large\n    start_tok = \"[CLS]\",\n    end_tok = \"[SEP]\",\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forward tokenizer\n\nclass FastAiRobertaTokenizer(BaseTokenizer):\n    \"\"\"Wrapper around RobertaTokenizer to be compatible with fastai\"\"\"\n    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs): \n        self._pretrained_tokenizer = tokenizer\n        self.max_seq_len = max_seq_len \n    def __call__(self, *args, **kwargs): \n        return self \n    def tokenizer(self, t:str) -> List[str]: \n        \"\"\"Adds Roberta bos and eos tokens and limits the maximum sequence length\"\"\" \n        return [config.start_tok] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [config.end_tok]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# backward tokenizer\n\nclass FastAiRobertaTokenizerBackward(BaseTokenizer):\n    \"\"\"Wrapper around RobertaTokenizer to be compatible with fastai\"\"\"\n    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs): \n        self._pretrained_tokenizer = tokenizer\n        self.max_seq_len = max_seq_len \n    def __call__(self, *args, **kwargs): \n        return self \n    def tokenizer(self, t:str) -> List[str]: \n        \"\"\"Adds Roberta bos and eos tokens and limits the maximum sequence length\"\"\" \n        return [config.end_tok] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [config.start_tok]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create fastai tokenizer for roberta\nbert_tok = BertTokenizer.from_pretrained('../input/pretrained-bert-models-for-pytorch/bert-base-uncased-vocab.txt')\n\nfastai_tokenizer = Tokenizer(tok_func=FastAiRobertaTokenizer(bert_tok, max_seq_len=config.max_seq_len), \n                             pre_rules=[], post_rules=[])\n\nfastai_tokenizer_bwd = Tokenizer(tok_func=FastAiRobertaTokenizerBackward(bert_tok, max_seq_len=config.max_seq_len), \n                             pre_rules=[], post_rules=[])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create fastai vocabulary for roberta\npath = Path()\nbert_tok.save_vocabulary(path)\n   \nfastai_bert_vocab = Vocab(list(bert_tok.vocab.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"databunch = TextDataBunch.from_df(\".\", train, val, test,\n                  tokenizer=fastai_tokenizer,\n                  vocab=fastai_bert_vocab,\n                  include_bos=False,\n                  include_eos=False,\n                  text_cols=input_columns,\n                  label_cols=targets,\n                  bs=16,\n                  mark_fields=True,\n                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n             )\n\ndatabunch.save('databunch.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"databunch = load_data(path, 'databunch.pkl', bs=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"databunch.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\n\nseed = 42\n\nnum_labels = len(targets)\nn_epochs = 3\nlr = 2e-5\nwarmup = 0.05\nbatch_size = 16\naccumulation_steps = 4\n\nbert_model_config = '../input/pretrained-bert-models-for-pytorch/bert-base-uncased/bert_config.json'\n\nbert_model = 'bert-base-uncased'\ndo_lower_case = 'uncased' in bert_model\ndevice = torch.device('cuda')\n\noutput_model_file = 'bert_pytorch.bin'\noutput_optimizer_file = 'bert_pytorch_optimizer.bin'\noutput_amp_file = 'bert_pytorch_amp.bin'\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build BERT Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertForSequenceClassification(BertPreTrainedModel):\n    r\"\"\"\n        **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n            Labels for computing the sequence classification/regression loss.\n            Indices should be in ``[0, ..., config.num_labels - 1]``.\n            If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n            If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n        **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n            Classification (or regression if config.num_labels==1) loss.\n        **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n            of shape ``(batch_size, sequence_length, hidden_size)``:\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n    Examples::\n        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids, labels=labels)\n        loss, logits = outputs[:2]\n    \"\"\"\n    def __init__(self, config):\n        super(BertForSequenceClassification, self).__init__(config)\n        self.num_labels = config.num_labels\n\n        self.bert = BertModel(config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n\n        self.init_weights()\n\n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n                position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n\n        outputs = self.bert(input_ids,\n                            attention_mask=attention_mask,\n                            token_type_ids=token_type_ids,\n                            position_ids=position_ids,\n                            head_mask=head_mask,\n                            inputs_embeds=inputs_embeds)\n\n        pooled_output = outputs[1]\n\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n\n        return logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_func = nn.BCEWithLogitsLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup model"},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_config = BertConfig.from_json_file(bert_model_config)\nbert_config.num_labels = len(targets)\n\nmodel_path = os.path.join('../input/pretrained-bert-models-for-pytorch/bert-base-uncased/')\n\nmodel = BertForSequenceClassification.from_pretrained(model_path, config=bert_config)\nlearn_bert = Learner(databunch, model, loss_func=loss_func, model_dir='/temp/model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_clas_split(self) -> List[nn.Module]:\n    \n    bert = model.bert\n    embedder = bert.embeddings\n    pooler = bert.pooler\n    encoder = bert.encoder\n    classifier = [model.dropout, model.classifier]\n    n = len(encoder.layer)//3\n    print(n)\n    groups = [[embedder], list(encoder.layer[:n]), list(encoder.layer[n+1:2*n]), list(encoder.layer[(2*n)+1:]), [pooler], classifier]\n    return groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = bert_clas_split(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.layer_groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.split([x[1],  x[3],  x[5]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.layer_groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.freeze_to(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\nimport matplotlib.style as style\nstyle.use('seaborn-poster')\nstyle.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.fit_one_cycle(7, max_lr=slice(1e-3, 1e-2), moms=(0.8,0.7), pct_start=0.2, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.save('head-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.freeze_to(-2)\nlearn_bert.fit_one_cycle(7, max_lr=slice(1e-4, 1e-3), moms=(0.8,0.7), pct_start=0.4, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.save('head-2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.freeze_to(-3)\nlearn_bert.fit_one_cycle(7, max_lr=slice(1e-5, 1e-4), moms=(0.8,0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.unfreeze()\nlearn_bert.lr_find()\nlearn_bert.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bert.fit_one_cycle(12, slice(1e-5, 1e-4), moms=(0.8,0.7), pct_start=0.4, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fastai - ULMFiT"},{"metadata":{"trusted":true},"cell_type":"code","source":"bs, bptt = 32, 80\n\ndata_lm = TextLMDataBunch.from_df('.', train, val, test,\n                  include_bos=False,\n                  include_eos=False,\n                  text_cols=['question_title', 'question_body', 'answer'],\n                  label_cols=targets,\n                  bs=bs,\n                  mark_fields=True,\n                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n             )\n\ndata_lm.save('data_lm.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \".\"\ndata_lm = load_data(path, 'data_lm.pkl', bs=bs, bptt=bptt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \".\"\ndata_bwd = load_data(path, 'data_lm.pkl', bs=bs, bptt = bptt, backwards=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bwd.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"awd_lstm_lm_config = dict( emb_sz=400, n_hid=1150, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.1,\n                          hidden_p=0.15, input_p=0.25, embed_p=0.02, weight_p=0.2, tie_weights=True, out_bias=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"awd_lstm_clas_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=1, qrnn=False, bidir=False, output_p=0.4,\n                       hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Forward Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5,\n                               config=awd_lstm_lm_config, pretrained = False)\nlearn = learn.to_fp16(clip=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = ['../input/awd-lstm/lstm_wt103.pth','../input/awd-lstm/itos_wt103.pkl']\nlearn.load_pretrained(*fnames, strict=False)\nlearn.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(2, max_lr=slice(5e-3, 5e-2), moms=(0.8, 0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('fit_head')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(12, max_lr = slice(1e-4, 1e-3), moms=(0.8, 0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('fine-tuned')\nlearn.load('fine-tuned')\nlearn.save_encoder('fine-tuned-fwd')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Backward Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_bwd, AWD_LSTM, drop_mult=0.5,\n                               config=awd_lstm_lm_config, pretrained = False)\nlearn = learn.to_fp16(clip=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = ['../input/awd-lstm/lstm_wt103.pth','../input/awd-lstm/itos_wt103.pkl']\nlearn.load_pretrained(*fnames, strict=False)\nlearn.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(2, max_lr=slice(5e-2, 1e-1), moms=(0.8, 0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('fit_head-bwd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(12, max_lr = slice(1e-4, 1e-3), moms=(0.8, 0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('fine-tuned-bwd')\nlearn.load('fine-tuned-bwd')\nlearn.save_encoder('fine-tuned-bwd')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_cols = ['question_title', \"question_body\", 'answer']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls = TextClasDataBunch.from_df('.', train, val, test, vocab = data_lm.vocab,\n                  include_bos=False,\n                  include_eos=False,\n                  text_cols=text_cols,\n                  label_cols=targets,\n                  bs=bs,\n                  mark_fields=True,\n                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n             )\n\ndata_cls.save('data_cls.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls = load_data(path, 'data_cls.pkl', bs=bs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls_bwd = load_data(path, 'data_cls.pkl', bs=bs, backwards=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cls_bwd.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Forward Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = text_classifier_learner(data_cls, AWD_LSTM, drop_mult=0.5,config=awd_lstm_clas_config, pretrained = False, loss_func=loss_func)\nlearn.load_encoder('fine-tuned-fwd')\nlearn = learn.to_fp16(clip=0.1)\n#learn.loss_func = L1LossFlat()\nfnames = ['../input/awd-lstm/lstm_wt103.pth','../input/awd-lstm/itos_wt103.pkl']\nlearn.load_pretrained(*fnames, strict=False)\nlearn.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(2, max_lr=slice(1e-2, 1e-1), moms=(0.8, 0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('first-head')\nlearn.load('first-head')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-2)\nlearn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('second')\nlearn.load('second')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-3)\nlearn.fit_one_cycle(2, slice(1e-4/(2.6**4),1e-4), moms=(0.8,0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('third')\nlearn.load('third')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10, slice(1e-4/(2.6**4),1e-4), moms=(0.8,0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('fwd-cls')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Backward Training\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd = text_classifier_learner(data_cls_bwd, AWD_LSTM, drop_mult=0.5, config=awd_lstm_clas_config, loss_func=loss_func,\n                                    pretrained = False)\nlearn_bwd.load_encoder('fine-tuned-bwd')\nlearn_bwd = learn_bwd.to_fp16(clip=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = ['../input/awd-lstm/lstm_wt103.pth','../input/awd-lstm/itos_wt103.pkl']\nlearn_bwd.load_pretrained(*fnames, strict=False)\nlearn_bwd.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.lr_find()\nlearn_bwd.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.fit_one_cycle(2, max_lr=slice(5e-2, 1e-1), moms=(0.8, 0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.save('first-head-bwd')\nlearn_bwd.load('first-head-bwd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.freeze_to(-2)\nlearn_bwd.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.save('second-bwd')\nlearn_bwd.load('second-bwd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.freeze_to(-3)\nlearn_bwd.fit_one_cycle(2, slice(1e-5/(2.6**4),1e-5), moms=(0.8,0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.save('third-bwd')\nlearn_bwd.load('third-bwd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.unfreeze()\nlearn_bwd.lr_find()\nlearn_bwd.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.fit_one_cycle(10, slice(1e-5/(2.6**4),1e-5), moms=(0.8,0.7), pct_start=0.3, wd =0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn_bwd.save('bwd-cls')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ordered_preds(learn_bert, ds_type, preds):\n  np.random.seed(42)\n  sampler = [i for i in learn_bert.data.dl(ds_type).sampler]\n  reverse_sampler = np.argsort(sampler)\n  preds = [p[reverse_sampler] for p in preds]\n  return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_raw_preds = learn_bert.get_preds(ds_type=DatasetType.Test)\ntest_preds_bert = get_ordered_preds(learn_bert, DatasetType.Test, test_raw_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_fwd_test, lbl_fwd_test = learn.get_preds(ds_type=DatasetType.Test,ordered=True)\npred_bwd_test, lbl_bwd_test = learn_bwd.get_preds(ds_type=DatasetType.Test,ordered=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(pred_fwd_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds_bert = torch.FloatTensor(test_preds_bert[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_preds_test = (0.4*pred_fwd_test + 0.4*pred_bwd_test + 0.2*test_preds_bert)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.iloc[:, 1:] = final_preds_test.numpy()\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(6, 5, figsize=(18, 15))\naxes = axes.ravel()\nbins = np.linspace(0, 1, 20)\n\nfor i, col in enumerate(targets):\n    ax = axes[i]\n    sns.distplot(train[col], label=col, bins=bins, ax=ax, color='blue')\n    sns.distplot(sub[col], label=col, bins=bins, ax=ax, color='orange')\n    # ax.set_title(col)\n    ax.set_xlim([0, 1])\nplt.tight_layout()\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_train = train[targets].values\n\n# for column_ind in range(30):\n#     curr_column = y_train[:, column_ind]\n#     values = np.unique(curr_column)\n#     map_quantiles = []\n#     for val in values:\n#         occurrence = np.mean(curr_column == val)\n#         cummulative = sum(el['occurrence'] for el in map_quantiles)\n#         map_quantiles.append({'value': val, 'occurrence': occurrence, 'cummulative': cummulative})\n            \n#     for quant in map_quantiles:\n#         pred_col = final_preds_test[:, column_ind]\n#         q1, q2 = np.quantile(pred_col, quant['cummulative']), np.quantile(pred_col, min(quant['cummulative'] + quant['occurrence'], 1))\n#         pred_col[(pred_col >= q1) & (pred_col <= q2)] = quant['value']\n#         final_preds_test[:, column_ind] = pred_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sub.iloc[:, 1:] = final_preds_test.numpy()\n# sub.to_csv('submission.csv', index=False)\n# sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, axes = plt.subplots(6, 5, figsize=(18, 15))\n# axes = axes.ravel()\n# bins = np.linspace(0, 1, 20)\n\n# for i, col in enumerate(targets):\n#     ax = axes[i]\n#     sns.distplot(train[col], label=col, bins=bins, ax=ax, color='blue')\n#     sns.distplot(sub[col], label=col, bins=bins, ax=ax, color='orange')\n#     # ax.set_title(col)\n#     ax.set_xlim([0, 1])\n# plt.tight_layout()\n# plt.show()\n# plt.close()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"086421f7eec44c769f08f5f68fafafdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e7c81c0da784e04b530236bad005c33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18b951cd8c1447eaa1e12f972ac37d42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"  9%","description_tooltip":null,"layout":"IPY_MODEL_9e743ecd26cd4877a539f9bbbd23d114","max":308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e34fafda1e234d9c981322beff1068e7","value":29}},"35645b239e914aee807cfdc234fc5b75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfdee9b109bc4176a0bc3a26ae38f7a3","placeholder":"​","style":"IPY_MODEL_086421f7eec44c769f08f5f68fafafdc","value":" 29/308 [7:12:46&lt;66:18:40, 855.63s/it]"}},"554271f3ed5d48efa844608a0b72fdac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"685ecca481e3463d83a2465f15f7b33f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_80ae0d356c3e4b1bbe511c5f5a2694b5","max":4059,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a34804b28be74d7c9972a0a13410ba77","value":4059}},"7f49d7d685554687bc2d131959058cb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80ae0d356c3e4b1bbe511c5f5a2694b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"840e74b11eb44a58b1ed0433e924dc82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e743ecd26cd4877a539f9bbbd23d114":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a34804b28be74d7c9972a0a13410ba77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"a61c8f56dbd74e29a155fad0d7095f79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18b951cd8c1447eaa1e12f972ac37d42","IPY_MODEL_35645b239e914aee807cfdc234fc5b75"],"layout":"IPY_MODEL_7f49d7d685554687bc2d131959058cb3"}},"c9ab84b07a32426282543b5ff054ddec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_840e74b11eb44a58b1ed0433e924dc82","placeholder":"​","style":"IPY_MODEL_554271f3ed5d48efa844608a0b72fdac","value":" 4059/4059 [14:53&lt;00:00,  4.54it/s]"}},"dfdee9b109bc4176a0bc3a26ae38f7a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e34fafda1e234d9c981322beff1068e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"fd692cff30e343aa8afa007a05d66acc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_685ecca481e3463d83a2465f15f7b33f","IPY_MODEL_c9ab84b07a32426282543b5ff054ddec"],"layout":"IPY_MODEL_0e7c81c0da784e04b530236bad005c33"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":1}