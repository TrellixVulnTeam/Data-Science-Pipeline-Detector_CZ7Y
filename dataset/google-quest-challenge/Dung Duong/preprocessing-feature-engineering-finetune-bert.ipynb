{"cells":[{"metadata":{"colab_type":"text","id":"bTrHALFdjWkt"},"cell_type":"markdown","source":"## Import library"},{"metadata":{"colab_type":"code","id":"9pMmMTlnja20","outputId":"487a4416-aace-4be7-ff46-1badf354c54b","colab":{"base_uri":"https://localhost:8080/","height":69},"trusted":true},"cell_type":"code","source":"!pip install ../input/sacremoses/sacremoses-master/ > /dev/null\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow_hub as hub\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport gc\nimport sys\nimport os\nimport sys\nimport glob\nimport torch\nimport re \nimport math\nimport pickle\nimport datetime\nimport string \nimport nltk \nimport spacy\nimport tensorflow.keras.backend as K\n\nfrom scipy.stats import spearmanr\nfrom math import floor, ceil\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import GroupKFold\nfrom scipy import spatial\nfrom nltk.tokenize import sent_tokenize\nfrom nltk import wordpunct_tokenize\nfrom sklearn.linear_model import MultiTaskElasticNet\nfrom scipy.stats import spearmanr, rankdata\n\nsys.path.insert(0, \"../input/transformers/transformers-master/\")\n\nimport transformers as ppb\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"Ctb1v-JdjcNy"},"cell_type":"markdown","source":"## Read data"},{"metadata":{"colab_type":"code","id":"lepIIvrm7GZk","colab":{},"trusted":true},"cell_type":"code","source":"DEVICE = torch.device(\"cuda\")","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"xiyns9qZ7HLc","colab":{},"trusted":true},"cell_type":"code","source":"root_path = '../input/google-quest-challenge/'\nss = pd.read_csv(root_path + '/sample_submission.csv')\ntrain = pd.read_csv(root_path + '/train.csv')\ntest = pd.read_csv(root_path + '/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"Dn_hXPxblScW"},"cell_type":"markdown","source":"### Concat sentences"},{"metadata":{"colab_type":"code","id":"bIjU6qhSlevu","colab":{},"trusted":true},"cell_type":"code","source":"# train.columns","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"EgT9e7jskS2x","colab":{},"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"foblx3HZloX-","colab":{},"trusted":true},"cell_type":"code","source":"# train['full_text']","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"ynSvF7R4N_wV","colab":{},"trusted":true},"cell_type":"code","source":"# technology=train[train.category == \"TECHNOLOGY\"]","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"9K4gH90A94lN","colab":{},"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"E2tvHV3LIagN","colab_type":"text"},"cell_type":"markdown","source":"## Exploratory"},{"metadata":{"id":"aDTfxnkCIdW2","colab_type":"code","outputId":"2e311951-d17d-42fc-e5db-9c593e5dbc47","colab":{"base_uri":"https://localhost:8080/","height":424},"trusted":true},"cell_type":"code","source":"train[['question_title', 'question_body', 'answer']]","execution_count":null,"outputs":[]},{"metadata":{"id":"Qx0Q-a3c1-oB","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train['question_title'] = train['question_title'] + '?'\ntrain['question_body'] = train['question_body'] + '?'\ntrain['answer'] = train['answer'] + '.'\n","execution_count":null,"outputs":[]},{"metadata":{"id":"2oTS7SBv_pHf","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train['full_question'] = train['question_title'] + \" [SEP] \" + train['question_body']\ntest['full_question'] = test['question_title'] + \" [SEP] \" + test['question_body']","execution_count":null,"outputs":[]},{"metadata":{"id":"ECtOb-F61vf4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# count = 0\n# for i in train.answer:\n#   print(count)\n#   print(i)\n#   print(\"-\"*100)\n#   count += 1\n#   if count == 10:\n#     break","execution_count":null,"outputs":[]},{"metadata":{"id":"eB9uXS8pJLAS","colab_type":"text"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = torch.device(\"cuda\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_model_config = '../input/pretrained-bert-models-for-pytorch/bert-base-uncased/bert_config.json'\nbert_config = ppb.BertConfig.from_json_file(bert_model_config)\ntokenizer = ppb.BertTokenizer.from_pretrained('../input/pretrained-bert-models-for-pytorch/bert-base-uncased-vocab.txt')\nbert_model = ppb.BertModel.from_pretrained('../input/pretrained-bert-models-for-pytorch/bert-base-uncased/', config=bert_config)\nbert_model.to(DEVICE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#text = 'i love you embedding'\n#print(tokenizer.tokenize(text))\n#print(tokenizer.vocab)","execution_count":null,"outputs":[]},{"metadata":{"id":"V98l3XhgJM-T","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport re\nalphabets= \"([A-Za-z])\"\nprefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\nsuffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\nstarters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\nacronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\nwebsites = \"[.](com|net|org|io|gov)\"\n\ndef split_into_sentences(text):\n    text = \" \" + text + \"  \"\n    text = text.replace(\"\\n\",\" \")\n    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n    text = re.sub(websites,\"<prd>\\\\1\",text)\n    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n    text = text.replace(\".\",\".<stop>\")\n    text = text.replace(\"?\",\"?<stop>\")\n    text = text.replace(\"!\",\"!<stop>\")\n    text = text.replace(\"<prd>\",\".\")\n    sentences = text.split(\"<stop>\")\n    sentences = sentences[:-1]\n    sentences = [s.strip() for s in sentences]\n    return sentences\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"A48I95EK0V9N","outputId":"91ce1429-5cbb-49b2-d78c-981f8cb1feef","colab":{"base_uri":"https://localhost:8080/","height":52},"trusted":true},"cell_type":"code","source":"import itertools\nwords = set(nltk.corpus.words.words())\n\ndef remove_non_english(text):\n    return \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in words or not w.isalpha())\n\n#     doc = spacy_nlp(x) \n#     tokens = [token.text for token in doc]\n#     preprocessed_doc = \" \".join(w for w in tokens if w.lower() in words)\n#     return preprocessed_doc\n\n\ndef add_token_url(text):\n    URL_REGEX = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\"\n    urls = re.findall(URL_REGEX,text)\n    count = 0\n    for url in urls:\n        text = text.replace(url, '<URL>')\n    text = sent_tokenize(text)\n    text = [x for x in text if x not in string.punctuation]\n    result = []\n    text = [x.splitlines() for x in text]\n    text = list(itertools.chain.from_iterable(text))\n    text = list(filter(None, text))\n\n    text = [remove_non_english(x) for x in text]\n    text = [x for x in text if x not in string.punctuation]\n    text = [re.sub(r'[^\\w\\s]','',x) for x in text]\n    text = [re.sub(' +', ' ', x) for x in text]\n    text = [x.strip() for x in text]\n    text = list(filter(None, text))\n\n    return ' [SEP] '.join(text)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"_PgpdlQq2K-Y","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train['preprocessed_full_question'] = [add_token_url(x) for x in train['full_question']]\ntrain['preprocessed_answer'] = [add_token_url(x) for x in train['answer']]\n\ntest['preprocessed_full_question'] = [add_token_url(x) for x in test['full_question']]\ntest['preprocessed_answer'] = [add_token_url(x) for x in test['answer']]\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"QFzemeubjf6r"},"cell_type":"markdown","source":"## Load Bert model"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(tokenizer))  # 28997\ntokenizer.add_tokens([\"<URL>\"])\nprint(len(tokenizer))  # 28997\n\nbert_model.resize_token_embeddings(len(tokenizer)) \n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"BF6h5xzLmp2r"},"cell_type":"markdown","source":"## Convert to Bert inputs"},{"metadata":{"colab_type":"code","id":"BQ-4pU4s7NSZ","colab":{},"trusted":true},"cell_type":"code","source":"def convert_text_to_vector(df, col, tokenizer, model):\n    df[col] = [x[:512] for x in df[col]]\n    tokenized = df[col].apply(lambda x: tokenizer.encode(x, add_special_tokens = True))\n    max_len= 512 \n    padded = [i + [0]*(max_len - len(i)) for i in tokenized]\n\n    for i in tqdm(range(len(tokenized))):\n        tokenized[i].extend([0]*(max_len - len(tokenized[i])))\n    tokenized = [np.array(x) for x in tokenized]\n    tokenized = np.array(tokenized)\n    attention_mask = np.where(tokenized != 0,1,0)\n    input_ids = torch.tensor(tokenized).to(DEVICE)\n    attention_mask = torch.tensor(attention_mask).to(DEVICE)\n    \n    segments = []\n    for tokens in tqdm(tokenized):\n      segment = []\n      current_segment_id = 0\n      for token in tokens:\n          segment.append(current_segment_id)\n          if token == 102:\n            current_segment_id += 1\n      segment = segment + [current_segment_id+1] * (512 - len(tokens))\n      segments.append(segment)\n    segments = torch.tensor(segments).to(DEVICE)\n    return input_ids, attention_mask, segments\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"_kNeSP4d83hu","colab":{},"trusted":true},"cell_type":"code","source":"batch_size = 64\n\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"K_XSxxopgxAj","colab":{},"trusted":true},"cell_type":"code","source":"targets = [\n        'question_asker_intent_understanding',\n        'question_body_critical',\n        'question_conversational',\n        'question_expect_short_answer',\n        'question_fact_seeking',\n        'question_has_commonly_accepted_answer',\n        'question_interestingness_others',\n        'question_interestingness_self',\n        'question_multi_intent',\n        'question_not_really_a_question',\n        'question_opinion_seeking',\n        'question_type_choice',\n        'question_type_compare',\n        'question_type_consequence',\n        'question_type_definition',\n        'question_type_entity',\n        'question_type_instructions',\n        'question_type_procedure',\n        'question_type_reason_explanation',\n        'question_type_spelling',\n        'question_well_written',\n        'answer_helpful',\n        'answer_level_of_information',\n        'answer_plausible',\n        'answer_relevance',\n        'answer_satisfaction',\n        'answer_type_instructions',\n        'answer_type_procedure',\n        'answer_type_reason_explanation',\n        'answer_well_written'    \n    ]\n\ny = train[targets].values\n","execution_count":null,"outputs":[]},{"metadata":{"id":"dh8inKhTzS9m","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# ----","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"hX6vipXrBZSc"},"cell_type":"markdown","source":"## Features Engineering"},{"metadata":{"colab_type":"code","id":"bajtScNrYlZj","colab":{},"trusted":true},"cell_type":"code","source":"def chunks(l, n):\n    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n    for i in range(0, len(l), n):\n        yield l[i:i + n]\n\ndef splitDataFrameIntoSmaller(df, chunkSize = 10000): \n    listOfDf = list()\n    numberChunks = len(df) // chunkSize + 1\n    for i in range(numberChunks):\n        listOfDf.append(df[i*chunkSize:(i+1)*chunkSize])\n    return listOfDf\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"zn37i75KHaNN","colab_type":"text"},"cell_type":"markdown","source":"### Categpry features"},{"metadata":{"colab_type":"code","id":"T1-VaoYFBYmB","colab":{},"trusted":true},"cell_type":"code","source":"import sklearn\nle = sklearn.preprocessing.LabelEncoder()\nle.fit(train['category'])\ncategory_features_train = le.fit_transform(train['category'])\ncategory_features_test = le.fit_transform(test['category'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"GL8YDrL25Ofy"},"cell_type":"markdown","source":"### Universal Google Encoding"},{"metadata":{"colab_type":"code","id":"lDG0VWisTnfM","outputId":"3c9eabad-996e-4ec7-bdd4-5bfbbe957d61","colab":{"base_uri":"https://localhost:8080/","height":191},"trusted":true},"cell_type":"code","source":"module_url = \"../input/universalsentenceencoderlarge4/\"\nembed = hub.load(module_url)\n\ndef encoding_sentence(df, col, batch_size, model):   \n    all_features = []\n    for tokenized_batch in tqdm(splitDataFrameIntoSmaller(df[col].values, chunkSize = batch_size)):\n        all_features.append(model(tokenized_batch)[\"outputs\"].numpy())\n    all_features = np.vstack(all_features)\n    return all_features\n\ndef calculate_text_distance(question_title_features,question_body_features,answer_features):\n\n    dist1 = list(map(lambda x, y: np.linalg.norm(x-y), question_title_features, question_body_features))\n    dist2 = list(map(lambda x, y: np.linalg.norm(x-y), question_body_features,answer_features))\n    dist3 =list(map(lambda x, y: np.linalg.norm(x-y), answer_features,question_title_features))\n    cosdist = np.array([dist1, dist2, dist3])\n    cosdist = cosdist.T\n\n    dist1 = list(map(lambda x, y: spatial.distance.cosine(x,y), question_title_features, question_body_features))\n    dist2 = list(map(lambda x, y: spatial.distance.cosine(x,y), question_body_features,answer_features))\n    dist3 = list(map(lambda x, y: spatial.distance.cosine(x,y), answer_features,question_title_features))\n    l2dist = np.array([dist1, dist2, dist3])\n    l2dist = l2dist.T\n\n    distance = np.hstack([cosdist,l2dist])\n    return distance\n\n\n\n\nquestion_title_encoding = encoding_sentence(train, 'question_title', 32, embed)\nquestion_body_encoding = encoding_sentence(train, 'question_body', 32, embed)\nanswer_encoding  = encoding_sentence(train, 'answer', 32, embed)\n\nquestion_title_encoding_test = encoding_sentence(test, 'question_title', 32, embed)\nquestion_body_encoding_test = encoding_sentence(test, 'question_body', 32, embed)\nanswer_encoding_test  = encoding_sentence(test, 'answer', 32, embed)\n\ntrain_distance = calculate_text_distance(question_title_encoding,question_body_encoding,answer_encoding)\ntest_distance = calculate_text_distance(question_title_encoding_test,question_body_encoding_test,answer_encoding_test)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"kcRuyL8RmBRr"},"cell_type":"markdown","source":"## Build model "},{"metadata":{"colab_type":"code","id":"gYXzOpu4nVGs","colab":{},"trusted":true},"cell_type":"code","source":"def compute_spearmanr(trues, preds):    \n    rhos = []\n    for col_trues, col_pred in zip(trues.T, preds.T):\n        rhos.append(\n            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n    return np.mean(rhos)\n\n\nclass CustomCallback(tf.keras.callbacks.Callback):\n    \n    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n\n        self.valid_inputs = valid_data[0]\n        self.valid_outputs = valid_data[1]\n        self.test_inputs = test_data\n        \n        self.batch_size = batch_size\n        self.fold = fold\n        \n    def on_train_begin(self, logs={}):\n        self.valid_predictions = []\n        self.test_predictions = []\n        \n    def on_epoch_end(self, epoch, logs={}):\n        self.valid_predictions = self.model.predict(self.valid_inputs)\n        \n        rho_val = compute_spearmanr(self.valid_outputs, self.valid_predictions)\n        print('\\n Epoch {}, Validation score {}'.format(epoch,rho_val))\n\n        \n        if self.fold is not None:\n            self.model.save_weights(f'bert-base-{fold}-{epoch}.h5py')\n        \n        #self.test_predictions = self.model.predict(self.test_inputs)\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"vnLexOnnmAjn","colab":{},"trusted":true},"cell_type":"code","source":"# BERT_PATH = '../input/bert-base-uncased-huggingface-transformer/'\n# from transformers import *\n\nclass BertClassification(tf.keras.Model):\n    def __init__(self,flag_distance = False, flag_cat = False,flag_lstm = False, trainable = True):\n        super().__init__(name='BertClassification')\n        self.bert_layer = hub.KerasLayer('../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12', trainable=trainable)\n#         config = BertConfig() # print(config) to see settings\n#         config.output_hidden_states = False # Set to True to obtain hidden states\n#         config.trainable = True\n#         self.bert_layer = TFBertModel.from_pretrained(BERT_PATH+'bert-base-uncased-tf_model.h5', config=config)\n\n        self.global_avarage = tf.keras.layers.GlobalAveragePooling1D()\n        self.dense_out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")\n        self.embed =  tf.keras.layers.Embedding(500, 64, input_length=1)\n        self.dropout = tf.keras.layers.Dropout(0.25)\n        self.flag_distance = flag_distance\n        self.flag_cat = flag_cat\n        self.flag_lstm = flag_lstm\n\n\n    def call(self, inputs):\n        max_len = 512\n        inputs = [tf.cast(x, tf.int32) for x in inputs]\n\n        input_word_ids_title, input_masks_title, input_segments_title = inputs[0],inputs[1],inputs[2]\n        input_word_ids_answer, input_masks_answer, input_segments_answer =  inputs[3],inputs[4],inputs[5]     \n\n        features_cat = inputs[6]\n        distance_features = tf.cast(inputs[7], tf.float32)  \n\n        _, sequence_output_title = self.bert_layer([input_word_ids_title, input_masks_title, input_segments_title])\n        global_title = self.global_avarage(sequence_output_title)\n\n\n        _, sequence_output_answer = self.bert_layer([input_word_ids_answer, input_masks_answer, input_segments_answer])\n        global_answer = self.global_avarage(sequence_output_answer)\n\n\n        embedding_cat = self.embed(features_cat)\n        embedding_cat = self.global_avarage(embedding_cat)\n        embedding_cat = self.dropout(embedding_cat)\n        distance_features = self.dropout(distance_features)\n\n        concat = tf.keras.layers.concatenate([global_title,\n                                              global_answer,\n                                              embedding_cat,\n                                              distance_features])\n\n        concat = self.dropout(concat)\n        out = self.dense_out(concat)\n        return out\n\n# model = BertClassification()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"avQH-hJOAueY","colab":{},"trusted":true},"cell_type":"code","source":"# def training(X_train,y_train,X_val,y_val,X_test):  \n#   batch_size  =  2\n#   custom_callback = CustomCallback(valid_data=(X_val,y_val),test_data=X_test, batch_size=batch_size)\n#   learning_rate = 3e-5\n#   epochs = 20\n#   loss_function = 'binary_crossentropy'\n#   optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n#   model = BertClassification()\n#   model.compile(loss=loss_function, optimizer=optimizer)\n#   model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,callbacks=[custom_callback])\n#   return model\n\n\n# def training_2(X_train,y_train,X_val,y_val,X_test):  \n#   batch_size  =  2\n#   custom_callback = CustomCallback(valid_data=(X_val,y_val),test_data=X_test, batch_size=batch_size)\n#   learning_rate = 3e-5\n#   epochs = 3\n#   loss_function = 'binary_crossentropy'\n#   optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n#   model = question_answer_model()\n#   model.compile(loss=loss_function, optimizer=optimizer)\n#   model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,callbacks=[custom_callback])\n#   return model  ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"4Up6irCQLZqk","outputId":"3b8974a2-95eb-4d25-8967-0e2c0fe5db82","colab":{"base_uri":"https://localhost:8080/","height":156},"trusted":true},"cell_type":"code","source":"#inputs_ids, attention_masks, segments = convert_text_to_vector(train, 'full_text', tokenizer, bert_model)\n#inputs_ids_test, attention_masks_test, segments_test = convert_text_to_vector(test, 'full_text', tokenizer, bert_model)\n\n\ninputs_ids_title, attention_masks_title, segments_title = convert_text_to_vector(train, 'preprocessed_full_question', tokenizer, bert_model)\ninputs_ids_test_title, attention_masks_test_title, segments_test_title = convert_text_to_vector(test, 'preprocessed_full_question', tokenizer, bert_model)\n\ninputs_ids_answer, attention_masks_answer, segments_answer = convert_text_to_vector(train, 'preprocessed_answer', tokenizer, bert_model)\ninputs_ids_test_answer, attention_masks_test_answer, segments_test_answer = convert_text_to_vector(test, 'preprocessed_answer', tokenizer, bert_model)\n\n\n\nX = [inputs_ids_title.cpu().data.numpy(), \n     attention_masks_title.cpu().data.numpy(), \n     segments_title.cpu().data.numpy(),\n     inputs_ids_answer.cpu().data.numpy(),\n     attention_masks_answer.cpu().data.numpy(),\n     segments_answer.cpu().data.numpy(),\n     category_features_train,\n     train_distance\n     ]\n\nX_test = [inputs_ids_test_title.cpu().data.numpy(), \n     attention_masks_test_title.cpu().data.numpy(), \n     segments_test_title.cpu().data.numpy(),\n     inputs_ids_test_answer.cpu().data.numpy(),\n     attention_masks_test_answer.cpu().data.numpy(),\n     segments_test_answer.cpu().data.numpy(),\n     category_features_test,\n     test_distance\n     ]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"COKUoTzSyKzM","colab_type":"code","outputId":"3b5099a4-b3c5-4b08-c3bd-a81f3b9a9f02","colab":{"base_uri":"https://localhost:8080/","height":992},"trusted":true},"cell_type":"code","source":"import timeit\n\nbatch_size  = 4\nlearning_rate = 3e-5\nepochs = 3\nloss_function = 'binary_crossentropy'\n\ngkf = GroupKFold(n_splits=5).split(X=train.category, groups=train.category)\n\nvalid_preds = []\ntest_preds = []\nvalidation_score = []\n\n\nfor fold, (train_idx, valid_idx) in tqdm(enumerate(gkf)):\n    if fold in [1, 2]:\n        print(\"Fold {}\".format(fold))\n\n        start = timeit.default_timer()\n\n        X_train = [X[i][train_idx] for i in range(len(X))]\n        y_train = y[train_idx]\n        X_val = [X[i][valid_idx] for i in range(len(X))]\n        y_val = y[valid_idx]   \n        K.clear_session()\n        \n        custom_callback = CustomCallback(valid_data=(X_val,y_val),test_data=X_test, batch_size=batch_size)\n        \n        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n        \n        model = BertClassification()\n        model.compile(loss=loss_function, optimizer=optimizer)\n\n        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n        \n        test_prediction = model.predict(X_test)\n        valid_preds.append(model.predict(X_val))\n        test_preds.append(test_prediction)       \n        rho_val = compute_spearmanr(y_val, valid_preds[-1])\n        validation_score.append(rho_val)\n        \n        #print(\"Spearman score {}\".format(rho_val))\n        \n        stop = timeit.default_timer()\n        training_time = stop  -  start  \n        \n        print(\"Training time {}\".format(training_time))\n        \n        \n        del model\n        del X_train\n        del y_train\n        del X_val\n        del y_val \n\nprint(\"Validation score {}\".format(np.mean(validation_score)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds[1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(test_preds, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"rXQIb4S-iG-B","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\"\"\"\n\n\nfrom sklearn.model_selection import train_test_split\nX_train,y_train, X_val, y_val = train_test_split(X,y,random_state = 1,test_size = 0.25)\nprint(\"Validation score {}\".format(compute_spearmanr(y_val, model.predict(X_val)))\n\"\"\"\n# test_preds[0]","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"R9xqaKryhfQ5","colab":{},"trusted":true},"cell_type":"code","source":"# batch_size  = 2\n# learning_rate = 3e-5\n# epochs = 2\n# loss_function = 'binary_crossentropy'\n\n# X_val = [X[i][:500] for i in range(len(X))]\n# y_val = y[:500]   \n        \n\n# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n# model = BertClassification()\n# model.compile(loss=loss_function, optimizer=optimizer)\n\n# # custom_callback = CustomCallback(valid_data=(X_val,y_val),test_data=X_test, batch_size=batch_size)\n# model.fit(X, y, epochs=epochs, batch_size=batch_size)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"iAIC9F1x24Wm"},"cell_type":"markdown","source":"## Elastic Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['category'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nonehotencoder = OneHotEncoder()\nonehotencoder.fit(category_features_train.reshape(-1,1))\n    \ncategory_onehot_train = onehotencoder.transform(category_features_train.reshape(-1,1)).toarray()\ncategory_onehot_test = onehotencoder.transform(category_features_test.reshape(-1,1)).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_onehot_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_distance.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(X):\n    return 1/(1+np.exp(-X))","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"JNJmst1L26zx","colab":{},"trusted":true},"cell_type":"code","source":"X = np.hstack([\n     category_onehot_train,\n     train_distance\n     ])\n\nX_test = np.hstack([\n     category_onehot_test,\n     test_distance\n     ])\n\nelastic_model = MultiTaskElasticNet(alpha=0.001, random_state=42, l1_ratio=0.5)\nelastic_model.fit(X, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"elastic_prediction = sigmoid(elastic_model.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"elastic_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds.append(elastic_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = np.mean(test_preds, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"n9GzqOsVg4Nz","colab":{},"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns = list(ss.columns))\nsubmission['qa_id'] = test['qa_id']\nsubmission[targets] = test_preds\nsubmission.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"id":"ib5lyK_wyKz5","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"id":"kVKChuZXyK0M","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/","execution_count":null,"outputs":[]},{"metadata":{"id":"q8-gZN_-IBc4","colab_type":"text"},"cell_type":"markdown","source":"https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/ \\\nhttps://medium.com/miq-tech-and-analytics/how-to-detect-non-english-language-words-and-remove-them-from-your-keyword-insights-599b91916071 \\\nhttps://trituenhantao.io/lap-trinh/huong-dan-fine-tuning-bert-voi-pytorch/"},{"metadata":{"id":"tHTPn_uSIB6J","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"fork-of-fine-tune-bert-de8f2d.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4b8d607420be4dbe8595a6af811d9da4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_123cc1d5b84d474d9791a4a3ef2b14a8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1f53e6cd5855411eb05bfa60e512692b","IPY_MODEL_957a8f18a13f49d5975edc87d4f58bbd"]}},"123cc1d5b84d474d9791a4a3ef2b14a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f53e6cd5855411eb05bfa60e512692b":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0522e27d5fdd40a7984708648733f05a","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2fab5ef84b3c4571abdc5cb0050b34c0"}},"957a8f18a13f49d5975edc87d4f58bbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2d5f9283da9d4c6fad82958294632d5a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 232k/232k [00:00&lt;00:00, 2.68MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b3a98dbae534f8c933e5109a2a0914d"}},"0522e27d5fdd40a7984708648733f05a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2fab5ef84b3c4571abdc5cb0050b34c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d5f9283da9d4c6fad82958294632d5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9b3a98dbae534f8c933e5109a2a0914d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2932d365d03467983af58b520b48b2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0e89618a1ca643178b0075fd41ee4b68","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_962d56a80f754fcabc8de08c44b31c8c","IPY_MODEL_587b592e34a6418cbc7756b1d6d51fb9"]}},"0e89618a1ca643178b0075fd41ee4b68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"962d56a80f754fcabc8de08c44b31c8c":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_45926b73bfdd4730ba3f7d9c17ac9b0d","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":361,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":361,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_921304090ef342ac9e24db128af6ef64"}},"587b592e34a6418cbc7756b1d6d51fb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9b3eef36fe4149bbb10b868539d2d4bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 361/361 [00:00&lt;00:00, 9.10kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8d31522a6f534cadb0d41df207eb1243"}},"45926b73bfdd4730ba3f7d9c17ac9b0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"921304090ef342ac9e24db128af6ef64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b3eef36fe4149bbb10b868539d2d4bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8d31522a6f534cadb0d41df207eb1243":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"788b7b4966f547ae95aa41d59c54fbb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1bbee2be23b54a30be9f43396e2d4388","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_56986652085442f3b9143efedad3b67f","IPY_MODEL_cb05c65ef60146c084043b62335e0bde"]}},"1bbee2be23b54a30be9f43396e2d4388":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56986652085442f3b9143efedad3b67f":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bfa8b1e6eae34a76a66025b721b90eb4","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b928664b17e54fec9f703d36398237a6"}},"cb05c65ef60146c084043b62335e0bde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_02103b64488b468990b966de03316032","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 440M/440M [00:05&lt;00:00, 74.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c318336734f94413ace2727501182d03"}},"bfa8b1e6eae34a76a66025b721b90eb4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b928664b17e54fec9f703d36398237a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"02103b64488b468990b966de03316032":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c318336734f94413ace2727501182d03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":1}