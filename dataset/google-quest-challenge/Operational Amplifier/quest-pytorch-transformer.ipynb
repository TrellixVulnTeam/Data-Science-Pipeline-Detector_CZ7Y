{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Pytorch BERT baseline**","metadata":{}},{"cell_type":"markdown","source":"In this version, I convert https://www.kaggle.com/akensert/bert-base-tf2-0-minimalistic into pytorch version","metadata":{}},{"cell_type":"markdown","source":"**Please upvote the kernel if you find it helpful**","metadata":{}},{"cell_type":"markdown","source":"### Install HuggingFace transformers & sacremoses dependency","metadata":{}},{"cell_type":"markdown","source":"As we are not allowed to use internet I've created required datasets and commands to setup Hugging Face Transformers setup in offline mode. You can find the required github codebases in the datasets.\n\n* sacremoses dependency - https://www.kaggle.com/axel81/sacremoses\n* transformers - https://www.kaggle.com/axel81/transformers","metadata":{}},{"cell_type":"code","source":"!pip install ../input/sacremoses/sacremoses-master/\n!pip install ../input/transformers/transformers-master/","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-12T19:13:56.183115Z","iopub.execute_input":"2022-04-12T19:13:56.183523Z","iopub.status.idle":"2022-04-12T19:14:10.279781Z","shell.execute_reply.started":"2022-04-12T19:13:56.183468Z","shell.execute_reply":"2022-04-12T19:14:10.278874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Required Imports\n\nI've added imports that will be used in training too","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nDATA_DIR = '../input/google-quest-challenge'","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:10.283246Z","iopub.execute_input":"2022-04-12T19:14:10.283611Z","iopub.status.idle":"2022-04-12T19:14:10.288515Z","shell.execute_reply.started":"2022-04-12T19:14:10.283537Z","shell.execute_reply":"2022-04-12T19:14:10.287653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:10.289918Z","iopub.execute_input":"2022-04-12T19:14:10.290492Z","iopub.status.idle":"2022-04-12T19:14:10.998331Z","shell.execute_reply.started":"2022-04-12T19:14:10.290444Z","shell.execute_reply":"2022-04-12T19:14:10.997412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:11.000148Z","iopub.execute_input":"2022-04-12T19:14:11.000524Z","iopub.status.idle":"2022-04-12T19:14:11.045073Z","shell.execute_reply.started":"2022-04-12T19:14:11.000457Z","shell.execute_reply":"2022-04-12T19:14:11.044226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_columns = sub.columns.values[1:].tolist()\ntarget_columns","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:11.049527Z","iopub.execute_input":"2022-04-12T19:14:11.049787Z","iopub.status.idle":"2022-04-12T19:14:11.056648Z","shell.execute_reply.started":"2022-04-12T19:14:11.049741Z","shell.execute_reply":"2022-04-12T19:14:11.055718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(f'{DATA_DIR}/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:11.059855Z","iopub.execute_input":"2022-04-12T19:14:11.060405Z","iopub.status.idle":"2022-04-12T19:14:11.230565Z","shell.execute_reply.started":"2022-04-12T19:14:11.060354Z","shell.execute_reply":"2022-04-12T19:14:11.229799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(f'{DATA_DIR}/test.csv')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:11.231867Z","iopub.execute_input":"2022-04-12T19:14:11.23234Z","iopub.status.idle":"2022-04-12T19:14:11.262449Z","shell.execute_reply.started":"2022-04-12T19:14:11.232285Z","shell.execute_reply":"2022-04-12T19:14:11.261644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n#import torch.utils.data as data\nfrom torchvision import datasets, models, transforms\nfrom transformers import *\nfrom sklearn.utils import shuffle\nimport random\nfrom math import floor, ceil\nfrom sklearn.model_selection import GroupKFold\n\nfrom torchtext.datasets import WikiText2\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\n\nMAX_LEN = 512\n#MAX_Q_LEN = 250\n#MAX_A_LEN = 259\nSEP_TOKEN_ID = 102\n\nclass QuestDataset(torch.utils.data.Dataset):\n    def __init__(self, df, train_mode=True, labeled=True):\n        self.df = df\n        self.train_mode = train_mode\n        self.labeled = labeled\n        #self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        #self.tokenizer = BertTokenizer.from_pretrained('../input/d/datasets/abhishek/bert-base-uncased/')\n        \n        self.tokenizer = get_tokenizer('basic_english')\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        token_ids, seg_ids = self.get_token_ids(row)\n        \n        self.vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n        self.vocab.set_default_index(vocab['<unk>'])\n        \n        if self.labeled:\n            labels = self.get_label(row)\n            return token_ids, seg_ids, labels\n        else:\n            return token_ids, seg_ids\n\n    def __len__(self):\n        return len(self.df)\n\n    def select_tokens(self, tokens, max_num):\n        if len(tokens) <= max_num:\n            return tokens\n        if self.train_mode:\n            num_remove = len(tokens) - max_num\n            remove_start = random.randint(0, len(tokens)-num_remove-1)\n            return tokens[:remove_start] + tokens[remove_start + num_remove:]\n        else:\n            return tokens[:max_num//2] + tokens[-(max_num - max_num//2):]\n\n    def trim_input(self, title, question, answer, max_sequence_length=MAX_LEN, \n                t_max_len=30, q_max_len=239, a_max_len=239):\n        t = self.tokenizer.tokenize(title)\n        q = self.tokenizer.tokenize(question)\n        a = self.tokenizer.tokenize(answer)\n\n        t_len = len(t)\n        q_len = len(q)\n        a_len = len(a)\n\n        if (t_len+q_len+a_len+4) > max_sequence_length:\n\n            if t_max_len > t_len:\n                t_new_len = t_len\n                a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n                q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n            else:\n                t_new_len = t_max_len\n\n            if a_max_len > a_len:\n                a_new_len = a_len \n                q_new_len = q_max_len + (a_max_len - a_len)\n            elif q_max_len > q_len:\n                a_new_len = a_max_len + (q_max_len - q_len)\n                q_new_len = q_len\n            else:\n                a_new_len = a_max_len\n                q_new_len = q_max_len\n\n\n            if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n                raise ValueError(\"New sequence length should be %d, but is %d\" \n                                 % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n\n            t = t[:t_new_len]\n            q = q[:q_new_len]\n            a = a[:a_new_len]\n\n        return t, q, a\n        \n    def get_token_ids(self, row):\n        t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer)\n\n        tokens = ['[CLS]'] + t_tokens + ['[SEP]'] + q_tokens + ['[SEP]'] + a_tokens + ['[SEP]']\n        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        if len(token_ids) < MAX_LEN:\n            token_ids += [0] * (MAX_LEN - len(token_ids))\n        ids = torch.tensor(token_ids)\n        seg_ids = self.get_seg_ids(ids)\n        return ids, seg_ids\n    \n    def get_seg_ids(self, ids):\n        seg_ids = torch.zeros_like(ids)\n        seg_idx = 0\n        first_sep = True\n        for i, e in enumerate(ids):\n            seg_ids[i] = seg_idx\n            if e == SEP_TOKEN_ID:\n                if first_sep:\n                    first_sep = False\n                else:\n                    seg_idx = 1\n        pad_idx = torch.nonzero(ids == 0)\n        seg_ids[pad_idx] = 0\n\n        return seg_ids\n\n    def get_label(self, row):\n        print(row[target_columns].values)\n        return torch.tensor(row[target_columns].values.astype(np.float32))\n\n    def collate_fn(self, batch):\n        token_ids = torch.stack([x[0] for x in batch])\n        seg_ids = torch.stack([x[1] for x in batch])\n    \n        if self.labeled:\n            labels = torch.stack([x[2] for x in batch])\n            return token_ids, seg_ids, labels\n        else:\n            return token_ids, seg_ids\n\ndef get_test_loader(batch_size=4):\n    df = pd.read_csv(f'{DATA_DIR}/test.csv')\n    ds_test = QuestDataset(df, train_mode=False, labeled=False)\n    loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=ds_test.collate_fn, drop_last=False)\n    loader.num = len(df)\n    \n    return loader\n        \ndef get_train_val_loaders(batch_size=4, val_batch_size=4, ifold=0):\n    df = pd.read_csv(f'{DATA_DIR}/train.csv')\n    df = shuffle(df, random_state=1234)\n    #split_index = int(len(df) * (1-val_percent))\n    gkf = GroupKFold(n_splits=5).split(X=df.question_body, groups=df.question_body)\n    for fold, (train_idx, valid_idx) in enumerate(gkf):\n        if fold == ifold:\n            df_train = df.iloc[train_idx]\n            df_val = df.iloc[valid_idx]\n            break\n\n    #print(df_val.head())\n    #df_train = df[:split_index]\n    #df_val = df[split_index:]\n\n    print(df_train.shape)\n    print(df_val.shape)\n\n    ds_train = QuestDataset(df_train)\n    train_loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=ds_train.collate_fn, drop_last=True)\n    train_loader.num = len(df_train)\n\n    ds_val = QuestDataset(df_val, train_mode=False)\n    val_loader = torch.utils.data.DataLoader(ds_val, batch_size=val_batch_size, shuffle=False, num_workers=0, collate_fn=ds_val.collate_fn, drop_last=False)\n    val_loader.num = len(df_val)\n    val_loader.df = df_val\n\n    return train_loader, val_loader\n\ndef test_train_loader():\n    loader, _ = get_train_val_loaders(4, 4, 1)\n    for ids, seg_ids, labels in loader:\n        print(\"ids: \",ids)\n        print(\"seg_ids: \",seg_ids.numpy())\n        print(\"labels: \",labels)\n        break\ndef test_test_loader():\n    loader = get_test_loader(4)\n    for ids, seg_ids in loader:\n        print(\"ids: \",ids)\n        print(\"seg_ids: \",seg_ids)\n        break","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:11.26435Z","iopub.execute_input":"2022-04-12T19:14:11.264876Z","iopub.status.idle":"2022-04-12T19:14:11.309842Z","shell.execute_reply.started":"2022-04-12T19:14:11.264669Z","shell.execute_reply":"2022-04-12T19:14:11.308663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:11.311286Z","iopub.execute_input":"2022-04-12T19:14:11.311736Z","iopub.status.idle":"2022-04-12T19:14:11.323542Z","shell.execute_reply.started":"2022-04-12T19:14:11.311545Z","shell.execute_reply":"2022-04-12T19:14:11.322753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls ../input/d/datasets/abhishek/bert-base-uncased","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:11.326794Z","iopub.execute_input":"2022-04-12T19:14:11.327184Z","iopub.status.idle":"2022-04-12T19:14:12.027928Z","shell.execute_reply.started":"2022-04-12T19:14:11.327001Z","shell.execute_reply":"2022-04-12T19:14:12.026661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Model","metadata":{}},{"cell_type":"code","source":"import math\nfrom typing import Tuple\n\nimport torch\nfrom torch import nn, Tensor\nimport torch.nn.functional as F\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torch.utils.data import dataset\n\nclass TransformerModel(nn.Module):\n\n    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n                 nlayers: int, dropout: float = 0.5):\n        super().__init__()\n        self.model_type = 'Transformer'\n        self.pos_encoder = PositionalEncoding(d_model, dropout)\n        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n        self.encoder = nn.Embedding(ntoken, d_model)\n        self.d_model = d_model\n        self.decoder = nn.Linear(d_model, ntoken)\n\n        self.init_weights()\n\n    def init_weights(self) -> None:\n        initrange = 0.1\n        self.encoder.weight.data.uniform_(-initrange, initrange)\n        self.decoder.bias.data.zero_()\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n        \"\"\"\n        Args:\n            src: Tensor, shape [seq_len, batch_size]\n            src_mask: Tensor, shape [seq_len, seq_len]\n\n        Returns:\n            output Tensor of shape [seq_len, batch_size, ntoken]\n        \"\"\"\n        src = self.encoder(src) * math.sqrt(self.d_model)\n        src = self.pos_encoder(src)\n        output = self.transformer_encoder(src, src_mask)\n        output = self.decoder(output)\n        return output\n\n\ndef generate_square_subsequent_mask(sz: int) -> Tensor:\n    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:12.031741Z","iopub.execute_input":"2022-04-12T19:14:12.03202Z","iopub.status.idle":"2022-04-12T19:14:12.046545Z","shell.execute_reply.started":"2022-04-12T19:14:12.03197Z","shell.execute_reply":"2022-04-12T19:14:12.045667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(max_len, 1, d_model)\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"\n        Args:\n            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n        \"\"\"\n        x = x + self.pe[:x.size(0)]\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:14:12.04814Z","iopub.execute_input":"2022-04-12T19:14:12.048799Z","iopub.status.idle":"2022-04-12T19:14:12.059868Z","shell.execute_reply.started":"2022-04-12T19:14:12.048748Z","shell.execute_reply":"2022-04-12T19:14:12.059153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import *\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass QuestModel(nn.Module):\n    def __init__(self,ids, n_classes=30):\n        super(QuestModel, self).__init__()\n        self.model_name = 'QuestModel'\n        #self.bert_model = BertModel.from_pretrained('../input/d/datasets/abhishek/bert-base-uncased/')\n        \n        #ntokens = len(vocab)  # size of vocabulary\n        ntokens = len(ids)  # size of vocabulary\n        emsize = 200  # embedding dimension\n        d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n        nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n        nhead = 2  # number of heads in nn.MultiheadAttention\n        dropout = 0.2  # dropout probability\n        \n        self.transformer_model=TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout)\n        \n        self.fc = nn.Linear(768, n_classes)\n        \n    def forward(self, ids, seg_ids):\n        attention_mask = (ids > 0)\n        #layers, pool_out = self.bert_model(input_ids=ids, token_type_ids=seg_ids, attention_mask=attention_mask)\n        \n        out =  self.transformer_model(ids, seg_ids)\n        \n        #print(layers[-1][0].size())\n        #print(pool_out.size())\n\n        #out = F.dropout(layers[-1][:, 0, :], p=0.2, training=self.training)\n        #out =  F.dropout(pool_out, p=0.2, training=self.training)\n        \n        logit = self.fc(out)\n        return logit\n    \ndef test_model():\n    x = torch.tensor([[1,2,3,4,5, 0, 0], [1,2,3,4,5, 0, 0]])\n    seg_ids = torch.tensor([[0,0,0,0,0, 0, 0], [0,0,0,0,0, 0, 0]])\n    model = QuestModel(x)\n\n    y = model(x, seg_ids)\n    print(y)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:15:31.495611Z","iopub.execute_input":"2022-04-12T19:15:31.49592Z","iopub.status.idle":"2022-04-12T19:15:31.5082Z","shell.execute_reply.started":"2022-04-12T19:15:31.49587Z","shell.execute_reply":"2022-04-12T19:15:31.507011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:15:31.789359Z","iopub.execute_input":"2022-04-12T19:15:31.789657Z","iopub.status.idle":"2022-04-12T19:15:32.511787Z","shell.execute_reply.started":"2022-04-12T19:15:31.789605Z","shell.execute_reply":"2022-04-12T19:15:32.510774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(ids):\n    model = QuestModel(ids)\n    #model.load_state_dict(torch.load(model_file))\n    model = model.cuda()\n    #model = DataParallel(model)\n    return model\n\ndef create_models(ids):\n    models = []\n    for i in range(5):\n        model = create_model(ids)\n        model.eval()\n        models.append(model)\n    return models","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:14.000359Z","iopub.execute_input":"2022-04-12T19:16:14.000673Z","iopub.status.idle":"2022-04-12T19:16:14.006737Z","shell.execute_reply.started":"2022-04-12T19:16:14.000623Z","shell.execute_reply":"2022-04-12T19:16:14.00599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch\ndef predict(models, test_loader):\n    all_scores = []\n    with torch.no_grad():\n        for ids, seg_ids in tqdm(test_loader, total=test_loader.num // test_loader.batch_size):\n            ids, seg_ids = ids.cuda(), seg_ids.cuda()\n            scores = []\n            for model in models:\n                outputs = torch.sigmoid(model(ids, seg_ids)).cpu()\n                scores.append(outputs)\n            all_scores.append(torch.mean(torch.stack(scores), 0))\n\n    all_scores = torch.cat(all_scores, 0).numpy()\n    \n    return all_scores","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:14.293521Z","iopub.execute_input":"2022-04-12T19:16:14.293853Z","iopub.status.idle":"2022-04-12T19:16:14.301922Z","shell.execute_reply.started":"2022-04-12T19:16:14.293784Z","shell.execute_reply":"2022-04-12T19:16:14.301044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = get_test_loader(batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:14.595836Z","iopub.execute_input":"2022-04-12T19:16:14.596137Z","iopub.status.idle":"2022-04-12T19:16:14.618998Z","shell.execute_reply.started":"2022-04-12T19:16:14.596083Z","shell.execute_reply":"2022-04-12T19:16:14.618345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = create_models(test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:14.999695Z","iopub.execute_input":"2022-04-12T19:16:15.000093Z","iopub.status.idle":"2022-04-12T19:16:15.074916Z","shell.execute_reply.started":"2022-04-12T19:16:15.000016Z","shell.execute_reply":"2022-04-12T19:16:15.074075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = predict(models, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:15.291215Z","iopub.execute_input":"2022-04-12T19:16:15.291529Z","iopub.status.idle":"2022-04-12T19:16:15.382394Z","shell.execute_reply.started":"2022-04-12T19:16:15.29147Z","shell.execute_reply":"2022-04-12T19:16:15.381078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:1]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:15.584336Z","iopub.execute_input":"2022-04-12T19:16:15.584634Z","iopub.status.idle":"2022-04-12T19:16:15.611245Z","shell.execute_reply.started":"2022-04-12T19:16:15.58458Z","shell.execute_reply":"2022-04-12T19:16:15.610271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:15.932519Z","iopub.execute_input":"2022-04-12T19:16:15.932833Z","iopub.status.idle":"2022-04-12T19:16:15.958457Z","shell.execute_reply.started":"2022-04-12T19:16:15.932779Z","shell.execute_reply":"2022-04-12T19:16:15.957098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generate Submission","metadata":{}},{"cell_type":"code","source":"test_loss = evaluate(best_model, test_data)\ntest_ppl = math.exp(test_loss)\nprint('=' * 89)\nprint(f'| End of training | test loss {test_loss:5.2f} | '\n      f'test ppl {test_ppl:8.2f}')\nprint('=' * 89)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:16.060632Z","iopub.execute_input":"2022-04-12T19:16:16.060925Z","iopub.status.idle":"2022-04-12T19:16:16.086357Z","shell.execute_reply.started":"2022-04-12T19:16:16.060876Z","shell.execute_reply":"2022-04-12T19:16:16.085265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[target_columns] = preds","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:16.087585Z","iopub.status.idle":"2022-04-12T19:16:16.088314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:16.190614Z","iopub.execute_input":"2022-04-12T19:16:16.190904Z","iopub.status.idle":"2022-04-12T19:16:16.221485Z","shell.execute_reply.started":"2022-04-12T19:16:16.190852Z","shell.execute_reply":"2022-04-12T19:16:16.220723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:16:16.34582Z","iopub.execute_input":"2022-04-12T19:16:16.346136Z","iopub.status.idle":"2022-04-12T19:16:16.375888Z","shell.execute_reply.started":"2022-04-12T19:16:16.346085Z","shell.execute_reply":"2022-04-12T19:16:16.375129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}