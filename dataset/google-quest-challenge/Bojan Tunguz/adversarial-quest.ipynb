{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook we'll try to use adversarial validation in order to see how similar/different the train and test sets are. Since we don't have access to the final train dataset, this exercise is meant more to inform the modeling process than to use the information from the train set for the final submission. All the features for this kernel, as well as the references to previous kernels that created them, can be found here: https://www.kaggle.com/tunguz/distilbert-use-features-just-the-features"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold\nfrom sklearn import model_selection, preprocessing, metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import roc_auc_score\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport shap\nimport os\nprint(os.listdir(\"../input\"))\nfrom sklearn import preprocessing\nimport xgboost as xgb\nimport gc\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = np.load('../input/distilbert-use-features-just-the-features/X_train.npy')\ntest = np.load('../input/distilbert-use-features-just-the-features/X_test.npy')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.zeros((6079,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test = np.vstack([train, test])\ntarget = np.hstack([np.zeros((6079,)), np.ones((476,))])\ndel train, test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test, train_y, test_y = model_selection.train_test_split(train_test, target, test_size=0.33, random_state=42, shuffle=True)\ndel train_test, target\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = lgb.Dataset(train, label=train_y)\ntest = lgb.Dataset(test, label=test_y)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {'num_leaves': 50,\n         'min_data_in_leaf': 20, \n         'objective':'binary',\n         'max_depth': 2,\n         'learning_rate': 0.01,\n         \"min_child_samples\": 20,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.5,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9 ,\n         \"bagging_seed\": 44,\n         \"metric\": 'auc',\n         \"verbosity\": -1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_round = 500\nclf = lgb.train(param, train, num_round, valid_sets = [train, test], verbose_eval=1000, early_stopping_rounds = 1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's not too shabby - AUC of 0.61 between train and test sets indicates high variability between distinct features. Unfortunately most of our featues come from the transformers embedding space(s), so it will not be easy to interpret whcih ones are responsible for what. Nonetheless, let's try to take a quick look."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['feature_'+str(x) for x in range(3142)]\n\nfeature_imp = pd.DataFrame(sorted(zip(clf.feature_importance(),features)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 20))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).head(100))\nplt.title('LightGBM Features')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So it seams that \"feature_717\" is the most distinct feature between the train and test sets, with a long tail of features that have a relatively low value in this regard. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}