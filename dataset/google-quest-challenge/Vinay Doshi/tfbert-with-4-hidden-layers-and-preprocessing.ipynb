{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/huggingface-transformers/sacremoses-master/sacremoses-master\n!pip install ../input/huggingface-transformers/transformers-master/transformers-master","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nimport tensorflow.keras as keras\nimport gc\nfrom sklearn.model_selection import train_test_split, GroupKFold\n# import bert_tokenization as tokenization\nfrom scipy.stats import spearmanr\nfrom math import floor, ceil\nfrom transformers import TFPreTrainedModel, TFBertMainLayer, BertConfig, TFBertModel, BertTokenizer\nfrom tqdm import tqdm\ntqdm.pandas()\nimport pyprind \nimport warnings\nwarnings.filterwarnings('ignore')\nimport operator\nimport string\nimport json\nimport re\nimport gensim\nfrom gensim.models import KeyedVectors\nimport seaborn as sns\nimport time\nimport random\nimport pickle\nimport joblib\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nimport operator\nfrom nltk.tokenize.treebank import TreebankWordTokenizer\nfrom spacy.lang.en import English\nimport re\nfrom keras.preprocessing import text\n# from tqdm import tqdm, tqdm_notebook\n# tqdm_notebook().pandas()\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH = '../input/google-quest-challenge/'\n\nBERT_PATH = '../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'\n# tokenizer = tokenization.FullTokenizer(BERT_PATH+'/assets/vocab.txt', True)\ntokenizer2 = BertTokenizer.from_pretrained(BERT_PATH+'/assets/vocab.txt', do_lower_case=True,)\nMAX_SEQUENCE_LENGTH = 512\n\ndf_train = pd.read_csv(PATH+'train.csv',header=0,encoding='utf-8')\ndf_test = pd.read_csv(PATH+'test.csv',header=0,encoding='utf-8')\ndf_sub = pd.read_csv(PATH+'sample_submission.csv')\ndf = pd.concat([df_train,df_test],axis=0,ignore_index=True)\nprint(f'''Train Shape: {df_train.shape}\nTest Shape: {df_test.shape}\nDf Shape:{df.shape}''')\n\noutput_categories = ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\ninput_categories = ['question_title', 'question_body', 'answer']\nprint('\\noutput categories:\\n\\t', output_categories)\nprint('\\ninput categories:\\n\\t', input_categories)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_tokenizer = TreebankWordTokenizer()\ndef get_tree_tokens(x):\n    x = tree_tokenizer.tokenize(x)\n    x = ' '.join(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in input_categories:\n    df_train[f'treated_{col}'] = df_train[col].apply(lambda x: get_tree_tokens(x))\n    df_test[f'treated_{col}'] = df_test[col].apply(lambda x: get_tree_tokens(x))\n    df[f'treated_{col}'] = df_test[col].apply(lambda x: get_tree_tokens(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = text.Tokenizer(lower=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_question = df_train['question_body']\nX_train_title    = df_train['question_title']\nX_train_answer   = df_train['answer']\n\nX_test_question  = df_test['question_body']\nX_test_title     = df_test['question_title']\nX_test_answer    = df_test['answer']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.fit_on_texts(list(X_train_title)+list(X_train_question)+list(X_train_answer)+list(X_test_title)+list(X_test_question)+list(X_test_answer))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = English()\nsentencizer = nlp.create_pipe('sentencizer')\nnlp.add_pipe(sentencizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_document(texts):\n    all_sents = []\n    max_num_sentences = 0.0\n    for text in texts:\n        doc = nlp(text)\n#         print('Sents',doc.sents)\n        sents=[]\n        for i,sent in enumerate(doc.sents):\n            sents.append(sent.text)\n        all_sents.append(sents)\n    \n    return all_sents\n        \nX_train_question = split_document(X_train_question)\n# X_train_title = split_document(X_train_title)\nX_train_answer = split_document(X_train_answer)\n\nX_test_question = split_document(X_test_question)\nX_test_answer = split_document(X_test_answer)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_question_metadata_features(text):\n    doc=nlp(text)\n    indirect = 0\n    choice_words=0\n    reason_explanation_words = 0\n    question_count = 0\n    \n    for sent in doc.sents:\n        if '?' in sent.text and '?' == sent.text[-1]:\n            question_count += 1\n            for token in sent:\n                if token.text.lower()=='why':\n                    reason_explanation_words+=1\n                elif token.text.lower()=='or':\n                    choice_words+=1\n    if question_count==0:\n        indirect+=1\n    \n    return np.array([indirect, question_count, reason_explanation_words, choice_words])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans_user_and_category=df_train[df_train[['answer_user_name', 'category']].duplicated()][['answer_user_name', 'category']].values\nans_user_and_category.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def question_answer_author_same(df):\n    q_username = df['question_user_name']\n    a_username = df['answer_user_name']\n    author_same=[]\n    \n    for i in range(len(df)):\n        if q_username[i] == a_username[i]:\n            author_same.append(int(1))\n        else:\n            author_same.append(int(0))\n    return author_same\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_external_features(df):\n    df['question_body'] = df['question_body'].progress_apply(lambda x: str(x))\n    df['question_body_num_words'] = df['question_body'].str.count('\\S+')\n    \n    df['answer'] = df['answer'].progress_apply(lambda x: str(x))\n    df['answer_num_words'] = df['answer'].str.count('\\S+')\n    \n    df['question_vs_answer_length'] = df['question_body_num_words']/df['answer_num_words']\n    \n    df['q_a_author_same'] = question_answer_author_same(df)\n    \n    answer_user_cat = []\n    for i in tqdm(df[['answer_user_name', 'category']].values):\n        if i in ans_user_and_category:\n            answer_user_cat.append(int(1))\n        else:\n            answer_user_cat.append(int(0))\n    df['answer_user_cat'] = answer_user_cat\n    \n    handmade_features=[]\n    for text in df['question_body'].values:\n        handmade_features.append(add_question_metadata_features(text))\n\n    \n    return df, np.array(handmade_features)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, handmade_features = add_external_features(df_train)\ndf_test, handmade_features_test = add_external_features(df_test)\n\ndf_train = pd.concat([df_train,pd.DataFrame(handmade_features, columns=['indirect', 'question_count', 'reason_explanation_words', 'choice_words'])],axis=1)\ndf_test = pd.concat([df_test,pd.DataFrame(handmade_features_test, columns=['indirect', 'question_count', 'reason_explanation_words', 'choice_words'])],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_words_scaler = MinMaxScaler()\ndf_train[['question_body_num_words', 'answer_num_words']] = num_words_scaler.fit_transform(df_train[['question_body_num_words', 'answer_num_words']].values)\ndf_test[['question_body_num_words', 'answer_num_words']] = num_words_scaler.transform(df_test[['question_body_num_words', 'answer_num_words']].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unique_categories = list(set(df_train['category'].unique().tolist() + df_test['category'].unique().tolist()))\n# category_dict = {i + 1: e for i, e in enumerate(unique_categories)}\n# category_dict_reverse = {v: k for k, v in category_dict.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# le_cat = LabelEncoder()\n# df_train['category']=le_cat.fit_transform(df_train['category'])\n# df_test['category']=le_cat.transform(df_test['category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# le_host = LabelEncoder()\n# le_host.fit(list(set(df_train['host'].values.tolist()+df_test['host'].values.tolist())))\n# df_train['host']=le_host.transform(df_train['host'])\n# df_test['host']=le_host.transform(df_test['host'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import cdist\ncols = output_categories+['question_body_num_words',\n       'answer_num_words', 'question_vs_answer_length', 'q_a_author_same',\n       'answer_user_cat', 'indirect', 'question_count',\n       'reason_explanation_words', 'choice_words']\nfig, ax = plt.subplots(figsize=(25,25))\nsns.heatmap(df_train[cols].corr() , ax=ax, annot=True, cmap='vlag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.concat([df,pd.get_dummies(df['host'], drop_first=False, prefix='host')],axis=1)\ndf=pd.concat([df,pd.get_dummies(df['category'], drop_first=False, prefix='cat')],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(['qa_id']+[i for i in df.columns if i.startswith('host_') or i.startswith('cat_')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=pd.merge(df_train, df[['qa_id']+[i for i in df.columns if i.startswith('host_') or i.startswith('cat_')]], how='inner', on='qa_id')\ndf_test = pd.merge(df_test, df[['qa_id']+[i for i in df.columns if i.startswith('host_') or i.startswith('cat_')]], how='inner', on='qa_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train=pd.concat([df_train,pd.get_dummies(df_train['host'], drop_first=False, prefix='host')],axis=1)\n# df_train=pd.concat([df_train,pd.get_dummies(df_train['category'], drop_first=False, prefix='cat')],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_test=pd.concat([df_test,pd.get_dummies(df_test['host'], drop_first=False, prefix='host')],axis=1)\n# df_test=pd.concat([df_test,pd.get_dummies(df_test['category'], drop_first=False, prefix='cat')],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(['host', 'category'], inplace=True, axis=1)\ndf_test.drop(['host', 'category'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_masks(tokens, max_seq_length):\n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    return [1]*len(tokens)+[0]*(max_seq_length-len(tokens))\n\ndef _get_segments(tokens, max_seq_length):\n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    \n    segments=[]\n    first_sep=True\n    current_segment_id = 0\n    for token in tokens:\n        segments.append(current_segment_id)\n        if token == '[ANS]':\n#             if first_sep:\n#                 first_sep=False\n#             else:\n            current_segment_id=1\n    return segments+[0]*(max_seq_length-len(tokens))\n\ndef _trim_input(title, question, answer, max_sequence_length, t_max_len=30, q_max_len=239, a_max_len=239):\n\n    t = tokenizer2.tokenize(title)\n    q = tokenizer2.tokenize(question)\n    a = tokenizer2.tokenize(answer)\n    \n    t_len = len(t)\n    q_len = len(q)\n    a_len = len(a)\n\n    if (t_len+q_len+a_len+4) > max_sequence_length:\n        \n        if t_max_len > t_len:\n            t_new_len = t_len\n            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n        else:\n            t_new_len = t_max_len\n      \n        if a_max_len > a_len:\n            a_new_len = a_len \n            q_new_len = q_max_len + (a_max_len - a_len)\n        elif q_max_len > q_len:\n            a_new_len = a_max_len + (q_max_len - q_len)\n            q_new_len = q_len\n        else:\n            a_new_len = a_max_len\n            q_new_len = q_max_len\n            \n            \n        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n            raise ValueError(\"New sequence length should be %d, but is %d\" \n                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n        \n        t = t[:t_new_len]\n        q = q[:q_new_len]\n        a = a[:a_new_len]\n    \n    return t, q, a\n\ndef _get_ids(tokens, tokenizer, max_seq_length):\n    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n    input_ids = token_ids + [0]*(max_seq_length - len(token_ids))\n    return input_ids\n\ndef _convert_to_bert_inputs(title, question, answer, tokenizer, max_seq_length):\n    stoken = ['[CLS]']+title+['[QBODY]']+question+['[ANS]']+answer+['[SEP]']\n    input_ids = _get_ids(tokens=stoken, tokenizer=tokenizer,max_seq_length=max_seq_length)\n    input_masks = _get_masks(tokens=stoken, max_seq_length=max_seq_length)\n    input_segments = _get_segments(tokens=stoken, max_seq_length=max_seq_length)\n    \n    return [input_ids, input_masks, input_segments]\n\ndef compute_input_array(df, columns, tokenizer, max_sequence_length):\n    input_ids, input_masks, input_segments = [], [], []\n    for _, col in tqdm(df[columns].iterrows()):\n        t, q, a = col['treated_question_title'], col['treated_question_body'], col['treated_answer']\n        t,q,a = _trim_input(t,q,a, max_sequence_length)\n        ids, masks, segments = _convert_to_bert_inputs(t,q,a, tokenizer, max_sequence_length)\n        input_ids.append(ids)\n        input_masks.append(masks)\n        input_segments.append(segments)\n        \n    return [np.array(input_ids, dtype=np.int32), np.array(input_masks, dtype=np.int32), \n            np.array(input_segments, dtype=np.int32)]\n\ndef compute_output_arrays(df, columns):\n    return np.asarray(df[columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_spearmanr(trues, preds):\n    rhos=[]\n    for t, p in zip(trues.T, preds.T):\n        rhos.append(\n            spearmanr(t,p).correlation\n        )\n    return np.nanmean(rhos)\n\ntest_predictions=[]\n\nclass CustomCallback(keras.callbacks.Callback):\n    def __init__(self, valid_data, test_data, test_predictions=test_predictions, batch_size=16, fold=None):\n        self.valid_inputs = valid_data[0]\n        self.valid_outputs = valid_data[1]\n        self.test_inputs = test_data\n        self.batch_size = batch_size\n        self.test_predictions = test_predictions\n        self.fold = fold\n        \n    def on_train_begin(self, logs={}):\n        self.valid_predictions=[]\n        #self.test_predictions=[]\n        \n    def on_epoch_end(self, epoch, logs={}):\n        self.valid_predictions.append(self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n        \n        rho_val = compute_spearmanr(self.valid_outputs, np.average(self.valid_predictions, axis=0))\n        print(f\"\\nvalidation rho: {round(rho_val,4)}\")\n        \n        if (epoch+1)%4==0:\n            self.model.save_weights(f'/kaggle/working/bert-base-{fold}-{epoch}.hdf5')\n            \n        self.test_predictions.append(self.model.predict(self.test_inputs, batch_size=self.batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bert_config=BertConfig(unk_token=\"[QBODY]\", pad_token=\"[ANS]\").from_pretrained('../input/bert-tensorflow/bert-base-uncased-config.json',output_hidden_states=True)\ndef bertModel():\n    input_ids = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_word_ids')\n    input_mask = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_masks')\n    input_segments = keras.layers.Input((MAX_SEQUENCE_LENGTH), dtype = tf.int32, name = 'input_segments')\n    input_categories = keras.layers.Input((len([i for i in df.columns if i.startswith('host_') or i.startswith('cat_')])),dtype=tf.float32, name='input_categorical')\n    input_new_features = keras.layers.Input((9,), dtype=tf.float32, name='input_new_features') \n    bert_model = TFBertModel.from_pretrained(pretrained_model_name_or_path='../input/bert-tensorflow/bert-base-uncased-tf_model.h5',config = bert_config)\n#     bert_model.resize_token_embeddings(len(tokenizer2))\n    sequence_output, pooler_output, hidden_states = bert_model([input_ids,input_mask, input_segments])\n    \n    h12 = tf.reshape(hidden_states[-1][:,0],(-1,1,768))\n    h11 = tf.reshape(hidden_states[-2][:,0],(-1,1,768))\n    h10 = tf.reshape(hidden_states[-3][:,0],(-1,1,768))\n    h09 = tf.reshape(hidden_states[-4][:,0],(-1,1,768))\n    concat_hidden = keras.layers.Concatenate(axis=2)([h12, h11, h10, h09])\n\n    x = keras.layers.GlobalAveragePooling1D()(concat_hidden)\n    x = keras.layers.Concatenate()([x, input_new_features, input_categories])\n#     dense1 = keras.layers.Dense(768)(x)\n#     dense1 = keras.layers.LeakyReLU()(dense1)\n#     x = keras.layers.Add()([dense1,x])    \n    x = keras.layers.Dropout(0.2)(x)\n    out = keras.layers.Dense(len(output_categories), activation='sigmoid', name='final_dense_output')(x)\n    \n    model = keras.models.Model(inputs=[input_ids, input_mask, input_segments,input_categories, input_new_features], outputs=out)\n    model.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(lr=3e-5))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model=bertModel()\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gkf = GroupKFold(n_splits=10).split(X=df_train.question_body, groups=df_train.question_body)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\noutputs = compute_output_arrays(df_train, output_categories)\ninputs = compute_input_array(df_train, ['treated_question_title','treated_question_body','treated_answer'], tokenizer2, MAX_SEQUENCE_LENGTH)\ntest_inputs = compute_input_array(df_test, ['treated_question_title','treated_question_body','treated_answer'], tokenizer2, MAX_SEQUENCE_LENGTH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histories = []\n\nfor fold, (train_idx, valid_idx) in enumerate(gkf):\n    \n    if fold<3:\n        keras.backend.clear_session()\n        model = bertModel()\n        train_inputs = [inputs[i][train_idx] for i in range(3)] #+[df_train[[i for i in df_train.columns if i.startswith('cat_') or i.startswith('host_')]].iloc[train_idx,:].values]+[df_train[['question_body_num_words', 'answer_num_words','question_vs_answer_length', 'q_a_author_same', 'answer_user_cat','indirect', 'question_count', 'reason_explanation_words','choice_words']].iloc[train_idx,:].values]\n        train_inputs\n        train_outputs = outputs[train_idx]\n    \n        valid_inputs = [inputs[i][valid_idx] for i in range(3)]\n        valid_outputs = outputs[valid_idx]\n    \n        custom_callback = CustomCallback(valid_data=(valid_inputs + [df_train[[i for i in df.columns if i.startswith('host_') or i.startswith('cat_')]].iloc[valid_idx,:].values]+\n                                                      [df_train[['question_body_num_words', 'answer_num_words','question_vs_answer_length', 'q_a_author_same', 'answer_user_cat','indirect', 'question_count', 'reason_explanation_words','choice_words']].iloc[valid_idx,:].values],\n                                                      valid_outputs), \n                                         test_data=test_inputs + [df_test[[i for i in df.columns if i.startswith('host_') or i.startswith('cat_')]].values]+\n                                                    [df_test[['question_body_num_words', 'answer_num_words','question_vs_answer_length', 'q_a_author_same', 'answer_user_cat','indirect', 'question_count', 'reason_explanation_words','choice_words']].values],\n                                         batch_size=8, fold=fold)\n        H = model.fit(train_inputs+ \n                       [df_train[[i for i in df.columns if i.startswith('host_') or i.startswith('cat_')]].iloc[train_idx,:].values]+ \n                       [df_train[['question_body_num_words', 'answer_num_words','question_vs_answer_length', 'q_a_author_same', 'answer_user_cat','indirect', 'question_count', 'reason_explanation_words','choice_words']].iloc[train_idx,:].values],\n                      train_outputs, batch_size=8, epochs=4, callbacks=[custom_callback])\n        histories.append(H)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dghdhfdfffhkhhdrdffdrtyxcgdxsdfaassd5412","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(test_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = [test_predictions[i] for i in range(len(test_predictions))]\ntest_preds = [np.average(test_preds[i], axis=0) for i in range(len(test_preds))]\ntest_preds = np.mean(test_predictions, axis=0)\n\ndf_sub.iloc[:, 1:] = test_preds\n\ndf_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len([inputs[i][0] for i in range(3)]+[df_train[[i for i in df_train.columns if i.startswith('cat_') or i.startswith('host_')]].iloc[6078,:].values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len([i for i in df_test.columns if i.startswith('cat_') or i.startswith('host_')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for fold, (train_idx, valid_idx) in enumerate(gkf):\n#     print((train_train_idx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train[[i for i in df_train.columns if i.startswith('cat_') or i.startswith('host_')]].iloc[6078,:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train[['question_body_num_words', 'answer_num_words',\n#        'question_vs_answer_length', 'q_a_author_same', 'answer_user_cat',\n#        'indirect', 'question_count', 'reason_explanation_words',\n#        'choice_words']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}