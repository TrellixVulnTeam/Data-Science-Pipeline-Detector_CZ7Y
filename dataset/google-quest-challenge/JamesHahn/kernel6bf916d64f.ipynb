{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport json\nimport random\nimport pandas as pd\nimport numpy as np\n\n# useful constants\nTEST_PATH = os.path.join(\"../input/google-quest-challenge/test.csv\")\nUSEFUL_COLUMN_NAMES = [\"question_body\", \"answer\"]\n\ndef preprocess_text(text):\n    # TODO: maybe convert all text to lowercase? see if that affects accuracy?\n    text = text.replace(\".\", \" [EOS] \")\n    text = text.replace(\"?\", \" [EOQ] \")\n    text = text.replace(\"(\", \"\")\n    text = text.replace(\")\", \"\")\n    text = text.split(\" \")\n    return text\n\n# load data\nprint(\"Loading data...\")\ntest_data = pd.read_csv(TEST_PATH)\nwith open(\"../input/mydata/word2idx.json\", \"r\") as word2idx_file:\n    word2idx = json.loads(word2idx_file.read())\n    vocab_size = len(word2idx)\n\n# extract only the useful column names for text preprocessing\ntest_data = test_data[USEFUL_COLUMN_NAMES]\ntest_questions = []\ntest_answers = []\n\n# preprocess question and answer text\nprint(\"Preprocessing testing text...\")\nfor index, row in test_data.iterrows(): # iterate over testing data\n    # read in question and answer on this row\n    question, answer = row\n\n    # convert from \"This is my question?\" to [\"This\", \"is\", \"my\", \"question\", \"[EOQ]\"]\n    question_tokenized = preprocess_text(question)\n    answer_tokenized = preprocess_text(answer)\n\n    # prepare some variables so we can convert [\"This\", \"is\", \"my\", \"question\", \"[EOQ]\"] to [23, 486, 3, 54, 128]\n    question_numbered = []\n    answer_numbered = []\n\n    # convert [\"This\", \"is\", \"my\", \"question\", \"[EOQ]\"] to [23, 486, 3, 54, 128]\n    for index, word in enumerate(question_tokenized):\n        if index < 8172:\n            question_numbered.append(word2idx[word] if word in word2idx else word2idx[\"[NULL]\"])\n    for index, word in enumerate(answer_tokenized):\n        if index < 8172:\n            answer_numbered.append(word2idx[word] if word in word2idx else word2idx[\"[NULL]\"])\n    question_numbered += [0] * (8172 - len(question_numbered)) # choose 8172 as the max length of a sentence so we can pad the rest of the sentence with delimiters\n    answer_numbered += [0] * (8172 - len(answer_numbered))\n\n    test_questions.append(question_numbered)\n    test_answers.append(answer_numbered)\n\n# concatenate question/answer text and scores\nprint(\"Concatenating three columns together...\")\nnew_test_data = []\nfor index, row in enumerate(test_questions):\n    new_row = [test_questions[index], test_answers[index]]\n    new_test_data.append(new_row)\n\n# turn training and test data into DataFrames\nnew_test_data = pd.DataFrame(new_test_data, columns = [\"question\", \"answer\"])\nprint(new_test_data.shape)\n\n# save new data\nprint(\"Saving data...\")\nnew_test_data.to_csv(os.path.join(\"../test_preprocessed.csv\"))\nprint(\"\\nVocabulary size: {}\".format(len(word2idx)))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nclass QUESTModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size, lstm_layers, num_question_output, num_answer_output):\n        super(QUESTModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.embedding_dim = embedding_dim\n\n        self.question_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = self.embedding_dim)\n        self.question_lstm = nn.LSTM(input_size = self.embedding_dim, hidden_size = self.hidden_size, num_layers = lstm_layers, dropout = 0.0, bidirectional = False)\n        self.question_linear = nn.Linear(in_features = hidden_size, out_features = num_question_output)\n\n        self.answer_embeddings = nn.Embedding(num_embeddings = vocab_size, embedding_dim = self.embedding_dim)\n        self.answer_lstm = nn.LSTM(input_size = self.embedding_dim, hidden_size = self.hidden_size, num_layers = lstm_layers, dropout = 0.0, bidirectional = False)\n        self.answer_linear = nn.Linear(in_features = hidden_size, out_features = num_answer_output)\n\n    def forward(self, question, answer):\n        batch_size = len(question)\n\n        # NOTE: pytorch LSTM units take input in the form of [window_length, batch_size, num_features], which will end up being [WINDOW_SIZE, batch_size, 1] for our dataset\n        # reshape question and answer sizes\n        #print(question.shape, answer.shape, batch_size)\n        question = question.permute(1, 0)\n        answer = answer.permute(1, 0)\n\n        question_hidden_cell = (torch.zeros(1, batch_size, self.hidden_size).to(DEVICE),\n                                torch.zeros(1, batch_size, self.hidden_size).to(DEVICE))\n        answer_hidden_cell = (torch.zeros(1, batch_size, self.hidden_size).to(DEVICE),\n                              torch.zeros(1, batch_size, self.hidden_size).to(DEVICE))\n\n        question_embed = self.question_embeddings(question)\n        #print(question_embed.shape)\n        question_lstm_out, _ = self.question_lstm(question_embed, question_hidden_cell)\n        question_pred_scores = self.question_linear(question_lstm_out[-1])\n\n        answer_embed = self.answer_embeddings(answer)\n        #print(answer_embed.shape)\n        answer_lstm_out, _ = self.answer_lstm(answer_embed, answer_hidden_cell)\n        answer_pred_scores = self.answer_linear(answer_lstm_out[-1])\n\n        pred_scores = torch.cat((question_pred_scores, answer_pred_scores), dim = 1)\n        pred_scores = torch.sigmoid(pred_scores)\n\n        return pred_scores\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport pandas as pd\nimport ast\n\nclass QUESTDataset(data.Dataset):\n    def __init__(self, data_path):\n        super(QUESTDataset, self).__init__()\n\n        self.data = pd.read_csv(data_path)\n        self.train = True if \"scores\" in self.data.columns else False\n\n    def __getitem__(self, index):\n        row = self.data.iloc[index]\n        question = torch.as_tensor(ast.literal_eval(row[\"question\"]))\n        answer = torch.as_tensor(ast.literal_eval(row[\"answer\"]))\n        if self.train:\n            scores = torch.as_tensor(ast.literal_eval(row[\"scores\"]))\n            return {'question': question, 'answer': answer, 'scores': scores}\n        else:\n            return {'question': question, 'answer': answer}\n\n    def __len__(self):\n        return len(self.data)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport glob\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\n\nHIDDEN_SIZE = 100\nLSTM_LAYERS = 1\nEMBEDDING_DIM = 50\nWORD2IDX_PATH = os.path.join(\"../input/mydata/word2idx.json\")\n\nQUESTION_OUTPUT_SIZE = 21 # 21 features/attributes corresponding to the questions\nANSWER_OUTPUT_SIZE = 9 # 9 features/attributes corresponding to the answers\nCOLUMN_NAMES = ['question_asker_intent_understanding', 'question_body_critical',\n       'question_conversational', 'question_expect_short_answer',\n       'question_fact_seeking', 'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']\n\nsaved_model_names = glob.glob(\"../input/models/*\")\nMODEL_SAVE_DIR = max(saved_model_names, key = os.path.getctime) # get the model that was saved most recently\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# load in word2idx and determine vocab size\nwith open(WORD2IDX_PATH, \"r\") as word2idx_file:\n    word2idx = json.loads(word2idx_file.read())\n    vocab_size = len(word2idx)\n\n# init dataset and loaders for test dataset\ntest_data = QUESTDataset(data_path = os.path.join(\"../test_preprocessed.csv\"))\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size = 1, shuffle = False)\n\n# init training modules, such as the model, Adam optimizer and loss function\nmodel = QUESTModel(vocab_size = vocab_size, embedding_dim = EMBEDDING_DIM, hidden_size = HIDDEN_SIZE, lstm_layers = LSTM_LAYERS, num_question_output = QUESTION_OUTPUT_SIZE, num_answer_output = ANSWER_OUTPUT_SIZE)\nmodel.load_state_dict(torch.load(MODEL_SAVE_DIR, map_location=torch.device('cpu')))\n\n# create a 'models' directory to save models\nif not os.path.exists(\"../input/models\"):\n    print(\"No pretrained models exist. Please run train.py first...\")\n\n\n# run the model on the testing dataset\nprint(\"Testing model...\")\ntest_preds = []\nfor batch_id, samples in enumerate(test_loader):\n    question, answer = samples[\"question\"].to(DEVICE), samples[\"answer\"].to(DEVICE)\n    pred_scores = model(question.to(DEVICE), answer.to(DEVICE))\n    test_preds.append(pred_scores[0].cpu().detach().numpy())\n\n    if batch_id % 50 == 0:\n        print(\"Done with {}/{} test samples...\".format(batch_id+1, len(test_loader)))\n\n# save the predictions to a file\nprint(\"Saving predictions...\")\ntest_preds = pd.DataFrame(test_preds, columns = COLUMN_NAMES)\ntest_preds.to_csv(\"submission.csv\", index = False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}