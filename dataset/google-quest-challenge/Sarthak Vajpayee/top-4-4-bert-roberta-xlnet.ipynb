{"cells":[{"metadata":{"id":"pidIUEytrqvI","trusted":true},"cell_type":"code","source":"# importing necessary libraries\nimport random\nimport html\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport os\nfrom scipy.stats import spearmanr\nfrom scipy.optimize import minimize\nfrom transformers import *\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import KFold\nfrom scipy.stats import spearmanr","execution_count":null,"outputs":[]},{"metadata":{"id":"y7B8MjQabH0W","outputId":"bb4d2ef4-acfa-4795-cb01-3229f0c8cf83","trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom IPython.display import Image\nImage('../input/google-qna-ensemble-architecture/architecture.png')","execution_count":null,"outputs":[]},{"metadata":{"id":"Y6yvbEtuWnKv","outputId":"1297c795-4180-4b3f-d551-439aa1927ba9","trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\nx = PrettyTable()\nx.field_names = [\"model\",\"dataset\",\"train loss\",\"cv loss\",\"train rhos\",\"cv rhos\"] \n\nx.add_row(['bert_base_uncased','questions',0.3393, 0.3302, 0.5543, 0.6013]) \nx.add_row(['bert_base_uncased','answer',0.3320, 0.3278, 0.4967, 0.5438]) \nx.add_row(['bert_base_uncased','question+answer',0.3287, 0.3166, 0.5511, 0.6109])\n\nx.add_row(['roberta_base','questions',0.3542, 0.3400, 0.4953, 0.5674]) \nx.add_row(['roberta_base','answer',0.3430, 0.3253, 0.3927, 0.4993]) \nx.add_row(['roberta_base','question+answer',0.3546, 0.3397, 0.4305, 0.5082])\n\nx.add_row(['xlnet_base_cased','questions',0.3662, 0.3412, 0.4679, 0.5685]) \nx.add_row(['xlnet_base_cased','answer',0.3611, 0.3401, 0.3531, 0.4702]) \nx.add_row(['xlnet_base_cased','question+answer',0.3721, 0.3452, 0.3942, 0.5013]) \nprint(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"KGf6Tj3EYQbn","trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","execution_count":null,"outputs":[]},{"metadata":{"id":"cQfv-VF6rqsX","trusted":true},"cell_type":"code","source":"# fixing random seeds\nseed = 13\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"id":"BzQYF-uarwm9","trusted":true},"cell_type":"code","source":"def get_data():\n    print('getting test and train data...')\n    # reading the data into dataframe using pandas\n    path = '../input/google-quest-challenge/'\n    train = pd.read_csv(path+'train.csv')\n    test = pd.read_csv(path+'test.csv')\n    submission = pd.read_csv(path+'sample_submission.csv')\n\n    # Selecting data for training and testing\n    y = train[train.columns[11:]] # storing the target values in y\n    X = train[['question_title', 'question_body', 'answer']]\n    X_test = test[['question_title', 'question_body', 'answer']]\n\n    # Cleaning the data\n    X.question_body = X.question_body.apply(html.unescape)\n    X.question_title = X.question_title.apply(html.unescape)\n    X.answer = X.answer.apply(html.unescape)\n\n    X_test.question_body = X_test.question_body.apply(html.unescape)\n    X_test.question_title = X_test.question_title.apply(html.unescape)\n    X_test.answer = X_test.answer.apply(html.unescape)\n\n    return X, X_test, y, train, test","execution_count":null,"outputs":[]},{"metadata":{"id":"lyacQmXr6cst","trusted":true},"cell_type":"code","source":"def get_tokenizer(model_name):\n    print(f'getting tokenizer for {model_name}...')\n    if model_name == 'xlnet-base-cased':\n        tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n    elif model_name == 'roberta-base':\n        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n    elif model_name == 'bert-base-uncased':\n        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    \n    return tokenizer","execution_count":null,"outputs":[]},{"metadata":{"id":"xmbF0pjJrqq1","trusted":true},"cell_type":"code","source":"def fix_length(tokens, max_sequence_length=512, q_max_len=254, a_max_len=254, model_type='questions'):\n    if model_type == 'questions':\n        length = len(tokens)\n        if length > max_sequence_length:\n            tokens = tokens[:max_sequence_length-1]\n        return tokens\n\n    else:\n        question_tokens, answer_tokens = tokens\n        q_len = len(question_tokens)\n        a_len = len(answer_tokens)\n        if q_len + a_len + 3 > max_sequence_length:\n            if a_max_len <= a_len and q_max_len <= q_len:\n                q_new_len_head = q_max_len//2\n                question_tokens = question_tokens[:q_new_len_head] + question_tokens[-q_new_len_head:]\n                a_new_len_head = a_max_len//2\n                answer_tokens = answer_tokens[:a_new_len_head] + answer_tokens[-a_new_len_head:]\n            elif q_len <= a_len and q_len < q_max_len:\n                a_max_len = a_max_len + (q_max_len - q_len - 1)\n                a_new_len_head = a_max_len//2\n                answer_tokens = answer_tokens[:a_new_len_head] + answer_tokens[-a_new_len_head:]\n            elif a_len < q_len:\n                q_max_len = q_max_len + (a_max_len - a_len - 1)\n                q_new_len_head = q_max_len//2\n                question_tokens = question_tokens[:q_new_len_head] + question_tokens[-q_new_len_head:]\n\n    return question_tokens, answer_tokens","execution_count":null,"outputs":[]},{"metadata":{"id":"th-CbzxftwpL","trusted":true},"cell_type":"code","source":"# function for tokenizing the input data for transformer.\ndef transformer_inputs(title, question, answer, tokenizer, model_type='questions', MAX_SEQUENCE_LENGTH = 512):\n    if model_type == 'questions':\n        question = f\"{title} [SEP] {question}\"\n        question_tokens = tokenizer.tokenize(question)\n        question_tokens = fix_length(question_tokens, model_type=model_type)\n        ids_q = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + question_tokens)\n        padded_ids = (ids_q + [tokenizer.pad_token_id] * (MAX_SEQUENCE_LENGTH - len(ids_q)))[:MAX_SEQUENCE_LENGTH]\n        token_type_ids = ([0] * MAX_SEQUENCE_LENGTH)[:MAX_SEQUENCE_LENGTH]\n        attention_mask = ([1] * len(ids_q) + [0] * (MAX_SEQUENCE_LENGTH - len(ids_q)))[:MAX_SEQUENCE_LENGTH]\n        \n        return padded_ids, token_type_ids, attention_mask\n\n    else:\n        question = f\"{title} [SEP] {question}\"\n        question_tokens = tokenizer.tokenize(question)\n        answer_tokens = tokenizer.tokenize(answer)\n        question_tokens, answer_tokens = fix_length(tokens=(question_tokens, answer_tokens), model_type=model_type)\n        ids = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + question_tokens + [\"[SEP]\"] + answer_tokens + [\"[SEP]\"])\n        padded_ids = ids + [tokenizer.pad_token_id] * (MAX_SEQUENCE_LENGTH - len(ids))\n        token_type_ids = [0] * (1 + len(question_tokens) + 1) + [1] * (len(answer_tokens) + 1) + [0] * (MAX_SEQUENCE_LENGTH - len(ids))\n        attention_mask = [1] * len(ids) + [0] * (MAX_SEQUENCE_LENGTH - len(ids))\n\n        return padded_ids, token_type_ids, attention_mask","execution_count":null,"outputs":[]},{"metadata":{"id":"p9pV8G7HtxBy","trusted":true},"cell_type":"code","source":"# function for creating the input_ids, masks and segments for the bert input\ndef input_data(df, tokenizer, model_type='questions'):\n    print(f'generating {model_type} input for transformer...')\n    input_ids, input_token_type_ids, input_attention_masks = [], [], []\n    for title, body, answer in tqdm(zip(df[\"question_title\"].values, df[\"question_body\"].values, df[\"answer\"].values)):\n        ids, type_ids, mask = transformer_inputs(title, body, answer, tokenizer, model_type=model_type)\n        input_ids.append(ids)\n        input_token_type_ids.append(type_ids)\n        input_attention_masks.append(mask)\n    \n    return (\n        np.asarray(input_ids, dtype=np.int32),\n        np.asarray(input_attention_masks, dtype=np.int32),\n        np.asarray(input_token_type_ids, dtype=np.int32))","execution_count":null,"outputs":[]},{"metadata":{"id":"tPMKL1p_zIeD","trusted":true},"cell_type":"code","source":"def get_model(name):\n    if name == 'xlnet-base-cased':\n        config = XLNetConfig.from_pretrained('xlnet-base-cased', output_hidden_states=True)\n        model = TFXLNetModel.from_pretrained('xlnet-base-cased', config=config)\n    elif name == 'roberta-base':\n        config = RobertaConfig.from_pretrained('roberta-base', output_hidden_states=True)\n        model = TFRobertaModel.from_pretrained('roberta-base', config=config)\n    elif name == 'bert-base-uncased':\n        config = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n        model = TFBertModel.from_pretrained('bert-base-uncased', config=config)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"4zyVQmN8tw-h","trusted":true},"cell_type":"code","source":"def create_model(name='xlnet-base-cased', model_type='questions'):\n    print(f'creating model {name}...')\n    # Creating the model\n    K.clear_session()\n    max_seq_length = 512\n\n    input_tokens = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_tokens\")\n    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n    input_segment = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_segment\")\n\n    model = get_model(name)\n    if (name == 'xlnet-base-cased'):\n      sequence_output, hidden_states = model([input_tokens, input_mask])\n    elif (name=='roberta-base' and model_type!='questions'):\n      sequence_output, pooler_output, hidden_states = model([input_tokens, input_mask])\n    else:\n      sequence_output, pooler_output, hidden_states = model([input_tokens, input_mask, input_segment])\n\n    # Last 4 hidden layers of bert\n    h12 = tf.reshape(hidden_states[-1][:,0],(-1,1,768))\n    h11 = tf.reshape(hidden_states[-2][:,0],(-1,1,768))\n    h10 = tf.reshape(hidden_states[-3][:,0],(-1,1,768))\n    h09 = tf.reshape(hidden_states[-4][:,0],(-1,1,768))\n    concat_hidden = tf.keras.layers.Concatenate(axis=2)([h12, h11, h10, h09])\n\n    x = GlobalAveragePooling1D()(concat_hidden)\n\n    x = Dropout(0.2)(x)\n\n    if model_type == 'answers':\n      output = Dense(9, activation='sigmoid')(x)\n    elif model_type == 'questions':\n      output = Dense(21, activation='sigmoid')(x)\n    else:\n      output = Dense(30, activation='sigmoid')(x)\n\n    if (name == 'xlnet-base-cased') or (name=='roberta-base' and model_type!='questions'):\n      model = Model(inputs=[input_tokens, input_mask], outputs=output)\n    else:\n      model = Model(inputs=[input_tokens, input_mask, input_segment], outputs=output)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"CG8s5MvQtwmG","trusted":true},"cell_type":"code","source":"class data_generator:\n  def __init__(self, X, X_test, tokenizer, type_):\n      # test data\n      tokens, masks, segments = input_data(X_test, tokenizer, type_)\n      self.test_data = {'input_tokens': tokens, \n                        'input_mask': masks,\n                        'input_segment': segments} \n\n      # Train data\n      self.tokens, self.masks, self.segments = input_data(X, tokenizer, type_)\n  def generate_data(tr, cv, name='xlnet-base-cased', model_type='questions'):\n      if name!='xlnet-base-cased':\n          train_data = {'input_tokens': self.tokens[tr], \n                        'input_mask': self.masks[tr],\n                        'input_segment': self.segments[tr]}\n\n          cv_data = {'input_tokens': self.tokens[cv], \n                    'input_mask': self.masks[cv],\n                    'input_segment': self.segments[cv]}\n      else:\n          train_data = {'input_tokens': self.tokens[tr], \n                        'input_mask': self.masks[tr]}\n\n          cv_data = {'input_tokens': self.tokens[cv], \n                    'input_mask': self.masks[cv]}\n\n      if model_type=='questions':\n          y_tr = y.values[tr, 21:]\n          y_cv = y.values[cv, 21:]\n\n      elif model_type=='answers':\n          y_tr = y.values[tr, 21:]\n          y_cv = y.values[cv, 21:]\n\n      else:\n          y_tr = y.values[tr]\n          y_cv = y.values[cv]  \n\n      return train_data, cv_data, y_tr, y_cv","execution_count":null,"outputs":[]},{"metadata":{"id":"gmAfNI94Hqg1","trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/markpeng/ensemble-5models-v4-v7-magic/notebook?select=submission.csv#Do-Inference\ndef optimize_ranks(preds, unique_labels):\n    print(f'optimizing the predicted values...')\n    new_preds = np.zeros(preds.shape) \n    for i in range(preds.shape[1]):\n        interpolate_bins = np.digitize(preds[:, i], bins=unique_labels, right=False)\n        if len(np.unique(interpolate_bins)) == 1: \n            new_preds[:, i] = preds[:, i]\n        else:\n            new_preds[:, i] = unique_labels[interpolate_bins]\n\n    return new_preds","execution_count":null,"outputs":[]},{"metadata":{"id":"fcisW6nzH5jE","trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/markpeng/ensemble-5models-v4-v7-magic/notebook?select=submission.csv#Do-Inference\ndef get_exp_labels(train):\n    X = train.iloc[:, 11:]\n    unique_labels = np.unique(X.values)\n    denominator = 60\n    q = np.arange(0, 101, 100 / denominator)\n    exp_labels = np.percentile(unique_labels, q) # Generating the 60 bins.\n    return exp_labels","execution_count":null,"outputs":[]},{"metadata":{"id":"E_rh4f1et94h","trusted":true},"cell_type":"code","source":"# Function to calculate the Spearman's rank correlation coefficient 'rhos' of actual and predicted data.\ndef compute_spearmanr_ignore_nan(trues, preds):\n    rhos = []\n    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n        rhos.append(spearmanr(tcol, pcol).correlation)\n    return np.nanmean(rhos)","execution_count":null,"outputs":[]},{"metadata":{"id":"OekfaeiHt9zg","trusted":true},"cell_type":"code","source":"# Making the 'rhos' metric to tensorflow graph compatible.\ndef rhos(y, y_pred):\n    return tf.py_function(compute_spearmanr_ignore_nan, (y, y_pred), tf.double)","execution_count":null,"outputs":[]},{"metadata":{"id":"Esfxc7Olt9xa","trusted":true},"cell_type":"code","source":"def fit_model(model, model_name, model_type, data_gen, file_path, train, use_saved_weights=True): \n  path = '../input/google-qna-predicted-data/'\n  if use_saved_weights:\n    print(f'getting saved weights for {model_name}...')\n    model.load_weights(path+file_path)\n\n  else:\n    print(f'fitting data on {model_name}...')\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00002)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[rhos])\n    kf = KFold(n_splits=5, random_state=42)\n    for tr, cv in kf.split(np.arange(train.shape[0])):\n      tr_data, cv_data, y_tr, y_cv = data_gen.generate_data(tr, cv, model_name, model_type)\n      model.fit(tr_data, y_tr, epochs=1, batch_size=4, validation_data=(cv_data, y_cv))\n      model.save_weights(file_path)\n\n  return model","execution_count":null,"outputs":[]},{"metadata":{"id":"PKLPAroxPowX","trusted":true},"cell_type":"code","source":"def get_weighted_avg(model_predictions):\n  xlnet_q, xlnet_a, roberta_q, roberta_a, roberta_qa, bert_q, bert_a, bert_qa = model_predictions\n  xlnet_concat = np.concatenate((xlnet_q, xlnet_a), axis=1)\n  bert_concat = np.concatenate((bert_q, bert_a), axis=1)\n  roberta_concat = np.concatenate((roberta_q, roberta_a), axis=1)\n  predict = (roberta_qa + bert_qa + xlnet_concat + bert_concat + roberta_concat)/5\n\n  return predict","execution_count":null,"outputs":[]},{"metadata":{"id":"ws5J-xG_6Co6","trusted":true},"cell_type":"code","source":"def get_predictions(predictions_present=True, model_saved_weights_present=True):\n  msw = model_saved_weights_present\n  X, X_test, y, train, test = get_data()\n  path = '../input/google-qna-predicted-data/'\n  model_names = ['xlnet-base-cased', 'roberta-base', 'bert-base-uncased']\n  model_types = ['questions', 'answers', 'questions_answers']\n  saved_weights_names = ['xlnet_q.h5', 'xlnet_a.h5', 'roberta_q.h5', 'roberta_a.h5', \n                        'roberta_qa.h5', 'bert_q.h5', 'bert_a.h5', 'bert_qa.h5']\n\n  saved_model_predictions = [path+'xlnet_q.csv', path+'xlnet_a.csv', path+'roberta_q.csv', path+'roberta_a.csv', \n                              path+'roberta_qa.csv', path+'bert_q.csv', path+'bert_a.csv', path+'bert_qa.csv']\n  model_predictions = []\n\n  if predictions_present:\n    model_predictions = [pd.read_csv(file_name).values for file_name in saved_model_predictions]\n\n  else:\n    i = 0\n    for name_ in model_names:\n      for type_ in model_types:\n        if name_ == 'xlnet-base-cased' and type_ == 'questions_answers':\n          continue\n        print('-'*100)\n        model = create_model(name_, type_)\n        tokenizer = get_tokenizer(name_)\n        data_gen = data_generator(X, X_test, tokenizer, type_)\n        model = fit_model(model, name_, type_, data_gen, saved_weights_names[i], train, msw)\n        print(f'getting target predictions from {name_}...')\n        model_predictions.append(model.predict(data_gen.test_data))\n        i+=1\n\n  predicted_labels = get_weighted_avg(model_predictions)\n  exp_labels = get_exp_labels(train)\n  optimized_predicted_labels = optimize_ranks(predicted_labels, exp_labels)\n  df = pd.concat([test['qa_id'], pd.DataFrame(optimized_predicted_labels, columns=train.columns[11:])], axis=1)\n  print('done...!')\n\n  return df","execution_count":null,"outputs":[]},{"metadata":{"id":"FI5ThlZB6CmE","outputId":"38d1b92d-011c-481f-ed6b-77c0de318a0d","trusted":true},"cell_type":"code","source":"submission = get_predictions(predictions_present=True)\n# submission.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"JwttGF67QdL7","trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/google-qna-predicted-data/output.csv')\nsample_submission = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')\n\nsample_submission = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')\nid_in_sub = set(submission.qa_id)\nid_in_sample_submission = set(sample_submission.qa_id)\ndiff = id_in_sample_submission - id_in_sub\n\nsample_submission = pd.concat([submission, sample_submission[sample_submission.qa_id.isin(diff)]]).reset_index(drop=True)\nsample_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}