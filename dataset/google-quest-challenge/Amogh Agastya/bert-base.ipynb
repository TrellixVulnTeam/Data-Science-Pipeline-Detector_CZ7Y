{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BERT - TensorFlow 2.0\n\nBERT is a deep learning model that has given state-of-the-art results on a wide variety of natural language processing tasks. It stands for Bidirectional Encoder Representations for Transformers. It has been pre-trained on Wikipedia and BooksCorpus and requires (only) task-specific fine-tuning.\n\n## What is BERT?\n\nIt is basically a bunch of Transformer encoders stacked together (not the whole Transformer architecture but just the encoder). The concept of bidirectionality is the key differentiator between BERT and its predecessor, OpenAI GPT. BERT is bidirectional because its self-attention layer performs self-attention on both directions."},{"metadata":{},"cell_type":"markdown","source":"## Setting up Environment"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport os\nfrom scipy.stats import spearmanr\nfrom math import floor, ceil\nfrom transformers import *\n\nnp.set_printoptions(suppress=True)\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Loading and exploration"},{"metadata":{},"cell_type":"markdown","source":"#### 1. Read data and tokenizer\n\nRead tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/google-quest-challenge/'\n\nBERT_PATH = '../input/bert-base-uncased-huggingface-transformer/'\ntokenizer = BertTokenizer.from_pretrained(BERT_PATH+'bert-base-uncased-vocab.txt')\n\nMAX_SEQUENCE_LENGTH = 384\n\ndf_train = pd.read_csv(PATH+'train.csv')\ndf_test = pd.read_csv(PATH+'test.csv')\ndf_sub = pd.read_csv(PATH+'sample_submission.csv')\nprint('train shape =', df_train.shape)\nprint('test shape =', df_test.shape)\n\noutput_categories = list(df_train.columns[11:])\ninput_categories = list(df_train.columns[[1,2,5]])\nprint('\\ninput categories:\\n\\t', input_categories)\nprint('\\noutput categories:\\n\\t', output_categories)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Target labels\n\nEach row is identified by question id: qa_id, and other 30 columns are target labels.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# At First Glance:\n### Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"train0 = df_train.iloc[0]\nprint('URL           : ', train0['url'])\nprint('Question_title: ', train0['question_title'])\nprint('Question_body : ', train0['question_body'])\nprint('Answer        : ', train0['answer'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = [col for col in df_train.columns if col not in df_sub.columns]\nprint('Feature columns: ', feature_columns)\ndf_train[feature_columns].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categories\n\nThe dataset consists of 5 categories: \"Technology\", \"Stackoverflow\", \"Culture\", \"Science\", \"Life arts\".\nTrain/Test distribution is almost same."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_category = df_train['category'].value_counts()\ntest_category = df_test['category'].value_counts()\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\ntrain_category.plot(kind='bar', ax=axes[0])\naxes[0].set_title('Train')\ntest_category.plot(kind='bar', ax=axes[1])\naxes[1].set_title('Test')\nprint('Train/Test category distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word Cloud visualization\n\nLet's see what kind of word are used for question and answer. Also let's check the difference between train and test.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\n\ndef plot_wordcloud(text, ax, title=None):\n    wordcloud = WordCloud(max_font_size=None, background_color='white',\n                          width=1200, height=1000).generate(text_cat)\n    ax.imshow(wordcloud)\n    if title is not None:\n        ax.set_title(title)\n    ax.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training data Word Cloud')\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 18))\n\ntext_cat = ' '.join(df_train['question_title'].values)\nplot_wordcloud(text_cat, axes[0], 'Question title')\n\ntext_cat = ' '.join(df_train['question_body'].values)\nplot_wordcloud(text_cat, axes[1], 'Question body')\n\ntext_cat = ' '.join(df_train['answer'].values)\nplot_wordcloud(text_cat, axes[2], 'Answer')\n\nplt.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test data Word Cloud')\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 18))\n\ntext_cat = ' '.join(df_test['question_title'].values)\nplot_wordcloud(text_cat, axes[0], 'Question title')\n\ntext_cat = ' '.join(df_test['question_body'].values)\nplot_wordcloud(text_cat, axes[1], 'Question body')\n\ntext_cat = ' '.join(df_test['answer'].values)\nplot_wordcloud(text_cat, axes[2], 'Answer')\n\nplt.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## User check\n\nThe dataset contains question user and answer user information. This may be because user attribution is impotant, same user tend to answer same kind of question and same answer user tends to answer in similar quality."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_question_user = df_train['question_user_name'].unique()\ntest_question_user = df_test['question_user_name'].unique()\n\nprint('Number of unique question user in train: ', len(train_question_user))\nprint('Number of unique question user in test : ', len(test_question_user))\nprint('Number of unique question user in both train & test : ', len(set(train_question_user) & set(test_question_user)))\nprint('\\n')\ntrain_answer_user = df_train['answer_user_name'].unique()\ntest_answer_user = df_test['answer_user_name'].unique()\n\nprint('Number of unique answer user in train: ', len(train_answer_user))\nprint('Number of unique answer user in test : ', len(test_answer_user))\nprint('Number of unique answer user in both train & test : ', len(set(train_answer_user) & set(test_answer_user)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Preprocessing functions\n\nThese are some functions that will be used to preprocess the raw text data into useable Bert inputs."},{"metadata":{"trusted":true},"cell_type":"code","source":"def _convert_to_transformer_inputs(title, question, answer, tokenizer, max_sequence_length):\n    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n    \n    def return_id(str1, str2, truncation_strategy, length):\n\n        inputs = tokenizer.encode_plus(str1, str2,\n            add_special_tokens=True,\n            max_length=length,\n            truncation_strategy=truncation_strategy)\n        \n        input_ids =  inputs[\"input_ids\"]\n        input_masks = [1] * len(input_ids)\n        input_segments = inputs[\"token_type_ids\"]\n        padding_length = length - len(input_ids)\n        padding_id = tokenizer.pad_token_id\n        input_ids = input_ids + ([padding_id] * padding_length)\n        input_masks = input_masks + ([0] * padding_length)\n        input_segments = input_segments + ([0] * padding_length)\n        \n        return [input_ids, input_masks, input_segments]\n    \n    input_ids_q, input_masks_q, input_segments_q = return_id(\n        title + ' ' + question, None, 'longest_first', max_sequence_length)\n    \n    input_ids_a, input_masks_a, input_segments_a = return_id(\n        answer, None, 'longest_first', max_sequence_length)\n    \n    return [input_ids_q, input_masks_q, input_segments_q,\n            input_ids_a, input_masks_a, input_segments_a]\n\ndef compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n    input_ids_q, input_masks_q, input_segments_q = [], [], []\n    input_ids_a, input_masks_a, input_segments_a = [], [], []\n    for _, instance in tqdm(df[columns].iterrows()):\n        t, q, a = instance.question_title, instance.question_body, instance.answer\n\n        ids_q, masks_q, segments_q, ids_a, masks_a, segments_a = \\\n        _convert_to_transformer_inputs(t, q, a, tokenizer, max_sequence_length)\n        \n        input_ids_q.append(ids_q)\n        input_masks_q.append(masks_q)\n        input_segments_q.append(segments_q)\n\n        input_ids_a.append(ids_a)\n        input_masks_a.append(masks_a)\n        input_segments_a.append(segments_a)\n        \n    return [np.asarray(input_ids_q, dtype=np.int32), \n            np.asarray(input_masks_q, dtype=np.int32), \n            np.asarray(input_segments_q, dtype=np.int32),\n            np.asarray(input_ids_a, dtype=np.int32), \n            np.asarray(input_masks_a, dtype=np.int32), \n            np.asarray(input_segments_a, dtype=np.int32)]\n\ndef compute_output_arrays(df, columns):\n    return np.asarray(df[columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Create model\n\n`compute_spearmanr()` is used to compute the competition metric for the validation set\n<br><br>\n`create_model()` contains the actual architecture that will be used to finetune BERT to our dataset.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_spearmanr_ignore_nan(trues, preds):\n    rhos = []\n    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n        rhos.append(spearmanr(tcol, pcol).correlation)\n    return np.nanmean(rhos)\n\ndef create_model():\n    q_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    a_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    \n    q_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    a_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    \n    q_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    a_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n    \n    config = BertConfig() # print(config) to see settings\n    config.output_hidden_states = False # Set to True to obtain hidden states\n    # caution: when using e.g. XLNet, XLNetConfig() will automatically use xlnet-large config\n    \n    # normally \".from_pretrained('bert-base-uncased')\", but because of no internet, the \n    # pretrained model has been downloaded manually and uploaded to kaggle. \n    bert_model = TFBertModel.from_pretrained(\n        BERT_PATH+'bert-base-uncased-tf_model.h5', config=config)\n    \n    # if config.output_hidden_states = True, obtain hidden states via bert_model(...)[-1]\n    q_embedding = bert_model(q_id, attention_mask=q_mask, token_type_ids=q_atn)[0]\n    a_embedding = bert_model(a_id, attention_mask=a_mask, token_type_ids=a_atn)[0]\n    \n    q = tf.keras.layers.GlobalAveragePooling1D()(q_embedding)\n    a = tf.keras.layers.GlobalAveragePooling1D()(a_embedding)\n    \n    x = tf.keras.layers.Concatenate()([q, a])\n    \n    x = tf.keras.layers.Dropout(0.2)(x)\n    \n    x = tf.keras.layers.Dense(30, activation='sigmoid')(x)\n\n    model = tf.keras.models.Model(inputs=[q_id, q_mask, q_atn, a_id, a_mask, a_atn,], outputs=x)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Obtain inputs and targets, as well as the indices of the train/validation splits"},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs = compute_output_arrays(df_train, output_categories)\ninputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\ntest_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5. Training, validation and testing\n\nLoops over the folds in gkf and trains each fold for 3 epochs --- with a learning rate of 3e-5 and batch_size of 6. A simple binary crossentropy is used as the objective-/loss-function. "},{"metadata":{"trusted":true},"cell_type":"code","source":"gkf = GroupKFold(n_splits=5).split(X=df_train.question_body, groups=df_train.question_body)\n\nvalid_preds = []\ntest_preds = []\nfor fold, (train_idx, valid_idx) in enumerate(gkf):\n    \n    # will actually only do 2 folds (out of 5) to manage < 2h\n    if fold in [0, 2]:\n\n        train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n        train_outputs = outputs[train_idx]\n\n        valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n        valid_outputs = outputs[valid_idx]\n        \n        K.clear_session()\n        model = create_model()\n        optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n        model.compile(loss='binary_crossentropy', optimizer=optimizer)\n        model.fit(train_inputs, train_outputs, epochs=3, batch_size=6)\n        # model.save_weights(f'bert-{fold}.h5')\n        valid_preds.append(model.predict(valid_inputs))\n        test_preds.append(model.predict(test_inputs))\n        \n        rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_preds[-1])\n        print('validation score = ', rho_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6. Process and submit test predictions\n\nAverage fold predictions, then save as `submission.csv`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.iloc[:, 1:] = np.average(test_preds, axis=0) # for weighted average set weights=[...]\n\ndf_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":4}