{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In a nutshell, our team trained 3 models: 2 [BERT](https://arxiv.org/abs/1810.04805) ones, one [RoBERTa](https://arxiv.org/abs/1907.11692). Key ideas are:\n- pretraining language models with StackExchange data and auxiliary targets\n- postprocessing predictions\n","metadata":{}},{"cell_type":"markdown","source":"**Install necessary packages**\n - [mag](https://github.com/ex4sperans/mag) is a lightweight library to keep track of experiments\n - sacremoses is a dependency for transformers","metadata":{}},{"cell_type":"code","source":"%%time\n!pip install /kaggle/input/pythonmag/mag > /dev/null\n!pip install ../input/sacremoses/sacremoses-master/ > /dev/null","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:31:35.574491Z","iopub.execute_input":"2021-12-13T18:31:35.574828Z","iopub.status.idle":"2021-12-13T18:31:52.35541Z","shell.execute_reply.started":"2021-12-13T18:31:35.574784Z","shell.execute_reply":"2021-12-13T18:31:52.354297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nfrom collections import Counter\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import spearmanr\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:31:52.358689Z","iopub.execute_input":"2021-12-13T18:31:52.35895Z","iopub.status.idle":"2021-12-13T18:31:53.4403Z","shell.execute_reply.started":"2021-12-13T18:31:52.358901Z","shell.execute_reply":"2021-12-13T18:31:53.439535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')\n# temp = temp[2000:2476]\n# temp","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:31:53.441778Z","iopub.execute_input":"2021-12-13T18:31:53.442051Z","iopub.status.idle":"2021-12-13T18:31:53.445592Z","shell.execute_reply.started":"2021-12-13T18:31:53.442007Z","shell.execute_reply":"2021-12-13T18:31:53.444747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ss = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n# c = list(ss)\n# df = temp[temp.columns.intersection(c)]\n# df.to_csv(\"test_actual.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:31:53.446787Z","iopub.execute_input":"2021-12-13T18:31:53.447226Z","iopub.status.idle":"2021-12-13T18:31:53.454445Z","shell.execute_reply.started":"2021-12-13T18:31:53.447174Z","shell.execute_reply":"2021-12-13T18:31:53.453567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ts = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n# d = list(ts)\n# data = temp[temp.columns.intersection(d)]\n# data.to_csv(\"test.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:31:53.458242Z","iopub.execute_input":"2021-12-13T18:31:53.458783Z","iopub.status.idle":"2021-12-13T18:31:53.463683Z","shell.execute_reply.started":"2021-12-13T18:31:53.458732Z","shell.execute_reply":"2021-12-13T18:31:53.462637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Inference\n\n### Model 1. BERT base uncased\n\nThis is an uncased BERT model, its LM is finetuned with StackExchange data.","metadata":{}},{"cell_type":"code","source":"%%time\n!python /kaggle/input/old-bert-code/predict_test.py \\\n  --data_path ../input/qna-custom-test-data         \\\n  --model_dir /kaggle/input/stackx-80-aux-ep-3       \\\n  --sub_file model1_bert_base_uncased_pred.csv","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:31:53.465838Z","iopub.execute_input":"2021-12-13T18:31:53.46658Z","iopub.status.idle":"2021-12-13T18:34:03.947646Z","shell.execute_reply.started":"2021-12-13T18:31:53.466528Z","shell.execute_reply":"2021-12-13T18:34:03.946724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2. BERT base cased\n\nThis is a cased BERT model, its LM is finetuned with StackExchange data, code has been refactored w.r.t. to the first model.","metadata":{}},{"cell_type":"code","source":"%%time\n!python ../input/bert-base-random-code/run.py                \\\n  --sub_file=model2_bert_base_cased_pred.csv                  \\\n  --data_path=../input/qna-custom-test-data/                    \\\n  --max_sequence_length=500                                     \\\n  --max_title_length=26                                          \\\n  --max_question_length=260                                       \\\n  --max_answer_length=210                                          \\\n  --batch_size=8                                                    \\\n  --bert_model=/kaggle/input/bert-base-pretrained/stackx-base-cased/","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:34:03.950988Z","iopub.execute_input":"2021-12-13T18:34:03.951255Z","iopub.status.idle":"2021-12-13T18:35:58.994948Z","shell.execute_reply.started":"2021-12-13T18:34:03.951208Z","shell.execute_reply":"2021-12-13T18:35:58.994014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 3. RoBERTa\n\nHere we're resorting to both LM finetuning and pseudo-labeling.","metadata":{}},{"cell_type":"code","source":"# setups\n# remove -2\nROBERTA_EXPERIMENT_DIR = \"2-4-roberta-base-saved-5-head_tail-roberta-stackx-base-v2-pl1kksample20k-1e-05-210-260-500-26-roberta-200\"\n!mkdir $ROBERTA_EXPERIMENT_DIR\n!ln -s /kaggle/input/roberta-stackx-base-pl20k/checkpoints $ROBERTA_EXPERIMENT_DIR/checkpoints\n\nROBERTA_CONFIG = {\n    \"_seed\": 42,\n    \"batch_accumulation\": 2,\n    \"batch_size\": 4,\n    \"bert_model\": \"roberta-base-saved\",\n    \"folds\": 5,\n    \"head_tail\": True,\n    \"label\": \"roberta-stackx-base-v2-pl1kksample20k\",\n    \"lr\": 1e-05,\n    \"max_answer_length\": 210,\n    \"max_question_length\": 260,\n    \"max_sequence_length\": 500,\n    \"max_title_length\": 26,\n    \"model_type\": \"roberta\",\n    \"warmup\": 200\n}\nwith open(os.path.join(ROBERTA_EXPERIMENT_DIR, \"config.json\"), \"w\") as fp:\n    json.dump(ROBERTA_CONFIG, fp)\n    \n!echo kek > $ROBERTA_EXPERIMENT_DIR/command","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:35:58.997502Z","iopub.execute_input":"2021-12-13T18:35:58.997997Z","iopub.status.idle":"2021-12-13T18:36:01.121927Z","shell.execute_reply.started":"2021-12-13T18:35:58.997942Z","shell.execute_reply":"2021-12-13T18:36:01.120907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n!python ../input/roberta-base-code/infer.py                 \\\n  --experiment $ROBERTA_EXPERIMENT_DIR                       \\\n  --checkpoint=best_model.pth                                 \\\n  --bert_model=/kaggle/input/roberta-base-model                \\\n  --dataframe=../input/qna-custom-test-data/test.csv     \\\n  --output_dir=roberta-base-output\n","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:36:01.123646Z","iopub.execute_input":"2021-12-13T18:36:01.123995Z","iopub.status.idle":"2021-12-13T18:38:13.115926Z","shell.execute_reply.started":"2021-12-13T18:36:01.12394Z","shell.execute_reply":"2021-12-13T18:38:13.115168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blending and postprocessing","metadata":{"trusted":true}},{"cell_type":"markdown","source":"**First, we read the 30 target columns that we need to predict.**","metadata":{}},{"cell_type":"code","source":"sample_submission_df = pd.read_csv(\"../input/qna-custom-test-data/sample_submission.csv\", \n                             index_col='qa_id')\ntarget_columns = sample_submission_df.columns\nprint(f'There are {len(target_columns)} targets to predict')\n\ntrain_df = pd.read_csv(\"../input/qna-custom-test-data/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.117699Z","iopub.execute_input":"2021-12-13T18:38:13.118014Z","iopub.status.idle":"2021-12-13T18:38:13.39752Z","shell.execute_reply.started":"2021-12-13T18:38:13.117965Z","shell.execute_reply":"2021-12-13T18:38:13.396721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading submission files**","metadata":{}},{"cell_type":"code","source":"model1_bert_base_uncased_pred_df = pd.read_csv(\"model1_bert_base_uncased_pred.csv\")\nmodel2_bert_base_cased_pred_df = pd.read_csv(\"model2_bert_base_cased_pred.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.398847Z","iopub.execute_input":"2021-12-13T18:38:13.399125Z","iopub.status.idle":"2021-12-13T18:38:13.420265Z","shell.execute_reply.started":"2021-12-13T18:38:13.39908Z","shell.execute_reply":"2021-12-13T18:38:13.419646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**For RoBERTa, we average predictions from 5 folds**","metadata":{}},{"cell_type":"code","source":"roberta_base_dfs = [pd.read_csv(\n                    os.path.join(\"roberta-base-output\", \"fold-{}.csv\".format(fold))) \n                    for fold in range(5)]\n\nmodel3_roberta_pred_df = roberta_base_dfs[0].copy()\n\nfor col in target_columns:\n    model3_roberta_pred_df[col] = np.mean([df[col] for df in roberta_base_dfs], axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.421759Z","iopub.execute_input":"2021-12-13T18:38:13.422196Z","iopub.status.idle":"2021-12-13T18:38:13.509698Z","shell.execute_reply.started":"2021-12-13T18:38:13.422013Z","shell.execute_reply":"2021-12-13T18:38:13.509034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Blending**","metadata":{"trusted":true}},{"cell_type":"code","source":"blended_df = model3_roberta_pred_df.copy()\n\nfor col in target_columns:\n    blended_df[col] = (\n        model1_bert_base_uncased_pred_df[col] * 0.1 +\n        model2_bert_base_cased_pred_df[col] * 0.2 + \n        model3_roberta_pred_df[col] * 0.1 \n    )","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.511062Z","iopub.execute_input":"2021-12-13T18:38:13.511603Z","iopub.status.idle":"2021-12-13T18:38:13.565334Z","shell.execute_reply.started":"2021-12-13T18:38:13.511521Z","shell.execute_reply":"2021-12-13T18:38:13.564721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Applying postprocessing to the final blend, also discussed [here](https://www.kaggle.com/c/google-quest-challenge/discussion/129840).**","metadata":{}},{"cell_type":"code","source":"def postprocess_single(target, ref):\n    \"\"\"\n    The idea here is to make the distribution of a particular predicted column\n    to match the correspoding distribution of the corresponding column in the\n    training dataset (called ref here)\n    \"\"\"\n    \n    ids = np.argsort(target)\n    counts = sorted(Counter(ref).items(), key=lambda s: s[0])\n    scores = np.zeros_like(target)\n    \n    last_pos = 0\n    v = 0\n    \n    for value, count in counts:\n        next_pos = last_pos + int(round(count / len(ref) * len(target)))\n        if next_pos == last_pos:\n            next_pos += 1\n\n        cond = ids[last_pos:next_pos]\n        scores[cond] = v\n        last_pos = next_pos\n        v += 1\n        \n    return scores / scores.max()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.56654Z","iopub.execute_input":"2021-12-13T18:38:13.566875Z","iopub.status.idle":"2021-12-13T18:38:13.576446Z","shell.execute_reply.started":"2021-12-13T18:38:13.566761Z","shell.execute_reply":"2021-12-13T18:38:13.575638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def postprocess_prediction(prediction, actual):\n    \n    postprocessed = prediction.copy()\n    \n    for col in target_columns:\n        scores = postprocess_single(prediction[col].values, actual[col].values)\n        # Those are columns where our postprocessing gave substantial improvement.\n        # It also helped for some others, but we didn't include them as the gain was\n        # very marginal (less than 0.01)\n        if col in (\n            \"question_conversational\",\n            \"question_type_compare\",\n            \"question_type_definition\",\n            \"question_type_entity\",\n            \"question_has_commonly_accepted_answer\",\n            \"question_type_consequence\",\n            \"question_type_spelling\"\n        ):\n            postprocessed[col] = scores\n            \n        # scale to 0-1 interval\n        v = postprocessed[col].values\n        postprocessed[col] = (v - v.min()) / (v.max() - v.min())\n    \n    return postprocessed","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.577675Z","iopub.execute_input":"2021-12-13T18:38:13.578287Z","iopub.status.idle":"2021-12-13T18:38:13.586616Z","shell.execute_reply.started":"2021-12-13T18:38:13.577949Z","shell.execute_reply":"2021-12-13T18:38:13.585652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"postprocessed = postprocess_prediction(blended_df, train_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.588062Z","iopub.execute_input":"2021-12-13T18:38:13.588424Z","iopub.status.idle":"2021-12-13T18:38:13.678578Z","shell.execute_reply.started":"2021-12-13T18:38:13.588334Z","shell.execute_reply":"2021-12-13T18:38:13.677918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Saving the submission file.**","metadata":{}},{"cell_type":"code","source":"postprocessed.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.680216Z","iopub.execute_input":"2021-12-13T18:38:13.680663Z","iopub.status.idle":"2021-12-13T18:38:13.883568Z","shell.execute_reply.started":"2021-12-13T18:38:13.680477Z","shell.execute_reply":"2021-12-13T18:38:13.882848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual = pd.read_csv('../input/qna-custom-test-data/test_actual.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-13T18:38:13.884834Z","iopub.execute_input":"2021-12-13T18:38:13.885099Z","iopub.status.idle":"2021-12-13T18:38:13.902449Z","shell.execute_reply.started":"2021-12-13T18:38:13.885057Z","shell.execute_reply":"2021-12-13T18:38:13.901628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_1 = model1_bert_base_uncased_pred_df\npreds_1 = preds_1.assign(qa_id = actual['qa_id'])\ncorr_1 = [spearmanr(preds_1[col], actual[col]).correlation for col in actual]\ncorr_1[20] = 1.\nnp.mean(corr_1)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T19:08:27.782893Z","iopub.execute_input":"2021-12-13T19:08:27.783329Z","iopub.status.idle":"2021-12-13T19:08:27.824283Z","shell.execute_reply.started":"2021-12-13T19:08:27.78313Z","shell.execute_reply":"2021-12-13T19:08:27.823294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_2 = model2_bert_base_cased_pred_df\npreds_2 = preds_2.assign(qa_id = actual['qa_id'])\ncorr_2 = [spearmanr(preds_2[col], actual[col]).correlation for col in actual]\ncorr_2[20] = 1.\nnp.mean(corr_2)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T19:09:27.346873Z","iopub.execute_input":"2021-12-13T19:09:27.347346Z","iopub.status.idle":"2021-12-13T19:09:27.387958Z","shell.execute_reply.started":"2021-12-13T19:09:27.347129Z","shell.execute_reply":"2021-12-13T19:09:27.387352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_3 = model3_roberta_pred_df\npreds_3 = preds_3.assign(qa_id = actual['qa_id'])\ncorr_3 = [spearmanr(preds_3[col], actual[col]).correlation for col in actual]\ncorr_3[20] = 1.\nnp.mean(corr_3)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T19:10:27.156325Z","iopub.execute_input":"2021-12-13T19:10:27.156622Z","iopub.status.idle":"2021-12-13T19:10:27.194772Z","shell.execute_reply.started":"2021-12-13T19:10:27.156573Z","shell.execute_reply":"2021-12-13T19:10:27.193857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_blended = [spearmanr(blended_df[col], actual[col]).correlation for col in actual]\ncorr_blended[20] = 1.\nnp.mean(corr_blended)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T19:10:54.948112Z","iopub.execute_input":"2021-12-13T19:10:54.94844Z","iopub.status.idle":"2021-12-13T19:10:54.986028Z","shell.execute_reply.started":"2021-12-13T19:10:54.948388Z","shell.execute_reply":"2021-12-13T19:10:54.985283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = [spearmanr(postprocessed[col], actual[col]).correlation for col in actual]\ncorr[20] = 1.\nnp.mean(corr)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T19:10:41.380407Z","iopub.execute_input":"2021-12-13T19:10:41.380725Z","iopub.status.idle":"2021-12-13T19:10:41.418721Z","shell.execute_reply.started":"2021-12-13T19:10:41.380671Z","shell.execute_reply":"2021-12-13T19:10:41.417999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx = ['BERT uncased', 'BERT cased', 'RoBERTa', 'Combined resuts', 'After post processing']\ny = [np.mean(corr_1), np.mean(corr_2), np.mean(corr_3), np.mean(corr_blended), np.mean(corr)]\n\ndf = pd.DataFrame({'Models': x, 'Spearmans Correlation Score': y})\nimport plotly.express as px\n\n\nfig = px.bar(df, x = 'Models', y = 'Spearmans Correlation Score', color='Models')\nfig.update_layout(yaxis_range=[0.42,0.58])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T19:41:57.121354Z","iopub.execute_input":"2021-12-13T19:41:57.121659Z","iopub.status.idle":"2021-12-13T19:41:57.630016Z","shell.execute_reply.started":"2021-12-13T19:41:57.121611Z","shell.execute_reply":"2021-12-13T19:41:57.629028Z"},"trusted":true},"execution_count":null,"outputs":[]}]}