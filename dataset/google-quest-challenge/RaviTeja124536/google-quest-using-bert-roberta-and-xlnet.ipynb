{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as implt\nfrom sklearn.model_selection import KFold\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom transformers import BertTokenizer,TFBertModel,RobertaTokenizer,TFRobertaModel,XLNetTokenizer,TFXLNetModel\nfrom tensorflow.keras.layers import Dense,Dropout,Input,Conv1D,BatchNormalization\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-02T13:41:24.866654Z","iopub.execute_input":"2021-12-02T13:41:24.867176Z","iopub.status.idle":"2021-12-02T13:41:32.727869Z","shell.execute_reply.started":"2021-12-02T13:41:24.867089Z","shell.execute_reply":"2021-12-02T13:41:32.726989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:32.729327Z","iopub.execute_input":"2021-12-02T13:41:32.729537Z","iopub.status.idle":"2021-12-02T13:41:32.733879Z","shell.execute_reply.started":"2021-12-02T13:41:32.729512Z","shell.execute_reply":"2021-12-02T13:41:32.733149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpu_devices = tf.config.experimental.list_physical_devices('GPU')\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:32.735Z","iopub.execute_input":"2021-12-02T13:41:32.735644Z","iopub.status.idle":"2021-12-02T13:41:32.760839Z","shell.execute_reply.started":"2021-12-02T13:41:32.73561Z","shell.execute_reply":"2021-12-02T13:41:32.760154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random as rn\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(42)\nrn.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:32.762262Z","iopub.execute_input":"2021-12-02T13:41:32.762782Z","iopub.status.idle":"2021-12-02T13:41:32.772793Z","shell.execute_reply.started":"2021-12-02T13:41:32.762736Z","shell.execute_reply":"2021-12-02T13:41:32.772073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/google-quest-challenge/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:32.774908Z","iopub.execute_input":"2021-12-02T13:41:32.775596Z","iopub.status.idle":"2021-12-02T13:41:33.147712Z","shell.execute_reply.started":"2021-12-02T13:41:32.775559Z","shell.execute_reply":"2021-12-02T13:41:33.146876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_columns=None","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:33.148734Z","iopub.execute_input":"2021-12-02T13:41:33.148941Z","iopub.status.idle":"2021-12-02T13:41:33.153427Z","shell.execute_reply.started":"2021-12-02T13:41:33.148915Z","shell.execute_reply":"2021-12-02T13:41:33.152584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:33.15439Z","iopub.execute_input":"2021-12-02T13:41:33.154634Z","iopub.status.idle":"2021-12-02T13:41:33.21202Z","shell.execute_reply.started":"2021-12-02T13:41:33.154608Z","shell.execute_reply":"2021-12-02T13:41:33.211265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:33.213485Z","iopub.execute_input":"2021-12-02T13:41:33.213936Z","iopub.status.idle":"2021-12-02T13:41:33.232253Z","shell.execute_reply.started":"2021-12-02T13:41:33.213895Z","shell.execute_reply":"2021-12-02T13:41:33.231394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:33.234006Z","iopub.execute_input":"2021-12-02T13:41:33.234779Z","iopub.status.idle":"2021-12-02T13:41:33.268486Z","shell.execute_reply.started":"2021-12-02T13:41:33.23474Z","shell.execute_reply":"2021-12-02T13:41:33.267639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:33.269707Z","iopub.execute_input":"2021-12-02T13:41:33.270284Z","iopub.status.idle":"2021-12-02T13:41:33.276133Z","shell.execute_reply.started":"2021-12-02T13:41:33.270208Z","shell.execute_reply":"2021-12-02T13:41:33.275307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:33.277197Z","iopub.execute_input":"2021-12-02T13:41:33.277732Z","iopub.status.idle":"2021-12-02T13:41:33.289135Z","shell.execute_reply.started":"2021-12-02T13:41:33.277699Z","shell.execute_reply":"2021-12-02T13:41:33.288473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRE_NAME='bert-base-uncased'\n#PRE_NAME='bert-large-uncased'\n#PRE_NAME='roberta-base'\n#PRE_NAME='roberta-large'\n#PRE_NAME='xlnet-base-cased'\n#PRE_NAME='xlnet-large-cased'\nHEADS=1","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:33.290127Z","iopub.execute_input":"2021-12-02T13:41:33.290789Z","iopub.status.idle":"2021-12-02T13:41:33.299758Z","shell.execute_reply.started":"2021-12-02T13:41:33.290653Z","shell.execute_reply":"2021-12-02T13:41:33.299145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PRE_NAME.startswith('bert'):\n    tokenizer=BertTokenizer.from_pretrained(PRE_NAME)\n    print(f\"the input format is \\n\")\n    print(tokenizer('Example where we will have first sentence here','Example where we will have second sentence here',\n                   max_length=40,padding='max_length',truncation='longest_first'))\n    print(\"\\n the tokens are\\n\")\n    print(tokenizer.convert_ids_to_tokens(tokenizer('Example where we will have first sentence here','Example where we will have second sentence here',\n                   max_length=40,padding='max_length',truncation='longest_first')['input_ids']))\nelif PRE_NAME.startswith('roberta'):\n    tokenizer=RobertaTokenizer.from_pretrained(PRE_NAME)\n    print(tokenizer(' Example where we will have first sentence here',' Example where we will have second sentence here',\n                   max_length=40,padding='max_length',truncation='longest_first'))\n    print(\"\\n the tokens are\\n\")\n    print(tokenizer.convert_ids_to_tokens(tokenizer(' Example where we will have first sentence here',' Example where we will have second sentence here',\n                   max_length=40,padding='max_length',truncation='longest_first')['input_ids']))\nelse:\n    tokenizer=XLNetTokenizer.from_pretrained(PRE_NAME)\n    print(tokenizer('Example where we will have first sentence here','Example where we will have second sentence here',\n                   max_length=40,padding='max_length',truncation='longest_first'))\n    print(\"\\n the tokens are\\n\")\n    print(tokenizer.convert_ids_to_tokens(tokenizer('Example where we will have first sentence here','Example where we will have second sentence here',\n                   max_length=40,padding='max_length',truncation='longest_first')['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:33.300857Z","iopub.execute_input":"2021-12-02T13:41:33.301095Z","iopub.status.idle":"2021-12-02T13:41:37.759086Z","shell.execute_reply.started":"2021-12-02T13:41:33.301067Z","shell.execute_reply":"2021-12-02T13:41:37.758275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols=['question_title', 'question_body','answer']\nfor col in cols:\n    lens=[]\n    for i in tqdm(range(df.shape[0])):\n        lens.append(len(tokenizer.tokenize(df.loc[i,col])))\n    print(f\"{col} has len distribution\\n\")\n    print(pd.Series(lens).describe())\n    print('\\n##############\\n')","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:41:37.763491Z","iopub.execute_input":"2021-12-02T13:41:37.764182Z","iopub.status.idle":"2021-12-02T13:42:12.036662Z","shell.execute_reply.started":"2021-12-02T13:41:37.764117Z","shell.execute_reply":"2021-12-02T13:42:12.035312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(df['category'])\nplt.xticks(rotation=30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.037909Z","iopub.status.idle":"2021-12-02T13:42:12.038413Z","shell.execute_reply.started":"2021-12-02T13:42:12.038147Z","shell.execute_reply":"2021-12-02T13:42:12.038173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols=['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']\nplt.subplots(6,5,figsize=(40,50))\nfor i,col in enumerate(cols):\n    plt.subplot(6,5,i+1)\n    plt.hist(df[col])\n    plt.title(col)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.040606Z","iopub.status.idle":"2021-12-02T13:42:12.043623Z","shell.execute_reply.started":"2021-12-02T13:42:12.04336Z","shell.execute_reply":"2021-12-02T13:42:12.043391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold=KFold(n_splits=5)\ndf['kfold']=-1\nfor i,(train,test) in enumerate(kfold.split(df[['question_title', 'question_body','answer']],df[cols])):\n    df.loc[test,'kfold']=i","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.044608Z","iopub.status.idle":"2021-12-02T13:42:12.044913Z","shell.execute_reply.started":"2021-12-02T13:42:12.044754Z","shell.execute_reply":"2021-12-02T13:42:12.04477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['kfold'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.046363Z","iopub.status.idle":"2021-12-02T13:42:12.046845Z","shell.execute_reply.started":"2021-12-02T13:42:12.046631Z","shell.execute_reply":"2021-12-02T13:42:12.046663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# input types for models\n \n title&q,title&a\n \n title&q,a\n \n title,q&  title,a\n \n title,q&  q,a ","metadata":{}},{"cell_type":"markdown","source":"# models\nbert,roberta,xlnet","metadata":{}},{"cell_type":"code","source":"MAX_LENGTH=512\n#h1=[['question_title', 'question_body'],['question_title','answer']]\n#h2=[]\n####################\nh1=[['question_title', 'question_body'],['answer']]\nh2=[]\n####################\n#h1=[['question_title', 'question_body'],['question_body','answer']]\n#h2=[]\n#####################\n#h1=[['question_body'],['question_title','answer']]\n#h2=[]\n#######################\n#h1=[['question_title'],['question_body','answer']]\n#h2=[]\n#####################\n#h1=[['question_title'],[ 'question_body']]\n#h2=[['question_title'],['answer']]\n#######################\n#h1=[['question_title'],[ 'question_body']]\n#h2=[['question_body'],['answer']]","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.04767Z","iopub.status.idle":"2021-12-02T13:42:12.047964Z","shell.execute_reply.started":"2021-12-02T13:42:12.047808Z","shell.execute_reply":"2021-12-02T13:42:12.047824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# bert related input","metadata":{}},{"cell_type":"code","source":"def get_bert_single_head_inputs(tokenizer,s1,s2,max_length):\n    s1=tokenizer.tokenize(s1)\n    s2=tokenizer.tokenize(s2)\n    s_len=max_length-3\n    s1_len=len(s1)\n    s2_len=len(s2)\n    if s1_len+s2_len==s_len:\n        total_tokens=['[CLS]']+s1+['[SEP]']+s2+['[SEP]']\n    elif s1_len+s2_len<s_len:\n        total_tokens=['[CLS]']+s1+['[SEP]']+s2+['[SEP]']\n    else:\n        if s_len%2==0: #even length so, lets divide equally\n            req_s1_len=s_len//2\n            req_s2_len=s_len//2\n        else:\n            req_s1_len=s_len//2\n            req_s2_len=(s_len//2)+1\n        if s1_len<=req_s1_len and s2_len>req_s2_len:\n            # s1 is shorter but s2 is longer\n            s2=s2[:s_len-s1_len]\n            total_tokens=['[CLS]']+s1+['[SEP]']+s2+['[SEP]']\n        elif s1_len>req_s1_len and s2_len<=req_s2_len:\n            # s1 is longer but s2 is shorter\n            s1=s1[:s_len-s2_len]\n            total_tokens=['[CLS]']+s1+['[SEP]']+s2+['[SEP]']\n        elif s1_len>req_s1_len and s2_len>req_s2_len:\n            # both are longer\n            s1=s1[:req_s1_len]\n            s2=s2[:req_s2_len]\n            total_tokens=['[CLS]']+s1+['[SEP]']+s2+['[SEP]']\n    total_tokens=total_tokens+['[PAD]']*(max_length-len(total_tokens))\n    input_ids=tokenizer.convert_tokens_to_ids(total_tokens)\n    attention_mask=np.char.not_equal(total_tokens,'[PAD]').astype('int32')\n    token_type_ids=[]\n    seq_num=0\n    for tok in total_tokens:\n        if tok=='[SEP]':\n            token_type_ids.append(seq_num)\n            seq_num=1-seq_num\n        else:\n            token_type_ids.append(seq_num)\n    return input_ids,attention_mask,token_type_ids","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.048979Z","iopub.status.idle":"2021-12-02T13:42:12.049306Z","shell.execute_reply.started":"2021-12-02T13:42:12.049123Z","shell.execute_reply":"2021-12-02T13:42:12.049139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# roberta related input","metadata":{}},{"cell_type":"code","source":"def get_roberta_single_head_inputs(tokenizer,s1,s2,max_length):\n    s1=tokenizer.tokenize(s1)\n    s2=tokenizer.tokenize(s2)\n    s_len=max_length-4\n    s1_len=len(s1)\n    s2_len=len(s2)\n    if s1_len+s2_len==s_len:\n        total_tokens=['<s>']+s1+['</s>']+['</s>']+s2+['</s>']\n    elif s1_len+s2_len<s_len:\n        total_tokens=['<s>']+s1+['</s>']+['</s>']+s2+['</s>']\n    else:\n        if s_len%2==0: #even length so, lets divide equally\n            req_s1_len=s_len//2\n            req_s2_len=s_len//2\n        else:\n            req_s1_len=s_len//2\n            req_s2_len=(s_len//2)+1\n        if s1_len<=req_s1_len and s2_len>req_s2_len:\n            # s1 is shorter but s2 is longer\n            s2=s2[:s_len-s1_len]\n            total_tokens=['<s>']+s1+['</s>']+['</s>']+s2+['</s>']\n        elif s1_len>req_s1_len and s2_len<=req_s2_len:\n            # s1 is longer but s2 is shorter\n            s1=s1[:s_len-s2_len]\n            total_tokens=['<s>']+s1+['</s>']+['</s>']+s2+['</s>']\n        elif s1_len>req_s1_len and s2_len>req_s2_len:\n            # both are longer\n            s1=s1[:req_s1_len]\n            s2=s2[:req_s2_len]\n            total_tokens=['<s>']+s1+['</s>']+['</s>']+s2+['</s>']\n    total_tokens=total_tokens+['<pad>']*(max_length-len(total_tokens))\n    input_ids=tokenizer.convert_tokens_to_ids(total_tokens)\n    attention_mask=np.char.not_equal(total_tokens,'<pad>').astype('int32')\n    return input_ids,attention_mask","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.050768Z","iopub.status.idle":"2021-12-02T13:42:12.051075Z","shell.execute_reply.started":"2021-12-02T13:42:12.050915Z","shell.execute_reply":"2021-12-02T13:42:12.050933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# xlnet related input","metadata":{}},{"cell_type":"code","source":"def get_xlnet_single_head_inputs(tokenizer,s1,s2,max_length):\n    s1=tokenizer.tokenize(s1)\n    s2=tokenizer.tokenize(s2)\n    s_len=max_length-3\n    s1_len=len(s1)\n    s2_len=len(s2)\n    if s1_len+s2_len==s_len:\n        total_tokens=s1+['<sep>']+s2+['<sep>']+['<cls>']\n    elif s1_len+s2_len<s_len:\n        total_tokens=s1+['<sep>']+s2+['<sep>']+['<cls>']\n    else:\n        if s_len%2==0: #even length so, lets divide equally\n            req_s1_len=s_len//2\n            req_s2_len=s_len//2\n        else:\n            req_s1_len=s_len//2\n            req_s2_len=(s_len//2)+1\n        if s1_len<=req_s1_len and s2_len>req_s2_len:\n            # s1 is shorter but s2 is longer\n            s2=s2[:s_len-s1_len]\n            total_tokens=s1+['<sep>']+s2+['<sep>']+['<cls>']\n        elif s1_len>req_s1_len and s2_len<=req_s2_len:\n            # s1 is longer but s2 is shorter\n            s1=s1[:s_len-s2_len]\n            total_tokens=s1+['<sep>']+s2+['<sep>']+['<cls>']\n        elif s1_len>req_s1_len and s2_len>req_s2_len:\n            # both are longer\n            s1=s1[:req_s1_len]\n            s2=s2[:req_s2_len]\n            total_tokens=s1+['<sep>']+s2+['<sep>']+['<cls>']\n    token_type_ids=[]\n    seq_num=0\n    for tok in total_tokens:\n        if tok=='<sep>':\n            token_type_ids.append(seq_num)\n            seq_num=1-seq_num\n        elif tok=='<cls>':\n            token_type_ids.append(2)\n        else:\n            token_type_ids.append(seq_num)\n    token_type_ids=[3]*(max_length-len(total_tokens))+token_type_ids\n    total_tokens=['<pad>']*(max_length-len(total_tokens))+total_tokens\n    input_ids=tokenizer.convert_tokens_to_ids(total_tokens)\n    attention_mask=np.char.not_equal(total_tokens,'<pad>').astype('int32')\n    return input_ids,attention_mask,token_type_ids","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.051967Z","iopub.status.idle":"2021-12-02T13:42:12.052293Z","shell.execute_reply.started":"2021-12-02T13:42:12.052108Z","shell.execute_reply":"2021-12-02T13:42:12.052123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_inputs(data,h1,h2,inference=False):\n    columns=data.columns.tolist()\n    y_columns=['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']\n    if len(h2)==0:# single head model\n        INPUT_IDS=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n        ATTENTION_MASK=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n        if not inference:\n            Y=np.empty((data.shape[0],30))\n        if not PRE_NAME.startswith('roberta'):\n            TOKEN_TYPE_IDS=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n        for i in range(data.shape[0]):\n            t1,t2=h1\n            s1=' '.join(data.loc[i,t1].values)\n            s2=' '.join(data.loc[i,t2].values)\n            if PRE_NAME.startswith('bert'):\n                INPUT_IDS[i,],ATTENTION_MASK[i,],TOKEN_TYPE_IDS[i,]=get_bert_single_head_inputs(tokenizer,s1,s2,MAX_LENGTH)\n            elif PRE_NAME.startswith('xlnet'):\n                INPUT_IDS[i,],ATTENTION_MASK[i,],TOKEN_TYPE_IDS[i,]=get_xlnet_single_head_inputs(tokenizer,s1,s2,MAX_LENGTH)\n            else:\n                INPUT_IDS[i,],ATTENTION_MASK[i,]=get_roberta_single_head_inputs(tokenizer,' '+s1,' '+s2,MAX_LENGTH)\n            if not inference:\n                Y[i,]=data.loc[i,y_columns]\n        if not PRE_NAME.startswith('roberta') and not inference:\n            return INPUT_IDS,ATTENTION_MASK,TOKEN_TYPE_IDS,Y\n        if not PRE_NAME.startswith('roberta') and inference:\n            return INPUT_IDS,ATTENTION_MASK,TOKEN_TYPE_IDS\n        else:\n            if not inference:\n                return INPUT_IDS,ATTENTION_MASK,Y\n            else:\n                return INPUT_IDS,ATTENTION_MASK\n    else:\n        INPUT_IDS1=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n        ATTENTION_MASK1=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n        INPUT_IDS2=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n        ATTENTION_MASK2=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n        if not inference:\n            Y=np.empty((data.shape[0],30))\n        if not PRE_NAME.startswith('roberta'):\n            TOKEN_TYPE_IDS1=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n            TOKEN_TYPE_IDS2=np.empty((data.shape[0],MAX_LENGTH),dtype=np.int32)\n        for i in range(data.shape[0]):\n            t1,t2=h1\n            s1=' '.join(data.loc[i,t1].values)\n            s2=' '.join(data.loc[i,t2].values)\n            if PRE_NAME.startswith('bert'):\n                INPUT_IDS1[i,],ATTENTION_MASK1[i,],TOKEN_TYPE_IDS1[i,]=get_bert_single_head_inputs(tokenizer,s1,s2,MAX_LENGTH)\n            elif PRE_NAME.startswith('xlnet'):\n                INPUT_IDS1[i,],ATTENTION_MASK1[i,],TOKEN_TYPE_IDS1[i,]=get_xlnet_single_head_inputs(tokenizer,s1,s2,MAX_LENGTH)\n            else:\n                INPUT_IDS1[i,],ATTENTION_MASK1[i,]=get_roberta_single_head_inputs(tokenizer,' '+s1,' '+s2,MAX_LENGTH)\n            t1,t2=h2\n            s1=' '.join(data.loc[i,t1].values)\n            s2=' '.join(data.loc[i,t2].values)\n            if PRE_NAME.startswith('bert'):\n                INPUT_IDS2[i,],ATTENTION_MASK2[i,],TOKEN_TYPE_IDS2[i,]=get_bert_single_head_inputs(tokenizer,s1,s2,MAX_LENGTH)\n            elif PRE_NAME.startswith('xlnet'):\n                INPUT_IDS2[i,],ATTENTION_MASK2[i,],TOKEN_TYPE_IDS2[i,]=get_xlnet_single_head_inputs(tokenizer,s1,s2,MAX_LENGTH)\n            else:\n                INPUT_IDS2[i,],ATTENTION_MASK2[i,]=get_roberta_single_head_inputs(tokenizer,' '+s1,' '+s2,MAX_LENGTH)\n            if not inference:\n                Y[i,]=data.loc[i,y_columns]\n        if not PRE_NAME.startswith('roberta') and not inference:\n            return INPUT_IDS1,ATTENTION_MASK1,TOKEN_TYPE_IDS1,INPUT_IDS2,ATTENTION_MASK2,TOKEN_TYPE_IDS2,Y\n        if not PRE_NAME.startswith('roberta') and inference:\n            return INPUT_IDS1,ATTENTION_MASK1,TOKEN_TYPE_IDS1,INPUT_IDS2,ATTENTION_MASK2,TOKEN_TYPE_IDS2\n        else:\n            if not inference:\n                return INPUT_IDS1,ATTENTION_MASK1,INPUT_IDS2,ATTENTION_MASK2,Y\n            else:\n                return INPUT_IDS1,ATTENTION_MASK1,INPUT_IDS2,ATTENTION_MASK2","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.05331Z","iopub.status.idle":"2021-12-02T13:42:12.053611Z","shell.execute_reply.started":"2021-12-02T13:42:12.05345Z","shell.execute_reply":"2021-12-02T13:42:12.053466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_final_model_inputs(data,h1,h2,inference=False):\n    if HEADS==1:\n        if not PRE_NAME.startswith('roberta'):\n            if not inference:\n                INPUT_IDS,ATTENTION_MASK,TOKEN_TYPE_IDS,Y=get_inputs(data,h1,h2,inference)\n            else:\n                INPUT_IDS,ATTENTION_MASK,TOKEN_TYPE_IDS=get_inputs(data,h1,h2,inference)\n            model_inputs={'input_ids':INPUT_IDS,\n                         'attention_mask':ATTENTION_MASK,\n                         'token_type_ids':TOKEN_TYPE_IDS}\n            if not inference:\n                model_outputs=Y\n        else:\n            if not inference:\n                INPUT_IDS,ATTENTION_MASK,Y=get_inputs(data,h1,h2,inference)\n            else:\n                INPUT_IDS,ATTENTION_MASK=get_inputs(data,h1,h2,inference)\n            model_inputs={'input_ids':INPUT_IDS,\n                         'attention_mask':ATTENTION_MASK\n                         }\n            if not inference:\n                model_outputs=Y\n    else:\n        if not PRE_NAME.startswith('roberta'):\n            if not inference:\n                INPUT_IDS1,ATTENTION_MASK1,TOKEN_TYPE_IDS1,INPUT_IDS2,ATTENTION_MASK2,TOKEN_TYPE_IDS2,Y=get_inputs(data,h1,h2,inference)\n            else:\n                INPUT_IDS1,ATTENTION_MASK1,TOKEN_TYPE_IDS1,INPUT_IDS2,ATTENTION_MASK2,TOKEN_TYPE_IDS2=get_inputs(data,h1,h2,inference)\n            model_inputs=[{'input_ids1':INPUT_IDS1,\n                         'attention_mask1':ATTENTION_MASK1,\n                         'token_type_ids1':TOKEN_TYPE_IDS1},\n                          {'input_ids2':INPUT_IDS2,\n                         'attention_mask2':ATTENTION_MASK2,\n                         'token_type_ids2':TOKEN_TYPE_IDS2}]\n            if not inference:\n                model_outputs=Y\n        else:\n            if not inference:\n                INPUT_IDS1,ATTENTION_MASK1,INPUT_IDS2,ATTENTION_MASK2,Y=get_inputs(data,h1,h2,inference)\n            else:\n                INPUT_IDS1,ATTENTION_MASK1,INPUT_IDS2,ATTENTION_MASK2=get_inputs(data,h1,h2,inference)\n            model_inputs=[{'input_ids1':INPUT_IDS1,\n                         'attention_mask1':ATTENTION_MASK1},\n                          {'input_ids2':INPUT_IDS2,\n                         'attention_mask2':ATTENTION_MASK2}]\n            if not inference:\n                model_outputs=Y\n    if not inference:\n        return model_inputs,model_outputs\n    else:\n        return model_inputs","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.054498Z","iopub.status.idle":"2021-12-02T13:42:12.054802Z","shell.execute_reply.started":"2021-12-02T13:42:12.054648Z","shell.execute_reply":"2021-12-02T13:42:12.054664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# models","metadata":{}},{"cell_type":"code","source":"PRE_NAME='bert-base-uncased'\n#PRE_NAME='bert-large-uncased'\n#PRE_NAME='roberta-base'\n#PRE_NAME='roberta-large'\n#PRE_NAME='xlnet-base-cased'\n#PRE_NAME='xlnet-large-cased'\nHEADS=1\nMAX_LENGTH=512","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.055714Z","iopub.status.idle":"2021-12-02T13:42:12.056041Z","shell.execute_reply.started":"2021-12-02T13:42:12.055869Z","shell.execute_reply":"2021-12-02T13:42:12.055892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# single head model","metadata":{}},{"cell_type":"code","source":"def SINGLE_MODEL(sequence=False,final_activation=True,hidden_states=True,hidden_number=4):\n    tf.keras.backend.clear_session()\n    if PRE_NAME.startswith('bert'):\n        ins1=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins2=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins3=Input((MAX_LENGTH,),dtype=tf.int32)\n        pre_model=TFBertModel.from_pretrained(PRE_NAME,output_hidden_states=hidden_states,return_dict=True)\n        pre_layers=pre_model({'input_ids':ins1,'attention_mask':ins2,'token_type_ids':ins3})\n    elif PRE_NAME.startswith('xlnet'):\n        ins1=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins2=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins3=Input((MAX_LENGTH,),dtype=tf.int32)\n        pre_model=TFXLNetModel.from_pretrained(PRE_NAME,output_hidden_states=hidden_states,return_dict=True)\n        pre_layers=pre_model({'input_ids':ins1,'attention_mask':ins2,'token_type_ids':ins3})\n    else:\n        ins1=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins2=Input((MAX_LENGTH,),dtype=tf.int32)\n        pre_model=TFRobertaModel.from_pretrained(PRE_NAME,output_hidden_states=hidden_states,return_dict=True)\n        pre_layers=pre_model({'input_ids':ins1,'attention_mask':ins2})\n    if sequence:\n        x=Conv1D(1,1)(pre_layers[0])\n        x=tf.squeeze(x,axis=-1)\n        x=BatchNormalization()(x)\n        x=Dropout(0.1)(x)\n        x=tf.keras.layers.ReLU()(x)\n    elif hidden_states:\n        if not PRE_NAME.startswith('xlnet'):\n            x=tf.stack([layer[:,0,:] for layer in pre_layers[2][-hidden_number:]],axis=-1)\n            x=tf.keras.layers.Flatten()(x)\n            x=Dense(768*hidden_number,activation='tanh')(x)\n        else:\n            x=tf.stack([layer[:,-1,:] for layer in pre_layers[2][-hidden_number:]],axis=-1)\n            x=tf.keras.layers.Flatten()(x)\n            x=Dense(768*hidden_number,activation='tanh')(x)\n    else:\n        if not PRE_NAME.startswith('xlnet'):\n            x=pre_layers[1]\n        else:\n            x=pre_layers[0][:,-1,:]\n        x=BatchNormalization()(x)\n        x=Dropout(0.1)(x)\n    if final_activation:\n        outs=Dense(30,activation='sigmoid')(x)\n    else:\n        outs=Dense(30)(x)\n    if not PRE_NAME.startswith('roberta'):\n        model=tf.keras.models.Model(inputs={'input_ids':ins1,'attention_mask':ins2,'token_type_ids':ins3},outputs=outs)\n    else:\n        model=tf.keras.models.Model(inputs={'input_ids':ins1,'attention_mask':ins2},outputs=outs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.057236Z","iopub.status.idle":"2021-12-02T13:42:12.057577Z","shell.execute_reply.started":"2021-12-02T13:42:12.057393Z","shell.execute_reply":"2021-12-02T13:42:12.057428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# double head model","metadata":{}},{"cell_type":"code","source":"def DOUBLE_MODEL(sequence=False,final_activation=True,hidden_states=True):\n    tf.keras.backend.clear_session()\n    if PRE_NAME.startswith('bert'):\n        ins1=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins2=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins3=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins4=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins5=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins6=Input((MAX_LENGTH,),dtype=tf.int32)\n        pre_model=TFBertModel.from_pretrained(PRE_NAME,output_hidden_states=hidden_states,return_dict=True)\n        pre_layers1=pre_model({'input_ids':ins1,'attention_mask':ins2,'token_type_ids':ins3})\n        pre_layers2=pre_model({'input_ids':ins4,'attention_mask':ins5,'token_type_ids':ins6})\n    elif PRE_NAME.startswith('xlnet'):\n        ins1=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins2=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins3=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins4=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins5=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins6=Input((MAX_LENGTH,),dtype=tf.int32)\n        pre_model=TFXLNetModel.from_pretrained(PRE_NAME,output_hidden_states=hidden_states,return_dict=True)\n        pre_layers1=pre_model({'input_ids':ins1,'attention_mask':ins2,'token_type_ids':ins3})\n        pre_layers2=pre_model({'input_ids':ins4,'attention_mask':ins5,'token_type_ids':ins6})\n    else:\n        ins1=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins2=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins3=Input((MAX_LENGTH,),dtype=tf.int32)\n        ins4=Input((MAX_LENGTH,),dtype=tf.int32)\n        pre_model=TFRobertaModel.from_pretrained(PRE_NAME,output_hidden_states=hidden_states,return_dict=True)\n        pre_layers1=pre_model({'input_ids':ins1,'attention_mask':ins2})\n        pre_layers2=pre_model({'input_ids':ins3,'attention_mask':ins4})\n    if sequence:\n        x1=Conv1D(1,1)(pre_layers1[0])\n        x1=tf.squeeze(x1,axis=-1)\n        x1=BatchNormalization()(x1)\n        x1=Dropout(0.1)(x1)\n        x1=tf.keras.layers.ReLU()(x1)\n        x2=Conv1D(1,1)(pre_layers2[0])\n        x2=tf.squeeze(x2,axis=-1)\n        x2=BatchNormalization()(x2)\n        x2=Dropout(0.1)(x2)\n        x2=tf.keras.layers.ReLU()(x2)\n        x=tf.keras.layers.Concatenate()([x1,x2])\n    elif hidden_states:\n        if not PRE_NAME.startswith('xlnet'):\n            x1=tf.stack([layer[:,0,:] for layer in pre_layers1[2]],axis=-1)\n            x1=tf.squeeze(Conv1D(1,1)(x1),axis=-1)\n            x1=BatchNormalization()(x1)\n            x1=Dropout(0.1)(x1)\n            x1=tf.keras.layers.ReLU()(x1)\n            x2=tf.stack([layer[:,0,:] for layer in pre_layers2[2]],axis=-1)\n            x2=tf.squeeze(Conv1D(1,1)(x2),axis=-1)\n            x2=BatchNormalization()(x2)\n            x2=Dropout(0.1)(x2)\n            x2=tf.keras.layers.ReLU()(x2)\n        else:\n            x1=tf.stack([layer[:,-1,:] for layer in pre_layers1[2]],axis=-1)\n            x1=tf.squeeze(Conv1D(1,1)(x1),axis=-1)\n            x1=BatchNormalization()(x1)\n            x1=Dropout(0.1)(x1)\n            x1=tf.keras.layers.ReLU()(x1)\n            x2=tf.stack([layer[:,-1,:] for layer in pre_layers2[2]],axis=-1)\n            x2=tf.squeeze(Conv1D(1,1)(x2),axis=-1)\n            x2=BatchNormalization()(x2)\n            x2=Dropout(0.1)(x2)\n            x2=tf.keras.layers.ReLU()(x2)\n        x=tf.keras.layers.Concatenate()([x1,x2])\n    else:\n        if not PRE_NAME.startswith('xlnet'):\n            x1=pre_layers1[1]\n            x1=BatchNormalization()(x1)\n            x1=Dropout(0.1)(x1)\n            x2=pre_layers2[1]\n            x2=BatchNormalization()(x2)\n            x2=Dropout(0.1)(x2)\n        else:\n            x1=pre_layers1[0][:,-1,:]\n            x1=BatchNormalization()(x1)\n            x1=Dropout(0.1)(x1)\n            x2=pre_layers2[0][:,-1,:]\n            x2=BatchNormalization()(x2)\n            x2=Dropout(0.1)(x2)\n        x=tf.keras.layers.Concatenate()([x1,x2])\n    if final_activation:\n        outs=Dense(30,activation='sigmoid')(x)\n    else:\n        outs=Dense(30)(x)\n    if not PRE_NAME.startswith('roberta'):\n        model=tf.keras.models.Model(inputs=[{'input_ids1':ins1,'attention_mask1':ins2,'token_type_ids1':ins3},\n                                            {'input_ids2':ins4,'attention_mask2':ins5,'token_type_ids2':ins6}]\n                                    ,outputs=outs)\n    else:\n        model=tf.keras.models.Model(inputs=[{'input_ids1':ins1,'attention_mask1':ins2},\n                                            {'input_ids2':ins3,'attention_mask2':ins4}]\n                                    ,outputs=outs)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.06011Z","iopub.status.idle":"2021-12-02T13:42:12.060945Z","shell.execute_reply.started":"2021-12-02T13:42:12.060733Z","shell.execute_reply":"2021-12-02T13:42:12.060757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.backend as K","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.061927Z","iopub.status.idle":"2021-12-02T13:42:12.062272Z","shell.execute_reply.started":"2021-12-02T13:42:12.062092Z","shell.execute_reply":"2021-12-02T13:42:12.062113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_loss(y_true,y_pred):\n    y_true=tf.cast(y_true,dtype=y_pred.dtype)\n    bce=K.mean(-1*((y_true*K.log(y_pred+1e-5))+((1-y_true)*K.log(1-y_pred+1e-5))),axis=-1)\n    rmsle=K.sqrt(K.mean(K.square(K.log(y_true+1)-K.log(y_pred+1))))\n    total_loss=bce+rmsle\n    return K.mean(total_loss)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.06333Z","iopub.status.idle":"2021-12-02T13:42:12.06365Z","shell.execute_reply.started":"2021-12-02T13:42:12.063481Z","shell.execute_reply":"2021-12-02T13:42:12.063502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr=3e-5\nloss='binary_crossentropy'\nname='bert_4_hiddens_type2_bce'\nbatch_size=8","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.065379Z","iopub.status.idle":"2021-12-02T13:42:12.065706Z","shell.execute_reply.started":"2021-12-02T13:42:12.065531Z","shell.execute_reply":"2021-12-02T13:42:12.065558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.067099Z","iopub.status.idle":"2021-12-02T13:42:12.067449Z","shell.execute_reply.started":"2021-12-02T13:42:12.067275Z","shell.execute_reply":"2021-12-02T13:42:12.067295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    train=df[df['kfold']!=i].drop('kfold',axis=1).reset_index(drop=True)\n    test=df[df['kfold']==i].drop('kfold',axis=1).reset_index(drop=True)\n    model_inputs,model_outputs=get_final_model_inputs(train,h1,h2,inference=False)\n    print(\"\\nsome samples of training data\\n\")\n    print(model_inputs,model_outputs)\n    valid_inputs,valid_outputs=get_final_model_inputs(test,h1,h2,inference=False)\n    print(\"\\nsome samples of testing data\\n\")\n    print(valid_inputs,valid_outputs)\n    print('\\nsummary of the model\\n')\n    model=SINGLE_MODEL(sequence=False,final_activation=True,hidden_states=True,hidden_number=4)\n    model.summary()\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n                 loss=loss)\n    early=tf.keras.callbacks.EarlyStopping(patience=3,monitor='val_loss',mode='min',verbose=1,restore_best_weights=True)\n    saver=tf.keras.callbacks.ModelCheckpoint(monitor='val_loss',mode='min',save_best_only=True,\n                                            save_weights_only=True,save_freq='epoch',filepath=f\"{name}_fold_{i}.h5\",verbose=1)\n    model.fit(model_inputs,model_outputs,epochs=20,batch_size=batch_size,\n              validation_data=(valid_inputs,valid_outputs),\n             callbacks=[early,saver])\n    print(f\"\\nloss for fold {i} we got {model.evaluate(valid_inputs,valid_outputs)}\\n\")\n    del model\n    import gc\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.068413Z","iopub.status.idle":"2021-12-02T13:42:12.068727Z","shell.execute_reply.started":"2021-12-02T13:42:12.068555Z","shell.execute_reply":"2021-12-02T13:42:12.068577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#when using single cls token as output\n# for 1st H1,H2 bert gave 0.35417 for bce loss and 0.1 dropout\n# roberta,xlnet gave around 0.35 only\n#for remaining H1,H2 score is aroung 0.34...  and less than bert score in 1st H1,H2only\n##################################################################","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.070084Z","iopub.status.idle":"2021-12-02T13:42:12.070433Z","shell.execute_reply.started":"2021-12-02T13:42:12.070262Z","shell.execute_reply":"2021-12-02T13:42:12.070283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# after running bert base. the bench mark decided is 0.36262","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.072015Z","iopub.status.idle":"2021-12-02T13:42:12.072374Z","shell.execute_reply.started":"2021-12-02T13:42:12.072171Z","shell.execute_reply":"2021-12-02T13:42:12.072191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for h1=[['question_title', 'question_body'],['question_title','answer']]\n#h2=[]\n#using 4 hidden states\n# bert,0.1,3e-5->0.35909\n# roberta,0.1,3e-5-> 0.35331\n# roberta,0.1,1e-5-> 0.35096\n# sequence\n# bert,0.1,3e-5->0.28393","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.073902Z","iopub.status.idle":"2021-12-02T13:42:12.074259Z","shell.execute_reply.started":"2021-12-02T13:42:12.074055Z","shell.execute_reply":"2021-12-02T13:42:12.074078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for h1=[['question_title', 'question_body'],['answer']]\n#h2=[]\n# using 4 hidden states\n#bert,3e-5,0.1->0.36262\n#roberta,3e-5,0.1->0.35200\n#xlnet,3e-5,0.1->0.35375","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.075331Z","iopub.status.idle":"2021-12-02T13:42:12.075917Z","shell.execute_reply.started":"2021-12-02T13:42:12.07571Z","shell.execute_reply":"2021-12-02T13:42:12.075734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#h1=[['question_title', 'question_body'],['question_body','answer']]\n#h2=[]\n#bert with 4 hidden states-> 0.33143","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.07731Z","iopub.status.idle":"2021-12-02T13:42:12.077633Z","shell.execute_reply.started":"2021-12-02T13:42:12.077464Z","shell.execute_reply":"2021-12-02T13:42:12.077485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#h1=[['question_body'],['question_title','answer']]\n#h2=[]\n#using 4 hidden states\n#bert,3e-5,0.1->0.35709","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.078729Z","iopub.status.idle":"2021-12-02T13:42:12.079067Z","shell.execute_reply.started":"2021-12-02T13:42:12.078891Z","shell.execute_reply":"2021-12-02T13:42:12.078912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#h1=[['question_title'],['question_body','answer']]\n#h2=[]\n#using 4 hidden states\n#bert,3e-5,0.1->0.33911","metadata":{"execution":{"iopub.status.busy":"2021-12-02T13:42:12.080139Z","iopub.status.idle":"2021-12-02T13:42:12.080448Z","shell.execute_reply.started":"2021-12-02T13:42:12.080296Z","shell.execute_reply":"2021-12-02T13:42:12.080312Z"},"trusted":true},"execution_count":null,"outputs":[]}]}