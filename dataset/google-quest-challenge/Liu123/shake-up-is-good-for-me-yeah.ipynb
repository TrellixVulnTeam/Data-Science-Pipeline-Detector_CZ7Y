{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from transformers import *\nimport numpy as np\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = TFBertForMaskedLM.from_pretrained('bert-base-uncased') \n\n# DEFINE SENTENCE\nstr = '[CLS] Shaking up of kaggle is [MASK] for [MASK] . [SEP]'\nindices = tokenizer.encode(str, add_special_tokens=False, return_tensors='tf')\n\n# PREDICT MISSING WORDS\npred = bert_model(indices)\nmasked_indices = np.where(indices==103)[1]\n\n# DISPLAY MISSING WORDS\npredicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\npredicted_words_list = tokenizer.decode(predicted_words).split(' ')\nstr = str.split(' ')\nstr = [i for i in str if i not in ['[CLS]', '[SEP]']]\nstr = ' '.join(str)\nprint(str.replace('[MASK]', '{}').format(predicted_words_list[0], predicted_words_list[1]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}