{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nfrom functools import partial\nfrom pathlib import Path\n\nfrom fastai.text import *\nfrom fastai.callbacks import *\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\npd.set_option('display.max_colwidth', 200)\npd.set_option('display.max_columns', None)\npd.set_option('display.min_rows', 100)\npd.set_option('display.max_rows', 100)\n\nhome = Path(\".\")\ninput_dir = Path(\"/kaggle/input/google-quest-challenge/\")\n\n!mkdir -p ~/.fastai/models/\n!cp -R ../input/fastai-wt103-models/* ~/.fastai/models/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This notebook is to show how one can fine tune the language model for transfer learning and pre-process data.\n\nThe whole workflow:\n1. Fine tune fastai wt103 lm on the competition text\n2. Train a classification model using encodings from the previous step\n\nThe language model uses public test set, which is onle 13% of the whole test set. To improve results, you want to train LM on the private test set also. In other words, include the LM fine tuning in the submission notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"BS = 256","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pd.read_csv(input_dir/\"sample_submission.csv\").head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_test = pd.read_csv(input_dir/\"test.csv\"); raw_test.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train = pd.read_csv(input_dir/\"train.csv\"); raw_train.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess"},{"metadata":{},"cell_type":"markdown","source":"Using all the text data to fine tune LM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_df = raw_train.append(raw_test, ignore_index=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_df = lm_df.iloc[np.random.permutation(len(raw_train))]\ncut = int(0.2 * len(lm_df)) + 1\ntrain_lm_df, valid_lm_df = lm_df[cut:], lm_df[:cut]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = TextLMDataBunch.from_df(home, train_lm_df, valid_lm_df,\n                                  text_cols=[\"question_title\", \"question_body\", \"answer\"],\n                                  mark_fields=True,\n                                  bs=BS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm.save('./data_lm_export.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = raw_train.columns[(raw_train.columns.str.startswith(\"question_\")) |\n                           (raw_train.columns.str.startswith(\"answer_\"))].to_list()\nlabels = list(filter(lambda x: x not in ['question_title',\n                                         'question_body',\n                                         'question_user_name',\n                                         'question_user_page',\n                                         'answer_user_name',\n                                         'answer_user_page',], labels))\nassert len(labels) == 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas = TextClasDataBunch.from_csv(home, input_dir/\"train.csv\", test=input_dir/\"test.csv\",\n                                       vocab=data_lm.train_ds.vocab, bs=BS,\n                                       text_cols=[\"question_title\", \"question_body\", \"answer\"],\n                                       mark_fields=True,\n                                       label_cols=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas.show_batch(reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas.save('./data_clas.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fine tune LM"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = load_data(home, 'data_lm_export.pkl', bs=BS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5,\n                               metrics=[accuracy, Perplexity()],\n                               callback_fns=[partial(EarlyStoppingCallback, monitor=\"perplexity\", mode=\"min\", patience=5),\n                                             partial(SaveModelCallback, monitor=\"perplexity\", mode=\"min\", name=\"best_model\")])\nlearn = learn.to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot(skip_end=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 5e-02\nmoms = (0.8, 0.7)\nwd=0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, slice(lr), moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(30, slice(lr/2), moms=moms, wd=wd,\n                    callbacks=[SaveModelCallback(learn, monitor=\"perplexity\", name=\"best_model\"),\n                               ReduceLROnPlateauCallback(learn, monitor=\"perplexity\", patience=5,\n                                                         min_delta=0.1, min_lr=1e-6)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('ft_enc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict(\"As a non-mathematician, I am somewhat\", n_words=10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}