{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nfrom functools import partial\nfrom pathlib import Path\n\nfrom fastai.text import *\nfrom fastai.callbacks import *\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# pd.set_option('display.max_colwidth', 200)\n# pd.set_option('display.max_columns', None)\n# pd.set_option('display.min_rows', 100)\n# pd.set_option('display.max_rows', 100)\n\nhome = Path(\".\")\ninput_dir = Path(\"/kaggle/input/google-quest-challenge/\")\n\n!mkdir -p ~/.fastai/models/\n!cp -R /kaggle/input/fastai-wt103-models/* ~/.fastai/models/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"This notebook is to train fastai classifier with transfer learning.\n\nSources\nhttps://www.kaggle.com/melissarajaram/roberta-fastai-huggingface-transformers"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# seed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train = pd.read_csv(input_dir/\"train.csv\")\nraw_test = pd.read_csv(input_dir/\"test.csv\")\nsubm = pd.read_csv(input_dir/\"sample_submission.csv\")\n\nq_labels = subm.columns[subm.columns.str.startswith(\"question_\")].to_list()\nassert len(q_labels) == 21\n\na_labels = subm.columns[subm.columns.str.startswith(\"answer_\")].to_list()\nassert len(a_labels) == 9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = raw_train.iloc[np.random.permutation(len(raw_train))]\ncut = int(0.2 * len(train_df)) + 1\ntrain_df, valid_df = train_df[cut:], train_df[:cut]\ntrain_lm_df = train_df.append(raw_test, ignore_index=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = TextLMDataBunch.from_df(home, train_lm_df, valid_df,\n                                  text_cols=[\"question_title\", \"question_body\", \"answer\"],\n                                  mark_fields=True,\n                                  bs=128)\n\nq_data_clas = TextClasDataBunch.from_df(home, train_df, valid_df, raw_test,\n                                      vocab=data_lm.train_ds.vocab,\n                                      text_cols=[\"question_title\", \"question_body\"],\n                                      label_cols=q_labels,\n                                      mark_fields=True,\n                                      bs=64)\n\na_data_clas = TextClasDataBunch.from_df(home, train_df, valid_df, raw_test,\n                                      vocab=data_lm.train_ds.vocab,\n                                      text_cols=[\"question_title\", \"question_body\", \"answer\"],\n                                      label_cols=a_labels,\n                                      bs=64)\n\ndata_lm.save('./data_lm_export.pkl')\nq_data_clas.save('./q_data_clas.pkl')\na_data_clas.save('./a_data_clas.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5,\n                               metrics=[accuracy, Perplexity()],\n                               callback_fns=[partial(SaveModelCallback, monitor=\"perplexity\", mode=\"min\", name=\"best_model\"),\n                                             partial(EarlyStoppingCallback, monitor=\"perplexity\", mode=\"min\", patience=10)])\nlearn = learn.to_fp16()\nlr = 5e-02\nmoms = (0.8, 0.7)\nwd=0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, slice(lr), moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(10, slice(lr/2), moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('ft_enc')\nlearn.save('lm_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del learn\ndel data_lm\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# q_data_clas.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a_data_clas.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr\n\nclass AvgSpearman(Callback):\n    def on_epoch_begin(self, **kwargs):\n        self.preds = None\n        self.target = None\n    \n    def on_batch_end(self, last_output, last_target, **kwargs):\n        if self.preds is None or self.target is None:\n            self.preds = last_output\n            self.target = last_target\n        else:\n            self.preds = np.append(self.preds, last_output, axis=0)\n            self.target = np.append(self.target, last_target, axis=0)\n    \n    def on_epoch_end(self, last_metrics, **kwargs):\n        spearsum = 0\n        for col in range(self.preds.shape[1]):\n            spearsum += spearmanr(self.preds[:,col], self.target[:,col]).correlation\n        res = spearsum / (self.preds.shape[1] + 1)\n        return add_metrics(last_metrics, res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q_learn = text_classifier_learner(q_data_clas, AWD_LSTM,\n                                metrics=[AvgSpearman()],\n                                callback_fns=[partial(EarlyStoppingCallback, monitor='avg_spearman', mode=\"max\", min_delta=0.01, patience=7),\n                                              partial(SaveModelCallback, monitor=\"avg_spearman\", mode=\"max\", name=\"best_model\"),]).to_fp16()\nq_learn.load_encoder(\"ft_enc\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 5e-02\nmoms = (0.8, 0.7)\nwd=0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(learn, name):\n    learn.fit_one_cycle(4, lr, moms=moms, wd=wd)\n    learn.freeze_to(-2)\n    learn.fit_one_cycle(2, slice(lr/2/(2.6**4),lr), moms=moms, wd=wd)\n    learn.freeze_to(-3)\n    learn.fit_one_cycle(2, slice(lr/4/(2.6**4),lr/2), moms=moms, wd=wd)\n    learn.unfreeze()\n    learn.save(f'{name}-stage3-clas')\n    learn.fit_one_cycle(20, slice(lr/20/(2.6**4),lr), moms=moms, wd=wd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(q_learn, \"q\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q_test_preds, _ = q_learn.get_preds(DatasetType.Test, ordered=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del q_learn\ndel q_data_clas\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_learn = text_classifier_learner(a_data_clas, AWD_LSTM,\n                                  metrics=[AvgSpearman()],\n                                  callback_fns=[partial(EarlyStoppingCallback, monitor='avg_spearman', mode=\"max\", min_delta=0.01, patience=5),\n                                                partial(SaveModelCallback, monitor=\"avg_spearman\", mode=\"max\", name=\"best_model\"),]).to_fp16()\na_learn.load_encoder(\"ft_enc\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(a_learn, \"a\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_test_preds, _ = a_learn.get_preds(DatasetType.Test, ordered=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.DataFrame(columns=[\"qa_id\"]+q_labels+a_labels)\nsample_submission.loc[:, \"qa_id\"] = raw_test[\"qa_id\"]\nsample_submission.loc[:, q_labels] = q_test_preds\nsample_submission.loc[:, a_labels] = a_test_preds\n# sample_submission.loc[:, 1:] = np.clip(sample_submission.loc[:, 1:], 0.00001, 0.999999)\n\nsample_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}