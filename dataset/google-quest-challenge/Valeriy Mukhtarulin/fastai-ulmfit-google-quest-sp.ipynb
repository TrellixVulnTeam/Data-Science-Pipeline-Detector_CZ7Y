{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install -q ../input/python-ninja-package/ninja-1.9.0.post1-py3-none-manylinux1_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import gc\nfrom functools import partial\nfrom pathlib import Path\n\nfrom fastai.text import *\nfrom fastai.callbacks import *\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# pd.set_option('display.max_colwidth', 200)\n# pd.set_option('display.max_columns', None)\n# pd.set_option('display.min_rows', 100)\n# pd.set_option('display.max_rows', 100)\n\nhome = Path(\".\")\ninput_dir = Path(\"/kaggle/input/google-quest-challenge/\")\n!mkdir models\n!mkdir tmp\n!cp -R ../input/fastai-en-wiki-100kk-pretrained-sp-awdlstm/* {home}/models/\n!cp -R ../input/fastai-en-wiki-100kk-data-with-sentencepiece/spm.model {home}/tmp/\n!cp -R ../input/fastai-en-wiki-100kk-data-with-sentencepiece/spm.vocab {home}/tmp/","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"Training FASTAI classifier with transfer learning - ULMFIT with SentencePiece tokenizer."},{"metadata":{},"cell_type":"markdown","source":"**Changes**\n\nV9\nAdded actual bwd files\n\nV8\nNo rounding\n\nV6\n100kk awd-lstm 0.34, 0.32 rounded fixed for submissions\n\n\n500kk wiki - around 0.\n\nV3-V4\n100kk awd-lstm 0.34, 0.32 rounded\n\nV2\n500kk wiki\n\nV1\n100kk wiki qrnn - < 0.26"},{"metadata":{},"cell_type":"markdown","source":"Worked:\n1. Backwards model\n2. SP + AWD LSTM\n\nDidn't work:\n\n1. SP 500kk tokens from en wiki\n2. Rounding labels. The metric is correlation. There's no different if a predicted number is less or more than actual as long as the whole set of predictions have the same correlation as targets.\n3. Separated for Q and A models\n4. SP + QRNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The metric used in the competition\nfrom scipy.stats import spearmanr\n\nclass AvgSpearman(Callback):\n    def on_epoch_begin(self, **kwargs):\n        self.preds = None\n        self.target = None\n    \n    def on_batch_end(self, last_output, last_target, **kwargs):\n        if self.preds is None or self.target is None:\n            self.preds = last_output.cpu()\n            self.target = last_target.cpu()\n        else:\n            self.preds = np.append(self.preds, last_output.cpu(), axis=0)\n            self.target = np.append(self.target, last_target.cpu(), axis=0)\n    \n    def on_epoch_end(self, last_metrics, **kwargs):\n        spearsum = 0\n        for col in range(self.preds.shape[1]):\n            spearsum += spearmanr(self.preds[:,col], self.target[:,col]).correlation\n        res = spearsum / (self.preds.shape[1] + 1)\n        return add_metrics(last_metrics, res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_test = pd.read_csv(input_dir/\"test.csv\"); # raw_test.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_train = pd.read_csv(input_dir/\"train.csv\"); # raw_train.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just to be sane\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = pd.read_csv(input_dir/\"sample_submission.csv\").columns[1:].to_list()\nassert len(labels) == 30\ntext_cols = [\"question_title\", \"question_body\", \"answer\"] + [\"host\", \"category\", \"question_user_name\", \"question_user_page\", \"answer_user_page\", \"answer_user_name\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = raw_train\n#.iloc[np.random.permutation(len(raw_train))]\ntrain_lm_df = raw_train.append(raw_test, ignore_index=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LM\n## Tokenize code"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_code = re.compile(r\"(\\n(?:[a-z  ][\\s\\S]*?(?: = |{|\\()[\\s\\S]+?)+?\\n)\")\ncode = re.compile(r\"(  [\\s\\S]+?\\n){2,}\",)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_lm_df.loc[train_lm_df.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"]), [\"question_body\"]] = train_lm_df[train_lm_df.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"])][\"question_body\"].apply(lambda x: m_code.sub(\" xxcodeblock \", x))\n# train_lm_df.loc[train_lm_df.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"]), [\"answer\"]] = train_lm_df[train_lm_df.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"])][\"answer\"].apply(lambda x: m_code.sub(\" xxcodeblock \", x))\n\n# train_df.loc[train_df.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"]), [\"question_body\"]] = train_df[train_df.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"])][\"question_body\"].apply(lambda x: m_code.sub(\" xxcodeblock \", x))\n# train_df.loc[train_df.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"]), [\"answer\"]] = train_df[train_df.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"])][\"answer\"].apply(lambda x: m_code.sub(\" xxcodeblock \", x))\n\n# raw_test.loc[raw_test.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"]), [\"question_body\"]] = raw_test[raw_test.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"])][\"question_body\"].apply(lambda x: m_code.sub(\" xxcodeblock \", x))\n# raw_test.loc[raw_test.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"]), [\"answer\"]] = raw_test[raw_test.category.isin([\"STACKOVERFLOW\", \"TECHNOLOGY\"])][\"answer\"].apply(lambda x: m_code.sub(\" xxcodeblock \", x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BS = 512 + 128\n# BS = 512 + 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data for the language models\nprocessor = SPProcessor(mark_fields=True,\n                        max_vocab_sz=15_000,\n                        sp_model=home/\"tmp/spm.model\",\n                        sp_vocab=home/\"tmp/spm.vocab\")\n\nlm_label_list = (TextList.from_df(train_lm_df, \".\", text_cols, processor=processor)\n                 .split_by_rand_pct(0.1, seed=42)\n                 .label_for_lm())\n\ndata_lm = lm_label_list.databunch(bs=BS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data for classifiers\n# vocab = data_lm.vocab\nBSC = 120\n\nclas_label_list = (TextList.from_df(train_df, \".\", text_cols, processor=processor)\n                   .split_by_rand_pct(0.2, seed=42)\n                   .label_from_df(cols=labels)\n                   .add_test(TextList.from_df(raw_test, \".\", text_cols, processor=processor)))\n\ndata_clas = clas_label_list.databunch(bs=BSC)\ndata_clas_bwd = clas_label_list.databunch(bs=BSC, backwards=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine tune LM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-02\nlr *= BS/48\nmoms = (0.8, 0.7)\nwd=0.1\ndrop_mult = 0.5\nconfig = awd_lstm_lm_config.copy()\n\n\n# config['qrnn'] = True\n# config['n_hid'] = 1550 #default 1152\n# config['n_layers'] = 4 #default 3\n# wd=0.01\n# drop_mult = 0.3\n\ndef fit_lm(data, pretrained_fnames, epochs=8, head_epochs=5, prefix=\"fwd\"):\n    learn = language_model_learner(data, AWD_LSTM, config, drop_mult=drop_mult,\n                                   pretrained_fnames=pretrained_fnames,\n                                   metrics=[Perplexity()],\n                               )\n    learn = learn.to_fp16()\n    learn.fit_one_cycle(head_epochs, slice(lr), moms=moms, wd=wd)\n    learn.unfreeze()\n    learn.save(f\"{prefix}_lm_learn_1\")\n    learn = learn.load(f\"{prefix}_lm_learn_1\")\n    learn.fit_one_cycle(epochs, slice(lr/100, lr/2), moms=moms, wd=wd,\n#                         callbacks=[SaveModelCallback(learn, monitor=\"perplexity\", mode=\"min\", name=\"best_model\"),]\n                        )\n    learn.save_encoder(f\"{prefix}_enc\")\n    learn.save(f\"{prefix}_lm_model\")\n    return learn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn = language_model_learner(data_lm, AWD_LSTM, config, drop_mult=1.0,\n#                                pretrained_fnames=pretrained_fnames,\n#                                metrics=[accuracy, Perplexity()],\n#                                )\n# learn.lr_find()\n# learn.recorder.plot(skip_end=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1/0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.purge();\n# gc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = fit_lm(data_lm, [\"learn_en_wiki_15000\", \"learn_en_wiki_15_vocab\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.purge()\nlearn.destroy()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = lm_label_list.databunch(bs=BS, backwards=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = fit_lm(data_lm, [\"learn_en_wiki_15000_bwd\", \"learn_en_wiki_15_vocab\"], prefix=\"bwd\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.purge()\nlearn.destroy()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 5e-02\nlr *= BSC/48  # Scale learning rate by batch size\nmoms = (0.8, 0.7)\nwd=0.1\nconfig = awd_lstm_clas_config.copy()\n\n# config['qrnn'] = True\n# config['n_hid'] = 1550 #default 1152\n# config['n_layers'] = 4 #default 3\n# drop_mult = 0.5\n\ndef fit(data, prefix=\"fwd\", epochs=[2, 2, 2, 15]):\n    learn = text_classifier_learner(data, AWD_LSTM,\n                                    config=config,\n                                    pretrained=False,\n                                    metrics=[AvgSpearman()],\n                                    ).to_fp16()\n    learn.load_encoder(f\"{prefix}_enc\");\n    learn.fit_one_cycle(epochs[0], lr, moms=moms, wd=wd)\n\n    learn.freeze_to(-2)\n    learn.save(\"learn\")\n    learn = learn.load(\"learn\")\n    learn.fit_one_cycle(epochs[1], slice(lr/(2.6**4),lr), moms=moms, wd=wd)\n\n    learn.freeze_to(-3)\n    learn.save(\"learn\")\n    learn = learn.load(\"learn\")\n    learn.fit_one_cycle(epochs[2], slice(lr/2/(2.6**4),lr/2), moms=moms, wd=wd)\n\n    learn.unfreeze()\n    learn.save(f\"{prefix}_learn\")\n    learn = learn.load(f\"{prefix}_learn\")\n    learn.fit_one_cycle(epochs[3], slice(lr/10/(2.6**4),lr/10), moms=moms, wd=wd,\n                        callbacks=[SaveModelCallback(learn, monitor=\"avg_spearman\", mode=\"max\", name=\"best_model\")]\n                        )\n    return learn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn = text_classifier_learner(data_clas, AWD_LSTM,\n#                                 config=config,\n#                                 pretrained=False,\n#                                 metrics=[AvgSpearman()],\n#                                 ).to_fp16()\n# learn.lr_find()\n# learn.recorder.plot(skip_end=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = fit(data_clas, \"fwd\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds, _ = learn.get_preds(DatasetType.Test, ordered=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1/0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.purge()\nlearn.destroy()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = fit(data=data_clas_bwd, prefix=\"bwd\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn = text_classifier_learner(data_clas_bwd, AWD_LSTM,\n#                                 pretrained=False,\n#                                 metrics=[AvgSpearman()],\n#                                 ).to_fp16()\n# learn.load_encoder(f\"bwd_enc\");\n# learn.unfreeze()\n# learn.fit_one_cycle(1, slice(lr/10/(2.6**4),lr/10), moms=moms, wd=wd,\n#                     callbacks=[SaveModelCallback(learn, monitor=\"avg_spearman\", mode=\"max\", name=\"best_model\")]\n#                     )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.DataFrame(columns=[\"qa_id\"] + labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spearm(preds, target):\n    spearsum = 0\n    for col in range(preds.shape[1]):\n        spearsum += spearmanr(preds[:,col], target[:,col]).correlation\n    return spearsum / (preds.shape[1] + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds, target = learn.get_preds(DatasetType.Valid, ordered=True)\n# preds_b, _ = learn_bwd.get_preds(DatasetType.Valid, ordered=True)\n# spearm((preds+preds_b)/2, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds_bwd, _ = learn.get_preds(DatasetType.Test, ordered=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_avg = (test_preds+test_preds_bwd)/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.loc[:, \"qa_id\"] = raw_test[\"qa_id\"]\n# sample_submission.loc[:, labels] = test_preds\nsample_submission.loc[:, labels] = preds_avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.loc[:, labels] = np.clip(sample_submission.loc[:, labels], 0.000001, 0.999999)\nsample_submission.to_csv(\"submission.csv\", index=False, float_format='%.20f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_submission.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}