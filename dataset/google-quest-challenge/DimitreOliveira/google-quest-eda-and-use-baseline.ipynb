{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center> Google QUEST - EDA and USE Baseline </center></h1>\n<h2><center> Improving automated understanding of complex question answer content </center></h2>\n<img src=\"https://storage.googleapis.com/kaggle-media/competitions/google-research/human_computable_dimensions_1.png\" width=\"800\">\n\n#### From the competition overview:\n>In this competition, youâ€™re challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering. The question-answer pairs were gathered from nearly 70 different websites, in a \"common-sense\" fashion. Our raters received minimal guidance and training, and relied largely on their subjective interpretation of the prompts. As such, each prompt was crafted in the most intuitive fashion so that raters could simply use their common-sense to complete the task. By lessening our dependency on complicated and opaque rating guidelines, we hope to increase the re-use value of this data set. What you see is what you get!\n\n>Demonstrating these subjective labels can be predicted reliably can shine a new light on this research area. Results from this competition will inform the way future intelligent Q&A systems will get built, hopefully contributing to them becoming more human-like.\n\n##### Link for the dataset with the USE models: https://www.kaggle.com/dimitreoliveira/universalsentenceencodermodels"},{"metadata":{},"cell_type":"markdown","source":"## Dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import gc\nimport random\nimport warnings\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom nltk import FreqDist\nfrom nltk.corpus import stopwords\nfrom ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import Model, optimizers\nfrom tensorflow.keras.layers import Lambda, Input, Dense, Dropout, Concatenate, BatchNormalization, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom googleqa_utilityscript import *\n\nSEED = 0\nseed_everything(SEED)\nwarnings.filterwarnings(\"ignore\")\nsns.set(font_scale=1.5)\nplt.rcParams.update({'font.size': 16})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')\ntest = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n\ntrain['set'] = 'train'\ntest['set'] = 'test'\ncomplete_set = train.append(test)\n\nprint('Train samples: %s' % len(train))\nprint('Test samples: %s' % len(test))\ndisplay(train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\n#### Each sample main features are the question and it's answer\n#### First let's take a look at one pair of question/answer:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"samp_id = 9\nprint('Question Title: %s \\n' % train['question_title'].values[samp_id])\nprint('Question Body: %s \\n' % train['question_body'].values[samp_id])\nprint('Answer: %s' % train['answer'].values[samp_id])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Each question/answer are given some ratings, those ratings are the competition labels, let's see this sample labels"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"question_target_cols = ['question_asker_intent_understanding','question_body_critical', 'question_conversational', \n                        'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n                        'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', \n                        'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n                        'question_type_compare', 'question_type_consequence', 'question_type_definition', \n                        'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n                        'question_type_reason_explanation', 'question_type_spelling', 'question_well_written']\nanswer_target_cols = ['answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n                      'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', \n                      'answer_type_reason_explanation', 'answer_well_written']\ntarget_cols = question_target_cols + answer_target_cols\n\nprint('Question labels')\ndisplay(train.iloc[[samp_id]][question_target_cols])\nprint('Answer labels')\ndisplay(train.iloc[[samp_id]][answer_target_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### How are distributed between sets users that ask questions?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_users = set(train['question_user_page'].unique())\ntest_users = set(test['question_user_page'].unique())\n\nprint('Unique users in train set: %s' % len(train_users))\nprint('Unique users in test set: %s' % len(test_users))\nprint('Users in both sets: %s' % len(train_users & test_users))\nprint('What users are in both sets? %s' % list(train_users & test_users))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### How are distributed between sets users that answer questions?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_users = set(train['answer_user_page'].unique())\ntest_users = set(test['answer_user_page'].unique())\n\nprint('Unique users in train set: %s' % len(train_users))\nprint('Unique users in test set: %s' % len(test_users))\nprint('Users in both sets: %s' % len(train_users & test_users))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Could be interesting to see the ranks of users that ask and answer more questions\n#### Question user ranking"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"question_gp = complete_set[['qa_id', 'question_user_name', 'question_user_page']].groupby(['question_user_name', 'question_user_page'], as_index=False).count()\nquestion_gp.columns = ['question_user_name', 'question_user_page', 'count']\ndisplay(question_gp.sort_values('count', ascending=False).head())\n\ntrain_question_gp = train[['qa_id', 'question_user_page']].groupby('question_user_page', as_index=False).count()\ntest_question_gp = test[['qa_id', 'question_user_page']].groupby('question_user_page', as_index=False).count()\ntrain_question_gp.columns = ['question_user_page', 'Question count']\ntest_question_gp.columns = ['question_user_page', 'Question count']\n\nsns.set(style=\"darkgrid\")\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\nsns.countplot(x=\"Question count\", data=train_question_gp, palette=\"Set3\", ax=ax1).set_title(\"Train\")\nsns.countplot(x=\"Question count\", data=test_question_gp, palette=\"Set3\", ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Answer user ranking"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"answer_gp = complete_set[['qa_id', 'answer_user_name', 'answer_user_page']].groupby(['answer_user_name', 'answer_user_page'], as_index=False).count()\nanswer_gp.columns = ['answer_user_name', 'answer_user_page', 'count']\ndisplay(answer_gp.sort_values('count', ascending=False).head())\n\ntrain_answer_gp = train[['qa_id', 'answer_user_page']].groupby('answer_user_page', as_index=False).count()\ntest_answer_gp = test[['qa_id', 'answer_user_page']].groupby('answer_user_page', as_index=False).count()\ntrain_answer_gp.columns = ['answer_user_page', 'Answer count']\ntest_answer_gp.columns = ['answer_user_page', 'Answer count']\n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\nsns.countplot(x=\"Answer count\", data=train_answer_gp, palette=\"Set3\", ax=ax1).set_title(\"Train\")\nsns.countplot(x=\"Answer count\", data=test_answer_gp, palette=\"Set3\", ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's do the same for the question titles"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"question_title_gp = complete_set[['qa_id', 'question_title']].groupby('question_title', as_index=False).count()\nquestion_title_gp.columns = ['question_title', 'count']\ndisplay(question_title_gp.sort_values('count', ascending=False).head())\n\ntrain_question_title_gp = train[['qa_id', 'question_title']].groupby('question_title', as_index=False).count()\ntest_question_title_gp = test[['qa_id', 'question_title']].groupby('question_title', as_index=False).count()\ntrain_question_title_gp.columns = ['question_title', 'Question title count']\ntest_question_title_gp.columns = ['question_title', 'Question title count']\n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\nsns.countplot(x=\"Question title count\", data=train_question_title_gp, palette=\"Set3\", ax=ax1).set_title(\"Train\")\nsns.countplot(x=\"Question title count\", data=test_question_title_gp, palette=\"Set3\", ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now for the question bodies"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"question_body_gp = complete_set[['qa_id', 'question_body']].groupby('question_body', as_index=False).count()\nquestion_body_gp.columns = ['question_body', 'count']\ndisplay(question_body_gp.sort_values('count', ascending=False).head())\n\ntrain_question_body_gp = train[['qa_id', 'question_body']].groupby('question_body', as_index=False).count()\ntest_question_body_gp = test[['qa_id', 'question_body']].groupby('question_body', as_index=False).count()\ntrain_question_body_gp.columns = ['question_body', 'Question body count']\ntest_question_body_gp.columns = ['question_body', 'Question body count']\n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\nsns.countplot(x=\"Question body count\", data=train_question_body_gp, palette=\"Set3\", ax=ax1).set_title(\"Train\")\nsns.countplot(x=\"Question body count\", data=test_question_body_gp, palette=\"Set3\", ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### For the answers there are no duplicates\n\n## Now we will take a look at some statistics of the text data\n\n### Question title length and word count"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"complete_set['question_title_len'] = complete_set['question_title'].apply(lambda x : len(x))\ncomplete_set['question_body_len'] = complete_set['question_body'].apply(lambda x : len(x))\ncomplete_set['answer_len'] = complete_set['answer'].apply(lambda x : len(x))\ncomplete_set['question_title_wordCnt'] = complete_set['question_title'].apply(lambda x : len(x.split(' ')))\ncomplete_set['question_body_wordCnt'] = complete_set['question_body'].apply(lambda x : len(x.split(' ')))\ncomplete_set['answer_wordCnt'] = complete_set['answer'].apply(lambda x : len(x.split(' ')))\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 7), sharex=True)\nsns.distplot(complete_set[complete_set['set'] == 'train']['question_title_len'], ax=ax1).set_title(\"Train\")\nsns.distplot(complete_set[complete_set['set'] == 'test']['question_title_len'], ax=ax2).set_title(\"Test\")\nplt.show()\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 7), sharex=True)\nsns.distplot(complete_set[complete_set['set'] == 'train']['question_title_wordCnt'], ax=ax1).set_title(\"Train\")\nsns.distplot(complete_set[complete_set['set'] == 'test']['question_title_wordCnt'], ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Question body length and word count"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 7), sharex=True)\nsns.distplot(complete_set[complete_set['set'] == 'train']['question_body_len'], ax=ax1).set_title(\"Train\")\nsns.distplot(complete_set[complete_set['set'] == 'test']['question_body_len'], ax=ax2).set_title(\"Test\")\nplt.show()\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 7), sharex=True)\nsns.distplot(complete_set[complete_set['set'] == 'train']['question_body_wordCnt'], ax=ax1).set_title(\"Train\")\nsns.distplot(complete_set[complete_set['set'] == 'test']['question_body_wordCnt'], ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Answer length and word count"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 7), sharex=True)\nsns.distplot(complete_set[complete_set['set'] == 'train']['answer_len'], ax=ax1).set_title(\"Train\")\nsns.distplot(complete_set[complete_set['set'] == 'test']['answer_len'], ax=ax2).set_title(\"Test\")\nplt.show()\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 7), sharex=True)\nsns.distplot(complete_set[complete_set['set'] == 'train']['answer_wordCnt'], ax=ax1).set_title(\"Train\")\nsns.distplot(complete_set[complete_set['set'] == 'test']['answer_wordCnt'], ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We also have a \"category\" column that is related to the question/answer\n- It seems that at least the \"Technology\" and \"SCIENCE\" categories have a very diferent distribution among sets"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 7), sharex=True)\nsns.countplot(complete_set[complete_set['set'] == 'train']['category'], ax=ax1).set_title(\"Train\")\nsns.countplot(complete_set[complete_set['set'] == 'test']['category'], ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The \"host\" column is related to where the questions and answers where published"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"complete_set['host_first'] = complete_set['host'].apply(lambda x : x.split('.')[0])\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 12), sharex=True)\nsns.countplot(y=complete_set[complete_set['set'] == 'train']['host_first'], ax=ax1, palette=\"muted\").set_title(\"Train\")\nsns.countplot(y=complete_set[complete_set['set'] == 'test']['host_first'], ax=ax2, palette=\"muted\").set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lastly let's look at the labels distribution\n### Question related labels"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f = plt.subplots(figsize=(24, 7))\nfor col in question_target_cols[:5]:\n    sns.distplot(train[col], label=col, rug=True, hist=False)\nplt.show()\n\nf = plt.subplots(figsize=(24, 7))\nfor col in question_target_cols[5:10]:\n    sns.distplot(train[col], label=col, rug=True, hist=False)\nplt.show()\n\nf = plt.subplots(figsize=(24, 7))\nfor col in question_target_cols[10:15]:\n    sns.distplot(train[col], label=col, rug=True, hist=False)\nplt.show()\n\nf = plt.subplots(figsize=(24, 7))\nfor col in question_target_cols[15:]:\n    sns.distplot(train[col], label=col, rug=True, hist=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Answer related labels"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f = plt.subplots(figsize=(24, 7))\nfor col in answer_target_cols[:5]:\n    sns.distplot(train[col], label=col, rug=True, hist=False)\nplt.show()\n\nf = plt.subplots(figsize=(24, 7))\nfor col in answer_target_cols[5:]:\n    sns.distplot(train[col], label=col, rug=True, hist=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"eng_stopwords = stopwords.words('english')\n\ncomplete_set['question_title'] = complete_set['question_title'].str.replace('[^a-z ]','')\ncomplete_set['question_body'] = complete_set['question_body'].str.replace('[^a-z ]','')\ncomplete_set['answer'] = complete_set['answer'].str.replace('[^a-z ]','')\ncomplete_set['question_title'] = complete_set['question_title'].apply(lambda x: x.lower())\ncomplete_set['question_body'] = complete_set['question_body'].apply(lambda x: x.lower())\ncomplete_set['answer'] = complete_set['answer'].apply(lambda x: x.lower())\n\nfreq_dist = FreqDist([word for comment in complete_set['question_title'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on question title').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()\n\nfreq_dist = FreqDist([word for comment in complete_set['question_body'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on question body').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()\n\nfreq_dist = FreqDist([word for comment in complete_set['answer'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on answer').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model parameters"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"EPOCHS = 12\nBATCH_SIZE = 32\nLEARNING_RATE = 3e-4\nEMBEDDDING_SIZE = 512\nN_CLASS = len(target_cols)\nES_PATIENCE = 3\nRLROP_PATIENCE = 2\nDECAY_DROP = 0.3\nmodule_url = \"../input/universalsentenceencodermodels/universal-sentence-encoder-models/use-qa\"\n\nes = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\nrlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model\n## For the model we will use Universal Sentence Encoder (USE for short)\n#### From the [Tensorflow hub page](https://tfhub.dev/google/universal-sentence-encoder/4):\n>The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.\n\n>The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. The universal-sentence-encoder-large model is trained with a Transformer encoder.\n\n##### Link for the dataset with the USE models: https://www.kaggle.com/dimitreoliveira/universalsentenceencodermodels"},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"use_embed = hub.load(module_url)\n\ndef USEEmbedding(x):\n    return use_embed(tf.squeeze(tf.cast(x, tf.string)))\n\ndef model_fn():\n    input_title = Input(shape=(1,), dtype=tf.string, name='input_title')\n    embedding_title = Lambda(USEEmbedding, output_shape=(EMBEDDDING_SIZE,))(input_title)\n\n    input_body = Input(shape=(1,), dtype=tf.string, name='input_body')\n    embedding_body = Lambda(USEEmbedding, output_shape=(EMBEDDDING_SIZE,))(input_body)\n\n    input_answer = Input(shape=(1,), dtype=tf.string, name='input_answer')\n    embedding_answer = Lambda(USEEmbedding, output_shape=(EMBEDDDING_SIZE,))(input_answer)\n\n    x = Concatenate()([embedding_title, embedding_body, embedding_answer])\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(N_CLASS, activation='sigmoid', name='output')(x)\n    model = Model(inputs=[input_title, input_body, input_answer], outputs=[output])\n\n    optimizer = optimizers.Adam(LEARNING_RATE)\n    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train model (3-Fold)\n- I got the CV split and the evaluation from @ratthachat [awsome kernel](https://www.kaggle.com/ratthachat/quest-cv-analysis-on-different-splitting-methods), there is an explanation about why use this CV scheme checkout. "},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"feature_cols = ['question_title', 'question_body', 'answer']\nY_train = train[target_cols]\n\nNUM_FOLDS = 3\ntrain_rho_kfolds = []\nvalid_rho_kfolds = []\nmodel_path_list = []\nkf = MultilabelStratifiedKFold(n_splits=NUM_FOLDS, random_state=SEED)\n\nfor ind, (tr, val) in enumerate(kf.split(train[feature_cols], Y_train)):\n    print('FOLD', ind+1)\n    X_tr = train[feature_cols].loc[tr]\n    y_tr = Y_train.loc[tr].values\n    X_vl = train[feature_cols].loc[val]\n    y_vl = Y_train.loc[val].values\n\n    X_tr = [X_tr[col] for col in feature_cols]\n    X_vl = [X_vl[col] for col in feature_cols]\n    \n    \n    model = model_fn()\n    spearmanCallback = SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl))\n    callback_list = [es, rlrop, spearmanCallback]\n    history = model.fit(X_tr, y_tr, \n                        validation_data=(X_vl, y_vl), \n                        batch_size=BATCH_SIZE, \n                        callbacks=callback_list, \n                        epochs=EPOCHS, \n                        verbose=2).history\n    \n    preds_train = model.predict(X_tr)\n    preds_val = model.predict(X_vl)\n\n    rho_train = [spearmanr(y_tr[:, ind], preds_train[:, ind] + np.random.normal(0, 1e-7, preds_train.shape[0])).correlation for ind in range(preds_train.shape[1])]\n    rho_val = [spearmanr(y_vl[:, ind], preds_val[:, ind] + np.random.normal(0, 1e-7, preds_val.shape[0])).correlation for ind in range(preds_val.shape[1])]\n\n    train_rho_kfolds.append(rho_train)\n    valid_rho_kfolds.append(rho_val)\n    print('Train spearman-rho: %.3f' % np.mean(rho_train))\n    print('Validation spearman-rho: %.3f' % np.mean(rho_val))\n    \n    model_path = '../working/use_baseline_fold_%d.h5' % (ind+1)\n    model.save_weights(model_path)\n    model_path_list.append(model_path)\n    print('Saved model at: %s' % model_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model loss graph (the last one) "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.set(style=\"whitegrid\")\nfor key in spearmanCallback.history.keys():\n    history[key] = spearmanCallback.history[key]\n\nplot_metrics(history, metric_list=['loss', 'spearman'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Train')\nprint('Averaged spearman-rho: %.3f' % np.mean(train_rho_kfolds))\nprint('Averaged spearman-rho (nanmean): %.3f' % np.nanmean(train_rho_kfolds))\nprint('Averaged spearman-rho avg(regular and nanmean): %.3f +/- %.3f'% (np.mean(train_rho_kfolds), np.std(np.mean(train_rho_kfolds))))\nprint('\\nValidation')\nprint('Averaged spearman-rho: %.3f' % np.mean(valid_rho_kfolds))\nprint('Averaged spearman-rho (nanmean): %.3f' % np.nanmean(valid_rho_kfolds))\nprint('Averaged spearman-rho avg(regular and nanmean): %.3f +/- %.3f'% (np.mean(valid_rho_kfolds), np.std(np.mean(valid_rho_kfolds))))\n\nprint('\\nEach label :')\nspearman_avg_per_label = np.mean(valid_rho_kfolds, axis=0)\nspearman_std_per_label = np.std(valid_rho_kfolds, axis=0)\nfor ii in range(len(target_cols)):\n    print('%d - %.3f +/- %.3f - %s' % (ii+1,spearman_avg_per_label[ii],spearman_std_per_label[ii],\n                                       target_cols[ii] ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make predictions on test"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test features\nX_test_title = test['question_title']\nX_test_body = test['question_body']\nX_test_answer = test['answer']\n\nX_test = [X_test_title, X_test_body, X_test_answer]\nY_test = np.zeros((len(test), len(target_cols)))\n\nfor model_path in model_path_list:\n    model = model_fn()\n    model.load_weights(model_path)\n    Y_test += model.predict(X_test) / NUM_FOLDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\nsubmission[target_cols] = Y_test\nsubmission.to_csv(\"submission.csv\", index=False)\ndisplay(submission.head())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}