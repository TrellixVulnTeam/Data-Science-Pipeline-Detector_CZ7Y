{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Solution by XY\n\n## All in One\nI used this notebook for both training and prediction.\n\n## Model\nMy model is ensemble of the following 7 bert-based models.\n\n- 0206S0A1-squadBL CV413\n- 0206S0A1E0 CV412 \n- 0207S11A1E1 CV417\n- 0206S3A1E0 CV402\n- 0129SNA0 CV0403\n- 0127aS0A1 CV0425\n- 0129S11A1-squad2BL CV416\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_spell_host_clip = True\nconf_special_user_page = True\n\n\nconf_extra_clip = False\n\nconf_frac=1\n\n\nconf_train = False\nconf_save  = True # when train==False then False automaticaly\n\nconf_save_dir = f'pth-0206S3A1E0'\nconf_pretrain_dir = f'pth-0206S3A1E0'\n\nconf_headerN = 2\nconf_lr=3e-5\nconf_max_epoch=15\nconf_plot_result=True\nconf_batch_size=8//conf_headerN\nconf_num_fold=2\nconf_cat_emb_dim = 3\nconf_save=False if not conf_train else conf_save\nconf_max_roll = 11 # max 11 since we have max 12 same question","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%%capture\n!pip install ../input/sacremoses/sacremoses-master/\n!pip install ../input/transformers/transformers-2.2.2/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os,gc,random,glob \nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom scipy.stats import spearmanr\n\ndef _mkdir(directory):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n        \nDATA_DIR = '../input/google-quest-challenge'\nTRANSFORMERS_DIR='../input/bert-data'\nTRANSFORMERS2_DIR='../input/albert'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(f'{DATA_DIR}/train.csv')\ndf_test  = pd.read_csv(f'{DATA_DIR}/test.csv')\noutput_categories=df_train.columns[11:]\nqcols=df_train.columns[11:32]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# QuestDataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom transformers import *\nfrom math import floor, ceil\nfrom sklearn.model_selection import GroupKFold\n\nconf_CATEGORIES=['LIFE_ARTS', 'CULTURE', 'SCIENCE', 'STACKOVERFLOW', 'TECHNOLOGY']\nconf_CHAR=['why']\n\ndef df_average(_dfs):\n\n    ret_df = _dfs[0].copy()\n    ret = np.zeros((_dfs[0].shape[0],_dfs[0].shape[1],len(_dfs)))\n    for _i in range(len(_dfs)): \n        ret[:,:,_i] = _dfs[_i].values\n        \n    ret_df.iloc[:,:] = np.nanmean(ret,axis=-1)\n    \n    return ret_df\n\ndef compute_spearmanr(trues, preds,returnArray=False):\n    rhos = []\n    for col_trues, col_pred in zip(trues.T, preds.T):\n        col_pred=np.around(col_pred, decimals=2)\n        rho=spearmanr(col_trues, col_pred).correlation\n        if np.isfinite(rho) | returnArray: \n            rhos.append(rho)\n    return rhos if returnArray else np.mean(rhos)\n\ndef rollQuestion(_df):\n    if len(_df)>1: # Augment Same Questions \n        ret_df = (pd.concat([_df for _ in range(min(conf_max_roll+1,len(_df)))])).reset_index(drop=True)\n        ret_df[qcols] =pd.DataFrame({ col:np.concatenate([np.roll(_df[col],_i) for _i in range(min(conf_max_roll+1,len(_df))) ]) for col in qcols}).reset_index(drop=True)\n    else:\n        ret_df=_df.reset_index(drop=True)\n    return ret_df\n\ndef seed_everything(seed: int):\n    random.seed(seed);os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed);torch.manual_seed(seed);torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \ndef masked_mean(_x,_m,_dim=1):\n    return torch.sum(_x*_m,_dim)/torch.sum(_m,_dim)\n    \nseed_everything(42)\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\nMAX_LEN = 512;A_MAX_LEN=239;Q_MAX_LEN=239\nSEP_TOKEN_ID = 102  # by checking self.tokenizer.convert_tokens_to_ids('[SEP]')ã€€\n\nclass QuestDataset(torch.utils.data.Dataset):\n    def __init__(self, df, header_n, train_mode=True, labeled=True):\n        self.df = df\n        self.header_n = header_n\n        self.train_mode = train_mode\n        self.labeled = labeled\n        self.tokenizer = BertTokenizer.from_pretrained(f'{TRANSFORMERS_DIR}/bert-base-uncased')\n        \n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        aux = self.get_aux(row)\n        token_ids, seg_ids = self.get_token_ids(row)\n        if self.labeled:\n            labels = self.get_label(row)\n            return token_ids, seg_ids, aux,labels\n        else:\n            return token_ids, seg_ids, aux\n\n    def __len__(self):\n        return len(self.df)\n\n    def trim_input(self, title, question, answer, max_sequence_length=MAX_LEN, \n                t_max_len=30, q_max_len=239, a_max_len=239):\n        \n        ret_t=[];ret_q=[];ret_a=[]\n        t = self.tokenizer.tokenize(title)\n        q = self.tokenizer.tokenize(question)\n        a = self.tokenizer.tokenize(answer)\n        t_len = len(t);q_len = len(q);a_len = len(a)\n\n        if (t_len+q_len+a_len+4) > max_sequence_length:\n            if t_max_len > t_len:\n                t_new_len = t_len\n                a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n                q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n            else:\n                t_new_len = t_max_len\n            if a_max_len > a_len:\n                a_new_len = a_len \n                q_new_len = q_max_len + (a_max_len - a_len)\n            elif q_max_len > q_len:\n                a_new_len = a_max_len + (q_max_len - q_len)\n                q_new_len = q_len\n            else:\n                a_new_len = a_max_len\n                q_new_len = q_max_len\n            if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n                raise ValueError(\"New sequence length should be %d, but is %d\"% (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n\n            for idx in range(self.header_n):\n                \n                ret_t.append(t[:t_new_len])\n                if idx%2 == 0:\n                    ret_q.append(list(np.roll(q, -(idx//2)*q_new_len))[:q_new_len])\n                    ret_a.append(list(np.roll(a, -(idx//2)*a_new_len))[:a_new_len])\n                else:\n                    ret_q.append(list(np.roll(q, -(idx//2)*q_new_len))[-q_new_len:])\n                    ret_a.append(list(np.roll(a, -(idx//2)*a_new_len))[-a_new_len:])\n        else:\n           \n            ret_t=[t]*self.header_n ; ret_q=[q]*self.header_n ; ret_a=[a]*self.header_n\n                    \n        return ret_t, ret_q, ret_a\n        \n    def get_token_ids(self, row):\n        \n        t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer)\n        tokens=[];token_ids=[];ids=[];seg_ids=[]\n        for idx in range(self.header_n):\n        \n            tokens.append(['[CLS]'] + t_tokens[idx] + ['[SEP]'] + q_tokens[idx] + ['[SEP]'] + a_tokens[idx] + ['[SEP]'])\n                          \n            token_ids.append( self.tokenizer.convert_tokens_to_ids(tokens[idx]) )\n            \n            if len(token_ids[idx]) < MAX_LEN:\n                token_ids[idx] += [0] * (MAX_LEN - len(token_ids[idx]))\n            ids.append(torch.tensor(token_ids[idx]))\n            seg_ids.append(self.get_seg_ids(ids[idx]))\n            \n        return torch.stack(ids),torch.stack(seg_ids)\n    \n    def get_seg_ids(self, ids):\n        seg_ids = torch.zeros_like(ids)\n        seg_idx = 0\n        first_sep = True\n        for i, e in enumerate(ids):\n            seg_ids[i] = seg_idx\n            if e == SEP_TOKEN_ID:\n                if first_sep:\n                    first_sep = False\n                else:\n                    seg_idx = 1\n        pad_idx = torch.nonzero(ids == 0)\n        seg_ids[pad_idx] = 0\n\n        return seg_ids\n\n    def get_label(self, row):\n        return torch.tensor(row[output_categories].values.astype(np.float32))\n     \n    def get_aux(self, row):\n        return torch.tensor(row['aux'].astype(np.float32))\n\n    def collate_fn(self, batch):\n        token_ids = torch.stack([x[0] for x in batch])\n        seg_ids = torch.stack([x[1] for x in batch])\n        aux   = torch.stack([x[2] for x in batch])\n        if self.labeled:\n            labels = torch.stack([x[3] for x in batch])\n            return token_ids, seg_ids, aux, labels\n        else:\n            return token_ids, seg_ids, aux\n\ndef get_tst_loader(df,header_n,batch_size=conf_batch_size):\n    ds_test = QuestDataset(df,header_n, train_mode=False, labeled=False)\n    loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=ds_test.collate_fn, drop_last=False)\n    loader.num = len(df)\n    \n    return loader\n        \ndef get_trn_loader(df,header_n,batch_size=conf_batch_size,shuffle=True, drop_last=True):\n    ds_train = QuestDataset(df,header_n)\n    loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=shuffle, num_workers=4, collate_fn=ds_train.collate_fn, drop_last=drop_last)\n    loader.num = len(df)\n    \n    return loader\n\ndef get_val_loader(df,header_n,batch_size=conf_batch_size):\n    ds_val = QuestDataset(df,header_n, train_mode=False)\n    loader = torch.utils.data.DataLoader(ds_val, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=ds_val.collate_fn, drop_last=False)\n    loader.num = len(df)\n    loader.df = df\n    \n    return loader","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encode Labels "},{"metadata":{"trusted":true},"cell_type":"code","source":"uniqueLabels={}\nfor col in output_categories:\n    uniqueLabels[col] = df_train[col].unique()\n    uniqueLabels[col].sort()    \n    uniqueLabels[col] = uniqueLabels[col][1:]\n    \ndef encodeLabels(_labels,igCols=[],returnOrig=False):\n    \n    _nrow = _labels.shape[0]\n    \n    ret=[]\n    \n    for col in [ _c for _c in output_categories if _c not in igCols]:\n            \n        col_idx = list(output_categories).index(col)\n            \n        ret.append( np.expand_dims(_labels[:,col_idx],1)>=np.tile(uniqueLabels[col],(_nrow,1)) )\n    \n    _binaries = np.hstack(ret).astype('float')\n    \n    if returnOrig:\n        return np.hstack([_labels,_binaries])\n    else:\n        return _binaries\n    \n\ndef decodeLabels(_binaries,igCols=[]):\n    \n    ret=[]\n    \n    st=0\n    for col in [ _c for _c in output_categories if _c not in igCols]:\n        \n        ed = st + len(uniqueLabels[col])\n        ret.append(  np.mean(_binaries[:,st:ed],axis=-1) )\n        \n        st = ed\n        \n    return np.vstack(ret).T\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# AddFeatures"},{"metadata":{"trusted":true},"cell_type":"code","source":"class QuestDataset4Plugin(torch.utils.data.Dataset):\n    def __init__(self, df, qmconf):\n        self.df = df ; self.cfg = qmconf\n        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg['pgPath'])\n        self.MAX_LEN=512\n        self.SEP_ID = self.tokenizer.encode(self.tokenizer.sep_token,add_special_tokens=False)[0]\n    def clip(self,x):\n        return torch.tensor(x[:self.MAX_LEN])\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        q_input_ids = self.tokenizer.encode(row.question_title,row.question_body,max_length=self.MAX_LEN,pad_to_max_length=True)\n        a_input_ids = self.tokenizer.encode(row.question_title,row.answer,max_length=self.MAX_LEN,pad_to_max_length=True)\n        q_seg_ids = [0 if i <= q_input_ids.index(self.SEP_ID)  else 1 for i in range(len(q_input_ids)) ]\n        a_seg_ids = [0 if i <= a_input_ids.index(self.SEP_ID)  else 1 for i in range(len(a_input_ids)) ]\n        return self.clip(q_input_ids), self.clip(q_seg_ids), self.clip(a_input_ids), self.clip(a_seg_ids)\n                     \n    def __len__(self):\n        return len(self.df)\n\n    def collate_fn(self, batch):\n        q_input_ids = torch.stack([x[0] for x in batch]);q_seg_ids = torch.stack([x[1] for x in batch])\n        a_input_ids = torch.stack([x[2] for x in batch]);a_seg_ids = torch.stack([x[3] for x in batch])\n        return q_input_ids, q_seg_ids, a_input_ids, a_seg_ids\n\ndef get_plugin_loader(df,qmconf,batch_size=1):\n    ds_plugin = QuestDataset4Plugin(df,qmconf)\n    loader = torch.utils.data.DataLoader(ds_plugin, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=ds_plugin.collate_fn, drop_last=False)\n    loader.num = len(df)\n    return loader\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_pluginFeatures(_trn,_tst,qmconf):\n\n    _config=AutoConfig.from_pretrained(qmconf['pgPath'], output_hidden_states=True, output_attentions=False)\n    _model=AutoModel.from_pretrained(qmconf['pgPath'],config=_config)   \n    _SIZE=_config.hidden_size ; _MAX_LEN=512 ; _UseQ = True\n    \n    _model.eval();_model.to(device)\n    \n    qmconf['plugin-size'] = _SIZE*(_UseQ+1)\n\n    def append_pluginFeatureToDf(_df):\n        \n        aux_plg = np.zeros((len(_df),_SIZE*(_UseQ+1)))\n        \n        with torch.no_grad():\n\n            q_hidden=[] ; a_hidden=[]   \n            for _idx, (q_ids, q_seg_ids, a_ids, a_seg_ids)  in tqdm(enumerate(get_plugin_loader(_df, qmconf,batch_size=qmconf['pgBatchSize']))):\n\n                q_ids, q_seg_ids, a_ids, a_seg_ids = q_ids.to(device), q_seg_ids.to(device), a_ids.to(device), a_seg_ids.to(device)\n                q_outputs = _model(q_ids, token_type_ids=q_seg_ids) ; a_outputs = _model(a_ids, token_type_ids=a_seg_ids)\n                q_hidden_states=q_outputs[-1] ; a_hidden_states=a_outputs[-1] \n\n                q_mask = (q_ids>0).unsqueeze(-1).float()\n                a_mask = (a_ids>0).unsqueeze(-1).float()\n                \n                q_hidden.append( masked_mean(q_hidden_states[-1],q_mask,1).cpu().numpy().astype('float32') )\n                a_hidden.append( masked_mean(a_hidden_states[-1],a_mask,1).cpu().numpy().astype('float32') )\n\n        aux_plg[:,:_SIZE] = np.vstack(q_hidden)\n        aux_plg[:,_SIZE:] = np.vstack(a_hidden)\n\n        _df['aux_plugin']=[aux_plg[_i,:] for _i in range(len(_df))]\n        \n        return _df\n\n    if qmconf['train']:\n        _trn = append_pluginFeatureToDf(_trn)\n    \n    _tst = append_pluginFeatureToDf(_tst)\n    \n    del _config,_model;gc.collect();\n    \n    if device is torch.device(\"cuda:0\"):\n        torch.cuda.empty_cache()\n    if qmconf['train']:\n        return _trn,_tst,qmconf\n    else:\n        return _tst,qmconf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def addFeatrure(_trn,_tst,qmconf):\n\n    def myCatOh(x):\n        return np.eye(len(conf_CATEGORIES))[conf_CATEGORIES.index(x)] if x in conf_CATEGORIES else np.ones(len(conf_CATEGORIES))/len(conf_CATEGORIES)\n    _trn['aux'] = _trn['category'].apply(myCatOh) ; _tst['aux'] = _tst['category'].apply(myCatOh)\n    \n    def myCatOhChar(x):\n        return np.eye(1+len(conf_CHAR))[conf_CHAR.index(x)] if x in conf_CHAR else np.eye(1+len(conf_CHAR))[-1]\n    \n    _trn['aux_char'] = _trn.question_title.apply(lambda s:s[0:3].lower()).apply(myCatOhChar) \n    _tst['aux_char'] = _tst.question_title.apply(lambda s:s[0:3].lower()).apply(myCatOhChar)\n    \n    _trn['aux'] = [ np.concatenate([x0,x1]) for x0,x1 in zip(list(_trn['aux']),list(_trn['aux_char'])) ]\n    _tst['aux'] = [ np.concatenate([x0,x1]) for x0,x1 in zip(list(_tst['aux']),list(_tst['aux_char'])) ]\n    \n    if qmconf['plugin']==True:\n        \n        if qmconf['train']:\n            _trn,_tst,qmconf = append_pluginFeatures(_trn,_tst,qmconf)\n            _trn['aux'] = [ np.concatenate([x0,x1]) for x0,x1 in zip(list(_trn['aux']),list(_trn['aux_plugin'])) ]\n        else:\n            _tst,qmconf = append_pluginFeatures(_trn,_tst,qmconf)\n            \n        _tst['aux'] = [ np.concatenate([x0,x1]) for x0,x1 in zip(list(_tst['aux']),list(_tst['aux_plugin'])) ]\n    \n    return _trn,_tst,qmconf\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import *\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass QuestModel(nn.Module):\n\n    def __init__(self,headerN, cfg, n_classes=30):\n        super(QuestModel, self).__init__()\n        \n        self.model_name = 'QuestModel'\n        self.headerN = headerN\n        self.cfg = cfg\n        self.pluginSize = self.cfg['plugin-size'] if self.cfg['plugin'] else 0\n        \n        # overwrite n_classes\n        self.n_classes=30\n        if self.cfg['enc'] or self.cfg['enc2']:\n            self.n_classes = np.sum([len(uniqueLabels[col]) for col in output_categories])\n        \n        if self.cfg['enc2']:\n            self.decs = nn.ModuleList( [ nn.Linear(len(uniqueLabels[col]),1) for col in output_categories ])\n            for m in self.decs: \n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n                \n        config = BertConfig.from_pretrained(f'{TRANSFORMERS_DIR}/bert-base-uncased/', output_hidden_states=True, output_attentions=False)\n        \n        # Don't load pretrain model at inference\n        self.bert_model = BertForSequenceClassification.from_pretrained(f'{TRANSFORMERS_DIR}/bert-base-uncased/',config=config) if _qmconf['train'] else BertForSequenceClassification(config=config)\n\n        self.num_hidden_cls = 3        \n        self.num_hidden_seq = 2      \n        \n        # 2 sperate hidden state for Q and A if use QA augemntation\n        self.fc = nn.Linear( self.pluginSize + ((1+len(conf_CHAR))//2) + conf_cat_emb_dim + self.headerN*((1+self.cfg['aug'])*self.num_hidden_seq+self.num_hidden_cls)*768, self.n_classes)\n        \n        self.emb  = nn.Linear( len(conf_CATEGORIES), conf_cat_emb_dim )\n        self.emb2 = nn.Linear( 1+len(conf_CHAR), (1+len(conf_CHAR))//2)\n        \n        \n    def forward(self, ids, seg_ids, aux):\n        \n        # cat emb\n        catEmb = self.emb(aux[:,:len(conf_CATEGORIES)])\n        \n        # char emb\n        charEmb = self.emb2(aux[:,len(conf_CATEGORIES):( len(conf_CATEGORIES) + (1+len(conf_CHAR)) )])\n        \n        # Calc fc input for each header, ex (q-head,a-head) (q-tail,a-tail) in 2 header conf\n        all_header_fc_input=[]\n        for hidx in range(self.headerN):\n\n            mask = (ids[:,hidx,:] > 0)\n            _, hidden_states = self.bert_model(input_ids=ids[:,hidx,:], token_type_ids=seg_ids[:,hidx,:], attention_mask=mask)\n\n            cls_input = []\n            for _ith in range( self.num_hidden_cls ):\n                cls_input.append(hidden_states[-_ith][:, 0].reshape((-1,  768))) # [cls]\n                \n            # print(hidden_states[0].size())  [4, 512, 768]\n                \n            seq_inputQ = [] ; seq_inputA = [] ; seq_input  = []\n            \n            mask = mask.unsqueeze(-1).float() # > 4,512,1\n            maskQ = (( seg_ids[:,hidx,:]==0 )*(ids[:,hidx,:] > 0)).unsqueeze(-1).float()\n            maskA = (( seg_ids[:,hidx,:]==1 )*(ids[:,hidx,:] > 0)).unsqueeze(-1).float()\n            \n            for _ith in range( self.num_hidden_seq ):\n\n                if self.cfg['aug']:\n\n                    # masked-mean\n                    seq_inputQ.append( masked_mean( hidden_states[-_ith],maskQ,1) )\n                    seq_inputA.append( masked_mean( hidden_states[-_ith],maskA,1) )\n        \n                else:\n                    \n                    seq_input.append( masked_mean(hidden_states[-_ith],mask,1) )\n                    \n            cls_input  = torch.cat(cls_input, 1)\n            cls_input  = F.dropout(cls_input, p=0.2, training=self.training) \n            \n            if self.cfg['aug']:\n                seq_inputQ = torch.cat(seq_inputQ, 1)\n                seq_inputA = torch.cat(seq_inputA, 1)\n                fc_input   = torch.cat([cls_input,seq_inputQ,seq_inputA], 1) \n            else:\n                seq_input  = torch.cat(seq_input, 1)\n                fc_input   = torch.cat([cls_input,seq_input], 1) \n            \n            all_header_fc_input.append(fc_input)\n        \n        all_header_fc_input = torch.stack(all_header_fc_input)\n        all_header_fc_input=all_header_fc_input.permute(1, 0, 2)\n        all_header_fc_input=torch.flatten(all_header_fc_input, start_dim=1)\n        \n        # Final FC Input\n        if self.cfg['plugin']:\n            plugin_aux = aux[:,( len(conf_CATEGORIES) + (1+len(conf_CHAR)) ):]\n            final_fc_input= torch.cat([all_header_fc_input,catEmb,charEmb,plugin_aux],1)\n        else:\n            final_fc_input = torch.cat([all_header_fc_input,catEmb,charEmb],1)\n        \n        # FC layer\n        if self.cfg['msdropout']:\n            logits=[]\n            for _ in range(5):\n                logits.append( self.fc( F.dropout(final_fc_input, p=0.5, training=self.training) ) )\n            logit = torch.mean(torch.stack(logits),0)\n        else:\n            logit = self.fc( final_fc_input )\n            \n        # decode    \n        if self.cfg['enc2']:\n            \n            decoded=[]\n            st=0\n            for _i,col in enumerate(output_categories):\n                ed=st+len(uniqueLabels[col])\n                decoded.append( self.decs[_i](torch.sigmoid(logit[:,st:ed])) )\n                st=ed\n                \n            pred  = torch.cat(decoded,-1)\n            logit = torch.cat([pred,logit],1)\n            \n        return logit\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if conf_frac<1:\n    df_train=df_train.sample(frac=conf_frac,random_state=2019);df_test =df_test.sample(frac=conf_frac,random_state=2019);print(\"SAMPLED\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler((0.01, 0.99))\n\nC_token_ids, C_seg_ids, C_aux = [],[],[] # cash for estimation\ndef CC():#Clear Cash:\n    C_token_ids.clear(), C_seg_ids.clear(), C_aux.clear()\n    \ndef train_predict(_df_train,_df_test,_qmconf):\n    \n    tstPreds=[] ; valPreds=[] ; fold_split=[] ; fold_histories = []\n    gkf = GroupKFold(n_splits=conf_num_fold).split(X=_df_train.question_body, groups=_df_train.question_body)\n    \n    for fold, (train_idx, valid_idx) in enumerate(gkf):\n        \n        trn_df = _df_train.iloc[train_idx].copy()\n        val_df = _df_train.iloc[valid_idx].copy()\n        fold_split.append((train_idx, valid_idx))\n        \n        # Augmentation by swapping same question labels\n        if _qmconf['train']:trn_df = trn_df.groupby('question_title').apply(rollQuestion).reset_index(drop=True) if _qmconf['aug']==True else trn_df\n\n        print(f\"FOLD{fold} \")\n        _history={};_history['val']=[];_history['tst']=[];_history['rho']=[]\n        best_rho = -100\n\n        # model\n        model = QuestModel(headerN=conf_headerN, cfg=_qmconf)\n        plist = [{'params': model.parameters(), 'lr': conf_lr}]\n        optimizer = optim.Adam(plist, lr=conf_lr) \n        \n        criterion = torch.nn.BCEWithLogitsLoss()\n        \n        model.to(device)\n        \n        _max_epoch = conf_max_epoch if _qmconf['train'] else len(glob.glob(f\"../input/{_qmconf['pretrain_dir'].lower()}*/MW_fold{fold}_part*.pth\")) \n        \n        for epoch in range(_max_epoch):\n\n            torch.cuda.empty_cache()\n\n            print('Epoch {}/{}'.format(epoch, _max_epoch),end=\" \")\n\n            # training\n            if _qmconf['train']:\n                \n                model.train()    \n                tr_loss = 0\n                for step, (token_ids, seg_ids, aux, labels) in enumerate(get_trn_loader(trn_df,conf_headerN)):\n\n                    if _qmconf['enc'] or _qmconf['enc2']:\n                        labels = torch.tensor( encodeLabels(labels,returnOrig=_qmconf['enc2']),dtype=torch.float32 )\n                  \n                    token_ids, seg_ids, labels, aux = token_ids.to(device), seg_ids.to(device), labels.to(device), aux.to(device)\n\n                    outputs = model(token_ids, seg_ids, aux)\n                    \n                    if _qmconf['enc2']:\n\n                        loss = criterion(outputs[:30], labels[:30]) + criterion(outputs[:,30:], labels[:,30:]) \n                    \n                    else:\n                        loss = criterion(outputs, labels)\n                    \n                    loss.backward()\n                    optimizer.step()\n                    optimizer.zero_grad()\n\n            else:\n                \n                pthFileName = glob.glob(f\"../input/{_qmconf['pretrain_dir'].lower()}*/MW_fold{fold}_part{epoch}.pth\")[0]\n                print(f\"Loading {pthFileName} \")\n                model.load_state_dict(torch.load(f\"{pthFileName}\"))\n\n            with torch.no_grad():\n\n                model.eval()\n\n                # validate ( just load pre-calculated validation result at prediction mode )\n                if  _qmconf['train']:\n                    \n                    valPred=[];valTrue=[]\n                    for step, (token_ids, seg_ids, aux, labels)  in enumerate(get_val_loader(val_df,conf_headerN)):\n\n                        token_ids, seg_ids, aux= token_ids.to(device), seg_ids.to(device), aux.to(device)\n                        valPred.append(torch.sigmoid(model(token_ids, seg_ids, aux)).cpu())\n                        valTrue.append(labels)\n\n                    valPred = np.vstack(valPred);valTrue  = np.vstack(valTrue)\n                    if _qmconf['enc']:\n                        valPred = decodeLabels(valPred)\n                    elif _qmconf['enc2']:\n                        valPred0 = scaler.fit_transform(decodeLabels(valPred[:,30:]))\n                        valPred1 = scaler.fit_transform(valPred[:,:30])\n                        valPred = ( valPred0+valPred1)/2 \n\n                    rho = compute_spearmanr(valTrue,valPred)\n                    \n                    _history['rho'].append(rho) ; _history['val'].append(valPred) ;\n\n                # predict test\n                tstPred=[]\n                if len(C_token_ids) == 0: #no cash first run\n                    \n                    for step, (token_ids, seg_ids, aux) in enumerate(get_tst_loader(_df_test,conf_headerN,batch_size=_qmconf['BatchSize'])):\n\n                        #create cash\n                        C_token_ids.append(token_ids.clone());C_seg_ids.append(seg_ids.clone());C_aux.append(aux.clone())\n\n                        token_ids, seg_ids, aux= token_ids.to(device), seg_ids.to(device), aux.to(device)\n                        tstPred.append( torch.sigmoid(model(token_ids, seg_ids, aux)).cpu() )\n\n                else: # using cahsed data\n                    \n                    for step, (token_ids, seg_ids, aux) in enumerate(zip(C_token_ids, C_seg_ids, C_aux)):\n\n                        token_ids, seg_ids, aux= token_ids.to(device), seg_ids.to(device), aux.to(device)\n                        tstPred.append( torch.sigmoid(model(token_ids, seg_ids, aux)).cpu() )\n\n                tstPred = np.vstack(tstPred)\n                if _qmconf['enc']:\n                    tstPred = decodeLabels(tstPred)\n                elif _qmconf['enc2']:\n                    tstPred0 = scaler.fit_transform(decodeLabels(tstPred[:,30:]))\n                    tstPred1 = scaler.fit_transform(tstPred[:,:30])\n                    tstPred = ( tstPred0+tstPred1)/2 \n                    \n                _history['tst'].append(tstPred)\n\n                if _qmconf['train']:\n                    if conf_save:\n                        _mkdir(_qmconf['save_dir']);_mkdir(_qmconf['save_dir']+f'/fold{fold}')\n                        if epoch>2:\n                            !rm ./{_qmconf['save_dir']}/fold{fold}/MW_ep{epoch-3}.pth\n                        torch.save( model.state_dict(), f\"./{_qmconf['save_dir']}/fold{fold}/MW_ep{epoch}.pth\" )\n\n                    if rho>best_rho:\n                        best_rho=rho\n                    else:\n                        if epoch>1:\n                            print(f\"{rho:.4f} Stop training\")\n                            break\n\n                    print(f\"{_history['rho'][-1]:.4f}\")\n\n\n        fold_histories.append(_history)\n\n        del model,optimizer,criterion,trn_df,val_df\n\n        gc.collect();torch.cuda.empty_cache()\n\n    # ckpt ensemble\n    epochs = [ np.arange(-1,-1-min(3,len(fold_histories[_fold]['tst'])),-1) for _fold in range(conf_num_fold) ]\n    \n    test_predictions  = np.average( [ fold_histories[_fold]['tst'][_ep] for _fold in range(conf_num_fold) for _ep in epochs[_fold]  ] ,axis=0 )\n    \n    if  _qmconf['train']:\n        valid_predictions = np.zeros_like(df_train[output_categories])\n        for _fold in range(conf_num_fold):\n            valid_predictions[fold_split[_fold][1]] = np.average( [ fold_histories[_fold]['val'][_ep] for _ep in  epochs[_fold] ] ,axis=0 )\n    else:\n        # load validation results calculated at training stage\n        precal_val_df = pd.read_csv(glob.glob(f'../input/{_qmconf[\"pretrain_dir\"].lower()}*/*predVal_df.csv')[0])\n        valid_predictions = precal_val_df.values if conf_frac==1 else precal_val_df.sample(frac=conf_frac,random_state=2019).values\n        \n        \n    return test_predictions, valid_predictions\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nquestModelConfigs=[]\nif conf_train:\n    \n    # train config \n    questModelConfigs.append({'seed':11,'plugin':False,'aug':True ,'train':conf_train,'pretrain_dir':'pth-0207S11A1E1','save_dir':'pth-0207S11A1E1',\"BatchSize\":16,'msdropout':True,'enc':False,'enc2':True})\n    \nelse:\n    \n    # 7 models\n\n    # base model\n    questModelConfigs.append({'seed':'N','plugin':False,'aug':False ,'train':conf_train,'pretrain_dir':f'pth-0129SNA0','save_dir':f'pth-0129SNA0',\"BatchSize\":16,'msdropout':False,'enc':False,'enc2':False})\n    \n    # with data augmentation\n    questModelConfigs.append({'seed':0,'plugin':False,'aug':True ,'train':conf_train,'pretrain_dir':\"pth-0127aS0A1\",'save_dir':\"pth-0127aS0A1\",\"BatchSize\":16,'msdropout':False,'enc':False,'enc2':False})\n    \n    # predicts encoded label\n    questModelConfigs.append({'seed':0,'plugin':False,'aug':True ,'train':conf_train,'pretrain_dir':'pth-0206S0A1E0','save_dir':'pth-0206S0A1E0',\"BatchSize\":16,'msdropout':True,'enc':True,'enc2':False})\n    questModelConfigs.append({'seed':3,'plugin':False,'aug':True ,'train':conf_train,'pretrain_dir':'pth-0206S3A1E0','save_dir':'pth-0206S3A1E0',\"BatchSize\":16,'msdropout':True,'enc':True,'enc2':False})\n    \n    # predicts label and encoded label\n    questModelConfigs.append({'seed':11,'plugin':False,'aug':True ,'train':conf_train,'pretrain_dir':'pth-0207S11A1E1','save_dir':'pth-0207S11A1E1',\"BatchSize\":16,'msdropout':True,'enc':False,'enc2':True})\n    \n    # uses hugging face pretrained model's output as aux features \n    questModelConfigs.append({'seed':'CLEAR_CASH'})\n    questModelConfigs.append({'seed':0,'plugin':True,'aug':True,'train':conf_train,'pretrain_dir':'pth-0206S0A1-squadBL','save_dir':'pth-0206S0A1-squadBL',\n                              'pgPath':'../input/bert-data/bert-large-cased-whole-word-masking-finetuned-squad','pgBatchSize':16,\"BatchSize\":16,'msdropout':False,'enc':False,'enc2':False})\n    \n    questModelConfigs.append({'seed':'CLEAR_CASH'})\n    questModelConfigs.append({'seed':11,'plugin':True,'aug':True,'train':conf_train,'pretrain_dir':'pth-0129S11A1-squad2BL','save_dir':'pth-0129S11A1-squad2BL',\n                               'pgPath':'../input/bert-data/bert-large-uncased-whole-word-masking-squad2','pgBatchSize':16,\"BatchSize\":16,'msdropout':False,'enc':False,'enc2':False})\n    \n    \nhistory=[];predVals=[];predTsts=[]\n\nfor _qmconf in questModelConfigs:\n    \n    if _qmconf['seed'] is 'CLEAR_CASH':\n        CC()\n        continue\n    \n    trn = df_train.copy(); tst = df_test.copy()\n    \n    trn=trn.sample(frac=1,random_state=_qmconf['seed']) if _qmconf['seed']!='N' else trn \n    \n    trn,tst,_qmconf = addFeatrure(trn,tst,_qmconf) # append 'plugin-size' size to _qmconf\n    test_predictions,valid_predictions = train_predict(trn,tst,_qmconf)\n    \n    predVal_df = pd.DataFrame(valid_predictions, columns=output_categories, index=trn.index if _qmconf['train'] else df_train.index).sort_index()\n    predTst_df = pd.DataFrame(test_predictions,  columns=output_categories, index=df_test.index)\n    \n    predVals.append(predVal_df)\n    predTsts.append(predTst_df)\n    \n    predVal_df.to_csv(f'{_qmconf[\"save_dir\"]}predVal_df.csv',index=False);predTst_df.to_csv(f'{_qmconf[\"save_dir\"]}predTst_df.csv',index=False)\n\n    del trn,tst;gc.collect()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Blending"},{"metadata":{"trusted":true},"cell_type":"code","source":"cvs=np.vstack([ compute_spearmanr(df_train.iloc[:,11:].values, predVals[idx].values,returnArray=True) for idx in range(7) ])\ncvs=pd.DataFrame(cvs,columns=output_categories).round(3)\ncvs.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop={}\ndrop['question_asker_intent_understanding']=[0]\ndrop['question_body_critical']=[0]\ndrop['question_conversational']=[]\ndrop['question_expect_short_answer']=[]\ndrop['question_fact_seeking']=[]\ndrop['question_has_commonly_accepted_answer']=[]\ndrop['question_interestingness_others']=[0,6]\ndrop['question_interestingness_self']=[]\ndrop['question_multi_intent']=[4]\n\ndrop['question_not_really_a_question']=[2,3,4,6]\n\ndrop['question_opinion_seeking']=[]\ndrop['question_type_choice']=[]\ndrop['question_type_compare']=[]\ndrop['question_type_consequence']=[0,4]\ndrop['question_type_definition']=[0,4]\ndrop['question_type_entity']=[2,3,4]\ndrop['question_type_instructions']=[]\ndrop['question_type_procedure']=[6]\ndrop['question_type_reason_explanation']=[]\n\ndrop['question_type_spelling']=[0,2,3,4] #[0,2,3,4]\n\ndrop['question_well_written']=[]\ndrop['answer_helpful']=[0]\ndrop['answer_level_of_information']=[]\ndrop['answer_plausible']=[0]\ndrop['answer_relevance']=[]\ndrop['answer_satisfaction']=[]\ndrop['answer_type_instructions']=[]\ndrop['answer_type_procedure']=[6]\ndrop['answer_type_reason_explanation']=[]\ndrop['answer_well_written']=[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in output_categories:\n    \n    for drop_id in drop[col]:\n    \n        predVals[ drop_id ].loc[:,col] = np.nan\n        predTsts[ drop_id ].loc[:,col] = np.nan\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predVal_df = df_average(predVals) # averaging by nanmean\npredTst_df = df_average(predTsts)\npredVal_df.to_csv('predVal_df.csv',index=False);predTst_df.to_csv('predTst_df.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalize"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler((0.01, 0.99))\npredVal_df.iloc[:,:] = scaler.fit_transform(predVal_df)\npredTst_df.iloc[:,:] = scaler.fit_transform(predTst_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clipping"},{"metadata":{"trusted":true},"cell_type":"code","source":"if conf_frac<1:\n    df_train = df_train.sort_index()\n\nround_target = ['question_conversational','question_type_compare','question_type_consequence','question_type_definition', 'question_type_entity']\n\nhard_target_cols = ['question_type_spelling','question_not_really_a_question'] \n\nextra_lower_cols=[]\nif conf_extra_clip:\n    extra_lower_cols=['question_asker_intent_understanding',\n 'question_body_critical',\n 'question_expect_short_answer',\n 'question_fact_seeking',\n 'question_has_commonly_accepted_answer',\n 'question_interestingness_others',\n 'question_interestingness_self',\n 'question_multi_intent',\n 'question_type_choice',\n 'question_type_instructions',\n 'question_type_reason_explanation',\n 'question_well_written',\n 'answer_helpful',\n 'answer_level_of_information',\n 'answer_plausible',\n 'answer_relevance',\n 'answer_satisfaction',\n 'answer_type_instructions',\n 'answer_type_reason_explanation',\n 'answer_well_written']\n\nfor col in round_target+hard_target_cols+extra_lower_cols:\n\n    threshold = np.sum(df_train[col]==df_train[col].min())/len(df_train) \n\n    isNearZeroVal = predVal_df[col].rank(pct=True) < threshold\n    isNearZeroTst = predTst_df[col].rank(pct=True) < threshold\n\n    predVal_df.loc[isNearZeroVal,col] = 0.01\n    predTst_df.loc[isNearZeroTst,col] = 0.01\n    \nif conf_spell_host_clip:\n    \n    isEnglishHostVal = ( df_train.host=='english.stackexchange.com')  \n    isEnglishHostTst = ( df_test.host =='english.stackexchange.com') \n    predVal_df.loc[~isEnglishHostVal,'question_type_spelling']=0.01\n    predTst_df.loc[~isEnglishHostTst,'question_type_spelling']=0.01\n    \n    \nif conf_special_user_page:\n    \n    special_user_page = list(df_train[df_train.question_not_really_a_question>0].question_user_page.unique())\n    special_user_page_mean = df_train.loc[df_train.question_user_page.apply(lambda x:x in special_user_page),'question_not_really_a_question'].mean()\n\n    isSpecialUserPageVal = df_train.question_user_page.apply(lambda x:x in special_user_page)\n    isSpecialUserPageTst = df_test.question_user_page.apply(lambda x:x in special_user_page)\n\n    predVal_df.loc[isSpecialUserPageVal,'question_not_really_a_question']=special_user_page_mean\n    predTst_df.loc[isSpecialUserPageTst,'question_not_really_a_question']=special_user_page_mean\n\n    \nextra_higher_cols=[]\nif conf_extra_clip:\n    \n    extra_higher_cols=['question_has_commonly_accepted_answer',\n 'answer_helpful',\n 'answer_plausible',\n 'answer_relevance']\n    \nfor col in extra_higher_cols:\n\n    threshold = np.sum(df_train[col]==df_train[col].max())/len(df_train) \n\n    isNearOneVal = predVal_df[col].rank(pct=True) > threshold\n    isNearOneTst = predTst_df[col].rank(pct=True) > threshold\n\n    predVal_df.loc[isNearOneVal,col] = 0.99\n    predTst_df.loc[isNearOneTst,col] = 0.99\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rounding"},{"metadata":{"trusted":true},"cell_type":"code","source":"predVal_df = predVal_df.round(2)\npredTst_df = predTst_df.round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission "},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = predTst_df.copy()\nsub.insert(0,'qa_id',df_test.qa_id)\n\nsub.iloc[:, 1:] = predTst_df.values\n\n\nif ( predVal_df.iloc[:,1:].isnull().any().any()==True ) or ( (predVal_df.iloc[:,1:].std()==0).any()==True ):\n    \n    pass\n    \nelse:\n    \n    sub.to_csv('submission.csv', index=False)\n\n\nif conf_plot_result:\n    sub.iloc[:,1:].hist(bins=100,figsize=(18,18))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CV "},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_true_df = df_train.loc[:,output_categories[:30]].copy()\n\n# Caluclate rho of validation\nrhos = compute_spearmanr(valid_true_df.values,predVal_df.values,returnArray=True)\nfor _i,col in enumerate(predVal_df.columns):\n    print(f\"{col}:{rhos[_i]:.3f}\")\nprint(\"-\"*30);print(f\"average:{np.mean(rhos):.3f}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"086421f7eec44c769f08f5f68fafafdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e7c81c0da784e04b530236bad005c33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18b951cd8c1447eaa1e12f972ac37d42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"  9%","description_tooltip":null,"layout":"IPY_MODEL_9e743ecd26cd4877a539f9bbbd23d114","max":308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e34fafda1e234d9c981322beff1068e7","value":29}},"35645b239e914aee807cfdc234fc5b75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfdee9b109bc4176a0bc3a26ae38f7a3","placeholder":"â€‹","style":"IPY_MODEL_086421f7eec44c769f08f5f68fafafdc","value":" 29/308 [7:12:46&lt;66:18:40, 855.63s/it]"}},"554271f3ed5d48efa844608a0b72fdac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"685ecca481e3463d83a2465f15f7b33f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_80ae0d356c3e4b1bbe511c5f5a2694b5","max":4059,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a34804b28be74d7c9972a0a13410ba77","value":4059}},"7f49d7d685554687bc2d131959058cb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80ae0d356c3e4b1bbe511c5f5a2694b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"840e74b11eb44a58b1ed0433e924dc82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e743ecd26cd4877a539f9bbbd23d114":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a34804b28be74d7c9972a0a13410ba77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"a61c8f56dbd74e29a155fad0d7095f79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18b951cd8c1447eaa1e12f972ac37d42","IPY_MODEL_35645b239e914aee807cfdc234fc5b75"],"layout":"IPY_MODEL_7f49d7d685554687bc2d131959058cb3"}},"c9ab84b07a32426282543b5ff054ddec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_840e74b11eb44a58b1ed0433e924dc82","placeholder":"â€‹","style":"IPY_MODEL_554271f3ed5d48efa844608a0b72fdac","value":" 4059/4059 [14:53&lt;00:00,  4.54it/s]"}},"dfdee9b109bc4176a0bc3a26ae38f7a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e34fafda1e234d9c981322beff1068e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"fd692cff30e343aa8afa007a05d66acc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_685ecca481e3463d83a2465f15f7b33f","IPY_MODEL_c9ab84b07a32426282543b5ff054ddec"],"layout":"IPY_MODEL_0e7c81c0da784e04b530236bad005c33"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":1}