{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport warnings\nfrom math import floor, ceil\nimport re\nimport random\nimport torch \nfrom torch import nn\nimport torch.optim as optim\nfrom sklearn.model_selection import GroupKFold\nfrom scipy.stats import spearmanr\n\nfrom transformers import BertTokenizer, BertModel, BertConfig, XLNetTokenizer, XLNetModel, XLNetConfig\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_all(seed_value):\n    random.seed(seed_value) # Python\n    np.random.seed(seed_value) # cpu vars\n    torch.manual_seed(seed_value) # cpu  vars\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value) # gpu vars\n        torch.backends.cudnn.deterministic = True  #needed\n        torch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nseed_all(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\nTARGET_COLS = list(sub.columns[1:].values)\nfor label in TARGET_COLS: print(label) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decontract(text):\n    text = re.sub(r\"(W|w)on(\\'|\\’)t \", \"will not \", text)\n    text = re.sub(r\"(C|c)an(\\'|\\’)t \", \"can not \", text)\n    text = re.sub(r\"(Y|y)(\\'|\\’)all \", \"you all \", text)\n    text = re.sub(r\"(Y|y)a(\\'|\\’)ll \", \"you all \", text)\n    text = re.sub(r\"(I|i)(\\'|\\’)m \", \"i am \", text)\n    text = re.sub(r\"(A|a)isn(\\'|\\’)t \", \"is not \", text)\n    text = re.sub(r\"n(\\'|\\’)t \", \" not \", text)\n    text = re.sub(r\"(\\'|\\’)re \", \" are \", text)\n    text = re.sub(r\"(\\'|\\’)d \", \" would \", text)\n    text = re.sub(r\"(\\'|\\’)ll \", \" will \", text)\n    text = re.sub(r\"(\\'|\\’)t \", \" not \", text)\n    text = re.sub(r\"(\\'|\\’)ve \", \" have \", text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN = 512\n\nclass QuestDatasetBert(torch.utils.data.Dataset):\n    def __init__(self, df, train_mode=True, labeled=True):\n        self.df = df\n        self.train_mode = train_mode\n        self.labeled = labeled\n        self.tokenizer = BertTokenizer.from_pretrained('../input/btp-uncased-base/')\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        token_ids, seg_ids, masks = self.get_token_ids(row)\n        if self.labeled:\n            labels = self.get_label(row)\n            return token_ids, seg_ids, masks, labels\n        else:\n            return token_ids, seg_ids, masks\n\n    def __len__(self):\n        return len(self.df)\n\n    def select_tokens(self, tokens, max_num):\n        if len(tokens) <= max_num:\n            return tokens\n        if self.train_mode:\n            num_remove = len(tokens) - max_num\n            remove_start = random.randint(0, len(tokens)-num_remove-1)\n            return tokens[:remove_start] + tokens[remove_start + num_remove:]\n        else:\n            return tokens[:max_num//2] + tokens[-(max_num - max_num//2):]\n        \n    def preprocessing_text(self, text):\n        text = re.sub('\\t|\\n|\\r', '', text)\n        text = decontract(text)\n        \n        return text\n\n    def trim_input(self, title, question, answer, max_sequence_length=MAX_LEN, \n                t_max_len=30, q_max_len=239, a_max_len=239):\n        t = self.tokenizer.tokenize(self.preprocessing_text(title))\n        q = self.tokenizer.tokenize(self.preprocessing_text(question))\n        a = self.tokenizer.tokenize(self.preprocessing_text(answer))\n\n        t_len = len(t)\n        q_len = len(q)\n        a_len = len(a)\n\n        if (t_len+q_len+a_len+4) > max_sequence_length:\n\n            if t_max_len > t_len:\n                t_new_len = t_len\n                a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n                q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n            else:\n                t_new_len = t_max_len\n\n            if a_max_len > a_len:\n                a_new_len = a_len \n                q_new_len = q_max_len + (a_max_len - a_len)\n            elif q_max_len > q_len:\n                a_new_len = a_max_len + (q_max_len - q_len)\n                q_new_len = q_len\n            else:\n                a_new_len = a_max_len\n                q_new_len = q_max_len\n\n\n            if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n                raise ValueError(\"New sequence length should be %d, but is %d\" \n                                 % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n\n            t = self.select_tokens(t, t_new_len)\n            q = self.select_tokens(q, q_new_len)\n            a = self.select_tokens(a, a_new_len)\n\n        return t, q, a\n        \n    def get_token_ids(self, row):\n        t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer)\n\n        tokens = ['[CLS]'] + t_tokens + ['[SEP]'] + q_tokens + ['[SEP]'] + a_tokens + ['[SEP]']\n        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        if len(token_ids) < MAX_LEN:\n            token_ids += [0] * (MAX_LEN - len(token_ids))\n        ids = torch.tensor(token_ids)\n        seg_ids = self.get_seg_ids(ids)\n        masks = self.get_masks(ids)\n        return ids, seg_ids, masks\n    \n    def get_seg_ids(self, ids):\n        seg_ids = torch.zeros_like(ids)\n        seg_idx = 0\n        first_sep = True\n        for i, e in enumerate(ids):\n            seg_ids[i] = seg_idx\n            if e == 102:\n                if first_sep:\n                    first_sep = False\n                else:\n                    seg_idx = 1\n        return seg_ids\n    \n    def get_masks(self, ids):\n        masks = torch.where(ids != 0, torch.tensor(1), torch.tensor(0))\n        return masks\n\n    def get_label(self, row):\n        return torch.tensor(row[TARGET_COLS].values.astype(np.float32))\n    \nclass QuestDatasetXLNet(torch.utils.data.Dataset):\n    def __init__(self, df, train_mode=True, labeled=True):\n        self.df = df\n        self.train_mode = train_mode\n        self.labeled = labeled\n        self.tokenizer = XLNetTokenizer.from_pretrained('../input/xlnet-base-pytorch/xlnet-base-cased-spiece.model')\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        token_ids, seg_ids, masks, cls_index = self.get_token_ids(row)\n        if self.labeled:\n            labels = self.get_label(row)\n            return token_ids, seg_ids, masks, cls_index, labels\n        else:\n            return token_ids, seg_ids, masks, cls_index\n\n    def __len__(self):\n        return len(self.df)\n\n    def select_tokens(self, tokens, max_num):\n        if len(tokens) <= max_num:\n            return tokens\n        if self.train_mode:\n            num_remove = len(tokens) - max_num\n            remove_start = random.randint(0, len(tokens)-num_remove-1)\n            return tokens[:remove_start] + tokens[remove_start + num_remove:]\n        else:\n            return tokens[:max_num//2] + tokens[-(max_num - max_num//2):]\n        \n    def preprocessing_text(self, text):\n        text = re.sub('\\t|\\n|\\r', '', text)\n        text = decontract(text)\n        \n        return text\n\n    def trim_input(self, title, question, answer, max_sequence_length=MAX_LEN, \n                t_max_len=30, q_max_len=239, a_max_len=239):\n        t = self.tokenizer.tokenize(self.preprocessing_text(title))\n        q = self.tokenizer.tokenize(self.preprocessing_text(question))\n        a = self.tokenizer.tokenize(self.preprocessing_text(answer))\n\n        t_len = len(t)\n        q_len = len(q)\n        a_len = len(a)\n\n        if (t_len+q_len+a_len+4) > max_sequence_length:\n\n            if t_max_len > t_len:\n                t_new_len = t_len\n                a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n                q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n            else:\n                t_new_len = t_max_len\n\n            if a_max_len > a_len:\n                a_new_len = a_len \n                q_new_len = q_max_len + (a_max_len - a_len)\n            elif q_max_len > q_len:\n                a_new_len = a_max_len + (q_max_len - q_len)\n                q_new_len = q_len\n            else:\n                a_new_len = a_max_len\n                q_new_len = q_max_len\n\n\n            if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n                raise ValueError(\"New sequence length should be %d, but is %d\" \n                                 % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n\n            t = self.select_tokens(t, t_new_len)\n            q = self.select_tokens(q, q_new_len)\n            a = self.select_tokens(a, a_new_len)\n\n        return t, q, a\n        \n    def get_token_ids(self, row):\n        t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer)\n\n        tokens = t_tokens + ['<sep>'] + q_tokens + ['<sep>'] + a_tokens + ['<sep>'] + ['<cls>']\n        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        cls_index = torch.tensor(len(token_ids) - 1)\n        if len(token_ids) < MAX_LEN:\n            token_ids += [5] * (MAX_LEN - len(token_ids))\n        ids = torch.tensor(token_ids)\n        seg_ids = self.get_seg_ids(ids)\n        masks = self.get_masks(ids)\n        return ids, seg_ids, masks, cls_index\n    \n    def get_seg_ids(self, ids):\n        seg_ids = torch.zeros_like(ids)\n        seg_idx = 0\n        first_sep = True\n        for i, e in enumerate(ids):\n            seg_ids[i] = seg_idx\n            if e == 4:\n                if first_sep:\n                    first_sep = False\n                else:\n                    seg_idx = 1\n        return seg_ids\n    \n    def get_masks(self, ids):\n        masks = torch.where(ids != 5, torch.tensor(1), torch.tensor(0))\n        return masks\n    \n    def get_label(self, row):\n        return torch.tensor(row[TARGET_COLS].values.astype(np.float32))\n\ndef get_test_loader(batch_size=32, model='bert'):\n    df = pd.read_csv('../input/google-quest-challenge/test.csv')\n    if model == 'bert':\n        ds_test = QuestDatasetBert(df, train_mode=False, labeled=False)\n    else:\n        ds_test = QuestDatasetXLNet(df, train_mode=False, labeled=False)\n        \n    loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, \n                                         num_workers=2, drop_last=False)    \n    return loader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertForQA(nn.Module):\n    def __init__(self, net_bert, n_classes):\n        super(BertForQA, self).__init__()\n\n        self.bert = net_bert\n        self.dropout = nn.Dropout(0.5)\n        self.cls = nn.Linear(in_features=768, out_features=n_classes)\n\n        nn.init.normal_(self.cls.weight, std=0.02)\n        nn.init.normal_(self.cls.bias, 0)\n\n    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n        _, _, hidden_states = self.bert(input_ids, attention_mask, token_type_ids)\n\n        all_h = torch.cat([hidden_states[-i][:, 0].reshape((-1, 1, 768)) for i in range(1, 5)], 1)\n        mean_pool = torch.mean(all_h, 1)\n\n        pooled_output = self.dropout(mean_pool)\n        output = self.cls(pooled_output)\n                \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class XLNetForQA(nn.Module):\n    def __init__(self, xlnet, n_classes):\n        super(XLNetForQA, self).__init__()\n\n        self.xlnet = xlnet  \n        self.dropout = nn.Dropout(0.5)\n        self.cls = nn.Linear(in_features=768, out_features=n_classes)\n\n        nn.init.normal_(self.cls.weight, std=0.02)\n        nn.init.normal_(self.cls.bias, 0)\n\n    def forward(self, input_ids, token_type_ids, attention_mask, cls_index):\n        _, hidden_states = self.xlnet(\n            input_ids=input_ids, \n            attention_mask=attention_mask, \n            token_type_ids=token_type_ids)\n \n        cls_index = cls_index[:, None, None].expand(-1, -1, 768)  # shape (bsz, 1, hsz)        \n        all_h = torch.cat([hidden_states[-i].gather(-2, cls_index) for i in range(1, 5)], 1)\n        mean_pool = torch.mean(all_h, 1)\n\n        pooled_output = self.dropout(mean_pool)\n        output = self.cls(pooled_output)\n                \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(model='bert'):\n    if model == 'bert':\n        config = BertConfig.from_pretrained('../input/btp-uncased-base/bert_config.json', output_hidden_states=True)    \n        net_bert = BertModel.from_pretrained('../input/btp-uncased-base/pytorch_model.bin', config=config)\n        net = BertForQA(net_bert, 30)\n    else:\n        config = XLNetConfig.from_pretrained('../input/xlnet-base-pytorch/xlnet-base-cased-config.json', output_hidden_states=True)    \n        xlnet = XLNetModel.from_pretrained('../input/xlnet-base-pytorch/xlnet-base-cased-pytorch_model.bin', config=config)\n        net = XLNetForQA(xlnet, 30)\n    \n    return net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"improved_cols = [\n    'question_conversational', \n    'question_has_commonly_accepted_answer',\n    'question_interestingness_self',\n    'question_not_really_a_question',\n    'question_type_choice',\n    'question_type_compare',\n    'question_type_consequence',\n    'question_type_definition',\n    'question_type_entity',\n    'answer_plausible',\n    'answer_relevance',\n]\nbestcutting = [\n    # question_asker_intent_understanding\n    [],\n    # question_body_critical\n    [], \n    # question_conversational\n    [0.07143090909002797, 0.12004401497150083, 0.1848436328636153, 0.393906661243123], \n    # question_expect_short_answer\n    [], \n    # question_fact_seeking\n    [0.5079822811938757, 0.6784007255713459, 0.8821817039873604, 0.9433617221024944], \n    # question_has_commonly_accepted_answer\n    [0.3371636921591598, 0.5581504204597405, 0.7077497707969119, 0.7828705361913083], \n    # question_interestingness_others\n    [], \n    # question_interestingness_self\n    [0.4956358187787945, 0.5224040768530395, 0.5255965284962879, 0.5793678554651578, 0.609287211890339, 0.616010882506188, 0.6196306504341735, 0.6676136621794896], \n    # question_multi_intent\n    [], \n    # question_not_really_a_question\n    [0.006889458941723597, 0.3260944763731216, 0.41788196092069185, 0.8651878898710491], \n    # question_opinion_seeking\n    [], \n    # question_type_choice\n    [0.11795989772505418, 0.24754185187571828, 0.4745327419425606, 0.7234122358154191], \n    # question_type_compare\n    [0.09410719980735521, 0.15601674060996373, 0.282369801654087, 0.5313848085789701], \n    # question_type_consequence\n    [0.0004399460062622443, 0.03194983660092762, 0.07003471591529131, 0.1503817577814426], \n    # question_type_definition\n    [0.14375842154645047, 0.2616577902050483, 0.2625648734101294, 0.396704338334258], \n    # question_type_entity\n    [0.09127758816465084, 0.17097449682745675, 0.4003532557591638, 0.9950764536726562], \n    # question_type_instructions\n    [0.16265486023189857, 0.32208644678446063, 0.5417455427354888, 0.7751835127308364], \n    # question_type_procedure\n    [], \n    # question_type_reason_explanation\n    [], \n    # question_type_spelling\n    [],\n    # question_well_written\n    [], \n    # answer_helpful\n    [], \n    # answer_level_of_information\n    [], \n    # answer_plausible\n    [0.05277303723757072, 0.08296633934736848, 0.2892567828157349, 0.8733971791156417, 0.9508973759039053, 0.9536983669289478, 0.9693328391611057, 0.9815554213789836], \n    # answer_relevance\n    [0.675877531406042, 0.7222527113500082, 0.8276284368386688, 0.9215102556176764, 0.939746161126185, 0.9528639928103086, 0.9671258882221032, 0.978652006112756], \n    # answer_satisfaction\n    [0.06008624214559094, 0.08468818485434321, 0.17139508646282006, 0.42753923139658206, 0.47748050195355696, 0.5020362112065385, 0.6191407747833618, 0.6221662654090617, 0.7453504487470863, 0.8057253638493509, 0.8163920374283427, 0.8472975110653058, 0.8670318719402241, 0.8748592375242844, 0.9165127791415058, 0.9982222527210189], \n    # answer_type_instructions\n    [], \n    # answer_type_procedure\n    [], \n    # answer_type_reason_explanation\n    [], \n    # answer_well_written\n    []\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def postprocess(pred):\n    df = pd.read_csv('../input/google-quest-challenge/train.csv')\n    for i, col in enumerate(TARGET_COLS):\n        if not col in improved_cols:\n            continue\n        labels = np.sort(df[col].unique())\n        pred[: , i] = pd.cut(pred[:, i], [-np.inf] + bestcutting[i] + [np.inf], labels=labels)\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_bert(net_trained, test_dl):\n    net_trained.eval()\n    net_trained.cuda()\n\n    preds = []\n\n    for batch in test_dl:\n        token_ids = batch[0].cuda()\n        seg_ids = batch[1].cuda()\n        masks = batch[2].cuda()\n\n        with torch.set_grad_enabled(False):\n            outputs = net_trained(token_ids, token_type_ids=seg_ids, attention_mask=masks)\n            preds.append(torch.sigmoid(outputs).cpu())\n\n    return torch.cat(preds, 0).numpy()\n\ndef predict_xlnet(net_trained, test_dl):\n    net_trained.eval()\n    net_trained.cuda()\n\n    preds = []\n\n    for batch in test_dl:\n        token_ids = batch[0].cuda()\n        seg_ids = batch[1].cuda()\n        masks = batch[2].cuda()\n        cls_idx = batch[3].cuda()\n\n        with torch.set_grad_enabled(False):\n            outputs = net_trained(token_ids, token_type_ids=seg_ids, attention_mask=masks, cls_index=cls_idx)\n            preds.append(torch.sigmoid(outputs).cpu())\n\n    return torch.cat(preds, 0).numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor i in range(10): \n    net = build_model(model='bert')\n    net.load_state_dict(torch.load(f'../input/google-quest-bert-base-train/bert_fold{i+1}.pth'))\n    test_dl = get_test_loader(model='bert')\n    predictions.append(predict_bert(net, test_dl))\n    \nfor i in range(10): \n    net = build_model(model='xlnet')\n    net.load_state_dict(torch.load(f'../input/google-quest-xlnet-train/xlnet_fold{i+1}.pth'))\n    test_dl = get_test_loader(model='xlnet')\n    predictions.append(predict_xlnet(net, test_dl))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/google-quest-challenge/test.csv')\nn = df['url'].apply(lambda x:(('ell.stackexchange.com' in x) or ('english.stackexchange.com' in x))).tolist()\nspelling = []\nfor x in n:\n    if x:\n        spelling.append(0.5)\n    else:\n        spelling.append(0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[TARGET_COLS] = postprocess(np.mean(predictions, axis=0))\nsub['question_type_spelling'] = spelling\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}