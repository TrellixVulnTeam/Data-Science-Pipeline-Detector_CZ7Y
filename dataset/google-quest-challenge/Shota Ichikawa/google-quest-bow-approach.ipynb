{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://www.kaggle.com/c/google-quest-challenge/discussion/126778\n\nfrom scipy.stats import spearmanr\n\n\ndef mean_spearmanr_correlation_score(y, y_pred):\n    spearsum = 0\n    cnt = 0 \n    for col in range(y_pred.shape[1]):\n        v = spearmanr(y_pred[:,col], y[:,col]).correlation\n        if np.isnan(v):\n            continue\n        spearsum += v\n        cnt += 1\n    res = spearsum / cnt\n    return res","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")\ntest = pd.read_csv(\"../input/google-quest-challenge/test.csv\")\ntrain = pd.read_csv(\"../input/google-quest-challenge/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = [\n    'question_asker_intent_understanding',\n    'question_body_critical',\n    'question_conversational',\n    'question_expect_short_answer',\n    'question_fact_seeking',\n    'question_has_commonly_accepted_answer',\n    'question_interestingness_others',\n    'question_interestingness_self',\n    'question_multi_intent',\n    'question_not_really_a_question',\n    'question_opinion_seeking',\n    'question_type_choice',\n    'question_type_compare',\n    'question_type_consequence',\n    'question_type_definition',\n    'question_type_entity',\n    'question_type_instructions',\n    'question_type_procedure',\n    'question_type_reason_explanation',\n    'question_type_spelling',\n    'question_well_written',\n    'answer_helpful',\n    'answer_level_of_information',\n    'answer_plausible',\n    'answer_relevance',\n    'answer_satisfaction',\n    'answer_type_instructions',\n    'answer_type_procedure',\n    'answer_type_reason_explanation',\n    'answer_well_written'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(target_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stword=stopwords.words('english')\nmycorpus=[]\nps=PorterStemmer()\n#len(stword)\nfor i in range(0,len(train)):\n    try:\n        q_body= re.sub('[^a-zA-Z]',' ', train['question_body'][i])+re.sub('[^a-zA-Z]',' ', train['answer'][i])\n    except KeyError:\n        print(\"KeyError:\",i)\n    except TypeError:\n        print(\"TypeError\",i)\n    q_body=q_body.lower()\n    q_body=q_body.split()\n    q_body=[ps.stem(word) for word in q_body if not word in set(stword)]\n    q_body=' '.join(q_body)\n    mycorpus.append(q_body)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in target_columns:\n    try:\n        train[i]=pd.to_numeric(train[i],errors='coerce')\n    except ZeroDivisionError:\n        print('Error')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for i in target_columns:\n    #print(train[train[i].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test\nstword=stopwords.words('english')\nmycorpus_test=[]\nps=PorterStemmer()\n#len(stword)\nfor i in range(0,len(test)):\n    try:\n        q_body= re.sub('[^a-zA-Z]',' ', test['question_body'][i])+re.sub('[^a-zA-Z]',' ', test['answer'][i])\n    except KeyError:\n        print(\"KeyError:\",i)\n    except TypeError:\n        print(\"TypeError\",i)\n    q_body=q_body.lower()\n    q_body=q_body.split()\n    q_body=[ps.stem(word) for word in q_body if not word in set(stword)]\n    q_body=' '.join(q_body)\n    mycorpus_test.append(q_body)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q_body= re.sub('[^a-zA-Z]',' ', train['question_body'][0])\nq_body=q_body.lower()\nq_body=q_body.split()\nprint(q_body)\nprint(mycorpus[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer(max_features=14250,binary=True)\nX = cv.fit_transform(mycorpus).toarray()\ny_train = train[target_columns].copy()\ny_train=y_train.values\n\n#scaler=sklearn.preprocessing.StandardScaler()\n#scaler.fit(X)\n#X=scaler.transform(X)\n\n#print(X[6])\na=cv.get_feature_names()\n#a = pd.DataFrame(X)\n#a.head()\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cv_c = CountVectorizer(max_features =100)\nX_test=cv.transform(mycorpus_test).toarray()\nscaler=sklearn.preprocessing.StandardScaler()\nscaler.fit(X_test)\nX_test=scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RidgeCV\nridge_grid = RidgeCV(alphas=np.linspace(0.1, 20000.0, num=100)).fit(X, y_train)\nbest_Alpha = ridge_grid.alpha_\nbest_Alpha","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import KFold\nimport math\n\nn_splits = 5\n\nscores = []\nall_scores=[]\n\ncv_k = KFold(n_splits=n_splits, random_state=42)\ntrained_estimators = []\n\nfor train_idx, valid_idx in cv_k.split(X, y_train):\n    \n    x_train_train = X[train_idx]\n    y_train_train = y_train[train_idx]\n    x_train_valid = X[valid_idx]\n    y_train_valid = y_train[valid_idx]\n    \n    estimator = Ridge(alpha=best_Alpha, random_state=42)\n    #estimator = LogisticRegression()\n    estimator.fit(x_train_train, y_train_train)\n    trained_estimators.append(estimator)\n    \n    oof_part = estimator.predict(x_train_valid)\n    score = mean_spearmanr_correlation_score(y_train_valid, oof_part)\n    #score=estimator.score(x_train_valid, y_train_valid)\n    print('Score:', score)\n    scores.append(score)\n\n\nprint('Mean score:', np.mean(scores))\nall_scores.extend(scores)\n\n\ny_pred = []\nfor estimator in trained_estimators:\n    y_pred.append(estimator.predict(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = []\nfor estimator in trained_estimators:\n    y_pred.append(estimator.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(X_test[1][3000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len(trained_estimators)\n#y_pred[9][475]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_scores = sum(all_scores)\nweights = [x / sum_scores for x in all_scores]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import rankdata\n\n\ndef blend_by_ranking(data, weights):\n    out = np.zeros(data.shape[0])\n    for idx,column in enumerate(data.columns):\n        out += weights[idx] * rankdata(data[column].values)\n    out /= np.max(out)\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\", index_col='qa_id')\n\nout = pd.DataFrame(index=submission.index)\nfor column_idx,column in enumerate(target_columns):\n    \n    # collect all predictions for one column\n    column_data = pd.DataFrame(index=submission.index)\n    for prediction_idx,prediction in enumerate(y_pred):\n        column_data[str(prediction_idx)] = prediction[:, column_idx]\n    \n    out[column] = blend_by_ranking(column_data, weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}