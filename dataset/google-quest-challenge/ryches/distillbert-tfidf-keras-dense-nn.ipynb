{"cells":[{"metadata":{},"cell_type":"markdown","source":"Thanks to @abhishek for figuring out how to use huggingface with internet off. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/google-quest-challenge/train.csv\")\ntest = pd.read_csv(\"../input/google-quest-challenge/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/sacremoses/sacremoses-master/ > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.insert(0, \"../input/transformers/transformers-master/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport torch\nfrom transformers import *\nimport tqdm\ntokenizer = DistilBertTokenizer.from_pretrained(\"../input/distilbertbaseuncased/\")\nmodel = DistilBertModel.from_pretrained(\"../input/distilbertbaseuncased/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_body_ids = train[\"question_body\"].str.slice(0, 500).str.lower().apply(tokenizer.encode)\nquestion_body_ids_test = test[\"question_body\"].str.slice(0, 500).str.lower().apply(tokenizer.encode)\nquestion_body_vectors = []\nquestion_body_vectors_test = []\nfor question_body in tqdm.tqdm(question_body_ids):\n    input_ids = torch.Tensor(question_body).to(torch.int64).unsqueeze(0)\n    try:\n        outputs = model(input_ids.cuda())\n        question_body_vectors.append(outputs[0].detach().cpu().numpy().max(axis = 1))\n    except:\n        question_body_vectors.append(np.zeros(outputs[0].detach().cpu().numpy().max(axis = 1)).shape)\n    \nfor question_body in tqdm.tqdm(question_body_ids_test):\n    input_ids = torch.Tensor(question_body).to(torch.int64).unsqueeze(0)\n    try:\n        outputs = model(input_ids.cuda())\n        question_body_vectors_test.append(outputs[0].detach().cpu().numpy().max(axis = 1))\n    except:\n        question_body_vectors_test.append(np.zeros(outputs[0].detach().cpu().numpy().max(axis = 1)).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_title_ids = train[\"question_title\"].str.slice(0, 500).str.lower().apply(tokenizer.encode)\nquestion_title_ids_test = test[\"question_title\"].str.slice(0, 500).str.lower().apply(tokenizer.encode)\nquestion_title_vectors = []\nquestion_title_vectors_test = []\nfor question_title in tqdm.tqdm(question_title_ids):\n    input_ids = torch.Tensor(question_title).to(torch.int64).unsqueeze(0)\n    try:\n        outputs = model(input_ids.cuda())\n        question_title_vectors.append(outputs[0].detach().cpu().numpy().max(axis = 1))\n    except:\n        question_title_vectors.append(np.zeros(outputs[0].detach().cpu().numpy().max(axis = 1)).shape)\n    \nfor question_title in tqdm.tqdm(question_title_ids_test):\n    input_ids = torch.Tensor(question_title).to(torch.int64).unsqueeze(0)\n    try:\n        outputs = model(input_ids.cuda())\n        question_title_vectors_test.append(outputs[0].detach().cpu().numpy().max(axis = 1))\n    except:\n        question_title_vectors_test.append(np.zeros(outputs[0].detach().cpu().numpy().max(axis = 1)).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer_ids = train[\"answer\"].str.slice(0, 500).str.lower().apply(tokenizer.encode)\nanswer_ids_test = test[\"answer\"].str.slice(0, 500).str.lower().apply(tokenizer.encode)\nanswer_vectors = []\nanswer_vectors_test = []\nfor answer in tqdm.tqdm(answer_ids):\n    input_ids = torch.Tensor(answer).to(torch.int64).unsqueeze(0)\n    try:\n        outputs = model(input_ids.cuda())\n        answer_vectors.append(outputs[0].detach().cpu().numpy().max(axis = 1))\n    except:\n        answer_vectors.append(np.zeros(outputs[0].cpu().detach().numpy().max(axis = 1)).shape)\n    \nfor answer in tqdm.tqdm(answer_ids_test):\n    input_ids = torch.Tensor(answer).to(torch.int64).unsqueeze(0)\n    try:\n        outputs = model(input_ids.cuda())\n        answer_vectors_test.append(outputs[0].detach().cpu().numpy().max(axis = 1))\n    except:\n        answer_vectors_test.append(np.zeros(outputs[0].detach().cpu().numpy().max(axis = 1)).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(ngram_range=(1, 3))\ntsvd = TruncatedSVD(n_components = 50)\nquestion_title = tfidf.fit_transform(train[\"question_title\"].values)\nquestion_title_test = tfidf.transform(test[\"question_title\"].values)\nquestion_title = tsvd.fit_transform(question_title)\nquestion_title_test = tsvd.transform(question_title_test)\n\nquestion_body = tfidf.fit_transform(train[\"question_body\"].values)\nquestion_body_test = tfidf.transform(test[\"question_body\"].values)\nquestion_body = tsvd.fit_transform(question_body)\nquestion_body_test = tsvd.transform(question_body_test)\n\nanswer = tfidf.fit_transform(train[\"answer\"].values)\nanswer_test = tfidf.transform(test[\"answer\"].values)\nanswer = tsvd.fit_transform(answer)\nanswer_test = tsvd.transform(answer_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from gensim import utils\nfrom tqdm import tqdm\n# from gensim.models.keyedvectors import KeyedVectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import gc\n# def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n\n# def load_news(embed_dir = '../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin'):\n#     embeddings_index = KeyedVectors.load_word2vec_format(embed_dir, binary=True)\n#     emb_ind = {}\n#     for i, vec in tqdm(enumerate(embeddings_index.wv.vectors)):\n#         emb_ind[embeddings_index.wv.index2word[i]] = vec\n#     del embeddings_index\n#     gc.collect()\n#     return emb_ind","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vector_lookup = load_news()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# null_vector = vector_lookup[\"the\"]\n# def make_bov(sentence):\n#     sent_vec = np.zeros((300))\n#     sentence = sentence.split()\n#     sent_length = len(sentence)\n#     if sent_length == 0:\n#         sent_length = 1\n#     for word in sentence:\n#         try:\n#             sent_vec += vector_lookup[word.lower()]\n#         except:\n#             sent_vec += null_vector\n#     sent_vec /= sent_length\n#     return sent_vec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# question_title_bov = np.array([make_bov(sent) for sent in train[\"question_title\"].values])\n# question_title_bov_test = np.array([make_bov(sent) for sent in test[\"question_title\"].values])\n\n# question_bov = np.array([make_bov(sent) for sent in train[\"question_body\"].values])\n# question_bov_test = np.array([make_bov(sent) for sent in test[\"question_body\"].values])\n\n# answer_bov = np.array([make_bov(sent) for sent in train[\"answer\"].values])\n# answer_bov_test = np.array([make_bov(sent) for sent in test[\"answer\"].values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# question_title_len = np.array([len(sent.split()) + 1 for sent in train[\"question_title\"].values])[:, None]\n# question_title_len_test = np.array([len(sent.split()) + 1 for sent in test[\"question_title\"].values])[:, None]\n\n# question_len = np.array([len(sent.split()) + 1 for sent in train[\"question_body\"].values])[:, None]\n# question_len_test = np.array([len(sent.split()) + 1 for sent in test[\"question_body\"].values])[:, None]\n\n# answer_len = np.array([len(sent.split()) + 1 for sent in train[\"answer\"].values])[:, None]\n# answer_len_test = np.array([len(sent.split()) + 1 for sent in test[\"answer\"].values])[:, None]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# category_means_map = train.groupby(\"category\")[target_cols].mean().T.to_dict()\n# category_te = train[\"category\"].map(category_means_map).apply(pd.Series)\n# category_te_test = test[\"category\"].map(category_means_map).apply(pd.Series)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_features = np.concatenate([question_title, question_body, answer#, category_te.values\n#                                 ], axis = 1)\n# test_features = np.concatenate([question_title_test, question_body_test, answer_test#, category_te_test.values\n#                                ], axis = 1)\n\n# train_features = np.concatenate([question_title, question_body, answer,\n#                                 question_title_bov, question_bov, answer_bov,\n#                                  question_title_len, question_len, answer_len,\n#                                  #, category_te.values\n#                                 ], axis = 1)\n# test_features = np.concatenate([question_title_test, question_body_test, answer_test,\n#                                 question_title_bov_test, question_bov_test, answer_bov_test,\n#                                 question_title_len_test, question_len_test, answer_len_test,\n#                                 #, category_te_test.values\n#                                ], axis = 1)\n\n# train_features = np.array(question_body_vectors)[:, 0, :]\n# test_features = np.array(question_body_vectors_test)[:, 0, :]\n\n\ntrain_features = np.concatenate([question_title, question_body, answer,\n                                 np.array(question_body_vectors)[:, 0, :],\n                                np.array(question_title_vectors)[:, 0, :],\n                                np.array(answer_vectors)[:, 0, :]\n                               ], axis = 1)\ntest_features = np.concatenate([question_title_test, question_body_test, answer_test,\n                                np.array(question_body_vectors_test)[:, 0, :],\n                                np.array(question_title_vectors_test)[:, 0, :],\n                                np.array(answer_vectors_test)[:, 0, :]\n                               ], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom sklearn.model_selection import KFold\nfrom keras.callbacks.callbacks import EarlyStopping\nfrom scipy.stats import spearmanr\n\nnum_folds = 5\nfold_scores = []\nkf = KFold(n_splits = num_folds, shuffle = True, random_state = 42)\ntest_preds = np.zeros((len(test_features), len(target_cols)))\nfor train_index, val_index in kf.split(train_features):\n    train_X = train_features[train_index, :]\n    train_y = train[target_cols].iloc[train_index]\n    \n    val_X = train_features[val_index, :]\n    val_y = train[target_cols].iloc[val_index]\n    \n    model = Sequential([\n        Dense(2048, input_shape=(train_features.shape[1],)),\n        Activation('relu'),\n        Dense(1024),\n        Activation('relu'),\n        Dense(len(target_cols)),\n        Activation('sigmoid'),\n    ])\n    \n    es = EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy')\n    \n    model.fit(train_X, train_y, epochs = 50, validation_data=(val_X, val_y), callbacks = [es])\n    preds = model.predict(val_X)\n    overall_score = 0\n    for col_index, col in enumerate(target_cols):\n        overall_score += spearmanr(preds[:, col_index], val_y[col].values).correlation/len(target_cols)\n        print(col, spearmanr(preds[:, col_index], val_y[col].values).correlation)\n    fold_scores.append(overall_score)\n    print(overall_score)\n\n    test_preds += model.predict(test_features)/num_folds\n    \nprint(fold_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col_index, col in enumerate(target_cols):\n    sub[col] = test_preds[:, col_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}