{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/google-quest-challenge/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(PATH+'train.csv')\ntest = pd.read_csv(PATH+'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train.loc[:, 'qa_id':'host']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = train.loc[:, 'question_asker_intent_understanding':'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exclude useless columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train_x[['question_title','question_body','answer']]\ntest_x = test[['question_title','question_body','answer']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time for BERT"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow_hub as hub\nimport tensorflow as tf\nimport bert_tokenization as tokenization\nfrom tensorflow.keras.models import Model      \nimport tensorflow.keras.backend as K\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQ_LENGTH = 512\nBERT_PATH = '../input/bert-base-from-tfhub/bert_en_uncased_L-12_H-768_A-12'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bert model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(max_seq_length=MAX_SEQ_LENGTH,bert_path=BERT_PATH):\n    # BERT needs 3 inputs: ids, masks, segments     \n    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                           name=\"input_word_ids\")\n    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                       name=\"input_mask\")\n    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n                                        name=\"segment_ids\")\n    # pretrained BERT_base     \n    bert_layer = hub.KerasLayer(bert_path,\n                                trainable=True)\n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    \n    # Output layer for 30 classes to predict     \n    pooling = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n    dropout = tf.keras.layers.Dropout(0.2)(pooling)\n    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(dropout)\n\n    return Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preprocessing functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_masks(tokens, max_seq_length):\n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n\ndef get_segments(tokens, max_seq_length):\n    if len(tokens)>max_seq_length:\n        raise IndexError(\"Token length more than max seq length!\")\n    segments = []\n    current_segment_id = 0\n    first_sep = True\n    for token in tokens:\n        segments.append(current_segment_id)\n        if token == \"[SEP]\":\n            if first_sep:\n                first_sep = False \n            else:\n                current_segment_id = 1\n            \n    return segments + [0] * (max_seq_length - len(tokens))\n\ndef get_ids(tokens, tokenizer, max_seq_length):\n    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n    return input_ids\n\ndef trim_input(title, question, answer, max_sequence_length, \n                t_max_len=30, q_max_len=239, a_max_len=239):\n    \n    t_len,q_len,a_len = len(title),len(question),len(answer)\n\n    if (t_len+q_len+a_len+4) > max_sequence_length:\n        \n        if t_max_len <= t_len:\n            t_new_len = t_max_len\n        else:\n            t_new_len = t_len\n            a_max_len = a_max_len + math.floor((t_max_len - t_len)/2)\n            q_max_len = q_max_len + math.ceil((t_max_len - t_len)/2)            \n      \n        if a_max_len > a_len:\n            a_new_len = a_len \n            q_new_len = q_max_len + (a_max_len - a_len)\n        elif q_max_len > q_len:\n            a_new_len = a_max_len + (q_max_len - q_len)\n            q_new_len = q_len\n        else:\n            a_new_len = a_max_len\n            q_new_len = q_max_len            \n            \n        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n            raise ValueError(\"New sequence length should be %d, but is %d\" \n                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n            \n        title,question,answer = title[:t_new_len], question[:q_new_len], answer[:a_new_len]\n    \n    return title,question,answer\n\ndef get_inputs(title, question, answer, tokenizer,max_seq_length):\n    t = tokenizer.tokenize(title)\n    q = tokenizer.tokenize(question)\n    a = tokenizer.tokenize(answer)\n    t,q,a = trim_input(t, q, a,max_seq_length)\n    stokens = [\"[CLS]\"] + t + [\"[SEP]\"] + q + [\"[SEP]\"] + a + [\"[SEP]\"]\n\n    input_ids = get_ids(stokens, tokenizer, max_seq_length)\n    input_masks = get_masks(stokens, max_seq_length)\n    input_segments = get_segments(stokens, max_seq_length)\n    return input_ids,input_masks,input_segments\n\ndef compute_input_arays(df, tokenizer, max_sequence_length):\n    input_ids, input_masks, input_segments = [], [], []\n    for _, instance in df.iterrows():\n        t, q, a = instance.question_title, instance.question_body, instance.answer\n\n        ids, masks, segments = get_inputs(t, q, a, tokenizer, max_sequence_length)\n        input_ids.append(ids)\n        input_masks.append(masks)\n        input_segments.append(segments)\n        \n    return [np.asarray(input_ids, dtype=np.int32), \n            np.asarray(input_masks, dtype=np.int32), \n            np.asarray(input_segments, dtype=np.int32)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Callback for spearman calculation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_spearmanr(trues, preds):\n    rhos = []\n    for col_trues, col_pred in zip(trues.T, preds.T):\n        rhos.append(\n            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n    return np.mean(rhos)\n\n\nclass CustomCallback(tf.keras.callbacks.Callback):\n    \n    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n\n        self.valid_inputs = valid_data[0]\n        self.valid_outputs = valid_data[1]\n        self.test_inputs = test_data\n        \n        self.batch_size = batch_size\n        self.fold = fold\n        \n    def on_train_begin(self, logs={}):\n        self.valid_predictions = []\n        self.test_predictions = []\n        \n    def on_epoch_end(self, epoch, logs={}):\n        self.valid_predictions.append(\n            self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n        \n        rho_val = compute_spearmanr(\n            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n        \n        print(\"\\nvalidation rho: %.4f\" % rho_val)\n        \n        if self.fold is not None:\n            self.model.save_weights(f'bert-base-{fold}-{epoch}.h5py')\n        \n        self.test_predictions.append(\n            self.model.predict(self.test_inputs, batch_size=self.batch_size)\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_and_predict(model, train_data, valid_data, test_data, \n                      learning_rate, epochs, batch_size, loss_function, fold):\n        \n    custom_callback = CustomCallback(\n        valid_data=(valid_data[0], valid_data[1]), \n        test_data=test_data,\n        batch_size=batch_size)\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n    model.compile(loss=loss_function, optimizer=optimizer)\n    model.fit(train_data[0], train_data[1], epochs=epochs, \n              batch_size=batch_size, callbacks=[custom_callback])\n    \n    return custom_callback","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KFold"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GroupKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gkf = GroupKFold(n_splits=5).split(X=train_x.question_body, groups=train_x.question_body)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = tokenization.FullTokenizer(BERT_PATH + '/assets/vocab.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = compute_input_arays(train_x, tokenizer,MAX_SEQ_LENGTH)\ntest_inputs = compute_input_arays(test_x, tokenizer,MAX_SEQ_LENGTH)\noutputs = np.asarray(train_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"histories = []\nfor fold, (train_idx, valid_idx) in enumerate(gkf):\n    \n    # will actually only do 3 folds (out of 5) to manage < 2h\n    if fold < 3:\n        K.clear_session()\n        model = create_model()\n\n        train_inputs = [inputs[i][train_idx] for i in range(3)]\n        train_outputs = outputs[train_idx]\n\n        valid_inputs = [inputs[i][valid_idx] for i in range(3)]\n        valid_outputs = outputs[valid_idx]\n\n        # history contains two lists of valid and test preds respectively:\n        #  [valid_predictions_{fold}, test_predictions_{fold}]\n        history = train_and_predict(model, \n                          train_data=(train_inputs, train_outputs), \n                          valid_data=(valid_inputs, valid_outputs),\n                          test_data=test_inputs, \n                          learning_rate=3e-5, epochs=4, batch_size=8,\n                          loss_function='binary_crossentropy', fold=fold)\n\n        histories.append(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = [histories[i].test_predictions for i in range(len(histories))]\ntest_predictions = [np.average(test_predictions[i], axis=0) for i in range(len(test_predictions))]\ntest_predictions = np.mean(test_predictions, axis=0)\n\ndf_sub = pd.read_csv(PATH + 'sample_submission.csv')\n\ndf_sub.iloc[:, 1:] = test_predictions\n\ndf_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:kaggle-qa]","language":"python","name":"conda-env-kaggle-qa-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}