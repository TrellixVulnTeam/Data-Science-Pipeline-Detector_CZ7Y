{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Google QUEST Q&A Labeling\n\n**Improving automated understanding of complex question answer content**\n\n> Computers are really good at answering questions with single, verifiable answers. But, humans are often still better at answering questions about opinions, recommendations, or personal experiences.\n> ...\n> In this competition, youâ€™re challenged to use this new dataset to build predictive algorithms for different subjective aspects of question-answering.\n\n![](https://storage.googleapis.com/kaggle-media/competitions/google-research/human_computable_dimensions_1.png)\n\n\nThe competition is **Notebook-only competition**. Your Notebook will re-run automatically against an unseen test set.\n\nThis competition data is small, only made of 6079 rows of train dataset.<br/>\nSo I think this competition is **easy for beginners to participate** in terms of computational resource (unless you use BERT or any other heavy models to get good score), compared to the past competition hosted by Google like Open Image Challenges which requires a lot of GPU resources to train the model."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import gc\nimport os\nfrom pathlib import Path\nimport random\nimport sys\n\nfrom tqdm import tqdm_notebook as tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.core.display import display, HTML\n\n# --- plotly ---\nfrom plotly import tools, subplots\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\n# --- models ---\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data loading and data explanation"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\ndatadir = Path('/kaggle/input/google-quest-challenge')\n\n# Read in the data CSV files\ntrain = pd.read_csv(datadir/'train.csv')\ntest = pd.read_csv(datadir/'test.csv')\nsample_submission = pd.read_csv(datadir/'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check each data size.\n\nTrain and test data consists of 6079 rows and 476 rows respectively.<br/>\nWe have 30 different target labels to predict.<br/>\nRest 10 columns are given as feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train', train.shape)\nprint('test', test.shape)\nprint('sample_submission', sample_submission.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## target labels\n\nLet's check target labels at first.\n\nEach row is identified by question id: `qa_id`, and other 30 columns are target labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"30 target labels consist of 21 question related labels and 9 answer related labels.\n\nNOTE: the labels are given in the continuous range from [0, 1]. NOT binary value.\n\n> This is not a binary prediction challenge. Target labels are aggregated from multiple raters, and can have continuous values in the range [0,1]. Therefore, predictions must also be in that range."},{"metadata":{},"cell_type":"markdown","source":"## feature columns\n\nLet's check feature columns one by one."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = [col for col in train.columns if col not in sample_submission.columns]\nprint('Feature columns: ', feature_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each row contains question and answer information together with the original Q&A page URL of the StackExchange properties."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[feature_columns].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's focus on the first row of the data. You can access original page mentioned in the `url` column.\n\n - [https://photo.stackexchange.com/questions/9169/what-am-i-losing-when-using-extension-tubes-instead-of-a-macro-lens](https://photo.stackexchange.com/questions/9169/what-am-i-losing-when-using-extension-tubes-instead-of-a-macro-lens)\n \n \n Only the question contains \"title\" (`question_title`), and we have `question_body` and `answer` which is given by sentences."},{"metadata":{"trusted":true},"cell_type":"code","source":"train0 = train.iloc[0]\n\nprint('URL           : ', train0['url'])\nprint('question_title: ', train0['question_title'])\nprint('question_body : ', train0['question_body'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('answer        : ', train0['answer'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When you access to the URL, you can understand that multiple answer to the single question is given in the page. But only one answer is sampled in the dataset.\nAlso this answer may not be the most popular answer. We can find the answer of this data in the relatively bottom part of the homepage."},{"metadata":{},"cell_type":"markdown","source":"Other columns are metadata, which shows **question user** property, **answer user** property and **category** of question."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['url', 'question_user_name', 'question_user_page', 'answer_user_name', 'answer_user_page', 'url', 'category', 'host']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n\nLet's check each column of the data more carefully."},{"metadata":{},"cell_type":"markdown","source":"## target label distribution"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"target_cols = ['question_asker_intent_understanding',\n       'question_body_critical', 'question_conversational',\n       'question_expect_short_answer', 'question_fact_seeking',\n       'question_has_commonly_accepted_answer',\n       'question_interestingness_others', 'question_interestingness_self',\n       'question_multi_intent', 'question_not_really_a_question',\n       'question_opinion_seeking', 'question_type_choice',\n       'question_type_compare', 'question_type_consequence',\n       'question_type_definition', 'question_type_entity',\n       'question_type_instructions', 'question_type_procedure',\n       'question_type_reason_explanation', 'question_type_spelling',\n       'question_well_written', 'answer_helpful',\n       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n       'answer_satisfaction', 'answer_type_instructions',\n       'answer_type_procedure', 'answer_type_reason_explanation',\n       'answer_well_written']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train[target_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(6, 5, figsize=(18, 15))\naxes = axes.ravel()\nbins = np.linspace(0, 1, 20)\n\nfor i, col in enumerate(target_cols):\n    ax = axes[i]\n    sns.distplot(train[col], label=col, kde=False, bins=bins, ax=ax)\n    # ax.set_title(col)\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 6079])\nplt.tight_layout()\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems some of the labels are quite imbalanced. For example \"question_not_really_a_question\" is almost always 0, which means most of the question in the data is not a noisy data but an \"actual question\"."},{"metadata":{},"cell_type":"markdown","source":"## Nan values\n\nThere is no nan values in the data."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Category\n\nThe dataset consists of 5 categories: \"Technology\", \"Stackoverflow\", \"Culture\", \"Science\", \"Life arts\".<br/>\nTrain/Test distribution is almost same."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_category = train['category'].value_counts()\ntest_category = test['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\ntrain_category.plot(kind='bar', ax=axes[0])\naxes[0].set_title('Train')\ntest_category.plot(kind='bar', ax=axes[1])\naxes[1].set_title('Test')\nprint('Train/Test category distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word Cloud visualization\n\nLet's see what kind of word are used for question and answer. Also let's check the difference between train and test."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\n\ndef plot_wordcloud(text, ax, title=None):\n    wordcloud = WordCloud(max_font_size=None, background_color='white',\n                          width=1200, height=1000).generate(text_cat)\n    ax.imshow(wordcloud)\n    if title is not None:\n        ax.set_title(title)\n    ax.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Training data Word Cloud')\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 18))\n\ntext_cat = ' '.join(train['question_title'].values)\nplot_wordcloud(text_cat, axes[0], 'Question title')\n\ntext_cat = ' '.join(train['question_body'].values)\nplot_wordcloud(text_cat, axes[1], 'Question body')\n\ntext_cat = ' '.join(train['answer'].values)\nplot_wordcloud(text_cat, axes[2], 'Answer')\n\nplt.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Test data Word Cloud')\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 18))\n\ntext_cat = ' '.join(test['question_title'].values)\nplot_wordcloud(text_cat, axes[0], 'Question title')\n\ntext_cat = ' '.join(test['question_body'].values)\nplot_wordcloud(text_cat, axes[1], 'Question body')\n\ntext_cat = ' '.join(test['answer'].values)\nplot_wordcloud(text_cat, axes[2], 'Answer')\n\nplt.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems common word usage distribution is similar between train & test dataset!"},{"metadata":{},"cell_type":"markdown","source":"## Correlation in target labels\n\nI could find following 3 pairs are **correlated**:\n\n - \"question_type_instructions\" & \"answer_type_instructions\"\n - \"question_type_procedure\" & \"answer_type_procedure\"\n - \"question_type_reason_explanation\" & \"answer_type_reason_explanation\" \n\nThis is reasonable that same evaluation on both question & answer are correlated.\n\nOn the other hand, **Anticorrelation** pattern can be found on following pairs:\n\n - \"question_fact_seeking\" & \"question_opinion_seeking\"\n - \"answer_type_instruction\" & \"answer_type_reason_explanation\"\n\nI think this is also reasonable that question that asks fact & opinion conflicts.<br/>\nAnd answer which shows instruction or reason explanation also conflicts."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(train[target_cols].corr(), ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## User check\n\nThe dataset contains question user and answer user information. This may be because user attribution is impotant, same user tend to answer same kind of question and same answer user tends to answer in similar quality.\n\nLet's check if how the user are distributed, and the user are duplicated in train/test or not."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_question_user = train['question_user_name'].unique()\ntest_question_user = test['question_user_name'].unique()\n\nprint('Number of unique question user in train: ', len(train_question_user))\nprint('Number of unique question user in test : ', len(test_question_user))\nprint('Number of unique question user in both train & test : ', len(set(train_question_user) & set(test_question_user)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_answer_user = train['answer_user_name'].unique()\ntest_answer_user = test['answer_user_name'].unique()\n\nprint('Number of unique answer user in train: ', len(train_answer_user))\nprint('Number of unique answer user in test : ', len(test_answer_user))\nprint('Number of unique answer user in both train & test : ', len(set(train_answer_user) & set(test_answer_user)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems several users are in both train & test dataset.\n\nAlso, it seems many users ask question and answer."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Number of unique user in both question & anser in train  : ', len(set(train_answer_user) & set(train_question_user)))\nprint('Number of unique user in both question & anser in train  : ', len(set(test_answer_user) & set(test_question_user)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So these user information maybe important to predict `test` dataset!"},{"metadata":{},"cell_type":"markdown","source":"# Simple feature engineering\n\nNow, I will proceed simple feature engineering and check if it explains data well or not.\n\n - Number of words in question title, body and answer.\n - question_user's question count in train.\n - answer_user's answer count in train.\n \nWork in progress... Maybe I will write in another kernel..."},{"metadata":{},"cell_type":"markdown","source":"## Number of words"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def char_count(s):\n    return len(s)\n\ndef word_count(s):\n    return s.count(' ')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train['question_title_n_chars'] = train['question_title'].apply(char_count)\ntrain['question_title_n_words'] = train['question_title'].apply(word_count)\ntrain['question_body_n_chars'] = train['question_body'].apply(char_count)\ntrain['question_body_n_words'] = train['question_body'].apply(word_count)\ntrain['answer_n_chars'] = train['answer'].apply(char_count)\ntrain['answer_n_words'] = train['answer'].apply(word_count)\n\ntest['question_title_n_chars'] = test['question_title'].apply(char_count)\ntest['question_title_n_words'] = test['question_title'].apply(word_count)\ntest['question_body_n_chars'] = test['question_body'].apply(char_count)\ntest['question_body_n_words'] = test['question_body'].apply(word_count)\ntest['answer_n_chars'] = test['answer'].apply(char_count)\ntest['answer_n_words'] = test['answer'].apply(word_count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of chars and words in Question title**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\nsns.distplot(train['question_title_n_chars'], label='train', ax=axes[0])\nsns.distplot(test['question_title_n_chars'], label='test', ax=axes[0])\naxes[0].legend()\nsns.distplot(train['question_title_n_words'], label='train', ax=axes[1])\nsns.distplot(test['question_title_n_words'], label='test', ax=axes[1])\naxes[1].legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of chars and words in Question body**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(12, 6))\nsns.distplot(train['question_body_n_chars'], label='train', ax=axes[0])\nsns.distplot(test['question_body_n_chars'], label='test', ax=axes[0])\naxes[0].legend()\nsns.distplot(train['question_body_n_words'], label='train', ax=axes[1])\nsns.distplot(test['question_body_n_words'], label='test', ax=axes[1])\naxes[1].legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Outlier has too long, let's cut these outlier for visualization."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train['question_body_n_chars'].clip(0, 5000, inplace=True)\ntest['question_body_n_chars'].clip(0, 5000, inplace=True)\ntrain['question_body_n_words'].clip(0, 1000, inplace=True)\ntest['question_body_n_words'].clip(0, 1000, inplace=True)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\nsns.distplot(train['question_body_n_chars'], label='train', ax=axes[0])\nsns.distplot(test['question_body_n_chars'], label='test', ax=axes[0])\naxes[0].legend()\nsns.distplot(train['question_body_n_words'], label='train', ax=axes[1])\nsns.distplot(test['question_body_n_words'], label='test', ax=axes[1])\naxes[1].legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of chars and words in answer**\n\nAnswer number chars/words distribution is similar to question body."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train['answer_n_chars'].clip(0, 5000, inplace=True)\ntest['answer_n_chars'].clip(0, 5000, inplace=True)\ntrain['answer_n_words'].clip(0, 1000, inplace=True)\ntest['answer_n_words'].clip(0, 1000, inplace=True)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\nsns.distplot(train['answer_n_chars'], label='train', ax=axes[0])\nsns.distplot(test['answer_n_chars'], label='test', ax=axes[0])\naxes[0].legend()\nsns.distplot(train['answer_n_words'], label='train', ax=axes[1])\nsns.distplot(test['answer_n_words'], label='test', ax=axes[1])\naxes[1].legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Are these feature useful for predicting target values?<br/>\nLet's check correlation with target values."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import cdist\n\ndef calc_corr(df, x_cols, y_cols):\n    arr1 = df[x_cols].T.values\n    arr2 = df[y_cols].T.values\n    corr_df = pd.DataFrame(1 - cdist(arr2, arr1, metric='correlation'), index=y_cols, columns=x_cols)\n    return corr_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_feature_cols = ['question_title_n_chars', 'question_title_n_words', 'question_body_n_chars', 'question_body_n_words', 'answer_n_chars', 'answer_n_words']\n# train[number_feature_cols].corrwith(train[target_cols], axis=0)\n\ncorr_df = calc_corr(train, target_cols, number_feature_cols)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"corr_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(25, 5))\nsns.heatmap(corr_df, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see following relationship\n\n - length of answer is correlated with \"answer_level_of_information\".\n - length of question_title is correlated with \"question_body_critical\" and length of question body is anticorrelated with it.\n - length of question_body is anticorrelated with \"question_well_written\""},{"metadata":{},"cell_type":"markdown","source":"## Number of question or answer by user"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_question = train['question_user_name'].value_counts()\nnum_answer = train['answer_user_name'].value_counts()\n\ntrain['num_answer_user'] = train['answer_user_name'].map(num_answer)\ntrain['num_question_user'] = train['question_user_name'].map(num_question)\ntest['num_answer_user'] = test['answer_user_name'].map(num_answer)\ntest['num_question_user'] = test['question_user_name'].map(num_question)\n\n# # map is done by train data, we need to fill value for user which does not appear in train data...\n# test['num_answer_user'].fillna(1, inplace=True)\n# test['num_question_user'].fillna(1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"number_feature_cols = ['num_answer_user', 'num_question_user']\n# train[number_feature_cols].corrwith(train[target_cols], axis=0)\n\ncorr_df = calc_corr(train, target_cols, number_feature_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(30, 2))\nsns.heatmap(corr_df, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although correlation scale is small and it might not be a \"true correlation\", I can see following pattern:\n\n - `num_question_user` and `question_conversational` is correlated: People who post question a lot tend to ask question in conversational form."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's all for the start introduction of this competition!\n\n<h3 style=\"color:red\">If this kernel helps you, please upvote to keep me motivated :)<br>Thanks!</h3>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}