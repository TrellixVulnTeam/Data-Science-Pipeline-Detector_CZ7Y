{"cells":[{"metadata":{"_uuid":"ba4c1ed2-7e68-44bc-92b3-80f38cce8d70","_cell_guid":"0ea03263-2b16-42d3-90c4-467e147c5340","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nimport torch.optim as optim\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07fbfa5e-83f8-482c-bf1a-f09a0db72c75","_cell_guid":"d5bb27e3-e2c4-476a-9e42-e6dc970900cd","trusted":true},"cell_type":"code","source":"!pip install ../input/pytorchlightning/test_tube-0.7.5-py3-none-any.whl\n!pip install ../input/pytorchlightning/pytorch_lightning-0.5.3.2-py3-none-any.whl\n# !pip install transformers\n# !pip install pytorch_lightning","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48552dab-c29f-478e-a721-f659f97e5246","_cell_guid":"003d02e6-92b4-4558-a8cb-ed8ab26d1cb6","trusted":true},"cell_type":"code","source":"from collections import Counter\nimport spacy\nimport os\nfrom tqdm import tqdm, tqdm_notebook, tnrange\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d44c52ce-1f24-4b25-94ee-34468a5ec0fb","_cell_guid":"a13f5d14-b2dc-4591-90d4-a232773a540c","trusted":true,"scrolled":true},"cell_type":"code","source":"from transformers import *\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e471f4fc-5f2a-4903-a038-0691f31e974d","_cell_guid":"2a114e6b-9a04-49be-bf8a-d174c6c5bedd","trusted":true},"cell_type":"code","source":"targets = [\n        'question_asker_intent_understanding',\n        'question_body_critical',\n        'question_conversational',\n        'question_expect_short_answer',\n        'question_fact_seeking',\n        'question_has_commonly_accepted_answer',\n        'question_interestingness_others',\n        'question_interestingness_self',\n        'question_multi_intent',\n        'question_not_really_a_question',\n        'question_opinion_seeking',\n        'question_type_choice',\n        'question_type_compare',\n        'question_type_consequence',\n        'question_type_definition',\n        'question_type_entity',\n        'question_type_instructions',\n        'question_type_procedure',\n        'question_type_reason_explanation',\n        'question_type_spelling',\n        'question_well_written',\n        'answer_helpful',\n        'answer_level_of_information',\n        'answer_plausible',\n        'answer_relevance',\n        'answer_satisfaction',\n        'answer_type_instructions',\n        'answer_type_procedure',\n        'answer_type_reason_explanation',\n        'answer_well_written'    \n    ]\n\ninput_columns = ['question_title', 'question_body', 'answer']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d2b9b6a-eff1-4b4a-b82f-299ce10595a9","_cell_guid":"b72baf3d-5e1a-4042-a685-276db877287a","trusted":true},"cell_type":"code","source":"class VectorizeData(Dataset):\n    def __init__(self, df, maxlen=100):\n        self.maxlen = maxlen\n        self.df = df\n#         self.df['text_padded'] = self.df.vectorized.apply(lambda x: self.pad_data(x))\n        \n        self.tokenizer = BertTokenizer.from_pretrained(\"../input/bertbasepytorch/vocab.txt\")\n        self.targets = [\n        'question_asker_intent_understanding',\n        'question_body_critical',\n        'question_conversational',\n        'question_expect_short_answer',\n        'question_fact_seeking',\n        'question_has_commonly_accepted_answer',\n        'question_interestingness_others',\n        'question_interestingness_self',\n        'question_multi_intent',\n        'question_not_really_a_question',\n        'question_opinion_seeking',\n        'question_type_choice',\n        'question_type_compare',\n        'question_type_consequence',\n        'question_type_definition',\n        'question_type_entity',\n        'question_type_instructions',\n        'question_type_procedure',\n        'question_type_reason_explanation',\n        'question_type_spelling',\n        'question_well_written',\n        'answer_helpful',\n        'answer_level_of_information',\n        'answer_plausible',\n        'answer_relevance',\n        'answer_satisfaction',\n        'answer_type_instructions',\n        'answer_type_procedure',\n        'answer_type_reason_explanation',\n        'answer_well_written'    \n    ]\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        title = self.df.question_title.values[idx]\n        ques = self.df.question_body.values[idx]\n        ans = self.df.answer.values[idx]\n        \n        sent2idx = torch.tensor(self.tokenizer.encode(title+\" [SEP] \"+ques+\" [SEP] \"+ans, add_special_tokens=True)).unsqueeze(0)\n        sent2idx = sent2idx.reshape(-1)\n        sent2idx = self.pad_data(sent2idx)\n        \n        labelVect = torch.tensor([self.df.iloc[idx][x] for x in self.targets],requires_grad=False)\n        \n        return sent2idx,labelVect\n    \n    def pad_data(self, s):\n        padded = np.zeros((self.maxlen,), dtype=np.int64)\n        if len(s) > self.maxlen: padded[:] = s[:self.maxlen]\n        else: padded[:len(s)] = s\n        return padded","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"623889d6-18b3-43db-a196-36086efea785","_cell_guid":"ec4d614f-38ac-4af4-8f91-75c16703fe23","trusted":true},"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, df, maxlen=100):\n        self.maxlen = maxlen\n        self.df = df\n#         self.df['text_padded'] = self.df.vectorized.apply(lambda x: self.pad_data(x))\n        \n        self.tokenizer = BertTokenizer.from_pretrained(\"../input/bertbasepytorch/vocab.txt\")\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        title = self.df.question_title.values[idx]\n        ques = self.df.question_body.values[idx]\n        ans = self.df.answer.values[idx]\n        uniq_id = self.df['qa_id'].values[idx]\n        \n        sent2idx = torch.tensor(self.tokenizer.encode(title+\" [SEP] \"+ques+\" [SEP] \"+ans, add_special_tokens=True)).unsqueeze(0)\n        sent2idx = sent2idx.reshape(-1)\n        sent2idx = torch.tensor(self.pad_data(sent2idx))\n                \n        return uniq_id, sent2idx\n    \n    def pad_data(self, s):\n        padded = np.zeros((self.maxlen,), dtype=np.int64)\n        if len(s) > self.maxlen: padded[:] = s[:self.maxlen]\n        else: padded[:len(s)] = s\n        return padded","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06ce9b55-7658-479e-958a-8ecb96d4eab5","_cell_guid":"6a381f8c-cbbe-4816-95f0-2922b699d988","trusted":true},"cell_type":"code","source":"class BertGQA(pl.LightningModule):\n\n    def __init__(self):\n        super(BertGQA, self).__init__()\n\n        self.textEnc = BertModel.from_pretrained(\"../input/bertbasepytorch\")\n        self.tokenizer = BertTokenizer.from_pretrained(\"../input/bertbasepytorch/vocab.txt\")\n        self.fc = nn.Linear(768,30)\n        self.loss = nn.MSELoss()\n        self.sigm = nn.Sigmoid()\n        \n    def forward(self, x):\n        xVec = self.textEnc(x)[1]\n        \n        return self.sigm(self.fc(xVec))\n\n    def training_step(self, batch, batch_idx):\n        # REQUIRED\n        x, y = batch\n        y_hat = self.forward(x)\n        loss = self.loss(y_hat, y)\n        tensorboard_logs = {'train_loss': loss}\n        return {'loss': loss, 'log': tensorboard_logs}\n\n    def validation_step(self, batch, batch_idx):\n        # OPTIONAL\n        x, y = batch\n        y_hat = self.forward(x)\n        return {'val_loss': self.loss(y_hat, y)}\n\n    def validation_end(self, outputs):\n        # OPTIONAL\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        tensorboard_logs = {'val_loss': avg_loss}\n        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n        \n    def test_step(self, batch, batch_idx):\n        # OPTIONAL\n        x, y = batch\n        y_hat = self.forward(x)\n        return {'test_loss': self.loss(y_hat, y)}\n\n    def test_end(self, outputs):\n        # OPTIONAL\n        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n        tensorboard_logs = {'test_loss': avg_loss}\n        return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n\n    def configure_optimizers(self):\n        # REQUIRED\n        # can return multiple optimizers and learning_rate schedulers\n        # (LBFGS it is automatically supported, no need for closure function)\n        return torch.optim.Adam(self.fc.parameters(), lr=0.02)\n    \n    @pl.data_loader\n    def train_dataloader(self):\n        # REQUIRED\n        train = pd.read_csv('../input/google-quest-challenge/train.csv')\n        trainDataset = VectorizeData(train)\n        return DataLoader(dataset=trainDataset, batch_size=32, shuffle=True)\n\n    @pl.data_loader\n    def val_dataloader(self):\n#         # OPTIONAL\n        train = pd.read_csv('../input/google-quest-challenge/train.csv')\n        trainDataset = VectorizeData(train)\n        return DataLoader(dataset=trainDataset, batch_size=32, shuffle=True)\n        pass\n\n    @pl.data_loader\n    def test_dataloader(self):\n#         # OPTIONAL\n#         test =  pd.read_csv('./data/test.csv')\n        pass","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c5b2d8a-d83d-4592-91a1-2809d604202a","_cell_guid":"c802c2e4-43cc-41ba-ab6b-e15fe66269f5","trusted":true,"scrolled":true},"cell_type":"code","source":"model = BertGQA()\n\ntrainer = Trainer(min_nb_epochs=1, max_nb_epochs=1,gpus=1)\ntrainer.fit(model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a02fc9b-eaaa-4117-8351-a6c2bfdb8d7d","_cell_guid":"9d962fdf-f16d-45eb-9e14-481d12b4c20a","trusted":true},"cell_type":"code","source":"test =  pd.read_csv('../input/google-quest-challenge/test.csv')\ntestset = TestDataset(test)\ntestLoader = DataLoader(dataset=testset, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a30578fb-eb0c-49ca-9438-682f83f50f87","_cell_guid":"d2d7273f-3925-48e8-b8e8-f3315f78eebb","trusted":true},"cell_type":"markdown","source":"### Evaluation of Model"},{"metadata":{"_uuid":"c20fc40e-4e5e-41e4-a2e2-f698ffceffc4","_cell_guid":"ecf00ca6-3ad2-4476-9de5-407aaca7d2c7","trusted":true},"cell_type":"code","source":"results = []\n\nfor i, (idx,text) in enumerate(testLoader):\n    text = text.cuda()\n    out = model(text)\n    finallist = out.reshape(-1).tolist()\n    finallist = [x + 0.01 if x == 0 else x for x in finallist]\n    finallist = [x - 0.01 if x == 1 else x for x in finallist]\n    finallist = [x + np.random.uniform(0,0.001) for x in finallist]\n    results.append(finallist)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79f88a72-3cfa-4f7c-9cb2-2a7d559c00b8","_cell_guid":"3454b495-c01b-4899-9e2b-65af3a2cc7b4","trusted":true},"cell_type":"code","source":"# import csv\n\n# with open(\"./submission.csv\", \"w\", newline=\"\") as f:\n#     writer = csv.writer(f)\n#     writer.writerows(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaler = MinMaxScaler((0.01, 0.99))\n# results = scaler.fit_transform(results)\n# results.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34d8929a-3718-4520-86a7-07d76c7074e5","_cell_guid":"45aa03b6-bc75-459a-9fde-689a05b22626","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nsubmission_df = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')\nsubmission_df[targets] =  results\nsubmission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_file_name = 'submission.csv'\nsubmission_df.to_csv(sub_file_name, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}