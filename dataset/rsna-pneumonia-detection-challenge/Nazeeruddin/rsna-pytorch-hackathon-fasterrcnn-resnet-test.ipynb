{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#%%writefile test.py\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport re\nimport albumentations as A\nimport torch\nimport torchvision\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\nfrom PIL import Image\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nDIR_INPUT = '../input/rsna-pneumonia-detection-2018/input/images'\ndf = pd.read_csv(\"../input/rsna-pneumonia-detection-2018/input/stage_2_train_labels.csv\")\n#print(df.shape)\n#df.head()\n\ndf_pos = pd.DataFrame(columns=['patientId', 'x', 'y', 'width', 'height'])\n\nk = 0\ndf.loc[df['patientId']==\"00436515-870c-4b36-a041-de91049b9ab4\"]\nfor i in range(len(df)):\n    if df.loc[i]['Target'] == 1:\n        df_pos.loc[k] = df.loc[i]\n        k += 1\nimage_ids = df_pos['patientId'].unique()\n#print(image_ids)\nDIR_TEST = \"../input/rsna-pneumonia-detection-2018/input/images\"\nvalid_ids = image_ids[-300:]\nvalid_df = df_pos[df_pos['patientId'].isin(valid_ids)]\nprint(valid_df.head())\nprint(\"****************\",valid_df.shape)\ntest_images = os.listdir(DIR_TEST)\n#print(f\"Validation instances: {len(valid_ids)}\")\n\n# load a model; pre-trained on COCO\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, min_size=1024)\nnum_classes = 2  # 1 class (pnueomonia) + background\n# get the number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\nos.makedirs('../validation_predictions', exist_ok=True)\nmodel.load_state_dict(torch.load('../input/rsna-pytorch-hackathon-fasterrcnn-resnet-training/fasterrcnn_resnet50_fpn.pth'))\nmodel.to(device)\n\ndef format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], \n                                                             int(j[1][0]), int(j[1][1]), \n                                                             int(j[1][2]), int(j[1][3])))\n\n    return \" \".join(pred_strings)\n\ndetection_threshold = 0.9\nimg_num = 0\nresults = []\nmodel.eval()\nf, ax = plt.subplots(3,3, figsize=(16,18))\nimg = []\nwith torch.no_grad():\n    for i, image_s in tqdm(enumerate(image_ids)):\n        #print(i,image_s)\n        if i>100:\n            break\n        #orig_image = cv2.imread(f\"{DIR_TEST}/{test_images[i]}\", cv2.IMREAD_COLOR)\n        orig_image = cv2.imread(f\"{DIR_TEST}/{image_ids[i]}.jpg\", cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        image = np.transpose(image, (2, 0, 1)).astype(np.float)\n        image = torch.tensor(image, dtype=torch.float).cuda()\n        image = torch.unsqueeze(image, 0)\n\n        model.eval()\n        cpu_device = torch.device(\"cpu\")\n\n        outputs = model(image)\n        \n        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n        #print(outputs)\n        if len(outputs[0]['boxes']) != 0:\n            for counter in range(len(outputs[0]['boxes'])):\n                boxes = outputs[0]['boxes'].data.cpu().numpy()\n                scores = outputs[0]['scores'].data.cpu().numpy()\n                boxes = boxes[scores >= detection_threshold].astype(np.int32)\n                draw_boxes = boxes.copy()\n                boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n                boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n                \n            for box in draw_boxes:\n                img=cv2.rectangle(orig_image,\n                            (int(box[0]), int(box[1])),\n                            (int(box[2]), int(box[3])),\n                            (0, 0, 255), 3)\n\n            #print(\"**********start********\")\n            plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n            plt.axis('off')\n            \n            #plt.savefig(f\"./{image}.jpg\")\n            plt.close()\n\n            result = {\n                'patientId': image_s,\n                'PredictionString': format_prediction_string(boxes, scores),\n                'pred_cls': 1 if len(draw_boxes) >0 else 0,\n                'actual_cls': 1,\n            }\n            results.append(result)\n        else:\n            result = {\n                'patientId': image_s,\n                'PredictionString': None,\n                'pred_cls': 0,\n                'actual_cls': 1,\n            }\n            results.append(result)\n\n#print(results)\nsub_df = pd.DataFrame(results, columns=['patientId', 'PredictionString', 'pred_cls', 'actual_cls'])\nprint(sub_df)\n#sub_df.to_csv('submission.csv', index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T08:36:54.072053Z","iopub.execute_input":"2021-07-15T08:36:54.072505Z","iopub.status.idle":"2021-07-15T08:38:16.995623Z","shell.execute_reply.started":"2021-07-15T08:36:54.07247Z","shell.execute_reply":"2021-07-15T08:38:16.994344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndf_cm = confusion_matrix(sub_df['actual_cls'], sub_df['pred_cls'])\ntn, fp, fn, tp = confusion_matrix(sub_df['actual_cls'], sub_df['pred_cls']).ravel()\nprint(\"Accuracy : \",(tp+fp)/(tn+fp+fn+tp))\nsn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T08:44:14.906034Z","iopub.execute_input":"2021-07-15T08:44:14.906543Z","iopub.status.idle":"2021-07-15T08:44:15.456389Z","shell.execute_reply.started":"2021-07-15T08:44:14.906509Z","shell.execute_reply":"2021-07-15T08:44:15.455198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!python test.py","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-15T08:45:03.519393Z","iopub.execute_input":"2021-07-15T08:45:03.519808Z","iopub.status.idle":"2021-07-15T08:45:03.527343Z","shell.execute_reply.started":"2021-07-15T08:45:03.519773Z","shell.execute_reply":"2021-07-15T08:45:03.526322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}