{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Problem Statement:\n\nPneumonia is an infection in one or both lungs. Bacteria, viruses, and fungi cause it. The infection causes inflammation in the air sacs in your lungs, which are called alveoli.\n\nNow to detection Pneumonia we need to detect Inflammation of the lungs. In this project, youâ€™re challenged to build an algorithm to detect a visual signal for pneumonia in medical images. Specifically, your algorithm needs to automatically locate lung opacities on chest radiographs.\n\nBusiness Domain Value Automating Pneumonia screening in chest radiographs, providing affected area details through bounding box. Assist physicians to make better clinical decisions or even replace human judgement in certain functional areas of healthcare (eg, radiology).\n\nProject objective In this capstone project, the goal is to build a pneumonia detection system, to locate the position of inflammation in an image.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing all the standard libraries\n#..... array/martrix operations and dataframe libraries\nimport numpy as np\nimport pandas as pd\n#...........\n#.......... Visulaization libraries\nimport pydicom\nimport pylab\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nfrom skimage.transform import resize\n\n#......\nfrom sklearn.model_selection import train_test_split\n\n# NN model building linraries\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n#...................................................","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting path for each of the files\nclass_path='/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_detailed_class_info.csv'\nlabels_path='/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_labels.csv'\nImage_train_path='/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Files descrition\n#1. stage_2_detailed_class_info.csv- contains the information of target label\n#2. stage_2_train_labels.csv- contains information on Target and bounding box\n#3. stage_2_train_images- contains training images in dcm format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading class file (first file) as dataframe and check few entries and shape\ndf_class=pd.read_csv(class_path)\nprint(df_class.head(10))\nprint(df_class.shape[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observation:\n# This file ocntains patient Id and repective class ifnormation. \n#. There are 30277 records\n# There are three classes- \n#    1. Lung Opacity- Patient havinig pneumonia, \n#    2. Normal- Patient not having pnemonia and not having any other lung problem\n#    3. No Lung Opacity/Not Normal- Patient not having pnemonia but having any other lung problem","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Observation- There are no null values ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the number of unique entries with respect to patient ID\nprint(df_class['patientId'].value_counts().shape[0],'patient cases')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Reading label file (second file) as dataframe and check few entries and shape\ndf_label=pd.read_csv(labels_path)\nprint(df_label.head())\nprint(df_label.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observation\n#1. There are 30277 lables record (same as the class dataframe)\n#2. There are 6 columns - pateint ID (same as order as in class dataframe), bounding box co-ordinates, height and widht and Target label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets drop the duplicate cases\ndf=pd.concat([df_label,df_class.drop('patientId',1)],1)\nprint(df.shape)\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classes and Targets based on Patient count\ndf.groupby(['class','Target']).size().reset_index(name='patient_numbers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of duplicate entries accross rows:\\n', df[df.duplicated()].count())\nprint('Number of duplicate Patient Id entries :\\n', df[df.duplicated(subset='patientId')].count())\nprint('Number of unique Patient Id entries: \\n', df['patientId'].nunique())\nprint('Count of various classes: \\n',df.groupby('class')['patientId'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Observation\n#1. All the Normal and No Lung Opacity / Not Normal\tpatients are grouped under Target label 0 (no pnemonia)\n#2. Data Imabalance- there are ~30% pneumonia records and rest ~70% no pneumonia\n#3  There are no duplicates accross rows\n#4. Checking for duplicate patientId's, there are 26684 unique Patient Ids","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#--------------------------------------- Exploring training images data -------------------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# chekcing the type of image file format and total number of images\nimage_path='/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/'\nprint(os.listdir(image_path)[0])\nimport glob\nprint(len(list(glob.iglob(\"/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/*.dcm\", recursive=True))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Observations:\n# All the images are in dcm format \n# these image file saved in the Digital Imaging and Communications in Medicine (DICOM) image format. \n#It stores a medical image, such as a CT scan or ultrasound\n# There are in total 26684 images which matches with the unique patient IDs. Seems there is no missing image file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking sample image file for first entry in dataframe which is normal case\nprint(df.iloc[3])\npatientId = df['patientId'][3]\nimage_path_1='/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/%s.dcm' %patientId\ndcm_data=pydicom.read_file(image_path_1)\nprint(dcm_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Observations:\n# dcm file contains metadata information about Patient (sample with no pnemonia): \n#             name, ID, Age, Sex, body part examines, view position, pixel data of image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#size of image\ndcm_data.pixel_array.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#observations:\n#1. All the 26684 images have same size of 1024 X 1024","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the image \nplt.figure(figsize=(12,10))\nplt.subplot(121)\nplt.title('Pateint- Normal case class')\nplt.imshow(dcm_data.pixel_array)\nplt.subplot(122)\nplt.title('Pateint- Normal case class')\nplt.imshow(dcm_data.pixel_array,cmap=plt.cm.gist_gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#... Sample No Lung Opacity / Not Normal case ----------------\nprint(df.iloc[0])\npatientId = df['patientId'][0]\nimage_path_1='/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/%s.dcm' %patientId\ndcm_data=pydicom.read_file(image_path_1)\nprint(dcm_data)\n\n#Plotting the image \nplt.figure(figsize=(12,10))\nplt.subplot(121)\nplt.title('Pateint- No Lung Opacity / Not Normal case')\nplt.imshow(dcm_data.pixel_array)\nplt.subplot(122)\nplt.title('Pateint- No Lung Opacity / Not Normal case')\nplt.imshow(dcm_data.pixel_array,cmap=plt.cm.gist_gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets us plot one Patient with pnemonia (Target = 1)\nprint(df.iloc[4])\npatientId = df['patientId'][4]\nimage_path_1='/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/%s.dcm' %patientId\ndcm_data=pydicom.read_file(image_path_1)\nprint(dcm_data)\n#Plotting the image \nplt.figure(figsize=(12,10))\nplt.subplot(121)\nplt.title('Pateint- With pneumonia class')\nplt.imshow(dcm_data.pixel_array)\nplt.subplot(122)\nplt.title('Pateint- With pneumonia class')\nplt.imshow(dcm_data.pixel_array,cmap=plt.cm.gist_gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to show to a sample image with overlayed bounding box \ndef showImage(row):\n    \"\"\"\n    Method to draw single patient with bounding box(es) if present \n\n    \"\"\"\n    # --- Open DICOM file\n    imagePath = \"/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/{0}.dcm\".format(row['patientId'])\n    d = pydicom.read_file(imagePath)\n    image = d.pixel_array\n    image = np.stack([image] * 3, axis=2)\n\n    if row['Target'] == 1:        \n        image = drawbox(image=image, row=row)\n\n    plt.imshow(image, cmap=plt.cm.gist_gray)\n    \n    \ndef drawbox(image, row):\n    color = np.floor(np.random.rand(3) * 256).astype('int')\n    stroke=6\n  \n    # --- Extract coordinates\n    x1 = int(row['x'])\n    y1 = int(row['y'])\n    y2 = y1 + int(row['height'])\n    x2 = x1 + int(row['width'])\n    \n    #print(x1)\n    #print(x2)\n    #print(y1)\n    #print(y2)\n    \n    image[y1:y1 + stroke, x1:x2] = color\n    image[y2:y2 + stroke, x1:x2] = color\n    image[y1:y2, x1:x1 + stroke] = color\n    image[y1:y2, x2:x2 + stroke] = color\n\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#patient = labels_w_class.iloc[[10]]\npatient = list(df.T.to_dict().values())[4]\nprint(\"Path : stage_2_train_images/{0}.dcm\".format(patient['patientId']))\nprint(\"Target : {0}\".format(patient['Target']))\n\nplt.figure(figsize=(7,7))\nplt.title(\"Sample Patient - Lung Opacity\")\nshowImage(patient)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#----------------------------------------- Data generation for training, Model Building and training model-----","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to collect three major information (Patient ID, box and corresponding image file path) into a dictonary called parsed\nextract_boxes=lambda row: [ row['y'], row['x'], row ['height'], row['width']]\nparsed={}\nfor n, row in df.iterrows():\n    pid=row['patientId']\n    if pid not in parsed:\n        parsed[pid]={\n            'dicom': '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_train_images/%s.dcm' % pid,\n            'label': row['Target'],\n            'boxes':[]\n            }\n                 \n    if parsed[pid]['label']==1:\n        parsed[pid]['boxes'].append(extract_boxes(row))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(parsed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parsed[df['patientId'][7]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#............ function to get the images with bounbding box for any given Patient ID\ndef draw(data):\n#    \"\"\"\n#    Method to draw single patient with bounding box(es) if present \n\n#   \"\"\"\n    # --- Open DICOM file\n    d = pydicom.read_file(data['dicom'])\n    im = d.pixel_array\n\n    # --- Convert from single-channel grayscale to 3-channel RGB\n    im = np.stack([im] * 3, axis=2)\n\n    # --- Add boxes with random color if present\n    for box in data['boxes']:\n        rgb = np.floor(np.random.rand(3) * 256).astype('int')\n        im = overlay_box(im=im, box=box, rgb=rgb, stroke=6)\n\n    pylab.imshow(im, cmap=pylab.cm.gist_gray)\n    pylab.axis('off')\n\ndef overlay_box(im, box, rgb, stroke=1):\n    \"\"\"\n    Method to overlay single box on image\n\n    \"\"\"\n    # --- Convert coordinates to integers\n    box = [int(b) for b in box]\n    \n    # --- Extract coordinates\n    y1, x1, height, width = box\n    y2 = y1 + height\n    x2 = x1 + width\n\n    im[y1:y1 + stroke, x1:x2] = rgb\n    im[y2:y2 + stroke, x1:x2] = rgb\n    im[y1:y2, x1:x1 + stroke] = rgb\n    im[y1:y2, x2:x2 + stroke] = rgb\n\n    return im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# overalaping bounding box with image for sample pnemonia case\n#Plotting the image \nprint(df.iloc[4])\npatientId = df['patientId'][4]\ndraw(parsed[patientId])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n# empty dictionary\npneumonia_locations = {}\n# load table\nwith open(os.path.join(labels_path), mode='r') as infile:\n    # open reader\n    reader = csv.reader(infile)\n    # skip header\n    next(reader, None)\n    # loop through rows\n    for rows in reader:\n        # retrieve information\n        filename = rows[0]\n        location = rows[1:5]\n        pneumonia = rows[5]\n        # if row contains pneumonia add label to dictionary\n        # which contains a list of pneumonia locations per filename\n        if pneumonia == '1':\n            # convert string to float to int\n            location = [int(float(i)) for i in location]\n            # save pneumonia location in dictionary\n            if filename in pneumonia_locations:\n                pneumonia_locations[filename].append(location)\n            else:\n                pneumonia_locations[filename] = [location]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pneumonia_locations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load and shuffle filenames\nfolder = Image_train_path\nfilenames = os.listdir(folder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.transform import resize\nimport keras\nimport random\nclass generator(keras.utils.Sequence):\n    \n    def __init__(self, folder, filenames, pneumonia_locations=None, batch_size=32, image_size=256, shuffle=True, augment=False, predict=False):\n        self.folder = folder\n        self.filenames = filenames\n        self.pneumonia_locations = pneumonia_locations\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.shuffle = shuffle\n        self.augment = augment\n        self.predict = predict\n        self.on_epoch_end()\n        \n    def __load__(self, filename):\n        # load dicom file as numpy array\n        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n        # create empty mask\n        msk = np.zeros(img.shape)\n        # get filename without extension\n        filename = filename.split('.')[0]\n        # if image contains pneumonia\n        if filename in self.pneumonia_locations:\n            # loop through pneumonia\n            for location in self.pneumonia_locations[filename]:\n                # add 1's at the location of the pneumonia\n                x, y, w, h = location\n                msk[y:y+h, x:x+w] = 1\n        # resize both image and mask\n        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.5\n        # if augment then horizontal flip half the time\n        if self.augment and random.random() > 0.5:\n            img = np.fliplr(img)\n            msk = np.fliplr(msk)\n        # add trailing channel dimension\n        img = np.expand_dims(img, -1)\n        msk = np.expand_dims(msk, -1)\n        return img, msk\n    \n    def __loadpredict__(self, filename):\n        # load dicom file as numpy array\n        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n        # resize image\n        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n        # add trailing channel dimension\n        img = np.expand_dims(img, -1)\n        return img\n        \n    def __getitem__(self, index):\n        # select batch\n        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n        # predict mode: return images and filenames\n        if self.predict:\n            # load files\n            imgs = [self.__loadpredict__(filename) for filename in filenames]\n            # create numpy batch\n            imgs = np.array(imgs)\n            return imgs, filenames\n        # train mode: return images and masks\n        else:\n            # load files\n            items = [self.__load__(filename) for filename in filenames]\n            # unzip images and masks\n            imgs, msks = zip(*items)\n            # create numpy batch\n            imgs = np.array(imgs)\n            msks = np.array(msks)\n            return imgs, msks\n        \n    def on_epoch_end(self):\n        if self.shuffle:\n            random.shuffle(self.filenames)\n        \n    def __len__(self):\n        if self.predict:\n            # return everything\n            return int(np.ceil(len(self.filenames) / self.batch_size))\n        else:\n            # return full batches only\n            return int(len(self.filenames) / self.batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_downsample(channels, inputs):\n    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(x)\n    x = keras.layers.MaxPool2D(2)(x)\n    return x\n\ndef create_resblock(channels, inputs):\n    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n    return keras.layers.add([x, inputs])\n\ndef create_network(input_size, channels, n_blocks=2, depth=4):\n    # input\n    inputs = keras.Input(shape=(input_size, input_size, 1))\n    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)\n    #residual blocks\n    for d in range(depth):\n        channels = channels * 2\n        x = create_downsample(channels, x)\n        for b in range(n_blocks):\n            x = create_resblock(channels, x)\n    # output\n    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n    x = keras.layers.LeakyReLU(0)(x)\n    x = keras.layers.Conv2D(1, 1, activation='sigmoid')(x)\n    outputs = keras.layers.UpSampling2D(2**depth)(x)\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ndef iou_loss(y_true, y_pred):\n    y_true = tf.reshape(y_true, [-1])\n    y_pred = tf.reshape(y_pred, [-1])\n    intersection = tf.reduce_sum(y_true * y_pred)\n    score = (intersection + 1.) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)\n    return 1 - score\n\n# combine bce loss and iou loss\ndef iou_bce_loss(y_true, y_pred):\n    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)\n\n# mean iou as a metric\ndef mean_iou(y_true, y_pred):\n    y_pred = tf.round(y_pred)\n    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n    smooth = tf.ones(tf.shape(intersect))\n    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))\n\n# create network and compiler\nmodel = create_network(input_size=256, channels=32, n_blocks=2, depth=4)\nmodel.compile(optimizer='adam',\n              loss=iou_bce_loss,\n              metrics=['accuracy', mean_iou])\n\n# cosine learning rate annealing\ndef cosine_annealing(x):\n    lr = 0.001\n    epochs = 1\n    return lr*(np.cos(np.pi*x/epochs)+1.)/2\nlearning_rate = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[-1].output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from keras import backend as K\nsample= \n\ninp = model.input                                           # input placeholder\noutputs = model.layers[-1].output         # all layer outputs\nfunctors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n\n# Testing\nlayer_outs = [func([sample]) for func in functors]\nprint(layer_outs)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\ncheckpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n                             save_weights_only=True, mode=\"max\", period=1) # Checkpoint best validation model\n#stop = EarlyStopping(monitor=\"loss\", patience=PATIENCE, mode=\"max\") # Stop early, if the validation error deteriorates\n#reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=10, min_lr=1e-7, verbose=1, mode=\"max\")\n\n# create train and validation generators\n#folder = '../input/stage_1_train_images'\ntrain_gen = generator(folder, filenames, pneumonia_locations, batch_size=64, image_size=256, shuffle=True, augment=True, predict=False)\n#valid_gen = generator(folder, valid_filenames, pneumonia_locations, batch_size=32, image_size=256, shuffle=False, predict=False)\n\nhistory = model.fit_generator(train_gen, callbacks=[checkpoint], epochs=3, workers=4, use_multiprocessing=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nfrom skimage import measure\n\n\n# load and shuffle filenames\nfolder = '/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_test_images'\ntest_filenames = os.listdir(folder)\nprint('n test samples:', len(test_filenames))\n\n# create test generator with predict flag set to True\ntest_gen = generator(folder, test_filenames, None, batch_size=16, image_size=256, shuffle=False, predict=True)\n\n# create submission dictionary\nsubmission_dict = {}\n# loop through testset\nfor imgs, filenames in test_gen:\n    # predict batch of images\n    preds = model.predict(imgs)\n    # loop through batch\n    for pred, filename in zip(preds, filenames):\n        # resize predicted mask\n        pred = resize(pred, (1024, 1024), mode='reflect')\n        # threshold predicted mask\n        comp = pred[:, :, 0] > 0.5\n        # apply connected components\n        comp = measure.label(comp)\n        # apply bounding boxes\n        predictionString = ''\n        for region in measure.regionprops(comp):\n            # retrieve x, y, height and width\n            y, x, y2, x2 = region.bbox\n            height = y2 - y\n            width = x2 - x\n            # proxy for confidence score\n            conf = np.mean(pred[y:y+height, x:x+width])\n            # add to predictionString\n            predictionString += str(conf) + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + ' '\n        # add filename and predictionString to dictionary\n        filename = filename.split('.')[0]\n        submission_dict[filename] = predictionString\n    # stop if we've got them all\n    if len(submission_dict) >= len(test_filenames):\n        break\n        \nprint(\"Done predicting...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save dictionary as csv file\nsub = pd.DataFrame.from_dict(submission_dict,orient='index')\nsub.index.names = ['patientId']\nsub.columns = ['PredictionString']\nsub.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#----------------------------------------------------------------- RFCNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from __future__ import division\nimport random\nimport pprint\nimport sys\nimport time\nimport numpy as np\n#from optparse import OptionParser\nimport pickle\n\nfrom keras import backend as K\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.layers import Input\nfrom keras.models import Model\n\nimport sys\nsys.path.append('/kaggle/working/dt-keras-frcnn')\n\nfrom keras_frcnn import config, data_generators\nfrom keras_frcnn import losses as losses\nimport keras_frcnn.roi_helpers as roi_helpers\nfrom keras.utils import generic_utils","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"train_path = 'annotate.txt'\nparser = 'simple'\n\nnum_rois = 32\nnetwork = 'resnet50'\nhorizontal_flips = False\nvertical_flips =  False\nrot_90 = False\nnum_epochs = 2000\nconfig_filename = \"config.pickle\"\noutput_weight_path = './model_frcnn.hdf5'\n#input_weight_path = ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"train_path = 'annotate.txt'\nparser = 'simple'\n\nnum_rois = 32\nnetwork = 'resnet50'\nhorizontal_flips = False\nvertical_flips =  False\nrot_90 = False\nnum_epochs = 2000\nconfig_filename = \"config.pickle\"\noutput_weight_path = './model_frcnn.hdf5'\n#input_weight_path = ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}