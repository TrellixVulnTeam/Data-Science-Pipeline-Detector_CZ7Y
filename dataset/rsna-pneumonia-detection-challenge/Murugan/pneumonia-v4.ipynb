{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import the basic libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport skimage.io as io\nimport cv2\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.gridspec as gspec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydicom\nimport glob\nimport pylab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read the bounding box & target class dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasetDir = '../input/rsna-pneumonia-detection-challenge/'\n#datasetDir = '/Users/murugan/Repository/learn-ml/Great Lakes/datasets/pneumonia/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df = pd.read_csv(datasetDir + 'stage_2_train_labels.csv')\ntargets_df = pd.read_csv(datasetDir + 'stage_2_detailed_class_info.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df.isnull().values.any(), targets_df.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df.patientId.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df.sort_values('patientId')\ntargets_df.sort_values('patientId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df.shape, targets_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Total number of records in each dataframe are same as expected"},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df['patientId'].value_counts().shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Only 26684 records are unique out of the total 30227 records "},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df[bbox_df.Target == 1]['patientId'].value_counts().shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df[bbox_df.Target == 0]['patientId'].value_counts().shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df[bbox_df.Target == 0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_df['patientId'].value_counts().shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df.count().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are around 20672 records which are having null values for the bounding coordinates and remaining 9555 records associated with target 1 are having valie bounding box informations"},{"metadata":{},"cell_type":"markdown","source":"### Merge the bounding box details & target class dataset"},{"metadata":{},"cell_type":"markdown","source":"#### Now, as we have the dataset merge the bounding box details & targets dataframe together"},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_w_targets_df = pd.concat([bbox_df, targets_df.drop('patientId', axis=1)], axis=1)\nbbox_w_targets_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check the duplicate entries now against each patientId"},{"metadata":{},"cell_type":"markdown","source":"##### Even though the patientId's are same, they are having different/multiple bounding box co-ordinates. The x,y co-ordinates of the bounding boxes are not duplicated, so we can't remove them.\n\n- Multiple bounding boxes may indicate multiple area of pneumonia detected for a single patient"},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_w_targets_df.groupby(['class', 'Target']).size().reset_index(name='Count By Class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicateCounts_df = bbox_w_targets_df.groupby('patientId').size().reset_index(name='counts')\nduplicateCounts_df.groupby('counts').size().reset_index(name='Count By Duplicates')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 1 indicates that there are no duplicates rows for 23286 records.\n- 2 : Two entries associated for a single patient we have 3266 such patient records.\n- 3 : Three bounding boxes associated for 119 patient records.\n- 4 : Four bounding boxes are present fo very minimal number of patients. 13 exactly"},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicateCounts_df[duplicateCounts_df.counts == 4].sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Just refering a sample of one of the patient Id with 4 bounding boxes\nbbox_w_targets_df[bbox_w_targets_df.patientId == \n                  duplicateCounts_df[duplicateCounts_df.counts == 4].iloc[0].patientId]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merge the above row count entries also in our actual bbox dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_w_counts = pd.merge(bbox_w_targets_df, duplicateCounts_df, on='patientId')\nbbox_w_counts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Non Null Values Count: ', bbox_w_targets_df.x.notnull().sum())\nprint('Null Values Count: ', bbox_w_targets_df.x.isnull().sum())\nprint('Total Count: ', bbox_w_targets_df.x.notnull().sum() + bbox_w_targets_df.x.isnull().sum())\nprint(\"Null Values in % : {0} ({1:2.2f}%)\".format(bbox_w_targets_df.x.isnull().sum(), \n                                                  (bbox_w_targets_df.x.isnull().sum()/len(bbox_w_targets_df))*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18,5))\nfig.add_subplot(1, 3, 1)\np1 = sb.countplot(bbox_w_targets_df['Target'])\nfig.add_subplot(1, 3, 2)\np2 = sb.countplot(bbox_w_targets_df['class'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sb.countplot(bbox_w_targets_df['class'])\nax.set(title = 'Class Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_disc = bbox_w_targets_df['class'].value_counts()\nprint('Percentage of patients with No Long opacity/Not Normal : {:5d} or {:.2f}%'.format(class_disc[0],(class_disc[0]/bbox_w_targets_df['class'].count())*100))\nprint('Percentage of patients with Long opacity : {:5d} or {:.2f}% '.format(class_disc[1],(class_disc[1]/bbox_w_targets_df['class'].count())*100))\nprint('Percentage of patients with Normal : {:5d} or {:.2f}% '.format(class_disc[2],(class_disc[2]/bbox_w_targets_df['class'].count())*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read the CPR image data provided in dcm format"},{"metadata":{"trusted":true},"cell_type":"code","source":"dicom_img_dir = os.path.join(datasetDir, 'stage_2_train_images')\ndicom_img_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(dicom_img_dir)\nlen(filenames)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Total of 26684 images are present which is exactly equivalent to the unique patient id provided in the labels dataset"},{"metadata":{},"cell_type":"markdown","source":"### Read the dcm image metadata of a single patient file at first"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_dir = os.path.join(datasetDir,'stage_2_train_images')\ntest_images_dir = os.path.join(datasetDir,'stage_2_test_images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of Training images available are : {:5d}'.format(len(list(glob.iglob(train_images_dir + \"/*.dcm\", recursive=True)))))\nprint('Total number of Test images available are : {:5d}'.format(len(list(glob.iglob(test_images_dir + \"/*.dcm\", recursive=False)))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dcm_file = os.path.join(dicom_img_dir, filenames[0])\ndcm_file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pydicom.read_file(dcm_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The actual image of the CPR report is present in the last element tagged as Pixel data which is of array format.\n- All the remaining tags or elements are metadata providing additional details"},{"metadata":{"trusted":true},"cell_type":"code","source":"dcm_img = pydicom.read_file(dcm_file).pixel_array\ndcm_img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dcm_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dcm_img_3ch = np.stack([dcm_img]*3, -1)\ndcm_img_3ch.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,20))\nfig.add_subplot(1, 3, 1)\nplt.imshow(dcm_img)\nfig.add_subplot(1, 3, 2)\nplt.imshow(dcm_img_3ch)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's plot the bounding box on top of the CPR data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Bounding box from data sst and visualize the bounding box in image\ndef extract_data(dataset):\n    extract_bbox = lambda row: [row['y'], row['x'], row['height'], row['width']]\n    datacol = {}\n    index = 0\n    for n, row in dataset.iterrows():        \n        pid = row['patientId']\n        if pid not in datacol:\n            index = index+1\n            datacol[pid] = {\n                'dicom': train_images_dir + '/%s.dcm' % pid,\n                'label': row['Target'],\n                'boxes': [],\n                'index': index}\n            \n        if datacol[pid]['label'] == 1:\n            datacol[pid]['boxes'].append(extract_bbox(row))\n    return datacol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_data_dict = extract_data(bbox_w_targets_df)\nbbox_data_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select a patient Id with postive target value '1'\nsamplePatientId = bbox_df[bbox_df.Target == 1]['patientId'].iloc[0]\nsamplePatientId","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotBoundingBoxes(imgdata):\n    d = pydicom.read_file(imgdata['dicom'])\n    im = d.pixel_array    \n    im = np.stack([im] * 3, axis=2)\n    #Add boxes with random color if present\n    for box in imgdata['boxes']:\n        rgb = np.floor(np.random.rand(3) * 256).astype('int')\n        im = overlayBoudingBox(im=im, box=box, rgb=rgb, stroke=6)\n\n    pylab.imshow(im, cmap=pylab.cm.gist_gray)\n    pylab.axis('off')\n\ndef overlayBoudingBox(im, box, rgb, stroke=1):\n    #Convert coordinates to integers\n    box = [int(b) for b in box]\n    \n    #Extract coordinates\n    y1, x1, height, width = box\n    y2 = y1 + height\n    x2 = x1 + width\n\n    im[y1:y1 + stroke, x1:x2] = rgb\n    im[y2:y2 + stroke, x1:x2] = rgb\n    im[y1:y2, x1:x1 + stroke] = rgb\n    im[y1:y2, x2:x2 + stroke] = rgb\n    return im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotBoundingBoxes(bbox_data_dict[samplePatientId])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgdata = bbox_data_dict[samplePatientId]\nd = pydicom.read_file(imgdata['dicom'])\nim = d.pixel_array    \nim = np.stack([im] * 3, axis=2)\nfor box in imgdata['boxes']:\n    rgb = np.floor(np.random.rand(3) * 256).astype('int')\n    im = overlayBoudingBox(im=im, box=box, rgb=rgb, stroke=6)\npylab.imshow(im, cmap=pylab.cm.gist_gray)\npylab.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox_df[bbox_df.Target == 1].index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot some 5 random images from the dataset which are identified as Pneumonia positive"},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_positive_patientIds = random.sample(list(bbox_df[bbox_df.Target == 1].index), 1)\nrand_positive_patientIds\nfor i in rand_positive_patientIds:\n    print(bbox_df[bbox_df.index == i].patientId.iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rand_positive_index = random.sample(list(bbox_df[bbox_df.Target == 1].index), 5)\nfig = plt.figure()\nfig.set_figheight(25)\nfig.set_figwidth(25)\npltloc = 0\nfor randIndex in rand_positive_index:\n    pltloc += 1\n    patientId = bbox_df[bbox_df.index == randIndex].patientId.iloc[0]\n    a = fig.add_subplot(1, 5, pltloc)\n    a.set(title = 'Index:' + str(randIndex))\n    plotBoundingBoxes(bbox_data_dict[patientId])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare & Split the dataset as training & test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet import preprocess_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(bbox_data_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_DIM = 256","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for key, value in list(bbox_data_dict.items())[0:10]:\n    print(key, value['dicom'], value['label'], value['boxes'], value['index'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_count = math.ceil(10/100 * len(bbox_data_dict))\nsample_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ARRAY_DIM = int(sample_count+1)\n#TODO: Will process only the first 50/100 records initially\n#ARRAY_DIM = int(len(bbox_data_dict))\nmasks = np.zeros((ARRAY_DIM, IMAGE_DIM, IMAGE_DIM))\nX = np.zeros((ARRAY_DIM, IMAGE_DIM, IMAGE_DIM, 3))\nY = np.zeros((ARRAY_DIM, IMAGE_DIM, IMAGE_DIM))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def displayProcessedImageAndMask(imageIndex):\n    for key, value in list(bbox_data_dict.items())[(imageIndex-1):imageIndex]:\n        #print(key, value['dicom'], value['label'], value['boxes'], value['index'])\n        dcm_path = value['dicom']\n        dcm_data = pydicom.read_file(dcm_path)\n        img = dcm_data.pixel_array\n        mask = np.zeros(img.shape)\n        img = cv2.resize(img, dsize=(IMAGE_DIM, IMAGE_DIM), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n        fig = plt.figure(figsize=(20,20))\n        ax1 = fig.add_subplot(1, 3, 1)\n        ax1.set_title(\"Rezied Original Image\")\n        plt.imshow(img) \n        ax2 = fig.add_subplot(1, 3, 2)\n        ax2.set_title(\"Processed Input Image\")\n        plt.imshow(preprocess_input(np.array(img, dtype=np.float32)))\n        ax3 = fig.add_subplot(1, 3, 3)\n        ax3.set_title(\"Mask Layer\")\n        for boxes in value['boxes']:\n                x1, y1, w, h = boxes\n                y2 = y1 + h\n                x2 = x1 + w\n                mask[int(x1):int(x2), int(y1):int(y2)] = 1\n        plt.imshow(cv2.resize(mask, dsize=(IMAGE_DIM, IMAGE_DIM)))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"displayProcessedImageAndMask(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generateData(n=10):\n    for key, value in list(bbox_data_dict.items())[0:n]:\n        #print(key, value['dicom'], value['label'], value['boxes'], value['index'])\n        dcm_path = value['dicom']\n        index = value['index']\n        target = value['label']\n        dcm_data = pydicom.read_file(dcm_path)\n        img = dcm_data.pixel_array\n        mask = np.zeros(img.shape)\n        img = cv2.resize(img, dsize=(IMAGE_DIM, IMAGE_DIM), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n        X[index] = preprocess_input(np.array(img, dtype=np.float32))\n        for boxes in value['boxes']:\n            x1, y1, w, h = boxes\n            y2 = y1 + h\n            x2 = x1 + w\n            mask[int(x1):int(x2), int(y1):int(y2)] = 1\n        masks = cv2.resize(mask, dsize=(IMAGE_DIM, IMAGE_DIM))\n        Y[index] = masks\n    return X,Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generateData(sample_count)\nX.shape, Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data into training and validation dataset\nsplit_index = 10\nX_train = X[split_index:]\nX_valid = X[:split_index]\nY_train = Y[split_index:]\nY_valid = Y[:split_index]\nX_train.shape, X_valid.shape, Y_train.shape, Y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Concatenate, UpSampling2D, Conv2D, Reshape, Conv2DTranspose, Dropout, Lambda\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def iou_bce_loss(y_true, y_pred):\n    return 0.5 * binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean iou as a metric\ndef mean_iou(y_true, y_pred):\n    y_pred = tf.round(y_pred)    \n    intersect = tf.reduce_sum(y_true * y_pred, axis=[1])\n    union = tf.reduce_sum(y_true, axis=[1]) + tf.reduce_sum(y_pred, axis=[1])\n    smooth = tf.ones(tf.shape(intersect))\n    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - log(dice_coefficient(y_true, y_pred) + epsilon())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coefficient(y_true, y_pred):\n    numerator = 2 * tensorflow.reduce_sum(y_true * y_pred)\n    denominator = tensorflow.reduce_sum(y_true + y_pred)\n    return numerator / (denominator + epsilon())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define iou or jaccard loss function\ndef iou_loss(y_true, y_pred):\n    y_true = tf.reshape(y_true, [-1])\n    y_pred = tf.reshape(y_pred, [-1])\n    intersection = tf.reduce_sum(y_true * y_pred)\n    score = (intersection + 1.) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)\n    return 1 - score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(trainable=True):\n    model = MobileNet(input_shape=(IMAGE_DIM, IMAGE_DIM, 3), \n                      include_top=False, alpha=1, weights=\"imagenet\")\n\n    for layer in model.layers[:-20]:\n        layer.trainable = trainable\n\n    block1 = model.get_layer(\"conv1_relu\").output\n    block2 = model.get_layer(\"conv_pw_1_relu\").output\n    block3 = model.get_layer(\"conv_pw_3_relu\").output\n    block4 = model.get_layer(\"conv_pw_5_relu\").output\n    block5 = model.get_layer(\"conv_pw_11_relu\").output\n    block6 = model.get_layer(\"conv_pw_13_relu\").output\n\n    x = Concatenate()([UpSampling2D()(block6), block5])\n    x = Conv2D(100, (1, 1), activation='relu') (x)\n    x = Concatenate()([UpSampling2D()(x), block4])\n    x = Conv2D(100, (1, 1), activation='relu') (x)\n    x = Concatenate()([UpSampling2D()(x), block3])\n    x = Conv2D(100, (1, 1), activation='relu') (x)\n    x = Concatenate()([UpSampling2D()(x), block2])\n    x = Conv2D(100, (1, 1), activation='relu') (x)\n    x = Concatenate()([UpSampling2D()(x),UpSampling2D()(block1)])\n    x = Conv2D(1, kernel_size=1,strides=1, activation=\"sigmoid\")(x)\n    x = Reshape((256, 256,1))(x)\n    \n    return Model(inputs=model.input, outputs=x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Give trainable=False as argument, if you want to freeze lower layers for fast training (but low accuracy)\nmodel1 = create_model()\n\n# Print summary\nprint(model1.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the layer details of mobilenet and improve the Upsampling\nfor layer in model1.layers:\n    if('conv_pw' in layer.name and 'relu' in layer.name):\n        print(layer.name, layer.output_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel1.compile(optimizer=optimizer, loss=iou_bce_loss,  metrics=['accuracy', mean_iou])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n                             save_weights_only=True, mode=\"min\", save_freq=1)\nstop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\nreduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"min\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model1.fit(X_train, Y_train, validation_data = (X_valid, Y_valid), \n           epochs=10, batch_size=32, verbose=1, callbacks=[checkpoint, stop, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"PRED_DIM = int(1)\nX_test = np.zeros((PRED_DIM, IMAGE_DIM, IMAGE_DIM, 3))\nY_test = np.zeros((PRED_DIM, IMAGE_DIM, IMAGE_DIM))\nmask_pred = np.zeros((PRED_DIM, IMAGE_DIM, IMAGE_DIM))\ndef viewModelPrediction(n, model=model1):\n    for key, value in list(bbox_data_dict.items())[(n-1):n]:\n        #print(key, value['dicom'], value['label'], value['boxes'], value['index'])\n        dcm_path = value['dicom']\n        actul_target = value['label']\n        dcm_data = pydicom.read_file(dcm_path)\n        img = dcm_data.pixel_array\n        mask = np.zeros(img.shape)\n        img = cv2.resize(img, dsize=(IMAGE_DIM, IMAGE_DIM), interpolation=cv2.INTER_CUBIC)\n        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n        X_test[0] = preprocess_input(np.array(img, dtype=np.float32))\n        preds = model1.predict(X_test)\n        fig = plt.figure(figsize=(20,20))\n        ax1 = fig.add_subplot(1, 4, 1)\n        ax1.set_title(\"Rezied Original Image\")\n        plt.imshow(img) \n        ax2 = fig.add_subplot(1, 4, 2)\n        ax2.set_title(\"Processed Input Image\")\n        plt.imshow(preprocess_input(np.array(img, dtype=np.float32)))\n        ax3 = fig.add_subplot(1, 4, 3)\n        ax3.set_title(\"Mask Layer\")\n        for boxes in value['boxes']:\n                x1, y1, w, h = boxes\n                y2 = y1 + h\n                x2 = x1 + w\n                mask[int(x1):int(x2), int(y1):int(y2)] = 1\n        plt.imshow(cv2.resize(mask, dsize=(IMAGE_DIM, IMAGE_DIM)))\n        ax4 = fig.add_subplot(1, 4, 4)\n        ax4.set_title(\"Predicted Mask Layer\")\n        mask_pred = preds[0]\n        plt.imshow(cv2.resize(mask_pred, dsize=(IMAGE_DIM, IMAGE_DIM)))\n    plt.show()\n    \nviewModelPrediction(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"viewModelPrediction(8)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"for key, value in list(bbox_data_dict.items())[0:50]:\n    if(value['label'] == 1):\n        viewModelPrediction(value['index'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}