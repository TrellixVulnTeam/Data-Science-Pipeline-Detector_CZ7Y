{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os \nimport random \nimport pandas as pd \nimport glob\nimport pydicom\nimport torch \nimport numpy as np \nimport torchvision.transforms as transforms \nimport matplotlib.pyplot as plt\nimport torch.nn.functional as fun\nimport torch.optim as optim\nimport torch.nn as nn\nimport json\n\nfrom collections import OrderedDict\nfrom torchvision import datasets ,models\nfrom torch.utils.data.sampler import SubsetRandomSampler \nfrom torch.utils.data import Dataset\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"gpu=torch.cuda.is_available()\nif gpu : print(\"gpu\")\nelse : print(\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nos.chdir(\"../input/\")\nos.chdir('chest-xray-pneumonia')\nos.chdir('chest_xray')\nos.chdir('chest_xray')\ntest_dir='train'\ntrain_dir='/kaggle/input'\n#os.chdir('rsna-pneumonia-detection-challenge')\nprint(os.listdir(os.getcwd()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detailed_labels=pd.read_csv(\"/kaggle/input/rsna-pneumonia-detection-challenge/stage_2_detailed_class_info.csv\")\n# train_labels=pd.read_csv(\"stage_2_train_labels.csv\")\ntrain_dir=os.path.join('/kaggle/input/rsna-pneumonia-detection-challenge',\"stage_2_train_images\")\n# test_dir=os.path.join(os.getcwd(),'stage_2_test_images')\nprint(train_dir)\nprint(test_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dicom_fps(dicom_dir):\n    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n    return list(set(dicom_fps))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_dataset(dicom_dir, anns): \n    string=\"\"\n    image_fps = get_dicom_fps(dicom_dir)\n    image_annotations = {fp: string for fp in image_fps}\n    for index, row in anns.iterrows(): \n        if row['class']==\"No Lung Opacity / Not Normal\":\n            fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n            image_annotations.pop(fp)\n        else:    \n            fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n            if row['class']==\"Normal\":\n                image_annotations[fp]=(0)#row['Target']\n            else :\n                 image_annotations[fp]=(1)#row['Target']\n    return image_fps, image_annotations ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_fps,image_annotations=parse_dataset(train_dir,detailed_labels)\nprint(len(image_annotations))\n# print(image_annotations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keys=image_annotations.keys()\nprint(list(keys)[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RsnaDataset(Dataset):\n    \n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n        self.list_keys=list(data.keys())\n        \n    def __len__(self):\n        return len(self.data)\n    def transform(self,image):\n        return self.tansform(image)\n    \n    \n    def __getitem__(self, index):\n        # load image as ndarray type (Height * Width * Channels)\n        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n        # in this example, i don't use ToTensor() method of torchvision.transforms\n        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n        image = pydicom.read_file(self.list_keys[index]).pixel_array\n        #image=np.stack((image,)*3,axis=-1)\n#         print(\"inside dataset\",image.shape)\n       # image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((1, 28, 28))\n        label = torch.tensor(self.data[self.list_keys[index]])\n        \n        if self.transform is not None:\n            image = self.transform(image)\n#         print(\"inside dataset\",image.shape)    \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform=transforms.Compose([transforms.ToPILImage(),                           \n                              transforms.Resize(480),\n                              transforms.CenterCrop(240),\n                              transforms.ToTensor(),\n                              transforms.Normalize((0.5,),(0.5,)),\n#                               transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),   \n                             ])\ntest_transform=transforms.Compose([transforms.Grayscale(),                          \n                              transforms.Resize(480),\n                              transforms.CenterCrop(240),\n                              transforms.ToTensor(),\n                              transforms.Normalize((0.5,),(0.5,)),\n#                               transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)),   \n                             ])\n\ntrain_data=RsnaDataset(image_annotations,transform=transform)\ntest_data=datasets.ImageFolder(test_dir,transform=test_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=16\nvalid_size=0.2\n# test_size=0.05","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_trained=len(train_data)\nindices=list(range(num_trained))\nnp.random.shuffle(indices)\nvalid_split=int(np.floor(num_trained*valid_size))\n# test_split=int(np.floor(num_trained*test_size))\n# test_id=indices[:test_split]\nvalid_id=indices[:valid_split]\ntrain_id=indices[valid_split:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sampler=SubsetRandomSampler(train_id)\nvalid_sampler=SubsetRandomSampler(valid_id)\n# test_sampler=SubsetRandomSampler(test_id)\n\ntrain_Loader=torch.utils.data.DataLoader(train_data,sampler=train_sampler,\n                                       batch_size=batch_size,num_workers=0)\nvalid_Loader=torch.utils.data.DataLoader(train_data,sampler=valid_sampler,\n                                       batch_size=20,num_workers=0)\ntest_Loader=torch.utils.data.DataLoader(test_data,\n                                       batch_size=batch_size,num_workers=0)\n\nclasses = ['Normal','Pnemunia']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class Model(nn.Module):\n    \n#     def __init__(self):\n#         super(Model, self).__init__()\n#         self.conv1=nn.Conv2d(3, 22, kernel_size=(7,7),stride=(2, 2), padding=(3, 3), bias=False)\n        \n#         self.conv2=nn.Conv2d(22, 128, kernel_size=(7,7),stride=(2, 2), padding=(3, 3), bias=False)\n        \n#         #self.pool1=nn.MaxPool2d(2, 2)\n#         #\n#         self.conv3 = nn.Conv2d(128,128,kernel_size=(7,7),stride=(2,2),padding=(3,3),dilation=1,groups=128,bias=False)\n#         self.pointwise1 = nn.Conv2d(128,128,1,1,0,1,1,bias=False)\n        \n#         self.conv4 = nn.Conv2d(128,128,kernel_size=(7,7),stride=(2,2),padding=(3,3),dilation=1,groups=128,bias=False)\n#         self.pointwise2 = nn.Conv2d(128,256,1,1,0,1,1,bias=False)\n#         #\n#         #self.pool2=nn.MaxPool2d(2, 2)\n        \n#         self.batch1=nn.BatchNorm2d(num_features=256)\n        \n#         self.conv5 = nn.Conv2d(256,256,kernel_size=(7,7),stride=(2,2),padding=(3,3),dilation=1,groups=128,bias=False)\n#         self.pointwise3 = nn.Conv2d(256,256,1,1,0,1,1,bias=False)\n#         #\n#         self.batch2=nn.BatchNorm2d(num_features=256)\n        \n#         self.conv6 = nn.Conv2d(256,256,kernel_size=(7,7),stride=(2,2),padding=(3,3),dilation=1,groups=128,bias=False)\n#         self.pointwise4 = nn.Conv2d(256,512,1,1,0,1,1,bias=False)\n#         #\n#         #self.pool3=nn.MaxPool2d(2, 2)\n#         self.conv7 = nn.Conv2d(512,512,kernel_size=(7,7),stride=(2,2),padding=(3,3),dilation=1,groups=128,bias=False)\n#         self.pointwise5 = nn.Conv2d(512,512,1,1,0,1,1,bias=False)\n#         self.batch3=nn.BatchNorm2d(num_features=512)\n        \n#         self.conv8 = nn.Conv2d(512,512,kernel_size=(7,7),stride=(2,2),padding=(3,3),dilation=1,groups=128,bias=False)\n#         self.pointwise5 = nn.Conv2d(512,512,1,1,0,1,1,bias=False)\n        \n#         self.batch4=nn.BatchNorm2d(num_features=512)\n#         self.conv9 = nn.Conv2d(512,512,kernel_size=(7,7),stride=(2,2),padding=(3,3),dilation=1,groups=128,bias=False)\n        \n#         self.pointwise6 = nn.Conv2d(512,512,1,1,0,1,1,bias=False)\n#         self.batch4=nn.BatchNorm2d(num_features=512,eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        \n#         #self.pool4=nn.MaxPool2d(2, 2)\n        \n#         self.fc1=nn.Linear(1,2048)\n#         self.dropout=nn.Dropout(p=0.25)\n#         self.fc2=nn.Linear(2048,2)\n#         self.fc3=nn.Linear(2,2)\n#         self.softmax=nn.LogSoftmax(dim=1)\n        \n        \n    \n#     def forward(self,image):\n#         #first layer \n#         #print(image.size())\n#         image=self.conv1(image)\n#         image=f.relu(image)\n#         #second layer\n#         image=self.conv2(image)\n#         image=f.relu(image)\n#         #third layer\n#         #image=self.pool1(image)\n#         #fourth layer\n#         image = self.conv3(image)\n#         image = self.pointwise1(image)\n#         image=f.relu(image)\n#         #fifth_layer\n#         image = self.conv4(image)\n#         image = self.pointwise2(image)\n#         image=f.relu(image)\n        \n#         print(\"sixth layer\")\n#         #sixth layer\n#        # image=self.pool2(image)\n        \n#         image=self.batch1(image)\n        \n#         image = self.conv5(image)\n#         image = self.pointwise3(image)\n#         image=f.relu(image)\n        \n#         image=self.batch2(image)\n        \n#         image = self.conv6(image)\n#         image = self.pointwise4(image)\n#         image=f.relu(image)\n        \n#         #image=self.pool3(image)\n        \n#         image = self.conv7(image)\n#         image = self.pointwise5(image)\n#         image=f.relu(image)\n#         image=self.batch3(image)\n        \n#         image = self.conv8(image)\n#         image = self.pointwise5(image)\n#         image=f.relu(image)\n#         #image=self.batch4(image)\n#         #image=self.pool4(image)\n        \n#         image = self.conv9(image)\n#         image = self.pointwise6(image)\n#         image=f.relu(image)\n#         image=self.batch4(image)\n#         print(image.size())\n#         print(\"linear layers\")\n#         image=image.view(-1,1,512,16)\n#         image=self.fc1(image)\n#         print(image.size())\n#         print(\"after linear layer 1\")\n#         image=f.relu(image)\n#         print(image.size())\n#         image=self.dropout(image)\n#         print(image.size())\n#         image=self.fc2(image)\n#         print(image.size())\n#         image=self.fc3(image)\n#         print(image.size())\n#         print(\"after linear network\",image.size())\n#         image=f.relu(image)\n#         print(image.size())\n#         image=self.softmax(image)\n#         print(image.size())\n#         #print(\"before return \")\n#         return image\n      \n        \n# model= Model()\n# model  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.conv1=nn.Conv2d(1,32,3,padding=1)\n        #self.batch1=nn.BatchNorm2d(num_features=)\n        self.conv2=nn.Conv2d(32,64,3,padding=1)\n        self.conv3=nn.Conv2d(64,128,3,padding=1)\n        self.conv4=nn.Conv2d(128,256,3,padding=1)\n        self.conv5=nn.Conv2d(256,512,3,padding=1)\n        self.conv6=nn.Conv2d(512,1024,3,padding=1)\n        self.conv7=nn.Conv2d(1024,512,3,padding=1)\n        self.conv8=nn.Conv2d(512,256,3,padding=1)\n#         self.conv9=nn.Conv2d(2048,4096,3,padding=1)\n        self.pool=nn.MaxPool2d(2,2)\n        self.fc1=nn.Linear(256*30*30,128)\n        self.fc2=nn.Linear(128,2)\n        self.dropout=nn.Dropout(0.25)\n        self.softmax=nn.LogSoftmax(dim=1)\n    def forward (self,x):\n        x= fun.relu(self.conv1(x))\n#         print(x.size())\n        x= self.pool(fun.relu(self.conv2(x)))\n#         print(x.size())\n        x= fun.relu(self.conv3(x))\n#         print(x.size())\n        x= self.pool(fun.relu(self.conv4(x)))\n#         print(x.size())\n        x= fun.relu(self.conv5(x))\n#         print(x.size())\n        x= self.pool(fun.relu(self.conv6(x)))\n#         print(x.size())\n        x= fun.relu(self.conv7(x))\n#         print(x.size())\n        x= fun.relu(self.conv8(x))\n#         print(x.size())\n#         x= fun.relu(self.conv9(x))\n#         print(x.size())\n        x=x.view(-1,256*30*30)\n#         print(x.size())\n        x=self.dropout(x)\n#         print(x.size())\n        x=fun.relu(self.fc1(x))\n#         print(x.size())\n        x=self.dropout(x)\n#         print(x.size())\n        x=self.fc2(x)\n        x=self.softmax(x)\n        return x\n    \n \n\n\nmodel=Net()\nprint(model)\nif gpu:\n    model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classifier = nn.Sequential(OrderedDict([\n#                           ('fc1', nn.Linear(1024, 512)),\n#                           ('relu', nn.ReLU()),\n#                           ('dropout1', nn.Dropout(p=0.25)),\n#                           ('fc2', nn.Linear(512, 2)),\n#                           ('output', nn.LogSoftmax(dim=1))\n#                           ]))\n# model.classifier=classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#criterion=nn.NLLLoss()\n#criterion=nn.BCELoss()\ncriterion=nn.CrossEntropyLoss()\n# optimizer=optim.SGD(model.parameters(),lr=0.0001,momentum=0.9)\noptimizer = optim.Adam(model.parameters(),betas=(0.9, 0.999), lr=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\ntrain_data\nepochs=5\nvalid_min_loss=np.Inf\n\nfor epoch in range(1,epochs+1):\n    train_loss=0.0\n    valid_loss=0.0\n    \n    # train model \n    \n    model.train()\n    \n    for data,target in train_Loader:\n#         \n        if gpu: \n            \n            data=data.cuda()\n#             data=data.unsqueeze(0)\n           \n            target=target.cuda()\n#             print(target1.size())\n#             target=target.squeeze(0)\n            optimizer.zero_grad()\n            output=model(data)\n            #print(output.size())\n            #print(target[0])\n            loss=criterion(output,target)\n            loss.backward()\n            optimizer.step()\n            train_loss=loss.item()*data.size(0)\n            \n    \n    \n    #validate model \n    \n    model.eval()\n    for data,target in valid_Loader:\n        if gpu:\n            data=data.cuda()\n            target=target.cuda()\n        output=model(data)\n        loss=criterion(output,target)\n        valid_loss+=loss.item()*data.size(0)\n        \n    train_loss=train_loss/len(train_Loader.dataset)\n    valid_loss=valid_loss/len(valid_Loader.dataset)\n    \n    \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_min_loss:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_min_loss,\n        valid_loss))\n        torch.save(model.state_dict(), '/kaggle/working/new chest model1.pth')\n        valid_min_loss = valid_loss\n\n#torch.save(model.state_dict(), 'model_flower.pth')\nprint('end')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_dict=torch.load(\"/kaggle/working/new chest model1.pth\",map_location='cpu')\nmodel.load_state_dict(state_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss=0\nclass_correct=list(0. for i in range (2))\nclass_total=list(0. for i in range(2))\n\nmodel.eval\n\nfor data ,target in test_Loader:\n    if gpu:\n        data,target=data.cuda(),target.cuda()\n    #print(list(target.size())[0],target.size())\n    output=model(data)\n    loss=criterion(output,target)\n    test_loss +=loss.item()*data.size(0)\n    _,pred=torch.max(output,1)\n    correct_tensor=pred.eq(target.data.view_as(pred))\n    correct=np.squeeze(correct_tensor.numpy()) if not gpu else np.squeeze(correct_tensor.cpu().numpy())\n    \n    batch=16\n    if list(target.size())[0]==7: batch=6\n    \n    for i in range (batch):\n        #print(i)\n        label=target.data[i]\n        \n        class_correct[label]+=correct[i].item()\n        class_total[label]+=1\n        \ntest_loss = test_loss/len(test_Loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss=0\nclass_correct=list(0. for i in range (2))\nclass_total=list(0. for i in range(2))\nmodel.eval\n\nfor data ,target in train_Loader:\n    if gpu:\n        data,target=data.cuda(),target.cuda()\n    #print(list(target.size())[0],target.size())\n    output=model(data)\n    loss=criterion(output,target)\n    test_loss +=loss.item()*data.size(0)\n    _,pred=torch.max(output,1)\n    correct_tensor=pred.eq(target.data.view_as(pred))\n    correct=np.squeeze(correct_tensor.numpy()) if not gpu else np.squeeze(correct_tensor.cpu().numpy())\n    \n    batch=16\n    if list(target.size())[0]==7: batch=6\n    \n    for i in range (batch):\n        if correct.size<16 :\n            continue\n        label=target.data[i]\n      #  print(\"batch\",batch,\"label\",label,\"class_correct\",class_correct,\"target_size\",target.size(),\"correct\",correct)\n        class_correct[label]+=correct[i].item()\n        class_total[label]+=1\n        \ntest_loss = test_loss/len(test_Loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(2):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataiter=iter(test_Loader)\n\n# for i in range(1):\n\n#     images,labels=dataiter.next()\n#     images.numpy()\n\n#     if gpu :\n#         images=images.cuda()\n\n#     output=model(images)\n#     _,preds_tensor=torch.max(output,1)\n#     preds=np.squeeze(preds_tensor.numpy()) if not gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n#     fig=plt.figure(figsize=(50,50))\n\n#     for id in np.arange(1,16):\n#         photo=fig.add_subplot(2,20/2,id+1,xticks=[],yticks=[])\n#         images=images.cpu()\n#         imshow(images[id])\n\n#         photo.set_title(\"{} ({})\".format(classes[preds[id]], classes[labels[id].numpy()]),\n#                      color=(\"green\" if preds[id]==labels[id].item() else \"red\"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}