{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\nThe goal is to make a simple Keras model for predicting which category an image falls in","metadata":{"_uuid":"323f22eb85744ef15a54946a58a017e52942133e"}},{"cell_type":"code","source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T10:05:00.867434Z","iopub.execute_input":"2022-03-28T10:05:00.867755Z","iopub.status.idle":"2022-03-28T10:05:00.875479Z","shell.execute_reply.started":"2022-03-28T10:05:00.86768Z","shell.execute_reply":"2022-03-28T10:05:00.874716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params we will probably want to do some hyperparameter optimization later\nBASE_MODEL= 'InceptionV3' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\nIMG_SIZE = (224, 224) # [(224, 224), (384, 384), (512, 512), (640, 640)]\nBATCH_SIZE = 24 # [1, 8, 16, 24]\nDENSE_COUNT = 64 # [32, 64, 128, 256]\nDROPOUT = 0.20 # [0, 0.25, 0.5]\nLEARN_RATE = 4e-3 # [1e-4, 1e-3, 4e-3]\nTRAIN_SAMPLES = 3000 # [3000, 6000, 15000]\nTEST_SAMPLES = 800\nUSE_ATTN = False # [True, False]","metadata":{"_uuid":"b148e50a8ba9440c2b4ee582496dbf63608cb92c","execution":{"iopub.status.busy":"2022-03-28T10:05:01.044778Z","iopub.execute_input":"2022-03-28T10:05:01.045094Z","iopub.status.idle":"2022-03-28T10:05:01.050786Z","shell.execute_reply.started":"2022-03-28T10:05:01.045037Z","shell.execute_reply":"2022-03-28T10:05:01.049866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_bbox_df = pd.read_csv('../input/lung-opacity-overview/image_bbox_full.csv')\nimage_bbox_df['path'] = image_bbox_df['path'].map(lambda x: \n                                                  x.replace('input', \n                                                            'input/rsna-pneumonia-detection-challenge'))\nprint(image_bbox_df.shape[0], 'images')\nimage_bbox_df.sample(3)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-03-28T10:05:01.210215Z","iopub.execute_input":"2022-03-28T10:05:01.210548Z","iopub.status.idle":"2022-03-28T10:05:01.348282Z","shell.execute_reply.started":"2022-03-28T10:05:01.210488Z","shell.execute_reply":"2022-03-28T10:05:01.347445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the labels in the right format\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nclass_enc = LabelEncoder()\nimage_bbox_df['class_idx'] = class_enc.fit_transform(image_bbox_df['class'])\noh_enc = OneHotEncoder(sparse=False)\nimage_bbox_df['class_vec'] = oh_enc.fit_transform(\n    image_bbox_df['class_idx'].values.reshape(-1, 1)).tolist() \nimage_bbox_df.sample(3)","metadata":{"_uuid":"f4925492adb4f55f01794709cb751a42ca5c2177","execution":{"iopub.status.busy":"2022-03-28T10:05:01.349773Z","iopub.execute_input":"2022-03-28T10:05:01.350224Z","iopub.status.idle":"2022-03-28T10:05:01.584649Z","shell.execute_reply.started":"2022-03-28T10:05:01.35017Z","shell.execute_reply":"2022-03-28T10:05:01.583893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split into Training and Validation\nThis will give us some feedback on how well our model is doing and if we are overfitting","metadata":{"_uuid":"b562636a2a48a0557fb16d98841fcbf650245641"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimage_df = image_bbox_df.groupby('patientId').apply(lambda x: x.sample(1))\nraw_train_df, valid_df = train_test_split(image_df, test_size=0.25, random_state=2018,\n                                    stratify=image_df['class'])\nprint(raw_train_df.shape, 'training data')\nprint(valid_df.shape, 'validation data')","metadata":{"_uuid":"c12bfd5115610163c2b63ece8fa8845bb7792327","execution":{"iopub.status.busy":"2022-03-28T10:05:01.586332Z","iopub.execute_input":"2022-03-28T10:05:01.586825Z","iopub.status.idle":"2022-03-28T10:05:35.710493Z","shell.execute_reply.started":"2022-03-28T10:05:01.586775Z","shell.execute_reply":"2022-03-28T10:05:35.709486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Balance Training Set\nAnd reduce the total image count","metadata":{"_uuid":"71c22947c5007a28627b41af14ee8a7f2e990174"}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\nraw_train_df.groupby('class').size().plot.bar(ax=ax1)\ntrain_df = raw_train_df.groupby('class')\ntrain_df = train_df.apply(lambda x: x.sample(TRAIN_SAMPLES//3))\ntrain_df = train_df.reset_index(drop=True)\ntrain_df.groupby('class').size().plot.bar(ax=ax2) \nprint(train_df.shape[0], 'new training size')","metadata":{"_uuid":"48b8d60f4435d3ca50d11e12d4eee518c6972ab5","execution":{"iopub.status.busy":"2022-03-28T10:05:35.712144Z","iopub.execute_input":"2022-03-28T10:05:35.712414Z","iopub.status.idle":"2022-03-28T10:05:36.281359Z","shell.execute_reply.started":"2022-03-28T10:05:35.71237Z","shell.execute_reply":"2022-03-28T10:05:36.28071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Keras Image Transplantation\nSince Keras is design for color jpeg images we need to hack a bit to make it dicom friendly","metadata":{"_uuid":"e9b274bfc403678cd6428b8d245bcb1a08fa0808"}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras","metadata":{"execution":{"iopub.status.busy":"2022-03-28T10:05:36.283425Z","iopub.execute_input":"2022-03-28T10:05:36.283739Z","iopub.status.idle":"2022-03-28T10:05:36.288068Z","shell.execute_reply.started":"2022-03-28T10:05:36.283664Z","shell.execute_reply":"2022-03-28T10:05:36.287315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport timeit\n\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T10:05:36.290486Z","iopub.execute_input":"2022-03-28T10:05:36.290976Z","iopub.status.idle":"2022-03-28T10:05:36.30342Z","shell.execute_reply.started":"2022-03-28T10:05:36.290924Z","shell.execute_reply":"2022-03-28T10:05:36.302491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        try:\n            # keras 2.2\n            import keras_preprocessing.image as KPImage\n        except:\n            # keras 2.1\n            import keras.preprocessing.image as KPImage\n\n        from PIL import Image\n        import pydicom\n        def read_dicom_image(in_path):\n            img_arr = pydicom.read_file(in_path).pixel_array\n            return img_arr/img_arr.max()\n\n        class medical_pil():\n            @staticmethod\n            def open(in_path):\n                if '.dcm' in in_path:\n                    c_slice = read_dicom_image(in_path)\n                    int_slice =  (255*c_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n                    return Image.fromarray(int_slice)\n                else:\n                    return Image.open(in_path)\n            fromarray = Image.fromarray\n        KPImage.pil_image = medical_pil\nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"9548edfc1a318edfcd2a387468a5b7950a376cc5","execution":{"iopub.status.busy":"2022-03-28T10:05:36.304306Z","iopub.execute_input":"2022-03-28T10:05:36.304587Z","iopub.status.idle":"2022-03-28T10:05:36.314366Z","shell.execute_reply.started":"2022-03-28T10:05:36.304542Z","shell.execute_reply":"2022-03-28T10:05:36.313582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\nHere we can perform simple augmentation (the `imgaug` and `Augmentation` packages offer much more flexiblity). In order to setup the augmentation we need to know which model we are using","metadata":{"_uuid":"a0d2ca01b3719e94212234b9d3e4ed43520262eb"}},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        \n        from keras.preprocessing.image import ImageDataGenerator\n        if BASE_MODEL=='VGG16':\n            from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n        elif BASE_MODEL=='RESNET52':\n            from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n        elif BASE_MODEL=='InceptionV3':\n            from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n        elif BASE_MODEL=='Xception':\n            from keras.applications.xception import Xception as PTModel, preprocess_input\n        elif BASE_MODEL=='DenseNet169': \n            from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n        elif BASE_MODEL=='DenseNet121':\n            from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n        else:\n            raise ValueError('Unknown model: {}'.format(BASE_MODEL))\n    \nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"b655a151895a67cb66b41ccf0bf97c5cd80cc0f2","execution":{"iopub.status.busy":"2022-03-28T10:05:36.31567Z","iopub.execute_input":"2022-03-28T10:05:36.316242Z","iopub.status.idle":"2022-03-28T10:05:36.326911Z","shell.execute_reply.started":"2022-03-28T10:05:36.316184Z","shell.execute_reply":"2022-03-28T10:05:36.326156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'): \n        img_gen_args = dict(samplewise_center=False, \n                                      samplewise_std_normalization=False, \n                                      horizontal_flip = True, \n                                      vertical_flip = False, \n                                      height_shift_range = 0.05, \n                                      width_shift_range = 0.02, \n                                      rotation_range = 3, \n                                      shear_range = 0.01,\n                                      fill_mode = 'nearest',\n                                      zoom_range = 0.05,\n                                       preprocessing_function=preprocess_input)\n        img_gen = ImageDataGenerator(**img_gen_args)\nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"a068b664c8bb465938fa3974c7b6e6120bf0860e","execution":{"iopub.status.busy":"2022-03-28T10:05:36.327742Z","iopub.execute_input":"2022-03-28T10:05:36.327999Z","iopub.status.idle":"2022-03-28T10:05:36.337528Z","shell.execute_reply.started":"2022-03-28T10:05:36.327916Z","shell.execute_reply":"2022-03-28T10:05:36.336849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, seed = None, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways: seed: {}'.format(seed))\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                              seed = seed,\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values,0)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","metadata":{"_uuid":"9a3983f1be91084ba8c04441280efb18290814f2","execution":{"iopub.status.busy":"2022-03-28T10:05:36.338356Z","iopub.execute_input":"2022-03-28T10:05:36.338643Z","iopub.status.idle":"2022-03-28T10:05:36.349604Z","shell.execute_reply.started":"2022-03-28T10:05:36.3386Z","shell.execute_reply":"2022-03-28T10:05:36.348958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        train_gen = flow_from_dataframe(img_gen, train_df, \n                                     path_col = 'path',\n                                    y_col = 'class_vec', \n                                    target_size = IMG_SIZE,\n                                     color_mode = 'rgb',\n                                    batch_size = BATCH_SIZE)\n\n        valid_gen = flow_from_dataframe(img_gen, valid_df, \n                                     path_col = 'path',\n                                    y_col = 'class_vec', \n                                    target_size = IMG_SIZE,\n                                     color_mode = 'rgb',\n                                    batch_size = 256) # we can use much larger batches for evaluation\nexcept RuntimeError as e:\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T10:05:36.350321Z","iopub.execute_input":"2022-03-28T10:05:36.350565Z","iopub.status.idle":"2022-03-28T10:06:10.034357Z","shell.execute_reply.started":"2022-03-28T10:05:36.350521Z","shell.execute_reply":"2022-03-28T10:06:10.033486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        # used a fixed dataset for evaluating the algorithm\n        valid_X, valid_Y = next(flow_from_dataframe(img_gen, \n                                    valid_df, \n                                    path_col = 'path',\n                                    y_col = 'class_vec', \n                                    target_size = IMG_SIZE,\n                                     color_mode = 'rgb',\n                                    batch_size = TEST_SAMPLES)) # one big batch\nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"720a67aaa3a8f4c9d5d50752c3f18f4e54dc3af0","execution":{"iopub.status.busy":"2022-03-28T10:06:10.035675Z","iopub.execute_input":"2022-03-28T10:06:10.036143Z","iopub.status.idle":"2022-03-28T10:06:32.89168Z","shell.execute_reply.started":"2022-03-28T10:06:10.036089Z","shell.execute_reply":"2022-03-28T10:06:32.890863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show a batch\nHere we see what the augmentation actually looks like on a few sample images","metadata":{"_uuid":"085cf677a4704dce34c679958674a84469e2ef4f"}},{"cell_type":"code","source":"t_x, t_y = next(train_gen)\nprint(t_x.shape, t_y.shape)\nfig, m_axs = plt.subplots(3, 4, figsize = (16, 8))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    c_ax.set_title('%s' % class_enc.classes_[np.argmax(c_y)])\n    c_ax.axis('off')","metadata":{"_uuid":"37c9b66822c5dd59162813909c31d384db881026","execution":{"iopub.status.busy":"2022-03-28T10:06:32.897431Z","iopub.execute_input":"2022-03-28T10:06:32.897869Z","iopub.status.idle":"2022-03-28T10:06:34.929266Z","shell.execute_reply.started":"2022-03-28T10:06:32.897682Z","shell.execute_reply":"2022-03-28T10:06:34.928508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build our pretrained model\nHere we build the pretrained model and download the weights","metadata":{"_uuid":"f273320778cca1188e3bf7800248ebf06533c61c"}},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):        \n        base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n                                      include_top = False, weights = 'imagenet')\n        base_pretrained_model.trainable = False\n        \nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"7ec309826c33787294dd1ba2cac5e4e65bab1755","execution":{"iopub.status.busy":"2022-03-28T10:06:34.931474Z","iopub.execute_input":"2022-03-28T10:06:34.932045Z","iopub.status.idle":"2022-03-28T10:06:50.890504Z","shell.execute_reply.started":"2022-03-28T10:06:34.931955Z","shell.execute_reply":"2022-03-28T10:06:50.889767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Model Supplements\n# Here we add a few other layers to the model to make it better suited for the classification problem. ","metadata":{"_uuid":"c0af654a22993505bd8dc48355c4bd347b89947a","execution":{"iopub.status.busy":"2022-03-28T10:06:50.891452Z","iopub.execute_input":"2022-03-28T10:06:50.891689Z","iopub.status.idle":"2022-03-28T10:06:50.895543Z","shell.execute_reply.started":"2022-03-28T10:06:50.891645Z","shell.execute_reply":"2022-03-28T10:06:50.894684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        \n        from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\n        from keras.models import Model\n        from keras.optimizers import Adam\n        from keras import layers\n        pt_features = Input(base_pretrained_model.get_output_shape_at(0)[1:], name = 'feature_input')\n        pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n        from keras.layers import BatchNormalization\n        bn_features = BatchNormalization()(pt_features)\n        gap = GlobalAveragePooling2D()(bn_features)\n\n        gap_dr = Dropout(DROPOUT)(gap)\n        dr_steps = Dropout(DROPOUT)(Dense(DENSE_COUNT, activation = 'linear', use_bias=False)(gap_dr))\n        dr_steps = BatchNormalization()(dr_steps)\n        dr_steps = layers.LeakyReLU(0.1)(dr_steps)\n        out_layer = Dense(t_y.shape[1], activation = 'softmax')(dr_steps)\n\n        attn_model = Model(inputs = [pt_features], \n                           outputs = [out_layer], name = 'trained_model')\n\n        attn_model.summary()\n    \nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"b0f2055383236d17f0d5455ecc2af5de922fc3b8","execution":{"iopub.status.busy":"2022-03-28T10:06:50.896887Z","iopub.execute_input":"2022-03-28T10:06:50.897426Z","iopub.status.idle":"2022-03-28T10:06:51.184953Z","shell.execute_reply.started":"2022-03-28T10:06:50.897376Z","shell.execute_reply":"2022-03-28T10:06:51.184034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.optimizers import Adam\n    \ntry:\n    with tf.device('/device:GPU:0'):\n        \n        \n        pneu_model = Sequential(name = 'combined_model')\n        base_pretrained_model.trainable = True\n        pneu_model.add(base_pretrained_model)\n        pneu_model.add(attn_model)\n        pneu_model.compile(optimizer = Adam(lr = LEARN_RATE), \n                           loss = 'categorical_crossentropy',\n                           metrics = ['categorical_accuracy'])\n        pneu_model.summary()\nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"74103ef71c30a9725949fbeed864174cbe62c69d","execution":{"iopub.status.busy":"2022-03-28T10:06:51.186461Z","iopub.execute_input":"2022-03-28T10:06:51.186928Z","iopub.status.idle":"2022-03-28T10:07:01.245124Z","shell.execute_reply.started":"2022-03-28T10:06:51.186756Z","shell.execute_reply":"2022-03-28T10:07:01.242776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n        weight_path=\"{}_weights.best.hdf5\".format('lung_opacity')\n\n        checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                                     save_best_only=True, mode='min', save_weights_only = True)\n\n        reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, \n                                           patience=10, verbose=1, mode='auto', \n                                           epsilon=0.0001, cooldown=5, min_lr=0.0001)\n        early = EarlyStopping(monitor=\"val_loss\", \n                              mode=\"min\", \n                              patience=10) # probably needs to be more patient, but kaggle time is limited\n        callbacks_list = [checkpoint, early, reduceLROnPlat]\nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"0f6ff110ed2db877c1daee57de63e7dc16593c0e","execution":{"iopub.status.busy":"2022-03-28T10:07:01.245993Z","iopub.execute_input":"2022-03-28T10:07:01.246231Z","iopub.status.idle":"2022-03-28T10:07:01.253966Z","shell.execute_reply.started":"2022-03-28T10:07:01.246184Z","shell.execute_reply":"2022-03-28T10:07:01.253101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport timeit\n\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T10:07:01.255326Z","iopub.execute_input":"2022-03-28T10:07:01.255836Z","iopub.status.idle":"2022-03-28T10:07:01.270271Z","shell.execute_reply.started":"2022-03-28T10:07:01.255783Z","shell.execute_reply":"2022-03-28T10:07:01.268786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        train_gen.batch_size = BATCH_SIZE\n        pneu_model.fit_generator(train_gen, \n                                 steps_per_epoch=train_gen.n//BATCH_SIZE,\n                                 validation_data=(valid_X, valid_Y), \n                                 epochs=100, \n                                 callbacks=callbacks_list,\n                                 workers=2)\nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"58347af9669fed1e5308ac90a6ce06b3579761c5","execution":{"iopub.status.busy":"2022-03-28T10:07:01.271757Z","iopub.execute_input":"2022-03-28T10:07:01.272204Z","iopub.status.idle":"2022-03-28T11:28:16.463425Z","shell.execute_reply.started":"2022-03-28T10:07:01.272105Z","shell.execute_reply":"2022-03-28T11:28:16.462484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        pneu_model.load_weights(weight_path)\n        pneu_model.save('full_model.h5')\nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"08e50876364886ef4a39723055136d741597348a","execution":{"iopub.status.busy":"2022-03-28T11:28:16.464419Z","iopub.execute_input":"2022-03-28T11:28:16.464671Z","iopub.status.idle":"2022-03-28T11:28:20.550724Z","shell.execute_reply.started":"2022-03-28T11:28:16.464631Z","shell.execute_reply":"2022-03-28T11:28:20.549938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    with tf.device('/device:GPU:0'):\n        pred_Y = pneu_model.predict(valid_X, \n                          batch_size = BATCH_SIZE, \n                          verbose = True)\nexcept RuntimeError as e:\n    print(e)","metadata":{"_uuid":"f67dd5726e24517401ff0724f2aa07b1787cf791","execution":{"iopub.status.busy":"2022-03-28T11:28:20.551583Z","iopub.execute_input":"2022-03-28T11:28:20.551834Z","iopub.status.idle":"2022-03-28T11:28:24.543203Z","shell.execute_reply.started":"2022-03-28T11:28:20.55179Z","shell.execute_reply":"2022-03-28T11:28:24.542486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nplt.matshow(confusion_matrix(np.argmax(valid_Y, -1), np.argmax(pred_Y,-1)))\nprint(classification_report(np.argmax(valid_Y, -1), \n                            np.argmax(pred_Y,-1), target_names = class_enc.classes_))","metadata":{"_uuid":"40f86cabdbea5e8dfc736882c4e7f5036297ec0a","execution":{"iopub.status.busy":"2022-03-28T11:28:24.544049Z","iopub.execute_input":"2022-03-28T11:28:24.544277Z","iopub.status.idle":"2022-03-28T11:28:24.686714Z","shell.execute_reply.started":"2022-03-28T11:28:24.544233Z","shell.execute_reply":"2022-03-28T11:28:24.685821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(np.argmax(valid_Y,-1)==0, pred_Y[:,0])\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'VGG-Model (AUC:%2.2f)' % roc_auc_score(np.argmax(valid_Y,-1)==0, pred_Y[:,0]))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nax1.set_title('Lung Opacity ROC Curve')\nfig.savefig('roc_valid.pdf')","metadata":{"_uuid":"1c217311f0f08d5473f493244cc4c4e17c0b6e9d","execution":{"iopub.status.busy":"2022-03-28T11:28:24.689945Z","iopub.execute_input":"2022-03-28T11:28:24.69234Z","iopub.status.idle":"2022-03-28T11:28:25.471426Z","shell.execute_reply.started":"2022-03-28T11:28:24.692277Z","shell.execute_reply":"2022-03-28T11:28:25.470726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make a submission\nWe load in the test images and make a submission using those images and a guess for $x, y$ and the width and height for all values where the model is more than 50% convinced there is something suspicious going on.","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"_uuid":"cf0f87166720c24ced3b2eae4b2afe77e6529225"}},{"cell_type":"code","source":"# from glob import glob\n# sub_img_df = pd.DataFrame({'path': \n#               glob('../input/rsna-pneumonia-detection-challenge/stage_2_test_images/*.dcm')})\n# sub_img_df['patientId'] = sub_img_df['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\n# sub_img_df.sample(3)","metadata":{"_uuid":"2c8c27edd01ad87653e2c55284d64fa029afc472","execution":{"iopub.status.busy":"2022-03-28T11:28:25.472556Z","iopub.execute_input":"2022-03-28T11:28:25.473053Z","iopub.status.idle":"2022-03-28T11:28:25.476765Z","shell.execute_reply.started":"2022-03-28T11:28:25.473003Z","shell.execute_reply":"2022-03-28T11:28:25.476048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission_gen = flow_from_dataframe(img_gen, \n#                                      sub_img_df, \n#                              path_col = 'path',\n#                             y_col = 'patientId', \n#                             target_size = IMG_SIZE,\n#                              color_mode = 'rgb',\n#                             batch_size = BATCH_SIZE,\n#                                     shuffle=False)","metadata":{"_uuid":"96510ebcc831ef0e9839b4050ba8294c5732fbb3","execution":{"iopub.status.busy":"2022-03-28T11:28:25.478082Z","iopub.execute_input":"2022-03-28T11:28:25.478744Z","iopub.status.idle":"2022-03-28T11:28:25.485285Z","shell.execute_reply.started":"2022-03-28T11:28:25.478678Z","shell.execute_reply":"2022-03-28T11:28:25.484603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict for each image twice and average the results\nWe shouldn't get the same answer since the data are being augmented (here at so-called test-time)","metadata":{"_uuid":"9ac79cbc09dce5a09fd05e021792b5ff26eb658e"}},{"cell_type":"code","source":"from tqdm import tqdm\nsub_steps = 2*sub_img_df.shape[0]//BATCH_SIZE\nout_ids, out_vec = [], []\nfor _, (t_x, t_y) in zip(tqdm(range(sub_steps)), submission_gen):\n    out_vec += [pneu_model.predict(t_x)]\n    out_ids += [t_y]\nout_vec = np.concatenate(out_vec, 0)\nout_ids = np.concatenate(out_ids, 0)","metadata":{"_uuid":"bd564f016278a31bee570f7d6aedc953ca2ff432","execution":{"iopub.status.busy":"2022-03-28T11:28:25.486151Z","iopub.execute_input":"2022-03-28T11:28:25.486364Z","iopub.status.idle":"2022-03-28T11:28:25.520502Z","shell.execute_reply.started":"2022-03-28T11:28:25.486318Z","shell.execute_reply":"2022-03-28T11:28:25.518735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df = pd.DataFrame(out_vec, columns=class_enc.classes_)\npred_df['patientId'] = out_ids\npred_avg_df = pred_df.groupby('patientId').agg('mean').reset_index()\npred_avg_df['Lung Opacity'].hist()\npred_avg_df.to_csv('image_level_class_probs.csv', index=False) # not hte submission file\npred_avg_df.sample(2)","metadata":{"_uuid":"527e6c29c66f2de2ec03b53f8de2406b6d051608","execution":{"iopub.status.busy":"2022-03-28T11:28:25.521508Z","iopub.status.idle":"2022-03-28T11:28:25.522165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple Strategy\nWe use the `Lung Opacity` as our confidence and predict the image image. It will hopefully do a little bit better than a trivial baseline, and can be massively improved.","metadata":{"_uuid":"5c7e5670184b1b9e7de9ad842de6ca671731b057"}},{"cell_type":"code","source":"pred_avg_df['PredictionString'] = pred_avg_df['Lung Opacity'].map(lambda x: ('%2.2f 0 0 1024 1024' % x) if x>0.5 else '')","metadata":{"_uuid":"68ee79e068892d310cc39209517ec20172db8889","execution":{"iopub.status.busy":"2022-03-28T11:28:25.523147Z","iopub.status.idle":"2022-03-28T11:28:25.523765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_avg_df[['patientId', 'PredictionString']].to_csv('submission.csv', index=False)","metadata":{"_uuid":"d746f6e21788945f5dc19843811a4e9068302255","execution":{"iopub.status.busy":"2022-03-28T11:28:25.524694Z","iopub.status.idle":"2022-03-28T11:28:25.525334Z"},"trusted":true},"execution_count":null,"outputs":[]}]}