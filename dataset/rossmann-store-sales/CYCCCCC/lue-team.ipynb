{"cells":[{"metadata":{},"cell_type":"markdown","source":"import tools & data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\n\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n    \nfrom datetime import datetime\nimport time\nimport sys\nimport gc\nimport pickle\nsys.version_info\n\nimport joblib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/rossmann-store-sales/train.csv\")\ndf_test = pd.read_csv(\"../input/rossmann-store-sales/test.csv\")\nstore = pd.read_csv(\"../input/rossmann-store-sales/store.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"merge data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Id'] = 0\ndf_train['data_type'] = 1\n\ndf_train.reindex(sorted(df_train.columns), axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['Customers'] = 9999\ndf_test['Sales'] = 0\ndf_test['data_type'] = 2\n\ndf_test.reindex(sorted(df_test.columns), axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df_train, df_test])\ndf = pd.merge(df, store, how='left', on='Store')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 減少記憶體用量\ndel df_train\ndel df_test\ndel store","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#時間處理\n\ndef is_weekend(dates):\n    results = []\n    for date_value in pd.DatetimeIndex(dates.values):\n        weekno = date_value.weekday()\n        result = 0 if weekno < 5 else 1\n        results.append(result)\n    return results\n\n\ndate_to_season_mapping = {1: [12, 2], 2: [3, 5], 3: [6, 8], 4: [9, 11]}\n\n\ndef date_to_season(dates):\n    results = []\n    date_values = dates.values\n    for date in date_values:\n        month = int(date.split('-')[1])\n        result = 'None'\n        for each_season in date_to_season_mapping:\n            start, end = date_to_season_mapping[each_season]\n            if ((start < end) and (start <= month <= end)) or \\\n               ((start > end) and ((month >= start) or (month <= end))):\n                result = each_season\n                break\n\n        results.append(result)\n    return results\n\nmonth_no_to_name_mapping = [\n    1,2,3,4,5,6,7,8,9,10,11,12\n]\n\ndef date_to_month_name(dates):\n    month_values = pd.DatetimeIndex(dates).month.values\n    results = []\n    for month in month_values:\n        result = month_no_to_name_mapping[month - 1]\n        results.append(result)\n    return results\n\n# def weekday_or_weekend(dates):\n#     results = []\n#     for date_value in pd.DatetimeIndex(dates.values):\n#         weekno = date_value.weekday()\n#         result = \"Weekday\" if weekno < 5 else \"Weekend\"\n#         results.append(result)\n#     return results\n\n# def weekday(dates):\n#     results = []\n#     for date_value in pd.DatetimeIndex(dates.values):\n#         weekno = date_value.weekday()\n#         result = weekno\n#         results.append(result)\n#     return results\n\n\nimport holidays\nholidays_usa = holidays.USA()\n\ndef is_holiday(dates):\n    results = []\n    for date_value in pd.DatetimeIndex(dates.values):\n        result = 1 if date_value.date() in holidays_usa else 0\n        results.append(result)\n    return results\n\n\n# date_to_day_period_mapping = {'Morning': [4, 11], 'Afternoon': [12, 17], \n#                               'Evening': [18, 19], 'Night': [20, 4]}\n# def date_to_day_period(datetimes):\n#     results = []\n#     datetime_values = datetimes.values\n#     for datetime in datetime_values:\n#         _, time_of_day = datetime.split(' ')\n#         hour, _, _ = time_of_day.split(':')\n#         hour = int(hour)\n#         result = 'None'\n#         for each_day_period in date_to_day_period_mapping:\n#             start, end = date_to_day_period_mapping[each_day_period]\n#             if ((start < end) and (start <= hour <= end)) or \\\n#                ((start > end) and ((hour >= start) or (hour <= end))):\n#                 result = each_day_period\n#                 break\n\n#         results.append(result)\n#     return results\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['is_weekend'] = is_weekend(df['Date'])\ndf['Month'] = date_to_month_name(df['Date'])\ndf['Year'] = pd.DatetimeIndex(df['Date']).year\ndf['Season'] = date_to_season(df['Date'])\ndf['is_holiday'] = is_holiday(df['Date'])\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lag_feature(df, lags, col):\n    tmp = df[['num_of_week','Store',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['num_of_week','Store', col+'_lag_'+str(i)]\n        shifted['num_of_week'] += i\n        shifted = shifted.groupby(['num_of_week','Store'], as_index=False).agg({col+'_lag_'+str(i): 'mean'})\n        df = pd.merge(df, shifted, on=['num_of_week','Store'], how='left')\n    return df\n\ndf['date'] = df['Date'].apply( lambda x: np.datetime64(x))\ndf['num_of_week'] = (df.date.dt.year-2013)*52 + df.date.dt.week\n\nts = time.time()\ndf = lag_feature(df, [4,13,26,52], 'Sales')\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['date'] = df['Date'].apply( lambda x: np.datetime64(x))\ndf['yyyymm'] = df['date'].dt.strftime('%Y%m')\ndf['last_year'] = df['date'] - np.timedelta64(1, 'Y')\ndf['last_yyyymm'] = df['last_year'].dt.strftime('%Y%m')\n\ntmp = df.groupby(['Store', 'yyyymm'])['Customers'].mean().reset_index()\ndf = df.merge(tmp, left_on = ['Store','last_yyyymm'], right_on = ['Store', 'yyyymm'], how ='left')\n\ndf.drop('yyyymm_y', axis=1, inplace=True)\ndf = df.rename(columns= {'Customers_x':'Customers', 'Customers_y':'last_Customers', 'yyyymm_x':'yyyymm'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"one-hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 有重複數值須先處理\ndf['StateHoliday'] = np.where(df['StateHoliday']=='a', 'a', \n                              np.where(df['StateHoliday']=='b', 'b',\n                                      np.where(df['StateHoliday']=='c', 'c', 0)\n                             ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = [\n    'StateHoliday',\n    'StoreType',\n    'Assortment',\n    'PromoInterval'\n]\n\n# SchoolHiliday 只有1/0不做one-hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat = pd.get_dummies(df[cat_col])\ndf_cat = df_cat.astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_col = list(set(df.columns.tolist())-set(cat_col))\ndf_num = df[num_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_cat.shape)\nprint(df_num.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([df_num, df_cat], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dummy\n\n# data_temp = df.copy()\n# data_temp.drop(columns = ['Date'], inplace=True)\n\n# description = pd.DataFrame(index=['observations(rows)', 'percent missing', 'dtype', 'range'])\n# numerical = []\n# categorical = []\n# for col in data_temp.columns:\n#     obs = data_temp[col].size\n#     p_nan = round(data_temp[col].isna().sum()/obs, 2)\n#     num_nan = f'{p_nan}% ({data_temp[col].isna().sum()}/{obs})'\n#     dtype = 'categorical' if data_temp[col].dtype == object else 'numerical'\n#     numerical.append(col) if dtype == ['numerical','int64'] else categorical.append(col)\n#     rng = f'{len(data_temp[col].unique())} labels' if dtype == 'categorical' else f'{data_temp[col].min()}-{data_temp[col].max()}'\n#     description[col] = [obs, num_nan, dtype, rng]\n\n# data_num = data_temp.copy()    \n# data_num.drop(columns = categorical, inplace=True)\n\n# data_dummy = pd.get_dummies(data_temp[categorical], drop_first=True)\n# data_dummy.head()\n# display(description)\n\n\n\n# data_dummy.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"exclude_col = [\n    'Date',\n    'date',\n    'yyyymm',\n    'last_year',\n    'last_yyyymm',\n    'data_type',\n    'Id',\n    'Customers'\n]\n\ny_col = ['Sales']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_col = list(set(df_all.columns.tolist())-set(exclude_col)-set(y_col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = df_all[df_all['data_type']==1][x_col]\ny_train = df_all[df_all['data_type']==1][y_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.3, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"ts = time.time()\n\nmodel = XGBRegressor(\n    max_depth=7,\n    n_estimators=1000,\n    min_child_weight=100, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,    \n    seed=42)\n\nmodel.fit(\n    x_train, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(x_train, y_train), (x_valid, y_valid)], \n    verbose=True, \n    early_stopping_rounds = 10)\n\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = df_all[df_all['data_type']==2][x_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_y = pd.DataFrame()\ndf_y['Id'] = df_all[df_all['data_type']==2]['Id']\ndf_y['Sales'] = y_pred\ndf_y.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_features(model, (10,14))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}