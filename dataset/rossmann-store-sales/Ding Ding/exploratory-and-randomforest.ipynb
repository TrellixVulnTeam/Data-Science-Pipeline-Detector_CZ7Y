{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea498b90-f22f-437a-bf3c-60c8c064a871"},"outputs":[],"source":"%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af8a52a9-bf15-4b6c-b4fb-de1f8e3ca32f"},"outputs":[],"source":"import pandas as pd\nimport numpy as np  \nimport matplotlib.pyplot as plt \nimport matplotlib.dates \nimport datetime \n%matplotlib inline\ntrain = pd.read_csv('../input/train.csv')\nstore = pd.read_csv('../input/store.csv')\ntest = pd.read_csv('../input/test.csv') \n\nstore.head()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9011dd8f-b49e-4092-9fb8-3e40d3d4c53b"},"outputs":[],"source":"train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae66448e-ecc8-44fc-9b64-20e5e3d84d82"},"outputs":[],"source":"test.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1d8abe6-9a89-430e-bbf8-1c5ad5ad59cf"},"outputs":[],"source":"## transform date variable\ndatetimes = [datetime.datetime.strptime(t, \"%Y-%m-%d\") for t in train.Date]\nplotData = matplotlib.dates.date2num(datetimes) \ntrain = train.join(pd.DataFrame(plotData,columns = ['datetimes']))\ndef splitTime(x): \n    mysplit = datetime.datetime.strptime(x,  \"%Y-%m-%d\") \n    return [mysplit.year,mysplit.month,mysplit.day]\ntrain = train.join(pd.DataFrame(train.Date.apply(splitTime).tolist(), columns = ['year','mon','day']))\n\n# plot the first 5 stores sales vs time\n\nfor i in range(1,5):\n plt.figure(i,figsize=(20,10)) \n plt.subplot(211)\n plt.plot_date(train.loc[train.Store==i,'datetimes'],train.loc[train.Store==i,'Sales'],linestyle='-') \n plt.title('Store %d' %i)  \n plt.subplot(212)\n train2014 = train.loc[train.year == 2014,:]\n plt.plot_date(train2014.loc[train2014.Store==i,'datetimes'],train2014.loc[train2014.Store==i,'Sales'],linestyle='-') \n plt.title('Store %d, 2014' %i)  \n plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c1127047-294f-48d0-b8d7-03267e9feeba"},"outputs":[],"source":"## distribution of sales variable\nplt.figure(1,figsize=(15,10)) \nplt.subplot(221)\nplt.hist(train.Sales,bins=30)\nplt.title(\"Distribution of Sales\") \nplt.subplot(222)\nplt.hist(np.log(train.Sales+1),bins=30)\nplt.title(\"Distribution of log(Sales)\") "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"577e5615-ffb6-474e-919a-7897af5251b1"},"outputs":[],"source":"## average log sales, by store\n\nplt.hist([np.log(train.groupby('Store').Sales.mean()) ],bins=30)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"430b9199-306f-44c6-b83d-8495792039ef"},"outputs":[],"source":"toAppend = pd.DataFrame(np.log(train.Sales+1),dtype=float)\ntoAppend.columns.values[0]='LogSale'\ntrain=train.join(toAppend)\ntrain.dtypes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"284c1eb9-1e60-4a23-ad4c-d7f1e806dff4"},"outputs":[],"source":"### data transformation on store data set\n\n## transform variable PromoInterval to 12 dummy variables\ndef myPinterval(x):\n    if x=='Feb,May,Aug,Nov':  return([0,1,0,0,1,0,0,1,0,0,1,0])\n    elif x=='Jan,Apr,Jul,Oct':  return([1,0,0,1,0,0,1,0,0,1,0,0])\n    elif x== 'Mar,Jun,Sept,Dec': return([0,0,1,0,0,1,0,0,1,0,0,1])\n    else: return(np.repeat(0,12).tolist())\n\nproInt = store.PromoInterval.apply(myPinterval).tolist()\nproInt = pd.DataFrame(proInt, columns = ['ProInt'+ str(i) for i in range(1,13)])\nstore = store.drop('PromoInterval',1).join(proInt)\n\nstore = store.drop('StoreType',1).join(pd.get_dummies(store['StoreType']).rename(columns=lambda x: 'StoreType' +\"_\"+str(x)))  \nstore = store.drop('Assortment',1).join(pd.get_dummies(store['Assortment']).rename(columns=lambda x: 'Assortment' +\"_\"+str(x)))  \n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8bb31ba7-b1ac-410e-9fc8-c66f740d6cb6"},"outputs":[],"source":"##assume 0 and '0' are the same in train.StateHoliday \ndef mychange(x):\n     if type(x)!= str: x=str(x)\n     return x\n        \ntrain.StateHoliday = [mychange(x) for x in train.StateHoliday]\n\nnewtrain = train.drop('StateHoliday',1).join(pd.get_dummies(train['StateHoliday']).rename(columns=lambda x: 'StateHoliday' +\"_\"+str(x)))  \n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a24f8425-a433-4a44-b7b6-14d7f2e67f95"},"outputs":[],"source":"## merge training set with store\n\nnewtrain=pd.merge(newtrain, store, on=\"Store\")  \nnewtrain.drop(['Date','Customers','datetimes','Sales'],axis = 1,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98f153fd-d874-4262-a57b-d8ecfd162331"},"outputs":[],"source":"## do the same thing on testing set\ntest = test.join(pd.DataFrame(test.Date.apply(splitTime).tolist(), columns = ['year','mon','day']))\nnewtest = test.drop('StateHoliday',1).join(pd.get_dummies(test['StateHoliday']).rename(columns=lambda x: 'StateHoliday' +\"_\"+str(x)))  \nnewtest = pd.merge(newtest,store, on=\"Store\")\nnewtest.drop(['Date'],axis = 1,inplace=True) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6472f75c-2a38-434f-b9c6-f9788a1015e6"},"outputs":[],"source":"## check if there exists any constant variable\nnp.sum(newtrain.var()==0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f5b5d71-3bd1-4ad0-97b8-365a713c920e"},"outputs":[],"source":"##### randomforest\nfrom sklearn.ensemble.forest import RandomForestRegressor\n\n##### delete variables that do not exist in the test set\ntoDrop = list(set(newtrain.columns.values)-set(newtest.columns.values) )\nfeatures = newtrain.columns.drop(toDrop,1)\n\nrf = RandomForestRegressor(n_estimators=100)\nrf.fit(newtrain.drop(toDrop ,1).fillna(-1),newtrain.LogSale)\nnewtrain.drop(toDrop ,1).fillna(-1)\n\n\nimportances = rf.feature_importances_ \n# return the indices that would sort the importance, decreasing\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\n\nFeatures = newtrain.columns.drop('LogSale')\nfor f in range(35):\n    print(\"%d. feature %d :%s (%f)\" % (f + 1, indices[f],Features[indices[f]], importances[indices[f]]))\n\n# Plot the feature importances of the forest\n# the most important feature 'open' is left out in the plot to make it easier to see the other features\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(1,10), importances[indices[range(1,10)]]) \nplt.xlim([-1, 10])\nplt.show()\n\n# make prediction on test data\nmypred = rf.predict(newtest.drop('Id',1).fillna(-1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"069ef9c7-6678-4947-93cc-9515211fc230"},"outputs":[],"source":"mypred = np.exp(mypred)-1\nmypred = pd.DataFrame({ 'Id': test['Id'],\n                            'Sales': mypred[np.argsort(newtest['Id'])] })\n#mypred.to_csv(\"randomForest_1stSubmission.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7e1e48e-04bf-479a-b63f-dfb4359e81ed"},"outputs":[],"source":"############lasso for prediction \nimport pasty\nfrom sklearn import linear_model\ny,X  = patsy.dmatrices(\"LogSale ~ 1+sx+rk+yr+dg+yd\",newtrain)\n\nnewtrain.columns\n\n\n\nalphas = np.logspace(-4, -.5, 30)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7004c8f8-f25a-e8a2-1ed2-1dce0515a46d"},"outputs":[],"source":"newtrain.LogSale"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aae1e7b0-c2c5-ea6c-d630-003a25e1fa73"},"outputs":[],"source":"newtrain"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f213ddca-3155-0949-0dfa-ad86e067a08d"},"outputs":[],"source":"newtrain.drop(toDrop ,1).fillna(-1)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}