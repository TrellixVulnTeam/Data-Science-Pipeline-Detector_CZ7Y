{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### In this notebook I have tried to take the data of each store and make predictions with XGB. This way it is less taxing on the processor and also score does not decrease too much.\n\nNote : I have not tried to integrate average weather data for past Europe past records. If we use it, there is high chance of improving results. Also trying to predict with AutoRegression is also an option","metadata":{}},{"cell_type":"markdown","source":"## Importing data\nSo lets get started with importing required libraries and importing input data from compitition.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV, KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-10T21:33:43.946677Z","iopub.execute_input":"2021-12-10T21:33:43.947203Z","iopub.status.idle":"2021-12-10T21:33:44.409999Z","shell.execute_reply.started":"2021-12-10T21:33:43.947056Z","shell.execute_reply":"2021-12-10T21:33:44.409074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(r'../input/rossmann-store-sales/train.csv', parse_dates=['Date'], low_memory=False)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:44.411729Z","iopub.execute_input":"2021-12-10T21:33:44.411984Z","iopub.status.idle":"2021-12-10T21:33:45.499115Z","shell.execute_reply.started":"2021-12-10T21:33:44.411953Z","shell.execute_reply":"2021-12-10T21:33:45.498277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(r'../input/rossmann-store-sales/test.csv', parse_dates=['Date'], low_memory=False, index_col='Id')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:45.500444Z","iopub.execute_input":"2021-12-10T21:33:45.500678Z","iopub.status.idle":"2021-12-10T21:33:45.561966Z","shell.execute_reply.started":"2021-12-10T21:33:45.500648Z","shell.execute_reply":"2021-12-10T21:33:45.561111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store = pd.read_csv(r'../input/rossmann-store-sales/store.csv', index_col='Store')\nstore.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:45.563408Z","iopub.execute_input":"2021-12-10T21:33:45.563643Z","iopub.status.idle":"2021-12-10T21:33:45.586352Z","shell.execute_reply.started":"2021-12-10T21:33:45.563614Z","shell.execute_reply":"2021-12-10T21:33:45.585453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Integration and Cleaning\n\nLet's considers all the features one by one\n- First, 'CompetitionDistance' column in store data, it had 3 null values, so imputing them with mean would do.\n- Next, Promo2 columns : We will need to compare when the promo2 started with each date later to calculate if it is active currently. So just clearing some null values for now.\n- Same is the case for the Compititors column. We will need to check when compititor shop opened.  I have created 'CompetitionOpen' column to know if we have data on the compititor or not.\n- Also let's Label encode the PromoInterval and Assortment columns as they are nominal","metadata":{}},{"cell_type":"code","source":"mean_dist = store['CompetitionDistance'].mean()\nstore.loc[store['CompetitionDistance'].isnull(), 'CompetitionDistance'] = mean_dist\n\nstore.loc[store['Promo2'] == 0, ['Promo2SinceWeek','Promo2SinceYear']] = 0\nstore['Promo2SinceWeek'] = store['Promo2SinceWeek'].astype('int')\nstore['Promo2SinceYear'] = store['Promo2SinceYear'].astype('int')\n\nstore['CompetitionOpen'] = 1\nstore.loc[store['CompetitionOpenSinceMonth'].isnull(),['CompetitionOpen', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear']] = 0\nstore['CompetitionOpenSinceMonth'] = store['CompetitionOpenSinceMonth'].astype('int')\nstore['CompetitionOpenSinceYear'] = store['CompetitionOpenSinceYear'].astype('int')\n\nlabel_map = {'PromoInterval' : {'Jan,Apr,Jul,Oct' : 1,\n                                'Feb,May,Aug,Nov' : 2,\n                                'Mar,Jun,Sept,Dec' : 3,\n                                np.nan : 0},\n             'Assortment' : {'a':0,\n                             'b':1,\n                             'c':2}}\nstore.replace(label_map, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:45.588396Z","iopub.execute_input":"2021-12-10T21:33:45.588604Z","iopub.status.idle":"2021-12-10T21:33:45.610477Z","shell.execute_reply.started":"2021-12-10T21:33:45.588578Z","shell.execute_reply":"2021-12-10T21:33:45.609331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- when I took a look at data and it lookd like the type of Holiday a/b/c does not affect the drop in Sales, its just that if it is StateHoliday, there is a chance of Sales to drop. So encoding all the Holiday's a/b/c as 1.\n- Also, we need to split Date column into Year,Month and Date for it to be a little bit useful for model\n- Not going to drop Date column for now cause it will be useful later on for calculations on Promo2 and Compititors","metadata":{}},{"cell_type":"code","source":"train.loc[train['StateHoliday'] != '0', 'StateHoliday'] = '1'\ntrain['StateHoliday'] = train['StateHoliday'].astype('int')\n\ntest.loc[test['StateHoliday'] != '0', 'StateHoliday'] = '1'\ntest['StateHoliday'] = test['StateHoliday'].astype('int')\n\ntrain['year'] = train['Date'].dt.year\ntrain['month'] = train['Date'].dt.month\ntrain['day'] = train['Date'].dt.day\n\ntest['year'] = test['Date'].dt.year\ntest['month'] = test['Date'].dt.month\ntest['day'] = test['Date'].dt.day\n\ntest.loc[test['Open'].isnull(), 'Open'] = 1\ntest['Open'] = test['Open'].astype('int')\n\ntrain.drop('Customers', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:45.613279Z","iopub.execute_input":"2021-12-10T21:33:45.613741Z","iopub.status.idle":"2021-12-10T21:33:46.315269Z","shell.execute_reply.started":"2021-12-10T21:33:45.613705Z","shell.execute_reply":"2021-12-10T21:33:46.314589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Difining our basic model\n- First I checked with grid search on first 30 stores with very large parameter set and took the best models\n- As a result I found out these things:\n    - learning rate was varying between 0.1 to 0.4, with most of them with 0.2 learning rate. So keeping it as hyper parameter with values [0.1,0.2,0.35]\n    - n_estimators were always best at 100\n    - max_depth was best at 4, only once it was showing best results for max_depth=3.","metadata":{}},{"cell_type":"code","source":"kfold = KFold(n_splits=5, random_state=2021, shuffle=True)\nparameters = {'learning_rate' : [0.1,0.2,0.35]}\nclf = XGBRegressor(random_state=2021, use_label_encoder=False, n_estimators=100, max_depth=4)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:46.316468Z","iopub.execute_input":"2021-12-10T21:33:46.317098Z","iopub.status.idle":"2021-12-10T21:33:46.323009Z","shell.execute_reply.started":"2021-12-10T21:33:46.317041Z","shell.execute_reply":"2021-12-10T21:33:46.322358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here I have simply created an empty dataframe to append the predicted results","metadata":{}},{"cell_type":"code","source":"submit_frame = pd.DataFrame(columns=['Id','Sales'])","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:46.324311Z","iopub.execute_input":"2021-12-10T21:33:46.325186Z","iopub.status.idle":"2021-12-10T21:33:46.343855Z","shell.execute_reply.started":"2021-12-10T21:33:46.325139Z","shell.execute_reply":"2021-12-10T21:33:46.343108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- These are the functions which will take in a date and return the value for promo2 and compititor if it is currently active.\n- as for promo2, we have got the value for when the promo gets renewed, so I have added the column to determine the age in months of promo, it will return 0 if promo2 is inactive, or a number between 1 to 3 if promo2 is active\n- for example if for the store, promo2 gets renewed each Jan,Apr,Jul and Oct, it will return 1 if date is in Jan, 2 if date is in Feb, 3 if date is in Mar and 1 again if date is in April, and so on.....","metadata":{}},{"cell_type":"code","source":"def calc_promo(dt):\n    if (dt.isocalendar()[0] * 100 + dt.isocalendar()[1]) >= (st_t['Promo2SinceYear'] * 100 + st_t['Promo2SinceWeek']):\n        mt = (dt.month + st_t['PromoInterval'] - 1) % 3\n        if mt == 0:\n            mt = 3\n        return (1,mt)\n    else:\n        return (0,0)\n\ndef calc_comp(dt):\n    if (dt.year * 12 + dt.month) >= (st_t['CompetitionOpenSinceYear'] * 12 + st_t['CompetitionOpenSinceYear']):\n        return 1\n    else:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:46.344918Z","iopub.execute_input":"2021-12-10T21:33:46.345762Z","iopub.status.idle":"2021-12-10T21:33:46.352799Z","shell.execute_reply.started":"2021-12-10T21:33:46.345723Z","shell.execute_reply":"2021-12-10T21:33:46.352156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making Predictions on each Store\n- Now the part which takes too much time for execution...\n- We are going to iterate through data for each store and make predictions...","metadata":{}},{"cell_type":"code","source":"for st_no in range(1,1116):\n    train_t = train.loc[train['Store'] == st_no].copy()\n    train_t.drop('Store', axis=1, inplace=True)\n\n    test_t = test.loc[test['Store'] == st_no].copy()\n    test_t.drop('Store',axis=1,inplace=True)\n\n    st_t = store.loc[store.index==st_no].iloc[0,:]\n    \n    if test_t.shape[0] > 0:\n        train_t['Promo2'] = 0\n        train_t['NewPromoAge'] = 0\n        train_t['Competition'] = 0\n\n        test_t['Promo2'] = 0\n        test_t['NewPromoAge'] = 0\n        test_t['Competition'] = 0\n\n        if st_t['Promo2'] == 1:\n            train_t['Promo2'], train_t['NewPromoAge'] = zip(*train_t['Date'].map(calc_promo))\n            test_t['Promo2'], test_t['NewPromoAge'] = zip(*test_t['Date'].map(calc_promo))\n\n        if st_t['CompetitionOpen']:\n            train_t['Competition'] = train_t['Date'].map(calc_comp)\n            test_t['Competition'] = test_t['Date'].map(calc_comp)\n\n        train_t.drop('Date', axis=1, inplace=True)\n        test_t.drop('Date', axis=1, inplace=True)\n        \n        X_train_t = train_t.drop('Sales',axis=1)\n        y_train_t = train_t['Sales']\n        \n        cv = GridSearchCV(clf,\n                          param_grid=parameters,\n                          cv=kfold,\n                          scoring='neg_mean_squared_error')\n        cv.fit(X_train_t, y_train_t)\n        y_pred_t = cv.predict(test_t)\n        y_pred_t[y_pred_t < 0] = 0\n        \n        out_frame = pd.DataFrame([test_t.index, y_pred_t]).T\n        out_frame.columns = ['Id','Sales']\n        out_frame['Id'] = out_frame['Id'].astype('int')\n        submit_frame = submit_frame.append(out_frame)\n        print(f'Predicted on : {st_no}, train_rows={train_t.shape[0]}, test_rows={len(y_pred_t)}')\n    else:\n        print(f'Skipped: {st_no}, train_rows={train_t.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2021-12-10T21:33:46.353675Z","iopub.execute_input":"2021-12-10T21:33:46.354149Z","iopub.status.idle":"2021-12-10T22:36:48.749594Z","shell.execute_reply.started":"2021-12-10T21:33:46.354121Z","shell.execute_reply":"2021-12-10T22:36:48.748832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"sorting index of submittion dataframe and outputting it to csv ","metadata":{}},{"cell_type":"code","source":"submit_frame.sort_values('Id', inplace=True)\nprint(submit_frame.shape)\nprint(submit_frame.head())\nsubmit_frame.to_csv(r'submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T22:37:35.535785Z","iopub.execute_input":"2021-12-10T22:37:35.536525Z","iopub.status.idle":"2021-12-10T22:37:35.727838Z","shell.execute_reply.started":"2021-12-10T22:37:35.536474Z","shell.execute_reply":"2021-12-10T22:37:35.727098Z"},"trusted":true},"execution_count":null,"outputs":[]}]}