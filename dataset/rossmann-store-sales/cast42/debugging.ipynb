{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"%matplotlib inline"},{"cell_type":"markdown","metadata":{},"source":"# Experiment with ipython notebooks on Kaggle (work in progress)"},{"cell_type":"markdown","metadata":{},"source":"I'm not succeeding (yet) in getting my notebook onto Kaggle. Have a look here :\n[https://gist.github.com/cast42/bcfd70b919e6648c2b58](https://gist.github.com/cast42/bcfd70b919e6648c2b58)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport datetime\nimport random"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"!pip freeze | grep pandas"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def build_features(features, data):\n    # remove NaNs\n    data.fillna(0, inplace=True)\n    data.loc[data.Open.isnull(), 'Open'] = 1\n    # Use some properties directly\n    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n\n    # Label encode some features\n    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n    data.StoreType.replace(mappings, inplace=True)\n    data.Assortment.replace(mappings, inplace=True)\n    data.StateHoliday.replace(mappings, inplace=True)\n\n    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n    data['Year'] = data.Date.dt.year\n    data['Month'] = data.Date.dt.month\n    data['Day'] = data.Date.dt.day\n    data['DayOfWeek'] = data.Date.dt.dayofweek\n    data['WeekOfYear'] = data.Date.dt.weekofyear\n\n    # CompetionOpen en PromoOpen from https://www.kaggle.com/ananya77041/rossmann-store-sales/randomforestpython/code\n    # Calculate time competition open time in months\n    features.append('CompetitionOpen')\n    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n        (data.Month - data.CompetitionOpenSinceMonth)\n    # Promo open time in months\n    features.append('PromoOpen')\n    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n\n    # Indicate that sales on that day are in promo interval\n    features.append('IsPromoMonth')\n    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n             7:'Jul', 8:'Aug', 9:'Sept', 10:'Okt', 11:'Nov', 12:'Dec'}\n    data['monthStr'] = data.Month.map(month2str)\n    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n    data['IsPromoMonth'] = 0\n    for interval in data.PromoInterval.unique():\n        if interval != '':\n            for month in interval.split(','):\n                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n\n    return data"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Load the training, test and store data using pandas\")\ntypes = {'CompetitionOpenSinceYear': np.dtype(int),\n         'CompetitionOpenSinceMonth': np.dtype(int),\n         'StateHoliday': np.dtype(str),\n         'Promo2SinceWeek': np.dtype(int),\n         'SchoolHoliday': np.dtype(int),\n         'PromoInterval': np.dtype(str)}\ntrain = pd.read_csv(\"../input/train.csv\", parse_dates=[2], dtype=types)\ntest = pd.read_csv(\"../input/test.csv\", parse_dates=[3], dtype=types)\nstore = pd.read_csv(\"../input/store.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"Assume store open, if not provided\")\ntest.fillna(1, inplace=True)\n\n# print(\"Consider only open stores for training. Closed stores wont count into the score.\")\n# train = train[train[\"Open\"] != 0]\n# print(\"Use only Sales bigger then zero\")\n# train = train[train[\"Sales\"] > 0]\n\nprint(\"Join with store\")\ntrain = pd.merge(train, store, on='Store')\ntest = pd.merge(test, store, on='Store')\n\nfeatures = []\n\nprint(\"augment features\")\ntrain = build_features(features, train)\ntest = build_features([], test)\nprint(features)\n\nprint('training data processed')"},{"cell_type":"markdown","metadata":{},"source":"What must be forecasted ? The sales per store. For what period ?"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print ('From',test.Date.min(),'to', test.Date.max())\nprint ('That is', test.Date.max()-test.Date.min(), 'days')"},{"cell_type":"markdown","metadata":{},"source":"For how many stores ?"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"test.Store.nunique()"},{"cell_type":"markdown","metadata":{},"source":"Let's take a random store from the trainings data and plot how the Sales data looks like"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS = 979 # rS =  random.choice(train.Store.unique())\nprint ('Random store number =', rS)"},{"cell_type":"markdown","metadata":{},"source":"How many year's of data do we have in the trainingset?"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.Year.unique()"},{"cell_type":"markdown","metadata":{},"source":"Let look at the sales of store 979 in 2013"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS = 979\ntrain[(train.Store==rS) & (train.Year==2013)].Sales.plot(label='2013', figsize=(16,4))\nplt.title('Store {}'.format(rS))\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"We see some patters emerge. Let's make Date the index so that we have date's at the x-axis."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train.set_index('Date', inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"st = train[train.Store==rS] # Select store rS\nst['2013']['Sales'].plot(label='2013', figsize=(17,4), title='Store {}'.format(rS))\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"The sharp needles in the Sales that touch the zero axis are the sunday's. The reason is that on Sunday most store are not open and have no sales. Let's check that by summing all sales on Sunday's:"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[train.DayOfWeek==6].Sales.sum()"},{"cell_type":"markdown","metadata":{},"source":"This should be zero. How come it's not? The reason is that some store's are occasionally open on sunday:"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"salesOnSundayPerStore = train[(train.Open) & (train.DayOfWeek==6)].groupby('Store')['Sales']\nsalesOnSundayPerStore.count().sort_values().plot(kind='barh')\nplt.title('Number of sunday open per store')\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"Indeed, store number 85 had many open days on sunday:"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[(train.Store==85) & (train.DayOfWeek==6)].Sales.plot(figsize=(17,4))\nplt.title('Sales of store 85 on sundays')\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"Let's take a look to the sales of the store 979 and search for patterns."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def plotStore(rS):\n    st = train[train.Store==rS]\n    storerS13 = st[st.Year==2013].Sales.reset_index(drop=True)\n    storerS14 = st[st.Year==2014].Sales.reset_index(drop=True)\n    storerS15 = st[st.Year==2015].Sales.reset_index(drop=True)\n\n    df_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\n    df_plot.columns = ['2013', '2014', '2015']\n    df_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\n    df_plot.plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\n    plt.show()\nplotStore(979)"},{"cell_type":"markdown","metadata":{},"source":"From above chart, are task is clear. We have to predict how the read curve is continuing for 48 days starting from the first of august until and included 19 september. We can also spot some patterns. Peak's are the beginning of every month. The second week have rather constant sales. On the beginning of the third week, we see again peak altough a bit smaller than the beginning of the month. The reason for this patterns is probably paycheck days typically at the beginning of the month or in the middle of the month. Also in 2014 and 2015 we see a big peak in the beginning of July but not in 2013. Maybe a lot of Germans got extra holdiday money in 2014 and 2015 on there paycheck in July? Let's check another store."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS = 1013  # rS =  random.choice(train.Store.unique())\nplotStore(1013)"},{"cell_type":"markdown","metadata":{},"source":"Store 1013 has no extra big peak beginning of July. Let check another store."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS =  85 #random.choice(train.Store.unique())\nplotStore(rS)"},{"cell_type":"markdown","metadata":{},"source":"Store 85 looks different. Remember store 85 ? It's the store that is open on sundays a lot. Let check another store that is open on sunday a lot: store 769."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"plotStore(769)"},{"cell_type":"markdown","metadata":{},"source":"We are lucky because neither store 86 nor store 769 are to be predicted so we can ingnore them.\nStill have to check\nfor the other stores later.\n"},{"cell_type":"markdown","metadata":{},"source":"# First Prediction\nSales look rather a constant repeating pattern. Let's exploit that pattern to make a prediction. The most basic assuption could be that sales of the store in same period but one or two year ago are a good prediction for this year. "},{"cell_type":"markdown","metadata":{},"source":"Let's take the mean of August and the first two weeks of September in 2013 and 2014 as prediction:\n[http://i.imgur.com/3ii8Y0I.png](http://i.imgur.com/3ii8Y0I.png)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS = 1013\ntrainStore = train[train.Store == rS]\nprevy1 = trainStore.ix['2014-08-02':'2014-09-18']['Sales'].reset_index(drop=True)\nprevy2 = trainStore.ix['2013-08-03':'2013-09-19']['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\ndf_plot = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.columns = ['Prediction']\ndf_plot.plot(title='Prediction for store {}'.format(rS));"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Adapt above code so it runs on Kaggle\nrS = 1013\nperiodym1 = train.ix['2014-08-02':'2014-09-18']\nperiodym2 = train.ix['2013-08-03':'2013-09-19']\nprevy1 = periodym1[periodym1.Store == rS]['Sales'].reset_index(drop=True)\nprevy2 = periodym2[periodym2.Store == rS]['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\ndf_plot = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.columns = ['Prediction']\ndf_plot.plot(title='Prediction for store {}'.format(rS));"},{"cell_type":"markdown","metadata":{},"source":"Hoeray, we got our first prediction! Let's make a plot to find out how our prediction looks with respect to the trainings data."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS = 1013  # rS =  random.choice(train.Store.unique())\nstorerS13 = train[(train.Store==rS) & (train.Year==2013)].Sales.reset_index(drop=True)\nstorerS14 = train[(train.Store==rS) & (train.Year==2014)].Sales.reset_index(drop=True)\nstorerS15 = train[(train.Store==rS) & (train.Year==2015)].Sales.reset_index(drop=True)\n\ndf_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\ndf_plot.columns = ['2013', '2014', '2015']\ndf_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\ndf_plot['pred'] = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"Let's look to our prediction in 2015 alone:"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def plotTrainPred(rS, pred, title=None):\n    trainStore = train[train.Store==rS]\n    plotIndex = pd.date_range('1/1/2015', periods=270, freq='D')\n    df_plot = pd.DataFrame(trainStore['2015']['Sales'], index = plotIndex)\n    df_plot.columns = ['2015']\n    predIndex = pd.date_range('8/1/2015', periods=48, freq='D')\n    df_plot['pred'] = pd.DataFrame(pred, index = predIndex)\n    df_plot['2015'].plot(label='train')\n    if title:\n        df_plot['pred'].plot(label='pred', figsize=(17, 5), title=title)\n    else:\n        df_plot['pred'].plot(label='pred', figsize=(17, 5), title='Sales at store {} in 2015'.format(rS))\n    plt.legend();\n\nplotTrainPred(1013, meanSales)"},{"cell_type":"markdown","metadata":{},"source":"We spot two problems with our prediction. The first problem has to do with the size of our patterns. Beginning of month sale in 2015 are peaking between 6000 and 7000. Our prediction has peaks between 12000 adn 14000. That looks like a scaling problem. The second problem is that sales for store 1013 are anticyclical in 2013 with respect to 2014. The result is that the two week pattern in our prediction is gone! Before we tackle those problems, let's check another store."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS = 344\nperiodym1 = train.ix['2014-08-02':'2014-09-18']\nperiodym2 = train.ix['2013-08-03':'2013-09-19']\nprevy1 = periodym1[periodym1.Store == rS]['Sales'].reset_index(drop=True)\nprevy2 = periodym2[periodym2.Store == rS]['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n\nplotTrainPred(344, meanSales)"},{"cell_type":"markdown","metadata":{},"source":"Same problems in store 344. But here we have to scale up. Let check another store."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rs= 876 # rS =  random.choice(train.Store.unique())\nperiodym1 = train.ix['2014-08-02':'2014-09-18']\nperiodym2 = train.ix['2013-08-03':'2013-09-19']\nprevy1 = periodym1[periodym1.Store == rS]['Sales'].reset_index(drop=True)\nprevy2 = periodym2[periodym2.Store == rS]['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n\nplotTrainPred(876, meanSales)"},{"cell_type":"markdown","metadata":{},"source":"Store 876 is missing data in the last two weeks of July in 2015. Lukily our simple prediction model only use data from 2013 and 2014. Iterating above code several times with the random choise (see the comment) learns that all sales peaks differ between 2013 and 2014. Moreover the pattern changes around 1 August 2014. The last week of July 2014 is a peak but the first weak of August 2014 too ! Lets check some other stores:"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS = 265 # random.choice(train.Store.unique())\nperiodym1 = train.ix['2014-08-02':'2014-09-18']\nperiodym2 = train.ix['2013-08-03':'2013-09-19']\nprevy1 = periodym1[periodym1.Store == rS]['Sales'].reset_index(drop=True)\nprevy2 = periodym2[periodym2.Store == rS]['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n\nstorerS13 = train[(train.Store==rS) & (train.Year==2013)].Sales.reset_index(drop=True)\nstorerS14 = train[(train.Store==rS) & (train.Year==2014)].Sales.reset_index(drop=True)\nstorerS15 = train[(train.Store==rS) & (train.Year==2015)].Sales.reset_index(drop=True)\n\ndf_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\ndf_plot.columns = ['2013', '2014', '2015']\ndf_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\ndf_plot['pred'] = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"Let's see it if there's a montly pattern:"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"fig, ax = plt.subplots(1, 3, figsize=(16, 6), sharey=True)\ntrain2013 = train['2013']\ntrain2013.groupby(train2013.index.day)['Sales'].mean().plot(label='2013', ax=ax[0],\n    title='Monthly pattern of sales in 2013')\ntrain2014 = train['2014']\ntrain2014.groupby(train2014.index.day)['Sales'].mean().plot(label='2014', ax=ax[1],\n    title='Monthly pattern of sales in 2014')\ntrain2015 = train['2015']\ntrain2015.groupby(train2015.index.day)['Sales'].mean().plot(label='2015', ax=ax[2],\n     title='Monthly pattern of sales in 2014')\nplt.legend(loc='upper center')\nplt.title('Monthly pattern of sales in 2015');"},{"cell_type":"markdown","metadata":{},"source":"There is some pattern in 2015. Clearly peaks around the beginning and the end of the month. In 2013 and 2014, the pattern is not there on the average. Probably that's because the phase of the pattern changed in those years. Here's the two weekly pattern in 2013, 2014 and 2015:"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train2013 = train['2013']\ntrain2013.groupby(train2013.index.dayofyear%14)['Sales'].mean().plot(label='2013')\ntrain2014 = train['2014']\ntrain2014.groupby(train2014.index.dayofyear%14)['Sales'].mean().plot(label='2014')\ntrain2015 = train['2015']\ntrain2015.groupby(train2015.index.dayofyear%14)['Sales'].mean().plot(label='2015')\nplt.legend(loc='lower left');\nplt.title('14 days pattern of sales in 2013/14/15');"},{"cell_type":"markdown","metadata":{},"source":"Let's shift the green 2014 pattern 1 day to the left and the blue 2013 pattern 2 days to the left:"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train2013 = train['2013']\ntrain2013.groupby((train2013.index.dayofyear+12)%14)['Sales'].mean().plot(label='2013')\ntrain2014 = train['2014']\ntrain2014.groupby((train2014.index.dayofyear+13)%14)['Sales'].mean().plot(label='2014')\ntrain2015 = train['2015']\ntrain2015.groupby(train2015.index.dayofyear%14)['Sales'].mean().plot(label='2015')\nplt.legend(loc='lower left');\nplt.title('14 days pattern of sales in 2013/14/15');"},{"cell_type":"markdown","metadata":{},"source":"There you have it. In 2013 sales tend to peak on the second monday. In 2014 the peak is on the first monday.\n2015 is in between. Probably because the pattern switched during the year and the peaks are averiging out."},{"cell_type":"markdown","metadata":{},"source":"Also store 265 (and a lot of other stores that I checked switch in the pattern around end of \nJuly 20014 and beginning of August 2014. Let's use that for our prediction. \nLet's assume that the change in august is only in 2014 and not in 2015. \nSo we must start our prediction with a low week. \nWe can do that by taking the data from 2014 7 days further from the first saturday of august:\n[http://i.imgur.com/GrERfoZ.png](http://i.imgur.com/GrERfoZ.png)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"rS = 660 # random.choice(train.Store.unique())\nperiodym1 = train.ix['2014-08-09':'2014-09-25']\nperiodym2 = train.ix['2013-08-03':'2013-09-19']\nprevy1 = periodym1[periodym1.Store == rS]['Sales'].reset_index(drop=True)\nprevy2 = periodym2[periodym2.Store == rS]['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n\nstorerS13 = train[(train.Store==rS) & (train.Year==2013)].Sales.reset_index(drop=True)\nstorerS14 = train[(train.Store==rS) & (train.Year==2014)].Sales.reset_index(drop=True)\nstorerS15 = train[(train.Store==rS) & (train.Year==2015)].Sales.reset_index(drop=True)\n\ndf_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\ndf_plot.columns = ['2013', '2014', '2015']\ndf_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\ndf_plot['pred'] = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"periodym1 = train.ix['2014-08-09':'2014-09-25']\nperiodym1[periodym1.Store == 660]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[train.Store==600].index.min()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train[train.Store==600].index.max()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from IPython.display import Image\nImage('http://i.imgur.com/GrERfoZ.png')"},{"cell_type":"markdown","metadata":{},"source":"[http://i.imgur.com/GrERfoZ.png](http://i.imgur.com/GrERfoZ.png)"},{"cell_type":"markdown","metadata":{},"source":"can't display this image\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"periodym1 = train.ix['2014-08-02':'2014-09-18']\nperiodym2 = train.ix['2013-08-03':'2013-09-19']\nprevy1 = periodym1[periodym1.Store == rS]['Sales'].reset_index(drop=True)\nprevy2 = periodym2[periodym2.Store == rS]['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\ndf_plot = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.columns = ['Prediction']\ndf_plot.plot(title='Prediction for store {}'.format(rS));"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}