{"cells":[{"cell_type":"markdown","metadata":{},"source":"\n\n```python\nfrom __future__ import print_function\nfrom __future__ import division\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport random\n```\n\n\n```python\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom seaborn import set_style\nset_style(\"darkgrid\")\nimport seaborn as sns\n```\n\n    /usr/local/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n      warnings.warn(self.msg_depr % (key, alt_key))\n\n\n\n```python\ndef build_features(features, data):\n    # remove NaNs\n    data.fillna(0, inplace=True)\n    data.loc[data.Open.isnull(), 'Open'] = 1\n    # Use some properties directly\n    features.extend(['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday'])\n\n    # Label encode some features\n    features.extend(['StoreType', 'Assortment', 'StateHoliday'])\n    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n    data.StoreType.replace(mappings, inplace=True)\n    data.Assortment.replace(mappings, inplace=True)\n    data.StateHoliday.replace(mappings, inplace=True)\n\n    features.extend(['DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear'])\n    data['Year'] = data.Date.dt.year\n    data['Month'] = data.Date.dt.month\n    data['Day'] = data.Date.dt.day\n    data['DayOfWeek'] = data.Date.dt.dayofweek\n    data['WeekOfYear'] = data.Date.dt.weekofyear\n\n    # CompetionOpen en PromoOpen from https://www.kaggle.com/ananya77041/rossmann-store-sales/randomforestpython/code\n    # Calculate time competition open time in months\n    features.append('CompetitionOpen')\n    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n        (data.Month - data.CompetitionOpenSinceMonth)\n    # Promo open time in months\n    features.append('PromoOpen')\n    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n    data['PromoOpen'] = data.PromoOpen.apply(lambda x: x if x > 0 else 0)\n\n    # Indicate that sales on that day are in promo interval\n    features.append('IsPromoMonth')\n    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n             7:'Jul', 8:'Aug', 9:'Sept', 10:'Okt', 11:'Nov', 12:'Dec'}\n    data['monthStr'] = data.Month.map(month2str)\n    data.loc[data.PromoInterval == 0, 'PromoInterval'] = ''\n    data['IsPromoMonth'] = 0\n    for interval in data.PromoInterval.unique():\n        if interval != '':\n            for month in interval.split(','):\n                data.loc[(data.monthStr == month) & (data.PromoInterval == interval), 'IsPromoMonth'] = 1\n\n    return data\n```\n\n\n```python\nprint(\"Load the training, test and store data using pandas\")\ntypes = {'CompetitionOpenSinceYear': np.dtype(int),\n         'CompetitionOpenSinceMonth': np.dtype(int),\n         'StateHoliday': np.dtype(str),\n         'Promo2SinceWeek': np.dtype(int),\n         'SchoolHoliday': np.dtype(int),\n         'PromoInterval': np.dtype(str)}\ntrain = pd.read_csv(\"../input/train_filled_gap.csv\", parse_dates=[2], dtype=types)\ntest = pd.read_csv(\"../input/test.csv\", parse_dates=[3], dtype=types)\nstore = pd.read_csv(\"../input/store.csv\")\n```\n\n    Load the training, test and store data using pandas\n\n\n\n```python\nprint(\"Assume store open, if not provided\")\ntest.fillna(1, inplace=True)\n\n# print(\"Consider only open stores for training. Closed stores wont count into the score.\")\n# train = train[train[\"Open\"] != 0]\n# print(\"Use only Sales bigger then zero\")\n# train = train[train[\"Sales\"] > 0]\n\nprint(\"Join with store\")\ntrain = pd.merge(train, store, on='Store')\ntest = pd.merge(test, store, on='Store')\n\nfeatures = []\n\nprint(\"augment features\")\ntrain = build_features(features, train)\ntest = build_features([], test)\nprint(features)\n\nprint('training data processed')\n```\n\n    Assume store open, if not provided\n    Join with store\n    augment features\n    ['Store', 'CompetitionDistance', 'Promo', 'Promo2', 'SchoolHoliday', 'StoreType', 'Assortment', 'StateHoliday', 'DayOfWeek', 'Month', 'Day', 'Year', 'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']\n    training data processed\n\n\nWhat must be forecasted ? The sales per store. For what period ?\n\n\n```python\nprint ('From',test.Date.min(),'to', test.Date.max())\nprint ('That is', test.Date.max()-test.Date.min(), 'days')\n```\n\n    From 2015-08-01 00:00:00 to 2015-09-17 00:00:00\n    That is 47 days 00:00:00 days\n\n\nFor how many stores ?\n\n\n```python\ntest.Store.nunique()\n```\n\n\n\n\n    856\n\n\n\nLet's take a random store from the trainings data and plot how the Sales data looks like\n\n\n```python\nrS = 979 # rS =  random.choice(train.Store.unique())\nprint ('Random store number =', rS)\n```\n\n    Random store number = 979\n\n\nHow many year's of data do we have in the trainingset?\n\n\n```python\ntrain.Year.unique()\n```\n\n\n\n\n    array([2013, 2014, 2015])\n\n\n\nLet look at the sales of store 979 in 2013\n\n\n```python\ntrain[(train.Store==rS) & (train.Year==2013)].Sales.plot(label='2013', figsize=(18,4))\nplt.title('Store {}'.format(rS))\nplt.show()\n```\n\n\n![png](output_14_0.png)\n\n\nWe see some patters emerge. Let's make Date the index so that we have date's at the x-axis.\n\n\n```python\ntrain.set_index('Date', inplace=True)\n```\n\n\n```python\nst = train[train.Store==rS] # Select store rS\nst['2013']['Sales'].plot(label='2013', figsize=(18,4), title='Store {}'.format(rS))\nplt.show()\n```\n\n\n![png](output_17_0.png)\n\n\nThe sharp needles in the Sales that touch the zero axis are the sunday's.\nThe reason is that on Sunday most store are not open\nand have no sales. Let's check that by summing all sales on Sunday's:\n\n\n```python\ntrain[train.DayOfWeek==6].Sales.sum()\n```\n\n\n\n\n    29551433.0\n\n\n\nThis should be zero. How come it's not?\nThe reason is that some store's are occasionally open on sunday:    \n\n\n```python\nsalesOnSundayPerStore = train[(train.Open) & (train.DayOfWeek==6)].groupby('Store')['Sales']\nsalesOnSundayPerStore.count().sort_values().plot(kind='barh')\nplt.title('Number of sunday open per store')\nplt.show()\n```\n\n\n![png](output_21_0.png)\n\n\nIndeed, store number 85 had many open days on sunday:\n\n\n```python\ntrain[(train.Store==85) & (train.DayOfWeek==6)].Sales.plot(figsize=(18,4))\nplt.title('Sales of store 85 on sundays')\nplt.show()\n```\n\n\n![png](output_23_0.png)\n\n\nLet's take a look to the sales of the store 979 and search for patterns.\n\n\n```python\n# fig, axes = plt.subplots(3, 1, figsize=(18, 4));\ndef plotStore(rS):\n    st = train[train.Store==rS]\n    storerS13 = st[st.Year==2013].Sales.reset_index(drop=True)\n    storerS14 = st[st.Year==2014].Sales.reset_index(drop=True)\n    storerS15 = st[st.Year==2015].Sales.reset_index(drop=True)\n\n    df_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\n    df_plot.columns = ['2013', '2014', '2015']\n    df_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\n    df_plot.plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\n    plt.show()\nplotStore(rS)\n```\n\n\n![png](output_25_0.png)\n\n\nFrom above chart, are task is clear. We have to predict how the read curve is continuing for\n48 days starting from the first of august until and included 19 september. We can also spot\nsome patterns. Peak's are the beginning of every month. The second week have rather constant\nsales. On the beginning of the third week, we see again peak altough a bit smaller than the\nbeginning of the month. The reason for this patterns is probably paycheck days typically at\nthe beginning of the month or in the middle of the month. Also in 2014 and 2015 we see a big peak in the beginning of July but not in 2013. Maybe a lot of Germans got extra holdiday money in 2014 and 2015 on there paycheck in July? Let's check another store.\n\n\n```python\nrS = 1013  # rS =  random.choice(train.Store.unique())\nplotStore(1013)\n```\n\n\n![png](output_27_0.png)\n\n\nStore 1013 has no extra big peak beginning of July.\nLet check another store. \n\n\n```python\nrS =  85 #random.choice(train.Store.unique())\nplotStore(rS)\n```\n\n\n![png](output_29_0.png)\n\n\nStore 85 looks different. Remeber store 85 ? It's the store that is open on sundays a lot. Let check another store \nthat is open on sunday a lot: store 769.\n\n\n```python\nplotStore(769)\n```\n\n\n![png](output_31_0.png)\n\n\nWe are lucky because neither store 86 nor store 769 are to be predicted so we can ingnore them. Still have to check\nfor the other stores later.\n\n# First Prediction\nSales look rather a constant repeating pattern. Let's exploit that pattern to make a prediction. The most basic assuption could be that sales of the store in same period but one or two year ago are a good prediction for this year. Let's take the mean of August and the first two weeks of September in 2013 and 2014 as prediction:\n\n\n\n```python\ntrainStore = train[train.Store == rS]\nprevy1 = trainStore.ix['2014-08-02':'2014-09-18']['Sales'].reset_index(drop=True)\nprevy2 = trainStore.ix['2013-08-03':'2013-09-19']['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\ndf_plot = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.columns = ['Prediction']\ndf_plot.plot(title='Prediction for store {}'.format(rS));\n```\n\n\n![png](output_34_0.png)\n\n\nHoeray, we got our first prediction! Let's make a plot to find out how our prediction looks\nwith respect to the trainings data.\n\n\n```python\nrS = 1013  # rS =  random.choice(train.Store.unique())\nstorerS13 = train[(train.Store==rS) & (train.Year==2013)].Sales.reset_index(drop=True)\nstorerS14 = train[(train.Store==rS) & (train.Year==2014)].Sales.reset_index(drop=True)\nstorerS15 = train[(train.Store==rS) & (train.Year==2015)].Sales.reset_index(drop=True)\n\ndf_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\ndf_plot.columns = ['2013', '2014', '2015']\ndf_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\ndf_plot['pred'] = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\nplt.show()\n```\n\n\n![png](output_36_0.png)\n\n\nLet's look to our prediction in 2015 alone:\n\n\n```python\ndef plotTrainPred(rS, pred, title=None):\n    trainStore = train[train.Store==rS]\n    plotIndex = pd.date_range('1/1/2015', periods=270, freq='D')\n    df_plot = pd.DataFrame(trainStore['2015']['Sales'], index = plotIndex)\n    df_plot.columns = ['2015']\n    predIndex = pd.date_range('8/1/2015', periods=48, freq='D')\n    df_plot['pred'] = pd.DataFrame(pred, index = predIndex)\n    df_plot['2015'].plot(label='train')\n    if title:\n        df_plot['pred'].plot(label='pred', figsize=(19, 5), title=title)\n    else:\n        df_plot['pred'].plot(label='pred', figsize=(19, 5), title='Sales at store {} in 2015'.format(rS))\n    plt.legend();\n\nplotTrainPred(1013, meanSales)\n```\n\n\n![png](output_38_0.png)\n\n\nWe spot two problems with our prediction. The first problem has to do with the size of our patterns. Beginning of month sale in 2015 are peaking between 6000 and 7000. Our prediction has peaks between 12000 adn 14000.\nThat looks like a scaling problem. The second problem is that sales for store 1013 are anticyclical in 2013 with respect to 2014. The result is that the two week pattern in our prediction is gone! Before we tackle those problems, let's check another store.\n\n\n```python\nrS = 344 # rS =  random.choice(train.Store.unique())\ntrainStore = train[train.Store == rS]\nprevy1 = trainStore.ix['2014-08-02':'2014-09-18']['Sales'].reset_index(drop=True)\nprevy2 = trainStore.ix['2013-08-03':'2013-09-19']['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n\nplotTrainPred(344, meanSales)\n```\n\n\n![png](output_40_0.png)\n\n\nSame problems in store 344. But here we have to scale up. Let check another store.\n\n\n```python\nrs= 876 # rS =  random.choice(train.Store.unique())\ntrainStore = train[train.Store == rS]\nprevy1 = trainStore.ix['2014-08-02':'2014-09-18']['Sales'].reset_index(drop=True)\nprevy2 = trainStore.ix['2013-08-03':'2013-09-19']['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n\nplotTrainPred(876, meanSales)\n```\n\n\n![png](output_42_0.png)\n\n\nStore 876 is missing data in the last two weeks of July in 2015. Lukily our simple prediction model only\nuse data from 2013 and 2014. \nIterating above code several times with the random choise (see the comment) learns that all sales peaks differ\nbetween 2013 and 2014. Moreover the pattern changes around 1 August 2014. The last week of July 2014 is a peak but the first weak of August 2014 too !\nLets check some other stores:\n\n\n```python\nrS = 265 # random.choice(train.Store.unique())\ntrainStore = train[train.Store == rS]\nprevy1 = trainStore.ix['2014-08-02':'2014-09-18']['Sales'].reset_index(drop=True)\nprevy2 = trainStore.ix['2013-08-03':'2013-09-19']['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n\nstorerS13 = train[(train.Store==rS) & (train.Year==2013)].Sales.reset_index(drop=True)\nstorerS14 = train[(train.Store==rS) & (train.Year==2014)].Sales.reset_index(drop=True)\nstorerS15 = train[(train.Store==rS) & (train.Year==2015)].Sales.reset_index(drop=True)\n\ndf_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\ndf_plot.columns = ['2013', '2014', '2015']\ndf_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\ndf_plot['pred'] = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\nplt.show()\n```\n\n\n![png](output_44_0.png)\n\n\nAlso store 265 (and a lot of other stores that I checked switch in the pattern around end of July 20014 and beginning\nof August 2014. Let's use that for our prediction. Let's assume that the change in august is\nonly in 2014 and not in 2015. So we must start our prediction with a low week. We can do that\nby taking the data from 2014 7 days further from the first saturday of august:\n\n\n\n```python\nrS = 660 # random.choice(train.Store.unique())\ntrainStore = train[train.Store == rS]\nprevy1 = trainStore.ix['2014-08-09':'2014-09-25']['Sales'].reset_index(drop=True)\nprevy2 = trainStore.ix['2013-08-03':'2013-09-19']['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n\nstorerS13 = train[(train.Store==rS) & (train.Year==2013)].Sales.reset_index(drop=True)\nstorerS14 = train[(train.Store==rS) & (train.Year==2014)].Sales.reset_index(drop=True)\nstorerS15 = train[(train.Store==rS) & (train.Year==2015)].Sales.reset_index(drop=True)\n\ndf_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\ndf_plot.columns = ['2013', '2014', '2015']\ndf_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\ndf_plot['pred'] = pd.DataFrame(meanSales, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot.plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\nplt.show()\n```\n\n\n![png](output_46_0.png)\n\n\nSee, the prediction for store 660 in august 2015 starts with a low week, has a peak in the second week, a low constant third week\nand so on. Let's plot 2015 only:\n\n\n```python\nplotTrainPred(660, meanSales)\n```\n\n\n![png](output_48_0.png)\n\n\nOkay, now the prediction for store 660 has the desired two weekly pattern but is still suffering\nfrom a scaling issue. Peak sales in 2015 are around 10000 and our prediction peaks to 8000.\nLet's scale our prediction. First find the peaks in 2015:\n\n\n```python\ntrain[(train.Store==rS) & (train.Year==2015) & (train.Sales > 7000)]['Sales']\n```\n\n\n\n\n    Date\n    2015-01-05    8771\n    2015-01-12    7691\n    2015-01-26    7143\n    2015-02-02    8254\n    2015-02-16    8583\n    2015-03-02    7206\n    2015-03-16    7785\n    2015-03-30    9686\n    2015-03-31    7924\n    2015-04-13    7547\n    2015-04-27    7313\n    2015-04-30    7526\n    2015-05-04    7725\n    2015-05-18    7241\n    2015-06-01    7922\n    2015-06-05    7144\n    2015-06-15    7261\n    2015-06-16    7652\n    2015-06-29    9529\n    2015-06-30    8210\n    2015-07-13    8957\n    2015-07-14    7158\n    2015-07-27    8778\n    2015-07-28    7592\n    2015-07-30    7027\n    Name: Sales, dtype: float64\n\n\n\nHere we spot the pattern. Sales are peaking around the beginning of the month and in the middle the month. There are exception to this pattern but let's ignore them for a moment and concentrate on the beginning of the month first.\n\n\n```python\npeakIndex= (train.Store==rS) & (train.Year==2015) & (train.Sales > 7500)\npeakIndexStartMonth = peakIndex & ((train.Day > 26) | (train.Day < 6))\npeakSalesStartMonth = train[peakIndexStartMonth]['Sales']\nprint (peakSalesStartMonth)\nprint ('Mean peak Sales beginning of the month', peakSalesStartMonth.mean())\n```\n\n    Date\n    2015-01-05    8771\n    2015-02-02    8254\n    2015-03-30    9686\n    2015-03-31    7924\n    2015-04-30    7526\n    2015-05-04    7725\n    2015-06-01    7922\n    2015-06-29    9529\n    2015-06-30    8210\n    2015-07-27    8778\n    2015-07-28    7592\n    Name: Sales, dtype: float64\n    Mean peak Sales beginning of the month 8356.09090909\n\n\nWe still have more then one peak per month. Let's just take the maximum of each month:\n\n\n```python\ntrain[(train.Store == rS)  & (train.Year == 2015)].groupby('Month')['Sales'].max()\n```\n\n\n\n\n    Month\n    1    8771\n    2    8583\n    3    9686\n    4    7547\n    5    7725\n    6    9529\n    7    8957\n    Name: Sales, dtype: float64\n\n\n\nThe mean of the peak's:\n\n\n```python\ntrainrS15 = train[(train.Store == rS)  & (train.Year == 2015)]\nmeanPeaks=trainrS15.groupby('Month')['Sales'].max().mean()\nprint (meanPeaks)\n```\n\n    8685.42857143\n\n\nThe maximum's per month in our prediction are:\n\n\n```python\npredPeaks = df_plot['pred'].groupby(df_plot.index.month).max()\npredPeaks[predPeaks.notnull()]\n```\n\n\n\n\n    8    7262\n    9    7752\n    Name: pred, dtype: float64\n\n\n\nThe mean of the peak's:\n\n\n```python\npredPeakMean = predPeaks[predPeaks.notnull()].mean()\nprint (predPeakMean)\n```\n\n    7507.0\n\n\nLet's scale our prediction and plot them (first unscaled for reference and then scaled):\n\n\n```python\ntrainStore = train[train.Store == rS]\nprevy1 = trainStore.ix['2014-08-09':'2014-09-25']['Sales'].reset_index(drop=True)\nprevy2 = trainStore.ix['2013-08-03':'2013-09-19']['Sales'].reset_index(drop=True)\nmeanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\nscaledMeanSales = meanSales * (meanPeaks/predPeakMean)\nplotTrainPred(660, meanSales, 'Unscaled prediction for store 660 in 2015')\nplt.show()\nplotTrainPred(660, scaledMeanSales, 'Scaled prediction for store 660 in 2015')\n```\n\n\n![png](output_62_0.png)\n\n\n\n![png](output_62_1.png)\n\n\nOkay, the pattern and the scaling looks reasonably. Let's apply prediction for all the stores that must be predicted:\n\n\n```python\nfor rS in test.Store.unique():\n    trainStore = train[train.Store == rS]\n    prevy1 = trainStore.ix['2014-08-09':'2014-09-25']['Sales'].reset_index(drop=True)\n    prevy2 = trainStore.ix['2013-08-03':'2013-09-19']['Sales'].reset_index(drop=True)\n    meanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n    predRange = pd.date_range('8/1/2015', periods=48, freq='D')\n    df_meanSales = pd.DataFrame(meanSales, index = predRange)\n    meanPredPeaks = df_meanSales.groupby(df_meanSales.index.month).max().mean()\n    trainrS15 = train[(train.Store == rS)  & (train.Year == 2015)]\n    meanPeaks=trainrS15.groupby('Month')['Sales'].max().mean()\n    pred = meanSales * (meanPeaks/predPeakMean)\n    test.loc[test.Store == rS, 'Sales'] = pred\n```\n\nLet's check our prediction visually for some store's\n\n\n```python\nrS = 341 # random.choice(train.Store.unique())\nplotTrainPred(341, test[test.Store==rS]['Sales'].values)\n```\n\n\n![png](output_66_0.png)\n\n\n\n```python\nrS = 1047 # random.choice(train.Store.unique())\nplotTrainPred(341, test[test.Store==rS]['Sales'].values)\n```\n\n\n![png](output_67_0.png)\n\n\nThe prediction for store's 341 and 1047 look promising. Let's make a submission and check the\nscore on the leaderboard.\n\n\n```python\ntest.loc[ test.Open == 0, 'Sales' ] = 0\n\nresult = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': test['Sales']})\nassert result.Sales.dropna().shape[0] == 41088\nresult.to_csv(\"timeserie_8_submission.csv\", index=False)\n```\n\nChecking this prediction gives a really bad score of: 0.79625 ! Damn. There are some possibilities. Or there is some problem (an assumption error or a programming bug) in above code. Or the assumption about the first weeks and the pattern thereafter was the wrong choice. Let try the other assumption. There's peak in the last week of July 2015, a peak in the first week of august 2015, followed by a valley in week two of august 2015 and so on. We do this by averinging the series of sales starting in the second week in augustus 2013 (a peak) and the first week of august in 2014 (also a peak):\n\n\n\n```python\nfor rS in test.Store.unique():\n    trainStore = train[train.Store == rS]\n    prevy1 = trainStore.ix['2014-08-02':'2014-09-18']['Sales'].reset_index(drop=True)\n    prevy2 = trainStore.ix['2013-08-10':'2013-09-26']['Sales'].reset_index(drop=True)\n    meanSales = np.mean(np.vstack((prevy1, prevy2)), axis=0)\n    predRange = pd.date_range('8/1/2015', periods=48, freq='D')\n    df_meanSales = pd.DataFrame(meanSales, index = predRange)\n    meanPredPeaks = df_meanSales.groupby(df_meanSales.index.month).max().mean()\n    trainrS15 = train[(train.Store == rS)  & (train.Year == 2015)]\n    meanPeaks = trainrS15.groupby('Month')['Sales'].max().mean()\n    pred = meanSales * (meanPeaks/predPeakMean)\n    test.loc[test.Store == rS, 'Sales'] = pred\n```\n\n\n```python\nrS = 1047 # random.choice(train.Store.unique())\nstorerS13 = train[(train.Store==rS) & (train.Year==2013)].Sales.reset_index(drop=True)\nstorerS14 = train[(train.Store==rS) & (train.Year==2014)].Sales.reset_index(drop=True)\nstorerS15 = train[(train.Store==rS) & (train.Year==2015)].Sales.reset_index(drop=True)\n\ndf_plot = pd.concat([storerS13, storerS14, storerS15], axis=1)\ndf_plot.columns = ['2013', '2014', '2015']\ndf_plot.index = pd.date_range('1/1/2015', periods=365, freq='D')\npred = test[test.Store==rS]['Sales'].values\ndf_plot['pred'] = pd.DataFrame(pred, index = pd.date_range('8/1/2015', periods=48, freq='D'))\ndf_plot['2015+pred'] = df_plot['2015'].fillna(0) + df_plot['pred'].fillna(0)\ndf_plot[['2013','2014','2015+pred']].plot(subplots=True,figsize=(18, 6), title='Sales at store {}'.format(rS))\nplt.show()\n```\n\n\n![png](output_72_0.png)\n\n\n\n```python\nrS = 1047\nplotTrainPred(1047, test[test.Store==rS]['Sales'].values)\n```\n\n\n![png](output_73_0.png)\n\n\n\n```python\ntest.loc[ test.Open == 0, 'Sales' ] = 0\n\nresult = pd.DataFrame({\"Id\": test[\"Id\"], 'Sales': test['Sales']})\nassert result.Sales.dropna().shape[0] == 41088\nresult.to_csv(\"timeserie_9_submission.csv\", index=False)\n```\n\nThis score even worse: 0.78191. Okay, back to the drawing board.\n\nYou probably think that applying the bazooka solution in the toolbelt of most datascientiest might help. Let's try XGBoost. The best public solution on the leaderboard (as of mon 16 november 2015) obtains a RMSPE of 0.10361 ! Let's download that solution and plot the solutions after training XGBoost for hour's and plot them for store's 341, 660, 1013 and 1047:\n\n\n```python\npredValues = pd.read_csv('rf1.csv')\ntest.Sales = predValues.Sales\nplotTrainPred(341, test[test.Store==341]['Sales'].values)\nplotTrainPred(660, test[test.Store==660]['Sales'].values)\nplotTrainPred(1013, test[test.Store==1013]['Sales'].values)\nplotTrainPred(1047, test[test.Store==1047]['Sales'].values,title='XGBoost prediction for 341, 660, 1013 and 1047 store')\n```\n\n\n![png](output_77_0.png)\n\n\nWe see that sales for the four store have a reasonable pattern but that the prediction obtained trough XGBoost go in\nall directions ! So, our simple timeserie approach was perhaps to simple but still promising. But that's for another weekend....\n\n\n```python\n\n```\n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}