{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Rossmann Store Data Analysis and Sales Prediction\n### Created by : Ezhilarasan \nTo analyse Rossmann Store Data and prodict the future Sales using XGB Regressor along with Parameter Tuning (using Randomized Search)\n"},{"metadata":{},"cell_type":"markdown","source":"Import necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler \n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom xgboost.sklearn import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport gc\nfrom scipy.stats import uniform\nimport calendar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read given datasets (train & store)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/rossmann-store-sales/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store = pd.read_csv(\"/kaggle/input/rossmann-store-sales/store.csv\")\nstore.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the data set for any null values and correct (fill with some values or drop them)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#store.shape\n#store.dropna(inplace=True)\n#store.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replace numerical values for the columns which have labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"store['StoreType'].value_counts()\nstore['Assortment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store['StoreType']= store['StoreType'].map({'a':1, 'b' : 2, 'c': 3, 'd' : 4})\nstore['Assortment'] = store['Assortment'].map({'a':1, 'b' : 2, 'c': 3})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge train and store data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(train, store,on = 'Store', how='left')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"StateHoliday field has label values. we will convert the values to numeric group"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data['StateHoliday'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Date column has to be converted to numerical fields"},{"metadata":{},"cell_type":"markdown","source":"Since the data size is more (almost 10 lakhs) and system is hanging if I run fulle data set, I am trying to minimize the data set before processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tried with reducing the dataset by taking only the records have Sales > 0.\n#still system is getting longer time for procesing the model\n\n#data = data[data['Sales'] > 0]\n\ndata.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will process the dataset for changing the date field to numerical fields and StateHoliday field as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"# credits to kaggle link on specifying how to handle date and month values\n# https://www.kaggle.com/rohinigarg/random-forest-and-xgboost-parameter-tuning\n\ndef checkpromomonth(row):\n if (row['MonthName'] in row['PromoInterval']):\n    return 1\n else:\n    return 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ProcessData(data):\n    data[\"CompetitionDistance\"].fillna(data[\"CompetitionDistance\"].mean(), inplace = True)\n    \n    data['StateHoliday']= data['StateHoliday'].map({'0':0, 0: 0,'a':1, 'b' : 2, 'c': 3})\n    \n    data['Date']=pd.to_datetime(data['Date'])\n    data['Year']=data['Date'].dt.year\n    data['MonthNumber']=data['Date'].dt.month\n    data['MonthName']=data['MonthNumber'].apply(lambda x: calendar.month_abbr[x])\n    data['Day']=data['Date'].dt.day\n    data['WeekNumber']=data['Date'].dt.weekofyear\n\n    data['CompetitionOpen'] = 12 * (data['Year'] - data['CompetitionOpenSinceYear']) + (data['MonthNumber'] - data['CompetitionOpenSinceMonth'])\n    data['CompetitionOpen'] = data['CompetitionOpen'].apply(lambda x: x if x > 0 else 0)\n\n    data['Promo2Open'] = 12 * (data['Year'] - data['Promo2SinceYear']) + (data['WeekNumber'] - data['Promo2SinceWeek']) / float(4)\n    data['Promo2Open'] = data['Promo2Open'].apply(lambda x: x if x > 0 else 0)\n\n    data['PromoInterval']=data['PromoInterval'].astype(str)\n    \n    data['IsPromoMonth'] =  data.apply(lambda row: checkpromomonth(row),axis=1)\n\n    data.drop(['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear'], axis = 1,  inplace = True)\n    data.drop(['Promo2SinceYear', 'Promo2SinceWeek'], axis = 1,  inplace = True)\n    data.drop(['Date', 'MonthName','PromoInterval'], axis = 1,  inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ProcessData(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will check minimum and maximum values of the data set and try to reduce the memory size"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.min().min()           \ndata.max().max() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we use the organized data set for regression problem"},{"metadata":{},"cell_type":"markdown","source":"drop both sales and customer column in train data set since in test data set sales and customer fields are not there. before that use sales as target variable from train data set as we will be predicting sales in test data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['Sales']\ndata.drop(['Sales','Customers'], axis = 1,  inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_columns = data.columns[data.nunique() > 12]\ncat_columns = data.columns[data.nunique() <= 12]\nnum_columns\ncat_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.distributions._has_statsmodels=False\nfor i in range(len(num_columns)):\n    plt.subplot(2,3,i+1)\n    sns.distplot(data[num_columns[i]])\n    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the graph, we will use RobustScaler for the numerical column"},{"metadata":{"trusted":true},"cell_type":"code","source":"ct=ColumnTransformer([\n    ('rs',RobustScaler(),num_columns),\n    ('ohe',OneHotEncoder(),cat_columns),\n    ],\n    remainder=\"passthrough\"\n    )\nct.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use the scaled data split it internally to train and test, create our model and predict the test data (before going to predict the Sales for the actual test data given in the kaggle link)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape\nX_test.shape\ny_train.shape\ny_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pipeline creation for XGB Regressor. "},{"metadata":{"trusted":true},"cell_type":"code","source":"steps_xg = [('sts', StandardScaler() ),\n            ('pca', PCA()),\n            ('xg',  XGBRegressor(objective='reg:squarederror',silent = False, n_jobs=3, reg_lambda=1,gamma=0))\n            ]\n\npipe_xg = Pipeline(steps_xg)\n\npipe_xg.get_params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below function is for evluating the RMSPE (Root Mean Square Percentage Error)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#credit : https://www.kaggle.com/tushartilwankar/sklearn-rf\ndef ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1./(y[ind]**2)\n    return w\n\ndef RMSPE(y, yhat):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.metrics import make_scorer, r2_score, mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use Random Search for tuning the pipeline parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Randomized Search\nparameters = {'xg__learning_rate':  uniform(0, 1),\n              'xg__n_estimators':   range(50,300),\n              'xg__max_depth':      range(3,10),\n              'pca__n_components' : range(10,17)}\n\nrs = RandomizedSearchCV(pipe_xg,\n                        param_distributions=parameters,\n                        #scoring=make_scorer(mean_squared_error, squared=False),\n                        #scoring= RMSPE,\n                        n_iter=15,    \n                        verbose = 1,\n                        #refit = RMSPE,\n                        n_jobs = 3,\n                        cv = 3              \n                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nrs.fit(X_train, y_train)\nend = time.time()\n(end - start)/60 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs.best_estimator_.named_steps[\"xg\"].feature_importances_\nrs.best_estimator_.named_steps[\"xg\"].feature_importances_.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the Model with the best parameters from RandomSearch Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model with parameters of random search\nmodel_rs = XGBRegressor(objective='reg:squarederror',silent = False, n_jobs=3, reg_lambda=1,gamma=0,\n                    learning_rate = rs.best_params_['xg__learning_rate'],\n                    max_depth = rs.best_params_['xg__max_depth'],\n                    n_estimators=rs.best_params_['xg__max_depth']\n                    )\n\n\nmodel_rs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict our test data in the final model created"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rs = model_rs.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSPE(y_test,y_pred_rs)\n\nrs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"accuracy_rs =  math.sqrt(sum((y_test - y_pred_rs)**2)/y_test.count())\nprint(\"Accuracy with Random search XGB model:\",accuracy_rs*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will check the predicted sales values from randomized search with target data as below"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_df = X_test.reset_index()\ny_test_df = y_test.reset_index()\ny_pred_df  = pd.DataFrame(y_pred_rs)\n\nfinal = X_test_df\n#final\nfinal = final.merge(y_test_df, left_index=True, right_index=True)\nfinal = final.merge(y_pred_df, left_index=True, right_index=True)\nfinal","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the above table, last 2 columns (Actual Sales & Predicted Sales) are relatively matching."},{"metadata":{},"cell_type":"markdown","source":"We will load test dat given in the kaggle merge with store data, process it and predict the sales in our randomized search model"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/rossmann-store-sales/test.csv\")\ntest.head()\n\ntest.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will consider 0 where the Store field has null value"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Open.fillna(0, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(test, store,on = 'Store', how='left')\ndata.head()\n\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ProcessData(data)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = data['Id']\ndata=data.drop('Id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.min().min()           \ndata.max().max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_columns = data.columns[data.nunique() > 12]\ncat_columns = data.columns[data.nunique() <= 12]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_columns\ncat_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.distributions._has_statsmodels=False\nfor i in range(len(num_columns)):\n    plt.subplot(2,3,i+1)\n    graph = sns.distplot(data[num_columns[i]])\n    \nplt.tight_layout()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct=ColumnTransformer([\n    ('rs',RobustScaler(),num_columns),\n    ('ohe',OneHotEncoder(),cat_columns),\n    ],\n    remainder=\"passthrough\"\n    )\nct.fit_transform(data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rs = model_rs.predict(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = submission.reset_index()\ny_pred_df  = pd.DataFrame(y_pred_rs)\n\nfinal = final.merge(y_pred_df, left_index=True, right_index=True)\nfinal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion : We could predict the Sales using XGB Regressor (upon parameter tuning using Random Search)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}