{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"## DATA SHAPE","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/rossmann-store-sales/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"storedf = pd.read_csv(\"/kaggle/input/rossmann-store-sales/store.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"storedf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DATA TYPE","metadata":{}},{"cell_type":"code","source":"storedf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"storedf.isna().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().any() # is null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge \nMerging store data frame and sales record dataframe to get flat and single dataframe","metadata":{}},{"cell_type":"code","source":"mergedf = df.merge(storedf,on=[\"Store\"],how=\"inner\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergedf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Statistical Data Visualization\n","metadata":{}},{"cell_type":"markdown","source":"#### Maximum minimum average sale count","metadata":{}},{"cell_type":"code","source":"# Store with maximum sale count\nmergedf[mergedf[\"Sales\"] == mergedf[\"Sales\"].max()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLOT: store sale with maximum sale count \n\ndf_max_store = mergedf[mergedf[\"Store\"] == 909]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_max_store[[\"Date\",\"Sales\"]].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nmergedf['Date'] = pd.to_datetime(mergedf['Date'],infer_datetime_format=True)\nmergedf['Month'] = mergedf[\"Date\"].dt.month\nmergedf['Quarter'] = mergedf[\"Date\"].dt.quarter\nmergedf[\"Year\"] = mergedf[\"Date\"].dt.year\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergedf[\"Day\"] = mergedf[\"Date\"].dt.day\nmergedf[\"Week\"] = mergedf[\"Date\"].dt.week\nmergedf[\"Season\"] = np.where(mergedf[\"Month\"].isin([3,4,5]),\"spring\",\n                            np.where(mergedf[\"Month\"].isin([6,7,8]),\n                                    \"summer\",np.where(mergedf[\"Month\"].isin([9,10,11]),\"fall\",\n                                                     np.where(mergedf[\"Month\"].isin([12,1,2]),\n                                                             \"winter\",\"None\"))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mergedf[[\"Date\",\"Year\",\"Month\",\"Day\",\"Week\",\"Quarter\",\"Season\"]].head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.hist(mergedf[\"Sales\"])\nplt.title(\"Histogram for Store Sales\")\nplt.xlabel(\"bins\")\nplt.xlabel(\"Frequency\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergedf.hist(figsize=(20,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergedf.isnull().sum()/mergedf.shape[0] * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \nsns.set(style=\"whitegrid\")\n\nax = sns.barplot(x=\"Season\", y=\"Sales\", data=mergedf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x=\"Assortment\",y=\"Sales\",data=mergedf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x=\"StoreType\",y=\"Sales\",data=mergedf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x=\"Season\", y=\"Sales\", data=mergedf,estimator=np.size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x=\"Assortment\", y=\"Sales\", data=mergedf,estimator=np.size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.barplot(x=\"StoreType\", y=\"Sales\", data=mergedf,estimator=np.size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA PREPARATION","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\ntarget = [\"Sales\"]\nnumeric_columns = [\"Customers\",\"Open\",\"Promo\",\"Promo2\", \"StateHoliday\",\"SchoolHoliday\",\"CompetitionDistance\"]\ncategorical_columns = [\"DayOfWeek\",\"Quarter\",\"Month\",\"Year\",\"StoreType\",\"Assortment\",\"Season\"]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergedf.isna().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mergedf[\"CompetitionDistance\"]=mergedf[\"CompetitionDistance\"].fillna(mergedf[\"CompetitionDistance\"].mode()[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ONE HOT ENCODING","metadata":{}},{"cell_type":"code","source":"def one_hot(df,column):\n    \n    uniqueList = df[column].unique()\n    \n    \n    temp = pd.DataFrame()\n    i = 1\n    for item in uniqueList:\n        \n        cname = str(column)+\"_\"+str(i)\n        \n        temp[cname] = [1 if d == True else 0 for d in mergedf[column]==item]\n        \n        \n        i+=1\n        \n    \n    return temp\n\n#mergedf[\"Year\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctemp = pd.DataFrame()\nfirst = True\n\nfor c in categorical_columns:\n\n\n    ttdf = one_hot(mergedf[[c]],c)\n    \n    if first == True:\n        ctemp = ttdf.copy()\n        first = False\n    else:\n        ctemp = pd.concat([ctemp,ttdf], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctemp # checking one-hot encoding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = pd.concat([ctemp,mergedf[numeric_columns]],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#total columns\n\nlen(temp.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all columns \n\ntemp.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making StateHoliday numerical\n\ntemp[\"StateHoliday\"] = [ 1 if a == 'b' else 0 for a in list(temp[\"StateHoliday\"])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SPLITING TRAIN TEST DATA","metadata":{}},{"cell_type":"code","source":"\nx_train, x_test, y_train, y_test = train_test_split(temp,mergedf[target],test_size=0.2,random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,test_size=0.1,random_state=42)\nprint(\"Shape of x_train:\",x_train.shape)\nprint(\"Shape of x_val:\",x_val.shape)\nprint(\"Shape of x_test:\",x_test.shape)\nprint(\"Shape of y_train:\",y_train.shape)\nprint(\"Shape of y_val:\",y_val.shape)\nprint(\"Shape of y_test:\",y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_sales = y_train.mean()\nprint(\"Average Sales :\",mean_sales)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CREATING MODEL","metadata":{}},{"cell_type":"code","source":"# check if  there are any non-numeric value\n\n\n# i=0\n# for a in x_train[\"StateHoliday\"]:\n#     print(i)\n#     i+=1\n#     print(int(a))\n\n# x_train[x_train[\"StateHoliday\"]=='b'][\"StateHoliday\"] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nmodel = Sequential()\nmodel.add(Dense(150,input_dim = 44,activation=\"relu\"))\n\nmodel.add(Dense(1,activation = \"linear\"))\n\nmodel.compile(optimizer='adam',loss=\"mean_absolute_error\",\nmetrics=[\"mean_absolute_error\"])\n\nmodel.fit(x_train.astype(np.float32),y_train.astype(np.float32),epochs=10,batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = model.evaluate(x_test.astype(np.float32),y_test.astype(np.float32))\n\nfor i in range(len(model.metrics_names)):\n    print(\"Metric \",model.metrics_names[i],\":\",str(round(result[i],2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion\n\nWe will try to improve this performance next time. Thanks for reading.","metadata":{}},{"cell_type":"markdown","source":"## References\n* Learn Keras for Deep Neural Networks By Jojo Moolayil ,2019","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}