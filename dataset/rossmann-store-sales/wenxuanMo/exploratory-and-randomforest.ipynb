{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11bb4778-cb3c-4c62-b8cc-1970540345fd","collapsed":true},"outputs":[],"source":"%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d17b7cf5-cab8-4912-a3ad-56dabeeed8eb"},"outputs":[],"source":"import pandas as pd\nimport numpy as np  \nimport matplotlib.pyplot as plt \nimport matplotlib.dates \nimport datetime \n%matplotlib inline\ntrain = pd.read_csv('../input/train.csv')\nstore = pd.read_csv('../input/store.csv')\ntest = pd.read_csv('../input/test.csv') \n\nstore.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55e5a485-a057-48d7-8c56-e82e41c8c375"},"outputs":[],"source":"train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07e3e29b-c46a-4817-ad52-87a1802bae81"},"outputs":[],"source":"test.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e44c4ebf-1121-4b33-ac57-817ddccc5de2"},"outputs":[],"source":"## transform date variable\ndatetimes = [datetime.datetime.strptime(t, \"%Y-%m-%d\") for t in train.Date]\nplotData = matplotlib.dates.date2num(datetimes) \ntrain = train.join(pd.DataFrame(plotData,columns = ['datetimes']))\ndef splitTime(x): \n    mysplit = datetime.datetime.strptime(x,  \"%Y-%m-%d\") \n    return [mysplit.year,mysplit.month,mysplit.day]\ntrain = train.join(pd.DataFrame(train.Date.apply(splitTime).tolist(), columns = ['year','mon','day']))\n\n# plot the first 5 stores sales vs time\n\nfor i in range(1,5):\n plt.figure(i,figsize=(20,10)) \n plt.subplot(211)\n plt.plot_date(train.loc[train.Store==i,'datetimes'],train.loc[train.Store==i,'Sales'],linestyle='-') \n plt.title('Store %d' %i)  \n plt.subplot(212)\n train2014 = train.loc[train.year == 2014,:]\n plt.plot_date(train2014.loc[train2014.Store==i,'datetimes'],train2014.loc[train2014.Store==i,'Sales'],linestyle='-') \n plt.title('Store %d, 2014' %i)  \n plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f6d3db5-272d-4169-8237-0d73c5b82a31"},"outputs":[],"source":"## distribution of sales variable\nplt.figure(1,figsize=(15,10)) \nplt.subplot(221)\nplt.hist(train.Sales,bins=30)\nplt.title(\"Distribution of Sales\") \nplt.subplot(222)\nplt.hist(np.log(train.Sales+1),bins=30)\nplt.title(\"Distribution of log(Sales)\") "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e448bb90-d780-4c7a-a292-4ceb6dcf0cee"},"outputs":[],"source":"## average log sales, by store\n\nplt.hist([np.log(train.groupby('Store').Sales.mean()) ],bins=30)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"658db766-da1f-4280-8faf-8d091702890d"},"outputs":[],"source":"toAppend = pd.DataFrame(np.log(train.Sales+1),dtype=float)\ntoAppend.columns.values[0]='LogSale'\ntrain=train.join(toAppend)\ntrain.dtypes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4b436fb3-5b64-4bb9-9504-df33e84d0267"},"outputs":[],"source":"### data transformation on store data set\n\n## transform variable PromoInterval to 12 dummy variables\ndef myPinterval(x):\n    if x=='Feb,May,Aug,Nov':  return([0,1,0,0,1,0,0,1,0,0,1,0])\n    elif x=='Jan,Apr,Jul,Oct':  return([1,0,0,1,0,0,1,0,0,1,0,0])\n    elif x== 'Mar,Jun,Sept,Dec': return([0,0,1,0,0,1,0,0,1,0,0,1])\n    else: return(np.repeat(0,12).tolist())\n\nproInt = store.PromoInterval.apply(myPinterval).tolist()\nproInt = pd.DataFrame(proInt, columns = ['ProInt'+ str(i) for i in range(1,13)])\nstore = store.drop('PromoInterval',1).join(proInt)\n\nstore = store.drop('StoreType',1).join(pd.get_dummies(store['StoreType']).rename(columns=lambda x: 'StoreType' +\"_\"+str(x)))  \nstore = store.drop('Assortment',1).join(pd.get_dummies(store['Assortment']).rename(columns=lambda x: 'Assortment' +\"_\"+str(x)))  \n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88ac578d-c225-46ed-b929-f82a259a9c98"},"outputs":[],"source":"##assume 0 and '0' are the same in train.StateHoliday \ndef mychange(x):\n     if type(x)!= str: x=str(x)\n     return x\n        \ntrain.StateHoliday = [mychange(x) for x in train.StateHoliday]\n\nnewtrain = train.drop('StateHoliday',1).join(pd.get_dummies(train['StateHoliday']).rename(columns=lambda x: 'StateHoliday' +\"_\"+str(x)))  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b17d6a97-c961-44c9-8b59-c2fc7a1a7198"},"outputs":[],"source":"## merge training set with store\n\nnewtrain=pd.merge(newtrain, store, on=\"Store\")  \nnewtrain.drop(['Date','Customers','datetimes','Sales'],axis = 1,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9383ee64-f341-4c86-ae5b-8bc751fe3af0"},"outputs":[],"source":"## do the same thing on testing set\ntest = test.join(pd.DataFrame(test.Date.apply(splitTime).tolist(), columns = ['year','mon','day']))\nnewtest = test.drop('StateHoliday',1).join(pd.get_dummies(test['StateHoliday']).rename(columns=lambda x: 'StateHoliday' +\"_\"+str(x)))  \nnewtest = pd.merge(newtest,store, on=\"Store\")\nnewtest.drop(['Date'],axis = 1,inplace=True) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53ece6ce-ffb8-4466-b0f0-220c2a244caf"},"outputs":[],"source":"## check if there exists any constant variable\nnp.sum(newtrain.var()==0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c83abbd-882d-4db7-949e-7183f6431546"},"outputs":[],"source":"##### randomforest\nfrom sklearn.ensemble.forest import RandomForestRegressor\n\n##### delete variables that do not exist in the test set\ntoDrop = list(set(newtrain.columns.values)-set(newtest.columns.values) )\nfeatures = newtrain.columns.drop(toDrop,1)\n\nrf = RandomForestRegressor(n_estimators=100)\nrf.fit(newtrain.drop(toDrop ,1).fillna(-1),newtrain.LogSale)\n\n\nimportances = rf.feature_importances_ \n# return the indices that would sort the importance, decreasing\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\n\nFeatures = newtrain.columns.drop('LogSale')\nfor f in range(35):\n    print(\"%d. feature %d :%s (%f)\" % (f + 1, indices[f],Features[indices[f]], importances[indices[f]]))\n\n# Plot the feature importances of the forest\n# the most important feature 'open' is left out in the plot to make it easier to see the other features\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(1,10), importances[indices[range(1,10)]]) \nplt.xlim([-1, 10])\nplt.show()\n\n# make prediction on test data\nmypred = rf.predict(newtest.drop('Id',1).fillna(-1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"150f61b2-76b4-4353-b46d-29292bf4c467"},"outputs":[],"source":"mypred = np.exp(mypred)-1\nmypred = pd.DataFrame({ 'Id': test['Id'],\n                            'Sales': mypred[np.argsort(newtest['Id'])] })\n#mypred.to_csv(\"randomForest_1stSubmission.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2c66189-b42d-461e-9d4b-c534a94e995a"},"outputs":[],"source":"############lasso for prediction \nimport pasty\nfrom sklearn import linear_model\ny,X  = patsy.dmatrices(\"LogSale ~ 1+sx+rk+yr+dg+yd\",newtrain)\n\nnewtrain.columns\n\n\n\nalphas = np.logspace(-4, -.5, 30)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}