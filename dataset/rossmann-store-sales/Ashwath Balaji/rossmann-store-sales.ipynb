{"cells":[{"metadata":{},"cell_type":"markdown","source":"Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rossmann-store-sales/train.csv')\nstore = pd.read_csv('/kaggle/input/rossmann-store-sales/store.csv')\ntest = pd.read_csv('/kaggle/input/rossmann-store-sales/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of rows and columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\nprint(store.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Date column is of the object type , we need to convert it to DateTime "},{"metadata":{"trusted":true},"cell_type":"code","source":"store.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe(include='object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()[['Sales','Customers']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Average number of customers across all the stores every day is 633 <br>\nAverage sales across all the stores everyday is about 57738 units"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Store.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a total of 1115 Stores all across"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.DayOfWeek.value_counts().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.Open.value_counts() , '\\n',train.Promo.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isna().sum())\nprint('-'*20)\nprint(store.isna().sum())\nprint('-'*20)\nprint(test.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"Exploring a particular Store"},{"metadata":{},"cell_type":"markdown","source":"#### Store 1 Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"store1 = train[train['Store']==1]\nstore1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(store1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store1['Date'] = pd.to_datetime(store1['Date'])\nprint(min(store1['Date']))\nprint(max(store1['Date']))\nstore1['Year'] = store1['Date'].dt.year\nstore1['Month'] = store1['Date'].dt.month","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data for Store 1 is available from 2013-01-01 to 2015-07-31"},{"metadata":{"trusted":true},"cell_type":"code","source":"store1.resample('1D',on='Date')['Sales'].sum().plot.line(figsize=(14,4))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The gaps in the above plot show that there are missing records for those dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.distplot(store1.Sales , bins=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train.Sales)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sales are 0 for many records , which might be because the stores are closed"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Treating Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"store.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[store['Store']==1].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[~(store['Promo2']==0)].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fill Promo2SinceWeek with 0  & <br>\nPromo2SinceYear & PromoInterval with mode <br>\nFill CompetitionDistance with max value to keep them far from the stores since we dont know about them<br>\nCompetitionOpenSinceMonth & CompetitionOpenSinceYear with mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"store['Promo2SinceWeek'] = store['Promo2SinceWeek'].fillna(0)\nstore['Promo2SinceYear'] = store['Promo2SinceYear'].fillna(store['Promo2SinceYear'].mode().iloc[0])\nstore['PromoInterval'] = store['PromoInterval'].fillna(store['PromoInterval'].mode().iloc[0])\n\nstore['CompetitionDistance'] = store['CompetitionDistance'].fillna(store['CompetitionDistance'].max())\nstore['CompetitionOpenSinceMonth'] = store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode().iloc[0])\nstore['CompetitionOpenSinceYear'] = store['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode().iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Merging Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.merge(store , on='Store' , how='left')\nprint(train.shape)\nprint(store.shape)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Day'] = df['Date'].dt.day\ndf['Month'] = df['Date'].dt.month\ndf['Year'] = df['Date'].dt.year\n\n# df['DayOfWeek'] = df['Date'].dt.strftime(%a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Cols"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = df.select_dtypes(include=['object']).columns\n\nfor i in cat_cols:\n    print(i)\n    print(df[i].value_counts())\n    print('-'*20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['StateHoliday'] = df['StateHoliday'].map({'0':0 , 0:0 , 'a':1 , 'b':2 , 'c':3})\ndf['StateHoliday'] = df['StateHoliday'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['StoreType'] = df['StoreType'].map({'a':1 , 'b':2 , 'c':3 , 'd':4})\ndf['StoreType'] = df['StoreType'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Assortment'] = df['Assortment'].map({'a':1 , 'b':2 , 'c':3})\ndf['Assortment'] = df['Assortment'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['PromoInterval'] = df['PromoInterval'].map({'Jan,Apr,Jul,Oct':1 , 'Feb,May,Aug,Nov':2 , 'Mar,Jun,Sept,Dec':3})\ndf['PromoInterval'] = df['PromoInterval'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Train & Validate Split"},{"metadata":{},"cell_type":"markdown","source":"Applying Log Transformation of the Target Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Sales','Date','Customers'],1)\n#Transform Target Variable\ny = np.log(df['Sales']+1)\n\nfrom sklearn.model_selection import train_test_split\nX_train , X_val , y_train , y_val = train_test_split(X , y , test_size=0.30 , random_state = 1 )\n\nX_train.shape , X_val.shape , y_train.shape , y_val.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndt = DecisionTreeRegressor(max_depth=11)\ndt.fit(X_train , y_train)\ny_pred_dt = dt.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)Reverse the Transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_dt = np.exp(y_pred_dt)-1\ny_val = np.exp(y_val)-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score , mean_squared_error\n\nprint(r2_score(y_val , y_pred_dt))\nprint(np.sqrt(mean_squared_error(y_val , y_pred_dt)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSPE - Root Mean Square Percentage Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1./(y[ind]**2)\n    return w\n\ndef rmspe(y, yhat):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ROOT MEAN SQUARE PERCENTAGE ERROR"},{"metadata":{"trusted":true},"cell_type":"code","source":"rmspe(y_val,y_pred_dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter Tuning"},{"metadata":{},"cell_type":"markdown","source":"#### Customized Metric "},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_rmspe_score(model, input_values, y_actual):\n    y_predicted=model.predict(input_values)\n    y_actual=np.exp(y_actual)-1\n    y_predicted=np.exp(y_predicted)-1\n    score=rmspe(y_actual, y_predicted)\n    return score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nparams = {\n    'max_depth' : list(range(5,25))\n}\n\nbase  = DecisionTreeRegressor()\n\nmodel_tuned = RandomizedSearchCV(base , params , return_train_score=True).fit(X_train , y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cv_results = pd.DataFrame(model_tuned.cv_results_).sort_values(by='mean_test_score' , ascending=False)\nmodel_cv_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cv_results.set_index('param_max_depth')['mean_test_score'].plot(color='g',legend=True)\nmodel_cv_results.set_index('param_max_depth')['mean_train_score'].plot(color='r' , legend=True)\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the model Underfits with the max_depth is <10 an=d Overfits when the max_depth is >12<br>\nSo we can choose max_depth as 11"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### XGBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(X_train,y_train)\ndvalidate = xgb.DMatrix(X_val[X_train.columns],y_val)\n\nparams = {\n    'eta' : 1,\n    'max_depth' : 5,\n    'objecive' : 'reg:linear'\n}\n\nmodel_xg = xgb.train(params, dtrain , 5)\n\ny_pred_xg = model_xg.predict(dvalidate)\n\ny_pred_xg = np.exp(y_pred_xg)-1\n\n\nrmspe(y_val , y_pred_xg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"ROOT MEAN SQUARE PERCENTAGE ERROR"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"\nFeature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.barh(X_train.columns , dt.feature_importances_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Process Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cust = train.groupby(['Store'])[['Customers']].mean().reset_index().astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_1 = test.merge(test_cust , on='Store' , how='left')\ntest_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_m = test_1.merge(store , on='Store' , how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_m.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_m['Open'].fillna(1,inplace=True)\n\ntest_m['Date'] = pd.to_datetime(test_m['Date'])\n\ntest_m['Day'] = test_m['Date'].dt.day\ntest_m['Month'] = test_m['Date'].dt.month\ntest_m['Year'] = test_m['Date'].dt.year\n\ntest_m.drop('Date',1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = test_m.select_dtypes(include=['object']).columns\n\nfor i in cat_cols:\n    print(i)\n    print(test_m[i].value_counts())\n    print('-'*20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_m['StateHoliday'] = test_m['StateHoliday'].map({'0':0 , 'a':1})\ntest_m['StateHoliday'] = test_m['StateHoliday'].astype(int)\n\ntest_m['StoreType'] = test_m['StoreType'].map({'a':1 , 'b':2 , 'c':3 , 'd':4})\ntest_m['StoreType'] = test_m['StoreType'].astype(int)\n\ntest_m['Assortment'] = test_m['Assortment'].map({'a':1 , 'b':2 , 'c':3})\ntest_m['Assortment'] = test_m['Assortment'].astype(int)\n\ntest_m['PromoInterval'] = test_m['PromoInterval'].map({'Jan,Apr,Jul,Oct':1 , 'Feb,May,Aug,Nov':2 , 'Mar,Jun,Sept,Dec':3})\ntest_m['PromoInterval'] = test_m['PromoInterval'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_m.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_m.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = dt.predict(test_m[X_train.columns])\ntest_pred_inv = np.exp(test_pred)-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_inv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'Id' : test_m['Id'] , 'Sales' : test_pred_inv})\nsubmission['Sales'] = submission['Sales'].astype(int)\nsubmission['Id']= submission.index\nsubmission['Id'] = submission['Id']+1\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('sumbission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}