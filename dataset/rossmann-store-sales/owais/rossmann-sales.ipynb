{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"store = pd.read_csv(\"/kaggle/input/rossmann-store-sales/store.csv\")\ntrain = pd.read_csv(\"/kaggle/input/rossmann-store-sales/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/rossmann-store-sales/test.csv\",parse_dates=[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()[['Sales','Customers']].loc['min']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()[['Sales','Customers']].loc['max']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  no. of stores\ntrain.Store.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Store'].value_counts().head(50).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.DayOfWeek.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Open.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#date wise line plot for sales\ntrain['Date'] = pd.to_datetime(train['Date'],format = '%Y-%m-%d')\nstore_id = train.Store.unique()[0]\nprint(store_id)\nstore_rows = train[train['Store'] == store_id]\nprint(store_rows.shape)\nstore_rows.resample('1D',on = 'Date')['Sales'].sum().plot.line(figsize = (18,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing values on days\nstore_rows[store_rows['Sales']==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the same for test data\ntest['Date'] = pd.to_datetime(test['Date'],format = '%Y-%m-%d')\nstore_test_rows = test[test['Store'] == store_id]\nprint(store_test_rows.shape)\nstore_test_rows['Date'].min(), store_test_rows['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_rows['Sales'].plot.hist(figsize = (14,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Store data\nstore.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[store['Store']==store_id].T # here store id was 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the non null values in store data to make sure what we can fill in the missing values\nstore[~store['Promo2SinceYear'].isna()].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing values treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"#method 1\nstore['Promo2SinceWeek'].fillna(0,inplace = True)\nstore['Promo2SinceYear'].fillna(store['Promo2SinceYear'].mode()[0],inplace = True)\nstore['PromoInterval'].fillna(store['PromoInterval'].mode()[0],inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode()[0],inplace = True)\nstore['CompetitionDistance'].fillna(store['CompetitionDistance'].max(),inplace = True)\nstore['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode()[0],inplace = True)\nstore.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge the data train and store\ndata_merged = train.merge(store,on = 'Store',how = 'left')\nprint(train.shape)\nprint(data_merged.shape)\nprint(data_merged.isnull().sum().sum()) # cross check if there are any missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Encoding\n# 3 categorical columns, 1 date column, rest are numerical\ndata_merged.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['day'] = data_merged['Date'].dt.day\ndata_merged['month'] = data_merged['Date'].dt.month\ndata_merged['year'] = data_merged['Date'].dt.year\n#data_merged['weekday'] = data_merged['Date'].dt.strftime(%a)  This is already in data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stateHoliday, StoreType, Assortment, PromoInterval\ndata_merged['StateHoliday'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['StateHoliday'] = data_merged['StateHoliday'].map({'a':1,'b':2,'c':3,'0':0,0:0})\ndata_merged['StateHoliday'] = data_merged['StateHoliday'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns',None)\ndata_merged.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['Assortment'] = data_merged['Assortment'].map({'a':1,'b':2,'c':3})\ndata_merged['Assortment'] = data_merged['Assortment'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['StoreType'] = data_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ndata_merged['StoreType'] = data_merged['StoreType'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_promo = {'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ndata_merged['PromoInterval'] = data_merged['PromoInterval'].map(map_promo)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train and Validate split just to check the accuracy we can get after final model we will make we will use test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data_merged.columns.drop(['Sales','Date'])\nX = data_merged[features]\ny = np.log(data_merged['Sales']+1)\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Building Decision Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dt  = DecisionTreeRegressor(max_depth = 20, random_state = 42).fit(X_train,y_train)\ny_pred = model_dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_tree(model, columns):\n    import pydotplus\n    from sklearn.externals.six import StringIO\n    from IPython.display import Image\n    import os\n    from sklearn import tree\n    \n    graphviz_path = 'C:\\Program Files (x86)\\Graphviz2.38/bin/'\n    os.environ[\"PATH\"] += os.pathsep + graphviz_path\n\n    dot_data = StringIO()\n    tree.export_graphviz(model,\n                         out_file=dot_data,\n                         feature_names=columns)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n    return Image(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# draw_tree(model_dt,X.columns)y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1./(y[ind]**2)\n    return w\n\ndef rmspe(y, yhat):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_inv = np.exp(y_test)-1\ny_pred_inv = np.exp(y_pred)-1\nnp.sqrt(mean_squared_error(y_inv,y_pred_inv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmspe(y_inv,y_pred_inv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## taking the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.figure(figsize = (18,8))\n# plt.bar(X,model_dt.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_avg_cust = train.groupby(['Store'])[['Customers']].mean().reset_index().astype(int)\ntest_1 = test.merge(train_avg_cust,on = 'Store',how = 'left')\ntest.shape,test_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_merged = test_1.merge(store,on = 'Store',how = 'inner')\ntest_merged['Open'] = test_merged['Open'].fillna(1)\ntest_merged['Date'] = pd.to_datetime(test_merged['Date'],format = '%Y-%m-%d')\ntest_merged['day'] = test_merged['Date'].dt.day\ntest_merged['month'] = test_merged['Date'].dt.month\ntest_merged['year'] = test_merged['Date'].dt.year\ntest_merged['StateHoliday'] = test_merged['StateHoliday'].map({'0':0,'a':1})\ntest_merged['StateHoliday'] = test_merged['StateHoliday'].astype(int)\ntest_merged['Assortment'] = test_merged['Assortment'].map({'a':1,'b':2,'c':3})\ntest_merged['Assortment'] = test_merged['Assortment'].astype(int)\ntest_merged['StoreType'] = test_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ntest_merged['StoreType'] = test_merged['StoreType'].astype(int)\nmap_promo = {'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ntest_merged['PromoInterval'] = test_merged['PromoInterval'].map(map_promo)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model_dt.predict(test_merged[features])\ntest_pred_inv = np.exp(test_pred)-1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf = RandomForestRegressor(n_jobs = -1)\n# param_grid = { \n#         \"n_estimators\"      : [10,50,100],\n#         \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n#         \"min_samples_split\" : [2,4],\n#         \"bootstrap\": [True, False],\n#         \"max_depth\" : [5,10,20]\n#         }\n\n# grid = GridSearchCV(estimator = rf,param_grid = param_grid, cv=3)\n\n# grid.fit(X_train, y_train)\n\n# grid.best_score_ , grid.best_params_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Hyperparameter Tuning\n\n'''\ndef get_rmspe_score(input_values,y_actual):\n    y_predicted = model.predict(input_values)\n    y_actual = np.exp(y_actual)-1\n    y_predicted = np.exp(y_predicted)-1\n    score = rmspe(y_actual,y_predicted)\n\n\nparams = {'max_depth': list(range(5,40))}\nbase_model = DecisionTreeRegressor()\ncv_model = GridSearchCV(base_model,param_grid = params,cv = 5,return_train_score=True,scoring = get_rmspe_score).fit(X_train,y_train)\n\npd.DataFrame(cv_model.cv_results)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_cv_results = pd.DataFrame(cv_model.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_cv_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_cv_results[df_cv_results['param_max_depth']==11].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# df_cv_results = pd.DataFrame(cv_model.cv_results_).sort_values(by='mean_test_score',ascending=False)\n# df_cv_results.set_index('param_max_depth')['mean_test_score'].plot.line()\n# df_cv_results.set_index('param_max_depth')['mean_train_score'].plot.line()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf = RandomForestRegressor()\n# rf.fit(X_train,y_train)\n# y_pred = rf.predict(X_test)\n# y_inv = np.exp(y_test)-1\n# y_pred_inv = np.exp(y_pred)-1\n# np.sqrt(mean_squared_error(y_inv,y_pred_inv))\n# test_pred = rf.predict(test_merged[features])\n# test_pred_inv = np.exp(test_pred)-1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data_merged.columns.drop(['Sales','Customers','Date'])\nX = data_merged[features]\ny = np.log(data_merged['Sales']+1)\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dt  = DecisionTreeRegressor(max_depth = 12, random_state = 1).fit(X_train,y_train)\ny_pred = model_dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_inv = np.exp(y_test)-1\ny_pred_inv = np.exp(y_pred)-1\nnp.sqrt(mean_squared_error(y_inv,y_pred_inv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmspe(y_inv,y_pred_inv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model_dt.predict(test_merged[features])\ntest_pred_inv = np.exp(test_pred)-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_predicted = pd.DataFrame({'Id' : test['Id'],'Sales':test_pred_inv })\nsubmission_predicted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_predicted.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}