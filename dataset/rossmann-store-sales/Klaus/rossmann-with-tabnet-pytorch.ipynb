{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A quick comparison of XGBoost with TabNet\n\nThis notebook is based on https://www.kaggle.com/danspace/rossmann-store-sales-xgboost. I wanted to compare XGBoost with TabNet, a neural network made for tabular data. I tried a few configurations, but was not able to come close to the out-of-the-box performance of XGBoost. If anyone finds better hyper-parameters I would be glad to hear it. I tried feature scaling, but it had no effect.","metadata":{}},{"cell_type":"code","source":"!pip install pytorch_tabnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\nfrom pathlib import Path as P\n\nimport torch\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\nfrom sklearn.model_selection import train_test_split\n\n\nPATH = P('/kaggle/input/rossmann-store-sales')\n\nstore = pd.read_csv(PATH/'store.csv').fillna(0)\ntrain = pd.read_csv(PATH/'train.csv',parse_dates=[2])\n\n# merge data with store \ntrain = pd.merge(train, store, on='Store')\n\n# split the last 6 weeks data as hold-out set (idea from Gert https://www.kaggle.com/c/rossmann-store-sales/discussion/18024)\ntrain = train.sort_values(['Date'],ascending = False)\ntrain_total = train.copy()\n\nsplit_index = 6*7*1115\nvalid = train[:split_index] \ntrain = train[split_index:]\n\n# only use data of Sales>0 and Open is 1\nvalid = valid[(valid.Open != 0)&(valid.Sales >0)]\ntrain = train[(train.Open != 0)&(train.Sales >0)]\ntrain_total = train_total[(train_total.Open != 0)&(train_total.Sales >0)]\n\ndef process(data, isTest = False):\n    # label encode some features\n    mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n    data.StoreType.replace(mappings, inplace=True)\n    data.Assortment.replace(mappings, inplace=True)\n    data.StateHoliday.replace(mappings, inplace=True)\n    \n    # extract some features from date column  \n    data['Month'] = data.Date.dt.month\n    data['Year'] = data.Date.dt.year\n    data['Day'] = data.Date.dt.day\n    data['WeekOfYear'] = data.Date.dt.weekofyear\n    \n    # calculate competiter open time in months\n    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + \\\n        (data.Month - data.CompetitionOpenSinceMonth)\n    data['CompetitionOpen'] = data['CompetitionOpen'].apply(lambda x: x if x > 0 else 0)\n    \n    # calculate promo2 open time in months\n    data['PromoOpen'] = 12 * (data.Year - data.Promo2SinceYear) + \\\n        (data.WeekOfYear - data.Promo2SinceWeek) / 4.0\n    data['PromoOpen'] = data['PromoOpen'].apply(lambda x: x if x > 0 else 0)\n                                                 \n    # Indicate whether the month is in promo interval\n    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n             7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n    data['month_str'] = data.Month.map(month2str)\n\n    def check(row):\n        if isinstance(row['PromoInterval'],str) and row['month_str'] in row['PromoInterval']:\n            return 1\n        else:\n            return 0\n        \n    data['IsPromoMonth'] =  data.apply(lambda row: check(row),axis=1)    \n    \n    # select the features we need\n    features = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday',\n       'StoreType', 'Assortment', 'CompetitionDistance',\n       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n       'Promo2SinceWeek', 'Promo2SinceYear', 'Year', 'Month', 'Day',\n       'WeekOfYear', 'CompetitionOpen', 'PromoOpen', 'IsPromoMonth']  \n    if not isTest:\n        features.append('Sales')\n        \n    data = data[features]\n    return data\n\ntrain = process(train)\nvalid = process(valid)\ntrain_total = process(train_total)\n\n# sort by index\nvalid.sort_index(inplace = True)\ntrain.sort_index(inplace = True)\ntrain_total.sort_index(inplace = True)\n\n# split x and y\nX_train, y_train = train.drop(columns = ['Sales']), np.log1p(train[['Sales']])\nX_valid, y_valid = valid.drop(columns = ['Sales']), np.log1p(valid[['Sales']])\nX_train_total, y_train_total = train_total.drop(columns = ['Sales']), np.log1p(train_total[['Sales']])\n\ndef rmspe(y, yhat):\n    return np.sqrt(np.mean((yhat/y-1) ** 2))\n\nfrom pytorch_tabnet.metrics import Metric\n\nclass RMSPE_EXP(Metric):\n    def __init__(self):\n        self._name = \"rmspe\"\n        self._maximize = False\n\n    def __call__(self, y_true, y_pred):\n        y_true = np.expm1(y_true)\n        #y_pred = y_pred[:, 1]\n        y_pred = np.expm1(y_pred)\n        return \"rmspe\", rmspe(y_pred, y_true)  \n\ncat_idxs = [0, 1, 3, 5, 6, 14, 15, 16]\nX_train.iloc[:,cat_idxs]\n\nclf = TabNetRegressor(\n    n_d=64, n_a=64, \n    n_steps=5,\n    lambda_sparse=1e-5,\n    optimizer_params=dict(lr=2e-2),\n    scheduler_params={\"factor\": .1, \"patience\": 3},\n    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n    cat_idxs=cat_idxs,\n#    cat_dims=[1115, # Store\n#              7,    # Day of week \n#              5,    # Store Type\n#              4,    # Assortment\n#              12,   # Month\n#              31,   # Day\n#              52,   # Week of year\n#             ],\n)\n\nclf.fit(\n  X_train.values, \n  y_train.values,\n  eval_set=[\n            (X_train.values, y_train.values), \n            (X_valid.values, y_valid.values)\n           ],\n  eval_name=[\n             'train',\n             'valid'\n            ],\n  eval_metric=['rmse'],\n  max_epochs=1000,\n  batch_size=8192, \n  virtual_batch_size=256\n)\n\ny_pred = clf.predict(X_train.values)\nerror = rmspe( np.expm1(y_train.values) , np.expm1(y_pred))\nprint('Train RMSPE:', error)\n\ny_pred = clf.predict(X_valid.values)\nerror = rmspe( np.expm1(y_valid.values) , np.expm1(y_pred))\nprint('Valid RMSPE:', error)\n\ntest = pd.read_csv(PATH/'test.csv',  parse_dates=[3])\ntest = pd.merge(test, store, on='Store')\ntest.fillna(value = 1, inplace = True)\nX_test = process(test, isTest = True)    \n\npreds = clf.predict(X_test.values).flatten()\n\nresult = pd.DataFrame({\"Id\": test[\"Id\"],'Sales': np.expm1(preds)})\nresult.to_csv(\"submission.csv\", index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}