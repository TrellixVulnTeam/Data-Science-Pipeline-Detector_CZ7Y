{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-24T18:37:26.026195Z","iopub.execute_input":"2022-01-24T18:37:26.026774Z","iopub.status.idle":"2022-01-24T18:37:26.05109Z","shell.execute_reply.started":"2022-01-24T18:37:26.026665Z","shell.execute_reply":"2022-01-24T18:37:26.050298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\n\nimport pylab\nimport csv\nimport datetime\nimport math\nimport re\nimport time\nimport random\nimport os\nimport seaborn as sns\n\nfrom IPython.core.display import display\nfrom pandas.tseries.offsets import *\nfrom operator import *\n\nfrom sklearn.model_selection import train_test_split\n\n\n# plt.style.use('ggplot') # Good looking plots\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:26.308686Z","iopub.execute_input":"2022-01-24T18:37:26.308982Z","iopub.status.idle":"2022-01-24T18:37:27.645631Z","shell.execute_reply.started":"2022-01-24T18:37:26.308951Z","shell.execute_reply":"2022-01-24T18:37:27.644502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Thanks to Chenglong Chen for providing this in the forum\ndef ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1./(y[ind]**2)\n    return w\n\ndef rmspe(yhat, y):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe\n\ndef rmspe_xg(yhat, y):\n    # y = y.values\n    y = y.get_label()\n    y = np.exp(y) - 1\n    yhat = np.exp(yhat) - 1\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n    return \"rmspe\", rmspe","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:27.647431Z","iopub.execute_input":"2022-01-24T18:37:27.647715Z","iopub.status.idle":"2022-01-24T18:37:27.655481Z","shell.execute_reply.started":"2022-01-24T18:37:27.64768Z","shell.execute_reply":"2022-01-24T18:37:27.654538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/rossmann-store-sales/train.csv',\n                       parse_dates=['Date'],\n                       date_parser=(lambda dt: pd.to_datetime(dt, format='%Y-%m-%d')))\n\ndf_store = pd.read_csv('../input/rossmann-store-sales/store.csv')\n\ndf_submit = pd.read_csv('../input/rossmann-store-sales/test.csv', \n                        parse_dates=['Date'],\n                        date_parser=(lambda dt: pd.to_datetime(dt, format='%Y-%m-%d')))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:27.657182Z","iopub.execute_input":"2022-01-24T18:37:27.657723Z","iopub.status.idle":"2022-01-24T18:37:29.054676Z","shell.execute_reply.started":"2022-01-24T18:37:27.657674Z","shell.execute_reply":"2022-01-24T18:37:29.053687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.merge(df_train,df_store, how = 'left', on = 'Store')","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:29.056827Z","iopub.execute_input":"2022-01-24T18:37:29.057107Z","iopub.status.idle":"2022-01-24T18:37:29.580561Z","shell.execute_reply.started":"2022-01-24T18:37:29.057073Z","shell.execute_reply":"2022-01-24T18:37:29.579543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Setting a variable to easily distinguish train (1) from submit (0) set\ndf_train['Set'] = 1\ndf_submit['Set'] = 0","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:29.581899Z","iopub.execute_input":"2022-01-24T18:37:29.582187Z","iopub.status.idle":"2022-01-24T18:37:29.589898Z","shell.execute_reply.started":"2022-01-24T18:37:29.582153Z","shell.execute_reply":"2022-01-24T18:37:29.58884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frames = [df_train, df_submit]\ndf = pd.concat(frames)\ndf.sort_values(['Date','Store'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:29.591414Z","iopub.execute_input":"2022-01-24T18:37:29.591728Z","iopub.status.idle":"2022-01-24T18:37:30.20852Z","shell.execute_reply.started":"2022-01-24T18:37:29.591659Z","shell.execute_reply":"2022-01-24T18:37:30.207621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:30.209899Z","iopub.execute_input":"2022-01-24T18:37:30.21062Z","iopub.status.idle":"2022-01-24T18:37:30.242659Z","shell.execute_reply.started":"2022-01-24T18:37:30.210523Z","shell.execute_reply":"2022-01-24T18:37:30.241727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_x = ['Store', 'Date', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'StateHoliday']\nfeatures_y = ['SalesLog']\n### Remove rows where store is open, but no sales.\ndf = df.loc[~((df['Open'] == 1) & (df['Sales'] == 0))]\ndf.loc[df['Set'] == 1, 'SalesLog'] = np.log1p(df.loc[df['Set'] == 1]['Sales']) # = np.log(df['Sales'] + 1)\ndf['StateHoliday'] = df['StateHoliday'].astype('category').cat.codes\nvar_name = 'Date'\n\ndf[var_name + 'Day'] = pd.Index(df[var_name]).day\ndf[var_name + 'Week'] = pd.Index(df[var_name]).week\ndf[var_name + 'Month'] = pd.Index(df[var_name]).month\ndf[var_name + 'Year'] = pd.Index(df[var_name]).year\ndf[var_name + 'DayOfYear'] = pd.Index(df[var_name]).dayofyear\n\ndf[var_name + 'Day'] = df[var_name + 'Day'].fillna(0)\ndf[var_name + 'Week'] = df[var_name + 'Week'].fillna(0)\ndf[var_name + 'Month'] = df[var_name + 'Month'].fillna(0)\ndf[var_name + 'Year'] = df[var_name + 'Year'].fillna(0)\ndf[var_name + 'DayOfYear'] = df[var_name + 'DayOfYear'].fillna(0)\ndf['DateInt'] = df['Date'].astype(np.int64)\n\nfeatures_x.remove(var_name)\nfeatures_x.append(var_name + 'Day')\nfeatures_x.append(var_name + 'Week')\nfeatures_x.append(var_name + 'Month')\nfeatures_x.append(var_name + 'Year')\nfeatures_x.append(var_name + 'DayOfYear')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:30.243954Z","iopub.execute_input":"2022-01-24T18:37:30.244213Z","iopub.status.idle":"2022-01-24T18:37:31.732916Z","shell.execute_reply.started":"2022-01-24T18:37:30.244183Z","shell.execute_reply":"2022-01-24T18:37:31.731799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:31.734798Z","iopub.execute_input":"2022-01-24T18:37:31.735089Z","iopub.status.idle":"2022-01-24T18:37:31.763135Z","shell.execute_reply.started":"2022-01-24T18:37:31.735056Z","shell.execute_reply":"2022-01-24T18:37:31.761968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mad_based_outlier(points, thresh=3.5):\n    if len(points.shape) == 1:\n        points = points[:,None]\n    median = np.median(points, axis=0)\n    diff = np.sum((points - median)**2, axis=-1)\n    diff = np.sqrt(diff)\n    med_abs_deviation = np.median(diff)\n\n    modified_z_score = 0.6745 * diff / med_abs_deviation\n\n    return modified_z_score > thresh\n\nfor i in df['Store'].unique():\n    df.loc[(df['Set'] == 1) & (df['Store'] == i) & (df['Open'] == 1), 'Outlier'] = \\\n        mad_based_outlier(df.loc[(df['Set'] == 1) & (df['Store'] == i) & (df['Open'] == 1)]['Sales'], 3)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:37:31.76623Z","iopub.execute_input":"2022-01-24T18:37:31.766541Z","iopub.status.idle":"2022-01-24T18:38:09.995531Z","shell.execute_reply.started":"2022-01-24T18:37:31.766503Z","shell.execute_reply":"2022-01-24T18:38:09.994576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.Sales>0].head()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:38:09.999697Z","iopub.execute_input":"2022-01-24T18:38:09.999987Z","iopub.status.idle":"2022-01-24T18:38:10.19158Z","shell.execute_reply.started":"2022-01-24T18:38:09.99995Z","shell.execute_reply":"2022-01-24T18:38:10.189419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=40\nX_train, X_test, y_train, y_test = train_test_split(df.loc[(df['Set'] == 1) & (df['Open'] == 1) & (df['Outlier'] == False)][features_x],\n                                                    df.loc[(df['Set'] == 1) & (df['Open'] == 1) & (df['Outlier'] == False)][features_y],\n                                                    test_size=0.1, random_state=seed)\n\ndtrain = xgb.DMatrix(X_train, y_train)\ndtest = xgb.DMatrix(X_test, y_test)\n\nnum_round = 20000\n#num_round = 5000\nevallist = [(dtrain, 'train'), (dtest, 'test')]\n\nparam = {'bst:max_depth':12,\n         'bst:eta':0.01,\n         'subsample':0.8,\n         'colsample_bytree':0.7,\n         'silent':1,\n         'objective':'reg:linear',\n         'nthread':6,\n         'seed':seed}\n\nplst = param.items()\n\nbst = xgb.train(list(plst), dtrain, num_round, evallist, feval=rmspe_xg, verbose_eval=250, early_stopping_rounds=250)\n\ndpred = xgb.DMatrix(df.loc[(df['Set'] == 1) & (df['Open'] == 1) & (df['Outlier'] == True)][features_x])\n\nypred_bst = bst.predict(dpred)\n\ndf.loc[(df['Set'] == 1) & (df['Open'] == 1) & (df['Outlier'] == True), 'SalesLog'] = ypred_bst\ndf.loc[(df['Set'] == 1) & (df['Open'] == 1) & (df['Outlier'] == True), 'Sales'] = np.exp(ypred_bst) - 1\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:38:10.193042Z","iopub.execute_input":"2022-01-24T18:38:10.193832Z","iopub.status.idle":"2022-01-24T18:48:53.167747Z","shell.execute_reply.started":"2022-01-24T18:38:10.193783Z","shell.execute_reply":"2022-01-24T18:48:53.16681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_submit = df.loc[df['Set'] == 0]\ndsubmit = xgb.DMatrix(X_submit[features_x])\nypred_bst = bst.predict(dsubmit)\ndf_ypred = X_submit['Id'].reset_index()\ndel df_ypred['index']\ndf_ypred['Id'] = df_ypred['Id'].astype('int')\ndf_ypred['Sales'] = (np.exp(ypred_bst) - 1) * 0.985\n\ndf_ypred.sort_values('Id', inplace=True)\ndf_ypred[['Id', 'Sales']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:48:53.169042Z","iopub.execute_input":"2022-01-24T18:48:53.169272Z","iopub.status.idle":"2022-01-24T18:48:53.980653Z","shell.execute_reply.started":"2022-01-24T18:48:53.169244Z","shell.execute_reply":"2022-01-24T18:48:53.979636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Convert Storetype and Assortment to numerical categories\ndf_store['StoreType'] = df_store['StoreType'].astype('category').cat.codes\ndf_store['Assortment'] = df_store['Assortment'].astype('category').cat.codes\n### Convert competition open year and month to float\ndef convertCompetitionOpen(df):\n    try:\n        date = '{}-{}'.format(int(df['CompetitionOpenSinceYear']), int(df['CompetitionOpenSinceMonth']))\n        return pd.to_datetime(date)\n    except:\n        return np.nan\n\ndf_store['CompetitionOpenInt'] = df_store.apply(lambda df: convertCompetitionOpen(df), axis=1).astype(np.int64)\n### Convert competition open year and month to float\ndef convertPromo2(df):\n    try:\n        date = '{}{}1'.format(int(df['Promo2SinceYear']), int(df['Promo2SinceWeek']))\n        return pd.to_datetime(date, format='%Y%W%w')\n    except:\n        return np.nan\n\ndf_store['Promo2SinceFloat'] = df_store.apply(lambda df: convertPromo2(df), axis=1).astype(np.int64)\ns = df_store['PromoInterval'].str.split(',').apply(pd.Series, 1)\ns.columns = ['PromoInterval0', 'PromoInterval1', 'PromoInterval2', 'PromoInterval3']\ndf_store = df_store.join(s)\ndef monthToNum(date):\n    return{\n            'Jan' : 1,\n            'Feb' : 2,\n            'Mar' : 3,\n            'Apr' : 4,\n            'May' : 5,\n            'Jun' : 6,\n            'Jul' : 7,\n            'Aug' : 8,\n            'Sept' : 9, \n            'Oct' : 10,\n            'Nov' : 11,\n            'Dec' : 12\n    }[date]\n\ndf_store['PromoInterval0'] = df_store['PromoInterval0'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\ndf_store['PromoInterval1'] = df_store['PromoInterval1'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\ndf_store['PromoInterval2'] = df_store['PromoInterval2'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\ndf_store['PromoInterval3'] = df_store['PromoInterval3'].map(lambda x: monthToNum(x) if str(x) != 'nan' else np.nan)\ndel df_store['PromoInterval']","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:48:53.981994Z","iopub.execute_input":"2022-01-24T18:48:53.982256Z","iopub.status.idle":"2022-01-24T18:48:54.441532Z","shell.execute_reply.started":"2022-01-24T18:48:53.982226Z","shell.execute_reply":"2022-01-24T18:48:54.440667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''store_features = ['Store', 'StoreType', 'Assortment', \n                  'CompetitionDistance', 'CompetitionOpenInt',\n                  'PromoInterval0']\n\n### Features not helping\n# PromoInterval1, PromoInterval2, PromoInterval3\n\nfeatures_x = list(set(features_x + store_features))\n\ndf = pd.merge(df, df_store[store_features], how='left', on=['Store'])\n### Convert every NAN to -1\nfor feature in features_x:\n    df[feature] = df[feature].fillna(-1)'''","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:48:54.442733Z","iopub.execute_input":"2022-01-24T18:48:54.442962Z","iopub.status.idle":"2022-01-24T18:48:54.449859Z","shell.execute_reply.started":"2022-01-24T18:48:54.442934Z","shell.execute_reply":"2022-01-24T18:48:54.449028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''store_dates_to_remove = {   105:1.368e18, 163:1.368e18,\n                            172:1.366e18, 364:1.37e18,\n                            378:1.39e18, 523:1.39e18,\n                            589:1.37e18, 663:1.39e18,\n                            676:1.366e18, 681:1.37e18,\n                            700:1.373e18, 708:1.368e18,\n                            709:1.423e18, 730:1.39e18,\n                            764:1.368e18, 837:1.396e18,\n                            845:1.368e18, 861:1.368e18,\n                            882:1.368e18, 969:1.366e18,\n                            986:1.368e18, 192:1.421e18,\n                            263:1.421e18, 500:1.421e18,\n                            797:1.421e18, 815:1.421e18,\n                            825:1.421e18}\n\nfor key,value in store_dates_to_remove.items():\n    df.loc[(df['Store'] == key) & (df['DateInt'] < value), 'Delete'] = True\n    \n### Delete the data where sales in the first period is much different from the rest\ndf = df.loc[df['Delete'] != True]'''","metadata":{"execution":{"iopub.status.busy":"2022-01-24T18:48:54.451202Z","iopub.execute_input":"2022-01-24T18:48:54.451471Z","iopub.status.idle":"2022-01-24T18:48:54.466874Z","shell.execute_reply.started":"2022-01-24T18:48:54.451444Z","shell.execute_reply":"2022-01-24T18:48:54.465708Z"},"trusted":true},"execution_count":null,"outputs":[]}]}