{"cells":[{"metadata":{},"cell_type":"markdown","source":"# やったこと\n* train, testに対して、storeの情報を連結し、全ての変数（\"Store\"は除く）を使用して、線形回帰モデルを適用した。\n* scoreは0.43091だった。\n* 条件付き単純平均（五十嵐さんの例）でのスコアが0.14283なので、線形回帰モデルでもまだまだ改善できるはず。ただ、\"Store\"で条件付けして平均するのが有効すぎる気もする。\n\n# 次に取り組むこと\n* 残差分析とクロスバリデーションにより、予測精度の低いレコードの特徴を抽出する。\n* 標準化して、変数のスケールを合わせる。\n* 取り込み方の悪い変数（例えば、CompetitionDistance,CompetitionOpenSinceMonth,CompetitionOpenSinceYear,Promo2SinceWeek,Promo2SinceYear\t）の扱いを考える。単純に落としてしまってもいいと思う。\n* LASSOで雑に変数選択する。\n* 来客数と単価を別に予測して、売上＝来客数×単価とする\n* 日曜とそれ以外でモデルを組む\n* 外部データを活用する","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#1.データ、ライブラリの読み込み\n# data wrangling\nimport numpy as np\nimport pandas as pd\n#import pandas_profiling as pdp\nfrom collections import Counter\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import display\n\n# modeling\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_validate\n\n# evaluation\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n#正規表現\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#データの読み込み\ntrain = pd.read_csv('../input/rossmann-store-sales/train.csv')\ntest = pd.read_csv('../input/rossmann-store-sales/test.csv')\nstore = pd.read_csv('../input/rossmann-store-sales/store.csv')\n\n#いつでも元データを取り出せるようにしておく（0:train, 1:test, 2:store）\ndef gen_data():\n    return([train,test,store])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#加工用にデータを分離する\nx_train = gen_data()[0]\nx_test = gen_data()[1]\nx_store = gen_data()[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2.1.特徴量の構成（trainの加工）\n#データの外形を確認\ndisplay(x_train.head())\n#欠損値、データタイプの確認\ndisplay(x_train.info())\n#trainには欠損なし。\"Date\"と\"StateHoliday\"がobjectなので、線形モデルに取り込めるように変換する。","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\"Date\"の処理\n#\"Date\" は時系列データとしてではなく、\"DayOfWeek\"（月曜：1～日曜：7）のみ取り込むこととにする。\n\nx_train[\"StateHoliday\"]=x_train[\"StateHoliday\"].replace(\"0\",0)\n\nx_train_2 = x_train.drop(\"Date\",axis=1)\nx_train_2 =pd.get_dummies(x_train_2,drop_first=True)\nx_train_2 =pd.get_dummies(x_train_2, drop_first=True, columns=['DayOfWeek'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#\"StateHoliday\"の処理\n#内容確認\nx_train[\"StateHoliday\"] = x_train[\"StateHoliday\"].astype(str)\nimport collections\nprint(collections.Counter(x_train[\"StateHoliday\"]))\n\n#'StateHoliday'はダミー変数で置き換える。(One hot encoding)\nx_train = pd.concat([x_train.drop('StateHoliday', axis=1), pd.get_dummies(x_train['StateHoliday']).iloc[:, :-1]], axis=1)\nx_train.head()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trainへの処理は終わり\nx_train_2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2.2.特徴量の構成（testの加工）\n\n#test　「open(float64)」に欠損あり。\ndisplay(x_test.info())\n\n#最頻値で置き換える。（つまり1）\nx_test['Open'].fillna(x_test['Open'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_2 = x_test.drop(\"Date\",axis=1)\nx_test_2 =pd.get_dummies(x_test_2, drop_first=True)\nx_test_2 =pd.get_dummies(x_test_2, drop_first=True, columns=['DayOfWeek'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2.3.特徴量の構成（storeの加工）\nx_store.info()\n#\"CompetitionDistance\"、\"CompetitionOpenSinceMonth\"、\"CompetitionOpenSinceYear\"、\n#\"Promo2SinceWeek\"、\"Promo2SinceYear\"、\"PromoInterval\"に欠損あり","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#欠損値は次のとおり置き換える。\n#いずれも雑な気がするので、後でちゃんと考えること、、、\n\n#\"CompetitionDistance\"は平均で置き換える\nx_store['CompetitionDistance'].fillna(x_store['CompetitionDistance'].mean(), inplace=True)\n\n#\"CompetitionOpenSinceMonth\"と\"CompetitionOpenSinceYear\"は最頻値で置き換える。\nx_store['CompetitionOpenSinceMonth'].fillna(x_store['CompetitionOpenSinceMonth'].mode()[0], inplace=True)\nx_store['CompetitionOpenSinceYear'].fillna(x_store['CompetitionOpenSinceYear'].mode()[0], inplace=True)\n\n#Note: \"Promo2SinceWeek\",\"Promo2SinceYear\",\"PromoInterval\"は\"Promo2\"が「0」の場合、自動的に空白となる。\n#\"Promo2SinceWeek\"→0, \"Promo2SinceYear\"→2016, \"PromoInterval\"→0　と置換する。※2015年9月17日時点で始まっていないの意\nx_store['Promo2SinceWeek'].fillna(0, inplace=True)\nx_store['Promo2SinceYear'].fillna(2016, inplace=True)\nx_store['PromoInterval'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_store_2=pd.get_dummies(x_store, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#変数絞る場合ここに。\n#x_store_2=x_store_2[[\"Store\",\"CompetitionDistance\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3. 線形回帰で予測値を算出する\n\n#train・testとstoreを結合\n#trainとstoreを結合すると何故か\"Id\"が消える、、、\ntrain_store = pd.merge(x_train_2, x_store_2, how = 'left', on = 'Store')\n\ntest_store = pd.merge(x_test_2, x_store_2, how = 'left', on = 'Store')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trainから\"Sales\"と\"Customers\"を分離\ny_train_store = train_store[[\"Sales\"]]\nx_train_store = train_store.drop([\"Sales\",\"Customers\",\"StateHoliday_b\",\"StateHoliday_c\"], axis = 1)\n\n#\"Store\"も回帰変数には含めないので落とす\n#x_train_store = x_train_store.drop([\"Store\"], axis = 1)\n\n#\"Store\"も回帰変数には含めないので落とす\n#x_test_store = test_store.drop([\"Store\"], axis = 1)\n\n#storeをダミー変数にする。→⭐️⭐️メモリ不足で死んだ。\nx_train_store =pd.get_dummies(x_train_store, drop_first=True, columns=['Store'])\ntest_store =pd.get_dummies(test_store, drop_first=True, columns=['Store'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#３．線形回帰する\nfrom sklearn.linear_model import LinearRegression\n\n#線形回帰実行（普通の重回帰）\nmodel = LinearRegression()\nmodel.fit(x_train_store,y_train_store)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#線形回帰による予測\npred_sample = pd.read_csv('../input/rossmann-store-sales/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#線形回帰による予測\npred_linear_1 = model.predict(x_test_store)\n\npred_linear=pred_sample \npred_linear[\"Sales\"]=pred_linear_1\npred_linear[\"Sales\"]=pred_linear[\"Sales\"].apply(lambda x:max(x,0))\n\npred_linear.to_csv('./submission_linear_0.csv', index = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#回帰係数が大きすぎる？\npd.DataFrame({\"変数\":np.ravel(x_train_store.columns.values), \"係数\":np.ravel(model.coef_)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSPEを算出\ndef gen_RMSPE(pred, ans):\n    tmp_0 = (pred - ans)/ans\n    tmp_1 = tmp_0[np.isfinite(tmp_0)] #ansが0のレコード(=tmp0がinfのレコード)は無視する\n    return(np.sqrt(np.power(tmp_1,2).sum()/tmp_1.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_RMSPE = []\n\n#クロスバリデーションを行う\n#学習データを4つに分割し、うち1つをバリデーションデータとすることをバリデーションデータを変えて繰り返す\nkf = KFold(n_splits=2, shuffle =True, random_state=71)\n\nfor tr_idx, va_idx in kf.split(x_train_store):\n    #学習データを学習データとバリデーションデータに分ける\n    tr_x, va_x = x_train_store.iloc[tr_idx], x_train_store.iloc[va_idx]\n    tr_y, va_y = y_train_store.iloc[tr_idx], y_train_store.iloc[va_idx]\n    \n    #モデルの学習を行う \n    model_cv = LinearRegression()\n    model_cv.fit(tr_x,tr_y)\n    \n    #バリデーションデータの予測値を確率で出力する\n    va_pred = pd.DataFrame(model_cv.predict(va_x)[:len(model_cv.predict(va_x))])\n    va_pred[0] = va_pred[0].apply(lambda x:0 if x<0 else x)\n    #pd.DataFrame({\"Sales_pred\":model_cv.predict(va_x)[:len(model_cv.predict(va_x))]})\n    \n    #バリデーションデータでスコアを計算する\n    RMSPE = gen_RMSPE(va_pred[0], va_y[\"Sales\"])\n        \n    #そのfoldスコアを保持する\n    scores_RMSPE.append(RMSPE)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#各foldのスコアを保存するリスト\nscores_RMSPE = []\n\n#クロスバリデーションを行う\n#学習データを4つに分割し、うち1つをバリデーションデータとすることをバリデーションデータを変えて繰り返す\nkf = KFold(n_splits=2, shuffle =True, random_state=71)\n\nfor tr_idx, va_idx in kf.split(x_train_store):\n    #学習データを学習データとバリデーションデータに分ける\n    tr_x, va_x = x_train_store.iloc[tr_idx], x_train_store.iloc[va_idx]\n    tr_y, va_y = y_train_store.iloc[tr_idx], y_train_store.iloc[va_idx]\n    \n    #モデルの学習を行う \n    model_xgb_cv = LinearRegression()\n    model_xgb_cv.fit(tr_x,tr_y)\n    \n    #バリデーションデータの予測値を確率で出力する\n    va_pred = model_xgb_cv.predict(va_x)\n    va_pred= np.where(va_pred < 0, 0, va_pred)\n    #va_pred[0] = va_pred[0].apply(lambda x:0 if x<0 else x)\n    #pd.DataFrame({\"Sales_pred\":model_cv.predict(va_x)[:len(model_cv.predict(va_x))]})\n    \n    #バリデーションデータでスコアを計算する\n    RMSPE = gen_RMSPE(np.ravel(va_pred), va_y[\"Sales\"].values)\n    #RMSPE = np.sqrt(np.mean(((pred - true) / true)**2))*100\n        \n    #そのfoldスコアを保持する\n    scores_RMSPE.append(RMSPE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_RMSPE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.DataFrame({\"変数\":np.ravel(x_train_store.columns.values), \"係数\":np.ravel(model_cv.coef_)}))\nprint({\"定数項\":model_cv.intercept_})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Xgboost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGboostのライブラリをインポート\nimport xgboost as xgb\n# モデルのインスタンス作成\nmod = xgb.XGBRegressor()\nmod.fit(x_train_store,y_train_store)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_xgb_1 = mod.predict(x_test_store)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_xgb=pred_sample \npred_xgb[\"Sales\"]=pred_xgb_1\npred_xgb[\"Sales\"]=pred_xgb[\"Sales\"].apply(lambda x:max(x,0))\n\npred_xgb.to_csv('./submission_xgb.csv', index = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#各foldのスコアを保存するリスト\nscores_RMSPE = []\n\n#クロスバリデーションを行う\n#学習データを4つに分割し、うち1つをバリデーションデータとすることをバリデーションデータを変えて繰り返す\nkf = KFold(n_splits=2, shuffle =True, random_state=71)\n\nfor tr_idx, va_idx in kf.split(x_train_store):\n    #学習データを学習データとバリデーションデータに分ける\n    tr_x, va_x = x_train_store.iloc[tr_idx], x_train_store.iloc[va_idx]\n    tr_y, va_y = y_train_store.iloc[tr_idx], y_train_store.iloc[va_idx]\n    \n    #モデルの学習を行う \n    model_xgb_cv = xgb.XGBRegressor()\n    model_xgb_cv.fit(tr_x,tr_y)\n    \n    #バリデーションデータの予測値を確率で出力する\n    va_pred = model_xgb_cv.predict(va_x)\n    va_pred= np.where(va_pred < 0, 0, va_pred)\n    #va_pred[0] = va_pred[0].apply(lambda x:0 if x<0 else x)\n    #pd.DataFrame({\"Sales_pred\":model_cv.predict(va_x)[:len(model_cv.predict(va_x))]})\n    \n    #バリデーションデータでスコアを計算する\n    RMSPE = gen_RMSPE(np.ravel(va_pred), va_y[\"Sales\"].values)\n    #RMSPE = np.sqrt(np.mean(((pred - true) / true)**2))*100\n        \n    #そのfoldスコアを保持する\n    scores_RMSPE.append(RMSPE)\n    #RMSPE = np.sqrt(np.mean(((pred - true) / true)**2))*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_RMSPE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 線形回帰。day7か否かで分ける。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_store_open0=train_store[train_store[\"Open\"]==0]\ntest_store_open0=test_store[test_store[\"Open\"]==0]\n\ntrain_store_open1=train_store[train_store[\"Open\"]==1]\ntest_store_open1=test_store[test_store[\"Open\"]==1]\n\ntrain_store_day7=train_store_open1[train_store_open1['DayOfWeek_7']==1].drop([\"DayOfWeek_2\",\"DayOfWeek_3\",\"DayOfWeek_4\",\"DayOfWeek_5\",\"DayOfWeek_6\",\"DayOfWeek_7\"], axis = 1)\ntest_store_day7=test_store_open1[test_store_open1['DayOfWeek_7']==1].drop([\"DayOfWeek_2\",\"DayOfWeek_3\",\"DayOfWeek_4\",\"DayOfWeek_5\",\"DayOfWeek_6\",\"DayOfWeek_7\"], axis = 1)\n\ntrain_store_daynot7=train_store_open1[train_store_open1['DayOfWeek_7']==0].drop([\"DayOfWeek_7\"], axis = 1)\ntest_store_daynot7=test_store_open1[test_store_open1['DayOfWeek_7']==0].drop([\"DayOfWeek_7\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_open0=pd.DataFrame(test_store_open0[\"Id\"],columns=[\"Id\"])\npred_open0[\"Sales\"]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trainから\"Sales\"と\"Customers\"を分離\ny_train_store_day7 = train_store_day7[[\"Sales\"]]\nx_train_store_day7 = train_store_day7.drop([\"Sales\",\"Customers\"], axis = 1)\n\n#\"Store\"も回帰変数には含めないので落とす\nx_train_store_day7 = x_train_store_day7.drop([\"Store\",\"StateHoliday_b\",\"StateHoliday_c\"], axis = 1)\n\n#\"Store\"も回帰変数には含めないので落とす\nx_test_store_day7_id= test_store_day7[\"Id\"]\nx_test_store_day7 = test_store_day7.drop([\"Id\",\"Store\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trainから\"Sales\"と\"Customers\"を分離\ny_train_store_daynot7 = train_store_daynot7[[\"Sales\"]]\nx_train_store_daynot7 = train_store_daynot7.drop([\"Sales\",\"Customers\"], axis = 1)\n\n#\"Store\"も回帰変数には含めないので落とす\nx_train_store_daynot7 = x_train_store_daynot7.drop([\"Store\",\"StateHoliday_b\",\"StateHoliday_c\"], axis = 1)\n\n#\"Store\"も回帰変数には含めないので落とす\nx_test_store_daynot7_id= test_store_daynot7[\"Id\"]\nx_test_store_daynot7 = test_store_daynot7.drop([\"Id\",\"Store\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#３．線形回帰する\nfrom sklearn.linear_model import LinearRegression\n\n#線形回帰実行（普通の重回帰）\nmodel_day7 = LinearRegression()\nmodel_day7.fit(x_train_store_day7,y_train_store_day7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#線形回帰による予測\npred_linear_1 = model_day7.predict(x_test_store_day7)\n\npred_linear_day7=pd.DataFrame(x_test_store_day7_id,columns=[\"Id\"])\npred_linear_day7[\"Sales\"]=pred_linear_1\npred_linear_day7[\"Sales\"]=pred_linear_day7[\"Sales\"].apply(lambda x:max(x,0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({\"変数\":np.ravel(x_train_store_day7.columns.values), \"係数\":np.ravel(model_day7.coef_)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#３．線形回帰する\n#線形回帰実行（普通の重回帰）\nmodel_daynot7 = LinearRegression()\nmodel_daynot7.fit(x_train_store_daynot7,y_train_store_daynot7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#線形回帰による予測\npred_linear_1 = model.predict(x_test_store_daynot7)\n\npred_linear_daynot7=pd.DataFrame(x_test_store_daynot7_id,columns=[\"Id\"])\npred_linear_daynot7[\"Sales\"]=pred_linear_1\npred_linear_daynot7[\"Sales\"]=pred_linear_daynot7[\"Sales\"].apply(lambda x:max(x,0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({\"変数\":np.ravel(x_train_store_daynot7.columns.values), \"係数\":np.ravel(model_daynot7.coef_)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_bunri=pd.concat([pred_linear_daynot7,pred_linear_day7,pred_open0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_bunri.to_csv('./submission_bunri_linear.csv', index = False )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"↓ここより下は未確認↓","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 雑だったところをちゃんとつめていく。まずは変数選択","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#変数選択\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Lasso\n\n#変数選択はとりあえずLASSOで、正則化パラメータは10とする（適当）。\n\nscaler = StandardScaler()\nclf = Lasso(alpha=10)\n\n#30秒くらいかかった\nscaler.fit(x_train_store)\nclf.fit(scaler.transform(x_train_store), y_train_store)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#一部の変数の寄与が0になった\npd.DataFrame({\"変数\":np.ravel(x_train_store.columns.values), \"係数\":np.ravel(clf.coef_)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#線形回帰(Lasso)による予測\nscaler.fit(x_test_store)\npred_linear_2 = clf.predict(scaler.transform(x_test_store))\n#1次元配列に変換\npred_linear_2 = np.ravel(pred_linear_2)\n\n#提出用にデータを結合\nsubmission_linear_lasso = pd.DataFrame({\n        \"Id\": id_test,\n        \"Sales\": pred_linear_2\n    })\n\n#\"Id\"順に並べ替え\nsubmission_linear_lasso = submission_linear_lasso.sort_values('Id')\n\n#0より小さい予測値を0に変換\nsubmission_linear_lasso[\"Sales\"] = submission_linear_lasso[\"Sales\"].apply(lambda x:max(x,0))\n\nsubmission_linear_lasso.to_csv('./submission_linear_lasso.csv', index = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_linear_2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# submission_linear_lassoのスコアは0.40623となった。少しだけ上がったが根本的な改善はなかった。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 来客数（Customers）の情報を生かすことを考える。来客数と単価を別に予測して、売上＝来客数×単価として予測する。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#train・testとstoreを結合\n#trainとstoreを結合すると何故か\"Id\"が消える、、、\nx_train_store = pd.merge(x_train, x_store, how = 'inner', on = 'Store')\nx_test_store = pd.merge(x_test, x_store, how = 'inner', on = 'Store')\n\n#単価を算出する\nx_train_store[\"Unit\"] = x_train_store[\"Sales\"] /x_train_store[\"Customers\"] \n#\"Customers\"=0 のときInfになるので0に置き換える。\nx_train_store[\"Unit\"] = x_train_store[\"Unit\"] .fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trainから\"Sales\", \"Customers\", \"Unit\"を分離、うち\"Sales\"は捨てる\ny_train_store = x_train_store.loc[:,[\"Customers\",\"Unit\"]]\nx_train_store = x_train_store.drop([\"Sales\",\"Customers\",\"Unit\"], axis = 1)\n\n#\"Store\"も回帰変数には含めないので落とす\nx_train_store = x_train_store.drop([\"Store\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#変数選択はとりあえずLASSOで、正則化パラメータは10とする（適当）。\n\nscaler = StandardScaler()\nclf_cust = Lasso(alpha=10) #適当\nclf_unit = Lasso(alpha=0.1) #適当。10だと退化してしまったので、、\n\n#30秒くらいかかった\nscaler.fit(x_train_store)\nclf_cust.fit(scaler.transform(x_train_store), y_train_store[\"Customers\"])\nclf_unit.fit(scaler.transform(x_train_store), y_train_store[\"Unit\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testから\"Id\"を分離\nid_test = x_test_store[\"Id\"]\n#\"Store\"も回帰変数には含めないので落とす\nx_test_store = x_test_store.drop([\"Id\",\"Store\"], axis = 1)\n\n#CostomerとUnitの積を予測値とする。\npred_linear_3 = clf_cust.predict(scaler.transform(x_test_store))*clf_unit.predict(scaler.transform(x_test_store))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1次元配列に変換\npred_linear_3 = np.ravel(pred_linear_3)\n\n#提出用にデータを結合\nsubmission_linear_lasso_unit = pd.DataFrame({\n        \"Id\": id_test,\n        \"Sales\": pred_linear_3\n    })\n\n#\"Id\"順に並べ替え\nsubmission_linear_lasso_unit = submission_linear_lasso_unit.sort_values('Id')\n\n#0より小さい予測値を0に変換\nsubmission_linear_lasso_unit[\"Sales\"] = submission_linear_lasso_unit[\"Sales\"].apply(lambda x:max(x,0))\n\nsubmission_linear_lasso_unit.to_csv('./submission_linear_lasso_unit.csv', index = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_linear_lasso_unitのスコアは0.43454となった。","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# しきりなおし\n\n少ない変数からスタートし、残差分析を通じてモデルを改良していく。\n\n参考：https://www.kaggle.com/amithanayak/predict-sales-using-linear-regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#加工用にデータを分離する\ntrain2 = gen_data()[0]\ntest2 = gen_data()[1]\nstore2 = gen_data()[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.set(style=\"whitegrid\")\nsns.boxplot(data=train2,x=\"DayOfWeek\",y=\"Sales\")\nprint(\"曜日ごとに箱ひげ図を描画し、外れ値の検証をした。曜日によってまちまちだが20000超は外れ値扱いでよさそう。\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#曜日ごとのばらつきを確認\nsales_DayOfWeek_df=pd.DataFrame({\"Avg SalesPerDoW\":train2[\"Sales\"],\"DayOfWeek\":train2[\"DayOfWeek\"]})\nAvgSalesDayOfWeek=sales_DayOfWeek_df.groupby(\"DayOfWeek\").mean()\nprint(\"曜日ごとに一定のばらつきがある。\")\nprint(plt.plot(AvgSalesDayOfWeek, marker = \"o\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#外れ値を特定の値で置き換える(Clipping)\ntrain2[\"Sales\"]=train2[\"Sales\"].apply(lambda x: 20000 if x>20000 else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dateの情報を活用する\ntrain2[\"Date\"]=pd.to_datetime(train2[\"Date\"])\ntrain2[\"Year\"]=train2[\"Date\"].dt.year\ntrain2[\"Month\"]=train2[\"Date\"].dt.month\ntrain2[\"Day\"]=train2[\"Date\"].dt.day\n#その月の第何週かに無理やり読み替える\ntrain2[\"Week\"]=train2[\"Date\"].dt.week%4\n#季節別\ntrain2[\"Season\"] = np.where(train2[\"Month\"].isin([3,4]),\"Spring\",np.where(train2[\"Month\"].isin([5,6,7,8]), \"Summer\",np.where(train2[\"Month\"].isin ([9,10,11]),\"Fall\",np.where(train2[\"Month\"].isin ([12,1,2]),\"Winter\",\"None\"))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#月別売上高のばらつきを確認\nsales_time_df=pd.DataFrame({\"Avg SalesPerMonth\":train2[\"Sales\"],\"Month\":train2[\"Month\"]})\nAvgCustomerperMonth=sales_time_df.groupby(\"Month\").mean()\nprint(\"月ごとに一定のばらつきがある。\")\nprint(plt.plot(AvgCustomerperMonth, marker = \"o\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_store2=store2.merge(train2,on=[\"Store\"],how=\"inner\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#store type別のばらつきを確認\nstype_df=pd.DataFrame({\"Avg storetype\":train_store2[\"Sales\"],\"StoreType\":train_store2[\"StoreType\"]})\nAvgstoretype=stype_df.groupby(\"StoreType\").mean()\nprint(\"「b」だけ明らかに高い\")\nprint(plt.plot(Avgstoretype, marker = \"o\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assortment別のばらつきを確認\nAssortment_df=pd.DataFrame({\"Avg Assortment\":train_store2[\"Sales\"],\"Assortment\":train_store2[\"Assortment\"]})\nAvgAssortment=Assortment_df.groupby(\"Assortment\").mean()\nprint(\"「b」が高いが各々差分がある\")\nprint(plt.plot(AvgAssortment, marker = \"o\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kaggleのカーネルでは動かない、why...\n\n#StateHoliday別のばらつきを確認\n#StateHoliday_df=pd.DataFrame({\"Avg StateHoliday\":train_store2[\"Sales\"],\"StateHoliday\":train_store2[\"StateHoliday\"]})\n#AvgStateHoliday=StateHoliday_df.groupby(\"StateHoliday\").mean()\n#print(\"「0」が高く、あとは一律に低い\")\n#print(plt.plot(AvgStateHoliday, marker = \"o\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Promo2別のばらつきを確認\nPromo2_df=pd.DataFrame({\"Avg Promo2\":train_store2[\"Sales\"],\"Promo2\":train_store2[\"Promo2\"]})\nAvgPromo2=Promo2_df.groupby(\"Promo2\").mean()\nprint(\"以外にも「0」が高い\")\nprint(plt.plot(AvgPromo2, marker = \"o\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#欠損値になっている箇所は一旦無視する\ntrain_store2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list = [\"CompetitionDistance\",\"CompetitionOpenSinceMonth\",\"CompetitionOpenSinceYear\",\"Promo2SinceWeek\",\"Promo2SinceWeek\",\"Promo2SinceYear\",\"PromoInterval\"]\nfeature = train_store2.drop(drop_list, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#特徴量の構成\n#\"Month\"は12月かそれ以外か\nfeature[\"Month\"] = feature[\"Month\"].apply(lambda x: 1 if x==12 else 0)\n#\"Assortment\"は「b」かそれ以外か   ##ダミー変数にする\n#feature = pd.concat([feature.drop('Assortment', axis=1), pd.get_dummies(feature['Assortment']).iloc[:, :-1]], axis=1)\nfeature[\"Assortment\"] = feature[\"Assortment\"].apply(lambda x: 1 if x==\"b\" else 0)\n#\"DayOfWeek\"は日曜(「7」)かそれ以外か\nfeature[\"DayOfWeek\"] = feature[\"DayOfWeek\"].apply(lambda x: 1 if x==7 else 0)\n#\"Store Type\"は「b」かそれ以外か\nfeature[\"StoreType\"] = feature[\"StoreType\"].apply(lambda x: 1 if x==\"b\" else 0)\n#\"StateHoliday\"は「\"0\"」かそれ以外か\nfeature[\"StateHoliday\"] = feature[\"StateHoliday\"].apply(lambda x: 0 if x==\"0\" else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\ncollections.Counter(train_store2[\"Assortment\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#細かい変数を落とす\n#\"Week\"は残す\ndrop_list2 = [\"Store\",\"Date\",\"Year\",\"Day\",\"Season\"]\nfeature2 = feature.drop(drop_list2, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#回帰用の変数を作成\ny_feature2 = feature[\"Sales\"]\nx_feature2 = feature2.drop([\"Sales\",\"Customers\"],axis=1)\nx_feature2 = feature2.drop([\"Sales\",\"Customers\"],axis=1)\nx_feature2[\"Open_stHoli\"] = feature[\"Open\"]*x_feature2[\"StateHoliday\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_feature2.head())\nprint(x_feature2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_feature2.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#３．線形回帰する\nfrom sklearn.linear_model import LinearRegression\n\n#線形回帰実行（普通の重回帰）\nmodel_0 = LinearRegression()\nmodel_0.fit(x_feature2,y_feature2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coeficient = pd.DataFrame({\"変数\":x_feature2.columns,\"係数\":model_0.coef_})\nprint(coeficient)\nprint({\"定数項\":model_0.intercept_})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame({\"Sales_pred\":model_0.predict(x_feature2)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n#各foldのスコアを保存するリスト\nscores_RMSPE = []\n\n#クロスバリデーションを行う\n#学習データを4つに分割し、うち1つをバリデーションデータとすることをバリデーションデータを変えて繰り返す\nkf = KFold(n_splits=4, shuffle =True, random_state=72)\n\nfor tr_idx, va_idx in kf.split(x_feature2):\n    #学習データを学習データとバリデーションデータに分ける\n    tr_x, va_x = x_feature2.iloc[tr_idx], x_feature2.iloc[va_idx]\n    tr_y, va_y = y_feature2.iloc[tr_idx], y_feature2.iloc[va_idx]\n    \n    #モデルの学習を行う \n    model_cv = LinearRegression()\n    model_cv.fit(tr_x,tr_y)\n    \n    #バリデーションデータの予測値を確率で出力する\n    va_pred = pd.DataFrame({\"Sales_pred\":model_cv.predict(va_x)})\n    \n    #バリデーションデータでスコアを計算する\n    RMSPE = gen_RMSPE(va_pred[\"Sales_pred\"], va_y)\n        \n    #そのfoldスコアを保持する\n    scores_RMSPE.append(RMSPE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_RMSPE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#残差分析\n#以下、コンペの趣旨に沿ってSalesが0の先は対象外とする\nfeature[\"pred_Sales\"] = pred\nfeature_analysis = feature[feature[\"Sales\"]>0]\nfeature_analysis[\"Residuals\"] = np.power((feature_analysis[\"pred_Sales\"] - feature_analysis[\"Sales\"])/feature_analysis[\"Sales\"], 2)\nfeature_analysis.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#残差の大きいレコードを抽出する\nres_anal = feature_analysis.sort_values('Residuals',ascending=False)\nres_anal.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_anal[res_anal[\"Open\"]!=1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}