{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\n# Plotting Library\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nplt.style.use('Solarize_Light2')\n\n# Other Libraries\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom scipy.stats import ttest_ind ,linregress , ttest_rel\nimport statsmodels.api as sm\nfrom scipy.stats import probplot\nfrom scipy.stats import zscore\nfrom sklearn.metrics import r2_score\nfrom statsmodels.graphics.regressionplots import influence_plot\nfrom sklearn.preprocessing import PolynomialFeatures , StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso ,ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import train_test_split\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data PreProcessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ispromomonth(rows):\n#   if not rows[0].isnull():\n    months = {}\n    months = str(rows['PromoInterval']).split(',')\n    if str(rows['month_str']) in months:\n        return 1\n    else:\n        return 0\ndef rmspe(y, yhat):\n    return np.sqrt(np.mean((yhat/y-1) ** 2))\n\ndef rmspe_xg(yhat, y):\n    y = np.expm1(y.get_label())\n    yhat = np.expm1(yhat)\n    return \"rmspe\", rmspe(y,yhat)\n\nclass Rossmann_:\n    def __init__(self , train_data_path = '../input/train.csv' , test_data_path='../input/test.csv' , store_path='../input/store.csv' , nrows =100000):\n        self.train_data_path =  train_data_path\n        self.test_data_path = test_data_path\n        self.store_path = store_path\n        self.read_size = nrows\n        self.train_data_original = pd.read_csv(self.train_data_path , low_memory = False , nrows = self.read_size)\n        self.test_data_original = pd.read_csv(self.test_data_path ,low_memory = False , nrows = self.read_size)\n        self.store_data_original = pd.read_csv(self.store_path)\n        \n        self.start_preprocessing_train(self.train_data_original , self.store_data_original)\n        self.start_preprocessing_test(self.test_data_original , self.store_data_original)\n    \n    def start_preprocessing_train(self , train_data , store):\n        train_data.StateHoliday = train_data.StateHoliday.replace('0',0)\n        train_data.StateHoliday = train_data.StateHoliday.replace('a',1)\n        train_data.StateHoliday = train_data.StateHoliday.replace('b',2)\n        train_data.StateHoliday = train_data.StateHoliday.replace('c',3)\n        train_data['Date_Year'] = train_data['Date'].apply(lambda x: int(x[:4]))\n        train_data['Date_Month'] = train_data['Date'].apply(lambda x: int(x[5:7]))\n        train_data['Date_Day'] = train_data['Date'].apply(lambda x: int(x[8:]))\n        train_data_m = pd.merge(train_data, store, on='Store')\n        mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n        train_data_m.StoreType.replace(mappings, inplace=True)\n        train_data_m.Assortment.replace(mappings, inplace=True)\n        \n        #Finding the week of the year \n        train_data_m['Date'] = pd.to_datetime(train_data_m['Date'], errors='coerce')\n        train_data_m['date_WeekOfYear'] = train_data_m.Date.dt.weekofyear\n        \n        #Combining the Week and Year for Competition and Promo\n        train_data_m['Competition_Weeks'] = 12*(train_data_m.Date_Year - train_data_m.CompetitionOpenSinceYear ) + (train_data_m.Date_Month - train_data_m.CompetitionOpenSinceMonth) \n        train_data_m['Promo_Weeks'] = 12*(train_data_m.Date_Year - train_data_m.Promo2SinceYear ) + (train_data_m.Date_Month - train_data_m.Promo2SinceWeek)\n        train_data_m['Competition_Weeks'] =  train_data_m['Competition_Weeks'].apply(lambda x: x if x > 0 else 0)\n        train_data_m['Promo_Weeks'] =  train_data_m['Promo_Weeks'].apply(lambda x: x if x > 0 else 0)\n        \n        # is promo month is the months the promo is valid so\n        month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n        train_data_m['month_str'] = train_data_m.Date_Month.map(month2str)\n        \n        train_data_m['IsPromoMonth'] = train_data_m[[ 'PromoInterval' , 'month_str' ]].apply(ispromomonth , axis = 1) \n        train_data_m.fillna(0, inplace=True)\n        \n        #updating the rows with sales>0 and customes>0 \n        train_data_updated = train_data_m[train_data_m['Sales']>0]\n        train_data_updated = train_data_updated[train_data_updated['Customers']>0]\n        \n        features = ['Store', 'DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo','StateHoliday', 'SchoolHoliday', 'Date_Year', 'Date_Month', 'Date_Day','StoreType', 'Assortment', 'CompetitionDistance','CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2','Promo2SinceWeek', 'Promo2SinceYear', 'date_WeekOfYear', 'Competition_Weeks', 'Promo_Weeks', 'IsPromoMonth']   \n                \n        self.train_final = train_data_updated[features]\n        cols = self.train_final.columns\n        self.train_final = pd.DataFrame(StandardScaler().fit_transform(self.train_final) , columns = cols)\n        \n    def start_preprocessing_test(self , test_data , store):\n        test_data.fillna(1 , inplace=True)\n        # These are all the Oprations appied on the Data\n        test_data['Date_Year'] = test_data['Date'].apply(lambda x: int(x[:4]))\n        test_data['Date_Month'] = test_data['Date'].apply(lambda x: int(x[5:7]))\n        test_data['Date_Day'] = test_data['Date'].apply(lambda x: int(x[8:]))\n        test_data_m = pd.merge(test_data, store, on='Store')\n        mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\n        test_data_m.StoreType.replace(mappings, inplace=True)\n        test_data_m.Assortment.replace(mappings, inplace=True)\n        test_data_m.StateHoliday.replace(mappings, inplace=True)\n        test_data_m['Date'] = pd.to_datetime(test_data_m['Date'], errors='coerce')\n        test_data_m['date_WeekOfYear'] = test_data_m.Date.dt.weekofyear\n        test_data_m['Competition_Weeks'] = 12*(test_data_m.Date_Year - test_data_m.CompetitionOpenSinceYear ) + (test_data_m.Date_Month - test_data_m.CompetitionOpenSinceMonth) \n        test_data_m['Promo_Weeks'] = 12*(test_data_m.Date_Year - test_data_m.Promo2SinceYear ) + (test_data_m.Date_Month - test_data_m.Promo2SinceWeek)\n        test_data_m['Competition_Weeks'] =  test_data_m['Competition_Weeks'].apply(lambda x: x if x > 0 else 0)\n        test_data_m['Promo_Weeks'] =  test_data_m['Promo_Weeks'].apply(lambda x: x if x > 0 else 0)\n        month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n        test_data_m['month_str'] = test_data_m.Date_Month.map(month2str)\n        test_data_m['IsPromoMonth'] = test_data_m[[ 'PromoInterval' , 'month_str' ]].apply(ispromomonth , axis = 1) \n        test_data_m.fillna(0, inplace=True)\n        features = ['Store', 'DayOfWeek', 'Open', 'Promo','StateHoliday', 'SchoolHoliday', 'Date_Year', 'Date_Month', 'Date_Day','StoreType', 'Assortment', 'CompetitionDistance','CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2','Promo2SinceWeek', 'Promo2SinceYear', 'date_WeekOfYear', 'Competition_Weeks', 'Promo_Weeks', 'IsPromoMonth']   \n        self.test_final  = test_data_m[features]\n        \n    def prepare_sample_data(self , limit =100 , testing_limit = 30):\n        self.data = self.train_final.sample(frac = 1 , random_state = 98).head(limit)\n        self.test_data = self.train_final.sample(frac = 1 , random_state = 98).tail(testing_limit)\n        \n    def Linear_Regression(self):\n        print('Creating Linear Regression Model Between Sales and Customers... ')\n        lr = LinearRegression()\n        lr.fit(self.data['Customers'].values.reshape(-1,1) , self.data['Sales'].values.reshape(-1,1))\n        print('Fitting Done on Model ... ')\n        print(lr)\n        r2_score = lr.score(self.data['Customers'].values.reshape(-1,1), self.data['Sales'].values.reshape(-1,1))\n#         print('R2 Score is ',r2_score)\n#         print('Since the Model R2 Score is ',r2_score , ', the model explains ',round(r2_score*100,2) , ' % of the variation in GI')\n        print('Coefficients for the linear regression problem is ',lr.coef_)\n        print('Intersect Value is ',lr.intercept_)\n        y_pred = lr.predict(self.data['Customers'].values.reshape(-1, 1))\n        rms = sqrt(mean_squared_error(self.data['Sales'].values.reshape(-1,1), y_pred))\n        ty_pred = lr.predict(self.test_data['Customers'].values.reshape(-1, 1))\n        trms = sqrt(mean_squared_error(self.test_data['Sales'].values.reshape(-1,1), ty_pred))\n        print('Root Mean Squared Error of Training Set is ',rms)\n        print('Root Mean Squared Error of Testing Set is ',trms)\n        \n#         print('R2 Score of Training Set is ',r2_score(y_pred, self.data['Sales'].values.reshape(-1,1)))\n#         print('R2 Score of Testing Set is ',r2_score(ty_pred, self.test_data['Sales'].values.reshape(-1,1)))\n        \n        plt.figure(figsize=(15,10))\n        plt.scatter(self.data['Customers'].values.reshape(-1, 1) ,  self.data['Sales'].values.reshape(-1,1) , color ='r' , label = 'Actual Values')\n        plt.scatter(self.data['Customers'].values.reshape(-1, 1) , y_pred , color ='b' , label = 'Predicted')\n        plt.plot(self.data['Customers'].values.reshape(-1, 1) , y_pred , color ='k' , label = 'Predicted Line')\n        plt.xlabel('Customers Index')\n        plt.ylabel('Sales Index')\n        plt.legend()\n        plt.savefig('Linear Regression Training.png')\n        \n        plt.figure(figsize=(15,10))\n        plt.scatter(self.test_data['Customers'].values.reshape(-1, 1) ,  self.test_data['Sales'].values.reshape(-1,1) , color ='g' , label = 'Actual Values')\n        plt.scatter(self.test_data['Customers'].values.reshape(-1, 1) , ty_pred , color ='y' , label = 'Predicted')\n        plt.plot(self.test_data['Customers'].values.reshape(-1, 1) , ty_pred , color ='k' , label = 'Predicted Line')\n        plt.xlabel('Customers Index')\n        plt.ylabel('Sales Index')\n        plt.legend()\n        plt.savefig('Linear Regression Testing.png')\n        \n    def display_graphs(self,simple = False , orders = 1):\n        for i in range(1, orders+1,1):\n            lm = sns.lmplot(x =\"Customers\", y =\"Sales\", data = self.data, scatter = True, order = i, fit_reg = True, ci  = 95 ) \n            lm.fig.suptitle(\"Scatter plot with Order = \"+str(i), fontsize=16)\n            \n    def Mulitple_Linear_Regression(self):\n        print('Creating Multiple Linear Regression Model... ')\n        print('Using Columns -> ',self.data.drop(columns = ['Sales','Customers']).columns)\n        lr = LinearRegression()\n        lr.fit(self.data.drop(columns = ['Sales','Customers']).values , self.data['Sales'].values)\n        print(lr)\n        print('Fitting Done on Model ... ')\n        print('Coefficients for the linear regression problem is ',lr.coef_)\n        print('Intersect Value is ',lr.intercept_)\n        y_pred = lr.predict(self.data.drop(columns = ['Sales','Customers']).values)\n        rms = sqrt(mean_squared_error(self.data['Sales'].values, y_pred))\n        ty_pred = lr.predict(self.test_data.drop(columns = ['Sales','Customers']).values)\n        trms = sqrt(mean_squared_error(self.test_data['Sales'].values, ty_pred))\n        print('Root Mean Squared Error of Training Set is ',rms)\n        print('Root Mean Squared Error of Testing Set is ',trms)\n#         print('R2 Score of Training Set is ',r2_score(y_pred, self.data['Sales'].values.reshape(-1,1)))\n#         print('R2 Score of Testing Set is ',r2_score(ty_pred, self.test_data['Sales'].values.reshape(-1,1)))\n\n        self.data['pred'] = y_pred\n        self.test_data['pred'] = ty_pred\n        plt.figure(figsize=(15,10))\n        sns.jointplot(x = 'Sales' , y = 'pred' , data = self.data, height=10, ratio=3 , color='g' )\n        plt.savefig('Multiple Linear Regression Training.png')\n        \n        plt.figure(figsize=(15,10))\n        sns.jointplot(x = 'Sales' , y = 'pred' , data = self.test_data, height=10, ratio=3 , color='r' )\n        plt.savefig('Multiple Linear Regression Testing.png')\n        \n#         plt.figure(figsize=(15,10))\n#         plt.scatter(self.test_data['Customers'].values.reshape(-1,1)  ,  self.test_data['Sales'].values.reshape(-1,1) , color ='g',label = 'Actual Values')\n#         plt.scatter(self.test_data['Customers'].values.reshape(-1,1)  , ty_pred , color ='y', label = 'Predicted')\n#         plt.plot(self.test_data['Customers'].values.reshape(-1,1)  , ty_pred , color ='k' , label = 'Predicted Line')\n#         plt.xlabel('Customers Index')\n#         plt.ylabel('Sales Index')\n#         plt.legend()\n#         plt.savefig('Multiple Linear Regression Testing.png')\n    \n    def Polynomial_Regression(self , degrees = 4):\n        print('To Reduce Complexity...\\nUsing Single Data Column Customers Rather than All...')\n        Input=[('polynomial',PolynomialFeatures(degree=degrees)),('modal',LinearRegression())]\n        lr=Pipeline(Input)\n        lr.fit(self.data['Customers'].values.reshape(-1,1) , self.data['Sales'].values.reshape(-1,1))\n        print('Fitting Done on Model ... ')\n        r2_score = lr.score(self.data['Customers'].values.reshape(-1,1), self.data['Sales'].values.reshape(-1,1))\n#         print('R2 Score is ',r2_score)\n#         print('Since the Model R2 Score is ',r2_score , ', the model explains ',round(r2_score*100,2) , ' % of the variation in GI')\n        self.data.sort_values(by='Customers' , inplace = True)\n        self.test_data.sort_values(by='Customers' , inplace = True)\n        y_pred = lr.predict(self.data['Customers'].values.reshape(-1, 1))\n        rms = sqrt(mean_squared_error(self.data['Sales'].values.reshape(-1,1), y_pred))\n        ty_pred = lr.predict(self.test_data['Customers'].values.reshape(-1, 1))\n        trms = sqrt(mean_squared_error(self.test_data['Sales'].values.reshape(-1,1), ty_pred))\n        print('Root Mean Squared Error of Training Set is ',rms)\n        print('Root Mean Squared Error of Testing Set is ',trms)\n#         print('R2 Score of Training Set is ',r2_score(y_pred, self.data['Sales'].values.reshape(-1,1)))\n#         print('R2 Score of Testing Set is ',r2_score(ty_pred, self.test_data['Sales'].values.reshape(-1,1)))\n\n        plt.figure(figsize=(15,10))\n        plt.scatter(self.data['Customers'].values.reshape(-1, 1) ,  self.data['Sales'].values.reshape(-1,1) , color ='r',label = 'Actual Values')\n        plt.scatter(self.data['Customers'].values.reshape(-1, 1) , y_pred , color ='b', label = 'Predicted')\n        plt.plot(self.data['Customers'].values.reshape(-1, 1) , y_pred , color ='k' , label = 'Predicted Line')\n        plt.xlabel('Customers Index')\n        plt.ylabel('Sales Index')\n        plt.legend()\n        plt.savefig('Polynomial Regression Training {}.png'.format(degrees))\n        \n        plt.figure(figsize=(15,10))\n        plt.scatter(self.test_data['Customers'].values.reshape(-1, 1) ,  self.test_data['Sales'].values.reshape(-1,1) , color ='g',label = 'Actual Values')\n        plt.scatter(self.test_data['Customers'].values.reshape(-1, 1) , ty_pred , color ='y', label = 'Predicted')\n        plt.plot(self.test_data['Customers'].values.reshape(-1, 1) , ty_pred , color ='k' , label = 'Predicted Line')\n        plt.xlabel('Customers Index')\n        plt.ylabel('Sales Index')\n        plt.legend()\n        plt.savefig('Polynomial Regression Testing {}.png'.format(degrees))\n    \n    def return_model(self,reg = 'Ridge' , alpha = 0.01):\n        if reg == 'Ridge':\n            lr = Ridge(alpha=alpha)\n        elif reg =='Lasso':\n            lr = Lasso(alpha=alpha)\n        elif reg =='Elastic':\n            lr = ElasticNet(alpha = alpha)\n        else:\n            lr = Ridge(alpha=alpha , solver = 'cholesky', tol = .005)\n        return lr\n    \n    def Other_Regression(self , reg = 'Ridge'):\n        print('Creating Multiple {} Regression Model... '.format(reg))\n        print('Using Columns -> ',self.data.drop(columns = ['Sales','Customers']).columns)\n        lr = self.return_model(reg = reg)\n        lr.fit(self.data.drop(columns = ['Sales','Customers']).values , self.data['Sales'].values)\n        print(lr)\n        print('Fitting Done on Model ... ')\n        print('Coefficients for the linear regression problem is ',lr.coef_)\n        print('Intersect Value is ',lr.intercept_)\n        y_pred = lr.predict(self.data.drop(columns = ['Sales','Customers']).values)\n        rms = sqrt(mean_squared_error(self.data['Sales'].values, y_pred))\n        ty_pred = lr.predict(self.test_data.drop(columns = ['Sales','Customers']).values)\n        trms = sqrt(mean_squared_error(self.test_data['Sales'].values, ty_pred))\n        print('Root Mean Squared Error of Training Set is ',rms)\n        print('Root Mean Squared Error of Testing Set is ',trms)\n        \n        print('Creating Alpha VS Mean Squared Error Graph for Alpha')\n        alphas = []\n        train_loss = []\n        test_loss = []\n        for i in range(10000):\n            alphas.append(i*0.0015 +0.0001)\n            lr = self.return_model(reg = reg , alpha = (i*0.0015 +0.0001))\n            lr.fit(self.data.drop(columns = ['Sales','Customers']).values , self.data['Sales'].values)\n            y_pred = lr.predict(self.data.drop(columns = ['Sales','Customers']).values)\n            rms = sqrt(mean_squared_error(self.data['Sales'].values, y_pred))\n            ty_pred = lr.predict(self.test_data.drop(columns = ['Sales','Customers']).values)\n            trms = sqrt(mean_squared_error(self.test_data['Sales'].values, ty_pred))\n            train_loss.append(rms)\n            test_loss.append(trms)\n        \n        plt.figure(figsize=(15,10))\n        plt.plot(alphas , train_loss , color ='r' , label = 'Training Loss')\n        plt.xlabel('Alpha')\n        plt.ylabel('Loss (RMSE)')\n        plt.legend()\n        plt.savefig('{} Regression Alpha Training.png'.format(reg))\n        plt.figure(figsize=(15,10))\n        plt.plot(alphas , test_loss , color ='g' , label = 'Testing Loss')\n        plt.xlabel('Alpha')\n        plt.ylabel('Loss (RMSE)')\n        plt.legend()\n        plt.savefig('{} Regression Alpha Testing.png'.format(reg))\n        \n        print('Using Single Column now ....')\n        lr = self.return_model(reg = reg)\n        \n        lr.fit(self.data['Customers'].values.reshape(-1,1) , self.data['Sales'].values.reshape(-1,1))\n        print('Fitting Done on Model ... ')\n        print(lr)\n        r2_score = lr.score(self.data['Customers'].values.reshape(-1,1), self.data['Sales'].values.reshape(-1,1))\n        print('Coefficients for the linear regression problem is ',lr.coef_)\n        print('Intersect Value is ',lr.intercept_)\n        y_pred = lr.predict(self.data['Customers'].values.reshape(-1, 1))\n        rms = sqrt(mean_squared_error(self.data['Sales'].values.reshape(-1,1), y_pred))\n        ty_pred = lr.predict(self.test_data['Customers'].values.reshape(-1, 1))\n        trms = sqrt(mean_squared_error(self.test_data['Sales'].values.reshape(-1,1), ty_pred))\n        print('Root Mean Squared Error of Training Set is ',rms)\n        print('Root Mean Squared Error of Testing Set is ',trms)\n        \n        plt.figure(figsize=(15,10))\n        plt.scatter(self.data['Customers'].values.reshape(-1, 1) ,  self.data['Sales'].values.reshape(-1,1) , color ='r' , label = 'Actual Values')\n        plt.scatter(self.data['Customers'].values.reshape(-1, 1) , y_pred , color ='b' , label = 'Predicted')\n        plt.plot(self.data['Customers'].values.reshape(-1, 1) , y_pred , color ='k' , label = 'Predicted Line')\n        plt.xlabel('Customers Index')\n        plt.ylabel('Sales Index')\n        plt.legend()\n        plt.savefig('{} Regression Training.png'.format(reg))\n        \n        plt.figure(figsize=(15,10))\n        plt.scatter(self.test_data['Customers'].values.reshape(-1, 1) ,  self.test_data['Sales'].values.reshape(-1,1) , color ='g' , label = 'Actual Values')\n        plt.scatter(self.test_data['Customers'].values.reshape(-1, 1) , ty_pred , color ='y' , label = 'Predicted')\n        plt.plot(self.test_data['Customers'].values.reshape(-1, 1) , ty_pred , color ='k' , label = 'Predicted Line')\n        plt.xlabel('Customers Index')\n        plt.ylabel('Sales Index')\n        plt.legend()\n        plt.savefig('{} Regression Testing.png'.format(reg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross = Rossmann_()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross.prepare_sample_data(limit =200 , testing_limit = 40)\nross.Linear_Regression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross.prepare_sample_data(limit =2000 , testing_limit = 400)\nross.Mulitple_Linear_Regression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross.prepare_sample_data(limit =10000 , testing_limit = 4000)\nross.Polynomial_Regression(degrees = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross.prepare_sample_data(limit =10000 , testing_limit = 4000)\nross.Polynomial_Regression(degrees = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross.prepare_sample_data(limit =1000 , testing_limit = 400)\nross.Other_Regression(reg = 'Ridge')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross.prepare_sample_data(limit =1000 , testing_limit = 400)\nross.Other_Regression(reg = 'Lasso')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross.prepare_sample_data(limit =1000 , testing_limit = 400)\nross.Other_Regression(reg = 'Elastic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ross.prepare_sample_data(limit =1000 , testing_limit = 400)\nross.Other_Regression(reg = 'Bridge')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Other Ways\n ## The most of work is done \n "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"test_data['Date_Year'] = test_data['Date'].apply(lambda x: int(x[:4]))\ntest_data['Date_Month'] = test_data['Date'].apply(lambda x: int(x[5:7]))\ntest_data['Date_Day'] = test_data['Date'].apply(lambda x: int(x[8:]))\ntest_data_m = pd.merge(test_data, store, on='Store')\nmappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\ntest_data_m.StoreType.replace(mappings, inplace=True)\ntest_data_m.Assortment.replace(mappings, inplace=True)\ntest_data_m.StateHoliday.replace(mappings, inplace=True)\ntest_data_m['Date'] = pd.to_datetime(test_data_m['Date'], errors='coerce')\ntest_data_m['date_WeekOfYear'] = test_data_m.Date.dt.weekofyear\ntest_data_m['Competition_Weeks'] = 12*(test_data_m.Date_Year - test_data_m.CompetitionOpenSinceYear ) + (test_data_m.Date_Month - test_data_m.CompetitionOpenSinceMonth) \ntest_data_m['Promo_Weeks'] = 12*(test_data_m.Date_Year - test_data_m.Promo2SinceYear ) + (test_data_m.Date_Month - test_data_m.Promo2SinceWeek)\ntest_data_m['Competition_Weeks'] =  test_data_m['Competition_Weeks'].apply(lambda x: x if x > 0 else 0)\ntest_data_m['Promo_Weeks'] =  test_data_m['Promo_Weeks'].apply(lambda x: x if x > 0 else 0)\nmonth2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\ntest_data_m['month_str'] = test_data_m.Date_Month.map(month2str)\ntest_data_m['IsPromoMonth'] = test_data_m[[ 'PromoInterval' , 'month_str' ]].apply(ispromomonth , axis = 1) \nfeatures = ['Store', 'DayOfWeek', 'Open', 'Promo','StateHoliday', 'SchoolHoliday', 'Date_Year', 'Date_Month', 'Date_Day','StoreType', 'Assortment', 'CompetitionDistance','CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2','Promo2SinceWeek', 'Promo2SinceYear', 'date_WeekOfYear', 'Competition_Weeks', 'Promo_Weeks', 'IsPromoMonth']   \ntest_data_updated  = test_data_m[features]\ntest_data_updated.fillna(0 , inplace=True)\ntest_data_updated.isnull().sum()\ny_pred_test = clf1.predict(test_data_updated)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# now using Xgb ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Here are notes of parameters used for tuning the model\n* booster [default=gbtree]\n        Select the type of model to run at each iteration. It has 2 options:\n            gbtree: tree-based models\n            gblinear: linear models\n* nthread [default to maximum number of threads available if not set]\n        This is used for parallel processing and number of cores in the system should be entered\n        If you wish to run on all cores, value should not be entered and algorithm will detect automatically\n        objective [default=reg:linear]\n* objective [default=reg:linear]\n        This defines the loss function to be minimized. Mostly used values are:\n            binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n            multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities)\n            you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n            multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n* eta [default=0.3]\n        Analogous to learning rate in GBM\n        Makes the model more robust by shrinking the weights on each step\n        Typical final values to be used: 0.01-0.2\n* subsample [default=1]\n        Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.\n        Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\n        Typical values: 0.5-1\n* colsample_bytree [default=1]\n    Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n    Typical values: 0.5-1\n\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import xgboost as xgb\n\nparams = {\"objective\": \"reg:linear\", # for linear regression\n          \"booster\" : \"gbtree\",   # use tree based models \n          \"eta\": 0.03,   # learning rate\n          \"max_depth\": 10,    # maximum depth of a tree\n          \"subsample\": 0.9,    # Subsample ratio of the training instances\n          \"colsample_bytree\": 0.7,   # Subsample ratio of columns when constructing each tree\n          \"silent\": 1,   # silent mode\n          \"seed\": 10   # Random number seed\n          }\nnum_boost_round = 4000\n\ndtrain = xgb.DMatrix(train_data_updated.drop(columns = ['Sales' , 'Customers']) , np.log1p(train_data_updated['Sales']) )\n# train the xgboost model\nmodel = xgb.train(params, dtrain, num_boost_round )\ndtest = xgb.DMatrix(test_data_updated)\nxgb_preds = model.predict(dtest)\nresult = pd.DataFrame({\"Id\": test_data_m[\"Id\"],'Sales': np.expm1(y_pred_test*0.995)})\nresult.to_csv(\"submission_xgb_final.csv\", index=False)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}