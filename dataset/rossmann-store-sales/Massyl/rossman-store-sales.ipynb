{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"825eb745cc20b131ef8a0498e5ac04ac5732c29e"},"cell_type":"markdown","source":"# Loading Data "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"sales = pd.read_csv(\"../input/train.csv\")\nsales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"sales.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ecb6b8c7a30bb103624f10b1e8a327498be8c60","scrolled":false},"cell_type":"code","source":"stores = pd.read_csv(\"../input/store.csv\")\nstores.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"stores.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5829cb5724306995064e0fdb6f9cfc8462f8c83","scrolled":false},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')\ntest = pd.merge(test, stores, 'left', 'Store')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb93897e820cf2b4af26a08dd10b99499b822d8c","scrolled":false},"cell_type":"code","source":"data = pd.merge(sales, stores, 'left', 'Store').sample(frac= 1)\ndata['Date'] = pd.to_datetime(data['Date'])\ndata['Month'] = data['Date'].dt.month\ndata['Year'] = data['Date'].dt.year\ndata['Day'] = data['Date'].dt.day\ndata['WeekOfYear'] = data.Date.dt.weekofyear\ndata['Quarter'] = data.Date.dt.quarter\ndata['StateHoliday'] = data['StateHoliday'].replace(0, '0')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"309056fd22ac515fd80dd0432b61d1f393d074a0","scrolled":false},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of stores in sales not in stores data\n\nprint(len(set(sales['Store']) - set(stores['Store'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of test stores not in train stores\n\nprint(len(set(test['Store']) - set(data['Store'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of train stores not in test stores\n\nprint(len(set(data['Store']) - set(test['Store'])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0be1b6ff849fc7899376a49a3599e8e4af565a23"},"cell_type":"markdown","source":"# EDA "},{"metadata":{"trusted":true,"_uuid":"0c00c043a4bd174b0c6a48a0565c099cb39f9a02","scrolled":false},"cell_type":"code","source":"g = sns.distplot(data['Sales'])\ng.set_title(\"Data Distribution\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Log normal target sales with several no sales data. Let's investigate that."},{"metadata":{"_uuid":"fadd7a8a60a8353677efc1332de077b429c9c0ec"},"cell_type":"markdown","source":"### Zero Sales"},{"metadata":{"trusted":true,"_uuid":"404119b3b9003596138bc3f8a1a20dc655582d67","scrolled":false},"cell_type":"code","source":"zero_sales = data[data['Sales']==0].copy()\ndata =  data[data['Sales']!=0].drop('Open', 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"717088edfd90f79c410b2818c271cc9a5781a46b","scrolled":true},"cell_type":"code","source":"fig, ax = plt.subplots (1,4, figsize=(20,4))\nsns.barplot(['Size'], [len(zero_sales)], ax=ax[0])\nsns.countplot('DayOfWeek', data=zero_sales, ax=ax[1])\nsns.countplot('Open', data=zero_sales, ax=ax[2])\nsns.countplot('Promo', data=zero_sales, ax=ax[3])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"324ab00dd1507540f737ff373a022bd8fd1a3fd5"},"cell_type":"markdown","source":"Most of them are recorded on Sundays, stores were closed, mainly during non promo days."},{"metadata":{"trusted":true,"_uuid":"1bdf5810f491dfcfbea5e8b53565db12eab3cc55","scrolled":false},"cell_type":"code","source":"print (len(sales[(sales['Sales']==0) & (sales['Open'])]))\nsales[(sales['Sales']==0) & (sales['Open'])].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74302827bf2299d59ea139774441e8a03998b368"},"cell_type":"markdown","source":"Will be removed"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"markdown","source":"stores_id = np.random.choice(stores['Store'], 200)\ndata_sub = data[data['Store'].isin(stores_id)].copy()"},{"metadata":{"trusted":true},"cell_type":"code","source":"int_cols = data.select_dtypes(include='int').drop(['Store', 'Customers', 'Sales'], 1).columns\ncategorical_cols = data.select_dtypes(include='object').columns\nfloat_cols = data.select_dtypes(include='float').drop('CompetitionDistance', 1).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, len(int_cols)//2, figsize=(25,10))\n\nfor i,j in enumerate(ax.flatten()):\n    \n    if int_cols[i] !='Sales':\n#         sns.boxplot(int_cols[i], 'Sales', data=data, ax=j)\n        sns.pointplot(int_cols[i], 'Sales', data=data, ax=j, n_boot=50)\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of sales are observed during Promo days, school holidays en of years and promo2 = 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, len(categorical_cols), figsize=(25,6))\n\nfor i,j in enumerate(ax.flatten()):\n    \n    if int_cols[i] !='Sales':\n#         sns.boxplot(categorical_cols[i], 'Sales', data=data, ax=j)\n        sns.pointplot(categorical_cols[i], 'Sales', data=data, ax=j, n_boot=100)\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"high variations in sales observed in these features."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, len(float_cols)//2, figsize=(25,12))\n\nfor i,j in enumerate(ax.flatten()):\n    \n#     sns.boxplot(float_cols[i], 'Sales', data=data_sub, ax=j)\n    sns.pointplot(float_cols[i], 'Sales', data=data, ax=j, n_boot=100)\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Usefull information could be extracted from these features."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(15,6))\ncols_to_plot = ['CompetitionDistance', 'Customers']\nfor i,j in enumerate(ax.flatten()):\n    \n    sns.regplot(cols_to_plot[i], 'Sales', data=data, ax=j, n_boot=100)\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Strong correlation between Sales and Customers, worth creating features about customers."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.heatmap(data .corr(), cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features ingineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.fillna(0, inplace=True)\n\ntest.fillna(1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining train and test data\n# Decomposing date features\n\ndata['part'] = 'train'\ntest['part'] = 'test'\nall_data = pd.concat([data, test], 0)[data.columns.tolist()+['Id']]\nall_data['Date'] = pd.to_datetime(all_data['Date'])\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year\nall_data['Day'] = all_data['Date'].dt.day\nall_data['WeekOfYear'] = data.Date.dt.weekofyear\nall_data['Quarter'] = data.Date.dt.quarter\nall_data.sort_values('Date', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"all_data['CompetitionOpen'] = 12 * (2015 - all_data.Year - all_data.CompetitionOpenSinceYear) + \\\n        (all_data.Month - all_data.CompetitionOpenSinceMonth)\nall_data['CompetitionOpen'] = all_data['CompetitionOpen'].apply(lambda x: x if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = all_data[all_data['part']=='train']\nsns.regplot('CompetitionOpen', 'Sales', data=tmp, ci=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"all_data['PromoOpen'] = 12 * (all_data.Year - all_data.Promo2SinceYear) + \\\n    (all_data.WeekOfYear - all_data.Promo2SinceWeek) / 4.0\nall_data['PromoOpen'] = all_data['PromoOpen'].apply(lambda x: x if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = all_data[all_data['part']=='train']\nsns.regplot('PromoOpen', 'Sales', data=tmp, ci=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \\\n         7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\nall_data['month_str'] = all_data.Month.map(month2str)\n\ndef check(row):\n    if isinstance(row['PromoInterval'],str) and row['month_str'] in row['PromoInterval']:\n        return 1\n    else:\n        return 0\n\nall_data['IsPromoMonth'] =  all_data.apply(lambda row: check(row),axis=1)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = all_data[all_data['part']=='train']\nsns.boxplot('IsPromoMonth', 'Sales', data=tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"all_data ['isBeforeCompetition'] = all_data.apply(lambda x: 1 if x['Year'] < x['CompetitionOpenSinceYear'] else 0, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = all_data[all_data['part']=='train']\nsns.boxplot('isBeforeCompetition', 'Sales', data=tmp)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57dfa508a9f9ca5ea1275ca444265d80d2da5357"},"cell_type":"markdown","source":"### Time Analysis"},{"metadata":{"trusted":true,"_uuid":"c1309f95189b21d88bdcc812410e87fd62c71728"},"cell_type":"code","source":"fig, ax = plt.subplots(5, 1, figsize=(15,10))\nfor p in range (5):\n    i = np.random.choice(data['Store'].unique())\n    data[data['Store']== i ].plot('Date', 'Sales', ax=ax[p])\n    ax[p] .set_title(\"Store %d\" %i)\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Several stores have missing data"},{"metadata":{"_uuid":"416446cd6c15621b735d9f913369a0c70b713550"},"cell_type":"markdown","source":"### Stores Performance"},{"metadata":{"trusted":true,"_uuid":"05ff56fe19c48c8383cc027577a2799112443525"},"cell_type":"code","source":"fig, ax = plt.subplots (1,5, figsize=(25,4))\nsns.boxplot('StoreType',  'Sales','Promo', data=data, ax=ax[0])\nsns.boxplot('StoreType', 'Sales', 'SchoolHoliday', data=data, ax=ax[1])\nsns.boxplot('StoreType','Sales','Assortment',  data=data, ax=ax[2])\nsns.boxplot('StoreType', 'Sales', 'StateHoliday', data=data, ax=ax[3])\nsns.boxplot('StoreType', 'Sales', 'Promo2', data=data, ax=ax[4])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfd371377e546757e6a84c9c8d613ae9a6dabf0b"},"cell_type":"markdown","source":"Small difference observeds by promo. \n\nStoreType b is somehow different / assortment b"},{"metadata":{"trusted":true,"_uuid":"8a65ff8ac35a56c80b12618cdfe603a3ceabd49e"},"cell_type":"code","source":"grid = sns.FacetGrid(data, col=\"StoreType\", row=\"Promo\", palette=\"tab10\", col_order=\"abcd\")\ngrid.map(sns.pointplot, \"Month\", \"Sales\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c59e13ea765c8423dce325d32bce61a9f771ced3"},"cell_type":"markdown","source":"StoreType b got the most total sales.\nHigher average sales when promo"},{"metadata":{"trusted":true,"_uuid":"1be47f2f61546f3cce7e51300e2e93e58d7451dc","scrolled":false},"cell_type":"code","source":"all_data['SalesPerCustomer'] = data['Sales']/data['Customers']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10a9821626385eb29520bc60787980adfb680c77"},"cell_type":"code","source":"grid = sns.FacetGrid(all_data, col=\"StoreType\", row=\"Promo\", palette=\"tab10\", col_order=\"abcd\")\ngrid.map(sns.pointplot, \"Month\", \"SalesPerCustomer\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00c3da3ab2aee74c2ff8530af19d3c8735dcf9f2"},"cell_type":"markdown","source":"But got less total sale per customer !"},{"metadata":{"trusted":true},"cell_type":"code","source":"mappings = {'0':0, 'a':1, 'b':2, 'c':3, 'd':4}\nall_data.StoreType.replace(mappings, inplace=True)\nall_data.Assortment.replace(mappings, inplace=True)\nall_data.StateHoliday.replace(mappings, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def prepareDf (df, submission=False):\n    \n    tests_date = \"2015-06-12\"\n    tmp_data = all_data[all_data['part']=='train'] .copy()\n    if not submission:\n        tmp_data = tmp_data[tmp_data['Date']<tests_date]\n        \n    shift = 48\n\n    cols = ['isBeforeCompetition', 'IsPromoMonth', 'PromoOpen', 'DayOfWeek', 'Promo', 'Promo2', 'Month', 'Year', 'Day', 'StateHoliday', 'Assortment', 'Quarter']\n\n    for i in ['Sales', 'Customers']:\n        for j in cols:\n            tmp = pd.pivot_table(tmp_data, i, ['Store', 'StoreType',j], aggfunc='mean').reset_index().rename(columns={i: i+'_StrType_'+j})\n            df = pd.merge(df, tmp, 'left', ['Store','StoreType', j])\n\n    cols = ['DayOfWeek', 'Promo', 'Promo2', 'Month', 'Year', 'Day', 'StateHoliday', 'StoreType', 'Assortment', 'PromoInterval', 'Quarter',\n           'isBeforeCompetition', 'IsPromoMonth', 'PromoOpen']\n\n\n    for i in ['Sales', 'Customers']:\n        for j in cols:\n            tmp = pd.pivot_table(tmp_data, i, ['Store', j], aggfunc='mean').reset_index().rename(columns={i: i+'_'+j})\n            df = pd.merge(df, tmp, 'left', ['Store', j])\n\n   \n\n    df['rolling_mean_t7_sales']  = df.groupby(['Store'])['Sales'].transform(lambda x:  x.shift(shift).rolling(7).mean())\n    df['rolling_mean_t30_sales'] = df.groupby(['Store'])['Sales'].transform(lambda x:  x.shift(shift).rolling(30).mean())\n    df['rolling_mean_t360_sales'] = df.groupby(['Store'])['Sales'].transform(lambda x:  x.shift(shift).rolling(360).mean())\n\n    df['rolling_mean_t7_customer']  = df.groupby(['Store'])['Customers'].transform(lambda x:  x.shift(shift).rolling(7).mean())\n    df['rolling_mean_t30_customer'] = df.groupby(['Store'])['Customers'].transform(lambda x:  x.shift(shift).rolling(30).mean())\n    df['rolling_mean_t360_customer'] = df.groupby(['Store'])['Customers'].transform(lambda x:  x.shift(shift).rolling(360).mean())\n\n    df['shift_sales']  = df.groupby(['Store'])['Sales'].transform(lambda x: x.shift(shift))\n    df['shift_t7_sales']  = df.groupby(['Store'])['Sales'].transform(lambda x: x.shift(shift+7))\n    df['shift_t30_sales'] = df.groupby(['Store'])['Sales'].transform(lambda x: x.shift(shift+30))\n    df['shift_t360_sales'] = df.groupby(['Store'])['Sales'].transform(lambda x: x.shift(shift+360))\n    \n    df['shift_customer']  = df.groupby(['Store'])['Customers'].transform(lambda x: x.shift(shift))\n    df['shift_t7_customer']  = df.groupby(['Store'])['Customers'].transform(lambda x: x.shift(shift+7))\n    df['shift_t30_customer'] = df.groupby(['Store'])['Customers'].transform(lambda x: x.shift(shift+30))\n    df['shift_t360_customer'] = df.groupby(['Store'])['Customers'].transform(lambda x: x.shift(shift+360))\n\n    cols = ['Quarter']\n\n    for i in ['Sales', 'Customers']:\n        for j in cols:\n            tmp = pd.pivot_table(tmp_data, i, ['Store', 'Year',j], aggfunc='mean').reset_index().rename(columns={i: i+'_Year_'+j})\n            df = pd.merge(df, tmp, 'left', ['Store','Year', j])\n\n   \n\n    cols = ['DayOfWeek', 'Promo', 'Promo2', 'Month', 'Year', 'Day', 'StateHoliday', 'Assortment']\n\n    for i in ['SalesPerCustomer']:\n        for j in cols:\n            tmp = pd.pivot_table(tmp_data, i, ['Store', 'StoreType',j], aggfunc='mean').reset_index().rename(columns={i: i+'_StrType_'+j})\n            df = pd.merge(df, tmp, 'left', ['Store','StoreType', j])\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = prepareDf(all_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Store']== 696 ].sort_values('Date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1309f95189b21d88bdcc812410e87fd62c71728"},"cell_type":"code","source":"fig, ax = plt.subplots(5, 1, figsize=(15,10))\nfor p in range (5):\n    i = np.random.choice(data['Store'].unique())\n    df[df['Store']== i ].plot('Date', 'Sales', ax=ax[p])\n    df[df['Store']== i ].plot('Date', 'shift_sales', ax=ax[p])\n    ax[p] .set_title(\"Store %d\" %i)\n    ax[p].legend(bbox_to_anchor=(1,.5))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1309f95189b21d88bdcc812410e87fd62c71728"},"cell_type":"code","source":"fig, ax = plt.subplots(5, 1, figsize=(15,10))\nfor p in range (5):\n    i = np.random.choice(data['Store'].unique())\n    df[df['Store']== i ].plot('Date', 'Sales', ax=ax[p])\n    df[df['Store']== i ].plot('Date', 'shift_t7_sales', ax=ax[p])\n    ax[p] .set_title(\"Store %d\" %i)\n    ax[p].legend(bbox_to_anchor=(1,.5))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1309f95189b21d88bdcc812410e87fd62c71728"},"cell_type":"code","source":"fig, ax = plt.subplots(5, 1, figsize=(15,10))\nfor p in range (5):\n    i = np.random.choice(data['Store'].unique())\n    df[df['Store']== i ].plot('Date', 'Sales', ax=ax[p])\n    df[df['Store']== i ].plot('Date', 'rolling_mean_t7_sales', ax=ax[p])\n    ax[p] .set_title(\"Store %d\" %i)\n    ax[p].legend(bbox_to_anchor=(1,.5))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1309f95189b21d88bdcc812410e87fd62c71728"},"cell_type":"code","source":"fig, ax = plt.subplots(5, 1, figsize=(15,10))\nfor p in range (5):\n    i = np.random.choice(data['Store'].unique())\n    df[df['Store']== i ].plot('Date', 'Customers', ax=ax[p])\n    df[df['Store']== i ].plot('Date', 'shift_t30_customer', ax=ax[p])\n    ax[p] .set_title(\"Store %d\" %i)\n    ax[p].legend(bbox_to_anchor=(1,.5))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1309f95189b21d88bdcc812410e87fd62c71728"},"cell_type":"code","source":"fig, ax = plt.subplots(5, 1, figsize=(15,10))\nfor p in range (5):\n    i = np.random.choice(data['Store'].unique())\n    df[df['Store']== i ].plot('Date', 'Customers', ax=ax[p])\n    df[df['Store']== i ].plot('Date', 'rolling_mean_t7_customer', ax=ax[p])\n    ax[p] .set_title(\"Store %d\" %i)\n    ax[p].legend(bbox_to_anchor=(1,.5))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9d555a9ef76866878c76f74cfea1cc97d21c74d"},"cell_type":"code","source":"plt.figure(figsize=(25,12))\nmask = np.zeros_like(df.corr())\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(df.corr(), cmap='coolwarm', vmax=1.0, vmin=-1.0 , mask = mask, linewidths=2.5)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"92a89adf07db9db4bd1578ae35b03d820057379f"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6473308c847ce29b223704d46d4791be8b0b7e62"},"cell_type":"markdown","source":"# Training models"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df[df['part']== 'train']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_train = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Promo','PromoOpen',\n#               'shift_sales','shift_t7_sales', 'shift_t30_sales','shift_customer','shift_t7_customer', 'shift_t30_customer',\n           'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n           'CompetitionDistance', 'Promo2', 'Month', 'Year', 'Day','IsPromoMonth',\n#            'Sales_DayOfWeek', 'Sales_Promo', 'Sales_Promo2', 'Sales_Month', 'Sales_Year', 'Sales_Day', 'Sales_StateHoliday', 'Sales_StoreType',\n#            'Sales_Assortment', 'Customers_DayOfWeek', #'isBeforeCompetition', 'Customers_Promo', 'Customers_Promo2', 'Customers_Month',\n#            'Customers_Year', 'Customers_Day', 'Customers_StateHoliday','Customers_StoreType', 'Customers_Assortment',\n#            'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear',\n           'Sales_StrType_DayOfWeek','SalesPerCustomer_StrType_Assortment', 'Customers_StrType_Promo2',\n           'Sales_StrType_Promo', 'Sales_StrType_Promo2', 'Sales_StrType_Month','Customers_StrType_StateHoliday',\n           'Sales_StrType_Year', 'Sales_StrType_Day', 'Sales_StrType_StateHoliday','SalesPerCustomer_StrType_Promo2',\n           'Sales_StrType_Assortment', 'Customers_StrType_DayOfWeek', 'Customers_StrType_Promo', \n           'Customers_StrType_Month', 'Customers_StrType_Year', 'Customers_StrType_Day', 'SalesPerCustomer_StrType_StateHoliday',\n           'Customers_StrType_Assortment', 'SalesPerCustomer_StrType_DayOfWeek', 'SalesPerCustomer_StrType_Promo', \n           'SalesPerCustomer_StrType_Month', 'SalesPerCustomer_StrType_Year', 'SalesPerCustomer_StrType_Day', \n#          'Sales_StrType_Quarter', 'Customers_StrType_Quarter', 'Sales_Year_Quarter','Customers_Year_Quarter',   'Customers_Quarter','Sales_Quarter',\n#            'Quarter'\n             ]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"objective\": \"reg:linear\", # for linear regression\n          \"booster\" : \"gbtree\",   # use tree based models \n          \"eta\": 0.02,   # learning rate\n          \"max_depth\": 11,    # maximum depth of a tree\n          \"subsample\": 0.9,    # Subsample ratio of the training instances\n          \"colsample_bytree\": 0.7,   # Subsample ratio of columns when constructing each tree\n          \"silent\": 1,   # silent mode\n          \"seed\": 10,   # Random number seed\n          'tree_method': 'gpu_hist',\n          }\nnum_boost_round = 800\n\n\ndef rmspe_xg(yhat, y):\n    y = np.expm1(y.get_label())\n    yhat = np.expm1(yhat)\n    return \"rmspe\", rmspe(y,yhat)\n\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Use only top Stores to train models"},{"metadata":{"trusted":true,"_uuid":"f5e13cc0244b90a6186bce4ae1c05e550b2f294d","scrolled":false},"cell_type":"code","source":"tmp= pd.pivot_table(data, ['Date'], \"Store\", aggfunc=\"count\").reset_index().sort_values('Date', ascending=False).head(300)\ntop_stores = tmp[\"Store\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2180ada246af23410021263d9d60ccfcf8df139d","scrolled":false},"cell_type":"code","source":"# from sklearn.manifold import TSNE\n# from sklearn.preprocessing import StandardScaler\n\n\ndef process(x, cols=None, all_stores=False):\n    x.sort_values(\"Date\",inplace=True)\n#     scaler = StandardScaler()\n    \n    if cols is None:\n        cols = x.columns\n        \n    x = x.fillna(x.median())\n       \n#     for i in x.columns[(x.dtypes.values == np.dtype('float64'))]:\n#         if i not in ['Id', 'Promo2SinceWeek', 'Promo2SinceYear','CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Sales',\n#                         'Quarter', 'WeekOfYear', 'PromoOpen', 'Promo2SinceWeek', 'Promo2SinceYear']:\n#             x[i] = np.round(np.log1p(x[i]),2)\n    \n    x_train = x[x[\"Date\"]<=\"2015-06-12\"][cols].copy()\n    x_test  = x[x[\"Date\"]>\"2015-06-12\"][cols].copy()\n\n    store_test = x_test['Store'].unique().tolist()\n    x_train = x_train[(x_train['Store'].isin(store_test))]\n    \n    y_train = np.log(x_train['Sales'])\n    \n    if all_stores:\n        rmv = ['Date', 'Sales']\n    else:\n        rmv = ['Date', 'Sales', 'Store']\n  \n    x_train= x_train.drop(rmv, 1)\n    x_train = pd.get_dummies(x_train)\n    x_train_arr = x_train.values\n    x_test_arr = pd.get_dummies(x_test.drop(rmv, 1)).values\n    \n    #scaler.fit(x_train_arr)\n    #x_train_arr = scaler.transform(x_train_arr)\n    #x_test_arr = scaler.transform(x_test_arr)\n    #reduc = TSNE(n_components=2)\n    #reduc.fit(x_train_arr)\n    #x_train_arr = reduc.transform(x_train_arr)\n    #x_test_arr = reduc.transform(x_test_arr)\n   \n    return x_train.columns, x_train_arr, y_train, x_test, x_test_arr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d99dcda05585df18fa203596d86c9f50a19d3e7d"},"cell_type":"markdown","source":"### Xgboost Model"},{"metadata":{"trusted":true,"_uuid":"74a079cf608eaa0ed5ad8984b7219a437726d3e0"},"cell_type":"code","source":"fig, ax = plt.subplots(5, 2, figsize=(25, 15))\n\nX = df_train[df_train['Store'].isin(top_stores)] .copy()\nX_train_col, X_train_arr, Y_train, X_test, X_test_arr = process(X, cols_train, True)\n\ndtrain = xgb.DMatrix(X_train_arr, Y_train)\nestimator = xgb.train(params, dtrain, num_boost_round, feval=rmspe_xg,)\nY_pred = estimator.predict(xgb.DMatrix(X_test_arr))\nX_test[\"Pred\"] = np.exp(Y_pred)\n\nscores = np.round(mean_squared_error(X_test['Sales'], X_test[\"Pred\"]))\ncpt = 0\n\nfor i in top_stores[:5]: \n    \n    x_train = df_train[df_train[\"Store\"]==i]\n    x_test = X_test[X_test[\"Store\"]==i]\n    ax[cpt, 0].plot(x_train[\"Date\"], x_train[\"Sales\"])\n    ax[cpt, 0].plot(x_test[\"Date\"], x_test[\"Pred\"])\n    ax[cpt, 0].set_title(i)\n\n    ax[cpt, 1].scatter(x_test[\"Date\"].values, x_test['Sales'].values - x_test[\"Pred\"].values)\n    ax[cpt, 1].plot(x_test[\"Date\"], [0 for _ in range(len(x_test))])\n    ax[cpt, 1].set_title( np.round(mean_squared_error(X_test['Sales'], X_test[\"Pred\"])))\n\n    #feat_importances = pd.Series(reg.feature_importances_, index=X_train_col)\n    #feat_importances.nlargest(10).sort_values(ascending = True).plot(kind='barh', ax=ax[cpt, 2])\n#     ax[cpt, 2].set_xlabel('importance')\n    cpt+=1\n    \n    \nplt.tight_layout()\nprint (np.mean(scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74a079cf608eaa0ed5ad8984b7219a437726d3e0","scrolled":false},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\n\nfig, ax = plt.subplots(5, 2, figsize=(25, 15))\ncpt = 0\nresult = pd.Series()\nscores= []\ncpt_store=0\nfor i in top_stores[:5] : \n    X = data[data['Store']== i].sort_values('Date').copy()\n    print(adfuller(X['Sales'])[1])\n    if cpt<5:\n        fig = sm.graphics.tsa.plot_acf(X['Sales'].diff().dropna(), lags=40, ax=ax[cpt,0] )\n        fig = sm.graphics.tsa.plot_pacf(X['Sales'].diff().dropna(), lags=40, ax=ax[cpt ,1])\n        \n        cpt+=1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74a079cf608eaa0ed5ad8984b7219a437726d3e0"},"cell_type":"code","source":"fig, ax = plt.subplots(5, 2, figsize=(25, 15))\ncpt = 0\nfor i in top_stores[:5] : \n    X = data[data['Store']==i] .sort_values('Date').copy()\n    \n    X_train = X[X[\"Date\"]<\"2015-06-12\"][['Date', 'Sales']].copy()\n    X_train.index = X_train.Date\n    X_train= np.log(X_train[[ 'Sales']])\n    X_test  = X[X[\"Date\"]>=\"2015-06-12\"].copy()\n\n    reg = sm.tsa.statespace.SARIMAX(X_train,order=(7,1,5),seasonal_order=(2,1,1,7),trend='c',enforce_invertibility=False)\n    res = reg.fit()\n    \n    #Y_pred = res.predict(start=\"2015-01-01\", end=\"2015-07-31\", dynamic=True)\n    Y_pred = res.forecast(len(X_test)).values\n    X_test[\"Pred\"] = np.exp(Y_pred)\n    \n    score = np.round(mean_squared_error(X_test[ 'Sales'], X_test[\"Pred\"]))\n    data[data[\"Store\"]==i].plot(\"Date\",  'Sales', ax=ax[cpt, 0])\n    ax[cpt, 0].plot(X_test[\"Date\"], X_test[\"Pred\"], label='Predictions')\n    ax[cpt, 0].set_title(i)\n\n    res.resid.plot(ax=ax[cpt, 1] )\n#     fig = sm.graphics.tsa.plot_acf(res.resid, lags=40, ax=ax[2])\n#     fig = sm.graphics.tsa.plot_pacf(res.resid, lags=40, ax=ax[3])\n    cpt+=1\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfcfc2d5ee155ecf8a1d9f93ed52251add63e96e"},"cell_type":"markdown","source":"# Training for submissions"},{"metadata":{"trusted":true,"_uuid":"39d042c4256b6d82e0656399421ad4ba3d35f66e"},"cell_type":"code","source":"num_boost_round = 500\n\nparams = {\"objective\": \"reg:linear\", # for linear regression\n          \"booster\" : \"gbtree\",   # use tree based models \n          \"eta\": 0.03,   # learning rate\n          \"max_depth\": 10,    # maximum depth of a tree\n          \"subsample\": 0.9,    # Subsample ratio of the training instances\n          \"colsample_bytree\": 0.7,   # Subsample ratio of columns when constructing each tree\n          \"silent\": 1,   # silent mode\n          \"seed\": 10,   # Random number seed\n          'tree_method': 'gpu_hist',\n          }\n\n\ntmp = prepareDf(all_data, True)\ntmp = tmp.fillna(tmp.dropna().median())\n \n\n# for i in tmp.columns[(tmp.dtypes.values == np.dtype('float64'))]:\n#     if i not in ['Id', 'Promo2SinceWeek', 'Promo2SinceYear', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear',\n#                 'Sales', 'Quarter', 'WeekOfYear', 'PromoOpen', 'Promo2SinceWeek', 'Promo2SinceYear']:\n#         tmp[i] = np.log1p(tmp[i])\n\ntest = tmp[tmp['part']=='test'].sort_values('Id')\ndf_train = tmp[tmp['part']=='train']\n\nresult = pd.Series()\n\nX_train = df_train\nX_train= X_train[cols_train]\nX_test  = test\n\nstore_test = X_test['Store'].unique().tolist()\nX_train = X_train[(X_train['Store'].isin(store_test))]\n\nstore_ind = X_test[\"Id\"]\nY_train = np.log(X_train[\"Sales\"])\n\nX_train = pd.get_dummies(X_train.drop(['Date', 'Sales'], 1)).values\nX_test = pd.get_dummies(X_test[cols_train]).drop(['Date', 'Sales'], 1).values# .drop(['Date'], 1)).values\n\ndtrain = xgb.DMatrix(X_train, Y_train)\nestimator = xgb.train(params, dtrain, num_boost_round, feval=rmspe_xg,)\nY_pred = np.exp(estimator.predict(xgb.DMatrix(X_test)))\nresult = result.append(pd.Series(Y_pred, index=store_ind))\nresults = pd.DataFrame({ \"Id\": result.index, \"Sales\": result.values})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5829cb5724306995064e0fdb6f9cfc8462f8c83","scrolled":false},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv')\ndf_test = pd.merge(df_test, stores, 'left', 'Store')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4df874474659103808c58a43a6c49fff87c9d45a","trusted":true,"scrolled":false},"cell_type":"code","source":"merged_test = pd.merge(df_test, results, 'left', ['Id']) \nmerged_test.loc[ merged_test.Open == 0, 'Sales' ] = 0 \nsub = merged_test[['Id', 'Sales']].copy() \n\nsub['Sales'] = sub['Sales'].fillna(0) \nsub.to_csv('submission.csv', index=False) \n\nsub.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}