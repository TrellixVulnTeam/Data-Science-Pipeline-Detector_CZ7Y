{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"store=pd.read_csv('/kaggle/input/rossmann-store-sales/store.csv')\ndata=pd.read_csv('/kaggle/input/rossmann-store-sales/train.csv')\ntest=pd.read_csv('/kaggle/input/rossmann-store-sales/test.csv')\nsubmission=pd.read_csv('/kaggle/input/rossmann-store-sales/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\nprint(store.shape)\nprint(test.shape)\nprint(submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes  # date and stateholidays as categorical columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets dive into the statistical description of data\ndata.describe(include='object')  # we have 942 similar dates and 5 similar etries in state holidays","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we have sales and customer column in which we have to focus more on the customer segment as this will also be one of the major factor affecting the sales \n\ndata.describe()[['Sales','Customers']].loc['max']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()[['Sales','Customers']].loc['mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Store.nunique()\n\ndata.Store.value_counts().head(20).plot.bar()\ndata.Store.value_counts().tail(20).value_counts()\n\ndata.Store.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check for the store to be open\ndata.Open.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#record of dayof week for the store\ndata.DayOfWeek.value_counts()\n\n#record for the store\ndata.groupby(['DayOfWeek'])[['Sales']].mean()  # the first day of the week ,the sales is higher","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the null values\ndata.isnull().sum()\nstore.isnull().sum()   # the store data has more null values so for furthur imputations we have to fill it \ntest.isnull().sum()   # there is some missing values in test data too","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert datetime column to date\ndata['Date']=pd.to_datetime(data['Date'],format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets take one store and make visualisations to  se the pattern \nstore_id=data.Store.unique()[0]\nprint(store_id)\n\nstore_rows=data[data['Store']==store_id]\nstore_rows.resample('1D',on='Date')['Sales'].sum().plot.line(figsize=(10,8))\n\n#plotting the 1day sales for the selected store_id over past 2 years before 2015","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#carry on our analysis over the picked store\n\nstore_rows[store_rows['Sales']==0]  # showing the analysis of no sales for the store 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date']=pd.to_datetime(test['Date'],format='%Y-%m-%d')\nstore_test_rows=test[test['Store']==store_id]\nstore_test_rows['Date'].min(),store_test_rows['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_test_rows['Open'].value_counts() # the shop will be closed(7days )means the sales will be zero for the given days \n                                       #lets proceed ahead to the exploration for predictig the sales for the dates on test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_rows['Sales'].plot.hist()\n\n#it is slightly skewed  in target column means there are certain rows where slaes data is missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()\nstore[store['Store']==store_id].T  # we dont know what value imputaion we can do to fill the missinng values so we are takinng a single store and anlaysing the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[~store['Promo2SinceYear'].isna()].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[~store['Promo2SinceYear'].isna()].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing value treatment\nstore.isna().sum()\n# its obvious technically to say that the week that have zero promos so we can fill it with zero\nstore['Promo2SinceWeek']=store['Promo2SinceWeek'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store['Promo2SinceYear']=store['Promo2SinceYear'].fillna(store['Promo2SinceYear'].mode().iloc[0])\n#technically its wrong to say promos missed for 2 years but for current scenrio we can fill it with mode\n\nstore['PromoInterval']=store['PromoInterval'].fillna(store['PromoInterval'].mode().iloc[0])\n\n#its obvious that there is no competitor\nstore['CompetitionDistance']=store['CompetitionDistance'].fillna(0)\nstore['CompetitionOpenSinceMonth']=store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode().iloc[0])\nstore['CompetitionOpenSinceYear']=store['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode().iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store['Promo2SinceYear'].mode()\ndata_merged=data.merge(store,on='Store',how='left')\nprint(data.shape)\nprint(data_merged.shape)\n#just have a  look over the missing value after merging the data over store data/sometimes there is missing value after the merge\nprint(data_merged.isna().sum().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets do the  decision tree regresssion  \n\n#Encoding\n#3 cat_cols,1date_col,rest are numerical\ndata_merged.dtypes\n\ndata_merged['day']=data_merged['Date'].dt.day\ndata_merged['month']=data_merged['Date'].dt.month\ndata_merged['year']=data_merged['Date'].dt.year\n\n# will give the day of week extracion\n# data_merged['dayofweek']=data_merged['Date'].dt.strftime('%A')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged.dtypes\n#stateholiday,assortment,promointerval,storetype-cat_cols\ndata_merged['StateHoliday'].unique()\n\ndata_merged['StateHoliday']=data_merged['StateHoliday'].map({'0':0,0:0,'a':1,'b':2,'c':3})\ndata_merged['StateHoliday']=data_merged['StateHoliday'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the assortment columns for missing value imputation\ndata_merged['Assortment'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data_merged.dtypes\n#stateholiday,assortment,promointerval,storetype-cat_cols\ndata_merged['Assortment'].unique()\n\ndata_merged['Assortment']=data_merged['Assortment'].map({'a':1,'b':2,'c':3})\ndata_merged['Assortment']=data_merged['Assortment'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['StoreType']=data_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ndata_merged['StoreType']=data_merged['StoreType'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_promo={'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ndata_merged['PromoInterval']=data_merged['PromoInterval'].map(map_promo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trainn and test validate\n\nfeatures=data_merged.columns.drop(['Sales','Date'])\nfrom sklearn.model_selection import train_test_split\ntrain_x,validate_x,train_y,validate_y=train_test_split(data_merged[features],np.log(data_merged['Sales']+1),test_size=0.2,random_state=1)\n\ntrain_x.shape,validate_x.shape,train_y.shape,validate_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply decision tree regressor\n\nfrom sklearn.tree import DecisionTreeRegressor\n    \nmodel_dt=DecisionTreeRegressor(max_depth=11,random_state=1).fit(train_x,train_y)\nvalidate_y_pred=model_dt.predict(validate_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validate_y_pred=model_dt.predict(validate_x)\n\nfrom sklearn.metrics import mean_squared_error\n\ndef ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1./(y[ind]**2)\n    return w\n\ndef rmspe(y, yhat):\n    w = ToWeight(y)\n    rmspe= np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe\n\nvalidate_y_inv=np.exp(validate_y)-1\nvalidate_y_pred_inv=np.exp(validate_y_pred)-1\n\nrmse_val=np.sqrt(mean_squared_error(validate_y_inv,validate_y_pred_inv))\nrmspe_val=rmspe(validate_y_inv,validate_y_pred_inv)\nprint(rmse_val,rmspe_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n\n# parameters={'max_depth':list(range(5,20))}   # parmeters{'max_depth':list(range(5,20),'min_sample_split':[5,10,20])}\n# base_model=DecisionTreeRegressor()\n# cv_model=GridSearchCV(base_model,param_grid=parameters,cv=5,return_train_score=True).fit(train_x,train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_cv_results=pd.DataFrame(cv_model.cv_results_).sort_values(by='mean_test_score',ascending=False)[['param_max_depth','mean_test_score','mean_train_score']]\n# plt.figure(figsize=(10,5))\n# df_cv_results.set_index('param_max_depth')['mean_test_score'].plot.line()\n# df_cv_results.set_index('param_max_depth')['mean_train_score'].plot.line()\n# print(df_cv_results)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(model_dt.feature_importances_,index=features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the most important feature for test data from the merged data\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\nyvalues=model_dt.feature_importances_\nxvalues=features\nplt.bar(xvalues,yvalues)\nplt.xticks(rotation=90,color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to check the importance of each column over the merged data on sales (target variable)\ndata_merged.corr().loc['Sales'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we rae finding the average number of customers as it will help in addition of customers  column in test data will help in prediction of customers\nstore_avg_cust=data.groupby(['Store'])[['Customers']].mean().reset_index().astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1=test.merge(store_avg_cust,on='Store',how='left')\n\ntest1.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_merged=test1.merge(store,on='Store',how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_merged['Open']=test_merged['Open'].fillna(1)\ntest_merged['Date']=pd.to_datetime(test_merged['Date'],format='%Y-%m-%d')\ntest_merged['day']=test_merged['Date'].dt.day\ntest_merged['month']=test_merged['Date'].dt.month\ntest_merged['year']=test_merged['Date'].dt.year\n\n\ntest_merged['StateHoliday']=test_merged['StateHoliday'].map({'0':0,'a':1})\ntest_merged['StateHoliday']=test_merged['StateHoliday'].astype(int)\ntest_merged.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_merged['Assortment']=test_merged['Assortment'].map({'a':1,'b':2,'c':3})\ntest_merged['Assortment']=test_merged['Assortment'].astype(int)\ntest_merged['StoreType']=test_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ntest_merged['StoreType']=test_merged['StoreType'].astype(int)\nmap_promo={'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ntest_merged['PromoInterval']=test_merged['PromoInterval'].map(map_promo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred=model_dt.predict(test_merged[features])\ntest_pred_inv=np.exp(test_pred)-1\n\n\nsubmission_predicted=pd.DataFrame({'Id':test['Id'],'Sales':test_pred_inv})\nsubmission_predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_predicted.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1./(y[ind]**2)\n    return w\n\ndef rmspe(y, yhat):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe\nvalidate_y_inv=np.exp(validate_y)-1\nvalidate_y_pred_inv=np.exp(validate_y_pred)-1\n\nrmse_val=np.sqrt(mean_squared_error(validate_y_inv,validate_y_pred_inv))\nrmspe_val=rmspe(validate_y_inv,validate_y_pred_inv)\nprint(rmse_val,rmspe_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import GridSearchCV\ndef get_rmspe_score(model,input_values,y_actual):\n    y_predicted=model.predict(input_values)\n    \n    Y_actual=np.exp(y_actual)-1\n    y_predicted=np.exp(y_predicted)-1\n    score=rmspe(y_actual,y_predicted)\n    return score\nparameter={'max_depth':list(range(5,8))}\nbase_model=DecisionTreeRegressor()\ncv_model=GridSearchCV(base_model,param_grid=parameter,cv=5,return_train_score=True,scoring=get_rmspe_score).fit(train_x,train_y)\npd.DataFrame(cv_model.cv_results_)[['params','mean_test_score','mean_train_score']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}