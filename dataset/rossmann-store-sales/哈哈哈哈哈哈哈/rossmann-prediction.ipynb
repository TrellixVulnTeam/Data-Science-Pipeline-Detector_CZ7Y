{"cells":[{"metadata":{"_uuid":"d12b96cd0fae9c59e1cfddba6c743d80638c8f70","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\ntrain_df = pd.read_csv(\"../input/train.csv\", parse_dates=[2])\ntrain_df.describe()\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"4c98986d48b3e24ae1d54f072cf8d6d55f24c146","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"def load_raw_df():\n    train_df = pd.read_csv(\"../input/train.csv\", parse_dates=[2])\n    store_df = pd.read_csv(\"../input/store.csv\")\n    test_df = pd.read_csv(\"../input/test.csv\", parse_dates=[3])\n    train_df.head()\n    store_df.head()\n    test_df.head()\n    display(train_df.isnull().sum(),store_df.isnull().sum(),test_df.isnull().sum())\n    mereged_train_df = pd.merge(train_df, store_df, on='Store')\n    merged_test_df = pd.merge(test_df, store_df, on='Store')\n    return mereged_train_df, merged_test_df\n\ndef extract_linear_feature(df):\n    df.drop(\"Customers\", 1)\n    mappings = {'0': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4}\n    df[\"StoreType\"] = df[\"StoreType\"].map(mappings)\n    df[\"Assortment\"] = df[\"Assortment\"].map(mappings)\n    df[\"StateHoliday\"].loc[df[\"StateHoliday\"] == 0] = \"0\"\n    df[\"StateHoliday\"] = df[\"StateHoliday\"].map(mappings)\n    df[\"CompetitionDistance\"].fillna(df[\"CompetitionDistance\"].median())\n    # merege_train_df['WeekOfYear'] = merege_train_df.Date.dt.weekofyear\n#     df['store_a'] = df['StoreType'] == 3\n    df[\"year\"] = df.Date.dt.year\n    df[\"month\"] = df.Date.dt.month\n    df[\"day\"] = df.Date.dt.day\n    df[\"year\"] = df.Date.dt.year\n    df[\"month\"] = df.Date.dt.month\n    df[\"day\"] = df.Date.dt.day\n    \n    df.drop([\"Date\", \"PromoInterval\", \"Promo2SinceWeek\", \"Promo2SinceYear\"], axis=1, inplace=True)\n    return df\n\n# return x_train, y_train, x_test\ndef get_train_test_label():\n    train_df, test_df = load_raw_df()\n    train_df_2 = extract_linear_feature(train_df)\n    train_df_2.head()\n    y_true = train_df_2.loc[:, 'Sales'].as_matrix(columns=None)\n    train_df_2.drop(\"Sales\", axis =1)\n\n    test_df[\"Customers\"] = 1\n    test_df = extract_linear_feature(test_df)\n    test_df.head()\n    feature_list = list(train_df_2.columns)\n    print(feature_list)\n    return train_df_2,y_true,test_df\n\nx_train, y_train, x_test = get_train_test_label()\n# features = ['Store', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'year', 'month', 'day']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8b64aa821503ac8efaa65bfdb82794bc236dbb4","collapsed":true},"cell_type":"code","source":"\n# from sklearn.linear_model import LinearRegression\n# x_train.fillna(0)\n# # x_train = x_train[x_train[\"Open\"] != 0]\n# x_test.fillna(0)\n# features = ['Store', 'DayOfWeek', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'year', 'month', 'day']\n# features = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment','Promo2', 'year', 'month', 'day']\n\n# lm_reg = LinearRegression()\n# lm_reg.fit(x_train[features].values, list(y_train))\n# x_test_closed = x_test[\"Id\"][x_test[\"Open\"] == 0].values\n# x_test = x_test[x_test[\"Open\"] != 0]\n\n# y_test_pred = lm_reg.predict(x_test[features])\n# print(y_test_pred[:10])\n\n# result = pd.Series()\n# result = result.append(pd.Series(y_test_pred, index=x_test[\"Id\"]))\n# result = result.append(pd.Series(0, index=x_test_closed))\n# result = pd.DataFrame({ \"Id\": result.index, \"Sales\": result.values})\n# result.to_csv('result_new.csv', index=False)\n\n# print(os.listdir(\".\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9807a66deeaa3ac338522e96018236a2f7c8af9d","collapsed":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.cross_validation import train_test_split\ntrain_df = pd.read_csv(\"../input/train.csv\", parse_dates=[2])\nstore_df = pd.read_csv(\"../input/store.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\", parse_dates=[3])\nfeatures = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment','Promo2', 'WeekOfYear','year', 'month', 'day']\ndef extract_feature(df):\n#     df.drop(\"Customers\", 1)\n    mappings = {'0': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4}\n    df[\"StoreType\"] = df[\"StoreType\"].map(mappings)\n    df[\"Assortment\"] = df[\"Assortment\"].map(mappings)\n    df[\"StateHoliday\"].loc[df[\"StateHoliday\"] == 0] = \"0\"\n    df[\"StateHoliday\"] = df[\"StateHoliday\"].map(mappings)\n    df[\"CompetitionDistance\"].fillna(df[\"CompetitionDistance\"].median())\n    df['WeekOfYear'] = df.Date.dt.weekofyear\n    df[\"year\"] = df.Date.dt.year\n    df[\"month\"] = df.Date.dt.month\n    df[\"day\"] = df.Date.dt.day\n#     df.drop([\"Date\", \"PromoInterval\", \"Promo2SinceWeek\", \"Promo2SinceYear\"], axis=1, inplace=True)\n    return df\n\ntrain_df = pd.merge(train_df, store_df, on='Store')\ntest_df = pd.merge(test_df, store_df, on='Store')\ntrain_df = extract_feature(train_df)\ntest_df = extract_feature(test_df)\ntrain_df = train_df[train_df[\"Open\"] != 0]\n\ntrain, valid = train_test_split(train_df, test_size=0.03)\ny_train = np.log1p(train.Sales)\ny_valid = np.log1p(valid.Sales)\ndtrain = xgb.DMatrix(train[features], y_train)\ndvalid = xgb.DMatrix(valid[features], y_valid)\n\nwatchlist = [(dtrain, 'train'), (dvalid, 'eval')]\ndef rmspe(y, yhat):\n    return np.sqrt(np.mean(((y - yhat)/y) ** 2))\n\ndef rmspe_xg(yhat, y):\n    y = np.expm1(y.get_label())\n    yhat = np.expm1(yhat)\n    return \"rmspe\", rmspe(y, yhat)\nparams = {\"objective\": \"reg:linear\",\n          \"booster\" : \"gbtree\",\n          \"eta\": 0.1,\n          \"max_depth\": 10,\n          \"subsample\": 0.85,\n          \"colsample_bytree\": 0.4,\n          \"min_child_weight\": 6,\n          \"thread\": 1,\n          \"seed\": 10\n          }\nnum_boost_round = 1000\ngbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=1000, \\\n  feval=rmspe_xg, verbose_eval=True)\n\nprint(\"Validating\")\nyhat = gbm.predict(xgb.DMatrix(valid[features]))\nerror = rmspe(valid.Sales.values, np.expm1(yhat))\nprint('RMSPE: {:.6f}'.format(error))\n\nprint(\"Make predictions on the test set\")\ndtest = xgb.DMatrix(test_df[features])\ntest_probs = gbm.predict(dtest)\nprint(test_probs[:5])\n# Make Submission\nresult = pd.DataFrame({\"Id\": test_df[\"Id\"], 'Sales': np.expm1(test_probs)})\nresult.to_csv(\"xgb_v2.csv\", index=False)\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}