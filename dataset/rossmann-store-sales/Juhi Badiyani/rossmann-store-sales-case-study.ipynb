{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/rossmann-store-sales/train.csv')\nstore=pd.read_csv('/kaggle/input/rossmann-store-sales/store.csv')\ntest= pd.read_csv('/kaggle/input/rossmann-store-sales/test.csv')\nprint(data.shape)\nprint(store.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n* Train Data : Input and target variable is present\n\n* Test Data: Input is present but there is no target variable here"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#categorical columns\ndata.describe(include='object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#numeric columns\ndata.describe(exclude='object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()[['Sales','Customers']].loc['mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()[['Sales','Customers']].loc['max']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.Store.nunique())\ndata.Store.value_counts().head(50).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Store.value_counts().tail(50).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Store.value_counts() # Store is treated as categorical column although its numeric\n#Hence we cannot compute mean,min,max,etc... for such categorical columns.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.DayOfWeek.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Open.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Promo.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Date']=pd.to_datetime(data['Date'],format='%Y-%m-%d')\nstore_id=data.Store.unique()[0]  #taking 1st unique storeid and storing in a variable\nprint(store_id)\nstore_rows=data[data['Store']==store_id] #if store_id we got above is present in Store table\nprint(store_rows.shape)\nstore_rows.resample('1D',on='Date')['Sales'].sum().plot.line(figsize=(14,4))\n#ID means 1Day, this shows data day-wise for all the data where store_id[0] which is 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_rows[store_rows['Sales']==0] #checking storeod of all sales==0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date']=pd.to_datetime(test['Date'],format='%Y-%m-%d')\nstore_test_rows=test[test['Store']==store_id]\nstore_test_rows['Date'].min(),store_test_rows['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_test_rows['Open'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_rows['Sales'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[store['Store']==store_id].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[~store['Promo2SinceYear'].isna()].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling missing values\nstore['Promo2SinceWeek']=store['Promo2SinceWeek'].fillna(0)\nstore['Promo2SinceYear']=store['Promo2SinceYear'].fillna(store['Promo2SinceYear'].mode().iloc[0])\nstore['PromoInterval']=store['PromoInterval'].fillna(store['PromoInterval'].mode().iloc[0])\nstore['CompetitionDistance']=store['CompetitionDistance'].fillna(store['CompetitionDistance'].max())\nstore['CompetitionOpenSinceMonth']=store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode().iloc[0])\nstore['CompetitionOpenSinceYear']=store['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode().iloc[0])\nstore.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store['Promo2SinceYear'].mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged=data.merge(store,on='Store',how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\nprint(data_merged.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged.isna().sum().sum() #cross checking if there are any missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding\n#3 categorical column -- StateHoliday,StoreType,Assortment,PromoInterval\n#1 date column\n#rest are numerical\ndata_merged.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['day']=data_merged['Date'].dt.day\ndata_merged['month']=data_merged['Date'].dt.month\ndata_merged['year']=data_merged['Date'].dt.year\ndata_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for all categorical columns one by one\ndata_merged['StateHoliday'].unique()\ndata_merged['StateHoliday']=data_merged['StateHoliday'].map({'0':0,0:0,'a':1,'b':2,'c':3})\ndata_merged['StateHoliday']=data_merged['StateHoliday'].astype(float).astype(int)\ndata_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['Assortment'].unique()\ndata_merged['Assortment']=data_merged['Assortment'].map({'0':0,0:0,'a':1,'b':2,'c':3,'d':4})\ndata_merged['Assortment']=data_merged['Assortment'].astype(int)\ndata_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['StoreType'].unique()\ndata_merged['StoreType']=data_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ndata_merged['StoreType']=data_merged['StoreType'].astype(int)\ndata_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged['PromoInterval'].unique()\nmap_promo = {'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ndata_merged['PromoInterval']=data_merged['PromoInterval'].map(map_promo)\ndata_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train and validate Split\nfeatures= data_merged.columns.drop(['Sales','Date'])\nfrom sklearn.model_selection import train_test_split\ntrain_x,validate_x,train_y,validate_y = train_test_split(data_merged[features],np.log(data_merged['Sales']+1),test_size=0.2,random_state=1)\ntrain_x.shape,validate_x.shape,train_y.shape,validate_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nmodel_dt=DecisionTreeRegressor(max_depth=10,random_state=1).fit(train_x,train_y)\nvalidate_y_pred=model_dt.predict(validate_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_tree(model, columns):\n    import pydotplus\n    from sklearn.externals.six import StringIO\n    from IPython.display import Image\n    import os\n    from sklearn import tree\n    \n    graphviz_path = 'C:\\Program Files (x86)\\Graphviz2.38/bin/'\n    os.environ[\"PATH\"] += os.pathsep + graphviz_path\n\n    dot_data = StringIO()\n    tree.export_graphviz(model,\n                         out_file=dot_data,\n                         feature_names=columns)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n    return Image(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_tree(model_dt,features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(np.log(data_merged['Sales']+1)).plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validate_y_pred = model_dt.predict(validate_x)\nfrom sklearn.metrics import mean_squared_error\nvalidate_y_inv=np.exp(validate_y)-1 #becaused we added +1 while log transformation\nvalidate_y_pred_inv=np.exp(validate_y_pred)-1\nnp.sqrt(mean_squared_error(validate_y_inv,validate_y_pred_inv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dt.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\nplt.bar(features,model_dt.feature_importances_)\npd.Series(model_dt.feature_importances_,index=features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV\n\nparameters={'max_depth':list(range(5,20))}\nbase_model=DecisionTreeRegressor()\ncv_model=GridSearchCV(base_model,param_grid=parameters,cv=5,return_train_score=True).fit(train_x,train_y)\nparameters\n#by default cv=2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(cv_model.cv_results_).sort_values(by='mean_test_score',ascending=False) #[['param_max_depth','mean_test_score']]\n#differnt types tried with different max depth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cv_results=pd.DataFrame(cv_model.cv_results_).sort_values(by='mean_test_score',ascending=False)\nimport matplotlib.pyplot as plt\ndf_cv_results.set_index('param_max_depth')['mean_test_score'].plot.line()\ndf_cv_results.set_index('param_max_depth')['mean_train_score'].plot.line()\nplt.legend(['Test Scores','Train Scores'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stores_avg_cust = data.groupby(['Store'])[['Customers']].mean().reset_index().astype(int)\ntest_1 = test.merge(stores_avg_cust,on='Store',how='left')\ntest.shape,test_1.shape\ntest_merged = test_1.merge(store,on='Store',how='inner')\ntest_merged['Open']=test_merged['Open'].fillna(1)\ntest_merged['Date']=pd.to_datetime(test_merged[\"Date\"],format='%Y-%m-%d')\ntest_merged['day']=test_merged['Date'].dt.day\ntest_merged['month']=test_merged['Date'].dt.month\ntest_merged['year']=test_merged['Date'].dt.year\ntest_merged['StateHoliday']=test_merged['StateHoliday'].map({'0':0,'a':1})\ntest_merged['StateHoliday']=test_merged['StateHoliday'].astype(int)\ntest_merged['Assortment']=test_merged['Assortment'].map({'a':1,'b':2,'c':3})\ntest_merged['Assortment']=test_merged['Assortment'].astype(int)\ntest_merged['StoreType']=test_merged['StoreType'].map({'a':1,'b':2,'c':3,'d':4})\ntest_merged['StoreType']=test_merged['StoreType'].astype(int)\nmap_promo = {'Jan,Apr,Jul,Oct':1,'Feb,May,Aug,Nov':2,'Mar,Jun,Sept,Dec':3}\ntest_merged['PromoInterval']=test_merged['PromoInterval'].map(map_promo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred=model_dt.predict(test_merged[features])\ntest_pred_inv=np.exp(test_pred)-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_predicted=pd.DataFrame({'Id':test['Id'],'Sales':test_pred_inv})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_predicted.to_csv('submission.csv',index=False)\nsubmission_predicted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to calculate RMSPE(Root Mean Square Percentage Error)\ndef ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1./(y[ind]**2)\n    return w\n\ndef rmspe(y, yhat):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe\n\nvalidate_y_inv=np.exp(validate_y)-1 #becaused we added +1 while log transformation\nvalidate_y_pred_inv=np.exp(validate_y_pred)-1\nrmse_val=np.sqrt(mean_squared_error(validate_y_inv,validate_y_pred_inv))\nrmspe_val=rmspe(validate_y_inv,validate_y_pred_inv)\nprint(rmse_val,rmspe_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}