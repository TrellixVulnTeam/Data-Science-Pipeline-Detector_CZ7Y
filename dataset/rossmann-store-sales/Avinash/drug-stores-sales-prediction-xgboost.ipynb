{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem Statement\n\nRossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. \n\n\nWith thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. \n\n<b>Note</b>: Some stores in the dataset were temporarily closed for refurbishment.\n\nView and download the data here: https://www.kaggle.com/c/rossmann-store-sales/data\n\n<b> Files</b><br>\ntrain.csv - historical data including Sales<br>\ntest.csv - historical data excluding Sales<br>\nsample_submission.csv - a sample submission file in the correct format<br>\nstore.csv - supplemental information about the stores<br>\n\n<b>Data fields</b>\nMost of the fields are self-explanatory. The following are descriptions for those that aren't.<br>\n\nId - an Id that represents a (Store, Date) duple within the test set<br>\nStore - a unique Id for each store<br>\nSales - the turnover for any given day (this is what you are predicting)<br>\nCustomers - the number of customers on a given day<br>\nOpen - an indicator for whether the store was open: 0 = closed, 1 = open<br>\nStateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None<br>\nSchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools<br>\nStoreType - differentiates between 4 different store models: a, b, c, d<br>\nAssortment - describes an assortment level: a = basic, b = extra, c = extended<br>\nCompetitionDistance - distance in meters to the nearest competitor store<br>\nCompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened<br>\nPromo - indicates whether a store is running a promo on that day<br>\nPromo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating<br>\nPromo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2<br>\nPromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nfrom xgboost import plot_tree\nfrom matplotlib.pylab import rcParams\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport joblib","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Configurations","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_columns',120)\npd.set_option('display.max_rows',120)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Datasets","metadata":{}},{"cell_type":"code","source":"ross_df = pd.read_csv('../input/rossmann-store-sales/train.csv', low_memory=False)\nstore_df = pd.read_csv('../input/rossmann-store-sales/store.csv')\ntest_df = pd.read_csv('../input/rossmann-store-sales/test.csv')\nsubmission_df = pd.read_csv('../input/rossmann-store-sales/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ross_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Note :</b>\nCustomers column is present in train set(ross_df) but not in test set.<br>\nSales column is the target column.","metadata":{}},{"cell_type":"code","source":"submission_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since store_df contains additional information about the stores, let's merge store_df to the ross_df and test_df.<br>\n`Left Outer Join` on the column name `Store`.","metadata":{}},{"cell_type":"code","source":"merged_df = ross_df.merge(store_df, how='left', on='Store')\nmerged_test_df = test_df.merge(store_df, how='left', on='Store')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing And Feature Engineering","metadata":{}},{"cell_type":"code","source":"merged_df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_date(data):\n    data['Date'] = pd.to_datetime(data['Date'])\n    data['Year'] = data.Date.dt.year\n    data['Month'] = data.Date.dt.month\n    data['Day'] = data.Date.dt.day\n    data['WeekOfYear'] = data.Date.dt.isocalendar().week\n    #data.drop('Date', axis=1, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_date(merged_df)\nextract_date(merged_test_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Note</b> : Date column in training set is the past (2013 - 2015) and that in the test set is the future(2015).<br>\nLet's first extract different parts of the Date.","metadata":{}},{"cell_type":"code","source":"merged_df.Year.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_test_df.Year.value_counts()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `Open` Column\nThe open column in the dataset describes whether the store is opened or not.<br>\nAnd if the store is not opened on a day there will not be any Sales.<br>\nIt can be seen that the stores are closed for 172817 days (rows).<br>","metadata":{}},{"cell_type":"code","source":"#merged_df[merged_df.Open == 0].Sales.value_counts()\nmerged_df[merged_df.Open == 0].Sales","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore it is obvious that if a store is closed then the Sales on that day is zero.<br>\nTherefore, let's drop all columns in the merged_df for which Open=0.<br>\nAnd while predicting, Sales of merged_test_df = 0 when Open = 0.<br>","metadata":{}},{"cell_type":"code","source":"merged_df = merged_df[merged_df.Open == 1].copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CompetitionOpenSinceMonth & CompetitionOpenSinceYear\n\n- CompetitionOpenSinceYear : On which year the competitor store was opened.\n- CompetitionOpenSinceMonth : On which month the competitor store was opened.\n\nIt will be helpful for our model if the duration of competition (number of months) is known instead of the exact date in which the competition store has opened.<br>\nSo, we'll use these two rows along with Year, Month columns to derive the duration column and use it to train our model.<br>\n\nThe longer the compititor store has opened, the more the more impact on the Sales of the store.","metadata":{}},{"cell_type":"markdown","source":"<b>Note : </b><br>\nThere are Nan Values also in `CompetitionOpenSinceYear` & `CompetitionOpenSinceMonth` which means there is no competition store nearby for which the value is to be replaced as zero.<br>\n\nAlso for a store there might not be competition in a particular date but the competition arises in future and in such cases the difference will be negative value.<br>\n\nThese are not relevant values since it represent the future in which the competition arises and also no competition.<br>\nTherefore, negative and NaN values are replaced with zero.","metadata":{}},{"cell_type":"code","source":"merged_df[['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Year', 'Month']].info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_duration_competition(data):\n    data['CompetitionOpen'] = 12 * (data.Year - data.CompetitionOpenSinceYear) + (data.Month - data.CompetitionOpenSinceMonth)\n    data['CompetitionOpen'] = data['CompetitionOpen'].apply(lambda x:0 if x<0 else x).fillna(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calc_duration_competition(merged_df)\ncalc_duration_competition(merged_test_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df[['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Year', 'Month']].info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df[['Date', 'CompetitionDistance', 'CompetitionOpenSinceYear', 'CompetitionOpenSinceMonth', 'CompetitionOpen']].sample(20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Promotion of Store\nPromotions given by a store increases the sales.<br>\n\nPromo - indicates whether a store is running a promo on that day<br>\nPromo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating<br>\nPromo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2<br>\nPromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store\n\nWe can also add some additional columns to indicate how long (Number of months) a store has been running `Promo2` and whether a new round of `Promo2` starts in the current month.<br>\n\n<b>Note : </b>Here also negative values and NaN values are replaced as zero.","metadata":{}},{"cell_type":"code","source":"def check_promo_month(row):#check if promo is given in the particular month\n    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',              \n                 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n    try:\n        months = (row['PromoInterval'] or '').split(',')\n        if(row['Promo2Open'] and month2str[row['Month']] in months):\n            return 1\n        else:\n            return 0\n    except:\n        return 0\n    \ndef promo_cols(data): #calculate duration of promotion(in months)\n    data['Promo2Open'] = 12 * (data.Year - data.Promo2SinceYear) + (data.WeekOfYear - data.Promo2SinceWeek)*7/30.5\n    data['Promo2Open'] = data['Promo2Open'].apply(lambda x: 0 if x < 0 else x).fillna(0)*data['Promo2']#only when there is promo\n    #whether a new round of promotion started in curent month\n    data['IsPromo2Month'] = data.apply(check_promo_month, axis=1) * data['Promo2']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npromo_cols(merged_df)\npromo_cols(merged_test_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df[['Date', 'Promo2', 'Promo2SinceYear', 'Promo2SinceWeek', 'PromoInterval', 'Promo2Open', 'IsPromo2Month']].sample(20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input & Target Columns","metadata":{}},{"cell_type":"code","source":"merged_df.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_cols = ['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', \n              'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpen', \n              'Day', 'Month', 'Year', 'WeekOfYear',  'Promo2', \n              'Promo2Open', 'IsPromo2Month']\ntarget_col = 'Sales'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Date is dropped because all relevant information is extracted\n- Sales is target column\n- Customers is not present in test data so drop.( or create a model to predict number of customers and use the values in test data). \n- Open : Sales = 0 when Open =0 (obvious so not needed to feed into our model)\n- 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear' is used to derive 'CompetitionOpen'\n- 'Promo2SinceYear', 'PromoInterval' is used to derive 'Promo2Open', 'IsPromo2Month'","metadata":{}},{"cell_type":"code","source":"inputs = merged_df[input_cols].copy()\ntargets = merged_df[target_col].copy()\ntest_inputs = merged_test_df[input_cols].copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Numerical & Categorical Columns","metadata":{}},{"cell_type":"code","source":"numeric_cols = ['Store', 'Promo', 'SchoolHoliday', \n              'CompetitionDistance', 'CompetitionOpen', 'Promo2', 'Promo2Open', 'IsPromo2Month',\n              'Day', 'Month', 'Year', 'WeekOfYear',  ]\ncategorical_cols = ['DayOfWeek', 'StateHoliday', 'StoreType', 'Assortment']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Impute Missing Numerical Data","metadata":{}},{"cell_type":"code","source":"inputs[numeric_cols].isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_inputs[numeric_cols].isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only Competition Distance numerical column has null values.<br>\nCompetition Distance having null values means that there is no competitor store near by so these are to be imputed with `larger value constant` not zero (since larger the distance means lesser the competition).<br>\n\nWe'll impute with the maximum value.","metadata":{}},{"cell_type":"code","source":"max_distance = inputs.CompetitionDistance.max()\ninputs['CompetitionDistance'].fillna(max_distance, inplace=True)\ntest_inputs['CompetitionDistance'].fillna(max_distance, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling Numerical Values","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler().fit(inputs[numeric_cols])\ninputs[numeric_cols] = scaler.transform(inputs[numeric_cols])\ntest_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encode Categorical Columns\n\n<img src=\"https://i.imgur.com/n8GuiOO.png\" width=\"640\">\n\nLet's one-hot encode categorical columns.","metadata":{}},{"cell_type":"code","source":"encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(inputs[categorical_cols])\nencoded_cols = list(encoder.get_feature_names(categorical_cols))\ninputs[encoded_cols] = encoder.transform(inputs[categorical_cols])\ntest_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = inputs[numeric_cols + encoded_cols]\nX_test = test_inputs[numeric_cols + encoded_cols]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting","metadata":{}},{"cell_type":"code","source":"model = XGBRegressor(random_state=42, n_jobs=-1, n_estimators=20, max_depth=4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.fit(X, targets)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(a, b):\n    return mean_squared_error(a, b, squared=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse(preds, targets)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"trees = model.get_booster().get_dump()\nlen(trees)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(trees[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature importance\n\nJust like decision trees and random forests, XGBoost also provides a feature importance score for each column in the input.","metadata":{}},{"cell_type":"code","source":"importance_df = pd.DataFrame({\n    'feature': X.columns,\n    'importance': model.feature_importances_\n}).sort_values('importance', ascending=False)\nimportance_df.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(10,6))\nplt.title('Feature Importance')\nsns.barplot(data=importance_df.head(10), x='importance', y='feature');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K Fold Cross Validation\n\nNotice that we didn't create a validation set before training our XGBoost model. We'll use a different validation strategy this time, called K-fold cross validation ([source](https://vitalflux.com/k-fold-cross-validation-python-example/)):\n\n![](https://vitalflux.com/wp-content/uploads/2020/08/Screenshot-2020-08-15-at-11.13.53-AM.png)","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate(X_train, train_targets, X_val, val_targets, **params):\n    model = XGBRegressor(random_state=42, n_jobs=-1, **params)\n    model.fit(X_train, train_targets)\n    train_rmse = rmse(model.predict(X_train), train_targets)\n    val_rmse = rmse(model.predict(X_val), val_targets)\n    return model, train_rmse, val_rmse","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = KFold(n_splits=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\n\nfor train_idxs, val_idxs in kfold.split(X):\n    X_train, train_targets = X.iloc[train_idxs], targets.iloc[train_idxs]\n    X_val, val_targets = X.iloc[val_idxs], targets.iloc[val_idxs]\n    model, train_rmse, val_rmse = train_and_evaluate(X_train, \n                                                     train_targets, \n                                                     X_val, \n                                                     val_targets, \n                                                     max_depth=4, \n                                                     n_estimators=20)\n    models.append(model)\n    print('Train RMSE: {}, Validation RMSE: {}'.format(train_rmse, val_rmse))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_avg(models, inputs):\n    return np.mean([model.predict(inputs) for model in models], axis=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = predict_avg(models, X_train)\npreds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning and Regularization\n\nJust like other machine learning models, there are several hyperparameters we can to adjust the capacity of model and reduce overfitting.\n\n<img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"480\">\n\nCheck out the following resources to learn more about hyperparameter supported by XGBoost:\n\n- https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n- https://xgboost.readthedocs.io/en/latest/parameter.html","metadata":{}},{"cell_type":"code","source":"def test_params_kfold(n_splits, **params):\n    train_rmses, val_rmses, models = [], [], []\n    kfold = KFold(n_splits)\n    for train_idxs, val_idxs in kfold.split(X):\n        X_train, train_targets = X.iloc[train_idxs], targets.iloc[train_idxs]\n        X_val, val_targets = X.iloc[val_idxs], targets.iloc[val_idxs]\n        model, train_rmse, val_rmse = train_and_evaluate(X_train, train_targets, X_val, val_targets, **params)\n        models.append(model)\n        train_rmses.append(train_rmse)\n        val_rmses.append(val_rmse)\n    print('Train RMSE: {}, Validation RMSE: {}'.format(np.mean(train_rmses), np.mean(val_rmses)))\n    return models","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, train_targets, val_targets = train_test_split(X, targets, test_size=0.1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_params(**params):\n    model = XGBRegressor(n_jobs=-1, random_state=42, **params)\n    model.fit(X_train, train_targets)\n    train_rmse = rmse(model.predict(X_train), train_targets)\n    val_rmse = rmse(model.predict(X_val), val_targets)\n    print('Train RMSE: {}, Validation RMSE: {}'.format(train_rmse, val_rmse))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_params(n_estimators=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### max_depth","metadata":{}},{"cell_type":"code","source":"test_params(max_depth=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_params(max_depth=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### learning_rate\n\nThe scaling factor to be applied to the prediction of each tree. A very high learning rate (close to 1) will lead to overfitting, and a low learning rate (close to 0) will lead to underfitting.","metadata":{}},{"cell_type":"code","source":"test_params(n_estimators=50, learning_rate=0.01)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_params(n_estimators=50, learning_rate=0.1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### booster\n\nInstead of using Decision Trees, XGBoost can also train a linear model for each iteration. This can be configured using `booster`.","metadata":{}},{"cell_type":"code","source":"test_params(booster='gblinear')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train with best parameters","metadata":{}},{"cell_type":"code","source":"model = XGBRegressor(n_jobs=-1, random_state=42, n_estimators=1000, \n                     learning_rate=0.2, max_depth=10, subsample=0.9, \n                     colsample_bytree=0.7)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.fit(X, targets)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"test_preds = model.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['Sales']  = test_preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Recall, however, if if the store is not open, then the sales must be 0. Thus, wherever the value of `Open` in the test set is 0, we can set the sales to 0. Also, there some missing values for `Open` in the test set. We'll replace them with 1 (open).","metadata":{}},{"cell_type":"code","source":"test_df.Open.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Preparing submission.csv","metadata":{}},{"cell_type":"code","source":"submission_df['Sales'] = submission_df['Sales'] * test_df.Open.fillna(1.)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Single Input Prediction","metadata":{}},{"cell_type":"code","source":"sample_input={\n    'Store':2,\n    'DayOfWeek':4,\n    'Promo' :1,\n    'Date':'2015-09-30',\n    'Open':1,\n    'StateHoliday':'a',\n    'SchoolHoliday':0\n}\ninput_df = pd.DataFrame([sample_input])\ninput_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_merged_df = input_df.merge(store_df, on='Store')\ninput_merged_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving & Loading Models","metadata":{}},{"cell_type":"code","source":"drug_store = {\n    'model': model,\n    'scaler': scaler,\n    'encoder': encoder,\n    'input_cols': input_cols,\n    'target_col': target_col,\n    'numeric_cols': numeric_cols,\n    'categorical_cols': categorical_cols,\n    'encoded_cols': encoded_cols\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joblib.dump(drug_store, 'drug_store.joblib')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drug_store = joblib.load('drug_store.joblib')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Engineering","metadata":{}},{"cell_type":"code","source":"extract_date(input_merged_df)\ncalc_duration_competition(input_merged_df)\npromo_cols(input_merged_df)\ninput_merged_df","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Preprocessing","metadata":{}},{"cell_type":"code","source":"input_merged_df[numeric_cols] = scaler.transform(input_merged_df[numeric_cols])\ninput_merged_df[encoded_cols] = encoder.transform(input_merged_df[categorical_cols])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_input = input_merged_df[numeric_cols+encoded_cols]\nmodel.predict(X_input)[0]","metadata":{},"execution_count":null,"outputs":[]}]}