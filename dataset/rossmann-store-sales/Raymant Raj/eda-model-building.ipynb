{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rossmann-store-sales/train.csv')\nstore = pd.read_csv('/kaggle/input/rossmann-store-sales/store.csv')\ntest = pd.read_csv('/kaggle/input/rossmann-store-sales/test.csv')\nsubmission = pd.read_csv('/kaggle/input/rossmann-store-sales/sample_submission.csv')\nprint(train.shape)\nprint(store.shape)\nprint(test.shape)\nprint(submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()[['Sales','Customers']].loc['max']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Store.nunique()\n#train.Store.value_counts().head(50).plot.bar()\n#train.Store.value_counts().tail(50).plot.bar()\ntrain.Promo.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date'] = pd.to_datetime(train['Date'],format='%Y-%m-%d')\nstore_id = train.Store.unique()[0]\nprint(store_id)\nstore_rows = train[train['Store']==store_id]\nprint(store_rows.shape)\nstore_rows.resample('1D',on='Date')['Sales'].sum().plot.line(figsize=(14,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_rows[store_rows['Sales']==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date'] = pd.to_datetime(test['Date'],format='%Y-%m-%d')\nstore_test_rows = test[test['Store']==store_id]\nstore_test_rows['Date'].min(),store_test_rows['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_test_rows['Open'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_rows['Sales'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Sales'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[store['Store']==store_id].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store[~store['Promo2SinceYear'].isna()].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing Value Treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"store.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method 1\nstore['Promo2SinceWeek'] = store['Promo2SinceWeek'].fillna(0)\nstore['Promo2SinceYear'] = store['Promo2SinceYear'].fillna(store['Promo2SinceYear'].mode().iloc[0])\nstore['PromoInterval'] = store['PromoInterval'].fillna(store['PromoInterval'].mode().iloc[0])\n\nstore['CompetitionDistance'] = store['CompetitionDistance'].fillna(store['CompetitionDistance'].max())\nstore['CompetitionOpenSinceMonth'] = store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode().iloc[0])\nstore['CompetitionOpenSinceYear'] = store['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode().iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_merged = train.merge(store,on='Store',how='left')\nprint(data_merged.shape)\nprint(data_merged.isna().sum().sum())  # Cross check if there are missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Encoding\n# 3 catgorical column, 1 date column, rest are numerical\n#data_merged_dtypes\ndata_merged['day'] = data_merged['Date'].dt.day\ndata_merged['month'] = data_merged['Date'].dt.month\ndata_merged['year'] = data_merged['Date'].dt.year\n#data_merged['dayofweek'] = data_merged['Date'].dt.strftime('%a') ## This is already there in data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data_merged.dtypes\n#StateHoliday, StoreType, Assortment, PromoInterval\n#data_merged['StateHoliday'].unique()\ndata_merged['StateHoliday'] = data_merged['StateHoliday'].map({'0':0, 0:0, 'a':1, 'b':2, 'c':3})\ndata_merged['StateHoliday'] = data_merged['StateHoliday'].astype(int)\n#data_merged['Assortment'].unique()\ndata_merged['Assortment'] = data_merged['Assortment'].map({'a':1, 'b':2, 'c':3})\ndata_merged['Assortment'] = data_merged['Assortment'].astype(int)\n#data_merged['StoreType'].unique()\ndata_merged['StoreType'] = data_merged['StoreType'].map({'a':1, 'b':2, 'c':3, 'd':4})\ndata_merged['StoreType'] = data_merged['StoreType'].astype(int)\n#data_merged['PromoInterval'].unique()\nmap_promo = {'Jan,Apr,Jul,Oct': 1, 'Feb,May,Aug,Nov': 2, 'Mar,Jun,Sept,Dec': 3}\ndata_merged['PromoInterval'] = data_merged['PromoInterval'].map(map_promo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Train and Validate split\n\nfeatures = data_merged.columns.drop(['Sales','Date'])\nfrom sklearn.model_selection import train_test_split\ntrain_x, validate_x, train_y, validate_y = train_test_split(data_merged[features],np.log(data_merged['Sales']+1),test_size=0.2,random_state=1)\ntrain_x.shape, validate_x.shape, train_y.shape, validate_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\nmodel_dt = DecisionTreeRegressor(max_depth=20, random_state=1).fit(train_x,train_y)\nvalidate_y_pred = model_dt.predict(validate_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_tree(model, columns):\n    import pydotplus\n    from sklearn.externals.six import StringIO\n    from IPython.display import Image\n    import os\n    from sklearn import tree\n    \n    graphviz_path = 'C:\\Program Files (x86)\\Graphviz2.38/bin/'\n    os.environ[\"PATH\"] += os.pathsep + graphviz_path\n\n    dot_data = StringIO()\n    tree.export_graphviz(model,\n                         out_file=dot_data,\n                         feature_names=columns)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n    return Image(graph.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw_tree(model_dt,features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validate_y_pred = model_dt.predict(validate_x)\nfrom sklearn.metrics import mean_squared_error\nvalidate_y_inv = np.exp(validate_y) - 1\nvalidate_y_pred_inv = np.exp(validate_y_pred) - 1\nnp.sqrt(mean_squared_error(validate_y_inv,validate_y_pred_inv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize=(10,4))\n#plt.bar(features,model_dt.feature_importances_)\n#plt.xtickks(rotation=90)\n#pd.Series(model_dt.feature_importances_,index=features).sort_values(ascending=False)\n#data_merged.corr().loc['Sales'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stores_avg_cust = train.groupby(['Store'])[['Customers']].mean().reset_index().astype(int)\ntest1 = test.merge(stores_avg_cust, on='Store', how='left')\ntest.shape,test1.shape\ntest_merged = test1.merge(store, on='Store', how='inner')\ntest_merged['Open'] = test_merged['Open'].fillna(1)\ntest_merged['Date'] = pd.to_datetime(test_merged['Date'],format='%Y-%m-%d')\ntest_merged['day'] = test_merged['Date'].dt.day\ntest_merged['month'] = test_merged['Date'].dt.month\ntest_merged['year'] = test_merged['Date'].dt.year\ntest_merged['StateHoliday'] = test_merged['StateHoliday'].map({'0':0, 'a':1})\ntest_merged['StateHoliday'] = test_merged['StateHoliday'].astype(int)\ntest_merged['Assortment'] = test_merged['Assortment'].map({'a':1, 'b':2, 'c':3})\ntest_merged['Assortment'] = test_merged['Assortment'].astype(int)\ntest_merged['StoreType'] = test_merged['StoreType'].map({'a':1, 'b':2, 'c':3, 'd':4})\ntest_merged['StoreType'] = test_merged['StoreType'].astype(int)\nmap_promo = {'Jan,Apr,Jul,Oct': 1, 'Feb,May,Aug,Nov': 2, 'Mar,Jun,Sept,Dec': 3}\ntest_merged['PromoInterval'] = test_merged['PromoInterval'].map(map_promo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model_dt.predict(test_merged[features])\ntest_pred_inv = np.exp(test_pred)-1\nsubmission_predicted = pd.DataFrame({'Id':test['Id'],\n                                    'Sales':test_pred_inv})\nsubmission_predicted.to_csv('submission.csv',index=False)\nsubmission_predicted.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\n- Missing Value treatment\n- Merging data with store file\n- Label Encoding\n- Log transformation on target column\n- Exponential transform after prediction\n- Make sure columns/features are same in both training,validation & test datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}