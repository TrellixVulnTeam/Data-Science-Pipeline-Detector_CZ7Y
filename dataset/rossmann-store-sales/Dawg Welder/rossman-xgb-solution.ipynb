{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\".\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c226effb7c8b4c009b9fbe3a26f0c1cf4e071742","trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_store = pd.read_csv('../input/store.csv')\ndf = pd.read_csv('../input/train.csv', low_memory=False)\n\ndf = df.merge(df_store, on='Store')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0473529e2cfd8326e5f00637df7c71d6ca9655df"},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv', low_memory=False)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8bb9ba87d1e5f3b733496d7f09d445be2826b4a","trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7599b705fd510361ea4c4e83dbaf6658c82be014","trusted":true},"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Month'] = df.Date.apply(lambda dt: dt.month)\ndf['Year'] = df.Date.apply(lambda dt: dt.year)\ndf['WeekOfYear'] = df.Date.apply(lambda dt: dt.weekofyear)\ndf['Day'] = df.Date.apply(lambda dt: dt.day)\n\ndf['isMonthEnd'] = df.Date.apply(lambda dt: dt.is_month_end)\ndf['isMonthStart'] = df.Date.apply(lambda dt: dt.is_month_start)\ndf['isQuarterEnd'] = df.Date.apply(lambda dt: dt.is_quarter_end )\ndf['isQuarterStart'] = df.Date.apply(lambda dt: dt.is_quarter_start)\ndf['isYearEnd'] = df.Date.apply(lambda dt: dt.is_year_end)\ndf['isYearStart'] = df.Date.apply(lambda dt: dt.is_year_start)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"083b839788720a09b0600db77a8b174c8444f30f","trusted":true},"cell_type":"code","source":"features = []\nfor feat in df.columns.drop('Sales'):\n    if df[feat].dtype == np.float64 or df[feat].dtype == np.int64:\n        features.append(feat)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd4a232e2d222430abff6f2cda07f805e2a27f0d","scrolled":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 20));\ndf_sample = df.sample(frac=0.05)\n\nfor idx, feature in enumerate(features):\n    df_sample.plot(feature, \"Sales\", subplots=True, kind=\"scatter\", ax=axes[idx // 4, idx % 4]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3b2a5b4456a52e0cdcd9fd3945ad188000d7bcf","trusted":true},"cell_type":"code","source":"import gc \n\ndel df_sample\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f581187094f647f574bde3ecca193b391568856","scrolled":true,"trusted":true},"cell_type":"code","source":"# сильно выраженная линейная корреляция между Customers и Sales (а так же Open/Promo). Но прогнозирование количества покупателей - отдельная задача\n# Promo2 возможно не столь хороша в целом\n\ndf[df.columns.drop('Sales')].corrwith(df.Sales)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c843d7fa271775a9b4d4dd06f8760555433a1941","trusted":true},"cell_type":"code","source":"# Тип магазина \"b\" почти в два раза увеличивает продажи \n\ndf.groupby('StoreType')['Sales'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1e45e27eb20b7d008845fae10d203a8618547af","trusted":true},"cell_type":"code","source":"sns.distplot(df.Sales[df.Sales > 0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37060f3c5594875478f02524591cfa07fc0b1c43","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6b2142f307de82ec362a6328db5b33c39b4b144","trusted":true},"cell_type":"code","source":"# нет пропущенных данных для Promo2, если нет значений для ~SinceWeek или ~SinceYear\ndf[(pd.isnull(df.Promo2SinceWeek) | pd.isnull(df.Promo2SinceYear)) & df.Promo2 != 0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a92e19e5ff78c58756e7e2f55f737ce1339206e","trusted":true},"cell_type":"code","source":"df['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\ndf['CompetitionOpenSinceYear'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9076a1f723bc27f3730185ee0f9bd0fba955297b","trusted":true},"cell_type":"code","source":"df['Promo2SinceWeek'].fillna(0, inplace=True)\ndf['Promo2SinceYear'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b42793cfb320d905993796b22eaaedba664594d","trusted":true},"cell_type":"code","source":"df['CompetitionDistance'].fillna(df['CompetitionDistance'].median(), inplace=True)\ndf['CompetitionDistance'] = np.log(df.CompetitionDistance) + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18ddb862ec58f0adbee4cdd361e8ace8365b7390"},"cell_type":"code","source":"df.sample(frac=.001).plot('CompetitionDistance', \"Sales\", subplots=True, kind=\"scatter\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c450cba1871578b4e8a51375727bc6b56ed2c9bb"},"cell_type":"code","source":"# учитывается лишь один магазин конкурентов поблизости, так что нет возможности ввести дополнительный предиктор о количестве конкурентов\ndf.groupby('Store')['CompetitionDistance'].unique().apply(lambda l: 1 if len(l) > 1 else 0).sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d214df0bed0048afa8e8d90abf29ef3946d21a1","trusted":true},"cell_type":"code","source":"# большинство магазинов закрыто по праздникам, да и весомой разницы между ними в продажах не оказалось\ndf['StateHoliday'] = df['StateHoliday'].replace(0, '0')\ndf['Holiday'] = df.StateHoliday.apply(lambda x: 0 if x == '0' else 1)\n\ndf.drop('StateHoliday', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fbdda2270ced012bf4b7653ef5434aea374fc59","trusted":true},"cell_type":"code","source":"df = df.sort_values(by='Date')\ndf.drop('Date', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6192f61103d9d250bcd3962c2a120980813702e","trusted":true},"cell_type":"code","source":"df = df[(df['Open'] != 0) & (df['Sales'] != 0)]\ndf.drop('Open', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ebf6633965dbf212bbce0d49d44cef3e6b76077","trusted":true},"cell_type":"code","source":"# можно интерпретировать как категориальную фичу \n\ndf.PromoInterval.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2d3ea1902a1ef3a8624a4e88f89021d7abdcc5b"},"cell_type":"code","source":"df['isMonthEnd'] = df['isMonthEnd'].astype(int)\ndf['isMonthStart'] = df['isMonthStart'].astype(int)\ndf['isQuarterEnd'] = df['isQuarterEnd'].astype(int)\ndf['isQuarterStart'] = df['isQuarterStart'].astype(int)\ndf['isYearEnd'] = df['isYearEnd'].astype(int)\ndf['isYearStart'] = df['isYearStart'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"183c057d804bca0ae99077b63e3eba2d79037bb7"},"cell_type":"code","source":"# competition open time (in months)\ndf['CompetitionOpen'] = 12 * (df.Year - df.CompetitionOpenSinceYear) + \\\n        (df.Month - df.CompetitionOpenSinceMonth)\n    \n# Promo open time\ndf['PromoOpen'] = 12 * (df.Year - df.Promo2SinceYear) + \\\n        (df.WeekOfYear - df.Promo2SinceWeek) / 4.0\n\ndf = pd.get_dummies(df, columns=['DayOfWeek', 'StoreType', 'Assortment','PromoInterval'], dummy_na=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbb24efeffb06e1eb11e677dc5609a0062d86d8d","trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.metrics import r2_score, make_scorer\n\ndef ToWeight(y):\n    w = np.zeros(y.shape, dtype=float)\n    ind = y != 0\n    w[ind] = 1./(y[ind]**2)\n    return w\n\n\ndef rmspe(yhat, y):\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n    return rmspe\n\n\ndef rmspe_xg(yhat, y):\n    # y = y.values\n    y = y.get_label()\n    y = np.exp(y) - 1\n    yhat = np.exp(yhat) - 1\n    w = ToWeight(y)\n    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n    return \"rmspe\", rmspe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fb2975e247489dd4d2530d348ab18916aa3e3b7"},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestRegressor\n\n# rfr = RandomForestRegressor(n_estimators=300, criterion='mae', max_depth=12, n_jobs=-1, verbose=True)\n# rfr.fit(X_train.values, np.log(y_train.values) + 1)\n\n# y_hat = rfr.predict(X_test.values)\n# y_hat = np.exp(y_hat) - 1\n\n# print(f'MAE: {mae(y_test, y_hat)}')\n# print(f'RMSPE: {rmspe(y_hat, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77069691308b5d69e5a2706c55954a19da288d14","trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom hyperopt import hp\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\ndef train(index, train, hp_selection=False):\n    train_store = train[index]\n    X = train_store[train_store.columns.drop(['Sales', 'Store', 'Customers'])]\n    y = train_store['Sales']\n\n    train_size = int(X.shape[0]*.99)\n    print(f'Regressor for {index} store\\nTraining on {X.shape[0]} samples')\n    X_train, y_train = X.iloc[:train_size], y.iloc[:train_size]\n    X_test, y_test = X.iloc[train_size:], y.iloc[train_size:]\n\n    xtrain = xgb.DMatrix(X_train, np.log(y_train.values) + 1)\n    xtest = xgb.DMatrix(X_test, np.log(y_test.values) + 1)\n    \n    if hp_selection:\n        def score(params):\n            num_round = 200\n            model = xgb.train(params, xtrain, num_round, feval=rmspe_xg)\n            predictions = model.predict(xtest)\n            score = rmspe(y=y_test, yhat=predictions)\n            return {'loss': score, 'status': STATUS_OK}\n\n        def optimize(trials):\n            space = {\n                     'n_estimators' : hp.quniform('n_estimators', 1, 1000, 1),\n                     'eta' : hp.quniform('eta', 0.2, 0.825, 0.025),\n                     'max_depth' : hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n                     'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n                     'subsample' : hp.quniform('subsample', 0.7, 1, 0.05),\n                     'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n                     'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n                     'eval_metric': 'rmse',\n                     'objective': 'reg:linear',\n                     'nthread': 4,\n                     'silent' : 1\n                     }\n\n            best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n            return best\n        \n        trials = Trials()\n        best_opts = optimize(trials)\n        best_opts['silent'] = 1\n    else:\n        best_opts = {'colsample_bytree': 0.7, \n                  'eta': 0.625, \n                  'gamma': 0.8, \n                  'max_depth': 6,\n                  'eval_metric': 'rmse',\n                  'min_child_weight': 6.0, \n                  'n_estimators': 8.0,  # 585\n                  'silent': 1,\n                  'nthread': 4,\n                  'subsample': 0.95}\n        \n    watchlist = [(xtrain, 'train'), (xtest, 'eval')]\n    num_round = 10000\n    regressor = xgb.train(best_opts, xtrain, num_round, watchlist, feval=rmspe_xg,\n                          verbose_eval=10, early_stopping_rounds=50)\n    print(\"Validating\")\n    train_probs = regressor.predict(xtest)\n    indices = train_probs < 0\n    train_probs[indices] = 0\n    error = rmspe(np.exp(train_probs) - 1, y_test.values)\n    print('error', error)\n    regressor = xgb.train(best_opts, xtest, 10, feval=rmspe_xg, xgb_model=regressor)\n    return regressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3e495928654f37a47baa5d701a3974fa7b4d139","scrolled":true,"trusted":true},"cell_type":"code","source":"# params = {'colsample_bytree': 0.7000000000000001, \n#           'eta': 0.625, \n#           'gamma': 0.8, \n#           'max_depth': 6,\n#           'eval_metric': 'rmse',\n#           'min_child_weight': 6.0, \n#           'n_estimators': 8.0,  # 585\n#           'silent': 1,\n#           'subsample': 0.9500000000000001}\n\n\n# watchlist = [(xtrain, 'train'), (xtest, 'eval')]\n# num_round = 10000\n# xgb_regressor = xgb.train(params, xtrain, num_round, watchlist, feval=rmspe_xg,\n#                           verbose_eval=10, early_stopping_rounds=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fee838b584d0d02c6a2cb40b5339c0d761abd762","_kg_hide-output":true},"cell_type":"code","source":"# fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 20));\n# xgb.plot_importance(xgb_regressor, axes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb3c2a8c027326314b39a6132b1fdd75f498f0f4"},"cell_type":"code","source":"# print(\"Validating\")\n# train_probs = xgb_regressor.predict(xtest)\n# indices = train_probs < 0\n# train_probs[indices] = 0\n# error = rmspe(np.exp(train_probs) - 1, y_test.values)\n# print('error', error)\n\n# xgb_regressor = xgb.train(params, xtest, 1000, feval=rmspe_xg, xgb_model=xgb_regressor)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5993b9291009815cdbc36a6563b32e3c1f77199","trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv', low_memory=False)\nclosed_store_ids = df_test[\"Id\"][df_test[\"Open\"] == 0].values\n\ndf_test = df_test.merge(df_store, on='Store')\ndf_test['Date'] = pd.to_datetime(df_test['Date'])\ndf_test['Month'] = df_test.Date.apply(lambda dt: dt.month)\ndf_test['Year'] = df_test.Date.apply(lambda dt: dt.year)\ndf_test['WeekOfYear'] = df_test.Date.apply(lambda dt: dt.weekofyear)\ndf_test['Day'] = df_test.Date.apply(lambda dt: dt.day)\n\ndf_test['isMonthEnd'] = df_test.Date.apply(lambda dt: dt.is_month_end).astype(int)\ndf_test['isMonthStart'] = df_test.Date.apply(lambda dt: dt.is_month_start).astype(int)\ndf_test['isQuarterEnd'] = df_test.Date.apply(lambda dt: dt.is_quarter_end ).astype(int)\ndf_test['isQuarterStart'] = df_test.Date.apply(lambda dt: dt.is_quarter_start).astype(int)\ndf_test['isYearEnd'] = df_test.Date.apply(lambda dt: dt.is_year_end).astype(int)\ndf_test['isYearStart'] = df_test.Date.apply(lambda dt: dt.is_year_start).astype(int)\n\ndf_test['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\ndf_test['CompetitionOpenSinceYear'].fillna(0, inplace=True)\n\ndf_test['Promo2SinceWeek'].fillna(0, inplace=True)\ndf_test['Promo2SinceYear'].fillna(0, inplace=True)\n\ndf_test['CompetitionDistance'].fillna(df_test['CompetitionDistance'].median(), inplace=True)\n\ndf_test['StateHoliday'] = df_test['StateHoliday'].replace(0, '0')\ndf_test['Holiday'] = df_test.StateHoliday.apply(lambda x: 0 if x == '0' else 1)\n\ndf_test.drop('StateHoliday', axis=1, inplace=True)\ndf_test.drop('Date', axis=1, inplace=True)\n\n# competition open time (in months)\ndf_test['CompetitionOpen'] = 12 * (df_test.Year - df_test.CompetitionOpenSinceYear) + \\\n        (df_test.Month - df_test.CompetitionOpenSinceMonth)\n    \n# Promo open time\ndf_test['PromoOpen'] = 12 * (df_test.Year - df_test.Promo2SinceYear) + \\\n        (df_test.WeekOfYear - df_test.Promo2SinceWeek) / 4.0\n\ndf_test.drop(['Open'], axis=1, inplace=True)\n\ndf_test = pd.get_dummies(df_test, columns=['DayOfWeek', 'StoreType', 'Assortment','PromoInterval'], dummy_na=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2718a2b5fecc1a0d0cb960f81e1ec1673ef48bec"},"cell_type":"code","source":"store_grouped = dict(list(df.groupby('Store')))\ntest_grouped = dict(list(df_test.groupby('Store')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ccd69e853fc3bb77584d0c12adc7764f1f743bb"},"cell_type":"code","source":"submission = pd.Series(np.zeros(df_test.Id.shape))\nsubmission.index += 1\n\nfor store in test_grouped:\n    test = test_grouped[store].copy()\n    ids = test['Id']\n    dpred = xgb.DMatrix(test[test.columns.drop(['Id', 'Store'])]) \n    regressor = train(store, store_grouped)\n    preds = regressor.predict(dpred)\n    preds[preds < 0] = 0\n    preds = np.exp(preds) - 1\n    submission[ids] = preds\n\nsubmission[closed_store_ids] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4618cb46e5157a9361c14a986ec5f507721ab95"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71916750ae8c63b869211358d43d93936bfc3734"},"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission['Id'] = submission.index\ndf_submission['Sales'] = submission.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8346d30b14001da663d4dba2c840bf5328fec39f"},"cell_type":"code","source":"df_submission","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"230c653df663e255d4f88e6d3640c9952d10a44e","trusted":true},"cell_type":"code","source":"df_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9c0f8adfa47df037d6f93e2336bab26e80ba999","trusted":true,"scrolled":true},"cell_type":"code","source":"# def score(params):\n#     print(\"Training with params : \")\n#     print(params)\n#     num_round = int(params['n_estimators'])\n#     model = xgb.train(params, xtrain, num_round, feval=rmspe_xg)\n#     predictions = model.predict(xtest)\n#     score = rmspe(y=y_test, yhat=predictions)\n#     br = '-'*124\n#     print(f'{br}\\n\\tScore of RMSPE: {score}\\n{br}')\n#     return {'loss': score, 'status': STATUS_OK}\n\n# def optimize(trials):\n#     space = {\n#              'n_estimators' : hp.quniform('n_estimators', 1, 1000, 1),\n#              'eta' : hp.quniform('eta', 0.3, 0.825, 0.025),\n#              'max_depth' : hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n#              'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n#              'subsample' : hp.quniform('subsample', 0.7, 1, 0.05),\n#              'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n#              'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n#              'eval_metric': 'rmse',\n#              'objective': 'reg:linear',\n#              'nthread': 4,\n#              'silent' : 1\n#              }\n\n#     best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n\n#     print(best)\n#     return best\n\n    \n# trials = Trials()\n# best_opts = optimize(trials)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"726b04fce303e591bf2dcd4015a06b03417c1251","trusted":true},"cell_type":"code","source":"# print(best_opts)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f1c5738ce5a734697daeb8e52257fc3a1329616"},"cell_type":"markdown","source":"Best params:\n{'colsample_bytree': 0.7000000000000001, 'eta': 0.625, 'gamma': 0.8, 'max_depth': 6, 'min_child_weight': 6.0, 'n_estimators': 585.0, 'subsample': 0.9500000000000001}\n---"},{"metadata":{"_uuid":"561e9fdc8c5f96548ab1e0429223dd5aabd4ee34","trusted":false},"cell_type":"code","source":"# def score(params):\n#     print(\"Training with params : \")\n#     print(params)\n#     num_round = 25  # int(params['n_estimators'])\n#     # del params['n_estimators']\n#     dtrain = xgb.DMatrix(X_train, label=y_train)\n#     dvalid = xgb.DMatrix(X_test, label=y_test)\n#     model = xgb.train(params, dtrain, num_round)\n#     predictions = model.predict(dvalid)\n#     score = mae(y_test, predictions)\n#     br = '-'*130\n#     print(f'{br}\\n\\tScore of MAE: {score}\\n{br}')\n#     return {'loss': score, 'status': STATUS_OK}\n\n# def optimize(trials):\n#     space = {\n#              'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n#              'eta' : hp.quniform('eta', 0.4, 0.825, 0.025),\n#              'max_depth' : hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n#              'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n#              'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n#              'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n#              'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n#              'eval_metric': 'mae',\n#              'objective': 'reg:linear',\n#              'nthread': 4,\n#              'silent' : 1\n#              }\n\n#     best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=50)\n\n#     print(best)\n    \n# trials = Trials()\n# optimize(trials)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}