{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"11da5d18-147f-65dc-56b8-3f7600982fca"},"source":"## Rossmann Store - Forecasting Sales\n\nRossmann Store Sales data is available via [Kaggle](https://www.kaggle.com/c/rossmann-store-sales). Data is from a chemist store that has over 6000 stores across Europe. \n\nI have previously presented a notebook with insights on Rossmann Store, [Rossmann Store -Insights](https://www.kaggle.com/virusme/rossmann-store-sales/rossmann-store-insights). In this notebook, I will attempt to forecast or predict sales for each store, six weeks in advance. \n\n_**Note**: I am always looking forward for constructive feedback. If you find a bug or if you think there are some fundamental mistakes, please do let me know. If you think this analysis could be further improved, again please do let me know. Your inputs will be highly appreciated. My contact email: info@theportfoliotrader.com_\n\n\n### Feature Selection\n\nOne of the most important things to do before embarking on any sort of modelling task is to understand the features, in order to make sure our model is trained with the best feature set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c5fe289-6453-c979-e048-6ead11d917a8"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d69dc354-c32d-8762-1f13-4be20a988830"},"outputs":[],"source":"%matplotlib inline\n# packages\nimport matplotlib.pyplot as plt\n#import mpld3\nimport warnings\nimport seaborn as sns\nsns.set(style='darkgrid')\n\n#\nwarnings.filterwarnings('ignore')\n#mpld3.enable_notebook()\n#\n# sales data, lets load the data\ntrain = pd.read_csv('../input/train.csv')\n# sort the dates \ntrain.sort_values(by='Date', ascending=True, inplace=True)\n# stores data\nstores = pd.read_csv('../input/store.csv')\n#\nprint('-----Train data ------------------------------------')\nprint(train.head(10))\nprint('-----------------------------------------')\nprint('-----Stores data ------------------------------------')\nprint(stores.head(10))\nprint('-----------------------------------------')\n#\n# lets collate sales and customer data on monthly and yearly charts\n# split Year-Month-Date to three different columns\ntrain['Month'] = train['Date'].apply(lambda x : int(str(x)[5:7]))\ntrain['Year'] = train['Date'].apply(lambda x : int(str(x)[:4]))\ntrain['MonthYear'] = train['Date'].apply(lambda x : (str(x)[:7]))\n\n#\ntrain.info()\nstores.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f2f8826a-b02f-97f0-d0f2-b2e3cad56a8e"},"source":"### Train data\n\n`Customers` numbers will be co-related to `Sales` however from a business perspective, future customer numbers are unknown therefore, we can discount `Customers` being one of the features for preliminary forecasting or predictions. `Sales` are only possible if the stores are open therefore we should retain `Open` being a feature. Let's explore whether the rest of the attributes have any co-relation with `Sales`. As the remaining attributes are all categorical, therefore let's explore their relationship with `Sales` using boxplot. Meantime, we will also convert `Sales` to logscale for modelling."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc471638-6b2e-0a94-a2fd-ddd2b543b7c0"},"outputs":[],"source":"train['LogSales'] = np.log(train['Sales']+1)  # +1 to take care of log(0) condition\ntrain_stores = train[train['Open']!=0]\ncols = ['DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Month','Year']  # interested in these attributes\n\nfig, axis = plt.subplots(3,2, figsize=(15,15))\naxis = axis.ravel()\nfor i, attr in enumerate(cols):\n    ax1 = sns.boxplot(x=attr, y='Sales', data=train_stores[['Sales', attr]], palette='husl', ax=axis[i])\n    axis[i].set_title('Distributions per ' + attr)"},{"cell_type":"markdown","metadata":{"_cell_guid":"921fa84a-099f-9fb1-db8e-9122da2cba0f"},"source":"**DayOfWeek**: It does appear that day-1, day-2, day-6 an day-7 have varying distributions wheres day-3,4,5 appear to have similar distributions. May be we can club day-3,4,5 as day-3 reducing the dimensionality of this feature\n\n**Promo**: Promo does have varying distributions hence will be a good feature to have\n\n**StateHoliday**: StateHoliday also appears to be a good feature to have. However, '0' (string 0) and 0 (numeric 0) as categories appears to be mis-labelled categories and can be clubbed as '0' (string 0)\n\n**SchoolHoliday**: SchoolHoliday does not appear to have much interesting information. May be we can discard this feature.\n\n**Month**: This is an important feature because of the seasonality factor\n\n**Year**: Year could be discarded as a feature.\n\n\n### Stores data\nLet's explore the stores data to see if any of those attributes could be used as a feature. Each store has one data-point for each attribute. Therefore, we will have to expand the data to fit the `train` data. First, let's look at `Promo2`, by itself it only conveys whether a store had a second promotion, so it may not very useful to expand. However we could use `Promo2SinceWeek`, `Promo2SinceYear` and `PromoInterval` to create a step-function that switches from `0` to `1` when `Promo2` started thereby covering the expanse of the `train` data. I think, similar processing could be done to `CompetitionOpen` using `CompetitionOpenSinceMonth` and `CompetitionOpenSinceYear`, instead of a step-function we could convert this into a function of `CompetitionDistance`. `StoreType` and `Assortment` are important features of a store hence let us retain them as is.\n\nI will first prepare data for `CompetitionOpen` by creating `CompOpenDate` and using a inverse of `CompetitionDistance` as `CompImpact`. I use inverse relationship because, from [Rossmann Store -Insights](https://www.kaggle.com/virusme/rossmann-store-sales/rossmann-store-insights), we have seen that competition distance has inverse relationship with sales and performance. That is, larger the competition distance better the sales and performance and vice-versa."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f35571a-b7f9-864e-ad8e-674df8f34956"},"outputs":[],"source":"import datetime\n# stores data\nstores = pd.read_csv('../input/store.csv')\n# there are many NANs, remove them\nstores_notnull = stores['CompetitionOpenSinceMonth'].notnull() & stores['CompetitionOpenSinceYear'].notnull()\n# create CompetitionOpenDate\nstores['CompOpen'] = stores[stores_notnull]['CompetitionOpenSinceYear'].astype(int).astype(str).str.cat(stores[stores_notnull]['CompetitionOpenSinceMonth'].astype(int).astype(str).str.zfill(2), sep='-')\nstores['CompOpenDate'] = pd.Series([datetime.datetime.strptime(str(ym), '%Y-%m').strftime('%Y-%m-%d') for ym in stores[stores_notnull]['CompOpen'].tolist()], index = stores[stores_notnull].index)    \n# fill CompetitionDistance for Nan as high number\nstores['CompetitionDistance'].fillna(value=1000000, inplace=True)\n\n\n# let's update train data\n# create a step function based on CompOpenDate for train\nprint('processing Stores...')\nfor store in stores['Store']:\n    print('\\r', 'Store: ', store, end='')\n    storedata = train[train['Store'] == store]\n    compd = stores[stores['Store']==store]['CompOpenDate']\n    dist = stores[stores['Store']==store]['CompetitionDistance']\n    train.ix[train['Store']==store, 'CompImpact'] = (storedata['Date'] > compd.values[0]).astype(int).values * (1/dist.values[0])\n\nprint('\\n','finished')"},{"cell_type":"markdown","metadata":{"_cell_guid":"46d192e5-f723-4679-e8f9-2f6052226b47"},"source":"_Note: using `\\r` in the `print` statement should overwrite the previous printed line, oddly enough that does not seem to be the case in Kaggle notebook. However, on `jupyter-notebook` it works fine._\n\nWe have now created a `CompImpact` step function for each store. We can use some sort of inverse function of `CompetitionDistance` combined with step function to generate a meaningful series that hopefully adds more dimensionality to our model building.\n\nNow, let's look at generating a similar series for `Promo2`. `Promo2SinceWeek` and `Promo2SinceYear` appears to be straightforward. However, `PromoInterval` is quite confusing. For example, what `Jan, Apr, Jul, Oct` mean for `PromoInterval`. From the data description, it appears:\n\n> describes the consecutive intervals Promo2 is started, naming the months the\npromotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in\nFebruary, May, August, November of any given year for that store\n\nSo, if `Promo2` started in Feb, how long does it run? If it started anew in May, did `Promo2` that started in Feb end before May and was there a no promotion period? If there was no period with no promotion then why should not I consider `Promo2` being ON from Feb till Jan, i.e. entire 52 weeks. If there were more details provided as to what promotions were held at each of those intervals then it would have been lot more informative. For example, Feb - 10$\\%$ discount promotion, May - free $\\$$10 voucher promotion, etc. Some stores have one or two intervals, again information on how long did the promotions run for would have been really helpful. I will discard `PromoInterval` as of now and create a step function using `Promo2SinceWeek` and `Promo2SinceYear`.\n\nTo convert `year-week` string format to `date`, I will use `datetime` with `-0` and `-$\\%$w` options, as suggested [here](http://stackoverflow.com/a/17087427/2979010). `-w` will directs the parser to convert to week starting `Monday`. Assuming businesses would like to start promotions on `Sunday`, `-0` will pick `Sunday` as the starting dat of the week. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d874232d-cb4b-bbb1-f69d-b23a00e7daf0"},"outputs":[],"source":"# there are many NANs, remove them\nstores_notnull = stores['Promo2SinceWeek'].notnull() & stores['Promo2SinceYear'].notnull()\n# create Promo2OpenDate\nstores['Promo2Open'] = stores[stores_notnull]['Promo2SinceYear'].astype(int).astype(str).str.cat(stores[stores_notnull]['Promo2SinceWeek'].astype(int).astype(str).str.zfill(2), sep='-')\nstores['Promo2OpenDate'] = pd.Series([datetime.datetime.strptime(str(ym)+'-0', '%Y-%W-%w').strftime('%Y-%m-%d') for ym in stores[stores_notnull]['Promo2Open'].tolist()], index = stores[stores_notnull].index)    \n\n# let's update train data\n# create a step function based on CompOpenDate for train\nprint('processing Stores...')\nfor store in stores['Store']:\n    print('\\r', 'Store: ', store, end='')\n    storedata = train[train['Store'] == store]\n    p2d = stores[stores['Store']==store]['Promo2OpenDate']\n    train.ix[train['Store']==store, 'Promo2'] = (storedata['Date'] > p2d.values[0]).astype(int).values\n\n\nprint('\\n','finished')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7a73b1f8-e63a-0a80-a605-68c38ea80b5e"},"outputs":[],"source":"# plot\nfig, (axis1, axis2, axis3) = plt.subplots(3,1, sharex=True, figsize=(10,7))\n# We will now plot the generated series for one store to see if it looks alright.\n# Pick a random store which has CompOpenDate and Promo2OpenDate  \nstore = stores[(stores['CompOpenDate'].notnull()) & (stores['Promo2OpenDate'].notnull())]['Store'].sample(n=1).values[0]\n\n# display CompOpenDate and Promo2OpenDate\nprint('Competition Open Date: ' + stores[stores['Store']==store]['CompOpenDate'].astype(str))\nprint('Promo2 Start Date: ' + stores[stores['Store']==store]['Promo2OpenDate'].astype(str))\n# plot generated series along with sales\nstoredata = train[train['Store']==store]\nstoredata['Date'] = pd.to_datetime(storedata['Date'])\n#\nstoredata['CompImpact'].plot(marker='o', ax=axis1)\ntmp = axis1.set_title('Store-{} :Competition Impact'.format(store))\nstoredata['Promo2'].plot(marker='o', ax=axis2)\ntmp = axis2.set_title('Promo2 Start')\nstoredata['Sales'].plot(marker='o', ax=axis3)\ntmp = axis3.set_title('Sales')\ntmp = axis3.set_xticks(storedata['Date'].index[::20])\ntmp = axis3.set_xticklabels(storedata['Date'][::20], rotation=90)"},{"cell_type":"markdown","metadata":{"_cell_guid":"4756d62a-d377-1bac-e46b-2525f8cac495"},"source":"_Note: Above plot are generated by selecting a store at random, everytime you run, the plots will change._\n\nAbove plots, show the step-functions for `CompImpact` and `Promo2` plotted along with the `Sales` data for a random store. In this case(i.e. `Store=115`), we can see that the `CompImpact` is always `1` suggesting that the competition was in existence even before the first data point was collected. Also, there is a large gap in the data starting `2014-06-25`, this could be because of renovations, etc being performed on the store during which there was no data collected as the store was closed. We have to be mindful of such data-gaps and make sure they do not exist before while training/constructing a model.\n\nNow, let's add `StoreType` and `Assortment` data for each store."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adee74b1-7b45-ff5d-4818-9a72d67ddbe6"},"outputs":[],"source":"# StoreType and Assortment\nprint('processing Stores...')\nfor store in stores['Store']:\n    print('\\r', 'Store: ', store, end='')\n    storedata = train[train['Store'] == store]\n    st = stores[stores['Store']==store]['StoreType']\n    train.ix[train['Store']==store, 'StoreType'] = st.values[0]\n    asst = stores[stores['Store']==store]['Assortment']\n    train.ix[train['Store']==store, 'Assortment'] = asst.values[0]\n    \nprint('\\n','finished')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c9efcb2-04a3-8d19-1c9a-4207dd5a4c1c"},"outputs":[],"source":"## lets prepare data for training and testing\n\n# make a copy of the data \ntrain_copy = train.copy()\n\n# StateHoliday, StoreType and Assortment are categorical strings, convert using simple LabelEncoder/DictVectoriser\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction import DictVectorizer\ntrain_copy['StateHoliday'].replace(0, '0', inplace=True)\ntrain_copy['StateHoliday'] = LabelEncoder().fit_transform(train_copy['StateHoliday'])\ntrain_copy['StoreType'] = LabelEncoder().fit_transform(train_copy['StoreType'])\ntrain_copy['Assortment'] = LabelEncoder().fit_transform(train_copy['Assortment'])\n\n# Date is already sorted\nunique_dates = train_copy['Date'].unique()\ntrain_length = np.round(unique_dates.shape[0] * 0.8).astype(int)\n#\ntrain_data = train_copy[train_copy['Date'].isin(unique_dates[0:train_length])]\ntest_data = train_copy[train_copy['Date'].isin(unique_dates[train_length+1:])]\n# feature attributes\nfeature_attributes = ['Open', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', 'CompImpact', 'Promo2', 'Month', 'Year', 'StoreType', 'Assortment']\ntarget_attribute = ['LogSales']\n#"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a879de0a-aa62-94bb-fcb5-09575f8ec4da"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}