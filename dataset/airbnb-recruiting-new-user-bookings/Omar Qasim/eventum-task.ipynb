{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Airbnb New User Bookings"},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading The DataSet"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load the data into DataFrames\ntrain_users = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/train_users_2.csv')\ntest_users = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/test_users.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of users in training set =\", train_users.shape[0] )\nprint(\"Number of users in test set =\",test_users.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_users.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_users.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above, We can see that date_first_booking feature is allways NaN in test dataset so I will remove it from both training and testing."},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train_users['country_destination'].values\ntrain_users = train_users.drop(['country_destination', 'date_first_booking'], axis=1)\ntest_users = test_users.drop(['date_first_booking'], axis=1)\nid_test = test_users['id']\n\n# Merge train and test users\nall_users = pd.concat((train_users, test_users), axis=0, ignore_index=True)\n\n# Remove ID's since now we are not interested in making predictions\nall_users.drop('id',axis=1, inplace=True)\n\nall_users.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nall_users['date_account_created'] = pd.to_datetime(all_users['date_account_created'])\nall_users['timestamp_first_active'] = pd.to_datetime((all_users.timestamp_first_active // 1000000), format='%Y%m%d')\n\nall_users['date_account_created'] = [datetime.timestamp(d) for d in all_users['date_account_created']]\nall_users['timestamp_first_active'] = [datetime.timestamp(d) for d in all_users['timestamp_first_active']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_users.age.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(all_users.age.dropna())\nplt.xlabel('Age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see above, the common age to travel is between 14 and 70. So I will smooth Age distribution by remove all values bellow 14 and above 70."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(all_users.age.loc[all_users['age'] < 70].dropna())\nplt.xlabel('Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_users['age'] = np.where(all_users['age']<=14, 14, all_users['age'])\nall_users['age'] = np.where(all_users['age']>=70, 70, all_users['age'])\nall_users['age'] = all_users['age'].fillna(all_users['age'].dropna().values.mean())\nall_users['age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_users['age'].values.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = [\n    'affiliate_channel',\n    'affiliate_provider',\n    'first_affiliate_tracked',\n    'first_browser',\n    'first_device_type',\n    'gender',\n    'language',\n    'signup_app',\n    'signup_method'\n]\n\n# one-hot-encoding\nfor categorical_feature in categorical_features:\n    all_users_dummies = pd.get_dummies(all_users[categorical_feature], prefix=categorical_feature)\n    all_users = all_users.drop([categorical_feature], axis=1)\n    all_users = pd.concat((all_users, all_users_dummies), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_users.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ntrain_users_n = train_users.shape[0]\nX_train = all_users.values[:train_users_n]\nle = LabelEncoder()\ny_train = le.fit_transform(labels)   \nX_test = all_users.values[train_users_n:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_answer(y_pred, classifer_name):\n    #Taking the 5 classes with highest probabilities\n    ids = []  #list of ids\n    cts = []  #list of countries\n    for i in range(len(id_test)):\n        idx = id_test[i]\n        ids += [idx] * 5\n        cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n    \n    sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n    sub.to_csv(classifer_name+'.csv',index=False)\n    return sub","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MLP Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier()\nmlp.fit(X_train, y_train)\ny_pred_mlp = mlp.predict_proba(X_test)\ngenerate_answer(y_pred_mlp, 'MLP')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost.sklearn import XGBClassifier\n\nxgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \nxgb.fit(X_train, y_train)\ny_pred_xgb = xgb.predict_proba(X_test)\ngenerate_answer(y_pred_xgb, 'XGB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}