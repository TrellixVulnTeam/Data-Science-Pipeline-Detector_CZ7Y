{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf1df949-e4aa-955f-6782-24a42efc9eb3"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57db3579-c6b2-c79e-40ac-7bbda92858b9"},"outputs":[],"source":"df_train = pd.read_csv(\"../input/train_users_2.csv\")\ndf_test = pd.read_csv(\"../input/test_users.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59ebc7a0-9865-0275-6bfc-171af9a4f01a"},"outputs":[],"source":"labels = df_train['country_destination'].values # Get the values of the country destination for each row\ndf_train = df_train.drop(['country_destination'], axis=1) # It's the output variable for the decision tree\nid_test = df_test['id']\npiv_train = df_train.shape[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f51ea440-5227-f003-bbaa-4dcbde0179cc"},"outputs":[],"source":"df_all = pd.concat((df_train, df_test), axis = 0, ignore_index = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e61339b6-0c14-29a0-e9df-bd1ec2a0aa85"},"outputs":[],"source":"df_all = df_all.drop(['id','date_first_booking'], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed6ff1ac-b78a-58e2-c717-0ec7467363c9"},"outputs":[],"source":"df_all.gender.replace('-unknown-', np.nan, inplace=True) # -unknown- is not considered as a missing value so we replace it by nan\nprint(df_all.isnull().sum())\ndf_all = df_all.fillna(-1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0613a26d-b324-3c62-5fb1-6dc5399c8d8f"},"outputs":[],"source":"dac = np.vstack(df_all.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\nprint(dac)\ndf_all['dac_year'] = dac[:,0]\ndf_all['dac_mounth'] = dac[:,1]\ndf_all['dac_day'] = dac[:,2]\ndf_all = df_all.drop(['date_account_created'], axis = 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cad882d-6e7f-ee99-4746-0d267111c18e"},"outputs":[],"source":"tfa = np.vstack(df_all.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8],x[8:10],x[10:12],x[12:14]]))).values)\nprint(tfa)\ndf_all['tfa_year'] = tfa[:,0]\ndf_all['tfa_month'] = tfa[:,1]\ndf_all['tfa_day'] = tfa[:,2]\ndf_all = df_all.drop(['timestamp_first_active'], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"543e6052-c0dc-98b7-d46a-39e5a2863ae3"},"outputs":[],"source":"print(df_all.age.describe()) # We can see that the age has some inconsistancy variables\nav = df_all.age.values\ndf_all['age'] = np.where(np.logical_or(av<14, av>100), -1, av)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1fa26c7a-70bf-6045-85e3-39c24fd73bde"},"outputs":[],"source":"features = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"556f591b-0d1b-8900-b903-7f9227d3e985"},"outputs":[],"source":"for f in features:\n    df_all_dummy = pd.get_dummies(df_all[f], prefix=f)\n    df_all = df_all.drop([f], axis=1)\n    df_all = pd.concat((df_all, df_all_dummy), axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45398842-92c5-f73c-28c2-c406f302a019"},"outputs":[],"source":"vals = df_all.values\nX = vals[:piv_train]\nle = LabelEncoder()\ny = le.fit_transform(labels)   \nX_test = vals[piv_train:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9add9356-e818-5ab4-b260-d77eecdf9186"},"outputs":[],"source":"model = RandomForestClassifier()\nmodel.fit(X,y)\ny_pred = model.predict_proba(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f71e4d27-5683-58cd-a015-b720a0ebc9fc"},"outputs":[],"source":"ids = []  #list of ids\ncts = []  #list of countries\nfor i in range(len(id_test)):\n    idx = id_test[i]\n    ids += [idx] * 5\n    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}