{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/airbnb-recruiting-new-user-bookings/train_users_2.csv.zip')\ntest = pd.read_csv('../input/airbnb-recruiting-new-user-bookings/test_users.csv.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissionid=test.id","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---> Test datam ve Train datamı birleştirdim. Burada Train datasına, Train datasının ortamalası vs ile yapacağım imputation'ları da tek seferde ekleyebilmek istediğim bu adımı gerçekleştirdim."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# For identification purposes\ntrain.loc[:,'Train'] = 1\ntest.loc[:,'Train'] = 0\n\ntest['country_destination'] = 0\n\ndf = pd.concat([train,test], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=df[df['Train']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=df[df['Train']==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['age'].fillna(train['age'].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['age'].fillna(train['age'].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['first_affiliate_tracked'] = train['first_affiliate_tracked'].fillna('Unknown')\ntest['first_affiliate_tracked'] = test['first_affiliate_tracked'].fillna('Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['date_account_created','timestamp_first_active','date_first_booking','Train'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['date_account_created','timestamp_first_active','date_first_booking','country_destination','Train'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder() \n  \ntrain['gender']= le.fit_transform(train['gender'])\ntrain['signup_method']= le.fit_transform(train['signup_method']) \ntrain['first_affiliate_tracked']= le.fit_transform(train['first_affiliate_tracked']) \ntrain['signup_method']= le.fit_transform(train['signup_method']) \ntrain['language']= le.fit_transform(train['language'])\ntrain['affiliate_channel']= le.fit_transform(train['affiliate_channel'])\ntrain['affiliate_provider']= le.fit_transform(train['affiliate_provider'])\ntrain['signup_app']= le.fit_transform(train['signup_app'])\ntrain['first_device_type']= le.fit_transform(train['first_device_type'])\ntrain['first_browser']= le.fit_transform(train['first_browser'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder() \n  \ntest['gender']= le.fit_transform(test['gender'])\ntest['signup_method']= le.fit_transform(test['signup_method']) \ntest['first_affiliate_tracked']= le.fit_transform(test['first_affiliate_tracked']) \ntest['signup_method']= le.fit_transform(test['signup_method']) \ntest['language']= le.fit_transform(test['language'])\ntest['affiliate_channel']= le.fit_transform(test['affiliate_channel'])\ntest['affiliate_provider']= le.fit_transform(test['affiliate_provider'])\ntest['signup_app']= le.fit_transform(test['signup_app'])\ntest['first_device_type']= le.fit_transform(test['first_device_type'])\ntest['first_browser']= le.fit_transform(test['first_browser'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.country_destination.replace('NDF',0,inplace=True)\ntrain.country_destination.replace('US',1,inplace=True)\ntrain.country_destination.replace('other',2,inplace=True)\ntrain.country_destination.replace('FR',3,inplace=True)\ntrain.country_destination.replace('CA',4,inplace=True)\ntrain.country_destination.replace('GB',5,inplace=True)\ntrain.country_destination.replace('ES',6,inplace=True)\ntrain.country_destination.replace('IT',7,inplace=True)\ntrain.country_destination.replace('PT',8,inplace=True)\ntrain.country_destination.replace('NL',9,inplace=True)\ntrain.country_destination.replace('DE',10,inplace=True)\ntrain.country_destination.replace('AU',11,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ny=train['country_destination']\nX=train.drop(['country_destination','id'],axis=1)\n# split the dataset into train and test sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1,shuffle=True,stratify=y )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_country={0:\"NDF\", 1:\"US\", 2:\"other\", 3:\"FR\", 4:\"CA\", 5:\"GB\", 6:\"ES\", 7:\"IT\", 8:\"PT\", 9:\"DE\", 10:\"NL\", 11:\"AU\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.metrics import classification_report\ntarget_names = ['NDF', 'US', 'other', 'FR', 'CA', 'GB', 'ES', 'IT', 'PT', 'NL','DE', 'AU']\n\nrf=RandomForestClassifier(n_estimators=10)\n\n#Train the model using the training sets y_pred=rf.predict(X_test)\nrf.fit(X_train,y_train)\n\n# prediction on test set\ny_predrf=rf.predict(X_test)\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(classification_report(y_test, y_predrf, target_names=target_names))"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictionsrf=rf.predict(test.drop(['id'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#results=[]\n#for i in predictionsrf:\n#    results.append(pred_country[i])\n#print(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_submissionrf = pd.DataFrame({'id': test.id, 'country':results})\n#my_submissionrf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\nmlpgridsearch = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\nmlpgridsearch.fit(X_train,y_train)\npredsgridmlp = mlpgridsearch.predict(X_test)\n\nprint(mlpgridsearch.score(X_train, y_train))\nprint(mlpgridsearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n#Generate prediction using Neural Net\n\n#mlp = MLPClassifier()\n#mlp.fit(X_train,y_train)\n#predsmlp = mlp.predict(X_test)\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(classification_report(y_test, predsgridmlp, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictionsmlp=mlpgridsearch.predict(test.drop(['id'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results=[]\nfor i in predictionmlp:\n    results.append(pred_country[i])\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submissionmlp = pd.DataFrame({'id': test.id, 'country':results})\nmy_submissionmlp.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import xgboost\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \nxgb.fit(X_train, y_train)\ny_pred = xgb.predict_proba(X_test)\nprint(classification_report(y_test, y_predrf, target_names=target_names))"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictionsxgb=xgb.predict(test.drop(['id'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gridsearch yapıp xgboost denenebilir veya bir önceki drafta nn kullanarak yaptıgın modele gridsearch denenebilir. Zaten hepsinden iyi çalıştı. başka boosting yöntemleri denenebilir. Yeni özellik eklenmeye çalışılabilir. Seasonal bir etki var çünkü."},{"metadata":{"trusted":true},"cell_type":"code","source":"#results=[]\n#for i in predictionsxgb:\n#    results.append(pred_country[i])\n#print(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_submissionxgb = pd.DataFrame({'id': test.id, 'country':results})\n#my_submissionxgb.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MLP classifiyer en iyi sonucu verdi şimdiye kadar. Ama rf ve xgb scoru arasında pek bir fark oldugu söylenemez. 0.68 0.69 alabildiğim en yüksek score. Grid searchle modelimi geliştirecek en uygun parametreleri seçmeyi deneyebilirim."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}