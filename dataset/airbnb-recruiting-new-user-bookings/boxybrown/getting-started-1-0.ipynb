{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Imports\n\n\n\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn, sklearn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nsns.set_style('whitegrid')\n##%matplotlib inline\n\n\n\n#### import the data\ntrain_users   = pd.read_csv('../input/train_users_2.csv')\ntest_users    = pd.read_csv('../input/test_users.csv')\ngender = pd.read_csv('../input/age_gender_bkts.csv')\nsessions = pd.read_csv('../input/sessions.csv')\ncountries = pd.read_csv('../input/countries.csv')\n\n##all_users = pd.concat((train_users, test_users), axis=0, ignore_index=True)\n\nmobile_browsers = []\nfor x in train_users['first_browser'].unique():\n    if 'Mobile' in x:\n        mobile_browsers.append(x)\n    else:\n        pass \n\nmajor_browsers = ['IE', 'Safari', '-unknown- ', 'Chrome', 'Firefox', 'Mobile']  \n\n### group up those first_browsers\ntrain_users['first_browser_grouped'] = np.where(train_users['first_browser'].isin(mobile_browsers), 'Mobile', train_users['first_browser'])\ntrain_users['first_browser_grouped'] = np.where(train_users['first_browser_grouped'].isin(major_browsers), train_users['first_browser_grouped'], 'Other')\n\n### find year of account creation\n#train_users['year_account_creation'] = pd.DatetimeIndex(train_users['date_account_created']).year\n\n### group up the first_device_type\ndict_first_device_type = {\"Mac Desktop\": \"Desktop\",\n                          \"Windows Desktop\": \"Desktop\",\n                          \"Desktop (Other)\": \"Desktop\",\n                          \"iPhone\": \"Phone/Pad\",\n                          \"iPad\": \"Phone/Pad\",\n                          \"Android Tablet\": \"Phone/Pad\", \n                          \"Android Phone\": \"Phone/Pad\",\n                          \"SmartPhone (Other)\": \"Phone/Pad\"}\ntrain_users = train_users.replace({\"first_device_type\": dict_first_device_type})\n\n\n\n######### apply the above adjustments to the test dataset\ntest_users['first_browser_grouped'] = np.where(test_users['first_browser'].isin(mobile_browsers), 'Mobile', test_users['first_browser'])\ntest_users['first_browser_grouped'] = np.where(test_users['first_browser_grouped'].isin(major_browsers), test_users['first_browser_grouped'], 'Other')\n#test_users['year_account_creation'] = pd.DatetimeIndex(test_users['date_account_created']).year\ntest_users = test_users.replace({\"first_device_type\": dict_first_device_type})\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"language_distance = {'language' : ['en', 'du', 'fr', 'es'],\n                     'levenshtein_distance_from_en' : [0, 72.61, 92.06, 92.25]}\n\nlanguage_distance = pd.DataFrame(language_distance)\n\ntrain_users = pd.merge(train_users, language_distance, on = 'language', how = 'left')\ntest_users = pd.merge(test_users, language_distance, on = 'language', how = 'left')\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n########## fill in the missing values\ntrain_users['levenshtein_distance_from_en'].fillna(-1)\ntest_users['levenshtein_distance_from_en'].fillna(-1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##train_users['year_account_creation'] = pd.DatetimeIndex(train_users['date_account_created']).year\ntrain_users['timestamp_first_active'] = train_users['timestamp_first_active'].astype(str)\n\ntrain_users['date_account_created'] = pd.to_datetime(train_users['date_account_created'])\n\n#### converting the first active day to a date-time var\ntrain_users['timestamp_first_active_day'] = train_users['timestamp_first_active'].str[:8]\ntrain_users['timestamp_first_active_day'] = pd.to_datetime(train_users['timestamp_first_active_day'], format='%Y%m%d')\n\n#### find the first active year\ntrain_users['timestamp_first_active_year'] = train_users['timestamp_first_active'].str[:4]\ntrain_users['timestamp_first_active_hour'] = train_users['timestamp_first_active'].str[8:10]\n\n#### create a var to see if they searched before joining\n#train_users['searched_before_joining'] = (train_users['timestamp_first_active_day'] < train_users['date_account_created'])\n#train_users['searched_before_joining'] = train_users['searched_before_joining'] * 1\n\n#### did they do a previous trip? This appears to be a weird variable..\n##train_users['first_trip'] = pd.isnull(train_users['date_first_booking']) * 1\n\nmajor_languages = ['en']  \ntrain_users['language_bucket'] = np.where(train_users['language'].isin(major_languages), 'en', 'other')\n\n##### group up the age variable\nlabels = [1, 2, 3, 4, 5, 6, 7]\nbins = [0, 20, 30, 40, 50, 60, 9000, 100000]\ntrain_users['age'].fillna(10000)\ntrain_users['age_group'] = pd.cut(train_users['age'], bins, right=False, labels=labels)\ntrain_users['age_group'] = train_users['age_group'] * 1\n\ntrain_users[\"signup_combo\"] = train_users[\"signup_method\"].map(str) + train_users[\"signup_flow\"].map(str)\n\n##### let's group the affiliate_provider variable\n\nmajor_affiliate_providers = ['direct', 'google', 'bing', 'craigslist', 'facebook']\ntrain_users['affiliate_provider_grp'] = np.where(train_users['affiliate_provider'].isin(major_affiliate_providers), train_users['affiliate_provider'], 'other')\ntrain_users[\"affiliate_combined\"] = train_users[\"affiliate_provider_grp\"].map(str) + train_users[\"affiliate_channel\"].map(str)\n\n\n\n\n\n\n###### adjust test so it matches the adjustments made to the train dataset\ntest_users['timestamp_first_active'] = test_users['timestamp_first_active'].astype(str)\ntest_users['date_account_created'] = pd.to_datetime(test_users['date_account_created'])\ntest_users['timestamp_first_active_day'] = test_users['timestamp_first_active'].str[:8]\ntest_users['timestamp_first_active_day'] = pd.to_datetime(test_users['timestamp_first_active_day'], format='%Y%m%d')\ntest_users['timestamp_first_active_year'] = test_users['timestamp_first_active'].str[:4]\n#test_users['searched_before_joining'] = (test_users['timestamp_first_active_day'] < test_users['date_account_created'])\n#test_users['searched_before_joining'] = test_users['searched_before_joining'] * 1\n##test_users['first_trip'] = pd.isnull(test_users['date_first_booking']) * 1\ntest_users['language_bucket'] = np.where(test_users['language'].isin(major_languages), 'en', 'other')\ntest_users['age'].fillna(10000)\ntest_users['age_group'] = pd.cut(test_users['age'], bins, right=False, labels=labels)\ntest_users['age_group'] = test_users['age_group'] * 1\ntest_users['timestamp_first_active_day'] = pd.to_datetime(test_users['timestamp_first_active_day'], format='%Y%m%d')\ntest_users[\"signup_combo\"] = test_users[\"signup_method\"].map(str) + test_users[\"signup_flow\"].map(str)\ntest_users['timestamp_first_active_hour'] = test_users['timestamp_first_active'].str[8:10]\ntest_users['affiliate_provider_grp'] = np.where(test_users['affiliate_provider'].isin(major_affiliate_providers), test_users['affiliate_provider'], 'other')\ntest_users[\"affiliate_combined\"] = test_users[\"affiliate_provider_grp\"].map(str) + test_users[\"affiliate_channel\"].map(str)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##train_users.head()\n##train_users[train_users['first_browser_grouped'] == 'Mobile']\n\n#### language doesn't appear that helpful.. anyway we can adjust it some?\n\n#train_users.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n#test = [0]\n#train_users['tester'] = np.where((train_users['timestamp_first_active_day'] - train_users['date_account_created']).isin(test), 0, 1)\n\n#fig, (axis1) = plt.subplots(1,1,figsize=(15,5))\n#fig, (axis1, axis2, axis3) = plt.subplots(3,1,figsize=(15,15))\n#sns.countplot(x='language_bucket', hue = 'country_destination', data=train_users, palette=\"husl\", ax=axis1)\n#sns.countplot(x = 'affiliate_channel', hue = 'country_destination', data = train_users, palette = 'husl', ax = axis2)\n#sns.countplot(x = 'affiliate_provider_grp', hue = 'country_destination', data = train_users, palette = 'husl', ax = axis3)\n#sns.countplot(x = 'signup_app', hue = 'country_destination', data = train_users, palette = 'husl', ax = axis4)\n#sns.countplot(x = 'affiliate_provider', hue = 'country_destination', data = train_users[train_users['affiliate_provider'] != 'direct'], palette = 'husl', ax = axis5)\n#sns.countplot(x = 'tester', hue = 'country_destination', data = train_users[train_users['tester'] == 1], palette = 'husl', ax = axis1)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#fig, (axis1, axis2) = plt.subplots(2,1,figsize=(15,10))\n#sns.countplot(x='affiliate_channel', hue = 'country_destination', data=train_users[train_users['affiliate_provider_grp'] == 'google'], palette=\"husl\", ax=axis1)\n#sns.countplot(x='affiliate_provider_grp', hue = 'country_destination', data=train_users[train_users['affiliate_channel'] == 'seo'], palette=\"husl\", ax=axis2)\n\n\n\n\n##### I'm curious, what's the interaction between date_account_created and timestamp_first_active? \n#train_users['date_account_created'] = pd.to_datetime(train_users['date_account_created'])\n#train_users['dif_btwn_creation_and_search'] = (train_users['timestamp_first_active_day'] - train_users['date_account_created']).astype('timedelta64[M]')\n#train_users['dif_btwn_creation_and_search_rounded'] = train_users['dif_btwn_creation_and_search'].round(-1)\n\n\n#fig, (axis1) = plt.subplots(1,1,figsize=(15,5))\n#sns.countplot(x='dif_btwn_creation_and_search_rounded', hue = 'country_destination', data=train_users, palette=\"husl\", ax=axis1)\n\n#train_users.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n\n#fig, (axis1) = plt.subplots(1,1,figsize=(15,5))\n#sns.countplot(x='age_group', hue = 'country_destination', data=train_users, palette=\"husl\", ax=axis1)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##### is it worthwhile to group up some of these X vars w/ a lot of subclasses? \n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#######\n\ntrain_users['month_created'] = train_users['date_account_created'].map(lambda x: x.month)\ntrain_users['year_created'] = train_users['date_account_created'].map(lambda x: x.year)\ntrain_users['month_year_created'] = train_users['date_account_created'].map(lambda x: x.year * 1000 + x.month)\n\ntrain_users['month_first_active'] = train_users['timestamp_first_active_day'].map(lambda x: x.month)\ntrain_users['year_first_active'] = train_users['timestamp_first_active_day'].map(lambda x: x.year)\ntrain_users['month_year_first_active'] = train_users['timestamp_first_active_day'].map(lambda x: x.year * 1000 + x.month)\n\n########\ntest_users['month_created'] = test_users['date_account_created'].map(lambda x: x.month)\ntest_users['year_created'] = test_users['date_account_created'].map(lambda x: x.year)\ntest_users['month_year_created'] = test_users['date_account_created'].map(lambda x: x.year * 1000 + x.month)\n\ntest_users['month_first_active'] = test_users['timestamp_first_active_day'].map(lambda x: x.month)\ntest_users['year_first_active'] = test_users['timestamp_first_active_day'].map(lambda x: x.year)\ntest_users['month_year_first_active'] = test_users['timestamp_first_active_day'].map(lambda x: x.year * 1000 + x.month)\n\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"############\ntrain_users = train_users.drop(['date_account_created', 'timestamp_first_active', 'timestamp_first_active_day', 'date_first_booking'], axis = 1)\ntest_users = test_users.drop(['date_account_created', 'timestamp_first_active', 'timestamp_first_active_day', 'date_first_booking'], axis = 1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##### this removes the missing values\nfrom sklearn.base import TransformerMixin\nclass DataFrameImputer(TransformerMixin):\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n            index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\n    \ntrain_users_imputed = DataFrameImputer().fit_transform(train_users)\ntest_users_imputed = DataFrameImputer().fit_transform(test_users)\n\n\n### this will transfer the categorical variables to floats for the algo\ndef do_treatment(df):\n    for col in df:\n        if df[col].dtype == np.dtype('O') and df[col].name != 'id' and df[col].name != 'country_destination' and df[col].name != 'age_group' and df[col].name != 'timestamp_first_active_day':\n            df[col] = df[col].apply(lambda x : hash(str(x)))\n\n    \ndo_treatment(train_users_imputed)\ndo_treatment(test_users_imputed)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#np.any(np.isnan(train_users['id']))\n#print(np.all(np.isfinite(col)))\n\n#np.isnan(train_users.any())\n#np.isfinite(train_users.any())\n\n#np.isnan(test_users.any())\n#np.isfinite(test_users.any())\n\n\n\n\n#train_users.head()\n\n\nX_train = train_users_imputed.drop(['signup_app', 'affiliate_provider', 'affiliate_channel', 'levenshtein_distance_from_en', 'month_year_first_active', 'month_year_created', 'year_first_active', 'timestamp_first_active_year', 'country_destination', 'id', 'first_browser', 'age', 'language'], axis=1)\ny_train = train_users_imputed['country_destination']\nX_test = test_users_imputed.drop(['signup_app', 'affiliate_provider', 'affiliate_channel', 'levenshtein_distance_from_en', 'month_year_first_active', 'month_year_created', 'year_first_active', 'timestamp_first_active_year', 'id', 'age', 'first_browser', 'language'], axis = 1)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\ncountry_num_dic = {'NDF': 0, 'US': 1, 'other': 2, 'FR': 3, 'IT': 4, 'GB': 5, 'ES': 6, 'CA': 7, 'DE': 8, 'NL': 9, 'AU': 10, 'PT': 11}\nnum_country_dic = {y:x for x,y in country_num_dic.items()}\n\ny_train    = y_train.map(country_num_dic)\n\n##### build the model\n\nclf = RandomForestClassifier(n_estimators = 200, max_features = 'sqrt',\n                             max_depth = None, verbose = 1, n_jobs = -1)\nclf.fit(X_train, y_train)\nclf_probs = clf.predict_proba(X_test) ## prob of being in a certain class\ntest_preds = clf.predict(X_test)\ntest_preds = test_preds.astype(int)\n\n# change values back to original country symbols\ntest_preds = Series(test_preds).map(num_country_dic)\n\noutput = pd.DataFrame(test_users.id).join(pd.DataFrame(clf_probs))\noutput_melted = pd.melt(output, id_vars = 'id')\n# convert type to integer\noutput_melted['variable'] = output_melted['variable'].astype(int)\n\n# change values back to original country symbols\noutput_melted['variable'] = Series(output_melted['variable']).map(num_country_dic)\n\noutput_sorted = output_melted.sort(['id', 'value'], ascending=[1, 0])\ntop_5_records = output_sorted.groupby('id').head(5)\ntop_5_records_trimmed = top_5_records.drop(['value'], axis = 1)\ntop_5_records_trimmed.columns = ['id', 'country']\n\nfinal_output = DataFrame(columns=['id', 'country'])\nfinal_output = final_output.append(top_5_records_trimmed)\n\n\n\n\n##### get the output ready for a csv submission\n#output = pd.DataFrame(test_users.id).join(pd.DataFrame(test_preds))\n#output.columns = ['id', 'country_destination']\n\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n\n\n\n###### look at variable importance in the model \n\nimportances = clf.feature_importances_\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in indices:\n    print(X_train.columns[f], importances[f])\n    #print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n#for x in range(X_train.shape[1]):\n#    print(X_train.columns[x])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"### alright, if none of the entries for an id is NDF, then set the 5th obs == NDF\nno_ndf_ppl = top_5_records[~top_5_records['id'].isin(top_5_records['id'][top_5_records['variable'] == 'NDF'])]\nndf_ppl = top_5_records[top_5_records['id'].isin(top_5_records['id'][top_5_records['variable'] == 'NDF'])]\n\nno_ndf_ppl_first = no_ndf_ppl.sort(['value'], ascending=[1])\nno_ndf_ppl_first_ndf = no_ndf_ppl_first.groupby('id').head(1)\nno_ndf_ppl_first_ndf['variable'] = 'NDF'\n\nno_ndf_ppl_first_4 = no_ndf_ppl.sort(['value'], ascending=[0])\nno_ndf_ppl_first_other = no_ndf_ppl_first_4.groupby('id').head(4)\n\n##### combine all of the dataframes together\nresult = pd.concat([no_ndf_ppl_first_ndf, no_ndf_ppl_first_other , ndf_ppl])\nresult = result.drop(['value'], axis = 1)\nresult.columns = ['id', 'country']\n\n#### create the final output dataframe\nfinal_output_adjusted = DataFrame(columns=['id', 'country'])\nfinal_output_adjusted = final_output_adjusted.append(result)\n\n#### convert to csv\nfinal_output_adjusted.to_csv('adjusted.csv', index = False, header = ['id', 'country'])\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}