{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nWith the pt 1 exploration notebook, I left off with a lot of variables to look into. Theory-wise, the data was too complex to manage in my head, so for this notebook I will look to apply clustering to make more sense of the high dimensional data. \n\nI will take the unsupervised and supervised approach to clustering the data using K-means for the unsupervised method. With K-means, I will have to first change all the categorical columns in the training data to dummy variables. I will then iterate through different numbers of clusters and use the elbow method to help determine which ones to keep. From there I can further analyze the data based on the categorized cluster. \n\nContinuing with the categorized cluster, it may help with classification to build smaller models based on the clusters. For example, users that have the id in the session dataset vs those that do not. There may or may not be a difference. This notebook will explore this potential relationship. Some caveats of this exploration are that the categorical variables explored in the previous dataset are unbalanced. There are a lot of long tailed groups for dates, age, advertising data, and the target predictions. ","metadata":{}},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(f'{dirname + \"/\" + \"train_users_2.csv.zip\"}')\n# Cleaning code from the pt. 1 notebook. \ntrain[\"date_account_created\"] = pd.to_datetime(train.date_account_created)\ntrain[\"timestamp_first_active\"] = pd.to_datetime(train.timestamp_first_active, format=\"%Y%m%d%H%M%S\")\ntrain[\"date_first_booking\"] = pd.to_datetime(train.date_first_booking)\ntrain.loc[train.age >= 90, \"age\"] = -1\ntrain.loc[train.age <= 14, \"age\"] = 0\n\n\ngender_dummies = pd.get_dummies(train.gender, prefix=\"gender\")\ntrain = pd.concat([train, gender_dummies], axis=1)\ntrain = train.drop([\"gender\", \"gender_-unknown-\"], axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_intervals = [-1, 0, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90]\nage_dummies = pd.get_dummies(pd.cut(train.age, bins=age_intervals, right=False), prefix=\"age\")\ntrain = pd.concat([train, age_dummies], axis=1)\ntrain = train.drop([\"age\"], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Actionables\nNow that got the dummies out of the ages set into intervals to smooth out performance, I will try to make dummies out of the other variables. \n\nGender was set to dummy because it ordinal genders does not make sense to me. \nA male is not twice the magnitude of a female. -unknown- was removed since it is perfectly collinear when the other gender dummies are False/0.\n\n```\ngender_map = {\n    \"-unknown-\" : -1,\n    \"FEMALE\" : 0,\n    \"MALE\" : 1,\n    \"OTHER\" : 2\n}\ntrain[\"gender\"] = train[\"gender\"].map(gender_map)```\n\nThe next step I will look at the years.","metadata":{}},{"cell_type":"code","source":"train.date_account_created.dt.year.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.timestamp_first_active.dt.year.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"dac_year\"] = train.date_account_created.dt.year - 2008\ntrain[\"dac_month\"] = train.date_account_created.dt.month\ntrain[\"dac_day\"] = train.date_account_created.dt.day\n\ntrain[[\"dac_year\", \"dac_month\", \"dac_day\"]].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"tfa_year\"] = train.timestamp_first_active.dt.year - 2008\ntrain[\"tfa_month\"] = train.timestamp_first_active.dt.month\ntrain[\"tfa_day\"] = train.timestamp_first_active.dt.day\n\ntrain[[\"tfa_year\", \"tfa_month\", \"tfa_day\"]].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate delay between days\n(train.date_account_created - train.timestamp_first_active).dt.days.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nIt is interesting how there are so many days that are -1. That would suggest that there are people who sign up before becoming active. I wonder what their first affiliates are.\n\nI subtracted 2008 from the years since I will be clustering these values. I would like to normalize them, but I think that reducing the number to be a lot closer to 0 would be sufficient. I do not want to have negative values here. I used 2008 because that was the year that airbnb started. \n","metadata":{}},{"cell_type":"code","source":"train[(train.date_account_created - train.timestamp_first_active).dt.days == -1][\"affiliate_channel\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.affiliate_channel.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nThere is barely any difference between the two. Maybe I am caculating incorrectly. I think that for the time delta since timestamps are during the day while date account creates are strictly for the day that a non-integer day result gets rounded down. \nTo balance this out, I will add 1 to the values then. I am comfortable doing this because I did not find any values smaller than -1. If there were values that were smaller then it might suggest that people were tracked before their first time becoming active. \n\nI thought about seasons, but I am going to ignore it because I feel that it will be highly correlated with months, and that since I will end up using a dimensionality reducer that seasons would be nullified anyways. ","metadata":{}},{"cell_type":"code","source":"# Number of days it took to create the account since becoming first active\ntrain[\"delay_days\"] = (train.date_account_created - train.timestamp_first_active).dt.days + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adv_columns = [\"affiliate_channel\", \"affiliate_provider\", \"first_affiliate_tracked\", \"first_browser\", \"first_device_type\", \"signup_flow\", \"language\", \"signup_method\", \"signup_app\"]\nadv_dummies = pd.get_dummies(train[adv_columns])\n\ntrain = pd.concat([train, adv_dummies], axis=1)\ntrain = train.drop(adv_columns, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nI think that the data is done being processed. I will first run this through k-means and see what results we can get. I will do the first run with 12 clusters since we have 12 outputs for country destinations. I will then use the elbow method to see if the number of optimal clusters are the same. \n\nI will explore the data with the clusters given, then move onto integrating the sessions data with the training and test data. ","metadata":{}},{"cell_type":"code","source":"print(train.columns, train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop([\n    \"id\", \n    \"date_account_created\", \n    \"timestamp_first_active\", \n    \"date_first_booking\"], \n    axis=1)\ntrain.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.country_destination.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output_map = {\n#     'NDF': 0, \n#     'US': 1, \n#     'other': 2, \n#     'FR': 3, \n#     'CA': 4, \n#     'GB': 5, \n#     'ES': 6, \n#     'IT': 7, \n#     'PT': 8, \n#     'NL': 9,\n#     'DE': 10, \n#     'AU': 11\n# }\n# train[\"ordinal_output\"] = train[\"country_destination\"].map(output_map)\n\noutput_dummies = pd.get_dummies(train.country_destination, prefix=\"output\")\ntrain = pd.concat([train, output_dummies], axis=1)\ntrain = train.drop(\"country_destination\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nmodel_12 = KMeans(n_clusters=12, random_state=42*42)\nmodel_12 = model_12.fit(train)\npredict_12 = model_12.predict(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_12.inertia_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_proc(explore):\n    age_intervals = [-1, 0, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90]\n    \n    explore[\"date_account_created\"] = pd.to_datetime(explore.date_account_created)\n    explore[\"timestamp_first_active\"] = pd.to_datetime(explore.timestamp_first_active, format=\"%Y%m%d%H%M%S\")\n    explore[\"date_first_booking\"] = pd.to_datetime(explore.date_first_booking)\n    explore.loc[explore.age >= 90, \"age\"] = -1\n    explore.loc[explore.age <= 14, \"age\"] = 0\n\n    explore['age'] = pd.cut(explore.age, bins=age_intervals, right=False)\n\n    explore[\"dac_year\"] = explore.date_account_created.dt.year - 2008\n    explore[\"dac_month\"] = explore.date_account_created.dt.month\n    explore[\"dac_day\"] = explore.date_account_created.dt.day\n\n\n    explore[\"tfa_year\"] = explore.timestamp_first_active.dt.year - 2008\n    explore[\"tfa_month\"] = explore.timestamp_first_active.dt.month\n    explore[\"tfa_day\"] = explore.timestamp_first_active.dt.day\n\n    explore[\"delay_days\"] = (explore.date_account_created - explore.timestamp_first_active).dt.days + 1\n    \n    return explore\n\n\nexplore = pd.read_csv(f'{dirname + \"/\" + \"train_users_2.csv.zip\"}')\nexplore = data_proc(explore)\nexplore = pd.concat([explore, pd.Series(predict_12, name=\"Cluster\")], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explore.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(explore.columns) - 4):\n    plt.figure(i, figsize=(12, 8))\n    sns.countplot(x=explore.columns[4 + i], hue='Cluster',data=explore)\n    plt.xticks(rotation=45)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nI think it is very interesting how there are several clusters with almost nothing in them. for custer 1, 4, 6, and 11. Why are these so low? But other than that, the other clusters seem to be repeating their frequency in all of the areas, which suggest that a lot of the variables are pretty randomly distributed. This is frustrating because it seems like that it is just impossible to use the data in train to predict the output. This also suggests that the session dataset must be used. \n\nThere is a difference in the dates based on the clusters. I think that instead of spotting a relationship based on the country destination, which is only one column, the clustering algorithm found patterns based on the dates. \n\nI will look into that before using the elbow method and adding in the session data.","metadata":{}},{"cell_type":"code","source":"for i in range(len(explore.columns) - 4):\n    plt.figure(i, figsize=(12, 8))\n    sns.countplot(x=explore.columns[4 + i], data=explore[explore.Cluster == 0])\n    plt.xticks(rotation=45)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(explore.columns) - 4):\n    plt.figure(i, figsize=(12, 8))\n    sns.countplot(x=explore.columns[4 + i], data=explore[explore.Cluster == 11])\n    plt.xticks(rotation=45)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nI definitely can see a correlation with date for cluster 0. Cluster 11 on the other hand, being an outlier cluster had more random seeming values. \n\nBut in terms of country destination, cluster 0 shows a few things. There is a pattern emerging between NDF and the other variables. I thought it was interesting how the age of cluster 0 reflected the general population as shown in previous exploration visualizations. So it really shows the listed age is not a good deteminant at least for that cluster for the output. Intead it showed a lot of first browsers that were not extremely popular when they create an account on the first day. \n\nAnother takeaway is that I should convert the delay_days to an interval in the same way I did for the ages. \n","metadata":{}},{"cell_type":"code","source":"def data_proc(explore):\n    age_intervals = [-1, 0, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90]\n    delay_days_intervals = [0, 1, 2, 3, 4, 5, 6, 7, 14, 30, 60, 90, 180, 365]\n    \n    explore[\"date_account_created\"] = pd.to_datetime(explore.date_account_created)\n    explore[\"timestamp_first_active\"] = pd.to_datetime(explore.timestamp_first_active, format=\"%Y%m%d%H%M%S\")\n    explore[\"date_first_booking\"] = pd.to_datetime(explore.date_first_booking)\n    explore.loc[explore.age >= 90, \"age\"] = -1\n    explore.loc[explore.age <= 14, \"age\"] = 0\n\n    explore['age'] = pd.cut(explore.age, bins=age_intervals, right=False)\n    \n\n    explore[\"dac_year\"] = explore.date_account_created.dt.year - 2008\n    explore[\"dac_month\"] = explore.date_account_created.dt.month\n    explore[\"dac_day\"] = explore.date_account_created.dt.day\n\n\n    explore[\"tfa_year\"] = explore.timestamp_first_active.dt.year - 2008\n    explore[\"tfa_month\"] = explore.timestamp_first_active.dt.month\n    explore[\"tfa_day\"] = explore.timestamp_first_active.dt.day\n\n    explore[\"delay_days\"] = (explore.date_account_created - explore.timestamp_first_active).dt.days + 1\n    explore[\"delay_days\"] = pd.cut(explore.delay_days, bins=delay_days_intervals, right=False).astype(str)\n    explore[\"delay_days\"] = explore[\"delay_days\"].fillna(720)\n    \n    return explore","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\n\nmodel = KMeans(random_state=42*42)\nvisualizer = KElbowVisualizer(model, k=(1,10))\nvisualizer.fit(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nThe transition seems to be around the 3-5 clusters.\n\nI will repeat the clustering without the destinations","metadata":{}},{"cell_type":"code","source":"model = KMeans(random_state=42*42)\nvisualizer = KElbowVisualizer(model, k=(1,10))\nvisualizer.fit(train.drop(train.columns[train.columns.str.contains(\"output\")], axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nAfter dropping the output dummies, it seems that the clusters converged to 3. \nUnfortunately with only three clusters, I do not feel that I can easily get a lot of clear information for which factors contribute to determining the country destination. \n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\noutput = pca.fit_transform(train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(output[:, 0], output[:, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nFor visualization, I ran PCA with a n_component of 2. I will not apply PCA for the clustering because the number of columns is much smaller than the rows. I have not put in the sessions data, and also the data is not standardly scaled, which may negatively affect the performance of PCA. \n\nLooking at this graph, it also does not seem like clustering would be able to get a good representation of the data, it might be densely populated information on the y axis, one that is further up, and another that captures the outliers. The other possibility is that the densely populated part is split in two and then the reamaining values are captured in the outliers. That would reminde me of hte previous clusters where each cluster had a different overlap based on dates, and then there were three clusters that caught all the points of lower density.","metadata":{}},{"cell_type":"code","source":"model_3 = KMeans(n_clusters=3, random_state=42*42)\nmodel_3 = model_3.fit(train)\npredict_3 = model_3.predict(train)\nexplore = pd.read_csv(f'{dirname + \"/\" + \"train_users_2.csv.zip\"}')\nexplore = data_proc(explore)\nexplore = pd.concat([explore, pd.Series(predict_3, name=\"Cluster\")], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(output[:, 0], output[:, 1], c=explore.Cluster, cmap=\"brg\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(len(explore.Cluster.unique())):\n    for i in range(len(explore.columns) - 4):\n        plt.figure((i+1)*(j+1))\n        sns.countplot(x=explore.columns[4 + i], data=explore[explore.Cluster == j])\n        plt.xticks(rotation=45)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nThese three clusters show a much better difference compared to the 12 cluster. But that is expected. A few differences that I see here are in the delay days, of gender, and also first browsers. But as I came to realize when exploring the previous clustering model, these are not clustered against the classes, so the data as it is will not be very useful to look into. ","metadata":{}},{"cell_type":"markdown","source":"# Sessions Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsessions = pd.read_csv(\"/kaggle/input/airbnb-recruiting-new-user-bookings/sessions.csv.zip\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sessions.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sessions[\"id\"] = sessions[\"user_id\"]\nsessions = sessions.drop(\"user_id\", axis=1)\nsessions.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in sessions.columns:\n    print(sessions[column].isnull().value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for elem in sessions.columns: \n    print(sessions[elem].value_counts(), \"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_event = sessions.id.value_counts()[sessions.id.value_counts() == 1].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(single_event)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/airbnb-recruiting-new-user-bookings/train_users_2.csv.zip\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train.id.isin(single_event)][\"country_destination\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[\n    (train.id.isin(single_event)) & \n    (train.country_destination == \"US\")\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nNo obvious pattern. I am surprised how some people can have only one session recroded despite having an account created, a period of inactivity, and then a date first booking. This could show that the session data is incomplete or trimmed down. This period was too old for the feature of group booking to take place since that feature was introduced in 2017. \n\nI need to decide which features from sessions to keep. Action and action detail have an unbalanced set of features, so the small ones should be cut out to reduce dimensions. Action detail and action type both have 1030k unknown actions, on top of 1126k missing values. \n\nSo I think I should change small frequency values to 0, and then a standardscalar. Unlike age, I think that the relative values are not as important and certain age milestones might have a bigger impact than the number of events. \nI will look to see what is a good cutoff range and then round to a clean number. \nAn example of what I will cut off are the booking_response in action type since there are only 4 overall. \n\nFor action, there are 359 different recorded actions, a lot of these will just be trimmed off. ","metadata":{}},{"cell_type":"code","source":"sessions.groupby([\"id\"])[\"action\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vc = sessions.action.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vc[vc<5000].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vc[vc<500].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vc[vc<200].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaway\nIn terms of which variables to be cut off as whole, a good cut off amount seems to be around 1000, where the concavity of the curve seems to be the greatest. Or I should choose the section right when the curve flattens out, which looks to be around 60. \nA log transformation might help distribute these counts. But I do not feel that a log transformation would be helpful since these fewer represented categories are not frequently counted as part of a customer's journey. \n\nOn the other hand, there may be parts in this data that immediately show interest such as reaching out to an AirBnB host which would be incredibly useful data buildling a model for a person who would NDF or select a location. It may not help with determining which location, but the binary case of a booking is possible. ","metadata":{}},{"cell_type":"code","source":"vc[vc<200].head(30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nFrom a manual look, I see a user interest action such as requesting photography, and then from the host aspect I see a lot of features showing that the owner is active. Since I will have to repeat this step with action type and action detail, I will remove the data and go with a lighter model. The total number of columns will still be under 10000 regardless and is a small fraction of the number of rows, but since these long tailed actions seem more host centric than user centric, I will move forward in removing them. ","metadata":{}},{"cell_type":"code","source":"sessions.groupby([\"id\"])[\"action_detail\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advc = sessions.action_detail.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advc[advc<10000].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advc[advc<1000].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advc[advc<200].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nSimilarly the cut off seems to be around 60. To err on caution, I will set the cut off to 70 for both. Then as mentioned in previous takeaways I will get the counts of each category as a variable for each id. ","metadata":{}},{"cell_type":"code","source":"vc[vc < 70].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advc[advc < 70].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sessions.loc[sessions.action_type == \"booking_response\", \"action_type\"] = None\nsessions.loc[sessions.action_type == \"-unknown-\", \"action_type\"] = None\n\nsessions.loc[sessions.action.isin(vc[vc < 70].index), \"action\"] = None\nsessions.loc[sessions.action == \"-unknown-\", \"action\"] = None\n\nsessions.loc[sessions.action_detail.isin(advc[advc < 70].index), \"action_detail\"] = None\nsessions.loc[sessions.action_detail == \"-unknown-\", \"action_detail\"] = None\n\nsessions.loc[sessions.device_type == \"-unknown-\", \"device_type\"] = None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for elem in sessions.columns: \n    print(sessions[elem].value_counts(), \"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nThose adjustments have been made. The final two steps would be to process seconds and then convert it into dataframe that can be added onto the original training data. Since the training data and the test data are in the same format, it will also be added to the test data to help predictions. \n\nTo process seconds, since it is ordinal and continuous, applyng a log transformation and then converting it into a range would be great to retain counts in a manageable format. To extract more information, I will create two variables for the average log time spent per event and the user's log standard deviation.","metadata":{}},{"cell_type":"code","source":"# 1 is added because ln(0) is not a value. \n# 172800 is 48 hours equivalent\nsessions.loc[sessions.secs_elapsed > 172800, \"secs_elapsed\"] = 172800\nsessions[\"log_seconds\"] = np.log(sessions.secs_elapsed + 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lsec_intervals = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\nsessions[\"seconds_range\"] = pd.cut(sessions.log_seconds, bins=lsec_intervals, right=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nGreat, now I need to run a groupby and build a dataframe with all previously mentioned information.\nPer id get all the counts of each of the categories and calculate two features from the 1sec_intervals","metadata":{}},{"cell_type":"code","source":"gb = sessions.groupby([\"id\"])\na_temp = gb[\"action\"].value_counts()\nat_temp = gb[\"action_type\"].value_counts()\nad_temp = gb[\"action_detail\"].value_counts()\ndt_temp = gb[\"device_type\"].value_counts()\nsr_temp = gb[\"seconds_range\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"action = a_temp.unstack().fillna(0).astype(int)\naction_type = at_temp.unstack().fillna(0).astype(int)\naction_detail = ad_temp.unstack().fillna(0).astype(int)\ndevice_type = dt_temp.unstack().fillna(0).astype(int)\nseconds_range = sr_temp.unstack().fillna(0).astype(int)\naction_type.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lmean = gb[\"log_seconds\"].mean()\nlmean.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstd = gb[\"log_seconds\"].std()\nlstd.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sess_join = pd.DataFrame(sessions.id.value_counts())\njoin_list = [action, action_type, action_detail, device_type, lmean, lstd, seconds_range]\njoin_list_name = [action, action_type, action_detail, device_type, lmean, lstd, seconds_range]\n\nfor i in range(len(join_list)): \n    sess_join = sess_join.join(join_list[i], rsuffix=join_list_name)\nsess_join.drop(\"id\", axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sess_join.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seconds_range.add_prefix(\"seconds_range_\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sess_join.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adv_dummies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.get_dummies(train.signup_flow.astype(str))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[train == \"-unknown-\"] = np.nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.gender.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Takeaways\nAll the data is prepared. I will take the data processing methods from this notebook into another notebook where I will focus on running a prediction method. \n\nI will use logistic regression, random forests, and XGboost. \nThe first two will be fairly explainable, and I am using XGboost because it was all the rage for kaggle several years ago. ","metadata":{}}]}