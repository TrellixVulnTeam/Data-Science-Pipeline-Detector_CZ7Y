{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt"},{"cell_type":"markdown","metadata":{},"source":"# Features"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# https://www.kaggle.com/satomacoto/airbnb-recruiting-new-user-bookings/script-0-1\n\n#Loading data\ndf_train_raw = pd.read_csv('../input/train_users_2.csv')\ndf_test = pd.read_csv('../input/test_users.csv')\nlabels = df_train_raw['country_destination'].values\ndf_train = df_train_raw.drop(['country_destination'], axis=1)\nid_test = df_test['id']\npiv_train = df_train.shape[0]\n#Creating a DataFrame with train+test data\ndf_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n#Removing id and date_first_booking\ndf_all = df_all.drop(['id', 'date_first_booking'], axis=1)\n#Filling nan\ndf_all = df_all.fillna(-1)\n\n#####Feature engineering#######\n#date_account_created\ndf_all.date_account_created = pd.to_datetime(df_all.date_account_created)\ndf_all['dac_year'] = df_all.date_account_created.apply(lambda x: x.year)\ndf_all['dac_month'] = df_all.date_account_created.apply(lambda x: x.month)\ndf_all['dac_day'] = df_all.date_account_created.apply(lambda x: x.day)\ndf_all['dac_weekday'] = df_all.date_account_created.apply(lambda x: x.weekday())\ndf_all['dac_week'] = df_all.date_account_created.apply(lambda x: x.week)\ndf_all['dac_log_elapsed'] = np.log((datetime.date(2016, 1, 1) - df_all.date_account_created).astype('timedelta64[D]'))\ndf_all = df_all.drop(['date_account_created'], axis=1)\n\n#timestamp_first_active\ndf_all.timestamp_first_active = pd.to_datetime(df_all.timestamp_first_active, format='%Y%m%d%H%M%S')\ndf_all['tfa_year'] = df_all.timestamp_first_active.apply(lambda x: x.year)\ndf_all['tfa_month'] = df_all.timestamp_first_active.apply(lambda x: x.month)\ndf_all['tfa_day'] = df_all.timestamp_first_active.apply(lambda x: x.day)\ndf_all['tfa_weekday'] = df_all.timestamp_first_active.apply(lambda x: x.weekday())\ndf_all['tfa_week'] = df_all.timestamp_first_active.apply(lambda x: x.week)\ndf_all['tfa_log_elapsed'] = np.log((datetime.date(2016, 1, 1) - df_all.timestamp_first_active).astype('timedelta64[D]'))\ndf_all = df_all.drop(['timestamp_first_active'], axis=1)\n\n#Age\nav = df_all.age.values\ndf_all['age'] = np.where(np.logical_or(av<14, av>90), -1, av)\ndf_all['age_year'] = np.where(av > 1900, -1, av)\n\n#One-hot-encoding features\nohe_feats = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel',\n             'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type',\n             'first_browser']\nfor f in ohe_feats:\n    df_all_dummy = pd.get_dummies(df_all[f], prefix=f)\n    df_all = df_all.drop([f], axis=1)\n    df_all = pd.concat((df_all, df_all_dummy), axis=1)\n\n#Splitting train and test\nvals = df_all.values\nX_train = vals[:piv_train]\nle = LabelEncoder()\ny_train = le.fit_transform(labels)\nX_test = vals[piv_train:]\n\n#Sampling\nnp.random.seed(42)\nsamples = np.random.choice(piv_train, 10000)\nX_train = vals[samples]\ny_train = le.fit_transform(labels)[samples]"},{"cell_type":"markdown","metadata":{},"source":"# Cross val score"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.model_selection import cross_val_score, cross_val_predict"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.dummy import DummyClassifier\nmodel = DummyClassifier('prior')\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"model = DummyClassifier('stratified')\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier()\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.ensemble import ExtraTreesClassifier\nmodel = RandomForestClassifier()\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.ensemble import GradientBoostingClassifier\nmodel = GradientBoostingClassifier()\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.svm import SVC\nmodel = SVC(kernel=\"linear\", C=0.025)\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"model = SVC(gamma=2, C=1)\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.neural_network import MLPClassifier\nmodel = MLPClassifier(hidden_layer_sizes=(10, 10))\ncross_val_score(model, X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#from xgboost.sklearn import XGBClassifier\n#model = XGBClassifier()\n#cross_val_score(model, X_train, y_train)"},{"cell_type":"markdown","metadata":{},"source":"# Try voting classifier\n\n- http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier\n- cf. [KAGGLE ENSEMBLING GUIDE](http://mlwave.com/kaggle-ensembling-guide/)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.ensemble import VotingClassifier\n\nclf1 = LogisticRegression(random_state=1)\nclf2 = RandomForestClassifier(random_state=1)\nclf3 = GradientBoostingClassifier(random_state=1)\n\neclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gb', clf3)], voting='soft')\n\nfor clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'Gradient Boosting', 'Ensemble']):\n    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}