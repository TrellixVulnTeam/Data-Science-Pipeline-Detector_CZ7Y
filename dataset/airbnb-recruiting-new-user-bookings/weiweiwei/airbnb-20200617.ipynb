{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **1. Data Explotary**\n# **2. Data Preparation**\n            * Missing Values\n            * One Hot Encoding\n            * LabelEncode Goal Data\n# **3. Modeling**\n            * Optimize module\n            * Feature Importance\n            * ExPORT Result","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Explotary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/airbnb-recruiting-new-user-bookings/train_users_2.csv.zip\")\ntest = pd.read_csv(\"/kaggle/input/airbnb-recruiting-new-user-bookings/test_users.csv.zip\")\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Before doing anything, let's get all the dates to date type\ndataset = pd.concat([train, test])\ndataset['date_account_created'] = pd.to_datetime(dataset['date_account_created'])\ndataset['timestamp_first_active'] = pd.to_datetime(dataset['timestamp_first_active'].astype('object'), format='%Y%m%d%H%M%S')\ndataset['date_first_booking'] = pd.to_datetime(dataset['date_first_booking'])\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(dataset['age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* we can see that there are many outliers which are alive longer than turtles, removing them is next step","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['signup_flow'] = dataset['signup_flow'].astype('object')\nobj = []\nfor col in dataset.drop(columns='id').columns:\n    if dataset[col].dtype == 'object':\n        obj.append(col)\nlen(obj)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 18))\nfor i, c in enumerate(obj):\n    plt.subplot(4,3,i+1)\n    sns.countplot(dataset[c])\n    plt.xticks(rotation=60)\nplt.tight_layout()    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Some of the charts have less than 6 categories, they can be transformed by get_dummies directly\n* Some of the charts have too many categories, further process is needed","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Missing Values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data = dataset.isnull().sum().sort_values(ascending=False)\nmissing_percent = missing_data/len(dataset)\npd.DataFrame({'Count': missing_data, 'Percent': missing_percent})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Too many missing values in \"date_first_booking\"\ndataset = dataset.drop(columns= ['date_first_booking', 'id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate year, month, day from date columns\n\ndataset['year_account_created'] = pd.DatetimeIndex(dataset['date_account_created']).year\ndataset['month_account_created'] = pd.DatetimeIndex(dataset['date_account_created']).month\ndataset['day_account_created'] = pd.DatetimeIndex(dataset['date_account_created']).day\ndataset['year_first_active'] = pd.DatetimeIndex(dataset['timestamp_first_active']).year\ndataset['month_first_active'] = pd.DatetimeIndex(dataset['timestamp_first_active']).month\ndataset['day_first_active'] = pd.DatetimeIndex(dataset['timestamp_first_active']).day\ndataset['hour_first_active'] = pd.DatetimeIndex(dataset['timestamp_first_active']).hour\ndataset['minute_first_active'] = pd.DatetimeIndex(dataset['timestamp_first_active']).minute\n# dataset['year_first_booking'] = pd.DatetimeIndex(dataset['date_first_booking']).year\n# dataset['month_first_booking'] = pd.DatetimeIndex(dataset['date_first_booking']).month\n# dataset['day_first_booking'] = pd.DatetimeIndex(dataset['date_first_booking']).day\ndataset = dataset.drop(columns=['date_account_created', 'timestamp_first_active'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"country destination\" is the target, the missing data is all from test \n# only age and first_affiliate_tracked need to be addressed(as well as the info seperated from \"first booking\")\n# before dealing with age, remember we found that there were some outliers so let's remove/modify the outliers first","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_values = dataset['age'].values\ndataset['age'] = np.where(np.logical_or(age_values>14, age_values<90), age_values, -1)\ndataset['first_affiliate_tracked'] = dataset['first_affiliate_tracked'].fillna(dataset['first_affiliate_tracked'].mode()[0])\n# dataset.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**One Hot Encoding**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dummy = pd.get_dummies(dataset.drop(columns='country_destination'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = data_dummy[:len(train)]\ny = train['country_destination']\ndf_test = data_dummy[len(train):]\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Label Encode y**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ny = le.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom xgboost import XGBClassifier, plot_importance\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import learning_curve\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* At the very beginning, I wanted to use different modules to get the best one or ones, but the goal has too many classifications which makes my intention hard to accomplish.\n* So I chose xgboost which is able to cross validate and train multiâ€”classification data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(df_train, y)\nparams = {\n    'objective': 'multi:softprob',              # So beneficial to multi classifications\n    'max_depth': 6,\n    'eval_metric': 'merror',                    # Multiclass classification error rate. It is calculated as #(wrong cases)/#(all cases)\n    'learning_rate': 0.3,                       # https://xgboost.readthedocs.io/en/latest/parameter.html this link includes all the params and the options\n    'colsample_bytree': 0.3,                    # of each params\n    'subsample': 0.5,\n    'num_class': len(pd.Series(y).value_counts().index)\n}\nres = xgb.cv(params, dtrain, num_boost_round=50, nfold=5, early_stopping_rounds=1, verbose_eval=1, show_stdv=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.train(dtrain=dtrain, params=params, num_boost_round=res['test-merror-mean'].idxmin())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Importance**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_importance(clf, max_num_features=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Export Result**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtest = xgb.DMatrix(df_test)\ny_pred = clf.predict(dtest)\nids = []\npred = []\nfor i in range(len(test)):\n    ids += [test['id'][i]]*5\n    pred += list(le.inverse_transform(y_pred[i].argsort()[::-1][:5]))\nsub = pd.DataFrame({'id': ids, 'country': pred})\nsub.to_csv('sub.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}