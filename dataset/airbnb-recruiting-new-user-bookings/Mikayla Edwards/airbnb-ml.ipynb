{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this analysis, I will try different feature engineering and modeling approaches to predict the destination a user will book on AirBnb. Because there a multiple country destinations represented in the dataset, this is a multi-class classification problem. \n\nI was interested in this AirBnb problem because it presents an unbalanced class-representation problem: a large majority of the outcome variable is concentrated in two classes, with NDF and the US representing 58% and 29% respectively. Furthermore, the problem also includes an additional dataset (sessions) which contains additional information about user behavior on the site. I thought it would be interesting to engineer features from this data to see if it could improve the performance of a model to predict user booking destinations. \n\nTo solve the unbalanced problem, I test various ensemble classifiers and hyperparameter configurations. In particular, I compare a boosted ensemble approach (using AdaBoost) with an averaging approach (using ExtraTrees). I also engineer features from the sessions data to measure performance gains. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport warnings\nfrom tabulate import tabulate\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below I read in two dataframe: \n\n1. train_users is the dataset with information about users and the outcome variable ('country_destination')\n2. sessions is a transactional dataset with entries for user behavior on the site (e.g. clicks, searches, etc.)\n\nI will first try modeling with just the train_users data to see if country_destination can be predicted based on user attributes. Then, I will do additional feature engineering on the sessions data to see if including this information improves model performance. For example, does knowing how many times a user searched on the site increase the liklihood of correctly predicting his or her ultimate destination choice? "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_users = pd.read_csv('/kaggle/input/airbnb-recruiting-new-user-bookings/train_users_2.csv.zip')\nsessions=pd.read_csv('/kaggle/input/airbnb-recruiting-new-user-bookings/sessions.csv.zip')\ntrain_users.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will use scikit pipelines to build a pre-processing and classification pipeline to make predictions. Before starting with scikit pipelines, it is first useful to look at the datatypes of predictor variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_users.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I need to remove the id column and outcome variable from the dataset. Also, I need to split it into a train & test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef get_split(df):\n    X = df.drop(columns=['country_destination', 'id'])\n    y = df['country_destination']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    return(X_train,X_test,y_train,y_test)\n\nX_train,X_test,y_train,y_test=get_split(train_users)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the scikit pre-processing pipeline, I will have a separate procedure for numeric and categorical column/feature types. Therefore, below I will create a list of the column names for each type."},{"metadata":{"trusted":true},"cell_type":"code","source":"#get columns by type\ndef get_coltypes(df):\n    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n    categorical_features = df.select_dtypes(include=['object']).columns\n    return numeric_features,categorical_features\n\nnumeric_features,categorical_features=get_coltypes(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scikit Pipeline  \n1. First, I will define a transformer for each column type (numeric/categorical. \n2. Then, I will put them together into a preprocessing object and specify the columns captured above to which the transformers should be applied."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n#define transformers as pipeline\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the pre-processing part of the pipeline defined, now I will add the classification step. \n1. First, I define two classifiers I want to compare. Here I use AdaBoost and ExtraTrees classifiers.\n2. For each classifier, I apply the pipeline: pre-processing and fitting the classifier. Then the model is scored on the test data. \n\nHere I will compare an AdaBoost classifier with an ExtraTrees classifier. AdaBoost is a \"meta-estimator\" that initially fits a \"base\" classifier (here a decision tree) on the original dataset and then fits additional copies of the classifier on the same dataset but adjusts weights of incorrect classifications to target these more difficult cases.\n\nExtraTrees (from sklearn.ensemble) is also a \"meta-estimator\" that fits randomized decision trees (\"extra-trees\") on sub-samples of the dataset and then uses averaging to "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.ensemble import AdaBoostClassifier,ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# classifiers = [\n#     AdaBoostClassifier(),\n#     ExtraTreesClassifier()\n#     ]\n\ndef make_preds(classifier):\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('classifier', classifier)])\n    model=pipe.fit(X_train, y_train)\n    print(classifier)\n    print(\"model score: \",pipe.score(X_test, y_test))\n    y_pred = pipe.predict(X_test)\n    return model,y_pred\n\nada_model,ada_pred=make_preds(AdaBoostClassifier())\net_model,et_pred=make_preds(ExtraTreesClassifier())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below I will write a function to compare the distribution of predictions produced by each model above to the actual distribution of the outcome variable (country destination) in the dataset. \nIt first gets the value counts of each country in the original and predicted datasets. It then adds % columns. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def compare_preds(y_pred):\n    preds_df = pd.DataFrame(data = y_pred, columns = ['y_pred'], index = X_test.index.copy())\n    df_out = pd.merge(y_test, preds_df, how = 'left', left_index = True, right_index = True)\n    preds_summary=df_out.apply(pd.Series.value_counts).fillna(0)\n    preds_summary['cdest_pct'] = preds_summary.country_destination / preds_summary.country_destination.sum()\n    preds_summary['predicted_pct'] = preds_summary.y_pred / preds_summary.y_pred.sum()\n    return preds_summary.reset_index().sort_values('country_destination',ascending=False)\n\nada_preds_df=compare_preds(ada_pred)\net_preds_df=compare_preds(et_pred)\n\nada_preds_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above we can see that AdaBoost only ever predicts NDF or US as destinations. The percent of predictions for NDF is roughly the same as in the dataset but the US is over-predicted. \n\nBelow I gather variables for plotting with ggplot..(the one part of R I can't give up)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_plot=pd.melt(ada_preds_df,id_vars=['index'], value_vars=['country_destination','y_pred','cdest_pct','predicted_pct'])\nada_plot=ada_plot[ada_plot['variable'].str.contains(\"pct\")]\n\net_plot=pd.melt(et_preds_df,id_vars=['index'], value_vars=['country_destination','y_pred','cdest_pct','predicted_pct'])\net_plot=et_plot[et_plot['variable'].str.contains(\"pct\")]\n\nada_plot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotnine import *\n\n(ggplot(ada_plot)+\n    aes(x='index',y='value')+\n    geom_col()+\n    facet_wrap('variable')+\n    xlab(\"country\")+\n    ylab(\"percent\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(et_preds_df)\n(ggplot(et_plot)+\n    aes(x='index',y='value')+\n    geom_col()+\n    facet_wrap('variable')+\n    xlab(\"country\")+\n    ylab(\"percent\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly, although the Extra Trees classifier was less accurate overall, it does have some predictions for all classes and more closely resembles the distribution of the outcome variable in the orginal dataset. \n\nSo why does the extra trees classifier have predictions for each class while AdaBoost does not? According to the scikit learn [documentation](https://scikit-learn.org/stable/modules/ensemble.html#forest), ExtraTrees (like RandomForest) is a \"perturb-and-combine technique\" specifically designed for trees, which means a diverse set of classifiers is created by introducing randomness in the classifier construction. The prediction of the ExtraTrees ensemble is then constructed as the averaged prediction of the individual classifiers."},{"metadata":{},"cell_type":"markdown","source":"Additional Feature Engineering from sessions data\n\nCan adding additional features from user sessions history improve performance?"},{"metadata":{"trusted":true},"cell_type":"code","source":"#base new features\nsess_feat = sessions.loc[ : , ['user_id', 'secs_elapsed','action']] \\\n    .groupby('user_id')\\\n    . agg(total_secs=('secs_elapsed', 'sum'),\n          total_actions=('action', 'count'))\n\nsess_feat.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I will get the get the top 10 actions and append a count of each action for each user"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get top 10 actions\ntop_actions=sessions \\\n    .groupby('action')\\\n    .count().sort_values('user_id',ascending=False).nlargest(10,'action_type').reset_index()\nprint(top_actions['action'])\n\n\nsessions=sessions.loc[sessions['action'].isin(top_actions['action'])]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gets count of each user,action pair and counts--> pivots to wide w/unstack\nuser_actions=sessions.groupby(['user_id', 'action']) \\\n        .size().unstack('action',fill_value=0).reset_index()\n        \n\nuser_actions=user_actions.drop(columns=['index'],axis=1)\n\nuser_actions.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Joining additional features (user_actions) back to train_users..\nTwo-part join: \n1. First join to get all user ids in train users in user_actions. Fill missing users with 0, as they have not completed the actions."},{"metadata":{"trusted":true},"cell_type":"code","source":"user_actions=train_users[['id']].merge(user_actions,right_on=\"user_id\",left_on=\"id\",how=\"left\").fillna(0)\n\nuser_actions=user_actions.drop('user_id',axis=1)\n\n# add session features to user_actions\nuser_actions=user_actions.merge(sess_feat,left_on=\"id\",right_on=\"user_id\",how=\"left\").fillna(0)\n\nuser_actions.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for all users..."},{"metadata":{"trusted":true},"cell_type":"code","source":"assert user_actions['id'].nunique() == train_users['id'].nunique(), \"Uh oh..\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Then join again to update train users to contain the additional features in user_actions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#join to train df\ntrain_users=train_users \\\n    .merge(user_actions,on=\"id\",how=\"left\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that I have a \"new\" dataset with additional features, I have to re-implement the pre-processing and classification on the new train_users df. Luckily I have a convenient pipeline!! I can just call the functions/steps I defined above. \n1. First update X_train, X_test, etc. to reflect additional features added\n2. Then get new list of column names by type\n3. Then apply pipeline to updated data and column types\n\nI will again use AdaBoost and ExtraTrees to see if there is any improvement. However, since AdaBoost only predicted two classes using the default parameters, I will tune the parameters to add additional estimators."},{"metadata":{"trusted":true},"cell_type":"code","source":"#1\nX_train,X_test,y_train,y_test=get_split(train_users)\n\n#2\nnumeric_features,categorical_features=get_coltypes(X_train)\n\n#3\nada_model,ada_pred=make_preds(AdaBoostClassifier(n_estimators=100))\net_model,et_pred=make_preds(ExtraTreesClassifier())\n\n#preds summary df (see above)\nada_preds_df=compare_preds(ada_pred)\net_preds_df=compare_preds(et_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Count number of rows with each unique value of outcome variable (destination)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, ada_pred))\nprint(classification_report(y_test, et_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Importance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"headers = [\"name\", \"score\"]\nada_values = sorted(zip(X_train.columns, ada_model['classifier'].feature_importances_), key=lambda x: x[1] * -1)\net_values=sorted(zip(X_train.columns, et_model['classifier'].feature_importances_), key=lambda x: x[1] * -1)\n\nprint(tabulate(ada_values, headers, tablefmt=\"plain\"))\nprint(tabulate(et_values, headers, tablefmt=\"plain\"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}