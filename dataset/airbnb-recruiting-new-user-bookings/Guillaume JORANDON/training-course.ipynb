{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e964f12-39c8-8c84-63d4-6dde39aa9b5a"},"outputs":[],"source":"import os\n\nimport numpy as np\nimport pandas as pd # Ã§a c'est vraiment..."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9b7d4130-cdbd-a71b-071a-af1a43480b15"},"outputs":[],"source":"df_train = pd.read_csv(\"../input/train_users_2.csv\")\ndf_train.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54690106-e5e3-174f-1dcf-401b834d7c77"},"outputs":[],"source":"df_test = pd.read_csv(\"../input/test_users.csv\")\ndf_test.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f98851a0-5968-bfd9-8c60-d43f18115f5c"},"outputs":[],"source":"df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\ndf_all.head(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cdeeffe6-c9c3-0b05-a3fa-4a37b3969d0c"},"outputs":[],"source":"df_all.drop('date_first_booking', axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1dbdeace-e62e-c69c-d60c-0a0cbcc382b1"},"outputs":[],"source":"df_all.head(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"482e60f0-1c03-b685-86d3-c4c10430d2da"},"outputs":[],"source":"df_all['date_account_created'] = pd.to_datetime(df_all['date_account_created'], format='%Y-%m-%d')\ndf_all.head(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"daded5ad-3330-03fd-d562-913be653ba5f"},"outputs":[],"source":"df_all['timestamp_first_active'] = pd.to_datetime(df_all['timestamp_first_active'], format='%Y%m%d%H%M%S')\ndf_all.head(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ebd23c8-0099-1ff3-8eb9-0f7858d22398"},"outputs":[],"source":"def remove_age_outliers(x, min_value=15, max_value=90):\n    if np.logical_or(x<=min_value, x>=max_value):\n        return np.nan\n    else:\n        return x"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23dfdea1-669a-6870-e0dc-09d8eba9b531"},"outputs":[],"source":"df_all['age'] = df_all['age'].apply(lambda x: remove_age_outliers(x) if(not np.isnan(x)) else np.nan)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d70bcf0d-c38d-9f40-53e8-ead35bb977ce"},"outputs":[],"source":"df_all['age'].fillna(-1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1ee8add-121a-9c20-b8fd-2901583953fe"},"outputs":[],"source":"df_all.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7efd3918-996e-36b8-d3fa-e40a24c3d213"},"outputs":[],"source":"df_all.age = df_all.age.astype(int)\ndf_all.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df51910f-10e9-1caa-6df2-7f197979868a"},"outputs":[],"source":"def check_NaN_values_in_df(df):\n    for col in df:\n        nan_count = df[col].isnull().sum()\n        if nan_count != 0:\n            print(col + \" => \" + str(nan_count) + \" NaN value(s)\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa45e1cd-8f22-3086-7b9d-9d0f0c0aa218"},"outputs":[],"source":"check_NaN_values_in_df(df_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84e72a5a-578c-4721-8c66-3f5ad51002c1"},"outputs":[],"source":"df_all[\"first_affiliate_tracked\"].fillna(-1, inplace=True)\ncheck_NaN_values_in_df(df_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8eecd651-e325-179a-ccb9-3beeda0ad76b"},"outputs":[],"source":"df_all = df_all[df_all[\"date_account_created\"] > '2013-02-01']\ndf_all.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b178d2b5-c07f-b2f0-52df-1d19948c0c54"},"outputs":[],"source":"if not os.path.exists(\"output\"):\n    os.makedirs(\"output\")\n    \ndf_all.to_csv(\"output/cleaned.csv\", sep=\",\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ad46771-787a-45e5-ecf6-ba7bbc81b271"},"outputs":[],"source":"from datetime import datetime\nimport sklearn as sk\n\ndf_all = pd.read_csv(\n    \"output/cleaned.csv\", \n    dtype={\n        'country_destination': str\n    }\n)\n\n# We transform again the date column into datetime\ndf_all['date_account_created'] = pd.to_datetime(df_all['date_account_created'], format='%Y-%m-%d %H:%M:%S')\ndf_all['timestamp_first_active'] = pd.to_datetime(df_all['timestamp_first_active'], format='%Y-%m-%d %H:%M:%S')\n\n# Check for NaN Values => We must find: country_destination => 62096 NaN Values\ncheck_NaN_values_in_df(df_all) \n\ndf_all.sample(n=5) # Only display a few lines and not the whole dataframe"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99bccf10-b1d4-3953-a27b-18f249503c86"},"outputs":[],"source":"# Home made One Hot Encoding function\ndef convert_to_binary(df, column_to_convert):\n    categories = list(df[column_to_convert].drop_duplicates())\n\n    for category in categories:\n        cat_name = str(category).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\"-\", \"\").lower()\n        col_name = column_to_convert[:5] + '_' + cat_name[:10]\n        df[col_name] = 0\n        df.loc[(df[column_to_convert] == category), col_name] = 1\n\n    return df\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fe43aa6-7af6-4637-35d6-739b6cbae5f1"},"outputs":[],"source":"columns_to_convert = [\n    'gender', \n    'signup_method', \n    'signup_flow', \n    'language', \n    'affiliate_channel', \n    'affiliate_provider', \n    'first_affiliate_tracked', \n    'signup_app', \n    'first_device_type', \n    'first_browser'\n]\n\n# One Hot Encoding\nfor column in columns_to_convert:\n    df_all = convert_to_binary(df=df_all, column_to_convert=column)\n    df_all.drop(column, axis=1, inplace=True)\n    \ndf_all.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d5ad4f2-1618-25f0-06fc-9cf301da4c10"},"outputs":[],"source":"# Add new date related fields\ndf_all['day_account_created'] = df_all['date_account_created'].dt.weekday\ndf_all['month_account_created'] = df_all['date_account_created'].dt.month\ndf_all['quarter_account_created'] = df_all['date_account_created'].dt.quarter\ndf_all['year_account_created'] = df_all['date_account_created'].dt.year\ndf_all['hour_first_active'] = df_all['timestamp_first_active'].dt.hour\ndf_all['day_first_active'] = df_all['timestamp_first_active'].dt.weekday\ndf_all['month_first_active'] = df_all['timestamp_first_active'].dt.month\ndf_all['quarter_first_active'] = df_all['timestamp_first_active'].dt.quarter\ndf_all['year_first_active'] = df_all['timestamp_first_active'].dt.year\ndf_all['created_less_active'] = (df_all['date_account_created'] - df_all['timestamp_first_active']).dt.days\n\n# Drop unnecessary columns\ncolumns_to_drop = ['date_account_created', 'timestamp_first_active', 'date_first_booking', 'country_destination']\nfor column in columns_to_drop:\n    if column in df_all.columns:\n        df_all.drop(column, axis=1, inplace=True)\n\nprint (\"Dataframe Shape:\", df_all.shape)\ndf_all.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"41e21445-32c7-c37f-3827-0bbded6e63b6"},"outputs":[],"source":"df_sessions = pd.read_csv(\"../input/sessions.csv\")\nprint (\"DF Session Shape:\", df_sessions.shape)\ndf_sessions.head(n=5) # Only display a few lines and not the whole dataframe\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"35288947-933b-8d68-58e5-3fbb62e017e9"},"outputs":[],"source":"# Determine primary device\nsessions_device = df_sessions.loc[:, ['user_id', 'device_type', 'secs_elapsed']]\naggregated_lvl1 = sessions_device.groupby(['user_id', 'device_type'], as_index=False, sort=False).aggregate(np.sum)\nidx = aggregated_lvl1.groupby(['user_id'], sort=False)['secs_elapsed'].transform(max) == aggregated_lvl1['secs_elapsed']\ndf_primary = pd.DataFrame(aggregated_lvl1.loc[idx , ['user_id', 'device_type', 'secs_elapsed']])\ndf_primary.rename(columns = {'device_type':'primary_device', 'secs_elapsed':'primary_secs'}, inplace=True)\ndf_primary = convert_to_binary(df=df_primary, column_to_convert='primary_device')\ndf_primary.drop('primary_device', axis=1, inplace=True)\n\ndf_primary.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58811e82-76cd-9454-725b-d9b0ad2e9c62"},"outputs":[],"source":"# Determine Secondary device\nremaining = aggregated_lvl1.drop(aggregated_lvl1.index[idx])\nidx = remaining.groupby(['user_id'], sort=False)['secs_elapsed'].transform(max) == remaining['secs_elapsed']\ndf_secondary = pd.DataFrame(remaining.loc[idx , ['user_id', 'device_type', 'secs_elapsed']])\ndf_secondary.rename(columns = {'device_type':'secondary_device', 'secs_elapsed':'secondary_secs'}, inplace=True)\ndf_secondary = convert_to_binary(df=df_secondary, column_to_convert='secondary_device')\ndf_secondary.drop('secondary_device', axis=1, inplace=True)\n\ndf_secondary.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9d80c19-5486-f977-5955-d44b0bc64420"},"outputs":[],"source":"# Count occurrences of value in a column\ndef convert_to_counts(df, id_col, column_to_convert):\n    id_list = df[id_col].drop_duplicates()\n    \n    df_counts = df.loc[:,[id_col, column_to_convert]]\n    df_counts['count'] = 1\n    df_counts = df_counts.groupby(by=[id_col, column_to_convert], as_index=False, sort=False).sum()\n    \n    new_df = df_counts.pivot(index=id_col, columns=column_to_convert, values='count')\n    new_df = new_df.fillna(0)\n    \n    # Rename Columns\n    categories = list(df[column_to_convert].drop_duplicates())\n    for category in categories:\n        cat_name = str(category).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\"-\", \"\").lower()\n        col_name = column_to_convert + '_' + cat_name\n        new_df.rename(columns = {category:col_name}, inplace=True)\n        \n    return new_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de0b61a6-1686-ddaa-7d36-77e5972e5d0e"},"outputs":[],"source":"# Aggregate and combine actions taken columns\n\nsession_actions = df_sessions.loc[:,['user_id', 'action', 'action_type', 'action_detail']]\ncolumns_to_convert = ['action', 'action_type', 'action_detail']\n\nsession_actions = session_actions.fillna('not provided')\nfirst = True\n\nfor column in columns_to_convert:\n    print(\"Converting \" + column + \" column...\")\n    current_data = convert_to_counts(df=session_actions, id_col='user_id', column_to_convert=column)\n\n    # If first loop, current data becomes existing data, otherwise merge existing and current\n    if first:\n        first = False\n        actions_data = current_data\n    else:\n        actions_data = pd.concat([actions_data, current_data], axis=1, join='inner')\n        \nactions_data.sample(n=5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee0fa499-a341-7309-4aa6-1ad4511bb1ba"},"outputs":[],"source":"# Merge device datasets\ndf_primary.set_index('user_id', inplace=True)\ndf_secondary.set_index('user_id', inplace=True)\ndevice_data = pd.concat([df_primary, df_secondary], axis=1, join=\"outer\")\n\n# Merge device and actions datasets\ncombined_results = pd.concat([device_data, actions_data], axis=1, join='outer')\ndf_sessions = combined_results.fillna(0)\n\n# Merge user and session datasets\ndf_all.set_index('id', inplace=True)\ndf_all = pd.concat([df_all, df_sessions], axis=1, join='inner')\n\ndf_all.head(n=5)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}