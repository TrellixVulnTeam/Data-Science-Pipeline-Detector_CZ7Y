{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n\n# from keras.preprocessing.image import load_img\n\nimport keras.backend as K\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization\n\nfrom skimage.data import imread\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\n\n# Load truncated iamges https://www.kaggle.com/c/airbus-ship-detection/discussion/62574#latest-445141\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hide some the messy warning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_WIDTH = 768\nIMG_HEIGHT = 768\nIMG_CHANNELS = 3\nTARGET_WIDTH = 128\nTARGET_HEIGHT = 128\nepochs=2\nbatch_size=10\nimage_shape=(768, 768)\nFAST_RUN=True # use for development only\nFAST_PREDICTION=True # use for development only","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/train_ship_segmentations_v2.csv\")\nsub_df = pd.read_csv(\"../input/sample_submission_v2.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"508802845b0b1bbe9c8789b5d4b9c8335b8a2ac3"},"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\nno_mask = np.zeros(image_shape[0]*image_shape[1], dtype=np.uint8)\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    rle = ' '.join(str(x) for x in runs)\n    return rle\n\ndef rle_decode(mask_rle, shape=image_shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    if pd.isnull(mask_rle):\n        img = no_mask\n        return img.reshape(shape).T\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31ab2ddab1476fc41f1b122636c3f820cd98242f"},"cell_type":"markdown","source":"**Image With Ship**"},{"metadata":{"trusted":true,"_uuid":"4ae7c4fa062953837054218c79f735825a2c7fe2"},"cell_type":"code","source":"segmentation = df[df.EncodedPixels.notnull()].sample().iloc[0]\nimage = imread('../input/train_v2/'+segmentation.ImageId)\n\nfig=plt.figure(figsize=(16, 8))\nfig.add_subplot(2, 2, 1)\nplt.imshow(image)\nfig.add_subplot(2, 2, 2)\nplt.imshow(rle_decode(segmentation.EncodedPixels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6a93812b202d5f31328e6f3d343a98784557a45"},"cell_type":"markdown","source":"**Image without ship**"},{"metadata":{"trusted":true,"_uuid":"537d326d0712e8c2299b3a4b7225753ff96dc101"},"cell_type":"code","source":"segmentation = df[df.EncodedPixels.isnull()].sample().iloc[0]\nimage = imread('../input/train_v2/'+segmentation.ImageId)\n\nfig=plt.figure(figsize=(16, 8))\nfig.add_subplot(2, 2, 1)\nplt.imshow(image)\nfig.add_subplot(2, 2, 2)\nplt.imshow(rle_decode(segmentation.EncodedPixels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define U-Net Model"},{"metadata":{"trusted":true,"_uuid":"ab2a80002202ea2c25042045894d842eac668f9c"},"cell_type":"code","source":"inputs = Input((TARGET_WIDTH , TARGET_HEIGHT, IMG_CHANNELS))\n\n# 128\n\ndown1 = Conv2D(64, (3, 3), padding='same')(inputs)\ndown1 = BatchNormalization()(down1)\ndown1 = Activation('relu')(down1)\ndown1 = Conv2D(64, (3, 3), padding='same')(down1)\ndown1 = BatchNormalization()(down1)\ndown1 = Activation('relu')(down1)\ndown1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n# 64\n\ndown2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\ndown2 = BatchNormalization()(down2)\ndown2 = Activation('relu')(down2)\ndown2 = Conv2D(128, (3, 3), padding='same')(down2)\ndown2 = BatchNormalization()(down2)\ndown2 = Activation('relu')(down2)\ndown2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n# 32\n\ndown3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\ndown3 = BatchNormalization()(down3)\ndown3 = Activation('relu')(down3)\ndown3 = Conv2D(256, (3, 3), padding='same')(down3)\ndown3 = BatchNormalization()(down3)\ndown3 = Activation('relu')(down3)\ndown3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n# 16\n\ndown4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\ndown4 = BatchNormalization()(down4)\ndown4 = Activation('relu')(down4)\ndown4 = Conv2D(512, (3, 3), padding='same')(down4)\ndown4 = BatchNormalization()(down4)\ndown4 = Activation('relu')(down4)\ndown4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n# 8\n\ncenter = Conv2D(1024, (3, 3), padding='same')(down4_pool)\ncenter = BatchNormalization()(center)\ncenter = Activation('relu')(center)\ncenter = Conv2D(1024, (3, 3), padding='same')(center)\ncenter = BatchNormalization()(center)\ncenter = Activation('relu')(center)\n# center\n\nup4 = UpSampling2D((2, 2))(center)\nup4 = concatenate([down4, up4], axis=3)\nup4 = Conv2D(512, (3, 3), padding='same')(up4)\nup4 = BatchNormalization()(up4)\nup4 = Activation('relu')(up4)\nup4 = Conv2D(512, (3, 3), padding='same')(up4)\nup4 = BatchNormalization()(up4)\nup4 = Activation('relu')(up4)\nup4 = Conv2D(512, (3, 3), padding='same')(up4)\nup4 = BatchNormalization()(up4)\nup4 = Activation('relu')(up4)\n# 16\n\nup3 = UpSampling2D((2, 2))(up4)\nup3 = concatenate([down3, up3], axis=3)\nup3 = Conv2D(256, (3, 3), padding='same')(up3)\nup3 = BatchNormalization()(up3)\nup3 = Activation('relu')(up3)\nup3 = Conv2D(256, (3, 3), padding='same')(up3)\nup3 = BatchNormalization()(up3)\nup3 = Activation('relu')(up3)\nup3 = Conv2D(256, (3, 3), padding='same')(up3)\nup3 = BatchNormalization()(up3)\nup3 = Activation('relu')(up3)\n# 32\n\nup2 = UpSampling2D((2, 2))(up3)\nup2 = concatenate([down2, up2], axis=3)\nup2 = Conv2D(128, (3, 3), padding='same')(up2)\nup2 = BatchNormalization()(up2)\nup2 = Activation('relu')(up2)\nup2 = Conv2D(128, (3, 3), padding='same')(up2)\nup2 = BatchNormalization()(up2)\nup2 = Activation('relu')(up2)\nup2 = Conv2D(128, (3, 3), padding='same')(up2)\nup2 = BatchNormalization()(up2)\nup2 = Activation('relu')(up2)\n# 64\n\nup1 = UpSampling2D((2, 2))(up2)\nup1 = concatenate([down1, up1], axis=3)\nup1 = Conv2D(64, (3, 3), padding='same')(up1)\nup1 = BatchNormalization()(up1)\nup1 = Activation('relu')(up1)\nup1 = Conv2D(64, (3, 3), padding='same')(up1)\nup1 = BatchNormalization()(up1)\nup1 = Activation('relu')(up1)\nup1 = Conv2D(64, (3, 3), padding='same')(up1)\nup1 = BatchNormalization()(up1)\nup1 = Activation('relu')(up1)\n# 128\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid')(up1)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compile Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = tf.train.RMSPropOptimizer(0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=optimizer, \n    loss=\"binary_crossentropy\", \n    metrics=[\"accuracy\"]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a237a27bbda0942e217b4c0ea6396803d0c2d03"},"cell_type":"code","source":"# use for development to run it faster\nif FAST_RUN:\n    df = df.sample(n=1000).reset_index().drop(columns=[\"index\"]) # after reset index dataframe will have one more column call index\n    \nif FAST_PREDICTION:\n    sub_df = sub_df.sample(n=100).reset_index().drop(columns=[\"index\"]) # after reset index dataframe will have one more column call index\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split train and validate data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, validate_df = train_test_split(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image(image_name):\n    img = imread('../input/train_v2/'+image_name)[:,:,:IMG_CHANNELS]\n    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT), mode='constant', preserve_range=True)\n    return img\n    \ndef get_mask(code):\n    img = rle_decode(code)\n    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT, 1), mode='constant', preserve_range=True)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_image_generator(precess_batch_size, data_df):\n    while True:\n        for k, group_df in data_df.groupby(np.arange(data_df.shape[0])//precess_batch_size):\n            imgs = []\n            labels = []\n            for index, row in group_df.iterrows():\n                # images\n                original_img = get_image(row.ImageId) / 255.0\n                # masks\n                mask = get_mask(row.EncodedPixels) / 255.0\n                \n                imgs.append(original_img)\n                labels.append(mask)\n                \n            imgs = np.array(imgs)\n            labels = np.array(labels)\n            yield imgs, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = create_image_generator(batch_size, train_df)\nvalidate_generator = create_image_generator(batch_size, validate_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_steps=np.ceil(float(train_df.shape[0]) / float(batch_size)).astype(int)\nvalidate_steps=np.ceil(float(validate_df.shape[0]) / float(batch_size)).astype(int)\n\nhistory = model.fit_generator(\n    train_generator, \n    steps_per_epoch=train_steps,\n    validation_data=validate_generator,\n    validation_steps=validate_steps,\n    epochs=epochs\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_image(image_name):\n    img = imread('../input/test_v2/'+image_name)[:,:,:IMG_CHANNELS]\n    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT), mode='constant', preserve_range=True)\n    return img\n    \ndef create_test_generator(precess_batch_size):\n    while True:\n        for k, ix in sub_df.groupby(np.arange(sub_df.shape[0])//precess_batch_size):\n            imgs = []\n            labels = []\n            for index, row in ix.iterrows():\n                original_img = get_test_image(row.ImageId) / 255.0\n                imgs.append(original_img)\n                \n            imgs = np.array(imgs)\n            yield imgs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = create_test_generator(batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_steps = np.ceil(float(sub_df.shape[0]) / float(batch_size)).astype(int)\npredict_mask = model.predict_generator(test_generator, steps=test_steps)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# See our prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(16, 8))\nfor index, row in sub_df.head(6).iterrows():\n    origin_image = imread('../input/test_v2/'+row.ImageId)\n    predicted_image = resize(predict_mask[index], image_shape).reshape(IMG_WIDTH, IMG_HEIGHT) * 255\n    plt.subplot(3, 4, 2*index+1)\n    plt.imshow(origin_image)\n    plt.subplot(3, 4, 2*index+2)\n    plt.imshow(predicted_image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, row in sub_df.iterrows():\n    predict = predict_mask[index]\n    resized_predict =  resize(predict, (IMG_WIDTH, IMG_HEIGHT)) * 255\n    mask = resized_predict > 0.5\n    sub_df.at[index,'EncodedPixels'] = rle_encode(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Working in Progress"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}