{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preparar datos y librerias","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom skimage.measure import label\nfrom skimage.measure import regionprops\nimport imageio\nfrom skimage.color import rgb2gray\nimport random\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, ReLU, Conv2D, Dropout, MaxPooling2D, concatenate, UpSampling2D\nimport tensorflow.keras as keras\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Método creado por mi para poder mostrar más de dos historias\ndef multi_plot_compare(histories, names, title, field, legend_loc):\n    \"\"\"Compara losses de una lista de entrenamientos(histories) con nombres(names). Max 10\"\"\"\n    legend = []\n    for history, name, color in zip(histories, names, mcolors.TABLEAU_COLORS):\n        plt.plot(history.history[field], color=color)\n        plt.plot(history.history[f'val_{field}'], 'r--', color=color)\n        legend.append('Train ' + name)\n        legend.append('Val ' + name)\n    plt.title(title)\n    plt.ylabel(field)\n    plt.xlabel('Epoch')\n    plt.legend(legend,\n               loc=legend_loc)\n    plt.show()\n\ndef multi_plot_compare_losses(histories, names, title):\n    multi_plot_compare(histories, names, f'{title} losses', 'loss', 'upper right')\n    \ndef multi_plot_compare_accs(histories, names, title):\n    multi_plot_compare(histories, names, f'{title} accuracies', 'acc', 'lower right')\n\ndef multi_plot_compare_histories(histories, names, title):\n    multi_plot_compare_losses(histories, names, title)\n    multi_plot_compare_accs(histories, names, title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = f'/kaggle/input/airbus-ship-detection/'\nfor x in os.listdir(DATA_PATH):\n    print(x)\n    \nTRAINING_CSV = f'{DATA_PATH}/train_ship_segmentations_v2.csv'\nTRAINING_IMAGES_PATH = f'{DATA_PATH}/train_v2/'\nTEST_IMAGES_PATH = f'{DATA_PATH}/test_v2/'\n\n\nOUTPUT_PATH = f'/kaggle/output'\n\nPath(OUTPUT_PATH).mkdir(exist_ok=True)\nfor x in os.listdir(OUTPUT_PATH):\n    print(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AirbusImage(object):\n    images_path = TRAINING_IMAGES_PATH\n    def __init__(self, imageId, data):\n        self.imageId = imageId\n        self.image = None\n        image_data = data.loc[data['ImageId'] == self.imageId, 'EncodedPixels'].tolist()\n        self.flat_masks, self.masks, self.labels, self.boxes = self.__create_boats_data(image_data)\n\n    def __rle_decode_flatten(self, mask_rle):\n        shape=(768, 768)\n        s = mask_rle.split()\n        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n        starts -= 1\n        ends = starts + lengths\n        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n        for lo, hi in zip(starts, ends):\n            img[lo:hi] = 1\n        return img\n\n    def __rle_decode(self, mask_rle):\n        shape=(768, 768)\n        flat_mask = self.__rle_decode_flatten(mask_rle)\n        return flat_mask.reshape(shape).T\n\n    def __create_boats_data(self, data):\n        masks = []\n        flat_masks = []\n        labels = []\n        boxes = []\n        if data != [-1]:\n            for encoded_mask in data:\n                img_mask = self.__rle_decode(encoded_mask)\n                flat_masks.append(self.__rle_decode_flatten(encoded_mask))\n                masks.append(img_mask)\n                img_label = label(img_mask)\n                labels.append(img_label)\n                img_box = regionprops(img_label)[0].bbox\n                boxes.append(img_box)\n        return flat_masks, masks, labels, boxes\n\n    def get_image(self):\n        return imageio.imread(f'{TRAINING_IMAGES_PATH}/{self.imageId}')\n\n    def get_flat_grey_image(self):\n        gray_image = rgb2gray(imageio.imread(f'{TRAINING_IMAGES_PATH}/{self.imageId}'))\n        flat_gray_image = [item for sublist in gray_image for item in sublist]\n        return flat_gray_image\n    \n    def get_masks(self):\n        return self.masks\n\n    def get_united_masks(self):\n        united_mask = self.get_flat_united_mask()\n        united_mask = np.reshape(united_mask, (768, 768)).T\n        return united_mask\n    \n    def get_flat_masks(self):\n        return self.flat_masks\n\n    def get_flat_united_mask(self):\n        unite_mask = np.zeros(768 * 768, dtype=np.uint8)\n        for mask in self.flat_masks:\n            unite_mask += mask\n        return unite_mask\n    \n    def get_boxes(self):\n        return self.boxes\n\n    def get_labels(self):\n        return self.labels\n    \n    def get_height(self):\n        return 768\n    \n    def get_width(self):\n        return 768\n    \n    def get_encoded_jpg(self):\n        with tf.gfile.GFile(f'{TRAINING_IMAGES_PATH}/{self.imageId}', 'rb') as fid:\n            encoded_jpg = fid.read()\n        return encoded_jpg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.draw import rectangle_perimeter\n\ndata = pd.read_csv(TRAINING_CSV).fillna(-1)\nimage_name = 'c8b051d24.jpg'\nimage = AirbusImage(image_name, data)\n\nimg = image.get_image()\nmasks = image.get_masks()\n#print(masked_image.shape)\nunified_mask = np.zeros((img.shape[0], img.shape[1]))\nfor mask in masks:\n   unified_mask += mask\n\nprint(unified_mask.shape)\nprint(img.shape)\n\nmask2 = image.get_flat_united_mask()\nunique, counts = np.unique(mask2, return_counts=True)\nprint(dict(zip(unique, counts)))\nprint(mask2.shape)\nmask2 = np.reshape(mask2, (768, 768)).T\n\nfig=plt.figure(figsize=(20, 10))\nax = fig.add_subplot(1, 3, 1)\nplt.imshow(img)\nax = fig.add_subplot(1, 3, 2)\nplt.imshow(unified_mask)\nax = fig.add_subplot(1, 3, 3)\nplt.imshow(mask2)\nplt.show()\n\nplt.show()      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Red neuronal profunda","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataset_X_y(chosen_image, full_dataset):\n    # TODO instanciate as a tensor from the begining\n    X_data = []\n    y_data = []\n    c = 0\n    for index, image_id in chosen_image.items():\n        #print(image_id)\n        img_obj = AirbusImage(image_id, full_dataset)\n        X_data.append(tf.convert_to_tensor(img_obj.get_flat_grey_image(), dtype=tf.float32))\n        mask = img_obj.get_flat_united_mask()\n        y_data.append(tf.convert_to_tensor(mask, dtype=tf.bool))\n        c += 1\n        if c % 50 == 0:\n            print(c)\n    print('Converting to tensor')\n    X_data = tf.convert_to_tensor(X_data)\n    y_data = tf.convert_to_tensor(y_data)\n    y_data = keras.utils.to_categorical(y_data, 2)\n    print('End converting to tensor')\n    return X_data, y_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_data = pd.read_csv(TRAINING_CSV).dropna()\nimage_data = image_data.reset_index(drop=True)\n\nimages_name = image_data['ImageId']\nimages_name = images_name.drop_duplicates()\nimages_name = images_name.sample(frac=1) # shuffle\nprint(f'Original images with data {images_name.shape}')\n#print(images_name.head())\n#images_to_use, images_discarded = train_test_split(images_name, test_size=0.95)\nimages_to_use, images_discarded = train_test_split(images_name, test_size=0.9995)\nprint(f'After reducing the size {images_to_use.shape}')\ntrain_df, test_df = train_test_split(images_to_use, test_size=0.3)\nprint(f'Training data shape: {train_df.shape}')\nprint(f'Test data shape: {test_df.shape}')\n\nX_train, y_train = get_dataset_X_y(train_df, image_data)\nX_test, y_test = get_dataset_X_y(test_df, image_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()\nmodel.add(Input(shape=(768*768,)))\nmodel.add(Dense(128))\nmodel.add(ReLU(128))\nmodel.add(BatchNormalization())#model.add(layers.Dense(16))\nmodel.add(Dense(768*768))\nmodel.add(ReLU(128))\n#model.add(Conv2D(2, (1,) , padding='same'))\nmodel.compile(optimizer='adam',\n              #loss=keras.losses.binary_crossentropy,\n              loss=keras.losses.categorical_crossentropy,\n              #loss=keras.losses.sparse_categorical_crossentropy,\n              metrics = ['acc'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train,\n                    batch_size=64,\n                    epochs=3,#epochs=30,\n                    shuffle=True,\n                    callbacks = [keras.callbacks.EarlyStopping(patience=3)],\n                    #class_weight = {0: 0.1, 1: 0.9},\n                    #class_weight = {0: 0.11, 1: 0.89},\n                    validation_data=(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_plot_compare_histories([history],['Data'], 'Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = model.predict(np.array([X_test[2]]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_prediction(num_predictions):\n    print(f'Predictions of {num_predictions} images')\n    fig=plt.figure(figsize=(20, (num_predictions/6 * 25)))\n    for i in range(0, num_predictions):\n        image_num = random.randint(0,X_test.shape[0])\n        print(f'Preparing prediction {i+1}. Choosen image number {image_num}')\n        img = np.reshape(X_test[image_num], (768, 768))\n        \n        real_mask = np.reshape(y_test[image_num], (768, 768)).T\n        \n        prediction = model.predict(np.array([X_test[image_num]]))     \n        predicted_mask = np.reshape(prediction[0], (768, 768)).T\n        predicted_mask = predicted_mask > 0.5        \n        \n        ax = fig.add_subplot(num_predictions, 3, 1 + (i*3))\n        ax.axis('off')\n        plt.imshow(img)\n        ax = fig.add_subplot(num_predictions, 3, 2 + (i*3))\n        ax.axis('off')\n        plt.imshow(real_mask)\n        ax = fig.add_subplot(num_predictions, 3, 3 + (i*3))\n        ax.axis('off')\n        plt.imshow(predicted_mask)\n    plt.show()\n\nplot_prediction(10)\n    \n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}