{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Activation, AveragePooling2D, BatchNormalization, Concatenate\nfrom keras.layers import Conv2D, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, Lambda, MaxPooling2D\nfrom keras.layers import SeparableConv2D, DepthwiseConv2D\nfrom keras.layers import Add, Multiply, Reshape\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.utils.data_utils import get_file\nfrom keras import backend as K\n\nfrom keras.utils.generic_utils import get_custom_objects\n\n\ndef relu6(x):\n    # relu函数\n    return K.relu(x, max_value=6.0)\n\n\nget_custom_objects().update({'relu6': Activation(relu6)})\n\n\ndef hard_swish(x):\n    # 利用relu函数乘上x模拟sigmoid\n    return x * K.relu(x + 3.0, max_value=6.0) / 6.0\n\n\nget_custom_objects().update({'hard_swish': Activation(hard_swish)})\n\n\ndef return_activation(x, nl):\n    # 用于判断使用哪个激活函数\n    if nl == 'HS':\n        x = Activation(hard_swish)(x)\n    if nl == 'RE':\n        x = Activation(relu6)(x)\n    return x\n\n\ndef channel_split(x, name=''):\n    in_channels = x.shape.as_list()[-1]\n    ip = in_channels // 2\n    c_hat = Lambda(lambda z: z[:, :, :, 0:ip])(x)\n    c = Lambda(lambda z: z[:, :, :, ip:])(x)\n\n    return c_hat, c\n\n\ndef channel_shuffle(x):\n    height, width, channels = x.shape.as_list()[1:]\n    channels_per_split = channels // 2\n\n    x = K.reshape(x, [-1, height, width, 2, channels_per_split])\n    x = K.permute_dimensions(x, (0, 1, 2, 4, 3))\n    x = K.reshape(x, [-1, height, width, channels])\n\n    return x\n\n\ndef squeeze(inputs):\n    # 注意力机制单元\n    input_channels = int(inputs.shape[-1])\n\n    x = GlobalAveragePooling2D()(inputs)\n    x = Dense(int(input_channels / 4))(x)\n    x = Activation(relu6)(x)\n    x = Dense(input_channels)(x)\n    x = Activation(hard_swish)(x)\n    x = Reshape((1, 1, input_channels))(x)\n    x = Multiply()([inputs, x])\n\n    return x\n\n\ndef _shuffle_unit(inputs, out_channels, sq, nl, strides=2, stage=1, block=1):\n    bn_axis = -1  # 通道在后还是在前\n    prefix = 'stage%d/block%d' % (stage, block)\n\n    branch_channels = out_channels // 2\n\n    if strides == 2:\n        x_1 = DepthwiseConv2D(kernel_size=3, strides=2, padding='same',\n                              use_bias=False, name='%s/3x3dwconv_1' % prefix)(inputs)\n        x_1 = BatchNormalization(axis=bn_axis, name='%s/bn_3x3dwconv_1' % prefix)(x_1)\n        x_1 = Conv2D(filters=branch_channels, kernel_size=1, strides=1, padding='same',\n                     use_bias=False, name='%s/1x1conv_1' % prefix)(x_1)\n        x_1 = BatchNormalization(axis=bn_axis, name='%s/bn_1x1conv_1' % prefix)(x_1)\n        x_1 = Activation('relu6')(x_1)\n\n        x_2 = Conv2D(filters=branch_channels, kernel_size=1, strides=1, padding='same',\n                     use_bias=False, name='%s/1x1conv_2' % prefix)(inputs)\n        x_2 = BatchNormalization(axis=bn_axis, name='%s/bn_1x1conv_2' % prefix)(x_2)\n        x_2 = Activation('relu6')(x_2)\n        x_2 = DepthwiseConv2D(kernel_size=3, strides=2, padding='same',\n                              use_bias=False, name='%s/3x3dwconv_2' % prefix)(x_2)\n        x_2 = BatchNormalization(axis=bn_axis, name='%s/bn_3x3dwconv_2' % prefix)(x_2)\n        x_2 = Conv2D(filters=branch_channels, kernel_size=1, strides=1, padding='same',\n                     use_bias=False, name='%s/1x1conv_3' % prefix)(x_2)\n        x_2 = BatchNormalization(axis=bn_axis, name='%s/bn_1x1conv_3' % prefix)(x_2)\n        x_2 = Activation('relu6')(x_2)\n\n        x = Concatenate(axis=bn_axis, name='%s/concat' % prefix)([x_1, x_2])\n\n    if strides == 1:\n        c_hat, c = channel_split(inputs, name='%s/split' % prefix)\n\n        c = Conv2D(filters=branch_channels, kernel_size=1, strides=1, padding='same',\n                   use_bias=False, name='%s/1x1conv_4' % prefix)(c)\n        # c = BatchNormalization(axis=bn_axis, name='%s/bn_1x1conv_4' % prefix)(c)\n        # c = Activation('relu6')(c)\n        c = DepthwiseConv2D(kernel_size=3, strides=1, padding='same',\n                            use_bias=False, name='%s/3x3dwconv_3' % prefix)(c)\n        c = BatchNormalization(axis=bn_axis, name='%s/bn_3x3dwconv_3' % prefix)(c)\n        # c = Activation('relu6')(c)\n        c = return_activation(c, nl)\n        # 引入注意力机制\n        if sq:\n            c = squeeze(c)\n        # 下降通道数\n        c = Conv2D(filters=branch_channels, kernel_size=1, strides=1, padding='same',\n                   use_bias=False, name='%s/1x1conv_5' % prefix)(c)\n        c = BatchNormalization(axis=bn_axis, name='%s/bn_1x1conv_4' % prefix)(c)\n        x = Concatenate(axis=bn_axis, name='%s/concat' % prefix)([c_hat, c])\n\n    x = Lambda(channel_shuffle, name='%s/channel_shuffle' % prefix)(x)\n\n    return x\n\n\ndef exblock(inputs, out_channels, sq, stage=1, block=1):\n    prefix = 'stage%d/block%d' % (stage, block)\n\n    residual = Conv2D(out_channels, (1, 1), strides=(2, 2), padding='same', use_bias=False)(inputs)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(out_channels, (3, 3), padding='same', use_bias=False, name='%s/_sepconv1' % prefix)(inputs)\n    x = BatchNormalization(name='%s/_sepconv1_bn' % prefix)(x)\n    x = Activation('hard_swish', name='%s/_sepconv2_ac_hs' % prefix)(x)\n    x = SeparableConv2D(out_channels, (3, 3), padding='same', use_bias=False, name='%s/_sepconv2' % prefix)(x)\n    # 引入注意力机制\n    if sq:\n        x = squeeze(x)\n\n    x = BatchNormalization(name='%s/_sepconv2_bn' % prefix)(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='%s/_pool' % prefix)(x)\n    x = layers.add([x, residual])\n\n    return x\n\n\ndef inception_unit(inputs, channel1, channel2, channel3, ):\n    branch_0 = Conv2D(channel1, (1, 1), strides=(1, 1), padding='same', use_bias=False)(inputs)\n    branch_0 = BatchNormalization(axis=-1, scale=False, name='stage1X1_1BN')(branch_0)\n    branch_0 = Activation('relu6', name='stage1X1_1ac')(branch_0)\n\n    branch_1 = Conv2D(channel2, (3, 3), strides=(1, 1), padding='same', use_bias=False)(inputs)\n    branch_1 = BatchNormalization(axis=-1, scale=False, name='stage3X3_1BN')(branch_1)\n    branch_1 = Activation('relu6', name='stage3X3_1ac')(branch_1)\n\n    branch_pool = AveragePooling2D(3, strides=1, padding='same')(inputs)\n    branch_pool = Conv2D(channel3, (1, 1), strides=(1, 1), padding='same', use_bias=False)(branch_pool)\n    branch_pool = BatchNormalization(axis=-1, scale=False, name='stagep1X1_1BN')(branch_pool)\n    branch_pool = Activation('relu6', name='stagep1X1_1ac')(branch_pool)\n\n    branches = [branch_0, branch_1, branch_pool]\n\n    x = Concatenate(name='mixed_5b')(branches)\n\n    return x\n\n\ndef qzynetnew(input_shape=[256, 256, 3], classes=2,target=1):\n    input_shape = [256, 256, 3]\n\n    img_input = Input(shape=input_shape)\n\n    x = Conv2D(32, (3, 3), strides=(1, 1), padding='same', use_bias=False)(img_input)\n    x = BatchNormalization(axis=-1, scale=False, name='stage0.1X1_1BN')(x)\n    x = Activation('relu6', name='stage0.1X1_1ac')(x)\n    x = Conv2D(64, (3, 3), strides=(2, 2), padding='same', use_bias=False)(x)\n    x = BatchNormalization(axis=-1, scale=False, name='stage00.1X1_1BN')(x)\n    x = Activation('relu6', name='stage00.1X1_1ac')(x)\n    x = MaxPooling2D(3, strides=1,padding='same')(x)#2\n    #   x=_shuffle_unit(x, 128, sq=False, nl='RE',strides=1, stage=2, block=1)\n    #   x=_shuffle_unit(x, 128, sq=False, nl='RE',strides=1, stage=2, block=2)\n\n    #   x=_shuffle_unit(x, 128, sq=False, nl='RE',strides=2, stage=2, block=3)#128,128,128 -> 64 x 64 x 128\n\n    #   x=_shuffle_unit(x, 128, sq=False, nl='RE',strides=1, stage=2, block=4)\n    #   x=_shuffle_unit(x, 128, sq=False, nl='RE',strides=1, stage=2, block=5)\n    f1=x\n    x = exblock(x, 128, sq=True, stage=1, block=1)\n    f2=x\n\n    x = exblock(x, 192, sq=True, stage=1, block=2)\n    # x=_shuffle_unit(x, 256, sq=False, nl='RE',strides=2, stage=2, block=6)#64,64,128 -> 32 x 32 x 256\n    x = inception_unit(x, 116, 116, 24)\n    x = _shuffle_unit(x, 256, sq=False, nl='RE', strides=1, stage=2, block=7)\n    x = _shuffle_unit(x, 256, sq=False, nl='RE', strides=1, stage=2, block=8)\n    f3= x\n\n    x = _shuffle_unit(x, 512, sq=False, nl='RE', strides=2, stage=2, block=9)  # 32,32,256 -> 16 x 16 x 512\n\n    x = _shuffle_unit(x, 512, sq=False, nl='RE', strides=1, stage=2, block=10)\n    x = _shuffle_unit(x, 512, sq=False, nl='RE', strides=1, stage=2, block=11)\n    x = _shuffle_unit(x, 512, sq=False, nl='RE', strides=1, stage=2, block=12)\n    f4= x\n\n    x = _shuffle_unit(x, 1024, sq=False, nl='RE', strides=2, stage=2, block=13)  # 16 x 16 x 512 -> 8 x 8 x 1024\n\n    x = _shuffle_unit(x, 1024, sq=False, nl='RE', strides=1, stage=2, block=14)\n    f5= x\n\n    if target == 1:\n         x = GlobalAveragePooling2D(name='global_max_pool')(x)\n         x = Dense(classes, name='fc')(x)\n         x = Activation('softmax')(x)\n\n         inputs = img_input\n    # 创建模型\n         model = Model(inputs, x, name='qzynet')\n         return model\n\n    if target == 2:\n         return img_input, [f1, f2, f3, f4, f5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Activation, AveragePooling2D, BatchNormalization, Concatenate\nfrom keras.layers import Conv2D, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, Lambda, MaxPooling2D\nfrom keras.layers import SeparableConv2D, DepthwiseConv2D\nfrom keras.layers import Add, Multiply, Reshape\nfrom keras.layers import ZeroPadding2D, UpSampling2D, concatenate\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.utils.data_utils import get_file\nfrom keras import backend as K\n\n# from qzynetwork1 import qzynetnew\n\nIMAGE_ORDERING = 'channels_last'\nMERGE_AXIS = -1\n\ndef conv_block(tensor, num_filters, kernel_size, padding='same', strides=1, dilation_rate=1, w_init='he_normal'):\n    x = (Conv2D(filters=num_filters,\n                               kernel_size=kernel_size,\n                               padding=padding,\n                               strides=strides,\n                               dilation_rate=dilation_rate,\n                               kernel_initializer=w_init,\n                               use_bias=False))(tensor)\n    x = (BatchNormalization())(x)\n    x =  Activation('relu')(x)\n\n    return x\n\n\ndef sepconv_block(tensor, num_filters, kernel_size, padding='same', strides=1, dilation_rate=1, w_init='he_normal'):\n    x = (SeparableConv2D(filters=num_filters,\n                                        depth_multiplier=1,\n                                        kernel_size=kernel_size,\n                                        padding=padding,\n                                        strides=strides,\n                                        dilation_rate=dilation_rate,\n                                        depthwise_initializer=w_init,\n                                        use_bias=False))(tensor)\n    x =(BatchNormalization())(x)\n    x = Activation('relu')(x)\n    return x\n\n\n# def JPU(encoder=qzynetnew, out_channels=512):\n#     img_inputs, levels = encoder(input_shape=[256, 256, 3], classes=2,target=2)\n#     [f2, f3, f4, f5] = levels  # f5:8,f4:16,f3:32,f2:64\n#     #h=128\n#     #w=128\n#\n#     # yc = UpSampling2D(size=(2, 2), interpolation='bilinear')(yc)#得到128\n#     # for i in range(1, 4):\n#     #     levels[i] = conv_block(levels[i], out_channels, 3)\n#     #     if i != 1:\n#     #         h_t, w_t = levels[i].shape.as_list()[1:3]\n#     #         scale = (h // h_t, w // w_t)\n#     #         levels[i] = tf.keras.layers.UpSampling2D(\n#     #             size=scale, interpolation='bilinear')(levels[i])\n#     # yc = tf.keras.layers.Concatenate(axis=-1)(levels[1:])\n#     ym = []\n#     for rate in [1, 2]:\n#         ym.append(sepconv_block(yc, 512, 3, dilation_rate=rate))\n#     y = Concatenate(axis=-1)(ym)\n#\n#     y = conv_block(y, num_filters=128, kernel_size=1)\n#     # return  y\n#     model = Model(img_inputs,y,name='jpu')\n#\n#     return model\n\ndef _unet(n_classes=2, encoder=qzynetnew,  input_height=256, input_width=256):\n    img_input, levels = encoder(input_shape=[256, 256, 3], classes=2,target=2)\n    [f1, f2, f3, f4, f5] = levels#f5:8,f4:16,f3:32,f2:64\n\n    o = f5\n    # 8,8,512\n    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n    o = (Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n    o = (BatchNormalization())(o)\n\n    # 16,16,512\n    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n    # 16,16,768\n    o = (concatenate([o, f4], axis=MERGE_AXIS))\n    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n    # 16,16,256\n    o = (Conv2D(256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n    o = (BatchNormalization())(o)\n\n    # 32,32,256\n    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n    # 32,32,384\n    o = (concatenate([o, f3], axis=MERGE_AXIS))\n    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n    # 32,32,128\n    o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n    o = (BatchNormalization())(o)\n    # 64,64,64\n    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n\n    o = (concatenate([o, f2], axis=MERGE_AXIS))\n\n    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n    o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n    o = (BatchNormalization())(o)\n\n    f5 = conv_block(f5, 96, 3)#8\n    f4 = conv_block(f4, 64, 3)#16\n    f3 = conv_block(f3, 32, 3)#32\n    f5 = UpSampling2D(size=(8, 8))(f5)\n    f4 = UpSampling2D(size=(4, 4))(f4)\n    f3 = UpSampling2D(size=(2, 2))(f3)\n    yc = Concatenate(axis=-1)([f3,f4,f5])\n    ym = []\n    for rate in [1, 2]:\n        ym.append(sepconv_block(yc, 64, 3, dilation_rate=rate))\n    y = Concatenate(axis=-1)(ym)\n    y = conv_block(y, num_filters=64, kernel_size=1)\n\n    z = concatenate([o, y])\n    z = (Conv2D(64, (3, 3), padding='same'))(z)#得到64*64*32\n    z = (BatchNormalization())(z)\n\n    z = UpSampling2D(size=(2,2))(z)\n\n    \n    z = (concatenate([z, f1], axis=MERGE_AXIS))\n    z = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(z)\n    z = (Conv2D(32, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(z)\n    z = (BatchNormalization())(z)\n    z = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(z)\n    \n    z = (Conv2D(1, (1, 1), padding='same'))(z)\n    z = Activation('sigmoid')(z)\n    model = Model(input=img_input, output=z, name='jpu_unet')\n\n    return model\n\nseg_model =_unet()\nseg_model.load_weights(\"../input/qzy-tversky-40/seg_model_weights.best.hdf5\")\nseg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom matplotlib.cm import get_cmap\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.util import montage\nfrom skimage.morphology import binary_opening, disk, label\nimport gc; gc.enable()\n\ntest_image_dir='../input/airbus-ship-detection/test_v2'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nship_dir = '../input'\n\n\ndef multi_rle_encode(img, **kwargs):\n    '''\n    Encode connected regions as separated masks\n    '''\n    labels = label(img)\n    if img.ndim > 2:\n        return [rle_encode(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n    else:\n        return [rle_encode(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_encode(img, min_max_threshold=1e-3, max_mean_threshold=None):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    if np.max(img) < min_max_threshold:\n        return '' ## no need to encode if it's all zeros\n    if max_mean_threshold and np.mean(img) > max_mean_threshold:\n        return '' ## ignore overfilled mask\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list):\n    # Take the individual ship masks and create a single mask array for all ships\n    all_masks = np.zeros((768, 768), dtype = np.uint8)\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks |= rle_decode(mask)\n    return all_masks\n\ndef masks_as_color(in_mask_list):\n    # Take the individual ship masks and create a color mask array for each ships\n    all_masks = np.zeros((768, 768), dtype = np.float)\n    scale = lambda x: (len(in_mask_list)+x+1) / (len(in_mask_list)*2) ## scale the heatmap image to shift \n    for i,mask in enumerate(in_mask_list):\n        if isinstance(mask, str):\n            all_masks[:,:] += scale(i) * rle_decode(mask)\n    return all_masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np  \ntest_paths = np.array(os.listdir('../input/airbus-ship-detection/test_v2'))\nprint(len(test_paths), 'test images found')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SCALING=(3,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def raw_prediction(img, path=test_image_dir):\n    c_img = imread(os.path.join(path, c_img_name))\n    c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n    c_img = np.expand_dims(c_img, 0)/255.0\n    cur_seg = seg_model.predict(c_img)[0]\n    return cur_seg, c_img[0]\n\ndef smooth(cur_seg):\n    return binary_opening(cur_seg>0.99, np.expand_dims(disk(2), -1))\n\ndef predict(img, path=test_image_dir):\n    cur_seg, c_img = raw_prediction(img, path=path)\n    return smooth(cur_seg), c_img\n\nfrom tqdm import tqdm_notebook\n\ndef pred_encode(img, **kwargs):\n    cur_seg, _ = predict(img)\n    cur_rles = multi_rle_encode(cur_seg, **kwargs)\n    return [[img, rle] for rle in cur_rles if rle is not None]\n\nout_pred_rows = []\nfor c_img_name in tqdm_notebook(test_paths[:30000]): ## only a subset as it takes too long to run\n    out_pred_rows += pred_encode(c_img_name, min_max_threshold=1.0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd \n\nsub = pd.DataFrame(out_pred_rows)\nsub.columns = ['ImageId', 'EncodedPixels']\nsub = sub[sub.EncodedPixels.notnull()]\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TOP_PREDICTIONS=5\nfig, m_axs = plt.subplots(TOP_PREDICTIONS, 2, figsize = (9, TOP_PREDICTIONS*5))\n[c_ax.axis('off') for c_ax in m_axs.flatten()]\n\nfor (ax1, ax2), c_img_name in zip(m_axs, sub.ImageId.unique()[:TOP_PREDICTIONS]):\n    c_img = imread(os.path.join(test_image_dir, c_img_name))\n    c_img = np.expand_dims(c_img, 0)/255.0\n    ax1.imshow(c_img[0])\n    ax1.set_title('Image: ' + c_img_name)\n    ax2.imshow(masks_as_color(sub.query('ImageId==\"{}\"'.format(c_img_name))['EncodedPixels']))\n    ax2.set_title('Prediction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1 = pd.read_csv('../input/airbus-ship-detection/sample_submission_v2.csv')\nsub1 = pd.DataFrame(np.setdiff1d(sub1['ImageId'].unique(), sub['ImageId'].unique(), assume_unique=True), columns=['ImageId'])\nsub1['EncodedPixels'] = None\nprint(len(sub1), len(sub))\n\nsub = pd.concat([sub, sub1])\nprint(len(sub))\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}