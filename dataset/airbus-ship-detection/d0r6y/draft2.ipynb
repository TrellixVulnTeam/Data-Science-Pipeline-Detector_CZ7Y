{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Folder List\n\n!ls ../input/airbus-ship-detection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load necessary libraries\n\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n\n# from keras.preprocessing.image import load_img\n\nimport keras.backend as K\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization\n\n!pip install Pillow\n!pip install scipy==1.1.0\nfrom scipy.misc.pilutil import imread # 지금은 deprecated 되어 기존의 imread에서 scipy.misc.pilutil 의 imread 함수로 대체한다\nfrom skimage.transform import resize\n\nfrom sklearn.model_selection import train_test_split\n\n# Load truncated iamges https://www.kaggle.com/c/airbus-ship-detection/discussion/62574#latest-445141\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Variables\n\nIMG_WIDTH = 768\nIMG_HEIGHT = 768\nIMG_CHANNELS = 3\nTARGET_WIDTH = 128\nTARGET_HEIGHT = 128\nbatch_size=10\nimage_shape=(768, 768)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading masks (RLE Encoded)\n\nmasks = pd.read_csv(\"../input/airbus-ship-detection/train_ship_segmentations_v2.csv\")\nsub_masks = pd.read_csv(\"../input/airbus-ship-detection/sample_submission_v2.csv\") # for submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pre-defined Functions\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n\n# nomask -> default vector\nno_mask = np.zeros(image_shape[0]*image_shape[1], dtype=np.uint8)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    rle = ' '.join(str(x) for x in runs)\n    return rle\n\ndef rle_decode(mask_rle, shape=image_shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    if pd.isnull(mask_rle):\n        img = no_mask\n        return img.reshape(shape).T\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# file_name to image vector (for model input)\n\ndef get_image(image_name):\n    img = imread('../input/airbus-ship-detection/train_v2/'+image_name)[:,:,:IMG_CHANNELS]\n    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT), mode='constant', preserve_range=True)\n    return img\n\ndef get_test_image(image_name):\n    img = imread('../input/airbus-ship-detection/test_v2/'+image_name)[:,:,:IMG_CHANNELS]\n    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT), mode='constant', preserve_range=True)\n    return img\n    \n# RLE Code to Mask Vector\ndef get_mask(code):\n    img = rle_decode(code)\n    img = resize(img, (TARGET_WIDTH, TARGET_HEIGHT, 1), mode='constant', preserve_range=True)\n    return img\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# U-Net Building\n\ninputs = Input((TARGET_WIDTH , TARGET_HEIGHT, IMG_CHANNELS))\n\n# 128\n\ndown1 = Conv2D(64, (3, 3), padding='same')(inputs)\ndown1 = BatchNormalization()(down1)\ndown1 = Activation('relu')(down1)\ndown1 = Conv2D(64, (3, 3), padding='same')(down1)\ndown1 = BatchNormalization()(down1)\ndown1 = Activation('relu')(down1)\ndown1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n# 64\n\ndown2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\ndown2 = BatchNormalization()(down2)\ndown2 = Activation('relu')(down2)\ndown2 = Conv2D(128, (3, 3), padding='same')(down2)\ndown2 = BatchNormalization()(down2)\ndown2 = Activation('relu')(down2)\ndown2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n# 32\n\ndown3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\ndown3 = BatchNormalization()(down3)\ndown3 = Activation('relu')(down3)\ndown3 = Conv2D(256, (3, 3), padding='same')(down3)\ndown3 = BatchNormalization()(down3)\ndown3 = Activation('relu')(down3)\ndown3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n# 16\n\n\ncenter = Conv2D(512, (3, 3), padding='same')(down3_pool)\ncenter = BatchNormalization()(center)\ncenter = Activation('relu')(center)\ncenter = Conv2D(512, (3, 3), padding='same')(center)\ncenter = BatchNormalization()(center)\ncenter = Activation('relu')(center)\n# center\n\n\nup3 = UpSampling2D((2, 2))(center)\nup3 = concatenate([down3, up3], axis=3)\nup3 = Conv2D(256, (3, 3), padding='same')(up3)\nup3 = BatchNormalization()(up3)\nup3 = Activation('relu')(up3)\nup3 = Conv2D(256, (3, 3), padding='same')(up3)\nup3 = BatchNormalization()(up3)\nup3 = Activation('relu')(up3)\nup3 = Conv2D(256, (3, 3), padding='same')(up3)\nup3 = BatchNormalization()(up3)\nup3 = Activation('relu')(up3)\n# 32\n\nup2 = UpSampling2D((2, 2))(up3)\nup2 = concatenate([down2, up2], axis=3)\nup2 = Conv2D(128, (3, 3), padding='same')(up2)\nup2 = BatchNormalization()(up2)\nup2 = Activation('relu')(up2)\nup2 = Conv2D(128, (3, 3), padding='same')(up2)\nup2 = BatchNormalization()(up2)\nup2 = Activation('relu')(up2)\nup2 = Conv2D(128, (3, 3), padding='same')(up2)\nup2 = BatchNormalization()(up2)\nup2 = Activation('relu')(up2)\n# 64\n\nup1 = UpSampling2D((2, 2))(up2)\nup1 = concatenate([down1, up1], axis=3)\nup1 = Conv2D(64, (3, 3), padding='same')(up1)\nup1 = BatchNormalization()(up1)\nup1 = Activation('relu')(up1)\nup1 = Conv2D(64, (3, 3), padding='same')(up1)\nup1 = BatchNormalization()(up1)\nup1 = Activation('relu')(up1)\nup1 = Conv2D(64, (3, 3), padding='same')(up1)\nup1 = BatchNormalization()(up1)\nup1 = Activation('relu')(up1)\n# 128\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid')(up1)\n\nmodel = Model(inputs=inputs, outputs=outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data split for train, validate\n\ntrain_df, validate_df = train_test_split(masks) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile model\n\nfrom tensorflow.keras.optimizers import RMSprop\n\nopt = RMSprop(lr=0.0001, decay=1e-6)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=opt,\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# automating pre-processing process functions\n# Creating Generators\n\ndef create_image_generator(precess_batch_size, data_df):\n    while True:\n        for k, group_df in data_df.groupby(np.arange(data_df.shape[0])//precess_batch_size):\n            imgs = []\n            labels = []\n            for index, row in group_df.iterrows():\n                # images\n                original_img = get_image(row.ImageId) / 255.0\n                # masks\n                mask = get_mask(row.EncodedPixels) / 255.0\n                \n                imgs.append(original_img)\n                labels.append(mask)\n                \n            imgs = np.array(imgs)\n            labels = np.array(labels)\n            yield imgs, labels\n            \n            \ndef create_test_generator(precess_batch_size):\n    while True:\n        for k, ix in sub_masks.groupby(np.arange(sub_masks.shape[0])//precess_batch_size):\n            imgs = []\n            labels = []\n            for index, row in ix.iterrows():\n                original_img = get_test_image(row.ImageId) / 255.0\n                imgs.append(original_img)\n                \n            imgs = np.array(imgs)\n            yield imgs\n            \ntrain_generator = create_image_generator(batch_size, train_df)\nvalidate_generator = create_image_generator(batch_size, validate_df)\ntest_generator = create_test_generator(batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_steps=np.ceil(float(train_df.shape[0]) / float(batch_size)).astype(int) # np.ceil -> gausse function\nvalidate_steps=np.ceil(float(validate_df.shape[0]) / float(batch_size)).astype(int)\ntest_steps = np.ceil(float(sub_masks.shape[0]) / float(batch_size)).astype(int)\n\n# start model fitting\n\nhistory = model.fit_generator(\n    train_generator, \n    steps_per_epoch=train_steps,\n    validation_data=validate_generator,\n    validation_steps=validate_steps,\n    epochs=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Start Prediction\n\npredict_mask = model.predict_generator(test_generator, steps=test_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Submission\n\nfor index, row in sub_masks.iterrows():\n    predict = predict_mask[index]\n    resized_predict =  resize(predict, (IMG_WIDTH, IMG_HEIGHT)) * 255\n    mask = resized_predict > 0.5\n    sub_masks.at[index,'EncodedPixels'] = rle_encode(mask)\n    \nsub_masks.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}