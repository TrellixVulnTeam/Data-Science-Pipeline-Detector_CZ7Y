{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib as mpl","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:38.659403Z","iopub.execute_input":"2022-05-03T14:03:38.659749Z","iopub.status.idle":"2022-05-03T14:03:38.686651Z","shell.execute_reply.started":"2022-05-03T14:03:38.659666Z","shell.execute_reply":"2022-05-03T14:03:38.685965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set images to bigger size\nmpl.rcParams['figure.figsize'] = [6.0, 6.0]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:38.802955Z","iopub.execute_input":"2022-05-03T14:03:38.8037Z","iopub.status.idle":"2022-05-03T14:03:38.808167Z","shell.execute_reply.started":"2022-05-03T14:03:38.803615Z","shell.execute_reply":"2022-05-03T14:03:38.80741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/airbus-ship-detection/train_ship_segmentations_v2.csv\")\ndf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-03T14:03:40.471999Z","iopub.execute_input":"2022-05-03T14:03:40.472805Z","iopub.status.idle":"2022-05-03T14:03:41.4092Z","shell.execute_reply.started":"2022-05-03T14:03:40.472759Z","shell.execute_reply":"2022-05-03T14:03:41.408488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General info about dataset\n\nimport math\nfrom pprint import pprint\n\ndf[\"ShipPresent\"] = df.EncodedPixels.apply(type) != float\n\nprint(\"Empty images (no ships in frame)\", len(df.ShipPresent[df.ShipPresent == False]))\n\n# Drop empty images to reduce weight of dfset\n# df = df[ship_present]\n\nship_occurances = dict()\nfor name in df.ImageId:\n    ship_occurances[name] = ship_occurances.get(name, 0) + 1\n\nnumber_of_occurances = dict()\nfor num in ship_occurances.values():\n    number_of_occurances[num] = number_of_occurances.get(num, 0) + 1\n\nprint(f\"Number of ships in image: \")\npprint(number_of_occurances)  # Special print for dictionaries that sortes them by keys\n\nprint(f\"Average number of ships in image = {sum(ship_occurances.values()) / len(ship_occurances.values())}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:41.410609Z","iopub.execute_input":"2022-05-03T14:03:41.41101Z","iopub.status.idle":"2022-05-03T14:03:41.64034Z","shell.execute_reply.started":"2022-05-03T14:03:41.410973Z","shell.execute_reply":"2022-05-03T14:03:41.639522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:41.641761Z","iopub.execute_input":"2022-05-03T14:03:41.64209Z","iopub.status.idle":"2022-05-03T14:03:41.655003Z","shell.execute_reply.started":"2022-05-03T14:03:41.642045Z","shell.execute_reply":"2022-05-03T14:03:41.654096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test image from dfset\n\nimg = mpimg.imread(f'../input/airbus-ship-detection/train_v2/{df.ImageId[2]}')\nplt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:43.266727Z","iopub.execute_input":"2022-05-03T14:03:43.267171Z","iopub.status.idle":"2022-05-03T14:03:43.600126Z","shell.execute_reply.started":"2022-05-03T14:03:43.267136Z","shell.execute_reply":"2022-05-03T14:03:43.599487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    \n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n\n    return img.reshape(shape).T","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:44.332527Z","iopub.execute_input":"2022-05-03T14:03:44.3331Z","iopub.status.idle":"2022-05-03T14:03:44.339582Z","shell.execute_reply.started":"2022-05-03T14:03:44.333059Z","shell.execute_reply":"2022-05-03T14:03:44.338909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display ship\nmask = df[\"EncodedPixels\"][2]\n\nmask = rle_decode(mask, (768, 768))\nplt.imshow(mask)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:44.523372Z","iopub.execute_input":"2022-05-03T14:03:44.523968Z","iopub.status.idle":"2022-05-03T14:03:44.836417Z","shell.execute_reply.started":"2022-05-03T14:03:44.523934Z","shell.execute_reply":"2022-05-03T14:03:44.835746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import defaultdict\n\n\ndf = df.head(2000)  # Shorten dataset\n\ndsf = pd.DataFrame()\n\nnames = set()\ncontains_ship = dict()\nfor index, row in df.iterrows():\n    names.add(row.ImageId)\n    if row.ShipPresent:\n        contains_ship[row.ImageId] = True\n    else:\n        contains_ship[row.ImageId] = False\n\n        \nfor name in names:\n    dsf = dsf.append({'X': name, 'Y': contains_ship[name]}, ignore_index=True)\n    \n# dsf","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:44.838247Z","iopub.execute_input":"2022-05-03T14:03:44.838488Z","iopub.status.idle":"2022-05-03T14:03:48.062817Z","shell.execute_reply.started":"2022-05-03T14:03:44.838454Z","shell.execute_reply":"2022-05-03T14:03:48.061976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################################################################################################################################################\n##   Training classifier\n################################################################################################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:48.064494Z","iopub.execute_input":"2022-05-03T14:03:48.064755Z","iopub.status.idle":"2022-05-03T14:03:48.069291Z","shell.execute_reply.started":"2022-05-03T14:03:48.064719Z","shell.execute_reply":"2022-05-03T14:03:48.068584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mplcyberpunk","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:48.070605Z","iopub.execute_input":"2022-05-03T14:03:48.071055Z","iopub.status.idle":"2022-05-03T14:03:57.254885Z","shell.execute_reply.started":"2022-05-03T14:03:48.070993Z","shell.execute_reply":"2022-05-03T14:03:57.254037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom matplotlib import pyplot as plt\nfrom skimage import io, transform\nfrom sklearn.datasets import load_digits\nfrom torch import optim\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.utils import data\nimport numpy as np\nfrom IPython.display import clear_output\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom torch.nn import MSELoss\n\nfrom sklearn.metrics import accuracy_score\n\nimport mplcyberpunk","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:03:57.257663Z","iopub.execute_input":"2022-05-03T14:03:57.258154Z","iopub.status.idle":"2022-05-03T14:04:00.490226Z","shell.execute_reply.started":"2022-05-03T14:03:57.258104Z","shell.execute_reply":"2022-05-03T14:04:00.489496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, csv_file, root_dir, df):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.landmarks_frame = df\n        self.root_dir = root_dir\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.landmarks_frame)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])\n        x = io.imread(img_name)\n        \n        y = self.landmarks_frame.iloc[idx, 1:][0]\n        y = y.astype('int')\n        \n        norm = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(0.5, 0.5)\n        ])\n        \n#         print(type(x))\n#         print(type(norm(x)))\n\n        return norm(x), y","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:20:52.707288Z","iopub.execute_input":"2022-05-03T14:20:52.707543Z","iopub.status.idle":"2022-05-03T14:20:52.716916Z","shell.execute_reply.started":"2022-05-03T14:20:52.707505Z","shell.execute_reply":"2022-05-03T14:20:52.716062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataloader\nIMAGE_SIZE = 768\n\nds = ImageDataset(csv_file='../input/airbus-ship-detection/sample_submission_v2.csv', root_dir='../input/airbus-ship-detection/train_v2/', df=dsf)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:20:52.718406Z","iopub.execute_input":"2022-05-03T14:20:52.719825Z","iopub.status.idle":"2022-05-03T14:20:52.725477Z","shell.execute_reply.started":"2022-05-03T14:20:52.719784Z","shell.execute_reply":"2022-05-03T14:20:52.724836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\nBATCH_SIZE = 8\ntrain_len = int(len(ds) / 100 * 80)\n\nprint(len(ds))\n\n# Train/test split\nds_train, ds_test = random_split(ds, [train_len, len(ds) - train_len], generator=torch.Generator().manual_seed(1303))\n\ntrain_loader = DataLoader(ds_train, batch_size=BATCH_SIZE)\ntest_loader = DataLoader(ds_test, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:20:52.727564Z","iopub.execute_input":"2022-05-03T14:20:52.727963Z","iopub.status.idle":"2022-05-03T14:20:52.736853Z","shell.execute_reply.started":"2022-05-03T14:20:52.727926Z","shell.execute_reply":"2022-05-03T14:20:52.735879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n\nprint(len(train_loader))\nprint(len(test_loader))\n\n# Print first 5 images for testing purposes\nfor idx, batch in enumerate(train_loader):\n    if (idx > 2):\n        break\n    \n    x, y = batch\n    \n    img = x[0].permute(1, 2, 0).cpu().numpy() * 256\n\n    plt.imshow(img)\n\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:20:52.738288Z","iopub.execute_input":"2022-05-03T14:20:52.73857Z","iopub.status.idle":"2022-05-03T14:20:54.03385Z","shell.execute_reply.started":"2022-05-03T14:20:52.738535Z","shell.execute_reply":"2022-05-03T14:20:54.033089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"present, none = 0, 0\n\nfor x, y in train_loader:\n    for ans in y:\n        if ans == 1:\n            present += 1\n        else:\n            none += 1\n            \nprint(f\"Present ship in train: {present} / {present + none}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:20:54.035094Z","iopub.execute_input":"2022-05-03T14:20:54.035334Z","iopub.status.idle":"2022-05-03T14:21:20.784096Z","shell.execute_reply.started":"2022-05-03T14:20:54.035302Z","shell.execute_reply":"2022-05-03T14:21:20.783325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"present, none = 0, 0\n\nfor x, y in test_loader:\n    for ans in y:\n        if ans == 1:\n            present += 1\n        else:\n            none += 1\n            \nprint(f\"Present ship in test: {present} / {present + none}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:21:20.785525Z","iopub.execute_input":"2022-05-03T14:21:20.785794Z","iopub.status.idle":"2022-05-03T14:21:30.73803Z","shell.execute_reply.started":"2022-05-03T14:21:20.785758Z","shell.execute_reply":"2022-05-03T14:21:30.737293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classifier down below\n\nEPOCH_NUMBER = 15\n\nplt.style.use(\"cyberpunk\")\n\n\n# Net structure\nnet = nn.Sequential(\n    nn.Conv2d(3, 32, 3, stride=1, padding=1, padding_mode=\"circular\"),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    \n    nn.Conv2d(32, 64, 3, stride=1, padding=1, padding_mode=\"circular\"),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    \n    nn.Conv2d(64, 128, 3, stride=1, padding=1, padding_mode=\"circular\"),\n    nn.ReLU(),\n    nn.MaxPool2d(2),\n    \n    nn.Flatten(),\n    \n    nn.Linear(int(IMAGE_SIZE / 8) ** 2 * 128, 256),\n    nn.LeakyReLU(0.1),\n    \n    nn.Linear(256, 256),\n    nn.LeakyReLU(0.1),\n    \n    nn.Linear(256, 256),\n    nn.LeakyReLU(0.1),\n    nn.Linear(256, 2),\n    \n    nn.Sigmoid()\n).cuda()\n\n\nopt = optim.SGD(net.parameters(), lr=1e-1)\ncriterion = MSELoss()  # From now on error = criterion(pred, y)\n\n\ntrain_loss, test_loss = [], []\nfor epoch in range(EPOCH_NUMBER):\n    train_errors, train_accuracy = [], []\n    \n    for x, y in train_loader:\n#         x = x.permute(0, 3, 1, 2).float()\n        pred = net(x.cuda())\n        \n        y = F.one_hot(y, 2).to(torch.float32).cuda()\n        \n        err = criterion(pred, y)\n        err.backward()\n        \n        pred_conv = torch.argmax(pred, dim=1).detach().cpu().numpy()\n        y_conv = torch.argmax(y, dim=1).detach().cpu().numpy()\n        \n#         print(pred, pred_conv, y_conv)\n#         print()\n        \n        train_accuracy.append(accuracy_score(pred_conv, y_conv))\n        train_errors.append(err.item())\n        \n        opt.step()\n        opt.zero_grad()\n\n\n    test_errors, test_accuracy = [], []\n    for x, y in test_loader:\n#         x = x.permute(0, 3, 1, 2).float()\n        pred = net(x.cuda())\n        y = F.one_hot(y, 2).to(torch.float32).cuda()\n        \n        pred_conv = torch.argmax(pred, dim=1).detach().cpu().numpy()\n        y_conv = torch.argmax(y, dim=1).detach().cpu().numpy()\n\n        test_accuracy.append(accuracy_score(pred_conv, y_conv))\n        test_errors.append(err.item())\n        \n    \n    train_loss.append(sum(train_errors) / len(train_errors))\n    test_loss.append(sum(test_errors) / len(test_errors))\n    \n    # Output\n    clear_output(True)\n    \n    print(f'Epoch: {epoch} train: error: {sum(train_errors) / len(train_errors)}, accuracy: {sum(train_accuracy) / len(train_accuracy)}')\n    print(f'Epoch: {epoch} test: error: {sum(test_errors) / len(test_errors)}, accuracy: {sum(test_accuracy) / len(test_accuracy)}')\n    print()\n    \n    plt.plot(train_loss, label='train') \n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend()\n    plt.show()\n    \n    plt.plot(test_loss, label='test')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend()\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:54:40.648828Z","iopub.execute_input":"2022-05-03T14:54:40.649375Z","iopub.status.idle":"2022-05-03T15:11:19.627105Z","shell.execute_reply.started":"2022-05-03T14:54:40.649336Z","shell.execute_reply":"2022-05-03T15:11:19.626429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}