{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plot & image processing\nfrom skimage.morphology import label\nfrom skimage.data import imread\n\nimport os\nimport time\nimport sys\n\n# Configurations\n# Split x ratio of train dataset for validation \nTRAINING_VALIDATION_RATIO = 0.2\nWORKING_DIR = '/kaggle/working'\nINPUT_DIR = '../input/airbus-ship-detection'\nOUTPUT_DIR = '/kaggle/output'\nLOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\nTRAIN_DATA_PATH = os.path.join(INPUT_DIR, 'train_v2')\nTEST_DATA_PATH = os.path.join(INPUT_DIR, 'test_v2')\nSAMPLE_SUBMISSION_PATH = os.path.join(INPUT_DIR, 'sample_submission_v2.csv')\nTRAIN_SHIP_SEGMENTATIONS_PATH = os.path.join(INPUT_DIR, 'train_ship_segmentations_v2.csv')\nMASK_RCNN_PATH = os.path.join(WORKING_DIR, 'Mask_RCNN-master')\nCOCO_WEIGHTS_PATH = os.path.join(WORKING_DIR, \"mask_rcnn_coco.h5\")\nSHIP_CLASS_NAME = 'ship'\nIMAGE_WIDTH = 768\nIMAGE_HEIGHT = 768\nSHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n\ntest_ds = os.listdir(TEST_DATA_PATH)\ntrain_ds = os.listdir(TRAIN_DATA_PATH)\n\nprint('Working Dir:', WORKING_DIR, os.listdir(WORKING_DIR))\nprint('Input Dir:', INPUT_DIR, os.listdir(INPUT_DIR))\nprint('train dataset from: {}, {}'.format(TRAIN_DATA_PATH, len(train_ds)))\nprint('test dataset from: {}, {}'.format(TRAIN_DATA_PATH, len(test_ds)))\nprint(TRAIN_SHIP_SEGMENTATIONS_PATH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39020e0712387e8a2fc11ca92a93bb23e40d07d6"},"cell_type":"markdown","source":"# Preparing Dataset\n## Run-length mask encording"},{"metadata":{"trusted":true,"_uuid":"2bf4b1b2e24e9d212210d635f17a15eeb3e11dc0"},"cell_type":"code","source":"# if to clone Mask_R-CNN git when it exists \nUPDATE_MASK_RCNN = False\n\nos.chdir(WORKING_DIR)\nif UPDATE_MASK_RCNN:\n    !rm -rf {MASK_RCNN_PATH}\n\n# Downlaod Mask RCNN code to a local folder \nif not os.path.exists(MASK_RCNN_PATH):\n    ! wget https://github.com/samlin001/Mask_RCNN/archive/master.zip -O Mask_RCNN-master.zip\n    ! unzip Mask_RCNN-master.zip 'Mask_RCNN-master/mrcnn/*'\n    ! rm Mask_RCNN-master.zip\n\n# Import Mask RCNN\nsys.path.append(MASK_RCNN_PATH)  # To find local version of the library\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d65d5335db367f346c2b8c71859a102c2ca44884"},"cell_type":"code","source":"class AirbusShipDetectionChallengeGPUConfig(Config):\n    \"\"\"\n    Configuration of Airbus Ship Detection Challenge Dataset \n    Overrides values in the base Config class.\n    From https://github.com/samlin001/Mask_RCNN/blob/master/mrcnn/config.py\n    \"\"\"\n    # https://www.kaggle.com/docs/kernels#technical-specifications\n    NAME = 'ASDC_GPU'\n    # NUMBER OF GPUs to use.\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 2\n    \n    NUM_CLASSES = 2  # ship or background\n    IMAGE_MIN_DIM = IMAGE_WIDTH\n    IMAGE_MAX_DIM = IMAGE_WIDTH\n    STEPS_PER_EPOCH = 300\n    VALIDATION_STEPS = 50\n    SAVE_BEST_ONLY = True\n    \n    # Minimum probability value to accept a detected instance\n    # ROIs below this threshold are skipped\n    DETECTION_MIN_CONFIDENCE = 0.95\n\n    # Non-maximum suppression threshold for detection\n    # Keep it small to merge overlapping ROIs \n    DETECTION_NMS_THRESHOLD = 0.05\n\n    \nconfig = AirbusShipDetectionChallengeGPUConfig()\nconfig.display()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62d99adbb8c5b7eaf19b1f731acbb01f87b24553"},"cell_type":"code","source":"# import cv2\nfrom PIL import Image\nclass InferenceConfig(AirbusShipDetectionChallengeGPUConfig):\n    GPU_COUNT = 1\n    # 1 image for inference \n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\n# create a model in inference mode\ninfer_model = modellib.MaskRCNN(mode=\"inference\", \n                          config=inference_config,\n                          model_dir=WORKING_DIR)\n\nmodel_path = '../input/model-best/mask_rcnn_asdc_gpu_0017.h5'\n# print(model_path)\n# Load trained weights\nprint(\"Loading weights from \", model_path)\ninfer_model.load_weights(model_path, by_name=True)\ndef get_box(infer_model,image_path):\n    original_image = np.asarray(Image.open(image_path) )\n    results = infer_model.detect([original_image], verbose=1)\n    r = results[0]\n    return r['rois']\nprint(get_box(infer_model,'../input/teestthedata/16.png'))\n\n# Test on a random imag\n# Compute VOC-Style mean Average Precision @ IoU=0.5\n# Running on a few images. Increase for better accuracy.\n# image_ids = np.random.choice(dataset_val.image_ids, 20)\n# APs = []\n# inference_start = time.time()\n# for image_id in image_ids:\n#     # Load image and ground truth data\n#     image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n#         modellib.load_image_gt(dataset_val, inference_config,\n#                                image_id, use_mini_mask=False)\n#     molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n#     # Run object detection\n#     results = infer_model.detect([image], verbose=1)\n#     r = results[0]\n#     visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n#                             dataset_val.class_names, r['scores'])\n\n#     # Compute AP\n#     AP, precisions, recalls, overlaps =\\\n#         utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n#                          r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n#     APs.append(AP)\n\n# inference_end = time.time()\n# print('Inference Time: %0.2f Minutes'%((inference_end - inference_start)/60))\n# print(\"mAP: \", np.mean(APs))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}