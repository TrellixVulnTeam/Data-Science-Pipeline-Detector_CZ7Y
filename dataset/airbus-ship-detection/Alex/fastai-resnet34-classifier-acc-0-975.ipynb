{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Train a ship/no-ship classifier on Airbus Challenge dataset**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os \nimport numpy as np \nimport pandas as pd \nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom fastai.vision.models import *\nfrom fastai.callbacks.hooks import *\nfrom fastai.utils.mem import *\n\nimport torch \n\ndata_root = '../input/airbus-ship-detection/'\npath_train = os.path.join(data_root,'train_v2')\npath_test = os.path.join(data_root,'test_v2')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Get dataframe with label\nmasks = pd.read_csv(os.path.join(data_root, 'train_ship_segmentations_v2.csv'))\nmasks = masks[~masks['ImageId'].isin(['6384c3e78.jpg'])]  # remove corrupted image\n\ndf_clf = masks.groupby('ImageId').size().reset_index(name='counts')\ndf_clf = pd.merge(masks, df_clf)\ndf_clf['label'] = df_clf.apply(lambda c_row: 1 if isinstance(c_row['EncodedPixels'], str) else 0, 1)\ndf_clf = df_clf.drop(columns=['EncodedPixels','counts'])\n\n# Prepare data\ndef get_data(bs=64, size=256, split=0.2):\n   \n    tf = get_transforms(do_flip=True, flip_vert=False, max_rotate=30, max_zoom=0.1, max_lighting=0.1)\n\n    return (ImageList.from_df(df_clf, path=path_train)\n    .split_by_rand_pct(split)\n    .label_from_df(cols=1)\n    .transform(tf, size=size)\n    .add_test(vision.Path(path_test).ls())\n    .databunch(path=data_root, bs=bs)\n    .normalize(vision.imagenet_stats))\n            \ndata = get_data(bs=64, size=256)\n\n# Create learner\nlearner = cnn_learner(data, models.resnet34, pretrained=True, metrics=accuracy, ps=0.5, callback_fns=ShowGraph)\nlearner.model_dir = \"/kaggle/working\" ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find optimal LR\nlearner.lr_find()\nlearner.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train first epoch\nlearner.fit_one_cycle(1, max_lr=2e-2)\nlearner.show_results()\nlearner.save(\"resnet34_clf_256_1ep\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unfreeze the backbone and train second and third epochs \n# use same learning rate for the head\n# use smaller learner rates for the backbone\nlearner.unfreeze()\nlearner.fit_one_cycle(2, max_lr=slice(1e-4, 2e-2))\nlearner.recorder.plot_lr(show_moms=True)\nlearner.save(\"resnet34_clf_256_ep3\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create CSV file with results"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds, _ = learner.get_preds(ds_type=DatasetType.Test)\npreds = preds.argmax(dim=1)\npreds = preds.numpy()\nclf_out_df = pd.DataFrame(list(zip(map(lambda x: x.name, data.test_ds.items),preds)), columns=['ImageId','Label'])\nclf_out_df.to_csv('clf_256_test_preds.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('clf_256_test_preds.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink('resnet34_clf_256_ep3.pth')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}