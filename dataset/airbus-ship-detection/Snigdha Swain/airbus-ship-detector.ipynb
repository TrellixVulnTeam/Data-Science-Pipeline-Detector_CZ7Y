{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom skimage.feature import canny\nfrom skimage.filters import sobel,threshold_otsu, threshold_niblack,threshold_sauvola\nfrom skimage.segmentation import felzenszwalb, slic, quickshift, watershed\nfrom skimage.segmentation import mark_boundaries\nfrom scipy import signal\nfrom pathlib import Path\n\n\nimport cv2\nfrom PIL import Image\nimport pdb\nfrom tqdm import tqdm\nimport seaborn as sns\nimport os \nfrom glob import glob\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/train_ship_segmentations_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"645229cfa99136f2a190fc53dba3df10af928b62"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31ee0c9f77cca41b79f53286c5a2298d39ad00b9"},"cell_type":"code","source":"PATH='../input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cb00ab3e4a4625d0fd9db12e70a163ae138ba94"},"cell_type":"code","source":"train_imgs=os.listdir(PATH+'train_v2')\ntest_imgs=os.listdir(PATH+'test_v2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5dd2cff050d35433e5434142de1ac8f86778cb5"},"cell_type":"code","source":"masks = pd.read_csv(os.path.join('../input/',\n                                 'train_ship_segmentations_v2.csv'))\nprint(masks.shape[0], 'masks found')\nprint(masks['ImageId'].value_counts().shape[0])\nmasks.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d7e9d59c4ba2240a71696f9d469628b720f642c"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nunique_img_ids = masks.groupby('ImageId').size().reset_index(name='counts')\ntrain_ids, valid_ids = train_test_split(unique_img_ids, \n                 test_size = 0.3, \n                 stratify = unique_img_ids['counts'])\ntrain_df = pd.merge(masks, train_ids)\nvalid_df = pd.merge(masks, valid_ids)\nprint(train_df.shape[0], 'training masks')\nprint(valid_df.shape[0], 'validation masks')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bf12929b23fdfb6aacdb93a4c54b0401c4e1d4c"},"cell_type":"code","source":"train_imgs[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97beb5aac0b4de585a05ae4b931c48fea580e1be"},"cell_type":"code","source":"test_imgs[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c53e6ba09fe45e5f12e986c9799ec6d565a8c6e"},"cell_type":"code","source":"data = data.reset_index()\ndata['ship_count'] = data.groupby('ImageId')['ImageId'].transform('count')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d4f0c2b79512848d8798b04040da81d0ec4755c"},"cell_type":"code","source":"print(data['ship_count'].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f24cecddc7bc077c8f1cd5e875b4433c23bff887"},"cell_type":"code","source":"df = df.ImageId()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40429bca47e3d3d1d96a244a96f154ed7ac91104"},"cell_type":"code","source":"def get_filename(image_id, image_type):\n    check_dir = False\n    if \"Train\" == image_type:\n        data_path = train_imgs\n    elif \"mask\" in image_type:\n        data_path = masks\n    elif \"Test\" in image_type:\n        data_path = test_imgs\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    if check_dir and not os.path.exists(data_path):\n        os.makedirs(data_path)\n\n    return os.path.join(data_path, \"{}\".format(image_id))\n\ndef get_image_data(image_id, image_type, **kwargs):\n    img = _get_image_data_opencv(image_id, image_type, **kwargs)\n    img = img.astype('uint8')\n    return img\n\ndef _get_image_data_opencv(image_id, image_type, **kwargs):\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n   \n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b7aca25c54fb061f9332c4fdb111ed579509bbb"},"cell_type":"markdown","source":"Let's have a sneek peek into 9 images."},{"metadata":{"trusted":true,"_uuid":"49be093290c0891005334db42496cf8421402216"},"cell_type":"code","source":"sample = masks[~masks.EncodedPixels.isna()].sample(9)\n\nfig, ax = plt.subplots(3, 3, sharex='col', sharey='row')\nfig.set_size_inches(20, 20)\n\nfor i, imgid in enumerate(sample.ImageId):\n    col = i % 3\n    row = i // 3\n    \n    path = Path('../input/train_v2') / '{}'.format(imgid)\n    img = imread(path)\n    \n    ax[row, col].imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf599e3d37ec89f5bdef9614463fd4bdf44291ea"},"cell_type":"markdown","source":"**IMAGE TRANSFORMATION**\nLet's try to give contrast in a way to differentiate between ship and background."},{"metadata":{"trusted":true,"_uuid":"7f0f475fbdec24172efa025f8993bca4708664f0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f549b8e47e9cbae6633551bfdc797c508df9bbd"},"cell_type":"code","source":"from skimage.filters import gaussian,laplace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4dd123ce9b477c82c2f6c2081c8b90297d74af3"},"cell_type":"code","source":"ImageId = '0005d01c8.jpg'\n\nimg = imread('../input/train_v2/' + ImageId)\nimg_masks = masks.loc[masks['ImageId'] == ImageId, 'EncodedPixels'].tolist()\n\n# Take the individual ship masks and create a single mask array for all ships\nall_masks = np.zeros((768, 768))\nfor mask in img_masks:\n    all_masks += rle_decode(mask)\n\nfig, axarr = plt.subplots(1, 3, figsize=(15, 40))\naxarr[0].axis('off')\naxarr[1].axis('off')\naxarr[2].axis('off')\naxarr[0].imshow(img)\naxarr[1].imshow(all_masks)\naxarr[2].imshow(img)\naxarr[2].imshow(all_masks, alpha=0.4)\nplt.tight_layout(h_pad=0.1, w_pad=0.1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}