{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport numpy as np \nimport pandas as pd \nfrom PIL import Image, ImageDraw\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.applications.mobilenet import MobileNet, preprocess_input\nfrom keras.applications.densenet import DenseNet201\n\nimport tensorflow as tf\nfrom keras import Model\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm.notebook import tqdm_notebook as tqdm\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback, LearningRateScheduler\n\nimport random\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_img_dir = '../input/airbus-ship-detection/train_v2/'\ntrain_seg_csv = '../input/airbus-ship-detection/train_ship_segmentations_v2.csv'\ntest_img_dir = '../input/airbus-ship-detection/test_v2'\ntraincsv = pd.read_csv('../input/airbus-ship-detection/train_ship_segmentations_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traincsv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=[]\nfor i in (traincsv[\"EncodedPixels\"].notnull()):\n\n    if i==True:\n        c.append(1)\n    else:\n        c.append(0)\n        \ntraincsv[\"class\"]=c\n\ntraincsv_unique = traincsv.drop_duplicates(subset=['ImageId'], keep='first')\n\nprint(traincsv_unique.head())\nprint(\"\\n Shape of the Dataframe:\",traincsv_unique.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traincsv_unique = traincsv_unique.sort_values(by = [\"class\"])\ntraincsv_unique.reset_index(drop = True, inplace = True)\n\ntraincsv_unique = pd.concat([traincsv_unique.loc[:4999], traincsv_unique.loc[187556:]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traincsv_unique[\"class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 128\npaths = traincsv_unique[\"ImageId\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_images = np.zeros((len(traincsv_unique[\"ImageId\"]), IMAGE_SIZE, IMAGE_SIZE,3), dtype=np.float32)\n\nfor i, f in tqdm(enumerate(paths)):\n  #print(f)\n  img = Image.open(train_img_dir+f)\n  img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n  img = img.convert('RGB')\n  batch_images[i] = preprocess_input(np.array(img, dtype=np.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save(\"D:\\\\Resume\",batch_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save(\"class\",y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch_images1=batch_images.flatten()\n# batch_images1=batch_images.swapaxes(1, 2).reshape(10000*128, 128*3)\n\n# from numpy import savetxt\n# savetxt('batch_images.csv', batch_images1, delimiter=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array(traincsv_unique[\"class\"])\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_data , X_val, y_train_data , y_val = train_test_split(batch_images, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = DenseNet201(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3),include_top=False, weights='imagenet', classes=2)\n\n\n# for layers in model.layers:\n#   layers.trainable = False\n\n# x=model.layers[-1].output\n# # x=tf.keras.layers.Dense(1024,activation='relu')(x)  \n# #x=tf.keras.layers.Dense(512,activation='relu')(x) \n# x=tf.keras.layers.Flatten()(x)\n# # x=tf.keras.layers.Dense(128,activation='tanh')(x)\n# # x=tf.keras.layers.Dropout(0.4)(x)\n# x=tf.keras.layers.Dense(64,activation='tanh')(x)\n# x=tf.keras.layers.Dropout(0.4)(x)\n# preds=tf.keras.layers.Dense(1,activation='sigmoid')(x) \n\n\n# model = Model(inputs = model.inputs, outputs = preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ALPHA = 1.0\n\ndef schedule(epoch, lr):\n        if epoch < 10:\n            return lr\n        else:\n            return lr * tf.math.exp(-0.1)\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = MobileNet(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3), include_top=False, alpha=ALPHA)\n\n    for layers in model.layers:\n      layers.trainable = False\n\n    x=model.layers[-1].output\n    x=tf.keras.layers.Flatten()(x)\n    x=tf.keras.layers.BatchNormalization()(x)\n    x=tf.keras.layers.Dense(64,activation='relu')(x)\n    x=tf.keras.layers.Dropout(0.6)(x)\n    preds=tf.keras.layers.Dense(1,activation='sigmoid')(x) \n\n\n    model = Model(inputs = model.inputs, outputs = preds)\n\n    model.compile(loss='binary_crossentropy',\n                 optimizer='adam',\n                 metrics=['binary_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = EarlyStopping(monitor='val_iou', patience=5, mode=\"max\" )\nlearning_rate = LearningRateScheduler(schedule)\nreduce_lr = ReduceLROnPlateau(monitor='val_iou',factor=0.2,patience=5, min_lr=1e-7, verbose=1, mode=\"max\" )\n\nmodel.fit(x_train_data,\n          y_train_data,\n          batch_size=64,\n          epochs=20,\n          callbacks=[stop,reduce_lr,learning_rate],\n          validation_data=(X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.round(np.squeeze(model.predict(X_val)))\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=random.randint(1,1500)\n\nplt.imshow(X_val[i][:, :, 0],cmap='gray')\nprint(\"For {}th image:\".format(i))\nprint(\"\\tThe actual label class: \",y_val[i])\nprint(\"\\tThe predicted label class: \",int(predictions[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unscaled = cv2.imread(\"../input/airbus-ship-detection/test_v2/000f7d875.jpg\")\n\nimage_height, image_width, _ = unscaled.shape\nimage = cv2.resize(unscaled,(IMAGE_SIZE,IMAGE_SIZE))\nfeat_scaled = preprocess_input(np.array(image, dtype=np.float32))\nprint(\"The predicted label\",np.round(np.squeeze(model.predict(x = np.array([feat_scaled])))))\nplt.imshow(unscaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}