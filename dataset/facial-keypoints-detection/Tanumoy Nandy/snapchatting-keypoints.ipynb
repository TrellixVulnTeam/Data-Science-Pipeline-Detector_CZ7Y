{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21f9240ad1e30ad77f25569e13997883ae4af2cc"},"cell_type":"markdown","source":"**Loading the data**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/facial-keypoints-detection/training/training.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ac5036bf9a037be91f14a67aa0f119441a1406e"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05f997ac5ebaa92efe019270bb369534b074b238"},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c6f89df990d8933be42b778fb63fa5a6ca32a5d"},"cell_type":"markdown","source":"**Analyzing the data**\n\nThe Image column contains the face data for which the 30 first columns represent the keypoint data (15 x-coordinates and 15 y-coordinates)"},{"metadata":{"trusted":true,"_uuid":"5bec924deff649e4b27eeeb57a1389fc3003d06d"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c9ba25c23586396db723ac6be900bfcca221d2f"},"cell_type":"code","source":"def string2image(string):\n    \"\"\"Converts a string to a numpy array.\"\"\"\n    return np.array([int(item) for item in string.split()]).reshape((96, 96))\n\ndef plot_faces(nrows=5, ncols=5):\n    \"\"\"Randomly displays some faces from the training data.\"\"\"\n    selection = np.random.choice(df.index, size=(nrows*ncols), replace=False)\n    image_strings = df.loc[selection]['Image']\n    fig, axes = plt.subplots(figsize=(10, 10), nrows=nrows, ncols=ncols)\n    for string, ax in zip(image_strings, axes.ravel()):\n        ax.imshow(string2image(string), cmap='gray')\n        ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65808941a093439c08d16b9b3c7e9a77af32e842"},"cell_type":"code","source":"plot_faces()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"164d15aa17637e760509f5669f45469db3aa6906"},"cell_type":"code","source":"keypoint_cols = list(df.columns)[:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d392a8a51aa1d32564211aff7205988073fbea6d"},"cell_type":"code","source":"#first row/image's keypoints\nxy = df.iloc[1][keypoint_cols].values.reshape((15, 2))\nxy ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfe169d07e2e63228a235870d19467c71ac56263"},"cell_type":"code","source":"plt.plot(xy[:, 0], xy[:, 1], 'ro')\nplt.imshow(string2image(df.iloc[1]['Image']), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9011519f4312a1fa266a2b5c54d55797bf82d848"},"cell_type":"code","source":"def plot_faces_with_keypoints(nrows=5, ncols=5):\n    \"\"\"Randomly displays some faces from the training data with their keypoints.\"\"\"\n    selection = np.random.choice(df.index, size=(nrows*ncols), replace=False)\n    image_strings = df.loc[selection]['Image']\n    keypoint_cols = list(df.columns)[:-1]\n    keypoints = df.loc[selection][keypoint_cols]\n    fig, axes = plt.subplots(figsize=(10, 10), nrows=nrows, ncols=ncols)\n    for string, (iloc, keypoint), ax in zip(image_strings, keypoints.iterrows(), axes.ravel()):\n        xy = keypoint.values.reshape((15, 2))\n        ax.imshow(string2image(string), cmap='gray')\n        ax.plot(xy[:, 0], xy[:, 1], 'ro')\n        ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39f1015ef58f0ba60d9f74a9bdbf4aa9cfc8bf33"},"cell_type":"code","source":"plot_faces_with_keypoints()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff2d723983c793414b48311ef5ba05ec8faf813a"},"cell_type":"markdown","source":"We can make several observations from this image:\n\n* some images are high resolution, some are low\n* some images have all 15 keypoints, while some have only a few"},{"metadata":{"trusted":true,"_uuid":"3bbda11d1b1b709cf8a54f77d375a148a652dc99"},"cell_type":"code","source":"df.describe().loc['count'].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"023dbb606e1181e81e94ee76971102fe1a55f0b4"},"cell_type":"markdown","source":"What this plot tells us is that in this dataset, only 2000 images are \"high quality\" with all keypoints, while 5000 other images are \"low quality\" with only 4 keypoints labelled.\n\nLet's start training the data with the high quality images"},{"metadata":{"trusted":true,"_uuid":"4697af29e2943253b4a727c2de5681b73656cfa4"},"cell_type":"code","source":"fully_annotated = df.dropna()\nfully_annotated.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f3f832f7f78602acd8a7db28577d574a841626f"},"cell_type":"markdown","source":"**Data Pre-processing : Pipelining**"},{"metadata":{"trusted":true,"_uuid":"052428ebced8022570949ee62d6ad5f9f535e6aa"},"cell_type":"code","source":"X = np.stack([string2image(string) for string in fully_annotated['Image']]).astype(np.float)[:, :, :, np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fb8b6642fc5d5ea19bd7ee6dd1dc653fd2c06f1"},"cell_type":"code","source":"y = np.vstack(fully_annotated[fully_annotated.columns[:-1]].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"128de2b7935b621621c53abe75c0f618326d346e"},"cell_type":"code","source":"X.shape, X.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"717e3d975bf6bb396b017d2b5cb3ef116532d2ae"},"cell_type":"code","source":"y.shape, y.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01e7153e20f1444cf17e7fadff11f349c9bf6fab"},"cell_type":"code","source":"X_train = X / 255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca9a4585af2998c62be6bc6cd2062c3ccc399378"},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\noutput_pipe = make_pipeline(\n    MinMaxScaler(feature_range=(-1, 1))\n)\n\ny_train = output_pipe.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90e6da5ee2b4d0aa197193d5bb51b1a0511d2097"},"cell_type":"markdown","source":"**Building a Keras model**"},{"metadata":{"trusted":true,"_uuid":"96cfd0d37dc7b85695f15980cf0c72a61cdc5400"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv2D, Activation, MaxPooling2D, Dense, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten\n\nmodel = Sequential()\n# input layer\nmodel.add(BatchNormalization(input_shape=(96, 96, 1)))\nmodel.add(Conv2D(24, (5, 5), kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n# layer 2\nmodel.add(Conv2D(36, (5, 5)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n# layer 3\nmodel.add(Conv2D(48, (5, 5)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n# layer 4\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n# layer 5\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\n# layer 6\nmodel.add(Dense(500, activation=\"relu\"))\n# layer 7\nmodel.add(Dense(90, activation=\"relu\"))\n# layer 8\nmodel.add(Dense(30))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"814f20eb556674eb92c21caadce25d7ba3142fed"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nmodel.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\ncheckpointer = ModelCheckpoint(filepath='face_model.h5', verbose=1, save_best_only=True)\nepochs = 50\n\nhist = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)\n                               \n                               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cec434bd02b1a8b192fa403789f7e5507c321574"},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(hist.history['acc'])\nplt.plot(hist.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe99d5a666c05c868389b99b4ba8fa5fa2edfbd2"},"cell_type":"code","source":"def plot_faces_with_keypoints_and_predictions(model, nrows=5, ncols=5, model_input='flat'):\n    \"\"\"Plots sampled faces with their truth and predictions.\"\"\"\n    selection = np.random.choice(np.arange(X.shape[0]), size=(nrows*ncols), replace=False)\n    fig, axes = plt.subplots(figsize=(10, 10), nrows=nrows, ncols=ncols)\n    for ind, ax in zip(selection, axes.ravel()):\n        img = X_train[ind, :, :, 0]\n        if model_input == 'flat':\n            predictions = model.predict(img.reshape(1, -1))\n        else:\n            predictions = model.predict(img[np.newaxis, :, :, np.newaxis])\n        xy_predictions = output_pipe.inverse_transform(predictions).reshape(15, 2)\n        ax.imshow(img, cmap='gray')\n        ax.plot(xy_predictions[:, 0], xy_predictions[:, 1], 'bo')\n        ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19ddfce4c6fd28efdcc5f74c5f7323e25f93b20f"},"cell_type":"code","source":"plot_faces_with_keypoints_and_predictions(model, model_input='2d')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0dc3c3ab6cdbbf51fec926ff96fcc3f6204e1095"},"cell_type":"markdown","source":"Now lets prepare our testing data"},{"metadata":{"trusted":true,"_uuid":"cf0e22cd4f1542aa7b67fa9dee9c2519b5cb92f3"},"cell_type":"code","source":"Test_Dir = '../input/facial-keypoints-detection/test/test.csv'\ntest_data = pd.read_csv(Test_Dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a508526ea486cd24b96b26c85b85d816aa6a7089"},"cell_type":"code","source":"X_test = np.stack([string2image(string) for string in test_data['Image']]).astype(np.float)[:, :, :, np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfdb75a1d2085119dd9fc8daccbb5cd790a07d47"},"cell_type":"code","source":"y_test = np.vstack(test_data[test_data.columns[:-1]].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbfc31aabedb67f041e8a355b3f512231df07964"},"cell_type":"code","source":"X.shape, X.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c96148f7dd255a603007e77fbe86d9b42b3bb9d2"},"cell_type":"code","source":"y.shape, y.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"962506da3a70b95c52483f4f407cf1054780b9b0"},"cell_type":"code","source":"X_test = X_test / 255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"659203fee5802986a826f5a7eeb162f86e0c97fa"},"cell_type":"code","source":"def plot_faces_with_keypoints_and_predictions_test(model, nrows=5, ncols=5, model_input='flat'):\n    \"\"\"Plots sampled faces with their truth and predictions.\"\"\"\n    selection = np.random.choice(np.arange(X_test.shape[0]), size=(nrows*ncols), replace=False)\n    fig, axes = plt.subplots(figsize=(10, 10), nrows=nrows, ncols=ncols)\n    for ind, ax in zip(selection, axes.ravel()):\n        img = X_test[ind, :, :, 0]\n        if model_input == 'flat':\n            predictions = model.predict(img.reshape(1, -1))\n        else:\n            predictions = model.predict(img[np.newaxis, :, :, np.newaxis])\n        xy_predictions = output_pipe.inverse_transform(predictions).reshape(15, 2)\n        ax.imshow(img, cmap='gray')\n        ax.plot(xy_predictions[:, 0], xy_predictions[:, 1], 'bo')\n        ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1bd89981aa92e1b3e190a523788c006c7d4bcca"},"cell_type":"code","source":"plot_faces_with_keypoints_and_predictions_test(model, model_input='2d')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"064ca4093c66eaf07184304c1fd7de16671a4987"},"cell_type":"markdown","source":"**Testing on Individual data**"},{"metadata":{"trusted":true,"_uuid":"7c059940403d14ccd3bbcd0b0d167194dfadec77"},"cell_type":"code","source":"img = X_test[2, :, :, :][np.newaxis, :, :, :]\npredictions = model.predict(img)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f49f771a7c3741ebbcf00b000fc33b5ee9f1dbe3"},"cell_type":"code","source":"xy_predictions = output_pipe.inverse_transform(predictions).reshape(15, 2)\nxy_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"dfd97a70fc376eac08e3c73a4eeb3e5afc6308d6"},"cell_type":"code","source":"plt.imshow(X_test[2, :, :, 0], cmap='gray')\nplt.plot(xy_predictions[:, 0], xy_predictions[:, 1], 'b*')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb93aac9d8509c341487e29d0215a2a8e9b241eb"},"cell_type":"markdown","source":"**Playing Around : Applying silly filters**"},{"metadata":{"trusted":true,"_uuid":"2db118ad44e572767ec7e664cd06d98298017cb1"},"cell_type":"code","source":"import skimage.color\nfrom skimage.filters import median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a85f0a468ee4e85a46d67c195ff985896cf5c97"},"cell_type":"code","source":"moustache = plt.imread('../input/filter2/moustache-png-by-spoonswagging-on-deviantart-1.png')\nmoustache = skimage.color.rgb2gray(moustache)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"facba305340db86c6fbf51459620add9d294fcd0"},"cell_type":"code","source":"moustache = median(moustache, selem=np.ones((3, 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3179cb5a0bbdb29102e69253bc34a145c5200f9b"},"cell_type":"code","source":"plt.imshow(moustache, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc3301b5d5502b1a34fd025bd9abfd1d904f8e30"},"cell_type":"code","source":"from skimage import measure\nmoustache_contour = measure.find_contours(moustache, 0.8)[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52a4be026c64b265fbe4afd5155ff3e3b6627e3f"},"cell_type":"code","source":"moustache_contour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc48060fc61297028128576fea32e373b8ebc954"},"cell_type":"code","source":"moustache_contour -= np.array([250, 250])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5dd4ae9b5e1bf65338454da135a445033f85523"},"cell_type":"code","source":"def plot_scaled_moustache(ax, center_xy, dx):\n    \"\"\"Plots a moustache scaled by its width, dx, on current ax.\"\"\"\n    moustache_scaled = moustache_contour.copy()\n    moustache_scaled -= moustache_contour.min(axis=0)\n    moustache_scaled /= moustache_scaled.max(axis=0)[1]\n    deltas = moustache_scaled.max(axis=0) - moustache_scaled.min(axis=0)\n    moustache_scaled -= np.array([deltas[0]/2, deltas[1]/2])\n    moustache_scaled *= dx\n    moustache_scaled += center_xy[::-1]\n    ax.fill(moustache_scaled[:, 1], moustache_scaled[:, 0], \"black\", linewidth=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a1804c1b1bec3a0ce129109c3a8893a10e1c0ec"},"cell_type":"code","source":"ax = plt.gca()\nplot_scaled_moustache(ax, np.array([2, 3]), dx=3)\nax.invert_yaxis()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39b3cfd865f3b0ab2b83ee762154927394dd5a11"},"cell_type":"code","source":"def draw_moustache(predicted_points, ax):\n    \"\"\"Draws a moustache using the predicted face points.\"\"\"\n    dx = 2 * np.linalg.norm(predicted_points[12, :] - predicted_points[11, :])\n    center_xy = predicted_points[13, :]\n    plot_scaled_moustache(ax, center_xy, dx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1a267ec5eb33742707de99ed5a913b39db59b0b"},"cell_type":"code","source":"img = X_train[0, :, :, :][np.newaxis, :, :, :]\npredictions = model.predict(img)\nxy_predictions = output_pipe.inverse_transform(predictions).reshape(15, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f247cf3771eb5a6816b845cbf8a1dbf38fe4a8c"},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.imshow(X_train[0, :, :, 0], cmap='gray')\ndraw_moustache(xy_predictions, ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c042b6f96eaeaa4a9a0616ec136f1ab019b68595"},"cell_type":"code","source":"def plot_faces_with_moustaches(model, nrows=5, ncols=5, model_input='flat'):\n    \"\"\"Plots sampled faces with their truth and predictions.\"\"\"\n    selection = np.random.choice(np.arange(X.shape[0]), size=(nrows*ncols), replace=False)\n    fig, axes = plt.subplots(figsize=(10, 10), nrows=nrows, ncols=ncols)\n    for ind, ax in zip(selection, axes.ravel()):\n        img = X_train[ind, :, :, 0]\n        if model_input == 'flat':\n            predictions = model.predict(img.reshape(1, -1))\n        else:\n            predictions = model.predict(img[np.newaxis, :, :, np.newaxis])\n        xy_predictions = output_pipe.inverse_transform(predictions).reshape(15, 2)\n        ax.imshow(img, cmap='gray')\n        draw_moustache(xy_predictions, ax)\n        ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee2f42b0b680ade8220ac71f8937518a0c8b6fa1"},"cell_type":"code","source":"plot_faces_with_moustaches(model, model_input='2d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da8e25d22fa342093d8c0348838858b656059b8f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}