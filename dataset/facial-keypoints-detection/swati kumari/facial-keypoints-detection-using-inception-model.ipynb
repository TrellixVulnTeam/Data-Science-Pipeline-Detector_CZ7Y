{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Download Inception model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install gdown\n!gdown \"https://drive.google.com/uc?id=1-EcjB6mHCWkYdeCpg9PDmEed_CHwIohJ\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\ninception_model = pickle.load(open('inception_model.dt','rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 30\nbatch_size = 256\nnum_epochs = 20","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyModel(torch.nn.Module):\n    def __init__(self,num_classes ):\n        super(MyModel, self).__init__()\n        inception_model = pickle.load(open('inception_model.dt','rb'))\n        for param in inception_model.parameters():\n            param.requires_grad = False\n        num_ftrs = inception_model.AuxLogits.fc.in_features\n        inception_model.AuxLogits.fc = nn.Linear(num_ftrs, 512)\n        num_ftrs = inception_model.fc.in_features\n        inception_model.fc = nn.Linear(num_ftrs, 512) \n        \n        self.model = inception_model\n        self.linear = torch.nn.Linear(512 ,num_classes)\n\n        \n    def forward(self, x):   \n        if self.model.training:\n            y, y_aux= self.model(x)    \n        else:\n            y = self.model(x)\n        y_pred = self.linear(y)\n        y_out = torch.relu(y_pred)\n        return y_out    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom skimage.transform import resize\nfrom skimage.color import gray2rgb\nimport skimage\n\n\nclass FacialDataset(Dataset):\n    def __init__(self, filename):\n        train_df = pd.read_csv(filename)\n        self.x = train_df['Image'].to_numpy()\n        train_df.drop(['Image'], axis=1, inplace=True)\n        self.y = train_df.to_numpy()\n\n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, index):\n        y = torch.Tensor(self.y[index])\n        y = y.type(torch.cuda.FloatTensor)\n        x_pixels = np.array(self.x[index].split(' '), dtype = float).reshape(96,96)\n        x_resized = skimage.transform.resize(x_pixels,(299,299))\n        x = torch.Tensor(gray2rgb(x_resized)).permute(2,0,1)/255     \n        x = x.type(torch.cuda.FloatTensor)\n        return x,y\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define Dataloader","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file = \"/kaggle/input/facial-keypoints-detection/training.zip\"\ntrain_dataset = FacialDataset(train_file)\ntrain_dl = DataLoader(train_dataset, batch_size, shuffle = True)\n# for x,y in train_dl:\n#     print(x,y)\nlen(train_dl.dataset)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=20):\n    since = time.time()\n    best_acc = 0.0\n    loss_hist = []\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n        model.train()\n        model.to(\"cuda\")\n        running_loss = 0.0\n        running_corrects = 0\n        for inputs, labels in dataloaders:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            label_mask = (labels != labels)\n            if label_mask.any():\n                labels[label_mask] = outputs[label_mask]\n            loss = criterion(outputs, labels)\n            #loss2 = criterion(aux_outputs, labels)\n            #loss = loss1 + 0.4 * loss2\n\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            loss_hist.append(loss)\n            \n\n        epoch_loss = running_loss / len(dataloaders.dataset)\n        print('Epoch {} Loss: {:.4f}'.format(epoch+1, epoch_loss))\n        torch.save(model.state_dict(),'/kaggle/working/weights.dt')\n        torch.save(loss, '/kaggle/working/loss.dt')\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    return model, loss_hist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model = MyModel(num_classes)\nprint(my_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Loss criterion and optimizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"params_to_update = my_model.parameters()\nprint(\"Params to learn:\")\nparams_to_update = []    \nfor name,param in my_model.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n        print(\"\\t\",name)\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.Adam(params_to_update, lr=0.003)\ncriterion = nn.MSELoss()    #for multilabel classification\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train and evaluate\nmodel_ft, hist = train_model(my_model, train_dl, criterion, optimizer_ft, num_epochs=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization of predicted datapoints on images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nplt.figure(figsize = (15,10))\nno_imgs = 5\nno_cols = 5\nno_rows = no_imgs//no_cols +1 \nfor i in range(no_imgs):\n    x = train_dataset.x[i]\n    x_pixels = np.array(x.split(' '), dtype = float).reshape(96,96)\n    y_orig = train_dataset.y[i]\n    y_orig = y_orig.reshape(-1,2)\n    x_tensor, _ = train_dataset.__getitem__(i)\n    model_ft.eval()\n    y_pred = model_ft(x_tensor.unsqueeze(0))\n    y_pred = y_pred.cpu().detach().numpy().reshape(-1,2)\n    plt.subplot(no_rows, no_cols, i+1)\n    plt.imshow(x_pixels)\n    plt.title(f\"Image {i+1}\")\n    plt.axis(\"off\")\n    \n    plt.tight_layout()\n    plt.scatter(y_orig[:, 0], y_orig[:, 1], marker = 'v', c = 'g')\n    plt.scatter(y_pred[:, 0], y_pred[:, 1], marker = '.', c = 'r')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction for test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"id_table = pd.read_csv('/kaggle/input/facial-keypoints-detection/IdLookupTable.csv')\ntest_data = pd.read_csv('/kaggle/input/facial-keypoints-detection/test.zip')\n\nfeature_map = {'left_eye_center_x': 0, 'left_eye_center_y': 1, 'right_eye_center_x' : 2,\n       'right_eye_center_y' : 3, 'left_eye_inner_corner_x' : 4,\n       'left_eye_inner_corner_y' : 5, 'left_eye_outer_corner_x' : 6,\n       'left_eye_outer_corner_y' : 7, 'right_eye_inner_corner_x' : 8,\n       'right_eye_inner_corner_y' : 9, 'right_eye_outer_corner_x' : 10,\n       'right_eye_outer_corner_y' : 11, 'left_eyebrow_inner_end_x' : 12,\n       'left_eyebrow_inner_end_y' : 13, 'left_eyebrow_outer_end_x' : 14,\n       'left_eyebrow_outer_end_y' : 15, 'right_eyebrow_inner_end_x' : 16,\n       'right_eyebrow_inner_end_y' : 17, 'right_eyebrow_outer_end_x' : 18,\n       'right_eyebrow_outer_end_y' : 19, 'nose_tip_x' : 20, 'nose_tip_y' : 21,\n       'mouth_left_corner_x' : 22, 'mouth_left_corner_y' : 23,\n       'mouth_right_corner_x' : 24, 'mouth_right_corner_y' : 25,\n       'mouth_center_top_lip_x' : 26, 'mouth_center_top_lip_y' : 27,\n       'mouth_center_bottom_lip_x' : 28, 'mouth_center_bottom_lip_y' : 29\n       }\n\nmodel_ft.eval()\n\n#img_data = test_data['Image'].to_numpy()\nold_img_id = -1\nfor i in range(len(id_table)):\n    new_img_id = id_table.loc[i,'ImageId']\n    if (i == 0) or (new_img_id != old_img_id) :\n        x = test_data.loc[new_img_id-1,'Image']\n        img = np.array(x.split(' '), dtype = float).reshape(96,96)\n        img = torch.Tensor(gray2rgb(skimage.transform.resize(img,(299,299)))).permute(2,0,1)/255\n        img = img.type(torch.cuda.FloatTensor)\n        features = model_ft(img.unsqueeze(0))\n        features = features.cpu().detach().numpy().reshape(-1)\n        old_img_id = new_img_id\n    feature_location = features[feature_map[id_table.loc[i,'FeatureName']]]\n    if feature_location > 96:\n        feature_location = 96\n    id_table.loc[i,'Location'] = feature_location \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop other columns to create submission file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"id_table.drop(['ImageId'], axis=1, inplace=True)\nid_table.drop(['FeatureName'], axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_table.to_csv('/kaggle/working/submission.csv', index = False )\nx = pd.read_csv('/kaggle/working/submission.csv')\nx.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}