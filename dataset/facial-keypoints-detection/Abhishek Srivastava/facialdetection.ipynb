{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom torch.utils.data import Dataset, DataLoader\nfrom skimage.transform import resize\nfrom skimage.color import gray2rgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)\n\n! pip install gdown\n!gdown \"https://drive.google.com/uc?id=1Q7YxZ5zMAab9cHWVbYiX2Jdue8229jx8\"\n\nimport pickle\nmodel_inception_v3 = pickle.load(open('inception_model.dt', 'rb'))\n\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False\n\ndef initialize_model(model_name, num_classes, feature_extract = True, use_pretrained=True):\n    model_ft = None\n    input_size = 0\n    if model_name == \"inception\":\n        model_ft = model_inception_v3\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 299\n\n    return model_ft, input_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset2D(Dataset):\n    def convert_to_matrix(self,data):\n        return np.array(data.split(' '),dtype=float).reshape(96,96) # Images are 96 * 96\n\n    def __init__(self,filename):\n        input_data = pd.read_csv(filename)\n        #Seperate X,y\n        self.X = input_data['Image'].to_numpy()\n        input_data.drop(['Image'], axis=1, inplace=True)\n        self.Y = input_data.to_numpy()\n        self.len = input_data.shape[0]\n        return\n    def __getitem__(self,index):\n        x = torch.from_numpy(gray2rgb(resize(self.convert_to_matrix(self.X[index]),(299,299)))).type(torch.FloatTensor).permute(2,0,1) / 255\n        x = x.type(torch.cuda.FloatTensor)\n        y = torch.from_numpy(self.Y[index]).type(torch.cuda.FloatTensor)\n        return x,y\n    def __len__(self):\n        return self.len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ft, input_size = initialize_model('inception', 30,feature_extract = True, use_pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=Dataset2D(\"/kaggle/input/facial-keypoints-detection/training.zip\")\ndataset_loader = DataLoader(dataset=dataset,batch_size=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=True):\n    since = time.time()\n    val_acc_history = []\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        model.train()\n        running_loss = 0.0\n        batch = 1\n        total_batch = 7049 / 256\n        for x,y in dataset_loader:\n            print('Batch {}/{}'.format(batch, total_batch))\n            batch += 1\n            optimizer.zero_grad()\n            outputs, aux_outputs = model(x)\n            #To handle Nan in y -> assuming our output is correct to predict them\n            non_final_mask = (y != y)\n            if non_final_mask.any():\n                y[non_final_mask] = outputs[non_final_mask]\n\n            loss1 = criterion(outputs, y)\n            loss2 = criterion(aux_outputs, y)\n            loss = loss1 + 0.4 * loss2\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        epoch_loss = running_loss\n        print(\"Epoch Loss : \",epoch_loss)\n        print()\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    return model\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"params_to_update = []\nfor name,param in model_ft.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n        print(\"\\t\",name)\noptimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\ncriterion = nn.MultiLabelSoftMarginLoss() # For multilabel classifiers -> where output is multible labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_ft.to(\"cuda\")\nmodel_ft.train()\nmodel_trained = train_model(model_ft,dataset_loader,criterion,optimizer_ft,num_epochs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model_trained.state_dict(),'trained_model.dt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_trained.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\ndef convert_to_matrix(data):\n    return np.array(data.split(' '),dtype=float).reshape(96,96)\ndef show_feature_on_image(x,y,y_o):\n    x = convert_to_matrix(x)\n    plt.imshow(x, cmap='gray')\n    y = y.cpu().numpy().reshape(-1,2)\n    y_o = y_o.reshape(-1,2)\n    plt.scatter(y[:, 0], y[:, 1], s=24, marker ='.', c='r')\n    plt.scatter(y_o[:, 0], y_o[:, 1], s=24, marker ='x', c='g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nRANGE = 20\nCOLS = 5\nnrows = RANGE // COLS + 1\nfor label in range(RANGE):\n    x = dataset.X[label]\n    y = dataset.Y[label]\n    x_tensor = torch.from_numpy(gray2rgb(resize(convert_to_matrix(x),(299,299)))).type(torch.FloatTensor).permute(2,0,1).unsqueeze(0) / 255\n    x_tensor = x_tensor.type(torch.cuda.FloatTensor)\n    y_predict = model_trained(x_tensor)\n    plt.subplot(nrows,COLS,label+1)\n    plt.title(f'Sample #{label}')\n    plt.axis('off')\n    plt.tight_layout()\n    show_feature_on_image(x,y_predict.detach(),y)\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}