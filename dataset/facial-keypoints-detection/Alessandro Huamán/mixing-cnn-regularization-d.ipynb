{"cells":[{"metadata":{"_uuid":"e6ffe0a1b3225807863418f75464248beaa58374"},"cell_type":"markdown","source":"# Examen Parcial:\n\nPara ejecutar el código: crear un kernel en la competencia de kaggle (https://www.kaggle.com/c/facial-keypoints-detection) y partir de este notebook. Una vez terminado, se debe descargar el notebook final y subirlo en paideia.\n\n\n## Descripcion de la tarea\n\nEl objetivo de esta tarea es predecir las posiciones de los puntos clave en imágenes de rostros.\n\nLas imágenes de entrada son de 96x96 píxeles y en escala de grises (descritas con números enteros entre 0 y 255).\n\nCada punto clave se especifica mediante un par de valores reales (x, y) en el espacio de los índices de píxeles. Hay 15 puntos clave, que representan los siguientes elementos de la cara:\n\n    left_eye_center, right_eye_center, left_eye_inner_corner, left_eye_outer_corner, right_eye_inner_corner, right_eye_outer_corner, left_eyebrow_inner_end, left_eyebrow_outer_end, right_eyebrow_inner_end, right_eyebrow_outer_end, nose_tip, mouth_left_corner, mouth_right_corner, mouth_center_top_lip, mouth_center_bottom_lip\n\nDe modo que se debe entrenar una red neuronal que tome como input la imagen en escala de grises y de como output 30 números (las coordenadas x,y de los 15 puntos claves).\n\nAl compilar el modelo, especificar como función de pérdida el mean squared error **(mse)** y como métrica el mean absolute error **(mae)**. Por ejemplo:\n``` python\nmodel.compile(Adam(lr), loss='mse', metrics=['mae'])\n```\n\n## Calificación\n\n- Normalizar las imágenes (1 pt)\n- Definir correctamente la red neuronal (4 pts)\n- Entrenar la red neuronal (2 pts)\n  - mae entre 10 y 15 (3 pts)\n  - mae entre 8 y 11 (5 pts)\n  - mae entre 5 y 8 (7 pts)\n  - mae menor o igual a 4.0 (9 pts)\n- Mostrar 5 resultados aleatorios del set de validación (1 pt)\n- Mostrar las 5 mejores predicciones del set de validación (1 pt)\n- Mostrar las 5 peores predicciones del set de validación (1 pt)\n\n## Recomendaciones\n\nActivar el uso de GPU en el kernel de kaggle.\n\nDentro del kernel de kaggle, los botones para bajar y subir kernels, se encuentran en la parte superior de la pagina, a la izquierda del boton commit.\n\n![](https://i.imgur.com/m4inkg3.png)"},{"metadata":{"_uuid":"c8b0f0132af06f13d0039cbe5f637d1da9f8e25b"},"cell_type":"markdown","source":"# Información de alumno\n- Nombre: Alessandro Oscar Huamán Molina\n- Código: 20141131\n- Correo: alessandro.huaman@pucp.pe"},{"metadata":{"_uuid":"87ec9f2d8fc00145bd25dec013c4702e52ca6e61"},"cell_type":"markdown","source":"# Lectura de datos"},{"metadata":{"_uuid":"2f5c78d687321190a1f18d41353df563c5d4598f","trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c05f73b59fdf82bad23d023847ca167890dc07c","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/training/training.csv')\ndf.dropna(inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93fe18a573babd8366025e74334bd57bb00918a7","trusted":true},"cell_type":"code","source":"from joblib import Parallel, delayed\n\ndef format_img(x):\n    return np.asarray([int(e) for e in x.split(' ')], dtype=np.uint8).reshape(96,96)\n\nwith Parallel(n_jobs=10, verbose=1, prefer='threads') as ex:\n    x = ex(delayed(format_img)(e) for e in df.Image)\n    \nx = np.stack(x)[..., None]\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43420894cb6644857492717aa31f38466030b615","trusted":true},"cell_type":"code","source":"y = df.iloc[:, :-1].values\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c283496d535887dbabbd562492e7a894a73f997","trusted":true},"cell_type":"code","source":"def show(x, y=None):\n    plt.imshow(x[..., 0], 'gray')\n    if y is not None:\n        points = np.vstack(np.split(y, 15)).T\n        plt.plot(points[0], points[1], 'o', color='red')\n        \n    plt.axis('off')\n\nsample_idx = np.random.choice(len(x))    \nshow(x[sample_idx], y[sample_idx])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9220e4260519d84d6ab614b100536e6026317d0"},"cell_type":"markdown","source":"# Train validation split"},{"metadata":{"_uuid":"0baf25763093d7cb88732f19c28a2bb386b7089d","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\nx_train.shape, x_val.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbdc920036ffd69ef347a1da580b43a6f8dab996"},"cell_type":"markdown","source":"# Normalización de imágenes\nPara ello se utiliza reshape de numpy para estirar las imagenes, normalizarlas y volver a dimensionarla como imagen"},{"metadata":{"trusted":true,"_uuid":"2ecf1d3efbc8f2f0e65fccf6c7f762502e007403"},"cell_type":"code","source":"# Observamos las dimensiones de \"y\"\ny_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aeea8a4726181a5d5aaa9bd83504322279efd298","trusted":true},"cell_type":"code","source":"# Normalizar las imágenes (1pt)\n\n# Opto por normalizar utilizando la media y las desviación estándar\n# Estiramos las imágenes:\nx_train_norm=x_train[:,:,:,:]\nx_val_norm=x_val[:,:,:,:]\nx_train_norm=x_train_norm.reshape([1712,96*96,1])\nx_val_norm=x_val_norm.reshape([428,96*96,1])\n\n# Normalización:\nmu=x_train_norm.mean()\nsigma=x_train_norm.std()\n\nx_train_norm=(x_train_norm - mu)/sigma\nx_val_norm=(x_val_norm - mu)/sigma # Se normaliza siempre con el mu y sigma de los datos de entrenamiento\n\nx_train_norm.shape, x_val_norm.shape, x_train_norm.mean(), x_train_norm.std(), x_val_norm.mean(), x_val_norm.std()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de563276aeb36c5c15c3eff773b8e86b59878a5e"},"cell_type":"code","source":"# Observamos arriba que efectivamente están normalizados. Ahora retornamos a las dimensiones de matriz de imagen:\nx_train_norm=x_train_norm.reshape([1712,96,96,1])\nx_val_norm=x_val_norm.reshape([428,96,96,1])\n\nx_train_norm.shape, x_val_norm.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"388c03033ffefc08f982cc252eba5cb3fb13f366"},"cell_type":"code","source":"# Observamos una imagen para ver si está todo en orden:\nshow(x_train_norm[15], y_train[15])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2ee2caf30ccaf81e38e790231108e3a481b5e81"},"cell_type":"markdown","source":"Todo bien hasta ahora."},{"metadata":{"_uuid":"f4e397a9c47d78d68a591e42e06b6532feda7f35"},"cell_type":"markdown","source":"# Model\nNotamos que se trata de un problema de regresión dado que los puntos faciales clave que debemos predecir tienen coordenadas X y Y (continuas). Entonces, la lógica de la red a construir será: convertir la imagen facial a las 30 coordenadas (output), comparándolas con el valor real mediante la pérdida MSE."},{"metadata":{"_uuid":"e794bdc34cf97f1bf08afd8546f20705e3115e92","trusted":true},"cell_type":"code","source":"# Definir correctamente la red neuronal (5 pts)\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, AvgPool2D, BatchNormalization, Dropout\nfrom keras.optimizers import Adam\nfrom keras import regularizers\n\nmodel=Sequential([\n    Conv2D(72,4,input_shape=(96,96,1),activation='relu',kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.01)),\n    AvgPool2D(pool_size=(2,2)),\n    Conv2D(48,2,activation='relu',use_bias=False,kernel_initializer='he_normal' ,kernel_regularizer=regularizers.l2(0.01)), #Según clase, no se debe inicializar bias antes de un batchnorm\n    BatchNormalization(),\n    Flatten(),\n    Dropout(0.5), #Actúa como regularizador\n    Dense(48,activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01)), #Importante utilizar he initialization para relu\n#     Dropout(0.2), #Actúa como regularizador\n#     Dense(40,activation='relu', kernel_initializer='he_normal'), #Importante utilizar he initialization para relu\n    Dense(30, kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.01)) # No hay activación acá por ser un problema de regresión\n])\n\nmodel.compile(optimizer=Adam(0.01),loss='mse',metrics=['mae']) # Settings según indicaciones","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93e6cb2649372f16086ee5996c96d7a04a869b66"},"cell_type":"code","source":"# Resumen de las capas del modelo:\nmodel.summary(), model.input, model.output","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5900afe6a0d236cbf3fc404cc30ec7de5752e533","trusted":true},"cell_type":"code","source":"# Entrenar la red neuronal (2 pts)\nlog=model.fit(x_train_norm, y_train, epochs=150, batch_size=256, validation_data=[x_val_norm,y_val])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e52c82993607305a10d11055ee208ad76f712f26"},"cell_type":"markdown","source":"Nota para el profesor: Ojo que el modelo está entrenado para procesar adecuadamente datos normalizados, así que también normalizo el **x_val** para imprimir el error adecuado."},{"metadata":{"_uuid":"e09e0af94fc007ba7de1b241c487c963d6d6e335","trusted":true},"cell_type":"code","source":"# Resultado del entrenamiento\n# - mae entre 10 y 15 (3 pts)\n# - mae entre 8 y 11 (5 pts)\n# - mae entre 5 y 8 (7 pts)\n# - mae menor o igual a 4.0 (9 pts)\n\nprint(f'MAE final: {model.evaluate(x_val, y_val)[1]}')\nprint(f'MAE final: {model.evaluate((x_val-mu)/sigma, y_val)[1]}')\nprint(f'MAE final: {model.evaluate(x_val_norm, y_val)[1]}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db84c5aed6a6d223e95417e6a141f4e07fb70987"},"cell_type":"markdown","source":"Se observa entonces que se logra obtener un MAE menor a 4 (3.5462)."},{"metadata":{"_uuid":"67ef37ec37d1c2b0aa784337b142284b7e2d5953","trusted":true},"cell_type":"code","source":"# Ver la perdida en el entrenamiento\ndef show_results(*logs):\n    trn_loss, val_loss, trn_acc, val_acc = [], [], [], []\n    \n    for log in logs:\n        trn_loss += log.history['loss']\n        val_loss += log.history['val_loss']\n    \n    fig, ax = plt.subplots(figsize=(8,4))\n    ax.plot(trn_loss, label='train')\n    ax.plot(val_loss, label='validation')\n    ax.set_xlabel('epoch'); ax.set_ylabel('loss')\n    ax.legend()\n    \nshow_results(log)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb08561250cd9c0202fafad2d7e8677d22832560"},"cell_type":"markdown","source":"# Resultados"},{"metadata":{"_uuid":"196508d8c81e610aedc69c17a46bd81cf4bd951a","trusted":true},"cell_type":"code","source":"# Función para visualizar un resultado\ndef show_pred(x, y_real, y_pred):\n    fig, axes = plt.subplots(1, 2, figsize=(10,5))\n    for ax in axes:\n        ax.imshow(x[0, ..., 0], 'gray')\n        ax.axis('off')\n        \n    points_real = np.vstack(np.split(y_real[0], 15)).T\n    points_pred = np.vstack(np.split(y_pred[0], 15)).T\n    axes[0].plot(points_pred[0], points_pred[1], 'o', color='red')\n    axes[0].set_title('Predictions', size=16)\n    axes[1].plot(points_real[0], points_real[1], 'o', color='green')\n    axes[1].plot(points_pred[0], points_pred[1], 'o', color='red', alpha=0.5)\n    axes[1].set_title('Real', size=16)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e09fad1f1066358446b11df676404b7487b4d912"},"cell_type":"markdown","source":"Ej:\n``` python\nsample_x = x_val[0, None]\nsample_y = y_val[0, None]\npred = model.predict(sample_x)\nshow_pred(sample_x, sample_y, pred)\n```"},{"metadata":{"trusted":true,"_uuid":"4b42c9c5d080c3188579669d2bd44ad443464302"},"cell_type":"code","source":"# Ordenamos el set de validación según el ranking de errores obtenidos al predecir el set de validación:\npredicciones_val=model.predict(x_val_norm)\nresiduales_val=np.abs(predicciones_val - y_val)\nmad_val=np.sum(residuales_val, axis=1)/30\n\nindices=mad_val.argsort()\nindices.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51de296277b79bdf5a16b33f13675dc194a30df1","trusted":true},"cell_type":"code","source":"# Mostrar 5 resultados aleatorios del set de validación (1 pt)\nfor _ in range(5):\n    index = np.random.choice(x_val_norm.shape[0])\n    sample_x = x_val_norm[index, None]\n    sample_y = y_val[index, None]\n    pred = model.predict(sample_x)\n    show_pred(sample_x, sample_y, pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51de296277b79bdf5a16b33f13675dc194a30df1","trusted":true},"cell_type":"code","source":"# Mostrar las 5 mejores predicciones del set de validación (1 pt)\nfor i in range(5):\n    sample_x = x_val_norm[indices[i], None]\n    sample_y = y_val[indices[i], None]\n    pred = model.predict(sample_x)\n    show_pred(sample_x, sample_y, pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51de296277b79bdf5a16b33f13675dc194a30df1","trusted":true},"cell_type":"code","source":"# Mostrar las 5 peores predicciones del set de validación (1 pt)\nfor i in [-1,-2,-3,-4,-5]:\n    sample_x = x_val_norm[indices[i], None]\n    sample_y = y_val[indices[i], None]\n    pred = model.predict(sample_x)\n    show_pred(sample_x, sample_y, pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}