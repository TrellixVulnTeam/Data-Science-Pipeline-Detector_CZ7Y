{"cells":[{"metadata":{},"cell_type":"markdown","source":"1, Prepare the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport time \nimport mxnet as mx\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom mxnet import nd, autograd, gluon, init\nfrom mxnet.gluon import data as gdata, loss as gloss, nn\nfrom sklearn.model_selection import train_test_split\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#data processing, cited from https://www.kaggle.com/karanjakhar/facial-keypoint-detection\nTrain_Dir = '../input/training/training.csv'\nTest_Dir = '../input/test/test.csv'\nlookid_dir = '../input/IdLookupTable.csv'\ntrain_data = pd.read_csv(Train_Dir)  \ntest_data = pd.read_csv(Test_Dir)\nlookid_data = pd.read_csv(lookid_dir)\nos.listdir('../input')\n#fill null with the previous values in that row\ntrain_data.fillna(method = 'ffill',inplace = True)\n# fill the missing values in some images\nimag = []\nfor i in range(0,7049):\n    img = train_data['Image'][i].split(' ')\n    img = ['0' if x == '' else x for x in img]\n    imag.append(img)\n#reshape the face images in [96,96]\nimage_list = np.array(imag,dtype = 'float')\n# train data\nX_train = image_list.reshape(-1,96,96)\n#\ntraining = train_data.drop('Image',axis = 1)\ny_train = []\nfor i in range(0,7049):\n    y = training.iloc[i,:]\n    y_train.append(y)\n#y data\nY_train = np.array(y_train,dtype = 'float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax=fig.add_subplot(3,3,i+1)\n    ax.imshow(X_train[i+1],cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # keras model from  https://www.kaggle.com/karanjakhar/facial-keypoint-detection\n# from keras.layers import Conv2D,Dropout,Dense,Flatten\n# from keras.models import Sequential\n\n# model = Sequential([Flatten(input_shape=(96,96)),\n#                          Dense(128, activation=\"relu\"),\n#                          Dropout(0.1),\n#                          Dense(64, activation=\"relu\"),\n#                          Dense(30)\n#                          ])\n\n# model.compile(optimizer='adam', \n#               loss='mean_squared_error',\n#               metrics=['mae'])\n# model.fit(X_train,y_train,epochs = 500,batch_size = 128,validation_split = 0.2)\n\n# timag = []\n# for i in range(0,1783):\n#     timg = test_data['Image'][i].split(' ')\n#     timg = ['0' if x == '' else x for x in timg] \n#     timag.append(timg)\n    \n# timage_list = np.array(timag,dtype = 'float')\n# X_test = timage_list.reshape(-1,96,96)\n# pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2, Generate a resnet34 model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef log_test(net,test_iter,ctx):\n    test_l = 0\n    for X,y in test_iter:\n        X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n        l = loss(net(X),y)\n    test_l = l.mean().asscalar()\n    return test_l\n\ndef train(net, X_train, Y_train,num_epochs, trainer, batch_size, ctx):\n    train_files,val_files = train_test_split(range(len(X_train)),test_size=0.1,shuffle=True)\n    train_data,train_label = nd.array(X_train[train_files]),nd.array(Y_train[train_files])\n    val_data,val_label = nd.array(X_train[val_files]),nd.array(Y_train[val_files])\n    train_iter = gdata.DataLoader(gdata.ArrayDataset(train_data,train_label),batch_size,shuffle=True)\n    test_iter = gdata.DataLoader(gdata.ArrayDataset(val_data,val_label),batch_size)\n    train_ls,test_ls=[],[]\n    print('train on:',ctx)\n    for epoch in range(num_epochs):\n        start = time.time()\n        train_sum_l =0\n        for X,y in train_iter:\n#             print(X.shape)\n            X, y = X.expand_dims(axis=1).as_in_context(ctx), y.as_in_context(ctx)\n            with autograd.record():\n                l = loss(net(X),y)\n            l.backward()\n            trainer.step(batch_size)\n        train_loss = loss(net(train_data.expand_dims(axis=1).as_in_context(ctx)),train_label.as_in_context(ctx)).mean().asscalar()\n        train_ls.append(train_loss)\n        print()\n        if val_files:\n            test_ls.append(loss(net(val_data.expand_dims(axis=1).as_in_context(ctx)),val_label.as_in_context(ctx)).mean().asscalar())\n        else:\n            test_ls.append(train_loss)\n        print('epoch %d, train loss %.4f, test loss %.3f, time %.1f sec' % (epoch + 1,train_ls[-1], test_ls[-1], time.time() - start))\n    return train_ls, test_ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" $L = \\frac{1}{2} \\sum_i \\vert {pred}_i - {label}_i \\vert^2.$\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from mxnet.gluon.model_zoo import vision\n#use gpu for training\nctx=mx.gpu(0)\nresnet = vision.resnet34_v1(pretrained=False, ctx=mx.cpu())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_net = resnet.features\n# fine_net.add(nn.Conv2D(64,7,strides=(2,2),padding=(3,3)),resnet18.features[1:])\nfine_net.add(nn.Dense(30))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3,Train the net"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr, num_epochs = 0.001, 500\nbatch_size=128\nloss = gloss.L2Loss()\nnet = fine_net\n# fine-tuning\n# net[0].initialize(force_reinit=True,ctx=ctx, init=init.Xavier())\n# net[2].initialize(force_reinit=True,ctx=ctx, init=init.Xavier())\n# net[0].collect_params().setattr('lr_mult', 10)\n# net[2].collect_params().setattr('lr_mult', 10)\nnet.initialize(force_reinit=True,ctx=ctx, init=init.Xavier())\nnet.collect_params().reset_ctx(ctx)\ntrainer = gluon.Trainer(net.collect_params(),'adam',{'learning_rate':lr})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ls,test_ls = train(net, X_train, Y_train,num_epochs, trainer, batch_size, ctx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_ls,test_ls = train(net, X_train, Y_train,500, trainer, batch_size, ctx)\nnet.save_parameters('fine_tune_resnet34_20190616_adam.params')\n%matplotlib inline\nplt.plot(range(num_epochs),train_ls)\nplt.plot(range(num_epochs),test_ls)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['train','test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4, Predict the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing test data, cited from https://www.kaggle.com/karanjakhar/facial-keypoint-detection\ntimag = []\nfor i in range(len(test_data)):\n    timg = test_data['Image'][i].split(' ')\n    timg = ['0' if x == '' else x for x in timg]\n    timag.append(timg)\ntimage_list = np.array(timag,dtype = 'float')\nX_test = timage_list.reshape(-1,96,96)\nplt.imshow(X_test[0],cmap = 'gray')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test = net(nd.array(X_test).expand_dims(axis=1).as_in_context(ctx))\nY_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred=Y_test.asnumpy().flatten()\n# rowid= pd.Series(range(1,len(pred)+1),name = 'RowId')\n# loc = pd.Series(pred,name = 'Location')\n# submission = pd.concat([rowid,loc],axis = 1)\n# submission.to_csv('resnet18_submission_1.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5, make a submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"lookid_list = list(lookid_data['FeatureName'])\nimageID = list(lookid_data['ImageId']-1)\npre_list = list(Y_test.asnumpy())\nrowid = lookid_data['RowId']\nrowid=list(rowid)\nfeature = []\nfor f in list(lookid_data['FeatureName']):\n    feature.append(lookid_list.index(f))\npreded = []\nfor x,y in zip(imageID,feature):\n    # sometimes preded will be larger than 96\n    preded.append(pre_list[x][y] if pre_list[x][y]<96 else 96) \nrowid = pd.Series(rowid,name = 'RowId')\nloc = pd.Series(preded,name = 'Location')\nsubmission = pd.concat([rowid,loc],axis = 1)\nsubmission.to_csv('resnet18_submission_0616.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}