{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Facial Keypoint Detection\n\nDetect the location of keypoints on face images.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip ../input/facial-keypoints-detection/test.zip\n!unzip ../input/facial-keypoints-detection/training.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\nfrom collections import namedtuple, Counter\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.functional as F\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, SubsetRandomSampler\n\ndevice = torch.device('cuda:0')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset classes\n\nWe create two custom classes:\n\n- class for train dataset;\n\n- class for test dataset.\n\nThis classes inherit `torch.utils.data.Dataset` and override the following methods:\n\n- `__len__` so that `len(dataset)` returns the size of the dataset.\n\n- `__getitem__` to support the indexing such that `dataset[i]` can be used to get $i$th sample. The sample it is dict: `{'img': img, 'landmarks': landmarks}`, where `img` in is transformed torch Tensor and `landmarks` it is Tensor with facial keypoints.\n\nAlso, the classes has method `show_samples` that plot example images.\n\n**Remark 1.** Train dataset has NA/NaN values. We fill this values using pandas and `fillna` method for pandas DataFrame.\n\n**Remark 2.** Also, we convert images from grayscale to RGB using original image for all channels.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class FacialKeypoiuntsTrainDataset(Dataset):\n    '''Facial Keypoint Detection Train Dataset.\n\n    Url:\n        https://www.kaggle.com/c/facial-keypoints-detection/overview\n\n    Arguments:\n        data_file (str): csv file with train dataset.\n        transform (callable, optional):\n            Optional transform to be applied on a sample.\n    '''\n\n    def __init__(self, data_file, transform=None):\n        self.transform = transform\n \n        dataset = pd.read_csv(data_file)\n        dataset.fillna(method='ffill', inplace=True)\n\n        self.images = dataset['Image']\n        dataset = dataset.drop(['Image'], axis=1)\n\n        self.positions_name = list(dataset.columns)\n        self.positions = dataset.to_numpy()\n\n    def __len__(self):\n        return len(self.positions)\n\n    def __getitem__(self, index):\n        '''Get sample by index. The sample it is dict:\n\n                {'img': img, 'landmarks': landmarks},\n\n        where `img` in is transformed image in torch Tensor format and\n        `landmarks` it is Tensor with facial keypoints.\n        \n        Also, we convert images from grayscale to RGB using original image for\n        all channels.\n        '''\n        x = self.images[index]\n        x = np.array([float(x) for x in x.split(' ')])\n        x = x.reshape((96, 96))\n        img = np.stack((x, x, x), axis=-1) / 255.\n\n        y = self.positions[index]\n        sample = {'img': img, 'landmarks': y}\n\n        if self.transform:\n            sample = self.transform(sample)\n\n        return sample\n\n    def show_samples(self, indices, title=None, count=10):\n        '''Show image with landmarks by indices.\n        \n        Arguments:\n            indices (array_like): the array with image indeces.\n            title (str, optional): the title of figure.\n            count (int, optional): the number of images for plot.\n        '''\n        plt.figure(figsize=(count*3, 3))\n        display_indices = indices[:count]\n\n        if title:\n            plt.suptitle(title)\n\n        for i, index in enumerate(display_indices):\n            sample = self.__getitem__(index)\n\n            x, y = sample['img'], sample['landmarks']\n            x = np.asarray(x)\n            y = np.asarray(y)\n\n            y = y.reshape((y.size // 2, 2))\n\n            plt.subplot(1, count, i + 1)\n            if self.transform:\n                plt.imshow(np.transpose(x, (1, 2, 0)))\n            else:    \n                plt.imshow(x)\n            plt.scatter(y[:, 0], y[:, 1], s=15, marker='.', c='r')\n\n            plt.grid(False)\n            plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FacialKeypoiuntsTestDataset(Dataset):\n    '''Facial Keypoint Detection Test Dataset.\n\n    Url:\n        https://www.kaggle.com/c/facial-keypoints-detection/overview\n\n    Arguments:\n        data_file (str): csv file with test dataset.\n    '''\n\n    def __init__(self, data_file):\n        self.dataset = pd.read_csv(data_file)\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, index):\n        '''Get sample by index. The sample it is tuple:\n\n                (img_t, img_id),\n\n        where `img_t` in is image in torch Tensor format and\n        `img_id` it is image id from test dataset.\n\n        Also, we convert images from grayscale to RGB using original image for\n        all channels.\n        '''\n        data_sr = self.dataset.iloc[index]\n        img_id = int(data_sr['ImageId'])\n        x = data_sr['Image']\n\n        x = np.array([float(x) for x in x.split(' ')])\n        x = x.reshape((96, 96))\n        img = np.stack((x, x, x), axis=-1) / 255.\n        img = np.transpose(img, (2, 0, 1)).copy()\n\n        img_t = torch.from_numpy(img).type(torch.FloatTensor)\n\n        return img_t, img_id\n\n    def show_samples(self, indices, title=None, count=10):\n        '''Show image by indices.\n        \n        Arguments:\n            indices (array_like): the array with image indeces.\n            title (str, optional): the title of figure.\n            count (int, optional): the number of images for plot.\n        '''\n        plt.figure(figsize=(count*3, 3))\n        display_indices = indices[:count]\n\n        if title:\n            plt.suptitle(title)\n\n        for i, index in enumerate(display_indices):\n            x, y = self.__getitem__(index)\n            x = np.asarray(x)\n\n            plt.subplot(1, count, i + 1)\n            plt.imshow(np.transpose(x, (1, 2, 0)))\n            plt.title(f'Image Id {y}')\n\n            plt.grid(False)\n            plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Letâ€™s instantiate this class. We show a few samples.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = FacialKeypoiuntsTrainDataset('./training.csv')\ntest_dataset = FacialKeypoiuntsTestDataset('./test.csv')\n\n# indices for plot\ntrain_plot_indices = np.random.choice(len(train_dataset), 10)\ntest_plot_indices = np.random.choice(len(test_dataset), 10)\n\ntrain_dataset.show_samples(\n    train_plot_indices, title='Samples from Facial Keypoints Train Dataset', count=7)\n\ntest_dataset.show_samples(\n    test_plot_indices, title='Samples from Facial Keypoints Test Dataset', count=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transforms\n\nLetâ€™s create three transforms:\n\n- `RandomVerticalFlip`: to vertical flip the image. This is data augmentation.\n\n- `RandomTranslation`: to random translation the image. This is data augmentation.\n\n- `ToTensor`: to convert the numpy images to torch images (we need to swap axes).\n\nObserve below how these transforms had to be applied both on the image and landmarks.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class RandomVerticalFlip(object):\n    '''Random Vertical Flip for sample.\n\n    Arguments:\n        p (float, optional):\n            Probability of the image being flipped. Default value is 0.5\n    '''\n\n    def __init__(self, p=0.5):\n        assert isinstance(p, float), 'p must be of type float.'\n        assert (p >= 0.) and (p <= 1.), 'p must be from [0, 1].'\n        self.p = p\n\n    def __call__(self, sample):\n        img, landmarks = sample['img'], sample['landmarks']\n        flip_prob = np.random.binomial(1, self.p)\n\n        if flip_prob == 0:\n            new_img = img\n            new_landmarks = landmarks\n        else:\n            n = img.shape[0]\n\n            new_img = np.flip(img, axis=1)\n            new_landmarks = np.zeros(landmarks.size)\n\n            # left eye center\n            (new_landmarks[0], new_landmarks[1]) = (n - landmarks[2], landmarks[3])\n            # right eye center\n            (new_landmarks[2], new_landmarks[3]) = (n - landmarks[0], landmarks[1])\n            # left_eye_inner_corner\n            (new_landmarks[4], new_landmarks[5]) = (n - landmarks[8], landmarks[9])\n            # left_eye_outer_corner\n            (new_landmarks[6], new_landmarks[7]) = (n - landmarks[10], landmarks[11])\n            # right_eye_inner_corner\n            (new_landmarks[8], new_landmarks[9]) = (n - landmarks[4], landmarks[5])\n            # right_eye_outer_corner\n            (new_landmarks[10], new_landmarks[11]) = (n - landmarks[6], landmarks[7])\n            # left_eyebrow_inner_end\n            (new_landmarks[12], new_landmarks[13]) = (n - landmarks[16], landmarks[17])\n            # left_eyebrow_outer_end\n            (new_landmarks[14], new_landmarks[15]) = (n - landmarks[18], landmarks[19])\n            # right_eyebrow_inner_end\n            (new_landmarks[16], new_landmarks[17]) = (n - landmarks[12], landmarks[13])\n            # right_eyebrow_outer_end\n            (new_landmarks[18], new_landmarks[19]) = (n - landmarks[14], landmarks[15])\n            # nose_tip\n            (new_landmarks[20], new_landmarks[21]) = (n - landmarks[20], landmarks[21])\n            # mouth_left_corner\n            (new_landmarks[22], new_landmarks[23]) = (n - landmarks[24], landmarks[25])\n            # mouth_right_corner\n            (new_landmarks[24], new_landmarks[25]) = (n - landmarks[22], landmarks[23])\n            # mouth_center_top_lip_x\n            (new_landmarks[26], new_landmarks[27]) = (n - landmarks[26], landmarks[27])\n            # mouth_center_bottom_lip_x\n            (new_landmarks[28], new_landmarks[29]) = (n - landmarks[28], landmarks[29])\n\n        return {'img': new_img, 'landmarks': new_landmarks}\n\n\nclass RandomTranslation(object):\n    '''Random Translation for sample.\n\n    Arguments:\n        translate (tuple, optional): \n            Tuple of maximum absolute fraction for horizontal and vertical\n            translations. For example translate=(a, b), then horizontal shift\n            is randomly sampled in the range\n                -img_width * a < dx < img_width * a\n            and vertical shift is randomly sampled in the range\n                -img_height * b < dy < img_height * b.\n            Will not translate by default.\n    '''\n\n    def __init__(self, translate=None):\n        self.translate = translate\n\n        if self.translate is not None:\n            assert1_text = 'translate must be (float, float).'\n            assert2_text = 'translate[0] must be from [0, 1].'\n            assert3_text = 'translate[1] must be from [0, 1].'\n\n            assert (isinstance(self.translate, tuple)) and (len(self.translate) == 2), assert1_text\n            assert (self.translate[0] >= 0.) and (self.translate[0] <= 1.), assert2_text\n            assert (self.translate[1] >= 0.) and (self.translate[1] <= 1.), assert2_text\n\n    def __call__(self, sample):\n        img, landmarks = sample['img'], sample['landmarks']\n        n_img = img.shape[0]\n        n_landmarks = landmarks.size\n\n        max_dx = self.translate[0] * n_img\n        max_dy = self.translate[1] * n_img\n\n        dx = np.random.randint(-max_dx, max_dx)\n        dy = np.random.randint(-max_dy, max_dy)\n\n        new_img = np.zeros(img.shape)\n        new_landmarks = np.zeros(n_landmarks)\n\n        if dx >= 0:\n            li_x, ri_x = dx, n_img\n        else:\n            li_x, ri_x = 0, n_img + dx \n\n        if dy >= 0:\n            li_y, ri_y = dy, n_img\n        else:\n            li_y, ri_y = 0, n_img + dy\n\n        new_img[li_x:ri_x, li_y:ri_y, 0] = img[li_x-dx:ri_x-dx, li_y-dy:ri_y-dy, 0]\n        new_img[li_x:ri_x, li_y:ri_y, 1] = img[li_x-dx:ri_x-dx, li_y-dy:ri_y-dy, 1]\n        new_img[li_x:ri_x, li_y:ri_y, 2] = img[li_x-dx:ri_x-dx, li_y-dy:ri_y-dy, 2]\n\n        for j in range(n_landmarks // 2):\n            new_landmarks[2*j + 1] = landmarks[2*j + 1] + dx\n            new_landmarks[2*j] = landmarks[2*j] + dy\n\n        return {'img': new_img, 'landmarks': new_landmarks}\n\n\nclass ToTensor(object):\n    '''Convert ndarrays in sample to Tensors.'''\n\n    def __call__(self, sample):\n        img, landmarks = sample['img'], sample['landmarks']\n        img = np.transpose(img, (2, 0, 1)).copy()\n\n        return {'img': torch.from_numpy(img).type(torch.FloatTensor),\n                'landmarks': torch.from_numpy(landmarks).type(torch.FloatTensor)}\n\n\nclass Normalization(object):\n    '''Normalize a tensor image with mean and standard deviation.'''\n\n    def __init__(self, mean, std, inplace=False):\n        self.normalization = transforms.Normalize(mean, std, inplace)\n\n    def __call__(self, sample):\n        img = sample['img']\n        img_n = self.normalization(img)\n\n        return {'img': img_n, 'landmarks': sample['landmarks']}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we apply the transforms on a sample.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = FacialKeypoiuntsTrainDataset(\n    './training.csv',\n    transform=transforms.Compose([\n        RandomVerticalFlip(0.5),\n        RandomTranslation((0.2, 0.2)),\n        ToTensor(),\n    ])\n)\n\ntrain_dataset.show_samples(\n    train_plot_indices, title='Samples from Facial Keypoints Train Dataset', count=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Iterating through the dataset\n\nNow we create Data Loader using pytorch.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\n\ndata_size = len(train_dataset)\nvalidation_fraction = .2\n\nval_split_size = int(np.floor(validation_fraction * data_size))\nindeces = list(range(data_size))\nnp.random.shuffle(indeces)\n\nval_indeces, train_indeces = indeces[:val_split_size], indeces[val_split_size:]\n\ntest_indeces = list(range(len(test_dataset)))\nprint(f'train size = {len(train_indeces)}, validation size = {len(val_indeces)}')\nprint(f'test size = {len(test_indeces)}')\n\ntrain_sampler = SubsetRandomSampler(train_indeces)\nval_sampler = SubsetRandomSampler(val_indeces)\ntest_sampler = SubsetRandomSampler(test_indeces)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                           batch_size=batch_size,\n                                           sampler=train_sampler)\n\nval_loader = torch.utils.data.DataLoader(train_dataset,\n                                         batch_size=batch_size,\n                                         sampler=val_sampler)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=batch_size,\n                                          sampler=test_sampler)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\n\nWe using Transfer learning method. We will take as the basic model is `resnet18`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_model = models.resnet18(pretrained=True)\n\n# add new output layer\n# also, recall that landmarks has size 30\nnn_model.fc = nn.Linear(nn_model.fc.in_features, 30)\n\nnn_model = nn_model.type(torch.FloatTensor)\nnn_model = nn_model.to(device)\n\n*old_params, new_params = nn_model.parameters()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train model\n\nWe create utils function for training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, train_loader, val_loader, loss, optimizer, scheduler, num_epoch, plot_epoch):\n    '''The train model.\n    \n    Arguments:\n        model (torch.nn.Module): the model for training.\n        train_loader (torch.utils.data.dataloader.DataLoader):\n            the loader of train dataset.\n        val_loader (torch.utils.data.dataloader.DataLoader):\n            the loader of validation dataset.\n        loss (torch.nn.modules.loss): the loss for optimization.\n        optimizer (torch.optim): the optimizer.\n        scheduler (torch.optim.lr_scheduler): the scheduler.\n        num_epoch (int): the number of epochs.\n        plot_epoch (int): the length of the interval for showing intermediate results.\n    '''\n    loss_history = []\n    train_rmse_history = []\n    val_rmse_history = []\n\n    best_model = None\n    best_val_rmse = None\n\n    indices = np.random.choice(batch_size, 10)\n\n    for epoch in range(num_epoch):\n        print(f'Epoch {epoch + 1:2d} / {num_epoch:2d}', end=' ')\n\n        model.train()\n\n        average_loss = 0\n        average_rmse = 0\n\n        for i_step, sample in enumerate(train_loader):\n            x, y = sample['img'], sample['landmarks']\n            x_gpu = x.to(device)\n            y_gpu = y.to(device)\n\n            prediction = model(x_gpu)\n\n            loss_value = loss(prediction, y_gpu)\n            optimizer.zero_grad()\n            loss_value.backward()\n            optimizer.step()\n\n            average_loss += loss_value.item()\n\n            rmse = mean_squared_error(\n                y,\n                prediction.cpu().detach().numpy(),\n                squared=False)\n            average_rmse += rmse\n\n        average_loss = average_loss / i_step\n        train_rmse = average_rmse / i_step\n        val_rmse = compute_rmse(model, val_loader)\n\n        loss_history.append(average_loss)\n        train_rmse_history.append(train_rmse)\n        val_rmse_history.append(val_rmse)\n\n        print(f'Loss = {average_loss:.4f}, Train RMSE = {train_rmse:.4f}, Val RMSE = {val_rmse:.4f}')\n\n        if best_val_rmse is None:\n            best_val_rmse = val_rmse\n            best_model = copy.deepcopy(model)\n\n        if val_rmse < best_val_rmse:\n            best_val_rmse = val_rmse\n            best_model = copy.deepcopy(model)\n\n        scheduler.step()\n\n        if ((epoch + 1) % plot_epoch) == 0:\n            plot_results(model, val_loader, indices, title=f'Examples for epoch {epoch + 1}')\n\n    print(f'   Best val RMSE = {best_val_rmse:.4f}')\n\n    return loss_history, train_rmse_history, val_rmse_history, best_val_rmse, best_model\n\n\ndef compute_rmse(model, val_loader):\n    '''Compute Root Mean Square Error for validation data.'''\n    average_rmse = 0\n\n    model.eval()\n    for i_step, sample in enumerate(val_loader):\n        x, y = sample['img'], sample['landmarks']\n        x_gpu = x.to(device)\n\n        with torch.no_grad():\n            prediction = model(x_gpu)\n\n        rmse = mean_squared_error(\n            y,\n            prediction.cpu().detach().numpy(),\n            squared=False)\n\n        average_rmse += rmse\n\n    val_rmse = float(average_rmse) / i_step\n\n    return val_rmse\n\n\ndef plot_results(model, val_loader, indices, title=None, count=10):\n    '''\n    '''\n    plt.figure(figsize=(count*3, 3))\n    display_indices = indices[:count]\n\n    if title:\n        plt.suptitle(title)\n\n    model.eval()\n\n    for i_step, samples in enumerate(val_loader):\n        x_gpu, _ = samples['img'], samples['landmarks']\n        x_gpu = x_gpu.to(device)\n\n        with torch.no_grad():\n            prediction = model(x_gpu)\n\n        ys = prediction.cpu().detach().numpy()\n        xs = x_gpu.cpu().detach().numpy()\n\n        for i, index in enumerate(display_indices):\n            x = xs[index]\n\n            y = ys[index]\n            y = y.reshape((y.size // 2, 2))\n\n            plt.subplot(1, count, i + 1)\n            if x.shape[0] == 3:\n                plt.imshow(np.transpose(x, (1, 2, 0)))\n            else:    \n                plt.imshow(x)\n            plt.scatter(y[:, 0], y[:, 1], s=15, marker='.', c='r')\n\n            plt.grid(False)\n            plt.axis('off')\n        plt.show()\n\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's start training!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = nn.MSELoss().to(device)\n\noptimizer = optim.Adam([\n    {'params': old_params, 'lr': 0.0001},\n    {'params': new_params}    \n], lr=0.001, weight_decay=0.01)\n\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1.)\n\n(loss_history, train_rmse_history, val_rmse_history,\n best_val_rmse, best_model) = train_model(nn_model, train_loader, val_loader, loss,\n                                          optimizer, scheduler, num_epoch=50, plot_epoch=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_dataset_prediction(test_loader, submissions_data_file,\n                            lookup_table_data_file, positions_name, model):\n    '''Prediction of test dataset samples.\n\n    Arguments:\n        test_loader (): Path to csv file with test dataset.\n        submission_data_file (str): Path to csv file with submission template.\n        lookup_table_data_file (str): Path to csv file with lookup table.\n        position_names (list): Facial positions name.\n        model (nn.Module): The model for prediction.\n    '''\n    submission = pd.read_csv(submissions_data_file)\n    lookup_table = pd.read_csv(lookup_table_data_file)\n\n    model.eval()\n    for i_step, (x, img_id) in enumerate(test_loader):\n        x_gpu = x.to(device)\n\n        with torch.no_grad():\n            prediction = model(x_gpu)\n\n        prediction = np.asarray(prediction.cpu())\n\n        for b_id in range(prediction.shape[0]):\n            for p_id in range(len(positions_name)):\n                p_name = positions_name[p_id]\n                location = prediction[b_id, p_id]\n\n                row_id = lookup_table.loc[(\n                    (lookup_table['FeatureName'] == p_name) &\n                    (lookup_table['ImageId'] == img_id[b_id].item())\n                )]['RowId'].to_numpy()\n\n                if row_id.size == 1:\n                    submission['Location'][int(row_id[0]) - 1] = location\n\n    return submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_submissions = test_dataset_prediction(\n    test_loader, '../input/facial-keypoints-detection/SampleSubmission.csv',\n    '../input/facial-keypoints-detection/IdLookupTable.csv',\n    train_dataset.positions_name, best_model)\n\ntest_submissions.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}