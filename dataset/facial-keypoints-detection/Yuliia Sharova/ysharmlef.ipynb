{"cells":[{"metadata":{},"cell_type":"raw","source":"We are given three CSV files.\n1)training.csv :Its has coordinates of facial keypoints like left eye, rigth eye etc and also the image.\n2) test.csv : Its has image only and we have to give coordinates of various facial keypoints\n3) We use a csv file to solve the problem which is IdLookupTable.csv"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Importation of packages\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom IPython.display import clear_output\nfrom time import sleep\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# Any results we write to the current directory are saved as output.\ntrain_data = pd.read_csv('data/training/training.csv')\ntest_data = pd.read_csv('data/test/test.csv')\nlookid_data = pd.read_csv('data/IdLookupTable.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Exploration of our dataset\nlookid_data.head().T\nprint('size of training data {}'.format(len(train_data)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Checking for missing values\ntrain_data.isnull().any().value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"There are missing values in 28 columns.\nWe can do two things here one remove the rows having missing values and\nanother is the fill missing values with something.\nWe used two option as removing rows will reduce our dataset.\nWe filled the missing values with the previous values in that row."},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data.fillna(method = 'ffill',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Checking for missing values one more time\ntrain_data.isnull().any().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":" len(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"As there is no missing values we can now separate the labels and features.\nAs image column values are in string format and there is also some\nmissing values so we have to split the string by space and append it and\nalso handling missing values"},{"metadata":{"trusted":false},"cell_type":"code","source":"# conversion of image col to int and also check NaN\nimag = []\nfor i in range(0,len(train_data)):\n    img = train_data['Image'][i].split(' ')\n    img = ['0' if x == '' else x for x in img]\n    imag.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# reshape the face images in [96,96] and convert it into float value.\nimage_list = np.array(imag,dtype = 'float')\nX_train = image_list.reshape(-1,96,96)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Lets see what is the first image.\nplt.imshow(X_train[0],cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# separate labels\ntraining_y = train_data.drop('Image',axis = 1)\n\ny_train = []\nfor i in range(0,len(train_data)):\n    y = training_y.iloc[i,:]\n\n    y_train.append(y)\ny_train = np.array(y_train,dtype = 'float')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"As our data is ready for training , lets define our model.\nWe am using keras and simple dense layers.\nFor loss function we are using 'mse' ( mean squared error )\nas we have to predict new values.\nOur result evaluted on the basics of 'mae' ( mean absolute error ) ."},{"metadata":{"trusted":false},"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D,Dropout,Dense,Flatten\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Configure Model\nmodel = Sequential()\nmodel.add(Flatten(input_shape=[96,96]))\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(30))\n\n# Compile model\n\nmodel.compile(optimizer='adam', \n              loss='mse',\n              metrics=['mae'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Now our model is defined and we will train it by calling fit method.\nWe ran it for 500 iteration keeping batch size and validtion set size as\n20% ( 20% of the training data will be kept for validating the model )."},{"metadata":{"trusted":false},"cell_type":"code","source":"#Test of different methods: EarlyStopping, ModelCheckpoint\n\n#k = EarlyStopping(patience = 10)\n#k  = ModelCheckpoint(filepath = \"/home/bogkosh/IdeaProjects/Python Ylii/my.h5\", save_best_only = True)\nhist = model.fit(X_train,y_train,epochs = 300,batch_size = 64,validation_split = 0.2) #callbacks = [k]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#model = load_model(\"my.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot_learning_curves(hist):\n    pd.DataFrame(hist.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 100)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_learning_curves(hist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Preparing our testing data\n# convert image col to int  also check NaN\n#len(timag) = 1783 test data\ntimag = []\nfor i in range(0,len(test_data)):\n    timg = test_data['Image'][i].split(' ')\n    timg = ['0' if x == '' else x for x in timg]\n    \n    timag.append(timg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Reshaping and converting the images back to 96*96 pixels\ntimages_list = np.array(timag,dtype = 'float')\nX_test = timages_list.reshape(-1,96,96)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Preview result on test data with the first image\n# We can check the performance of the model on the image dataset\nplt.imshow(X_test[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#predict our results\npred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Now the last step is the create our submission file keeping\nin the mind required format. There should be two columns :\n   - RowId and Location Location column values should be\n  filled according the lookup table provided ( IdLookupTable.csv)"},{"metadata":{"trusted":false},"cell_type":"code","source":"lookid_list = list(lookid_data['FeatureName'])\nimageID = list(lookid_data['ImageId']-1)\npre_list = list(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rowid = lookid_data['RowId']\nrowid=list(rowid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature = []\nfor f in list(lookid_data['FeatureName']):\n    feature.append(lookid_list.index(f))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"preded = []\nfor x,y in zip(imageID,feature):\n    preded.append(pre_list[x][y])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rowid = pd.Series(rowid,name = 'RowId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"loc = pd.Series(preded,name = 'Location')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission = pd.concat([rowid,loc],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.Location=submission.Location.map(lambda x:0 if x<0 else x)\nsubmission.Location=submission.Location.map(lambda x:96 if x>96 else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.to_csv('face_key_detection_submission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}