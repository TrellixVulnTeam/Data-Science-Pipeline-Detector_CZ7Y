{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install visualkeras","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-12-23T02:57:52.022569Z","iopub.execute_input":"2021-12-23T02:57:52.023017Z","iopub.status.idle":"2021-12-23T02:58:00.777775Z","shell.execute_reply.started":"2021-12-23T02:57:52.022969Z","shell.execute_reply":"2021-12-23T02:58:00.776916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport visualkeras\nfrom math import sin, cos, pi\nimport cv2, os\nfrom tqdm.auto import tqdm\nfrom keras import layers, callbacks, utils, applications, optimizers\nfrom keras.models import Sequential, Model, load_model","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:00.779901Z","iopub.execute_input":"2021-12-23T02:58:00.780277Z","iopub.status.idle":"2021-12-23T02:58:06.076896Z","shell.execute_reply.started":"2021-12-23T02:58:00.780237Z","shell.execute_reply":"2021-12-23T02:58:06.075695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:           #定义类决定数据增强的方案\n    horizontal_flip = False\n    rotation_augmentation = True\n    brightness_augmentation = True\n    shift_augmentation = True\n    random_noise_augmentation = True\n\n    rotation_angles = [12]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)\n    pixel_shifts = [12]    # Horizontal & vertical shift amount in pixels (includes shift from all 4 corners)\n\n    NUM_EPOCHS = 100\n    BATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:06.079134Z","iopub.execute_input":"2021-12-23T02:58:06.0797Z","iopub.status.idle":"2021-12-23T02:58:06.085696Z","shell.execute_reply.started":"2021-12-23T02:58:06.079659Z","shell.execute_reply":"2021-12-23T02:58:06.084931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"print(\"Contents of input/facial-keypoints-detection directory: \")\n!ls ../input/facial-keypoints-detection/\n\nprint(\"\\nExtracting .zip dataset files to working directory ...\")\n!unzip -u ../input/facial-keypoints-detection/test.zip\n!unzip -u ../input/facial-keypoints-detection/training.zip\n\nprint(\"\\nCurrent working directory:\")\n!pwd\nprint(\"\\nContents of working directory:\")\n!ls","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:06.087726Z","iopub.execute_input":"2021-12-23T02:58:06.088208Z","iopub.status.idle":"2021-12-23T02:58:12.46967Z","shell.execute_reply.started":"2021-12-23T02:58:06.08815Z","shell.execute_reply":"2021-12-23T02:58:12.468694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntrain_file = 'training.csv'\ntest_file = 'test.csv'\nidlookup_file = '../input/facial-keypoints-detection/IdLookupTable.csv'\ntrain_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)\nidlookup_data = pd.read_csv(idlookup_file)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:12.474262Z","iopub.execute_input":"2021-12-23T02:58:12.474579Z","iopub.status.idle":"2021-12-23T02:58:15.186955Z","shell.execute_reply.started":"2021-12-23T02:58:12.474547Z","shell.execute_reply":"2021-12-23T02:58:15.185893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:15.190081Z","iopub.execute_input":"2021-12-23T02:58:15.190724Z","iopub.status.idle":"2021-12-23T02:58:15.19755Z","shell.execute_reply.started":"2021-12-23T02:58:15.190677Z","shell.execute_reply":"2021-12-23T02:58:15.196692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring Data","metadata":{}},{"cell_type":"code","source":"train_data.head()     #包含了用于训练的人脸关键点坐标和图像","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:15.199364Z","iopub.execute_input":"2021-12-23T02:58:15.199872Z","iopub.status.idle":"2021-12-23T02:58:15.244955Z","shell.execute_reply.started":"2021-12-23T02:58:15.199831Z","shell.execute_reply":"2021-12-23T02:58:15.244293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()      #包含了用于测试的人脸关键点图像，没有标注关键点坐标","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:15.246126Z","iopub.execute_input":"2021-12-23T02:58:15.246478Z","iopub.status.idle":"2021-12-23T02:58:15.257799Z","shell.execute_reply.started":"2021-12-23T02:58:15.246451Z","shell.execute_reply":"2021-12-23T02:58:15.256709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idlookup_data.head()   #测试集关键点的位置的对应名称","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:15.259588Z","iopub.execute_input":"2021-12-23T02:58:15.260101Z","iopub.status.idle":"2021-12-23T02:58:15.270681Z","shell.execute_reply.started":"2021-12-23T02:58:15.259922Z","shell.execute_reply":"2021-12-23T02:58:15.26965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Length of train data:\", len(train_data))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:15.272044Z","iopub.execute_input":"2021-12-23T02:58:15.272737Z","iopub.status.idle":"2021-12-23T02:58:15.279118Z","shell.execute_reply.started":"2021-12-23T02:58:15.272697Z","shell.execute_reply":"2021-12-23T02:58:15.278244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Find columns having Null values and their counts**","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()   #判断哪些列包含缺失值","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:15.282248Z","iopub.execute_input":"2021-12-23T02:58:15.283019Z","iopub.status.idle":"2021-12-23T02:58:15.296061Z","shell.execute_reply.started":"2021-12-23T02:58:15.282976Z","shell.execute_reply":"2021-12-23T02:58:15.295055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can observe that approx. 68% of data is missing for several keypoints","metadata":{}},{"cell_type":"code","source":"#两种操作\n\nclean_train_data = train_data.dropna()  #删除所有包含NaN的行\nprint(\"clean_train_data shape:\", np.shape(clean_train_data))\n\nunclean_train_data = train_data.fillna(method = 'ffill')  #默认为’ffill’，向前填充\nprint(\"unclean_train_data shape:\", np.shape(unclean_train_data))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-23T02:58:15.297768Z","iopub.execute_input":"2021-12-23T02:58:15.298752Z","iopub.status.idle":"2021-12-23T02:58:15.331587Z","shell.execute_reply.started":"2021-12-23T02:58:15.29871Z","shell.execute_reply":"2021-12-23T02:58:15.330898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)/255.\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop('Image',axis = 1)\n    keypoint_features = []\n    for idx, sample_keypoints in keypoint_data.iterrows():\n        keypoint_features.append(sample_keypoints)\n    keypoint_features = np.array(keypoint_features, dtype = 'float')\n    return keypoint_features\n\nclean_train_images = load_images(clean_train_data)\nprint(\"Shape of clean_train_images:\", np.shape(clean_train_images))\nclean_train_keypoints = load_keypoints(clean_train_data)\nprint(\"Shape of clean_train_keypoints:\", np.shape(clean_train_keypoints))\ntest_images = load_images(test_data)\nprint(\"Shape of test_images:\", np.shape(test_images))\n\ntrain_images = clean_train_images        #对clean操作后的images和keypoints进行数据增强\ntrain_keypoints = clean_train_keypoints\nfig, axis = plt.subplots()\nplot_sample(clean_train_images[19], clean_train_keypoints[19], axis, \"Sample image & keypoints\")\n\nunclean_train_images = load_images(unclean_train_data)\nprint(\"Shape of unclean_train_images:\", np.shape(unclean_train_images))\nunclean_train_keypoints = load_keypoints(unclean_train_data)\nprint(\"Shape of unclean_train_keypoints:\", np.shape(unclean_train_keypoints))\n\n#拼接数组train_images和unclean_train_images\ntrain_images = np.concatenate((train_images, unclean_train_images))\ntrain_keypoints = np.concatenate((train_keypoints, unclean_train_keypoints))","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:15.332829Z","iopub.execute_input":"2021-12-23T02:58:15.333166Z","iopub.status.idle":"2021-12-23T02:58:51.446355Z","shell.execute_reply.started":"2021-12-23T02:58:15.333138Z","shell.execute_reply":"2021-12-23T02:58:51.445438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"def left_right_flip(images, keypoints):\n    flipped_keypoints = []\n    flipped_images = np.flip(images, axis=2)   # Flip column-wise (axis=2)\n    for idx, sample_keypoints in enumerate(keypoints):\n        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx,coor in enumerate(sample_keypoints)])    # Subtract only X co-ordinates of keypoints from 96 for horizontal flipping\n    return flipped_images, flipped_keypoints\n\nif config.horizontal_flip:\n    flipped_train_images, flipped_train_keypoints = left_right_flip(clean_train_images, clean_train_keypoints)\n    print(\"Shape of flipped_train_images:\", np.shape(flipped_train_images))\n    print(\"Shape of flipped_train_keypoints:\", np.shape(flipped_train_keypoints))\n    train_images = np.concatenate((train_images, flipped_train_images))\n    train_keypoints = np.concatenate((train_keypoints, flipped_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(flipped_train_images[19], flipped_train_keypoints[19], axis, \"Horizontally Flipped\") ","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:51.447724Z","iopub.execute_input":"2021-12-23T02:58:51.448083Z","iopub.status.idle":"2021-12-23T02:58:51.458666Z","shell.execute_reply.started":"2021-12-23T02:58:51.448042Z","shell.execute_reply":"2021-12-23T02:58:51.457375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rotate_augmentation(images, keypoints):\n    rotated_images = []\n    rotated_keypoints = []\n    print(\"Augmenting for angles (in degrees): \")\n    for angle in config.rotation_angles:    # Rotation augmentation for a list of angle values\n        for angle in [angle,-angle]:\n            print(f'{angle}', end='  ')\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n            angle_rad = -angle*pi/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n            # For train_images\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            # For train_keypoints\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n                for idx in range(0,len(rotated_keypoint),2):\n                    # https://in.mathworks.com/matlabcentral/answers/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   # Add the earlier subtracted value\n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\nprint()\n\n#正负两种角度\nif config.rotation_augmentation:\n    rotated_train_images, rotated_train_keypoints = rotate_augmentation(clean_train_images, clean_train_keypoints)\n    print(\"Shape of rotated_train_images:\", np.shape(rotated_train_images))\n    print(\"Shape of rotated_train_keypoints:\", np.shape(rotated_train_keypoints))\n    train_images = np.concatenate((train_images, rotated_train_images))\n    train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(rotated_train_images[19], rotated_train_keypoints[19], axis, \"Rotation Augmentation\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:51.460111Z","iopub.execute_input":"2021-12-23T02:58:51.460505Z","iopub.status.idle":"2021-12-23T02:58:53.215218Z","shell.execute_reply.started":"2021-12-23T02:58:51.460466Z","shell.execute_reply":"2021-12-23T02:58:53.213688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    # Increased brightness by a factor of 1.2 & clip any values outside the range of [-1,1]\n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    # Decreased brightness by a factor of 0.6 & clip any values outside the range of [-1,1]\n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\n#明暗两种变换\nif config.brightness_augmentation:\n    altered_brightness_train_images, altered_brightness_train_keypoints = alter_brightness(clean_train_images, clean_train_keypoints)\n    print(\"Shape of altered_brightness_train_images:\", np.shape(altered_brightness_train_images))\n    print(\"Shape of altered_brightness_train_keypoints:\", np.shape(altered_brightness_train_keypoints))\n    train_images = np.concatenate((train_images, altered_brightness_train_images))\n    train_keypoints = np.concatenate((train_keypoints, altered_brightness_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_train_images[19], altered_brightness_train_keypoints[19], axis, \"Increased Brightness\") \n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_train_images[len(altered_brightness_train_images)//2+19], altered_brightness_train_keypoints[len(altered_brightness_train_images)//2+19], axis, \"Decreased Brightness\") ","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:53.221381Z","iopub.execute_input":"2021-12-23T02:58:53.224339Z","iopub.status.idle":"2021-12-23T02:58:54.496028Z","shell.execute_reply.started":"2021-12-23T02:58:53.224278Z","shell.execute_reply":"2021-12-23T02:58:54.495166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shift_images(images, keypoints):\n    shifted_images = []\n    shifted_keypoints = []\n    for shift in config.pixel_shifts:    # Augmenting over several pixel shift values\n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n    return shifted_images, shifted_keypoints\n\n#四个方向位移（移动有阈值）\nif config.shift_augmentation:\n    shifted_train_images, shifted_train_keypoints = shift_images(clean_train_images, clean_train_keypoints)\n    print(\"Shape of shifted_train_images:\", np.shape(shifted_train_images))\n    print(\"Shape of shifted_train_keypoints:\", np.shape(shifted_train_keypoints))\n    train_images = np.concatenate((train_images, shifted_train_images))\n    train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(shifted_train_images[19], shifted_train_keypoints[19], axis, \"Shift Augmentation\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:54.497521Z","iopub.execute_input":"2021-12-23T02:58:54.498103Z","iopub.status.idle":"2021-12-23T02:58:57.57615Z","shell.execute_reply.started":"2021-12-23T02:58:54.49806Z","shell.execute_reply":"2021-12-23T02:58:57.575301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#添加随机噪声\ndef add_noise(images):\n    noisy_images = []\n    for image in images:\n        noisy_image = cv2.add(image, 0.008*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n        noisy_images.append(noisy_image.reshape(96,96,1))\n    return noisy_images\n\nif config.random_noise_augmentation:\n    noisy_train_images = add_noise(clean_train_images)\n    print(\"Shape of noisy_train_images:\", np.shape(noisy_train_images))\n    train_images = np.concatenate((train_images, noisy_train_images))\n    train_keypoints = np.concatenate((train_keypoints, clean_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(noisy_train_images[19], clean_train_keypoints[19], axis, \"Random Noise Augmentation\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:57.577621Z","iopub.execute_input":"2021-12-23T02:58:57.578185Z","iopub.status.idle":"2021-12-23T02:58:59.373225Z","shell.execute_reply.started":"2021-12-23T02:58:57.578143Z","shell.execute_reply":"2021-12-23T02:58:59.372306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize Train images & corresponding Keypoints","metadata":{}},{"cell_type":"code","source":"print(\"Shape of final train_images:\", np.shape(train_images))   #增强前增强后所有数据相加\nprint(\"Shape of final train_keypoints:\", np.shape(train_keypoints))\n\nprint(\"\\nClean Train Data: \")\nfig = plt.figure(figsize=(20,8))\nfor i in range(10):\n    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n    plot_sample(clean_train_images[i], clean_train_keypoints[i], axis, \"\")\nplt.show()\n\nprint(\"Unclean Train Data: \")\nfig = plt.figure(figsize=(20,8))\nfor i in range(10):\n    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n    plot_sample(unclean_train_images[i], unclean_train_keypoints[i], axis, \"\")\nplt.show()\n\nif config.horizontal_flip:\n    print(\"Horizontal Flip Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(flipped_train_images[i], flipped_train_keypoints[i], axis, \"\")\n    plt.show()\n\nif config.rotation_augmentation:\n    print(\"Rotation Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(rotated_train_images[i], rotated_train_keypoints[i], axis, \"\")\n    plt.show()\n    \nif config.brightness_augmentation:\n    print(\"Brightness Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(altered_brightness_train_images[i], altered_brightness_train_keypoints[i], axis, \"\")\n    plt.show()\n\nif config.shift_augmentation:\n    print(\"Shift Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(shifted_train_images[i], shifted_train_keypoints[i], axis, \"\")\n    plt.show()\n    \nif config.random_noise_augmentation:\n    print(\"Random Noise Augmentation: \")\n    fig = plt.figure(figsize=(20,8))\n    for i in range(10):\n        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n        plot_sample(noisy_train_images[i], clean_train_keypoints[i], axis, \"\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:58:59.374795Z","iopub.execute_input":"2021-12-23T02:58:59.375408Z","iopub.status.idle":"2021-12-23T02:59:02.487551Z","shell.execute_reply.started":"2021-12-23T02:58:59.375364Z","shell.execute_reply":"2021-12-23T02:59:02.486548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\n#将处理过的图片送入预训练的特征网络中\n#Application提供了带有预训练权重的Keras模型\npretrained_model = applications.mobilenet_v2.MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')   #主干网络MobileNetV2做特征提取\n\npretrained_model.trainable = True    #不冻结\n\nmodel.add(layers.Convolution2D(3, (1, 1), padding='same', input_shape=(96,96,1)))\nmodel.add(layers.LeakyReLU(alpha = 0.1))\nmodel.add(pretrained_model)\nmodel.add(layers.GlobalAveragePooling2D())    #将每一张特征图计算所有像素点的均值，输出一个数据值\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(30))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:59:02.489327Z","iopub.execute_input":"2021-12-23T02:59:02.489751Z","iopub.status.idle":"2021-12-23T02:59:07.639982Z","shell.execute_reply.started":"2021-12-23T02:59:02.489709Z","shell.execute_reply":"2021-12-23T02:59:07.639027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.plot_model(model, show_shapes=True, expand_nested=True)\nvisualkeras.layered_view(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:59:07.641233Z","iopub.execute_input":"2021-12-23T02:59:07.641581Z","iopub.status.idle":"2021-12-23T02:59:08.994231Z","shell.execute_reply.started":"2021-12-23T02:59:07.641552Z","shell.execute_reply":"2021-12-23T02:59:08.993173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"#预训练\nearly_stop = callbacks.EarlyStopping(\n    monitor='loss', patience=30, verbose=1, mode='min', baseline=None, restore_best_weights=True\n)              #监控指标loss；用patience检查epoch数量\n\nrlp = callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-15, mode='min', verbose=1\n)\n\n#配置训练方法\nmodel.compile(\n    optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc']\n)\n\n#将训练过程记录在history中\n#model.fit执行训练过程\nhistory = model.fit(\n    train_images, train_keypoints, epochs=int(1.5*config.NUM_EPOCHS), batch_size=config.BATCH_SIZE, \n    validation_split=0.05, callbacks=[early_stop, rlp]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T02:59:08.995796Z","iopub.execute_input":"2021-12-23T02:59:08.996085Z","iopub.status.idle":"2021-12-23T04:00:36.393969Z","shell.execute_reply.started":"2021-12-23T02:59:08.996055Z","shell.execute_reply":"2021-12-23T04:00:36.393053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('darkgrid')\n\nfig, ax = plt.subplots(3, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['mae', 'val_mae']].plot(ax=ax[0])       #validation验证集\ndf[['loss', 'val_loss']].plot(ax=ax[1])\ndf[['acc', 'val_acc']].plot(ax=ax[2])\nax[0].set_title('Model MAE', fontsize=12)     #平方绝对误差\nax[1].set_title('Model Loss', fontsize=12)\nax[2].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","metadata":{"execution":{"iopub.status.busy":"2021-12-23T04:00:36.395938Z","iopub.execute_input":"2021-12-23T04:00:36.396341Z","iopub.status.idle":"2021-12-23T04:00:37.181003Z","shell.execute_reply.started":"2021-12-23T04:00:36.396298Z","shell.execute_reply":"2021-12-23T04:00:37.180133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fit the model on full dataset","metadata":{}},{"cell_type":"code","source":"%%time\n#微调\nearly_stop = callbacks.EarlyStopping(\n    monitor='loss', patience=30, verbose=1, mode='min', baseline=None, restore_best_weights=True\n)\n\nrlp = callbacks.ReduceLROnPlateau(\n    monitor='loss', factor=0.5, patience=5, min_lr=1e-15, mode='min', verbose=1\n)\n\n\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=history.history['lr'][-1]), loss='mean_squared_error', metrics=['mae', 'acc']\n)\n\nhistory = model.fit(\n    train_images, train_keypoints, epochs=2*config.NUM_EPOCHS, batch_size=config.BATCH_SIZE, callbacks=[early_stop, rlp]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T04:00:37.182398Z","iopub.execute_input":"2021-12-23T04:00:37.182966Z","iopub.status.idle":"2021-12-23T04:23:26.154152Z","shell.execute_reply.started":"2021-12-23T04:00:37.182922Z","shell.execute_reply":"2021-12-23T04:23:26.153342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['mae']].plot(ax=ax[0])\ndf[['loss']].plot(ax=ax[1])\ndf[['acc']].plot(ax=ax[2])\nax[0].set_title('Model MAE', fontsize=12)\nax[1].set_title('Model Loss', fontsize=12)\nax[2].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","metadata":{"execution":{"iopub.status.busy":"2021-12-23T04:23:26.156311Z","iopub.execute_input":"2021-12-23T04:23:26.156912Z","iopub.status.idle":"2021-12-23T04:23:27.337144Z","shell.execute_reply.started":"2021-12-23T04:23:26.156872Z","shell.execute_reply":"2021-12-23T04:23:27.3363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predicting on Test Set","metadata":{}},{"cell_type":"code","source":"%%time\n \ntest_preds = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T04:23:27.338598Z","iopub.execute_input":"2021-12-23T04:23:27.343092Z","iopub.status.idle":"2021-12-23T04:23:28.569713Z","shell.execute_reply.started":"2021-12-23T04:23:27.34305Z","shell.execute_reply":"2021-12-23T04:23:28.56893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing Test Predictions","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,16))\nfor i in range(20):\n    axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n    plot_sample(test_images[i], test_preds[i], axis, \"\")","metadata":{"execution":{"iopub.status.busy":"2021-12-23T04:23:28.571103Z","iopub.execute_input":"2021-12-23T04:23:28.571459Z","iopub.status.idle":"2021-12-23T04:23:29.602253Z","shell.execute_reply.started":"2021-12-23T04:23:28.571429Z","shell.execute_reply":"2021-12-23T04:23:29.601432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating Submission File","metadata":{}},{"cell_type":"code","source":"feature_names = list(idlookup_data['FeatureName'])\nimage_ids = list(idlookup_data['ImageId']-1)\nrow_ids = list(idlookup_data['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-23T04:23:29.603438Z","iopub.execute_input":"2021-12-23T04:23:29.603884Z","iopub.status.idle":"2021-12-23T04:23:30.080099Z","shell.execute_reply.started":"2021-12-23T04:23:29.603848Z","shell.execute_reply":"2021-12-23T04:23:30.079321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}