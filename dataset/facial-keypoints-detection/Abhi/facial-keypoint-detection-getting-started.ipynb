{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ## Facial Keypoint Detection\n \nI have tried to make a very simple kernal, which would help anyone in getting started with this exercise.\n\nOnce you are comfortable with this, you can go on to experiment with other methods to improve the accuracy. \n\n**Have fun and do upvote if you find this kernel helpful.**","metadata":{}},{"cell_type":"code","source":"#Import required libraries\nimport numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n#List the locations of input data and directories\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-30T07:18:35.003505Z","iopub.execute_input":"2022-03-30T07:18:35.003777Z","iopub.status.idle":"2022-03-30T07:18:35.011651Z","shell.execute_reply.started":"2022-03-30T07:18:35.003747Z","shell.execute_reply":"2022-03-30T07:18:35.010783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data to DataFrame","metadata":{}},{"cell_type":"code","source":"#Unzip the train and test data\n\n!unzip -o ../input/facial-keypoints-detection/test.zip\n!unzip -o ../input/facial-keypoints-detection/training.zip","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:35.013817Z","iopub.execute_input":"2022-03-30T07:18:35.014589Z","iopub.status.idle":"2022-03-30T07:18:38.977157Z","shell.execute_reply.started":"2022-03-30T07:18:35.014538Z","shell.execute_reply":"2022-03-30T07:18:38.976118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read csv data into a DataFrame\n\ntrain_data = pd.read_csv('./training.csv')\ntest_data = pd.read_csv('./test.csv')\nid_lookup = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:38.97925Z","iopub.execute_input":"2022-03-30T07:18:38.979542Z","iopub.status.idle":"2022-03-30T07:18:41.926232Z","shell.execute_reply.started":"2022-03-30T07:18:38.979499Z","shell.execute_reply":"2022-03-30T07:18:41.925484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Number of data samples in train and test set\n\nlen(train_data),len(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:41.928107Z","iopub.execute_input":"2022-03-30T07:18:41.928424Z","iopub.status.idle":"2022-03-30T07:18:41.936533Z","shell.execute_reply.started":"2022-03-30T07:18:41.928386Z","shell.execute_reply":"2022-03-30T07:18:41.935802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show sample training data \ntrain_data.head().T","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:41.938132Z","iopub.execute_input":"2022-03-30T07:18:41.938643Z","iopub.status.idle":"2022-03-30T07:18:41.963116Z","shell.execute_reply.started":"2022-03-30T07:18:41.938591Z","shell.execute_reply":"2022-03-30T07:18:41.962362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show sample test data\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:41.964433Z","iopub.execute_input":"2022-03-30T07:18:41.964686Z","iopub.status.idle":"2022-03-30T07:18:41.97591Z","shell.execute_reply.started":"2022-03-30T07:18:41.964653Z","shell.execute_reply":"2022-03-30T07:18:41.975197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show sample data from id_lookup file\nid_lookup.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:41.977013Z","iopub.execute_input":"2022-03-30T07:18:41.977418Z","iopub.status.idle":"2022-03-30T07:18:41.98724Z","shell.execute_reply.started":"2022-03-30T07:18:41.977381Z","shell.execute_reply":"2022-03-30T07:18:41.986473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for Null Values","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:41.988406Z","iopub.execute_input":"2022-03-30T07:18:41.988765Z","iopub.status.idle":"2022-03-30T07:18:42.001129Z","shell.execute_reply.started":"2022-03-30T07:18:41.98873Z","shell.execute_reply":"2022-03-30T07:18:42.000377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop null values\ntrain_data_clean = train_data.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:42.004045Z","iopub.execute_input":"2022-03-30T07:18:42.004231Z","iopub.status.idle":"2022-03-30T07:18:42.017012Z","shell.execute_reply.started":"2022-03-30T07:18:42.004209Z","shell.execute_reply":"2022-03-30T07:18:42.016364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Features and Labels for Training Model","metadata":{}},{"cell_type":"code","source":"#Create list of feature and labels\nimages = []\nlabels = []\n\nfor i, sample in train_data_clean.iterrows():\n    #Features\n    img = np.array((sample['Image'].split(' ')), dtype=float)\n    img = np.reshape(img, (96, 96, 1))\n    images.append(img)\n    #Labels\n    labels.append(sample[0:30])    ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:42.01811Z","iopub.execute_input":"2022-03-30T07:18:42.018542Z","iopub.status.idle":"2022-03-30T07:18:46.480151Z","shell.execute_reply.started":"2022-03-30T07:18:42.018503Z","shell.execute_reply":"2022-03-30T07:18:46.479421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot sample image and markers","metadata":{}},{"cell_type":"code","source":"# Define function to plot images and markers\ndef plot_image(img_id, img, lab, axis):\n    axis.imshow(img[img_id], cmap='gray')\n    axis.scatter(lab[img_id][0:30:2], lab[img_id][1:30:2], marker='x', c = 'red')\n\n# Plot 5 sample images\nfig = plt.figure(figsize=(18,6))\nfor i in range(5):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])    \n    plot_image(i, images, labels, ax)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:46.481387Z","iopub.execute_input":"2022-03-30T07:18:46.481662Z","iopub.status.idle":"2022-03-30T07:18:46.835607Z","shell.execute_reply.started":"2022-03-30T07:18:46.481611Z","shell.execute_reply":"2022-03-30T07:18:46.834873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a CNN model","metadata":{}},{"cell_type":"code","source":"# Import all building blocks to build a CNN using Keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, BatchNormalization, MaxPool2D, Flatten, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU","metadata":{"execution":{"iopub.status.busy":"2022-03-30T09:43:21.662209Z","iopub.execute_input":"2022-03-30T09:43:21.662645Z","iopub.status.idle":"2022-03-30T09:43:26.596892Z","shell.execute_reply.started":"2022-03-30T09:43:21.662607Z","shell.execute_reply":"2022-03-30T09:43:26.596008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the architecture for CNN model\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3,3), padding='same', input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(32, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(64, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.1))\n          \nmodel.add(Conv2D(128, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(128, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(256, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.1))\n          \nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(512, (3,3), padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T09:43:27.826516Z","iopub.execute_input":"2022-03-30T09:43:27.826775Z","iopub.status.idle":"2022-03-30T09:43:30.491023Z","shell.execute_reply.started":"2022-03-30T09:43:27.826738Z","shell.execute_reply":"2022-03-30T09:43:30.49032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compile model with optimizer and loss function\n\nmodel.compile(optimizer='adam', \n             loss='mean_squared_error',\n             metrics=[tf.keras.metrics.RootMeanSquaredError()])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:47.288766Z","iopub.execute_input":"2022-03-30T07:18:47.289004Z","iopub.status.idle":"2022-03-30T07:18:47.618475Z","shell.execute_reply.started":"2022-03-30T07:18:47.288973Z","shell.execute_reply":"2022-03-30T07:18:47.617779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting lists to array in order to be compatable with model.fit()\nimages = np.array(images, dtype=float)\nlabels = np.array(labels, dtype=float)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:18:47.619824Z","iopub.execute_input":"2022-03-30T07:18:47.620075Z","iopub.status.idle":"2022-03-30T07:18:47.703072Z","shell.execute_reply.started":"2022-03-30T07:18:47.620039Z","shell.execute_reply":"2022-03-30T07:18:47.702342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the model to training data\nhistory = model.fit(images, labels, epochs=500, validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T09:51:39.171362Z","iopub.execute_input":"2022-03-30T09:51:39.171617Z","iopub.status.idle":"2022-03-30T09:51:39.370634Z","shell.execute_reply.started":"2022-03-30T09:51:39.171588Z","shell.execute_reply":"2022-03-30T09:51:39.369555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Root Mean Squared Error (RMSE)","metadata":{}},{"cell_type":"code","source":"history.history.keys()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:20:13.794501Z","iopub.execute_input":"2022-03-30T07:20:13.794776Z","iopub.status.idle":"2022-03-30T07:20:13.799699Z","shell.execute_reply.started":"2022-03-30T07:20:13.794741Z","shell.execute_reply":"2022-03-30T07:20:13.798959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\nax1.plot(history.history['root_mean_squared_error'])\nax1.plot(history.history['val_root_mean_squared_error'])\nax1.set_title('RMS Error')\nax1.set(xlabel='epoch', ylabel='rms')\nax1.legend(['train', 'val'])\n\nax2.plot(history.history['loss'])\nax2.plot(history.history['val_loss'])\nax2.set_title('Loss')\nax1.set(xlabel='epoch', ylabel='rms')\nax2.legend(['train', 'val'])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:20:13.801004Z","iopub.execute_input":"2022-03-30T07:20:13.801487Z","iopub.status.idle":"2022-03-30T07:20:14.159183Z","shell.execute_reply.started":"2022-03-30T07:20:13.801441Z","shell.execute_reply":"2022-03-30T07:20:14.158479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predicting on Test set","metadata":{}},{"cell_type":"code","source":"#Create test data\ntest_images = []\n\nfor i, sample in test_data.iterrows():\n    #Features\n    img = np.array((sample['Image'].split(' ')), dtype=float)\n    img = np.reshape(img, (96, 96, 1))\n    test_images.append(img) \ntest_images = np.array(test_images, dtype=float)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:20:14.160571Z","iopub.execute_input":"2022-03-30T07:20:14.161029Z","iopub.status.idle":"2022-03-30T07:20:17.722934Z","shell.execute_reply.started":"2022-03-30T07:20:14.160993Z","shell.execute_reply":"2022-03-30T07:20:17.722161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict on test set\npred = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:20:17.72636Z","iopub.execute_input":"2022-03-30T07:20:17.726572Z","iopub.status.idle":"2022-03-30T07:20:18.669172Z","shell.execute_reply.started":"2022-03-30T07:20:17.726547Z","shell.execute_reply":"2022-03-30T07:20:18.668363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualising Test Predictions","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,6))\nfor i in range(5):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n    plot_image(i, test_images, pred, ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:20:18.671642Z","iopub.execute_input":"2022-03-30T07:20:18.672105Z","iopub.status.idle":"2022-03-30T07:20:18.976069Z","shell.execute_reply.started":"2022-03-30T07:20:18.672065Z","shell.execute_reply":"2022-03-30T07:20:18.975453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating Submission File","metadata":{}},{"cell_type":"code","source":"row_ids = list(id_lookup['RowId'])\nimg_ids = list(id_lookup['ImageId']-1)\nfeature_names = list(id_lookup['FeatureName'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(img_ids, feature_list):\n    predictions.append(pred[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location').clip(0,96)\n\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)    ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T07:20:18.977436Z","iopub.execute_input":"2022-03-30T07:20:18.977904Z","iopub.status.idle":"2022-03-30T07:20:19.109788Z","shell.execute_reply.started":"2022-03-30T07:20:18.977867Z","shell.execute_reply":"2022-03-30T07:20:19.109053Z"},"trusted":true},"execution_count":null,"outputs":[]}]}