{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-12T17:44:25.156682Z","iopub.execute_input":"2021-10-12T17:44:25.157245Z","iopub.status.idle":"2021-10-12T17:44:25.252286Z","shell.execute_reply.started":"2021-10-12T17:44:25.157156Z","shell.execute_reply":"2021-10-12T17:44:25.251162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip ../input/facial-keypoints-detection/test.zip -d /kaggle/working/\n!unzip ../input/facial-keypoints-detection/training.zip -d /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:25.2539Z","iopub.execute_input":"2021-10-12T17:44:25.25428Z","iopub.status.idle":"2021-10-12T17:44:29.627796Z","shell.execute_reply.started":"2021-10-12T17:44:25.254244Z","shell.execute_reply":"2021-10-12T17:44:29.62701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"./test.csv\")\ntrain = pd.read_csv(\"./training.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:29.629163Z","iopub.execute_input":"2021-10-12T17:44:29.62945Z","iopub.status.idle":"2021-10-12T17:44:32.173159Z","shell.execute_reply.started":"2021-10-12T17:44:29.62941Z","shell.execute_reply":"2021-10-12T17:44:32.17244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:32.174439Z","iopub.execute_input":"2021-10-12T17:44:32.174685Z","iopub.status.idle":"2021-10-12T17:44:32.185924Z","shell.execute_reply.started":"2021-10-12T17:44:32.174654Z","shell.execute_reply":"2021-10-12T17:44:32.185015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train =train.dropna()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:32.188999Z","iopub.execute_input":"2021-10-12T17:44:32.189863Z","iopub.status.idle":"2021-10-12T17:44:32.21633Z","shell.execute_reply.started":"2021-10-12T17:44:32.189827Z","shell.execute_reply":"2021-10-12T17:44:32.215733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_without_images = train.drop(\"Image\",1)\nimages = train[\"Image\"]\n","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:32.217461Z","iopub.execute_input":"2021-10-12T17:44:32.217916Z","iopub.status.idle":"2021-10-12T17:44:32.224241Z","shell.execute_reply.started":"2021-10-12T17:44:32.217883Z","shell.execute_reply":"2021-10-12T17:44:32.223532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_without_images.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:32.225327Z","iopub.execute_input":"2021-10-12T17:44:32.225713Z","iopub.status.idle":"2021-10-12T17:44:32.261012Z","shell.execute_reply.started":"2021-10-12T17:44:32.22568Z","shell.execute_reply":"2021-10-12T17:44:32.260301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_data = []\nfor img in images:\n    img = [int(i) for i in img.split(\" \")]\n    img = np.array(img)\n    img = img.reshape(96,96,1)\n    img_data.append(img)\nimg_data = np.array(img_data)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:32.262003Z","iopub.execute_input":"2021-10-12T17:44:32.262351Z","iopub.status.idle":"2021-10-12T17:44:39.816514Z","shell.execute_reply.started":"2021-10-12T17:44:32.262321Z","shell.execute_reply":"2021-10-12T17:44:39.815688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keypoint_features = []\nfor idx, features in df_without_images.iterrows():\n    keypoint_features.append(features)\nkeypoint_features = np.array(keypoint_features, dtype=float)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:39.817808Z","iopub.execute_input":"2021-10-12T17:44:39.818264Z","iopub.status.idle":"2021-10-12T17:44:39.997306Z","shell.execute_reply.started":"2021-10-12T17:44:39.818226Z","shell.execute_reply":"2021-10-12T17:44:39.996683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:39.998575Z","iopub.execute_input":"2021-10-12T17:44:39.998826Z","iopub.status.idle":"2021-10-12T17:44:40.004151Z","shell.execute_reply.started":"2021-10-12T17:44:39.998795Z","shell.execute_reply":"2021-10-12T17:44:40.003332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_indexes = np.random.randint(0,img_data.shape[0],9)\nprint(rand_indexes)\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(3*4, 3*4))\nfor r in range(3):\n    for c in range(3):\n        idx = r * 3 + c\n        axes[r, c].imshow(img_data[rand_indexes[r+c]])\n        axes[r, c].scatter(keypoint_features[rand_indexes[r+c]][0::2], keypoint_features[rand_indexes[r+c]][1::2], s=20,c=\"white\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:40.005703Z","iopub.execute_input":"2021-10-12T17:44:40.005967Z","iopub.status.idle":"2021-10-12T17:44:41.576785Z","shell.execute_reply.started":"2021-10-12T17:44:40.005931Z","shell.execute_reply":"2021-10-12T17:44:41.576088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"norm_images = img_data / 255.0\nnorm_keypoints = keypoint_features / 96.0","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:41.577691Z","iopub.execute_input":"2021-10-12T17:44:41.577931Z","iopub.status.idle":"2021-10-12T17:44:41.644463Z","shell.execute_reply.started":"2021-10-12T17:44:41.577903Z","shell.execute_reply":"2021-10-12T17:44:41.643717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(101)\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,Activation,BatchNormalization\nfrom tensorflow.keras.models import Sequential,Model,load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:41.645872Z","iopub.execute_input":"2021-10-12T17:44:41.646136Z","iopub.status.idle":"2021-10-12T17:44:45.984607Z","shell.execute_reply.started":"2021-10-12T17:44:41.646105Z","shell.execute_reply":"2021-10-12T17:44:45.983877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv2d_model():\n    model = Sequential()\n    \n    model.add(Conv2D(3, (1,1), padding='same', input_shape=(96,96,1)))\n    pretrained_model = MobileNetV2(input_shape=(96,96,3), include_top=False, weights='imagenet')\n    pretrained_model.trainable = True\n    model.add(pretrained_model)\n    \n    model.add(Flatten())\n    #flatten = GlobalAveragePooling2D()(flatten)\n    model.add(Dense(1024, activation=\"relu\"))\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dense(256, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(Dense(64, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(32, activation=\"relu\"))\n\n    model.add(Dense(30))\n    model.compile(loss='mse', optimizer=Adam(learning_rate =0.003),metrics=['accuracy',\"mse\"])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:44:45.98702Z","iopub.execute_input":"2021-10-12T17:44:45.987218Z","iopub.status.idle":"2021-10-12T17:44:45.996635Z","shell.execute_reply.started":"2021-10-12T17:44:45.987195Z","shell.execute_reply":"2021-10-12T17:44:45.995667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = conv2d_model()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:47:07.79393Z","iopub.execute_input":"2021-10-12T17:47:07.79421Z","iopub.status.idle":"2021-10-12T17:47:09.127462Z","shell.execute_reply.started":"2021-10-12T17:47:07.794181Z","shell.execute_reply":"2021-10-12T17:47:09.12671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:47:09.129094Z","iopub.execute_input":"2021-10-12T17:47:09.129346Z","iopub.status.idle":"2021-10-12T17:47:09.152386Z","shell.execute_reply.started":"2021-10-12T17:47:09.129313Z","shell.execute_reply":"2021-10-12T17:47:09.151736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EarlyStopper = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=10)\ncheckpoint_path_quality = f\"/kaggle/working/face_kp.h5\"\n\ncheckpoint = ModelCheckpoint(checkpoint_path_quality, \n                             monitor='mse', \n                             verbose=1,\n                             save_best_only=True, \n                             mode='min')\nlearning_rate_reduction = ReduceLROnPlateau(monitor='mse',\n                                            patience=2,\n                                            verbose=1,\n                                            factor=0.5,\n                                            min_lr=0.000001)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:47:09.154841Z","iopub.execute_input":"2021-10-12T17:47:09.155032Z","iopub.status.idle":"2021-10-12T17:47:09.160168Z","shell.execute_reply.started":"2021-10-12T17:47:09.15501Z","shell.execute_reply":"2021-10-12T17:47:09.159529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(norm_images,norm_keypoints, batch_size = 16,\n\tepochs=20,callbacks = [checkpoint,learning_rate_reduction,EarlyStopper])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:47:09.162106Z","iopub.execute_input":"2021-10-12T17:47:09.162368Z","iopub.status.idle":"2021-10-12T17:48:50.470179Z","shell.execute_reply.started":"2021-10-12T17:47:09.162322Z","shell.execute_reply":"2021-10-12T17:48:50.46933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"test_images = test[\"Image\"]","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:51:18.146623Z","iopub.execute_input":"2021-10-12T17:51:18.147421Z","iopub.status.idle":"2021-10-12T17:51:18.152182Z","shell.execute_reply.started":"2021-10-12T17:51:18.147375Z","shell.execute_reply":"2021-10-12T17:51:18.151108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img_data = []\nfor img in test_images:\n    img = [int(i) for i in img.split(\" \")]\n    img = np.array(img)\n    img = img.reshape(96,96,1)\n    test_img_data.append(img)\ntest_img_data = np.array(test_img_data)\ntest_img_data = test_img_data/ 255.0","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:51:19.455799Z","iopub.execute_input":"2021-10-12T17:51:19.456548Z","iopub.status.idle":"2021-10-12T17:51:25.658007Z","shell.execute_reply.started":"2021-10-12T17:51:19.456504Z","shell.execute_reply":"2021-10-12T17:51:25.657265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = load_model(\"/kaggle/working/face_kp.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:48:59.715946Z","iopub.execute_input":"2021-10-12T17:48:59.716545Z","iopub.status.idle":"2021-10-12T17:49:01.858807Z","shell.execute_reply.started":"2021-10-12T17:48:59.716495Z","shell.execute_reply":"2021-10-12T17:49:01.857964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict = loaded_model.predict(test_img_data)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:52:11.453658Z","iopub.execute_input":"2021-10-12T17:52:11.453912Z","iopub.status.idle":"2021-10-12T17:52:12.714297Z","shell.execute_reply.started":"2021-10-12T17:52:11.453885Z","shell.execute_reply":"2021-10-12T17:52:12.713553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predict = test_predict * 96","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:52:34.107603Z","iopub.execute_input":"2021-10-12T17:52:34.107877Z","iopub.status.idle":"2021-10-12T17:52:34.113773Z","shell.execute_reply.started":"2021-10-12T17:52:34.107849Z","shell.execute_reply":"2021-10-12T17:52:34.112725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_indexes = np.random.randint(0,test_img_data.shape[0],9)\nprint(rand_indexes)\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(3*4, 3*4))\nfor r in range(3):\n    for c in range(3):\n        idx = r * 3 + c\n        axes[r, c].imshow(test_img_data[rand_indexes[r+c]])\n        axes[r, c].scatter(test_predict[rand_indexes[r+c]][0::2], test_predict[rand_indexes[r+c]][1::2], s=20,c=\"white\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:54:44.770933Z","iopub.execute_input":"2021-10-12T17:54:44.771548Z","iopub.status.idle":"2021-10-12T17:54:46.290451Z","shell.execute_reply.started":"2021-10-12T17:54:44.771506Z","shell.execute_reply":"2021-10-12T17:54:46.289675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idlookup_file = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv')\nfeature_names = list(idlookup_file['FeatureName'])\nimage_ids = list(idlookup_file['ImageId']-1)\nrow_ids = list(idlookup_file['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_predict[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T17:59:24.069013Z","iopub.execute_input":"2021-10-12T17:59:24.069799Z","iopub.status.idle":"2021-10-12T17:59:24.254811Z","shell.execute_reply.started":"2021-10-12T17:59:24.069765Z","shell.execute_reply":"2021-10-12T17:59:24.253981Z"},"trusted":true},"execution_count":null,"outputs":[]}]}