{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Truong Van Gia Lan 19146204 \nTính toán tỉ lệ vàng khuôn mặt dựa trên tọa độ mốc.\n","metadata":{}},{"cell_type":"code","source":"#Import required libraries\nimport numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n#List the locations of input data and directories\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-22T20:59:22.342131Z","iopub.execute_input":"2022-06-22T20:59:22.342666Z","iopub.status.idle":"2022-06-22T20:59:27.251935Z","shell.execute_reply.started":"2022-06-22T20:59:22.342573Z","shell.execute_reply":"2022-06-22T20:59:27.251194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data to DataFrame","metadata":{}},{"cell_type":"code","source":"#Unzip the train and test data\n\n!unzip -o ../input/facial-keypoints-detection/test.zip\n!unzip -o ../input/facial-keypoints-detection/training.zip","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:27.253679Z","iopub.execute_input":"2022-06-22T20:59:27.253939Z","iopub.status.idle":"2022-06-22T20:59:31.055312Z","shell.execute_reply.started":"2022-06-22T20:59:27.253904Z","shell.execute_reply":"2022-06-22T20:59:31.05441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read csv data into a DataFrame\n\ntrain_data = pd.read_csv('./training.csv')\ntest_data = pd.read_csv('./test.csv')\nid_lookup = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:31.056742Z","iopub.execute_input":"2022-06-22T20:59:31.057068Z","iopub.status.idle":"2022-06-22T20:59:33.770548Z","shell.execute_reply.started":"2022-06-22T20:59:31.057028Z","shell.execute_reply":"2022-06-22T20:59:33.769833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Number of data samples in train and test set\n\nlen(train_data),len(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:33.772582Z","iopub.execute_input":"2022-06-22T20:59:33.772773Z","iopub.status.idle":"2022-06-22T20:59:33.77955Z","shell.execute_reply.started":"2022-06-22T20:59:33.77275Z","shell.execute_reply":"2022-06-22T20:59:33.77891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show sample training data \n\ntrain_data = train_data[['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y', 'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x', 'mouth_right_corner_y', 'Image']]\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:33.780675Z","iopub.execute_input":"2022-06-22T20:59:33.781429Z","iopub.status.idle":"2022-06-22T20:59:33.81535Z","shell.execute_reply.started":"2022-06-22T20:59:33.781394Z","shell.execute_reply":"2022-06-22T20:59:33.814672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show sample test data\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:33.816448Z","iopub.execute_input":"2022-06-22T20:59:33.81673Z","iopub.status.idle":"2022-06-22T20:59:33.828413Z","shell.execute_reply.started":"2022-06-22T20:59:33.816692Z","shell.execute_reply":"2022-06-22T20:59:33.827466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show sample data from id_lookup file\nid_lookup.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:33.829871Z","iopub.execute_input":"2022-06-22T20:59:33.831229Z","iopub.status.idle":"2022-06-22T20:59:33.841638Z","shell.execute_reply.started":"2022-06-22T20:59:33.831189Z","shell.execute_reply":"2022-06-22T20:59:33.840878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for Null Values","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:33.842905Z","iopub.execute_input":"2022-06-22T20:59:33.843593Z","iopub.status.idle":"2022-06-22T20:59:33.85459Z","shell.execute_reply.started":"2022-06-22T20:59:33.843555Z","shell.execute_reply":"2022-06-22T20:59:33.85376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop null values\ntrain_data_clean = train_data.dropna()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:33.856034Z","iopub.execute_input":"2022-06-22T20:59:33.85641Z","iopub.status.idle":"2022-06-22T20:59:33.865723Z","shell.execute_reply.started":"2022-06-22T20:59:33.856373Z","shell.execute_reply":"2022-06-22T20:59:33.865005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Features and Labels for Training Model","metadata":{}},{"cell_type":"code","source":"#Create list of feature and labels\nimages = []\nlabels = []\n\nfor i, sample in train_data_clean.iterrows():\n    #Features\n    img = np.array((sample['Image'].split(' ')), dtype=float)\n    img = np.reshape(img, (96, 96, 1))\n    images.append(img)\n    #Labels\n    labels.append(sample[0:8])    ","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:33.869188Z","iopub.execute_input":"2022-06-22T20:59:33.870847Z","iopub.status.idle":"2022-06-22T20:59:39.102436Z","shell.execute_reply.started":"2022-06-22T20:59:33.870818Z","shell.execute_reply":"2022-06-22T20:59:39.101717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot sample image and markers","metadata":{}},{"cell_type":"code","source":"# Define function to plot images and markers\ndef plot_image(img_id, img, lab, axis):\n    axis.imshow(img[img_id], cmap='gray')\n    axis.scatter(lab[img_id][0:30:2], lab[img_id][1:30:2], marker='x', c = 'red')\n\n# Plot 5 sample images\nfig = plt.figure(figsize=(18,6))\nfor i in range(5):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])    \n    plot_image(i, images, labels, ax)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:39.103621Z","iopub.execute_input":"2022-06-22T20:59:39.103888Z","iopub.status.idle":"2022-06-22T20:59:39.455296Z","shell.execute_reply.started":"2022-06-22T20:59:39.103855Z","shell.execute_reply":"2022-06-22T20:59:39.454628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a CNN model","metadata":{}},{"cell_type":"code","source":"# Import all building blocks to build a CNN using Keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, BatchNormalization, MaxPool2D, Flatten, Dropout, MaxPooling2D\nfrom keras import Input\n#from keras.layers.advanced_activations import LeakyReLU","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:39.456246Z","iopub.execute_input":"2022-06-22T20:59:39.456474Z","iopub.status.idle":"2022-06-22T20:59:40.009857Z","shell.execute_reply.started":"2022-06-22T20:59:39.456441Z","shell.execute_reply":"2022-06-22T20:59:40.009099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the architecture for CNN model\n\n# model = Sequential()\n\n# model.add(Conv2D(32, (3,3), padding='same', input_shape=(96,96,1),activation='relu'))\n# # model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(32, (3,3), padding='same'))\n# # model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D((2,2)))\n# model.add(Dropout(0.1))\n\n# model.add(Conv2D(64, (3,3), padding='same'))\n# # model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, (3,3), padding='same'))\n# # model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D((2,2)))\n# model.add(Dropout(0.1))\n          \n# model.add(Conv2D(128, (3,3), padding='same'))\n# # model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(128, (3,3), padding='same'))\n# # model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D((2,2)))\n# model.add(Dropout(0.1))\n\n# model.add(Conv2D(256, (3,3), padding='same'))\n# # model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(256, (3,3), padding='same'))\n# # model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D((2,2)))\n# model.add(Dropout(0.1))\n          \n# model.add(Conv2D(512, (3,3), padding='same'))\n# model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(512, (3,3), padding='same'))\n# model.add(LeakyReLU(alpha=0.1))\n# model.add(BatchNormalization())\n# model.add(MaxPool2D((2,2)))\n# model.add(Dropout(0.1))\n\n# model.add(Flatten())\n# model.add(Dense(512,activation='relu'))\n# model.add(Dropout(0.1))\n# model.add(Dense(8))\n###########################################################################3\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3,3), padding='same', input_shape=(96,96,1), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(32, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n          \nmodel.add(Conv2D(128, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(256, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n          \nmodel.add(Conv2D(512, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(8))\n\n# model = Sequential([\n#     Conv2D(input_shape=(96,96,1), filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n#     Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n#     MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n#     BatchNormalization(),\n    \n#     Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'),\n#     Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'),\n#     MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n#     BatchNormalization(),\n    \n#     Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'),\n#     Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'),\n#     Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'),\n#     MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n#     BatchNormalization(),\n    \n#     Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'),\n#     Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'),\n#     Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'),\n#     MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n#     BatchNormalization(),\n    \n#     Conv2D(filters=1024, kernel_size=(3,3), padding='same', activation='relu'),\n#     Conv2D(filters=1024, kernel_size=(3,3), padding='same', activation='relu'),\n# #     Conv2D(filters=1024, kernel_size=(3,3), padding='same', activation='relu'),\n#     MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n#     BatchNormalization(),\n#     Flatten(),\n#     Dense(4082, activation=\"relu\"),\n#     Dropout(0.1),\n#     Dense(4082,activation=\"relu\"),\n#     Dropout(0.1),\n#     Dense(8)\n# ])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:40.01134Z","iopub.execute_input":"2022-06-22T20:59:40.01168Z","iopub.status.idle":"2022-06-22T20:59:43.182001Z","shell.execute_reply.started":"2022-06-22T20:59:40.011642Z","shell.execute_reply":"2022-06-22T20:59:43.181318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compile model with optimizer and loss function\nimport tensorflow as tf\nfrom tensorflow import keras\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), \n             loss='mean_squared_error',\n#              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n              metrics=['accuracy',tf.keras.metrics.RootMeanSquaredError()])","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:43.183224Z","iopub.execute_input":"2022-06-22T20:59:43.183455Z","iopub.status.idle":"2022-06-22T20:59:43.541651Z","shell.execute_reply.started":"2022-06-22T20:59:43.183422Z","shell.execute_reply":"2022-06-22T20:59:43.540932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting lists to array in order to be compatable with model.fit()\nimages = np.array(images, dtype=float)\nlabels = np.array(labels, dtype=float)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:43.543028Z","iopub.execute_input":"2022-06-22T20:59:43.54326Z","iopub.status.idle":"2022-06-22T20:59:43.623807Z","shell.execute_reply.started":"2022-06-22T20:59:43.543227Z","shell.execute_reply":"2022-06-22T20:59:43.623074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the model to training data\nhistory = model.fit(images, labels, epochs=100, validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:59:43.625222Z","iopub.execute_input":"2022-06-22T20:59:43.62547Z","iopub.status.idle":"2022-06-22T21:02:45.989629Z","shell.execute_reply.started":"2022-06-22T20:59:43.625436Z","shell.execute_reply":"2022-06-22T21:02:45.988978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Root Mean Squared Error (RMSE)","metadata":{}},{"cell_type":"code","source":"history.history.keys()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:45.991443Z","iopub.execute_input":"2022-06-22T21:02:45.991722Z","iopub.status.idle":"2022-06-22T21:02:45.997126Z","shell.execute_reply.started":"2022-06-22T21:02:45.991683Z","shell.execute_reply":"2022-06-22T21:02:45.996353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2,) = plt.subplots(1, 2,  figsize=(15,5))\nax1.plot(history.history['root_mean_squared_error'])\nax1.plot(history.history['val_root_mean_squared_error'])\nax1.set_title('RMS Error')\nax1.set(xlabel='epoch', ylabel='rms')\nax1.legend(['train', 'val'])\n\nax2.plot(history.history['accuracy'])\nax2.plot(history.history['val_accuracy'])\nax2.set_title('accuracy')\nax1.set(xlabel='epoch', ylabel='rms')\nax2.legend(['train', 'val'])\n\n# ax3.plot(history.history['loss'])\n# ax3.plot(history.history['val_loss'])\n# ax3.set_title('Loss')\n# ax1.set(xlabel='epoch', ylabel='rms')\n# ax3.legend(['train', 'val'])","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:45.998811Z","iopub.execute_input":"2022-06-22T21:02:45.999438Z","iopub.status.idle":"2022-06-22T21:02:46.352254Z","shell.execute_reply.started":"2022-06-22T21:02:45.999394Z","shell.execute_reply":"2022-06-22T21:02:46.351551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predicting on Test set","metadata":{}},{"cell_type":"code","source":"#Create test data\ntest_images = []\n\nfor i, sample in test_data.iterrows():\n    #Features\n    img = np.array((sample['Image'].split(' ')), dtype=float)\n    img = np.reshape(img, (96, 96, 1))\n#     print(img.shape)\n    test_images.append(img) \ntest_images = np.array(test_images, dtype=float)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:46.353607Z","iopub.execute_input":"2022-06-22T21:02:46.353864Z","iopub.status.idle":"2022-06-22T21:02:50.021731Z","shell.execute_reply.started":"2022-06-22T21:02:46.35383Z","shell.execute_reply":"2022-06-22T21:02:50.020982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict on test set\npred = model.predict(test_images)\npred","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:50.023437Z","iopub.execute_input":"2022-06-22T21:02:50.023715Z","iopub.status.idle":"2022-06-22T21:02:51.041368Z","shell.execute_reply.started":"2022-06-22T21:02:50.023675Z","shell.execute_reply":"2022-06-22T21:02:51.04066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualising Test Predictions","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,6))\nfor i in range(4):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n    plot_image(i+1, test_images, pred, ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:51.042502Z","iopub.execute_input":"2022-06-22T21:02:51.042763Z","iopub.status.idle":"2022-06-22T21:02:51.291709Z","shell.execute_reply.started":"2022-06-22T21:02:51.042728Z","shell.execute_reply":"2022-06-22T21:02:51.29065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(18,6))\nfor i in range(5):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n    plot_image(i+25, test_images, pred, ax)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:51.293007Z","iopub.execute_input":"2022-06-22T21:02:51.293273Z","iopub.status.idle":"2022-06-22T21:02:51.586058Z","shell.execute_reply.started":"2022-06-22T21:02:51.293236Z","shell.execute_reply":"2022-06-22T21:02:51.585362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('my_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:51.587264Z","iopub.execute_input":"2022-06-22T21:02:51.587596Z","iopub.status.idle":"2022-06-22T21:02:51.852467Z","shell.execute_reply.started":"2022-06-22T21:02:51.587563Z","shell.execute_reply":"2022-06-22T21:02:51.851722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport dlib\nimport argparse\nimport time\nimport numpy as np\nfrom keras.models import load_model\n\nfrom IPython.display import Image\nimport os\n!ls ../input/\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:51.853863Z","iopub.execute_input":"2022-06-22T21:02:51.854125Z","iopub.status.idle":"2022-06-22T21:02:52.917816Z","shell.execute_reply.started":"2022-06-22T21:02:51.854089Z","shell.execute_reply":"2022-06-22T21:02:52.916821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define function to plot images and markers\nfrom math import sqrt\ndef plot_image(img_id, img, lab, axis):\n    GOLDEN_RATIO = 1.618\n    axis.imshow(img[img_id], cmap='gray')\n    axis.scatter(lab[img_id][0:8:2], lab[img_id][1:8:2], marker='x', c = 'red')\n    eye_distance = sqrt((lab[img_id][0] - lab[img_id][2]) ** 2 + (lab[img_id][1] - lab[img_id][3]) ** 2)\n    mouth_distance = sqrt((lab[img_id][4] - lab[img_id][6]) ** 2 + (lab[img_id][5] - lab[img_id][7]) ** 2)\n    axis.set_xlabel(f'Golden ratio:  {(eye_distance / mouth_distance) * 100/ GOLDEN_RATIO:.2f}%')\n# Plot 5 sample images\nfig = plt.figure(figsize=(18,6))\nfor i in range(4):\n    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])    \n    plot_image(i, images, labels, ax)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:52.919868Z","iopub.execute_input":"2022-06-22T21:02:52.920164Z","iopub.status.idle":"2022-06-22T21:02:53.253809Z","shell.execute_reply.started":"2022-06-22T21:02:52.920124Z","shell.execute_reply":"2022-06-22T21:02:53.253147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path =\"../input/test-555555/2.png\"\nimage = tf.keras.preprocessing.image.load_img(path, color_mode='grayscale', target_size=(96,96,1),  interpolation=\"nearest\")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr], dtype=float)  # Convert single image to a batch.\nprint(input_arr.shape)\nprediction = model.predict(input_arr)\nprint(prediction)\nfig = plt.figure(figsize=(18,6))\nfor i in range(1):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n    plot_image(i, input_arr, prediction, ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:53.254912Z","iopub.execute_input":"2022-06-22T21:02:53.255268Z","iopub.status.idle":"2022-06-22T21:02:53.442274Z","shell.execute_reply.started":"2022-06-22T21:02:53.255233Z","shell.execute_reply":"2022-06-22T21:02:53.441428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path =\"../input/test-thucte/2.jpg\"\nimage = tf.keras.preprocessing.image.load_img(path, color_mode='grayscale', target_size=(96,96,1),  interpolation=\"nearest\")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr], dtype=float)  # Convert single image to a batch.\nprint(input_arr.shape)\nprediction = model.predict(input_arr)\nprint(prediction)\nfig = plt.figure(figsize=(50,6))\nfor i in range(1):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n    plot_image(i, input_arr, prediction, ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:53.446498Z","iopub.execute_input":"2022-06-22T21:02:53.446789Z","iopub.status.idle":"2022-06-22T21:02:53.604355Z","shell.execute_reply.started":"2022-06-22T21:02:53.446733Z","shell.execute_reply":"2022-06-22T21:02:53.603606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path =\"../input/test-thucte/2.jpg\"\nimage = tf.keras.preprocessing.image.load_img(path, color_mode='grayscale', target_size=(96,96,1),  interpolation=\"nearest\")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr], dtype=float)  # Convert single image to a batch.\nprint(input_arr.shape)\nprediction = model.predict(input_arr)\nprint(prediction)\nfig = plt.figure(figsize=(50,6))\nfor i in range(1):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n    plot_image(i, input_arr, prediction, ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:53.608904Z","iopub.execute_input":"2022-06-22T21:02:53.609482Z","iopub.status.idle":"2022-06-22T21:02:53.781202Z","shell.execute_reply.started":"2022-06-22T21:02:53.60944Z","shell.execute_reply":"2022-06-22T21:02:53.78032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path =\"../input/test-555555/1.png\"\nimage = tf.keras.preprocessing.image.load_img(path, color_mode='grayscale', target_size=(96,96,1),  interpolation=\"nearest\")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr], dtype=float)  # Convert single image to a batch.\nprint(input_arr.shape)\nprediction = model.predict(input_arr)\nprint(prediction)\nfig = plt.figure(figsize=(18,6))\nfor i in range(1):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n    plot_image(i, input_arr, prediction, ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:53.786513Z","iopub.execute_input":"2022-06-22T21:02:53.787128Z","iopub.status.idle":"2022-06-22T21:02:53.971871Z","shell.execute_reply.started":"2022-06-22T21:02:53.78708Z","shell.execute_reply":"2022-06-22T21:02:53.97101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path =\"../input/test-nu-lan-3/3.jpg\"\nimage = tf.keras.preprocessing.image.load_img(path, color_mode='grayscale', target_size=(96,96,1),  interpolation=\"nearest\")\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr], dtype=float)  # Convert single image to a batch.\nprint(input_arr.shape)\nprediction = model.predict(input_arr)\nprint(prediction)\nfig = plt.figure(figsize=(50,6))\nfor i in range(1):\n    ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n    plot_image(i, input_arr, prediction, ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T21:02:53.973415Z","iopub.execute_input":"2022-06-22T21:02:53.973693Z","iopub.status.idle":"2022-06-22T21:02:54.141002Z","shell.execute_reply.started":"2022-06-22T21:02:53.973658Z","shell.execute_reply":"2022-06-22T21:02:54.140172Z"},"trusted":true},"execution_count":null,"outputs":[]}]}