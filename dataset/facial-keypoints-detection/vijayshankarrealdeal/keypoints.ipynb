{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!unzip '../input/facial-keypoints-detection/training.zip'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-20T06:51:42.861479Z","iopub.execute_input":"2022-01-20T06:51:42.861751Z","iopub.status.idle":"2022-01-20T06:51:42.865466Z","shell.execute_reply.started":"2022-01-20T06:51:42.861723Z","shell.execute_reply":"2022-01-20T06:51:42.86436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip '../input/facial-keypoints-detection/test.zip'","metadata":{"execution":{"iopub.status.busy":"2022-01-20T06:51:42.871624Z","iopub.execute_input":"2022-01-20T06:51:42.872062Z","iopub.status.idle":"2022-01-20T06:51:42.875784Z","shell.execute_reply.started":"2022-01-20T06:51:42.872019Z","shell.execute_reply":"2022-01-20T06:51:42.874932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 1e-4\nWEIGHT_DECAY = 5e-4\nBATCH_SIZE = 64\nNUM_EPOCHS = 100\nNUM_WORKERS = 4\nCHECKPOINT_FILE = \"b0_4.pth.tar\"\nPIN_MEMORY = True\nSAVE_MODEL = True\nLOAD_MODEL = True","metadata":{"execution":{"iopub.status.busy":"2022-01-20T06:51:42.877585Z","iopub.execute_input":"2022-01-20T06:51:42.877996Z","iopub.status.idle":"2022-01-20T06:51:42.885317Z","shell.execute_reply.started":"2022-01-20T06:51:42.877944Z","shell.execute_reply":"2022-01-20T06:51:42.884472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = A.Compose([\n    A.Resize(width = 96,height = 96),\n    A.Rotate(limit = 15,border_mode = cv2.BORDER_CONSTANT,p=0.8),\n    A.IAAAffine(shear = 15,scale = 1.0,mode = 'constant',p = 0.2),\n    A.RandomBrightnessContrast(contrast_limit=0.5,brightness_limit=0.5,p=0.2),\n    A.OneOf([\n        A.GaussNoise(p=0.8),\n        A.CLAHE(p=0.8),\n        A.ImageCompression(p=0.8),\n        A.RandomGamma(p=0.8),\n        A.Posterize(p=0.8),\n        A.Blur(p=0.8),\n    ],p=1.0),\n    A.OneOf([\n        A.GaussNoise(p=0.8),\n        A.CLAHE(p=0.8),\n        A.ImageCompression(p=0.8),\n        A.RandomGamma(p=0.8),\n        A.Posterize(p=0.8),\n        A.Blur(p=0.8),\n    ],p=1.0),\n    A.ShiftScaleRotate(shift_limit=0.1,scale_limit=0.1,rotate_limit=0,p=2,border_mode=cv2.BORDER_CONSTANT),\n    A.Normalize(\n        mean=[0.4897,0.4897,0.4897],\n        std = [0.2330,0.2330,0.2330],\n        max_pixel_value=255.0,\n    ),\n    ToTensorV2(),\n    \n],keypoint_params = A.KeypointParams(format=\"xy\",remove_invisible = False)\n)\n\nval_transforms = A.Compose(\n   [ \n    A.Resize(height=96,width=96),\n    A.Normalize(\n        mean=[0.4897,0.4897,0.4897],\n        std = [0.2330,0.2330,0.2330],\n        max_pixel_value=255.0,\n    ),\n    ToTensorV2(),    \n],keypoint_params = A.KeypointParams(format=\"xy\",remove_invisible = False)\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T06:51:42.887597Z","iopub.execute_input":"2022-01-20T06:51:42.888211Z","iopub.status.idle":"2022-01-20T06:51:42.902346Z","shell.execute_reply.started":"2022-01-20T06:51:42.888177Z","shell.execute_reply":"2022-01-20T06:51:42.901607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, Dataset\n\n\nclass FacialKeypointDataset(Dataset):\n    def __init__(self, csv_file, train=True, transform=None):\n        super().__init__()\n        self.data = pd.read_csv(csv_file)\n        self.category_names = ['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y', 'left_eye_inner_corner_x', 'left_eye_inner_corner_y', 'left_eye_outer_corner_x', 'left_eye_outer_corner_y', 'right_eye_inner_corner_x', 'right_eye_inner_corner_y', 'right_eye_outer_corner_x', 'right_eye_outer_corner_y', 'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y', 'nose_tip_x', 'nose_tip_y', 'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x', 'mouth_right_corner_y', 'mouth_center_top_lip_x', 'mouth_center_top_lip_y', 'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y']\n        self.transform = transform\n        self.train = train\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, index):\n        if self.train:\n            image = np.array(self.data.iloc[index, 30].split()).astype(np.float32)\n            labels = np.array(self.data.iloc[index, :30].tolist())\n            labels[np.isnan(labels)] = -1\n        else:\n            image = np.array(self.data.iloc[index, 1].split()).astype(np.float32)\n            labels = np.zeros(30)\n\n        ignore_indices = labels == -1\n        labels = labels.reshape(15, 2)\n\n        if self.transform:\n            image = np.repeat(image.reshape(96, 96, 1), 3, 2).astype(np.uint8)\n            augmentations = self.transform(image=image, keypoints=labels)\n            image = augmentations[\"image\"]\n            labels = augmentations[\"keypoints\"]\n\n        labels = np.array(labels).reshape(-1)\n        labels[ignore_indices] = -1\n\n        return image, labels.astype(np.float32)\n\n\n\nds = FacialKeypointDataset(csv_file=\"./training.csv\", train=True, transform=train_transforms)\nloader = DataLoader(ds, batch_size=1, shuffle=True, num_workers=0)\ncount = 0\nfor idx, (x, y) in enumerate(loader):\n    plt.imshow(x[0][0].detach().cpu().numpy(), cmap='gray')\n    plt.plot(y[0][0::2].detach().cpu().numpy(), y[0][1::2].detach().cpu().numpy(), \"go\")\n    plt.show()\n    count += 1\n    if count > 4:\n        break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-20T06:51:42.904077Z","iopub.execute_input":"2022-01-20T06:51:42.904451Z","iopub.status.idle":"2022-01-20T06:51:46.11451Z","shell.execute_reply.started":"2022-01-20T06:51:42.904416Z","shell.execute_reply":"2022-01-20T06:51:46.113776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_submission(loader, dataset, model_15, model_4):\n    model_15.eval()\n    model_4.eval()\n    id_lookup = pd.read_csv(\"../input/facial-keypoints-detection/IdLookupTable.csv\")\n    predictions = []\n    image_id = 1\n\n    for image, label in tqdm(loader):\n        image = image.to(DEVICE)\n        preds_15 = torch.clip(model_15(image).squeeze(0), 0.0, 96.0)\n        preds_4 = torch.clip(model_4(image).squeeze(0), 0.0, 96.0)\n        feature_names = id_lookup.loc[id_lookup[\"ImageId\"] == image_id][\"FeatureName\"]\n\n        for feature_name in feature_names:\n            feature_index = dataset.category_names.index(feature_name)\n            if feature_names.shape[0] < 10:\n                predictions.append(preds_4[feature_index].item())\n            else:\n                predictions.append(preds_15[feature_index].item())\n\n        image_id += 1\n\n    df = pd.DataFrame({\"RowId\": np.arange(1, len(predictions)+1), \"Location\": predictions})\n    df.to_csv(\"submission.csv\", index=False)\n    model_15.train()\n    model_4.train()\n\n\ndef get_rmse(loader, model, loss_fn, device):\n    model.eval()\n    num_examples = 0\n    losses = []\n    for batch_idx, (data, targets) in enumerate(loader):\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n\n        # forward\n        scores = model(data)\n        loss = loss_fn(scores[targets != -1], targets[targets != -1])\n        num_examples += scores[targets != -1].shape[0]\n        losses.append(loss.item())\n\n    model.train()\n    print(f\"Loss on val: {(sum(losses)/num_examples)**0.5}\")\n\n\ndef save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\n\ndef load_checkpoint(checkpoint, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr","metadata":{"execution":{"iopub.status.busy":"2022-01-20T06:51:46.11626Z","iopub.execute_input":"2022-01-20T06:51:46.116633Z","iopub.status.idle":"2022-01-20T06:51:46.130511Z","shell.execute_reply.started":"2022-01-20T06:51:46.116596Z","shell.execute_reply":"2022-01-20T06:51:46.129746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade efficientnet-pytorch","metadata":{"execution":{"iopub.status.busy":"2022-01-20T06:52:24.095591Z","iopub.execute_input":"2022-01-20T06:52:24.095842Z","iopub.status.idle":"2022-01-20T06:52:34.732145Z","shell.execute_reply.started":"2022-01-20T06:52:24.095813Z","shell.execute_reply":"2022-01-20T06:52:34.731104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn, optim\nimport os\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom efficientnet_pytorch import EfficientNet","metadata":{"execution":{"iopub.status.busy":"2022-01-20T06:52:34.734735Z","iopub.execute_input":"2022-01-20T06:52:34.735072Z","iopub.status.idle":"2022-01-20T06:52:34.746335Z","shell.execute_reply.started":"2022-01-20T06:52:34.735027Z","shell.execute_reply":"2022-01-20T06:52:34.74544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(loader, model, optimizer, loss_fn, scaler, device):\n    losses = []\n    loop = tqdm(loader)\n    num_examples = 0\n    for batch_idx, (data, targets) in enumerate(loop):\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n\n        # forward\n        scores = model(data)\n        scores[targets == -1] = -1\n        loss = loss_fn(scores, targets)\n        num_examples += torch.numel(scores[targets != -1])\n        losses.append(loss.item())\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Loss average over epoch: {(sum(losses)/num_examples)**0.5}\")\n\n\ndef main():\n    train_ds = FacialKeypointDataset(\n        csv_file=\"./training.csv\",\n        transform=train_transforms,\n    )\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY,\n        shuffle=True,\n    )\n    val_ds = FacialKeypointDataset(\n        transform=val_transforms,\n        csv_file=\"./training.csv\",\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY,\n        shuffle=False,\n    )\n\n    test_ds = FacialKeypointDataset(\n        csv_file=\"./test.csv\",\n        transform=val_transforms,\n        train=False,\n    )\n\n    test_loader = DataLoader(\n        test_ds,\n        batch_size=1,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY,\n        shuffle=False,\n    )\n    loss_fn = nn.MSELoss(reduction=\"sum\")\n    model = EfficientNet.from_pretrained(\"efficientnet-b0\")\n    model._fc = nn.Linear(1280, 30)\n    model = model.to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scaler = torch.cuda.amp.GradScaler()\n\n    model_4 = EfficientNet.from_pretrained(\"efficientnet-b0\")\n    model_4._fc = nn.Linear(1280, 30)\n    model_15 = EfficientNet.from_pretrained(\"efficientnet-b0\")\n    model_15._fc = nn.Linear(1280, 30)\n    model_4 = model_4.to(DEVICE)\n    model_15 = model_15.to(DEVICE)\n\n    if LOAD_MODEL and CHECKPOINT_FILE in os.listdir():\n        load_checkpoint(torch.load(CHECKPOINT_FILE), model, optimizer, LEARNING_RATE)\n        load_checkpoint(torch.load(\"b0_4.pth.tar\"), model_4, optimizer, LEARNING_RATE)\n        load_checkpoint(torch.load(\"b0_15.pth.tar\"), model_15, optimizer,LEARNING_RATE)\n\n    get_submission(test_loader, test_ds, model_15, model_4)\n\n    for epoch in range(NUM_EPOCHS):\n        get_rmse(val_loader, model, loss_fn, DEVICE)\n        train_one_epoch(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n\n        # get on validation\n        if SAVE_MODEL:\n            checkpoint = {\n                \"state_dict\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n            }\n            save_checkpoint(checkpoint, filename=CHECKPOINT_FILE)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T06:52:39.508367Z","iopub.execute_input":"2022-01-20T06:52:39.509Z","iopub.status.idle":"2022-01-20T07:55:43.248224Z","shell.execute_reply.started":"2022-01-20T06:52:39.508938Z","shell.execute_reply":"2022-01-20T07:55:43.245414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}