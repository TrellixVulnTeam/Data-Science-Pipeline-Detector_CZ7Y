{"cells":[{"metadata":{"colab":{},"colab_type":"code","id":"FnYGnKK06XPZ","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":578},"colab_type":"code","id":"X0R67wrT6mTR","outputId":"73287ffd-05b6-402d-c616-bbfd612d7542","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/training/training.csv')\nprint(train_data.shape)\ntrain_data.isna().sum()\n# train_data.isnull().any().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"AQ--IpJPTmag","trusted":true},"cell_type":"code","source":"# Using ffill to fill the na values:\ntrain_data.fillna(method='ffill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"hAAArnF0aZX-"},"cell_type":"markdown","source":"Now, there are no missing values in the dataset. We now need to segregate the data into two parts: X and y. Here X is the Image feature values and y are all the other feature values"},{"metadata":{"colab":{},"colab_type":"code","id":"B1FZ126Oabz9","trusted":true},"cell_type":"code","source":"img_dt = []\n\nfor i in range(len(train_data)):\n  img_dt.append(train_data['Image'][i].split(' '))\n  \nX = np.array(img_dt, dtype='float')","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"colab_type":"code","id":"pIl5XeogjhzO","outputId":"a3b04654-3fab-4797-e488-a090848bf056","trusted":true},"cell_type":"code","source":"# Visualizing one of the images:\nplt.imshow(X[1].reshape(96,96), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"VXB67TfokdR9","trusted":true},"cell_type":"code","source":"facial_pts_data = train_data.drop(['Image'], axis=1)\nfacial_pts = []\n\nfor i in range(len(facial_pts_data)):\n  facial_pts.append(facial_pts_data.iloc[i])\n  \ny = np.array(facial_pts, dtype='float')","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"bgmuNtFqPS6R","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n\n# class Basic_CNN(nn.Module):\n#     def __init__(self):\n#         super(Basic_CNN, self).__init__()\n#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5) # (1,1,96,96) to (1,4,92,92)\n# #         self.conv1_bn = nn.BatchNorm2d(16)\n#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5) # (1,4,46,46) to (1,8,42,42)\n# #         self.conv2_bn = nn.BatchNorm2d(32)\n#         self.fc1 = nn.Linear(32*21*21, 250)\n#         self.fc2 = nn.Linear(250, 30)\n#         self.dp1 = nn.Dropout(p=0.4)\n    \n        \n    \n#     def forward(self, x, verbose=False):\n# #         x = self.conv1_bn(self.conv1(x))\n#         x = self.conv1(x)\n#         x = F.relu(x)\n#         x = F.max_pool2d(x, kernel_size=2)\n#         x = self.dp1(x)\n# #         x = self.conv2_bn(self.conv2(x))\n#         x = self.conv2(x)\n#         x = F.relu(x)\n#         x = F.max_pool2d(x, kernel_size=2)\n#         x = self.dp1(x)\n#         x = x.view(-1, 32*21*21)\n#         x = self.fc1(x)\n#         x = F.relu(x)\n#         x = self.dp1(x)\n#         x = self.fc2(x)\n#         return x\n      \nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5) # (b,1,96,96) to (b,4,92,92)\n        self.conv1_bn = nn.BatchNorm2d(4)\n        self.conv2 = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=3) # (b,4,46,46) to (b,64,44,44)\n        self.conv2_bn = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3) # (b,64,22,22) to (b,128,20,20)\n        self.conv3_bn = nn.BatchNorm2d(128)\n        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3) # (b,128,10,10) to (b,256,8,8)\n        self.conv4_bn = nn.BatchNorm2d(256)\n        self.fc1 = nn.Linear(256*4*4, 1024)\n        self.fc2 = nn.Linear(1024, 256)\n        self.fc3 = nn.Linear(256, 30)\n        self.dp1 = nn.Dropout(p=0.4)\n    \n        \n    \n    def forward(self, x, verbose=False):\n        # apply conv1, relu and maxpool2d\n        x = self.conv1_bn(self.conv1(x))\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n        x = self.dp1(x)\n        \n        # apply conv2, relu and maxpool2d\n        x = self.conv2_bn(self.conv2(x))\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n        x = self.dp1(x)\n        \n        # apply conv3, relu and maxpool2d\n        x = self.conv3_bn(self.conv3(x))\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n        x = self.dp1(x)\n        \n        # apply conv4, relu and maxpool2d\n        x = self.conv4_bn(self.conv4(x))\n        x = F.relu(x)\n        x = F.max_pool2d(x, kernel_size=2)\n        \n        # apply dropout\n        x = self.dp1(x)\n        \n        x = x.view(-1, 256*4*4)\n        \n        # now use FC layer with relu\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dp1(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.dp1(x)\n        x = self.fc3(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"NSga5h9FFtVr","trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndef testing(model, device, valid_loader):\n  model.eval()\n  test_loss = 0\n  for data, target in valid_loader:\n    data, target = data.to(device), target.to(device)\n    data = data.view(-1, 96*96)\n    data = data.view(-1, 1, 96, 96)\n    output = model(data)\n    loss = criterion(output, target)\n    test_loss += loss.item()\n    \n  test_loss /= len(valid_loader.dataset)\n  return test_loss\n\ndef training(epochs, model, criterion, device, train_loader, valid_loader, optimizer):\n  train_error_list = []\n  val_error_list = []\n  for epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    for batch_idx, (data, target) in enumerate(train_loader):\n      data, target = data.to(device), target.to(device)\n      data = data.view(-1, 96*96)\n      data = data.view(-1, 1, 96, 96)\n      optimizer.zero_grad()\n      output = model(data)\n      loss = criterion(output, target)\n      train_loss += loss.item()\n      loss.backward()\n      optimizer.step()\n    \n    train_loss /= len(train_loader.dataset)\n    eval_loss = testing(model, device, valid_loader)\n    train_error_list.append(train_loss)\n    val_error_list.append(eval_loss)\n    if (epoch+1) % 25 == 0:\n      print(\"End of epoch {}: \\nTraining error = [{}]\\tValidation error = [{}]\".format(epoch+1, train_loss, eval_loss))\n  return train_error_list, val_error_list\n","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"CbV_nn3qqDWG","trusted":true},"cell_type":"code","source":"def train_test_split(X, validation_split):\n  dataset_size = len(X)\n  indices = list(range(dataset_size))\n  val_num = int(np.floor(validation_split*dataset_size))\n  np.random.shuffle(indices)\n  train_indices, val_indices = indices[val_num:], indices[:val_num]\n\n  train_sampler = SubsetRandomSampler(train_indices)\n  valid_sampler = SubsetRandomSampler(val_indices)\n\n  loader_object = data_utils.TensorDataset(torch.from_numpy(X).float(), torch.from_numpy(y).float())\n  train_loader = data_utils.DataLoader(loader_object, batch_size=32, sampler=train_sampler)\n  valid_loader = data_utils.DataLoader(loader_object, batch_size=32, sampler=valid_sampler)\n  return train_loader, valid_loader","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":714},"colab_type":"code","id":"9aJ2gHxWS_kI","outputId":"fd9c7883-5970-48f9-af2a-62f4343455c7","trusted":true},"cell_type":"code","source":"def get_n_params(model):\n    np=0\n    for p in list(model.parameters()):\n        np += p.nelement()\n    return np\n\nn_hidden = 128 # number of hidden units\noutput_size = 30\ntrain_loader, valid_loader = train_test_split(X, 0.2)\n\nmodel = CNN()\nmodel.to(device)\ncriterion = torch.nn.MSELoss() \noptimizer = optim.Adam(model.parameters())\n\nprint('Number of parameters: {}'.format(get_n_params(model)))\n\ntrain_error_list, valid_error_list = training(500, model, criterion, device, train_loader, valid_loader, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"4TOZ2g3sT_Ak"},"cell_type":"markdown","source":"# Visualizing the outputs:"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":704},"colab_type":"code","id":"_ZD3yQOHHMyD","outputId":"3dddc495-56bb-4717-a842-45f5e179ed23","trusted":true},"cell_type":"code","source":"def plot_samples(X, y, model, num_samples):\n  fig, axes = plt.subplots(nrows=num_samples, ncols=2, figsize=(12,12))\n  \n  for row in range(num_samples):\n    sample_idx = np.random.choice(len(X))\n    x = X[sample_idx]\n    x = torch.from_numpy(x).float().view(1,1,96,96).to(device)\n    actual_y = y[sample_idx]\n    pred_y = model(x)\n    img = X[sample_idx].reshape(96,96)\n    \n    actual_y = np.vstack(np.split(actual_y, 15)).T\n    pred_y = pred_y.cpu().data.numpy()[0]\n    pred_y = np.vstack(np.split(pred_y, 15)).T\n    \n    axes[row, 0].imshow(img, cmap='gray')\n    axes[row, 0].plot(actual_y[0], actual_y[1], 'o', color='red', label='actual')\n    axes[row, 0].legend()\n    axes[row, 1].imshow(img, cmap='gray')\n    axes[row, 1].plot(actual_y[0], actual_y[1], 'o', color='red', label='actual')\n    axes[row, 1].plot(pred_y[0], pred_y[1], 'o', color='green', label='predicted')\n    axes[row, 1].legend()\n\n  \nplot_samples(X, y, model, 3)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"S7mFhVHBOTlG"},"cell_type":"markdown","source":"# Reading the test dataset:\n"},{"metadata":{"colab":{},"colab_type":"code","id":"pOSLOZPxCdJk","trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/test/test.csv')\n\nimg_dt = []\n\nfor i in range(len(test_data)):\n  img_dt.append(test_data['Image'][i].split(' '))\n  \ntest_X = np.array(img_dt, dtype='float')","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"E4AD_FpNFC26"},"cell_type":"markdown","source":"# Prediction on test set:"},{"metadata":{"colab":{},"colab_type":"code","id":"2fy5O0MtFGLI","trusted":true},"cell_type":"code","source":"test_X_torch = torch.from_numpy(test_X).float().view(len(test_X),1,96,96).to(device)\ntest_predictions = model(test_X_torch)\ntest_predictions = test_predictions.cpu().data.numpy()\n\nkeypts_labels = train_data.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"0aeZ4PyCRwFV"},"cell_type":"markdown","source":"# Visualizing the test predictions"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"colab_type":"code","id":"43R-cwC4ngri","outputId":"9fed5034-e9c2-4133-eee2-3ef16e25997a","trusted":true},"cell_type":"code","source":"# Visualizing the outputs:\n\ndef plot_samples_test(X, y, num_samples):\n  fig, axes = plt.subplots(nrows=1, ncols=num_samples, figsize=(20,12))\n  \n  for row in range(num_samples):\n    sample_idx = np.random.choice(len(X))\n    img = X[sample_idx].reshape(96,96)\n    predicted = y[sample_idx]\n    \n    predicted = np.vstack(np.split(predicted, 15)).T\n#     print(img, predicted)\n    axes[row].imshow(img, cmap='gray')\n    axes[row].plot(predicted[0], predicted[1], 'o', color='green', label='predicted')\n    axes[row].legend()\n  \nplot_samples_test(test_X, test_predictions, 6)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"BdZntO_sRrFS"},"cell_type":"markdown","source":"# Creating the submission file"},{"metadata":{"colab":{},"colab_type":"code","id":"OkN-zbqWRZbF","trusted":true},"cell_type":"code","source":"id_lookup = pd.read_csv('../input/IdLookupTable.csv')\nid_lookup_features = list(id_lookup['FeatureName'])\nid_lookup_image = list(id_lookup['ImageId'])\n\nfor i in range(len(id_lookup_features)):\n  id_lookup_features[i] = keypts_labels.index(id_lookup_features[i])\n\nlocation = []\nfor i in range(len(id_lookup_features)):\n  location.append(test_predictions[id_lookup_image[i]-1][id_lookup_features[i]])","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"iXm4zM8vnaZ5","trusted":true},"cell_type":"code","source":"id_lookup['Location'] = location","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","id":"KUUomxLL3d1R","outputId":"46505c59-253a-417e-d157-af17abdccc28","trusted":true},"cell_type":"code","source":"submission = id_lookup[['RowId', 'Location']]\nsubmission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"6L2qo5VlpyZG","trusted":false},"cell_type":"code","source":"submission.to_csv('../input/SubmissionFile.csv')","execution_count":0,"outputs":[]}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"collapsed_sections":[],"name":"facial_recog.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"}},"nbformat":4,"nbformat_minor":1}