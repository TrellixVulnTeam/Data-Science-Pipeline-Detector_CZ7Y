{"cells":[{"metadata":{"id":"dVTymJearEJn"},"cell_type":"markdown","source":"#  IMPORT LIBRARIES AND DATASETS"},{"metadata":{"id":"vQFbssqfr_UL","trusted":true},"cell_type":"code","source":"# Import the necessary packages\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport PIL\nimport seaborn as sns\nimport pickle\nfrom PIL import *\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom IPython.display import display\nfrom tensorflow.python.keras import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"klj2F-OQr_Wn","trusted":true},"cell_type":"code","source":"raw = pd.read_csv('../input/facial-keypoints-detection/training.zip', compression='zip', header=0, sep=',', quotechar='\"')\ntest_data = pd.read_csv('../input/facial-keypoints-detection/test.zip', compression='zip', header=0, sep=',', quotechar='\"')\nIdLookupTable = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv',header=0, sep=',', quotechar='\"')\nSampleSubmission = pd.read_csv('../input/facial-keypoints-detection/SampleSubmission.csv',header=0, sep=',', quotechar='\"')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nEvery null value is filled according to the value of the previous entry. this is in order to avoid losing data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw.fillna(method = \"ffill\",inplace=True)\nraw.isnull().any().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A list of images is created. iterating through the image column of the dataset which will become the input data. Each image is turned into a 1D list with 0 filled in for blank values"},{"metadata":{"trusted":true},"cell_type":"code","source":"images = []\nfor i in range(0,7049):\n    img = raw[\"Image\"][i].split(\" \")\n    img = ['0' if x ==\" \" else x for x in img]\n    images.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = np.array(images,dtype='float')\nimages.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A sample image is displayed below with a monochrome color map"},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain = images.reshape(-1,96,96)\nplt.imshow(xtrain[11].reshape(96,96),cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By using broadcasting we can normalize each image by understanding that the maximum value for any pixel is 355"},{"metadata":{"trusted":true},"cell_type":"code","source":"for row in images:\n    row/=255\nimages","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nNow drop the image axis from the training data as we will now prepare the yvalues for the data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(images[4].reshape(96,96),cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now drop the image axis from the training data as we will now prepare the yvalues for the data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntraining = raw.drop([\"Image\"],axis=1)\ntraining.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The rest of the data less the images is the ydata to evaluate on"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = []\nfor i in range(0,7049):\n    y = training.iloc[i,:]\n    y_train.append(y)\nytrain = np.array(y_train,dtype = 'float')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a convolutional network model. some of the code and logic has been taken from online tutorials for learning purposes"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n# model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(96, 96, 1)))\n# model.add(Convolution2D(32, 3, 3, activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Convolution2D(32, 3, 3, activation='relu'))\n# model.add(Dropout(0.1))\n# model.add(Flatten())\n# model.add(Dense(128, activation='relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(30, activation='softmax'))\nmodel.add(Convolution2D(32, (3, 3) ,activation='relu', input_shape=(96, 96, 1)))\nmodel.add(Convolution2D(32, (3, 3) , padding=\"same\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Convolution2D(64, (3, 3) , padding=\"same\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Convolution2D(128, (3, 3) , padding=\"same\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(30, activation='relu'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='mse',\n              optimizer='adam',\n              metrics=['mae',\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=images.reshape(-1,96,96,1)\nimages.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now the model is trained on the images and ytrain data with a 0.2 validation split"},{"metadata":{"id":"bNkYttG_tOKf"},"cell_type":"markdown","source":"#  PERFORM IMAGE VISUALIZATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(images, ytrain,epochs = 3,batch_size = 255,validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"facial_keypoints_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now the test data is prepared in a similar fashion"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testy = test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata = testy[\"Image\"]\ntestimages = []\nfor i in range(0,1783):\n    img = raw[\"Image\"][i].split(\" \")\n    img = ['0' if x ==\" \" else x for x in img]\n    testimages.append(img)\ntestimages = np.array(testimages,dtype=\"float\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testimages/=255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testimages = testimages.reshape(-1,96,96,1)\ntestimages.shape\ntestimages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.predict(testimages,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for imgind in range(200):\n    imgind = 5\n    img = xtrain[imgind]\n    fig, ax = plt.subplots()\n    x = range(300)\n    ax.imshow(img)\n    ax.scatter(history[imgind][0], history[imgind][1], color='firebrick')\n\n    ax.scatter(ytrain[\"nose_tip_y\"][imgind], ytrain[\"nose_tip_x\"][imgind], color='blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following code was used to create a properly formatted submission file for kaggle using a loockup table."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlookid_list = list(IdLookupTable['FeatureName'])\nimageID = list(IdLookupTable['ImageId']-1)\npre_list = list(result)\n\n\nrowid = IdLookupTable['RowId']\nrowid=list(rowid)\n\n\n\nfeature = []\nfor f in list(IdLookupTable['FeatureName']):\n    feature.append(lookid_list.index(f))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preded = []\nfor x,y in zip(imageID,feature):\n    preded.append(pre_list[x][y])\n\n\nrowid = pd.Series(rowid,name = 'RowId')\n\nloc = pd.Series(preded,name = 'Location')\nsubmission = pd.concat([rowid,loc],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SampleSubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SampleSubmission.to_csv('face_key_detection_submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}