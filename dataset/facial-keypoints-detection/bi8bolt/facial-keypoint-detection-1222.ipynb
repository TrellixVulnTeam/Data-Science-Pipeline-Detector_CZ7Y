{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom math import sin, cos, pi\n\nfrom keras.applications import ResNet50\nfrom keras.layers import Conv2D, LeakyReLU, GlobalAveragePooling2D, Dropout, Dense\nfrom keras.models import Sequential","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-22T13:06:12.835707Z","iopub.execute_input":"2021-12-22T13:06:12.836087Z","iopub.status.idle":"2021-12-22T13:06:12.846016Z","shell.execute_reply.started":"2021-12-22T13:06:12.836055Z","shell.execute_reply":"2021-12-22T13:06:12.844964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker=None, s=20)  \n    plt.title(title)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:12.84753Z","iopub.execute_input":"2021-12-22T13:06:12.849624Z","iopub.status.idle":"2021-12-22T13:06:12.855531Z","shell.execute_reply.started":"2021-12-22T13:06:12.849594Z","shell.execute_reply":"2021-12-22T13:06:12.854653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **加载数据**","metadata":{}},{"cell_type":"code","source":"!unzip ../input/facial-keypoints-detection/training.zip\n!unzip ../input/facial-keypoints-detection/test.zip","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:12.858207Z","iopub.execute_input":"2021-12-22T13:06:12.858708Z","iopub.status.idle":"2021-12-22T13:06:20.965507Z","shell.execute_reply.started":"2021-12-22T13:06:12.858656Z","shell.execute_reply":"2021-12-22T13:06:20.96412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_file = pd.read_csv('./training.csv')\ntest_file = pd.read_csv('./test.csv')\nidlookup_file = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:20.971659Z","iopub.execute_input":"2021-12-22T13:06:20.973521Z","iopub.status.idle":"2021-12-22T13:06:23.745666Z","shell.execute_reply.started":"2021-12-22T13:06:20.972866Z","shell.execute_reply":"2021-12-22T13:06:23.744774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_file.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:23.746948Z","iopub.execute_input":"2021-12-22T13:06:23.747297Z","iopub.status.idle":"2021-12-22T13:06:23.777248Z","shell.execute_reply.started":"2021-12-22T13:06:23.74726Z","shell.execute_reply":"2021-12-22T13:06:23.776425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_file.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:23.778577Z","iopub.execute_input":"2021-12-22T13:06:23.779153Z","iopub.status.idle":"2021-12-22T13:06:23.790666Z","shell.execute_reply.started":"2021-12-22T13:06:23.779114Z","shell.execute_reply":"2021-12-22T13:06:23.789572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **检查空值**","metadata":{}},{"cell_type":"code","source":"train_file.isnull().sum()  #统计列中为空的个数","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:23.792046Z","iopub.execute_input":"2021-12-22T13:06:23.792399Z","iopub.status.idle":"2021-12-22T13:06:23.803587Z","shell.execute_reply.started":"2021-12-22T13:06:23.792363Z","shell.execute_reply":"2021-12-22T13:06:23.802536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **过滤缺失数据、填充丢失数据**\n","metadata":{}},{"cell_type":"code","source":"clean_train_file = train_file.dropna() # 过滤缺失数据\ntrain_file = train_file.fillna(method='ffill')  #向前填充","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:23.806568Z","iopub.execute_input":"2021-12-22T13:06:23.806942Z","iopub.status.idle":"2021-12-22T13:06:23.8193Z","shell.execute_reply.started":"2021-12-22T13:06:23.806908Z","shell.execute_reply":"2021-12-22T13:06:23.818532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_file.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:23.820952Z","iopub.execute_input":"2021-12-22T13:06:23.82131Z","iopub.status.idle":"2021-12-22T13:06:23.831051Z","shell.execute_reply.started":"2021-12-22T13:06:23.821275Z","shell.execute_reply":"2021-12-22T13:06:23.830106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **导入图片和关键点**","metadata":{}},{"cell_type":"code","source":"def load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)/255.  #归一化处理\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop(['Image'], axis=1)\n    keypoint_features = []\n    for idx, features in keypoint_data.iterrows():\n        keypoint_features.append(features)\n    keypoint_features = np.array(keypoint_features, dtype=float)\n    return keypoint_features\n\ntrain_images = load_images(train_file)\nimages = load_images(clean_train_file)\ntrain_keypoints = load_keypoints(train_file)\nkeypoints = load_keypoints(clean_train_file)\ntest_images = load_images(test_file)\n\nprint(train_images.shape)\nprint(train_keypoints.shape)\n\nprint(images.shape)\nprint(keypoints.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:23.832742Z","iopub.execute_input":"2021-12-22T13:06:23.833139Z","iopub.status.idle":"2021-12-22T13:06:56.059163Z","shell.execute_reply.started":"2021-12-22T13:06:23.833101Z","shell.execute_reply":"2021-12-22T13:06:56.058258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **数据增强**","metadata":{}},{"cell_type":"code","source":"class aug_config:\n    rotation_augmentation = True  #旋转\n    brightness_augmentation = True  #亮度\n    shift_augmentation = True  #偏移\n    random_noise_augmentation = True  #随机噪声\n    rotation_angles = [15]\n    pixel_shifts = [15]","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:56.060606Z","iopub.execute_input":"2021-12-22T13:06:56.060994Z","iopub.status.idle":"2021-12-22T13:06:56.066636Z","shell.execute_reply.started":"2021-12-22T13:06:56.060951Z","shell.execute_reply":"2021-12-22T13:06:56.065594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **旋转**","metadata":{}},{"cell_type":"code","source":"def rotate_augmentation(images, keypoints, rotation_angles):\n    rotated_images = []\n    rotated_keypoints = []\n    for angle in rotation_angles:\n        for angle in [angle, -angle]:\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.)\n            angle_rad = -angle*pi/180.\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48.\n                for idx in range(0, len(rotated_keypoint), 2):\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48.   \n                rotated_keypoints.append(rotated_keypoint)\n            \n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\nif aug_config.rotation_augmentation:\n    rotated_train_images, rotated_train_keypoints = rotate_augmentation(images, keypoints, aug_config.rotation_angles)\n    train_images = np.concatenate((train_images, rotated_train_images))  #数组拼接\n    train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(rotated_train_images[18], rotated_train_keypoints[18], axis, \"Rotation Augmentation\")\n\nprint(rotated_train_images.shape)\nprint(len(rotated_train_keypoints))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:56.068436Z","iopub.execute_input":"2021-12-22T13:06:56.069124Z","iopub.status.idle":"2021-12-22T13:06:57.781457Z","shell.execute_reply.started":"2021-12-22T13:06:56.069085Z","shell.execute_reply":"2021-12-22T13:06:57.780589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **改变亮度**","metadata":{}},{"cell_type":"code","source":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    \n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    \n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\nif aug_config.brightness_augmentation:\n    altered_brightness_images, altered_brightness_keypoints = alter_brightness(images, keypoints)\n    train_images = np.concatenate((train_images, altered_brightness_images))\n    train_keypoints = np.concatenate((train_keypoints, altered_brightness_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(altered_brightness_images[1580], altered_brightness_keypoints[1580], axis, \"Alter Brightness Augmentation\")\n    \nprint(len(altered_brightness_images))\nprint(len(altered_brightness_keypoints))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:57.782878Z","iopub.execute_input":"2021-12-22T13:06:57.783239Z","iopub.status.idle":"2021-12-22T13:06:58.700079Z","shell.execute_reply.started":"2021-12-22T13:06:57.7832Z","shell.execute_reply":"2021-12-22T13:06:58.699072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **图像偏移**","metadata":{}},{"cell_type":"code","source":"def shift_images(images, keypoints, pixel_shifts):\n    shifted_images = []\n    shifted_keypoints = []\n    for shift in pixel_shifts:    \n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    #shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n    return shifted_images, shifted_keypoints\n\nif aug_config.shift_augmentation:\n    shifted_train_images, shifted_train_keypoints = shift_images(images, keypoints, aug_config.pixel_shifts)\n    train_images = np.concatenate((train_images, shifted_train_images))\n    train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(shifted_train_images[3200], shifted_train_keypoints[3200], axis, \"Shift Augmentation\")\n    \nprint(len(shifted_train_images))\nprint(len(shifted_train_keypoints))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:06:58.701604Z","iopub.execute_input":"2021-12-22T13:06:58.701977Z","iopub.status.idle":"2021-12-22T13:07:01.643169Z","shell.execute_reply.started":"2021-12-22T13:06:58.701938Z","shell.execute_reply":"2021-12-22T13:07:01.641341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **添加噪声**","metadata":{}},{"cell_type":"code","source":"def add_noise(images):\n    noisy_images = []\n    for image in images:\n        noisy_image = cv2.add(image, 0.008*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n        noisy_images.append(noisy_image.reshape(96,96,1))\n    return noisy_images\n\nif aug_config.random_noise_augmentation:\n    noisy_train_images = add_noise(images)\n    train_images = np.concatenate((train_images, noisy_train_images))\n    train_keypoints = np.concatenate((train_keypoints, keypoints))\n    fig, axis = plt.subplots()\n    plot_sample(noisy_train_images[19], keypoints[19], axis, \"Random Noise Augmentation\")\n    \nprint(len(noisy_train_images))\nprint(len(keypoints))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:07:01.644524Z","iopub.execute_input":"2021-12-22T13:07:01.644912Z","iopub.status.idle":"2021-12-22T13:07:03.217144Z","shell.execute_reply.started":"2021-12-22T13:07:01.644873Z","shell.execute_reply":"2021-12-22T13:07:03.215586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_images.shape)\nprint(train_keypoints.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:07:03.219508Z","iopub.execute_input":"2021-12-22T13:07:03.219795Z","iopub.status.idle":"2021-12-22T13:07:03.224276Z","shell.execute_reply.started":"2021-12-22T13:07:03.219765Z","shell.execute_reply":"2021-12-22T13:07:03.22344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Model**","metadata":{}},{"cell_type":"code","source":"model = Sequential()\npretrained_model = ResNet50(input_shape=(96,96,3), include_top=False, weights='imagenet')\npretrained_model.trainable = True\n\nmodel.add(Conv2D(3, (1,1), padding='same', input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(pretrained_model)\nmodel.add(GlobalAveragePooling2D())  #均值池化\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:07:03.225719Z","iopub.execute_input":"2021-12-22T13:07:03.226245Z","iopub.status.idle":"2021-12-22T13:07:05.202584Z","shell.execute_reply.started":"2021-12-22T13:07:03.226206Z","shell.execute_reply":"2021-12-22T13:07:05.201633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **训练模型**","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nearlyStopping = EarlyStopping(monitor='loss', patience=10, mode='min',baseline=None)\nrlp = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, min_lr=1e-15, mode='min', verbose=1)\n\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n\nhistory = model.fit(train_images, train_keypoints, epochs=100, batch_size=64, validation_split=0.15, callbacks=[earlyStopping, rlp])","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:07:05.207032Z","iopub.execute_input":"2021-12-22T13:07:05.209322Z","iopub.status.idle":"2021-12-22T13:11:42.324642Z","shell.execute_reply.started":"2021-12-22T13:07:05.209275Z","shell.execute_reply":"2021-12-22T13:11:42.323548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('darkgrid')\n\nfig, ax = plt.subplots(2, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['loss', 'val_loss']].plot(ax=ax[0])\ndf[['accuracy', 'val_accuracy']].plot(ax=ax[1])\nax[0].set_title('Model Loss', fontsize=12)\nax[1].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:11:42.32636Z","iopub.execute_input":"2021-12-22T13:11:42.326894Z","iopub.status.idle":"2021-12-22T13:11:42.947548Z","shell.execute_reply.started":"2021-12-22T13:11:42.32685Z","shell.execute_reply":"2021-12-22T13:11:42.946662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:11:42.948974Z","iopub.execute_input":"2021-12-22T13:11:42.949554Z","iopub.status.idle":"2021-12-22T13:11:44.907934Z","shell.execute_reply.started":"2021-12-22T13:11:42.949509Z","shell.execute_reply":"2021-12-22T13:11:44.906841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = list(idlookup_file['FeatureName'])\nimage_ids = list(idlookup_file['ImageId']-1)\nrow_ids = list(idlookup_file['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T13:11:44.909499Z","iopub.execute_input":"2021-12-22T13:11:44.909875Z","iopub.status.idle":"2021-12-22T13:11:45.068229Z","shell.execute_reply.started":"2021-12-22T13:11:44.909832Z","shell.execute_reply":"2021-12-22T13:11:45.067367Z"},"trusted":true},"execution_count":null,"outputs":[]}]}