{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n # linear algebra\n # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-19T14:23:25.345863Z","iopub.execute_input":"2021-07-19T14:23:25.346236Z","iopub.status.idle":"2021-07-19T14:23:25.36171Z","shell.execute_reply.started":"2021-07-19T14:23:25.346146Z","shell.execute_reply":"2021-07-19T14:23:25.360985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.keras import Sequential\nfrom tensorflow.keras import layers, optimizers, applications, callbacks\nfrom tensorflow.keras.applications import DenseNet121  \nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom IPython.display import display\nfrom tensorflow.keras import backend as K\nimport tensorflow.keras.preprocessing.image as tf_image\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:25.400644Z","iopub.execute_input":"2021-07-19T14:23:25.40097Z","iopub.status.idle":"2021-07-19T14:23:29.962396Z","shell.execute_reply.started":"2021-07-19T14:23:25.400943Z","shell.execute_reply":"2021-07-19T14:23:29.961449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/facial-keypoints-detection/training.zip')\ntest = pd.read_csv('/kaggle/input/facial-keypoints-detection/test.zip')\nidlookup_data = pd.read_csv('/kaggle/input/facial-keypoints-detection/IdLookupTable.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:29.963928Z","iopub.execute_input":"2021-07-19T14:23:29.964321Z","iopub.status.idle":"2021-07-19T14:23:35.581512Z","shell.execute_reply.started":"2021-07-19T14:23:29.96428Z","shell.execute_reply":"2021-07-19T14:23:35.58055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.583421Z","iopub.execute_input":"2021-07-19T14:23:35.583785Z","iopub.status.idle":"2021-07-19T14:23:35.608167Z","shell.execute_reply.started":"2021-07-19T14:23:35.58374Z","shell.execute_reply":"2021-07-19T14:23:35.607042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.61019Z","iopub.execute_input":"2021-07-19T14:23:35.610919Z","iopub.status.idle":"2021-07-19T14:23:35.633443Z","shell.execute_reply.started":"2021-07-19T14:23:35.610853Z","shell.execute_reply":"2021-07-19T14:23:35.632725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.634592Z","iopub.execute_input":"2021-07-19T14:23:35.634955Z","iopub.status.idle":"2021-07-19T14:23:35.65053Z","shell.execute_reply.started":"2021-07-19T14:23:35.634923Z","shell.execute_reply":"2021-07-19T14:23:35.649039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.652051Z","iopub.execute_input":"2021-07-19T14:23:35.652504Z","iopub.status.idle":"2021-07-19T14:23:35.687658Z","shell.execute_reply.started":"2021-07-19T14:23:35.652461Z","shell.execute_reply":"2021-07-19T14:23:35.686499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.68905Z","iopub.execute_input":"2021-07-19T14:23:35.689388Z","iopub.status.idle":"2021-07-19T14:23:35.705488Z","shell.execute_reply.started":"2021-07-19T14:23:35.689354Z","shell.execute_reply":"2021-07-19T14:23:35.704739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.707984Z","iopub.execute_input":"2021-07-19T14:23:35.708318Z","iopub.status.idle":"2021-07-19T14:23:35.720176Z","shell.execute_reply.started":"2021-07-19T14:23:35.708294Z","shell.execute_reply":"2021-07-19T14:23:35.719347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image = train.Image\ntrain = train.drop('Image', axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.722199Z","iopub.execute_input":"2021-07-19T14:23:35.722535Z","iopub.status.idle":"2021-07-19T14:23:35.728732Z","shell.execute_reply.started":"2021-07-19T14:23:35.722503Z","shell.execute_reply":"2021-07-19T14:23:35.727611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t1 = train.iloc[:2000, :]\nt2 = train.iloc[2000:4000, :]\nt3 = train.iloc[4000:6000, :]\nt4 = train.iloc[6000: , :]\nprint(t1.isnull().sum())\nprint('\\n', '--------------------------------', '\\n')\nprint(t2.isnull().sum())\nprint('\\n', '--------------------------------', '\\n')\nprint(t3.isnull().sum())\nprint('\\n', '--------------------------------', '\\n')\nprint(t4.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.730495Z","iopub.execute_input":"2021-07-19T14:23:35.731011Z","iopub.status.idle":"2021-07-19T14:23:35.750998Z","shell.execute_reply.started":"2021-07-19T14:23:35.730972Z","shell.execute_reply":"2021-07-19T14:23:35.7498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img = train_image.apply( lambda x: np.fromstring(x, dtype=float, sep=' ').reshape(96, 96) )\n\n# type(train_img[0])\ntrain_img[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:35.75242Z","iopub.execute_input":"2021-07-19T14:23:35.752842Z","iopub.status.idle":"2021-07-19T14:23:52.330873Z","shell.execute_reply.started":"2021-07-19T14:23:35.752804Z","shell.execute_reply":"2021-07-19T14:23:52.329753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_data = np.array(train).reshape(7049, 15,2)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.33241Z","iopub.execute_input":"2021-07-19T14:23:52.332839Z","iopub.status.idle":"2021-07-19T14:23:52.338998Z","shell.execute_reply.started":"2021-07-19T14:23:52.332798Z","shell.execute_reply":"2021-07-19T14:23:52.337937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(train_img[0], cmap='gray')\nplt.plot(train_data[0][:, 0], train_data[0][:, 1], 'rx')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.340506Z","iopub.execute_input":"2021-07-19T14:23:52.34109Z","iopub.status.idle":"2021-07-19T14:23:52.527328Z","shell.execute_reply.started":"2021-07-19T14:23:52.341047Z","shell.execute_reply":"2021-07-19T14:23:52.526506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(train_img[7048], cmap='gray')\nplt.plot(train_data[7048][:, 0], train_data[0][:, 1], 'rx')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.528674Z","iopub.execute_input":"2021-07-19T14:23:52.529267Z","iopub.status.idle":"2021-07-19T14:23:52.691801Z","shell.execute_reply.started":"2021-07-19T14:23:52.529221Z","shell.execute_reply":"2021-07-19T14:23:52.690846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.693101Z","iopub.execute_input":"2021-07-19T14:23:52.693434Z","iopub.status.idle":"2021-07-19T14:23:52.704602Z","shell.execute_reply.started":"2021-07-19T14:23:52.693398Z","shell.execute_reply":"2021-07-19T14:23:52.703538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Augmentation","metadata":{}},{"cell_type":"markdown","source":"#### Horizontal and Vertical Flip","metadata":{}},{"cell_type":"code","source":"def horizontal_flip(df, col):\n    image, keypoints = df[-1:], df[:-1]\n    image1 = np.array(image)[0]\n    n = int(keypoints.shape[0]/2)\n    keypoints1 = np.array(keypoints).reshape(-1, n, 2)[0]\n    \n    image2 = np.flip(image1, axis=1)\n    keypoints1[:, 0] = 96-keypoints1[:, 0]\n    \n    keypoints2 = keypoints1.reshape(-1, 2*n)[0]\n    s = pd.Series(keypoints2, index=col[:-1])\n    s['Image'] = image2\n    \n    return s\n\ndef vertical_flip(df, col):\n    image, keypoints = df[-1:], df[:-1]\n    image1 = np.array(image)[0]\n    n = int(keypoints.shape[0]/2)\n    keypoints1 = np.array(keypoints).reshape(-1, n, 2)[0]\n    \n    image2 = np.flip(image1, axis=0)\n    keypoints1[:, 1] = 96-keypoints1[:, 1]\n    \n    keypoints2 = keypoints1.reshape(-1, 2*n)[0]\n    s = pd.Series(keypoints2, index=col[:-1])\n    s['Image'] = image2\n    \n    return s\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.706063Z","iopub.execute_input":"2021-07-19T14:23:52.706655Z","iopub.status.idle":"2021-07-19T14:23:52.71755Z","shell.execute_reply.started":"2021-07-19T14:23:52.706617Z","shell.execute_reply":"2021-07-19T14:23:52.716613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Display Function","metadata":{}},{"cell_type":"code","source":"def display(image, keypoints=[]):\n    plt.figure()\n    plt.imshow(image, cmap='gray')\n    if len(keypoints)>0:\n        plt.plot(keypoints[:, 0], keypoints[:, 1], 'rx')\n    \ndef compare(image1, keypoints1, image2, keypoints2):\n    plt.figure()\n    plt.subplot(1,2,1)\n    plt.imshow(image1, cmap='gray')\n    plt.plot(keypoints1[:, 0], keypoints1[:, 1], 'rx')\n    \n    plt.subplot(1,2,2)\n    plt.imshow(image2, cmap='gray')\n    plt.plot(keypoints2[:, 0], keypoints2[:, 1], 'rx')\n    \n    \ndef df_plot(df):\n    fig = plt.figure(figsize=(24,24))\n    for i in range(6):\n        ax = fig.add_subplot(1, 6, i+1)\n        image = plt.imshow(df['Image'][i], cmap = 'gray')\n        n = int(df.iloc[i][:-1].shape[0]) + 1\n        for j in range(1, n, 2):\n            plt.plot(df.loc[i][j-1], df.loc[i][j], 'rx')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.71918Z","iopub.execute_input":"2021-07-19T14:23:52.719552Z","iopub.status.idle":"2021-07-19T14:23:52.730253Z","shell.execute_reply.started":"2021-07-19T14:23:52.719519Z","shell.execute_reply":"2021-07-19T14:23:52.729312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Rotation","metadata":{}},{"cell_type":"code","source":"def rotation(df, col):  \n    image, keypoints = df[-1:], df[:-1]\n    image1 = np.array(image)[0]\n    n = int(keypoints.shape[0]/2)\n    keypoints1 = np.array(keypoints).reshape(-1, n, 2)[0]\n    \n    angle = np.random.uniform(-60, 60)\n    h,w = 96, 96\n    cX, cY = 48, 48\n    \n    M = cv2.getRotationMatrix2D((cX, cY), angle, 1)\n    \n    #  \n    #  (rot_mat) M =  [ m00    m01  m02]   = [ cosx    sinx  (1−cosx)cX − sinx*cY ]\n    #                 [m10    m11  m12]      [-sinx   cosx   sinx*cX + (1−cosx)cY ]     \n    #\n    \n    cos = np.abs(M[0][0])\n    sin = np.abs(M[0][1])\n\n    #     nW = int(h*sin + w*cos)\n    #     nH = int(w*sin + h*cos)\n    \n    nW = 96\n    nH = 96\n\n    #     M[0, 2] += (nW / 2) - cX\n    #     M[1, 2] += (nH / 2) - cY\n    \n    r_img = cv2.warpAffine(image1, M, (nW, nH))\n    \n    keypoints1[:, 0] = keypoints1[:, 0] - cX\n    keypoints1[:, 1] = keypoints1[:, 1] - cY\n\n    r_angl = np.radians(angle)\n    cos = np.cos(r_angl)\n    sin = np.sin(r_angl)\n\n    M2 = np.array([[cos, sin],\n                  [-sin, cos]])\n    \n    r_keypoints = np.dot(M2, keypoints1.T)\n    r_keypoints = r_keypoints.T\n    r_keypoints[:, 0] = r_keypoints[:, 0] + (nW)/2.0\n    r_keypoints[:, 1] = r_keypoints[:, 1] + (nH)/2.0\n    \n    keypoints2 = r_keypoints.reshape(-1, 2*n)[0]\n    s = pd.Series(keypoints2, index=col[:-1])\n    s['Image'] = r_img\n    \n    return s\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.731838Z","iopub.execute_input":"2021-07-19T14:23:52.732387Z","iopub.status.idle":"2021-07-19T14:23:52.746993Z","shell.execute_reply.started":"2021-07-19T14:23:52.732353Z","shell.execute_reply":"2021-07-19T14:23:52.74599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Brightness","metadata":{}},{"cell_type":"code","source":"def brightness(df, col):\n    image, keypoints = df[-1:], df[:-1]\n    image1 = np.array(image)[0]\n    n = int(keypoints.shape[0]/2)\n    keypoints1 = np.array(keypoints).reshape(-1, n, 2)[0]\n    \n    image2 = np.clip(np.random.uniform(0.1, 3)*image1, 0.0, 255.0)\n    \n    keypoints2 = keypoints1.reshape(-1, 2*n)[0]\n    s = pd.Series(keypoints2, index=col[:-1])\n    s['Image'] = image2\n    \n    return s\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.748291Z","iopub.execute_input":"2021-07-19T14:23:52.748817Z","iopub.status.idle":"2021-07-19T14:23:52.760649Z","shell.execute_reply.started":"2021-07-19T14:23:52.748762Z","shell.execute_reply":"2021-07-19T14:23:52.759849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Shift","metadata":{}},{"cell_type":"code","source":"def shift(df, col):\n    image, keypoints = df[-1:], df[:-1]\n    image1 = np.array(image)[0]\n    n = int(keypoints.shape[0]/2)\n    keypoints1 = np.array(keypoints).reshape(-1, n, 2)[0]\n    \n    tx = np.random.uniform(-10, 10)\n    ty = np.random.uniform(-10, 10)\n    \n    M = np.array([[1, 0, tx],\n                  [0, 1, ty]])\n    \n    image2 = cv2.warpAffine(image1, M, (96, 96))\n    \n    keypoints1[:, 0] = keypoints1[:, 0] + tx \n    keypoints1[:, 1] = keypoints1[:, 1] + ty \n    \n    keypoints2 = keypoints1.reshape(-1, 2*n)[0]\n    s = pd.Series(keypoints2, index=col[:-1])\n    s['Image'] = image2\n    return s\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.762125Z","iopub.execute_input":"2021-07-19T14:23:52.76252Z","iopub.status.idle":"2021-07-19T14:23:52.773718Z","shell.execute_reply.started":"2021-07-19T14:23:52.762482Z","shell.execute_reply":"2021-07-19T14:23:52.772698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Noise and Blur","metadata":{}},{"cell_type":"code","source":"def noise(df, col):\n    image, keypoints = df[-1:], df[:-1]\n    image1 = np.array(image)[0]\n    n = int(keypoints.shape[0]/2)\n    keypoints1 = np.array(keypoints).reshape(-1, n, 2)[0]\n    \n    image2 = cv2.add(image1, np.random.uniform(0.1,0.9)*np.random.randint(50, size=(96,96)))\n    \n    keypoints2 = keypoints1.reshape(-1, 2*n)[0]\n    s = pd.Series(keypoints2, index=col[:-1])\n    s['Image'] = image2\n    return s\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.775349Z","iopub.execute_input":"2021-07-19T14:23:52.775715Z","iopub.status.idle":"2021-07-19T14:23:52.787006Z","shell.execute_reply.started":"2021-07-19T14:23:52.77568Z","shell.execute_reply":"2021-07-19T14:23:52.786099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def blur(df, col):\n    image, keypoints = df[-1:], df[:-1]\n    image1 = np.array(image)[0]\n    n = int(keypoints.shape[0]/2)\n    keypoints1 = np.array(keypoints).reshape(-1, n, 2)[0]\n    \n    image2 = cv2.GaussianBlur(image1, (5,5), 0)\n    \n    keypoints2 = keypoints1.reshape(-1, 2*n)[0]\n    s = pd.Series(keypoints2, index=col[:-1])\n    s['Image'] = image2\n    return s\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.788211Z","iopub.execute_input":"2021-07-19T14:23:52.788752Z","iopub.status.idle":"2021-07-19T14:23:52.7975Z","shell.execute_reply.started":"2021-07-19T14:23:52.788715Z","shell.execute_reply":"2021-07-19T14:23:52.796809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/facial-keypoints-detection/training.zip')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:52.803449Z","iopub.execute_input":"2021-07-19T14:23:52.803783Z","iopub.status.idle":"2021-07-19T14:23:56.241876Z","shell.execute_reply.started":"2021-07-19T14:23:52.803742Z","shell.execute_reply":"2021-07-19T14:23:56.240996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Image'] = df['Image'].apply(lambda x: np.fromstring(x, dtype=float, sep=' ').reshape(96,96))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:23:56.244604Z","iopub.execute_input":"2021-07-19T14:23:56.244974Z","iopub.status.idle":"2021-07-19T14:24:11.971737Z","shell.execute_reply.started":"2021-07-19T14:23:56.244938Z","shell.execute_reply":"2021-07-19T14:24:11.97089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_df = df[['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y', 'nose_tip_x', 'nose_tip_y', 'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'Image']]\nd_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:24:11.972946Z","iopub.execute_input":"2021-07-19T14:24:11.973271Z","iopub.status.idle":"2021-07-19T14:24:11.992099Z","shell.execute_reply.started":"2021-07-19T14:24:11.97324Z","shell.execute_reply":"2021-07-19T14:24:11.990837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_df = d_df.dropna()\nd_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:24:11.993436Z","iopub.execute_input":"2021-07-19T14:24:11.993993Z","iopub.status.idle":"2021-07-19T14:24:12.021743Z","shell.execute_reply.started":"2021-07-19T14:24:11.993949Z","shell.execute_reply":"2021-07-19T14:24:12.020722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:24:12.022951Z","iopub.execute_input":"2021-07-19T14:24:12.02328Z","iopub.status.idle":"2021-07-19T14:24:12.02915Z","shell.execute_reply.started":"2021-07-19T14:24:12.023245Z","shell.execute_reply":"2021-07-19T14:24:12.028001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_tf = d_df.copy()\nd_tf.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:24:12.030806Z","iopub.execute_input":"2021-07-19T14:24:12.031492Z","iopub.status.idle":"2021-07-19T14:24:12.203601Z","shell.execute_reply.started":"2021-07-19T14:24:12.03145Z","shell.execute_reply":"2021-07-19T14:24:12.202647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(d_tf.iloc[0, -1])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:24:12.205036Z","iopub.execute_input":"2021-07-19T14:24:12.205389Z","iopub.status.idle":"2021-07-19T14:24:12.358306Z","shell.execute_reply.started":"2021-07-19T14:24:12.205355Z","shell.execute_reply":"2021-07-19T14:24:12.35744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtf = d_tf.sample(frac=1).reset_index(drop=True)\ndcol = dtf.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:17.217761Z","iopub.execute_input":"2021-07-19T14:25:17.218181Z","iopub.status.idle":"2021-07-19T14:25:17.227295Z","shell.execute_reply.started":"2021-07-19T14:25:17.218138Z","shell.execute_reply":"2021-07-19T14:25:17.226357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dcol","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:17.228457Z","iopub.execute_input":"2021-07-19T14:25:17.22872Z","iopub.status.idle":"2021-07-19T14:25:17.239945Z","shell.execute_reply.started":"2021-07-19T14:25:17.228696Z","shell.execute_reply":"2021-07-19T14:25:17.238971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndtf1 = dtf.iloc[:3000].copy()\ndtf2 = dtf.iloc[3000:6000].copy()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:17.241391Z","iopub.execute_input":"2021-07-19T14:25:17.241742Z","iopub.status.idle":"2021-07-19T14:25:17.248449Z","shell.execute_reply.started":"2021-07-19T14:25:17.241707Z","shell.execute_reply":"2021-07-19T14:25:17.247726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtf1 = dtf1.apply(lambda row: horizontal_flip(row, dcol), axis=1)\ndtf2 = dtf2.apply(lambda row: vertical_flip(row, dcol), axis=1)\n\ndtf = pd.concat([dtf,dtf1, dtf2], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:17.250104Z","iopub.execute_input":"2021-07-19T14:25:17.250447Z","iopub.status.idle":"2021-07-19T14:25:23.955023Z","shell.execute_reply.started":"2021-07-19T14:25:17.250411Z","shell.execute_reply":"2021-07-19T14:25:23.954024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtf = dtf.sample(frac=1).reset_index(drop=True)\ndtf.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:23.956484Z","iopub.execute_input":"2021-07-19T14:25:23.956881Z","iopub.status.idle":"2021-07-19T14:25:23.969031Z","shell.execute_reply.started":"2021-07-19T14:25:23.956842Z","shell.execute_reply":"2021-07-19T14:25:23.967819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = int(len(dtf)/2)\ndtf3 = dtf.iloc[:n].copy()\ndtf3 = dtf3.apply(lambda row: rotation(row, dcol), axis=1)\ndtf = pd.concat([dtf, dtf3], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:23.970874Z","iopub.execute_input":"2021-07-19T14:25:23.971459Z","iopub.status.idle":"2021-07-19T14:25:33.259176Z","shell.execute_reply.started":"2021-07-19T14:25:23.971422Z","shell.execute_reply":"2021-07-19T14:25:33.256896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtf = dtf.sample(frac=1).reset_index(drop=True)\ndtf.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:33.262028Z","iopub.execute_input":"2021-07-19T14:25:33.263002Z","iopub.status.idle":"2021-07-19T14:25:33.280905Z","shell.execute_reply.started":"2021-07-19T14:25:33.262933Z","shell.execute_reply":"2021-07-19T14:25:33.279751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n1 = int(len(dtf)/4)\n\ndtf4 = dtf.iloc[:n1].copy()\ndtf5 = dtf.iloc[n1:2*n1].copy()\ndtf6 = dtf.iloc[2*n1:3*n1].copy()\ndtf7 = dtf.iloc[3*n1:].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:33.282504Z","iopub.execute_input":"2021-07-19T14:25:33.283399Z","iopub.status.idle":"2021-07-19T14:25:33.291709Z","shell.execute_reply.started":"2021-07-19T14:25:33.283362Z","shell.execute_reply":"2021-07-19T14:25:33.290658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtf4 = dtf4.apply(lambda row: brightness(row, dcol), axis=1)\ndtf5 = dtf5.apply(lambda row: noise(row, dcol), axis=1)\ndtf6 = dtf6.apply(lambda row: blur(row, dcol), axis=1)\ndtf7 = dtf7.apply(lambda row: shift(row, dcol), axis=1)\n\n\ndtf = pd.concat([dtf,dtf4, dtf5, dtf6, dtf7], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:33.293502Z","iopub.execute_input":"2021-07-19T14:25:33.294277Z","iopub.status.idle":"2021-07-19T14:25:56.810856Z","shell.execute_reply.started":"2021-07-19T14:25:33.294232Z","shell.execute_reply":"2021-07-19T14:25:56.81Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtf.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:56.812155Z","iopub.execute_input":"2021-07-19T14:25:56.812482Z","iopub.status.idle":"2021-07-19T14:25:56.818837Z","shell.execute_reply.started":"2021-07-19T14:25:56.812449Z","shell.execute_reply":"2021-07-19T14:25:56.817975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\npretrained_model = applications.MobileNet(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\npretrained_model.trainable = True\n\nmodel.add(layers.Convolution2D(3, (1, 1), padding='same', input_shape=(96,96,1)))\nmodel.add(layers.LeakyReLU(alpha = 0.1))\nmodel.add(pretrained_model)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(8))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:25:56.820162Z","iopub.execute_input":"2021-07-19T14:25:56.820487Z","iopub.status.idle":"2021-07-19T14:25:59.999059Z","shell.execute_reply.started":"2021-07-19T14:25:56.820452Z","shell.execute_reply":"2021-07-19T14:25:59.998255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:26:00.001617Z","iopub.execute_input":"2021-07-19T14:26:00.001899Z","iopub.status.idle":"2021-07-19T14:26:00.018537Z","shell.execute_reply.started":"2021-07-19T14:26:00.001873Z","shell.execute_reply":"2021-07-19T14:26:00.017782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = dtf.iloc[:, -1]\nimg = img/255.0\nX = np.empty((len(img), 96, 96, 1))\n\nfor i in range(len(img)):\n    X[i,] = np.expand_dims(img[i], axis = 2)\n\nX = np.asarray(X).astype(np.float32)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-19T14:29:28.886109Z","iopub.execute_input":"2021-07-19T14:29:28.886475Z","iopub.status.idle":"2021-07-19T14:29:28.950819Z","shell.execute_reply.started":"2021-07-19T14:29:28.886396Z","shell.execute_reply":"2021-07-19T14:29:28.949291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = dtf.iloc[:,:-1]\ny = np.asarray(y).astype(np.float32)\ny.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, batch_size = 256, epochs= 100, validation_split = 0.05)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = model.evaluate(X_test,y_test)\nprint(\"Accuracy : {}\".format(result[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the model history keys \nhistory.history.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss','val_loss'], loc = 'upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict = model.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\nrms = sqrt(mean_squared_error(y_test, df_predict))\nprint(\"RMSE value : {}\".format(rms))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_predict= pd.DataFrame(df_predict)\ndf_predict.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfig = plt.figure(figsize=(20, 20))\n\nfor i in range(8):\n    ax = fig.add_subplot(4, 2, i + 1)\n    # Using squeeze to convert the image shape from (96,96,1) to (96,96)\n    plt.imshow(X_test[i].squeeze(),cmap='gray')\n    for j in range(1,9,2):\n            plt.plot(df_predict.loc[i][j-1], df_predict.loc[i][j], 'rx')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image = test.iloc[:, -1].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image = test_image.apply(lambda x: np.fromstring(x, dtype=float, sep=' ').reshape(96, 96))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgt = test_image\nimgt = imgt/255.0\n\n# Create an empty array of shape (32k, 96, 96, 1) to train the model\nXt = np.empty((len(imgt), 96, 96, 1))\n\n# Iterate through the normalized images list and add image values to the empty array \n# Note that we need to expand it's dimension from (96,96) to (96,96,1)\nfor i in range(len(imgt)):\n    Xt[i,] = np.expand_dims(imgt[i], axis = 2)\n\n# Convert the array type to float32\nXt = np.asarray(Xt).astype(np.float32)\nXt.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = model.predict(Xt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(test_preds).to_csv('test_preds4_2.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\n\nfor i in range(64):\n    ax = fig.add_subplot(8, 8, i + 1)    \n    image = plt.imshow(Xt[i].reshape(96,96), cmap = 'gray')\n    for j in range(1,9,2):\n        plt.plot(test_preds[i][j-1], test_preds[i][j], 'rx')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}