{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-24T17:16:51.353793Z","iopub.execute_input":"2022-04-24T17:16:51.35417Z","iopub.status.idle":"2022-04-24T17:16:51.384461Z","shell.execute_reply.started":"2022-04-24T17:16:51.354068Z","shell.execute_reply":"2022-04-24T17:16:51.383416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:16:51.386347Z","iopub.execute_input":"2022-04-24T17:16:51.386589Z","iopub.status.idle":"2022-04-24T17:16:57.658598Z","shell.execute_reply.started":"2022-04-24T17:16:51.386558Z","shell.execute_reply":"2022-04-24T17:16:57.657489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\n\necho 'current working dir'\npwd\n\necho 'extracting training data .......'\nunzip ../input/facial-keypoints-detection/training.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:16:57.660254Z","iopub.execute_input":"2022-04-24T17:16:57.660604Z","iopub.status.idle":"2022-04-24T17:17:00.070506Z","shell.execute_reply.started":"2022-04-24T17:16:57.660555Z","shell.execute_reply":"2022-04-24T17:17:00.069744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\n\necho 'current working dir'\npwd\n\necho 'extracting test data .......'\nunzip ../input/facial-keypoints-detection/test.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:00.07306Z","iopub.execute_input":"2022-04-24T17:17:00.073364Z","iopub.status.idle":"2022-04-24T17:17:00.703588Z","shell.execute_reply.started":"2022-04-24T17:17:00.07332Z","shell.execute_reply":"2022-04-24T17:17:00.702559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! echo 'Working directory',$(pwd)\n! ls","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:00.706044Z","iopub.execute_input":"2022-04-24T17:17:00.706431Z","iopub.status.idle":"2022-04-24T17:17:02.240042Z","shell.execute_reply.started":"2022-04-24T17:17:00.706378Z","shell.execute_reply":"2022-04-24T17:17:02.239193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nwork_dir = '/kaggle/working'\ntrain_dir = os.path.join(work_dir,'training.csv')\ntest_dir = os.path.join(work_dir,'test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:02.241759Z","iopub.execute_input":"2022-04-24T17:17:02.242715Z","iopub.status.idle":"2022-04-24T17:17:02.247946Z","shell.execute_reply.started":"2022-04-24T17:17:02.242671Z","shell.execute_reply":"2022-04-24T17:17:02.247096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(train_dir)\ntest = pd.read_csv(test_dir)\nsample_submission_csv = pd.read_csv('/kaggle/input/facial-keypoints-detection/SampleSubmission.csv')\nlookup = pd.read_csv('/kaggle/input/facial-keypoints-detection/IdLookupTable.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:02.249269Z","iopub.execute_input":"2022-04-24T17:17:02.249829Z","iopub.status.idle":"2022-04-24T17:17:05.750389Z","shell.execute_reply.started":"2022-04-24T17:17:02.24979Z","shell.execute_reply":"2022-04-24T17:17:05.749381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Length of training data\", len(train))\nprint(\"Length of testing data\", len(test))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:05.751699Z","iopub.execute_input":"2022-04-24T17:17:05.751947Z","iopub.status.idle":"2022-04-24T17:17:05.758855Z","shell.execute_reply.started":"2022-04-24T17:17:05.751915Z","shell.execute_reply":"2022-04-24T17:17:05.757894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for null values","metadata":{}},{"cell_type":"code","source":"print(f'Feature \\t\\t\\t Missing \\t Percentage missing\\n')\nfor k,v in train.isna().sum().items():\n    print(f'{k !s:30} :{v :8} \\t {round(v/len(train),2)}%')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:05.760161Z","iopub.execute_input":"2022-04-24T17:17:05.76063Z","iopub.status.idle":"2022-04-24T17:17:05.788309Z","shell.execute_reply.started":"2022-04-24T17:17:05.760589Z","shell.execute_reply":"2022-04-24T17:17:05.787156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets split the data into two parts <br>\nGood_data = data that has no missing fields <br>\nBad_data = that has missing feilds -- we'll later inpute the missing  <br>\n\nLets start by working with good data and create a baseline model <br>\n","metadata":{}},{"cell_type":"code","source":"good_data = train.dropna()\nbad_data = train.drop(index=good_data.index)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:05.791523Z","iopub.execute_input":"2022-04-24T17:17:05.791815Z","iopub.status.idle":"2022-04-24T17:17:05.813172Z","shell.execute_reply.started":"2022-04-24T17:17:05.791772Z","shell.execute_reply":"2022-04-24T17:17:05.812117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of data we are going to work with',good_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:05.814475Z","iopub.execute_input":"2022-04-24T17:17:05.815425Z","iopub.status.idle":"2022-04-24T17:17:05.821318Z","shell.execute_reply.started":"2022-04-24T17:17:05.815352Z","shell.execute_reply":"2022-04-24T17:17:05.820412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset information","metadata":{}},{"cell_type":"code","source":"good_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:05.822709Z","iopub.execute_input":"2022-04-24T17:17:05.822977Z","iopub.status.idle":"2022-04-24T17:17:05.857583Z","shell.execute_reply.started":"2022-04-24T17:17:05.822944Z","shell.execute_reply":"2022-04-24T17:17:05.85671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The input image is given in the last field of the data files, and consists of a list of pixels (ordered by row), as integers in (0,255). The images are 96x96 pixels.","metadata":{}},{"cell_type":"code","source":"# IMAGES\ngood_data['Image'].head()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:05.858961Z","iopub.execute_input":"2022-04-24T17:17:05.859552Z","iopub.status.idle":"2022-04-24T17:17:05.871052Z","shell.execute_reply.started":"2022-04-24T17:17:05.859506Z","shell.execute_reply":"2022-04-24T17:17:05.870103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Images and targets\nLets create an util that accept a csv file and give us back the images and targets","metadata":{}},{"cell_type":"code","source":"def get_images(data):\n    images = []\n    # prepare the image\n    for img in iter(data.loc[:,'Image']):\n        img = np.array(img.split(), dtype=float)\n        img = img. reshape(96,96,1)\n        images.append(img)\n    return np.array(images)\n\ndef get_X_y(data):\n    images = get_images(data)\n    targets = np.array(data.iloc[:,:-1], dtype=float)\n    return images, targets","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:05.87238Z","iopub.execute_input":"2022-04-24T17:17:05.87306Z","iopub.status.idle":"2022-04-24T17:17:05.881639Z","shell.execute_reply.started":"2022-04-24T17:17:05.873024Z","shell.execute_reply":"2022-04-24T17:17:05.880881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, targets = get_X_y(good_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:05.882946Z","iopub.execute_input":"2022-04-24T17:17:05.883687Z","iopub.status.idle":"2022-04-24T17:17:10.52298Z","shell.execute_reply.started":"2022-04-24T17:17:05.883595Z","shell.execute_reply":"2022-04-24T17:17:10.521996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of images',images.shape)\nprint('Shape of targets',targets.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:10.524446Z","iopub.execute_input":"2022-04-24T17:17:10.52486Z","iopub.status.idle":"2022-04-24T17:17:10.531629Z","shell.execute_reply.started":"2022-04-24T17:17:10.524812Z","shell.execute_reply":"2022-04-24T17:17:10.530533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets create an util that will display the images\ndef display_images(img, feat):\n    plt.imshow(img, cmap=plt.cm.gray);\n    plt.scatter(feat[0::2], feat[1::2], c='r', marker='x')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:10.533319Z","iopub.execute_input":"2022-04-24T17:17:10.533649Z","iopub.status.idle":"2022-04-24T17:17:10.542385Z","shell.execute_reply.started":"2022-04-24T17:17:10.533586Z","shell.execute_reply":"2022-04-24T17:17:10.541612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets test visualization\ndisplay_images(images[0],targets[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:10.543824Z","iopub.execute_input":"2022-04-24T17:17:10.544273Z","iopub.status.idle":"2022-04-24T17:17:10.797511Z","shell.execute_reply.started":"2022-04-24T17:17:10.54424Z","shell.execute_reply":"2022-04-24T17:17:10.796628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation\n\nWe can add different augmenations like - \n* flipping \n* rotation\n* cropping\n* adding noise\n* bluring\n* brightness \n\netc..","metadata":{}},{"cell_type":"code","source":"# lets create an util to display the augumentation\ndef display_augmentation(img, feat, img_f, feat_f):\n    plt.figure(figsize=(8,8))\n    plt.subplot(2,2,1)\n    plt.scatter(feat[0::2],-feat[1::2],c='r',marker='x')\n    plt.subplot(2,2,2)\n    plt.scatter(feat_f[0::2],-feat_f[1::2],c='r',marker='x')\n    plt.subplot(2,2,3)\n    display_images(img, feat)\n    plt.subplot(2,2,4)\n    display_images(img_f, feat_f)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:10.798844Z","iopub.execute_input":"2022-04-24T17:17:10.799114Z","iopub.status.idle":"2022-04-24T17:17:10.80725Z","shell.execute_reply.started":"2022-04-24T17:17:10.799081Z","shell.execute_reply":"2022-04-24T17:17:10.806362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample image to test augmentation\nimage, feature = images[0].copy(), targets[0].copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:10.808489Z","iopub.execute_input":"2022-04-24T17:17:10.808745Z","iopub.status.idle":"2022-04-24T17:17:10.817796Z","shell.execute_reply.started":"2022-04-24T17:17:10.808713Z","shell.execute_reply":"2022-04-24T17:17:10.816764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Flipping ","metadata":{}},{"cell_type":"code","source":"flipped_img = np.fliplr(image)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:10.819252Z","iopub.execute_input":"2022-04-24T17:17:10.819532Z","iopub.status.idle":"2022-04-24T17:17:10.827841Z","shell.execute_reply.started":"2022-04-24T17:17:10.819499Z","shell.execute_reply":"2022-04-24T17:17:10.827042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flipped_feat = feature.copy()\nfor i, v in enumerate(feature):\n    if i % 2 ==0:\n        v = 96-v\n    flipped_feat[i]=v","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:10.829202Z","iopub.execute_input":"2022-04-24T17:17:10.829464Z","iopub.status.idle":"2022-04-24T17:17:10.839402Z","shell.execute_reply.started":"2022-04-24T17:17:10.829426Z","shell.execute_reply":"2022-04-24T17:17:10.838481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_augmentation(image, feature, flipped_img, flipped_feat)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:10.840636Z","iopub.execute_input":"2022-04-24T17:17:10.841715Z","iopub.status.idle":"2022-04-24T17:17:11.403139Z","shell.execute_reply.started":"2022-04-24T17:17:10.841635Z","shell.execute_reply":"2022-04-24T17:17:11.402333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets make an util that give us flipped images and targets\ndef flipping_augmentation(images, features):\n    flipped_images = np.flip(images, axis=2)\n    \n    flipped_features = features.copy()\n    for i, feat in enumerate(flipped_features):\n        for j, val in enumerate(feat):\n            if j%2==0:\n                flipped_features[i][j] = 96-val\n            \n    return flipped_images, flipped_features\n\n# let create an object to keep track of the augmentations\naugmentation_functions = {\n    'flip' : flipping_augmentation\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:11.404501Z","iopub.execute_input":"2022-04-24T17:17:11.404938Z","iopub.status.idle":"2022-04-24T17:17:11.411607Z","shell.execute_reply.started":"2022-04-24T17:17:11.404898Z","shell.execute_reply":"2022-04-24T17:17:11.410809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets see one more example\nflip_imgs, flip_feats = flipping_augmentation(images[:5], targets[:5])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:11.412854Z","iopub.execute_input":"2022-04-24T17:17:11.413267Z","iopub.status.idle":"2022-04-24T17:17:11.430009Z","shell.execute_reply.started":"2022-04-24T17:17:11.413233Z","shell.execute_reply":"2022-04-24T17:17:11.429019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_augmentation(images[1], targets[1], flip_imgs[1],flip_feats[1])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:11.43161Z","iopub.execute_input":"2022-04-24T17:17:11.431945Z","iopub.status.idle":"2022-04-24T17:17:11.997261Z","shell.execute_reply.started":"2022-04-24T17:17:11.431906Z","shell.execute_reply":"2022-04-24T17:17:11.996483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cropping","metadata":{}},{"cell_type":"code","source":"cropped_image = image.copy()\n\ncropped_image[:,:10] = 0\ncropped_image[:,86:] = 0\ncropped_image[:10,:] = 0\ncropped_image[86:,:] = 0\n\n\ncropped_image.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:11.998567Z","iopub.execute_input":"2022-04-24T17:17:11.9993Z","iopub.status.idle":"2022-04-24T17:17:12.006618Z","shell.execute_reply.started":"2022-04-24T17:17:11.999257Z","shell.execute_reply":"2022-04-24T17:17:12.005988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cropped_image, cmap=plt.cm.gray);\nplt.scatter(feature[0::2],feature[1::2],marker='x',c='r');","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:12.011472Z","iopub.execute_input":"2022-04-24T17:17:12.011946Z","iopub.status.idle":"2022-04-24T17:17:12.224506Z","shell.execute_reply.started":"2022-04-24T17:17:12.011903Z","shell.execute_reply":"2022-04-24T17:17:12.223873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets make an util that give us cropped images and targets\ndef crop_augmentation(images, targets):\n    cropped_images = images.copy()\n\n    for i in range(len(images)):\n        cropped_images[i,:,:10] = 0\n        cropped_images[i,:,86:] = 0\n        cropped_images[i,:10,:] = 0\n        cropped_images[i,86:,:] = 0\n\n    return cropped_images, targets\n\n\naugmentation_functions['crop']=crop_augmentation\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:12.225701Z","iopub.execute_input":"2022-04-24T17:17:12.226063Z","iopub.status.idle":"2022-04-24T17:17:12.232255Z","shell.execute_reply.started":"2022-04-24T17:17:12.226029Z","shell.execute_reply":"2022-04-24T17:17:12.230975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rotation","metadata":{}},{"cell_type":"code","source":"from scipy import ndimage, misc\n\nimg_45 = ndimage.rotate(image, 45, reshape=False)\nplt.imshow(img_45 , cmap=plt.cm.gray);","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:12.233639Z","iopub.execute_input":"2022-04-24T17:17:12.233903Z","iopub.status.idle":"2022-04-24T17:17:12.454731Z","shell.execute_reply.started":"2022-04-24T17:17:12.23387Z","shell.execute_reply":"2022-04-24T17:17:12.453654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rotate_points(points, angle):\n    # shift points in the plane so that the center of rotation is at the origin\n    points = points-48\n\n    # rotation matrix\n    theta = np.radians(angle)\n    c, s = np.cos(theta), np.sin(theta)\n    R = np.array(((c, s), (-s, c)))\n\n    # rotate the points\n    for i in range(0,len(points),2):\n        xy = np.array([points[i],points[i+1]])\n        xy_rot = R@xy\n        points[i],points[i+1]= xy_rot\n\n    #  shift again so the origin goes back to the desired center of rotation\n    points = points+48\n    return points","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:12.456003Z","iopub.execute_input":"2022-04-24T17:17:12.456305Z","iopub.status.idle":"2022-04-24T17:17:12.46414Z","shell.execute_reply.started":"2022-04-24T17:17:12.45627Z","shell.execute_reply":"2022-04-24T17:17:12.463174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rotated feature points \nfeat_45 = rotate_points(feature, 45)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:12.466015Z","iopub.execute_input":"2022-04-24T17:17:12.466386Z","iopub.status.idle":"2022-04-24T17:17:12.481699Z","shell.execute_reply.started":"2022-04-24T17:17:12.466336Z","shell.execute_reply":"2022-04-24T17:17:12.480733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets see the rotation\n\ndisplay_augmentation(image, feature, img_45, feat_45)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:12.482888Z","iopub.execute_input":"2022-04-24T17:17:12.483254Z","iopub.status.idle":"2022-04-24T17:17:13.060365Z","shell.execute_reply.started":"2022-04-24T17:17:12.483218Z","shell.execute_reply":"2022-04-24T17:17:13.059378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets make an util that give us rotated images and targets\n\ndef rotate_augmentation(images, features, angle):\n    rotated_images = []\n    for img in images:\n        img_rot = ndimage.rotate(img, angle, reshape=False)\n        rotated_images.append(img_rot)\n        \n    rotated_features=[]\n    for feat in features:\n        feat_rot = rotate_points(feat, angle)\n        rotated_features.append(feat_rot)\n        \n    \n    return np.array(rotated_images), np.array(rotated_features)\n\n\naugmentation_functions['rotate'] = rotate_augmentation","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:13.061939Z","iopub.execute_input":"2022-04-24T17:17:13.062344Z","iopub.status.idle":"2022-04-24T17:17:13.070737Z","shell.execute_reply.started":"2022-04-24T17:17:13.062294Z","shell.execute_reply":"2022-04-24T17:17:13.070054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check once more using a different angle\nimg_rot, feat_rot = rotate_augmentation(images[:5], targets[:5,:], angle=-45)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:13.071602Z","iopub.execute_input":"2022-04-24T17:17:13.071828Z","iopub.status.idle":"2022-04-24T17:17:13.089974Z","shell.execute_reply.started":"2022-04-24T17:17:13.071799Z","shell.execute_reply":"2022-04-24T17:17:13.089084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_augmentation(images[4], targets[4], img_rot[4], feat_rot[4])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:13.090976Z","iopub.execute_input":"2022-04-24T17:17:13.091213Z","iopub.status.idle":"2022-04-24T17:17:13.667938Z","shell.execute_reply.started":"2022-04-24T17:17:13.091184Z","shell.execute_reply":"2022-04-24T17:17:13.667154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,theta in enumerate([10,20,30,40,-10,-20,-30,-40]):\n    img, feat = rotate_augmentation(images[:10], targets[:10], theta)\n    plt.subplot(2,4,i+1)\n    display_images(img[i],feat[i])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:13.669016Z","iopub.execute_input":"2022-04-24T17:17:13.669365Z","iopub.status.idle":"2022-04-24T17:17:14.919619Z","shell.execute_reply.started":"2022-04-24T17:17:13.669331Z","shell.execute_reply":"2022-04-24T17:17:14.918615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Brightness","metadata":{}},{"cell_type":"code","source":"img = image.copy()\nimg = np.clip(img*2.5,0,255)\nplt.imshow(img, cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:14.921131Z","iopub.execute_input":"2022-04-24T17:17:14.921829Z","iopub.status.idle":"2022-04-24T17:17:15.129937Z","shell.execute_reply.started":"2022-04-24T17:17:14.921778Z","shell.execute_reply":"2022-04-24T17:17:15.128869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets create an util that adds brightness\ndef brightness_augmentation(images, features, factor=1.5):\n    bright = []\n    for img in images:\n        bright.append(np.clip(img*factor, 0, 255))\n    return np.array(bright), features\n\naugmentation_functions['brightness'] = brightness_augmentation","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:15.13145Z","iopub.execute_input":"2022-04-24T17:17:15.131805Z","iopub.status.idle":"2022-04-24T17:17:15.13845Z","shell.execute_reply.started":"2022-04-24T17:17:15.131753Z","shell.execute_reply":"2022-04-24T17:17:15.137734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets see one more example\nimg, feat = brightness_augmentation(images[:5], targets[:5], factor=2.0)\n\ndisplay_augmentation(images[2], targets[2], img[2], feat[2])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:15.140183Z","iopub.execute_input":"2022-04-24T17:17:15.140582Z","iopub.status.idle":"2022-04-24T17:17:15.708863Z","shell.execute_reply.started":"2022-04-24T17:17:15.140549Z","shell.execute_reply":"2022-04-24T17:17:15.707993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding noise ","metadata":{}},{"cell_type":"code","source":"img = image.copy()\nnoise = np.random.randint(low=0, high=255, size=img.shape)\nfactor = 0.25\nplt.imshow(img+(noise*factor), cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:15.710202Z","iopub.execute_input":"2022-04-24T17:17:15.710459Z","iopub.status.idle":"2022-04-24T17:17:15.927072Z","shell.execute_reply.started":"2022-04-24T17:17:15.710424Z","shell.execute_reply":"2022-04-24T17:17:15.926098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets create an utility that adds noise to the image\ndef noise_augmentation(images, features, factor):\n    augmented = []\n    noise = np.random.randint(low=0, high=255, size=images.shape[1:])\n    for img in images:\n        img = img + (noise*factor)\n        augmented.append(img)\n    \n    return np.array(augmented), features\n\naugmentation_functions['noise'] = noise_augmentation","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:15.928356Z","iopub.execute_input":"2022-04-24T17:17:15.928588Z","iopub.status.idle":"2022-04-24T17:17:15.93586Z","shell.execute_reply.started":"2022-04-24T17:17:15.928557Z","shell.execute_reply":"2022-04-24T17:17:15.934914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets see one another example\nimg, feat = noise_augmentation(images[:5], targets[:5], factor=0.15)\n\ndisplay_augmentation(images[2], targets[2], img[2], feat[2])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:15.937355Z","iopub.execute_input":"2022-04-24T17:17:15.93775Z","iopub.status.idle":"2022-04-24T17:17:16.505206Z","shell.execute_reply.started":"2022-04-24T17:17:15.937711Z","shell.execute_reply":"2022-04-24T17:17:16.504224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets prepare our training data ","metadata":{}},{"cell_type":"code","source":"# images, targets = get_X_y(good_data)\n\nprint('Shape of image data',images.shape)\nprint('Shape of target data', targets.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:16.506712Z","iopub.execute_input":"2022-04-24T17:17:16.507656Z","iopub.status.idle":"2022-04-24T17:17:16.514217Z","shell.execute_reply.started":"2022-04-24T17:17:16.507593Z","shell.execute_reply":"2022-04-24T17:17:16.513235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# ADDING AUGMENTATION\n\ndef augmentation(img, feat , method):\n    aug_img, aug_feat = method\n    img = np.concatenate([img,aug_img])\n    feat = np.concatenate([feat,aug_feat])\n    return img, feat\n\n\n# flip\nmethod = flipping_augmentation(images, targets)\naugmented_images, augmented_targets = augmentation(images, targets, method)\n\n# crop\nmethod = crop_augmentation(images, targets)\naugmented_images, augmented_targets = augmentation(augmented_images, augmented_targets, method)\n\n# rotate\nfor theta in [10,15,-10,-15]:\n    method = rotate_augmentation(images, targets, angle=theta)\n    augmented_images, augmented_targets = augmentation(augmented_images, augmented_targets, method)\n\n\n# brightness\nmethod = brightness_augmentation(images, targets, factor=2.0)\naugmented_images, augmented_targets = augmentation(augmented_images, augmented_targets, method)\n\n# noise\nmethod = noise_augmentation(images, targets, factor=0.2)\naugmented_images, augmented_targets = augmentation(augmented_images, augmented_targets, method)\n\n# just for visual \nfor k in augmentation_functions.keys():\n    print(k,'>'*50)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:16.515388Z","iopub.execute_input":"2022-04-24T17:17:16.516243Z","iopub.status.idle":"2022-04-24T17:17:35.874491Z","shell.execute_reply.started":"2022-04-24T17:17:16.516191Z","shell.execute_reply":"2022-04-24T17:17:35.873284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of data after augmentation')\nprint('Shape of image data',augmented_images.shape)\nprint('Shape of target data', augmented_targets.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:35.876199Z","iopub.execute_input":"2022-04-24T17:17:35.876812Z","iopub.status.idle":"2022-04-24T17:17:35.882163Z","shell.execute_reply.started":"2022-04-24T17:17:35.876768Z","shell.execute_reply":"2022-04-24T17:17:35.881535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets check our data one last time before we start building models\n\ndef visualize_data(images, targets):\n    plt.figure(figsize=(12,12))\n    for i in range(10):\n        idx = np.random.randint(images.shape[0])\n        plt.subplot(2,5,i+1)\n        display_images(images[idx], targets[idx])\n        plt.axis('off')\n    plt.subplots_adjust(bottom=0.5)\n    plt.show()\n\nvisualize_data(augmented_images, augmented_targets)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:35.883434Z","iopub.execute_input":"2022-04-24T17:17:35.88423Z","iopub.status.idle":"2022-04-24T17:17:36.402511Z","shell.execute_reply.started":"2022-04-24T17:17:35.88419Z","shell.execute_reply":"2022-04-24T17:17:36.401565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling \n\nMobileNetV2 is very similar to the original MobileNet, except that it uses inverted residual blocks with bottlenecking features. It has a drastically lower parameter count than the original MobileNet. MobileNets support any input size greater than 32 x 32, with larger image sizes offering better performance.\n","metadata":{}},{"cell_type":"code","source":"pretrained_model = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(96,96,3),include_top=False,weights='imagenet')\n# pretrained_model = tf.keras.applications.resnet_v2.ResNet50V2(input_shape=(96,96,3),include_top=False,weights='imagenet')\npretrained_model.trainable=False","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:36.40393Z","iopub.execute_input":"2022-04-24T17:17:36.404886Z","iopub.status.idle":"2022-04-24T17:17:39.225415Z","shell.execute_reply.started":"2022-04-24T17:17:36.404809Z","shell.execute_reply":"2022-04-24T17:17:39.22433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each Keras Application expects a specific kind of input preprocessing. For MobileNetV2, call tf.keras.applications.mobilenet_v2.preprocess_input on your inputs before passing them to the model. mobilenet_v2.preprocess_input will scale input pixels between -1 and 1.","metadata":{}},{"cell_type":"code","source":"augmented_images = tf.keras.applications.mobilenet_v2.preprocess_input(augmented_images)\n# augmented_images = tf.keras.applications.resnet_v2.preprocess_input(augmented_images)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:39.226703Z","iopub.execute_input":"2022-04-24T17:17:39.226935Z","iopub.status.idle":"2022-04-24T17:17:39.532935Z","shell.execute_reply.started":"2022-04-24T17:17:39.226904Z","shell.execute_reply":"2022-04-24T17:17:39.531826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets check our data to make sure everything is fine\n\nvisualize_data(augmented_images,augmented_targets)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:39.534254Z","iopub.execute_input":"2022-04-24T17:17:39.534479Z","iopub.status.idle":"2022-04-24T17:17:40.446643Z","shell.execute_reply.started":"2022-04-24T17:17:39.534449Z","shell.execute_reply":"2022-04-24T17:17:40.442737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets create a dataset for training and validation\nds = tf.data.Dataset.from_tensor_slices((augmented_images,augmented_targets))\nds = ds.shuffle(buffer_size=augmented_targets.shape[0])\nds = ds.batch(64)\nds = ds.prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:40.448362Z","iopub.execute_input":"2022-04-24T17:17:40.448768Z","iopub.status.idle":"2022-04-24T17:17:41.85262Z","shell.execute_reply.started":"2022-04-24T17:17:40.448724Z","shell.execute_reply":"2022-04-24T17:17:41.851957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = ds.skip(10).shuffle(100)\nval_ds = ds.take(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:41.853605Z","iopub.execute_input":"2022-04-24T17:17:41.853897Z","iopub.status.idle":"2022-04-24T17:17:41.895688Z","shell.execute_reply.started":"2022-04-24T17:17:41.853862Z","shell.execute_reply":"2022-04-24T17:17:41.894739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a preprocessing layer\nclass ImageTile(tf.keras.layers.Layer):\n    def __init__(self):\n        super().__init__(trainable = False)\n        \n    def call(self, inputs):\n        return tf.tile(inputs,tf.constant([1,1,1,3]))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:41.897205Z","iopub.execute_input":"2022-04-24T17:17:41.897458Z","iopub.status.idle":"2022-04-24T17:17:41.906506Z","shell.execute_reply.started":"2022-04-24T17:17:41.897428Z","shell.execute_reply":"2022-04-24T17:17:41.905792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    \n    tf.keras.Input(shape=(96,96,1)),\n    \n    ImageTile(),\n    \n    pretrained_model,\n    \n    tf.keras.layers.GlobalMaxPooling2D(),\n    \n    tf.keras.layers.Dense(512),  \n    \n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.Activation('relu'),\n    \n    tf.keras.layers.Dense(256),  \n    \n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.Activation('relu'),\n    \n    tf.keras.layers.Dense(128),\n    \n    tf.keras.layers.BatchNormalization(),\n    \n    tf.keras.layers.Activation('relu'),\n\n    tf.keras.layers.Dense(30)\n])\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:41.907939Z","iopub.execute_input":"2022-04-24T17:17:41.908249Z","iopub.status.idle":"2022-04-24T17:17:42.433711Z","shell.execute_reply.started":"2022-04-24T17:17:41.908203Z","shell.execute_reply":"2022-04-24T17:17:42.432734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.MeanSquaredError(),\n              metrics=['accuracy', 'mae', 'mse'])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:42.435083Z","iopub.execute_input":"2022-04-24T17:17:42.435309Z","iopub.status.idle":"2022-04-24T17:17:42.457042Z","shell.execute_reply.started":"2022-04-24T17:17:42.43528Z","shell.execute_reply":"2022-04-24T17:17:42.455944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n# decaying learing rate\ndef decay_lr(epoch):\n  return 0.01*math.pow(0.77,epoch)\n\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(decay_lr)\n\nlr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(patience=5)\n    \n    \nearly_stopping = tf.keras.callbacks.EarlyStopping(\n                        monitor='val_loss',\n                        patience=5,\n                        restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:42.458321Z","iopub.execute_input":"2022-04-24T17:17:42.458579Z","iopub.status.idle":"2022-04-24T17:17:42.464677Z","shell.execute_reply.started":"2022-04-24T17:17:42.458546Z","shell.execute_reply":"2022-04-24T17:17:42.463919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=[early_stopping,lr_on_plateau])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T17:17:42.466083Z","iopub.execute_input":"2022-04-24T17:17:42.466694Z","iopub.status.idle":"2022-04-24T18:07:29.486819Z","shell.execute_reply.started":"2022-04-24T17:17:42.466636Z","shell.execute_reply":"2022-04-24T18:07:29.485925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction\n\nLets use this model to make prediction","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:29.488341Z","iopub.execute_input":"2022-04-24T18:07:29.488876Z","iopub.status.idle":"2022-04-24T18:07:29.505339Z","shell.execute_reply.started":"2022-04-24T18:07:29.488824Z","shell.execute_reply":"2022-04-24T18:07:29.504357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = get_images(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:29.507757Z","iopub.execute_input":"2022-04-24T18:07:29.508159Z","iopub.status.idle":"2022-04-24T18:07:33.702424Z","shell.execute_reply.started":"2022-04-24T18:07:29.508096Z","shell.execute_reply":"2022-04-24T18:07:33.701739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of test images', test_images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:33.704029Z","iopub.execute_input":"2022-04-24T18:07:33.704389Z","iopub.status.idle":"2022-04-24T18:07:33.7092Z","shell.execute_reply.started":"2022-04-24T18:07:33.704358Z","shell.execute_reply":"2022-04-24T18:07:33.708069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predictions ","metadata":{}},{"cell_type":"code","source":"test_preds = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:33.710707Z","iopub.execute_input":"2022-04-24T18:07:33.710924Z","iopub.status.idle":"2022-04-24T18:07:40.232881Z","shell.execute_reply.started":"2022-04-24T18:07:33.710897Z","shell.execute_reply":"2022-04-24T18:07:40.232062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of test predictions', test_preds.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:40.23486Z","iopub.execute_input":"2022-04-24T18:07:40.235588Z","iopub.status.idle":"2022-04-24T18:07:40.241235Z","shell.execute_reply.started":"2022-04-24T18:07:40.235537Z","shell.execute_reply":"2022-04-24T18:07:40.240401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_images(test_images[0],test_preds[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:40.242863Z","iopub.execute_input":"2022-04-24T18:07:40.243335Z","iopub.status.idle":"2022-04-24T18:07:40.812291Z","shell.execute_reply.started":"2022-04-24T18:07:40.243288Z","shell.execute_reply":"2022-04-24T18:07:40.811367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_data(test_images,test_preds)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:40.813979Z","iopub.execute_input":"2022-04-24T18:07:40.814617Z","iopub.status.idle":"2022-04-24T18:07:41.355697Z","shell.execute_reply.started":"2022-04-24T18:07:40.814565Z","shell.execute_reply":"2022-04-24T18:07:41.354694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_data(test_images,test_preds)        ","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:41.357034Z","iopub.execute_input":"2022-04-24T18:07:41.357289Z","iopub.status.idle":"2022-04-24T18:07:41.891343Z","shell.execute_reply.started":"2022-04-24T18:07:41.357255Z","shell.execute_reply":"2022-04-24T18:07:41.890377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"feature_names = list(lookup['FeatureName'])\nimage_ids = list(lookup['ImageId']-1)\nrow_ids = list(lookup['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:07:41.893325Z","iopub.execute_input":"2022-04-24T18:07:41.893683Z","iopub.status.idle":"2022-04-24T18:07:42.054863Z","shell.execute_reply.started":"2022-04-24T18:07:41.893614Z","shell.execute_reply":"2022-04-24T18:07:42.053852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}