{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom multiprocessing import pool\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras \nimport sklearn \nimport scipy \nimport cv2\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n!pip install pyunpack\n!pip install patool\n\nfrom pyunpack import Archive\nArchive(\"../data/competitions/facial-keypoints-detection/test.zip\").extractall(\"../data/competitions/facial-keypoints-detection\")\nArchive(\"../data/competitions/facial-keypoints-detection/training.zip\").extractall(\"../data/competitions/facial-keypoints-detection\")\nprint(os.listdir(\"../data/competitions/facial-keypoints-detection\"))\ntrain_data=pd.read_csv(\"../data/competitions/facial-keypoints-detection/training.csv\")\ntest_data=pd.read_csv(\"../data/competitions/facial-keypoints-detection/test.csv\")\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"\ntrain_data.dropna(inplace=True)\ntrain_data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78ab8956d60e1481d520a2cea9690e80fd6bc74e","trusted":false},"cell_type":"code","source":"X_train=np.array(train_data.iloc[:,-1])\nX_test=np.array(test_data.iloc[:,-1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d7a0c8dab83f36c998d2fcee97bf8cf1ae88477","trusted":false},"cell_type":"code","source":"#for train set\nX_train_d=np.zeros([len(X_train),96,96])\nfor i,j in enumerate(X_train):\n    c=np.array([int(x) for x in j.strip().split()])\n    \n    X_train_d[i]=c.reshape([96,96]) \nX_train=X_train_d.copy()    \n#for test set\nX_test_d=np.zeros([len(X_test),96,96])\nfor i,j in enumerate(X_test):\n    c=np.array([int(x) for x in j.strip().split()])\n   \n    X_test_d[i]=c.reshape([96,96]) \nX_test=X_test_d.copy()    ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_uuid":"df377ea64b69483386d95b3a71c8e5f37b2200b9","trusted":false},"cell_type":"code","source":"#For Output\nY_train=train_data.iloc[:,:-1]\nY_test=train_data.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"378357ecdb6f0474f494779eb712e47c41020f75","scrolled":false,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"501f10d41c79ffeb29a7c9451735202ba8bc8013","trusted":false},"cell_type":"code","source":"##test train split\nfrom sklearn.cross_validation import train_test_split\na_train, a_test, b_train, b_test = train_test_split(X_train,Y_train, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"387b774fac2658099a9a7349895e68654c2b74ad","trusted":false},"cell_type":"code","source":"def affine_transform(img,i_points,f_points):\n    rows,cols = img.shape\n    x=[i_points[2*i] for i in range(15)]\n    y=[i_points[2*i-1] for i in range(1,15+1)]\n    i_pt=list(zip(x,y))\n    x=[f_points[2*i] for i in range(15)]\n    y=[f_points[2*i-1] for i in range(1,15+1)]\n    f_pt=list(zip(x,y))\n    pts1 = np.float32(i_pt)\n    pts2 = np.float32(f_pt)\n    pts=np.array(i_pt)\n    ones=np.ones([15,3])\n    \n    ones[:,:2]=pts\n    pts=ones.T\n   \n    M = cv2.getAffineTransform(pts1[[0,1,14]],pts2[[0,1,14]])\n    transform=np.matmul(M,pts)\n    dst = cv2.warpAffine(img.copy(),M,(cols,rows))\n    return dst,transform.T\ndef face_pt_plotter(img,pt):\n    imgd=img.copy()\n    x=[pt[2*i] for i in range(15)]\n    y=[pt[2*i-1] for i in range(1,15+1)]\n    pts=zip(x,y)\n    for i in pts:\n        imgd[int(i[1])][int(i[0])]=255\n    return imgd    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f702be234bc289bf0f0838eeb0aee1431fb907e","trusted":false},"cell_type":"code","source":"#plotting the images\narr=[]\nfor i in range(len(b_train)):\n    img,trans=affine_transform(a_train[400],b_train.values[400],b_train.values[i])\n    arr.append([img,trans])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa69c837cfd9821a086116e5ff2653a6d3392944","trusted":false},"cell_type":"code","source":"#plotting the images with transformation\nfig,axis=plt.subplots(nrows=5,ncols=5,figsize=[10,10])\ncount=0\n\nfor i in range(5):\n    for j in range(5):\n        axis[i,j].imshow(face_pt_plotter(arr[count+100][0],arr[count+100][1].reshape(30)))\n        count+=1\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6511c7288cc7dba4f72eefdf3d7300fcee01414","scrolled":true,"trusted":false},"cell_type":"code","source":"#print(Y_train.values[np.nonzero(Y_train.values[:,0]>float(68)),0])\nprint(np.nonzero(b_train.values[:,0]>71)[0].shape)\nprint(np.nonzero(b_train.values[:,0]<60)[0].shape)\nmedian=np.median(b_train.values[:,0])\nprint(median)\nvar=np.var(b_train.values[:,0])\nmean=np.mean(b_train.values[:,0])\nprint(var,mean)\nplt.hist(b_train.values[:,0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4616adaf9e38b6a9a2ba268c12d18a068bc1f9a3","scrolled":true,"trusted":false},"cell_type":"code","source":"T_points=b_train.values[np.concatenate([np.nonzero(b_train.values[:,0]>mean+var),np.nonzero(b_train.values[:,0]<mean-var)],axis=1).reshape(-1),:]\nprint(T_points.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37e6da8ea2f0cfc5506fa832bdff99cf8cbc0e70","trusted":false},"cell_type":"code","source":"#plotting image with T_points\narr=[]\nfor i in range(len(T_points)):\n    img,trans=affine_transform(a_train[0],b_train.values[0],T_points[i])\n    arr.append([img,trans])\nfig,axis=plt.subplots(nrows=15,ncols=5,figsize=[50,50])\ncount=0\nfor i in range(19):\n    for j in range(5):\n        try:\n         axis[i,j].imshow(face_pt_plotter(arr[count][0],arr[count][1].reshape(30)))\n        except IndexError:\n            pass\n        count+=1\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d6527763811587e9e774d621e7d33c344ab93a7","scrolled":false,"trusted":false},"cell_type":"code","source":"import random\nrandom.seed(1)\n##augmented data creation\nA_train=[]\nB_train=[]\nfor j in range(len(b_train)):\n        for i in np.random.choice(83,20):\n                img,transform=affine_transform(a_train[j],b_train.values[j],T_points[i])\n                A_train.append(img)\n                B_train.append(transform.reshape(30))\n            \nprint(len(A_train),len(B_train))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75d4158d581785eb076bdddab85db65bb3c4b30a","trusted":false},"cell_type":"code","source":"a_new=np.concatenate([a_train,np.array(A_train)],axis=0)\nprint(a_new.shape)\nb_new=np.concatenate([b_train,np.array(B_train)],axis=0)\nprint(b_new.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d6f65f09e4c80fb9eaf6f8eea443a6039f580c6","scrolled":true,"trusted":false},"cell_type":"code","source":"## model\nfrom tensorflow.keras.layers import Activation, Convolution2D, Dropout, Conv2D,Dense\nfrom tensorflow.keras.layers import AveragePooling2D, BatchNormalization\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import SeparableConv2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\ndef mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n    regularization = l2(l2_regularization)\n\n    # base\n    img_input = Input(input_shape)\n    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n               use_bias=False)(img_input)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n               use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # module 1\n    residual = Conv2D(16, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(16, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(16, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 2\n    residual = Conv2D(32, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(32, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(32, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 3\n    residual = Conv2D(64, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(64, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(64, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 4\n    residual = Conv2D(128, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(128, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(128, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    x = Conv2D(num_classes, (3, 3),\n               # kernel_regularizer=regularization,\n               padding='same')(x)\n    x = GlobalAveragePooling2D()(x)\n    output = Dense(30)(x)\n\n    model = Model(img_input, output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af4864a1c093b76746349a9455da89cc6a63f04f","trusted":false},"cell_type":"code","source":"#training the model\nbatch_size = 32\nnum_epochs = 100\ninput_shape = (96, 96, 1)\nverbose = 1\nnum_classes = 30\npatience = 50\nmodel = mini_XCEPTION(input_shape, num_classes)\nmodel.compile(optimizer='adam', loss='mse',\n              metrics=[\"mae\",'accuracy'])\nmodel.summary()\n\n# callbacks\n\nearly_stop = EarlyStopping('val_loss', patience=patience)\nreduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n                              patience=int(patience/4), verbose=1)\nmodel_checkpoint = ModelCheckpoint(\"{epoch}-{val_loss}.h5\", 'val_loss', verbose=1,save_best_only=True)\ncallbacks = [model_checkpoint,early_stop, reduce_lr]\n#model.fit(a_new.reshape(-1,96,96,1),b_new,batch_size=batch_size,epochs=num_epochs, verbose=1, callbacks=callbacks,validation_data=[a_test.reshape(-1,96,96,1),b_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ff69953107ff0d7f6a83d8883150c0898cacca9a"},"cell_type":"code","source":"prediction=model.predict(np.concatenate([X_test.reshape(-1,96,96,1),np.zeros([1,96,96,1])],axis=0))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a906317672d6aa356a478afaac53a26b392358d0"},"cell_type":"code","source":"#saving the predictions\nimport pickle\nwith open(\"predicitons.plk\",\"wb\") as a:\n    pickle.dump(prediction,a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3544a9626f7885b898166d87d8ca100df2ff5c47"},"cell_type":"code","source":"#plotting the test images with predicted points\nfig,axis=plt.subplots(nrows=15,ncols=5,figsize=[50,50])\ncount=0\nfor i in range(15):\n    for j in range(5):\n        try:\n         axis[i,j].imshow(face_pt_plotter(arr[count][0],arr[count][1].reshape(30)))\n        except IndexError:\n            pass\n        count+=1\n        \nplt.imshow(face_pt_plotter(X_test[-7],prediction[-7]),cmap=\"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"aa9fa083ab03886f6fbe478e64553fd71482cd75"},"cell_type":"code","source":"##creating the submission file \nidlook=pd.read_csv(\"../data/competitions/facial-keypoints-detection/IdLookupTable.csv\")\ntemp=pd.DataFrame(prediction,columns=list(Y_train.columns))\nrowid=np.arange(1,53491)\nlen(rowid)\ntemp.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b7dc0aab8293d74ab2db43969209d3d26ff99b68"},"cell_type":"code","source":"features=[]\nfor index,row in idlook.iterrows():\n    features.append(temp.iloc[[row[\"ImageId\"]-1]][row[\"FeatureName\"]].values)\nfeatures=np.concatenate(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bb0717234cc7d9943889c82a4b382216cad203bf"},"cell_type":"code","source":"d={\"RowId\":rowid,\"Location\":x}\nsubmission=pd.DataFrame(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b18a9e17b157153a30c6e4c13600d0fabbad2861"},"cell_type":"code","source":"submission.to_csv(\"facial_keypoint_detection.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}