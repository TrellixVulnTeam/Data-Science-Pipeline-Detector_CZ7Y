{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/training/training.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.isnull().any().value_counts(), df.shape)\ndf.dropna(inplace=True)\n#df.fillna(method = 'ffill',inplace = True)\n#df.reset_index(drop = True, inplace = True)\nprint(df.isnull().any().value_counts(), df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(frac=1)\nimg_data = df['Image'].values\ndf.drop('Image', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = [np.array(list(map(int, image.split())), dtype=np.uint8).reshape(96,96) for image in img_data]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# example images\nfig, ax = plt.subplots(nrows=3, ncols=3, figsize=(20,20))\nc = 0\nr = 0\nfor i in range(9):\n    ax[r, c].imshow(images[i], 'gray')\n    for j in range(0, len(list(df)), 2):\n        ax[r,c].scatter(df.loc[i][j], df.loc[i][j+1], s=15, c='red')\n    ax[r,c].axis('off')\n    c += 1\n    if c == 3:\n        r += 1\n        c = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\ndef build_model():\n    # output has to be 30 values: 15 x coordinates and 15 y coordinates corresponding to the facial keypoints\n    inp = keras.layers.Input(shape=(96,96,1))\n    x = keras.layers.Conv2D(16, (2,2), activation='relu', padding='same')(inp)\n    x = keras.layers.MaxPool2D((2,2))(x)\n    x = keras.layers.BatchNormalization()(x)\n    \n    x = keras.layers.Conv2D(32, (5,5), activation='relu')(x)\n    x = keras.layers.MaxPool2D((2,2))(x)\n    x = keras.layers.Dropout(.2)(x)\n    x = keras.layers.BatchNormalization()(x)\n    \n    x = keras.layers.Conv2D(64, (5,5), activation='relu')(x)\n    x = keras.layers.MaxPool2D((2,2))(x)\n    x = keras.layers.BatchNormalization()(x)\n\n    x = keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n    x = keras.layers.MaxPool2D((2,2))(x)\n    x = keras.layers.Dropout(.4)(x)\n    x = keras.layers.BatchNormalization()(x)\n\n    x = keras.layers.Flatten()(x)\n    x = keras.layers.Dense(500, activation='relu')(x)\n    x = keras.layers.Dropout(.5)(x)\n    x = keras.layers.Dense(128, activation='relu')(x)\n    x = keras.layers.Dropout(.5)(x)\n    out = keras.layers.Dense(30)(x)\n    \n    model = keras.models.Model(inp, out)\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = np.array([image / 255 for image in images])\nimages = np.expand_dims(images, axis=-1)\nprint(images.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df.values\ny /= 96\ny = y.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(images, y, \n                 epochs= 2000, batch_size=128,\n                 validation_split=.2)#, callbacks=[sched])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nepochs = range(1,len(hist.history['loss'])+1)\nplt.plot(epochs, hist.history['loss'], 'b', label='Training loss')\nplt.plot(epochs, hist.history['val_loss'], 'g', label='Validation loss')\nplt.yscale('log')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/test/test.csv')\n#preparing test data\ntimag = []\nfor i in range(0,1783):\n    timg = test_data['Image'][i].split(' ')\n    timg = ['0' if x == '' else x for x in timg]\n    \n    timag.append(timg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timage_list = np.array(timag, dtype = 'float')\nX_test = timage_list.reshape(-1,96,96)\nplt.imshow(X_test[0],cmap = 'gray')\nplt.scatter(pred[0][::2], pred[0][1::2])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(np.expand_dims(X_test/255,axis=-1))\npred = (pred * 96) # convert back to non-normalized\nprint(pred[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lookid_data = pd.read_csv('../input/IdLookupTable.csv')\nlookid_list = list(lookid_data['FeatureName'])\nimageID = list(lookid_data['ImageId']-1)\npre_list = list(pred)\nrowid = lookid_data['RowId']\nrowid=list(rowid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature = []\nfor f in list(lookid_data['FeatureName']):\n    feature.append(lookid_list.index(f))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preded = []\nfor x,y in zip(imageID,feature):\n    preded.append(pre_list[x][y])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rowid = pd.Series(rowid,name = 'RowId')\nloc = pd.Series(preded,name = 'Location')\nsubmission = pd.concat([rowid,loc],axis = 1)\nsubmission.to_csv('face_key_detection_submission.csv',\n                  index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}