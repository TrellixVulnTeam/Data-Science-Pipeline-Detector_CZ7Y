{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPool2D, BatchNormalization, LeakyReLU\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\n\nclass Data_Clean(object):\n    def __init__(self, trainPath, testPath):\n        self.train = pd.read_csv(trainPath)\n        self.test = pd.read_csv(testPath)\n        self.data_assemble = []\n        self.column = self.train.columns.drop('Image')\n\n    def seperate_data(self):\n        for column_name in self.train.columns.drop('Image'):\n            data = self.train[[column_name, 'Image']].dropna()\n            self.data_assemble.append([data[column_name], data['Image']])\n        self.test = self.test['Image']\n\n    def reshape_image(self):\n        for data in self.data_assemble:\n            data[1] = data[1].apply(lambda im: np.fromstring(im, sep=' ', dtype=float))\n            values = data[1].values / 255.0\n            values = np.vstack(values).reshape(-1, 96, 96, 1)\n            data[1] = values\n        self.test = self.test.apply(lambda img: np.fromstring(img, sep=' ', dtype=float))\n        self.test = self.test.values / 255.0\n        self.test = np.vstack(self.test).reshape(-1, 96, 96, 1)\n\n    def run(self):\n        self.seperate_data()\n        self.reshape_image()\n        return self.data_assemble, self.test, self.column\n\nclass CNN(object):\n    def __init__(self, train, test, columns_list):\n        self.train = train\n        self.test = test\n        self.columns_list = columns_list\n\n    def define_CNN(self):\n        model = Sequential()\n        model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', use_bias=False, input_shape=(96, 96, 1)))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n\n        model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D(pool_size=(2, 2)))\n\n        model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n\n        model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D(pool_size=(2, 2)))\n\n        model.add(Convolution2D(filters=96, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n\n        model.add(Convolution2D(filters=96, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D(pool_size=(2, 2)))\n\n        model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n\n        model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D(pool_size=(2, 2)))\n\n        model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n\n        model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D(pool_size=(2, 2)))\n\n        model.add(Convolution2D(filters=512, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n\n        model.add(Convolution2D(filters=512, kernel_size=(3, 3), padding='same', use_bias=False))\n        model.add(LeakyReLU(alpha=0.1))\n        model.add(BatchNormalization())\n\n        model.add(Flatten())\n        model.add(Dense(512, activation='relu'))\n        model.add(Dropout(0.1))\n        model.add(Dense(1))\n        self.model = model\n\n    def Adam(self, epochs, batchSize, xtrain, xvalidation, ytrain, yvalidation):\n        self.model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n        self.model.fit(xtrain, ytrain, batch_size=batchSize, epochs=epochs, validation_data=(xvalidation, yvalidation),\n                       verbose=0)\n\n    def show_a_result(self, ypred, ytest):\n        import copy\n        plt.imshow(ytest.reshape(96, 96))\n        ypred = copy.deepcopy(ypred)\n        xy = np.split(ypred, 30)\n        predx, predy = [], []\n        for i in range(0, 30, 2):\n            predx.append(xy[i])\n            predy.append(xy[i+1])\n        plt.plot(predx, predy, 'o', color='red')\n        plt.show()\n\n    def make_output(self, ypred):\n        pred = ypred\n        dataPath = '../input/IdLookupTable.csv'\n        lookid_data = pd.read_csv(dataPath)\n        lookid_list = list(lookid_data['FeatureName'])\n        imageID = list(lookid_data['ImageId'] - 1)\n        rowid = lookid_data['RowId']\n        rowid = list(rowid)\n        feature = []\n        for f in lookid_list:\n            feature.append(f)\n        preded = []\n        for x, y in zip(imageID, feature):\n            preded.append(pred[y].loc[x])\n        rowid = pd.Series(rowid, name='RowId')\n        loc = pd.Series(preded, name='Location')\n        submission = pd.concat([rowid, loc], axis=1)\n        submission.to_csv('Utkarsh.csv', index=False)\n\n\n    def run(self):\n        ypred = pd.DataFrame(index = [i for i in range(1783)] ,columns=self.columns_list)\n        for index, data in enumerate(self.train):\n            label = data[0]\n            columns_name = self.columns_list[index]\n            train = data[1]\n            xtrain, xvalidation, ytrain, yvalidation = train_test_split(train, label, test_size=0.1, random_state=9)\n            self.define_CNN()\n            print(columns_name, ' training started:')\n            self.Adam(epochs=100, batchSize=128, xtrain=xtrain, xvalidation=xvalidation, ytrain=ytrain, yvalidation=yvalidation)\n            ypred[columns_name] = self.model.predict(self.test)\n\n        self.make_output(ypred)\n        #show a results\n        self.show_a_result(ypred.loc[159], self.test[159])\n\nif __name__ == '__main__':\n    trainPath = '../input/training/training.csv'\n    testPath = '../input/test/test.csv'\n\n    data_clean = Data_Clean(trainPath, testPath)\n    train, test, columns_list = data_clean.run()\n\n    cnn = CNN(train, test, columns_list)\n    cnn.run()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}