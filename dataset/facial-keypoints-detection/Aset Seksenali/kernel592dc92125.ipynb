{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom numpy import asarray\nimport scipy\nimport gc\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_lookup = pd.read_csv('/kaggle/input/facial-keypoints-detection/IdLookupTable.csv')\ntrain = pd.read_csv('/kaggle/input/facial-keypoints-detection/training/training.csv')\nclear_data = train.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_images(dataframe):\n    return np.stack(dataframe.progress_apply(lambda row: np.array(row.Image.split()).reshape(96, 96).astype('int') / 255., axis=1)) / 96.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = get_images(clear_data)\ny_train = clear_data.iloc[:, :-1].values.flatten().reshape((-1, 30)) / 96.\nx_train = np.expand_dims(x_train, axis=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(4, 4), activation = 'elu', input_shape=(96, 96, 1), padding='valid'))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.1))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='elu', padding='valid'))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128, kernel_size=(2, 2), activation='elu', padding='valid'))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(256, kernel_size=(1, 1), activation='elu', padding='valid'))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(1000, activation='elu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1000, activation='elu'))\nmodel.add(Dropout(0.6))\nmodel.add(Dense(30, activation='linear')) # We add dense layers for processing input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='mse',\n             optimizer='adam',\n             metrics=['mae'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=x_train,y=y_train, batch_size=64, epochs=150, verbose=1, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/facial-keypoints-detection/test/test.csv')\ntest_images = np.expand_dims(get_images(test), axis=3)\nresult = model.predict(test_images) * 96.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame(result, columns=[train.columns[:-1]])\nres.index += 1\nres = res.unstack()\nkek = res.swaplevel().sort_index().reset_index()\nkek = kek.rename({'level_0':\"ImageId\", 'level_1': \"FeatureName\"}, axis=1)\nr = id_lookup.merge(kek, how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame({\n    \"RowId\": r.RowId,\n    \"Location\": r.iloc[:, -1]\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(test_images[874].reshape((96, 96)))\nplt.plot(res.unstack().iloc[:, 874].values[::2], res.unstack().iloc[:, 874].values[1::2], 'r.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.loc[result.Location > 96]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('result1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}