{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install git+https://github.com/Ritvik19/pyradox.git","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import sin, cos, pi\nimport cv2, os\nfrom tqdm.auto import tqdm\n\nfrom tensorflow.keras import layers, callbacks, utils, applications, optimizers, Input\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom pyradox import convnets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class config:\n    NUM_EPOCHS = 100\n    BATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Contents of input/facial-keypoints-detection directory: \")\n!ls ../input/facial-keypoints-detection/\n\nprint(\"\\nExtracting .zip dataset files to working directory ...\")\n!unzip -u ../input/facial-keypoints-detection/test.zip\n!unzip -u ../input/facial-keypoints-detection/training.zip\n\nprint(\"\\nCurrent working directory:\")\n!pwd\nprint(\"\\nContents of working directory:\")\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain_file = 'training.csv'\ntest_file = 'test.csv'\nidlookup_file = '../input/facial-keypoints-detection/IdLookupTable.csv'\ntrain_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)\nidlookup_data = pd.read_csv(idlookup_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96,96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idlookup_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Length of train data:\", len(train_data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Find columns having Null values and their counts**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can observe that approx. 68% of data is missing for several keypoints"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"clean_train_data = train_data.dropna()\nprint(\"clean_train_data shape:\", np.shape(clean_train_data))\n\nunclean_train_data = train_data.fillna(method = 'ffill')\nprint(\"unclean_train_data shape:\", np.shape(unclean_train_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef load_images(image_data):\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)/255.\n    return images\n\ndef load_keypoints(keypoint_data):\n    keypoint_data = keypoint_data.drop('Image',axis = 1)\n    keypoint_features = []\n    for idx, sample_keypoints in keypoint_data.iterrows():\n        keypoint_features.append(sample_keypoints)\n    keypoint_features = np.array(keypoint_features, dtype = 'float')\n    return keypoint_features\n\nclean_train_images = load_images(clean_train_data)\nprint(\"Shape of clean_train_images:\", np.shape(clean_train_images))\nclean_train_keypoints = load_keypoints(clean_train_data)\nprint(\"Shape of clean_train_keypoints:\", np.shape(clean_train_keypoints))\ntest_images = load_images(test_data)\nprint(\"Shape of test_images:\", np.shape(test_images))\n\ntrain_images = clean_train_images\ntrain_keypoints = clean_train_keypoints\nfig, axis = plt.subplots()\nplot_sample(clean_train_images[19], clean_train_keypoints[19], axis, \"Sample image & keypoints\")\n\nunclean_train_images = load_images(unclean_train_data)\nprint(\"Shape of unclean_train_images:\", np.shape(unclean_train_images))\nunclean_train_keypoints = load_keypoints(unclean_train_data)\nprint(\"Shape of unclean_train_keypoints:\", np.shape(unclean_train_keypoints))\ntrain_images = np.concatenate((train_images, unclean_train_images))\ntrain_keypoints = np.concatenate((train_keypoints, unclean_train_keypoints))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize Train images & corresponding Keypoints"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nClean Train Data: \")\nfig = plt.figure(figsize=(20,8))\nfor i in range(10):\n    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n    plot_sample(clean_train_images[i], clean_train_keypoints[i], axis, \"\")\nplt.show()\n\nprint(\"Unclean Train Data: \")\nfig = plt.figure(figsize=(20,8))\nfor i in range(10):\n    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n    plot_sample(unclean_train_images[i], unclean_train_keypoints[i], axis, \"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input(shape=(96, 96, 1))\nx = layers.Convolution2D(3, (1, 1), padding='same')(inputs)\nx = layers.LeakyReLU(alpha = 0.1)(x)\nx = convnets.MobileNetV3(config='small')(x)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.1)(x)\noutputs = layers.Dense(30)(x)\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_model(model, show_shapes=True, expand_nested=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"es = callbacks.EarlyStopping(\n    monitor='loss', patience=30, verbose=1, mode='min', baseline=None, restore_best_weights=True\n)\n\nrlp = callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-15, mode='min', verbose=1\n)\n\nmodel.compile(\n    optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc']\n)\n\nhistory = model.fit(\n    train_images, train_keypoints, epochs=int(1.5*config.NUM_EPOCHS), batch_size=config.BATCH_SIZE, \n    validation_split=0.05, callbacks=[es, rlp]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\n\nfig, ax = plt.subplots(3, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['mae', 'val_mae']].plot(ax=ax[0])\ndf[['loss', 'val_loss']].plot(ax=ax[1])\ndf[['acc', 'val_acc']].plot(ax=ax[2])\nax[0].set_title('Model MAE', fontsize=12)\nax[1].set_title('Model Loss', fontsize=12)\nax[2].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit the model on full dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nes = callbacks.EarlyStopping(\n    monitor='loss', patience=30, verbose=1, mode='min', baseline=None, restore_best_weights=True\n)\n\nrlp = callbacks.ReduceLROnPlateau(\n    monitor='loss', factor=0.5, patience=5, min_lr=1e-15, mode='min', verbose=1\n)\n\n\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=history.history['lr'][-1]), loss='mean_squared_error', metrics=['mae', 'acc']\n)\n\nhistory = model.fit(\n    train_images, train_keypoints, epochs=int(3.5*config.NUM_EPOCHS), batch_size=config.BATCH_SIZE, callbacks=[es, rlp]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3, 1, figsize=(20, 10))\ndf = pd.DataFrame(history.history)\ndf[['mae']].plot(ax=ax[0])\ndf[['loss']].plot(ax=ax[1])\ndf[['acc']].plot(ax=ax[2])\nax[0].set_title('Model MAE', fontsize=12)\nax[1].set_title('Model Loss', fontsize=12)\nax[2].set_title('Model Acc', fontsize=12)\nfig.suptitle('Model Metrics', fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting on Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n \ntest_preds = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing Test Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,16))\nfor i in range(20):\n    axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n    plot_sample(test_images[i], test_preds[i], axis, \"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generating Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = list(idlookup_data['FeatureName'])\nimage_ids = list(idlookup_data['ImageId']-1)\nrow_ids = list(idlookup_data['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_preds[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}