{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the necessary packages\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport PIL\nimport seaborn as sns\nimport pickle\nfrom PIL import *\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom IPython.display import display\nfrom tensorflow.keras import Input\nfrom tensorflow.python.keras import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, optimizers\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df = pd.read_csv('../input/facial-keypoints-detection/training.zip', compression='zip', header=0, sep=',', quotechar='\"')\ntest_data = pd.read_csv('../input/facial-keypoints-detection/test.zip', compression='zip', header=0, sep=',', quotechar='\"')\nIdLookupTable = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv',header=0, sep=',', quotechar='\"')\nSampleSubmission = pd.read_csv('../input/facial-keypoints-detection/SampleSubmission.csv',header=0, sep=',', quotechar='\"')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df.fillna(method = 'ffill',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reshape Image"},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df['Image'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df['Image']=keyfacial_df['Image'].apply(lambda x:np.fromstring(x,dtype=int,sep=' ').reshape(96,96))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df['Image'][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyfacial_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image visulaization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a random image from the dataset along with facial keypoints. \n# Image data is obtained from df['Image'] and plotted using plt.imshow\n# 15 x and y coordinates for the corresponding image \n# since x-coordinates are in even columns like 0,2,4,.. and y-coordinates are in odd columns like 1,3,5,..\n# we access their value using .loc command, which get the values for coordinates of the image based on the column it is refering to.\n\ni = np.random.randint(1, len(keyfacial_df))\nplt.imshow(keyfacial_df['Image'][i], cmap = 'gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df.loc[i][j-1], keyfacial_df.loc[i][j], 'rx')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n# Let's view more images in a grid format\nfig = plt.figure(figsize=(20, 20))\n\nfor i in range(16):\n    k=random.randint(1,len(keyfacial_df))\n    ax = fig.add_subplot(4, 4, i + 1)\n    image = plt.imshow(keyfacial_df['Image'][k],cmap = 'gray')\n    for j in range(1,31,2):\n        plt.plot(keyfacial_df.loc[k][j-1], keyfacial_df.loc[k][j], 'rx')\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a new copy of the dataframe\nimport copy\nkeyfacial_df_copy=copy.copy(keyfacial_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns =keyfacial_df_copy.columns[:-1]\ncolumns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Horizontal flip"},{"metadata":{"trusted":true},"cell_type":"code","source":"#horizontal-flip\nkeyfacial_df_copy['Image']=keyfacial_df_copy['Image'].apply(lambda x:np.flip(x,axis=1))\n#As Flipping horizontally , y coordiantes will be same \n# only x cordinate values will change ,So Subtract our x-coordinate  values from width of the image 96\nfor i in range(len(columns)):\n    if i%2 == 0:\n         keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x:96.-float(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Original image\nplt.imshow(keyfacial_df['Image'][1], cmap = 'gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df.loc[1][j-1], keyfacial_df.loc[1][j], 'rx')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# horizontal flip  image\nplt.imshow(keyfacial_df_copy['Image'][1], cmap = 'gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df_copy.loc[1][j-1], keyfacial_df_copy.loc[1][j], 'rx')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenating the original dataframe with the augmented dataframe\naugmented_df = np.concatenate((keyfacial_df, keyfacial_df_copy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Brightness"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Randomingly increasing the brightness of the images\n# We multiply pixel values by random values between 1.5 and 2 to increase the brightness of the image\n# we clip the value between 0 and 255\n\nimport random\n\nkeyfacial_df_copy = copy.copy(keyfacial_df)\nkeyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x:np.clip(random.uniform(1.5, 2)* x, 0.0, 255.0))\naugmented_df = np.concatenate((augmented_df, keyfacial_df_copy))\naugmented_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Image with increased brightness\n\nplt.imshow(keyfacial_df_copy['Image'][1], cmap='gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df_copy.loc[1][j-1], keyfacial_df_copy.loc[1][j], 'rx')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * Vertical Flip"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vertical flip \n#x-coordiantes will not change\n#y-coordinates will change \n#horizontal-flip\nkeyfacial_df_copy['Image']=keyfacial_df_copy['Image'].apply(lambda x:np.flip(x,axis=0))\nfor i in range(len(columns)):\n    if i%2 == 1:\n         keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x:96.-float(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(keyfacial_df_copy['Image'][1], cmap='gray')\nfor j in range(1, 31, 2):\n        plt.plot(keyfacial_df_copy.loc[1][j-1], keyfacial_df_copy.loc[1][j], 'rx')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Normalization and Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#values of Image\nimg=augmented_df[:,30]\n\n#Normalize the image\nimg=img/255.\n\n# empty array to feed the model of shape(96,96,1)\nX= np.empty((len(img),96,96,1))\n\n#expanding dimensions to (96,96,1)\nfor i in range(len(img)):\n    X[i,]=np.expand_dims(img[i],axis=2)\n\n#Converting array type to float\nX=np.asarray(X).astype(np.float32)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=augmented_df[:,:30]\ny=np.asarray(y).astype(np.float32)\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Residual Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"def res_block(X, filter, stage):\n    \n    \n\n  # Convolutional_block\n    X_copy = X\n\n    f1 , f2, f3 = filter\n\n  # Main Path\n    X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = MaxPool2D((2,2))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n\n  # Short path\n    X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n    X_copy = MaxPool2D((2,2))(X_copy)\n    X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n\n  # ADD\n    X = Add()([X,X_copy])\n    X = Activation('relu')(X)\n\n  # Identity Block 1\n    X_copy = X\n\n\n  # Main Path\n    X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n\n  # ADD\n    X = Add()([X,X_copy])\n    X = Activation('relu')(X)\n\n  # Identity Block 2\n    X_copy = X\n\n\n  # Main Path\n    X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n    X = Activation('relu')(X) \n\n    X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n    X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n\n  # ADD\n    X = Add()([X,X_copy])\n    X = Activation('relu')(X)\n\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (96, 96, 1)\n\n# Input tensor shape\nX_input = Input(input_shape)\n\n# Zero-padding\nX = ZeroPadding2D((3,3))(X_input)\n\n# 1 - stage\nX = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\nX = BatchNormalization(axis =3, name = 'bn_conv1')(X)\nX = Activation('relu')(X)\nX = MaxPooling2D((3,3), strides= (2,2))(X)\n\n# 2 - stage\nX = res_block(X, filter= [64,64,256], stage= 2)\n\n# 3 - stage\nX = res_block(X, filter= [128,128,512], stage= 3)\n\n\n# Average Pooling\nX = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n\n# Final layer\nX = Flatten()(X)\nX = Dense(4096, activation = 'relu')(X)\nX = Dropout(0.2)(X)\nX = Dense(2048, activation = 'relu')(X)\nX = Dropout(0.1)(X)\nX = Dense(30, activation = 'relu')(X)\n\n\nmodel_1_facialKeyPoints = Model( inputs= X_input, outputs = X)\nmodel_1_facialKeyPoints.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compile and Traning"},{"metadata":{"trusted":true},"cell_type":"code","source":"adam = tf.keras.optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\nmodel_1_facialKeyPoints.compile(loss = \"mean_squared_error\", optimizer = adam , metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the best model with least validation loss\ncheckpointer = ModelCheckpoint(filepath = \"FacialKeyPoints_weights.hdf5\", verbose = 1, save_best_only = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_1_facialKeyPoints.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_data=(X_test,y_test), callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}