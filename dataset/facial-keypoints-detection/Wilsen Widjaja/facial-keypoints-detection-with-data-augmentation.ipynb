{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library and Load Data","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nfrom matplotlib import pyplot\nimport os\nimport time\nimport cv2\n\nfrom math import sin, cos, pi\nfrom pandas import DataFrame\nfrom pandas.io.parsers import read_csv\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-20T11:10:54.741633Z","iopub.execute_input":"2021-12-20T11:10:54.742318Z","iopub.status.idle":"2021-12-20T11:10:59.772231Z","shell.execute_reply.started":"2021-12-20T11:10:54.742223Z","shell.execute_reply":"2021-12-20T11:10:59.77042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading data\n\nTrain_Dir = '../input/facial-keypoints-detection/training.zip'\nTest_Dir = '../input/facial-keypoints-detection/test.zip'\nlookid_dir = '../input/facial-keypoints-detection/IdLookupTable.csv'\nlookid_data = pd.read_csv(lookid_dir)\n\ndef load(test = False, cols = None):\n    \"\"\"\n    Loads the dataset.\n    Returns a tuple of X and y, if `test` was set to `True` y contains `None`.    \n    \"\"\"\n    \n    fname = Test_Dir if test else Train_Dir\n    df = read_csv(os.path.expanduser(fname))  # load pandas dataframe\n\n    # The Image column has pixel values separated by space; convert\n    # the values to numpy arrays:\n    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep = ' '))\n\n    if cols:  # get a subset of columns\n        df = df[list(cols) + ['Image']]\n    print(\"There are missing points:\")\n    print(df.count())  # prints the number of values for each column\n    df = df.dropna()  # drop all rows that have missing values in them\n\n    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1]\n    X = X.astype(np.float32)\n\n    if not test:  # only FTRAIN has any target columns\n        y = df[df.columns[:-1]].values\n        y = (y - 48) / 48  # scale target coordinates to [-1, 1]\n        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n        y = y.astype(np.float32)\n    else:\n        y = None\n        \n    return X.reshape(df.shape[0],96,96), y\n\ndef plot_sample(x, y):\n    \"\"\"\n    Plots a single sample image with keypoints on top.   \n    \"\"\"\n    pyplot.imshow(x, cmap='gray')\n    pyplot.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='x', s=10)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:10:59.775294Z","iopub.execute_input":"2021-12-20T11:10:59.775507Z","iopub.status.idle":"2021-12-20T11:10:59.81889Z","shell.execute_reply.started":"2021-12-20T11:10:59.775478Z","shell.execute_reply":"2021-12-20T11:10:59.818206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, y_train = load()\nx_train = np.expand_dims(x_train, -1)\nplot_sample(x_train[10],y_train[10])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:10:59.820295Z","iopub.execute_input":"2021-12-20T11:10:59.820547Z","iopub.status.idle":"2021-12-20T11:11:20.830564Z","shell.execute_reply.started":"2021-12-20T11:10:59.820512Z","shell.execute_reply":"2021-12-20T11:11:20.829885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test, y_test = load(True)\nx_test = np.expand_dims(x_test, -1)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T11:11:20.832307Z","iopub.execute_input":"2021-12-20T11:11:20.833239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"rotation_angles = [12]  # Rotation Degree\npixel_shifts = [12] # Pixel Moved\nx_train_original = x_train\ny_train_original = y_train\n\n# Bool Variable to trigger augmentation\nrotation_augmentation = True # Only use rotation_augmentation\nbrightness_augmentation = False\nshift_augmentation = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation 1 (Rotate Image)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def rotate_augmentation(images, keypoints): # Function to rotate image\n    rotated_images = []\n    rotated_keypoints = []\n    print(\"Augmentasi dengan sudut sebesar (derajat): \")\n    for angle in rotation_angles:\n        for angle in [angle,-angle]:\n            print(f'{angle}', end='  ')\n            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n            angle_rad = -angle*pi/180.     # mengambil nilai sudut dalam radian\n            # untuk nilai x\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            # untuk nilai y\n            for keypoint in keypoints:\n                keypoint = keypoint * 48 + 48 # Menyesuaikan nilai y untuk dirotasi\n                rotated_keypoint = keypoint - 48\n                for idx in range(0,len(rotated_keypoint),2):\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48\n                rotated_keypoint = (rotated_keypoint - 48) / 48  # scale target coordinates to [-1, 1]\n\n                rotated_keypoints.append(rotated_keypoint)\n\n    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n\n# Rotating images\nrotated_train_images, rotated_train_keypoints = rotate_augmentation(x_train, y_train)\nprint(\"\\nShape of rotated_train_images: {}\".format(np.shape(rotated_train_images)))\nprint(\"Shape of rotated_train_keypoints: {}\\n\".format(np.shape(rotated_train_keypoints)))\nrotated_train_images = rotated_train_images.reshape(rotated_train_images.shape[0],96,96,1)\nplot_sample(rotated_train_images[10].reshape(96,96), rotated_train_keypoints[10])\n\nif rotation_augmentation:\n    x_train = np.concatenate((x_train_original, rotated_train_images))\n    y_train = np.concatenate((y_train_original, rotated_train_keypoints))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation 2 (Alter Image Brightness)","metadata":{}},{"cell_type":"code","source":"def alter_brightness(images, keypoints): # Function to alter image brightness\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.4, 0.0, 1.0)    # Gambar menjadi lebih terang\n    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    # Gambar menjadi lebih gelap\n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\n# Altering images brightness\naltered_brightness_train_images, altered_brightness_train_keypoints = alter_brightness(x_train_original, y_train_original)\nprint(f\"Shape of altered_brightness_train_images: {np.shape(altered_brightness_train_images)}\")\nprint(f\"Shape of altered_brightness_train_keypoints: {np.shape(altered_brightness_train_keypoints)}\")\naltered_brightness_train_images = np.reshape(altered_brightness_train_images,(np.shape(altered_brightness_train_images)[0],96,96,1))\nplot_sample(altered_brightness_train_images[10].reshape(96,96), altered_brightness_train_keypoints[10]) \n\nif brightness_augmentation:\n    x_train = np.concatenate((x_train, altered_brightness_train_images))\n    y_train = np.concatenate((y_train, altered_brightness_train_keypoints))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation 3 (Shift Image)","metadata":{}},{"cell_type":"code","source":"def shift_images(images, keypoints): # Function to shift image vertically and horizontally\n    shifted_images = []\n    shifted_keypoints = []\n    final_keypoints = []\n    for shift in pixel_shifts:\n        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n                keypoint = keypoint * 48 + 48 # Menyesuaikan nilai y untuk digeser\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96,96,1))\n                    shifted_keypoints.append(shifted_keypoint)\n    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)\n\n    for keypoint in shifted_keypoints:\n      keypoint = (keypoint - 48) / 48\n      final_keypoints.append(keypoint)\n\n    return shifted_images, final_keypoints\n\n# Shifting images\nshifted_train_keypoints = []\nshifted_train_images, shifted_train_keypoints = shift_images(x_train_original, y_train_original)\nprint(f\"Shape of shifted_train_images: {np.shape(shifted_train_images)}\")\nprint(f\"Shape of shifted_train_keypoints: {np.shape(shifted_train_keypoints)}\")\nplot_sample(shifted_train_images[10].reshape(96,96), shifted_train_keypoints[10])\n\nif shift_augmentation:\n    x_train = np.concatenate((x_train, shifted_train_images))\n    y_train = np.concatenate((y_train, shifted_train_keypoints))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Predefined parameters\ninput_shape = (96, 96, 1)\noutput_shape = 30\n\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"LeakyReLU\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(96, kernel_size=(3, 3), activation=\"LeakyReLU\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(128, kernel_size=(3, 3), activation=\"LeakyReLU\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(256, kernel_size=(3, 3), activation=\"LeakyReLU\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(512, kernel_size=(3, 3), activation=\"LeakyReLU\", padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Flatten(),\n        layers.Dense(512, activation=\"tanh\"),\n        layers.Dense(256, activation=\"ReLU\"),\n        layers.Dense(128, activation=\"ReLU\"),\n        layers.Dropout(0.1),\n        layers.Dense(output_shape, activation=\"linear\"),\n    ]\n)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"batch_size = 128\nepochs = 100\n\nfrom keras import backend as K\n\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n\nmodel.compile(loss=root_mean_squared_error, optimizer=\"adam\")\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction and Submission","metadata":{}},{"cell_type":"code","source":"pred = model.predict(x_test)\npred = pred * 48 # scale target coordinates to [0, 96]\npred += 48","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lookid_list = list(lookid_data['FeatureName'])\nimageID = list(lookid_data['ImageId']-1)\npre_list = list(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rowid = lookid_data['RowId']\nrowid=list(rowid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature = []\nfor f in list(lookid_data['FeatureName']):\n    feature.append(lookid_list.index(f))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preded = []\nfor x,y in zip(imageID,feature):\n    preded.append(pre_list[x][y])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rowid = pd.Series(rowid,name = 'RowId')\nloc = pd.Series(preded,name = 'Location')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.concat([rowid,loc],axis = 1)\nsubmission.to_csv('submission.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}