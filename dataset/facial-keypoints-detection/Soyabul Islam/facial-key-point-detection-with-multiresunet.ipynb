{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport cv2\nimport os\nimport seaborn as sns\nimport sklearn\nimport zipfile\nimport random\nimport math\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport keras\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom keras.utils.data_utils import Sequence\nimport albumentations","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-16T06:29:10.14339Z","iopub.execute_input":"2021-07-16T06:29:10.143739Z","iopub.status.idle":"2021-07-16T06:29:10.150815Z","shell.execute_reply.started":"2021-07-16T06:29:10.143707Z","shell.execute_reply":"2021-07-16T06:29:10.149865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keypoint_data = pd.read_csv('../input/facial-keypoints-detection/IdLookupTable.csv')\nkeypoint_data.head(10).T","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:10.520866Z","iopub.execute_input":"2021-07-16T06:29:10.521256Z","iopub.status.idle":"2021-07-16T06:29:10.558767Z","shell.execute_reply.started":"2021-07-16T06:29:10.521214Z","shell.execute_reply":"2021-07-16T06:29:10.557889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Unzip File**","metadata":{}},{"cell_type":"code","source":"destination = '../kaggle/working/'\n\ntrain_archive = zipfile.ZipFile('../input/facial-keypoints-detection/training.zip')\ntest_archive = zipfile.ZipFile('../input/facial-keypoints-detection/test.zip')\n\n\n\ndef extraction(archive, destination):\n    for file in archive.namelist():\n        archive.extract(file, destination)\n        \n        \nextraction(train_archive, destination)\nextraction(test_archive, destination)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:10.911325Z","iopub.execute_input":"2021-07-16T06:29:10.911658Z","iopub.status.idle":"2021-07-16T06:29:13.527121Z","shell.execute_reply.started":"2021-07-16T06:29:10.911627Z","shell.execute_reply":"2021-07-16T06:29:13.526098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Or use !unzip**","metadata":{}},{"cell_type":"code","source":"!unzip -n ../input/facial-keypoints-detection/test.zip\n!unzip -n ../input/facial-keypoints-detection/training.zip","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:13.528706Z","iopub.execute_input":"2021-07-16T06:29:13.529077Z","iopub.status.idle":"2021-07-16T06:29:15.0663Z","shell.execute_reply.started":"2021-07-16T06:29:13.529037Z","shell.execute_reply":"2021-07-16T06:29:15.065022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = './training.csv'\nTEST_DIR = './test.csv'\nLOOKID_DIR = '../input/facial-keypoints-detection/IdLookupTable.csv'\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:15.070811Z","iopub.execute_input":"2021-07-16T06:29:15.071149Z","iopub.status.idle":"2021-07-16T06:29:15.078891Z","shell.execute_reply.started":"2021-07-16T06:29:15.071102Z","shell.execute_reply":"2021-07-16T06:29:15.077849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(TRAIN_DIR)\ntest_data = pd.read_csv(TEST_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:15.082846Z","iopub.execute_input":"2021-07-16T06:29:15.083262Z","iopub.status.idle":"2021-07-16T06:29:18.097357Z","shell.execute_reply.started":"2021-07-16T06:29:15.083221Z","shell.execute_reply":"2021-07-16T06:29:18.096371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Lets look at the train data**","metadata":{}},{"cell_type":"code","source":"train_data.head(10).T","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:18.098694Z","iopub.execute_input":"2021-07-16T06:29:18.09903Z","iopub.status.idle":"2021-07-16T06:29:18.12957Z","shell.execute_reply.started":"2021-07-16T06:29:18.098994Z","shell.execute_reply":"2021-07-16T06:29:18.128599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:18.131025Z","iopub.execute_input":"2021-07-16T06:29:18.131631Z","iopub.status.idle":"2021-07-16T06:29:18.152842Z","shell.execute_reply.started":"2021-07-16T06:29:18.13159Z","shell.execute_reply":"2021-07-16T06:29:18.151764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:18.1544Z","iopub.execute_input":"2021-07-16T06:29:18.154865Z","iopub.status.idle":"2021-07-16T06:29:18.166542Z","shell.execute_reply.started":"2021-07-16T06:29:18.154793Z","shell.execute_reply":"2021-07-16T06:29:18.165463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Lets see the test data**","metadata":{}},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:18.169603Z","iopub.execute_input":"2021-07-16T06:29:18.17014Z","iopub.status.idle":"2021-07-16T06:29:18.179945Z","shell.execute_reply.started":"2021-07-16T06:29:18.170093Z","shell.execute_reply":"2021-07-16T06:29:18.178685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **LOOK ID Directory**","metadata":{}},{"cell_type":"code","source":"lookup_data = pd.read_csv(LOOKID_DIR)\nlookup_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:18.182577Z","iopub.execute_input":"2021-07-16T06:29:18.183169Z","iopub.status.idle":"2021-07-16T06:29:18.209875Z","shell.execute_reply.started":"2021-07-16T06:29:18.183101Z","shell.execute_reply":"2021-07-16T06:29:18.208874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pairplot","metadata":{}},{"cell_type":"code","source":"sns.pairplot(train_data)\nplt.savefig('pairplot.png', dpi=300)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:29:18.211472Z","iopub.execute_input":"2021-07-16T06:29:18.21204Z","iopub.status.idle":"2021-07-16T06:35:44.646859Z","shell.execute_reply.started":"2021-07-16T06:29:18.211997Z","shell.execute_reply":"2021-07-16T06:35:44.645502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Histogram Plot","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(6, 5, figsize=(15, 10))\nax = ax.ravel() \nfor i in range(30):\n    ax[i].hist(train_data[train_data.columns[i]], bins=50, density=True, alpha=0.7, color='red')\n    ax[i].set_title(train_data.columns[i],fontsize=10)\n  # ax[i].axes.get_xaxis().set_visible(False)\nplt.tight_layout()  \nplt.savefig('hist_plot.png', dpi=200)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:35:44.648676Z","iopub.execute_input":"2021-07-16T06:35:44.64919Z","iopub.status.idle":"2021-07-16T06:35:54.982897Z","shell.execute_reply.started":"2021-07-16T06:35:44.649148Z","shell.execute_reply":"2021-07-16T06:35:54.982082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Handling Null Values with feature median values**","metadata":{}},{"cell_type":"code","source":"train_data.fillna(train_data.describe().T['50%'], inplace= True)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:35:54.984181Z","iopub.execute_input":"2021-07-16T06:35:54.98468Z","iopub.status.idle":"2021-07-16T06:35:55.080822Z","shell.execute_reply.started":"2021-07-16T06:35:54.984636Z","shell.execute_reply":"2021-07-16T06:35:55.079718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:35:55.082477Z","iopub.execute_input":"2021-07-16T06:35:55.082972Z","iopub.status.idle":"2021-07-16T06:35:55.093741Z","shell.execute_reply.started":"2021-07-16T06:35:55.082896Z","shell.execute_reply":"2021-07-16T06:35:55.092705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"def load_images(image):\n    images=[]\n    for idx, sample in image.iterrows():\n        img = np.array(sample['Image'].split(' '), dtype=np.float32)\n        img = np.reshape(img, (96, 96,1))\n        images.append(img)\n        \n    images = np.array(images)/255.0\n    return images\n\n\ndef format_dataset(data):\n    keypoints=[]\n    features = data.drop('Image', axis=1)\n    for idx, sample in features.iterrows():\n        keypoints.append(sample)\n    keypoints = np.array(keypoints, dtype='float')\n    return keypoints\n\n\n\ndef sample(image, keypoint, axis=None, color='red'):\n    if axis is None:\n        fig, axis = plt.subplots()\n        \n    axis.scatter(keypoint[0::2], keypoint[1::2], s=8, c=color, marker='*')\n    axis.imshow(image.squeeze(), cmap='gray')\n    \n    \n        \n\ndef sample_images(image_data,keypoints, n_rows=6, n_cols=4):\n    fig= plt.figure(figsize=(2*n_cols, 2*n_cols), dpi=200)\n    \n    for i, idx in enumerate(np.random.randint(0, len(keypoints), n_rows*n_cols)):\n        ax = fig.add_subplot(n_rows, n_cols, i+1, xticks=[], yticks=[])\n        sample(image_data[idx], keypoints[idx], axis=ax)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:35:55.095221Z","iopub.execute_input":"2021-07-16T06:35:55.095632Z","iopub.status.idle":"2021-07-16T06:35:55.107817Z","shell.execute_reply.started":"2021-07-16T06:35:55.095592Z","shell.execute_reply":"2021-07-16T06:35:55.106653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = load_images(train_data)\nkeypoints=  format_dataset(train_data)\nprint(images.shape)\nprint(keypoints.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:35:55.109035Z","iopub.execute_input":"2021-07-16T06:35:55.109537Z","iopub.status.idle":"2021-07-16T06:36:17.648808Z","shell.execute_reply.started":"2021-07-16T06:35:55.109502Z","shell.execute_reply":"2021-07-16T06:36:17.647912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = load_images(test_data)\ntest_images.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:36:17.650381Z","iopub.execute_input":"2021-07-16T06:36:17.650775Z","iopub.status.idle":"2021-07-16T06:36:22.649922Z","shell.execute_reply.started":"2021-07-16T06:36:17.65073Z","shell.execute_reply":"2021-07-16T06:36:22.649148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ***Show Sample Images***","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsample_images(images, keypoints)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:36:22.651247Z","iopub.execute_input":"2021-07-16T06:36:22.651612Z","iopub.status.idle":"2021-07-16T06:36:24.844131Z","shell.execute_reply.started":"2021-07-16T06:36:22.651572Z","shell.execute_reply":"2021-07-16T06:36:24.843065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Different data augmentation","metadata":{}},{"cell_type":"markdown","source":"Inspired from this beautiful [Notebook](http://www.kaggle.com/balraj98/data-augmentation-for-facial-keypoint-detection) by Balraj Ashwath","metadata":{}},{"cell_type":"markdown","source":"### Rotation","metadata":{}},{"cell_type":"code","source":"# Random angles\nangles =[] \nfor i in range(3):\n    n= random.randint(10,20)\n    angles.append(n)\n    \n    \ndef rotation(images, keypoints):\n    rotated_images=[]\n    rotated_keypoints=[]\n    for i in angles:\n        for angle in [i, -i]:\n            rotate = cv2.getRotationMatrix2D((48, 48), angle, 1.0)\n            radius = - angle*math.pi/180\n            \n            for image in images:\n                image_rotation=  cv2.warpAffine(image, rotate, (96, 96), flags = cv2.INTER_CUBIC)\n                #image_rotation=  np.reshape(image_rotation, ( 96, 96,1))\n                rotated_images.append(np.reshape(image_rotation, (96, 96,1)))\n                \n                \n            for keypoint in keypoints:\n                keypoint = keypoint - 48\n                \n                for idx in range(0, len(keypoint), 2):\n                    keypoint[idx]= keypoint[idx]*math.cos(radius)- keypoint[idx+1]*math.sin(radius)\n                    \n                    keypoint[idx+1]= keypoint[idx]*math.sin(radius)+ keypoint[idx+1]*math.cos(radius)\n                    \n                    \n                keypoint =keypoint + 48\n                    \n                rotated_keypoints.append(keypoint)\n                    \n                    \n    rotated_images = np.array(rotated_images)/255.0 \n    rotated_keypoints = np.array(rotated_keypoints, dtype='float')\n    return rotated_images, rotated_keypoints\n                    \n        \n                    \nrotated_images, rotated_keypoints = rotation(images, keypoints)\n\nsample_images(rotated_images, rotated_keypoints)\nprint(rotated_images.shape) \nprint(rotated_keypoints.shape)\n            ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:36:24.845523Z","iopub.execute_input":"2021-07-16T06:36:24.845855Z","iopub.status.idle":"2021-07-16T06:36:37.315742Z","shell.execute_reply.started":"2021-07-16T06:36:24.84582Z","shell.execute_reply":"2021-07-16T06:36:37.314985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class data_process(Sequence):\n    def __init__(self, image, keypoint, batch_size, augmentation):\n        self.image = image\n        self.keypoint = keypoint\n        self.batch_size = batch_size\n        self.augmentation = augmentation\n        self.shuffle= True\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.ceil(len(self.image)/ float(self.batch_size)))\n    \n    \n    def __getitem__(self, idx):\n        indexes = self.indexes[idx*self.batch_size: (idx+1)*self.batch_size]\n        \n        batch_image = self.image[indexes, ...]\n        batch_key = self.keypoint[indexes,:]\n        \n        if self.augmentation is not None:\n            keypoints = np.array([tuple(zip(key[::2], key[1::2])) for key in batch_key])\n            \n            transformed_image = [self.augmentation(image=image, keypoints=keypoint) for image, keypoint in zip(batch_image, keypoints)]\n            \n            batch_image = np.stack([z['image'] for z in transformed_image], axis=0)\n            \n            batch_key = np.stack([np.array(z['keypoints']).flatten(order='C') for z in transformed_image], axis=0)\n            \n        return batch_image, batch_key\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.image))\n        if self.shuffle ==True:\n            np.random.shuffle(self.indexes)\n            \n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:36:37.317005Z","iopub.execute_input":"2021-07-16T06:36:37.317512Z","iopub.status.idle":"2021-07-16T06:36:37.330168Z","shell.execute_reply.started":"2021-07-16T06:36:37.317476Z","shell.execute_reply":"2021-07-16T06:36:37.329362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain, xval,ytrain, yval = train_test_split(images, keypoints, test_size =0.18, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:36:37.331484Z","iopub.execute_input":"2021-07-16T06:36:37.332071Z","iopub.status.idle":"2021-07-16T06:36:37.398922Z","shell.execute_reply.started":"2021-07-16T06:36:37.332032Z","shell.execute_reply":"2021-07-16T06:36:37.398103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MultiResUnet architecture","metadata":{}},{"cell_type":"code","source":"def conv2d_block(input_tensor, filters, kernel_size, activation=\"relu\"):\n    \n    \n    x = keras.layers.Conv2D(filters, kernel_size=(kernel_size, kernel_size), \n                            padding='same', use_bias=False, strides=(1,1))(input_tensor)\n    x = keras.layers.BatchNormalization(axis=3, scale=False)(x)\n    if (activation==None):\n        return x\n        \n    x = keras.layers.Activation(activation='relu')(x)\n\n    return x\n\n\ndef MultiResBlock(filters, input_layers, alpha = 1.67):\n\n\n    W = alpha * filters\n    shortcut= input_layers\n    shortcut = conv2d_block(shortcut, int(W*0.167) + int(W*0.333) +\n                         int(W*0.5), 1,  activation=None)\n\n    conv3x3 = conv2d_block(input_layers, int(W*0.167), 3, activation=\"relu\" )\n\n    conv5x5 = conv2d_block(conv3x3, int(W*0.333), 3, activation=\"relu\")\n\n    conv7x7 = conv2d_block(conv5x5, int(W*0.5), 3, activation=\"relu\")\n\n    out = keras.layers.concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n    out = keras.layers.BatchNormalization(axis=3)(out)\n\n    out = keras.layers.add([shortcut, out])\n    out = keras.layers.Activation('relu')(out)\n    out = keras.layers.BatchNormalization(axis=3)(out)\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:36:37.400315Z","iopub.execute_input":"2021-07-16T06:36:37.400663Z","iopub.status.idle":"2021-07-16T06:36:37.411052Z","shell.execute_reply.started":"2021-07-16T06:36:37.400625Z","shell.execute_reply":"2021-07-16T06:36:37.410052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ResPath(filters, length, input_layers):\n\n\n    shortcut= input_layers\n    shortcut = conv2d_block(shortcut, filters, 1,activation=None)\n\n    out = conv2d_block(input_layers, filters, 3, activation=\"relu\")\n\n    out = keras.layers.add([shortcut, out])\n    out = keras.layers.Activation('relu')(out)\n    out = keras.layers.BatchNormalization(axis=3)(out)\n\n    for i in range(length-1):\n\n        shortcut = out\n        shortcut = conv2d_block(shortcut, filters, 1, activation=None)\n\n        out = conv2d_block(out, filters, 3, activation=\"relu\")\n\n        out = keras.layers.add([shortcut, out])\n        out = keras.layers.Activation('relu')(out)\n        out = keras.layers.BatchNormalization(axis=3)(out)\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:36:37.412338Z","iopub.execute_input":"2021-07-16T06:36:37.412845Z","iopub.status.idle":"2021-07-16T06:36:37.424292Z","shell.execute_reply.started":"2021-07-16T06:36:37.412809Z","shell.execute_reply":"2021-07-16T06:36:37.42341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv2d_block_T(input_tensor, filters, kernel_size):\n    x = keras.layers.Conv2DTranspose(filters, kernel_size=(kernel_size, kernel_size), strides=(2, 2), padding=\"same\")(input_tensor)\n    x = keras.layers.BatchNormalization(axis=3, scale=False)(x)\n    \n    return x\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:36:37.428162Z","iopub.execute_input":"2021-07-16T06:36:37.428444Z","iopub.status.idle":"2021-07-16T06:36:37.434873Z","shell.execute_reply.started":"2021-07-16T06:36:37.428416Z","shell.execute_reply":"2021-07-16T06:36:37.434007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\ndef MultiResUnet(input_shape):\n\n\n\n    inputs = keras.Input(input_shape)\n\n    mresblock1 = MultiResBlock(32, inputs)\n    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(mresblock1)\n    mresblock1 = ResPath(32, 4, mresblock1)\n\n    mresblock2 = MultiResBlock(32*2, pool1)\n    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(mresblock2)\n    mresblock2 = ResPath(32*2, 3, mresblock2)\n\n    mresblock3 = MultiResBlock(32*4, pool2)\n    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(mresblock3)\n    mresblock3 = ResPath(32*4, 2, mresblock3)\n\n    mresblock4 = MultiResBlock(32*8, pool3)\n    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(mresblock4)\n    mresblock4 = ResPath(32*8, 1, mresblock4)\n\n    mresblock5 = MultiResBlock(32*16, pool4)\n\n    up6 = keras.layers.concatenate([conv2d_block_T(mresblock5, 32*8, 2), mresblock4], axis=3)\n    mresblock6 = MultiResBlock(32*8, up6)\n\n    up7 = keras.layers.concatenate([conv2d_block_T(mresblock6, 32*4, 2), mresblock3], axis=3)\n    mresblock7 = MultiResBlock(32*4, up7)\n\n    up8 = keras.layers.concatenate([conv2d_block_T(mresblock7, 32*2, 2), mresblock2], axis=3)\n    mresblock8 = MultiResBlock(32*2, up8)\n\n    up9 = keras.layers.concatenate([conv2d_block_T(mresblock8, 32, 2), mresblock1], axis=3)\n    mresblock9 = MultiResBlock(32, up9)\n\n    conv10 = keras.layers.Conv2D(1, kernel_size=(1,1), strides=(1,1), padding=\"same\")(mresblock9)\n    conv10 = keras.layers.BatchNormalization( scale=False)(conv10)\n    conv10= keras.layers.Activation(activation=\"sigmoid\")(conv10)\n    \n    out = keras.layers.Flatten()(conv10)\n    out= keras.layers.Dropout(0.1)(out)\n    out= keras.layers.Dense(30)(out)\n\n    model = keras.Model(inputs=[inputs], outputs=[out])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:58:35.110535Z","iopub.execute_input":"2021-07-16T06:58:35.110859Z","iopub.status.idle":"2021-07-16T06:58:35.12574Z","shell.execute_reply.started":"2021-07-16T06:58:35.110827Z","shell.execute_reply":"2021-07-16T06:58:35.124854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape=(96, 96,1)\nmodel =MultiResUnet(input_shape)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:58:36.10373Z","iopub.execute_input":"2021-07-16T06:58:36.104059Z","iopub.status.idle":"2021-07-16T06:58:41.688262Z","shell.execute_reply.started":"2021-07-16T06:58:36.104027Z","shell.execute_reply":"2021-07-16T06:58:41.687332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model, to_file=\"MutiResUnet.png\", dpi=200)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:58:41.690833Z","iopub.execute_input":"2021-07-16T06:58:41.691238Z","iopub.status.idle":"2021-07-16T06:58:51.081807Z","shell.execute_reply.started":"2021-07-16T06:58:41.691195Z","shell.execute_reply":"2021-07-16T06:58:51.080892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The MultiresUnet model was taken from the paper [MultiResUNet : Rethinking the U-Net Architecture for Multimodal Biomedical Image Segmentation](https://www.sciencedirect.com/science/article/abs/pii/S0893608019302503)","metadata":{}},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', patience=20)\ncheckpoint = ModelCheckpoint('model.h5', monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True)\n\n\nmodel.compile(optimizer= Adam(), loss='mean_squared_error',  metrics=['mae', 'acc', 'mse'])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:58:51.083903Z","iopub.execute_input":"2021-07-16T06:58:51.084383Z","iopub.status.idle":"2021-07-16T06:58:51.110441Z","shell.execute_reply.started":"2021-07-16T06:58:51.084345Z","shell.execute_reply":"2021-07-16T06:58:51.109482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"augment = albumentations.Compose([albumentations.ShiftScaleRotate(rotate_limit=20, p=0.5),\n                           albumentations.RandomBrightnessContrast(p=0.5),\n                           albumentations.GaussianBlur(p=0.3),\n                           albumentations.GaussNoise(var_limit=(1e-5, 1e-3), p=0.5)],\n                          keypoint_params=albumentations.KeypointParams(format='xy', remove_invisible=False))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T05:29:24.227181Z","iopub.execute_input":"2021-07-16T05:29:24.227725Z","iopub.status.idle":"2021-07-16T05:29:24.23531Z","shell.execute_reply.started":"2021-07-16T05:29:24.227676Z","shell.execute_reply":"2021-07-16T05:29:24.233937Z"}}},{"cell_type":"code","source":"train=  data_process(xtrain, ytrain, batch_size=128, augmentation=None)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:58:51.112554Z","iopub.execute_input":"2021-07-16T06:58:51.113142Z","iopub.status.idle":"2021-07-16T06:58:51.118668Z","shell.execute_reply.started":"2021-07-16T06:58:51.11308Z","shell.execute_reply":"2021-07-16T06:58:51.11733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history= model.fit(train,   steps_per_epoch=len(train),\n                   validation_data=(xval, yval), batch_size=128,\n                   epochs=45, verbose=1, callbacks=[early_stop, checkpoint])","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:58:51.119882Z","iopub.execute_input":"2021-07-16T06:58:51.120423Z","iopub.status.idle":"2021-07-16T07:17:26.132979Z","shell.execute_reply.started":"2021-07-16T06:58:51.120387Z","shell.execute_reply":"2021-07-16T07:17:26.132191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history[\"val_{}\".format(metric)])\n    plt.title('{} vs Epoch'.format(metric))\n    plt.ylabel(metric)\n    plt.xlabel('Epochs')\n    plt.legend(['train', 'validation'], loc='upper right')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:17:26.135709Z","iopub.execute_input":"2021-07-16T07:17:26.135996Z","iopub.status.idle":"2021-07-16T07:17:26.141209Z","shell.execute_reply.started":"2021-07-16T07:17:26.135953Z","shell.execute_reply":"2021-07-16T07:17:26.140382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(\"acc\")\nplot_history(\"loss\")\nplot_history(\"mae\")\nplot_history(\"mse\")","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:17:26.142594Z","iopub.execute_input":"2021-07-16T07:17:26.143194Z","iopub.status.idle":"2021-07-16T07:17:27.171528Z","shell.execute_reply.started":"2021-07-16T07:17:26.143156Z","shell.execute_reply":"2021-07-16T07:17:27.170722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./model.h5')\n\nprediction= model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:17:27.173633Z","iopub.execute_input":"2021-07-16T07:17:27.173989Z","iopub.status.idle":"2021-07-16T07:17:31.161156Z","shell.execute_reply.started":"2021-07-16T07:17:27.173954Z","shell.execute_reply":"2021-07-16T07:17:31.160286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_images(test_images, prediction)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:17:31.162803Z","iopub.execute_input":"2021-07-16T07:17:31.163154Z","iopub.status.idle":"2021-07-16T07:17:32.494103Z","shell.execute_reply.started":"2021-07-16T07:17:31.163105Z","shell.execute_reply":"2021-07-16T07:17:32.493165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"print(\"Accuracy: {}\".format(np.mean(history.history['acc'])))\nprint(\"Loss: {}\".format(np.mean(history.history['loss'])))\nprint(\"Mean Absolute error: {}\".format(np.mean(history.history['mae'])))\nprint(\"Mean Squared Error: {}\".format(np.mean(history.history['mse'])))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T07:32:37.640874Z","iopub.execute_input":"2021-07-16T07:32:37.641313Z","iopub.status.idle":"2021-07-16T07:32:37.655791Z","shell.execute_reply.started":"2021-07-16T07:32:37.641273Z","shell.execute_reply":"2021-07-16T07:32:37.654608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy: 0.832591313123703\n## Loss: 8.787642423311869\n## Mean Absolute error: 0.9814965281221602\n## Mean Squared Error: 8.787642423311869","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}