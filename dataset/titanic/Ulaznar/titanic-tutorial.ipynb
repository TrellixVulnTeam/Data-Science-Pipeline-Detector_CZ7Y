{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview of the data","metadata":{}},{"cell_type":"code","source":"#import numpy as np\nimport pandas as pd\nimport seaborn as sns #graphs to be added, maybe along some machine learning explainability?\n\n# Load the data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\", index_col='PassengerId')\ntest_data  = pd.read_csv(\"/kaggle/input/titanic/test.csv\", index_col='PassengerId')\n\n# Print shape of datasets\nprint('Train Data Shape:', train_data.shape)\nprint('\\nTest Data Shape:', test_data.shape)\n\n# Print missing values of datasets\nprint('\\nMissing Values on Train Data:')\nfor col in train_data.columns:\n    missing_train= train_data[col].isnull().sum()\n    if missing_train>0:\n        print(col, missing_train, \"{0:.2%}\".format(missing_train/train_data.shape[0]))\n\nprint('\\nMissing Values on Test Data:')\nfor col in test_data.columns:\n    missing_test= test_data[col].isnull().sum()\n    if missing_test>0:\n        print(col, missing_test, \"{0:.2%}\".format(missing_test/test_data.shape[0]))\n        \n\n# Separate features acording to data type\ncon = [col for col in train_data.columns if train_data[col].dtypes == \"float\"]\ndis = [col for col in train_data.columns if train_data[col].dtypes == \"int\"]\ncat = [col for col in train_data.columns if train_data[col].dtypes == \"object\"]\n\nprint('\\nContinuous features:\\n', con)\nprint('\\nDiscrete features:\\n', dis)\nprint('\\nCategorical features:\\n', cat)\n\n# See which features are easy to encode and which aren't\nprint('\\nUnique categorical values in Train Data:')\nfor col in cat:\n    print(col,train_data[col].nunique())\n    \nprint('\\nUnique categorical values in Test Data:')\nfor col in [col for col in test_data.columns if test_data[col].dtypes == \"object\"]:\n    print(col,test_data[col].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-06-24T22:48:38.363828Z","iopub.execute_input":"2022-06-24T22:48:38.364147Z","iopub.status.idle":"2022-06-24T22:48:38.425739Z","shell.execute_reply.started":"2022-06-24T22:48:38.364113Z","shell.execute_reply":"2022-06-24T22:48:38.425093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plannification\n\nContinuous features:\n* Age  = **Impute median, add indicator** (missing values = ~20% of both training and test data)\n* Fare = **Impute median** (missing values = 1 on test data)\n\nDiscrete features:\n* Pclass = Ready\n* SibSp = Ready\n* Parch = Ready\n\nCategorical features:\n* Sex = **Ordinal Encode**\n* Embarked = **Ordinal Encode** (missing values = 2 on training data)\n* Name = **Drop** or Feature Engineer (all unique values)\n* Ticket = **Drop** or Feature Engineer (681 unique values on training data)\n* Cabin = **Drop** or Feature Engineer (147 unique values on training data) (missing values = 70%+ of both training and test data)","metadata":{}},{"cell_type":"markdown","source":"# Researching Titanic decks (for Feature Engineering Cabin)\n\nOrder of Decks from top to bottom (reverse for flooding order)\n* 1st = T\n* 2nd = A\n* 3rd = B\n* 4th = C\n* 5th = D\n* 6th = E\n* 7th = F\n* 8th = G (Most of it off limits to passengers)\n* 9th = Orlop (Completely off limits to passengers)\n* 10th = Tank Top","metadata":{}},{"cell_type":"code","source":"#Until I find a way to do Impute and Encode it through a more \"refined\" code...\n\ntrain_data.Cabin.fillna(\"NA\", inplace=True)\n\ndecks=[]\nfor cabin in train_data.Cabin:\n    decks.append(str(cabin)[0])\n    \ntrain_data['Deck'] = pd.Series(decks, index=train_data.index)\ntrain_data.Deck.replace(['N','T','A','B','C','D','E','F','G'], range(0,9), inplace=True)\n\ntrain_data['cabin']=1\ntrain_data.loc[train_data.Cabin==0,'cabin']=0\n\ntest_data.Cabin.fillna(\"NA\", inplace=True)\ndecks=[]\nfor cabin in test_data.Cabin:\n    decks.append(str(cabin)[0])\n    \ntest_data['Deck'] = pd.Series(decks, index=test_data.index)\ntest_data.Deck.replace(['N','T','A','B','C','D','E','F','G'], range(0,9), inplace=True)\n\ntest_data['cabin']=1\ntest_data.loc[test_data.Cabin==0,'cabin']=0","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-24T22:48:38.733811Z","iopub.execute_input":"2022-06-24T22:48:38.734128Z","iopub.status.idle":"2022-06-24T22:48:38.755727Z","shell.execute_reply.started":"2022-06-24T22:48:38.734086Z","shell.execute_reply":"2022-06-24T22:48:38.754747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing and model training","metadata":{}},{"cell_type":"code","source":"to_drop = [\"Name\",\"Ticket\",\"Cabin\"]\n\ny_train = train_data.Survived\nX_train = train_data.drop(to_drop, axis = 1).drop(\"Survived\", axis = 1)\nX_test  =  test_data.drop(to_drop, axis = 1)\n\nfrom sklearn.pipeline      import Pipeline\nfrom sklearn.impute        import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose       import ColumnTransformer\nfrom sklearn.ensemble      import RandomForestClassifier\n\nageSI  = SimpleImputer(strategy = \"median\", add_indicator=True)\nfareSI = SimpleImputer(strategy = \"median\")\n\nsexembOHE = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy = \"most_frequent\")),\\\n                           (\"ohenc\", OneHotEncoder(handle_unknown='ignore', sparse=False))])\n                                  \npreprocessor = ColumnTransformer(transformers=[('age',ageSI, ['Age']),\\\n                                               ('fare',fareSI, ['Fare']),\\\n                                               ('sex_emb', sexembOHE, ['Sex','Embarked'])])\n\nmodel = RandomForestClassifier( n_estimators=100,    #default=100\n                                max_depth=6,         #default=None\n                                min_samples_split=8, #default=2,\n                                min_samples_leaf=1,  #default=1,\n                                bootstrap=True,      #default=True\n                                ccp_alpha=0.0,       #default=0.0\n                                random_state=None)\n#finding optimal hyper parameters pending...\n\nclassifier = Pipeline(steps=[(\"preprocessor\",preprocessor),(\"model\",model)])\n\nclassifier.fit(X_train, y_train)\n\npredictions = classifier.predict(X_test)\n\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(classifier, X_train, y_train)\nprint(\"Average CV score:\", scores.mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-24T22:48:51.569688Z","iopub.execute_input":"2022-06-24T22:48:51.57033Z","iopub.status.idle":"2022-06-24T22:48:52.884321Z","shell.execute_reply.started":"2022-06-24T22:48:51.57029Z","shell.execute_reply":"2022-06-24T22:48:52.88338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"+ n_estimators=87: 0.7789215993974012\n+ **n_estimators=88: 0.7800451949030192** 0.7710815391375305\n+ **n_estimators=89: 0.7800451949030192** 0.7688280710564308\n+ n_estimators=90: 0.778927876467265\n\n+ max depth=5: 0.7934718473416609\n+ **max depth=6: 0.7957378695624883** 0.7957253154227607\n+ max depth=7:   0.7901198920343984\n\n+ min_samples_split=15 0.7867679367271359\n+ **min_samples_split=16: 0.7957441466323519** 0.7946142740568704\n+ min_samples_split=17: 0.7811499591990458\n\n+ min_samples_leaf=2: 0.7867679367271357\n+ **min_samples_leaf=3: 0.7901198920343984** 0.7923608059757704\n+ min_samples_leaf=4: 0.7856443412215177\n\n+ **bootstrap=True: 0.7778105580315108**\n+ bootstrap=False: 0.7575983930701149","metadata":{"_kg_hide-input":true,"_kg_hide-output":true}},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test_data.index, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T22:48:40.671443Z","iopub.execute_input":"2022-06-24T22:48:40.671842Z","iopub.status.idle":"2022-06-24T22:48:40.680358Z","shell.execute_reply.started":"2022-06-24T22:48:40.671797Z","shell.execute_reply":"2022-06-24T22:48:40.679557Z"},"trusted":true},"execution_count":null,"outputs":[]}]}