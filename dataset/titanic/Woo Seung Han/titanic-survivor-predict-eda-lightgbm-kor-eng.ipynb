{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### 처음으로 kaggle에 참여하여 코드를 올립니다. \n#### 대회 Rule과 Scoring기준에 따라 타이타닉 생존자 예측의 Accuracy를 가장 높게 산출하는 모델을 만들 예정입니다.    \n#### This is my first time participating in kaggle. \n#### In this code, I tried to make a model with high accuracy to predict the Titanic survivor.","metadata":{}},{"cell_type":"markdown","source":"## 1. 모듈 불러오기 (Import module)\n \n#### 제가 가장 자주 쓰는 모듈들을 불러올 예정입니다.\n#### It will load all the modules I use the most.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-20T07:01:39.764017Z","iopub.execute_input":"2021-10-20T07:01:39.76465Z","iopub.status.idle":"2021-10-20T07:01:41.832408Z","shell.execute_reply.started":"2021-10-20T07:01:39.764539Z","shell.execute_reply":"2021-10-20T07:01:41.831507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. 데이터 불러오기(Read Dataset)","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')\ngender_submission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:41.833896Z","iopub.execute_input":"2021-10-20T07:01:41.834146Z","iopub.status.idle":"2021-10-20T07:01:41.867677Z","shell.execute_reply.started":"2021-10-20T07:01:41.83411Z","shell.execute_reply":"2021-10-20T07:01:41.866915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. 탐색적 데이터 분석 (EDA)\n#### 향후 단계별로 Competition 참여를 하면서 def 함수로 묶어서 자동으로 할 수 있도록 만들 예정입니다.\n#### 우선 해당 데이터의 Column들이 어떤 것이 있고, 통계적으로 어떠한 결과가 있는지 확인할 겁니다.\n\n#### In the future, while participating in the competition step by step, \n#### I plan to bind it with the def function so that it can be done automatically.\n#### First, I will check what the columns of the data are and what the statistical results are.","metadata":{}},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:41.868691Z","iopub.execute_input":"2021-10-20T07:01:41.868903Z","iopub.status.idle":"2021-10-20T07:01:41.890512Z","shell.execute_reply.started":"2021-10-20T07:01:41.868878Z","shell.execute_reply":"2021-10-20T07:01:41.889711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:41.892347Z","iopub.execute_input":"2021-10-20T07:01:41.892739Z","iopub.status.idle":"2021-10-20T07:01:41.911346Z","shell.execute_reply.started":"2021-10-20T07:01:41.892706Z","shell.execute_reply":"2021-10-20T07:01:41.910712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender_submission.head(5)\n# head()를 활용하여 볼때 PassengerId를 통해서 test data의 결과를 예측할 수 있음을 예상할 수 있습니다.\n# When using head(), it can be expected that the result of test data can be predicted through PassengerId.","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:41.912328Z","iopub.execute_input":"2021-10-20T07:01:41.912965Z","iopub.status.idle":"2021-10-20T07:01:41.920771Z","shell.execute_reply.started":"2021-10-20T07:01:41.91293Z","shell.execute_reply":"2021-10-20T07:01:41.920179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'Survived' column을 잘 붙였는지 확인 합니다.\n# Check if the 'Survived' column is attached properly.\ndf_test['Survived'] = gender_submission['Survived']\ndf_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:41.921901Z","iopub.execute_input":"2021-10-20T07:01:41.922548Z","iopub.status.idle":"2021-10-20T07:01:41.946024Z","shell.execute_reply.started":"2021-10-20T07:01:41.922481Z","shell.execute_reply":"2021-10-20T07:01:41.945421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#통계적으로 분포가 어떠한지 Pair Plot 및 여러 그래프를 통하여 분석해 보겠습니다.\n# Let's analyze how the distribution is statistically through pair plots and several graphs.\n\nsns.pairplot(data = df_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:41.947408Z","iopub.execute_input":"2021-10-20T07:01:41.947826Z","iopub.status.idle":"2021-10-20T07:01:52.811882Z","shell.execute_reply.started":"2021-10-20T07:01:41.947793Z","shell.execute_reply":"2021-10-20T07:01:52.811267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def analysis(data):\n    print(\"1. 첫번째 그래프는 Data의 Heatmap 분석 결과입니다.상관관계가 높을수록 색깔이 진하도록 표시하였습니다.\")\n    print(\"2. 두번째 그래프는 null ratio를 그래프로 표시하였습니다.\")\n    sns.heatmap(data.corr(), annot=True, cmap='Reds')\n    null_percent = 100*(data.isnull().sum()/len(data))\n    null_percent = null_percent[null_percent>0].sort_values()\n    plt.figure(figsize= (10,4))\n    sns.barplot(x=null_percent.index, y= null_percent)\n    plt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:52.812906Z","iopub.execute_input":"2021-10-20T07:01:52.813539Z","iopub.status.idle":"2021-10-20T07:01:52.820112Z","shell.execute_reply.started":"2021-10-20T07:01:52.813502Z","shell.execute_reply":"2021-10-20T07:01:52.819363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"analysis(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:52.821287Z","iopub.execute_input":"2021-10-20T07:01:52.822009Z","iopub.status.idle":"2021-10-20T07:01:53.534997Z","shell.execute_reply.started":"2021-10-20T07:01:52.821975Z","shell.execute_reply":"2021-10-20T07:01:53.534253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"analysis(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:53.536116Z","iopub.execute_input":"2021-10-20T07:01:53.53637Z","iopub.status.idle":"2021-10-20T07:01:54.234998Z","shell.execute_reply.started":"2021-10-20T07:01:53.536339Z","shell.execute_reply":"2021-10-20T07:01:54.234133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fat=ols(formula='Survived~PassengerId+Pclass+Age+Sex+SibSp+Parch+Fare+Embarked', data=df_train).fit()\nprint(fat.summary())\n\n# 통계적으로는 성별에 따른 구분과 Pclass에 따라 생존률이 영향도가 가장 높은 것으로 나왔고, \n# OLS Regression으로 예측시 상기의 8개 변수만으로 본다면, R-squre 0.4/ Adjust R-square 0.39수준의 예측이 가능 할 것으로 예상 되었습니다.\n\n# Statistically, it was found that the survival rate was the most influential according to the classification according to gender and Pclass.\n# When predicting with OLS regression, if we consider only the above 8 variables, it was expected that the R-squre 0.4/ Adjust R-square 0.39 level could be predicted.","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.238929Z","iopub.execute_input":"2021-10-20T07:01:54.239183Z","iopub.status.idle":"2021-10-20T07:01:54.28859Z","shell.execute_reply.started":"2021-10-20T07:01:54.239154Z","shell.execute_reply":"2021-10-20T07:01:54.287808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 숫자 타입의 데이터 추출\n# Numeric Feature Enginearing\n\nnum_cols = [col for col in df_train.columns if df_train[col].dtype in ['int64','float64']]\ndf_train[num_cols].describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.289738Z","iopub.execute_input":"2021-10-20T07:01:54.28998Z","iopub.status.idle":"2021-10-20T07:01:54.324325Z","shell.execute_reply.started":"2021-10-20T07:01:54.289951Z","shell.execute_reply":"2021-10-20T07:01:54.32372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.corr(method='pearson')","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.325527Z","iopub.execute_input":"2021-10-20T07:01:54.325741Z","iopub.status.idle":"2021-10-20T07:01:54.341265Z","shell.execute_reply.started":"2021-10-20T07:01:54.325705Z","shell.execute_reply":"2021-10-20T07:01:54.340351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.342408Z","iopub.execute_input":"2021-10-20T07:01:54.342635Z","iopub.status.idle":"2021-10-20T07:01:54.357715Z","shell.execute_reply.started":"2021-10-20T07:01:54.342609Z","shell.execute_reply":"2021-10-20T07:01:54.35709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터내 중복 값은 없는지 확인해 보겠습니다. \n# Let's check that there are no duplicate values in the data.\n\ndf_train=df_train.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.358809Z","iopub.execute_input":"2021-10-20T07:01:54.359514Z","iopub.status.idle":"2021-10-20T07:01:54.370127Z","shell.execute_reply.started":"2021-10-20T07:01:54.359464Z","shell.execute_reply":"2021-10-20T07:01:54.369426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.371501Z","iopub.execute_input":"2021-10-20T07:01:54.37219Z","iopub.status.idle":"2021-10-20T07:01:54.387268Z","shell.execute_reply.started":"2021-10-20T07:01:54.372144Z","shell.execute_reply":"2021-10-20T07:01:54.386339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 왜도와 첨도를 확인하는 경우 Regression Modeling할 경우 많이 보나, 금번의 경우는 단순히 우리가 알고 싶은 Y값(Survived)의 분포가 3:2라는 것\n# 정도 밖의 정보를 얻을수 없었습니다.\n\n# When checking skewness and kurtosis, it is often seen in Regression Modeling, but in this case, we could not simply obtain information other than that the distribution of Y-value (Survived) we wanted to know was 3:2.\nprint(f'skew: {df_train.Survived.skew()}')\nprint(f'kert: {df_train.Survived.kurt()}')\nsns.distplot(df_train.Survived, fit = norm)\nf = plt.figure()\nprobplot(df_train.Survived, plot = plt)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.388744Z","iopub.execute_input":"2021-10-20T07:01:54.389129Z","iopub.status.idle":"2021-10-20T07:01:54.734263Z","shell.execute_reply.started":"2021-10-20T07:01:54.389084Z","shell.execute_reply":"2021-10-20T07:01:54.733461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.735327Z","iopub.execute_input":"2021-10-20T07:01:54.735567Z","iopub.status.idle":"2021-10-20T07:01:54.741813Z","shell.execute_reply.started":"2021-10-20T07:01:54.735539Z","shell.execute_reply":"2021-10-20T07:01:54.741238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_cols = [col for col in df_train if df_train[col].dtype in ['int64','float64']]\nnumeric_cols.remove('Survived')\ny = 'Survived'\nover_column_name = list()\n\nfor i in numeric_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, y, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)\n\nprint('Column내 변수가 20개 이상의 Column은 하단과 같습니다.\\n변수 20개 미만의 Column과 Survived 숫자 분포는 그래프와 같습니다.')\nprint(over_column_name)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:54.742891Z","iopub.execute_input":"2021-10-20T07:01:54.74319Z","iopub.status.idle":"2021-10-20T07:01:55.607652Z","shell.execute_reply.started":"2021-10-20T07:01:54.743164Z","shell.execute_reply":"2021-10-20T07:01:55.607087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(num_cols)\nnum_cols.remove('PassengerId')\n\nfig, ax = plt.subplots(3, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(num_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(60)\n        \nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:01:55.608584Z","iopub.execute_input":"2021-10-20T07:01:55.609294Z","iopub.status.idle":"2021-10-20T07:02:03.070976Z","shell.execute_reply.started":"2021-10-20T07:01:55.60926Z","shell.execute_reply":"2021-10-20T07:02:03.070069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = [col for col in df_train if df_train[col].dtype not in ['int64','float64']]\nprint(cat_cols)\ncat_cols.remove('Name')\n\nfig, ax = plt.subplots(2, 2, figsize=(20, 10))\n\nfor variable, subplot in zip(cat_cols, ax.flatten()):\n    sns.countplot(df_train[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)\n        \nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:03.0726Z","iopub.execute_input":"2021-10-20T07:02:03.072892Z","iopub.status.idle":"2021-10-20T07:02:17.819439Z","shell.execute_reply.started":"2021-10-20T07:02:03.072856Z","shell.execute_reply":"2021-10-20T07:02:17.818596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train data상 null값을 확인\ndf_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.820907Z","iopub.execute_input":"2021-10-20T07:02:17.821323Z","iopub.status.idle":"2021-10-20T07:02:17.832643Z","shell.execute_reply.started":"2021-10-20T07:02:17.821278Z","shell.execute_reply":"2021-10-20T07:02:17.831694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=df_train.drop(['Name','Ticket'],axis=1)\ndf_test=df_test.drop(['Name','Ticket'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.83423Z","iopub.execute_input":"2021-10-20T07:02:17.834794Z","iopub.status.idle":"2021-10-20T07:02:17.841764Z","shell.execute_reply.started":"2021-10-20T07:02:17.834751Z","shell.execute_reply":"2021-10-20T07:02:17.840959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cabin 정보는 다 버리기 아까워 글자수를 변수로 한번 활용해볼 생각입니다.\n# Rather than deleting the Cabin column, I will use \"len()\" to use the number of characters in the variable.\ndf_train['CabinCode'] = df_train['Cabin'].apply(lambda x : len(str(x)) if x!='nan' else 0)\ndf_test['CabinCode'] = df_test['Cabin'].apply(lambda x  : len(str(x)) if x!='nan' else 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.843262Z","iopub.execute_input":"2021-10-20T07:02:17.843775Z","iopub.status.idle":"2021-10-20T07:02:17.855779Z","shell.execute_reply.started":"2021-10-20T07:02:17.843735Z","shell.execute_reply":"2021-10-20T07:02:17.855053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=df_train.drop(['Cabin'],axis=1)\ndf_test=df_test.drop(['Cabin'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.85712Z","iopub.execute_input":"2021-10-20T07:02:17.858377Z","iopub.status.idle":"2021-10-20T07:02:17.866129Z","shell.execute_reply.started":"2021-10-20T07:02:17.858328Z","shell.execute_reply":"2021-10-20T07:02:17.865383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nan값 역시 하나의 변수가 아닐까라는 가정하에 금번 분석에서는 null값에 대한 보정 없이 진행해 보겠습니다.\n# Assuming that the nan value is also a variable, in this analysis, we will proceed without correction for the null value.\n\ndf_train=pd.get_dummies(df_train)\ndf_test=pd.get_dummies(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.867921Z","iopub.execute_input":"2021-10-20T07:02:17.868523Z","iopub.status.idle":"2021-10-20T07:02:17.884257Z","shell.execute_reply.started":"2021-10-20T07:02:17.868481Z","shell.execute_reply":"2021-10-20T07:02:17.88364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()\ndf_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.885423Z","iopub.execute_input":"2021-10-20T07:02:17.886248Z","iopub.status.idle":"2021-10-20T07:02:17.908307Z","shell.execute_reply.started":"2021-10-20T07:02:17.886186Z","shell.execute_reply":"2021-10-20T07:02:17.90742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.909596Z","iopub.execute_input":"2021-10-20T07:02:17.910456Z","iopub.status.idle":"2021-10-20T07:02:17.927293Z","shell.execute_reply.started":"2021-10-20T07:02:17.91041Z","shell.execute_reply":"2021-10-20T07:02:17.926422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. 모델링(Modeling) \n#### 학습 진행을 위하여 Train, validation, test data를 나누고, HyperParameter를 넣어 학습까지 시키겠습니다.\n#### In order to proceed with the training, we will divide the Train, validation, and test data, and put HyperParameter to train it.","metadata":{}},{"cell_type":"code","source":"# 7:3으로 제공된 train data를 train과 validation data로 구분\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.3\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.929137Z","iopub.execute_input":"2021-10-20T07:02:17.929444Z","iopub.status.idle":"2021-10-20T07:02:17.937499Z","shell.execute_reply.started":"2021-10-20T07:02:17.929412Z","shell.execute_reply":"2021-10-20T07:02:17.936645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"read.csv\"를 쓰다보면 가끔 Unnamed: 0으로 문제발생이 많이 발생함\n# 그래서 저는 분석시 무조건 넣어서 실행하곤 합니다.\n\n# When I use the \"read.csv\" function, sometimes I get a lot of problems with Unnamed: 0. So, when I analyze, I put it in unconditionally and run it.\n#train = train.drop(['Unnamed: 0'], axis= 1)\n#validation = validation.drop(['Unnamed: 0'], axis= 1)\n#test = df_test.drop(['Unnamed: 0'], axis= 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.939015Z","iopub.execute_input":"2021-10-20T07:02:17.939266Z","iopub.status.idle":"2021-10-20T07:02:17.945947Z","shell.execute_reply.started":"2021-10-20T07:02:17.939236Z","shell.execute_reply":"2021-10-20T07:02:17.945302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_col = ['Survived']\ny_nm = 'Survived'\n\ndf_train_x = train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test.drop(drop_col, axis = 1)\ndf_test_y = pd.DataFrame(df_test[y_nm])","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.947258Z","iopub.execute_input":"2021-10-20T07:02:17.947841Z","iopub.status.idle":"2021-10-20T07:02:17.965478Z","shell.execute_reply.started":"2021-10-20T07:02:17.947795Z","shell.execute_reply":"2021-10-20T07:02:17.964574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.97161Z","iopub.execute_input":"2021-10-20T07:02:17.972104Z","iopub.status.idle":"2021-10-20T07:02:17.978555Z","shell.execute_reply.started":"2021-10-20T07:02:17.972057Z","shell.execute_reply":"2021-10-20T07:02:17.977589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:17.980135Z","iopub.execute_input":"2021-10-20T07:02:17.980728Z","iopub.status.idle":"2021-10-20T07:02:18.31187Z","shell.execute_reply.started":"2021-10-20T07:02:17.980684Z","shell.execute_reply":"2021-10-20T07:02:18.311178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importance 확인 \n# 주요 영향을 미치는 변수가 무엇인지 확인을 하고, 이를 그래프화 진행하였습니다.\n# We checked the variables that have a major impact, and graphed them.\n\nfeature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png')","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:18.315703Z","iopub.execute_input":"2021-10-20T07:02:18.317484Z","iopub.status.idle":"2021-10-20T07:02:18.640912Z","shell.execute_reply.started":"2021-10-20T07:02:18.317446Z","shell.execute_reply":"2021-10-20T07:02:18.640117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for loop를 사용하여 가장 높은 accuracy를 산출하는 로직을 넣었습니다. \n# I put the logic that yields the highest accuracy using a for loop.\n\nresult_lst =[]\nmax_accuracy =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_accuracy <= accuracy:\n        max_accuracy = accuracy\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score', 'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('최고 Accuracy-SCORE =%f, 임계치=%f'%(max_accuracy, opt_threshold))\nprint('Threshold 설정 완료')","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:18.642025Z","iopub.execute_input":"2021-10-20T07:02:18.642259Z","iopub.status.idle":"2021-10-20T07:02:18.967127Z","shell.execute_reply.started":"2021-10-20T07:02:18.642232Z","shell.execute_reply":"2021-10-20T07:02:18.966049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. 모델 결과 분석(Analyze model results)\n#### 모델을 통해 나온 train, validation, test 결과치(precision에서부터 F1-Score, AUROC까지)를 산식을 직접 계산하여 결과가 나오도록 구현해 보았습니다.\n#### I tried to implement the results by directly calculating the train, validation, and test results (from precision to F1-Score, AUROC) through the model.","metadata":{}},{"cell_type":"code","source":"predict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:18.968585Z","iopub.execute_input":"2021-10-20T07:02:18.968899Z","iopub.status.idle":"2021-10-20T07:02:18.993845Z","shell.execute_reply.started":"2021-10-20T07:02:18.968858Z","shell.execute_reply":"2021-10-20T07:02:18.99312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train))","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:18.995062Z","iopub.execute_input":"2021-10-20T07:02:18.9953Z","iopub.status.idle":"2021-10-20T07:02:19.015667Z","shell.execute_reply.started":"2021-10-20T07:02:18.995272Z","shell.execute_reply":"2021-10-20T07:02:19.014782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:19.016721Z","iopub.execute_input":"2021-10-20T07:02:19.017026Z","iopub.status.idle":"2021-10-20T07:02:19.226592Z","shell.execute_reply.started":"2021-10-20T07:02:19.017Z","shell.execute_reply":"2021-10-20T07:02:19.225895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Accuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:19.227631Z","iopub.execute_input":"2021-10-20T07:02:19.22794Z","iopub.status.idle":"2021-10-20T07:02:19.237421Z","shell.execute_reply.started":"2021-10-20T07:02:19.227913Z","shell.execute_reply":"2021-10-20T07:02:19.236529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:19.238851Z","iopub.execute_input":"2021-10-20T07:02:19.239094Z","iopub.status.idle":"2021-10-20T07:02:19.474039Z","shell.execute_reply.started":"2021-10-20T07:02:19.239065Z","shell.execute_reply":"2021-10-20T07:02:19.473511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_test_y.values.ravel(), pred_test, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_test_y.values.ravel(), pred_test),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_test_y.values.ravel(), pred_test))\n\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_test_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nAccuracy_Rate = (tp + tn) / (tp + tn + fp + fn)\nRecall_Rate = tp / (tp + fn)\nPrecision_Rate = tp / (tp + fp)\nSpecificity_Rate = tn / (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) / (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:02:19.475105Z","iopub.execute_input":"2021-10-20T07:02:19.475428Z","iopub.status.idle":"2021-10-20T07:02:19.71359Z","shell.execute_reply.started":"2021-10-20T07:02:19.475401Z","shell.execute_reply":"2021-10-20T07:02:19.712729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.제출자료 작성(Prepare submission materials)","metadata":{}},{"cell_type":"code","source":"test_result= pd.DataFrame(pred_test)\ntest_result.columns = ['Survived']\npredict = test_result['Survived']\nId_No = df_test['PassengerId']\nsubmission = pd.DataFrame({'PassengerId': Id_No, \"Survived\": predict})\nsubmission['Survived'] = submission['Survived'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T07:12:49.889734Z","iopub.execute_input":"2021-10-20T07:12:49.890025Z","iopub.status.idle":"2021-10-20T07:12:49.908676Z","shell.execute_reply.started":"2021-10-20T07:12:49.889994Z","shell.execute_reply":"2021-10-20T07:12:49.907663Z"},"trusted":true},"execution_count":null,"outputs":[]}]}