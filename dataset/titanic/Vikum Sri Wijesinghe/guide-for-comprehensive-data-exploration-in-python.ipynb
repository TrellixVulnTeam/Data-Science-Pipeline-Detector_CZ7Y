{"cells":[{"metadata":{},"cell_type":"markdown","source":"# GUIDE FOR COMPREHENSIVE DATA EXPLORATION WITH PYTHON\n[Vikum Wijesinghe](https://www.linkedin.com/in/vikumwijesinghe/) - September 2019\n\nOther Kernels: https://www.kaggle.com/vikumsw/kernels\n\n---"},{"metadata":{},"cell_type":"markdown","source":"### Data Exploration?. Where to start?. How to Start?. What to use?. How to choose???????\n<img src=\"https://media.giphy.com/media/mvoxdYnpyk23u/giphy.gif\">\n\n#### Assume you are a beginner with limited knowlegde on data exploration. You get to know that there is an huge collection of tools out there for Data Exploration : Matplotlib, Seaborn, ggplot, Bokeh, Plotly, Pygal, Altair, Geoplotlib, Gleam, Missingno and etc. Which one should you use? How Use?, This broad availability itself has created a confusion. Objective of this kernel is to clear that confusion and make you competent in the beautiful world of EDA (Exploratory Data Analysis)\n\n#### One thing to remember... Does not matter which tool we use, how we use it as long as we get what we looking for which is insights on data!. So let's forget about the tools, let's focus on getting the JOB DONE!.\n\n### Two friends gonna join with us for today's lesson. Let's wait for a them, they should be here in any minute.\n\n<img src=\"https://media.giphy.com/media/3o6ZtcLKytmWgdDOFO/giphy.gif\">\n\n\nHere they are!. Let's welcome SpiderMan and IronMan. Today we are joining the class where IronMan teach Data Exploration to SpiderMan. Now let's be quite and listen to them.\n\n**Iron Man  :** Hi Spidy, Tell me what you wanna learn? \n\n**SpiderMan :** I was studing on data exploration with python, but after minutes into it, I was feeling confused. I know that there is an huge collection of tools out there for Data Exploration : Matplotlib, Seaborn, ggplot, Bokeh, Plotly, Pygal, Altair, Geoplotlib, Gleam, Missingno and etc. But Which one should I use? How to Use?, This broad availability itself has created a confusion.\n\n**Iron Man  :** Ok. I get it. So what do you expect from this session?.\n\n**SpiderMan :** What are the things we do in EDA? I mean like, is there a sequence of tasks?. What tools to use?. How to use?... and....\n\n**Iron Man  :** Okay. I get it.. It's best to explain the process while practicing. for demonstration let's use the two most known datasets in kaggle, the housing data set and titanic dataset. Are you ready spidy?.\n\n**SpiderMan :** More Than ever boss!\n\n**Iron Man  :** Let's get the party started!.\n\n<img src=\"https://media.giphy.com/media/MUlmRFnTQxwJ2/giphy.gif\">"},{"metadata":{},"cell_type":"markdown","source":"# Table Of Contents\n\n1. [Quick view at data -> head and tail of our data](#view)\n1. [Univariate Analysis](#UnivariateAnalysis)\n    1. [Analysis of a numerical feature](#AnalysisofaNumericalFeature)\n    1. [Analysis of a categorical feature](#Analysisofacategoricalfeature)\n1. [Bivariate Analysis](#BivariateAnalysis)\n    1. [Relationship of a numerical feature with another numerical feature](#Relationshipofanumericalfeaturewithanothernumericalfeature)\n    1. [Relationship of a numerical feature with a categorical feature](#Relationshipofanumericalfeaturewithcategoricalfeature)\n1. [Correlation Analysis](#CorrelationAnalysis)\n    1. [Correlation Heat Map](#CorrelationHeatMap)\n    1. [Zoomed Heat Map](#ZoomedHeatMap)\n1. [Investgation of missing values](#Null)\n    1. [What's missing? to what extent?](#MissingStats)\n    1. [Visualizing missing values in a dataframe](#VisualizingMissingvalues)\n1. [Distribution plots for list of numerical features](#DistplotsforallNumricals)\n1. [Describing categorical and numerical features separately](#DescribingCatAndNum)\n1. [List unique values in categorical columns](#UniqueValues)\n1. [Get to know your dataset using <span style=\"color:PURPLE\">Pandas Profiling</span>](#PandasProfiling)\n1. [Credits](#Credits)\n1. [This kernel is under Construction, Much more to be added here!!](#aa)"},{"metadata":{},"cell_type":"markdown","source":"**Iron Man  :** We need party people here.. Let's invite them"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Inviting Party People\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input\"))\n\n#Load datasets for demonstrations\ntitanic_data = pd.read_csv(\"../input/titanic/train.csv\")\nhouse_data = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Iron Man  :** First and foremost it is important to have a look at data to get a clear sense on what we work on."},{"metadata":{},"cell_type":"markdown","source":"### Peek Data,Setting the context [^](#view)<a id=\"view\" ></a><br>\n\nLet's get an idea ab at the data using following pandas functions.\n* DataFrame.head()\n* DataFrame.tail()\n* DataFrame.shape\n* DataFrame.columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"#look at first 5 rows using .head()\nhouse_data.head()\n\n#Wanna see more?. try -> house_data.head(13) for first 13 rows.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#look at last 5 rows using .tail()\nhouse_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"house_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** I see. Our dataset is has 1460 rows, 81 columns. That is how to start right?. But thats a lots of data. Looks bit confusing... \n\n**Iron Man  :** That's True.. Because of it let's focus on a single feature and study it. It's called **Univariate Analysis**.. I read that part for you. Listen carefully?."},{"metadata":{},"cell_type":"markdown","source":"---\n## Univariate Analysis [^](#UnivariateAnalysis)<a id=\"UnivariateAnalysis\" ></a><br>"},{"metadata":{},"cell_type":"markdown","source":"### Analysis of a numerical feature [^](#AnalysisofaNumericalFeature)<a id=\"AnalysisofaNumericalFeature\" ></a><br>\n\nOkay!, Time to look at the problem of analysing a numerical feature. Say you have given a numerical feature named 'SalePrice' and you are expected to explore it. What are the things you would do?. Feeling confused or feel incompetent?. Do not worry, its very simple when you get it right.\n\n**What is numerical data?**\nFirst, let's be clear about **what is numerical data** : Numerical data have meaning as a measurement, such as a person’s height, weight, IQ, or blood pressure; or they’re a count, such as the number of stock shares a person owns, how many teeth a dog has, or how many pages you can read of your favorite book before you fall asleep. *Statisticians also call numerical data quantitative data*. [Read more here](#https://www.dummies.com/education/math/statistics/types-of-statistical-data-numerical-categorical-and-ordinal/)\n\n**Two Types of Numerical Data** : Discrete Data & Continuous Data\n \n**What are we looking for?** : What things would help us develop an understanding on the numerical feature?. There are basic set of stats & figures we use as presented below.\n* Number of observations\n* Mean\n* Standard Deviation\n* Max, Min\n* Interquartile range (IQR)\n* Histograms\n* Skewness and Kurtosis\n\n**How to ?** life is much easier when what you want is only few code lines away. There are few basic things that we can do,\n\n1. Peek at data : everybody loves to look at what they work on.. :D\n1. Descriptive statistics summary\n1. Distribution plot\n1. Skewness and Kurtosis\n\n\nLet's use *'SalePrice'* column of the housing dataset for demonstation. This feature contains a list of sales prices for houses. That's all we know..  for now..:) "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Peek... head or tail\nhouse_data['SalePrice'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** Ah interesting!. A numerical feature with big values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive statistics summary\nhouse_data['SalePrice'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** Thats some valueble info we got from only one line of code!. Let me put it into words ... We got 1460 values with a mean value of approx 180921, showing a std value of 79442.5. Minimum feature value is observed as 34900 while max value is reported as 755000."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm\n# Distribution plot\ndef distribution_plot(data):\n    sns.distplot(data, fit=norm)\n    plt.ylabel('Frequency')\n    plt.title(f'{data.name} distribution')\n    \ndistribution_plot(house_data['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness and kurtosis\nprint(\"Skewness: %f\" % house_data['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % house_data['SalePrice'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** Distribution plot looks interesting. Even though the values spread from 34900 to 755000. Most of the values are at between 100000 and 200000. "},{"metadata":{},"cell_type":"markdown","source":"**Iron Man  :** That is univariate study of a numerical feature. Let's see what to do when we got a categorical variable. Like you did earlier.. listen carefully..."},{"metadata":{},"cell_type":"markdown","source":"### Analysis of a categorical feature [^](#Analysisofacategoricalfeature)<a id=\"Analysisofacategoricalfeature\" ></a><br>\n\nNext, Let me introduce you to the problem of analysing a categorical feature. Say you have given a categorical feature named 'OverallQual'(Overall material and finish quality) and you are expected to explore it. What are the things you would do?. Feeling confused or feel incompetent?. Do not worry, its very simple when you get it right.\n\n**What is categorical data?**\nFirst, let's be clear about **what is categorical data** : Categorical data represent characteristics such as a person’s gender, marital status, hometown, or the types of movies they like. Categorical data can take on numerical values (such as “1” indicating male and “2” indicating female), but those numbers don’t have mathematical meaning. You couldn’t add them together, for example. *Statisticians also call categorical data , qualitative data*. [Read more here](#https://www.dummies.com/education/math/statistics/types-of-statistical-data-numerical-categorical-and-ordinal/)\n\n**Two Types of Categorical Data** : Nominal Data & Ordinal Data\n \n**What are we looking for?** : What things would help us develop an understanding on a categorical feature?. There are basic set of stats & figures we use as presented below.\n* Number of observations\n* Cardinality : How many categories are there?\n* What are the diffrent categories?\n* What is the mot common category?\n* Values counts for each category.\n* Values percentages for each category.\n\n**How to ?** life is much easier when what you want is only few code lines away. There are few basic things that we can do,\n\n* Peek at data : everybody loves to look at what they work on.. :D\n* Descriptive statistics summary\n* Value count plots.\n* Pie Graph for precentages of each category. \n\n\nLet's use *'OverallQual'* column of the housing dataset for demonstation. This feature contains a list of Overall material and finish quality for houses. That's all we know.. and need to know for now..:) "},{"metadata":{"trusted":true},"cell_type":"code","source":"OverallQual = house_data['OverallQual'].astype('category')\n\n#Peek... head or tail\nOverallQual.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** ah that is some useful info .. OverallQual feature got 10 categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive statistics summary\nOverallQual.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** I see that we are getting answers to our questions fast.. There are 10  categories, the most frequent is '5' with a count of 397 out of 1460. "},{"metadata":{"trusted":true},"cell_type":"code","source":"column = OverallQual;\nprint('Column Name:{}\\nCardinality:{}\\nValues:{}'.format(column.name,column.nunique(), column.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OverallQual.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getPlotsforCatFeature(series,figX=15,figY=7):\n    f,ax=plt.subplots(1,2,figsize=(figX,figY))\n    series.value_counts().plot.pie(autopct='%1.1f%%',ax=ax[0])\n    ax[0].set_title(f'{series.name}')\n    ax[0].set_ylabel('')\n    sns.countplot(series,ax=ax[1])\n    ax[1].set_title(f'Count plot for {series.name}')\n    plt.show()\n    \ngetPlotsforCatFeature(OverallQual,15,5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** That is value counts for each category. Category '5' is ranked first at a count of 397, closely followed by '6' & '7' with counts 374 and 319 respectively. Lowest counts are reported from categories '1' & '2' with just 5 observations even when combined. Great!...\n\nI think I have an idea on univariate analysis now. But what about the relationships between features?\n<img src=\"https://media.giphy.com/media/dXICCcws9oxxK/giphy.gif\">\n"},{"metadata":{},"cell_type":"markdown","source":"**Iron Man  :** That's what we look for.. Let's  Analyse feature pairs at ones looking for relationships.. It's called Bivariate Analysis.."},{"metadata":{},"cell_type":"markdown","source":"---\n## Bivariate Analysis [^](#BivariateAnalysis)<a id=\"BivariateAnalysis\" ></a><br>"},{"metadata":{},"cell_type":"markdown","source":"### Relationship of a numerical feature with another numerical feature [^](#Relationshipofanumericalfeaturewithanothernumericalfeature)<a id=\"Relationshipofanumericalfeaturewithanothernumericalfeature\" ></a><br>\n\nMost often we feel curious on how two numerical features behave wrt each other. Following techniques helps us to develop insights on those hidden relationships.\n* Scatterplot\n\n\nFor demonstration lets use 'GrLivArea'(groundLivingArea) and 'SalePrice' from housing dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot\nhouse_data.plot.scatter(x='GrLivArea', y='SalePrice');\n\n''' Alternatively you could use following function \ndef scatterplot(seriesX,seriesY):\n    data = pd.concat([seriesY, seriesX], axis=1)\n    data.plot.scatter(x=seriesX.name, y=seriesY.name)\n    \nscatterplot(house_data['GrLivArea'],house_data['SalePrice'])\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** It seems that 'SalePrice' and 'GrLivArea' are good friends, with a linear relationship.\n\n**Iron Man  :** Nice.. You are getting it.. Next lets see how to find relationships of a numerical feature with a categorical feature"},{"metadata":{},"cell_type":"markdown","source":"### Relationship of a numerical feature with a categorical feature [^](#Relationshipofanumericalfeaturewithcategoricalfeature)<a id=\"Relationshipofanumericalfeaturewithcategoricalfeature\" ></a><br>\n\nLet's try to visualize a relationship between a numerical feature and a categorical feature. Lets use Sale Price as the numerical feature and OverallQual which indicates Overall material and finish quality as the categorical feature from housing dataset. I know what you are thinking... we expect to see sale price increase with overall quality.. Lets see whether we could see that using following techniques,\n* Box Plot\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot\nnum = 'SalePrice'\ncat = 'OverallQual'\ndf  =  house_data\n\ndata = pd.concat([df[num], df[cat]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=cat, y=num, data=data)\nfig.axis(ymin=0, ymax=800000);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SpiderMan :** How beautiful! Just as we expected! Sales Price increses with OverallQual(Overall material and finish quality). Shall we do this to analyse relationship with SalePrice for few more categorical columns?"},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxplot(x, y, **kwargs):\n    sns.boxplot(x=x, y=y)\n    x=plt.xticks(rotation=90)\n\ndef fillMissingCatColumns(data,categorical):\n    for c in categorical:\n        data[c] = data[c].astype('category')\n        if data[c].isnull().any():\n            data[c] = data[c].cat.add_categories(['MISSING'])\n            data[c] = data[c].fillna('MISSING')\n    \ndef getboxPlots(data,var,categorical):\n    fillMissingCatColumns(data,categorical)\n    f = pd.melt(data, id_vars=var, value_vars=categorical)\n    g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, size=5)\n    g = g.map(boxplot, \"value\", var)\n    \n\ndata = house_data.copy()\ncategorical = [f for f in data.columns if data.dtypes[f] == 'object']    \ngetboxPlots(data,'SalePrice',categorical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Iron Man  :** That's what you asked for... Going through each one to identify relationships is your homework.. :D. Guess whats next..\n\n**SpiderMan :** mm... Correlation Analysis??\n\n**Iron Man  :** Nope!. it is tea time!... <img src=\"https://media.giphy.com/media/g6VWn4bujbz2w/giphy.gif\"> \n\nWith some cake!\n\n<img src=\"https://media.giphy.com/media/11e56tPCqD9kjK/giphy.gif\"> \n"},{"metadata":{},"cell_type":"markdown","source":"---\n## Correlation Analysis[^](#CorrelationAnalysis)<a id=\"CorrelationAnalysis\" ></a><br>"},{"metadata":{},"cell_type":"markdown","source":"### Correlation Heat Map[^](#CorrelationHeatMap)<a id=\"CorrelationAnalysis\" ></a><br>\n\nlarge correlations between features is one of the best indicators used for feature selection. If we have a data set with many columns, a good way to quickly check correlations among columns is by visualizing the correlation matrix as a heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"def getCorrHeatMap(dataFrame,figSize=[12,9]):\n    corrmat = dataFrame.corr()\n    f, ax = plt.subplots(figsize=(figSize[0], figSize[1]))\n    sns.heatmap(corrmat, vmax=.8, square=True);\n\ngetCorrHeatMap(house_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Iron Man  :** When its lighter(Closer to white) that means it has a larger positive correlation whereas darker cells mean a larger negative correlation."},{"metadata":{},"cell_type":"markdown","source":"### Zoomed Heat Map[^](#ZoomedHeatMap)<a id=\"CorrelationAnalysis\" ></a><br>"},{"metadata":{},"cell_type":"markdown","source":"**Iron Man  :** We are more interested about larger correlations. So we can filter the columns and get a heatmap showing only larger correlations with feature 'SalePrice'."},{"metadata":{"trusted":true},"cell_type":"code","source":"def getZoomedCorrHeatMap(dataFrame,featureCount,target,figSize=[12,9]):\n    corrmat = dataFrame.corr()\n    cols = corrmat.nlargest(featureCount, target)[target].index\n    f , ax = plt.subplots(figsize = (figSize[0],figSize[1]))\n    cm = np.corrcoef(dataFrame[cols].values.T)\n    sns.set(font_scale=1.25)\n    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n    plt.show()\n\ngetZoomedCorrHeatMap(house_data,10,'SalePrice',[10,8])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top two features having highet correlations include OverallQual(Overall material and finish quality) with 0.79 and GrLivArea with 0.71.\n\n**SpiderMan :** \n<img src=\"https://media.giphy.com/media/l4oaTyxPwkjqxY8m40/giphy.gif\"> \n"},{"metadata":{},"cell_type":"markdown","source":"---\n**SpiderMan :** Wow great! Is that it?. Any more tips!\n\n**Iron Man  :** Yes!. go through the kernel below... I have noted down some tips for you.."},{"metadata":{},"cell_type":"markdown","source":"---\n## Investgation of missing values[^](#Null)<a id=\"Null\" ></a><br>"},{"metadata":{},"cell_type":"markdown","source":"### What's missing? to what extent?[^](#MissingStats)<a id=\"MissingStats\" ></a><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getMissingValuesInfo(df):\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = round(df.isnull().sum().sort_values(ascending = False)/len(df)*100, 2)\n    temp = pd.concat([total, percent], axis = 1,keys= ['Total Missing Count', '% of Total Observations'])\n    temp.index.name ='Feature Name'\n    return temp.loc[(temp['Total Missing Count'] > 0)]\n\ngetMissingValuesInfo(house_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing missing values in a dataframe[^](#VisualizingMissingvalues)<a id=\"VisualizingMissingvalues\" ></a><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing missing counts\nmissing = house_data.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nplt.subplots(figsize=(15,5))\nmissing.plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,5))\nsns.heatmap(house_data.isnull(), cbar=False, cmap=\"YlGnBu_r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"White spaces shows the missing value in the data frame."},{"metadata":{},"cell_type":"markdown","source":"---\n### Distribution plots for list of numerical features[^](#DistplotsforallNumricals)<a id=\"DistplotsforallNumricals\" ></a><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def distplots(data,num_features):\n    f = pd.melt(data, value_vars=num_features)\n    g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False)\n    g = g.map(sns.distplot, \"value\")\n    \n\nnum_features = house_data.select_dtypes(include=['int64','float64'])\ndistplots(house_data,num_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n### Describing Categorical and Numerical features separately[^](#DescribingCatAndNum)<a id=\"DescribingCatAndNum\" ></a><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = house_data.select_dtypes(include=['int64','float64'])\nnum_features.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = house_data.select_dtypes(include='object')\ncategorical_features.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n### Listing unique values in categorical columns[^](#UniqueValues)<a id=\"UniqueValues\" ></a><br>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def printUniqueValues(df,cardinality=1000):\n    n = df.select_dtypes(include=object)\n    for column in n.columns:\n        uCount = df[column].nunique()\n        if uCount<=cardinality:\n            print('{:>12}: {} {}'.format(column,uCount, df[column].unique()))\n            #print(column,': [',uCount , '] ', df[column].unique())\n\n\nprintUniqueValues(house_data,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n### Get to know your dataset using <span style=\"color:PURPLE\">Pandas Profiling</span>[^](#PandasProfiling)<a id=\"PandasProfiling\" ></a><br>\n\nThanks to Firath's kernel : https://www.kaggle.com/frtgnn/thorough-eda-with-a-single-line-pandas-profiling/\n\nPandas Profiling generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling\nprofile_report = pandas_profiling.ProfileReport(titanic_data)\n#profile_report.to_file(\"profile_report.html\")\nprofile_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can use pandas profiling on selected features too.\n\n# Using Pandas Profiling to analyse SalePrice feature in housing dataset.\nimport pandas_profiling\nseries = house_data['SalePrice']\nd = { series.name : series}\ndf = pd.DataFrame(d) \npandas_profiling.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n### Credits[^](#Credits)<a id=\"Credits\" ></a><br>\n#### Other Kernels I reffered whern writing this one\n* [Comprehensive data exploration with Python](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python/notebook)\n* [A Simple Tutorial on Exploratory Data Analysis](https://www.kaggle.com/pavansanagapati/a-simple-tutorial-on-exploratory-data-analysis) "},{"metadata":{},"cell_type":"markdown","source":"## Thank You! Let's Party!\n<img src=\"https://media.giphy.com/media/VFB3cJJne7b5m/giphy.gif\"> \n### If you found this useful I would be really glad if you could show your appreciation with an upvote! See you!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}