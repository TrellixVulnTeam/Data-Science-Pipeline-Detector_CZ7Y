{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Beginner's Approach to Titanic Dataset Analysis. Upvote if you like it! "},{"metadata":{},"cell_type":"markdown","source":"Libraries"},{"metadata":{"_uuid":"10648cd2-6196-428e-970e-8b54fb3bef60","_cell_guid":"cad20c13-a375-4994-9c76-798c2c46f244","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nfrom sklearn import metrics\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\nsubmission = test[[\"PassengerId\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring"},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"______TRAIN_______\")\nprint(train.info())\nprint(\"______TEST________\")\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cleaning Data \n* PassengerID may be dropped.\n* Pclass may be made string.\n* Title may be extracted from Name and then Name may be dropped.\n* Age may be rounded.\n* Cabin may be dropped."},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean1(df):\n    \n    Title = []\n    for name in df[\"Name\"]:\n        if \"Mr.\" in name:\n            Title.append(\"Mr\")\n        elif \"Mrs.\" in name:\n            Title.append(\"Mrs\")\n        elif \"Miss.\" in name:\n            Title.append(\"Miss\")\n        elif \"Master.\" in name:\n            Title.append(\"Master\")\n        elif \"Rev.\" in name:\n            Title.append(\"Rev\")\n        elif \"Don.\" in name:\n            Title.append(\"Don\")\n        elif \"Dr.\" in name:\n            Title.append(\"Dr\")\n        elif \"Mme.\" in name:\n            Title.append(\"Miss\")\n        elif \"Ms.\" in name:\n            Title.append(\"Mrs\")\n        elif \"Major.\" in name:\n            Title.append(\"Major\")\n        elif \"Mrs\" in name:\n            Title.append(\"Mrs\")\n        elif \"Mr\" in name:\n            Title.append(\"Mr\")\n        elif \"Mlle.\" in name:\n            Title.append(\"Miss\")\n        elif \"Col.\" in name:\n            Title.append(\"Col\")\n        elif \"Capt.\" in name:\n            Title.append(\"Capt\")\n        elif \"Countess.\" in name:\n            Title.append(\"Countess\")\n        elif \"Jonkheer.\" in name:\n            Title.append(\"Jonkheer\")\n        else:\n            Title.append(\"Other\")\n            \n    df[\"Title\"] = Title\n    \n    df = df.astype({\n        \"Pclass\" : str,\n    })\n\n    df[\"Age\"] = round(df[\"Age\"])\n    \n    df = df.drop(columns = [\"PassengerId\", \"Name\", \"Cabin\"])\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = clean1(train)\ntest = clean1(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"______TRAIN_______\")\nprint(train.isnull().sum())\nprint(\"______TEST________\")\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cleaning Data\n* Age, Embarked and Fair may be filled using some patterns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train[\"Embarked\"].isnull()]\n# pd.crosstab(train[\"Embarked\"], train[\"Survived\"])\n# pd.crosstab(train[\"Embarked\"], train[\"Pclass\"])\n# pd.crosstab(train[\"Embarked\"], train[\"Title\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embarked is likely \"S\" for both"},{"metadata":{"trusted":true},"cell_type":"code","source":"ind = train[train[\"Embarked\"].isnull()].index\ntrain.loc[ind, \"Embarked\"] = \"S\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test[\"Fare\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = \"Fare\", y = \"Age\", hue = \"Pclass\", data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = \"Fare\", y = \"Age\", hue = \"Sex\", data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = \"Fare\", y = \"Age\", hue = \"Embarked\", data = train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We may take Fare = average Fare of passengers with:\n1. 45<Age<75\n2. Sex = male\n3. Pclass = 3\n4. Embarked = S"},{"metadata":{"trusted":true},"cell_type":"code","source":"fare = np.nanmean(train[\"Fare\"][\n    (train[\"Age\"] > 45) & (train[\"Age\"] < 75) & \n    (train[\"Sex\"] == \"male\") & \n    (train[\"Pclass\"] == \"3\") &\n    (train[\"Embarked\"] == \"S\")\n])\nind = test[test[\"Fare\"].isnull()].index\ntest.loc[ind, \"Fare\"] = fare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = \"Embarked\", y = \"Age\", hue = \"Pclass\", kind = \"box\", data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = \"Embarked\", y = \"Age\", hue = \"Sex\", kind = \"box\", data = train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We may take Age = median Age of passengers with same:\n1. Embarked\n2. Pclass\n3. Sex"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean2(df, train):\n    ind = df[df[\"Age\"].isnull()].index\n    for i in ind:\n        emb = df.loc[i][\"Embarked\"]\n        pc = df.loc[i][\"Pclass\"]\n        sex = df.loc[i][\"Sex\"]\n        \n        age = np.nanmedian(train[\"Age\"][(train[\"Embarked\"] == emb) & (train[\"Pclass\"] == pc) & (train[\"Sex\"] == sex)])\n        df.loc[i, \"Age\"] = age\n\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = clean2(train, train)\ntest = clean2(test, train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean Data\n* Sex may be one-hot encoded.\n* Embarked may be one-hot & frequency encoded.\n* Ticket may be frequency encoded.\n* Title may be frequency encoded.\n* Pclass may be one-hot & frequency encoded."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\"Sex\", \"Embarked\", \"Pclass\"]\n    \ntrain_temp = train[cols]\ntrain_ind = train_temp.index\n    \ntest_temp = test[cols]\ntest_ind = test_temp.index\n    \nenc = OneHotEncoder(drop = \"first\")\n# To avoid multi-collinearlty (dummy variable trap) due to one-hot-encoding, use drop = \"first\"\nenc.fit(train_temp)\n        \ntrain_hot = enc.transform(train_temp).toarray()\ntrain_hot = pd.DataFrame(train_hot, columns = enc.get_feature_names(cols), index = train_ind)\ntrain = train.drop(columns = [\"Sex\"])\ntrain = pd.concat([train, train_hot], axis = 1)\n    \ntest_hot = enc.transform(test_temp).toarray()\ntest_hot = pd.DataFrame(test_hot, columns = enc.get_feature_names(cols), index = test_ind)\ntest = test.drop(columns = [\"Sex\"])\ntest = pd.concat([test, test_hot], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def GetFreqMap(train_data):\n    cols = [\"Embarked\", \"Ticket\", \"Title\", \"Pclass\"]\n    MyMap = {}\n    for col in cols:\n        temp = {}\n        temp = train_data[col].value_counts()/train_data.shape[0]\n        temp = defaultdict(lambda : 0, temp)\n        MyMap[col] = temp\n    \n    return MyMap ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def GetMeanMap(train_data):\n    cols = [\"Embarked\", \"Ticket\", \"Title\", \"Pclass\"]\n    MyMap = {}\n    for col in cols:\n        temp = {}\n        categories = train_data[col].value_counts().keys()\n        for cat in categories:\n            n1 = train_data[col][(train_data[col] == cat) & (train_data[\"Survived\"] == 1)].shape[0]\n            n2 = train_data[col][(train_data[col] == cat)].shape[0]\n            temp[cat] = n1/n2\n        \n        temp = defaultdict(lambda : 0, temp)\n        MyMap[col] = temp\n        \n    return MyMap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MapMe(df, FM, MM):\n    temp_freq = pd.DataFrame()\n    temp_mean = pd.DataFrame()\n    \n    cols = [\"Embarked\", \"Ticket\", \"Title\", \"Pclass\"]\n    for col in cols:\n        temp_freq[col + \"_freq\"] = df[col].map(FM[col])\n        temp_mean[col + \"_mean\"] = df[col].map(MM[col])\n        \n    df = pd.concat([df, temp_freq, temp_mean], axis = 1)\n    df = df.drop(columns = [\"Embarked\", \"Ticket\", \"Title\", \"Pclass\"])\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FM = GetFreqMap(train)\nMM = GetMeanMap(train)\ntrain = MapMe(train, FM, MM)\ntest = MapMe(test, FM, MM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train.loc[:, train.columns != \"Survived\"]\ntrain_labels = train[[\"Survived\"]]\ntest_data = test\n\n# scaler = MinMaxScaler()\n# scaler.fit(train_data)\n# cols = train_data.columns\n\n# train_ind = train_data.index\n# train_data = scaler.transform(train_data)\n# train_data = pd.DataFrame(train_data, columns = cols, index = train_ind)\n\n# test_ind = test_data.index\n# test_data = scaler.transform(test_data)\n# test_data = pd.DataFrame(test_data, columns = cols, index = test_ind) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean Data\n* Check for collinearity"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 15))\nsns.heatmap(train_data.corr(), cmap = \"YlGnBu\", annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing Pclass_3 and Embarked_S"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop(columns = [\"Pclass_3\", \"Embarked_S\"])\ntest_data = test_data.drop(columns = [\"Pclass_3\", \"Embarked_S\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ModelAccuracy(model, train_data, train_labels):\n    train_data, test_data, train_labels, test_labels = train_test_split(\n        train_data, \n        train_labels, \n        test_size = 0.2,\n    )\n    \n    if model == \"RandomForest\":\n        classifier = RandomForestClassifier(n_estimators = 100)\n    elif model == \"DecisionTree\":\n        classifier = DecisionTreeClassifier()\n    elif model == \"XGBoost\":\n        classifier = XGBClassifier()\n    elif model == \"Logistic\":\n        classifier = LogisticRegression(solver = \"lbfgs\") \n    elif model == \"SVM\":\n        classifier = SVC(gamma = \"scale\")\n    elif model == \"GradientBoost\":\n        classifier = GradientBoostingClassifier()\n    elif model == \"AdaBoost\":\n        classifier = AdaBoostClassifier()\n    elif model == \"LDA\":\n        classifier = LinearDiscriminantAnalysis()\n    elif model == \"QDA\":\n        classifier = QuadraticDiscriminantAnalysis()\n    elif model == \"CatBoost\":\n        classifier = CatBoostClassifier()\n\n    classifier.fit(train_data, train_labels.values.ravel())\n    prediction = classifier.predict(test_data)\n\n    accuracy = metrics.accuracy_score(test_labels, prediction)\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [\"RandomForest\", \"DecisionTree\", \"XGBoost\", \"Logistic\", \"SVM\", \"GradientBoost\", \n          \"AdaBoost\", \"LDA\", \"QDA\", \"CatBoost\"]\n\nperformance_table = []\nfor i in range(1):\n    scores = []\n    for model in models:\n        accuracy = ModelAccuracy(model, train_data, train_labels)\n        scores.append(accuracy)\n    performance_table.append(scores)\n\nperformance_table = pd.DataFrame(performance_table, columns = models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\nplt.style.use('seaborn-white')\n\npalette = plt.get_cmap(\"Set1\")\n\nfor i, column in enumerate(performance_table):\n    plt.plot(performance_table[column], color = palette(i), label = column)\n\nplt.legend(loc = 2, ncol = 2, bbox_to_anchor = (0,1.5))\nplt.title(\"Line Plot\")\nplt.xlabel(\"Run\")\nplt.ylabel(\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_table.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = performance_table.describe()\nmean_list = list(df.loc[\"mean\", :])\n\npalette = plt.get_cmap(\"Set1\")\n\nfor i, mean in enumerate(mean_list):\n    plt.axhline(y = mean, color = palette(i), label = models[i], linewidth = 2)\n    \nplt.legend(loc = 2, ncol = 2, bbox_to_anchor = (0,1.5))\nplt.xticks([])\nplt.ylim(min(mean_list) - 0.01, max(mean_list) + 0.01)\nplt.ylabel(\"Accuracy\")    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = CatBoostClassifier()\nclassifier.fit(train_data, train_labels.values.ravel())\nprediction = classifier.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame(list(zip(submission[\"PassengerId\"], prediction)), columns = [\"PassengerId\", \"Survived\"])\nsubmit[\"Survived\"] = submit[\"Survived\"].map({\n    1.0 : 1,\n    0.0 : 0,\n})\nsubmit.to_csv(\"submit.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}