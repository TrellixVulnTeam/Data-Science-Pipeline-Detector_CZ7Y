{"cells":[{"metadata":{"_cell_guid":"e12020f7-4f94-4ecc-9007-9b7a6e7458a6","_uuid":"1fecb0980d8d422ec0f005c4bfd6225385c2c60f"},"cell_type":"markdown","source":"This Notebook is a kaggle tutorial for Japanese kaggle beginners writen in Japanese.\n\n# 5. 機械学習アルゴリズムのお気持ち？！ ハイパーパラメータを調整してみよう","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"先にも説明したように、機械学習アルゴリズムの振る舞いはハイパーパラメータという値で制御されます。もちろん、ハイパーパラメータの値次第で予測結果は変わり得ます。\n\nハイパーパラメータの調整は、主に2種類の方法があります。\n\n- 手動で調整\n- チューニングツールを使う\n\n後者としては、[Grid search](https://qiita.com/yhyhyhjp/items/c81f7cea72a44a7bfd3a), [Bayesian Optimization](https://blog.amedama.jp/entry/2018/08/18/233841), [Hyperopt](https://blog.amedama.jp/entry/hyperopt), [Optuna](https://research.preferred.jp/2018/12/optuna-release/)など、いくつかのツールがあります。\n\nこの[Notebook](https://www.kaggle.com/sishihara/upura-kaggle-tutorial-05-tuning)では、最初に手動でハイパーパラメータを調整し、機械学習アルゴリズムの振る舞いが異なることを確認します。その後、Optunaを用いたチューニングを実施します。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 特徴量の準備\n\nimport numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\ngender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male','female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ndata['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_columns = ['Name', 'PassengerId', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"特徴量の準備が完了しました。\n\n## LightGBM\n\nX_trainをX_train（学習用）とX_valid（検証用）に分割します。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0, stratify=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# カテゴリ変数の指定\ncategorical_features = ['Embarked', 'Pclass', 'Sex']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 手動で調整\n\n次の部分で、LightGBMのハイパーパラメータを定義します。前回は `objective` のみを指定していました。明示的に指定しない場合は、 `default` の[値](https://lightgbm.readthedocs.io/en/latest/Parameters.html)が自動的に定義されます。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'objective': 'binary'\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"後の比較のために、このハイパーパラメータで学習・予測を実施しておきます。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\n\nlgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n\nmodel = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=10,\n    num_boost_round=1000,\n    early_stopping_rounds=10\n)\n\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ここでは公式documentationの「[Parameters Tuning](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)」に従って、手動で調整を行っていきましょう。いくつかのユースケース別に、ハイパーパラメータ調整のTipsが記載されています。\n\n今回は、精度を高めるのが目的なので「[For Better Accuracy](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#for-better-accuracy)」を参照します。\n\n> - Use large max_bin (may be slower)\n> - Use small learning_rate with large num_iterations\n> - Use large num_leaves (may cause over-fitting)\n> - Use bigger training data\n> - Try dart\n\n- 1つ目は「大きめの`max_bin`を使え」です。`default`の値は255なので、ここでは300にしてみます。\n- 2つ目は「小さめの`learning_rate`を使え」です。`default`の値は0.1なので、ここでは0.05にしてみます。\n- 3つ目は「大きめの`num_leaves`を使え」です。`default`の値は31なので、ここでは40にしてみます。\n\n手動で調整するにせよ、チューニングツールを使うにせよ、機械学習アルゴリズムをブラックボックス的に利用するのではなく、ハイパーパラメータを正しく理解することが非常に大切です。\n\nハイパーパラメータの説明については、英語ですが[公式のdocumentation](https://lightgbm.readthedocs.io/en/latest/Parameters.html)で確認するのが確実です。なお日本語の記事だと、例えば[こちら](https://nykergoto.hatenablog.jp/entry/2019/03/29/%E5%8B%BE%E9%85%8D%E3%83%96%E3%83%BC%E3%82%B9%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%A7%E5%A4%A7%E4%BA%8B%E3%81%AA%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%81%AE%E6%B0%97%E6%8C%81%E3%81%A1)にLightGBMなどの勾配ブースティングの主要なハイパーパラメータ解説が記載されています。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'objective': 'binary',\n    'max_bin': 300,\n    'learning_rate': 0.05,\n    'num_leaves': 40\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n\nmodel = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=10,\n    num_boost_round=1000,\n    early_stopping_rounds=10\n)\n\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"y_predがハイパーパラメータ変更前と異なる値を取っていると分かります。出力ログにも変化があり、最終的な`valid_1's binary_logloss`が 0.433251 と、変更前よりも小さい値になっています。`binary_logloss` は損失なので、小さい方が望ましいです。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = (y_pred > 0.5).astype(int)\ny_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = gender_submission\n\nsub['Survived'] = y_pred\nsub.to_csv(\"submission_lightgbm_handtuning.csv\", index=False)\n\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LightGBMでの予測結果を提出してみると、私の環境では0.77033というスコアが出ました。ハイパーパラメータ変更前の0.75598に比べて、スコアが向上しています。\n\n# Optunaを使う","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ここまで手動でハイパーパラメータを調整してきましたが、次のような感情が芽生えている方もいるのではないでしょうか。\n\n- 「大きめ」「小さめ」といっても、具体的にどの値にすればよいのか分からない\n- 各パラメータの組み合わせ方もいくつかあり、逐一設定・実行して性能を検証するのは煩わしい\n\nそのような課題を解決してくれるのが、ハイパーパラメータのチューニングツールです。今回はOptunaを使っていきます。\n\nOptunaを使うに当たっては、あらかじめ次の関数の`trial.suggest_int()`のように、探索範囲を定義します。 \n\nここでは、意図的に`learning_rate`の調整を実施していません。テーブルデータをLightGBMで扱う場合、一般に`learning_rate`が低いほど高い性能が得られるためです。そのため探索範囲には含めず、必要であれば後に手動で低い値に変更することにします。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# KaggleのKernelに搭載済\nimport optuna\nfrom sklearn.metrics import log_loss\n\n\ndef objective(trial):\n    params = {\n        'objective': 'binary',\n        'max_bin': trial.suggest_int('max_bin', 255, 500),\n        'learning_rate': 0.05,\n        'num_leaves': trial.suggest_int('num_leaves', 32, 128),\n    }\n    \n    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n\n    model = lgb.train(\n        params, lgb_train,\n        valid_sets=[lgb_train, lgb_eval],\n        verbose_eval=10,\n        num_boost_round=1000,\n        early_stopping_rounds=10\n    )\n\n    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n    score = log_loss(y_valid, y_pred_valid)\n    return score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`n_trials`は試行回数です。ここでは計算を短くするため、40回程度にしておきます。乱数も固定しておきます。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\nstudy.optimize(objective, n_trials=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study.best_params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"指定した範囲内で試行回数だけ探索した結果得られた最良のハイパーパラメータが表示されています。こちらで改めて予測し直して、提出してみましょう。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'objective': 'binary',\n    'max_bin': study.best_params['max_bin'],\n    'learning_rate': 0.05,\n    'num_leaves': study.best_params['num_leaves']\n}\n\nlgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n\nmodel = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=10,\n    num_boost_round=1000,\n    early_stopping_rounds=10\n)\n\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = (y_pred > 0.5).astype(int)\n\nsub['Survived'] = y_pred\nsub.to_csv(\"submission_lightgbm_optuna.csv\", index=False)\n\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"予測結果を提出してみると、私の環境では0.77033というスコアが出ました。偶然手動での調整と同じスコアになっています。探索範囲や試行回数を変えれば、より良いスコアが出るかもしれません。","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}