{"cells":[{"metadata":{"_cell_guid":"e12020f7-4f94-4ecc-9007-9b7a6e7458a6","_uuid":"1fecb0980d8d422ec0f005c4bfd6225385c2c60f"},"cell_type":"markdown","source":"This Notebook is a kaggle tutorial for Japanese kaggle beginners writen in Japanese.\n\n# 3. ここで差がつく！ 仮説に基づいて新しい特徴量を作ってみよう","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"この[Notebook](https://www.kaggle.com/sishihara/upura-kaggle-tutorial-03-feature-engineering)では、特徴量エンジニアリングを学びます。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 再現性の大切さ\n「再現性がある」とは、何度実行しても同じ結果が得られることです。Kaggleで言うと、同一のスコアが得られると言い換えても良いでしょう。\n\n再現性がないと、実行ごとに異なるスコアが得られてしまいます。今後、特徴量エンジニアリングなどでスコアの向上を試みても、予測モデルが改善されたか否かを正しく判断できなくなる問題が生じます。\n\n実は、2つ目のNotebookには再現性がありませんでした。その原因は、Ageという特徴量の欠損値を埋める際の乱数です。ここでは標準偏差を考慮した乱数で欠損値を穴埋めしているのですが、この乱数は実行ごとに値が変わるようになってしまっています。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 前回のAgeを処理する部分までを実行\n\nimport numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\ngender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male','female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`np.random.randint(age_avg - age_std, age_avg + age_std)` の実行ごとに、結果が異なります。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"age_avg = data['Age'].mean()\nage_std = data['Age'].std()\n\nnp.random.randint(age_avg - age_std, age_avg + age_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.randint(age_avg - age_std, age_avg + age_std)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"再現性を確保するためには、例えば次のような方法が考えられます。\n\n1. そもそも乱数を用いる部分を削除する\n2. 乱数のseedを与えて実行結果を固定する\n\nAgeについては、そもそも乱数を用いるよりも、欠損していないデータの中央値を与えた方が筋の良い補完ができそうです。今回は中央値で補完するようにコードを改変します。","execution_count":null},{"metadata":{"_cell_guid":"5717373d-91ce-4cfd-a579-ef7dab192771","_uuid":"42f1ebda5705d5272ea350bfd00e66c2f946a66e","trusted":true},"cell_type":"code","source":"data['Age'].fillna(data['Age'].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d3f3527c-8758-41c2-bbe3-14b604b2d317","_uuid":"f7341a6f089464180e94d5e09d1071e0350cff3d","trusted":true},"cell_type":"code","source":"# その他の特徴量エンジニアリングの部分の処理\n\ndelete_columns = ['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"19f52c93-701c-4ae1-ad7c-0c89004bc1a0","_uuid":"d2f7f7fd519f1fcc160304783c8b440e5cb552da"},"cell_type":"markdown","source":"## 機械学習アルゴリズム\n\n機械学習アルゴリズムの大半は乱数を利用するので、再現性を担保するためにはseedを設定しておかなければなりません。実は2つ目のKernelを振り返ると、機械学習アルゴリズムのロジスティック回帰のハイパーパラメータとして random_state=0 を与え、seedを固定していました。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(penalty='l2', solver=\"sag\", random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"このようにKaggleを進めていく際には、きちんと再現性が取れていることを随時確認していきましょう。（なお、GPUを利用する場合など、どうしても再現性が担保できない場合もあります）","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 仮説から新しい特徴量を作る\n\nここでは、実際に新しい特徴量を作っていきましょう。\n例として探索的なデータ分析を実施した結果、ぼんやりと「一緒に乗船した家族の人数が多い方が、生存率が低そうだ」という仮説が得られた状況を考えます。\n\n仮説が得られたので、次はこの仮説を検証するための可視化に移ります。新しい行「FamilySize」を作り、その大きさごとに生存したか否かを棒グラフにしましょう。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 改めてデータを読み込み直す\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\ngender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male','female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"「FamilySize」の作成に当たっては、ここまで削除していた「Parch」「SibSp」を使います。1を足しているのは、本人分です。\n\n- Parch: 両親、子供の数\n- SibSp: 兄弟、配偶者の数","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ntrain['FamilySize'] = data['FamilySize'][:len(train)]\ntest['FamilySize'] = data['FamilySize'][len(train):]\n\nimport seaborn as sns\nsns.countplot(x='FamilySize', data = train, hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ここでFamilySize >= 5の場合、死亡が生存を上回っており、生存率が低いことが分かります。\n\n- Survived == 0: 死亡\n- Survived == 1: 生存\n\n「一緒に乗船した家族の人数が多い方が、生存率が低そうだ」という（ぼんやりとした）仮説が、可視化を通じて「FamilySize >= 5の場合、生存率が低いので、この特徴量は予測精度に寄与しそうだ」という確信を持った仮説に変わりました。\n\n更に今回、可視化を通じて、それまで持っていなかった仮説（情報）を得ることもできました。「FamilySize == 1」の人が圧倒的に多く、かつ生存率が低いということです。\n\nこの「FamilySize == 1」であるという特徴量も予測精度に寄与しそうなので、下記のように新しく「IsAlone」という特徴量を作成してみましょう。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain['IsAlone'] = data['IsAlone'][:len(train)]\ntest['IsAlone'] = data['IsAlone'][len(train):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# その他の特徴量エンジニアリングの部分の処理\ndelete_columns = ['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a37e176c-3b55-43ab-b358-324dc384ceef","_uuid":"d4d6df3e6c40063309ea72f4d4cea51cf616fd80"},"cell_type":"markdown","source":"## 予測精度の比較\n\n新しい特徴量を加えた場合の予測精度を確認してみましょう。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = gender_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train)\ny_pred_familysize_isalone = clf.predict(X_test)\n\nsub['Survived'] = list(map(int, y_pred_familysize_isalone))\nsub.to_csv(\"submission_familysize_isalone.csv\", index = False)\n\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"比較のために、特徴量を加えなかった場合をいくつかのパターンで検証しておきます。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train.drop('FamilySize', axis=1), y_train)\ny_pred_isalone = clf.predict(X_test.drop('FamilySize', axis=1))\n\nsub['Survived'] = list(map(int, y_pred_isalone))\nsub.to_csv(\"submission_isalone.csv\", index = False)\n\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train.drop('IsAlone', axis=1), y_train)\ny_pred_familysize = clf.predict(X_test.drop('IsAlone', axis=1))\n\nsub['Survived'] = list(map(int, y_pred_familysize))\nsub.to_csv(\"submission_familysize.csv\", index = False)\n\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train.drop(['FamilySize', 'IsAlone'], axis=1), y_train)\ny_pred = clf.predict(X_test.drop(['FamilySize', 'IsAlone'], axis=1))\n\nsub['Survived'] = list(map(int, y_pred))\nsub.to_csv(\"submission.csv\", index = False)\n\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}