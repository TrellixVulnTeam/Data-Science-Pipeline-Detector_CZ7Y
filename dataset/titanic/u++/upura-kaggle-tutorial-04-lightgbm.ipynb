{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This Notebook is a kaggle tutorial for Japanese kaggle beginners writen in Japanese.\n\n# 4. 勾配ブースティングが最強？！ いろいろな機械学習アルゴリズムを使ってみよう","metadata":{"_cell_guid":"e12020f7-4f94-4ecc-9007-9b7a6e7458a6","_uuid":"1fecb0980d8d422ec0f005c4bfd6225385c2c60f"}},{"cell_type":"markdown","source":"これまでは機械学習アルゴリズムとして、ロジスティック回帰を採用していました。\n\nこの[Notebook](https://www.kaggle.com/sishihara/upura-kaggle-tutorial-04-lightgbm)では、いろいろな機械学習アルゴリズムを使ってみましょう。これまでロジスティック回帰を使っていた部分を差し替えて学習・予測を実行してみたいと思います。\n\nロジスティック回帰の実装に利用していたsklearnというパッケージは入出力のインタフェースが統一されており、手軽に機械学習アルゴリズムを変更できます。実際にいくつか試してみましょう。\n\nまた最近のKaggleのコンペティションで上位陣が利用している機械学習アルゴリズムとしては、勾配ブースティングやニューラルネットワークが挙げられます。これらはロジスティック回帰に比べて表現力が高く、高性能に予測できる可能性を秘めています。特に上位陣での採用率が高いのは「LightGBM」という勾配ブースティングのパッケージです。sklearnと同様のインターフェイスも用意されていますが、ここでは[Python-package Introduction](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)に記載の方式で実装します。","metadata":{}},{"cell_type":"code","source":"# 特徴量の準備\n\nimport numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\ngender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male','female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ndata['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:43.919916Z","iopub.execute_input":"2022-05-29T06:36:43.920585Z","iopub.status.idle":"2022-05-29T06:36:43.982413Z","shell.execute_reply.started":"2022-05-29T06:36:43.920494Z","shell.execute_reply":"2022-05-29T06:36:43.981543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:43.98405Z","iopub.execute_input":"2022-05-29T06:36:43.984458Z","iopub.status.idle":"2022-05-29T06:36:44.005568Z","shell.execute_reply.started":"2022-05-29T06:36:43.984415Z","shell.execute_reply":"2022-05-29T06:36:44.004386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delete_columns = ['Name', 'PassengerId','Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.007012Z","iopub.execute_input":"2022-05-29T06:36:44.0073Z","iopub.status.idle":"2022-05-29T06:36:44.023252Z","shell.execute_reply.started":"2022-05-29T06:36:44.007253Z","shell.execute_reply":"2022-05-29T06:36:44.021909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.026091Z","iopub.execute_input":"2022-05-29T06:36:44.026912Z","iopub.status.idle":"2022-05-29T06:36:44.048442Z","shell.execute_reply.started":"2022-05-29T06:36:44.026843Z","shell.execute_reply":"2022-05-29T06:36:44.047679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"特徴量の準備が完了しました。\n\n# sklearn\nまずはsklearn内で機械学習アルゴリズムを変更していきましょう。これまではロジスティック回帰を使ってきました。","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(penalty='l2', solver=\"sag\", random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.051255Z","iopub.execute_input":"2022-05-29T06:36:44.051802Z","iopub.status.idle":"2022-05-29T06:36:44.057067Z","shell.execute_reply.started":"2022-05-29T06:36:44.051749Z","shell.execute_reply":"2022-05-29T06:36:44.056265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"sklearnでは、clfで宣言するモデルを切り替えるだけで機械学習アルゴリズムを差し替えられます。例えば、[ランダムフォレスト](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)と呼ばれる機械学習アルゴリズムを使ってみましょう。","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.058818Z","iopub.execute_input":"2022-05-29T06:36:44.059239Z","iopub.status.idle":"2022-05-29T06:36:44.070505Z","shell.execute_reply.started":"2022-05-29T06:36:44.059187Z","shell.execute_reply":"2022-05-29T06:36:44.06957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"あとはロジスティック回帰の場合と同様に学習・予測が実行可能です。","metadata":{}},{"cell_type":"code","source":"clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.072058Z","iopub.execute_input":"2022-05-29T06:36:44.072477Z","iopub.status.idle":"2022-05-29T06:36:44.201534Z","shell.execute_reply.started":"2022-05-29T06:36:44.072433Z","shell.execute_reply":"2022-05-29T06:36:44.200793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.203019Z","iopub.execute_input":"2022-05-29T06:36:44.203337Z","iopub.status.idle":"2022-05-29T06:36:44.210765Z","shell.execute_reply.started":"2022-05-29T06:36:44.203277Z","shell.execute_reply":"2022-05-29T06:36:44.209885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = gender_submission","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.212083Z","iopub.execute_input":"2022-05-29T06:36:44.212485Z","iopub.status.idle":"2022-05-29T06:36:44.222266Z","shell.execute_reply.started":"2022-05-29T06:36:44.212435Z","shell.execute_reply":"2022-05-29T06:36:44.221405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['Survived'] = list(map(int, y_pred))\nsub.to_csv(\"submission_randomforest.csv\", index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.223777Z","iopub.execute_input":"2022-05-29T06:36:44.224355Z","iopub.status.idle":"2022-05-29T06:36:44.245359Z","shell.execute_reply.started":"2022-05-29T06:36:44.224028Z","shell.execute_reply":"2022-05-29T06:36:44.24467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ランダムフォレストでの予測結果を提出してみると、私の環境では0.77033というロジスティック回帰の時よりも格段に良いスコアが出ました。\n\n[sklearnには非常に多くの種類の機械学習アルゴリズムが実装されている](https://scikit-learn.org/stable/supervised_learning.html)ので、ぜひいろいろな機械学習アルゴリズムを試してみてください。","metadata":{}},{"cell_type":"markdown","source":"# LightGBM\n続いて、LightGBMを使います。sklearnとの差異もあり、いくつか下準備が必要です。\n\n1. 学習用・検証用にデータセットを分割する\n2. カテゴリ変数をリスト形式で宣言する\n\nLightGBMは大量の決定木を作成しながら学習を進めます。そのため、学習に利用したデータセットなどにのみ過剰に適合してしまい、本来の目的である未知の値に対する性能が劣化してしまう「過学習」という現象に陥りがちです。そこで学習に利用しない検証用のデータに対する性能を見ながら学習を打ち切る「early stopping」を利用するのが一般的となっています。\n\nここでは、X_trainをX_train（学習用）とX_valid（検証用）に分割します。","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.246469Z","iopub.execute_input":"2022-05-29T06:36:44.246781Z","iopub.status.idle":"2022-05-29T06:36:44.257732Z","shell.execute_reply.started":"2022-05-29T06:36:44.246719Z","shell.execute_reply":"2022-05-29T06:36:44.256776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[LightGBMでは、カテゴリ変数に対して特別な処理](https://tebasakisan.hatenadiary.com/entry/2019/01/27/222102)を自動的に実行してくれます。次のように、何をカテゴリ変数として扱ってほしいか明示的にLightGBMに教えてあげましょう。","metadata":{}},{"cell_type":"code","source":"categorical_features = ['Embarked', 'Pclass', 'Sex']","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.259768Z","iopub.execute_input":"2022-05-29T06:36:44.260276Z","iopub.status.idle":"2022-05-29T06:36:44.265727Z","shell.execute_reply.started":"2022-05-29T06:36:44.260029Z","shell.execute_reply":"2022-05-29T06:36:44.264608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"下準備も終わったところで、LightGBMで学習・予測を実施します。","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n\n\nlgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n\nparams = {\n    'objective': 'binary'\n}\n\nmodel = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=10,\n    num_boost_round=1000,\n    callbacks=[lgb.early_stopping(10)]\n)\n\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.267233Z","iopub.execute_input":"2022-05-29T06:36:44.267743Z","iopub.status.idle":"2022-05-29T06:36:44.361172Z","shell.execute_reply.started":"2022-05-29T06:36:44.267667Z","shell.execute_reply":"2022-05-29T06:36:44.36013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.362632Z","iopub.execute_input":"2022-05-29T06:36:44.363157Z","iopub.status.idle":"2022-05-29T06:36:44.372522Z","shell.execute_reply.started":"2022-05-29T06:36:44.363104Z","shell.execute_reply":"2022-05-29T06:36:44.371452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"今回のLightGBMの設定では、出力結果は1になる予測値になります。今回はしきい値を決め打って、0.5を上回っていれば1と予測したと見なして、提出してみます。","metadata":{}},{"cell_type":"code","source":"y_pred = (y_pred > 0.5).astype(int)\ny_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.374136Z","iopub.execute_input":"2022-05-29T06:36:44.374709Z","iopub.status.idle":"2022-05-29T06:36:44.386056Z","shell.execute_reply.started":"2022-05-29T06:36:44.374655Z","shell.execute_reply":"2022-05-29T06:36:44.384778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['Survived'] = y_pred\nsub.to_csv(\"submission_lightgbm.csv\", index=False)\n\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T06:36:44.387574Z","iopub.execute_input":"2022-05-29T06:36:44.388107Z","iopub.status.idle":"2022-05-29T06:36:44.409767Z","shell.execute_reply.started":"2022-05-29T06:36:44.38805Z","shell.execute_reply":"2022-05-29T06:36:44.40863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LightGBMでの予測結果を提出してみると、私の環境では0.75598というスコアが出ました。ランダムフォレスト同様、ロジスティック回帰の時のスコアよりも向上しているのが分かります。\n\nこのように利用する機械学習アルゴリズム次第で、Kaggleのスコアを向上させることが可能です。","metadata":{}}]}