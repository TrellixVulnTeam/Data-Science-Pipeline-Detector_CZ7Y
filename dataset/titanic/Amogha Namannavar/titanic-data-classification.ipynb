{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:350%;text-align:center\"> Titanic Data EDA and Logestic Regression </h1>\n\n\n<img src=\"https://data.whicdn.com/images/172028045/original.gif\">\n\n\n\n\n\n<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:250%;text-align:center\">Analysis of the different features of the Titanic Data Set and Classification </h1>\n\n<h1 style=\"background-color:BLUE;font-family:Georgia;font-size:100%;text-align:center\">Please Upvote and comment if you like the EDA and classification</h1>\n"},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\"> Step 1: Importing  Data</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing  datasets\ntrain=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\">Step 2: Inspecting the Dataframe </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#to see the rows and columns\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to see the info \ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to see the \ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\">Step 3: Data Cleaning and Preparation</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop('Cabin', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking only not null values from 'Age' and 'Embarked' since they have not null values\ntrain=train[train['Age'].notnull()]\ntrain=train[train['Embarked'].notnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\">Step 4: Data Visualization</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ndef plotcountgraph(var):\n    \n    sns.set(font_scale=1.25)\n    plt.figure(figsize=(10, 5))\n    ax = sns.countplot(x=var, hue='Survived', data=train,  palette=\"viridis\")\n    plt.setp(ax.get_xticklabels(), rotation=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var=['Sex','Pclass','Embarked','SibSp','Parch']\nfor i in var:\n    plotcountgraph(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\"> Inference from the above graphs\n   \n    \n    *Number of females survived is more when compared to male\n    *Lower the Pclass higher is the rate of survival\n    *Survival rate of people embarked from Southampton is higher \n    *Survival rate of people having no siblings is higher\n    *Survival rate of people having no parents / children aboard the Titanic is higher\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the correlation between the numeric variables\nplt.figure(figsize = (20,10))\nsns.heatmap(train.corr(),annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drpping the Parch as it is having low correlation with survived(target variable)\ntrain = train.drop('Parch', axis=1)\n#dropping ticket and Parch as it is not required for further analysis\ntrain = train.drop('Ticket', axis=1)\ntrain = train.drop('Name', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the test data set and checking\ntest=pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting  the categorical variables to numeric as required for model building\n\ndummy1 = pd.get_dummies(train[['Sex','Embarked']], drop_first=True)\n# Adding the results to the master dataframe\ntrain = pd.concat([train, dummy1], axis=1)\n\ndummy1 = pd.get_dummies(test[['Sex','Embarked']], drop_first=True)\n# Adding the results to the master dataframe\ntest = pd.concat([test, dummy1], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#since the dummies are already present\ntrain=train.drop(['Sex','Embarked'],1)\ntest=test.drop(['Sex','Embarked'],1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\">Step 5: Creating the Test and Train Data properly</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping the target variable for training the model\nX_train=train.drop('Survived', axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset for the target variable for training the model\ny_train=train['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the test data set X_test \nX_test=test\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\">Step 6: Model Building</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Running Your First Training Model\nimport statsmodels.api as sm\nlogm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\nlogm1.fit().summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\">Step 7: Feature Selection Using RFE</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nrfe = RFE(logreg,6)             # running RFE with 13 variables as output\nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.support_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns, rfe.support_, rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = X_train.columns[rfe.support_]\nX_train.columns[~rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assessing the model with StatsModels"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm = sm.add_constant(X_train[col])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the predicted values on the train set\ny_train_pred = res.predict(X_train_sm)\ny_train_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Creating a dataframe with the actual churn flag and the predicted probabilities"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final = pd.DataFrame({'Survived':y_train.values, 'Survived_prob':y_train_pred})\ny_train_pred_final['PassengerId'] = y_train.index\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating new column 'predicted' with 1 if Survived_Prob > 0.5 else 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final['predicted'] = y_train_pred_final.Survived_prob.map(lambda x: 1 if x > 0.54 else 0)\n\n# Let's see the head\ny_train_pred_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final.predicted )\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.accuracy_score(y_train_pred_final.Survived, y_train_pred_final.predicted))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The accuracy is pretty Good!"},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"background-color:Skyblue;font-family:Georgia;font-size:175%;text-align:left\">Step 8: Making predictions on the test set</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test[col]\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_sm = sm.add_constant(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making predictions on the test set\ny_test_pred = res.predict(X_test_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(y_test_pred)\ny_pred_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing index for both dataframes to append them side by side \ny_pred_1.reset_index(drop=True, inplace=True)\n#y_test_df.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a final \ny_pred_final = pd.concat([ y_pred_1],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming and Reaaranging the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Survived_Prob'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the head of y_pred_final\ny_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final['Survived'] = y_pred_final.Survived_Prob.map(lambda x: 1 if x > 0.54 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating the submission.csv for the submission \n\noutput = pd.DataFrame({'PassengerId': test.PassengerId , 'Survived': y_pred_final.Survived})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test.PassengerId , 'Survived': y_pred_final.Survived_Prob})\noutput.to_csv('my_submission_Prob.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}