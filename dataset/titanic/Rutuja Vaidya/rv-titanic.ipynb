{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  **Welcome to my notebook**\n\nSteps Involved:\n*     Data Cleaning & Data Manipluation on Train & Test Dataset & Imputing the Missing Values.\n*     Using XGBoost Model with HyperParameter Tuning\n*     Predicting the Class Survived","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport numpy as np\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading Dataset\ntrain=pd.read_csv('../input/titanic/train.csv')\ntest=pd.read_csv('../input/titanic/test.csv')\ndataset=[train,test]\ntrain.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualization**","metadata":{}},{"cell_type":"code","source":"# missing values graph\n# for training\nfig = plt.figure(figsize=(12,6))\n\nplt.subplot(121)   #  subplot 1 - female\nplt.title('training datset')\nsns.heatmap(train.isnull(),yticklabels=False,cmap='viridis')#, annot=True, fmt='.2f', square=True, cmap = 'Reds_r')\n\nplt.subplot(122)   #  subplot 2 - male\nplt.title('testing datset')\nsns.heatmap(test.isnull(),yticklabels=False,cmap='viridis' )#,annot=True, fmt='.2f', square=True, cmap = 'Blues_r')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> From above graph, we can see that \n> 1. in training dataset, Column **Age, Cabin** and **Embarked** have null values \n> 2. in training dataset, Column **Age**, and **Cabin**  have null values ","metadata":{}},{"cell_type":"markdown","source":"> From above figure , we can see that people","metadata":{}},{"cell_type":"code","source":"# visualize the number of male and female survived or not\n\nsns.countplot(data=train,x='Sex',hue='Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It shows that most of the women are survived as compared to men","metadata":{}},{"cell_type":"markdown","source":"> Now let's see the catplot which will give detailed distribution of the survival rate between different passenger classes on the Titanic for men and women.","metadata":{}},{"cell_type":"code","source":"## Count of number of family memebers\n#sns.countplot(x = 'Pclass',hue='Sex', data = train,palette='PuBuGn')\nsns.catplot(x=\"Pclass\", hue=\"Sex\", col=\"Survived\",\n                data=train, kind=\"count\",\n                height=4, aspect=.7, palette = 'PuBu');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check the distribution of age and sex with Survival Count","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='Sex', y='Age', hue = 'Survived',data=train);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" We can see that the Average age for both men and women is nearly about 30","metadata":{}},{"cell_type":"markdown","source":"**Distribution of Embarkation Port**","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=train,x='Embarked',hue='Survived')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Cleaning**","metadata":{}},{"cell_type":"markdown","source":"> SibSp and Parch Means number of sibling and Parents/children respectively. So to get family size we can do operation as adding them to 1. So we will get family size.","metadata":{}},{"cell_type":"code","source":"for data in dataset:\n    data['Family']=data['SibSp']+data['Parch']+1\n    \n# Drop columns SibSp and Parch\nfor data in dataset:\n    data.drop(columns=['SibSp','Parch'],inplace=True,axis=1)\n\n# Column Name Ticket and Cabin is not necessary to predict whether passanger will survive or not, So Drop column Name and Ticket and Cabin\nfor data in dataset:\n    data.drop(columns=['Name','Ticket','Cabin',],axis=1,inplace=True)\n    \n# manipulating Fare Column\nfor data in dataset:\n    data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare']   = 2\n    data.loc[(data['Fare'] > 31) & (data['Fare'] <= 99), 'Fare']   = 3\n    data.loc[(data['Fare'] > 99) & (data['Fare'] <= 250), 'Fare']   = 4\n    data.loc[ data['Fare'] > 250, 'Fare'] = 5\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Family'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=\"Family\", y=\"Survived\", data=train)\nplt.show;","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert Categorical Values to Numeric Value \nprint(data['Embarked'].value_counts())\nfor data in dataset:\n    data['Sex']=data['Sex'].map({'female':0,'male':1})\n    data['Embarked']=data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Imputing the missing values**","metadata":{}},{"cell_type":"code","source":"# information about training and testing dataset\nfor data in dataset:\n    data.info()\n    print('========================================')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding the null columns in train and test datasets\ntrain_null_cols=train.columns[train.isna().any()].to_list()\ntest_null_cols=test.columns[test.isna().any()].to_list()\nprint('train_null_cols : ',train_null_cols)\nprint('test_null_cols : ',test_null_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imputation of age in traing dataset by using mean\nfor data in dataset:\n    data['Age'].fillna(data['Age'].mean(),inplace=True)\n    \n#imputing Embarked column in traing dataset\ntrain['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)\n\n#imputing Fare column in testing dataset\ntest['Fare'].fillna(test['Fare'].mode()[0],inplace=True)\n\n#Check After Imputation\nfor data in dataset:\n    data=data.astype(int)\n    data.info()\n    print('========================================')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Applying XGBoost Classifier Model**","metadata":{}},{"cell_type":"code","source":"X_train=train.drop(columns='Survived',axis=1)\nY_train=train['Survived']\n\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier(objective='binary:logistic',booster = 'gbtree',eval_metric='logloss', gamma=5,learning_rate = 0.1, max_depth = 5, n_estimators = 100,colsample_bytree=1)\nxgb.fit(X_train, Y_train)\npredictions_xgb=xgb.predict(test)\n\n#feature importance graph\nfrom xgboost import plot_importance\nplot_importance(xgb)\nplt.show()\n\nSurvived=pd.Series(predictions_xgb,name='Survived')\nans=pd.concat([test['PassengerId'],Survived],axis=1)\nans.to_csv('XGB_Ans.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We can observe from above feature importance graph that PClass has highest importance.","metadata":{}},{"cell_type":"markdown","source":"# **Do upvote if you find it useful!**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}