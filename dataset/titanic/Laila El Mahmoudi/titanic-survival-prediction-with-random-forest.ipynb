{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![ ](https://scontent-arn2-2.xx.fbcdn.net/v/t1.0-9/57429716_2030860760555937_2750062083545497600_n.jpg?_nc_cat=100&ccb=2&_nc_sid=8bfeb9&_nc_ohc=y5d_WudgJy0AX9PNi5o&_nc_ht=scontent-arn2-2.xx&oh=a630ca82a715594c37e77c981b2f0b12&oe=6004F26F)\n                                   ","metadata":{}},{"cell_type":"markdown","source":"\n 1. EXPLORATORY DATA ANALYSIS\n   \n   - 1.1 Libraries\n   \n   - 1.2 Acquire the data\n  \n   - 1.3 Descriptive statistics\n  \n   - 1.4 Data visualisation\n   \n\n2. Feature Engineering\n\n   - 2.1 Filling missing Values\n  \n   - 2.2 Binning the categorical features\n  \n   - 2.3 Creating New Features\n   \n   - 2.4 Removing irrelevant variables\n   \n   - 2.4 Creating dummy variables\n   \n  \n\n3. Pre-Modeling Tasks\n\n\n   -  3.1 Defining Features in Training/Test Set\n   \n   -  3.2 Splitting the dataset\n   \n\n4. Modeling\n \n  \n   - Random Forest Model\n   \n   \n5. Evaluating the performance of the model\n     \n     - Confusion Matrix\n     - Classificarion Report\n     - Accuracy Score\n     - Precision Score\n     - ROC Curve\n     \n6. Submission\n\n\n- Useful resources\n  ","metadata":{}},{"cell_type":"markdown","source":"# 1. EXPLORATORY DATA ANALYSIS","metadata":{}},{"cell_type":"markdown","source":"\n ## Libraries ðŸ“š","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \nimport pandas_profiling\nimport matplotlib.pyplot as plt \nimport plotly.express as px \nimport seaborn as sns \nsns.set()\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder   \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n    \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report, balanced_accuracy_score\n\n\n\n# Color Palette\n\ncustom_colors = [\"#85CEDA\",\"#D2A7D8\", \"#A67BC5\", \"#BB1C8B\", \"#05A4C0\"]\ncustomPalette = sns.set_palette(sns.color_palette(custom_colors))\n\n# Set size\n\nsns.palplot(sns.color_palette(custom_colors),size=1)\nplt.tick_params(axis='both', labelsize=0, length = 0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Acquire data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/titanic/train.csv\")\ntest  = pd.read_csv(\"../input/titanic/test.csv\")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Variables** ","metadata":{}},{"cell_type":"markdown","source":"-`PassengerId` is the unique id of the row and it doesn't have any effect on target\n\n- `Name` \n\n- `Sex` \n\n- `Age`\n\n-`Survived` is the target variable we are trying to predict (0 or 1):\n     \n      1 = Survived\n      0 = Not Survived\n-`Pclass` (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature which has 3 unique values (1, 2 or 3):\n      \n      1 = Upper Class\n      2 = Middle Class\n      3 = Lower Class\n\n-`SibSp` is the total number of the passengers' siblings and spouse.\n\n-`Parch` is the total number of the passengers' parents and children.\n\n-`Ticket` is the ticket number of the passenger.\n\n-`Fare` is the passenger fare.\n\n-`Cabin` is the cabin number of the passenger.\n\n-`Embarked` is port of embarkation and it is a categorical feature which has 3 unique values (C, Q or S):\n      \n     C = Cherbourg\n     Q = Queenstown\n     S = Southampton","metadata":{}},{"cell_type":"markdown","source":"### 1.3 Descriptive Statistics","metadata":{}},{"cell_type":"markdown","source":"* So first we need to know **which variables are available in the dataset** ?","metadata":{}},{"cell_type":"code","source":"print (train.columns.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Categorical Features** : Survived,Embarked and Sex \n Ordinal: Pclass.","metadata":{}},{"cell_type":"markdown","source":"* **Numerical Features** : Continous: Age, Fare. Discrete: SibSp, Parch.","metadata":{}},{"cell_type":"markdown","source":"* **What are the data types for various features?**","metadata":{}},{"cell_type":"code","source":"train.info()\ntest.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The next step we'll do some descriptive statistics, this one helps us to describe and understand the features of a specific data by giving short summaries about the sample and measures of the data.\n","metadata":{}},{"cell_type":"markdown","source":"* **Statistical info about the numerical variables** :","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"survived_summary = train.groupby(\"Sex\")\nsurvived_summary.mean().reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Total samples are 891 or 40% of the actual number of passengers on board the Titanic (2,224).\n* only 38% passenger survived \n* 74% female passenger survived, and only 19% male passenger survived.\n* About 75% of passengers did not travel with their children or parents.\n* Around 30% of the passengers had siblings aboard\n","metadata":{}},{"cell_type":"markdown","source":"* **Checking for the correlation**","metadata":{}},{"cell_type":"code","source":"# Correlation Map\n\ntrain.corr\nf,ax = plt.subplots(figsize=(15,10))\nsns.heatmap(train.corr(), annot =True, linewidth =\".5\", fmt =\".2f\", cmap=custom_colors)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **pandas_profiling**","metadata":{}},{"cell_type":"code","source":"profile = pandas_profiling.ProfileReport(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profile","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.4 Data Visualization ðŸ“ŠðŸ“ˆ","metadata":{}},{"cell_type":"markdown","source":"* **Survived feature**","metadata":{}},{"cell_type":"markdown","source":"Distribution of survivals : 1 is for survival and 0 is for not","metadata":{}},{"cell_type":"code","source":"train[\"Survived\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(train.Survived.value_counts(), width=900, height=400)\nfig.update_traces(marker_color='orchid')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Survived by Age**","metadata":{}},{"cell_type":"code","source":"# BarPlot\n\n\nplt.figure(figsize=(10,8))\nplt.title(\"Survived people based on gender\")\nsns.barplot(x=\"Survived\",y=\"Age\", data =train,palette='mako_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Age**","metadata":{}},{"cell_type":"code","source":"def hist(x,title):\n    plt.figure(figsize = (10,8))\n    ax = sns.distplot(x, \n                 kde=False);\n    values = np.array([rec.get_height() for rec in ax.patches])\n    norm = plt.Normalize(values.min(), values.max())\n    colors = plt.cm.jet(norm(values))\n    for rec, col in zip(ax.patches, colors):\n        rec.set_color(col)\n    plt.title(title)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist(train['Age'],'Distribution of Age')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Fare**","metadata":{}},{"cell_type":"code","source":"hist(train['Fare'],'Distribution of Fare') \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Sex feature vs Survived feature**","metadata":{}},{"cell_type":"code","source":"# BarPlot\n\n# Set the width and the height of the figure\nplt.figure(figsize=(12,8))\n\n# Add the title\nplt.title(\"Survived people based on gender\")\n\n# Draw a barplot of survival people by sex\nsns.barplot(x=\"Sex\",y=\"Survived\", data =train,palette=(custom_colors))\n\n# Print percentage of males vs females that are survived \nprint(\"Percentage of females who survived :\",  train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\nprint (\"Percentage of males who survived :\",  train[\"Survived\"][train[\"Sex\"]==  'male'].value_counts(normalize= True)[1]*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# swarmplot\n\nplt.figure(figsize=(15,9))\n\nsns.swarmplot(x=train['Age'], y=train['Sex'], hue='Survived', data =train,palette =custom_colors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- According to this graph, we can notice that womens are more likely to survive.","metadata":{}},{"cell_type":"markdown","source":"* **PARCH feature vs Survived feature**","metadata":{}},{"cell_type":"code","source":"# Barplot\nplt.figure(figsize=(15,9))\nsns.barplot(x=\"Parch\", y=\"Survived\", data = train, palette=custom_colors)\nplt.show","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- People with less than four parents or childrens aboard more likely to survive.","metadata":{}},{"cell_type":"markdown","source":"* **SibSp Feature** ","metadata":{}},{"cell_type":"code","source":"# Barplot\n\nplt.figure(figsize=(15,9))\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train, palette= 'RdPu_r')\nplt.show","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- People with SibSp or spouses were less likely to survive, therefore people with no children were more less likely to survived than those with one children or two.","metadata":{}},{"cell_type":"markdown","source":"* **Embarked and fare features**","metadata":{}},{"cell_type":"markdown","source":"Let's now see how the embarkation site affects the survival.","metadata":{}},{"cell_type":"code","source":"# Violinplot\n\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x =\"Embarked\", y =\"Fare\", hue =\"Survived\", data=train, split =True , palette = {0: \"#3498db\", 1:\"#2ecc71\"});","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Passenger Class**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\nax = sns.countplot(x = 'Survived', hue = 'Pclass', data = train, palette = custom_colors)\nax.set_xlabel('Survived')\nax.set_title('Survival Rate for Passenger Classes', fontsize = 14, fontweight='bold');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"* **Inspect the missing values** ","metadata":{}},{"cell_type":"code","source":"# let's take more detaild look of what data is actually missing\n\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent_1 = train.isnull().sum()/train.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Missing values in train data**","metadata":{}},{"cell_type":"code","source":"train.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Missing values in test data**","metadata":{}},{"cell_type":"code","source":"test.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.1 Filling missing Values","metadata":{}},{"cell_type":"code","source":"#Age\n\n\ntrain[\"Age\"] = train[\"Age\"]. fillna(train[\"Age\"].mean())\n\ntest[\"Age\"]  = test[\"Age\"] . fillna(test[\"Age\"].mean())\n\n\n#Fare\n\ntest[\"Fare\"] = test [\"Fare\"]. fillna(test[\"Fare\"].mean())\n\n\n#Embarked\n\ntrain[\"Embarked\"].fillna(\"S\", inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Bining Categorical variables","metadata":{}},{"cell_type":"markdown","source":"\n* Before we fit the data into a machine learning algorithm, there is a step very crucial is that we make sure to encode categorical variables\n\n  correctly We will change Sex to binary, as either 1 for female and 0 for male. We do the same for Embarked. We do this same process on  \n\n  both the training and testing set to prepare our data for Machine Learning.","metadata":{}},{"cell_type":"markdown","source":"* **Preprocessing Sex**","metadata":{}},{"cell_type":"code","source":"train.loc[train[\"Sex\"] == \"male\" , \"Sex\"] = 0\ntrain.loc[train[\"Sex\"] == \"female\",\"Sex\"] = 1\n\n\ntest.loc[test[\"Sex\"] == \"male\", \"Sex\"] = 0\ntest.loc[test[\"Sex\"] == \"female\", \"Sex\"] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Processing Embarked**","metadata":{"trusted":true}},{"cell_type":"code","source":"train.loc[train[\"Embarked\"] == \"S\", \"Embarked\"] = 0\ntrain.loc[train[\"Embarked\"] == \"C\", \"Embarked\"] = 1\ntrain.loc[train[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n\n\ntest.loc[test[\"Embarked\"]  == \"S\", \"Embarked\"] = 0\ntest.loc[test[\"Embarked\"]  == \"C\", \"Embarked\"] = 1\ntest.loc[test[\"Embarked\"]  == \"Q\", \"Embarked\"] = 2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Creating New Features","metadata":{}},{"cell_type":"markdown","source":"- Then, introducing new features as Family size (to join these Parch and SibSp)","metadata":{}},{"cell_type":"markdown","source":"* **Family size**","metadata":{}},{"cell_type":"code","source":"train[\"FamSize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamSize\"]  =  test[\"SibSp\"] + test[\"Parch\"]  + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The next option is to cerate IsAlone feature to check wheter a person traveling alolne is more likely to survived or died","metadata":{}},{"cell_type":"markdown","source":"* **IsAlone**","metadata":{}},{"cell_type":"code","source":"train[\"IsAlone\"] = train.FamSize.apply(lambda x: 1 if x == 1 else 0)\ntest[\"IsAlone\"]  = test.FamSize.apply( lambda x: 1 if x == 1 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Extraction the passengers titles**","metadata":{"trusted":true}},{"cell_type":"markdown","source":"* If we have a quick look in the names of the passengers we will notice that each name has a title in it, so it can be a useful information \n\n  for our analyze. Therefore we can extract this title from the name of each passenger and then encode it like we did for Sex and Embarked.","metadata":{}},{"cell_type":"code","source":"for name in train[\"Name\"]:\n    train[\"Title\"] = train[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \nfor name in test[\"Name\"]:\n    test[\"Title\"] = test[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \ntitle_replacements = {\"Mlle\": \"Other\", \"Major\": \"Other\", \"Col\": \"Other\", \"Sir\": \"Other\", \"Don\": \"Other\", \"Mme\": \"Other\",\n          \"Jonkheer\": \"Other\", \"Lady\": \"Other\", \"Capt\": \"Other\", \"Countess\": \"Other\", \"Ms\": \"Other\", \"Dona\": \"Other\", \"Rev\": \"Other\", \"Dr\": \"Other\"}\n\ntrain.replace({\"Title\": title_replacements}, inplace=True)\ntest.replace({\"Title\": title_replacements}, inplace=True)\n\ntrain.loc[train[\"Title\"] == \"Miss\", \"Title\"] = 0\ntrain.loc[train[\"Title\"] == \"Mr\", \"Title\"] = 1\ntrain.loc[train[\"Title\"] == \"Mrs\", \"Title\"] = 2\ntrain.loc[train[\"Title\"] == \"Master\", \"Title\"] = 3\ntrain.loc[train[\"Title\"] == \"Other\", \"Title\"] = 4\n\ntest.loc[test[\"Title\"] == \"Miss\", \"Title\"] = 0\ntest.loc[test[\"Title\"] == \"Mr\", \"Title\"] = 1\ntest.loc[test[\"Title\"] == \"Mrs\", \"Title\"] = 2\ntest.loc[test[\"Title\"] == \"Master\", \"Title\"] = 3\ntest.loc[test[\"Title\"] == \"Other\", \"Title\"] = 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(set(train[\"Title\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.4 Removing irrelevant variables","metadata":{}},{"cell_type":"markdown","source":"* The next step is dropping the less relevant features because, The problem with less important features is that they create more noise\n \n  and actually take over the importance of real features like Sex and Pclass.","metadata":{}},{"cell_type":"code","source":"features_drop = ['Ticket', 'SibSp', 'Parch', \"Name\", \"Cabin\", \"Fare\", \"PassengerId\"]\n\ntrain = train.drop(features_drop, axis=1)\n\ntest = test.drop(features_drop, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.5 Creating dummy variables","metadata":{}},{"cell_type":"code","source":"train = pd.get_dummies(train, columns=['Pclass','Sex','Embarked','Title'], \n                       drop_first=False)\n\ntest = pd.get_dummies(test, columns=['Pclass','Sex','Embarked','Title'],\n                      drop_first=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3 Pre-Modeling Tasks","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Separating the independant and the dependant variable","metadata":{"trusted":true}},{"cell_type":"code","source":"X = train.drop('Survived', axis=1)\n\ny = train['Survived']\n\nX.shape,y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Splitting the training data \n","metadata":{}},{"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state= 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4- Modeling ","metadata":{}},{"cell_type":"markdown","source":"* **Training the Random Forest model** ","metadata":{}},{"cell_type":"code","source":"RF = RandomForestClassifier(criterion='gini',\n                                           n_estimators=1750,\n                                           max_depth=7,\n                                           min_samples_split=6,\n                                           min_samples_leaf=6,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=42,\n                                           n_jobs=-1,\n                                           verbose=1) \nRF.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Predict our model**","metadata":{}},{"cell_type":"code","source":"y_pred_train = RF.predict(X_train)\n\ny_pred_test = RF.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Accuracy of the model**","metadata":{}},{"cell_type":"code","source":"accu = RF.score(X_train, y_train)\nprint( \"Model Prediction Score\", (accu * 100).round(2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Training Accuracy\\ Testing Accuracy**","metadata":{}},{"cell_type":"code","source":"print(\"Training accuracy: \", accuracy_score(y_train, y_pred_train))\nprint(\"Testing accuracy: \", accuracy_score(y_test, y_pred_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5- Evaluating the performance of the model","metadata":{"trusted":true}},{"cell_type":"markdown","source":"* **Confusion Matrix**","metadata":{}},{"cell_type":"markdown","source":"![](https://i1.wp.com/interviewbubble.com/wp-content/uploads/2019/03/1pOtBHai4jFd-ujaNXPilRg.png?resize=936%2C340&ssl=1)","metadata":{}},{"cell_type":"code","source":"cm = np.array(confusion_matrix(y_test, y_pred_test, labels=[1,0]))\n\nconfusion_mat= pd.DataFrame(cm, index = [\"Not-Survived\", \"Survived\"],\n                           columns =[\"Predicted Not Survived\", \"Predicted Survived\"])\n\nconfusion_mat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(cm,annot=True,fmt='g',cmap='Set3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Accuracy_score**","metadata":{}},{"cell_type":"code","source":"accuracy_score(y_test, y_pred_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Precision_score**","metadata":{}},{"cell_type":"code","source":"precision_score(y_test, y_pred_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **classification_report**","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*** ROC Curve**","metadata":{}},{"cell_type":"markdown","source":"![](https://glassboxmedicine.files.wordpress.com/2019/02/roc-curve-v2.png?w=576)","metadata":{}},{"cell_type":"code","source":"fpr, tpr, _ = roc_curve(y_test, y_pred_test)\nroc_auc = auc(fpr, tpr)\nprint(\"\\nROC AUC on evaluation set\",roc_auc )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc,color=custom_colors[0])\nplt.plot([0, 1], [0, 1], 'k--',color=custom_colors[1])\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"passenger_IDs = pd.read_csv(\"/kaggle/input/titanic/test.csv\")[[\"PassengerId\"]].values\npreds = RF.predict(test.values)\npreds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = {'PassengerId': passenger_IDs.ravel(), 'Survived': preds}\ndf_predictions = pd.DataFrame(df).set_index(['PassengerId'])\ndf_predictions.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predictions.to_csv('/kaggle/working/Predictions.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Useful resources","metadata":{}},{"cell_type":"markdown","source":"- [How to Build a Machine Learning Model](https://towardsdatascience.com/how-to-build-a-machine-learning-model-439ab8fb3fb1)\n\n- [How to find optimal parameters using GridSearchCV?](https://www.dezyre.com/recipes/find-optimal-parameters-using-gridsearchcv)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}