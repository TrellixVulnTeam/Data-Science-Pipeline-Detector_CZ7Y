{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-17T08:10:28.2186Z","iopub.execute_input":"2022-02-17T08:10:28.218997Z","iopub.status.idle":"2022-02-17T08:10:28.258539Z","shell.execute_reply.started":"2022-02-17T08:10:28.218896Z","shell.execute_reply":"2022-02-17T08:10:28.257549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import & Explore Data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(r'../input/titanic/train.csv')\ntest_data = pd.read_csv(r'../input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.26091Z","iopub.execute_input":"2022-02-17T08:10:28.261544Z","iopub.status.idle":"2022-02-17T08:10:28.294322Z","shell.execute_reply.started":"2022-02-17T08:10:28.261495Z","shell.execute_reply":"2022-02-17T08:10:28.293354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.296252Z","iopub.execute_input":"2022-02-17T08:10:28.296512Z","iopub.status.idle":"2022-02-17T08:10:28.323855Z","shell.execute_reply.started":"2022-02-17T08:10:28.296479Z","shell.execute_reply":"2022-02-17T08:10:28.323178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The attributes have the following meaning:\n* **PassengerId**: a unique identifier for each passenger\n* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n* **Pclass**: passenger class.\n* **Name**, **Sex**, **Age**: self-explanatory\n* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n* **Parch**: how many children & parents of the passenger aboard the Titanic.\n* **Ticket**: ticket id\n* **Fare**: price paid (in pounds)\n* **Cabin**: passenger's cabin number\n* **Embarked**: where the passenger embarked the Titanic","metadata":{}},{"cell_type":"markdown","source":"### Set `Passengerid` column as the index column","metadata":{"execution":{"iopub.status.busy":"2022-01-31T04:24:35.806152Z","iopub.execute_input":"2022-01-31T04:24:35.806861Z","iopub.status.idle":"2022-01-31T04:24:35.81098Z","shell.execute_reply.started":"2022-01-31T04:24:35.806816Z","shell.execute_reply":"2022-01-31T04:24:35.809999Z"}}},{"cell_type":"code","source":"train_data = train_data.set_index(\"PassengerId\")\ntest_data = test_data.set_index(\"PassengerId\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.325266Z","iopub.execute_input":"2022-02-17T08:10:28.325716Z","iopub.status.idle":"2022-02-17T08:10:28.339628Z","shell.execute_reply.started":"2022-02-17T08:10:28.325683Z","shell.execute_reply":"2022-02-17T08:10:28.338344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.3428Z","iopub.execute_input":"2022-02-17T08:10:28.343731Z","iopub.status.idle":"2022-02-17T08:10:28.366469Z","shell.execute_reply.started":"2022-02-17T08:10:28.34368Z","shell.execute_reply":"2022-02-17T08:10:28.365575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General Information\ntrain_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.368346Z","iopub.execute_input":"2022-02-17T08:10:28.368872Z","iopub.status.idle":"2022-02-17T08:10:28.390792Z","shell.execute_reply.started":"2022-02-17T08:10:28.368824Z","shell.execute_reply":"2022-02-17T08:10:28.389921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking missing values\ntrain_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.392492Z","iopub.execute_input":"2022-02-17T08:10:28.392985Z","iopub.status.idle":"2022-02-17T08:10:28.404559Z","shell.execute_reply.started":"2022-02-17T08:10:28.392939Z","shell.execute_reply":"2022-02-17T08:10:28.403462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Cabin** has 687 missing values out of 891 instances. Its better to exclude the column\n- **Embarked** has only 2 missing values. We can easily replace them with `mode` of the variable without much side-effect.\n- **Age** is complicated. It has **177 missing values** out of 891. If we replaced missing values with some numbers, we risk adding bias to our model. Excluding this variable without good justification would risk losing some important information from this variable. We will dig further into this variable later to make our decision.\n<br></br>For now, we will remove **Cabin** from our training data.","metadata":{}},{"cell_type":"code","source":"train_data.drop(columns=\"Cabin\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.406161Z","iopub.execute_input":"2022-02-17T08:10:28.406656Z","iopub.status.idle":"2022-02-17T08:10:28.416545Z","shell.execute_reply.started":"2022-02-17T08:10:28.406609Z","shell.execute_reply":"2022-02-17T08:10:28.415798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns \"Name\" & 'Ticket' are identity data of passengers its not going to help\n # us predict their survivorship. So we're going to remove them\n    # from our training data\ntrain_data.drop(columns = ['Name', 'Ticket'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.418236Z","iopub.execute_input":"2022-02-17T08:10:28.419173Z","iopub.status.idle":"2022-02-17T08:10:28.427729Z","shell.execute_reply.started":"2022-02-17T08:10:28.419081Z","shell.execute_reply":"2022-02-17T08:10:28.426964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.429049Z","iopub.execute_input":"2022-02-17T08:10:28.429729Z","iopub.status.idle":"2022-02-17T08:10:28.441584Z","shell.execute_reply.started":"2022-02-17T08:10:28.429679Z","shell.execute_reply":"2022-02-17T08:10:28.440348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data distribution of each pair of numerical variables\nimport seaborn as sns\nsns.pairplot(train_data, hue = 'Survived')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:28.443386Z","iopub.execute_input":"2022-02-17T08:10:28.444504Z","iopub.status.idle":"2022-02-17T08:10:37.429811Z","shell.execute_reply.started":"2022-02-17T08:10:28.444454Z","shell.execute_reply":"2022-02-17T08:10:37.42894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select only numerical variables\nX_train_num = train_data.select_dtypes(include=np.number) # Numerical data\n\n# Survived is the label so we want the corr to be high\n# For other features, we want them to have low correlation\n# X_train_num.drop('Survived',axis = 1, inplace= True)\n\n# annot = True -> annotate corr value in each cell\nsns.heatmap(X_train_num.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:37.4317Z","iopub.execute_input":"2022-02-17T08:10:37.432327Z","iopub.status.idle":"2022-02-17T08:10:37.878053Z","shell.execute_reply.started":"2022-02-17T08:10:37.432285Z","shell.execute_reply":"2022-02-17T08:10:37.876913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deselect numerical variables (Categorical variables)\nX_train_cat = train_data.select_dtypes(exclude=np.number) # Categories data\nX_train_cat.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:37.879789Z","iopub.execute_input":"2022-02-17T08:10:37.880735Z","iopub.status.idle":"2022-02-17T08:10:37.898862Z","shell.execute_reply.started":"2022-02-17T08:10:37.880685Z","shell.execute_reply":"2022-02-17T08:10:37.897648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Data (Build a pipeline)","metadata":{}},{"cell_type":"markdown","source":"We want to treat numerical & categorical data differently.<br></br>\n**Numerical Attributes:** we can replace its missing values with averages and might want to normalize the numbers so that our estimators won't bias towards larger numbers ","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing Numerical Attributes","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n# `imputer` Replace missing values with mean\n# `scaler` normalizes (Standardization) numerical attributes\nnum_pipeline = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n        (\"scaler\", StandardScaler())\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:37.903728Z","iopub.execute_input":"2022-02-17T08:10:37.90425Z","iopub.status.idle":"2022-02-17T08:10:38.231823Z","shell.execute_reply.started":"2022-02-17T08:10:37.904214Z","shell.execute_reply":"2022-02-17T08:10:38.230793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Categorical Attributes","metadata":{}},{"cell_type":"markdown","source":"**Categorical Attributes:** We cannot replace its missing values with sample average because it doesn't make sense to have 0.65 as gender even if you convert male to '0' and female to '1'. So we're going to replace missing values with `mode` instead.\n<br></br>\nWe need to normalize numerical attributes. For categorical attributes, we need to **encode** them. Some estimators like `logistic regression` takes numerical attributes as predictors even though it is a classifier. i.e. these models cannot take `male` or `female` as input so we need to convert `male -> 0` and `female -> 1`.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# `imputer` Replaces missing values with mode\n# `cat_encoder` encoding is needed to feed categorical data into many scikit-learn estimators like linear models  \ncat_pipeline = Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:38.233384Z","iopub.execute_input":"2022-02-17T08:10:38.233633Z","iopub.status.idle":"2022-02-17T08:10:38.23898Z","shell.execute_reply.started":"2022-02-17T08:10:38.233605Z","shell.execute_reply":"2022-02-17T08:10:38.238105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Selecting features","metadata":{}},{"cell_type":"markdown","source":"Let's choose the attributes we're going to feed into the preprocessing pipelines ","metadata":{}},{"cell_type":"code","source":"# Define numerical attributes\n # Take columns where data type = numerical\nX_train_num = train_data.select_dtypes(include=np.number)\nX_train_num","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:38.240493Z","iopub.execute_input":"2022-02-17T08:10:38.241396Z","iopub.status.idle":"2022-02-17T08:10:38.266997Z","shell.execute_reply.started":"2022-02-17T08:10:38.241345Z","shell.execute_reply":"2022-02-17T08:10:38.265783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Although Pclass & Survived are int, let's remove them from numerical attributes \nX_train_num = train_data.select_dtypes(include=np.number)\nX_train_num.drop(['Pclass','Survived'],axis = 1, inplace= True)\nX_train_num","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:38.268583Z","iopub.execute_input":"2022-02-17T08:10:38.268828Z","iopub.status.idle":"2022-02-17T08:10:38.293955Z","shell.execute_reply.started":"2022-02-17T08:10:38.2688Z","shell.execute_reply":"2022-02-17T08:10:38.293182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What about 'Age'? We wasn't sure whether we want to include it in our training set.","metadata":{}},{"cell_type":"markdown","source":"## Analysis on 'Age'","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,12))\nplt.subplot(2,2,1)\nsns.distplot(train_data[train_data['Survived']==0]['Age'])\nplt.title('1. Age distibution (Not Survived)')\n\nplt.subplot(2,2,2)\nsns.distplot(train_data[train_data['Survived']==1]['Age'])\nplt.title('2. Age distibution (Survived)')\n\nplt.subplot(2,2,3)\nsns.distplot(train_data[train_data['Survived']==0]['Age'], label ='Not survived')\nsns.distplot(train_data[train_data['Survived']==1]['Age'], label ='Survived')\nplt.legend()\nplt.title('3. Overlapped Age distibution')\n\nplt.subplot(2,2,4)\nsns.distplot(train_data['Age'])\nplt.title('4. Age distibution (Survived & Not Survived)')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:38.295155Z","iopub.execute_input":"2022-02-17T08:10:38.295786Z","iopub.status.idle":"2022-02-17T08:10:39.482208Z","shell.execute_reply.started":"2022-02-17T08:10:38.29575Z","shell.execute_reply":"2022-02-17T08:10:39.48102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pay attention to the shape of distribution curve for \"Survived\" and \"Not Survived\". Can we make any interesting **hypothesis** on the effect of 'Age' on probability of survival?\n<br></br>\n- 0 < Age < 5 has higher chances of survival in figure 2 (f(x) > 0.020) compared to figure 4 (f(x) around 0.015). This could mean that babies were prioritized to broad on a safety boat.\n- Other parts of the distribution were more or less similar with passengers' age distribution.\n- We might be better (or not) if we just add a column to determine if age < 10. \n- But here we would just keep this column and replace the missing values with averages. Also missing values can be replaced with conditional mean imputation. (i.e. average age given passenger's sex.)\n","metadata":{}},{"cell_type":"code","source":"num_attribs = X_train_num.columns.tolist()\nnum_attribs","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:39.484063Z","iopub.execute_input":"2022-02-17T08:10:39.485001Z","iopub.status.idle":"2022-02-17T08:10:39.490465Z","shell.execute_reply.started":"2022-02-17T08:10:39.484935Z","shell.execute_reply":"2022-02-17T08:10:39.489604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert \"Pclass\" into an object instead of int\ntrain_data['Pclass'] = train_data['Pclass'].astype(str)\ntest_data['Pclass'] = test_data['Pclass'].astype(str)\nX_train_cat = train_data.select_dtypes(exclude=np.number)\nX_train_cat","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:39.492024Z","iopub.execute_input":"2022-02-17T08:10:39.492278Z","iopub.status.idle":"2022-02-17T08:10:39.518763Z","shell.execute_reply.started":"2022-02-17T08:10:39.492248Z","shell.execute_reply":"2022-02-17T08:10:39.517667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_attribs = X_train_cat.columns.tolist()\ncat_attribs","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:39.520344Z","iopub.execute_input":"2022-02-17T08:10:39.520566Z","iopub.status.idle":"2022-02-17T08:10:39.527269Z","shell.execute_reply.started":"2022-02-17T08:10:39.52054Z","shell.execute_reply":"2022-02-17T08:10:39.526203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\npreprocess_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", cat_pipeline, cat_attribs),\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:39.529748Z","iopub.execute_input":"2022-02-17T08:10:39.530115Z","iopub.status.idle":"2022-02-17T08:10:39.54752Z","shell.execute_reply.started":"2022-02-17T08:10:39.530071Z","shell.execute_reply":"2022-02-17T08:10:39.546456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Apply preprocessing_pipeline.fit_transform()","metadata":{}},{"cell_type":"code","source":"X_train = preprocess_pipeline.fit_transform(\n    train_data[num_attribs + cat_attribs])\nX_train","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:39.549355Z","iopub.execute_input":"2022-02-17T08:10:39.549805Z","iopub.status.idle":"2022-02-17T08:10:39.57638Z","shell.execute_reply.started":"2022-02-17T08:10:39.54976Z","shell.execute_reply":"2022-02-17T08:10:39.575651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define our target\ny_train = train_data['Survived']\ny_train","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:39.57778Z","iopub.execute_input":"2022-02-17T08:10:39.57825Z","iopub.status.idle":"2022-02-17T08:10:39.584893Z","shell.execute_reply.started":"2022-02-17T08:10:39.57821Z","shell.execute_reply":"2022-02-17T08:10:39.584324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:39.586247Z","iopub.execute_input":"2022-02-17T08:10:39.586675Z","iopub.status.idle":"2022-02-17T08:10:39.600494Z","shell.execute_reply.started":"2022-02-17T08:10:39.586642Z","shell.execute_reply":"2022-02-17T08:10:39.599635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# Defining grid search parameters\nparam = [\n    {'n_estimators': [100, 200, 300, 400], \n     'max_depth': [6, 8, 10, 12, 15, 20], \n     'max_leaf_nodes': [15, 20, 25]}, \n]\n# Random forest classifier\nrf = RandomForestClassifier()\n# Grid Search with 5-fold cross validation \ngs_rf = GridSearchCV(rf, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_rf.fit(X_train, y_train)\ngs_rf.best_estimator_, gs_rf.score(X_valid, y_valid), gs_rf.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:10:39.601952Z","iopub.execute_input":"2022-02-17T08:10:39.602813Z","iopub.status.idle":"2022-02-17T08:11:54.076544Z","shell.execute_reply.started":"2022-02-17T08:10:39.602765Z","shell.execute_reply":"2022-02-17T08:11:54.075241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing best parameters\nrf_best = gs_rf.best_estimator_\nrf_score = gs_rf.score(X_valid, y_valid)\nprint(\"Best score = \", rf_score)\nprint(\"Best parameters = \",rf_best)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:11:54.078614Z","iopub.execute_input":"2022-02-17T08:11:54.07888Z","iopub.status.idle":"2022-02-17T08:11:54.10121Z","shell.execute_reply.started":"2022-02-17T08:11:54.07885Z","shell.execute_reply":"2022-02-17T08:11:54.100232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nparam = [\n    {\n        'kernel': ['rbf'], 'C': [0.3, 1, 2, 3, 4, 6, 8], \n        'gamma': [0.001, 0.003, 0.01, 0.03, 0, 0.1, 0.3, 1, 3, 10]\n    }, \n]\n\nsvc = SVC(probability = True)\ngs_svc = GridSearchCV(svc, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_svc.fit(X_train, y_train)\ngs_svc.best_estimator_, gs_svc.score(X_valid, y_valid), gs_svc.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:11:54.102508Z","iopub.execute_input":"2022-02-17T08:11:54.102752Z","iopub.status.idle":"2022-02-17T08:12:03.400044Z","shell.execute_reply.started":"2022-02-17T08:11:54.102723Z","shell.execute_reply":"2022-02-17T08:12:03.399099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing best parameters\nsvc_best = gs_svc.best_estimator_\nsvc_score = gs_svc.score(X_valid, y_valid)\nprint(\"Best score = \", svc_score)\nprint(\"Best parameters = \",svc_best)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:03.401429Z","iopub.execute_input":"2022-02-17T08:12:03.40224Z","iopub.status.idle":"2022-02-17T08:12:03.411181Z","shell.execute_reply.started":"2022-02-17T08:12:03.402207Z","shell.execute_reply":"2022-02-17T08:12:03.410315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extra Trees Classifier (Extremely Randomized Trees)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nparam = [\n    {'n_estimators': range(8, 28, 4), \n     'max_depth': range(4, 20, 4),\n     'max_leaf_nodes': range(4, 20, 4),\n    }\n]\n\net = ExtraTreesClassifier()\ngs_et = GridSearchCV(et, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_et.fit(X_train, y_train)\ngs_et.best_estimator_, gs_et.score(X_valid, y_valid), gs_et.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:03.412644Z","iopub.execute_input":"2022-02-17T08:12:03.413005Z","iopub.status.idle":"2022-02-17T08:12:07.569411Z","shell.execute_reply.started":"2022-02-17T08:12:03.412972Z","shell.execute_reply":"2022-02-17T08:12:07.568606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Showing best parameters\net_best = gs_et.best_estimator_\net_score = gs_et.score(X_valid, y_valid)\nprint(\"Best score = \", et_score)\nprint(\"Best parameters = \",et_best)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:07.570553Z","iopub.execute_input":"2022-02-17T08:12:07.571495Z","iopub.status.idle":"2022-02-17T08:12:07.580672Z","shell.execute_reply.started":"2022-02-17T08:12:07.571459Z","shell.execute_reply":"2022-02-17T08:12:07.580003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n\nlr.score(X_valid, y_valid), lr.score(X_train, y_train)\nlr_score = lr.score(X_valid, y_valid)\nprint(\"Best score = \", lr_score)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:07.582041Z","iopub.execute_input":"2022-02-17T08:12:07.582628Z","iopub.status.idle":"2022-02-17T08:12:07.619411Z","shell.execute_reply.started":"2022-02-17T08:12:07.582583Z","shell.execute_reply":"2022-02-17T08:12:07.618322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Selection","metadata":{}},{"cell_type":"markdown","source":"## Accuracy across different fold of cross-validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nforest_scores = cross_val_score(rf_best, X_train, y_train, cv=10)\nsvc_scores = cross_val_score(svc_best, X_train, y_train, cv=10)\net_scores = cross_val_score(et_best, X_train, y_train, cv=10)\nlr_scores = cross_val_score(lr, X_train, y_train, cv=10)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:07.626283Z","iopub.execute_input":"2022-02-17T08:12:07.62986Z","iopub.status.idle":"2022-02-17T08:12:10.696401Z","shell.execute_reply.started":"2022-02-17T08:12:07.629775Z","shell.execute_reply":"2022-02-17T08:12:10.695387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 5))\nplt.plot([1]*10, forest_scores, \".\")\nplt.plot([2]*10, svc_scores, \".\")\nplt.plot([3]*10, et_scores, \".\")\nplt.plot([4]*10, lr_scores, \".\")\nplt.boxplot([forest_scores, svc_scores, et_scores, lr_scores ], \n            labels=(\"Random Forest\", \"SVM\", \"Extra Trees\", \"Logistic Regression\"))\nplt.ylabel(\"Accuracy\", fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:10.697827Z","iopub.execute_input":"2022-02-17T08:12:10.69896Z","iopub.status.idle":"2022-02-17T08:12:10.931383Z","shell.execute_reply.started":"2022-02-17T08:12:10.698921Z","shell.execute_reply":"2022-02-17T08:12:10.930482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- SVM is slightly better than random forest since it has higher upside while almost the same downside across all folds of cross-validation","metadata":{}},{"cell_type":"markdown","source":"## Accuracy on validation data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nmodels = [\"Random Forest\", \"SVM\", \"Extra Trees\", \"Logistic Regression\"]\nscores = [rf_score, svc_score, et_score, lr_score]\nax.bar(models,scores)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:10.933595Z","iopub.execute_input":"2022-02-17T08:12:10.934105Z","iopub.status.idle":"2022-02-17T08:12:11.115987Z","shell.execute_reply.started":"2022-02-17T08:12:10.934053Z","shell.execute_reply":"2022-02-17T08:12:11.115113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Here, random forest is slightly better than SVM with higher accuracy on validation data","metadata":{}},{"cell_type":"markdown","source":"# Final Model","metadata":{}},{"cell_type":"markdown","source":"- Actually Random Forest & SVM are equally good on their performance.\n- So it is okay to choose either one.\n- I would choose SVM from our conclusion in `Accuracy across different fold of cross-validation` session","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Transform test data\nX_test = preprocess_pipeline.transform(test_data[num_attribs + cat_attribs])\npredictions = svc_best.predict(X_test)\nsub = pd.read_csv('../input/titanic/gender_submission.csv')\nsub['Survived'] = predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:11.117205Z","iopub.execute_input":"2022-02-17T08:12:11.117434Z","iopub.status.idle":"2022-02-17T08:12:11.146144Z","shell.execute_reply.started":"2022-02-17T08:12:11.117407Z","shell.execute_reply":"2022-02-17T08:12:11.145225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('./submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:11.149778Z","iopub.execute_input":"2022-02-17T08:12:11.150277Z","iopub.status.idle":"2022-02-17T08:12:11.161515Z","shell.execute_reply.started":"2022-02-17T08:12:11.150231Z","shell.execute_reply":"2022-02-17T08:12:11.160207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"./submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T08:12:11.163107Z","iopub.execute_input":"2022-02-17T08:12:11.163564Z","iopub.status.idle":"2022-02-17T08:12:11.17727Z","shell.execute_reply.started":"2022-02-17T08:12:11.163532Z","shell.execute_reply":"2022-02-17T08:12:11.176388Z"},"trusted":true},"execution_count":null,"outputs":[]}]}