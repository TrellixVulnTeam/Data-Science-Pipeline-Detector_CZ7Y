{"cells":[{"metadata":{},"cell_type":"markdown","source":"# INRODUCTION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The objective of this analysis is to determine that on which variable of our dataset the survival of titanician are more dependent, how they are been survived,on which basis they have been survived or died, here we are also analysing by use of data Visualization for geeting more clear idea, we are applying different types of classifiaction model for predicting best outcome and at last we are making ROC for analysing that which classification model is best.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# CONTENTS","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. Importing important libraries\n2. Reading the dataset\n3. Exploratory data analysis\n4. Data Visualization\n5. Data pre-processing\n6. Building Model\n7. Classifications model\n8. Plotting ROC( Receiver Operating Characteristic)curve\n9. Creating submission file\n10. Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing important libraries...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Firstly we are importing the libraries which are important to do analysis.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# data analysis libraries\nimport pandas as pd\nimport numpy as np\n# visualization libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n# ignore warnings library\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading the dataset...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Train= pd.read_csv(\"../input/titanic/train.csv\")\nTest= pd.read_csv(\"../input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory data analysis...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Train.isnull().sum())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that except for the above mentioned missing values, no NaN values exist.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that except for the above mentioned missing values, no NaN values exist.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train shape:\", Train.shape)\nprint(\"Test shape:\", Test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see that there are 891 rows and 12 columns in training dataset,\nand there are 481 rows and 12 columns in testing dataset.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing first five lines of our training dataset\nTrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing first five lines of our testing dataset\nTest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we are calculating summary of our train dataset\nTrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we are calculating summary of our test dataset\nTest.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Sex feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting bar plot for sex vs survived\nsns.barplot(x=\"Sex\",y=\"Survived\",data=Train)\n# printing survival percentage of female\nprint(\"Percentage of females who survived:\", \n      Train[\"Survived\"][Train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\n# printing survival percentage of male\nprint(\"Percentage of males who survived:\", \n      Train[\"Survived\"][Train[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot shows that women are more likley survived then men.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting bar plot for SibSp vs Survived\nsns.barplot(x=\"SibSp\",y=\"Survived\",data= Train)\n# printing survival percentage of sibsp\nprint(\"Percentage of Sibsp- 0 who survived:\", \n      Train[\"Survived\"][Train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Sibsp- 1 who survived:\", \n      Train[\"Survived\"][Train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Sibsp- 2 who survived:\", \n      Train[\"Survived\"][Train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Sibsp- 3 who survived:\", \n      Train[\"Survived\"][Train[\"SibSp\"] == 3].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Sibsp- 4 who survived:\", \n      Train[\"Survived\"][Train[\"SibSp\"] == 4].value_counts(normalize = True)[1]*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThe plot confirms a person aboarded with more than 2 siblings or spouse more likely survived\nwhereas a person aboarded without siblings or spouse more likely dead","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting bar plot for Pclass vs Survived\nsns.barplot(x=\"Pclass\",y=\"Survived\",data= Train)\n# printing survival percentage of Pclass\nprint(\"Percentage of pclass- 1 who survived:\", \n      Train[\"Survived\"][Train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Pclass- 2 who survived:\", \n      Train[\"Survived\"][Train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Pclass- 3 who survived:\", \n      Train[\"Survived\"][Train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot confirms 1st class more likely survivied than other classes whereas\n 3rd class more likely dead than other classes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting bar plot for Parch vs Survived\nsns.barplot(x=\"Parch\",y=\"Survived\",data= Train)\n# printing survival percentage of Parch\nprint(\"Percentage of parch- 0 who survived:\", \n      Train[\"Survived\"][Train[\"Parch\"] == 0].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Parch- 1 who survived:\", \n      Train[\"Survived\"][Train[\"Parch\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Parch- 2 who survived:\", \n      Train[\"Survived\"][Train[\"Parch\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Parch- 3 who survived:\", \n      Train[\"Survived\"][Train[\"Parch\"] == 3].value_counts(normalize = True)[1]*100)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot confirms a person aboarded with more than 2 parents or children are more likely survived whereas a person aboarded alone more likely dead.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#sort the ages into logical categories\nTrain[\"Age\"] = Train[\"Age\"].fillna(-0.5)\nTest[\"Age\"] = Test[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\nTrain['AgeGroup'] = pd.cut(Train[\"Age\"], bins, labels = labels)\nTest['AgeGroup'] = pd.cut(Test[\"Age\"], bins, labels = labels)\n\n#draw a bar plot of Age vs. survival\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=Train)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Babies are more likely to survive than any other age group.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting bar plot for Embarked vs Survived\nsns.barplot(x=\"Embarked\",y=\"Survived\",data= Train)\n# printing survival percentage of Embarked\nprint(\"Survived :\\n\",Train[Train['Survived']==1]['Embarked'].value_counts())\nprint(\"Dead:\\n\",Train[Train['Survived']==0]['Embarked'].value_counts())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThe plot confirms a person aboarded from C slightly more likely survived,a person aboarded from Q more likely dead and a person aboarded from S more likely dead.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data pre-processing...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**cabin feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will first drop tha cabin column because there is not need of this in our prediction.\nTrain = Train.drop([\"Cabin\"],axis=1)\nTest = Test.drop([\"Cabin\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ticket feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will also drop the Ticket column because there is not need of this in our prediction\nTrain = Train.drop([\"Ticket\"],axis=1)\nTest = Test.drop([\"Ticket\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embarked feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we will fill in the missing values in the Embarked feature\nprint(\"Number of people embarking in Southampton (S):\")\nsouthampton = Train[Train[\"Embarked\"] == \"S\"].shape[0]\nprint(southampton)\n\nprint(\"Number of people embarking in Cherbourg (C):\")\ncherbourg = Train[Train[\"Embarked\"] == \"C\"].shape[0]\nprint(cherbourg)\n\nprint(\"Number of people embarking in Queenstown (Q):\")\nqueenstown = Train[Train[\"Embarked\"] == \"Q\"].shape[0]\nprint(queenstown)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above it is clear that more no of people are embarking in Southamoton, so we will fill NaN value with Southamonton.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we will replace missing value with Southampton\nTrain = Train.fillna({\"Embarked\": \"S\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we'll fill in the missing values in the Age feature. Since a higher percentage of values are missing, it would be not be correct to fill all of them with the same value (as we did with Embarked). Instead, let's try to find a way to predict the missing ages.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Age feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we are combining our dataset\ntrain_test_data = [Train,Test]\nfor dataset in train_test_data:\n    dataset[\"Title\"] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"Title\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test[\"Title\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Age feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map each of title groups to numerical values.\ntitle_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2,\n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset[\"Title\"].map(title_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Title\",y=\"Survived\",data= Train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot shows that title with mr and master are less survived where as miss and mrs are survived most.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor x in range(len(Train[\"Age\"])):\n    if Train[\"Age\"][x] == \"Unknown\":\n        Train[\"Age\"][x] = title_mapping[Train[\"Title\"][x]]\n        \nfor x in range(len(Test[\"Age\"])):\n    if Test[\"Age\"][x] == \"Unknown\":\n        Test[\"Age\"][x] = title_mapping[Test[\"Title\"][x]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\nTrain['AgeGroup'] = Train['AgeGroup'].map(age_mapping)\nTest['AgeGroup'] = Test['AgeGroup'].map(age_mapping)\n\nTrain.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"AgeGroup\"].fillna(Train.groupby(\"Title\")[\"AgeGroup\"].transform(\"median\"), inplace= True)\nTest[\"AgeGroup\"].fillna(Test.groupby('Title')['AgeGroup'].transform(\"median\"), inplace= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sex mapping**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we are mapping sex feature into numerical values\nsex_mapping = {\"male\": 0, \"female\": 1}\nTrain['Sex'] = Train['Sex'].map(sex_mapping)\nTest['Sex'] = Test['Sex'].map(sex_mapping)\n\nTrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Name Feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we are removing name column because it is not playing important role in doing prediction\nTrain = Train.drop(['Name'], axis = 1)\nTest = Test.drop(['Name'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Embarked feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we are mapping embarked feature into numerical values\nembarked_mapping = {\"S\":1,\"C\":2,\"Q\":3}\nTrain[\"Embarked\"] = Train[\"Embarked\"].map(embarked_mapping)\nTest[\"Embarked\"] = Test[\"Embarked\"].map(embarked_mapping)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fare Feature**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill in missing Fare value in test set based on mean fare for that Pclass \nfor x in range(len(Test[\"Fare\"])):\n    if pd.isnull(Test[\"Fare\"][x]):\n        pclass = Test[\"Pclass\"][x] #Pclass = 3\n        Test[\"Fare\"][x] = round(Train[Train[\"Pclass\"] == pclass][\"Fare\"].mean(), 4)\n        \n#map Fare values into groups of numerical values\nTrain['FareBand'] = pd.qcut(Train['Fare'], 4, labels = [1, 2, 3, 4])\nTest['FareBand'] = pd.qcut(Test['Fare'], 4, labels = [1, 2, 3, 4])\n\n#drop Fare values\nTrain = Train.drop(['Fare'], axis = 1)\nTest = Test.drop(['Fare'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train = Train.drop([\"Age\"],axis=1)\nTest = Test.drop([\"Age\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Model...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = Train.iloc[:, 2:10].values\ny = Train.iloc[:, 1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spliting the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.25,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Models...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"LOGISTIC REGRESSION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression (solver='liblinear', random_state=0)\nclassifier.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we are calculating accuracy rate of our model\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_lg= accuracy_score(y_test, y_pred)\nacc_lg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"K NEAREST NEIGHBORS","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifierr = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n                     weights='uniform')\nclassifierr.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifierr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_knn = accuracy_score(y_test, y_pred)\nacc_knn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SUPPORT VECTOR MACHINE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier1 = SVC(kernel=\"linear\",random_state=0,C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='scale',\n    max_iter=-1, probability=True,shrinking=True, tol=0.001,\n    verbose=False)\nclassifier1.fit(x_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier1.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_svm = accuracy_score(y_test, y_pred)\nacc_svm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KERNEL SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier2 = SVC(kernel=\"rbf\",random_state=0,probability=True)\nclassifier2.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier2.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\nacc_kernel = accuracy_score(y_test,y_pred)\nacc_kernel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NAIVE BAYES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclassifier3 = GaussianNB()\nclassifier3.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier3.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\nacc_naive = accuracy_score(y_test,y_pred)\nacc_naive","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DECISION TREE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier4 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier4.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier4.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\nacc_dt = accuracy_score(y_test,y_pred)\nacc_dt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RANDOM FOREST","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier5 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier5.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier5.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\nprint(cm)\nacc_rf = accuracy_score(y_test,y_pred)\nacc_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': [\"LOGISTIC REGRESSION\",\"K NEAREST NEIGHBORS\",\"SUPPORT VECTOR MACHINE\",\"KERNEL SVM\",\"NAIVE BAYES\",\"DECISION TREE\",\"RANDOM FOREST\"],\n    'Score': [acc_lg,acc_knn,acc_svm,acc_kernel,acc_naive,acc_dt,acc_rf\n              ]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from all the classification model Random Forest classifier is best model with accuracy 85 percent.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Plotting ROC( Receiver Operating Characteristic)curve...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the “ideal” point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries for plotting roc_curve\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [LogisticRegression(random_state=0),\n               KNeighborsClassifier(),\n               SVC(random_state=0,probability=True), \n               GaussianNB(), \n               DecisionTreeClassifier(random_state=0),\n               RandomForestClassifier(random_state=0)]\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\nfor cls in classifiers:\n    model = cls.fit(x_train, y_train)\n    yproba = model.predict_proba(x_test)[:,1]\n    \n    fpr, tpr, _ = roc_curve(y_test,  yproba)\n    auc = roc_auc_score(y_test, yproba)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'auc':auc}, ignore_index=True)\nresult_table.set_index('classifiers', inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,6))\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n    \nplt.plot([0,1], [0,1], color='orange', linestyle='--')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here in a Receiver Operating Characteristic (ROC) curve the true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points. Each point on the ROC curve represents a sensitivity/specificity pair corresponding to a particular decision threshold.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Creating submission file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#set ids as PassengerId and predict survival \nids = Test['PassengerId']\npredictions = classifier5.predict(Test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)\nprint(output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONCLUSION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Tere we have completed our analysis and our prediction . If there is need of any improvement that please feel free to share it.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}