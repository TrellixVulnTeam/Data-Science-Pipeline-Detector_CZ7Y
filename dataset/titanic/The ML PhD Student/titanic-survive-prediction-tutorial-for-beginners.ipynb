{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic Survive Prediction Tutorial for Beginners\nTitanic is kaggle's beginners competion where goal is to predict where passenger will survive or not.\n\n![](https://media.giphy.com/media/jXJYVWquFTXTG/giphy.gif)\n\n<center>Gif from [Giphy](https://giphy.com/gifs/titanic-jXJYVWquFTXTG)</center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Hello Everyone,\n#### Welcome to this kernel\nI have started this kernel to help beginners to understand Titanic Kaggle Challenge.\n\nI hope that anyone, regardless of their Machine Learning and Python skills can find something useful and helpful.\n\n# <font color='red'> Don't forget to upvote if you like it! </font>\n\n## Thanks and be safe!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Contents\n\n* [Import required libraries](#import-required-libraries)\n- [Load Data](#load-data)\n- [Looking into Training and Testing Data](#looking-into-training-and-testing-data)\n- [EDA (Exploratory Data Analysis)](#EDA-exploratory-data-analysis)\n- [Data Visualization](#data-visualization)\n- [Model Prediction](#model-prediction)\n- [Support Vector Machine](#support-vector-machine)\n- [K-Nearest Neighbour](#k-nearest-neighbour)\n- [Gaussian Naive Bayes](#gaussian-naive-bayes)\n- [Linear SVC](#linear-svc)\n- [Stochastic Gradient Descent](#stochastic-gradient-descent)\n- [Decision Tree](#decision-tree)\n- [Random Forest](#random-forest)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I am continuesly updating this kernel so I really appriciate you feedback.\n\nI you have any quetion do let me know in comment, I am more than happy to answer.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Required Libraries","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Firt thing first. It is very important to import all necessary python libraries. \nI am going to import NumPy and Pandas for Data Analysis. For visualization I am going to use Matplotlib and Seaborn. ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# data analysis\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# data visualization\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns # for data visualization\n\nsns.set_style('dark')\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Once you are dont with libraries, second step is to import dataset. As you can see in above cell's output. There is 3 files in our input folder. \n1. train.csv -- our training file.\n2. test.csv -- using our machine learning model we have to predict whethere gicen entries in this file will survive or not.\n3. gender_submission.csv -- sample submission file.\n\n\nSo I am going to load train.csv and test.csv in different data frames.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# load train data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load test data\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Looking into Training and Testing Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*50)\nprint(\"Number of columns in training data\")\nprint('='*50)\nprint(\"\\n\")\nprint(train_data.columns.values)\nprint(\"\\n\")\nprint('='*50)\nprint(\"Number of columns in test data\")\nprint('='*50)\nprint(\"\\n\")\nprint(test_data.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above column name we can see that test data doesn't have Survived column. That's our task to do. For test data we have to find out whethere give passenger will survive or not.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lets have look at each column information.\n\n* PassengerId: An unique index for each passenger. It starts from 1 and increments by 1 for every new passenger.\n* Survived: Shows if the passenger survived or not. 1 stands for survived and 0 stands for not survived.\n\n* Pclass: Ticket class. 1 stands for First class ticket. 2 stands for Second class ticket. 3 stands for Third class ticket.\n\n* Name: Passenger's name. Name also contain title. \"Mr\" for man. \"Mrs\" for woman. \"Miss\" for girl. \"Master\" for boy.\n\n* Sex: Passenger's sex. It's either Male or Female.\n\n* Age: Passenger's age. \"NaN\" values in this column indicates that the age of that particular passenger has not been recorded.\n\n* SibSp: Number of siblings or spouses travelling with each passenger.\n\n* Parch: Number of parents of children travelling with each passenger.\n\n* Ticket: Ticket number.\n\n* Fare: How much money the passenger has paid for the travel journey.\n\n* Cabin: Cabin number of the passenger. \"NaN\" values in this column indicates that the cabin number of that particular passenger has not been recorded.\n\n* Embarked: Port from where the particular passenger was embarked/boarded.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Have a look at data shape","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*10)\nprint(\"Train data shape\")\nprint('='*10)\nprint(\"\\n\")\nprint(train_data.shape)\nprint(\"\\n\")\nprint('='*10)\nprint(\"Test data shape\")\nprint('='*10)\nprint(\"\\n\")\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Describing training dataset\n\ndescribe() method can show different values like count, mean, standard deviation, etc. of numeric data types.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*50)\nprint(\"\\nDescribe traing data\\n\")\nprint('='*50) \nprint(\"\\n\")\nprint(train_data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Describe test data\")\nprint('='*50)\nprint(test_data.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Info of training data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*50)\nprint(\"\\nTraining data info\\n\")\nprint('='*50)\nprint(train_data.info())\nprint(\"\\n\")\nprint('='*50)\nprint(\"\\n Test data info \\n\")\nprint('='*50)\nprint(\"\\n\")\nprint(test_data.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Age, Cabin and Embarked have missing values.\n\nAge and Embarked have only few missing values. Whereas Cabin column have so many missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('='*50)\nprint('\\nNumber of null values in train data\\n')\nprint('='*50)\nprint('\\n')\nprint(train_data.isnull().sum())\nprint('\\n')\nprint('='*50)\nprint('\\n Number of null values in test data\\n')\nprint('='*50)\nprint(\"\\n\")\nprint(test_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age Feature\nOne solution is to fill in the null values with the median age.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cabin Feature\nI'll start off by dropping the Cabin feature since not a lot more useful information can be extracted from it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop(['Cabin'], axis = 1)\ntest_data = test_data.drop(['Cabin'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ticket Feature\nI will also drop the Ticket feature since it's unlikely to yield any useful information.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop(['Ticket'], axis = 1)\ntest_data = test_data.drop(['Ticket'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Embarked Features\nThere is two missing embarked values in train data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Embarked'] = train_data['Embarked'].fillna('S')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fare Feature\nFor only test data we have one missing value so I am going to fill that with median.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data[\"Fare\"].fillna(test_data[\"Fare\"].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let check missing value again\nprint('='*50)\nprint('\\nNumber of null values in train data\\n')\nprint('='*50)\nprint('\\n')\nprint(train_data.isnull().sum())\nprint('\\n')\nprint('='*50)\nprint('\\n Number of null values in test data\\n')\nprint('='*50)\nprint(\"\\n\")\nprint(test_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we don't have any missing value in train and test data. Let's do some visuaization.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# EDA (Exploratory Data Analysis)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To make some observations and assumptions, we need to quickly analyze some feature correlations by pivoting features against each other. As we cleaned our data, we are able to make this correlation for every feature.\n\n#### Observation: \n\n- It is clear that out of 891 passengers only 342 manage to survive. Which indicated majority of passengers died.\n- **Sex** Female passenger have high priority of survival.\n- **Pclass** First class passenger have higher change of survival, which is >50%.\n- **Embarked** Passger who board the ship from Cherbourg.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of survived passengers\ntrain_data.groupby(['Survived'])['Survived'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# percentage of male and female who survived\ntrain_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# percentage of people survived according to their Ticker Class\ntrain_data[[\"Pclass\", \"Survived\"]].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percentage of survived people based on their embarked. \ntrain_data[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Survived', data = train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw a bar plot of survival by sex\nsns.barplot(x = \"Embarked\", y = \"Survived\", data = train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# peaks for survived/not survived passengers by their age\nfacet = sns.FacetGrid(train_data, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train_data['Age'].max()))\nfacet.add_legend()\n\n# average survived passengers by age\nfig, axis1 = plt.subplots(1,1,figsize=(18,4))\naverage_age = train_data[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\nsns.barplot(x='Age', y='Survived', data=average_age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass')\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass')\ngrid.map(plt.hist, 'SibSp', alpha=.5, bins=20)\ngrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass')\ngrid.map(plt.hist, 'Embarked', alpha=.5, bins=20)\ngrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train_data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(20,12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting Categorial data to Numeric\n\nIn our data some of features are represent categorial values, like Sex, Embarked etc. So we have to convert them in numeric value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Sex'] = train_data['Sex'].map({'male':1, 'female':0})\ntest_data['Sex'] = test_data['Sex'].map({'male':1, 'female':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Embarked'] = train_data['Embarked'].map({'Q':2, 'S':1, 'C':0})\ntest_data['Embarked'] = test_data['Embarked'].map({'Q':2, 'S':1, 'C':0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Prediction\nNow our data is ready to prepare model to predict solution. There is plenty of predictive algorithm out there to try. However, our problem is classification problem thus I will try classification models. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# First import all required machine learning libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare data for train and test model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_data.drop([\"Name\", \"Survived\", \"PassengerId\"], axis=1)\nY_train = train_data[\"Survived\"]\nX_test  = test_data.drop(['Name',\"PassengerId\"], axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nsvm_Y_pred = svc.predict(X_test)\nsvc_accuracy = svc.score(X_train, Y_train)\nsvc_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-Nearest Neighbour","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# k-nearest neighbor\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nknn_Y_pred = knn.predict(X_test)\nknn_accuracy = knn.score(X_train, Y_train)\nknn_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gaussian Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nguassian_Y_pred = gaussian.predict(X_test)\ngaussian_accuracy = gaussian.score(X_train, Y_train)\ngaussian_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear SVC","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nlinear_svc_Y_pred = linear_svc.predict(X_test)\nlinear_svc_accuracy = linear_svc.score(X_train, Y_train)\nlinear_svc_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stochastic Gradient Descent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nsgd_Y_pred = sgd.predict(X_test)\nsgd_accuracy = sgd.score(X_train, Y_train)\nsgd_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\ndecision_tree_Y_pred = decision_tree.predict(X_test)\ndecision_tree_accuracy = decision_tree.score(X_train, Y_train)\ndecision_tree_accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nrandom_forest_Y_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nrandom_forest_accuracy = random_forest.score(X_train, Y_train)\nrandom_forest_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Gaussian Naive Bayes', 'Linear SVC',\n              'Stochastic Gradient Decent', 'Decision Tree','Random Forest'],\n    'Score': [svc_accuracy, knn_accuracy, gaussian_accuracy, linear_svc_accuracy, \n              sgd_accuracy, decision_tree_accuracy, random_forest_accuracy]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission file from each model\nsvm_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": svm_Y_pred})\nsvm_submission.to_csv('svm_submission.csv', index=False)\n\nknn_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": knn_Y_pred})\nknn_submission.to_csv('knn_submission.csv', index=False)\n\nguassian_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": guassian_Y_pred})\nguassian_submission.to_csv('guassian_submission.csv', index=False)\n\nlinear_svc_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": linear_svc_Y_pred})\nlinear_svc_submission.to_csv('linear_svc_submission.csv', index=False)\n\nsgd_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": sgd_Y_pred})\nsgd_submission.to_csv('sgd_submission.csv', index=False)\n\ndecision_tree_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": decision_tree_Y_pred})\ndecision_tree_submission.to_csv('decision_tree_submission.csv', index=False)\n\nrandom_forest_submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": random_forest_Y_pred})\nrandom_forest_submission.to_csv('random_forest_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue'> I hope you enjoyed this kernel , Please don't forget to appreciate me with an Upvote. </font>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}