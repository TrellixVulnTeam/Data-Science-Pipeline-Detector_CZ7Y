{"cells":[{"metadata":{},"cell_type":"markdown","source":"Imagine you are working as a data scientist for an e-commerce company. One of the company’s task is to send out e-mail offers to customers with a proposal to buy certain products. Your job as a data scientist is to determine whether the contacted person will buy the product or not. All you have is a sample of customers that were contacted recently, their age and a variable whether or not they took action.\n\n**So how do we do that?** \n\nThe only way that appears is to contact every person on the list and ask them whether they will buy the product or not. Although this appears to be the only solution, it isn’t the best one.\nSo as a Data Scientist, you apply your knowledge of Machine Learning to the problem. Clearly, the Linear Regression algorithm will not work here since it only works for problems with a continuous outcome variable. On the other hand, the problem at hand is categorical i.e whether customers will buy a product( =1) or not( =0).\n\nInstead of trying to predict exactly whether the people will buy a product or not, you calculate the **probability or a likelihood** of the person saying yes. Basically you try to fit in probabilities between 0 and 1, which are the two possible outcomes. You also decide a cut off value/threshold and then conclude that people with a probability higher than the threshold will buy the product and vice versa.\n\n**And how does it make the work of the company, easier?**\n\nSince it gives the probability of people who are more likely to buy a product, it enables the company, to focus only on the customers who are most likely to say Yes."},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression an extension of Linear regression where the dependent variable is categorical and not continuous. It predicts the probability of the outcome variable.\n\n**Logistic regression**(*aka Logit Regression, maximum-entropy classification (MaxEnt) or the log-linear classifier*) can be binomial,ordinal or multinomial. In the binomial or binary logistic regression, the outcome can have only two possible types of values (e.g. “Yes” or “No”, “Success” or “Failure”). Multinomial logistic refers to cases where the outcome can have three or more possible types of values (e.g., “good” vs. “very good” vs. “best” ). Generally, the outcome is coded as “0″ and “1″ in binary logistic regression.[Ordinal logistic](https://en.wikipedia.org/wiki/Ordered_logit) regression deals with dependent variables that are ordered.\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png)\n\nSource : https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png"},{"metadata":{},"cell_type":"markdown","source":"# Representation of Logistic regression\n\nJust like a lInear regression model, a logistic regression model also computes a weighted sum of input features(and adds a bias term to it). However, unlike linear regression, it calculates the logistic of the results so that the output is always between o and 1.\n\n**Logistic Regression model estimated probability (vectorized form)**\n\n![](https://i.imgur.com/JNnqrrL.png)\n\nThe logisitc also called as logit is denoted by σ is a sigmoid function and it outputs a number between 0 and 1.\n\n![](https://imgur.com/DNpFtRM.png)\n\n*source* : https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/\n\n\n* Positive values are predictive of class 1\n* Negative values are predictive of class 0\n\nThe output of a Logistic regression model is a probability. We can select a threshold value. If the probability is greater than this threshold value, the event is predicted to happen otherwise it is predicted not to happen.\n\nOnce the mpdel estimates the probabilities(p hat), it can then easily make the predictions as follows:\n\n![](https://imgur.com/cm53tL8.png)"},{"metadata":{},"cell_type":"markdown","source":"# Describing the Performance of a Logistic model\n\n![](https://media.licdn.com/dms/image/C5112AQHRd51OS1-Oaw/article-cover_image-shrink_720_1280/0?e=1575504000&v=beta&t=kzm0mOJoLPQeShqeFN6jgAQwblDum8S1Nc5I2FiPTBk)\n\n[source](https://medium.com/google-design/human-centered-machine-learning-a770d10562cd)\n\nA **confusion matrix** is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known.Let us look at some of the important terms of confusion matrix.\n\n   ![](https://miro.medium.com/max/386/1*GMlSubndVt3g7FmeQjpeMA.png)\n\n  confusion matrix whether employees will leave a company or not\n\n### The Confusion Matrix tells us the following:\n\n* There are two possible predicted classes: “yes” and “no”. If we were predicting that employees would leave an organisation, for example, “yes” would mean they will, and “no” would mean they won’t leave the organisation.\n* The classifier made a total of 165 predictions (e.g., 165 employees were being studied).\n* Out of those 165 cases, the classifier predicted “yes” 110 times, and “no” 55 times.\n* In reality, 105 employees in the sample leave the organisation, and 60 do not.\n\n\n### Basic terms related to Confusion matrix:\n\n* **True positives (TP)**: These are cases in which we predicted yes (employees will leave the organisation), and employees actually leave i.e 100\n* **True negatives (TN)**: We predicted no(employees will not leave the organisation) and they don’t leave i.e 50\n* **False positives (FP)**: We predicted yes they will leave, but they don’t leave. (Also known as a “Type I error.”) i.e 10\n* **False negatives (FN)**: We predicted no they will not leave, but they actually leave (Also known as a “Type II error.”) i.e 5\n\n### Evaluating a Classification Model\n\n* **Accuracy** : (TP+TN)/Total . Describes overall, how often the classifier correct. i.e 100+50/165\nMeasures of Accuracy\n\nSensitivity and specificity are statistical measures of the performance of a binary classification test:\n\n* **Sensitivity/Recall** = TP/(TP + FN). When it’s actually yes, how often does it predict yes? i.e 100/(100+5)\n\n* **Specificity** = TN/(TN + FP).When it’s actually no, how often does it predict no?? i.e 50/(50+10)\n* **Precision** = TP/predicted yes. When it predicts yes, how often is it correct?100/(10+100)\n\n### Evaluation metrics for a Classification model’s performance.\n\n**ROC curve**\n\nA **ROC(Receiver Operator Characteristic Curve)** can help in deciding the best threshold value. It is generated by plotting the True Positive Rate (y-axis) against the False Positive Rate (x-axis) as you vary the threshold for assigning observations to a given class.ROC curve will always end at (1,1). The threshold at this point will be 0. This means that we will always classify these observations falling into the class 1(Specificity will be 0. False positive rate is 1).\n\nOne should select the best threshold for the trade off you want to make. According to the criticality of the business, we need to compare the cost of failing to detect positives vs cost of raising false alarms.\n\n![](https://miro.medium.com/max/469/1*Y65IEOXvxLRKKqWxlQovsg.png)\n\nAn animation to demonstrate how an ROC curve relates to sensitivity and specificity for all possible cutoffs.\n\n![Alt Text](https://github.com/dariyasydykova/open_projects/blob/master/ROC_animation/animations/ROC.gif?raw=true)\n\n[Source](https://github.com/dariyasydykova/open_projects/blob/master/ROC_animation/animations/ROC.gif)\n\n**High Threshold:**\n* High specificity\n* Low sensitivity\n\n\n**Low Threshold**\n* Low specificity\n* High sensitivity\n\nThe area under ROC is called *Area Under the Curve(AUC)*. AUC gives the rate of successful classification by the logistic model. To get a more in-depth idea of what a ROC-AUC curve is and how is it calculated, here is a link to the [article](https://towardsdatascience.com/understanding-the-roc-and-auc-curves-a05b68550b69) I wrote on the same topic."},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression in Python\n\n### Importing necessary libraries\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# File system manangement\nimport os\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# List files available\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Data\n\ntrain = pd.read_csv('../input/titanic/train.csv')\nprint('Training data shape: ', train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training data has 891 observations and 12 features (variables) including the TARGET (the label we want to predict).In this case we want to predict whether a passenger on Titanic **survived** or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing data features\ntest = pd.read_csv('../input/titanic/test.csv')\nprint('Testing data shape: ', test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis(EDA)\n\nThe data page on Kaggle describes the columns in detail. It’s always worth exploring this in detail to get a full understanding of the data."},{"metadata":{},"cell_type":"markdown","source":"### Examining the Distribution of the Target Column "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Survived',data = train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, around 549 people perished while 342 survived."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Survived',hue = 'Sex',data = train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that females survived in much higher proportions than males did. Now, Let’s see how many people survived divided by class."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Survived',hue = 'Pclass',data = train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of survival rate class wise"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Pclass',y='Age',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Examining Missing Values\n\nNext we can look at the number and percentage of missing values in each column."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Null in Training set\")\nprint(\"---------------------\")\nprint(train.isnull().sum())\nprint(\"---------------------\")\nprint(\"Null in Testing set\")\nprint(\"---------------------\")\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The three columns i.e Age, cabin and Embarked have missing values which needs to be taken care of."},{"metadata":{},"cell_type":"markdown","source":"#### 1. Age Column\n\nLet’s create a function to impute ages regarding the corresponding age average per class."},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Age):\n        return int(train[train[\"Pclass\"] == Pclass][\"Age\"].mean())\n    else:\n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age'] = train[['Age','Pclass']].apply(add_age,axis=1)\ntest['Age'] = test[['Age','Pclass']].apply(add_age,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Missing values in Cabin \n\nSince we have lots of null values for Cabin column, so it is better to remove it."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(\"Cabin\",inplace=True,axis=1)\ntest.drop(\"Cabin\",inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Missing values in Embarked column\n\nSince there are just two missing values, we shall impute them with the mode of the Embarked column."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)\ntest['Embarked'].fillna(test['Embarked'].mode()[0],inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Missing values in Frame column in Test Dataset\n\nSince there is one missing value, we shall impute them with the mean of the Fare column."},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Fare'].fillna(test['Fare'].mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating new Features\n\n* WE shall create a new column called **Family** by combining Parch and SibSp columns\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef combine(df,col1,col2):\n    df[\"Family\"] = df[col1]+df[col2]\n    df.drop([col1,col2],inplace=True,axis=1)\n    return df\n\ntrain = combine(train,'SibSp','Parch')\ntest = combine(test,'SibSp','Parch')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let’s take a look at the Age column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the Age column needs to be treated slightly differently, as this is a continuous numerical column.we can separate this continuous feature into a categorical feature by dividing it into ranges."},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_age(df,cut_points,label_names):\n    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n    return df\n\ncut_points = [-1,0,5,12,18,35,60,100]\nlabel_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\ntrain = process_age(train,cut_points,label_names)\ntest = process_age(test,cut_points,label_names)\n\npivot = train.pivot_table(index=\"Age_categories\",values='Survived')\npivot.plot.bar()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding Categorical Variables"},{"metadata":{},"cell_type":"markdown","source":"We can use the pandas.get_dummies() function Now, we shall have to encode Sex, Embarked, Pclass and Age_categories. Name and Ticket columns have a lot of categories, hence we shall delete them."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dummies(df,column_name):\n    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    return df\n\nfor column in [\"Pclass\",\"Sex\",\"Age_categories\",'Embarked']:\n    train = create_dummies(train,column)\n    test = create_dummies(test,column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping Unnecessary columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['Name','Sex','Ticket','Pclass','Age_categories','Embarked'],inplace=True,axis=1)\ntest.drop(['Name','Sex','Ticket','Pclass','Age_categories','Embarked'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Implementation\n\nWe will use Logistic Regressionfrom [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model. The only change we will make from the default model settings is to lower the [regularization parameter](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), C, which controls the amount of overfitting (a lower value should decrease overfitting). This will get us slightly better results than the default Logistic Regression.\n\nThe .fit() method accepts two arguments: X and y. X must be a two dimensional array (like a dataframe) of the features that we wish to train our model on, and y must be a one-dimensional array (like a series) of our target, or the column we wish to predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\ncolumns = ['PassengerId', 'Age', 'Fare','Family',\n       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing', 'Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior']\n\nlr.fit(train[columns], train[\"Survived\"])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating Accuracy of our model\n\nThe evaluation criteria given on the Titanic Data page is accuracy, i.e how many correct predictions we have made out of the total predictions. We have created our model but how will we know how accurate it is? We do have a Test dataset but since it doesn't have the Target column, everytime we optimize our model, we will have to submit our predictions to public Leaderboard to assess it accuracy. \n\n#### Creating a Validation set\n\nAnother option would be to create a validation set from the training set. We will hold out a part of the training set during the start of the experiment and use it for evaluating our predictions. We shall use the scikit-learn library's `model_selection.train_test_split()` function that we can use to split our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train[columns]\ny = train['Survived']\n\ntrain_X, val_X, train_y, val_y = train_test_split(\n    X, y, test_size=0.20,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making predictions and measuring accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(train_X, train_y)\npredictions = lr.predict(val_X)\naccuracy = accuracy_score(val_y, predictions)\nprint(accuracy)\nfrom sklearn.metrics import classification_report\nprint(classification_report(val_y,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Using cross validation for more robust error measurement\n\nUsing a Validation dataset has a drawback. Firstly, it decreases the training data and secondly since it is tested against a small amount of data, it has high chances of overfitting. To overcome this, there is a technique called **[cross validation](https://scikit-learn.org/stable/modules/cross_validation.html)**. The most common form of cross validation, and the one we will be using, is called k-fold cross validation. ‘Fold’ refers to each different iteration that we train our model on, and ‘k’ just refers to the number of folds. In the diagram above, we have illustrated k-fold validation where k is 5.\n\n![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n\n[source](https://scikit-learn.org/stable/modules/cross_validation.html)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nscores = cross_val_score(lr, X, y, cv=10)\nscores.sort()\naccuracy = scores.mean()\n\nprint(scores)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making Predictions on Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X,y)\npredictions_test = lr.predict(test[columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission "},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/titanic/gender_submission.csv')\nsubmission_df = pd.DataFrame({'PassengerId' : test['PassengerId'],\n                              'Survived':predictions_test})\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can still can improve our model,however this notebook is intended to show how we can do some exploratory analysis, clean up data, perform predictions using Logistic regression Algorithm. In the Next notebook, I shall go in detail about Decision Trees and Random Forests."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}