{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-03-15T10:27:55.00131Z","iopub.execute_input":"2022-03-15T10:27:55.001615Z","iopub.status.idle":"2022-03-15T10:27:55.010659Z","shell.execute_reply.started":"2022-03-15T10:27:55.001578Z","shell.execute_reply":"2022-03-15T10:27:55.009986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the Data files","metadata":{}},{"cell_type":"code","source":"data_raw = pd.read_csv('/kaggle/input/titanic/train.csv')\ndata_for_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ndata_raw.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:27:57.765816Z","iopub.execute_input":"2022-03-15T10:27:57.766728Z","iopub.status.idle":"2022-03-15T10:27:57.80055Z","shell.execute_reply.started":"2022-03-15T10:27:57.766676Z","shell.execute_reply":"2022-03-15T10:27:57.799329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_for_test['Embarked']","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:29:07.050081Z","iopub.execute_input":"2022-03-15T10:29:07.050515Z","iopub.status.idle":"2022-03-15T10:29:07.058437Z","shell.execute_reply.started":"2022-03-15T10:29:07.050484Z","shell.execute_reply":"2022-03-15T10:29:07.057379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining a Function that will PREPARE THE DATA on demand","metadata":{}},{"cell_type":"code","source":"object_cols = list(data_raw.select_dtypes(include=np.object_))\nnum_cols = list(data_raw.select_dtypes(include=np.number))\n\nprint(\"object_cols\\n\", object_cols,)\nprint(\"\\nnum_cols\\n\", num_cols)\n\ndata_raw['Embarked'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:33:09.023675Z","iopub.execute_input":"2022-03-15T10:33:09.023979Z","iopub.status.idle":"2022-03-15T10:33:09.036786Z","shell.execute_reply.started":"2022-03-15T10:33:09.02394Z","shell.execute_reply":"2022-03-15T10:33:09.03622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(df,y=True, get_df = True):\n    object_cols = list(df.select_dtypes(include=np.object_))\n    num_cols = list(df.select_dtypes(include=np.number))\n    \n    # copying the data to make changes only in copied data\n    dfc = df.copy()\n    \n    # this column not necessary for training\n    num_cols.remove('PassengerId')\n    if 'Survived' in num_cols:\n        num_cols.remove('Survived')\n    \n    object_cols.remove('Name')\n    \n    # filling the nan values\n    dfc['Embarked'].fillna('S', inplace=True)\n    dfc['Sex'].fillna('female', inplace=True)\n    dfc['Name'].fillna('missing', inplace=True)\n    \n    for x in num_cols:\n        mn = dfc[x].mean()\n        dfc[x].fillna(mn , inplace=True)\n        \n    # making new columns\n    dfc['family_mems'] = dfc['SibSp'] + dfc['Parch'] + 1 # 1 because counting self\n    \n    def decide_marital_status(val):\n        if val==1:\n            return 'Single'\n        elif val==2:\n            return 'Couple'\n        elif val>2:\n            return 'Family'\n    \n    def decide_age_group(a):\n        if a<=5:\n            return 'infant'\n        elif 5<a<14:\n            return 'child'\n        elif 14<a<25:\n            return 'youth'\n        else:\n            return 'adult'\n    \n    # new column -> marital status\n    dfc['marital_status'] = dfc['family_mems'].apply(decide_marital_status)\n    # new column -> age_group\n    dfc['age_group'] = dfc['Age'].apply(decide_age_group)\n    # new column -> Title\n    titles = [some_name.split(',')[1].split('.')[0].strip() for some_name in df['Name']]\n    if 'missing' in titles:\n        titles.remove('missing')\n    dfc['Title'] = titles\n    dfc['Title'] = dfc['Title'].replace(\n        ['Lady', 'the Countess', 'Countess', 'Capt', \n        'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', \n        'Jonkheer', 'Dona', 'Ms', 'Mme', 'Mlle'], \n        'Rare')\n    \n    # Drop or not does not matter because we will be selecting columns\n    # mentioned in *attr_for_onehot* and *attr_for_scaling*\n    # Dropping columns assumed not necessary for training\n    # dfc.drop(['PassengerId','Ticket','Cabin','SibSp','Parch','Name'], axis=1, inplace=True)\n    \n    attr_for_onehot = ['Sex','Embarked','age_group','marital_status', 'Title']\n    attr_for_scaling = ['Fare','Age', 'family_mems']\n    \n    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n    one_hot = OneHotEncoder(sparse=False)\n    scaler = StandardScaler()\n    one_hot_tr = one_hot.fit_transform(dfc[attr_for_onehot])\n    scale_tr = scaler.fit_transform(dfc[attr_for_scaling])\n    \n    data_prepared = np.concatenate((one_hot_tr, scale_tr), axis=1)\n    \n    if get_df == True:\n        features = list(one_hot.get_feature_names_out()) + attr_for_scaling\n        data_prepared_df = pd.DataFrame(data_prepared,\n                                       columns=features,\n                                       index = dfc.index)\n        if y==False:\n            return data_prepared_df\n        return data_prepared_df, dfc['Survived']\n    \n    if y==False:\n            return data_prepared\n    return data_prepared, dfc['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:35:16.824514Z","iopub.execute_input":"2022-03-15T10:35:16.824791Z","iopub.status.idle":"2022-03-15T10:35:16.846493Z","shell.execute_reply.started":"2022-03-15T10:35:16.824764Z","shell.execute_reply":"2022-03-15T10:35:16.845545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_prepared, label = prepare_data(data_raw, get_df=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:35:19.68594Z","iopub.execute_input":"2022-03-15T10:35:19.686739Z","iopub.status.idle":"2022-03-15T10:35:19.715061Z","shell.execute_reply.started":"2022-03-15T10:35:19.686685Z","shell.execute_reply":"2022-03-15T10:35:19.714048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_prepared.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:35:20.385476Z","iopub.execute_input":"2022-03-15T10:35:20.38577Z","iopub.status.idle":"2022-03-15T10:35:20.42539Z","shell.execute_reply.started":"2022-03-15T10:35:20.385739Z","shell.execute_reply":"2022-03-15T10:35:20.424476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I inferred from previous version that RandomForestClassifier seems good for Predicitons","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import precision_score, recall_score\n\nprecisions = []\nrecalls = []\nscores = []\n\nfor n in range(20):\n    X, y = shuffle(data_train_prepared, label)\n    forest_clf = RandomForestClassifier()\n    forest_clf.fit(X, y)\n    y_pred = forest_clf.predict(X)\n    precisions.append(precision_score(y,y_pred))\n    recalls.append(recall_score(y,y_pred))\n    scores.append(forest_clf.score(X, y))\n    \nprint(sum(precisions)/len(precisions))\nprint(sum(recalls)/len(recalls))\nprint(sum(scores)/len(scores))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:35:30.104472Z","iopub.execute_input":"2022-03-15T10:35:30.104838Z","iopub.status.idle":"2022-03-15T10:35:35.63963Z","shell.execute_reply.started":"2022-03-15T10:35:30.104803Z","shell.execute_reply":"2022-03-15T10:35:35.638636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making predictions for Test data","metadata":{}},{"cell_type":"code","source":"test_prepared = prepare_data(data_for_test, y=False, get_df=True)\n\n# for col in data_train_prepared.columns:\n#     if col not in test_prepared.columns:\n#         print(col)\ntest_pred = forest_clf.predict(test_prepared)\n\nsubmission = pd.DataFrame({\n    'PassengerId': data_for_test['PassengerId'],\n    'Survived': test_pred\n})\n\nsubmission.to_csv('submission.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:35:59.493901Z","iopub.execute_input":"2022-03-15T10:35:59.49419Z","iopub.status.idle":"2022-03-15T10:35:59.549833Z","shell.execute_reply.started":"2022-03-15T10:35:59.494161Z","shell.execute_reply":"2022-03-15T10:35:59.548979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}