{"cells":[{"metadata":{},"cell_type":"markdown","source":"I solved this problem statement, Titanic: Machine Learning from Disaster (  https://lnkd.in/e3vg9ZY ) with 8 different approaches :\nYou can check other approaches by clicking either of the link below added.\n1. GBM : https://lnkd.in/eDD_FSP\n2. XGBClassifier https://lnkd.in/e_2fe7y\n3. Random Forest  https://lnkd.in/eAXXtR7\n4. kNN https://lnkd.in/eFuJRu5\n5. Naive Bayes https://lnkd.in/ens-x37 \n6. SVM https://lnkd.in/eDxKCRJ\n7. Decision Tree https://lnkd.in/eQ4AsTb\n8. Logistic Regression  https://lnkd.in/edqXmeD\n\n**If you find this interesting, do upvote this notebook. Thanks for the valuable time spend & sharing love with us**"},{"metadata":{},"cell_type":"markdown","source":"# The Challenge"},{"metadata":{},"cell_type":"markdown","source":"\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we neeedto build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc)."},{"metadata":{},"cell_type":"markdown","source":"![Image1](https://im-media.voltron.voanews.com/Drupal/01live-166/styles/sourced/s3/2019-04/ECD0C2AF-BA7E-42C8-8098-901A7AF88D11.png?itok=smo7sWLV)"},{"metadata":{},"cell_type":"markdown","source":"# Step 1: Importing and Merging Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np, seaborn as sns,matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train= pd.read_csv('/kaggle/input/titanic/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/titanic/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correcting Datatype for the variable in data"},{"metadata":{},"cell_type":"markdown","source":"Few Columns' datatype are defaulted as int64 but they are catergorical in nature "},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pclass"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Pclass'].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it's Catergorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train['Pclass']  : \",train.Pclass.dtype)\nprint(\"Test['Pclass']   : \",test.Pclass.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Pclass']=train['Pclass'].astype('object')\ntest['Pclass']=test['Pclass'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train['Pclass']  : \",train.Pclass.dtype)\nprint(\"Test['Pclass']   : \",test.Pclass.dtype)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Survived'].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's Catergorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train['Survived']  : \",train.Survived.dtype)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Variable are correctly classified & added in dataset"},{"metadata":{},"cell_type":"markdown","source":"# Decoding Values"},{"metadata":{},"cell_type":"markdown","source":"Pclass"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Pclass'] = train['Pclass'].replace({ 1 : '1st', 2: '2nd',3: '3rd'}).astype('category')\ntest['Pclass'] = test['Pclass'].replace({ 1 : '1st', 2: '2nd',3: '3rd'}).astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Pclass'].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Pclass'].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embarked"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Embarked'] = train['Embarked'].replace({ 'C' : 'Cherbourg', 'Q': 'Queenstown','S': 'Southampton'}).astype('object')\ntest['Embarked'] = test['Embarked'].replace({ 'C' : 'Cherbourg', 'Q': 'Queenstown','S': 'Southampton'}).astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Embarked'].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Embarked'].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Variable are all decoded & added in dataset"},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Inspecting the Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found few missing values in few of Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(test.isnull().sum()*100/len(test),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(train.isnull().sum()*100/len(train),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Impute Data for missing value "},{"metadata":{},"cell_type":"markdown","source":"Cabin"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(test.Cabin.isnull().sum()*100/len(test),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Cabin.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\ntest.Cabin.value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,8))\nsns.countplot(x='Cabin',data=test)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let replace missing value with a variable X, which means it's Unknown "},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Cabin'] = test['Cabin'].replace(np.nan,'X')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Cabin'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Cabin.value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32,8))\nax=sns.countplot(x='Cabin',data=test)\nax.set_yscale('log')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similarly, For train data "},{"metadata":{"trusted":true},"cell_type":"code","source":"round(train.Cabin.isnull().sum()*100/len(train),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Cabin.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\ntrain.Cabin.value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,8))\nsns.countplot(x='Cabin',data=train)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let replace missing value with a variable X, which means it's Unknown"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Cabin'] = train['Cabin'].replace(np.nan,'X')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Cabin'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Cabin.value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32,8))\nax=sns.countplot(x='Cabin',data=train)\nax.set_yscale('log')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fare"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(test.Fare.isnull().sum()*100/len(test),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Fare.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Fare.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.violinplot(x='Fare',data=test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are outliers for this variable, hence, Median is prefered over mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Fare'] = test['Fare'].replace(np.nan,train.Fare.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Fare.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(train.Age.isnull().sum()*100/len(train),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Age.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Age.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.violinplot(x='Age',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-  There are outliers for this variable, hence, Median is prefered over mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age'] = train['Age'].replace(np.nan,train.Age.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(test.Age.isnull().sum()*100/len(test),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Age.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Age.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.violinplot(x='Age',data=test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are outliers for this variable, hence, Median is prefered over mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Age'] = test['Age'].replace(np.nan,train.Age.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embarked"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(train.Embarked.isnull().sum()*100/len(train),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked.value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Since, it's catergorical datatype, we opt for Mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Embarked'] = train['Embarked'].replace(np.nan,train.Embarked.mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked.mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Final Check()"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Nan records are availble in any datasets"},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"### Checking the Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.heatmap(train.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nax = sns.countplot(x='Pclass',data=train,hue=\"Survived\")\nbars = ax.patches\nhalf = int(len(bars)/2)\nleft_bars = bars[:half]\nright_bars = bars[half:]\n\nfor left, right in zip(left_bars, right_bars):\n    height_l = left.get_height()\n    height_r = right.get_height()\n    total = height_l + height_r\n\n    ax.text(left.get_x() + left.get_width()/2., height_l + 10, '{0:.0%}'.format(height_l/total), ha=\"center\")\n    ax.text(right.get_x() + right.get_width()/2., height_r + 10, '{0:.0%}'.format(height_r/total), ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Insights\n- Total number of people travelled : 891\n- Number of People travelled in 1st pclass : 216\n- Number of People travelled in 1st pclass & Survived : 136\n- Number of People travelled in 1st pclass & Non Survived : 80\n- Number of People travelled in 2nd pclass : 184\n- Number of People travelled in 2nd pclass & Survived : 86\n- Number of People travelled in 2nd pclass & Non Survived : 98\n- Number of People travelled in 3rd pclass : 491\n- Number of People travelled in 3rd pclass & Survived : 118\n- Number of People travelled in 3rd pclass & Non Survived : 373\n- Percentage of People Travelling in 1st pclass : 24.24\n- Percentage of People Travelling in 2nd pclass : 20.65\n- Percentage of People Travelling in 3rd pclass : 55.10\n- Percentage of Survial in total Survial if travelling in 1st plass : 39.78\n- Percentage of Survial if total Survial travelling in 2nd plass : 25.15\n- Percentage of Survial if total Survial travelling in  3rd plass : 34.50\n- Percentage of Survial if travelling in 1st plass : 63\n- Percentage of Survial if travelling in 2nd plass : 47\n- Percentage of Survial if travelling in  3rd plass : 24\n\n- **Premium cost increased the chance of survival in that accident**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nax = sns.countplot(x='Sex',data=train,hue=\"Survived\")\nbars = ax.patches\nhalf = int(len(bars)/2)\nleft_bars = bars[:half]\nright_bars = bars[half:]\n\nfor left, right in zip(left_bars, right_bars):\n    height_l = left.get_height()\n    height_r = right.get_height()\n    total = height_l + height_r\n\n    ax.text(left.get_x() + left.get_width()/2., height_l + 10, '{0:.0%}'.format(height_l/total), ha=\"center\")\n    ax.text(right.get_x() + right.get_width()/2., height_r + 10, '{0:.0%}'.format(height_r/total), ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Insights\n- Total number of people travelled : 891\n- Number of People travelled were Female : 314\n- Number of People travelled were Female & Survived : 232\n- Number of People travelled were Female & Non Survived : 82\n- Number of People travelled were Male : 577\n- Number of People travelled were Male & Survived : 110\n- Number of People travelled were Male & Non Survived : 467\n- Percentage of People Travelling were Male : 35.24\n- Percentage of People Travelling were Female : 64.75\n- Percentage of Survial in total Survial if Male : 32.16\n- Percentage of Survial in total Survial if Female : 67.83\n\n\n- **Sex increased the chance of survival in that accident**"},{"metadata":{},"cell_type":"markdown","source":"# Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.violinplot(y='Age',x='Survived',hue='Survived',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Age[train.Survived==1].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Age[train.Survived==0].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" - Mean Age for people who survived is 28 years, which is less compared with Mean Age for people who didn't survived is 30 years.\n - Median , 75th percentitle is same for both cases"},{"metadata":{},"cell_type":"markdown","source":"We can create a column 'Family' which will store values of sibsp + parch, \n\n- sibsp\t-> # of siblings / spouses aboard the Titanic\t\n- parch\t-> # of parents / children aboard the Titanic  \n\n& later drop these 2 columns from both dataset for uniformity "},{"metadata":{},"cell_type":"markdown","source":"## Add new feature "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Family']= train['SibSp']+ train['Parch']+ 1 #including the passenger him/herself\ntrain=train.drop(['SibSp','Parch'],axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.violinplot(y='Age',x='Family',hue='Survived',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Family[train.Survived==1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Percentage of People Survived with their family member count')\ntrain.Family[train.Survived==1].value_counts()* 100/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of People Survived with their family member count')\ntrain.Family[train.Survived==1].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Perceptage in total Survival with family count as ')\ntrain.Family[train.Survived==1].value_counts()* 100/len(train.Family[train.Survived==1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Family[train.Survived==0].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Perecentage of People Not Survived with their family member count')\ntrain.Family[train.Survived==0].value_counts()* 100/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Perceptage in total Death with family count as ')\ntrain.Family[train.Survived==0].value_counts()* 100/len(train.Family[train.Survived==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of People Not Survived with their family member count')\ntrain.Family[train.Survived==0].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nax = sns.countplot(x='Family',data=train,hue=\"Survived\")\nbars = ax.patches\nhalf = int(len(bars)/2)\nleft_bars = bars[:half]\nright_bars = bars[half:]\n\nfor left, right in zip(left_bars, right_bars):\n    height_l = left.get_height()\n    height_r = right.get_height()\n    total = height_l + height_r\n\n    ax.text(left.get_x() + left.get_width()/2., height_l + 10, '{0:.0%}'.format(height_l/total), ha=\"center\")\n    ax.text(right.get_x() + right.get_width()/2., height_r + 10, '{0:.0%}'.format(height_r/total), ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- People with  family member count as  2,3,4 has better chance of surviving than people with family member count as  1,5,6,8 & 11\n- Single Traveller may be tried to help others , resulting max death in total death i.e. 68%\n- Family having members as 8 & 11 died all , may because they were too busy in panic to collect family members before they exit.\n- Single Traveller Couple (Family with 2 members), couple with 1 or 2 children survived the most, i.e. 90% of total survival.\n- Single Traveller has both Survial & Death when account in total dealth or total survival.\n"},{"metadata":{},"cell_type":"markdown","source":"Similarly, For testdata, we perform same action"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Family']= test['SibSp']+ test['Parch']+ 1 #including the passenger him/herself\ntest=test.drop(['SibSp','Parch'],axis=1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Name & Ticket Number are not an important feature for prediction "},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['Name','Ticket'],axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similarly, For testdata, we perform same action"},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test.drop(['Name','Ticket'],axis=1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fare"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.violinplot(y='Fare',x='Survived',hue='Survived',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Fare[train.Survived==1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Fare[train.Survived==0].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- People who survived has bought a ticket with a mean 48.40 compared to  22.11, who are dead\n- People who survived has bought a ticket with a median 26 compared to 10.5, who are dead\n- Premium tickets bought safer seat"},{"metadata":{},"cell_type":"markdown","source":"# Cabin"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Cabin.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32,8))\nax=sns.barplot(x='Cabin',y='Fare',hue='Survived',data=train)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Cabin[train.Survived==0].value_counts(ascending=False)*100/len(train.Cabin[train.Survived==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Cabin[train.Survived==1].value_counts(ascending=False)*100/len(train.Cabin[train.Survived==1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 87% of total death toll are from X Cabin , which means they don't had any cabin. They were Class 3 who paid little so, they have no premium service.\n- 60% of total Surviour are from X Cabin , which means they don't had any cabin. They were first who got alert and act fastest.\n- Luxury brough confort & premium services, same was the reason they were last who were alerted."},{"metadata":{},"cell_type":"markdown","source":"# Embarked"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nax = sns.countplot(x='Embarked',data=train,hue=\"Survived\")\nbars = ax.patches\nhalf = int(len(bars)/2)\nleft_bars = bars[:half]\nright_bars = bars[half:]\n\nfor left, right in zip(left_bars, right_bars):\n    height_l = left.get_height()\n    height_r = right.get_height()\n    total = height_l + height_r\n\n    ax.text(left.get_x() + left.get_width()/2., height_l + 10, '{0:.0%}'.format(height_l/total), ha=\"center\")\n    ax.text(right.get_x() + right.get_width()/2., height_r + 10, '{0:.0%}'.format(height_r/total), ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked.value_counts()*100/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked[train.Survived==0].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked[train.Survived==0].value_counts(ascending=False)*100/len(train.Embarked[train.Survived==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked[train.Survived==1].value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Embarked[train.Survived==1].value_counts(ascending=False)*100/len(train.Embarked[train.Survived==1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- People from Cherbourg have more survial than Deaths\n- 72% of poeple have Embarked at Southampton\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train.Cabin.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There 148 unique values for Cabin , this's not important field to be considered. Drop Cabin from both dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test.drop(['Cabin'],axis=1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['Cabin'],axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 3: Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain[['Age', 'Fare','Family']]= scaler.fit_transform(train[['Age', 'Fare','Family']])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['Age', 'Fare','Family']]= scaler.transform(test[['Age', 'Fare','Family']])\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(train[['Pclass', 'Sex','Embarked']], drop_first=True)\n\n# Adding the results to the master dataframe\ntrain = pd.concat([train, dummy1], axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop Already existing Columns "},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(['Pclass', 'Sex','Embarked'],axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy2 = pd.get_dummies(test[['Pclass', 'Sex','Embarked']], drop_first=True)\n\n# Adding the results to the master dataframe\ntest = pd.concat([test, dummy2], axis=1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=test.drop(['Pclass', 'Sex','Embarked'],axis=1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Checking the Survived Rate\nSurvived = (sum(train['Survived'])/len(train['Survived'].index))*100\nSurvived","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have almost 38.38% Survived rate"},{"metadata":{},"cell_type":"markdown","source":"Step 4: Looking at Correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Survived']=train['Survived'].astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make sure corr shows correct represtations "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the correlation matrix \nplt.figure(figsize = (10,10))   \nsns.heatmap(train.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 5: Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=train.pop('Survived')\nX_train=train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n# Logistic regression model\nlogm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\nlogm1.fit().summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 5: Feature Selection Using RFE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nfrom sklearn.feature_selection import RFE\nrfe = RFE(logreg, 5)             \nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns, rfe.support_, rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns[~rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm = sm.add_constant(X_train[col])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the predicted values on the train set\ny_train_pred = res.predict(X_train_sm)\ny_train_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final = pd.DataFrame({'Survived':y_train.values, 'Survived_Prob':y_train_pred})\ny_train_pred_final['PassengerId'] = y_train.index\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating new column 'predicted' with 1 if Survived_Prob > 0.5 else 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final['predicted'] = y_train_pred_final.Survived_Prob.map(lambda x: 1 if x > 0.5 else 0)\n\n# Let's see the head\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final.predicted )\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.accuracy_score(y_train_pred_final.Survived, y_train_pred_final.predicted))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking VIFs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All variables have a good value of VIF. So we need not drop any more variables and we can proceed with making predictions using this model only"},{"metadata":{},"cell_type":"markdown","source":"Metrics beyond simply accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the sensitivity of our logistic regression model\nTP / float(TP+FN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us calculate specificity\nTN / float(TN+FP)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate false postive rate - \nprint(FP/ float(TN+FP))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# positive predictive value \nprint (TP / float(TP+FP))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Negative predictive value\nprint (TN / float(TN+ FN))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 6: Plotting the ROC Curve"},{"metadata":{},"cell_type":"markdown","source":"An ROC curve demonstrates several things:\n\n* It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n* The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n* The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test."},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Survived, y_train_pred_final.Survived_Prob, drop_intermediate = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_roc(y_train_pred_final.Survived, y_train_pred_final.Survived_Prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 7: Finding Optimal Cutoff Point"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Survived_Prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the curve above, 0.38 is the optimum point to take it as a cutoff probability."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final['final_predicted'] = y_train_pred_final.Survived_Prob.map( lambda x: 1 if x > 0.38 else 0)\n\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the overall accuracy.\nmetrics.accuracy_score(y_train_pred_final.Survived, y_train_pred_final.final_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion2 = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final.final_predicted )\nconfusion2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the sensitivity of our logistic regression model\nTP / float(TP+FN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us calculate specificity\nTN / float(TN+FP)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate false postive rate - predicting Survived when customer does not have Survived\nprint(FP/ float(TN+FP))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Positive predictive value \nprint (TP / float(TP+FP))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Negative predictive value\nprint (TN / float(TN+ FN))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Precision and Recall"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looking at the confusion matrix again","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion = metrics.confusion_matrix(y_train_pred_final.Survived, y_train_pred_final.predicted )\nconfusion","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using sklearn utilities for the same"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\nprecision_score(y_train_pred_final.Survived, y_train_pred_final.predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recall_score(y_train_pred_final.Survived, y_train_pred_final.predicted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Precision and recall tradeoff"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\ny_train_pred_final.Survived.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final.predicted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p, r, thresholds = precision_recall_curve(y_train_pred_final.Survived, y_train_pred_final.Survived_Prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making predictions on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test[col]\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_sm = sm.add_constant(X_test)\nX_test_sm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = res.predict(X_test_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(y_test_pred)\n# Let's see the head\ny_pred_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final= y_pred_1\ny_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Survived_Prob'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the head of y_pred_final\ny_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final['final_predicted'] = y_pred_final.Survived_Prob.map(lambda x: 1 if x > 0.38 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": y_pred_final[\"final_predicted\"]\n    })\nsubmission.to_csv('titanic_2218.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I solved this problem statement, Titanic: Machine Learning from Disaster (  https://lnkd.in/e3vg9ZY ) with 8 different approaches :\nYou can check other approaches by clicking either of the link below added.\n1. GBM : https://lnkd.in/eDD_FSP\n2. XGBClassifier https://lnkd.in/e_2fe7y\n3. Random Forest  https://lnkd.in/eAXXtR7\n4. kNN https://lnkd.in/eFuJRu5\n5. Naive Bayes https://lnkd.in/ens-x37 \n6. SVM https://lnkd.in/eDxKCRJ\n7. Decision Tree https://lnkd.in/eQ4AsTb\n8. Logistic Regression  https://lnkd.in/edqXmeD\n\n**If you find this interesting, do upvote this notebook. Thanks for the valuable time spend & sharing love with us**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}