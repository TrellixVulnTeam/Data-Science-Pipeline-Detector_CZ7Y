{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# 1) Import all Library that will be used\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import linear_model, svm, gaussian_process\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score\n\n# 1) Data treatment and cleaning\n\ndf_train_original = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test_original = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ndf_train = df_train_original\ndf_test = df_test_original\n\ndf_train = df_train.drop(['Name'], axis=1)\ndf_test = df_test.drop(['Name'], axis=1)\n\ndf_train = df_train.drop(['Cabin'], axis=1)\ndf_test = df_test.drop(['Cabin'], axis=1)\n\ndf_train = df_train.drop(['Ticket'], axis=1)\ndf_test = df_test.drop(['Ticket'], axis=1)\n\ndf_train = df_train.drop(['SibSp'], axis=1)\ndf_test = df_test.drop(['SibSp'], axis=1)\n\ndf_train = df_train.drop(['Parch'], axis=1)\ndf_test = df_test.drop(['Parch'], axis=1)\n\n#concatena os dados do treino e teste, apenas entres os campos \"Pclass\" e \"Embarked\"\n# Ou seja, o campo \"PassengerId\" de ambos DFs serão deletados e o campo \"Survived\" do DF Treino\n\nall_data = pd.concat((df_train.loc[:,'Sex':'Fare'],\n                      df_test.loc[:,'Sex':'Fare']))\n\n\n# Get_Dummies para transformar categoricos em Numéricos \nall_data = pd.get_dummies(all_data)\n\n# Substitui os campos nulos pelas médias da coluna em questão\nall_data = all_data.fillna(all_data.mean())\n#all_data = all_data.fillna(0)\n\n#creating matrices for sklearn:\n\n#Cria Matriz X_train utilizando a Matriz com todos os dados all_data: do inicio da matriz (:) até o fim  da matriz df_train.shape[0]\nX_train = all_data[:df_train.shape[0]]\n\n#Cria Matriz X_test utilizando a Matriz com todos os dados all_data: a partir do último registro matriz df_train.shape[0], ou seja, todos os registros que não estiverem em df_train\nX_test = all_data[df_train.shape[0]:]\n\n# Cria o y, ou seja, o que será previsto, apenas com o campo \"Survived\"\ny = df_train.Survived\n\n# 2) Aplly Gradient Boost Model\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport statsmodels.formula.api as smf\nfrom sklearn.preprocessing import scale\ngbr = GradientBoostingRegressor()\n\ngbr.fit(X_train, y)\n\nyhat_Train = gbr.predict(X_train)\n#yhat_Train\n\nyhat_test = gbr.predict(X_test)\n#yhat_test\n\nyhat_rounded = [round(x,ndigits=None) for x in yhat_test]\nyhat_rounded = [int(x) for x in yhat_rounded]\n\nyhat_gbr = yhat_rounded\nprint ('# # # # Esse é o yhat com o método Gradiente Descendente # # # #')\nprint ('# # # # Ou seja, a previsão se Esse é o yhat com o método Gradiente Descendente # # # #')\nprint (yhat_gbr)\n\n# Gerando um CSV para o resultado obtido com o Gradiente Descendente:\ndf_test_gbr = df_test\ndf_test_gbr['Survived'] = yhat_gbr\ndf_test_gbr = df_test_gbr.drop(['Pclass'], axis=1)\ndf_test_gbr = df_test_gbr.drop(['Sex'], axis=1)\ndf_test_gbr = df_test_gbr.drop(['Age'], axis=1)\ndf_test_gbr = df_test_gbr.drop(['Fare'], axis=1)\ndf_test_gbr = df_test_gbr.drop(['Embarked'], axis=1)\ndf_test_gbr.to_csv('Titanic_GBR.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3) Aplly Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\n\n# Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y)\n\n# accuracy = round(logreg.score(X_train, y) * 100, 2)\n# print(accuracy)\n\nLR_yhat_train = logreg.predict(X_train)\n\nLR_yhat_test = logreg.predict(X_test)\n\nprint ('# # # # Esse é o yhat com o método Regressão Logistica # # # #')\nprint (LR_yhat_test)\n\n# Gerando um CSV para o resultado obtido com Regressão Logistica:\ndf_test_RL = df_test\ndf_test_RL['Survived'] = LR_yhat_test\ndf_test_RL = df_test_RL.drop(['Pclass'], axis=1)\ndf_test_RL = df_test_RL.drop(['Sex'], axis=1)\ndf_test_RL = df_test_RL.drop(['Age'], axis=1)\ndf_test_RL = df_test_RL.drop(['Fare'], axis=1)\ndf_test_RL = df_test_RL.drop(['Embarked'], axis=1)\ndf_test_RL.to_csv('Titanic_RL.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4) Aplly Random Forest Model\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, y)\n\nrandom_forest_train = random_forest.predict(X_train)\nrandom_forest_test = random_forest.predict(X_test)\n\nprint ('# # # # Esse é o yhat com o método Random Forest # # # #')\nprint (random_forest_test)\n\n# Gerando um CSV para o resultado obtido como o Randon Forest:\ndf_test_RF = df_test\ndf_test_RF['Survived'] = random_forest_test\ndf_test_RF = df_test_RF.drop(['Pclass'], axis=1)\ndf_test_RF = df_test_RF.drop(['Sex'], axis=1)\ndf_test_RF = df_test_RF.drop(['Age'], axis=1)\n#df_test_RF = df_test_RF.drop(['SibSp'], axis=1)\n#df_test_RF = df_test_RF.drop(['Parch'], axis=1)\n#df_test_RF = df_test_RF.drop(['Ticket'], axis=1)\ndf_test_RF = df_test_RF.drop(['Fare'], axis=1)\n#df_test_RF = df_test_RF.drop(['Cabin'], axis=1)\ndf_test_RF = df_test_RF.drop(['Embarked'], axis=1)\ndf_test_RF.to_csv('Titanic_RandonForest.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5) Aplly XGBOOST Model\n\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier()\nxgb.fit(X_train, y)\n\nxgb_train = xgb.predict(X_train)\nxgb_test = xgb.predict(X_test)\n\nprint ('# # # # Esse é o yhat com o método Xgboost # # # #')\nprint (xgb_test)\n\n# Gerando um CSV para o resultado obtido como o XGBOOST:\ndf_test_xgb = df_test\ndf_test_xgb['Survived'] = xgb_test\ndf_test_xgb = df_test_xgb.drop(['Pclass'], axis=1)\ndf_test_xgb = df_test_xgb.drop(['Sex'], axis=1)\ndf_test_xgb = df_test_xgb.drop(['Age'], axis=1)\n#df_test_xgb = df_test_xgb.drop(['SibSp'], axis=1)\n#df_test_xgb = df_test_xgb.drop(['Parch'], axis=1)\n#df_test_xgb = df_test_xgb.drop(['Ticket'], axis=1)\ndf_test_xgb = df_test_xgb.drop(['Fare'], axis=1)\n#df_test_xgb = df_test_xgb.drop(['Cabin'], axis=1)\ndf_test_xgb = df_test_xgb.drop(['Embarked'], axis=1)\ndf_test_xgb.to_csv('Titanic_Xgboost.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6) Aplly KNeighbors Model\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y)\n\nknn_train = knn.predict(X_train)\nknn_test = knn.predict(X_test)\n\nprint ('# # # # Esse é o yhat com o método KNeighbors # # # #')\nprint (knn_test)\n\n# Gerando um CSV para o resultado obtido como o KNeighbors:\ndf_test_knn = df_test\ndf_test_knn['Survived'] = knn_test\ndf_test_knn = df_test_knn.drop(['Pclass'], axis=1)\ndf_test_knn = df_test_knn.drop(['Sex'], axis=1)\ndf_test_knn = df_test_knn.drop(['Age'], axis=1)\n#df_test_knn = df_test_knn.drop(['SibSp'], axis=1)\n#df_test_knn = df_test_knn.drop(['Parch'], axis=1)\n#df_test_knn = df_test_knn.drop(['Ticket'], axis=1)\ndf_test_knn = df_test_knn.drop(['Fare'], axis=1)\n#df_test_knn = df_test_knn.drop(['Cabin'], axis=1)\ndf_test_knn = df_test_knn.drop(['Embarked'], axis=1)\ndf_test_knn.to_csv('Titanic_Knn.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7) Aplly SVC Model\n\nsvc = SVC(probability=True)\nsvc.fit(X_train, y)\n\nsvc_train = svc.predict(X_train)\nsvc_test = svc.predict(X_test)\n\nprint ('# # # # Esse é o yhat com o método KNeighbors # # # #')\nprint (svc_test)\n\n# Gerando um CSV para o resultado obtido como o SVC:\ndf_test_svc = df_test\ndf_test_svc['Survived'] = svc_test\ndf_test_svc = df_test_svc.drop(['Pclass'], axis=1)\ndf_test_svc = df_test_svc.drop(['Sex'], axis=1)\ndf_test_svc = df_test_svc.drop(['Age'], axis=1)\n#df_test_svc = df_test_svc.drop(['SibSp'], axis=1)\n#df_test_svc = df_test_svc.drop(['Parch'], axis=1)\n#df_test_svc = df_test_svc.drop(['Ticket'], axis=1)\ndf_test_svc = df_test_svc.drop(['Fare'], axis=1)\n#df_test_svc = df_test_svc.drop(['Cabin'], axis=1)\ndf_test_svc = df_test_svc.drop(['Embarked'], axis=1)\ndf_test_svc.to_csv('Titanic_SVC.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 8) Aplly Decision Tree Model\n\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y)\n\ndtc_train = dtc.predict(X_train)\ndtc_test = dtc.predict(X_test)\n\nprint ('# # # # Esse é o yhat com o método DecisionTree # # # #')\nprint (dtc_test)\n\n# Gerando um CSV para o resultado obtido como o SVC:\ndf_test_dtc = df_test\ndf_test_dtc['Survived'] = dtc_test\ndf_test_dtc = df_test_dtc.drop(['Pclass'], axis=1)\ndf_test_dtc = df_test_dtc.drop(['Sex'], axis=1)\ndf_test_dtc = df_test_dtc.drop(['Age'], axis=1)\n#df_test_dtc = df_test_dtc.drop(['SibSp'], axis=1)\n#df_test_dtc = df_test_dtc.drop(['Parch'], axis=1)\n#df_test_dtc = df_test_dtc.drop(['Ticket'], axis=1)\ndf_test_dtc = df_test_dtc.drop(['Fare'], axis=1)\n#df_test_dtc = df_test_dtc.drop(['Cabin'], axis=1)\ndf_test_dtc = df_test_dtc.drop(['Embarked'], axis=1)\ndf_test_dtc.to_csv('Titanic_dtc.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 9) Aplly GaussianNB Model\n\ngnb = GaussianNB()\ngnb.fit(X_train, y)\n\ngnb_train = gnb.predict(X_train)\ngnb_test = gnb.predict(X_test)\n\nprint ('# # # # Esse é o yhat com o método GaussianNB # # # #')\nprint (gnb_test)\n\n# Gerando um CSV para o resultado obtido como o SVC:\ndf_test_gnb = df_test\ndf_test_gnb['Survived'] = gnb_test\ndf_test_gnb = df_test_gnb.drop(['Pclass'], axis=1)\ndf_test_gnb = df_test_gnb.drop(['Sex'], axis=1)\ndf_test_gnb = df_test_gnb.drop(['Age'], axis=1)\n#df_test_gnb = df_test_gnb.drop(['SibSp'], axis=1)\n#df_test_gnb = df_test_gnb.drop(['Parch'], axis=1)\n#df_test_gnb = df_test_gnb.drop(['Ticket'], axis=1)\ndf_test_gnb = df_test_gnb.drop(['Fare'], axis=1)\n#df_test_gnb = df_test_gnb.drop(['Cabin'], axis=1)\ndf_test_gnb = df_test_gnb.drop(['Embarked'], axis=1)\ndf_test_gnb.to_csv('Titanic_gnb.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}