{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Created by Sanskar Hasija**\n\n**Model Soups üç≤ with Tensorflow + TFDSüìä**\n\n**20 February 2021**\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# <center>MODEL SOUPS üç≤ WITH TENSORFLOW + TFDSüìä</center>\n## <center>If you find this notebook useful, support with an upvoteüëç</center>","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n<a id=\"toc\"></a>\n[1. Introduction  ](#1)<br>\n[2. Imports](#2)<br>\n[3. Uniform Soup ](#3)<br>\n[4. Greedy Soup ](#4)<br>\n[5. Model Soups on Image Data](#5)<br>\n[6. Model Soups on Tabular Data](#6)<br>\n[7. Model Soups on Text Data](#7)<br>\n[8. Model Soups on Time-Series Data](#8)<br>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# **<center><span style=\"color:#00BFC4;\">Introduction </span></center>**","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Notebook overview : </span>\n* This notebook is an end-to-end implementation and code replication of the paper titled [\"Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time\"](https://arxiv.org/abs/2203.05482).\n* Model Soups is currently ranked the second-best state-of-the-art benchmark on the ImageNet Dataset. Check full rankings [here](https://paperswithcode.com/sota/image-classification-on-imagenet).\n* The code is reusable and can be used to create model soups for any TensorFlow model.\n* This notebook includes two model souping techniques namely Uniform Soup and Greedy Soup as  discussed in the research paper.\n* Model Souping is performed on four major data formats - Image, Tabular, Text, and Time Series. TF.Data API is used for building Image, Text and Time Series Dataset.\n","metadata":{}},{"cell_type":"markdown","source":"<h2> <span style=\"color:#e76f51;\"> Model Soups: </span></h2> \n<center><img ","metadata":{}},{"cell_type":"markdown","source":"<center><img src=\"https://raw.githubusercontent.com/sanskar-hasija/kaggle/main/images/uniform_soup.png\" width=\"550\" height=\"200\" /></center><br>\n\n* Model Soups is an alternative technique to ensembling which includes averaging different trained model weights without incurring any additional inference or memory costs.\n* Model soups can be analogical compared to an ensemble of n models for training but inferencing with only one model using 1/n of the time of that of the ensemble's inference.\n* Model Soup comprises two main steps.\n    * Saving trained model during hyperparameter tuning, and optimization.\n    * Averaging trained model's weights using either Uniform Soup or Greedy Soup.","metadata":{}},{"cell_type":"markdown","source":"    \n<h2> <span style=\"color:#e76f51;\">TF.data </span></h2> \n<center><img src=\"https://storage.googleapis.com/jalammar-ml/tf.data/images/tf.data.png\" width=\"800\" height=\"200\" /></center><br>\n\n\n\n* TF.DATA API is used for building efficient input pipelines which can handle large amounts of data and perform complex data transformations. <br>\n* TF.DATA API has provisions for handling different data formats.<br>\n\nCheck out tf.data guide and  documentation - [here](https://www.tensorflow.org/guide/data).<br>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"# <center><span style=\"color:#00BFC4;\"> Imports </span></center> \n<a id=\"2\"></a>","metadata":{}},{"cell_type":"code","source":"!pip install -q tensorflow==2.4.1 \n## downgrading tensorflow due to \"Cleanup Called\" issue with tfds datasets\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd \nimport tensorflow as tf \nfrom datasets import Dataset\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt \nimport tensorflow_addons as tfa\nimport tensorflow_datasets as tfds\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom transformers import TFAutoModel, AutoTokenizer, DataCollatorWithPadding\n\nimport gc\ngc.collect()\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom transformers import logging\nlogging.set_verbosity_error()\n\nfrom IPython.display import clear_output\nclear_output()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# **<center><span style=\"color:#00BFC4;\">Uniform Soup </span></center>** \n","metadata":{}},{"cell_type":"markdown","source":"#### In Uniform Soup, all trained model's weights are average irrespective of each model's performance on the held-out validation set.\n","metadata":{}},{"cell_type":"code","source":"def uniform_soup(model_paths, test_ds, model_fun, evaluate_fun, disable_tqdm = False):\n    \"\"\"\n    Returns Uniform Soup model and accuracy on test set \n    Args:\n    model_paths : List, List of saved model paths\n    test_ds : Test Dataset in tfds format.\n    model_fun : Fun, Model Instantiating Function\n    evaluate_fun : Fun, Model Test Set Evaluation Function\n    disable_tqdm : Bool, Wheter to disable TQDM Progress bar or not\n    \"\"\"\n    \n    soups = []\n    ## Instantiating model\n    \n    tf.keras.backend.clear_session()\n    model = model_fun()\n    \n    ## Iterating Over all models \n    for path in tqdm(model_paths, disable=disable_tqdm):\n        \n        ## loading model wieghts \n        model.load_weights(path)\n        \n        ## Adding model weights in soup list\n        soup = [np.array(weights) for weights in model.weights]\n        soups.append(soup)\n        \n    ## Averaing all weights \n    mean_soup = np.array(soups).mean(axis = 0)\n    \n    ## Replacing model's weight with Unifrom Soup Weights\n    for w1, w2 in zip(model.weights, mean_soup ):\n        tf.keras.backend.set_value(w1, w2)\n        \n    ## evaluating uniform soup performance   \n    accuracy =  evaluate_fun(model, test_ds)\n    return model, accuracy","metadata":{"execution":{"iopub.status.busy":"2022-06-22T04:47:25.009Z","iopub.execute_input":"2022-06-22T04:47:25.012041Z","iopub.status.idle":"2022-06-22T04:47:25.035469Z","shell.execute_reply.started":"2022-06-22T04:47:25.012003Z","shell.execute_reply":"2022-06-22T04:47:25.034623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### <center><span style=\"color:#e76f51;\">NOTE ON UNIFORM SOUP</span></center>\n##### <span style=\"color:#e76f51;\">In this notebook all the wieghts are intialized randomly to boost greedy soup score. Therefore, Uniform Soup model will perofm poorly or will be  equivalent to random guessing. This can be changed by setting up a random set for weigths initialization. </span>","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# **<center><span style=\"color:#00BFC4;\">Greedy Soup </span></center>** \n","metadata":{}},{"cell_type":"markdown","source":"####  In Greedy Soup, all trained models are first sorted in descending order, followed by adding weights to the best performing model if the overall soup's performance increases.\n\n\n<center><img src=\"https://raw.githubusercontent.com/sanskar-hasija/kaggle/main/images/greedy_soup.png\" width=\"750\" height=\"200\" /></center><br>\n","metadata":{}},{"cell_type":"code","source":"def greedy_soup(model_paths, test_ds, model_fun, evaluate_fun):\n    \"\"\"\n    Returns Greedy Soup model and accuracy on test set \n    Args:\n    model_paths : List, List of saved model paths\n    test_ds : Test Dataset in tfds format.\n    model_fun : Fun, Model Instantiating Function\n    evaluate_fun : Fun, Model Test Set Evaluation Function\n    \"\"\"\n    ## Creating intial soup with best performing model \n    soups =  [model_paths[0]]\n    \n    ## Instantiating model\n    \n    tf.keras.backend.clear_session()\n    model = model_fun()\n    \n    ## Loading best performing model's weights \n    model.load_weights(model_paths[0])\n    \n    ## Scoirng best performing model on test set \n    score_final = evaluate_fun(model,test_ds)\n    \n    ## Iterating over the remaining models \n    for path in tqdm(model_paths[1:]):\n        \n        ## Creating a temp soup \n        temp_soup =  soups.copy()\n        temp_soup.append(path)\n        \n        ## Getting score from temp soup\n        model, score = uniform_soup(temp_soup,test_ds,model_fun, evaluate_fun, disable_tqdm= True)\n        \n        ## Conditioning current model for appneding in main soup\n        ## if score from the temp soup is more than best perofming model\n        ## the temp soup path is appended to main soup \n        if score > score_final:\n            score_final = score\n            soups.append(path)\n\n    return model, score_final","metadata":{"execution":{"iopub.status.busy":"2022-06-22T04:47:25.040092Z","iopub.execute_input":"2022-06-22T04:47:25.043061Z","iopub.status.idle":"2022-06-22T04:47:25.061097Z","shell.execute_reply.started":"2022-06-22T04:47:25.043024Z","shell.execute_reply":"2022-06-22T04:47:25.059989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"# <center><span style=\"color:#00BFC4;\"> Model Soups on Image Data</span></center> \n<a id=\"5\"></a>","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Setting up TF.data Pipeline  : </span>","metadata":{}},{"cell_type":"markdown","source":"\n<center><img src=\"https://storage.googleapis.com/jalammar-ml/tf.data/images/tf.data-simple-pipeline.png\" width=\"800\" height=\"300\" />\n","metadata":{}},{"cell_type":"markdown","source":"üìå tf.data API is used for building efficient input pipelines which can handle large amounts of data and perform complex data transformations . tf.data API has provisions for handling different data formats.\n    \nüìåThe tf.data API enables you to build complex input pipelines from simple, reusable pieces. The tf.data API also makes it possible to handle large amounts of data, read from different data formats, and perform complex transformations.\n\nüìåThe tf.data API introduces a tf.data.Dataset abstraction that represents a sequence of elements, in which each element consists of one or more components. For example, in an image pipeline, an element might be a single training example, with a pair of tensor components representing the image and its label.\n\n\n \n**Transformations :**\n\n* The Dataset object can be transformed into a new Dataset by chaining method calls on the tf.data.Dataset object . Some of the transformations which can be applied are Dataset.map() , Dataset.batch() , Dataset.shuffle() , Dataset.prefetch() .\n\n* The Dataset object is a Python iterable which  it possible to consume its elements using a for loop .\n\n<center><img src=\"https://drive.google.com/uc?id=1x383ghyybTV0jQqBSlHDEc8FWD8AqaHz\" width=\"550\" height=\"500\" /></center>","metadata":{}},{"cell_type":"markdown","source":"##### For Model Soups with image data, CIFAR10 Dataset is used in this notebook. \n##### CIFAR10 dataset along with 100+ ML datasets can be explored and downloaded from the [TensorFlow Dataset Catalog](https://www.tensorflow.org/datasets/catalog/overview).","metadata":{}},{"cell_type":"code","source":"## Mapping utility functions \n\n\ndef normalize(image, label):\n    \"\"\"\n    TFDS map function to normalize images\n    \"\"\"\n    image = tf.cast(image, tf.float32)\n    image = tf.divide(image, 255)\n    return image, label\n\ndef augment1(image, label):\n    \"\"\"\n    TFDS map function to augument images randomly\n    \"\"\"\n    image = tf.image.random_saturation(image, 0.7, 1.3)\n    image = tf.image.random_brightness(image, 0.1)\n    return image, label \n\ndef augment2(image, label):\n    \"\"\"\n    TFDS map function to augument images randomly\n    \"\"\"\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_brightness(image, 0.1)\n    return image, label ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T04:47:25.064212Z","iopub.execute_input":"2022-06-22T04:47:25.064553Z","iopub.status.idle":"2022-06-22T04:47:25.077297Z","shell.execute_reply.started":"2022-06-22T04:47:25.064518Z","shell.execute_reply":"2022-06-22T04:47:25.07632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.AUTOTUNE\nignore_order = tf.data.Options()\n\nclass image_config:\n    BATCH_SIZE = 64\n    SHUFFLE_BUFFER = 1024 \n    NUM_MODELS = 20\n\n## download data in local drives and instantiating tfds datasets \ncifar_train, cifar_test = tfds.load(\"cifar10\", split= [\"train\", \"test\"],  as_supervised=True)\n\n\n## normaling images\ncifar_train = cifar_train.map(normalize, num_parallel_calls=AUTO)\n## shuffling training images\ncifar_train = cifar_train.shuffle(image_config.SHUFFLE_BUFFER)\n## batching training images\ncifar_train = cifar_train.batch(image_config.BATCH_SIZE, drop_remainder= True)\ncifar_train = cifar_train.prefetch(AUTO)\n\n\n\n## extracting labels for later use\ntest_ids_ds = cifar_test.map(lambda x,y : y)\ncifar_test_labels = next(iter(test_ids_ds.batch(len(test_ids_ds)))).numpy()\n\n\n\n## normalizing test images\ncifar_test = cifar_test.map(normalize, num_parallel_calls=AUTO)\n## batching test images\ncifar_test = cifar_test.batch(image_config.BATCH_SIZE, drop_remainder=False)\ncifar_test = cifar_test.prefetch(AUTO)\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T04:47:25.07889Z","iopub.execute_input":"2022-06-22T04:47:25.079292Z","iopub.status.idle":"2022-06-22T04:48:13.262348Z","shell.execute_reply.started":"2022-06-22T04:47:25.079186Z","shell.execute_reply":"2022-06-22T04:48:13.261369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Image Data Training Utility functions   : </span>","metadata":{}},{"cell_type":"code","source":"def create_cifar_model(weights = \"imagenet\"):\n    \"\"\"\n    Returns ResNet50V2 Model for Transfer Learning \n    Args:\n    weights : weights to load for ResNet50V2 Base Model\n    \"\"\"\n        \n    ## ResNet50V2 as Base Model ( Feature Extractor)\n    feature_extractor = tf.keras.applications.ResNet50V2(input_shape=(32,32, 3),\n                                               include_top=False,\n                                               weights=weights)\n    model= tf.keras.Sequential()\n    model.add(feature_extractor) \n    model.add(tf.keras.layers.GlobalAveragePooling2D())\n    model.add(tf.keras.layers.Dense(1024,activation='relu')) \n    model.add(tf.keras.layers.Dropout(0.3))\n    model.add(tf.keras.layers.Dense(512,activation='relu')) \n    model.add(tf.keras.layers.Dropout(0.2))\n    model.add(tf.keras.layers.Dense(10,activation='softmax'))\n    return model\n\ndef cifar_training(train_ds, \n                   test_ds,\n                   epochs, \n                   learning_rate, \n                   weight_decay,\n                   aug_map= None,\n                   save_dir = \"cifar/\"):\n    \"\"\"\n    Returns Saved trained model's path and test evaluation score\n    Args:\n    train_ds : Train Dataset in tfds format.\n    test_ds : Test Dataset in tfds format.\n    epochs : Int, Trainig Epochs count.\n    learning_rate : Float, Training Learning Rate\n    weight_decay : Float, AdamW optimizer Weight Decay\n    aug_map: Mapping function for augmentting train_ds\n    save_dir : Str, Model Save Directory Prefix\n    \"\"\"\n    ## Creating directory for saving models\n    if not os.path.isdir(save_dir):\n        os.makedirs(save_dir)\n    \n    \n    ## Augumentation Check\n    is_aug = False\n    if aug_map is not None:\n        train_ds = train_ds.unbatch().map(aug_map).batch(image_config.BATCH_SIZE).prefetch(AUTO)\n        is_aug = True\n        \n        \n    ## AdamW Optimizer Setup    \n    adamw_optimizer = tfa.optimizers.AdamW(weight_decay= weight_decay,\n                                     learning_rate= learning_rate)\n    \n    ## Instantiating model\n    tf.keras.backend.clear_session()\n    model = create_cifar_model()\n    \n    ## Compiling Model\n    model.compile(\n            \n            optimizer = adamw_optimizer,\n            loss = \"sparse_categorical_crossentropy\",\n            metrics = [\"accuracy\"]\n        )\n    \n    \n    ## Training Model\n    model.fit(\n        train_ds,\n        epochs = epochs,\n        verbose = 0\n    )\n    \n    ## Evaluating Model\n    test_loss , test_score  = model.evaluate(test_ds, verbose = 1 )\n    \n    ## Saving Trained Model\n    model_save_path = save_dir + \"cifar-\" +  str(epochs) + \"_\" + str(learning_rate) +  \"_\" + str(weight_decay) +  \"_\" + str(int(is_aug)) + \".h5\"\n    if not os.path.isdir(save_dir):\n        model.save_weights(model_save_path)\n    else:\n        ## if model with same parameter already exists\n        model_save_path = save_dir + \"cifar-\" +  str(epochs) + \"_\" + str(learning_rate) +  \"_\" + str(weight_decay) + str(random.choice(np.arange(0,1000))) +  \".h5\"\n        model.save_weights(model_save_path)\n        \n    ## Clearing GPU memory\n    ## Clearing GPU memory\n    del model \n    gc.collect()\n    return model_save_path, test_score\n\ndef cifar_eval(model,test_ds):\n    \"\"\"\n    Returns Accuracy of model on test set \n    Args:\n    model : Trained tensorflow model\n    test_ds : Test dataset for evaluation\n    \"\"\"\n    \n    preds = model.predict(test_ds)\n    preds = preds.argmax(axis = 1 )\n    acc = np.sum(preds == cifar_test_labels) / len(cifar_test_labels)\n    return acc","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T04:48:13.263973Z","iopub.execute_input":"2022-06-22T04:48:13.264806Z","iopub.status.idle":"2022-06-22T04:48:13.281489Z","shell.execute_reply.started":"2022-06-22T04:48:13.264767Z","shell.execute_reply":"2022-06-22T04:48:13.280593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Image Data Training : </span>","metadata":{}},{"cell_type":"code","source":"epochs = [8,10,12]\nlearning_rate = [1e-4, 1e-5, 5e-5]\nweight_decay = [1e-4, 1e-4, 1e-5]\naugments = [None, augment1, augment2]\n\n## Creating parameters dictonary for \n## hyperparameter tuning \nparameters = [ {\n    \"epochs\": random.choice(epochs),\n    \"learning_rate\": random.choice(learning_rate),\n    \"weight_decay\" : random.choice(weight_decay) ,\n    \"aug_map\" : random.choice(augments) \n} for count in range(image_config.NUM_MODELS)]\ncifar_params = pd.DataFrame(parameters)\n\n\nmodel_paths = []\ntest_scores = []\n\nfor params in tqdm(parameters):\n    model_save_path, test_score = cifar_training(cifar_train, \n                                                 cifar_test,\n                                                 params[\"epochs\"], \n                                                 params[\"learning_rate\"],\n                                                 params[\"weight_decay\"],\n                                                 params[\"aug_map\"],\n                                                 save_dir = \"cifar/\")\n    \n    model_paths.append(model_save_path)\n    test_scores.append(test_score)\n\n## saving scores and model paths to dataframe    \ncifar_params[\"paths\"] = model_paths\ncifar_params[\"scores\"] = test_scores\n\n## soring scores in descending order\ncifar_params.sort_values(by = \"scores\", ascending= False, inplace = True)\ncifar_params.reset_index(drop= True, inplace = True)\n\n## saving params with respective scores and model paths\ncifar_params.to_csv(\"cifar_params.csv\", index = False)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T04:48:13.282895Z","iopub.execute_input":"2022-06-22T04:48:13.283469Z","iopub.status.idle":"2022-06-22T05:06:07.483615Z","shell.execute_reply.started":"2022-06-22T04:48:13.283429Z","shell.execute_reply":"2022-06-22T05:06:07.482702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Uniform Soups on Image Data: </span>","metadata":{}},{"cell_type":"code","source":"unifrom_soup_model, uniform_soup_acc = uniform_soup(\n    cifar_params[\"paths\"].values, \n    cifar_test, \n    create_cifar_model, \n    cifar_eval\n)\nprint(\"Accuracy of Uniform Soup:\", uniform_soup_acc )","metadata":{"execution":{"iopub.status.busy":"2022-06-22T05:06:07.485141Z","iopub.execute_input":"2022-06-22T05:06:07.485776Z","iopub.status.idle":"2022-06-22T05:06:13.396887Z","shell.execute_reply.started":"2022-06-22T05:06:07.485736Z","shell.execute_reply":"2022-06-22T05:06:13.39593Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Greedy Soups on Image Data: </span>","metadata":{}},{"cell_type":"code","source":"greedy_soup_model, greedy_soup_acc = greedy_soup(\n    cifar_params[\"paths\"].values,\n    cifar_test,\n    create_cifar_model,\n    cifar_eval\n)\nprint(\"Accuracy of Uniform Soup:\", greedy_soup_acc)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T05:06:13.398848Z","iopub.execute_input":"2022-06-22T05:06:13.39921Z","iopub.status.idle":"2022-06-22T05:06:32.954744Z","shell.execute_reply.started":"2022-06-22T05:06:13.399173Z","shell.execute_reply":"2022-06-22T05:06:32.952696Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Uniform and Greedy Soups Visualizaiton and Comparison: </span>","metadata":{}},{"cell_type":"code","source":"uniform_soup_pos = cifar_params[cifar_params[\"scores\"].values[::-1] > uniform_soup_acc].index[0] - 0.5\n\nfig, ax = plt.subplots(figsize = (18,5))\nplt.plot( cifar_params[\"scores\"].values[::-1], \"bo\", label = \"Individual Models\")\nplt.plot( uniform_soup_pos,uniform_soup_acc,  marker= \"D\", color = \"green\", markersize = 12, label = \"Uniform Soup\")\nplt.plot( len(cifar_params), greedy_soup_acc,  marker= \"^\", color = \"red\", markersize = 12, label = \"Greedy Soup\")\nax.get_xaxis().set_visible(False)\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model Soups on CIFAR 10 Data\")\nplt.legend();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T05:06:32.959349Z","iopub.execute_input":"2022-06-22T05:06:32.960884Z","iopub.status.idle":"2022-06-22T05:06:33.181875Z","shell.execute_reply.started":"2022-06-22T05:06:32.960844Z","shell.execute_reply":"2022-06-22T05:06:33.180991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"# <center><span style=\"color:#00BFC4;\"> Model Soups on Tabular Data</span></center> \n<a id=\"6\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### For Tabular data, Famous Titanic Competition Data is used. The Target variable is binary and represents wheter a passenger survived the Titanic Crash or not.\n####  Link to Competition Data - https://www.kaggle.com/competitions/titanic/data","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Titanic Data Loading and Processing    : </span>","metadata":{}},{"cell_type":"code","source":"## All Data Processing is taken from one of my other \n## notebook on the same competition. \n## Link to notebook - https://www.kaggle.com/code/odins0n/titanic-27-different-models-comparison\n\n\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv('../input/titanic/test.csv')\n\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)\n\ntrain_X = train.drop(\"Survived\" , axis =1 )\ntrain_y = train[\"Survived\"]\n\nX_train , X_test , y_train , y_test = train_test_split(train_X , train_y, random_state = 12 ,test_size =0.33)\n\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nclass tabular_config:\n    NUM_MODELS = 20","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T05:06:33.183312Z","iopub.execute_input":"2022-06-22T05:06:33.183642Z","iopub.status.idle":"2022-06-22T05:06:33.270807Z","shell.execute_reply.started":"2022-06-22T05:06:33.183608Z","shell.execute_reply":"2022-06-22T05:06:33.26987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Tabular Data Training : </span>","metadata":{}},{"cell_type":"code","source":"def create_titanic_model(dropout_prob = 0):\n    \"\"\"\n    Returns TensorFlow DNN Model\n    Args:\n    dropout_prob : Dropout Probability for Dropout Layers\n    \"\"\"    \n        \n    model= tf.keras.Sequential()\n    model.add(tf.keras.layers.Input(shape = (8)))\n    model.add(tf.keras.layers.Dense(1024,activation='relu')) \n    model.add(tf.keras.layers.Dropout(dropout_prob))\n    model.add(tf.keras.layers.Dense(512,activation='relu')) \n    model.add(tf.keras.layers.Dropout(dropout_prob))\n    model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n    return model\n\ndef titanic_training(train_ds, \n                   test_ds,\n                   epochs, \n                   learning_rate, \n                   weight_decay,\n                   dropout_prob,\n                   save_dir = \"titanic/\"):\n    \"\"\"\n    Returns Saved trained model's path and test evaluation score\n    Args:\n    train_ds : Train Dataset in tfds format.\n    test_ds : Test Dataset in tfds format.\n    epochs : Int, Trainig Epochs count.\n    learning_rate : Float, Training Learning Rate\n    weight_decay : Float, AdamW optimizer Weight Decay\n    save_dir : Str, Model Save Directory Prefix\n    \"\"\"\n    ## Creating directory for saving models\n    \n    if not os.path.isdir(save_dir):\n        os.makedirs(save_dir)\n    ## AdamW Optimizer Setup    \n    adamw_optimizer = tfa.optimizers.AdamW(weight_decay= weight_decay,\n                                     learning_rate= learning_rate)\n    \n    ## Instantiating model\n    tf.keras.backend.clear_session()\n    model = create_titanic_model(dropout_prob)\n    \n    ## Compiling Model\n    model.compile(\n            \n            optimizer = adamw_optimizer,\n            loss = \"binary_crossentropy\",\n            metrics = [\"accuracy\"]\n        )\n    \n    ## Training Model\n    model.fit(\n        train_ds[0],\n        train_ds[1],\n        epochs = epochs,\n        verbose = 0\n    )\n    \n    ## Evaluating Model\n    test_loss , test_score  = model.evaluate(test_ds[0], test_ds[1], verbose = 1 )\n    \n    ## Saving Trained Model\n    model_save_path =save_dir +  save_dir + \"titanic-\"  +  str(epochs) + \"_\" + str(learning_rate) +  \"_\" + str(weight_decay) + \".h5\"\n    if not os.path.isdir(save_dir):\n        model.save_weights(model_save_path)\n    else:\n        ## if model with same parameter already exists\n        model_save_path = save_dir + \"titanic-\" +  str(epochs) + \"_\" + str(learning_rate) +  \"_\" + str(weight_decay) + str(random.choice(np.arange(0,1000))) +  \".h5\"\n        model.save_weights(model_save_path)\n        \n    ## Clearing GPU memory\n    del model \n    gc.collect()\n    return model_save_path, test_score\n\ndef titanic_eval(model,test_ds):\n    \"\"\"\n    Returns Accuracy of model on test set \n    Args:\n    model : Trained tensorflow model\n    test_ds : Test dataset for evaluation\n    \"\"\"\n    preds = model.predict(test_ds[0])\n    preds = preds.squeeze().round().astype(\"int\")\n    acc = np.sum(preds == test_ds[1]) / len(test_ds[1])\n    return acc","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T05:06:33.272154Z","iopub.execute_input":"2022-06-22T05:06:33.272494Z","iopub.status.idle":"2022-06-22T05:06:33.289188Z","shell.execute_reply.started":"2022-06-22T05:06:33.272462Z","shell.execute_reply":"2022-06-22T05:06:33.28824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = [20,25,30]\nlearning_rate = [1e-2, 1e-3, 1e-4, 2e-5, 5e-5]\nweight_decay = [1e-4, 1e-4, 1e-5]\ndropout_probs = [0.2,0.3,0.4]\n\n\n## Creating parameters dictonary for \n## hyperparameter tuning \nparameters = [ {\n    \"epochs\": random.choice(epochs),\n    \"learning_rate\": random.choice(learning_rate),\n    \"weight_decay\" : random.choice(weight_decay) ,\n    \"dropout_prob\" : random.choice(dropout_probs) \n} for count in range(tabular_config.NUM_MODELS)]\n\n## creating a dataframe for parameters\ntitanic_params = pd.DataFrame(parameters)\n\nmodel_paths = []\ntest_scores = []\n\n\n## Training models with different parameters\nfor params in tqdm(parameters):\n    model_save_path, test_score = titanic_training((X_train, y_train), \n                                                 (X_test, y_test),\n                                                 params[\"epochs\"], \n                                                 params[\"learning_rate\"],\n                                                 params[\"weight_decay\"],\n                                                 params[\"dropout_prob\"],\n                                                 save_dir = \"titanic/\")\n    \n    model_paths.append(model_save_path)\n    test_scores.append(test_score)\n\n## saving scores and model paths to dataframe\ntitanic_params[\"paths\"] = model_paths\ntitanic_params[\"scores\"] = test_scores\n\n\n## soring scores in descending order\ntitanic_params.sort_values(by = \"scores\", ascending= False, inplace = True)\ntitanic_params.reset_index(drop = True, inplace = True)\n\n## saving params with respective scores and model paths\ntitanic_params.to_csv(\"titanic_params.csv\", index = False)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T05:06:33.290385Z","iopub.execute_input":"2022-06-22T05:06:33.291402Z","iopub.status.idle":"2022-06-22T05:07:10.5974Z","shell.execute_reply.started":"2022-06-22T05:06:33.291366Z","shell.execute_reply":"2022-06-22T05:07:10.596432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Uniform Soups on Tabular Data: </span>","metadata":{}},{"cell_type":"code","source":"unifrom_soup_model, uniform_soup_acc = uniform_soup(\n    titanic_params[\"paths\"].values, \n    (X_test,y_test),\n    create_titanic_model,\n    titanic_eval\n)\nprint(\"Accuracy of Uniform Soup:\", uniform_soup_acc )","metadata":{"execution":{"iopub.status.busy":"2022-06-22T05:07:10.598751Z","iopub.execute_input":"2022-06-22T05:07:10.599716Z","iopub.status.idle":"2022-06-22T05:07:10.921939Z","shell.execute_reply.started":"2022-06-22T05:07:10.599677Z","shell.execute_reply":"2022-06-22T05:07:10.920926Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Greedy Soups on Tabular Data: </span>","metadata":{}},{"cell_type":"code","source":"greedy_soup_model, greedy_soup_acc = greedy_soup(\n    titanic_params[\"paths\"].values, \n    (X_test,y_test),\n    create_titanic_model,\n    titanic_eval\n)\nprint(\"Accuracy of Greedy Soup:\", greedy_soup_acc)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T05:07:10.923456Z","iopub.execute_input":"2022-06-22T05:07:10.92408Z","iopub.status.idle":"2022-06-22T05:07:13.470356Z","shell.execute_reply.started":"2022-06-22T05:07:10.924034Z","shell.execute_reply":"2022-06-22T05:07:13.469291Z"},"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Uniform and Greedy Soups Visualizaiton and Comparison: </span>","metadata":{}},{"cell_type":"code","source":"uniform_soup_pos = titanic_params[titanic_params[\"scores\"].values[::-1] > uniform_soup_acc].index[0] - 0.5\n\nfig, ax = plt.subplots(figsize = (18,5))\nplt.plot( titanic_params[\"scores\"].values[::-1], \"bo\", label = \"Individual Models\")\nplt.plot( uniform_soup_pos,uniform_soup_acc,  marker= \"D\", color = \"green\", markersize = 12, label = \"Uniform Soup\")\nplt.plot( len(titanic_params), greedy_soup_acc,  marker= \"^\", color = \"red\", markersize = 12, label = \"Greedy Soup\")\nax.get_xaxis().set_visible(False)\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model Soups on Titanic Data\")\nplt.legend();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T05:07:13.472228Z","iopub.execute_input":"2022-06-22T05:07:13.473012Z","iopub.status.idle":"2022-06-22T05:07:13.661593Z","shell.execute_reply.started":"2022-06-22T05:07:13.472973Z","shell.execute_reply":"2022-06-22T05:07:13.660574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"# <center><span style=\"color:#00BFC4;\"> Model Soups on Text Data</span></center> \n<a id=\"7\"></a>","metadata":{}},{"cell_type":"markdown","source":"#### For Text data, Top 20 Play Store App reviews dataset is used. Sentiment analysis will be done andt target variable will be  binary .\n#### Link to Top 20 Play Store App reviews dataset - https://www.kaggle.com/datasets/odins0n/top-20-play-store-app-reviews-daily-update","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Setting up TF.data Pipeline  : </span>","metadata":{}},{"cell_type":"code","source":"## loading data\ndata = pd.read_csv(\"../input/top-20-play-store-app-reviews-daily-update/all_combined.csv\")\ndata.dropna(inplace = True)\n\n## filtering only Facebook App Reviews\nreviews = data[data[\"app\"] == \"Facebook\"]\n\n## converting review scores to binary target\nreviews[\"score\"] = reviews[\"score\"].map(lambda x: 0 if x<=3 else 1 )\n\n\nclass text_config:\n    MODEL_NAME = \"distilbert-base-uncased\"\n    TOKENIZER_NAME = \"distilbert-base-uncased\"\n    MAX_LEN = 64\n    BATCH_SIZE = 128\n    LOWER_CASE = True\n    RANDOM_STATE = 12\n    TEST_SIZE = 0.2\n    NUM_MODELS = 10\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T09:06:17.617664Z","iopub.execute_input":"2022-06-22T09:06:17.6187Z","iopub.status.idle":"2022-06-22T09:06:18.381792Z","shell.execute_reply.started":"2022-06-22T09:06:17.618654Z","shell.execute_reply":"2022-06-22T09:06:18.380818Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Hugging Face Dataset API to tokenize data\ndataset = Dataset.from_pandas(reviews)\ndataset = dataset.rename_columns({\"score\": \"label\"})\ndataset = dataset.remove_columns([\"reviewId\", \"app\"])\ndataset = dataset.train_test_split(test_size = text_config.TEST_SIZE, seed = text_config.RANDOM_STATE )\nreviews_test_labels = dataset[\"test\"][\"label\"]\n\n## Instantiating Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(text_config.MODEL_NAME, do_lower_case = text_config.LOWER_CASE)\n\ndef tokenize(batch):\n    return tokenizer(batch[\"content\"], max_length = text_config.MAX_LEN, padding=True, truncation=True)\n\n\n## tokenizing data\ndataset = dataset.map(tokenize)\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, \n                                        padding = \"max_length\",\n                                        max_length = text_config.MAX_LEN,\n                                        return_tensors=\"tf\")\n\n## Converting huggingface datasets to tfds\ntrain_ds = dataset[\"train\"].to_tf_dataset( \n    columns = [\"input_ids\", \"attention_mask\"],\n    label_cols = [\"labels\"],\n    batch_size = text_config.BATCH_SIZE,\n    collate_fn= data_collator,\n    shuffle = True\n)\n\n## Converting huggingface datasets to tfds\ntest_ds = dataset[\"test\"].to_tf_dataset(\n    columns = [\"input_ids\", \"attention_mask\"],\n    label_cols = [\"labels\"],\n    batch_size = text_config.BATCH_SIZE,\n    collate_fn= data_collator,\n    shuffle = False\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T09:06:19.112014Z","iopub.execute_input":"2022-06-22T09:06:19.112389Z","iopub.status.idle":"2022-06-22T09:06:41.771345Z","shell.execute_reply.started":"2022-06-22T09:06:19.112358Z","shell.execute_reply":"2022-06-22T09:06:41.770366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Text Data Training : </span>","metadata":{}},{"cell_type":"code","source":"def create_reviews_model():\n    \"\"\"\n    Returns Transformer Model ( Tensorflow )\n    \"\"\"    \n    input_ids = tf.keras.layers.Input(\n            shape=(text_config.MAX_LEN), name=\"input_ids\", dtype=tf.int64\n        )\n    attention_masks = tf.keras.layers.Input(\n                shape=(text_config.MAX_LEN), name=\"attention_mask\", dtype=tf.int64\n            )\n    \n    ## dowloading pretrained wieghts from huggingface \n    bert = TFAutoModel.from_pretrained(text_config.MODEL_NAME)\n    out = bert(input_ids,attention_masks)[0]\n    out = tf.keras.layers.Dropout(0.3)(out)\n    out = tf.keras.layers.Dense(1024)(out)\n    out = tf.keras.layers.Dropout(0.3)(out)\n    out = tf.keras.layers.Dense(1, activation=\"sigmoid\")(out)\n\n    model = tf.keras.models.Model(\n                    inputs=[input_ids, attention_masks], outputs=out            \n                )\n    return model\n\ndef reviews_training(train_ds, \n                   test_ds,\n                   epochs, \n                   learning_rate, \n                   weight_decay,\n                   save_dir = \"reviews/\"):\n    \"\"\"\n    Returns Saved trained model's path and test evaluation score\n    Args:\n    train_ds : Train Dataset in tfds format.\n    test_ds : Test Dataset in tfds format.\n    epochs : Int, Trainig Epochs count.\n    learning_rate : Float, Training Learning Rate\n    weight_decay : Float, AdamW optimizer Weight Decay\n    save_dir : Str, Model Save Directory Prefix\n    \"\"\"\n    ## Creating directory for saving models\n    if not os.path.isdir(save_dir):\n        os.makedirs(save_dir)\n        \n    ## AdamW Optimizer Setup \n    adamw_optimizer = tfa.optimizers.AdamW(weight_decay= weight_decay,\n                                     learning_rate= learning_rate)\n    \n    ## Instantiating model\n    model = create_reviews_model()\n    \n    ## Compiling Model\n    model.compile(\n            optimizer = adamw_optimizer,\n            loss = \"binary_crossentropy\",\n            metrics = [\"accuracy\"]\n        )\n    \n    ## Training Model\n    model.fit(\n        train_ds,\n        epochs = epochs,\n        verbose = 0\n    )\n    ## Evaluating Model\n    test_loss , test_score  = model.evaluate(test_ds, verbose = 1 )\n    \n    ## Saving Trained Model\n    model_save_path = save_dir + \"reviews-\" +  str(epochs) + \"_\" + str(learning_rate) +  \"_\" + str(weight_decay) + \".h5\"\n    \n    if not os.path.isdir(save_dir):\n        model.save_weights(model_save_path)\n    else:\n        ## if model with same parameter already exists\n        model_save_path =save_dir +  \"reviews-\" +  str(epochs) + \"_\" + str(learning_rate) +  \"_\" + str(weight_decay) + str(random.choice(np.arange(0,1000))) +  \".h5\"\n        model.save_weights(model_save_path)\n        \n    ## Clearing GPU memory\n    \n    del model \n    gc.collect()\n    return model_save_path, test_score\n\ndef reviews_eval(model,test_ds):\n    \"\"\"\n    Returns Accuracy of model on test set \n    Args:\n    model : Trained tensorflow model\n    test_ds : Test dataset for evaluation\n    \"\"\"\n    model.compile(loss=  \"binary_crossentropy\",\n                  optimizer = \"adam\",\n                  metrics = [\"accuracy\"])\n    loss, acc = model.evaluate(test_ds, verbose = 0)\n    return acc","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T09:06:41.773605Z","iopub.execute_input":"2022-06-22T09:06:41.774284Z","iopub.status.idle":"2022-06-22T09:06:41.792744Z","shell.execute_reply.started":"2022-06-22T09:06:41.774245Z","shell.execute_reply":"2022-06-22T09:06:41.791752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = [3,4,5]\nlearning_rate = [1e-5, 2e-5, 5e-5]\nweight_decay = [1e-4, 1e-5, 2e-5]\n\n\n## Creating parameters dictonary for \n## hyperparameter tuning \nparameters = [ {\n    \"epochs\": random.choice(epochs),\n    \"learning_rate\": random.choice(learning_rate),\n    \"weight_decay\" : random.choice(weight_decay) ,\n} for count in range(text_config.NUM_MODELS)]\n\n## creating a dataframe for parameters\nreviews_params = pd.DataFrame(parameters)\n\nmodel_paths = []\ntest_scores = []\n\n\n## Training models with different parameters\nfor params in tqdm(parameters):\n    model_save_path, test_score = reviews_training(train_ds, \n                                                   test_ds,\n                                                 params[\"epochs\"], \n                                                 params[\"learning_rate\"],\n                                                 params[\"weight_decay\"],\n                                                 save_dir = \"reviews/\")\n    \n    model_paths.append(model_save_path)\n    test_scores.append(test_score)\n    \n## saving scores and model paths to dataframe\nreviews_params[\"paths\"] = model_paths\nreviews_params[\"scores\"] = test_scores\n\n\n## soring scores in descending order\nreviews_params.sort_values(by = \"scores\", ascending= False, inplace = True)\nreviews_params.reset_index(drop = True, inplace = True)\n\n## saving params with respective scores and model paths\nreviews_params.to_csv(\"review_params.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T09:06:41.793785Z","iopub.execute_input":"2022-06-22T09:06:41.795098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Uniform Soups on Text Data: </span>","metadata":{}},{"cell_type":"code","source":"unifrom_soup_model, uniform_soup_acc = uniform_soup(\n    reviews_params[\"paths\"].values, \n    test_ds,\n    create_reviews_model,\n    reviews_eval\n)\nprint(\"Accuracy of Uniform Soup:\", uniform_soup_acc )","metadata":{"execution":{"iopub.status.busy":"2022-06-22T05:34:46.010568Z","iopub.execute_input":"2022-06-22T05:34:46.011266Z","iopub.status.idle":"2022-06-22T05:34:53.915552Z","shell.execute_reply.started":"2022-06-22T05:34:46.011229Z","shell.execute_reply":"2022-06-22T05:34:53.914554Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Greedy Soups on Text Data: </span>","metadata":{}},{"cell_type":"code","source":"greedy_soup_model, greedy_soup_acc = greedy_soup(\n    reviews_params[\"paths\"].values, \n    test_ds,\n    create_reviews_model,\n    reviews_eval\n)\nprint(\"Accuracy of Greedy Soup:\", greedy_soup_acc)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T05:35:13.422907Z","iopub.execute_input":"2022-06-22T05:35:13.423255Z","iopub.status.idle":"2022-06-22T05:35:35.181956Z","shell.execute_reply.started":"2022-06-22T05:35:13.423226Z","shell.execute_reply":"2022-06-22T05:35:35.180994Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Uniform and Greedy Soups Visualizaiton and Comparison: </span>","metadata":{}},{"cell_type":"code","source":"uniform_soup_pos = reviews_params[reviews_params[\"scores\"].values[::-1] > uniform_soup_acc].index[0] - 0.5\n\nfig, ax = plt.subplots(figsize = (18,5))\nplt.plot( reviews_params[\"scores\"].values[::-1], \"bo\", label = \"Individual Models\")\nplt.plot( uniform_soup_pos,uniform_soup_acc,  marker= \"D\", color = \"green\", markersize = 12, label = \"Uniform Soup\")\nplt.plot( len(reviews_params), greedy_soup_acc,  marker= \"^\", color = \"red\", markersize = 12, label = \"Greedy Soup\")\nax.get_xaxis().set_visible(False)\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model Soups on Play Store App Reviws Data\")\nplt.legend();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T05:35:45.70079Z","iopub.execute_input":"2022-06-22T05:35:45.701337Z","iopub.status.idle":"2022-06-22T05:35:45.890598Z","shell.execute_reply.started":"2022-06-22T05:35:45.701301Z","shell.execute_reply":"2022-06-22T05:35:45.889597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"# <center><span style=\"color:#00BFC4;\"> Model Soups on Time-Series Data</span></center> \n<a id=\"8\"></a>","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Setting up TF.data Pipeline  : </span>","metadata":{}},{"cell_type":"markdown","source":"##### For Time-Series data, Exchange Rate to USD dataset is used. Time-Series forecasting is done on USD-UK_POUND Exchange pair\n##### Link to Exchange Rate to USD dataset  - https://kaggle.com/datasets/robikscube/exhange-rates-to-usd-from-imforg-updated-daily/","metadata":{}},{"cell_type":"code","source":"## loading data\ndata = pd.read_csv(\"../input/exhange-rates-to-usd-from-imforg-updated-daily/exchange_rate_to_usd.csv\",\n                   parse_dates=[\"date\"]\n                  )\n\n## filtering data\ndataset = data[[\"date\",\"uk_pound_to_usd\"]]\ndataset.dropna(inplace= True)\n\n## Spliting data to train and test split \ntest_split = 4* (len(dataset) // 5 )\ntrain_dataset = dataset.iloc[:test_split]\ntest_dataset = dataset.iloc[test_split:]\n\nclass timeseries_config:\n    WINDOW_SIZE = 10\n    BATCH_SIZE = 128\n    SHUFFLE_BUFFER = 1024\n    NUM_MODELS = 20","metadata":{"execution":{"iopub.status.busy":"2022-06-22T05:35:53.280089Z","iopub.execute_input":"2022-06-22T05:35:53.280487Z","iopub.status.idle":"2022-06-22T05:35:53.340517Z","shell.execute_reply.started":"2022-06-22T05:35:53.280453Z","shell.execute_reply":"2022-06-22T05:35:53.339541Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    \"\"\"\n    Returns Prefetched TFDS for train split\n    Args:\n    series : Array, Train Split values.\n    window_size : Int, Window SIze\n    batch_size : Int, Batch Size\n    shuffle_buffer : Int, Suffle Buffer for shuffling train split\n    \"\"\"\n    ## loading data from numpy arrays/ list\n    dataset = tf.data.Dataset.from_tensor_slices(series)\n    \n    ## Crearting windows of \"window_size\"\n    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n    \n    ## Shuffling data and seperating inputs and ouputs\n    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n    \n    ## Batchin and prefetching data\n    dataset = dataset.batch(batch_size, drop_remainder= True).prefetch(1)\n    return dataset\n\ndef test_windowed_dataset(series, window_size, batch_size):\n    \"\"\"\n    Returns Prefetched TFDS for test split\n    Args:\n    series : Array, Train Split values.\n    window_size : Int, Window SIze\n    batch_size : Int, Batch Size\n    \"\"\"\n    \n    ## loading data from numpy arrays/ list\n    dataset = tf.data.Dataset.from_tensor_slices(series)\n    \n    ## Crearting windows of \"window_size\"\n    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n    ## Serating inputs and ouputs\n    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n    \n    # Batchin and prefetching data\n    dataset = dataset.batch(batch_size, drop_remainder= False).prefetch(1)\n    return dataset\n\n\ntrain_dataset = train_windowed_dataset(\n    train_dataset[\"uk_pound_to_usd\"].values,\n    timeseries_config.WINDOW_SIZE,\n    timeseries_config.BATCH_SIZE,\n    timeseries_config.SHUFFLE_BUFFER\n)\n\ntest_dataset = test_windowed_dataset(\n    test_dataset[\"uk_pound_to_usd\"].values,\n    timeseries_config.WINDOW_SIZE,\n    timeseries_config.BATCH_SIZE,\n)\nusd_test_labels = next(iter(test_dataset.unbatch().map(lambda x,y:y).batch(918))).numpy()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T05:35:54.057616Z","iopub.execute_input":"2022-06-22T05:35:54.057985Z","iopub.status.idle":"2022-06-22T05:35:54.235013Z","shell.execute_reply.started":"2022-06-22T05:35:54.057954Z","shell.execute_reply":"2022-06-22T05:35:54.23408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Time-Series Data Training : </span>","metadata":{}},{"cell_type":"code","source":"def create_usd_model(dropout_prob = 0):\n    \"\"\"\n    Returns TensorFlow DNN Model\n    Args:\n    dropout_prob : Dropout Probability for Dropout Layers\n    \"\"\"    \n    model= tf.keras.Sequential()\n    model.add(tf.keras.layers.Input(shape = (10)))\n    model.add(tf.keras.layers.Dense(512,activation='relu' ))\n    model.add(tf.keras.layers.Dropout(dropout_prob))\n    model.add(tf.keras.layers.Dense(64,activation='relu'))\n    model.add(tf.keras.layers.Dropout(dropout_prob))\n    model.add(tf.keras.layers.Dense(1))\n    return model\n\n\ndef usd_training(train_ds, \n                   test_ds,\n                   epochs, \n                   learning_rate, \n                   weight_decay,\n                   save_dir = \"usd/\"):\n    \"\"\"\n    Returns Saved trained model's path and test evaluation score\n    Args:\n    train_ds : Train Dataset in tfds format.\n    test_ds : Test Dataset in tfds format.\n    epochs : Int, Trainig Epochs count.\n    learning_rate : Float, Training Learning Rate\n    weight_decay : Float, AdamW optimizer Weight Decay\n    save_dir : Str, Model Save Directory Prefix\n    \"\"\"\n    ## Creating directory for saving models\n    if not os.path.isdir(save_dir):\n        os.makedirs(save_dir)\n        \n    ## AdamW Optimizer Setup \n    adamw_optimizer = tfa.optimizers.AdamW(weight_decay= weight_decay,\n                                     learning_rate= learning_rate)\n    \n    ## Instantiating model\n    model = create_usd_model()\n    \n    ## Compiling Model\n    model.compile(\n            optimizer = adamw_optimizer,\n            loss = \"mse\",\n            metrics = [\"mae\"]\n        )\n    \n    ## Training Model\n    model.fit(\n        train_ds,\n        epochs = epochs,\n        verbose = 0\n    )\n    ## Evaluating Model\n    test_loss , test_score  = model.evaluate(test_ds, verbose = 1 )\n    \n    ## Saving Trained Model\n    model_save_path = save_dir + \"usd-\" +  str(epochs) + \"_\" + str(learning_rate) +  \"_\" + str(weight_decay) + \".h5\"\n    \n    if not os.path.isdir(save_dir):\n        model.save_weights(model_save_path)\n    else:\n        ## if model with same parameter already exists\n        model_save_path = save_dir + \"usd-\" +  str(epochs) + \"_\" + str(learning_rate) +  \"_\" + str(weight_decay) + str(random.choice(np.arange(0,1000))) +  \".h5\"\n        model.save_weights(model_save_path)\n        \n    ## Clearing GPU memory\n    del model \n    gc.collect()\n    return model_save_path, test_score\n\ndef usd_eval(model,test_ds):\n    \"\"\"\n    Returns Accuracy of model on test set \n    Args:\n    model : Trained tensorflow model\n    test_ds : Test dataset for evaluation\n    \"\"\"\n    preds = model.predict(test_ds)\n    mae = mean_absolute_error(usd_test_labels, preds)\n    return mae","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T06:04:35.546526Z","iopub.execute_input":"2022-06-22T06:04:35.547137Z","iopub.status.idle":"2022-06-22T06:04:35.586813Z","shell.execute_reply.started":"2022-06-22T06:04:35.547092Z","shell.execute_reply":"2022-06-22T06:04:35.585509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = [2,3,4]\nlearning_rate = [1e-2, 1e-3, 5e-3]\nweight_decay = [1e-5, 2e-5, 5e-5]\n\n\n## Creating parameters dictonary for \n## hyperparameter tuning \nparameters = [ {\n    \"epochs\": random.choice(epochs),\n    \"learning_rate\": random.choice(learning_rate),\n    \"weight_decay\" : random.choice(weight_decay) ,\n} for count in range(timeseries_config.NUM_MODELS)]\n\n## creating a dataframe for parameters\nusd_params = pd.DataFrame(parameters)\n\nmodel_paths = []\ntest_scores = []\n\n\n## Training models with different parameters\nfor params in tqdm(parameters):\n    model_save_path, test_score = usd_training(train_dataset,\n                                                 test_dataset,\n                                                 params[\"epochs\"], \n                                                 params[\"learning_rate\"],\n                                                 params[\"weight_decay\"],\n                                                 save_dir = \"usd/\")\n    \n    model_paths.append(model_save_path)\n    test_scores.append(test_score)\n    \n## saving scores and model paths to dataframe\nusd_params[\"paths\"] = model_paths\nusd_params[\"scores\"] = test_scores\n\n\n## soring scores in ascending order ( lower mae)\nusd_params.sort_values(by = \"scores\", ascending= True, inplace = True)\nusd_params.reset_index(drop = True, inplace = True)\n\n## saving params with respective scores and model paths\nusd_params.to_csv(\"usd_params.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:04:38.198062Z","iopub.execute_input":"2022-06-22T06:04:38.198413Z","iopub.status.idle":"2022-06-22T06:05:23.535818Z","shell.execute_reply.started":"2022-06-22T06:04:38.198383Z","shell.execute_reply":"2022-06-22T06:05:23.534712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Uniform Soups on Time-Series Data: </span>","metadata":{}},{"cell_type":"code","source":"unifrom_soup_model, uniform_soup_mae = uniform_soup(\n    usd_params[\"paths\"].values, \n    test_dataset,\n    create_usd_model,\n    usd_eval\n)\nprint(\"MAE of Uniform Soup:\", uniform_soup_mae )","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:05:23.537979Z","iopub.execute_input":"2022-06-22T06:05:23.538575Z","iopub.status.idle":"2022-06-22T06:05:23.8897Z","shell.execute_reply.started":"2022-06-22T06:05:23.538536Z","shell.execute_reply":"2022-06-22T06:05:23.888806Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Greedy Soups on Time-Series Data: </span>","metadata":{}},{"cell_type":"code","source":"## mae/mse score version of greedy soup\ndef greedy_soup_mae(model_paths, test_ds, model_fun, evaluate_fun):\n    \"\"\"\n    Returns Greedy Soup model and mae on test set (for time series/ regression data)\n    Args:\n    model_paths : List, List of saved model paths\n    test_ds : Test Dataset in tfds format.\n    model_fun : Fun, Model Instantiating Function\n    evaluate_fun : Fun, Model Test Set Evaluation Function\n    \"\"\"\n    ## Creating intial soup with best performing model \n    soups =  [model_paths[0]]\n    \n    ## Instantiating model\n    \n    tf.keras.backend.clear_session()\n    model = model_fun()\n    \n    ## Loading best performing model's weights \n    model.load_weights(model_paths[0])\n    \n    ## Scoirng best performing model on test set \n    score_final = evaluate_fun(model,test_ds)\n    \n    ## Iterating over the remaining models \n    for path in tqdm(model_paths[1:]):\n        \n        ## Creating a temp soup \n        temp_soup =  soups.copy()\n        temp_soup.append(path)\n        \n        ## Getting score from temp soup\n        model, score = uniform_soup(temp_soup,test_ds,model_fun, evaluate_fun, disable_tqdm= True)\n        \n        ## Conditioning current model for appneding in main soup\n        ## if score from the temp soup is more than best perofming model\n        ## the temp soup path is appended to main soup \n        if score < score_final:\n            score_final = score\n            soups.append(path)\n\n    return model, score_final","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-22T06:05:23.890956Z","iopub.execute_input":"2022-06-22T06:05:23.891299Z","iopub.status.idle":"2022-06-22T06:05:23.899879Z","shell.execute_reply.started":"2022-06-22T06:05:23.891262Z","shell.execute_reply":"2022-06-22T06:05:23.898869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"greedy_soup_model, greedy_soup_mae = greedy_soup_mae(\n    usd_params[\"paths\"].values, \n    test_dataset,\n    create_usd_model,\n    usd_eval\n)\nprint(\"MAE of Greedy Soup:\", greedy_soup_mae)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:05:23.902179Z","iopub.execute_input":"2022-06-22T06:05:23.902846Z","iopub.status.idle":"2022-06-22T06:05:28.828597Z","shell.execute_reply.started":"2022-06-22T06:05:23.902809Z","shell.execute_reply":"2022-06-22T06:05:28.827609Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:#e76f51;\"> Uniform and Greedy Soups Visualizaiton and Comparison: </span>","metadata":{}},{"cell_type":"code","source":"uniform_soup_pos = usd_params[usd_params[\"scores\"].values[::-1] < uniform_soup_mae].index[0] - 0.5\n\nfig, ax = plt.subplots(figsize = (18,5))\nplt.plot( usd_params[\"scores\"].values[::-1], \"bo\", label = \"Individual Models\")\nplt.plot( uniform_soup_pos,uniform_soup_mae,  marker= \"D\", color = \"green\", markersize = 12, label = \"Uniform Soup\")\nplt.plot( len(usd_params), greedy_soup_mae,  marker= \"^\", color = \"red\", markersize = 12, label = \"Greedy Soup\")\nax.get_xaxis().set_visible(False)\nplt.ylabel(\"MAE\")\nplt.title(\"Model Soups on USD Exchange Rate Data\")\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-06-22T06:05:28.829917Z","iopub.execute_input":"2022-06-22T06:05:28.830795Z","iopub.status.idle":"2022-06-22T06:05:29.015729Z","shell.execute_reply.started":"2022-06-22T06:05:28.830755Z","shell.execute_reply":"2022-06-22T06:05:29.014623Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#toc\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"color:#00BFC4;\"> References  : </span>","metadata":{}},{"cell_type":"markdown","source":"https://arxiv.org/abs/2203.05482\n\nhttps://paperswithcode.com/paper/model-soups-averaging-weights-of-multiple\n\nhttps://github.com/mlfoundations/model-soups\n\nhttps://www.kaggle.com/jalammar/intro-to-data-input-pipelines-with-tf-data\n\nhttps://www.kaggle.com/code/odins0n/jax-flax-tf-data-vision-transformers-tutorial\n\nhttps://www.kaggle.com/code/odins0n/titanic-27-different-models-comparison\n\nhttps://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C4/W2/ungraded_labs/C4_W2_Lab_1_features_and_labels.ipynb\n\nhttps://www.kaggle.com/code/odins0n/play-store-reviews-starter-sentiment-analysis\n","metadata":{}},{"cell_type":"markdown","source":"    \n### <center>Thank you for readingüôÇ</center><br>\n### <center>If you have any feedback, please let me know!</center><br>\n","metadata":{}}]}