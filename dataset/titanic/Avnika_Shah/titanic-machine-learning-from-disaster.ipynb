{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/af/bf/af/afbfafac1e700ed3ed9b4a4157a7fa98.jpg)\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/titanic/train.csv\" )\ntit1=train.select_dtypes(include=['float64','int64','object'])\ntrain.info()\n\ntest=pd.read_csv(\"../input/titanic/test.csv\")\ntit2=test.select_dtypes(include=['float64','int64','object'])\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We should know the size of the data we are working with.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train shape:\",train.shape)\nprint(\"test shape :\",test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tit1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tit2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idtrain=train['PassengerId']\nidtest=test['PassengerId']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Adding a column for Survived which has to be predicted in the test data.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tit2['survived']=np.nan\ntit2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EXPLORING FEATURES**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**First we start by checking the counts of survived(1) and dead(0).\nthus from the below graoh it is clear that there were more deaths than the ratio of survivors.\nWe also plot of graph for the division of genders, to see the ratio between men and women.\nwhen the graph i splotted we see that the range of women seem more equivalent to the range of survivors and the range of deaths seem more closely related to the range of men.\nSo thus that mean that there were more women who survuived?\nWe shall se that further.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(4,4))\nplt.title('SURVIVED',size=20)\ntit1.Survived.value_counts().plot.bar(color=['red','green'])\n\nplt.figure(figsize=(4,4))\nplt.title('SEX',size=20)\ntit1.Sex.value_counts().plot.bar(color=['skyblue','pink'])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets find out the Survival Rate**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total=train['Survived'].sum()\nprint(\"Total Survivors\",total)\npercent=round(np.mean(train['Survived']),3)*100\nprint(\"Percentage of Survivors:\",percent)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets find out the percentage of Women and Men**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmen=train[train['Sex']=='male']\nwomen=train[train['Sex']=='female']\nm=men['Sex'].count()\nw=women['Sex'].count()\nprint(\"male:\",m)\nprint(\"female:\",w)\nprint(\"percentage of women:\",round(w/(m+w)*100))\nprint(\"percentage of men:\",round(m/(m+w)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets check for the number of Null Values in our DATA SET**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**AGE and CABIN have the higest number of Null Values,so they will not be of major help since most of the values are missing,especially CABIN.\nBut lets see the Maximum age groups present.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Lets assign X value to all the NAN values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Cabin'] = train['Cabin'].fillna('X')\ntest['Cabin']=test['Cabin'].fillna('X')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Age'].hist(bins=40,color='salmon')\nplt.title(\"AGE\",size=20)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets examine the types of classes that were present**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.title(\"CLASS DIVISION\",size=20)\ntit1.Pclass.value_counts().plot.bar(color=['olive','coral','gold'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking out the distribution of Fares**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Fare'].hist(bins = 80, color = 'orange')\nplt.title(\"FARE\",size=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking out Embarked Attribute.\n  It has 3 discrete Divisions,namely S , C ,Q.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.title(\"Embarked\",size=20)\ntit1.Embarked.value_counts().plot.bar(color=['olive','coral','gold'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing the data in our dataframe into a correlation heatmap **","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train.corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **CLEANING DATA**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Since we have explored all the features in our dataset,now we shall draw close comparisons with \"SURVIVED\" feature,to help us draw some inference.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(5,5))\nsns.countplot(x = 'Survived', hue = 'Sex', data = train)\nplt.title(\"SURVIVED AND SEX\",size=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.countplot(x = 'Survived', hue = 'Pclass', data = train)\nplt.title(\"SURVIVED AND PCLASS\",size=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.countplot(x = 'Survived', hue = 'Embarked', data = train)\nplt.title(\"SURVIVED AND EMBARKED\",size=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculating median values of \"Age\" by using \"Pclass\" and \"Embarked\" to fill up the missing values.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"age_group = train.groupby(\"Pclass\")[\"Age\"]\nprint(age_group.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_group = train.groupby(\"Embarked\")[\"Age\"]\nprint(age_group.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.Age.isnull(),'Age']=train.groupby(\"Pclass\").Age.transform('median')\ntest.loc[test.Age.isnull(),'Age']=test.groupby(\"Pclass\").Age.transform('median')\nprint(train['Age'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we have no missing values for AGE**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Lets work out with the Cabin numbers**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Cabin'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cab = test.groupby(\"Cabin\")[\"Age\"]\nprint(cab.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain['Cabin'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will be searching for the initials of the cabin numbers like A,B,C,etc**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport re\n\ntest['Cabin'] = test['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\ntest['Cabin'].unique().tolist()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we are assigning values to the initials that we had found in the above step and replace them with integers by mapping them.\nSame step will be repeated for train and test data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"category = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'X':8}\ntest['Cabin'] = test['Cabin'].map(category)\ntest['Cabin'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cab = train.groupby(\"Cabin\")[\"Age\"]\nprint(cab.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrain['Cabin'] = train['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\ntrain['Cabin'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'X':8, 'T':9}\ntrain['Cabin'] = train['Cabin'].map(category)\ntrain['Cabin'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets check out the missing values again**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now only \"Embarked\" has two missing values in it.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statistics import mode\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(mode(train[\"Embarked\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So now we have filled the NAN values of embarked too.Lets check the null values again!**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**GG!!So no more missing values in our dataset**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Lets convert our categorical data to numeric form**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\ntrain[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n\ntest[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\ntest[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n\ntrain[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\ntrain[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\ntrain[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n\ntest[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\ntest[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\ntest[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets create a new column of fam using SibSp which means number of Siblings or Spouse and Parch which means number of Parents or Children,later we will be dropping SibSp and Parch from our data set since these values are alreday being used in Fam**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['fam']=train['SibSp']+train['Parch']+1\ntest['fam']=test['SibSp']+test['Parch']+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['fam'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**Lets play a little with Age as well**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Band'] = pd.cut(train['Age'], 5)\ntrain[['Band', 'Survived']].groupby(['Band'], as_index=False).mean().sort_values(by='Band', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range=[]\nfor i in train.Age:\n    if i<= 16:\n        range.append(0)\n    elif i>16 and i<=32:\n        range.append(1)\n    elif i>32 and i<=48:\n        range.append(2)\n    elif i>48 and i<=64: \n        range.append(3)\n    elif i>64 and i<=80:\n        range.append(4)\n    \n    \ntrain['range']=range    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range=[]\nfor i in test.Age:\n    if i<= 16:\n        range.append(0)\n    elif i>16 and i<=32:\n        range.append(1)\n    elif i>32 and i<=48:\n        range.append(2)\n    elif i>48 and i<=64: \n        range.append(3)\n    elif i>64 and i<=80:\n        range.append(4)\n    else:\n        range.append(5)\n    \ntest['range']=range  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check out if he is a lone wolf or is travelling in a pack!!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"solo=[]\nfor i in train.fam:\n    \n    if (i==1):  \n        solo.append(1)\n    else:\n        solo.append(0)\ntrain['solo'] =solo  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solo=[]\nfor i in test.fam:\n    \n    if (i==1):  \n        solo.append(1)\n    else:\n        solo.append(0)\ntest['solo'] =solo  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing NAN values from fare and further converting them into different ranges**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Fare'].fillna(train['Fare'].dropna().median(), inplace=True)\ntest['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['newfare']=pd.qcut(train['Fare'],4)\ntrain[['newfare','Survived']].groupby(['newfare'],as_index=False).mean().sort_values(by='newfare', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"farerange=[]\nfor i in train.Fare:\n    if i<= 8:\n        farerange.append(0)\n    elif i>8 and i<=14:\n        farerange.append(1)\n    elif i>14 and i<=31:\n        farerange.append(2)\n    elif i>31 and i<=513:\n        farerange.append(3)\n \n    \ntrain['farerange']=farerange  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"farerange=[]\nfor i in test.Fare:\n    if i<= 8:\n        farerange.append(0)\n    elif i>8 and i<=14:\n        farerange.append(1)\n    elif i>14 and i<=31:\n        farerange.append(2)\n    elif i>31 and i<=513:\n        farerange.append(3)\n    \ntest['farerange']=farerange  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets play around with Name as well!**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Searching for the titles and extracting them from the names in the given data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Title'] = train['Name'].map(lambda x: re.compile(\"([A-Za-z]+)\\.\").search(x).group())\ntest['Title'] = test['Name'].map(lambda x: re.compile(\"([A-Za-z]+)\\.\").search(x).group())\nprint(train['Title'].unique())\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test['Title'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mean survival rate according to the Titles assigned**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    train['Title'] = train['Title'].replace(['Lady.', 'Capt.', 'Col.',\n    'Don.', 'Dr.', 'Major.', 'Rev.', 'Jonkheer.', 'Dona.'], 'Rare.')\n    \n    train['Title'] = train['Title'].replace(['Countess.', 'Lady.', 'Sir.'], 'Royal.')\n    train['Title'] = train['Title'].replace('Mlle.', 'Miss.')\n    train['Title'] = train['Title'].replace('Ms.', 'Miss.')\n    train['Title'] = train['Title'].replace('Mme.', 'Mrs.')\n\ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Replacing to make the categories narrower and accurate**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    test['Title'] = test['Title'].replace(['Lady.', 'Capt.', 'Col.',\n    'Don.', 'Dr.', 'Major.', 'Rev.', 'Jonkheer.', 'Dona.'], 'Rare.')\n    \n    test['Title'] = test['Title'].replace(['Countess.', 'Lady.', 'Sir.'], 'Royal.')\n    test['Title'] = test['Title'].replace('Mlle.', 'Miss.')\n    test['Title'] = test['Title'].replace('Ms.', 'Miss.')\n    test['Title'] = test['Title'].replace('Mme.', 'Mrs.')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mapping new numerical values onto Titles**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"    title_mapping = {\"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4, \"Royal.\": 5, \"Rare.\": 6}\n\n    train['Title'] = train['Title'].map(title_mapping)\n    train['Title'] = train['Title'].fillna(0)\n\n    train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    title_mapping = {\"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4, \"Royal.\": 5, \"Rare.\": 6}\n\n    test['Title'] = test['Title'].map(title_mapping)\n    test['Title'] = test['Title'].fillna(0)\n\n   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets check whether the conversion has worked or not**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Cabin'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Embarked'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['fam'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The Data that we are dropping from the dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.select_dtypes(include=['object']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nc=('Name', 'Sex', 'Ticket', 'Embarked')\nfor i in c:\n    l=LabelEncoder()\n    l.fit(list(train[i].values))\n    train[i]=l.transform(list(train[i].values))\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=('Name', 'Sex', 'Ticket', 'Embarked')\nfor i in c:\n    l=LabelEncoder()\n    l.fit(list(test[i].values))\n    test[i]=l.transform(list(test[i].values))\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest = test.drop(['Parch','Age','Name','Cabin','PassengerId'], axis = 1)\ntest = test.drop(['Ticket','SibSp','fam','Fare'], axis = 1)\n\n\ntrain = train.drop(['Parch',\"Band\",'Name','Cabin','newfare','PassengerId'], axis = 1)\ntrain = train.drop(['Ticket','SibSp','Age','fam','Fare'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets start predicting,we will be using Logistic Regression.Logistic Regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**train_test_split :Split arrays or matrices into random train and test subsets**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(train.drop(['Survived'], axis=1), \n                                                    train['Survived'], test_size = 0.2, \n                                                    random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **LOGISTIC REGRESSION**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogisticRegression = LogisticRegression(max_iter = 30000)\nlogisticRegression.fit(X_train, y_train)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Making and Printing our predictions**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = logisticRegression.predict(X_test)\nacc_LOG = round(accuracy_score(predictions, y_test) * 100, 2)\nprint(acc_LOG)\nprint(predictions)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(np.mean(predictions), 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This mean is pretty close to the one that we had calculated earlier(0.384)**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Lets take help of confusion matrix to find out TP TN FP FN.A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix. The confusion matrix shows the ways in which your classification model is confused when it makes predictions. It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.\n**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nprint(confusion_matrix(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![image.png](attachment:image.png)\n","attachments":{"image.png":{"image/png":"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"}},"execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy=((84+50)/(84+50+26+19))\nprint('accuracy is: ', (round(accuracy, 2)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **RANDOM FOREST**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Lets try using Random Forest.A Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(random_state = 1,\n                                  n_estimators = 750,\n                                  max_depth = 15, \n                                  min_samples_split = 5,  min_samples_leaf = 1)\n\nrandom_forest.fit(X_train, y_train)\n\nY_pred = random_forest.predict(X_test)\n\nacc_rnd = round(accuracy_score(Y_pred, y_test) * 100, 2)\nprint(acc_rnd)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **GRADIENT BOOSTING**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60,max_depth=9,max_features='sqrt', subsample=0.8, random_state=10)\ngbk.fit(X_train, y_train)\npred = gbk.predict(X_test)\nacc_gbk = round(accuracy_score(pred, y_test) * 100, 2)\nprint(acc_gbk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(accuracy_score(Y_pred, y_test) * 100, 2)\nacc_decision_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=pd.DataFrame({'Model':['Logistic Regression','Random Forest','Gradient Boosting','Decision Tree'],'Score':[acc_LOG,acc_rnd,acc_gbk,acc_decision_tree]})\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SUBMISSION FILE**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = idtest\npredictions =decision_tree.predict(test)\n\n\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}