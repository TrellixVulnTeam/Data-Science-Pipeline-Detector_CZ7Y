{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SIT307 T1 2021\n# Assignment 2 - Data Mining Project\n***Group 5*** - Rhys McMillan (218335964), Brenton Fleming (217603898), Neb Miletic (218489118), Sean Pain (218137385), Oliver Bennett (218143462), Muhammad Sibtain (219345654), Asim Arshad (219337467)  \n  \n***Data*** - Titanic: Machine Learning From Disaster (https://www.kaggle.com/c/titanic/data)","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n\n* [1. Preparation](#1)\n    * [1.1 Import Relevant Libraries](#1_1)\n    * [1.2 Load Data from File](#1_2)\n* [2. Data Overview](#2)\n    * [2.1 Data Dictionary](#2_1)\n    * [2.2 Properties](#2_2)\n    * [2.3 Features](#2_3)\n    * [2.4 Null Values](#2_4)\n    * [2.5 Statistical Distribution](#2_5)\n* [3. Feature Engineering](#3)\n    * [3.1 Title](#3_1)\n    * [3.2 Relatives](#3_2)\n    * [3.3 Sex](#3_3)\n    * [3.4 UniqueTicket](#3_4)\n    * [3.5 Summary](#3_5)\n* [4. Data Cleaning](#4)\n    * [4.1 Discrete Data](#4_1)\n        * [4.1.1 Survived](#4_1_1)\n        * [4.1.2 Passenger Class (Pclass)](#4_1_2)\n        * [4.1.3 Sex](#4_1_3)\n        * [4.1.4 Siblings / Spouse (SibSp)](#4_1_4)\n        * [4.1.5 Parents / Children (Parch)](#4_1_5)\n        * [4.1.6 Relatives](#4_1_6)\n        * [4.1.7 Alone](#4_1_7)\n        * [4.1.8 UniqueTicket](#4_1_8)\n    * [4.2 Continuous Data](#4_2)\n        * [4.2.1 Age](#4_2_1)\n        * [4.2.2 Fare](#4_2_2)\n    * [4.3 Nominal Data](#4_3)\n        * [4.3.1 Cabin](#4_3_1)\n        * [4.3.2 Embarked](#4_3_2)\n        * [4.3.3 Title](#4_3_3)\n* [5. Feature Selection](#5)\n    * [5.1 Numerical Features](#5_1)\n    * [5.2 Categorical Features](#5_2)\n        * [5.2.1 Embarked](#5_2_1)\n        * [5.2.2 Title](#5_2_2)\n* [6. Exploratory Data Analysis (EDA)](#6)\n    * [6.1 Passenger Class (PClass)](#6_1)\n    * [6.2 Sex](#6_2)\n    * [6.3 Age](#6_3)\n    * [6.4 Fare](#6_4)\n    * [6.5 Alone](#6_5)\n    * [6.6 UniqueTicket](#6_6)\n    * [6.7 Embarked](#6_7)\n    * [6.8 Title](#6_8)","metadata":{}},{"cell_type":"markdown","source":"# 1. Preparation <a class=\"anchor\" id=\"1\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Import Relevant Libraries <a class=\"anchor\" id=\"1_1\"></a>","metadata":{}},{"cell_type":"code","source":"# data analysis\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\n# visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Load Data from File <a class=\"anchor\" id=\"1_2\"></a>\nThe source data (https://www.kaggle.com/c/titanic/data) contains two datasets - train.csv and test.csv.  \nTrain.csv is intended for model training and contains the entire feature set.  \nTest.csv is intended for testing a trained model and does not contain the outcome ('Survived').\n\nFor our analysis, we will be using train.csv only.","metadata":{}},{"cell_type":"code","source":"# load train.csv to pandas data frame, using 'PassengerId' as the index\nmaster_df = pd.read_csv('../input/titanic/train.csv' , index_col='PassengerId')\n\n# Create a working copy of the data frame for manipulation. The master will serve as the baseline.\nworking_df = master_df.copy()\n\n# Preview the data\nworking_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Overview <a class=\"anchor\" id=\"2\"></a>\nWe begin our analysis by taking a cursory look at the structure and properties of our data set. This will give some context to the data and help guide our exploration.\n## 2.1 Data Dictionary <a class=\"anchor\" id=\"2_1\"></a>\nThe following data dictionary was provided alongside the dataset:\n<table>\n    <tr>\n        <th>Variable</th>\n        <th>Definition</th>\n        <th>Key</th>\n    </tr>\n    <tr>\n        <td>pclass</td>\n        <td>Ticket class</td>\n        <td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n    </tr>\n    <tr>\n        <td>sex</td>\n        <td>Sex</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>Age</td>\n        <td>Age in years</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>sibsp</td>\n        <td># of siblings / spouses aboard the Titanic</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>parch</td>\n        <td># of parents / children aboard the Titanic</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>ticket</td>\n        <td>Ticket number</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>fare</td>\n        <td>Passenger fare</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>cabin</td>\n        <td>Cabin number</td>\n        <td></td>\n    </tr>\n    <tr>\n        <td>embarked</td>\n        <td>Port of Embarkation</td>\n        <td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n    </tr>\n</table>","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Properties <a class=\"anchor\" id=\"2_2\"></a>\nExamine the basic shape and properties of the dataset.","metadata":{}},{"cell_type":"code","source":"# print shape of the dataset\nprint(\"There are {} rows and {} columns in the dataset.\".format(master_df.shape[0] , master_df.shape[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print basic summary of the dataset\nprint(master_df.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Features <a class=\"anchor\" id=\"2_3\"></a>\nThe dataset contains 3 data types - float64, int64 and object. We will initially assume float64 represents continuous data, int64 represents discrete data and object represents categorical data. The data frame data type does not different between nominal and ordinal data. Manual inspection determined all categorical data to be nominal. Our feature set can therefore be classified as:\n\n - Discrete - Survived, Pclass, Sibsp, Parch\n - Continuous - Age, Fare\n - Ordinal - Name, Sex, Ticket, Cabin, Embarked","metadata":{}},{"cell_type":"markdown","source":"## 2.4 Null Values <a class=\"anchor\" id=\"2_4\"></a>","metadata":{}},{"cell_type":"code","source":"# get count of missing values\nmaster_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only 3 features contain null values - Age, Cabin, and Embarked.\n- Cabin null values consitute a significant portion of the data (687 of 891). Any imputation would likely introduce signficant bias. Consider dropping this feature.\n- Embarked null values only constitue a very minor portion of the data (2 of 891). Imputation of this feature will have minimal impact on correlation. Any simple imputation method will suffice.\n","metadata":{}},{"cell_type":"markdown","source":"## 2.5 Statistical Distribution <a class=\"anchor\" id=\"2_5\"></a>","metadata":{}},{"cell_type":"markdown","source":"Statistical distrubiton of numerical features:","metadata":{}},{"cell_type":"code","source":"# print statistical distrution of float and integer data types\nmaster_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Statistical distribution of categorical features:","metadata":{}},{"cell_type":"code","source":"# print statistical distrution of object types\nmaster_df.describe(include=['O'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Feature Engineering <a class=\"anchor\" id=\"3\"></a>","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Title <a class=\"anchor\" id=\"3_1\"></a>\nAll name values are unique in the data, as such no correlation is possible using this feature. As the name feature currently contains both the name and title of the passenger, we can extract title from this feature.","metadata":{}},{"cell_type":"code","source":"# create a new feature to extract title names from the Name column\nworking_df['Title'] = working_df.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\n\n# get unique titles\nunique_titles = working_df['Title'].unique()\nprint(\"Unique Titles:\", len(unique_titles))\nprint(unique_titles)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can further refine this list by grouping similar titles.","metadata":{}},{"cell_type":"code","source":"# normalize titles into dictionary\ntitle_dictionary = {\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"\n}\n\n# map normalized title to Title feature vector\nworking_df.Title = working_df.Title.map(title_dictionary)\n\n# print value counts\nprint(working_df.Title.value_counts())\n# to do transform titles to ordinal values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The name feature no longer holds any relevance and can be dropped from the dataset.","metadata":{}},{"cell_type":"code","source":"working_df = working_df.drop(columns='Name')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Relatives <a class=\"anchor\" id=\"3_2\"></a>\nSibSp (number of siblings or spouse) and Parch (number of parents or children) both relate to the number of relatives on board along with the passenger. These values can be combined as a single 'Relatives' feature.","metadata":{}},{"cell_type":"code","source":"# create a new feature to calculate number of relatives\nworking_df['Relatives'] = working_df['SibSp'] + working_df['Parch']\n\n# print value counts\nprint(working_df.Relatives.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a large number of passengers were travelling alone (537 of 891) we can also represent this as a seperate 'Alone' feature.","metadata":{}},{"cell_type":"code","source":"# create new feature to show if passenger was alone or with family\nworking_df['Alone'] = 0\nworking_df.loc[working_df['Relatives'] == 0, 'Alone'] = 1\n\n# print value counts\nprint(working_df.Alone.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Sex <a class=\"anchor\" id=\"3_3\"></a>\nSex contains two possible values male and female. We can more easily work with this information by coverting it to numeric data where 0 = male and 1 = female.","metadata":{}},{"cell_type":"code","source":"# convert sex to numeric values\nworking_df['Sex'] = working_df['Sex'].map({\"male\": 0, \"female\": 1})\n\n# print value counts\nprint(working_df.Sex.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 UniqueTicket <a class=\"anchor\" id=\"3_4\"></a>\nTicket contains 681 unique values. As is, strong correlation with any other feature will be highely unlikely. We will add a new feature 'UniqueTicket' to specify if a ticket number is unique in the dataset or a duplicate. The assumption is that a duplicate ticket number permitted more than 1 person to board.","metadata":{}},{"cell_type":"code","source":"# first find all unique tickets\nunique_tickets = pd.concat(i for _, i in working_df.groupby(\"Ticket\") if len(i) == 1).index\n\n# create new feature\nworking_df['UniqueTicket'] = 0\nworking_df.loc[unique_tickets, 'UniqueTicket'] = 1\n\n# print value counts\nprint(working_df.UniqueTicket.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ticket can be be dropped in favour of UniqueTicket.","metadata":{}},{"cell_type":"code","source":"# drop ticket column\nworking_df = working_df.drop(columns='Ticket')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.5 Summary <a class=\"anchor\" id=\"3_5\"></a>\nAfter feature engineering, our feature set has expanded to:\n- Discrete - Survived, Pclass, Sex, Sibsp, Parch, Relatives, Alone, UniqueTicket\n- Continuous - Age, Fare\n- Ordinal - Cabin, Embarked, Title","metadata":{}},{"cell_type":"markdown","source":"# 4. Data Cleaning <a class=\"anchor\" id=\"4\"></a>\nIndividually inspect each feature to determine unusual or missing values. Clean and impute values as required.","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Discrete Data <a class=\"anchor\" id=\"4_1\"></a>\nData cleaning requirements for discrete data can be determined by:\n- Check for any missing values.\n- Inspect unique values to determine if any do not make sense.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.1 Survived <a class=\"anchor\" id=\"4_1_1\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['Survived'].isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df['Survived'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Survived has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.2 Passenger Class (Pclass) <a class=\"anchor\" id=\"4_1_2\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['Pclass'].isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df['Pclass'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pclass has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.3 Sex <a class=\"anchor\" id=\"4_1_3\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['Sex'].isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df['Sex'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sex has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.4 Siblings / Souse (SibSp) <a class=\"anchor\" id=\"4_1_4\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['SibSp'].isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df['SibSp'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SibSp has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.5 Parents / Children (Parch) <a class=\"anchor\" id=\"4_1_5\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['Parch'].isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df['Parch'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Parch has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.6 Relatives  <a class=\"anchor\" id=\"4_1_6\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['Relatives'].isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df['Relatives'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Relatives has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.7 Alone  <a class=\"anchor\" id=\"4_1_7\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['Alone'].isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df['Alone'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Alone has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"### 4.1.8 UniqueTicket  <a class=\"anchor\" id=\"4_1_8\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['UniqueTicket'].isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df['UniqueTicket'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"UniqueTicket has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"## 4.2 Continuous Data <a class=\"anchor\" id=\"4_2\"></a>\nData cleaning requirements for continuous data can be determined by:\n- Check for any missing values.\n- Identify any outliers using zscore (threshold = +- 3).","metadata":{}},{"cell_type":"markdown","source":"### 4.2.1 Age  <a class=\"anchor\" id=\"4_2_1\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df['Age'].isnull().sum())\n\n# calculate zscore for each value\nzscore = (working_df.Age - working_df.Age.mean()) / working_df.Age.std(ddof=0)\n\n# calculate outliers using zscore\noutliers = working_df.loc[abs(zscore) > 3]\n\n# print outliers\nprint(\"Outlier count:\", len(outliers))\n    ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will first impute the missing values, then validate and handle outliers.","metadata":{}},{"cell_type":"markdown","source":"#### 4.2.1.1 Impute Missing Age Values  <a class=\"anchor\" id=\"4_2_1_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"We must first identify features which have a strong correlation with age to use as the basis of our imputation.  \nStart by correlating all numerical features against age:","metadata":{}},{"cell_type":"code","source":"# extract age column from data fxrame\nage = working_df['Age']\n\n# correlate with other numerical columns\ncorr = working_df.drop(columns='Age').corrwith(age)\n\n# display as bar graph\nax = corr.plot.bar(rot=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Categorical features can be checked by pivotting against age.  \nPivot Title vs Mean Age:","metadata":{}},{"cell_type":"code","source":"age_pivot = pd.pivot_table(working_df, index=['Title'], values=['Age'], aggfunc=np.mean)\nage_pivot.plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pivot Embarked vs Mean Age:","metadata":{}},{"cell_type":"code","source":"age_pivot = pd.pivot_table(working_df, index=['Embarked'], values=['Age'], aggfunc=np.mean)\nage_pivot.plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will impute our missing ages using Linear Regression imputation, we will be keeping very simple for now, but more complexities can be added to further improve the imputation","metadata":{}},{"cell_type":"code","source":"# pre-requisites - as title and class hugely impacts the age of passenegers, they' both will be used, and the feature\n# with high score will be consiered or maybe both values\n\n# we first need to map Title to numerical values to allow the algorithm to run\nworking_df['TitleMapped'] = working_df['Title'].map({'Mr':0, 'Mrs':1, 'Miss':2, 'Master':3, 'Royalty':4, 'Officer':5})\n\n# getting all data with known age values to train our model\ndata = working_df.loc[working_df['Age'].notna()]\n\n# creating X = features (Title and Class) and Y = response variable (Age)\nX = data[['TitleMapped' , 'Pclass']]\ny = data['Age']\n\n\n# extracting dataframe of missing ages we want to impute\nmissing_ages = working_df['Age'][working_df['Age'].isna()]\n\n# imputing age using regression imputation\nfrom sklearn.linear_model import LinearRegression\nregression_classifier = LinearRegression()\n\n# splitting our data for training and testing - Sklearn builtin methods can also be used\nX_train = X.head(537)  # contains p-class and title for known ages\ny_train = y.head(537)  # contains the actual age for known ages\nX_test = X.tail(177)   # contains p-class and title for missing ages to predict missing ages\n\nmodel = regression_classifier.fit(X_train,y_train) # data fitted to model to train\n\n# predict missing ages\nage_result = model.predict(X_test)\n\n# age_result contains the imputed values and can be imputed by:\nworking_df.loc[ working_df['Age'].isnull(), 'Age'] = age_result\n\n# check all age values have been filled\nprint(\"Null values:\", working_df['Age'].isnull().sum())\n\n# drop TitleMapped as it is no longer required\nworking_df = working_df.drop(columns=\"TitleMapped\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2.1.2 Validate Age Outliers  <a class=\"anchor\" id=\"4_2_1_2\"></a>\nIdentify and validate outliers.","metadata":{}},{"cell_type":"code","source":"# calculate zscore for each value\nzscore = (working_df.Age - working_df.Age.mean()) / working_df.Age.std(ddof=0)\n\n# calculate outliers using zscore\noutliers = working_df[abs(zscore) > 3]\n\n# print outliers\nprint(\"Outlier count:\", len(outliers))\nprint(\"Outliers:\")\noutliers","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are only seven outliers for age.  \nAll outliers are valid ages for a person and not erronous values. They can be retained in the dataset.  ","metadata":{}},{"cell_type":"markdown","source":"### 4.2.2 Fare  <a class=\"anchor\" id=\"4_2_2\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df.Fare.isnull().sum())\n\nzscore = (working_df.Fare - working_df.Fare.mean()) / working_df.Fare.std(ddof=0)\n\n# calculate outliers using zscore\noutliers = working_df.loc[abs(zscore) > 3]\n\n# print outlier count\nprint(\"Outlier count:\", len(outliers))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2.1.1 Validate Fare Outliers  <a class=\"anchor\" id=\"4_2_1_1\"></a>\nIdentify and validate outliers.","metadata":{}},{"cell_type":"code","source":"print(\"Outliers:\")\noutliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# group and count outlier values\noutliers.Fare.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are multiple instances of the most extreme outliers. All outliers are also from first class, which would expect to have higher ticket costs. We do not believe these are erronous values and will be retained in the dataset.","metadata":{}},{"cell_type":"markdown","source":"## 4.3 Nominal Data  <a class=\"anchor\" id=\"4_3\"></a>\nData cleaning requirements for discrete data can be determined by:\n- Check for any missing values.\n- Inspect unique values to determine if any do not make sense.","metadata":{}},{"cell_type":"markdown","source":"### 4.3.1 Cabin  <a class=\"anchor\" id=\"4_3_1\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df.Cabin.isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique count:\", working_df.Cabin.nunique())","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cabin is missing a significant portion of data. No meaningful correlation will be possible from this feature and it will be dropped from the data set.","metadata":{}},{"cell_type":"code","source":"working_df = working_df.drop(columns='Cabin')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3.2 Embarked <a class=\"anchor\" id=\"4_3_2\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df.Embarked.isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df.Embarked.dropna().unique())","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Embarked contains 2 missing values and no unusual values. ","metadata":{}},{"cell_type":"markdown","source":"#### 4.3.1.1 Impute Missing Embarked Values  <a class=\"anchor\" id=\"4_3_3_1\"></a>\nAs only 2 of 891 values are missing, we can simply fill these with the most common embarked value.","metadata":{}},{"cell_type":"code","source":"# print embarked value counts\nprint(working_df.Embarked.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most common value is 'S'. Fill missing embarked values with 'S'.","metadata":{}},{"cell_type":"code","source":"# fill emabrked na with 'S'\nworking_df.Embarked = working_df.Embarked.fillna('S')\n\n# confirm there are no more nulls\nprint(\"Null values:\", working_df.Embarked.isnull().sum())\nprint(working_df.Embarked.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3.3 Title  <a class=\"anchor\" id=\"4_3_3\"></a>","metadata":{}},{"cell_type":"code","source":"# print null value count\nprint(\"Null values:\", working_df.Title.isnull().sum())\n\n# print list of unique values to check for anything unusual\nprint(\"Unique values:\", working_df.Title.unique())","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Title has no unusual or missing values. No data cleaning required.","metadata":{}},{"cell_type":"markdown","source":"# 5. Feature Selection <a class=\"anchor\" id=\"5\"></a>\nThe primary goal of our analysis is to indentify which impacts had the greatest impact on a passengers chance of survivial. Features will be selected based on this criteria.","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Numerical Features <a class=\"anchor\" id=\"5_1\"></a>\nCorrelate all numerical features against survival.","metadata":{}},{"cell_type":"code","source":"# snapshot cleaned dataframe before selecting features\nclean_df = working_df.copy()\n\n# extract survived column from data frame\nsurvived = working_df['Survived']\n\n# correlate with other columns\ncorr = working_df.drop(columns='Survived').corrwith(survived)\n\n# display as bar graph\nax = corr.plot.bar(rot=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pclass, Sex, Age, Fare, Alone and UniqueTicket demonstrate low to moderate correlation with survival and require further investigation.  \nSibsp, Parch and Relatives demonstrate minimal to no correlation and will be dropped.","metadata":{}},{"cell_type":"code","source":"working_df = working_df.drop(columns=['SibSp', 'Parch', 'Relatives'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Categorical Features <a class=\"anchor\" id=\"5_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"Spearman / Pearson correlation is not possible for categorical features.  \nCorrelation and selection of categorical features will be done by pivotting and visualising features against 'Survived'.","metadata":{}},{"cell_type":"markdown","source":"### 5.2.1 Embarked  <a class=\"anchor\" id=\"5_2_1\"></a>\nPivot and visualise embarked vs survival.","metadata":{}},{"cell_type":"code","source":"pivot = pd.pivot_table(working_df, index=['Embarked'], values=['Survived'], aggfunc=np.mean)\npivot.plot(kind=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Embarked shows an uneven distrubiton of survival rate across the different values. This suggests there is some correlation between Embarked and Survived.","metadata":{}},{"cell_type":"markdown","source":"### 5.2.2 Title  <a class=\"anchor\" id=\"5_2_2\"></a>","metadata":{}},{"cell_type":"code","source":"pivot = pd.pivot_table(working_df, index=['Title'], values=['Survived'], aggfunc=np.mean)\npivot.plot(kind=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Title shows an uneven distribution of survival rates across the different titles, especially for Mr and Officer. Females, children and royalty appear to have the highest chance of survival. This suggests there is some correlation between Title and Survived.","metadata":{}},{"cell_type":"markdown","source":"# 6. Exploratory Data Analysis (EDA) <a class=\"anchor\" id=\"6\"></a>","metadata":{}},{"cell_type":"markdown","source":"Finally we will take a closer look at the selected features to identify any interesting relationships or trends.","metadata":{}},{"cell_type":"markdown","source":"## 6.1 Passenger Class (PClass) <a class=\"anchor\" id=\"6_1\"></a>","metadata":{}},{"cell_type":"markdown","source":"***What impact does Passenger Class have on survival***","metadata":{}},{"cell_type":"code","source":"# Visualise survival of each passenger class\nsns.set_style('whitegrid')\nsns.barplot(x='Pclass' , y='Survived' , data=working_df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation 1:** Survival of first class passengers was prioritised, followed by second class, then third.  \nTo confirm, we should investigate if there are any other relationships between Pclass and strong survival idicators which could account for the bias.","metadata":{}},{"cell_type":"markdown","source":"***What is the distribution of males and females for each class?***","metadata":{}},{"cell_type":"code","source":"# Visualise distribution of males and females for each class\nax = sns.barplot(x='Pclass' , y='Sex' , data=working_df)\nax.set(ylabel='Percentage of Females')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of males and females between each class does not account for the bias in Pclass survival. **Observation 1** still holds true.","metadata":{}},{"cell_type":"markdown","source":"## 6.2 Sex <a class=\"anchor\" id=\"6_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"***What impact does sex have on survival?***","metadata":{}},{"cell_type":"code","source":"# Calculating the value counts for our attributes\nmale_total = working_df[working_df['Sex']==0].shape[0]\nfemale_total = working_df[working_df['Sex']==1].shape[0]\nprint('Total male in our dataset:', male_total)\nprint('Total female in our dataset:', female_total)\n\n# Calculating value counts for male and female who survived\nmale_surv = working_df.loc[ (working_df['Sex'] == 0) & (working_df['Survived']==1)].shape[0]\nfemale_surv = working_df.loc[ (working_df['Sex'] == 1) & (working_df['Survived']==1)].shape[0]\nprint('\\nTotal male survived: {} ({}%)'.format(male_surv, round((male_surv / male_total)*100)))\nprint('Total female survived: {} ({}%)'.format(female_surv, round((female_surv / female_total)*100)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing male and female survivors\nsns.set_style('whitegrid')\nax = sns.barplot(x='Sex' , y='Survived' , data=working_df)\nax.set(xticklabels=[\"Male\", \"Female\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Females were almost 4 times more likely than males to surive the sinking of the titanic.  \n**Observation 2:** Females were prioritised over males for survival.","metadata":{}},{"cell_type":"markdown","source":"## 6.3 Age <a class=\"anchor\" id=\"6_2\"></a>","metadata":{}},{"cell_type":"markdown","source":"***What impact did age have on survival?***","metadata":{}},{"cell_type":"code","source":"# Calculate average age of those who survived and those who died\npd.pivot_table(working_df, index=['Survived'], values=['Age'], aggfunc=np.mean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the average age of survivors is lower than the average age of those who died, we can assume younger passengers were prioritised over older passengers.\nWe can explore this further by creating age clusters.","metadata":{}},{"cell_type":"code","source":"# create AgeGroup feature\nworking_df[\"AgeGroup\"] = 0\nworking_df.loc[ working_df['Age'] <= 10, 'AgeGroup'] = 10\nworking_df.loc[(working_df['Age'] > 10) & (working_df['Age'] <= 20), 'AgeGroup'] = 20\nworking_df.loc[(working_df['Age'] > 20) & (working_df['Age'] <= 30), 'AgeGroup'] = 30\nworking_df.loc[(working_df['Age'] > 30) & (working_df['Age'] <= 40), 'AgeGroup'] = 40\nworking_df.loc[(working_df['Age'] > 40) & (working_df['Age'] <= 50), 'AgeGroup'] = 50\nworking_df.loc[(working_df['Age'] > 50) & (working_df['Age'] <= 60), 'AgeGroup'] = 60\nworking_df.loc[(working_df['Age'] > 60) & (working_df['Age'] <= 70), 'AgeGroup'] = 70\nworking_df.loc[ working_df['Age'] > 70, 'AgeGroup'] = 80\n\n# confirm no abnormal values for AgeGroup\nworking_df.AgeGroup.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualise AgeGroup vs Survived\nsns.barplot(x='AgeGroup' , y='Survived' , data=working_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this graph we can see a general trend that younger people had a higher survival rate than older people, but there are spikes in the middle which prevent us using this as a definitive rule.  \nWe can identify there is a high survival rate of those in the 0 to 10 category, decreasing towards the 10 to 20 category.  \nWe will split between the two and categories those 15 and below as children.","metadata":{}},{"cell_type":"code","source":"# create IsChild feature\nworking_df[\"IsChild\"] = 0\nworking_df.loc[ working_df['Age'] <= 15, 'IsChild'] = 1\n\n# visualise IsChild vs Survived\nsns.barplot(x='IsChild' , y='Survived' , data=working_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation 3:** Children were much more likely to have survived than adults.  \nThis is a much more convincing indicator than our AgeGroup, so we will drop AgeGroup in favour of IsChild.","metadata":{}},{"cell_type":"code","source":"working_df = working_df.drop(columns='AgeGroup')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.4 Fare <a class=\"anchor\" id=\"6_4\"></a>","metadata":{}},{"cell_type":"markdown","source":"***What is the relationship between Fare and Survived?***","metadata":{}},{"cell_type":"code","source":"# Plot Fare vs Survived\nsns.lineplot(x=\"Fare\", y=\"Survived\", data=working_df[working_df.UniqueTicket == 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting Fare vs Survived does not reveal any direct relationships between the two variables.  \nIs Fare just a rough indicator of Pclass?","metadata":{}},{"cell_type":"code","source":"# Plot Fare vs Pclass\nsns.barplot(x=\"Pclass\", y=\"Fare\", data=working_df[working_df.UniqueTicket == 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, first class passengers paid more, followed by second, then third.  \nThe correlation seen between Fare and Survived is likely a derivative of Pclass.","metadata":{}},{"cell_type":"markdown","source":"## 6.5 Alone <a class=\"anchor\" id=\"6_5\"></a>","metadata":{}},{"cell_type":"markdown","source":"***Are Alone and UniqueTicket representing the same group of passengers?***  \nFrom our earlier correlation we know both Alone and UniqueTicket showed similar correlation with survived.  \nBased on our assumption that a UniqueTicket allowed only one passenger to board, while a duplicate ticket allowed multiple passengers to board, it would stand to reason that most solo travellers would have a unique ticket.","metadata":{}},{"cell_type":"code","source":"# print percentage of alone passengers who have a unique ticket\nalone_total = working_df.loc[ working_df['Alone'] == 1 ].shape[0]\nalone_unique = working_df.loc[ (working_df['Alone'] == 1) & (working_df['UniqueTicket']==1) ].shape[0]\nprint(\"Percentage of Alone passengers who have unique tickets: {}%\\n\".format(round((alone_unique / alone_total)*100, 2)))\n\n# Correlate Alone and UniqueTicket through visualisation\nsns.barplot(x='Alone' , y='UniqueTicket' , data=working_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"86% of passengers travelling alone had a UniqueTicket. We can conclude that both features are represententing essentially the same group of passengers. To reduce the number of dimensions in our dataset we can drop either Alone or UniqueTicket.\nWe will drop whichever has the lower correlation with survived:","metadata":{}},{"cell_type":"code","source":"# print correlation of Alone and Survived\nprint(\"Alone correlation:\", round(working_df.Alone.corr(working_df.Survived), 2))\n\n# print correlation of UniqueTicket and Survived\nprint(\"UniqueTicket correlation:\", round(working_df.UniqueTicket.corr(working_df.Survived), 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will drop Alone in favour of UniqueTicket.","metadata":{}},{"cell_type":"code","source":"working_df = working_df.drop(columns=\"Alone\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.6 UniqueTicket <a class=\"anchor\" id=\"6_6\"></a>","metadata":{}},{"cell_type":"markdown","source":"***What type of passengers were travelling with a unique ticket?***","metadata":{}},{"cell_type":"code","source":"# Visualise UniqueTicket vs Sex / Pclass\nax = sns.countplot(x=\"Sex\", hue=\"Pclass\", data=working_df[working_df.UniqueTicket == 1])\nax.set(xticklabels=[\"Male\", \"Female\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A passenger travelling with a unique ticket was most likely to be a third class male.","metadata":{}},{"cell_type":"markdown","source":"## 6.7 Embarked <a class=\"anchor\" id=\"6_7\"></a>","metadata":{}},{"cell_type":"markdown","source":"***Is Embarked actually a survival indicator?***  \nWe saw during feature selection that passengers who embarked in Cherbourg had a higher survival rate than those who embarked at Queenstown or Southampton.  \nIt doesn't seem logical that a persons port of embarkation would be a factor considered when prioritising survival during a time of crisis. We should cross reference embarked with other strong survival indicators to account for the Cherbourg bias.","metadata":{}},{"cell_type":"code","source":"# Visualise Embarked vs Sex\nsns.catplot(x=\"Embarked\", y=\"Sex\", kind=\"bar\", data=working_df, ci=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Females accounted for less than 50% of passengers from Cherbourg. Sex does not account for the bias.  \nWe will check Pclass next.","metadata":{}},{"cell_type":"code","source":"# Visualise Embarked vs Pclass\nsns.countplot(x=\"Embarked\", hue=\"Pclass\", data=working_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cherbourg has a much higher ratio of 1st class passengers to 3rd class passengers. This suggests that the higher survival rate of Cherbourg is infact just a coincidental indicator of Pclass. Embarked can therefore be discounted as a survival indicator.","metadata":{}},{"cell_type":"markdown","source":"## 6.8 Title <a class=\"anchor\" id=\"6_8\"></a>","metadata":{}},{"cell_type":"markdown","source":"What impact does Title have on Survived?","metadata":{}},{"cell_type":"code","source":"# Visualizing survivors by title\nsns.set_style('whitegrid')\nsns.barplot(x='Title' , y='Survived' , data=working_df,ci=None)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Passenger class & Title","metadata":{}},{"cell_type":"code","source":"#visualizing Title and Passenger class \n# A quick sanity check confirms prior observations\n# Passenger class is a strong indicator of survival (i.e. First & Second passengers had a significantly higher rate of survival to Third class passengers)\n# Gender is a strong indicator of survival (i.e. Female titles had a significantly higher rate of survival to Male titles)\nsns.catplot(\n    x=\"Title\", y=\"Survived\", hue=\"Pclass\", kind=\"bar\",\n    data=working_df, \n    ci=None,\n    height=8.27, aspect=11.7/8.27\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Titles & Gender","metadata":{}},{"cell_type":"code","source":"# Passengers with female titles ('Ms' or 'Miss') had a significantly higher rate of survival than male titles (Mr, Master)\n# All female royals & all females officers survived\n# Strengthens the case Gender is a strong indicator of survival\ng = sns.catplot(x=\"Title\", y=\"Survived\", hue=\"Sex\", kind=\"bar\", \n                data=working_df,\n                ci=None,legend=False, height=8.27, aspect=11.7/8.27)\nplt.legend(labels=['Male', 'Female'])\nplt.show(g)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First class passengers by title","metadata":{}},{"cell_type":"code","source":"#Interestingly, first class Mr's, Royals and Officers had a comparably low rate of survival\n# This subset weakens PClass as an indicator of survival, though strengthens the claim of gender\nsubset = working_df.loc[\n    ( \n        (working_df['Title']=='Mr') | (working_df['Title']=='Officer') | (working_df['Title']=='Royalty')) &\n        (working_df['Pclass']==1) &\n        (working_df['Sex']==0)\n]\nsubset.shape[0]\ng = sns.catplot(x=\"Title\", y=\"Survived\", kind=\"bar\", \n                data=subset,\n                ci=None,legend=False, height=8.27, aspect=11.7/8.27)\nplt.show(g)\n#In this sense, this subset presents a counter-example to our previous observations around Passenger class, but strengthens the case for gender as strong indicators\ng = sns.catplot(x=\"Title\", y=\"Survived\", hue=\"Sex\", kind=\"bar\", \n                data=working_df.loc[\n                (working_df['Pclass']==1)\n                ],\n                ci=None,legend=False, height=8.27, aspect=11.7/8.27)\nplt.legend(labels=['Male', 'Female'])\nplt.show(g)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}