{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **<center> <span style=\"color:crimson;font-family:Lucida Console;\"> TITANIC SURVIVAL  </span> </center>**"},{"metadata":{},"cell_type":"markdown","source":"![TTT.jpeg](attachment:TTT.jpeg)","attachments":{"TTT.jpeg":{"image/jpeg":"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"}}},{"metadata":{},"cell_type":"markdown","source":"## **Let's get started!**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom collections import Counter\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\nsns.set(style='white', context='notebook', palette='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Load train and test data sets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#load data set\ntrain=pd.read_csv(\"../input/titanic/train.csv\")\ntest=pd.read_csv(\"../input/titanic/test.csv\")\nIDtest=test[\"PassengerId\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **A quick look at our data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**> The meaning of each attribute is the following:**\n\n* PassengerId: the ID given to each passenger,\n* Survived: the target attribute (1 for passengers who survived, 0 for those who didn't),\n* Pclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd class),\n* Name, Sex, Age: self-explanatory,\n* SibSp: Number of siblings & spouses aboard the Titanic,\n* Parch: Number of parents & children aboard the Titanic,\n* Ticket: Ticket number,\n* Fare: Passenger fare (in pounds),\n* Cabin: Passenger's cabin number, and\n* Embarked: Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\n*'PassengerId' is unique to each passenger*"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### Outlier detection \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#outlier detection\n#tukey method\n\ndef detect_outliers(df, n, features):\n    outlier_indices = []\n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tukey's rule says that the outliers are values more than 1.5 times the interquartile range from the quartiles — either below Q1 − 1.5IQR, or above Q3 + 1.5IQR.\n\nHere, the code detects outliers from the numerical values features (Age, SibSp, Sarch and Fare). Then, considered outliers as rows that have at least two outlied numerical values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the outliers rows\ntrain.loc[Outliers_to_drop]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we detected 10 outliers. PassengerId 29, 89, 342 have very high ticket fare while the rest have high SibSp value. Hence, we drop these."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop outliers\ntrain = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Join train and test datasets in order to obtain the same number of features during categorical conversion"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining train and test data set\ntrain_len = len(train)\ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Let's take a closer look at the missing values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill empty and NaNs values with NaN\ndataset = dataset.fillna(np.nan)\n\n# Check for Null values\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Infos\ntrain.info()\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_counts = train.isnull().sum().sort_values(ascending = False)\npercent = (train.isnull().sum()*100/train.shape[0]).sort_values(ascending = False)\n\nmissing_df = pd.concat([missing_counts, percent], axis = 1, keys = ['Counts', '%'])\nprint('Missing values: ')\ndisplay(missing_df.head().style.background_gradient(cmap = 'Reds', axis = 0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While replacing missing values in the 'Age' and 'Embarked' columns won't be that difficult. However, we will probably have to discard the 'Cabin' attribute since more than 75% of all values are missing."},{"metadata":{},"cell_type":"markdown","source":"* Let's look at the statistical summary of the numerical attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Important things to note are:**\n* Mean age is approx 30 years old, while the median is 28.\n* Mean fair is £31.121\n* Only 38% of passenegers survived.\n* The median of both, SibSp and Parch, is 0 which indicates that most passengers were alone.\n\nLet's visualize the differences in scales,by plotting a histogram for each numerical attribute."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_atts = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass']\ntrain[num_atts].hist(figsize = (15, 6), color = 'steelblue', edgecolor = 'firebrick', linewidth = 1.5, layout = (2, 3));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It can be observed that most passengers:**\n* were young (age < 40)\n* boarded the ship alone (SibSp and Parch is 0)\n* paid a low fare\n* boarded in the 3rd class\n\n<hr>"},{"metadata":{},"cell_type":"markdown","source":"# 1. Feature Analysis\n## **1.1 NUMERICAL VALUES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix between numerical values (SibSp Parch Age and Fare values) and Survived \ng = sns.heatmap(train[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Only fare feature seems to have a significative corelation with the survival probability.\n\n> Let's explore all these features to find further corelation with the survival and subpopulation of these features.\n\n###  **1.11 SibSp**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"SibSp\",y=\"Survived\",data=train,kind=\"bar\", height = 6, palette=\"vlag\" )\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Single passengers (0 SibSP) or passengers having 1-2 relatives on board (SibSP 1 or 2) have more chance to survive while it seems that passengers having a lot of siblings/spouses have less chance to survive.\n\n### **1.12 Parch**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Parch feature vs Survived\ng  = sns.catplot(x=\"Parch\",y=\"Survived\",data=train,kind=\"bar\", height = 6 , \npalette = \"pastel\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">  Small families (Parch 1,2) have more chance to survive when compared to single (parch 0), medium(parch 3,4) and large family(parch 5)\n\n> **NOTE:** There is an important standard deviation in the survival of passengers with 3 parents/children\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"alone = train[(train['SibSp'] == 0) & (train['Parch'] == 0)]\nnot_alone = train[(train['SibSp'] != 0) | (train['Parch'] != 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 5))\n\nsns.countplot(x = 'Survived', data = alone,  palette = 'Blues', ax = ax1) \nax1.set_title('Count of Alone (non-)Survivors')\nax1.set_xlabel('')\nax1.set_xticklabels(['Deceased', 'Survived'])\nax1.set_ylabel('Number of Passengers')\n\nsns.countplot(x = 'Survived', data = not_alone,  palette = 'Blues', ax = ax2) \nax2.set_title('Count of (non-)Survivors with Family Onboard')\nax2.set_xlabel('')\nax2.set_xticklabels(['Deceased', 'Survived'])\nax2.set_ylabel('Number of Passengers')\n\nplt.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Hence we can say that having 1 to 2 relatives on board can actually increase your chances of survival.\n\n### **1.13 Age**"},{"metadata":{"trusted":true},"cell_type":"code","source":"men = train[train['Sex']  == 'male']\nwomen = train[train['Sex']  == 'female']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (13, 4))\n\nsns.distplot(train[train['Survived'] == 1]['Age'].dropna(), bins = 20, label = 'Survived', ax = ax1, kde = False)\nsns.distplot(train[train['Survived'] == 0]['Age'].dropna(), bins = 20, label = 'Deceased', ax = ax1, kde = False)\nax1.legend()\nax1.set_title('Age Distribution - All Passengers')\n\nsns.distplot(women[women['Survived'] == 1]['Age'].dropna(), bins = 20, label = 'Survived', ax = ax2, kde = False)\nsns.distplot(women[women['Survived'] == 0]['Age'].dropna(), bins = 20, label = 'Deceased', ax = ax2, kde = False)\nax2.legend()\nax2.set_title('Age Distribution - Women')\n\nsns.distplot(men[men['Survived'] == 1]['Age'].dropna(), bins = 20, label = 'Survived', ax = ax3, kde = False)\nsns.distplot(men[men['Survived'] == 0]['Age'].dropna(), bins = 20, label = 'Deceased', ax = ax3, kde = False)\nax3.legend()\nax3.set_title('Age Distribution - Men')\n\nplt.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> It is evident that different age groups had very different survival rates. For instance, both genders display a higher probability of survival between the ages of 15 and 45. Also, the spike at young ages (0-4) shows that infants and young children have higher odds of survival.We also see that passengers between 60-80 have less survived.\n\n> So, even if \"Age\" is not correlated with \"Survived\", we can see that there is age categories of passengers that of have more or less chance to survive.\n\n> It seems that very young passengers have more chance to survive."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Age distibution \ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 0) & (train[\"Age\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 1) & (train[\"Age\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not Survived\",\"Survived\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> When we superimpose the two densities , we cleary see a peak correponsing (between 0 and 5) to babies and very young childrens.\n\n### **1.14 Fare**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Fare\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill Fare missing values with the median value\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since we have one missing value , I decided to fill it with the median value which will not have an important effect on the prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Fare distribution \ng = sns.distplot(dataset[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(dataset[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As we can see, Fare distribution is very skewed. This can lead to overweigth very high values in the model, even if it is scaled.\n\n> In this case, it is better to transform it with the log function to reduce this skew."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply log to Fare to reduce skewness distribution\ndataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.distplot(dataset[\"Fare\"], color=\"b\", label=\"Skewness : %.2f\"%(dataset[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Skewness is clearly reduced after the log transformation\n\nOne would assume that fare is closely related to class. Let's plot a boxplot for the distribution of Fare values across classes and a histogram for survival:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 5))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', data = train, palette = 'tab20', ax = ax1)\nax1.set_title('Distribution of Fares by Class')\n\nsns.distplot(train[train['Survived'] == 1]['Fare'], label = 'Survived', ax = ax2)\nsns.distplot(train[train['Survived'] == 0]['Fare'], label = 'Not Survived', ax = ax2)\nax2.set_title('Distribution of Fares for (non-)Survivors')\nax2.set_xlim([-20, 200])\nax2.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's not a surprise that people in class 1 paid more than the other two classes."},{"metadata":{},"cell_type":"markdown","source":"## **1.2 CATEGORICAL VALUES**"},{"metadata":{},"cell_type":"markdown","source":"### **1.21 Gender**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (11, 4))\n\nsns.countplot(x = 'Sex', hue = 'Survived', data = train,  palette = 'tab20', ax = ax1) \nax1.set_title('Count of (non-)Survivors by Gender')\nax1.set_xlabel('Gender')\nax1.set_ylabel('Number of Passenger')\nax1.legend(labels = ['Deceased', 'Survived'])\n\nsns.barplot(x = 'Sex', y = 'Survived', data = train,  palette = ['#94BFA7', '#FFC49B'], ci = None, ax = ax2)\nax2.set_title('Survival Rate by Gender')\nax2.set_xlabel('Gender')\nax2.set_ylabel('Survival Rate');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"Sex\",\"Survived\"]].groupby('Sex').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There were more men than women on board. However, more women survived the shipwreck (the survival rate is almost 75% for women compared to only 20% for men!).Hence we can say that, \"women and children first\" protocol was implemented for boarding lifeboats.\nSo Gender might play an important role in the prediction of the survival.\n\n### **1.22 Pclass**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Number of passengers in each class:')\ntrain['Pclass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 5))\n\nsns.countplot(x = 'Pclass', hue = 'Survived', data = train,  palette = 'tab20', ax = ax1) \nax1.legend(['Deceased', 'Survived'])\nax1.set_title('Count of (non-)Survivors by Class')\nax1.set_ylabel('Number of Passengers')\n\nsns.barplot(x = 'Pclass', y = 'Survived', data = train,  palette = ['#C98BB9', '#F7D4BC', '#B5E2FA'], ci = None, ax = ax2)\nax2.set_title('Survival Rate by Class')\nax2.set_ylabel('Survival Rate');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> More than 50% of passengers boarded in the 3rd class. Nevertheless, survival favours the wealthy as shown in the right figure (the survival rate increases as we move from 3rd to 1st class)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Pclass vs Survived by Sex\ng = sns.catplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train,\n                   height=6, kind=\"bar\", palette=\"rocket\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This trend is conserved when we look at both male and female passengers.\n\n### **1.23 PORT OF EMBARKATION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Embarked\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill Embarked nan values of dataset set with 'S' most frequent value\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we have two missing values , i decided to fill them with the most fequent value of \"Embarked\" (S)."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Embarked', hue = 'Survived', data = train,  palette = 'tab20') \nplt.ylabel('Number of Passenger')\nplt.title('Count of (non-)Survivors by Port of Embarkation')\nplt.legend(['Deceased', 'Survived']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"Embarked\", y=\"Survived\",  data=train,\n                   height=6, kind=\"bar\", palette=\"Blues\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> From the above plot we can see that passengers coming from Cherbourg (C) have more chance to survive.\n\nMaybe the proportion of first class passengers is higher for those who came from Cherbourg (C) than Queenstown (Q), Southampton (S).\n\nLet's see the Pclass distribution vs Embarked"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Pclass vs Embarked \ng = sns.catplot(\"Pclass\", col=\"Embarked\",  data=train,\n                   height=6, kind=\"count\", palette=\"YlOrBr\")\ng.despine(left=True)\ng = g.set_ylabels(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Indeed, the third class is the most frequent for passenger coming from Southampton (S) and Queenstown (Q), whereas Cherbourg passengers are mostly in first class which have the highest survival rate.\n\n> Maybe we can say that first class passengers were prioritised during the evacuation due to their influence.\n\n## **2. Filling missing Values**\n"},{"metadata":{},"cell_type":"markdown","source":"\n### **2.1 AGE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Age vs Sex, Parch , Pclass and SibSP\ng = sns.catplot(y=\"Age\",x=\"Sex\",data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"Sex\",hue=\"Pclass\", data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"Parch\", data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"SibSp\", data=dataset,kind=\"box\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age distribution seems to be the same in Male and Female subpopulations, so Sex is not informative to predict Age.\n\nHowever, 1rst class passengers are older than 2nd class passengers who are also older than 3rd class passengers.\n\nMoreover, the more a passenger has parents/children the older he is and the more a passenger has siblings/spouses the younger he is."},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert Sex into categorical value 0 for male and 1 for female\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling missing value of Age \n\n## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n# Index of NaN age rows\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n    else :\n        dataset['Age'].iloc[i] = age_med","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"Survived\", y = \"Age\",data = train, kind=\"box\")\ng = sns.catplot(x=\"Survived\", y = \"Age\",data = train, kind=\"violin\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No difference between median value of age in survived and not survived subpopulation.\n\nBut in the violin plot of survived passengers, we still notice that very young passengers have higher survival rate."},{"metadata":{},"cell_type":"markdown","source":"### **2.2 Fare**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3. FEATURE ENGINEERING**\n### **3.1 NAME/TITLE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Name\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Name feature contains information on passenger's title.\n\nSince some passenger with distingused title may be preferred during the evacuation, it is interesting to add them to the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get Title from Name\ndataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\ndataset[\"Title\"] = pd.Series(dataset_title)\ndataset[\"Title\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.countplot(x=\"Title\",data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is 17 titles in the dataset, most of them are very rare and we can group them in 4 categories.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to categorical values Title \ndataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndataset[\"Title\"] = dataset[\"Title\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.countplot(dataset[\"Title\"])\ng = g.set_xticklabels([\"Master\",\"Miss/Ms/Mme/Mlle/Mrs\",\"Mr\",\"Rare\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"Title\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have already seen that women (Mrs or Miss) had higher odds of survival. Now here, notice that Masters and people with a Rare Title have indeed a higher chance of survival compared to 'common' men (Mr)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Name variable\ndataset.drop(labels = [\"Name\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3.2 FAMILY SIZE**\n\nWe can imagine that large families will have more difficulties to evacuate, looking for theirs sisters/brothers/parents during the evacuation. So, i choosed to create a \"Fize\" (family size) feature which is the sum of SibSp , Parch and 1 (including the passenger)."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Fsize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"Fsize\",y=\"Survived\",data = dataset, kind='bar', palette='Blues')\ng = g.set_ylabels(\"Survival Probability\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The family size seems to play an important role, survival probability is worst for large families.\n\nWe create 4 categories of family size."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create new feature of family size\ndataset['Single'] = dataset['Fsize'].map(lambda s: 1 if s == 1 else 0)\ndataset['SmallF'] = dataset['Fsize'].map(lambda s: 1 if  s == 2  else 0)\ndataset['MedF'] = dataset['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['LargeF'] = dataset['Fsize'].map(lambda s: 1 if s >= 5 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x=\"Single\",y=\"Survived\",data=dataset,kind=\"bar\", palette='husl')\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"SmallF\",y=\"Survived\",data=dataset,kind=\"bar\",palette='husl')\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"MedF\",y=\"Survived\",data=dataset,kind=\"bar\", palette='husl')\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"LargeF\",y=\"Survived\",data=dataset,kind=\"bar\", palette='husl')\ng = g.set_ylabels(\"Survival Probability\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Catplots of family size categories show that Small and Medium families have more chance to survive than single passenger and large families."},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to indicator values Title and Embarked \ndataset = pd.get_dummies(dataset, columns = [\"Title\"])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Cabin\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Cabin\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Cabin\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Cabin feature column contains 292 values and 1007 missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Cabin\"][dataset[\"Cabin\"].notnull()].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace the Cabin number by the type of cabin 'X' if not\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first letter of the cabin indicates the Desk, i choosed to keep this information only, since it indicates the probable location of the passenger in the Titanic."},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.countplot(dataset[\"Cabin\"],order=['A','B','C','D','E','F','G','T','X'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(y=\"Survived\",x=\"Cabin\",data=dataset,kind=\"bar\",order=['A','B','C','D','E','F','G','T','X'])\ng = g.set_ylabels(\"Survival Probability\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because of the low number of passenger that have a cabin, survival probabilities have an important standard deviation and we can't distinguish between survival probability of passengers in the different desks.\n\nBut we can see that passengers with a cabin have generally more chance to survive than passengers without (X).\n\nIt is particularly true for cabin B, C, D, E and F."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3.4 TICKET**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset[\"Ticket\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It could mean that tickets sharing the same prefixes could be booked for cabins placed together. It could therefore lead to the actual placement of the cabins within the ship.\n\nTickets with same prefixes may have a similar class and survival.\n\nSo let's replace the Ticket feature column by the ticket prefixe. Which may be more informative."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n\nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0])\n        #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\n\ndataset[\"Ticket\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create categorical values for Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop useless variables \ndataset.drop(labels = [\"PassengerId\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **4. MODELING**"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Separate train dataset and test dataset\n\ntrain = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Separate train features and label \n\ntrain[\"Survived\"] = train[\"Survived\"].astype(int)\n\nY_train = train[\"Survived\"]\n\nX_train = train.drop(labels = [\"Survived\"],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **4.1 Simple Modelling**\n\n#### **Cross Validate Model**\n\nLet's compare popular classifiers and evaluate the mean accuracy of each of them by a stratified kfold cross validation procedure.\n* SVC\n* Decision Tree\n* AdaBoost\n* Random Forest\n* Extra Trees\n* Gradient Boosting\n* Multiple layer perceprton (neural network)\n* KNN\n* Logistic regression\n* Linear Discriminant Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modeling step Test differents algorithms \nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we choose SVC, AdaBoost, RandomForest , ExtraTrees and the GradientBoosting classifiers for the ensemble modeling.\n\n#### **4.12 Hyperparameter tunning for best models**\n\ngrid search optimization for AdaBoost, ExtraTrees , RandomForest, GradientBoosting and SVC classifiers."},{"metadata":{"trusted":true},"cell_type":"code","source":"### META MODELING  WITH ADABOOST, RF, EXTRATREES and GRADIENTBOOSTING\n\n# Adaboost\nDTC = DecisionTreeClassifier()\n\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\n\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[1,2],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsadaDTC.fit(X_train,Y_train)\n\nada_best = gsadaDTC.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gsadaDTC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ExtraTrees \nExtC = ExtraTreesClassifier()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsExtC.fit(X_train,Y_train)\n\nExtC_best = gsExtC.best_estimator_\n\n# Best score\ngsExtC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RFC Parameters tunning \nRFC = RandomForestClassifier()\n\n\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsRFC.fit(X_train,Y_train)\n\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient boosting tunning\n\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,Y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SVC classifier\nSVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\n\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsSVMC.fit(X_train,Y_train)\n\nSVMC_best = gsSVMC.best_estimator_\n\n# Best score\ngsSVMC.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **4.13 Plot learning curves**\nLearning curves are a good way to see the overfitting effect on the training set and the effect of the training size on the accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\ng = plot_learning_curve(gsRFC.best_estimator_,\"RF mearning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsExtC.best_estimator_,\"ExtraTrees learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsSVMC.best_estimator_,\"SVC learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsadaDTC.best_estimator_,\"AdaBoost learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsGBC.best_estimator_,\"GradientBoosting learning curves\",X_train,Y_train,cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GradientBoosting and Adaboost classifiers tend to overfit the training set. According to the growing cross-validation curves GradientBoosting and Adaboost could perform better with more training examples.\n\nSVC and ExtraTrees classifiers seem to better generalize the prediction since the training and cross-validation curves are close together.\n\n#### **4.14 Feature importance of tree based classifiers**\n\nIn order to see the most informative features for the prediction of passengers survival, i displayed the feature importance for the 4 tree based classifiers."},{"metadata":{"trusted":true},"cell_type":"code","source":"nrows = ncols = 2\nfig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n\nnames_classifiers = [(\"AdaBoosting\", ada_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best),(\"GradientBoosting\",GBC_best)]\n\nnclassifier = 0\nfor row in range(nrows):\n    for col in range(ncols):\n        name = names_classifiers[nclassifier][0]\n        classifier = names_classifiers[nclassifier][1]\n        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n        g = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n        g.set_xlabel(\"Relative importance\",fontsize=12)\n        g.set_ylabel(\"Features\",fontsize=12)\n        g.tick_params(labelsize=9)\n        g.set_title(name + \" feature importance\")\n        nclassifier += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"plot the feature importance for the 4 tree based classifiers (Adaboost, ExtraTrees, RandomForest and GradientBoosting).\n\nWe note that the four classifiers have different top features according to the relative importance. It means that their predictions are not based on the same features. Nevertheless, they share some common important features for the classification , for example 'Fare', 'Title_2', 'Age' and 'Sex'.\n\nTitle_2 which indicates the Mrs/Mlle/Mme/Miss/Ms category is highly correlated with Sex.\n\nWe can say that:\n\n* Pc_1, Pc_2, Pc_3 and Fare refer to the general social standing of passengers.\n\n* Sex and Title_2 (Mrs/Mlle/Mme/Miss/Ms) and Title_3 (Mr) refer to the gender.\n\n* Age and Title_1 (Master) refer to the age of passengers.\n\n* Fsize, LargeF, MedF, Single refer to the size of the passenger family.\n\n**According to the feature importance of this 4 classifiers, the prediction of the survival seems to be more associated with the Age, the Sex, the family size and the social standing of the passengers more than the location in the boat.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Survived_RFC = pd.Series(RFC_best.predict(test), name=\"RFC\")\ntest_Survived_ExtC = pd.Series(ExtC_best.predict(test), name=\"ExtC\")\ntest_Survived_SVMC = pd.Series(SVMC_best.predict(test), name=\"SVC\")\ntest_Survived_AdaC = pd.Series(ada_best.predict(test), name=\"Ada\")\ntest_Survived_GBC = pd.Series(GBC_best.predict(test), name=\"GBC\")\n\n\n# Concatenate all classifier results\nensemble_results = pd.concat([test_Survived_RFC,test_Survived_ExtC,test_Survived_AdaC,test_Survived_GBC, test_Survived_SVMC],axis=1)\n\n\ng= sns.heatmap(ensemble_results.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The prediction seems to be quite similar for the 5 classifiers except when Adaboost is compared to the others classifiers.\n\nThe 5 classifiers give more or less the same prediction but there is some differences. Theses differences between the 5 classifier predictions are sufficient to consider an ensembling vote.\n\n### **4.2 Ensemble modeling**\n\n#### **4.21 Combining models**\n\nA voting classifier to combine the predictions coming from the 5 classifiers.\n\nPass the argument \"soft\" to the voting parameter to take into account the probability of each vote."},{"metadata":{"trusted":true},"cell_type":"code","source":"votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),\n('svc', SVMC_best), ('adac',ada_best),('gbc',GBC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **4.3 Prediction**\n\n#### **4.31 Predict and Submit results**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Survived = pd.Series(votingC.predict(test), name=\"Survived\")\n\nresults = pd.concat([IDtest,test_Survived],axis=1)\n\nresults.to_csv(\"ensemble_python_voting.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you liked the notebook then do upvote. It really does motivate!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}