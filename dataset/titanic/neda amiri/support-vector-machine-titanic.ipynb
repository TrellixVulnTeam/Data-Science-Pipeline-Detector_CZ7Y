{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> SVM implementation project on titanic dataset\n### hello!\n### wellcome to another Titanic dataset analysis and Prediction project using the SVM algorithm!","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<img src=\"https://s4.uupload.ir/files/1161691_vh1b.jpg\" border=\"0\" alt=\"آپلود عکس\" />","metadata":{}},{"cell_type":"markdown","source":"#  Introduction Support Vector Machine\n**Support Vector Machines (SVMs in short) are machine learning algorithms that are used for classification and regression purposes. SVMs are one of the powerful machine learning algorithms for classification, regression and outlier detection purposes. An SVM classifier builds a model that assigns new data points to one of the given categories. Thus, it can be viewed as a non-probabilistic binary linear classifier.**\n\n**The original SVM algorithm was developed by Vladimir N Vapnik and Alexey Ya. Chervonenkis in 1963. At that time, the algorithm was in early stages. The only possibility is to draw hyperplanes for linear classifier. In 1992, Bernhard E. Boser, Isabelle M Guyon and Vladimir N Vapnik suggested a way to create non-linear classifiers by applying the kernel trick to maximum-margin hyperplanes. The current standard was proposed by Corinna Cortes and Vapnik in 1993 and published in 1995.**\n\n**SVMs can be used for linear classification purposes. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using the kernel trick. It enable us to implicitly map the inputs into high dimensional feature spaces.**\n","metadata":{}},{"cell_type":"markdown","source":"#  Support Vector Machines intuition \n\n\n\n## familiar with some SVM terminology. \n\n\n###  Hyperplane\n\n**A hyperplane is a decision boundary which separates between given set of data points having different class labels. The SVM classifier separates data points using a hyperplane with the maximum amount of margin. This hyperplane is known as the `maximum margin hyperplane` and the linear classifier it defines is known as the `maximum margin classifier`.**\n\n\n###  Support Vectors\n\n**Support vectors are the sample data points, which are closest to the hyperplane.  These data points will define the separating line or hyperplane better by calculating margins.**\n\n\n###  Margin\n\n**A margin is a separation gap between the two lines on the closest data points. It is calculated as the perpendicular distance from the line to support vectors or closest data points. In SVMs, we try to maximize this separation gap so that we get maximum margin.**\n\nThe following diagram illustrates these concepts visually.\n\n\n###  Margin in SVM\n\n![Margin in SVM](https://static.wixstatic.com/media/8f929f_7ecacdcf69d2450087cb4a898ef90837~mv2.png)\n\n\n###  SVM Under the hood\n\n**In SVMs, our main objective is to select a hyperplane with the maximum possible margin between support vectors in the given dataset. SVM searches for the maximum margin hyperplane in the following 2 step process –**\n\n\n**1.\tGenerate hyperplanes which segregates the classes in the best possible way. There are many hyperplanes that might classify the data. We should look for the best hyperplane that represents the largest separation, or margin, between the two classes.**\n\n**2.\tSo, we choose the hyperplane so that distance from it to the support vectors on each side is maximized. If such a hyperplane exists, it is known as the **maximum margin hyperplane** **and the linear classifier it defines is known as a maximum margin classifier**. \n\n\nThe following diagram illustrates the concept of **maximum margin** and **maximum margin hyperplane** in a clear manner.\n\n\n###  Maximum margin hyperplane\n\n![Maximum margin hyperplane](https://static.packt-cdn.com/products/9781783555130/graphics/3547_03_07.jpg)\n\n\n\n###  Problem with dispersed datasets\n\n\n**Sometimes, the sample data points are so dispersed that it is not possible to separate them using a linear hyperplane. \nIn such a situation, SVMs uses a `kernel trick` to transform the input space to a higher dimensional space as shown in the diagram below. It uses a mapping function to transform the 2-D input space into the 3-D input space. Now, we can easily segregate the data points using linear separation.**\n\n\n###  Kernel trick - transformation of input space to higher dimensional space\n\n![Kernel trick](http://www.aionlinecourse.com/uploads/tutorials/2019/07/11_21_kernel_svm_3.png)\n\n\n### Kernel trick\n\n**In practice, SVM algorithm is implemented using a kernel. It uses a technique called the kernel trick. In simple words, a kernel is just a function that maps the data to a higher dimension where data is separable. A kernel transforms a low-dimensional input data space into a higher dimensional space. So, it converts non-linear separable problems to linear separable problems by adding more dimensions to it. Thus, the kernel trick helps us to build a more accurate classifier. Hence, it is useful in non-linear separation problems.**","metadata":{}},{"cell_type":"markdown","source":"### Define the kernel function\n\n\n**Kernel function**\n\n![Kernel function](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTodZptqcRor0LGo8Qn7_kJB9n9BACMt6jgIPZ4C3g_rgh_uSRZLQ&s)\n\n**In the context of SVMs, there are 4 popular kernels – Linear kernel,Polynomial kernel,Radial Basis Function (RBF) kernel (also called Gaussian kernel) and Sigmoid kernel. These are described below -**","metadata":{}},{"cell_type":"markdown","source":"##  Linear kernel\n\n**In linear kernel, the kernel function takes the form of a linear function as follows-**\n\n**linear kernel : K(xi , xj ) = xiT xj**\n\n**Linear kernel is used when the data is linearly separable. It means that data can be separated using a single line. It is one of the most common kernels to be used. It is mostly used when there are large number of features in a dataset. Linear kernel is often used for text classification purposes.**\n\n**Training with a linear kernel is usually faster, because we only need to optimize the C regularization parameter. When training with other kernels, we also need to optimize the γ parameter. So, performing a grid search will usually take more time.**\n\n**Linear kernel can be visualized with the following figure.**\n\n### Linear Kernel\n\n![Linear Kernel](https://scikit-learn.org/stable/_images/sphx_glr_plot_svm_kernels_thumb.png)","metadata":{}},{"cell_type":"markdown","source":"##  Polynomial Kernel\n\n**Polynomial kernel represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables. The polynomial kernel looks not only at the given features of input samples to determine their similarity, but also combinations of the input samples.**\n\n**For degree-d polynomials, the polynomial kernel is defined as follows –**\n\n**Polynomial kernel : K(xi , xj ) = (γxiT xj + r)d , γ > 0**\n\n**Polynomial kernel is very popular in Natural Language Processing. The most common degree is d = 2 (quadratic), since larger degrees tend to overfit on NLP problems. It can be visualized with the following diagram.**","metadata":{}},{"cell_type":"markdown","source":"##  Radial Basis Function Kernel\n\n**Radial basis function kernel is a general purpose kernel. It is used when we have no prior knowledge about the data. The RBF kernel on two samples x and y is defined by the following equation –**\n\n\n### Radial Basis Function kernel\n\n![RBK Kernel](data:image/png;base64,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)","metadata":{}},{"cell_type":"markdown","source":"##  Sigmoid kernel\n\n**Sigmoid kernel has its origin in neural networks. We can use it as the proxy for neural networks. Sigmoid kernel is given by the following equation –**\n\n**sigmoid kernel : k (x, y) = tanh(αxTy + c)**","metadata":{}},{"cell_type":"markdown","source":"**Sigmoid kernel can be visualized with the following diagram-**\n\n### Sigmoid kernel\n\n![Sigmoid kernel](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTKeXbOIlniBXYwMYlEYLKPwZZg8vFU1wVm3RWMACjVcT4iBVDy&s)","metadata":{}},{"cell_type":"markdown","source":"### To get started, we first import the necessary libraries :","metadata":{}},{"cell_type":"markdown","source":"# Import all Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:09:12.736314Z","iopub.execute_input":"2022-02-18T16:09:12.736614Z","iopub.status.idle":"2022-02-18T16:09:12.909958Z","shell.execute_reply.started":"2022-02-18T16:09:12.736582Z","shell.execute_reply":"2022-02-18T16:09:12.909102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Dataset","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/titanic/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:09:27.234496Z","iopub.execute_input":"2022-02-18T16:09:27.236174Z","iopub.status.idle":"2022-02-18T16:09:27.264496Z","shell.execute_reply.started":"2022-02-18T16:09:27.23612Z","shell.execute_reply":"2022-02-18T16:09:27.26344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Overview","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:09:30.521895Z","iopub.execute_input":"2022-02-18T16:09:30.522366Z","iopub.status.idle":"2022-02-18T16:09:30.551119Z","shell.execute_reply.started":"2022-02-18T16:09:30.522334Z","shell.execute_reply":"2022-02-18T16:09:30.550196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:09:31.652813Z","iopub.execute_input":"2022-02-18T16:09:31.653604Z","iopub.status.idle":"2022-02-18T16:09:31.683359Z","shell.execute_reply.started":"2022-02-18T16:09:31.653554Z","shell.execute_reply":"2022-02-18T16:09:31.682427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:09:33.116817Z","iopub.execute_input":"2022-02-18T16:09:33.117684Z","iopub.status.idle":"2022-02-18T16:09:33.12284Z","shell.execute_reply.started":"2022-02-18T16:09:33.11764Z","shell.execute_reply":"2022-02-18T16:09:33.122085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"### Now, I will explore the data to gain insights about the data.","metadata":{}},{"cell_type":"code","source":"df['Survived'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:09:37.650369Z","iopub.execute_input":"2022-02-18T16:09:37.650815Z","iopub.status.idle":"2022-02-18T16:09:37.658741Z","shell.execute_reply.started":"2022-02-18T16:09:37.650785Z","shell.execute_reply":"2022-02-18T16:09:37.657553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=df, x='Survived')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:09:38.955958Z","iopub.execute_input":"2022-02-18T16:09:38.9567Z","iopub.status.idle":"2022-02-18T16:09:39.12554Z","shell.execute_reply.started":"2022-02-18T16:09:38.956656Z","shell.execute_reply":"2022-02-18T16:09:39.124857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()['Survived'].sort_values()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:09:41.337542Z","iopub.execute_input":"2022-02-18T16:09:41.338078Z","iopub.status.idle":"2022-02-18T16:09:41.346589Z","shell.execute_reply.started":"2022-02-18T16:09:41.338028Z","shell.execute_reply":"2022-02-18T16:09:41.346043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.corr(),annot=True,cmap=\"prism\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:36:14.934969Z","iopub.execute_input":"2022-02-18T17:36:14.935916Z","iopub.status.idle":"2022-02-18T17:36:15.380165Z","shell.execute_reply.started":"2022-02-18T17:36:14.935868Z","shell.execute_reply":"2022-02-18T17:36:15.379167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data=df)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:58:45.668262Z","iopub.execute_input":"2022-02-18T17:58:45.668554Z","iopub.status.idle":"2022-02-18T17:58:55.052249Z","shell.execute_reply.started":"2022-02-18T17:58:45.668524Z","shell.execute_reply":"2022-02-18T17:58:55.051284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation\n ### 1. Check the missing values in the dataset","metadata":{}},{"cell_type":"code","source":"((df.isnull().sum())/len(df))*100","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:10:51.694206Z","iopub.execute_input":"2022-02-18T16:10:51.695183Z","iopub.status.idle":"2022-02-18T16:10:51.705256Z","shell.execute_reply.started":"2022-02-18T16:10:51.695137Z","shell.execute_reply":"2022-02-18T16:10:51.704075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('Cabin',axis=1,inplace=True)\ndf['Age'].fillna(df['Age'].mean(), inplace = True)\n\n((df.isnull().sum())/len(df))*100","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:10:55.6394Z","iopub.execute_input":"2022-02-18T16:10:55.639879Z","iopub.status.idle":"2022-02-18T16:10:55.654764Z","shell.execute_reply.started":"2022-02-18T16:10:55.639828Z","shell.execute_reply":"2022-02-18T16:10:55.653862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:03.017385Z","iopub.execute_input":"2022-02-18T16:11:03.017817Z","iopub.status.idle":"2022-02-18T16:11:03.032295Z","shell.execute_reply.started":"2022-02-18T16:11:03.017786Z","shell.execute_reply":"2022-02-18T16:11:03.031457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def missing_percent(df):\n    nan_percent=((df.isnull().sum())/len(df))*100\n    nan_percent=nan_percent[nan_percent>0].sort_values()\n    return nan_percent\nnan_percent=missing_percent(df)\nnan_percent","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:04.8936Z","iopub.execute_input":"2022-02-18T16:11:04.89388Z","iopub.status.idle":"2022-02-18T16:11:04.906129Z","shell.execute_reply.started":"2022-02-18T16:11:04.893851Z","shell.execute_reply":"2022-02-18T16:11:04.905113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['PassengerId','Name','Ticket','Fare','Embarked'],axis=1, inplace=True)\ndf.loc[df['Sex']=='male','Sex']=1\ndf.loc[df['Sex']=='female','Sex']=0","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:06.45333Z","iopub.execute_input":"2022-02-18T16:11:06.453635Z","iopub.status.idle":"2022-02-18T16:11:06.464536Z","shell.execute_reply.started":"2022-02-18T16:11:06.453604Z","shell.execute_reply":"2022-02-18T16:11:06.463014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def missing_percent(df):\n    nan_percent=((df.isnull().sum())/len(df))*100\n    nan_percent=nan_percent[nan_percent>0].sort_values()\n    return nan_percent\nnan_percent=missing_percent(df)\nnan_percent","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:08.076845Z","iopub.execute_input":"2022-02-18T16:11:08.07763Z","iopub.status.idle":"2022-02-18T16:11:08.087155Z","shell.execute_reply.started":"2022-02-18T16:11:08.077593Z","shell.execute_reply":"2022-02-18T16:11:08.086433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see that there are no missing values in the dataset.","metadata":{}},{"cell_type":"markdown","source":"### 2. Determine feature vector and label variable\n**Features & Label**","metadata":{}},{"cell_type":"code","source":"X=df.drop('Survived',axis=1)\ny=df['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:12.253344Z","iopub.execute_input":"2022-02-18T16:11:12.253795Z","iopub.status.idle":"2022-02-18T16:11:12.260446Z","shell.execute_reply.started":"2022-02-18T16:11:12.253764Z","shell.execute_reply":"2022-02-18T16:11:12.259502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Spliting data into separate training and test set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:21:36.801579Z","iopub.status.idle":"2022-02-18T16:21:36.801953Z","shell.execute_reply.started":"2022-02-18T16:21:36.801766Z","shell.execute_reply":"2022-02-18T16:21:36.801784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T18:35:26.30669Z","iopub.execute_input":"2022-02-18T18:35:26.307318Z","iopub.status.idle":"2022-02-18T18:35:26.317053Z","shell.execute_reply.started":"2022-02-18T18:35:26.307265Z","shell.execute_reply":"2022-02-18T18:35:26.316083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Scalling The Features","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscaler.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:18.301827Z","iopub.execute_input":"2022-02-18T16:11:18.302158Z","iopub.status.idle":"2022-02-18T16:11:18.314833Z","shell.execute_reply.started":"2022-02-18T16:11:18.302121Z","shell.execute_reply":"2022-02-18T16:11:18.313718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_X_train= scaler.transform(X_train)\nscaled_X_test= scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:19.714353Z","iopub.execute_input":"2022-02-18T16:11:19.715228Z","iopub.status.idle":"2022-02-18T16:11:19.725637Z","shell.execute_reply.started":"2022-02-18T16:11:19.715187Z","shell.execute_reply":"2022-02-18T16:11:19.724841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handle outliers with SVMs\n**There are 2 variants of SVMs. They are hard-margin variant of SVM and soft-margin variant of SVM.**\n\n**The hard-margin variant of SVM does not deal with outliers. In this case, we want to find the hyperplane with maximum margin such that every training point is correctly classified with margin at least 1. This technique does not handle outliers well.**\n\n**Another version of SVM is called soft-margin variant of SVM. In this case, we can have a few points incorrectly classified or classified with a margin less than 1. But for every such point, we have to pay a penalty in the form of C parameter, which controls the outliers. Low C implies we are allowing more outliers and high C implies less outliers.**\n\n**The message is that since the dataset contains outliers, so the value of C should be high while training the model.**","metadata":{}},{"cell_type":"markdown","source":"We now have X_train dataset ready to be fed into the Logistic Regression classifier. I will do it as follows.","metadata":{}},{"cell_type":"markdown","source":"# running of svm  model on train data","metadata":{}},{"cell_type":"markdown","source":"**Scikit-Learn provides useful libraries to implement Support Vector Machine algorithm on a dataset. There are many libraries that can help us to implement SVM smoothly. We just need to call the library with parameters that suit to our needs. In this project, I am dealing with a classification task. So, I will mention the Scikit-Learn libraries for SVM classification purposes.**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nmodel=SVC()\nmodel.fit(X_train , y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:23.694015Z","iopub.execute_input":"2022-02-18T16:11:23.69444Z","iopub.status.idle":"2022-02-18T16:11:23.720702Z","shell.execute_reply.started":"2022-02-18T16:11:23.694409Z","shell.execute_reply":"2022-02-18T16:11:23.720066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting Test Data","metadata":{}},{"cell_type":"code","source":"y_pred=model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:27.021885Z","iopub.execute_input":"2022-02-18T16:11:27.022371Z","iopub.status.idle":"2022-02-18T16:11:27.02939Z","shell.execute_reply.started":"2022-02-18T16:11:27.022323Z","shell.execute_reply":"2022-02-18T16:11:27.028718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nconfusion_matrix(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:30.087067Z","iopub.execute_input":"2022-02-18T16:11:30.087536Z","iopub.status.idle":"2022-02-18T16:11:30.098779Z","shell.execute_reply.started":"2022-02-18T16:11:30.087489Z","shell.execute_reply":"2022-02-18T16:11:30.097952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:31.813582Z","iopub.execute_input":"2022-02-18T16:11:31.81407Z","iopub.status.idle":"2022-02-18T16:11:31.825152Z","shell.execute_reply.started":"2022-02-18T16:11:31.814019Z","shell.execute_reply":"2022-02-18T16:11:31.824004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameters Tuning\n### Choosing the best hyperparameters through GridSearchCV","metadata":{}},{"cell_type":"code","source":"help(SVC)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:29:58.096761Z","iopub.execute_input":"2022-02-18T16:29:58.097469Z","iopub.status.idle":"2022-02-18T16:29:58.111632Z","shell.execute_reply.started":"2022-02-18T16:29:58.097422Z","shell.execute_reply":"2022-02-18T16:29:58.110486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:11:36.027195Z","iopub.execute_input":"2022-02-18T16:11:36.027606Z","iopub.status.idle":"2022-02-18T16:11:36.031403Z","shell.execute_reply.started":"2022-02-18T16:11:36.027576Z","shell.execute_reply":"2022-02-18T16:11:36.030673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = SVC()\nparam_grid = {'C':[0.01,0.1,1, 10, 100, 1000],'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\ngrid = GridSearchCV(svm,param_grid, cv=5)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:31:38.87629Z","iopub.execute_input":"2022-02-18T16:31:38.876721Z","iopub.status.idle":"2022-02-18T16:31:38.882769Z","shell.execute_reply.started":"2022-02-18T16:31:38.87668Z","shell.execute_reply":"2022-02-18T16:31:38.8815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:31:56.735045Z","iopub.execute_input":"2022-02-18T16:31:56.735588Z","iopub.status.idle":"2022-02-18T16:32:02.139412Z","shell.execute_reply.started":"2022-02-18T16:31:56.735523Z","shell.execute_reply":"2022-02-18T16:32:02.138544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:32:16.855288Z","iopub.execute_input":"2022-02-18T16:32:16.855641Z","iopub.status.idle":"2022-02-18T16:32:16.862049Z","shell.execute_reply.started":"2022-02-18T16:32:16.855601Z","shell.execute_reply":"2022-02-18T16:32:16.861257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:32:21.147223Z","iopub.execute_input":"2022-02-18T16:32:21.147525Z","iopub.status.idle":"2022-02-18T16:32:21.154536Z","shell.execute_reply.started":"2022-02-18T16:32:21.147497Z","shell.execute_reply":"2022-02-18T16:32:21.153551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_grid= grid.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:32:24.630979Z","iopub.execute_input":"2022-02-18T16:32:24.631288Z","iopub.status.idle":"2022-02-18T16:32:24.638777Z","shell.execute_reply.started":"2022-02-18T16:32:24.631256Z","shell.execute_reply":"2022-02-18T16:32:24.637652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test, y_pred_grid)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:32:30.096418Z","iopub.execute_input":"2022-02-18T16:32:30.096954Z","iopub.status.idle":"2022-02-18T16:32:30.105245Z","shell.execute_reply.started":"2022-02-18T16:32:30.096917Z","shell.execute_reply":"2022-02-18T16:32:30.104254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_grid))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:32:33.215827Z","iopub.execute_input":"2022-02-18T16:32:33.216763Z","iopub.status.idle":"2022-02-18T16:32:33.237395Z","shell.execute_reply.started":"2022-02-18T16:32:33.216694Z","shell.execute_reply":"2022-02-18T16:32:33.235773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finish\n\n**I hope you find this kernel useful and enjoyable.**\n\n**Your comments and feedback are most welcome.**\n\n**Thank you**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}