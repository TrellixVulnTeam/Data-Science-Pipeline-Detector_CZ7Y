{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Achieving 80% accuracy in easy way.\n\n**This notebook is a beginner's guide to first kaggle competition, I am using basic functions and libraries to perform my data analysis and fitting model into my data.\n\nTo achieve our goal we need to perform these tasks-\n\n* Importing data and reading it\n* Exploratory Data Analysis\n* Merging data\n* Feature Engineering(Filling missing data,Creating Columns,Dropping columns,mapping data)\n* Correlation and feature importance\n* Fitting the model\n* Predicting Resullts\n\n**Please if you find this notebook useful,upvote it and feel free to  copy and edit for use**\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing data\n#importing and reading data\ntrain=pd.read_csv('../input/titanic/train.csv')\ntest =pd.read_csv(\"../input/titanic/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading data\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As we can see the Survived column is the dependent feature and is absent in test data set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#looking at shape and other information of data\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nTrain has 891 rows and test has 418 rows with one missing column which is Survived","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that columns Age, Embarked, fare and Cabin have null values We can also plot it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n**We will use heatmap for plotting the missimg values, What is a heatmap? A heat map (or heatmap) is a graphical representation of data where values are depicted by color. Heat maps make it easy to visualize complex data and understand it at a glance. We'll see how!**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='rainbow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nHere we can see that since heatmap depicts value in colors, more than 80% of the cabin data is misssing and few age rows are also missing.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Anlysis\n*So what basically is exploratory data analysis In data mining, Exploratory Data Analysis (EDA) is an approach to analyzing datasets to summarize their main characteristics, often with visual methods. EDA is used for seeing what the data can tell us before the modeling task.It may be tedious, boring, and/or overwhelming to derive insights by looking at plain numbers. Exploratory data analysis techniques have been devised as an aid in this situation.*\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n**First we'll separate categorical and numerical features in our data set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features=[features for features in train.columns if train[features].dtypes=='O']\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features=[features for features in train.columns if train[features].dtypes!='O']\nnumerical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot depicting the relation between Pclass(Ticket class) and Passengers Survived\nsns.barplot(x=\"Pclass\",y=\"Survived\",data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting age feature\nsns.FacetGrid(train, hue=\"Survived\", size=5) \\\n   .map(sns.distplot, \"Age\") \\\n   .add_legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot depicting the relation between Gender and Passengers Survived\nsns.barplot(x=\"Sex\",y=\"Survived\",data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot depicting the relation between Embarked(Port of Embarkation) and Passengers Survived\nsns.barplot(x=\"Embarked\",y=\"Survived\",data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.pairplot(train[[\"Survived\",\"Pclass\",\"Fare\",\"Age\"]], hue=\"Survived\", height=3);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graphs we can easily depict the relation between Survived and mentioned features\n\n* As most of the first class passengers survived\n* Females Survived more than males\n* People who embarked from \"C\" had more chances of survival","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n**Now we'll merge our data**\n\nbut before mergin we'll seperate out our dependent feature 'Survived'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_train= train['Survived']\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ntrain = train.shape[0]\nntest = test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['Survived'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nall_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# **Feature Engineering\nAfter merging data we'll perform our feature engineering on data. We'll perform following 3 things\n\n* fill missing values\n* Create new column Family size,fare per person,Title and mapping the categorical features\n* Dropping Columns that are not important","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**Filling missing** values Age, fare and Embarked, Cabin have missing values we'll take different approach to fill them , but we'll drop the Cabin feature because it's usually advised to drop feature with high amount of missing values(>50%)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"age_by_pclass_sex =all_data.groupby(['Sex', 'Pclass']).median()['Age']\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n        \nprint('Median age of all passengers: {}'.format(all_data['Age'].median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nall_data['Age']= all_data.groupby(['Sex','Pclass'])['Age'].apply(lambda x:x.fillna(x.median()))\nall_data['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*I want to explain this further here, the code might seem a bit overwhelmimg but it simply is grouping age according to the ticket class and gender, and then by using the lamnda function and fillna function I am filling the missing value*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling the missing value in Embarked by mode(most freqquent) value\nmode=all_data['Embarked'].mode()\nall_data['Embarked']= all_data['Embarked'].fillna('mode')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#filling fare\nmed_fare= all_data.groupby(['Pclass','Parch','SibSp']).Fare.median()[3][0][0]\nmed_fare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['Fare'] = all_data['Fare'].fillna(med_fare)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now checking all the missing value\nall_data.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now stepping onto the second task that is creating a new column and creating catergorical fetures","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#family size is sum of SibSp(siblings / spouses aboard the Titanic) and Parch(parents / children aboard the Titanic)\nall_data['Family_size']= all_data['SibSp']+all_data['Parch']+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#creating column title\nall_data['Title'] = all_data['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\nall_data['Title']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['FarePerPerson']= all_data['Fare']/all_data['Family_size']\nall_data['FarePerPerson']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping columns that are not important\nall_data.drop(['Ticket','SibSp','Name','Parch','Cabin'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data=all_data.drop(['Fare'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mapping categorical features**\n\nI will use the label encoder function provided by scikit learn for pre-processing but we can also use mapping function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncategorical_features=[features for features in all_data.columns if all_data[features].dtypes=='O']\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# process columns, apply LabelEncoder to categorical features\nlbl= LabelEncoder()\nlbl.fit(list(all_data['Title'].values)) \nall_data['Title'] = lbl.transform(list(all_data['Title'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl.fit(list(all_data['Sex'].values)) \nall_data['Sex'] = lbl.transform(list(all_data['Sex'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlbl.fit(list(all_data['Embarked'].values)) \nall_data['Embarked'] = lbl.transform(list(all_data['Embarked'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seperating data\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correaltion and feature Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,8))\n\nsns.heatmap(train.corr(),annot=True,cmap='Oranges')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# finally fitting our training set and making prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier,  GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x= train\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nGBR = GradientBoostingClassifier(n_estimators=100, max_depth=4)\nGBR.fit(x,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finalMdG is the prediction by GradientBoostingClassifier\nfinalMdG=GBR.predict(test)\nfinalMdG","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ID = test['PassengerId']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.DataFrame()\nsubmission['PassengerId'] = ID\nsubmission['Survived'] = finalMdG\nsubmission.to_csv('submissiongb.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrd=RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rd.fit(x,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#finalMdR is the prediction by RandomForestClassifier\nfinalMdR=rd.predict(test)\nfinalMdR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmission=pd.DataFrame()\nsubmission['PassengerId'] = ID\nsubmission['Survived'] = finalMdR\nsubmission.to_csv('submissionrd.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The End \nI tried my best to keep the code easy and simple I've missed out some of the things like feature scaling and Hyperparameter Tunning but since this is a small dataset the model will work fine.\n\n**Feel free to comment,quries, suggestion or feedbacks**\n\n**Humble Request**- *My previous notebook have accidentaly deleted from kaggle(I don't know the reason), it was my first notebook and I managed to gather 30+ upvotes in 2 weeks,*\n**Please upvote my Notebook if you find it useful,and to support**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}