{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\n# # color palletes\n# male_female_pal = ['#3489d6', '#e64072']\n# survival_pal = ['#2a2a2a', '#ff0000']\n# sns.set_palette(survival_pal)\n# sns.set_style(\"whitegrid\")\n\n# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n# from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, LabelBinarizer, scale, Normalizer, PowerTransformer, MaxAbsScaler\n# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n# from sklearn.svm import SVC, NuSVC, LinearSVC\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.tree import DecisionTreeClassifier\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.neighbors import KNeighborsClassifier\n\n# import lightgbm as lgb\n\n# import eli5\n# from eli5.sklearn import PermutationImportance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# numerical analysis\nimport numpy as np\n# storing and processing in dataframes\nimport pandas as pd\n\n# basic plotting\nimport matplotlib.pyplot as plt\n# advanced plotting\nimport seaborn as sns\n\n# splitting dataset into train and test\nfrom sklearn.model_selection import train_test_split\n# scaling features\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelBinarizer, LabelEncoder\n# selecting important features\nfrom sklearn.feature_selection import RFECV\n# k nearest neighbors model\nfrom sklearn.neighbors import KNeighborsClassifier\n# accuracy\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Theme","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot style\nsns.set_style('whitegrid')\n\n# color palettes\nmale_female_pal = ['#3489d6', '#e64072']\nsurvival_pal = ['#2a2a2a', '#ff0000']\nsns.set_palette(survival_pal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data","execution_count":null},{"metadata":{"trusted":true,"_uuid":"b16838bd02ca7e36cab4d87341e7f0f38037e07d"},"cell_type":"code","source":"# get training dataset\ntrain = pd.read_csv('../input/train.csv')\n\n# first few rows of train dataset\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get test dataset\ntest = pd.read_csv('../input/test.csv')\n\n# first few rows of test dataset\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Task\n* test dataset doesn't have the column 'Survived'\n* we need to come up with a ML model that can predict 'Survived' value\n* we need to find wether the passenger survived or did not survived\n* this is a classic Classification task","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Features / Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"* Survival\n    > * Survival\n        0 - No - Did not survived\n        1 - Yes - Survived\n\n\n* Pclass\n    > * Ticket class  \n    > * A proxy for socio-economic status (SES) \n        1 - 1st - Upper   \n        2 - 2nd - Middle   \n        3 - 3rd - Lower \n        \n       \n* Sex\n    > * Gender\n    > * Male or Female\n    \n   \n* Age\n    > * Age in years\n    > * Age is fractional if less than 1. \n    > * If the age is estimated, is it in the form of xx.5\n    \n    \n* Sibsp\n    > * No. of siblings / spouses aboard the Titanic \n    > * Sibling = brother, sister, stepbrother, stepsister\n    > * Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n    \n    \n* Parch\n    > * No. of parents / children aboard the Titanic \n    > * Parent = mother, father\n    > * Child = daughter, son, stepdaughter, stepson\n    > * Some children travelled only with a nanny, therefore parch=0 for them.\n    \n    \n* Ticket\n    > * Ticket number \n    \n    \n* Fare\n    > * Passenger fare \n    \n    \n* Cabin\n    > * Cabin number \n    \n    \n* Embarked\n    > * Port of Embarkation \n        C = Cherbourg\n        Q = Queenstown\n        S = Southampton","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data properties","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# no. of rows and columns\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  columns names\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# consise summary of dataframe\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# descriptive statistics\ntrain.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inspecting Dataframes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_missing_vals_info(df):\n    '''get no. of missing values information'''\n    \n    # no. of missing values in each column of the dataframe\n    print(df.isna().sum())\n    \n    # visualizing missing values in each column\n    \n    # plot figure\n    plt.figure(figsize=(12, 6))\n    # plot missing values heatmap\n    sns.heatmap(df.isna(), cbar=False, cmap='cividis')\n    # title\n    plt.title('Missing values in each columns')\n    # show the plot\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values in train dataset\nget_missing_vals_info(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values in train dataset\nget_missing_vals_info(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class distribution\n\nplt.figure(figsize=(4, 5))\nsns.countplot(x='Survived', data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### No. of values in each category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# How being in different categories resulted in the survival ?\n\ncat_cols = ['Pclass', 'Sex', 'Embarked']\n\nfig, ax = plt.subplots(1, 3, figsize=(15, 4))\nfor ind, val in enumerate(cat_cols):\n    sns.countplot(x=val, hue='Survived', data=train, ax=ax[ind])\n    ax[ind].legend(['Did not survived', 'Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Did people hold on to their families ?\n\ncat_cols = ['SibSp', 'Parch']\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 4))\nfor ind, val in enumerate(cat_cols):\n    sns.countplot(x=val, hue='Survived', data=train, ax=ax[ind])\n    ax[ind].legend(['Did not survived', 'Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(20, 5))\nfor ind, col in enumerate(['Age', 'Fare']):\n    ax[ind] = sns.kdeplot(train.loc[train['Survived']==0, col].dropna(), shade=True, ax=ax[ind])\n    ax[ind] = sns.kdeplot(train.loc[train['Survived']==1, col].dropna(), shade=True, ax=ax[ind])\n    ax[ind].set_xlabel(col)\n    ax[ind].legend(['Did not survived', 'Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between columns\n\nplt.figure(figsize=(8, 6))\ndf_corr = train.drop('PassengerId', axis=1).corr()\nsns.heatmap(df_corr, annot=True, fmt='.2f', cmap='RdBu', vmax=0.8, vmin=-0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pairplot\n\nplt.figure(figsize=(7, 7))\nsns.pairplot(train.drop('PassengerId', axis=1), hue=\"Survived\", palette=survival_pal)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling Embarked with most frequent value\n# =========================================\n\nprint(train['Embarked'].value_counts())\nmost_freq = train['Embarked'].value_counts().index[0]\ntrain['Embarked'].fillna(most_freq, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling age with respect to title\n# ==================================\n\n# extracting the title\ntrain[\"Title\"] = train[\"Name\"].str.extract('([A-Za-z]+)\\.',expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract('([A-Za-z]+)\\.',expand=False)\n\n# replacing similar titles\nfor i in [train, test]:\n    i['Title'] = i['Title'].replace('Mr', 'Mr')\n    i['Title'] = i['Title'].replace(('Mme', 'Ms'), 'Mrs')\n    i['Title'] = i['Title'].replace('Mlle', 'Miss')\n    i['Title'] = i['Title'].replace(('Capt', 'Col', 'Major', 'Dr','Rev'), 'Officer')\n    i['Title'] = i['Title'].replace(('Jonkheer', 'Don', 'Sir', 'Countess','Dona', 'Lady'), 'Royalty')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Title vs Age Distribution\n\nsns.set_palette('Paired')\nplt.figure(figsize=(15, 6))\n\nax = sns.kdeplot(train[train['Title']=='Mr']['Age'], shade=True, label='Mr')\nax = sns.kdeplot(train[train['Title']=='Mrs']['Age'], shade=True, label='Mrs')\nax = sns.kdeplot(train[train['Title']=='Miss']['Age'], shade=True, label='Miss')\nax = sns.kdeplot(train[train['Title']=='Master']['Age'], shade=True, label='Master')\nax = sns.kdeplot(train[train['Title']=='Officer']['Age'], shade=True, label='Officer')\n\nax.set_xlim(-10, 90)\nax.set_xlabel('Age')\nax.set_title('Distribution of Age of based on Title')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill age wrt title\nfor df in [train, test]:\n    for title in df['Title'].unique():\n        age = df.loc[df['Title']==title, 'Age'].mean()\n        df[df['Title']==title].fillna(age, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Datatypes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting to catogorical values into categorical columns \n\ncat_cols = ['Pclass', 'Sex', 'Embarked']\nfor i in cat_cols:\n    train[i] = train[i].astype('category')\n    test[i] = test[i].astype('category')\n    \n# train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visual Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class - Gender - Survival\n\ng = sns.FacetGrid(train, col='Embarked', size=4)\ng.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', order=[1, 2, 3], \n      hue_order=['male', 'female'], palette=male_female_pal)\ng.add_legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x=\"Embarked\", hue=\"Title\", data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x=\"Pclass\", hue=\"Title\", data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mean of of age wrt Title\n\ntr = train[['Age', 'Title']]\nts = test[['Age', 'Title']]\ntr_ts = pd.concat([tr, ts])\n\nprint(tr_ts.groupby('Title').mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(60,5))\n# ax = sns.countplot(x='Age', hue='Survived', data=train)\n# plt.legend(['Not Survived', 'Survived'])\n# plt.show()\n\n# plt.figure(figsize=(200, 5))\n# ax = sns.countplot(x='Fare', hue='Survived', data=train)\n# plt.legend(['Not Survived', 'Survived'])\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Binning Age and Fare\n\ntrain['age_cat'] = pd.cut(train['Age'], \n                          bins = [0, 0.99, 7, 23, 58, 100],\n                          labels = [\"infant\", \"child\", \"young\", \"adult\", \"senior\"],\n                          include_lowest=True)\ntest['age_cat'] = pd.cut(test['Age'], \n                         bins = [0, 0.99, 7, 23, 58, 100],\n                         labels = [\"infant\", \"child\", \"young\", \"adult\", \"senior\"],\n                         include_lowest=True)\n\ntrain['fare_cat'] = pd.cut(train['Fare'], \n                           bins = [0, 12, 40, 80, 1000],\n                           labels = ['least', 'low', 'mid', 'high'],\n                           include_lowest=True)\ntest['fare_cat'] = pd.cut(test['Fare'], \n                           bins = [0, 12, 40, 80, 1000],\n                           labels = ['least', 'low', 'mid', 'high'],\n                           include_lowest=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting Cabin Type from Cabin name\n\nc_train_type = train['Cabin'].str[0]\ntrain['c_type'] = c_train_type\ntrain['c_type'] = train['c_type'].fillna('unknown')\n\nc_test_type = test['Cabin'].str[0]\ntest['c_type'] = c_test_type\ntest['c_type'] = test['c_type'].fillna('unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age, Fare, Cabin category vs Survival\n\nfig, ax = plt.subplots(1, 3, figsize=(24, 5))\nfor ind, val in enumerate(['age_cat', 'fare_cat', 'c_type']):\n    sns.countplot(x=val, hue='Survived', data=train, ax=ax[ind])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Family member count and Family Size and is alone\n\ntrain['fam_count'] = train['SibSp']+train['Parch']\ntest['fam_count'] = test['SibSp']+test['Parch']\n\nsize = {\n    0:'alone',\n    1:'small',\n    2:'small',\n    3:'small',\n    4:'large',\n    5:'large',\n    6:'large',\n    7:'large',\n    10:'large'\n}\n\ntrain['fam_size'] = train['fam_count'].map(size)\ntest['fam_size'] = test['fam_count'].map(size)\n\ntrain['is_alone'] = train['fam_size']=='alone'\ntest['is_alone'] = test['fam_size']=='alone'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 3, figsize=(20, 5))\nfor ind, val in enumerate(['fam_count', 'fam_size', 'is_alone']):\n    sns.countplot(x=val, hue='Survived', data=train, ax=ax[ind])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataframe\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling Age and Fare\n\nmm = MinMaxScaler()\nfor i in ['Age', 'Fare']:\n    train[i] =  mm.fit_transform(train[i].values.reshape(-1,1))\n    test[i] =  mm.fit_transform(test[i].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Binerizer Sex\n\nlb = LabelBinarizer()\nfor i in ['Sex', 'is_alone']:\n    train[i] =  lb.fit_transform(train[i])\n    test[i] =  lb.fit_transform(test[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Encoding Pclass\n\nen = LabelEncoder()\ntrain['Pclass'] =  en.fit_transform(train['Pclass'])\ntest['Pclass'] =  en.fit_transform(test['Pclass'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dummies for nominal categorical columns\n\ndef create_dummies(df, column_name):\n    dummies = pd.get_dummies(df[column_name], prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    df.drop(column_name, axis=1, inplace=True)\n    return df\n\n# for i in ['Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'age_cat', 'fare_cat', 'c_type', 'fam_count', 'fam_size']:\n#     train = create_dummies(train, i)\n#     test = create_dummies(test, i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping columns\n\ntrain.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\ntest.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataframe\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final correlation heatmap\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(train.drop('PassengerId', axis=1).corr(), annot=True, fmt='.1f', cmap='RdBu', vmax=0.8, vmin=-0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train - Test data splitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# X = train.drop(['Survived', 'PassengerId'], axis=1)\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'fam_count', 'is_alone']\nX = train[features]\ny = train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# naive bayes\n\nnb = GaussianNB()\nnb.fit(X_train, y_train)\ny_pred = nb.predict(X_test)\naccuracy_score(y_pred, y_test)\n#print(classification_report(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(3,3))\nsns.heatmap(confusion_matrix(y_pred, y_test), annot=True, cbar=False, fmt='1d', cmap='Blues')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(nb, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression\n\nlr = LogisticRegression(C = 1, penalty= 'l2', solver= 'liblinear')\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\naccuracy_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(classification_report(y_pred, y_test))\nplt.figure(figsize=(3,3))\nsns.heatmap(confusion_matrix(y_pred, y_test), annot=True, cbar=False, fmt='1d', cmap='Blues')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(lr, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# svm\n\nmodel = SVC()\n\nhyperparameters = {\n    'C': [0.1, 1, 10, 100],\n    'gamma': [1, 0.1, 0.01],\n    'kernel': ['rbf', 'linear']\n}\n\ngrid = GridSearchCV(model, param_grid=hyperparameters, cv=10)\ngrid.fit(X, y)\n\nbest_params = grid.best_params_\nbest_score = grid.best_score_\n\nsvc = grid.best_estimator_\ny_pred = svc.predict(X_test)\n\nprint(grid.best_params_)\nprint(grid.best_estimator_)\nprint(grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(classification_report(y_pred, y_test))\nplt.figure(figsize=(3,3))\nsns.heatmap(confusion_matrix(y_pred, y_test), annot=True, cbar=False, fmt='1d', cmap='Blues')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(svc, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# K Nearest Neighbours\n\nmodel = KNeighborsClassifier()\n\nhyperparameters = {\n    \"n_neighbors\" : range(1,20,2),\n    'weights' : ['uniform', 'distance'],\n    'p' : [1, 2]\n}\n\ngrid = GridSearchCV(model, param_grid=hyperparameters, cv=10)\ngrid.fit(X, y)\n\nbest_params = grid.best_params_\nbest_score = grid.best_score_\n\nknn = grid.best_estimator_\ny_pred = knn.predict(X_test)\n\nprint(grid.best_params_)\nprint(grid.best_estimator_)\nprint(grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(classification_report(y_pred, y_test))\nplt.figure(figsize=(3,3))\nsns.heatmap(confusion_matrix(y_pred, y_test), annot=True, cbar=False, fmt='1d', cmap='Blues')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(knn, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\naccuracy_score(y_pred, y_test)\n#print(classification_report(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nimport graphviz \n\ndot_data = tree.export_graphviz(dt, out_file=None) \ngraph = graphviz.Source(dot_data) \ngraph.render(\"iris\")\n\ndot_data = tree.export_graphviz(dt, out_file=None, \n                     feature_names=X_train.columns,  \n                     class_names=['Survived', 'Not Survived'],  \n                     filled=True, rounded=True,  \n                     special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyperparameters = {\"criterion\": [\"entropy\", \"gini\"],\n                   \"max_depth\": [3, 5, 7, 10],\n                   \"max_features\": [\"log2\", \"sqrt\", 'auto'], \n                   'min_samples_leaf' : [2, 3, 4, 5],\n                   'min_samples_split' : [2, 3, 4, 5]\n}\n\ngrid = GridSearchCV(dt, param_grid=hyperparameters, cv=10)\ngrid.fit(X, y)\n\nbest_params = grid.best_params_\nbest_score = grid.best_score_\n\ndt = grid.best_estimator_\ny_pred = dt.predict(X_test)\n\nprint(grid.best_params_)\nprint(grid.best_score_)\n\n#print(classification_report(y_pred, y_test))\nplt.figure(figsize=(3,3))\nsns.heatmap(confusion_matrix(y_pred, y_test), annot=True, cbar=False, fmt='1d', cmap='Blues')\n\nperm = PermutationImportance(dt, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\n\nmodel = RandomForestClassifier()\n\nhyperparameters = {\"criterion\": [\"entropy\", \"gini\"],\n                   \"max_depth\": [5, 10],\n                   \"max_features\": [\"log2\", \"sqrt\"],\n                   'min_samples_leaf' : [2, 3, 4, 5],\n                   'min_samples_split' : [2, 3, 4, 5],\n                   \"n_estimators\": [6, 9]\n}\n\ngrid = GridSearchCV(model, param_grid=hyperparameters, cv=10)\ngrid.fit(X, y)\n\nbest_params = grid.best_params_\nbest_score = grid.best_score_\n\nrf = grid.best_estimator_\ny_pred = rf.predict(X_test)\n\nprint(grid.best_params_)\nprint(grid.best_score_)\n\n#print(classification_report(y_pred, y_test))\nplt.figure(figsize=(3,3))\nsns.heatmap(confusion_matrix(y_pred, y_test), annot=True, cbar=False, fmt='1d', cmap='Blues')\n\nperm = PermutationImportance(rf, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Holdout Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout_ids = test[\"PassengerId\"]\nholdout_features = test[features]\nholdout_predictions = lr.predict(holdout_features)\n\nsubmission = pd.DataFrame({\"PassengerId\": holdout_ids, \n                           \"Survived\": holdout_predictions})\nprint(submission.head())\n\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}