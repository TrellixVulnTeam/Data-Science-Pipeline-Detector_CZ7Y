{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Version History\n* V22 - Added Keras Tune\n* V23 - Added Boxplots\n* V24 - Added Pipelines for Classifiers\n* V25 - Added Learning Curves\n* V26 - New Model Stacking\n* V27 - Added Model Building Function\n* V32 - Updated Model Building Function\n* V34 - Added History\n* V36 - Added CatBoost and LightGBM algorithms","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n### Welcome to my first ever Machine Learning project/Kaggle Competition!\n\nIn this notebook we'll do some easy data visualizations and feature engineering before applying different machine learning algorithms like Logistic Regression, Random Forest, Support Vector Machines and more. We're also using a Neural Network using Keras and Tensorflow with a Keras-Tuner for hyperparameter optimization. For better understanding of the dataset and algorithms we'll use a PCA and ROC-Curves.\n\n#### If you have any suggestions on how to improve this notebook please let me know!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# History\nRMS Titanic was a British passenger liner operated by the White Star Line that sank in the North Atlantic Ocean in the early morning hours of 15 April 1912, after striking an iceberg during her maiden voyage from Southampton to New York City. Of the estimated 2,224 passengers and crew aboard, more than 1,500 died, making the sinking one of modern history's deadliest peacetime commercial marine disasters. RMS Titanic was the largest ship afloat at the time she entered service and was the second of three Olympic-class ocean liners operated by the White Star Line. She was built by the Harland and Wolff shipyard in Belfast.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Goal\nIt is our job to predict if a passenger survived the sinking of the Titanic or not. For each person in the test set, we must predict a 0 or 1 value for the variable. Our score is the percentage of passengers we correctly predict. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Import modules","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport missingno\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import style\nfrom matplotlib.pyplot import plot\n\nstyle.use(\"seaborn-whitegrid\")\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Import data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_size_train = train.memory_usage().sum() / 1024 / 1024\nprint(\"Data memory size: %.2f MB\" % data_size_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_size_test = test.memory_usage().sum() / 1024 / 1024\nprint(\"Data memory size: %.2f MB\" % data_size_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)\ntest.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missingno.matrix(train, figsize = (10,5))\nplt.title(\"Missing Values (train)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missingno.matrix(test, figsize = (10,5))\nplt.title(\"Missing Values (test)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Embarked\"].fillna(train[\"Embarked\"].mode()[0], inplace = True)\ntrain[\"Age\"].fillna(train[\"Age\"].mean(), inplace = True)\ntrain = train.drop([\"Cabin\", \"Ticket\"], axis = 1)\nprint(train.isnull().sum().sort_values(ascending = False).head(3))\n\nprint(\"-------------\")\n\ntest[\"Fare\"].fillna(test[\"Fare\"].mean(), inplace = True)\ntest[\"Age\"].fillna(test[\"Age\"].mean(), inplace = True)\ntest = test.drop([\"Cabin\", \"Ticket\"], axis = 1)\nprint(test.isnull().sum().sort_values(ascending = False).head(3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Feature engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.1 Name Title","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"NameTitle\"] = train[\"Name\"].str.split(\", \", expand = True)[1].str.split(\". \", expand = True)[0]\ntest[\"NameTitle\"] = test[\"Name\"].str.split(\", \", expand = True)[1].str.split(\". \", expand = True)[0]\n\ntrain = train.drop(\"Name\", axis = 1)\ntest = test.drop(\"Name\", axis = 1)\n\nprint(train[\"NameTitle\"].unique())\nprint(\"------------------------\" * 3)\nprint(test[\"NameTitle\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_titles = (train[\"NameTitle\"].value_counts() < 10)\ntrain[\"NameTitle\"] = train[\"NameTitle\"].apply(lambda x: \"Misc\" if min_titles.loc[x] == True else x)\nprint(train[\"NameTitle\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_titles = (test[\"NameTitle\"].value_counts() < 10)\ntest[\"NameTitle\"] = test[\"NameTitle\"].apply(lambda x: \"Misc\" if min_titles.loc[x] == True else x)\nprint(test[\"NameTitle\"].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Family Size","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"]\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3 Age Group","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"AgeGroup\"] = \"\"\ntrain.loc[train[\"Age\"] < 21, \"AgeGroup\"] = \"under 21\"\ntrain.loc[train[\"Age\"] >= 21, \"AgeGroup\"] = \"21-65\"\ntrain.loc[train[\"Age\"] > 65, \"AgeGroup\"] = \"65+\"\n\ntest[\"AgeGroup\"] = \"\"\ntest.loc[test[\"Age\"] < 21, \"AgeGroup\"] = \"under 21\"\ntest.loc[test[\"Age\"] >= 21, \"AgeGroup\"] = \"21-65\"\ntest.loc[test[\"Age\"] > 65, \"AgeGroup\"] = \"65+\"\n\ntrain = train.drop(\"Age\", axis = 1)\ntest = test.drop(\"Age\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.4 Fare Group","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"FareGroup\"] = \"\"\ntrain.loc[train[\"Fare\"] < 170, \"FareGroup\"] = \"0-170\"\ntrain.loc[train[\"Fare\"] >= 170, \"FareGroup\"] = \"170-340\"\ntrain.loc[train[\"Fare\"] > 340, \"FareGroup\"] = \"340+\"\n\ntest[\"FareGroup\"] = \"\"\ntest.loc[test[\"Fare\"] < 170, \"FareGroup\"] = \"0-170\"\ntest.loc[test[\"Fare\"] >= 170, \"FareGroup\"] = \"170-340\"\ntest.loc[test[\"Fare\"] > 340, \"FareGroup\"] = \"340+\"\n\ntrain = train.drop(\"Fare\", axis = 1)\ntest = test.drop(\"Fare\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)\ntest.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Data visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 5.1 Survived","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,2))\nsns.countplot(data = train, y = \"Survived\", palette = \"viridis\")\nplt.title(\"Survived\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2 Class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,3))\nsns.countplot(data = train, y = \"Pclass\", hue = \"Survived\", palette = \"viridis\")\nplt.title(\"Class\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.3 Gender","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,2))\nsns.countplot(data = train, y = \"Sex\", hue = \"Survived\", palette = \"viridis\")\nplt.title(\"Gender\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.4 Family Size","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,10))\nsns.countplot(data = train, y = \"FamilySize\", hue = \"Survived\", palette = \"viridis\")\nplt.title(\"Family Size\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.5 Embarked","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,3))\nsns.countplot(data = train, y = \"Embarked\", hue = \"Survived\", palette = \"viridis\")\nplt.title(\"Embarked\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.6 Name Title","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,5))\nsns.countplot(data = train, y = \"NameTitle\", hue = \"Survived\", palette = \"viridis\")\nplt.title(\"Name Title\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.7 Age Group","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,5))\nsns.countplot(data = train, y = \"AgeGroup\", hue = \"Survived\", palette = \"viridis\")\nplt.title(\"Age Group\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.8 Fare Group","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,5))\nsns.countplot(data = train, y = \"FareGroup\", hue = \"Survived\", palette = \"viridis\")\nplt.title(\"Fare Group\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.9 Correlation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\nplt.figure(figsize = (8,6))\nsns.heatmap(corr, cmap = \"coolwarm\", linewidth = 4, linecolor = \"white\")\nplt.title(\"Correlation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop([\"SibSp\", \"Parch\"], axis = 1)\ntest = test.drop([\"SibSp\", \"Parch\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.get_dummies(train, columns = [\"Sex\", \"Embarked\", \"NameTitle\", \"AgeGroup\", \"FareGroup\"])\ntest = pd.get_dummies(test, columns = [\"Sex\", \"Embarked\", \"NameTitle\", \"AgeGroup\", \"FareGroup\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\nplt.figure(figsize = (8,6))\nsns.heatmap(corr, cmap = \"coolwarm\", linewidth = 4, linecolor = \"white\")\nplt.title(\"Correlation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"upper = corr.where(np.triu(np.ones(corr.shape), k = 1).astype(np.bool))\nto_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\nprint(to_drop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = train.drop([\"PassengerId\", \"Survived\"], axis = 1)\nY = train[\"Survived\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_pca = scaler.fit_transform(X)\n\npca = PCA(n_components = 2)\nX_pca_transformed = pca.fit_transform(X_pca)\n\nplt.figure(figsize = (12,6))\n\nfor i in Y.unique():\n    X_pca_filtered = X_pca_transformed[Y == i, :]\n    plt.scatter(X_pca_filtered[:, 0], X_pca_filtered[:, 1], s = 20, label = i)\n    \nplt.legend()\nplt.title(\"PCA\", fontsize = 14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Machine Learning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression \nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, StackingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.1 Model Building Function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n    \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import style\nfrom matplotlib.pyplot import plot\n\nstyle.use(\"seaborn-whitegrid\")\n%matplotlib inline\n%config InlineBackend.figure_format = \"retina\"\n    \nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.pipeline import Pipeline\n\ndef model_builder(X, Y, pipeline, params, kfolds, classifier_name, data_split = False):\n    \n    \"\"\"\n    Trains the selected classifier using GridSearchCV with StratifiedKFold and the given pipeline and parameters. \n    Scores are calculated using cross_val_score with StratifiedKFold.\n    \n    Returns the results of cross_val_score, the best estimator of GridSearchCV and \n    X_train, X_test, Y_train, Y_test if data_split set to True.\n    \n    Parameters:\n    -----------\n    X : input variables\n    \n    Y : output variables\n    \n    pipeline : scikit learn Pipeline object\n    \n    params : dictionary of hyperparamters for GridSearchCV\n    \n    kfolds : number of folds for StratifiedKFold\n    \n    classifier_name : name of algorithm as a string\n    \n    data_split : if true: will train_test_split the data\n                 if false: will proceed with given data\n                 \n    Example:\n    --------\n    With data_split = False:\n    results, model = model_builder(X, \n                                   Y, \n                                   pipeline, \n                                   params, \n                                   10, \n                                   \"Logistic Regression\")\n    \n    With data_split = True:\n    X_train, X_test, Y_train, Y_test, results, model = model_builder(X, \n                                                                     Y, \n                                                                     pipeline, \n                                                                     params, \n                                                                     10, \n                                                                     \"Logistic Regression\", \n                                                                      data_split = True)\n    \"\"\"\n    \n    if data_split == True:\n        \n        X_train, X_test, Y_train, Y_test = train_test_split(X, \n                                                            Y, \n                                                            random_state = 0, \n                                                            test_size = 0.25)\n        cv = StratifiedKFold(n_splits = kfolds)\n\n        start = time.time()\n\n        grid = GridSearchCV(pipeline, params, cv = cv, verbose = 0, n_jobs = -1)\n        grid = grid.fit(X_train, Y_train)\n\n        print(\"Best Params:\")\n        print(\"\")\n        print(grid.best_params_)\n\n        grid = grid.best_estimator_\n\n        classifier_score = cross_val_score(grid, X_test, Y_test, cv = cv, n_jobs = -1)\n        Y_predicted = grid.predict(X_test)\n\n        stop = time.time()\n    \n        print(\"\")\n        print(\"#\" * 11 + \" ACCURACY \" + \"#\" * 11)\n        print(\"Cross-Validated-Score: \" + str(round(classifier_score.mean(), 6)))\n        print(\"#\" * 32)\n\n        print(\"\")\n        print(\"Training time: \" + str(round(stop - start, 2)) + \"s\")\n\n        train_size, train_score, test_score = learning_curve(grid, X_train, Y_train, cv = cv, n_jobs = -1)\n\n        print(\"\")\n        print(\"Learning Curve:\")\n\n        plt.figure(figsize = (12,6))\n        plt.plot(train_size, np.mean(train_score, axis = 1), label = \"Train scores\")\n        plt.plot(train_size, np.mean(test_score, axis = 1), label = \"Test scores\")\n        plt.title(classifier_name)\n        plt.legend()\n        plt.show()\n\n        return X_train, X_test, Y_train, Y_test, classifier_score, grid\n    \n    if data_split == False:\n        \n        cv = StratifiedKFold(n_splits = kfolds)\n\n        start = time.time()\n\n        grid = GridSearchCV(pipeline, params, cv = cv, verbose = 0, n_jobs = -1)\n        grid = grid.fit(X, Y)\n\n        print(\"Best Params:\")\n        print(\"\")\n        print(grid.best_params_)\n\n        grid = grid.best_estimator_\n\n        classifier_score = cross_val_score(grid, X, Y, cv = cv, n_jobs = -1)\n        Y_predicted = grid.predict(X)\n\n        stop = time.time()\n    \n        print(\"\")\n        print(\"#\" * 11 + \" ACCURACY \" + \"#\" * 11)\n        print(\"Cross-Validated-Score: \" + str(round(classifier_score.mean(), 6)))\n        print(\"#\" * 32)\n\n        print(\"\")\n        print(\"Training time: \" + str(round(stop - start, 2)) + \"s\")\n\n        train_size, train_score, test_score = learning_curve(grid, X, Y, cv = cv, n_jobs = -1)\n\n        print(\"\")\n        print(\"Learning Curve:\")\n\n        plt.figure(figsize = (12,6))\n        plt.plot(train_size, np.mean(train_score, axis = 1), label = \"Train scores\")\n        plt.plot(train_size, np.mean(test_score, axis = 1), label = \"Test scores\")\n        plt.title(classifier_name)\n        plt.legend()\n        plt.show()\n\n        return classifier_score, grid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.2 Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_log = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"pca\", PCA()),\n    (\"log\", LogisticRegression())])\n\nparams_log = {\n    \"pca__n_components\" : [4, 8, 16, 18],\n    \"log__C\" : [0.001, 0.01, 0.1, 1, 1.1, 10],\n    \"log__max_iter\" : [10000],\n    \"log__solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}\n\nlog_score, grid_log = model_builder(X, Y, pipe_log, params_log, 10, \"Logistic Regression\")\nY_predicted_log = grid_log.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.3 XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_xgb = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"pca\", PCA()),\n    (\"xgb\", XGBClassifier())])\n\nparams_xgb = {\n    \"pca__n_components\" : [2, 6, 10, 18],\n    \"xgb__n_estimators\" : [300, 500, 700],\n    \"xgb__learning_rate\" : [0.005, 0.1],\n    \"xgb__max_depth\" : [5, 7],\n    \"xgb__max_features\" : [3, 5], \n    \"xgb__gamma\" : [0.5, 0.6, 0.7]}\n\nxgb_score, grid_xgb = model_builder(X, Y, pipe_xgb, params_xgb, 10, \"XGBoost\")\nY_predicted_xgb = grid_xgb.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.4 Gradient Boosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_boost = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"pca\", PCA()),\n    (\"boost\", GradientBoostingClassifier())])\n\nparams_boost = {\n    \"pca__n_components\" : [2, 6, 10, 18],\n    \"boost__n_estimators\" : [300, 500, 700],\n    \"boost__learning_rate\" : [0.005, 0.1],\n    \"boost__max_depth\" : [3, 5],\n    \"boost__max_features\" : [3, 5]}\n\nboost_score, grid_boost = model_builder(X, Y, pipe_boost, params_boost, 10, \"Gradient Boosting\")\nY_predicted_boost = grid_boost.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.5 Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_rf = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"pca\", PCA()),\n    (\"rf\", RandomForestClassifier(criterion = \"gini\", \n                                  max_features = \"auto\"))])\n\nparams_rf = {\n    \"pca__n_components\" : [2, 6, 10, 18],\n    \"rf__n_estimators\" : [200, 250, 300, 400],\n    \"rf__max_depth\" : [1, 3, 5, 7, 9]}\n\nrf_score, grid_rf = model_builder(X, Y, pipe_rf, params_rf, 10, \"Random Forest\")\nY_predicted_rf = grid_rf.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.6 SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_svm = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"pca\", PCA()),\n    (\"svm\", SVC(probability = True, kernel = \"rbf\"))])\n\nparams_svm = {\n    \"pca__n_components\" : [2, 6, 10, 18],\n    \"svm__C\" : [0.01, 0.1, 1, 1.1, 2],\n    \"svm__gamma\" : [0.01, 0.1, 1]}\n\nsvm_score, grid_svm = model_builder(X, Y, pipe_svm, params_svm, 10, \"Support Vector Machines\")\nY_predicted_svm = grid_svm.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.7 Bagging Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_bag = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"pca\", PCA()),\n    (\"bag\", BaggingClassifier())])\n\nparams_bag = {\n    \"pca__n_components\" : [2, 6, 10, 18],\n    \"bag__n_estimators\" : [30, 50, 70, 100],\n    \"bag__max_features\" : [3, 5, 7, 9],\n    \"bag__max_samples\" : [3, 5, 7, 9]}\n\nbag_score, grid_bag = model_builder(X, Y, pipe_bag, params_bag, 10, \"Bagging Classifier\")\nY_predicted_bag = grid_bag.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.8 Extra Trees Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_xt = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"pca\", PCA()),\n    (\"xt\", ExtraTreesClassifier(criterion = \"gini\", \n                                max_features = \"auto\"))])\n\nparams_xt = {\n    \"pca__n_components\" : [2, 6, 10, 18],\n    \"xt__n_estimators\" : [300, 500, 700],\n    \"xt__max_depth\" : [5, 7, 9]}\n\nxt_score, grid_xt = model_builder(X, Y, pipe_xt, params_xt, 10, \"Extra Trees\")\nY_predicted_xt = grid_xt.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.9 K-Nearest-Neighbor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_knn = Pipeline([\n    (\"scaler\", StandardScaler()),\n    #(\"pca\", PCA()),\n    (\"knn\", KNeighborsClassifier(algorithm = \"auto\"))])\n\nparams_knn = {\n    #\"pca__n_components\" : [2, 6, 10, 18],\n    \"knn__n_neighbors\" : [2, 3, 5, 7, 9],\n    \"knn__leaf_size\" : [10, 20, 30, 40]}\n\nknn_score, grid_knn = model_builder(X, Y, pipe_knn, params_knn, 10, \"KNN\")\nY_predicted_knn = grid_knn.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.10 CatBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_cat = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"cat\", CatBoostClassifier(verbose = 0))])\n\nparams_cat = {\n    \"cat__depth\" : [2, 3, 4, 5],\n    \"cat__learning_rate\" : [0.001, 0.01, 0.1, 1, 1.1],\n    \"cat__n_estimators\" : [300, 400, 500, 600]}\n\ncat_score, grid_cat = model_builder(X, Y, pipe_cat, params_cat, 10, \"CatBoost\")\nY_predicted_cat = grid_cat.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.11 LightGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_gbm = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"lgb\", lgb.LGBMClassifier())])\n\nparams_gbm = {\n        \"lgb__num_leaves\": [5, 7, 40, 60, 100],\n        \"lgb__n_estimators\": [300, 700, 1000],\n        \"lgb__learning_rate\" : [0.0001, 0.001, 0.01, 0.1, 1]}\n\ngbm_score, grid_gbm = model_builder(X, Y, pipe_gbm, params_gbm, 10, \"LightGBM\")\nY_predicted_gbm = grid_gbm.predict_proba(X)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7.12 Model Comparison","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_results = [xgb_score, boost_score, log_score, rf_score, \n               svm_score, bag_score, xt_score, knn_score, cat_score, gbm_score]\n\nresult_names = [\"XGBoost\", \n                \"Gradient Boosting\", \n                \"Logistic Regression\", \n                \"Random Forest\", \n                \"SVM\", \n                \"Bagging Classifier\", \n                \"Extra Trees Classifier\", \n                \"KNN\", \n                \"CatBoost\", \n                \"LightGBM\"]\n\nfig = plt.figure(figsize = (14,7))\nfig.suptitle(\"Algorithm Comparison\")\nax = fig.add_subplot(111)\nplt.boxplot(all_results)\nax.set_xticklabels(result_names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Neural Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!pip install keras-tuner","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom kerastuner.tuners import RandomSearch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, \n                                                    Y, \n                                                    random_state = 0, \n                                                    test_size = 0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n\ndef tune_model(hp):\n\n    nn = Sequential()\n\n    nn.add(Dense(hp.Choice(\"units_1\", [512, 1024, 2048]), activation = \"relu\", input_shape = (18,)))\n    nn.add(Dropout(hp.Choice(\"dropout_1\", [0.0, 0.15, 0.2, 0.25])))\n    nn.add(Dense(hp.Choice(\"units_2\", [128, 256, 512]), activation = \"relu\"))\n    nn.add(Dropout(hp.Choice(\"dropout_2\", [0.0, 0.15, 0.2, 0.25])))\n    nn.add(Dense(hp.Choice(\"units_3\", [32, 64, 128]), activation = \"relu\"))\n    nn.add(Dropout(hp.Choice(\"dropout_3\", [0.0, 0.15, 0.2, 0.25])))\n    nn.add(Dense(hp.Choice(\"units_4\", [8, 16, 32]), activation = \"relu\"))\n    nn.add(Dropout(hp.Choice(\"dropout_4\", [0.0, 0.15, 0.2, 0.25])))\n    nn.add(Dense(1, activation = \"relu\"))\n    \n    lr = hp.Choice(\"learning_rate\", [0.0001, 0.001, 0.01, 0.1])\n    mm = hp.Choice(\"momentum\", [0.0, 0.2, 0.4, 0.6, 0.8])\n    \n    nn.compile(optimizer = keras.optimizers.RMSprop(learning_rate = lr, momentum = mm), \n               loss = \"binary_crossentropy\", \n               metrics = [\"accuracy\"])\n    \n    return nn\n\ntuner = RandomSearch(tune_model, \n                     objective = \"val_accuracy\", \n                     max_trials = 3)\n\ntuner.search(x = X_train, \n             y = Y_train, \n             verbose = 3, \n             epochs = 400, \n             batch_size = 25, \n             validation_data = (X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best Params: \" + str(tuner.oracle.get_best_trials(num_trials = 1)[0].hyperparameters.values))\n\nnn = tuner.get_best_models()[0]\n\nprint(\"\")\nprint(\"Test score: \" + str(nn.evaluate(X_test, Y_test)))\nprint(\"\")\nprint(\"Train score: \" + str(nn.evaluate(X_train, Y_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_predicted_nn = nn.predict(test.drop([\"PassengerId\"], axis = 1))\nY_predicted_nn = (Y_predicted_nn.ravel() > 0.5).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. ROC-Curve and AUC-Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_fpr, log_tpr, log_treshholds = roc_curve(Y, Y_predicted_log)\nboost_fpr, boost_tpr, boost_treshholds = roc_curve(Y, Y_predicted_boost) \nsvm_fpr, svm_tpr, svm_treshholds = roc_curve(Y, Y_predicted_svm)\nrf_fpr, rf_tpr, rf_treshholds = roc_curve(Y, Y_predicted_rf)\nxgb_fpr, xgb_tpr, xgb_treshholds = roc_curve(Y, Y_predicted_xgb)\nbag_fpr, bag_tpr, bag_treshholds = roc_curve(Y, Y_predicted_bag)\nxt_fpr, xt_tpr, xt_treshholds = roc_curve(Y, Y_predicted_xt)\nknn_fpr, knn_tpr, knn_treshholds = roc_curve(Y, Y_predicted_knn)\n\nauc_score_log = roc_auc_score(Y, Y_predicted_log)\nauc_score_boost = roc_auc_score(Y, Y_predicted_boost)\nauc_score_svm = roc_auc_score(Y, Y_predicted_svm)\nauc_score_rf = roc_auc_score(Y, Y_predicted_rf)\nauc_score_xgb = roc_auc_score(Y, Y_predicted_xgb)\nauc_score_bag = roc_auc_score(Y, Y_predicted_bag)\nauc_score_xt = roc_auc_score(Y, Y_predicted_xt)\nauc_score_knn = roc_auc_score(Y, Y_predicted_knn)\n\nplt.figure(figsize = (14,7))\nplt.plot([0,1], [0,1])\nplt.plot(log_fpr, log_tpr, label = \"Logistic Regression (AUC-Score: \" + str(round(auc_score_log, 2)) + \")\")\nplt.plot(boost_fpr, boost_tpr, label = \"Gradient Boosting (AUC-Score: \" + str(round(auc_score_boost, 2)) + \")\")\nplt.plot(svm_fpr, svm_tpr, label = \"SVM (AUC-Score: \" + str(round(auc_score_svm, 2)) + \")\")\nplt.plot(rf_fpr, rf_tpr, label = \"Random Forest (AUC-Score: \" + str(round(auc_score_rf, 2)) + \")\")\nplt.plot(xgb_fpr, xgb_tpr, label = \"XGBoost (AUC-Score: \" + str(round(auc_score_xgb, 2)) + \")\")\nplt.plot(bag_fpr, bag_tpr, label = \"Bagging Classifier (AUC-Score: \" + str(round(auc_score_bag, 2)) + \")\")\nplt.plot(xt_fpr, xt_tpr, label = \"Extra Trees Clasifier (AUC-Score: \" + str(round(auc_score_xt, 2)) + \")\")\nplt.plot(knn_fpr, knn_tpr, label = \"K-Nearest-Neighbor (AUC-Score: \" + str(round(auc_score_knn, 2)) + \")\")\nplt.title(\"ROC-Curve\")\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Model Stacking","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stack = StackingClassifier(estimators = [(\"XGBoost\", grid_xgb), \n                                         (\"GradientBoosting\", grid_boost),\n                                         (\"RandomForest\", grid_rf), \n                                         (\"Logistic Regression\", grid_log), \n                                         (\"SVM\", grid_svm),  \n                                         (\"Extra Trees Classifier\", grid_xt), \n                                         (\"KNeighborsClassifier\", grid_knn), \n                                         (\"CatBoost\", grid_cat), \n                                         (\"LightGBM\", grid_gbm)], n_jobs = -1)\n\n\ncv = StratifiedKFold(n_splits = 5)\n\nstack = stack.fit(X, Y)\nstack_score = cross_val_score(stack, X, Y, cv = cv, n_jobs = -1)\n\nprint(\"#\" * 11 + \" FINAL ACCURACY \" + \"#\" * 11)\nprint(\"Cross-Validated-Score: \" + str(round(stack_score.mean(), 6)))\nprint(\"#\" * 38)\n\nY_predicted_stack = stack.predict(test.drop([\"PassengerId\"], axis = 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 10.1 Stacked Model Learning Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size, train_score, test_score = learning_curve(stack, X, Y, cv = cv, n_jobs = -1)\n\nplt.figure(figsize = (12,6))\nplt.plot(train_size, np.mean(train_score, axis = 1), label = \"Train\")\nplt.plot(train_size, np.mean(test_score, axis = 1), label = \"Test\")\nplt.title(\"Stacked Model\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11. Submission","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 11.1 Classifiers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"PassengerId\" : test.PassengerId, \n                           \"Survived\" : Y_predicted_stack})\n\nsubmission.to_csv(\"submission_clf.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 11.2 Neural Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_nn = pd.DataFrame({\"PassengerId\" : test.PassengerId, \n                           \"Survived\" : Y_predicted_nn})\n\nsubmission_nn.to_csv(\"submission_nn.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_nn.head(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}