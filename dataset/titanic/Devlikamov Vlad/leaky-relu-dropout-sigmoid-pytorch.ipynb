{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"***Titanic prediction with LogisticRegression with leaky_relu and dropout on Pytorch***","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-18T14:54:22.408808Z","iopub.execute_input":"2021-12-18T14:54:22.409832Z","iopub.status.idle":"2021-12-18T14:54:22.427428Z","shell.execute_reply.started":"2021-12-18T14:54:22.40968Z","shell.execute_reply":"2021-12-18T14:54:22.426339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:22.513759Z","iopub.execute_input":"2021-12-18T14:54:22.514553Z","iopub.status.idle":"2021-12-18T14:54:22.520867Z","shell.execute_reply.started":"2021-12-18T14:54:22.51451Z","shell.execute_reply":"2021-12-18T14:54:22.52002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:22.522076Z","iopub.execute_input":"2021-12-18T14:54:22.522477Z","iopub.status.idle":"2021-12-18T14:54:22.681708Z","shell.execute_reply.started":"2021-12-18T14:54:22.522448Z","shell.execute_reply":"2021-12-18T14:54:22.680761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:22.683438Z","iopub.execute_input":"2021-12-18T14:54:22.683868Z","iopub.status.idle":"2021-12-18T14:54:22.720128Z","shell.execute_reply.started":"2021-12-18T14:54:22.683837Z","shell.execute_reply":"2021-12-18T14:54:22.718413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:22.722499Z","iopub.execute_input":"2021-12-18T14:54:22.722962Z","iopub.status.idle":"2021-12-18T14:54:22.75595Z","shell.execute_reply.started":"2021-12-18T14:54:22.722892Z","shell.execute_reply":"2021-12-18T14:54:22.754924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = data.drop(['Survived'], axis = 1), data['Survived']","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:22.757411Z","iopub.execute_input":"2021-12-18T14:54:22.757743Z","iopub.status.idle":"2021-12-18T14:54:22.764631Z","shell.execute_reply.started":"2021-12-18T14:54:22.75771Z","shell.execute_reply":"2021-12-18T14:54:22.763658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols = [x for x in X.columns if data[x].dtype in ['int64', 'float64']]\ncat_cols = [x for x in X.columns if data[x].dtype == 'object']","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:22.766232Z","iopub.execute_input":"2021-12-18T14:54:22.766502Z","iopub.status.idle":"2021-12-18T14:54:22.776734Z","shell.execute_reply.started":"2021-12-18T14:54:22.766476Z","shell.execute_reply":"2021-12-18T14:54:22.77587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:22.778141Z","iopub.execute_input":"2021-12-18T14:54:22.778405Z","iopub.status.idle":"2021-12-18T14:54:23.898368Z","shell.execute_reply.started":"2021-12-18T14:54:22.778379Z","shell.execute_reply":"2021-12-18T14:54:23.897358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Предобработка данных**","metadata":{}},{"cell_type":"code","source":"num_transform = Pipeline(steps=[\n                ('impute', SimpleImputer(strategy='constant')),\n                ('scale', MaxAbsScaler())\n])\n\ncat_transform = Pipeline(steps=[\n                ('impute', SimpleImputer(strategy='most_frequent')),\n                ('onehot', OneHotEncoder(handle_unknown='ignore')),\n                ('scale', MaxAbsScaler())\n])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:23.899866Z","iopub.execute_input":"2021-12-18T14:54:23.90018Z","iopub.status.idle":"2021-12-18T14:54:23.906739Z","shell.execute_reply.started":"2021-12-18T14:54:23.90015Z","shell.execute_reply":"2021-12-18T14:54:23.905524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess = ColumnTransformer(transformers=[\n                               ('cat', cat_transform, cat_cols),\n                               ('num', num_transform, num_cols)\n])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:23.909731Z","iopub.execute_input":"2021-12-18T14:54:23.910017Z","iopub.status.idle":"2021-12-18T14:54:23.919389Z","shell.execute_reply.started":"2021-12-18T14:54:23.909991Z","shell.execute_reply":"2021-12-18T14:54:23.918652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = preprocess.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:23.92078Z","iopub.execute_input":"2021-12-18T14:54:23.92124Z","iopub.status.idle":"2021-12-18T14:54:23.940936Z","shell.execute_reply.started":"2021-12-18T14:54:23.921196Z","shell.execute_reply":"2021-12-18T14:54:23.940087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:23.942069Z","iopub.execute_input":"2021-12-18T14:54:23.942728Z","iopub.status.idle":"2021-12-18T14:54:23.947996Z","shell.execute_reply.started":"2021-12-18T14:54:23.942671Z","shell.execute_reply":"2021-12-18T14:54:23.946705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:23.94975Z","iopub.execute_input":"2021-12-18T14:54:23.950131Z","iopub.status.idle":"2021-12-18T14:54:23.961515Z","shell.execute_reply.started":"2021-12-18T14:54:23.950093Z","shell.execute_reply":"2021-12-18T14:54:23.960641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.toarray()\nX_test = X_test.toarray()\ny_train = y_train.values\ny_test = y_test.values","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:55:44.856798Z","iopub.execute_input":"2021-12-18T14:55:44.857218Z","iopub.status.idle":"2021-12-18T14:55:44.862416Z","shell.execute_reply.started":"2021-12-18T14:55:44.857187Z","shell.execute_reply":"2021-12-18T14:55:44.861199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Построение модели**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.utils import shuffle\nfrom torch.autograd import Variable\n\nclass LinearRegression(nn.Module):\n    def __init__(self,input_size,output_size):\n        super(LinearRegression,self).__init__()\n        self.f1 = nn.Linear(input_dim, 2000)\n        self.f2 = nn.Linear(2000, output_dim)\n\n\n    def forward(self,x):\n        x = self.f1(x)\n        x = F.leaky_relu(x)\n        x = F.dropout(x, p = 0.3)\n        x = self.f2(x)\n        return  F.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:55:47.53982Z","iopub.execute_input":"2021-12-18T14:55:47.540311Z","iopub.status.idle":"2021-12-18T14:55:48.702784Z","shell.execute_reply.started":"2021-12-18T14:55:47.540279Z","shell.execute_reply":"2021-12-18T14:55:48.701718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100\nbatch_no = len(X_train) // batch_size","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:56:01.740548Z","iopub.execute_input":"2021-12-18T14:56:01.740921Z","iopub.status.idle":"2021-12-18T14:56:01.745579Z","shell.execute_reply.started":"2021-12-18T14:56:01.740874Z","shell.execute_reply":"2021-12-18T14:56:01.744443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:55:51.771842Z","iopub.execute_input":"2021-12-18T14:55:51.772221Z","iopub.status.idle":"2021-12-18T14:55:51.777583Z","shell.execute_reply.started":"2021-12-18T14:55:51.77219Z","shell.execute_reply":"2021-12-18T14:55:51.776981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_batches(X, y, batch_size):\n    assert len(X) == len(y)\n    np.random.seed(42)\n    X = np.array(X)\n    y = np.array(y)\n    perm = np.random.permutation(len(X))\n\n    for i in range(len(X)//batch_size):\n        if i + batch_size >= len(X):\n            continue\n        ind = perm[i*batch_size : (i+1)*batch_size]\n        yield (X[ind], y[ind])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:55:53.37257Z","iopub.execute_input":"2021-12-18T14:55:53.373153Z","iopub.status.idle":"2021-12-18T14:55:53.380776Z","shell.execute_reply.started":"2021-12-18T14:55:53.373116Z","shell.execute_reply":"2021-12-18T14:55:53.379771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Код обучения**","metadata":{}},{"cell_type":"code","source":"input_dim = 1730\noutput_dim = 2\nlearning_rate = 1\nmodel = LinearRegression(input_dim,output_dim)\nerror = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.5)\n\nloss_list = []\nacc_list = []\niteration_number = 300\n\nfor iteration in range(iteration_number):\n    batch_loss = 0\n    batch_accur = 0\n    temp = 0\n\n    for (x, y) in generate_batches(X_train, y_train, batch_size):\n        inputs = Variable(torch.from_numpy(x)).float()\n        labels = Variable(torch.from_numpy(y))\n            \n        optimizer.zero_grad() \n\n        results = model(inputs)\n        \n        loss = error(results, labels)\n\n        batch_loss += loss.data\n        \n        loss.backward()\n        \n        optimizer.step()\n\n        with torch.no_grad():\n            _, pred = torch.max(results, 1)\n            batch_accur += torch.sum(pred == labels)\n            temp += len(pred)\n    \n    loss_list.append(batch_loss/batch_no)\n    acc_list.append(batch_accur/temp)\n    \n    if(iteration % 50 == 0):\n        print('epoch {}: loss {}, accuracy {}'.format(iteration, batch_loss/batch_no, batch_accur/temp))\n\nplt.plot(range(iteration_number),loss_list)\nplt.xlabel(\"Number of Iterations\")\nplt.ylabel(\"Loss\")\nplt.show()\nplt.plot(range(iteration_number),acc_list)\nplt.xlabel(\"Number of Iterations\")\nplt.ylabel(\"Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:56:08.021422Z","iopub.execute_input":"2021-12-18T14:56:08.02204Z","iopub.status.idle":"2021-12-18T14:56:08.162539Z","shell.execute_reply.started":"2021-12-18T14:56:08.021993Z","shell.execute_reply":"2021-12-18T14:56:08.160333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_var = Variable(torch.FloatTensor(X_test), requires_grad=True) \nwith torch.no_grad():\n    test_result = model(X_test_var)\nvalues, labels = torch.max(test_result, 1)\nsurvived = labels.data.numpy()\nprint((survived == y_test).sum()/len(survived))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:24.090458Z","iopub.status.idle":"2021-12-18T14:54:24.091087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Предсказания**","metadata":{}},{"cell_type":"code","source":"X_test_origin = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\nX_test_origin = preprocess.transform(X_test_origin)\nX_test_origin = X_test_origin.toarray()\nX_test_var = Variable(torch.FloatTensor(X_test_origin), requires_grad=True) \nwith torch.no_grad():\n    test_result = model(X_test_var)\nvalues, labels = torch.max(test_result, 1)\nsurvived = labels.data.numpy()\nX_test_1 = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:24.092001Z","iopub.status.idle":"2021-12-18T14:54:24.092596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\n\nsubmission = [['PassengerId', 'Survived']]\nfor i in range(len(survived)):\n    submission.append([X_test_1.PassengerId.loc[i], survived[i]])","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:24.093514Z","iopub.status.idle":"2021-12-18T14:54:24.094113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('submission.csv', 'w') as submissionFile:\n    writer = csv.writer(submissionFile)\n    writer.writerows(submission)\n    \nprint('Writing Complete!')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T14:54:24.095026Z","iopub.status.idle":"2021-12-18T14:54:24.095602Z"},"trusted":true},"execution_count":null,"outputs":[]}]}