{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Titanic Tutorial for Beginner**\n\n<h4>Thank you for visiting my notebook :)</h4>\n<h4>This notebook explains easily how to start a competition for beginner!!</h4>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 style='color:white; background:#707C4F; border:0' role=\"tab\" aria-controls=\"home\"><center>Contents</center></h2>\n    \n* **Import Library**\n    \n* **Load Data**\n    \n* **EDA & Preprocessing**\n    \n* **Modeling**\n    \n* **Evaluation**\n    \n* **Submission**","metadata":{}},{"cell_type":"markdown","source":"# **Import Library**\n\n\n<h4>In the kaggle notebook environment, you can import most of the libraries you want to use</h4>\n\n* pandas → Python Data Analysis Library\n\n* numpy → Linear algebra library that performs numerical operations such as vectors and matrices in Python\n\n* matplotlib & seaborn → Visualization Library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:11.742121Z","iopub.execute_input":"2021-09-12T21:03:11.742471Z","iopub.status.idle":"2021-09-12T21:03:11.748672Z","shell.execute_reply.started":"2021-09-12T21:03:11.742439Z","shell.execute_reply":"2021-09-12T21:03:11.747974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# You don't have to run this code!\n# It's just for clean visualization :)\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\npalette = sns.color_palette(\"bright\")\nsns.set_palette(\"Paired\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-12T21:03:11.754377Z","iopub.execute_input":"2021-09-12T21:03:11.75533Z","iopub.status.idle":"2021-09-12T21:03:11.763028Z","shell.execute_reply.started":"2021-09-12T21:03:11.75528Z","shell.execute_reply":"2021-09-12T21:03:11.761842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load Data**\n\n<h4>Using 'read_csv()' function in Pandas, you can read .csv file easily</h4>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\nsub = pd.read_csv('../input/titanic/gender_submission.csv')\n\nall_data = pd.concat([train, test]).reset_index(drop = True)\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:11.779898Z","iopub.execute_input":"2021-09-12T21:03:11.780199Z","iopub.status.idle":"2021-09-12T21:03:11.834607Z","shell.execute_reply.started":"2021-09-12T21:03:11.78017Z","shell.execute_reply":"2021-09-12T21:03:11.833554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*****","metadata":{}},{"cell_type":"markdown","source":"# **EDA & Preprocessing**\n\n<h4>EDA is an abbreviation of Exploratory Data Analysis !</h4>\n\n<h4>You can use 'Matplotlib & Seaborn' for Basic EDA :)</h4>\n\n<h4>With visualization, we can see the distribution of train, test data's features</h4>\n\n#### **Based on the information obtained through the above work, we can preprocess the data**","metadata":{}},{"cell_type":"markdown","source":"* ### **Countplot**\n\n#### Since this competition is a binary classification competition, you can check the balance of the target column using **countplot.**\n\n<h4>With below graph, we can see that Target(Survived) column is unbalanced.</h4>\n\n<h4>It's too bad that there are more people who haven't survived.</h4>","metadata":{}},{"cell_type":"code","source":"sns.countplot(train['Survived']);","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:11.83646Z","iopub.execute_input":"2021-09-12T21:03:11.836706Z","iopub.status.idle":"2021-09-12T21:03:12.020671Z","shell.execute_reply.started":"2021-09-12T21:03:11.836677Z","shell.execute_reply":"2021-09-12T21:03:12.019883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **We can also check the distribution of categorical columns!**\n\n#### **You can use 'nunique()' function to check which column is categorical**","metadata":{}},{"cell_type":"code","source":"all_data.nunique().sort_values()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:12.02185Z","iopub.execute_input":"2021-09-12T21:03:12.022084Z","iopub.status.idle":"2021-09-12T21:03:12.033671Z","shell.execute_reply.started":"2021-09-12T21:03:12.022057Z","shell.execute_reply":"2021-09-12T21:03:12.032854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>With above output, we can check top 4 columns are categorical.</h4>\n\n#### SibSp & Parch are not categorical columns!! You can visit [here](https://www.kaggle.com/c/titanic/data) and see the detail explanations about columns","metadata":{}},{"cell_type":"markdown","source":"#### So! Let's check about the distribution of those 4 columns using **Countplot**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 4, figsize = (12, 4)) # Making Subplots\n\nsns.countplot(train['Survived'], ax=ax[0]);\nsns.countplot(all_data['Sex'], ax=ax[1]);\nsns.countplot(all_data['Pclass'], ax=ax[2]);\nsns.countplot(all_data['Embarked'], ax=ax[3]);\n\nplt.tight_layout() # you can use this function for clear visualization\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:12.035739Z","iopub.execute_input":"2021-09-12T21:03:12.036022Z","iopub.status.idle":"2021-09-12T21:03:12.560066Z","shell.execute_reply.started":"2021-09-12T21:03:12.035993Z","shell.execute_reply":"2021-09-12T21:03:12.559296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **We checked the distribution of categorical columns!**\n\n#### **Now, aren't you curious about gender and survival rate?**\n\n#### Using **groupby()** function, the relationship between columns can be grasped!","metadata":{}},{"cell_type":"code","source":"sex_survived_rate = all_data.groupby('Sex')['Survived'].mean()\nsex_survived_rate","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:12.561155Z","iopub.execute_input":"2021-09-12T21:03:12.56149Z","iopub.status.idle":"2021-09-12T21:03:12.569446Z","shell.execute_reply.started":"2021-09-12T21:03:12.561461Z","shell.execute_reply":"2021-09-12T21:03:12.568602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### From the graph below, we can see that despite the large number of male passengers,\n#### the survival rate of male passengers is significantly lower than that of female passengers.\n\n#### Maybe thanks to captain's leadership","metadata":{}},{"cell_type":"code","source":"sex_survived_rate.plot(kind = 'bar');","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:12.570638Z","iopub.execute_input":"2021-09-12T21:03:12.570949Z","iopub.status.idle":"2021-09-12T21:03:12.777211Z","shell.execute_reply.started":"2021-09-12T21:03:12.570913Z","shell.execute_reply":"2021-09-12T21:03:12.776209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### You can practice with Pclass, Embarked columns!!\n#### Do it youself :)\n\n*****","metadata":{}},{"cell_type":"markdown","source":"* ### **distplot**\n\n#### With distplot, you can check the distribution of numeric columns!\n\n#### Below graphs : distribution of Age, Fare","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n\nsns.distplot(all_data['Age'], ax=ax[0], color='y');\nsns.distplot(all_data['Fare'], ax=ax[1], color='violet');\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:12.779115Z","iopub.execute_input":"2021-09-12T21:03:12.779449Z","iopub.status.idle":"2021-09-12T21:03:13.62436Z","shell.execute_reply.started":"2021-09-12T21:03:12.779406Z","shell.execute_reply":"2021-09-12T21:03:13.623183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Fare column looks like be skewed!!\n\n#### Maybe need to use scaler! (ex. StandardScaler, RobustScaler, LogScaling)\n\n#### If we use scaler, our model will be less affected by outliers. Check an image below :)","metadata":{}},{"cell_type":"markdown","source":"#### You can use scalers using function 'fit_transform()'\n\n#### **!! Need to transform your target value using reshape(-1, 1) !!**","metadata":{}},{"cell_type":"code","source":"ss = StandardScaler()\nrb = RobustScaler()\nmm = MinMaxScaler()\n\nfare_standard = ss.fit_transform(all_data['Fare'].values.reshape(-1, 1))\nfare_robust = rb.fit_transform(all_data['Fare'].values.reshape(-1, 1))\nfare_minmax = mm.fit_transform(all_data['Fare'].values.reshape(-1, 1))\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 5))\n\nsns.distplot(fare_standard, color='violet', ax = ax[0]).set_title('StandardScaler');\nsns.distplot(fare_robust, color='y', ax = ax[1]).set_title('RobustScaler');\nsns.distplot(fare_minmax, color='r', ax = ax[2]).set_title('MinMaxScaler');\nsns.distplot(np.log1p(train['Fare']), color='b', ax = ax[3]).set_title('LogScaling');\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:13.625891Z","iopub.execute_input":"2021-09-12T21:03:13.626227Z","iopub.status.idle":"2021-09-12T21:03:14.977949Z","shell.execute_reply.started":"2021-09-12T21:03:13.626182Z","shell.execute_reply":"2021-09-12T21:03:14.977052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### You can choose the scaler that has the highest performance of the model while using all four scalers above\n\n#### **Log Scaling** seems to be attractive → Because of **skewness**\n\n#### In this notebook, we will use **Log Scaling** :)\n\n*****","metadata":{}},{"cell_type":"markdown","source":"*  ## **Now, we need to check Missing Values**\n\n### You can use 'isna().sum()' function to see how many missing values are there","metadata":{}},{"cell_type":"code","source":"all_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:14.979184Z","iopub.execute_input":"2021-09-12T21:03:14.979432Z","iopub.status.idle":"2021-09-12T21:03:14.990479Z","shell.execute_reply.started":"2021-09-12T21:03:14.979405Z","shell.execute_reply":"2021-09-12T21:03:14.989215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can make good features using missing values!\n\n* **The number of missing values**\n* **One-Hot-Encoding - Missing values Y/N**","metadata":{}},{"cell_type":"markdown","source":"#### Let's make a feature of **the number of missing values**\n\n* **Excepting PassengerId, Survived columns**","metadata":{}},{"cell_type":"code","source":"all_data['missing_counts'] = all_data[all_data.columns[2:]].isna().sum(axis = 1)\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:14.993467Z","iopub.execute_input":"2021-09-12T21:03:14.993727Z","iopub.status.idle":"2021-09-12T21:03:15.028882Z","shell.execute_reply.started":"2021-09-12T21:03:14.993697Z","shell.execute_reply":"2021-09-12T21:03:15.027892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Next, making a feature about the presence or absence of missing values","metadata":{}},{"cell_type":"code","source":"miss_one_hot = all_data[['Age', 'Cabin', 'Fare', 'Embarked']].isna()\nmiss_one_hot.columns = ['Age_miss', 'Cabin_miss', 'Fare_miss', 'Embarked_miss']\nmiss_one_hot","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:15.030183Z","iopub.execute_input":"2021-09-12T21:03:15.03068Z","iopub.status.idle":"2021-09-12T21:03:15.050799Z","shell.execute_reply.started":"2021-09-12T21:03:15.030642Z","shell.execute_reply":"2021-09-12T21:03:15.050149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### You must concat those dataframe using axis = 1 !!","metadata":{}},{"cell_type":"code","source":"all_data = pd.concat([all_data, miss_one_hot], axis = 1)\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:15.052704Z","iopub.execute_input":"2021-09-12T21:03:15.05318Z","iopub.status.idle":"2021-09-12T21:03:15.084079Z","shell.execute_reply.started":"2021-09-12T21:03:15.053146Z","shell.execute_reply":"2021-09-12T21:03:15.083446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **EDA is a really important technique in data science**\n\n#### **Many features can be extracted, which plays an important role in improving model performance**","metadata":{}},{"cell_type":"markdown","source":"#### **Then, how can we handle those missing values?**\n\n#### Answer is..\n\n* **Fill in the numeric column with -1 and the categorical column with just 'nan'**\n\n* **Fill in the numeric column with each column's mean value**\n\n* **Predict the missing values using ML models** → **KNN Imputer**","metadata":{}},{"cell_type":"markdown","source":"#### In this notebook, I'll use knn imputer for numeric columns and fill 'nan' for categorical column\n\n#### For KnnImputer, I think it would be helpful to use the LableEncoder","metadata":{}},{"cell_type":"code","source":"all_data['Cabin'] = all_data['Cabin'].fillna('nan')\nall_data['Embarked'] = all_data['Embarked'].fillna('nan')\n\nle = LabelEncoder()\n\nall_data['Cabin'] = le.fit_transform(all_data['Cabin'])\nall_data['Sex'] = le.fit_transform(all_data['Sex'])\nall_data['Embarked'] = le.fit_transform(all_data['Embarked'])\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:15.085374Z","iopub.execute_input":"2021-09-12T21:03:15.085807Z","iopub.status.idle":"2021-09-12T21:03:15.120529Z","shell.execute_reply.started":"2021-09-12T21:03:15.085744Z","shell.execute_reply":"2021-09-12T21:03:15.11949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Need to except Name, PassengerId, Survived, Ticket columns for Imputing","metadata":{}},{"cell_type":"code","source":"columns = list(all_data.columns)\ncolumns.remove('PassengerId')\ncolumns.remove('Survived')\ncolumns.remove('Ticket')\ncolumns.remove('Name')\ncolumns","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:15.122136Z","iopub.execute_input":"2021-09-12T21:03:15.122424Z","iopub.status.idle":"2021-09-12T21:03:15.138872Z","shell.execute_reply.started":"2021-09-12T21:03:15.122395Z","shell.execute_reply":"2021-09-12T21:03:15.137858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Knn Imputer**","metadata":{}},{"cell_type":"code","source":"knn = KNNImputer()\n\nimputed_data = all_data[columns]\nimputed_data = knn.fit_transform(imputed_data)\nimputed_data","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:15.140587Z","iopub.execute_input":"2021-09-12T21:03:15.141137Z","iopub.status.idle":"2021-09-12T21:03:15.201975Z","shell.execute_reply.started":"2021-09-12T21:03:15.141102Z","shell.execute_reply":"2021-09-12T21:03:15.200898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### You must use iloc or loc for edit dataframe!","metadata":{}},{"cell_type":"code","source":"all_data.iloc[:, 5] = imputed_data[:, 2]\nall_data.iloc[:, 9] = imputed_data[:, 5]\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:15.203867Z","iopub.execute_input":"2021-09-12T21:03:15.204459Z","iopub.status.idle":"2021-09-12T21:03:15.260623Z","shell.execute_reply.started":"2021-09-12T21:03:15.20441Z","shell.execute_reply":"2021-09-12T21:03:15.259339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Clear!**","metadata":{}},{"cell_type":"code","source":"all_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:15.266411Z","iopub.execute_input":"2021-09-12T21:03:15.26745Z","iopub.status.idle":"2021-09-12T21:03:15.281486Z","shell.execute_reply.started":"2021-09-12T21:03:15.26738Z","shell.execute_reply":"2021-09-12T21:03:15.280303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*****","metadata":{}},{"cell_type":"markdown","source":"* ### **Preprocessing Name, Ticket columns**\n\n#### Thank you for following me all the way here. Please cheer up a little bit more. We're almost there :)","metadata":{}},{"cell_type":"markdown","source":"#### **I think that name column is very important**\n\n#### **If the family in the train data survived, other family members in the test data are more likely to survive.**","metadata":{}},{"cell_type":"code","source":"name=[]\nfor i in range(len(all_data['Name'])):\n    name.append(all_data['Name'].iloc[i].split(',')[1].split('.')[0])\nall_data['Name']=name\nall_data['Name']=all_data['Name'].replace([' Dr',' Mlle',' Rev',' Major',' Col',' Don',' the Countess',' Lady',' Jonkheer',' Sir',' Mme',' Ms',' Capt',' Dona'],'Rare')\nall_data['Name']=all_data['Name'].replace({' Mr':1,' Miss':2,' Mrs':2,' Master':3,'Rare':4})\n\nname=[]\nfor i in range(len(test['Name'])):\n    name.append(test['Name'].iloc[i].split(',')[1].split('.')[0])\ntest['Name']=name\ntest['Name']=test['Name'].replace([' Dr',' Mlle',' Rev',' Major',' Col',' Don',' the Countess',' Lady',' Jonkheer',' Sir',' Mme',' Ms',' Capt',' Dona'],'Rare')\ntest['Name']=test['Name'].replace({' Mr':1,' Miss':2,' Mrs':2,' Master':3,'Rare':4})","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:31.894906Z","iopub.execute_input":"2021-09-12T21:03:31.895613Z","iopub.status.idle":"2021-09-12T21:03:31.940742Z","shell.execute_reply.started":"2021-09-12T21:03:31.89557Z","shell.execute_reply":"2021-09-12T21:03:31.94004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Ticket?**\n\n#### **At first, we need to split by space**","metadata":{}},{"cell_type":"code","source":"ticket_split = all_data['Ticket'].apply(lambda x : x.split(' '))\nticket_split","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:35.808393Z","iopub.execute_input":"2021-09-12T21:03:35.80918Z","iopub.status.idle":"2021-09-12T21:03:35.820632Z","shell.execute_reply.started":"2021-09-12T21:03:35.809135Z","shell.execute_reply":"2021-09-12T21:03:35.819739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **How about binning those group??**\n\n#### Using agg(len), we can group those ticket data","metadata":{}},{"cell_type":"markdown","source":"#### Code presumed to be the type of ticket is included at the beginning of the list (A/5, STON/, etc..)","metadata":{}},{"cell_type":"code","source":"ticket_2 = ticket_split[ticket_split.agg(len) == 2]\nticket_2","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:37.495748Z","iopub.execute_input":"2021-09-12T21:03:37.496064Z","iopub.status.idle":"2021-09-12T21:03:37.507811Z","shell.execute_reply.started":"2021-09-12T21:03:37.49603Z","shell.execute_reply":"2021-09-12T21:03:37.506979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticket_2_index = ticket_split[ticket_split.agg(len) == 2].index\nticket_2_index","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:39.864754Z","iopub.execute_input":"2021-09-12T21:03:39.865068Z","iopub.status.idle":"2021-09-12T21:03:39.873699Z","shell.execute_reply.started":"2021-09-12T21:03:39.86504Z","shell.execute_reply":"2021-09-12T21:03:39.872803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticket_code_2 = []\n\nfor i in ticket_2.index:\n    ticket_code_2.append(ticket_2[i][0])\n    \nticket_code_2","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-12T21:03:42.208Z","iopub.execute_input":"2021-09-12T21:03:42.208351Z","iopub.status.idle":"2021-09-12T21:03:42.224337Z","shell.execute_reply.started":"2021-09-12T21:03:42.208316Z","shell.execute_reply":"2021-09-12T21:03:42.223276Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticket_code_2_labeled = le.fit_transform(ticket_code_2)\nticket_code_2_labeled += 1\nticket_code_2_labeled","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:47.494468Z","iopub.execute_input":"2021-09-12T21:03:47.49476Z","iopub.status.idle":"2021-09-12T21:03:47.50374Z","shell.execute_reply.started":"2021-09-12T21:03:47.494731Z","shell.execute_reply":"2021-09-12T21:03:47.502889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticket_3 = ticket_split[ticket_split.agg(len) == 3]\nticket_3","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:50.410484Z","iopub.execute_input":"2021-09-12T21:03:50.410825Z","iopub.status.idle":"2021-09-12T21:03:50.423398Z","shell.execute_reply.started":"2021-09-12T21:03:50.410771Z","shell.execute_reply":"2021-09-12T21:03:50.422441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticket_3_index = ticket_split[ticket_split.agg(len) == 3].index\n\nticket_code_3 = []\n\nfor i in ticket_3.index:\n    ticket_code_3.append(ticket_3[i][0])\n    \nticket_code_3","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:52.230064Z","iopub.execute_input":"2021-09-12T21:03:52.23039Z","iopub.status.idle":"2021-09-12T21:03:52.240372Z","shell.execute_reply.started":"2021-09-12T21:03:52.230348Z","shell.execute_reply":"2021-09-12T21:03:52.239481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ticket_code_3_labeled = le.fit_transform(ticket_code_3)\nticket_code_3_labeled += ticket_code_2_labeled.max()\nticket_code_3_labeled","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:53.917563Z","iopub.execute_input":"2021-09-12T21:03:53.918325Z","iopub.status.idle":"2021-09-12T21:03:53.926077Z","shell.execute_reply.started":"2021-09-12T21:03:53.918283Z","shell.execute_reply":"2021-09-12T21:03:53.925145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Making new columns !","metadata":{}},{"cell_type":"code","source":"all_data['ticket_code'] = 0\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:55.926929Z","iopub.execute_input":"2021-09-12T21:03:55.927624Z","iopub.status.idle":"2021-09-12T21:03:55.960325Z","shell.execute_reply.started":"2021-09-12T21:03:55.927579Z","shell.execute_reply":"2021-09-12T21:03:55.959703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data.loc[ticket_2_index, 'ticket_code'] = list(ticket_code_2_labeled)\nall_data.loc[ticket_3_index, 'ticket_code'] = list(ticket_code_3_labeled)\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:03:59.678149Z","iopub.execute_input":"2021-09-12T21:03:59.679369Z","iopub.status.idle":"2021-09-12T21:03:59.711375Z","shell.execute_reply.started":"2021-09-12T21:03:59.679324Z","shell.execute_reply":"2021-09-12T21:03:59.710615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Done!!!**","metadata":{}},{"cell_type":"code","source":"all_data2 = all_data.drop(columns = ['Ticket', 'Survived', 'PassengerId'])\nall_data2","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:04:07.198869Z","iopub.execute_input":"2021-09-12T21:04:07.199479Z","iopub.status.idle":"2021-09-12T21:04:07.22438Z","shell.execute_reply.started":"2021-09-12T21:04:07.19943Z","shell.execute_reply":"2021-09-12T21:04:07.223541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling","metadata":{}},{"cell_type":"code","source":"all_data2['Fare'] = np.log1p(all_data2['Fare'])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:04:09.758494Z","iopub.execute_input":"2021-09-12T21:04:09.759087Z","iopub.status.idle":"2021-09-12T21:04:09.764787Z","shell.execute_reply.started":"2021-09-12T21:04:09.759032Z","shell.execute_reply":"2021-09-12T21:04:09.764176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modeling**\n\n## There are many **categorical columns!**\n\n### How about using **CatBoost**?","metadata":{}},{"cell_type":"markdown","source":"* ### **Train_Test_Split**\n\n#### **Using validation data for evaluation**\n\n#### **In case of classification competition, you can use option 'stratify' for seperation balance**","metadata":{}},{"cell_type":"code","source":"train2 = all_data2[:len(train)]\ntest2 = all_data2[len(train):].reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:04:12.839554Z","iopub.execute_input":"2021-09-12T21:04:12.840134Z","iopub.status.idle":"2021-09-12T21:04:12.845541Z","shell.execute_reply.started":"2021-09-12T21:04:12.840079Z","shell.execute_reply":"2021-09-12T21:04:12.844942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(train2, train['Survived'], test_size = 0.2, random_state = 42, stratify = train['Survived'])","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:04:14.071528Z","iopub.execute_input":"2021-09-12T21:04:14.071836Z","iopub.status.idle":"2021-09-12T21:04:14.080711Z","shell.execute_reply.started":"2021-09-12T21:04:14.071807Z","shell.execute_reply":"2021-09-12T21:04:14.08005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat = CatBoostClassifier(verbose = 1000,\n                         eval_metric='Accuracy',\n                         early_stopping_rounds=1000,\n                         n_estimators=10000,\n                         learning_rate = 0.025,\n                         max_depth=7)\n\ncat.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n\nresult = cat.predict(test2)\n\nsub['Survived'] = result\n\nsub.to_csv('sub_catboost.csv', index = 0)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:04:48.597429Z","iopub.execute_input":"2021-09-12T21:04:48.598387Z","iopub.status.idle":"2021-09-12T21:04:50.546659Z","shell.execute_reply.started":"2021-09-12T21:04:48.598325Z","shell.execute_reply":"2021-09-12T21:04:50.545694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ### **Stratified Kfold**\n\n#### You can use the code below for your stratifiedKfold Baseline","metadata":{}},{"cell_type":"code","source":"stk = StratifiedKFold(n_splits=5, random_state = 42, shuffle = True)\n\nresult_cat = 0\n\nfor fold, (train_index, valid_index) in enumerate(stk.split(train2, train['Survived'])):\n    x_train, y_train = train2.iloc[train_index], train['Survived'][train_index]\n    x_valid, y_valid = train2.iloc[valid_index], train['Survived'][valid_index]\n    \n    cat = CatBoostClassifier(verbose = 1000,\n                         eval_metric='Accuracy',\n                         early_stopping_rounds=1000,\n                         n_estimators=10000,\n                         learning_rate = 0.02,\n                         max_depth=8)\n    print('----------Fold', fold+1, 'Start!--------')\n    cat.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n    print('----------Fold', fold+1, 'Done!--------')\n    result_cat += cat.predict_proba(test2)[:, 1] / 5\n\nprint('All Done!')","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:22:47.742887Z","iopub.execute_input":"2021-09-12T21:22:47.743244Z","iopub.status.idle":"2021-09-12T21:23:03.491722Z","shell.execute_reply.started":"2021-09-12T21:22:47.743206Z","shell.execute_reply":"2021-09-12T21:23:03.49112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['Survived'] = result_cat\nsub['Survived'] = sub['Survived'].astype(np.int64)\nsub.to_csv('sub_cat_stratifiedkfold.csv', index = 0)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T21:23:30.925789Z","iopub.execute_input":"2021-09-12T21:23:30.926118Z","iopub.status.idle":"2021-09-12T21:23:30.933912Z","shell.execute_reply.started":"2021-09-12T21:23:30.926083Z","shell.execute_reply":"2021-09-12T21:23:30.933282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Thank you so much for reading it until the end**\n## **I'm glad if it helped you!**\n## **If this notebook helped you to learn, please do not forget the Upvote!!**","metadata":{}}]}