{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nMy focus in this notebook is on the Random Forest Classifier hyperparameter tuning and not on exploratory data analysis.\n\nHowever, since we need a prepare and clean dataset for tuning, the first part of the notebook dedicated to data engineering on the Titanic dataset.\n\nFor explanation and details of methods used in the data cleaning part, you can visit these notebooks:\n\n1. Meditation on the Cabin\n\nhttps://www.kaggle.com/code/khashayarrahimi94/meditation-on-the-cabin\n\n2. What NOT TO DO in Titanic(Feature Engineering)\n\nhttps://www.kaggle.com/code/khashayarrahimi94/what-not-to-do-in-titanic-feature-engineering\n\n3. How divergence the train & test distributions are?\n\nhttps://www.kaggle.com/code/khashayarrahimi94/how-divergence-the-train-test-distributions-are","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom Levenshtein import distance as lev\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nimport re\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:44:01.484683Z","iopub.execute_input":"2022-03-30T16:44:01.485049Z","iopub.status.idle":"2022-03-30T16:44:01.492918Z","shell.execute_reply.started":"2022-03-30T16:44:01.48501Z","shell.execute_reply":"2022-03-30T16:44:01.492043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(r'../input/titanic/train.csv')\ntest =  pd.read_csv(r'../input/titanic/test.csv')\nAll = pd.concat([train, test], sort=True).reset_index(drop=True)\nAll","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:44:01.529418Z","iopub.execute_input":"2022-03-30T16:44:01.529698Z","iopub.status.idle":"2022-03-30T16:44:01.571402Z","shell.execute_reply.started":"2022-03-30T16:44:01.52967Z","shell.execute_reply":"2022-03-30T16:44:01.570613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"All[All['Fare'].isnull()]\nmean_fare = All.groupby(['Pclass', 'Parch', 'SibSp']).Fare.mean()[3][0][0]\n# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\nAll['Fare'] = All['Fare'].fillna(mean_fare)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:44:01.572861Z","iopub.execute_input":"2022-03-30T16:44:01.573244Z","iopub.status.idle":"2022-03-30T16:44:01.5825Z","shell.execute_reply.started":"2022-03-30T16:44:01.573212Z","shell.execute_reply":"2022-03-30T16:44:01.581665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"All[All['Embarked'].isnull()]\nAll['Embarked'] = All['Embarked'].fillna('S')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:44:01.603951Z","iopub.execute_input":"2022-03-30T16:44:01.604575Z","iopub.status.idle":"2022-03-30T16:44:01.610105Z","shell.execute_reply.started":"2022-03-30T16:44:01.604535Z","shell.execute_reply":"2022-03-30T16:44:01.609236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif as MIC\nmi_score = MIC(train.loc[: , ['Age' ,'Pclass','Parch','Fare','SibSp' ]].values.astype('int'),\n               train.loc[: , ['Age']].values.astype('int').reshape(-1, 1))\nFeature2 = ['Age' ,'Pclass','Parch','Fare','SibSp' ]\nMutual_Information_table = pd.DataFrame(columns=['Feature1', 'Feature2', 'MIC'], index=range(5))\nMutual_Information_table['Feature1'] = 'Age'\nfor feature in range(5):\n    Mutual_Information_table['Feature2'][feature] = Feature2[feature]\nfor value in range(5):\n    Mutual_Information_table['MIC'][value] = mi_score[value]\nMutual_Information_table","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:44:01.658317Z","iopub.execute_input":"2022-03-30T16:44:01.659205Z","iopub.status.idle":"2022-03-30T16:44:01.91131Z","shell.execute_reply.started":"2022-03-30T16:44:01.65916Z","shell.execute_reply":"2022-03-30T16:44:01.910397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_by_pclass_sex = round(All.groupby(['Sex', 'Pclass']).median()['Age'])\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Mean age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\nprint('Mean age of all passengers: {}'.format(round(All['Age'].mean())))\n\nAll['Age'] = All.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(round(x.median())))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:44:01.91299Z","iopub.execute_input":"2022-03-30T16:44:01.913248Z","iopub.status.idle":"2022-03-30T16:44:01.935623Z","shell.execute_reply.started":"2022-03-30T16:44:01.913219Z","shell.execute_reply":"2022-03-30T16:44:01.934727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"All1 = All.copy()\npclass = [1,2,3]\nfor t in pclass:\n    for i in range(All.shape[0]):\n        if (All1.Pclass[i]==t)&(pd.isnull(All1[\"Cabin\"][i])== True):\n            LD_Ticket={}\n            for j in range(All.shape[0]):\n                if (All1.Pclass[j]==t)&(pd.isnull(All1[\"Cabin\"][j])== False)&(All1.Fare[j]==All1.Fare[i])&(All1.Embarked[j]==All1.Embarked[i]):\n                    LD_Ticket[lev(All1.Ticket[i],All1.Ticket[j])] = j\n            if LD_Ticket !={}:\n                similar_ticket = LD_Ticket[min(list(LD_Ticket))]\n                #print(similar_ticket, LD_Ticket,i)                 #Uncomment this line to see the output, I comment it to make the notebook more clear\n                All[\"Cabin\"][i] = All[\"Cabin\"][similar_ticket]\n                \nAll2 = All.copy()\npclass = [1,2,3]\nfor t in pclass:\n    for i in range(All2.shape[0]):\n        if (All2.Pclass[i]==t)&(pd.isnull(All2[\"Cabin\"][i])== True):\n            LD_Ticket={}\n            for j in range(All.shape[0]):\n                if (All2.Pclass[j]==t)&(pd.isnull(All2[\"Cabin\"][j])== False)&(abs((All2.Fare[j])- (All2.Fare[i]))<1):\n                    LD_Ticket[lev(All2.Ticket[i],All2.Ticket[j])] = j\n            if LD_Ticket !={}:\n                similar_ticket = LD_Ticket[min(list(LD_Ticket))]\n                #print(similar_ticket, LD_Ticket,i)\n                All[\"Cabin\"][i] = All[\"Cabin\"][similar_ticket]\n                \nAll3 = All.copy()\npclass = [1,2,3]\nfor t in pclass:\n    for i in range(All3.shape[0]):\n        if (All3.Pclass[i]==t)&(pd.isnull(All3[\"Cabin\"][i])== True):\n            LD_Ticket={}\n            for j in range(All.shape[0]):\n                if (All3.Pclass[j]==t)&(pd.isnull(All3[\"Cabin\"][j])== False)&(abs((All3.Fare[j])-(All3.Fare[i]))<20):\n                    LD_Ticket[lev(All3.Ticket[i],All3.Ticket[j])] = j\n            if LD_Ticket !={}:\n                similar_ticket = LD_Ticket[min(list(LD_Ticket))]\n                #print(similar_ticket, LD_Ticket,i)\n                All[\"Cabin\"][i] = All[\"Cabin\"][similar_ticket]\n\nAll4 = All.copy()\npclass = [1,2,3]\nfor t in pclass:\n    for i in range(All.shape[0]):\n        if (All4.Pclass[i]==t)&(pd.isnull(All4[\"Cabin\"][i])== True):\n            LD_Ticket={}\n            for j in range(All.shape[0]):\n                if (All4.Pclass[j]==t)&(pd.isnull(All4[\"Cabin\"][j])== False):\n                    LD_Ticket[lev(All4.Ticket[i],All4.Ticket[j])] = j\n            if LD_Ticket !={}:\n                similar_ticket = LD_Ticket[min(list(LD_Ticket))]\n                #print(similar_ticket, LD_Ticket,i)\n                All[\"Cabin\"][i] = All[\"Cabin\"][similar_ticket]\n\nAll['Cabin']","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:44:01.93727Z","iopub.execute_input":"2022-03-30T16:44:01.937613Z","iopub.status.idle":"2022-03-30T16:45:54.361186Z","shell.execute_reply.started":"2022-03-30T16:44:01.937567Z","shell.execute_reply":"2022-03-30T16:45:54.360179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"All['Cabin'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:54.363715Z","iopub.execute_input":"2022-03-30T16:45:54.36412Z","iopub.status.idle":"2022-03-30T16:45:54.370905Z","shell.execute_reply.started":"2022-03-30T16:45:54.364076Z","shell.execute_reply":"2022-03-30T16:45:54.370032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name in All[\"Name\"]:\n    All[\"Title\"] = All[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n\ntitle_replacements = {\"Mlle\": \"Other\", \"Major\": \"Other\", \"Col\": \"Other\", \"Sir\": \"Other\", \"Don\": \"Other\", \"Mme\": \"Other\",\n          \"Jonkheer\": \"Other\", \"Lady\": \"Other\", \"Capt\": \"Other\", \"Countess\": \"Other\", \"Dona\": \"Other\"\n                     ,\"Dr\":\"Other\",\"Rev\":\"Other\"}\n\nAll.replace({\"Title\": title_replacements}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:54.37223Z","iopub.execute_input":"2022-03-30T16:45:54.372501Z","iopub.status.idle":"2022-03-30T16:45:58.795135Z","shell.execute_reply.started":"2022-03-30T16:45:54.372472Z","shell.execute_reply":"2022-03-30T16:45:58.794566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"All[[\"Age\", \"Fare\"]] = StandardScaler().fit_transform(All[[\"Age\", \"Fare\"]])","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:58.796487Z","iopub.execute_input":"2022-03-30T16:45:58.797169Z","iopub.status.idle":"2022-03-30T16:45:58.806808Z","shell.execute_reply.started":"2022-03-30T16:45:58.797107Z","shell.execute_reply":"2022-03-30T16:45:58.80588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"All[\"Deck\"]=All[\"Cabin\"]\nfor i in range(All.shape[0]):\n    All[\"Deck\"][i] = All[\"Cabin\"][i][0]\n\nAll.drop(['Cabin'], axis=1, inplace=True)\nAll","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:58.808454Z","iopub.execute_input":"2022-03-30T16:45:58.808735Z","iopub.status.idle":"2022-03-30T16:45:59.215111Z","shell.execute_reply.started":"2022-03-30T16:45:58.808694Z","shell.execute_reply":"2022-03-30T16:45:59.214436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"All['Title'] = pd.factorize(All['Title'])[0]\nAll['Deck'] = pd.factorize(All['Deck'])[0]\nAll['Sex'] = pd.factorize(All['Sex'])[0]\nAll['Embarked'] = pd.factorize(All['Embarked'])[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:59.216035Z","iopub.execute_input":"2022-03-30T16:45:59.216621Z","iopub.status.idle":"2022-03-30T16:45:59.224004Z","shell.execute_reply.started":"2022-03-30T16:45:59.216587Z","shell.execute_reply":"2022-03-30T16:45:59.223389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"All.drop(['Name','PassengerId','Ticket'], axis=1, inplace=True)\nAll.insert(10, \"survived\", All['Survived'])\nAll.drop(['Survived'], axis=1, inplace=True)\nAll","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:59.225273Z","iopub.execute_input":"2022-03-30T16:45:59.225507Z","iopub.status.idle":"2022-03-30T16:45:59.251492Z","shell.execute_reply.started":"2022-03-30T16:45:59.225479Z","shell.execute_reply":"2022-03-30T16:45:59.250501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = All.head(891)\ntest = All.tail(418)\ntest.drop(['survived'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:59.25366Z","iopub.execute_input":"2022-03-30T16:45:59.253912Z","iopub.status.idle":"2022-03-30T16:45:59.259547Z","shell.execute_reply.started":"2022-03-30T16:45:59.253883Z","shell.execute_reply":"2022-03-30T16:45:59.258691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest tuning (Layer Based)\n\nThe importance of Machine Learning models hyperparameter tuning is clear to all practitioners, and often is not a challengeable part of data science.\nHere I just want to share my approach for ML models tuning and in this case Random Forest tuning.\n\n## What is Layer based tuning?\n\nIn fact,this is not a formal concept and it was just named by me. Also, most likely many practitioners do the same.\n\nHere I mean modifying the hyperparameters after a best result in the pervious layer obtained until we achieve the best values for hyperparameters.\n\nIn other words, first we start with different values for hyperparameters and after running we obtain a best. In next step or layer, we modify the values in the **neighbourhood** of the pervious layer and repeat this process until achieving specific value for each hyperparameters.\n\nWe can combine all of this pocess in one cell or by defining a function. I hope to do it soon and share it here.","metadata":{}},{"cell_type":"code","source":"def estimator(param):\n    #param={}\n    #param = grid_result.best_params_\n\n    best_n_estimators = param.get('n_estimators')\n    \n    if param_grid[0].get('n_estimators')[1] - param_grid[0].get('n_estimators')[0] == 100:\n        n_estimators = [*range(best_n_estimators-90, best_n_estimators+90, 10)]  \n        \n    if param_grid[0].get('n_estimators')[1] - param_grid[0].get('n_estimators')[0] == 10:\n         n_estimators = [*range(best_n_estimators-9, best_n_estimators+9, 1)]\n        \n    return n_estimators\n\n\ndef depth(param):\n    #param={}\n    #param = grid_result.best_params_\n\n    best_max_depth = param.get('max_depth')\n    \n    if param_grid[0].get('max_depth')[1] - param_grid[0].get('max_depth')[0] == 2:\n        max_depth = [*range(best_max_depth-2, best_max_depth+2, 1)]\n        \n    if param_grid[0].get('max_depth')[1] - param_grid[0].get('max_depth')[0] == 1:\n        max_depth = [*range(best_max_depth-1, best_max_depth+1, 1)]\n        \n    return max_depth\n\n\ndef leaf_nodes(param):\n    #param = grid_result.best_params_\n\n    best_leaf_nodes = param.get('max_leaf_nodes')\n    \n    if param_grid[0].get('max_leaf_nodes')[1] - param_grid[0].get('max_leaf_nodes')[0] == 5:\n        max_leaf_nodes = [*range(best_leaf_nodes-5, best_leaf_nodes+5, 1)]\n    if param_grid[0].get('max_leaf_nodes')[1] - param_grid[0].get('max_leaf_nodes')[0] == 1:\n        max_leaf_nodes = [best_leaf_nodes]\n        \n    return max_leaf_nodes","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:59.260634Z","iopub.execute_input":"2022-03-30T16:45:59.260953Z","iopub.status.idle":"2022-03-30T16:45:59.273007Z","shell.execute_reply.started":"2022-03-30T16:45:59.260927Z","shell.execute_reply":"2022-03-30T16:45:59.272328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.values[:,:-1]\nY = train.values[:,-1]\nlabel_encoded_y = LabelEncoder().fit_transform(Y)\n\n\n\n# defining parameter range\nparam_grid = [\n    {'n_estimators': [100,200,300], \n     'max_depth': [2, 4, 6, 8, 10, 12], \n     'max_leaf_nodes': [10, 15, 20, 25]}, \n]\n\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    \ngrid_search = GridSearchCV(RandomForestClassifier(), param_grid, scoring=\"accuracy\", n_jobs=-1, cv=kfold)\ngrid_result = grid_search.fit(X, label_encoded_y)\n#summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\nprint('n_estimators =',param_grid[0].get('n_estimators'))\nprint('max_depth =',param_grid[0].get('max_depth'))\nprint('max_leaf_nodes =',param_grid[0].get('max_leaf_nodes'))\n\n#Uncomment these two line to see the result for all possible combination of hyperparameters\n\n#means = grid_result.cv_results_['mean_test_score']\n#stds = grid_result.cv_results_['std_test_score']\n#params = grid_result.cv_results_['params']\n\n\n\n#for mean, stdev, param in zip(means, stds, params):     \n#   print(\"%f (%f) with: %r\" % (mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:45:59.274321Z","iopub.execute_input":"2022-03-30T16:45:59.274607Z","iopub.status.idle":"2022-03-30T16:47:36.348111Z","shell.execute_reply.started":"2022-03-30T16:45:59.274547Z","shell.execute_reply":"2022-03-30T16:47:36.347102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param = grid_result.best_params_\n\n# defining parameter range\nparam_grid = [\n    {'n_estimators': estimator(param), \n     'max_depth': depth(param), \n     'max_leaf_nodes': leaf_nodes(param)}, \n]\n\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    \ngrid_search = GridSearchCV(RandomForestClassifier(), param_grid, scoring=\"accuracy\", n_jobs=-1, cv=kfold)\ngrid_result = grid_search.fit(X, label_encoded_y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\nprint('n_estimators =',param_grid[0].get('n_estimators'))\nprint('max_depth =',param_grid[0].get('max_depth'))\nprint('max_leaf_nodes =',param_grid[0].get('max_leaf_nodes'))\n\n#means = grid_result.cv_results_['mean_test_score']\n#stds = grid_result.cv_results_['std_test_score']\n#params = grid_result.cv_results_['params']\n\n\n#for mean, stdev, param in zip(means, stds, params):     \n#   print(\"%f (%f) with: %r\" % (mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T16:47:36.349878Z","iopub.execute_input":"2022-03-30T16:47:36.350317Z","iopub.status.idle":"2022-03-30T17:11:26.57494Z","shell.execute_reply.started":"2022-03-30T16:47:36.350267Z","shell.execute_reply":"2022-03-30T17:11:26.574085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param = grid_result.best_params_\n# defining parameter range\nparam_grid = [\n    {'n_estimators': estimator(param), \n     'max_depth': depth(param), \n     'max_leaf_nodes': leaf_nodes(param)}, \n]\n\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    \ngrid_search = GridSearchCV(RandomForestClassifier(), param_grid, scoring=\"accuracy\", n_jobs=-1, cv=kfold)\ngrid_result = grid_search.fit(X, label_encoded_y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\nprint('n_estimators =',param_grid[0].get('n_estimators'))\nprint('max_depth =',param_grid[0].get('max_depth'))\nprint('max_leaf_nodes =',param_grid[0].get('max_leaf_nodes'))\n\n#means = grid_result.cv_results_['mean_test_score']\n#stds = grid_result.cv_results_['std_test_score']\n#params = grid_result.cv_results_['params']\n\n\n#for mean, stdev, param in zip(means, stds, params):     \n#   print(\"%f (%f) with: %r\" % (mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T17:11:26.578013Z","iopub.execute_input":"2022-03-30T17:11:26.578514Z","iopub.status.idle":"2022-03-30T17:12:42.556973Z","shell.execute_reply.started":"2022-03-30T17:11:26.578475Z","shell.execute_reply":"2022-03-30T17:12:42.556161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\nRFC = RandomForestClassifier(max_depth=grid_result.best_params_.get('max_depth'),\n                            max_leaf_nodes= grid_result.best_params_.get('max_leaf_nodes'),\n                            n_estimators= grid_result.best_params_.get('n_estimators')\n)\n\nresults = cross_val_score(RFC, X, label_encoded_y, cv=kfold)\nprint(results.mean() ,results.std())","metadata":{"execution":{"iopub.status.busy":"2022-03-30T17:12:42.55823Z","iopub.execute_input":"2022-03-30T17:12:42.558453Z","iopub.status.idle":"2022-03-30T17:12:47.216728Z","shell.execute_reply.started":"2022-03-30T17:12:42.558425Z","shell.execute_reply":"2022-03-30T17:12:47.215811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameters for score: 0.79186\n\nThe hyperparameters may changes due to random_state or other things, However when I run this code I obtain the below values for hyperparameters:\n\n* max_depth = 6\n* max_leaf_nodes = 29\n* n_estimators = 112","metadata":{}},{"cell_type":"code","source":"kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7) \n\nRF = RandomForestClassifier(max_depth=6,max_leaf_nodes= 29,n_estimators=112)\n\nresults = cross_val_score(RF, X, label_encoded_y, cv=kfold)\nprint(results.mean() ,results.std())","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:15:59.720246Z","iopub.execute_input":"2022-03-30T19:15:59.723957Z","iopub.status.idle":"2022-03-30T19:16:01.637526Z","shell.execute_reply.started":"2022-03-30T19:15:59.723713Z","shell.execute_reply":"2022-03-30T19:16:01.636218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RFC.fit(X, label_encoded_y)\npredict_RFC = RFC.predict(test)\nSubmission = pd.DataFrame({'PassengerId':list(range(892,1310))})\nSubmission['Survived']=predict_RFC\nSubmission","metadata":{"execution":{"iopub.status.busy":"2022-03-30T19:16:12.01078Z","iopub.execute_input":"2022-03-30T19:16:12.011477Z","iopub.status.idle":"2022-03-30T19:16:12.238028Z","shell.execute_reply.started":"2022-03-30T19:16:12.011434Z","shell.execute_reply":"2022-03-30T19:16:12.237233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T17:12:49.199067Z","iopub.execute_input":"2022-03-30T17:12:49.199347Z","iopub.status.idle":"2022-03-30T17:12:49.208423Z","shell.execute_reply.started":"2022-03-30T17:12:49.199318Z","shell.execute_reply":"2022-03-30T17:12:49.207555Z"},"trusted":true},"execution_count":null,"outputs":[]}]}