{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization\nimport matplotlib.pyplot as plt # matplotlib\nfrom datetime import date\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\",index_col=\"PassengerId\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\",index_col=\"PassengerId\")\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,5,figsize=(25, 10))\n\nsns.countplot(x=train_df[\"Survived\"],ax=ax[0,0]) # count of survivors and deceased\nsns.countplot(x=train_df[\"Sex\"],ax=ax[0,1]) # Count of each sex\n\nsns.barplot(x=train_df[\"Survived\"],y=train_df[\"Pclass\"],ax=ax[0,2]) # Pclass cat vs survival\nsns.barplot(x=train_df[\"Survived\"],y=train_df[\"Sex\"],ax=ax[0,3]) # Sex vs survival\nsns.boxplot(x=train_df[\"Survived\"],y=train_df[\"Age\"],ax=ax[0,4]) # Age vs survival\nsns.boxplot(x=train_df[\"Survived\"],y=train_df[\"Fare\"],ax=ax[1,0]) # Fare cost vs survival\nsns.barplot(x=train_df[\"Survived\"],y=train_df[\"Embarked\"],ax=ax[1,1]) # Embark category vs survived\nsns.barplot(x=train_df[\"Survived\"],y=train_df[\"SibSp\"],ax=ax[1,2]) # SibSp category vs survived\nsns.barplot(x=train_df[\"Survived\"],y=train_df[\"Parch\"],ax=ax[1,3]) # Parch category vs survived\n\ntrain_df[\"Cabin\"] = train_df[\"Cabin\"].str[0]\nsns.barplot(x=train_df[\"Survived\"],y=train_df[\"Cabin\"],ax=ax[1,4]) # Cabin vs survived\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train a random forest model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoding classes as one hot vectors\ntrain_df = train_df.replace(np.nan, 0)\n\n\nX_data = pd.get_dummies(data=train_df[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Cabin\",\"Embarked\"]])\nX_data.drop(labels=[\"Cabin_0\",\"Embarked_0\",\"Cabin_T\"],axis=1,inplace=True)\n\ny_data = train_df[\"Survived\"]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X_data,y_data,train_size=0.7,shuffle=True)\n\nX_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"threshold = 0.5 # need to optimize the threshold\n# find an optimal tree count\nx_axis = []\ny_axis = []\nfor numTrees in range(5,150,5):\n    regressor = RandomForestRegressor(n_estimators=numTrees)\n    regressor.fit(X_train, y_train)\n    y_pred_prob = regressor.predict(X_test)\n    x_axis.append(numTrees)\n    y_axis.append(metrics.f1_score(y_test, y_pred_prob > threshold))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=x_axis,y=y_axis)\nplt.xlabel(\"Number of Trees\")\nplt.ylabel(\"f1 score\")\n\nnumTrees = x_axis[np.argmax(y_axis)] # max tree value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = RandomForestRegressor(n_estimators=numTrees)\nregressor.fit(X_train, y_train)\n\ny_pred_prob = regressor.predict(X_test)\ny_pred = y_pred_prob > threshold # assign a classification above a given threshold\n\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred > threshold)\naccuracy_score = metrics.accuracy_score(y_test, y_pred)\nprecision_score = metrics.precision_score(y_test, y_pred)\nrecall_score = metrics.recall_score(y_test, y_pred)\nf1_score = metrics.f1_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(confusion_matrix,cbar=False,annot=True,square=True,fmt=\"d\")\nplt.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = False, labeltop=True)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\n\nprint(\"accuracy:\",accuracy_score)\nprint(\"precision:\",precision_score)\nprint(\"recall:\",recall_score)\nprint(\"f1 score:\",f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assign predictions to unlabeled data set\ntest_df = test_df.replace(np.nan, 0)\ntest_df[\"Cabin\"] = test_df[\"Cabin\"].str[0]\n\nX_data_unk = pd.get_dummies(data=test_df[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Cabin\",\"Embarked\"]])\n\ny_pred_prob = regressor.predict(X_data_unk)\ny_pred = y_pred_prob > threshold # assign a classification above a given threshold\ntest_df[\"Survived\"] = y_pred.astype(int) # append to result to unlabeled data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df = pd.DataFrame(test_df[\"Survived\"])\nresult_df.head() # submission preview","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.to_csv(\"/kaggle/working/submission_randomforest{}.csv\".format(date.today()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\nmax_depth=1).fit(X_train, y_train)\nclf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_data_unk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"Survived\"] = y_pred.astype(int)\nresult_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.to_csv(\"/kaggle/working/submission_xgboost{}.csv\".format(date.today()))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}