{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div style=\"height:200px;width:100%;margin: 0;\">\n    <img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/header.png\" style=\"width:100%;\" />\n</div>"},{"metadata":{},"cell_type":"markdown","source":"# Notebook Goal\n\nClassic Titan notebook implemented with a Neural Network from Scratch based on each passenger survival."},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:yellow; background:black; border:1px dashed yellow;\" role=\"tab\" aria-controls=\"home\"><center>Data</center></h3>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/titanic/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Data"},{"metadata":{},"cell_type":"markdown","source":"To make a quick neural network using the data above,<br>\nwe can easily create a neural network using the following the columns:<br>\n'**Age**', '**Sex**', '**Fare**', '**Pclass**', '**SibSp**', '**Parch**'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets take out first the label\ntrain_y = df['Survived']\ntrain_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to filter the age, sex, fare pclass, sibsp, parch columns\ndef get_data(data):\n    # take only this specific column\n    data = data[['Age', 'Sex', 'Fare', 'Pclass', 'SibSp', 'Parch']]\n    \n    # replace male by 1, female by 0\n    data.replace({ 'male' : 1, 'female' : 0 }, inplace=True)\n    \n    # replace null/nan data by the mean (age and fare columns)\n    data['Fare'].fillna(int(data['Fare'].mean()), inplace=True)\n    data['Age'].fillna(int(data['Age'].mean()), inplace=True)\n    \n    # transform into a numpy array\n    data = data.to_numpy().astype(float)\n    \n    # normalize (make sure the data is between -1 and 1)\n    for i in range(data.shape[1]):\n        data[:,i] = (data[:,i] - data[:,i].mean()) / data[:,i].std()\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = get_data(df)\nprint(\"Train data shape:\", train_x.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shape will show us the number of rows and columns (891 and 6)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# same for the labels (contains 0 - 1 if the victim survived or not)\nprint(\"Label data shape:\", train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:yellow; background:black; border:1px dashed yellow;\" role=\"tab\" aria-controls=\"home\"><center>Implementation</center></h3>"},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{},"cell_type":"markdown","source":"## Activation function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# the activation function and derivative of the action function\ndef sigmoid(x):\n    return 1/(1+np.exp(-x))\n\ndef dsigmoid(x):\n    return sigmoid(x) * (1 - sigmoid(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# the loss function and its derivative\ndef loss_fn(y, y_hat):\n    return 1/2 * (y - y_hat) ** 2\n\ndef dloss_fn(y, y_hat):\n    return (y - y_hat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of rows\ninstances = train_x.shape[0]\n\n# number oof columns\nattributes = train_x.shape[1]\n\n# number of hidden node for first layer \nhidden_nodes = 8\n\n# number of hidden node for second layer\nhidden_nodes_two = 4\n\n# number of output labels \noutput_labels = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inititate the weights/biases\nw1 = np.random.rand(attributes,hidden_nodes)\nb1 = np.random.randn(1, hidden_nodes)\n\nw2 = np.random.rand(hidden_nodes,hidden_nodes_two)\nb2 = np.random.randn(1, hidden_nodes_two)\n\nw3 = np.random.rand(hidden_nodes_two, output_labels)\nb3 = np.random.randn(1, output_labels)\n\ntheta = w1, w2, w3, b1, b2, b3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Forward function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Neural Network Forward\ndef forward(x, theta):\n    w1, w2, w3, b1, b2, b3 = theta\n    \n    k = np.dot(x, w1) + b1\n    l = sigmoid(k)\n    \n    m = np.dot(l, w2) + b2\n    n = sigmoid(m)\n    \n    o = np.dot(n, w3) + b3\n    p = sigmoid(o)\n    \n    return k, l, m, n, o, p","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Backward function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Neural Network Backward\ndef backward(x, y, sigma, theta):\n    k, l, m, n, o, p = sigma\n    w1, w2, w3, b1, b2, b3 = theta\n    \n    # db3 = dloss * dsigm(o) * 1\n    # dw3 = dloss * dsigm(o) * n\n    \n    # db2 = dloss * dsigm(o) * w3 * dsigm(m) * 1\n    # dw2 = dloss * dsigm(o) * w3 * dsigm(m) * l\n    \n    # db1 = dloss * dsigm(o) * w3 * dsigm(m) * w2 * dsigm(k) \n    # dw1 = dloss * dsigm(o) * w3 * dsigm(m) * w2 * dsigm(k) * x\n    \n    dloss = dloss_fn(p, y)\n    dsigm_p = dsigmoid(o)\n    dsigm_n = dsigmoid(m)\n    dsigm_l = dsigmoid(k)\n    \n    db3 = dloss * dsigm_p\n    dw3 = np.dot(n.T, db3)\n    \n    db2 = np.dot(db3, w3.T) * dsigm_n\n    dw2 = np.dot(l.T, db2)\n    \n    db1 = np.dot(db2, w2.T) * dsigm_l\n    dw1 = np.dot(x, db1)\n    \n    return dw1, dw2, dw3, db1, db2, db3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the avg of the gradients for the derivative of each bias\ndef avg_bias(grads):\n    dw1, dw2, dw3, db1, db2, db3 = grads\n    db1 = db1.mean(axis=0)\n    db2 = db2.mean(axis=0)\n    db3 = db3.mean(axis=0)\n    return dw1, dw2, dw3, db1, db2, db3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the SGD in order to optimize the weights and biases\ndef optimize(theta, grads, lr=0.001):\n    dw1, dw2, dw3, db1, db2, db3 = grads\n    w1, w2, w3, b1, b2, b3 = theta\n    \n    w1 -= dw1 * lr\n    w2 -= dw2 * lr\n    w3 -= dw3 * lr\n    b1 -= db1 * lr\n    b2 -= db2 * lr\n    b3 -= db3 * lr\n    \n    return w1, w2, w3, b1, b2, b3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:yellow; background:black; border:1px dashed yellow;\" role=\"tab\" aria-controls=\"home\"><center>Prediction</center></h3>"},{"metadata":{},"cell_type":"markdown","source":"# Predict & Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"# return 1 if the prediction is higher than 0.5\n# return 0 if not\ndef predict(x, theta):\n    predict = forward(x, theta)[-1]\n    return np.where(predict > 0.5, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# time to train our model\nfor epoch in range(1000):\n    \n    for i in range(len(train_x)):\n        sigma = forward(train_x[i], theta)\n        grads = backward(train_x[i].reshape(6,1), train_y[i], sigma, theta)\n        theta = optimize(theta, avg_bias(grads))\n    \n    if(epoch % 100 == 0):\n        loss = loss_fn(sigma[-1], train_y[i]).mean()\n        print(\"Epoch:{:3d}, Loss:{:1.3f}\"\n                 .format(epoch, loss))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:yellow; background:black; border:1px dashed yellow;\" role=\"tab\" aria-controls=\"home\"><center>Submission</center></h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/titanic/test.csv\")\ntest = get_data(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get test data predictions\ntest_preds = predict(test, theta).reshape(-1)\n\n# Add passengers ids to the test predictions\npassenger_ids = test_df['PassengerId'].to_numpy()\n\n# combine passenger ids with the predictions\nfinal_result = np.array(list(map(list, zip(passenger_ids, test_preds))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# arraay final_result to dataframe\ndf_final = pd.DataFrame(data=final_result, columns=[\"PassengerId\", \"Survived\"])\n\n# save the result\ndf_final.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}