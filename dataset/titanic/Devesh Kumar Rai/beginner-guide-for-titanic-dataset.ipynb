{"cells":[{"metadata":{"_uuid":"2fba35bb3583c85b59a33ba86a5d6704de2afa57"},"cell_type":"markdown","source":"In this kernel we will do a complete analysis in order to determine which group of people were most likely to survive in the infamous Titanic incident. In particular, we will apply the tools of machine learning to predict which passengers would have survived the tragedy."},{"metadata":{"_uuid":"610534c130d2d044a2c7e154aa5a20b7dcd8912c"},"cell_type":"markdown","source":"**Description of the Data Fields:**\n**survival** - Survival (0 = No; 1 = Yes)  **class** - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd) **name** - Name **sex** - Sex **age** - Age **sibsp** - Number of Siblings/Spouses  **Aboard parch** - Number of Parents/Children Aboard **ticket** - Ticket Number **fare** - Passenger Fare **cabin** - Cabin **embarked** - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Reading the training and test data\ntitanic_train = pd.read_csv(\"../input/train.csv\")\ntitanic_test = pd.read_csv(\"../input/test.csv\")\n\n# The first thing after reading the dataset is to know the dimensions.\nprint(\"The dimensions of training data and test data is\",titanic_train.shape,\"and\",titanic_test.shape,\"respectively\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"646ae6e7a559fd5cd2855cea588951066d3981bc"},"cell_type":"markdown","source":"We can infer from above that training data contains an extra column which is the label Let’s get some more information about the dataset using .info() function.\n"},{"metadata":{"trusted":true,"_uuid":"81626cad400eee458c9bb5ae16dde52689b7fd7a"},"cell_type":"code","source":"titanic_train.info()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91b68a68e2d29a49bd44df3d0d495c12acdf7eac"},"cell_type":"markdown","source":"The most vital insight that we get from above is that about 20 percent of age data and 78 percent of Cabin data is having null value.\nLooking at the Cabin column, it seems like we are missing too much of that data to do something useful, even at a basic level. We will either remove the cabin column or give tags like 0/1 to the values in the column.\n\n**Exploratory Data Analysis**"},{"metadata":{"_uuid":"273913f3c2750e26dab1e11a6b9781a634ac6e5a","trusted":true},"cell_type":"code","source":"\nsns.set_style('whitegrid')\n\nsns.countplot(x='Survived', data= titanic_train)\n\n#people who survived v/s who didn't","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25d274e095c60b63ab1f794a22d13152af780abd"},"cell_type":"markdown","source":"From the above plot it is clear that the number of survivors was significantly lower than the number of people who didn’t survive. "},{"metadata":{"trusted":true,"_uuid":"7ec69a160b192f540c699da3f768de4c6f43a66a"},"cell_type":"code","source":"sns.countplot(x='Survived', hue='Sex', data= titanic_train,palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99765644d891a147ce1411bc44f11562c0859eb2"},"cell_type":"markdown","source":"The above  plot shows that the number of males was much higher in the list of people who didn’t survive. We can observe that the number of females was significantly greater than males in the list of survivors. Maybe females first policy was used by the ship crew while transferring people on lifeboats."},{"metadata":{"trusted":true,"_uuid":"f3c412c5879bd023e8e116f56e1c617bba5331ed"},"cell_type":"code","source":"sns.countplot(x='Survived', hue='Pclass', data= titanic_train, palette='rainbow')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea18b8de1f593b475167d3e5339dc99798fda49f"},"cell_type":"markdown","source":"The above plot shows that most of the passengers who lost their lives in this tragic incident belonged to Class 3. There were more survivors from Class 1 than any other class."},{"metadata":{"_uuid":"cbdabb081e9ad48c301dd8ce9de28224264fbd1a"},"cell_type":"markdown","source":"Now let's handle the missing values. For Cabin data giving '1' tag to value with valid Cabin no. and '0' tags to value with NaN.\n"},{"metadata":{"trusted":true,"_uuid":"e78300e5393f54e5409984ca22357bb55674a5cf"},"cell_type":"code","source":"def impute_cabin(col):\n   Cabin = col[0]\n   if type(Cabin) == str:\n       return 1\n   else:\n       return 0\n\ntitanic_train['Cabin'] = titanic_train[['Cabin']].apply(impute_cabin, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67d9869d64404d72652253fb929df624cd06ace2"},"cell_type":"code","source":"titanic_train['Cabin'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c9215255338ca66ce8fac5d95a08870e5b20fe7"},"cell_type":"markdown","source":"Now let's fill in the missing values of the age column. We can do this by taking the mean and standard deviation of the age and then filling up the null age values randomly ."},{"metadata":{"trusted":true,"_uuid":"640d013c0993e5d6184c7595349c2f816c230044"},"cell_type":"code","source":"age_avg=titanic_train['Age'].mean()\nage_std=titanic_train['Age'].std()\n\nimport random\nrandom_list = np.random.randint(age_avg - age_std, age_avg + age_std )\ntitanic_train['Age'][np.isnan(titanic_train['Age'])] = random_list\ntitanic_train['Age'] = titanic_train['Age'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ec86cc7ef4de06b941c06fcd6db10ab446b167d"},"cell_type":"code","source":"titanic_train['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dba512f64506856a51afe934b78cbc88ad709d65"},"cell_type":"code","source":"titanic_train[\"Embarked\"]=titanic_train[\"Embarked\"].fillna(\"S\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de273d8c46625a9f692abf5ef2bda7867c0e8666"},"cell_type":"markdown","source":"So we have now successfully handled the missing data. "},{"metadata":{"_uuid":"030f2e9b12b09d39b714701f929a43a07aea0071"},"cell_type":"markdown","source":"Adding certain columns:-\n1. Adding a column denoting the family size.\n2. Adding a column denoting whether the passenger travelled alone or not."},{"metadata":{"trusted":true,"_uuid":"dbf62aa6571ba8b95ae8a411b308ae4eab91d273"},"cell_type":"code","source":"titanic_train['family_size'] = titanic_train['SibSp'] + titanic_train['Parch'] + 1\ntitanic_train['is_alone'] = 0\ntitanic_train.loc[titanic_train['family_size'] == 1, 'is_alone'] = 1\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a0e687085e43e59edda748b32b3d68ff13ae284"},"cell_type":"markdown","source":"Now , we’ll need to convert categorical features to dummy variables using pandas! Otherwise, our machine learning algorithm won’t be able to directly take in those features as inputs. For that we would map the categorical data "},{"metadata":{"trusted":true,"_uuid":"bfbd5cb3b93a90df846101f167c597f89924ffd2"},"cell_type":"code","source":"train=titanic_train.copy()\n     #Mapping Sex\nsex_map = { 'female':0 , 'male':1 }\ntrain['Sex'] = train['Sex'].map(sex_map).astype(int)\n\n    #Mapping Embarked\nembark_map = {'S':0, 'C':1, 'Q':2}\ntrain['Embarked'] = train['Embarked'].map(embark_map).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de9e157f47630b4383495aa2471b2a18ea29cc0c"},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"583ebd12b33d9701ba60df0c92730f6a6006676c"},"cell_type":"markdown","source":"From above we can infer that ticket column is just composed of random strings which is not so much useful and the name column mainly comprises of Mr. ,Mrs. and Miss which obviously depicts their respective sex or might be age , hence name column is dependent on other columns and hence not so useful. So the above two features can be considered to be redundant and could be dropped. "},{"metadata":{"trusted":true,"_uuid":"63991301b6d02faf009945f876c9d247d24c779c"},"cell_type":"code","source":"train=train.drop(\"Name\",axis=1)\ntrain=train.drop(\"Ticket\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0a9ed9ef427653a0c1955595c334b7e44b70793"},"cell_type":"code","source":"train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e00b07a2fceab97b6dc0416c8d8d9a8c21ff12b5"},"cell_type":"markdown","source":"Following is our new cleaned dataset on which we will be applying our machine learning models."},{"metadata":{"trusted":true,"_uuid":"8914fbb2208433ebc5a16efcc45c755809f356ac"},"cell_type":"code","source":"Y=train.Survived\ntrain=train.drop(\"Survived\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a6474308e01f911118531cc74f53dc20d26ea48"},"cell_type":"markdown","source":"Now splitting the training data into training and validation set."},{"metadata":{"trusted":true,"_uuid":"293dd8006eb88824654a8fc19bba345963428cf9"},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(train, Y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3454a210f930cd6de7ca32ed4fae344f7c2a847a"},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, log_loss\nfrom xgboost import XGBClassifier\nclassifier =  XGBClassifier(n_estimators=1000, learning_rate=0.05,n_jobs=-1)\nclassifier.fit(X_train, y_train)\npred3 = classifier.predict(X_valid)\n\nprint(classification_report(y_valid, pred3))\nprint('\\n')\nprint(confusion_matrix(y_valid, pred3))\nprint('\\n')\nprint(accuracy_score(y_valid, pred3))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5321fa00e82abf206c0920d09d04adc78f5c83be"},"cell_type":"markdown","source":"By using this model , we  obtained a good accuracy."},{"metadata":{"trusted":true,"_uuid":"76b901c71533546b24bc287c80e4d2f1bc18d759"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}