{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is the second version of this notebook, that includes visualisation and feature engineering, as well as testing different models. So far, I have achieved an accuracy of 79.425%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"You can find more information and how I slowly improved my accuracy to arrive at this code by reading my blog: https://celineterranova.com/blog/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This notebook will be divided into the following sections:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1. Load and Import\n2. Data Description\n3. Data Visualisation\n4. Feature Engineering\n5. Model, Fit and Predict","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Load and Import","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing the packages that I need:","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport pylab as plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the csv files:","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Description","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, checking how the data looks like in both files.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each row represents a passenger, for which we have various information:\n\n* PassengerId: the ID number given for each passenger in this dataset. You can see it as the row number.\n* Survived: 0 if they died, 1 if they survived.\n* Pclass: whether they were in 1st, 2nd or 3rd class.\n* Name: full name including title and sometimes maiden name.\n* Sex: male or female\n* Age: in years\n* Sibsp: number of siblings and/or spouses aboard the Titanic\n* Parch: number of parents and/or children aboard the Titanic\n* Ticket: the ticket number\n* Fare: how much they paid for their ticket\n* Cabin: the cabin number\n* Embarked: which port they embarked from. C = Cherbourg, Q = Queenstown, S = Southampton.\n\nThe testing data’s layout is exactly the same, without the “Survived” column.\n\nThere are 891 rows in the training data, meaning 891 passengers. With a very quick describe() function, I can get some statistical information about this data:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Immediately we notice something interesting in the “count” row: the number for Age is lower, which means that, for some passengers, no age is present in the table. Note that this information only took in account the column that had numbers in them, not strings (which makes sense), so we have blanks in other columns too (especially in the “cabin” column).\n\nIf we do the same work for the test data:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also have missing information in the \"age\" column, as well as in the \"fare\" one.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Visualisation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this section, I will plot some of the parameters that have an influence on the outcome (for the training data). For each feature, I will plot those who survived vs those who died.\n\nFirst I'm choosing some parameters that will be used in the plots below (optional) and I'm adding a column \"Died\" to my dataset to make life easier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'medium',\n    'legend.fontsize': 'medium',\n    'legend.loc': \"best\",\n\n}\nplot.rcParams.update(params)\n\ntrain_data['Died'] = 1 - train_data['Survived']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *3a. Sex*\n\nLet's plot the survival rate for men and women:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', stacked=True)\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, women had almost 3 times more chances to survive the Titanic than men. This correlation is so strong that if you just use this parameter to predict who dies and who survives in your test sample, you would be 76.55% correct!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# *3b. Pclass*\n\nClass also plays a role: people in first class had more chances to survive than those in second and third class. Plotted (relatively to the number of passengers in each class):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.groupby('Pclass').agg('mean')[['Survived', 'Died']].plot(kind='bar', stacked=True)\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *3c. SibSp*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.groupby('SibSp').agg('mean')[['Survived', 'Died']].plot(kind='bar', stacked=True)\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *3d. ParCh*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.groupby('Parch').agg('mean')[['Survived', 'Died']].plot(kind='bar', stacked=True)\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *3e. Fare*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist([train_data[train_data['Survived'] == 1]['Fare'], train_data[train_data['Survived'] == 0]['Fare']], bins = 30, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *3f. Age*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist([train_data[train_data['Survived'] == 1]['Age'], train_data[train_data['Survived'] == 0]['Age']], bins = 8, label = ['Survived','Dead'])\nplt.xlabel('Age')\nplt.ylabel('Number of passengers')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# *4a. Titles*\n\nFrom the name field in the dataset, I can extract the title of the person. Let's first check what titles I have in both the training and the testing data:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sing_titles = list()\nfor name in train_data[\"Name\"]:\n    title = name.split(',')[1].split('.')[0].strip()\n    if title not in sing_titles: sing_titles.append(title)\nprint(sing_titles)\nsing_test = list()\nfor name in test_data[\"Name\"]:\n    title = name.split(',')[1].split('.')[0].strip()\n    if title not in sing_test: sing_test.append(title)\nprint(sing_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I decided to divide these into 5 categories: Miss, Mrs, Mr, Noble, Crew.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function that, given a title string, checks it and replaces it with the correct title\ndef title_corr(t):\n    newt = t\n    if t == 'Mrs' or t == 'Mr' or t == 'Miss':\n        return newt\n    elif t == 'Capt' or t == 'Col' or t == 'Major' or t == 'Dr' or t == 'Rev':\n        newt = 'Crew'\n    elif t == 'Jonkheer' or t == 'Sir' or t == 'the Countess' or t == 'Lady' or t == 'Master':\n        newt = 'Noble'\n    elif t == 'Don':\n        newt = 'Mr'\n    elif t == 'Dona' or t == 'Ms' or t == 'Mme':\n        newt = 'Mrs'\n    elif t == 'Mlle':\n        newt = 'Miss'\n    else: print(\"Title not included:\", t)\n    return newt\n\n# Extract the titles from the name and put them in a list, then correct them\n# Train data\ntitles = list()\nfor name in train_data[\"Name\"]:\n    titles.append(name.split(',')[1].split('.')[0].strip())\nfor i in range(len(titles)):\n    titles[i] = title_corr(titles[i])\ntrain_data[\"Titles\"] = titles\n\n# Plotting\nplt.hist([train_data[train_data['Survived'] == 1]['Titles'], train_data[train_data['Survived'] == 0]['Titles']], label = ['Survived','Dead'])\nplt.xlabel('Title')\nplt.ylabel('Number of passengers')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.show()\n\n# Test data\ntest_titles = list()\nfor name in test_data[\"Name\"]:\n    test_titles.append(name.split(',')[1].split('.')[0].strip())\nfor i in range(len(test_titles)):\n    test_titles[i] = title_corr(test_titles[i])\ntest_data[\"Titles\"] = test_titles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mapping the titles depending on survival rate:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title_mapping = {\"Mrs\": 4, \"Miss\": 3, \"Mr\": 0, \"Noble\": 2,\"Crew\": 1}\ntrain_data['Title Map'] = train_data['Titles'].map(title_mapping)\ntest_data['Title Map'] = test_data['Titles'].map(title_mapping)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *4b. Fare Groups*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Fill the missing fares with the median:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"Fare\"] = train_data[\"Fare\"].fillna(train_data[\"Fare\"].median())\ntest_data[\"Fare\"] = test_data[\"Fare\"].fillna(test_data[\"Fare\"].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As fare is a continuous parameters, we will benefit from grouping it:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['FareGroup'] = pd.cut(train_data['Fare'],3)\nprint(train_data[['FareGroup', 'Survived']].groupby('FareGroup', as_index=False).mean().sort_values('Survived', ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Group fares into 3 categories, weighed according to the survival rate:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def group_fare(fare):\n    if fare <= 170: return 0\n    if fare > 170 and fare <= 340: return 1\n    if fare > 340: return 2\n    \n# Loops over the df and fill the Fare Group column\nfor i, row in train_data.iterrows():\n    train_data.at[i,'Fare Group'] = group_fare(row[\"Fare\"])\n# Same for test data\nfor i, row in test_data.iterrows():\n    test_data.at[i,'Fare Group'] = group_fare(row[\"Fare\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *4c. Age Groups*\n\nFirst, let's fill the missing ages using a median for a specific sex, title and class for the whole dataset:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function that returns the median age for passengers from a certain class, sex and title\ndef calc_age(df, cl, sx, tl):\n    a = df.groupby([\"Pclass\", \"Sex\", \"Titles\"])[\"Age\"].median()\n    return a[cl][sx][tl]\n\n# Getting the full dataset (more accurate for median calculation)\nage_train = train_data.copy()\nage_train.drop('PassengerId', axis=1, inplace=True)\nage_train.drop('Survived',axis=1, inplace=True)\nage_test = test_data.copy()\nage_test.drop('PassengerId', axis=1, inplace=True)\ndf = pd.concat([age_train, age_test], sort=False).reset_index(drop=True)\n\n# Fill up missing ages\nfor i, row in train_data.iterrows():\n    if pd.isna(row['Age']) :\n        newage = (calc_age(df, row[\"Pclass\"], row[\"Sex\"], row[\"Titles\"]))\n        train_data.at[i,'Age'] = newage\n    else: continue\n# Same for test data\nfor i, row in test_data.iterrows():\n    if pd.isna(row['Age']) :\n        newage = (calc_age(df, row[\"Pclass\"], row[\"Sex\"], row[\"Titles\"]))\n        test_data.at[i,'Age'] = newage\n    else: continue","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, we want to group the ages:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['AgeGroup'] = pd.cut(train_data['Age'],5)\nprint(train_data[['AgeGroup', 'Survived']].groupby('AgeGroup', as_index=False).mean().sort_values('Survived', ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will group the ages in 5 groups, weighed according to the survival rate:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def group_age(age):\n    if age <= 16: return 4\n    if age > 16 and age <= 32: return 1\n    if age > 32 and age <= 48: return 2\n    if age > 48 and age <= 64: return 3\n    if age > 64: return 0\n\n# Loops over the df and fill the Age Group column\nfor i, row in train_data.iterrows():\n    train_data.at[i,'Age Group'] = group_age(row[\"Age\"])\n    # Same for test data\nfor i, row in test_data.iterrows():\n    test_data.at[i,'Age Group'] = group_age(row[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *4d. Family*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We want to use both SibSp and ParCh into one variable:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"Family\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\ntest_data[\"Family\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *4e. Embarked*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Fill missing data for embarked feature:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna('S')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check out the survival rate for each port:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data[['Embarked', 'Survived']].groupby('Embarked', as_index=False).mean().sort_values('Survived', ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Weigh the embarked feature with the survival rate into a new column:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def embarked_rate(embarked_port):\n    if embarked_port == 'C': return 2\n    if embarked_port == 'Q': return 1\n    if embarked_port == 'S': return 0\n\nfor i, row in train_data.iterrows():\n    train_data.at[i,'Emb Rate'] = embarked_rate(row[\"Embarked\"])\nfor i, row in test_data.iterrows():\n    test_data.at[i,'Emb Rate'] = embarked_rate(row[\"Embarked\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *4f. Sex Mapping*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sex_mapping = {\"male\": 0, \"female\": 1}\ntrain_data['Sex Map'] = train_data['Sex'].map(sex_mapping)\ntest_data['Sex Map'] = test_data['Sex'].map(sex_mapping)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Model, Fit and Predict","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Choose the features that will be used:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drops some columns\ncols_to_drop = [\"SibSp\", \"Parch\", \"Name\", \"Age\", \"Fare\",  \"Embarked\", \"Cabin\", \"Ticket\", \"Sex\", \"Titles\"]\nnew_train = train_data.drop(cols_to_drop, axis=1)\nnew_test = test_data.drop(cols_to_drop, axis=1)\n\ny = train_data[\"Survived\"]\nfeatures = [\"Pclass\", \"Sex Map\", \"Family\", \"Title Map\", \"Age Group\", \"Fare Group\", \"Emb Rate\"]\nX = pd.get_dummies(new_train[features])\nX_test = pd.get_dummies(new_test[features])\n# X = new_train.drop(\"Survived\", axis=1)\n# X_test = new_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use different models to predict y:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel1.fit(X, y)\ny1_test = model1.predict(X_test)\n\nmodel2 = XGBClassifier(max_depth=3, n_estimators=1000, learning_rate=0.05)\nmodel2.fit(X, y)\ny2_test = model2.predict(X_test)\n\nmodel3 = SVC(random_state=1)\nmodel3.fit(X,y)\ny3_test = model3.predict(X_test)\n\nmodel4 = GradientBoostingClassifier(random_state=42)\nmodel4.fit(X, y)\ny4_test = model4.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate accuracy of each model:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model1_preds = cross_val_predict(model1, X, y, cv=10)\nmodel1_acc = accuracy_score(y, model1_preds)\nmodel2_preds = cross_val_predict(model2, X, y, cv=10)\nmodel2_acc = accuracy_score(y, model2_preds)\nmodel3_preds = cross_val_predict(model3, X, y, cv=10)\nmodel3_acc = accuracy_score(y, model3_preds)\nmodel4_preds = cross_val_predict(model4, X, y, cv=10)\nmodel4_acc = accuracy_score(y, model4_preds)\n\nprint(\"Random Forest Accuracy:\", model1_acc)\nprint(\"XGBoost Accuracy:\", model2_acc)\nprint(\"SVC Accuracy:\", model3_acc)\nprint(\"GB Accuracy:\", model4_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create output:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y2_test})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}