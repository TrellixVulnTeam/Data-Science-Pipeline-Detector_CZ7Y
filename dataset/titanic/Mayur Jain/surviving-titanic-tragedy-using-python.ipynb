{"cells":[{"metadata":{"_uuid":"4f34d5be876d8cae9235a56dfcd3b01c2928c98c","_cell_guid":"5e658821-72c9-480b-a9a9-b87426805929"},"cell_type":"markdown","source":"# Titanic Survival with Python\n        \n   **Objective is to develop a classification model to predict, if a passenger survives or perishes. Let's begin our understanding of the dataset followed by widely used classification algorithm.**\n\n## Importing Libraries\n\n   Let's import libraries to get started!"},{"metadata":{"_uuid":"9ca38604a158df48fb35bc6d2cfeee07feb6ae41","_cell_guid":"0debf496-b9bc-4d94-9018-ae85cf090fb3","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC,NuSVC\nfrom sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,GradientBoostingClassifier,VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import FastICA\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Dense, Dropout\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold,StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics as met\nfrom sklearn.metrics import classification_report\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae0c5d5fab21f038cd7e0c5e4262eb6a5bdb54ac","_cell_guid":"de97dd3a-ad31-47f1-9c2e-2157a88c76d8"},"cell_type":"markdown","source":"### Dataset - Train and Test Dataset. Find columns in testing and training set and Number of records available in each set.\n\nImport the train and test dataset and verify the columns available."},{"metadata":{"_uuid":"d619681381cbe5a4c9d6742b4ef986ac0969e7e4","_cell_guid":"974eb7d7-e197-47da-8be4-d46af83d9f73","trusted":true},"cell_type":"code","source":"training_set = pd.read_csv('../input/train.csv')\ntesting_set = pd.read_csv('../input/test.csv')\npID = testing_set['PassengerId']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6c52b70c2987c77b78a444eceba4f504a7e3642","_cell_guid":"f9ebe769-5f64-4b0a-a271-d8d3d3c2db44","trusted":true},"cell_type":"code","source":"print(training_set.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b5f38622fb79c8be8dd3f8e22d5de85a0bfb6c0","_cell_guid":"2113273e-1415-40cd-a3bc-e683041e120d","trusted":true},"cell_type":"code","source":"print(testing_set.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34e5aa403c09fd1455ea759064840ecdab522cfb","_cell_guid":"fcd7efe2-073b-4b39-919a-a2cb9ea88baa","trusted":true},"cell_type":"code","source":"print(training_set.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"776611031187f3fa491c4979496d8fd12bfaa6e0","_cell_guid":"1b960d93-a67f-4230-999d-a669439e9039","trusted":true},"cell_type":"code","source":"print(testing_set.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c9dd9587a79fb425068f046716330705b4f93ba","_cell_guid":"33f99a8a-4dda-4f6a-9956-434451cb74d5"},"cell_type":"markdown","source":"  # Data Exploration :\n  \n  ### 'Survived' column is the target variable which needs to be predicted and is not present in testing set.\n  "},{"metadata":{"_uuid":"e5c4c27d2ba6374b53d453b0408484b7bffbb2d8","_cell_guid":"152839fa-5b23-42bc-8af9-d117356552d6","trusted":true},"cell_type":"code","source":"training_set.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c61020d5f1971864f5a62c5d884e22f083c6fac2","_cell_guid":"13679b8d-7ace-41a7-a7c7-885053e7b3e8","trusted":true},"cell_type":"code","source":"training_set.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"026b782dd0341d5a69ebffe81ad51897875e6f57","_cell_guid":"b20dcc18-8190-4539-baca-cd76174fff33"},"cell_type":"markdown","source":"**By Using .info() command, we can notice that \"Age\" and \"Cabin\" column have missing values.**\n\n**Roughly 20 percent values in Age column is missing. We can make a reasonable impution on Age column. But Cabin column, we are missing approx 80% values. We'll drop the cabin column.**"},{"metadata":{"_uuid":"b06cef0f8c448e8f0477a3c027272ad55a471a34","_cell_guid":"70013953-f962-42b9-ac04-ab169e9c318a"},"cell_type":"markdown","source":"## Plot the Data"},{"metadata":{},"cell_type":"markdown","source":"**Performing basic visulization with the help of Seaborn.**"},{"metadata":{"_uuid":"94c5605946ba9cf14bd61e8c8b82744341e332ff","_cell_guid":"2c536144-de76-4534-ba84-7ee75e707c22","trusted":true},"cell_type":"code","source":"sns.heatmap(training_set.isnull(),yticklabels=False,cbar=False,cmap='Dark2')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5eb0a8be5d865287a0ec73da35ad30b67ed50c01","_cell_guid":"426f2dd4-8bbd-46d3-9e25-526e6ae44f6a","trusted":true},"cell_type":"code","source":"sns.heatmap(testing_set.isnull(),yticklabels=False,cbar=False,cmap='Dark2')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a38d34459f0ac03343d2565eb6e6531bc4f28d81","_cell_guid":"e6143a85-2dd6-4409-9636-e4d9f972c315","trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',data=training_set,palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The plot between Gender and Target variable, clearly suggest that more men have suffered the fate of Jack from Titanic.**"},{"metadata":{"_uuid":"ac4976ff8a4b6641ca6751550ce40b2c4b6604b6","_cell_guid":"59d55bd2-ef88-42f9-93ad-64c2eb5ae9d8","trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=training_set,palette='RdBu_r')\nplt.title(\"Gender vs Survived\")\nplt.legend(loc = 'top left')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"937a43718298d805d03321ca3a3a9d63c42d5327","_cell_guid":"09429a44-ad79-4dcd-a761-3757d8e113b3","trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Pclass',data=training_set,palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec6d963dcb3edb615e23a5d0d91191d34945f28a","_cell_guid":"210684a8-f545-410d-9a4b-0945afcb2cb5","trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Embarked',data=training_set,palette='Dark2')\nplt.legend(loc = 'top left',bbox_to_anchor=(1.2, 1.2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6044958fbe229cac999e0023eea7ecb79589d829","_cell_guid":"afef9aad-2539-4289-9087-032e3e43294b","trusted":true},"cell_type":"code","source":"sns.distplot(training_set['Age'].dropna(),kde=False,color='darkred',bins=30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f52fd33b9a672598c7d606bd0cf4a96d2435f8d","_cell_guid":"350b7632-cf82-46e0-bb03-5b24f7dda70f","trusted":true},"cell_type":"code","source":"sns.countplot(x='SibSp',data=training_set)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb212539859afedf440d82a21d20e5c33af63195","_cell_guid":"f38d6ed2-f75e-4511-ab2a-63c124eac3b0","trusted":true},"cell_type":"code","source":"training_set['Fare'].hist(color='green',bins=40,figsize=(8,4))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53e3d74d7d603843d0d9c86fd495b5bc96b8e0b3","_cell_guid":"eaf81c2a-27ef-4589-b837-8ae75c27a848"},"cell_type":"markdown","source":"## Data Cleaning\n\nFill in missing age data instead of just dropping the missing age data rows. One way to do this is by filling in the mean age of all the passengers (imputation). However, we can be smarter about this and check the average age by passenger class."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(training_set.isnull().sum(),\"\\n\")\nprint(testing_set.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Engineering - https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy**"},{"metadata":{"_uuid":"aea323eca71122fd5c5b8a00bb20fc2f963d543f","_cell_guid":"8a750d25-9dde-4b93-8b14-4f53ed875fe4","trusted":true},"cell_type":"code","source":"for dataset in [training_set,testing_set]:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n\n    #complete missing fare with median\n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n    \n#delete the cabin feature/column and others previously stated to exclude in train dataset\ndrop_column = ['PassengerId','Cabin', 'Ticket']\ntraining_set.drop(drop_column, axis=1, inplace = True)\ntesting_set.drop(drop_column, axis=1, inplace = True)\nprint(training_set.isnull().sum())\nprint(\"-\"*10)\nprint(testing_set.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in [training_set,testing_set]:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n\n    #quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n    #dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n\n    #Continuous variable bins; qcut vs cut: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\n    #Fare Bins/Buckets using qcut or frequency bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n\n    #Age Bins/Buckets using cut or value bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html\n    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n\n\n    \n#cleanup rare title names\n# #print(data1['Title'].value_counts())\n# stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n# title_names = (training_set['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n\n# #apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n# training_set['Title'] = training_set['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n# print(training_set['Title'].value_counts())\n# print(\"-\"*10)\n\n\n#preview data again\ntraining_set.info()\ntesting_set.info()\ntraining_set.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set[training_set[\"Name\"].str.contains(\"Master\")]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa688e91f771d1295fa58fe0e4a6666f94069a41","_cell_guid":"c1b2a816-d273-42b7-be23-e90e52322b9b","trusted":true},"cell_type":"code","source":"#CONVERT: convert objects to category using Label Encoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in [training_set,testing_set]:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n    #dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n\n\n#define y variable aka target/outcome\nTarget = ['Survived']\n\n#define x variables for original features aka feature selection\ntraining_set_x = ['Sex','Pclass', 'Embarked','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] #pretty name/values for charts\ntraining_set_x_calc = ['Sex_Code','Pclass', 'Embarked_Code','SibSp', 'Parch', 'Age', 'Fare'] #coded for algorithm calculation\ntraining_set_xy =  Target + training_set_x\nprint('Original X Y: ', training_set_xy, '\\n')\n\n\n#define x variables for original w/bin features to remove continuous variables\ntraining_set_x_bin = ['Sex_Code','Pclass', 'Embarked_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\ntraining_set_xy_bin = Target + training_set_x_bin\nprint('Bin X Y: ', training_set_xy_bin, '\\n')\n\n\n#define x and y variables for dummy features original\ntraining_set_dummy = pd.get_dummies(training_set[training_set_x],drop_first=True)\ntraining_set_x_dummy = training_set_dummy.columns.tolist()\ntraining_set_xy_dummy = Target + training_set_x_dummy\nprint('Dummy X Y: ', training_set_xy_dummy, '\\n')\n\ntraining_set_dummy.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9082367d562848a597b15babd7a4146896ea88c","_cell_guid":"7191fd4f-527f-4483-9fe1-c22291daaa06","trusted":true},"cell_type":"code","source":"y = training_set['Survived']\nX = training_set_dummy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_set_dummy = pd.get_dummies(testing_set[training_set_x],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = MinMaxScaler()\n#ss = StandardScaler()\ntraining_set_dummy_ss= ss.fit_transform(training_set_dummy)\ntesting_set_dummy_ss= ss.fit_transform(testing_set_dummy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pca = PCA(n_components=6)\n# X_train_pca = pca.fit_transform(training_set_dummy)\n# X_test_pca = pca.transform(testing_set_dummy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transformer = FastICA()\n# X_train_ica = transformer.fit_transform(training_set_dummy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_test_ica = transformer.transform(testing_set_dummy)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"389ab96afb7253b37029994ac551e1204640faf6","_cell_guid":"3ce94ceb-c2b0-4d1d-9295-60e8dc00da60"},"cell_type":"markdown","source":"# Building Machine learning Models :"},{"metadata":{"_uuid":"877aa5196e79723e6949658595faa7bdd17e5c0e","_cell_guid":"d1a2a225-9f8d-4fb9-a909-c7348c0d371d","trusted":true},"cell_type":"code","source":"# Models\nclassifiers = {'Gradient Boosting Classifier':GradientBoostingClassifier(),'Adaptive Boosting Classifier':AdaBoostClassifier(),'RadiusNN':RadiusNeighborsClassifier(radius=40.0),\n               'Linear Discriminant Analysis':LinearDiscriminantAnalysis(), 'GaussianNB': GaussianNB(), 'BerNB': BernoulliNB(), 'KNN': KNeighborsClassifier(),\n               'Random Forest Classifier': RandomForestClassifier(min_samples_leaf=10,min_samples_split=20,max_depth=4),'Decision Tree Classifier': DecisionTreeClassifier(),'Logistic Regression':LogisticRegression(), \"XGBoost\": xgb.XGBClassifier()}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"671fd62c0db1a400f014537b213ac04e6e90b9e6","_cell_guid":"fe9f4b4a-4cfc-485a-a381-3f4b4ddce274"},"cell_type":"markdown","source":"## Sampling Data"},{"metadata":{"_uuid":"3996611abdb3bbff66ee782b9e090d7cb08038e1","_cell_guid":"e7a0061a-ed87-41be-8348-a720059fe7da"},"cell_type":"markdown","source":"### Train test split"},{"metadata":{"_uuid":"b47e541fc4d4ba6ad8d359855a4ee0b74bd2523b","_cell_guid":"4e20cdb0-fed3-4236-b0c7-1ecf5fe51b50","trusted":true},"cell_type":"code","source":"X_training, X_validating, y_training, y_validating = train_test_split(training_set_dummy, y, test_size=0.20, random_state=11)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93a381f43c075f767639d75c02d700dbbf12c9ce","_cell_guid":"3f9a3b2f-6038-44bf-8dc0-22df19dd218d","trusted":true},"cell_type":"code","source":"base_accuracy = 0\nfor Name,classify in classifiers.items():\n    classify.fit(X_training,y_training)\n    y_predictng = classify.predict(X_validating)\n    print('Accuracy Score of '+str(Name) + \" : \" +str(met.accuracy_score(y_validating,y_predictng)))\n    if met.accuracy_score(y_validating,y_predictng) > base_accuracy:\n        predictions_test = classify.predict(testing_set_dummy)\n        base_accuracy = met.accuracy_score(y_validating,y_predictng)\n    else:\n        continue\n\n# Generate Submission File \npredicted_test_value = pd.DataFrame({ 'PassengerId': pID,\n                        'Survived': predictions_test })\npredicted_test_value.to_csv(\"PredictedTestScore.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"529aa86527160bf3bcd233315c24a506ca2dd719","_cell_guid":"a3f98741-f6f0-49d3-ad96-cb59beace7e8"},"cell_type":"markdown","source":"### Stratified KFold Sampling"},{"metadata":{"_uuid":"208d4e1d8285170633aa1fdca84e47d101c69ab4","_cell_guid":"71b94a8f-abff-447e-b995-35a498409a04","trusted":true},"cell_type":"code","source":"# skfold = StratifiedKFold(n_splits=2,random_state=42,shuffle=True)\n# for Name,classify in classifiers.items():\n#     for train_KF, test_KF in skfold.split(X,y):\n#         X_train,X_test = X.iloc[train_KF], X.iloc[test_KF]\n#         y_train,y_test = y.iloc[train_KF], y.iloc[test_KF]\n#         classify.fit(X_train,y_train)\n#         y_pred = classify.predict(X_test)\n#         print('Accuracy Score of '+str(Name) + \" : \" +str(met.accuracy_score(y_test,y_pred)))\n#         print(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b70bb3931b7481793d206cc152a9bc61c2fcb8b3","_cell_guid":"300b17d1-607e-488f-b204-d9887858b026"},"cell_type":"markdown","source":"### Stratified Shuffle Split"},{"metadata":{"_uuid":"325f62bb584c2264d9db4e4f17babb5d99480ffc","_cell_guid":"e5a572cd-9f0f-4d79-b0cc-aee00dd5694c","trusted":true},"cell_type":"code","source":"# sss = StratifiedShuffleSplit(n_splits=1,test_size=0.3,random_state=1)\n# for Name,classify in classifiers.items():\n#     for train_KF, test_KF in sss.split(X,y):\n#         X_train,X_test = X.iloc[train_KF], X.iloc[test_KF]\n#         y_train,y_test = y.iloc[train_KF], y.iloc[test_KF]\n#         classify.fit(X_train,y_train)\n#         y_pred = classify.predict(X_test)\n#         print('Accuracy Score of '+str(Name) + \" : \" +str(met.accuracy_score(y_test,y_pred)))\n#         print(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b958ecdf553e47e6f27461550d515f0584d98e9e","_cell_guid":"02dd7bea-e63f-4153-8770-5971af6a8b5d"},"cell_type":"markdown","source":"### GridSearchCV"},{"metadata":{"_uuid":"285b42ef7116ccd2bda7407716bf2e454a612947","_cell_guid":"4fe29772-f9cd-4650-94ff-4991877200c8"},"cell_type":"markdown","source":"**GridSearchCV for SVC**"},{"metadata":{"_uuid":"09c617705b101dac8dc47b7809ca78d595d30487","_cell_guid":"576ecd62-f268-4651-b97f-8950344f893b","trusted":true},"cell_type":"code","source":"# param_grid = {'C':[5000],'gamma':[0.0001]}\n# gscv = GridSearchCV(SVC(),param_grid)\n# gscv.fit(X_training,y_training)\n# predictions = gscv.predict(X_validating)\n# print(met.accuracy_score(y_validating,predictions))\n# print(gscv.best_params_)\n# print(gscv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"556f548a13fe26d41aeb9360a293ffd366313a47","_cell_guid":"b3f8b18d-9c7d-46f6-aed5-e37f6f5460e5"},"cell_type":"markdown","source":"**GridSearchCV for Gradient Boosting Classifier**"},{"metadata":{"_uuid":"92114df19d2a49f7dec55cbe9bdb7d3c638553bb","_cell_guid":"e0e6c9d0-ec07-427d-be87-0cb94e13d190","trusted":true},"cell_type":"code","source":"# param_grid = {'learning_rate':[0.1],\"n_estimators\":[40],'min_samples_leaf':[15],'min_samples_split':[45],\"max_depth\":[3],'loss': ['deviance'],\"max_features\":[\"auto\"]}\n# gbccv = GridSearchCV(GradientBoostingClassifier(),param_grid)\n# gbccv.fit(X_training,y_training)\n# predictions_train = gbccv.predict(X_validating)\n# print(met.accuracy_score(y_validating,predictions_train))\n# print(gbccv.best_params_)\n# print(gbccv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**GridSearchCV for XGBoost**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# param_grid = {'learning_rate':[0.1],'gamma':[0.4],\"n_estimator\":[10],\"max_depth\":[3]}\n# xgbcv = GridSearchCV(xgb.XGBClassifier(),param_grid)\n# xgbcv.fit(X_training,y_training)\n# predictions_train = xgbcv.predict(X_validating)\n# print(met.accuracy_score(y_validating,predictions_train))\n# print(xgbcv.best_params_)\n# print(xgbcv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**GridSearchCV for Random Forest Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# param_grid = {'min_samples_leaf':[10],'min_samples_split':[20],\"max_depth\":[5]}\n# xgbcv = GridSearchCV(RandomForestClassifier(),param_grid)\n# xgbcv.fit(X_training,y_training)\n# predictions_train = xgbcv.predict(X_validating)\n# print(met.accuracy_score(y_validating,predictions_train))\n# print(xgbcv.best_params_)\n# print(xgbcv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cbr = xgb.XGBClassifier()#logging_level='Silent'\ncbr.fit(X_training,y_training)\npredictions_train = cbr.predict(X_validating)\nprint(met.accuracy_score(y_validating,predictions_train))\n#print(QDA.best_params_)\n#print(QDA.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = GradientBoostingClassifier()\n#clf2 = CatBoostClassifier(logging_level='Silent')\nclf3 = LinearDiscriminantAnalysis()\nclf4 = LogisticRegression()\nclf5 = xgb.XGBClassifier()\nexTreeClf = VotingClassifier(estimators=[('svc', clf1), ('gbc', clf3),('lr',clf4),('lda',clf5)])\nexTreeClf.fit(X_training,y_training)\n# y_pred = exTreeClf.predict(X_validating)\n# print(met.accuracy_score(y_validating,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# predictions_test = exTreeClf.predict(testing_set_dummy)\n# predicted_test_value = pd.DataFrame({ 'PassengerId': pID,\n#                         'Survived': predictions_test })\n# predicted_test_value.to_csv(\"PredictedTestScore.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Deep Learning Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(Dense(32, input_dim=10, activation='selu',kernel_initializer='uniform'))\n# model.add(Dropout(rate=0.4))\n# model.add(Dense(16, activation='selu'))\n# model.add(Dropout(rate=0.4))\n# model.add(Dense(8, activation='selu'))\n# model.add(Dropout(rate=0.4))\n# model.add(Dense(1, activation='sigmoid'))\n# opt = keras.optimizers.Adadelta()\n# model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import keras\n# keras.optimizers.\n# keras.activations.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #fit the keras model on the dataset\n# model.fit(X_training, y_training, epochs=500, batch_size=50,validation_data=(X_validating,y_validating),verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred = model.predict_classes(X_validating)\n# met.accuracy_score(y_validating,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted_test = []\n# for x in model.predict_classes(testing_set_dummy):\n#     predicted_test.append(x[:][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted_test_value = pd.DataFrame({ 'PassengerId': pID,\n#                         'Survived': predicted_test })\n# predicted_test_value.to_csv(\"PredictedTestScore.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pseudo-Labeling Technique - https://towardsdatascience.com/simple-explanation-of-semi-supervised-learning-and-pseudo-labeling-c2218e8c769b"},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgboost = CatBoostClassifier()\n# xgboost.fit(training_set_dummy,y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_index_with_80p = list(np.argwhere(xgboost.predict_proba(testing_set_dummy)>0.75)[:,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred_with_80p = pd.Series(list(np.argwhere(xgboost.predict_proba(testing_set_dummy)>0.75)[:,1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for idx in test_index_with_80p:\n#     training_set_dummy = training_set_dummy.append(testing_set_dummy.iloc[idx],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y = y.append(y_pred_with_80p,ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lda = CatBoostClassifier()\n# lda.fit(training_set_dummy,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_test = []\nfor x in exTreeClf.predict(testing_set_dummy):\n    predicted_test.append(x)\npredicted_test_value = pd.DataFrame({ 'PassengerId': pID,\n                        'Survived': predicted_test })\npredicted_test_value.to_csv(\"PredictedTestScore.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance using Permutation Importance - https://www.kaggle.com/dansbecker/permutation-importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# perm = PermutationImportance(xgboost, random_state=1).fit(X_validating, y_validating)\n# eli5.show_weights(perm, feature_names = X_validating.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training_set_dummy.drop(columns=[\"Fare\",\"SibSp\",\"IsAlone\",\"Embarked_Q\"],inplace=True)\n# testing_set_dummy.drop(columns=[\"Fare\",\"SibSp\",\"IsAlone\",\"Embarked_Q\"],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# exTreeClf.fit(training_set_dummy,y)\n# predicted_test = []\n# for x in exTreeClf.predict(testing_set_dummy):\n#     predicted_test.append(x)\n# predicted_test_value = pd.DataFrame({ 'PassengerId': pID,\n#                         'Survived': predicted_test })\n# predicted_test_value.to_csv(\"PredictedTestScore.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","name":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}