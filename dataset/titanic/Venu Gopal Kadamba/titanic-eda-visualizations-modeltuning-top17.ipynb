{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, plot_confusion_matrix\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATA_PATH = \"../input/titanic/train.csv\"\nTEST_DATA_PATH = \"../input/titanic/test.csv\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(TRAIN_DATA_PATH)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring the Data","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for duplicacy\nlen(data[\"PassengerId\"].unique()) == data.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that is no duplicacy present in the data. Let us drop the PassengerId, Name, Ticket from the data.","metadata":{}},{"cell_type":"code","source":"data.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\"],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.isnull().sum())\ndata.isnull().sum().plot(kind = \"bar\")\nplt.title(\"NaN values Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Univariate Analysis","metadata":{}},{"cell_type":"code","source":"# Checking the data if it is balanced or not\n\ncounts = data[\"Survived\"].value_counts()\ndiag_cols = [\"Not Survived\", \"Survived\"]\ndiag_counts = [counts[0], counts[1]]\n\nnd = (diag_counts[0] / sum(diag_counts))*100\nd = (diag_counts[1] / sum(diag_counts)) * 100\n\nprint(f\"Survived: {d}%\")\nprint(f\"Not Survived: {nd}%\")\n\nprint()\n\nplt.figure(figsize = (10, 8))\nsns.barplot(x = diag_cols, y = diag_counts)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Pclass\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Pclass\"].value_counts().sort_values().plot(kind = \"bar\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(\"Pclass\")[\"Survived\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we an see that the survivors mostly belonged to class 1 which is obvious. The 1st class people were given more priority than the 2nd and 3rd class people.","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Sex\"].value_counts().plot(kind = \"bar\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(\"Sex\")[\"Survived\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we an see that the survivors were mostly feamle which is obvious. Let us change the encoding for the Sex feature. Let us replace it with the values generated using Target Guided Encoding.","metadata":{}},{"cell_type":"code","source":"sex_map = {\"female\":1, \"male\":0}\ndata[\"Sex\"] = data[\"Sex\"].map(sex_map).values.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of missing values in Age: {data['Age'].isnull().sum()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (11, 7))\nsns.histplot(data[\"Age\"], kde=True, bins = 50)\nplt.title(\"Age Distribution\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using mean imputation let us fill the missing values in the age feature.","metadata":{}},{"cell_type":"code","source":"data[\"Age\"].fillna(data[\"Age\"].mean(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (11, 7))\nsns.histplot(data[\"Age\"], kde=True, bins = 50)\nplt.title(\"Age Distribution after Random Sample Inputation\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of missing values in Age: {data['Age'].isnull().sum()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"SibSp\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"SibSp\"].value_counts().plot(kind = \"bar\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(\"SibSp\")[\"Survived\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Parch\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Parch\"].value_counts().plot(kind = \"bar\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (11, 7))\nsns.histplot(data[\"Fare\"], kde=True, bins = 50)\nplt.title(\"Fare Distribution\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Fare\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of missing values in Cabin: {data['Cabin'].isnull().sum()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns = [\"Cabin\"], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Embarked\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Embarked\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(\"Embarked\")[\"Survived\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embark_map = {\n    \"S\":0,\n    \"Q\":1,\n    \"C\":2\n}\n\ndata[\"Embarked\"] = data[\"Embarked\"].map(embark_map).values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"continuous_data_cols = [\"Age\", \"Fare\"]\nplt.figure(figsize = (10,10))\nsns.pairplot(data[continuous_data_cols+[\"Survived\"]], hue=\"Survived\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cleaning the Test Data","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(TEST_DATA_PATH)\n\ntest_data.drop(columns = [\"Name\", \"Cabin\", \"Ticket\"], inplace = True)\n\nprint(\"Missing Values\")\nprint(test_data.isnull().sum())\n\ntest_data[\"Age\"].fillna(test_data[\"Age\"].mean(), inplace = True)\n\ntest_data['Fare'].fillna(test_data[\"Fare\"].mean() ,inplace = True)\n\ntest_data[\"Sex\"] = test_data[\"Sex\"].map(sex_map)\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].map(embark_map)\n\n\nprint()\nprint(\"Missing Values\")\nprint(test_data.isnull().sum())\n\ntest_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking for best Baseline Model","metadata":{}},{"cell_type":"code","source":"all_columns = list(data.columns)\nX = data[all_columns[1:]]\ny = data[\"Survived\"]\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_models = {\n    \"xgb_model\":XGBClassifier(eval_metric = \"logloss\",random_state=18),\n    \"rf_model\":RandomForestClassifier(random_state = 18),\n    \"logistic_model\":LogisticRegression(),\n    \"svm_model\":SVC(),\n    \"ada_model\":AdaBoostClassifier(RandomForestClassifier(random_state = 18))\n}\n\nfor model_name in all_models:\n    print(f\"Model Name: {model_name}\")\n    cv_score = cross_val_score(all_models[model_name],X, y, cv = 5)\n    print(cv_score)\n    print(f\"Mean Score: {np.mean(cv_score)}\")\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)\nprint(f\"Train Data: {X_train.shape}. {y_train.shape}\")\nprint(f\"Test Data: {X_test.shape}. {y_test.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM Model","metadata":{}},{"cell_type":"code","source":"svm_model = SVC()\nsvm_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = svm_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(svm_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = svm_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(svm_model, X_train, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning for SVM Model","metadata":{}},{"cell_type":"code","source":"param_grid = {'C': [0.1, 1, 10, 100, 1000], \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf']} \n  \ngrid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 0)\ngrid.fit(X_train, y_train)\n\nprint(\"Best Params:\",grid.best_params_)\nprint(\"Best Estimator\", grid.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_model = SVC(C=1000, gamma=0.01)\nsvm_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = svm_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(svm_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = svm_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(svm_model, X_train, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RandomForest Model","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state = 18)\nrf_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = rf_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(rf_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = rf_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(rf_model, X_train, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning for Random Forest Model","metadata":{}},{"cell_type":"code","source":"n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrf = RandomForestClassifier(random_state = 24)\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=24, n_jobs = -1)\nrf_random.fit(X_train, y_train)\n\nprint(\"Best Params:\",rf_random.best_params_)\nprint(\"Best Estimator\", rf_random.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(bootstrap=False, max_depth=80, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=600, random_state=24)\nrf_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = rf_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(rf_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = rf_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(rf_model, X_train, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost Model","metadata":{}},{"cell_type":"code","source":"xgb_model = XGBClassifier(random_state = 18)\nxgb_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions =xgb_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(xgb_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions =xgb_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(xgb_model, X_train, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adaboost Model","metadata":{}},{"cell_type":"code","source":"ada_model = AdaBoostClassifier()\nada_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = ada_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(ada_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = ada_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(ada_model, X_train, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Voting Classifier (RandomForest + XGBoost + SVM)","metadata":{}},{"cell_type":"code","source":"voting_model = VotingClassifier(\n    [\n        (\"rf_model\", RandomForestClassifier(bootstrap=False, max_depth=80, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=600, random_state=24)),\n        (\"xgb_model\", XGBClassifier(eval_metric=\"logloss\", random_state = 18)),\n        (\"svm_model\", SVC(C=1000, gamma=0.01))\n    ]\n)\n\nvoting_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = voting_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(voting_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = voting_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(voting_model, X_train, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Voting Classifier (RandomForest + XGBoost + AdaBoost)","metadata":{}},{"cell_type":"code","source":"voting_model = VotingClassifier(\n    [\n        (\"rf_model\", RandomForestClassifier(bootstrap=False, max_depth=80, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=600, random_state=24)),\n        (\"xgb_model\", XGBClassifier(eval_metric=\"logloss\",random_state = 18)),\n        (\"ada_model\", AdaBoostClassifier())\n    ]\n)\n\nvoting_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = voting_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(voting_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = voting_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(voting_model, X_train, y_train)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_voting_model = VotingClassifier(\n    [\n        (\"rf_model\", RandomForestClassifier(bootstrap=False, max_depth=80, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=600, random_state=24)),\n        (\"xgb_model\", XGBClassifier(eval_metric=\"logloss\", random_state = 18)),\n        (\"svm_model\", SVC(C=1000, gamma=0.01))\n    ]\n)\n\nfinal_voting_model.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_X = test_data.iloc[:, 1:]\ntest_X = scaler.transform(test_X)\ntest_predictions = final_voting_model.predict(test_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"PassengerId\":test_data[\"PassengerId\"].values,\n    \"Survived\":test_predictions\n})\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}