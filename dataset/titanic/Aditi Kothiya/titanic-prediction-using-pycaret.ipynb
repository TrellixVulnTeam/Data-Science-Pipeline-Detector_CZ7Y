{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Co-learning Lounge](https://s3.ap-south-1.amazonaws.com/townscript-production/images/2545d2c7-a6e8-486e-97e6-737c42cef670.jpg)\nThanks to the Co-learning Lounge for pushing to create learning content on [PyCaret](https://pycaret.org/) with Kaggle playground problem.\n\nYou can find most updated and comprehensive learning material in their community.\n\nJoin and follow the [Co-learning Lounge](https://linktr.ee/colearninglounge) for more.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Data Dictionary**:\n* survival - Survival (0 = No; 1 = Yes)\n* class - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n* name - Name\n* sex - Sex\n* age - Age\n* sibsp - Number of Siblings/Spouses Aboard\n* parch - Number of Parents/Children Aboard\n* ticket - Ticket Number\n* fare - Passenger Fare\n* cabin - Cabin\n* embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Libararies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quickly let us get into the installation and build a perfect model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install pycaret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Setup**\n\n* Setup() performs inferences about the data and creates the transformation pipeline to prepare the data for modeling and deployment. \n* Initializing setup() function performs some basic preprocessing tasks like ignoring the IDs and Date Columns, imputing the missing values, encoding the categorical variables, and splitting the dataset into the train-test split, data imbalance, feature selection, binning, etc. for the rest of the modeling steps. When you run the setup function, it will first confirm the data types, and then if you press enter, it will create an environment for data preprocessing.\n* It takes 2 mendatory parameter Dataframe and name of the target column\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret import classification\nclassification_setup = classification.setup(data=train,target='Survived', ignore_features = ['Ticket', 'Name', 'PassengerId'], silent = True, session_id=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, now the necessary preprocessing is done, let’s create a classification model. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Compare Models**\n\n* Compare_models function train all the models which are available in library using stratified cross validation, this function will return score grid of all model across k-fold(default=10).\n* Scoring matrics used are Accuracy, AUC, Recall, Precision, F1, Kappa and MCC. Mean and standard deviation of the scores across the folds are also returned.\n* You can blacklist(omit certain models from the comparison) and whiltelist(un only certain models for the comparison) the model, passig model ID’s as a list of strings\neg. whitelist = compare_models(whitelist = ['dt','rf','xgboost'])\nblacklist = compare_models(blacklist = ['catboost', 'svm'])\n* Best model return as per the sort parameter(default=Accuracy) passed.\n* Also we can select N top models passing n_select(default=1) parameter","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classification.compare_models()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import *\nmodels()\ncompare_models(whitelist = models(type='ensemble').index.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This returns you pandas dataframe with all ready-to-use models available in the library.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Just a functional execution call, and it will compare all the classification models with few seconds and display the sorted score grid.\n\nNote: It seems that the Ridge classifier gives higher accuracy than the rest classifier.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Create Model**\n\n* Let’s create an individual model that displays different evaluation matric using 10 k-fold with mean and std.\n* create_model function takes just the one parameter – the model abbreviation as a string.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_classifier = classification.create_model('lightgbm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Above score grid, shows the result of the model at each iteration and provide mean and std of it.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Hyperparameter Tuning**\n\n* Depending on the model evaluation metric(s) we are interested in pycaret helps us to straightaway zoom in on the top-performing model which we can further tune using the hyper-parameters.\n* tune_model() function tune the hyperparameters of a model and it takes one parameter model abbreviation string (same as we used for creating model)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001],\n          'n_estimators':[100,250,500,750,1000,1250,1500,1750],\n          'max_depth': np.random.randint(1, (len(train.columns)*.85),20),\n          'max_features': np.random.randint(1, len(train.columns),20),\n          'min_samples_split':[2,4,6,8,10,20,40,60,100], \n          'min_samples_leaf':[1,3,5,7,9],\n          'criterion': [\"gini\", \"entropy\"]}\n\ntune_lgb = classification.tune_model(lgb_classifier, custom_grid = params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune the model\nparams = {'alpha':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\ntune_ridge = classification.tune_model(create_model('ridge'), custom_grid = params, n_iter=50, fold=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In PyCaret, we can create bagging, boosting, blending, and stacking ensemble models with just one line of code.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Ensemble Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble boosting\nbagging = classification.ensemble_model(tune_lgb, method= 'Bagging')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Blend Models**\n\nCombining different machine learning models and use a majority vote or the average predicted probabilities in case of classification to predict the final outcome.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import blend_models\n# blending all models\nblend_all = blend_models(method='hard')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Stack Models**\n\nStacking is an ensembling method that uses meta-learning. The idea behind stacking is to build a meta-model that generates the final prediction using the prediction of multiple base estimators.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create individual models for stacking\nridge_cls = classification.create_model('ridge')\nextre_tr = classification.create_model('et')\nlgb = classification.create_model('lightgbm')\ncat_cls = classification.create_model('catboost')\nlg_cls = classification.create_model('lr')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import stack_models\n# stacking models\nstacker = stack_models(estimator_list = [ridge_cls, extre_tr, lgb, cat_cls, lg_cls],method='hard')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot Model**\nPycaret also evaluate your model performance as easy as you build the model with different plots","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"interpret_model(tune_lgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import *\n# plotting a model\nplot_model(tune_lgb,plot = 'pr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting a model\nplot_model(tune_lgb,plot = 'confusion_matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation Curve\nplot_model(tune_lgb, plot = 'vc')`","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AUC Curve\nplot_model(tune_lgb, plot = 'auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# error Curve\nplot_model(tune_lgb, plot = 'error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = predict_model(tune_lgb, data=test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": y_pred['Label']\n    })\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}