{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ⚖️ Machine Learning Model Evaluation Metrics","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://geab.eu/wp-content/uploads/2019/12/evaluation-1-800x395.jpg\" style=\"margin-left:130px\">","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The metrics that you choose to evaluate your machine learning algorithms are very important.\nChoice of metrics influences how the performance of machine learning algorithms is measured and compared.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Overview \nIn this kernel, i tryed to combine the most useful evaluation metrics in classification and regerssion in Python with scikit-learn.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"toc\"></a>\n<div style=\"background: #f9f9f9 none repeat scroll 0 0;border: 1px solid #aaa;display: table;font-size: 95%;margin-bottom: 1em;padding: 20px;width: 600px;\">\n<h1>Contents</h1>\n<ul style=\"font-weight: 700;text-align: left;list-style: outside none none !important;\">\n<li style=\"list-style: outside none none !important;font-size:17px\"><a href=\"#cl\">1 Classification</a></li>\n      <ul style=\"font-weight: 700;text-align: left;list-style: outside none none !important;\">\n            <li style=\"list-style: outside none none !important;\"><a href=\"#ac\">1.1 Accuracy</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#pr\">1.2 Precision</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#rr\">1.3 Recall ROC</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#f1\">1.4 F1Score</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#au\">1.5 AUC- ROC curve</a></li>\n          <li style=\"list-style: outside none none !important;\"><a href=\"#ll\">1.6 logistic loss</a></li>\n      </ul>\n<li style=\"list-style: outside none none !important;font-size:17px\"><a href=\"#reg\">2 Regression</a></li>\n      <ul style=\"font-weight: 700;text-align: left;list-style: outside none none !important;\">\n            <li style=\"list-style: outside none none !important;\"><a href=\"#RMSE\">2.1 Mean squared error MSE and Root mean squared error RMSE</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#MAE\">2.2 Mean absolute error MAE and Root Mean absolute error MAE</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#RMSLE\">2.3 Mean Squared Log Error and Root Mean Squared Log Error RMSLE</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#r-2\">2.4 R Squared and Adjusted R Squared</a></li>\n      </ul>\n    \n<li style=\"list-style: outside none none !important;font-size:17px\"><a href=\"#cv\">3 CrossValidation :</a></li>\n      <ul style=\"font-weight: 700;text-align: left;list-style: outside none none !important;\">\n            <li style=\"list-style: outside none none !important;\"><a href=\"#kf\">3.1 KFold</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#skf\">3.2 StratifiedKFold</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#lo\">3.3 LOOCV</a></li>\n            <li style=\"list-style: outside none none !important;\"><a href=\"#rc\">3.4 Repeated cv</a></li>\n      </ul>    \n    \n\n</ul>\n</div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h3 style=\"color:red\">If you enjoyed this work or you found it helpful , an upvotes would be very much appreciated :-) </h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Date preprocessing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" !pip install git+https://github.com/fastai/fastai@2e1ccb58121dc648751e2109fc0fbf6925aa8887 2>/dev/null 1>/dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.structured import train_cats,proc_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/house-prices-advanced-regression-techniques/train.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/titanic/train.csv\")\ntrain2 = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats(train)\ntrain_cats(train2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Age=train.Age.fillna(train.Age.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_c,y_c,_=proc_df(train,\"Survived\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_r,y_r,_=proc_df(train2,\"SalePrice\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#####  train test split 70% train 30% for test ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/1600/1*-8_kogvwmL1H6ooN1A1tsQ.png\" style=\"width:50%;\">","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_c, y_c, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestClassifier(n_jobs=-1)\nm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification <a class=\"anchor\" id=\"cl\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>[](http://)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Confusion matrix <a class=\"anchor\" id=\"cm\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://i.ytimg.com/vi/AOIkPnKu0YA/maxresdefault.jpg\" />","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, m.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy <a class=\"anchor\" id=\"ac\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Accuracy in classification problems is the number of correct predictions made by the model over all kinds predictions made.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/1600/1*5XuZ_86Rfce3qyLt7XMlhw.png\"/>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"m.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test,m.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When to use Accuracy:\n\nAccuracy is a good measure when the target variable classes in the data are nearly balanced. example Survived(60% yes - 40% no)  \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Precision <a class=\"anchor\" id=\"pr\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Precision is defined as the number of true positives divided by the number of true positives plus the number of false positives.\nPrecision is about being precise","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/640/1*KhlD7Js9leo0B0zfsIfAIA.png\" />","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Recall <a class=\"anchor\" id=\"rr\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"When it is actually the positive result, how often does it predict correctly","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/640/1*a8hkMGVHg3fl4kDmSIDY_A.png\" />","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## F1 score <a class=\"anchor\" id=\"f1\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"F1 score - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, <b style=\"color:red\">especially if you have an uneven class distribution</b>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/1600/1*UJxVqLnbSj42eRhasKeLOA.png\">","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, m.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Auc - Roc curve <a class=\"anchor\" id=\"au\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.\n\nThe ROC curve is plotted with TPR against the FPR .","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/1600/1*pk05QGzoWhCgRiiFbz-oKQ.png\">","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ROC curves are frequently used to show in a graphical way the connection/trade-off between clinical sensitivity and specificity for every possible cut-off for a test or a combination of tests.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y_test, m.predict_proba(X_test)[:,1])\n\nplt.plot(fpr, tpr, label='ROC curve')\nplt.plot([0, 1], [0, 1], 'k--', label='Random guess')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.xlim([-0.02, 1])\nplt.ylim([0, 1.02])\nplt.legend(loc=\"lower right\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic loss <a class=\"anchor\" id=\"ll\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Log loss, aka logistic loss or cross-entropy loss.\n\nThis is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true labels given a probabilistic classifier’s predictions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/1600/0*2ekvLNkZ0_cKcPtv\">","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_loss(y_test,m.predict_proba(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression <a class=\"anchor\" id=\"reg\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Mean squared error MSE and Root mean squared error RMSE <a class=\"anchor\" id=\"RMSE\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The mean squared error tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img style=\"height:100px\" src='https://cdn-images-1.medium.com/max/1600/1*3VJyfU1qBqoHwaDJm3KAKA.gif' />","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_r=np.log(y_r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_r, y_r, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_jobs=-1)\nm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=m.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(mean_squared_error(y_test,y_pred),3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sqrt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(sqrt(mean_squared_error(y_test,y_pred)),3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mean absolute error MAE and Root Mean absolute error MAE <a class=\"anchor\" id=\"MAE\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"MAE is the average of the absolute difference between the predicted values and observed value","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/640/1*iLabSjpdwd1TaZyKdDKYBA.png\">","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(mean_absolute_error(y_test,y_pred),3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(sqrt(mean_absolute_error(y_test,y_pred)),3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSE has the benefit of penalizing large errors more so can be more appropriate in some cases, for example, if being off by 10 is more than twice as bad as being off by 5. But if being off by 10 is just twice as bad as being off by 5, then MAE is more appropriate.<a href=\"https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d\">MAE vs RMSE</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Mean Squared Log Error and Root Mean Squared Log Error RMSLE <a class=\"anchor\" id=\"RMSLE\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img style=\"height:100px\" src=\"https://miro.medium.com/max/1200/0*AUzyQ1rc6mpQVYfn\" >","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(mean_squared_log_error( y_test, y_pred ),4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(np.sqrt(mean_squared_log_error( y_test, y_pred )),4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R Squared and Adjusted R Squared <a class=\"anchor\" id=\"r-2\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"R-squared is the “percent of variance explained” by the model.  That is, R-squared is the fraction by which the variance of the errors is less than the variance of the dependent variable.<br>\nJust like R², adjusted R² also shows how well terms fit a curve or line but adjusts for the number of terms in a model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/313/1*RyIMMQWd_X0Gpa0rrXzr9Q.png\" />","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2=r2_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n =len(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_adj =1- (1-r2)*(n-1)/(n-(13+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_adj","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"R Squared & Adjusted R Squared are often used for explanatory purposes and explains how well your selected independent variable(s) explain the variability in your dependent variable(s)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h3><a href=\"https://towardsdatascience.com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-1-regrression-metrics-3606e25beae0\">How to select the Right Evaluation Metric</a></h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Cross validation <a class=\"anchor\" id=\"cv\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## KFold <a class=\"anchor\" id=\"kf\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In K Fold cross validation, the data is divided into k subsets. Now the holdout method is repeated k times, such that each time, one of the k subsets is used as the test set/ validation set and the other k-1 subsets are put together to form a training set. The error estimation is averaged over all k trials to get total effectiveness of our model. As can be seen, every data point gets to be in a validation set exactly once, and gets to be in a training set k-1 times. This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/1600/1*me-aJdjnt3ivwAurYkB7PA.png\">","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold,StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fold = 10\nfolds = KFold(n_splits=n_fold, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_proba = np.zeros((df_c.shape[0], 2))\naccuracy = []\n    \nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(df_c, y_c)):\n        X_train, X_valid = df_c.iloc[train_idx], df_c.iloc[valid_idx]\n        y_train, y_valid = y_c[train_idx], y_c[valid_idx]\n        \n        model = RandomForestClassifier()\n        model.fit(X_train, y_train)\n\n        y_pred_valid = model.predict(X_valid)\n        accuracy.append(accuracy_score(y_valid,y_pred_valid))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## StratifiedKFold <a class=\"anchor\" id=\"skf\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" a slight variation in the K Fold cross validation technique is made, such that each fold contains approximately the same percentage of samples of each target class as the complete set, or in case of prediction problems, the mean response value is approximately equal in all the folds. This variation is also known as Stratified K Fold.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fold = 10\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = []\n    \nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(df_c, y_c)):\n        X_train, X_valid = df_c.iloc[train_idx], df_c.iloc[valid_idx]\n        y_train, y_valid = y_c[train_idx], y_c[valid_idx]\n        \n        model = RandomForestClassifier()\n        model.fit(X_train, y_train)\n\n        y_pred_valid = model.predict(X_valid)\n        accuracy.append(accuracy_score(y_valid,y_pred_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LOOCV <a class=\"anchor\" id=\"lo\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It is a special case of Kfold when K is equal to the number of samples in our dataset. This means that will iterate through every sample in our dataset each time using k-1 object as train samples and 1 object as test set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn-images-1.medium.com/max/880/1*vcWDRHJKkYN75bCibPefYg.png\">","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loocv = LeaveOneOut()\nm = RandomForestClassifier(n_jobs=-1)\nresults = cross_val_score(m, df_c, y_c, cv=loocv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Repeated cv  <a class=\"anchor\" id=\"rc\"></a>\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Another variation on k-fold cross validation is to create a random split of the data like the train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross validation.\n\nThis has the speed of using a train/test split and the reduction in variance in the estimated performance of k-fold cross validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import ShuffleSplit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = ShuffleSplit(n_splits=10, test_size=0.3)\nresults = cross_val_score(m, df_c, y_c, cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Thank you for reading \n\n<a href=\"#toc\"><img src= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Circle-icons-arrow-up.svg/1200px-Circle-icons-arrow-up.svg.png\" style=\"width:20px;hight:20px;float:left\" >Back to the table of contents</a>[](http://)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}