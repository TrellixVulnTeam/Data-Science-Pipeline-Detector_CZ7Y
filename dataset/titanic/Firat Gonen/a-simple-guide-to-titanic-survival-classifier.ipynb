{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Beginner's Guide to Machine Learning using Titanic Data Set\n\n![](https://api.time.com/wp-content/uploads/2015/10/titanic-cracker.jpg)\n","metadata":{}},{"cell_type":"markdown","source":"# This notebook is not aimed for a very high score but rather to explain the simplicity of things and methods used. ","metadata":{}},{"cell_type":"markdown","source":"# Importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter","metadata":{"_uuid":"16aa258bc051fa5cafe4b37182fd2d629d8c9e33","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the 3 files from the Titanic Data Set","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_test  = pd.read_csv('../input/test.csv')\ndf_sample= pd.read_csv('../input/gender_submission.csv')","metadata":{"_uuid":"24aa6ba62f00534540c2288e2d0795853d8262ef","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A simple Outlier detection function to find them","metadata":{}},{"cell_type":"code","source":"def detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   ","metadata":{"_uuid":"d24a5d7f608955d87eb215cb7e32ff2cbaf11070","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying the outliers to Age, SibSp, Parch, and Fare columns","metadata":{}},{"cell_type":"code","source":"Outliers_to_drop = detect_outliers(df_train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\ndf_train = df_train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","metadata":{"_uuid":"23c67279f0695fe0aa665170d105efd13741480c","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gotta work a little bit in the Name column, \n# Creating a Title column based on the titles found in Name column, mapping them into numbers and finally removing the Name column","metadata":{}},{"cell_type":"code","source":"dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in df_train[\"Name\"]]\ndf_train[\"Title\"] = pd.Series(dataset_title)\ndf_train[\"Title\"] = df_train[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndf_train[\"Title\"] = df_train[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndf_train[\"Title\"] = df_train[\"Title\"].astype(int)\ndf_train.drop(labels = [\"Name\"], axis = 1, inplace = True)","metadata":{"_uuid":"72d100bb45618f705d8e7a1cf823d9c56cdab1ee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# we need to impute age column, basically fill in the blanks, I'm filling the blanks based on their Priority Class means","metadata":{}},{"cell_type":"code","source":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age","metadata":{"_uuid":"2a9f15751333b269017d0d9788f349a8e1f083da","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# doing the same thing to the fare column","metadata":{}},{"cell_type":"code","source":"def impute_fare(cols):\n    Fare = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Fare):\n\n        if Pclass == 1:\n            return 84\n\n        elif Pclass == 2:\n            return 20\n\n        else:\n            return 13\n\n    else:\n        return Fare","metadata":{"_uuid":"20398abbb3d7ab965a027840d5e5588a647afa17","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# applying these functions to both columns","metadata":{}},{"cell_type":"code","source":"df_train['Age'] = df_train[['Age','Pclass']].apply(impute_age,axis=1)","metadata":{"_uuid":"5c12e661a777ac738c13e5497d129a2bd45eb5c0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# now the gender column, getting rid of the categorical strings and making new dummy columns","metadata":{}},{"cell_type":"code","source":"sex = pd.get_dummies(df_train['Sex'],drop_first=True)\nembark = pd.get_dummies(df_train['Embarked'],drop_first=True)\ndf_train = pd.concat([df_train,sex,embark],axis=1)","metadata":{"_uuid":"ad76d77838ddf1181f71e8e2a8cbbb33dfe5ffab","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making several new features based on the size of the family","metadata":{}},{"cell_type":"code","source":"df_train[\"Family\"] = df_train[\"SibSp\"] + df_train[\"Parch\"] + 1\ndf_train['Single'] = df_train['Family'].map(lambda s: 1 if s == 1 else 0)\ndf_train['SmallF'] = df_train['Family'].map(lambda s: 1 if  s == 2  else 0)\ndf_train['MedF']   = df_train['Family'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndf_train['LargeF'] = df_train['Family'].map(lambda s: 1 if s >= 5 else 0)\ndf_train['Senior'] = df_train['Age'].map(lambda s:1 if s>60 else 0)","metadata":{"_uuid":"a0857e525db973e6d1f041930fc68acc24662353","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Appying the previous stuff to the test as well","metadata":{}},{"cell_type":"code","source":"dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in df_test[\"Name\"]]\ndf_test[\"Title\"] = pd.Series(dataset_title)\ndf_test[\"Title\"] = df_test[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndf_test[\"Title\"] = df_test[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndf_test[\"Title\"] = df_test[\"Title\"].astype(int)\ndf_test.drop(labels = [\"Name\"], axis = 1, inplace = True)","metadata":{"_uuid":"6abcd29bac20e2078513142fbb14fc2e3a06d478","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['Age'] = df_test[['Age','Pclass']].apply(impute_age,axis=1)\nsex = pd.get_dummies(df_test['Sex'],drop_first=True)\nembark = pd.get_dummies(df_test['Embarked'],drop_first=True)\ndf_test = pd.concat([df_test,sex,embark],axis=1)\n\ndf_test['Fare'].fillna(value=df_test['Fare'].median(),inplace=True)","metadata":{"_uuid":"e7246b02c02a6757067fe4cf12c73589eadc0036","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['Fare'] = df_test[['Fare','Pclass']].apply(impute_fare,axis=1)","metadata":{"_uuid":"183b7fca3e8ac4033c0a98c3cf5751424c687609","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[\"Fare\"] = df_test[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"_uuid":"db1029e334f941b9146101b6bb98a56843fbbac5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[\"Family\"] = df_test[\"SibSp\"] + df_test[\"Parch\"] + 1","metadata":{"_uuid":"d8f9013b7f195e3cda144926f0057c4eb3f75200","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['Single'] = df_test['Family'].map(lambda s: 1 if s == 1 else 0)\ndf_test['SmallF'] = df_test['Family'].map(lambda s: 1 if  s == 2  else 0)\ndf_test['MedF']   = df_test['Family'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndf_test['LargeF'] = df_test['Family'].map(lambda s: 1 if s >= 5 else 0)\ndf_test['Senior'] = df_test['Age'].map(lambda s:1 if s>60 else 0)","metadata":{"_uuid":"8453897a0e6f723a96103680255e91d79ae36353","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_person(passenger):\n    age,sex = passenger\n    return 'child' if age < 16 else sex","metadata":{"_uuid":"7dc809cd15ff208b2163891bb2d06e557708f2e1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Person'] = df_train[['Age','Sex']].apply(get_person,axis=1)\ndf_test['Person']  = df_test[['Age','Sex']].apply(get_person,axis=1)\n\nperson_dummies_train  = pd.get_dummies(df_train['Person'])\nperson_dummies_train.columns = ['Child','Female','Male']\nperson_dummies_train.drop(['Male'], axis=1, inplace=True)\n\nperson_dummies_test  = pd.get_dummies(df_test['Person'])\nperson_dummies_test.columns = ['Child','Female','Male']\nperson_dummies_test.drop(['Male'], axis=1, inplace=True)\n\ndf_train = df_train.join(person_dummies_train)\ndf_test  = df_test.join(person_dummies_test)\n\ndf_train.drop(['Person'],axis=1,inplace=True)\ndf_test.drop(['Person'],axis=1,inplace=True)","metadata":{"_uuid":"22d8d90f1ed3b9ae27c368ee3349674285fa6d91","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.drop('male',axis=1,inplace=True)\ndf_test.drop('male',axis=1,inplace=True)","metadata":{"_uuid":"555df2d6f275a7191d4094c31ac488c214d50f1e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.drop(['Cabin','Ticket'],axis = 1, inplace= True)\ndf_test.drop(['Ticket','Cabin'],axis = 1, inplace= True)","metadata":{"_uuid":"d8a46a17459e10b5ed89fce1a50f9c7f80ec7cfe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.drop(['Sex','Embarked'],axis=1,inplace=True)\ndf_test.drop(['Sex','Embarked'],axis=1,inplace=True)","metadata":{"_uuid":"0faa70d4aad76c1a601390551eb9e3456a83f7ad","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"_uuid":"5d459651b74f5317e96e82351575c437223bd69a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"_uuid":"62a7cdbd7130b97ce5e4f1950e5da250d42ac9aa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()\nprint('.............................................')\ndf_test.info()","metadata":{"_uuid":"2d9510233757192aad631e3d093ff314053e2537","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df_train.drop('Survived',axis=1), \n                                                    df_train['Survived'], test_size=0.15, \n                                                    random_state=101)","metadata":{"_uuid":"50342aac506a4a91d94e3b07b4f14d24b9407eb6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree (only to show actual trees)","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import plot_tree\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train,y_train);\n\nplt.figure(figsize=(18,18))\nplot_tree(dt,filled=True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBOOST","metadata":{"_uuid":"303fb0dec5747dfd8e1431d4a538f5bff5e9f444"}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nXGB = XGBClassifier(max_depth=4,learning_rate=0.005,n_estimators=500,n_jobs=-1,min_child_weight=2)\nXGB.fit(X_train,y_train)","metadata":{"_uuid":"357b1249eca1f40629c57d832199ac88a67387cc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pd.DataFrame(XGB.predict(df_test))\ny_pred['Survived'] = y_pred[0]\ny_pred.drop(0,axis=1,inplace=True)\ny_pred['PassengerId'] = df_test['PassengerId']\ny_pred_xgb = y_pred\n\ny_pred.to_csv('titanic_pred_xgb.csv',index=False)","metadata":{"_uuid":"3e7fd34205074308b5fe3b50f6928fe57e456979","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{"_uuid":"529f95756053ec94c924d428903c926a325de4a4"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nScaler1 = StandardScaler()\nScaler2 = StandardScaler()\nX_train_scaled = Scaler1.fit_transform(X_train)\ndf_test_scaled  = Scaler2.fit_transform(df_test)","metadata":{"_uuid":"6c4124fbfb4ddb8b2eddcaf2c127550eeffa0933","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogmodel = LogisticRegression(C=10).fit(X_train,y_train)\n\ny_pred = pd.DataFrame(logmodel.predict(df_test))\n\ny_pred['Survived'] = y_pred[0]\ny_pred.drop(0,axis=1,inplace=True)\ny_pred['PassengerId'] = df_test['PassengerId']\ny_pred_lr = y_pred\n\ny_pred.to_csv('titanic_pred_logistic.csv',index=False)","metadata":{"_uuid":"384f28560ee54d421aa4344ce4cfbb84c5342770","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{"_uuid":"447ca2f319ab04fbe5712234f1044ea7dd0f8486"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier(n_estimators=500,max_depth=9,min_samples_split=3)\nRFC.fit(X_train,y_train)","metadata":{"_uuid":"d9b0bd4d9c1e6319bfb30306d4cff1cb81f2ce86","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pd.DataFrame(RFC.predict(df_test))\n\ny_pred['Survived'] = y_pred[0]\ny_pred.drop(0,axis=1,inplace=True)\ny_pred['PassengerId'] = df_test['PassengerId']\ny_pred_rf = y_pred\ny_pred.to_csv('titanic_pred_rfc.csv',index=False)","metadata":{"_uuid":"d0ae5096c275b9880246863ef52b9774e65fd28c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Light GBM","metadata":{"_uuid":"b7a83217364c4fd34a0bcc0c7485ee51ef314d9f"}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nlgb = LGBMClassifier(learning_rate=0.01,max_depth=5,n_estimators=500,num_leaves=3).fit(X_train,y_train)","metadata":{"_uuid":"d9f68fb22f808bd6c3f38dd2286bda01988c356e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pd.DataFrame(lgb.predict(df_test))\n\ny_pred['Survived'] = y_pred[0]\ny_pred.drop(0,axis=1,inplace=True)\ny_pred['PassengerId'] = df_test['PassengerId']\ny_pred_lgb = y_pred\ny_pred.to_csv('titanic_pred_lgb.csv',index=False)","metadata":{"_uuid":"93b9e955cefe8b1142c2e4e986a2e73191cf8965","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# General Scores","metadata":{}},{"cell_type":"code","source":"print(\"XGB train score:             \",round(XGB.score(X_train,y_train),2),     \"   XGB test score:           \",round(XGB.score(X_test,y_test),2))\nprint(\"Log-Reg. train score:        \",round(logmodel.score(X_train,y_train),2),\"   Log-Reg. test score:      \",round(logmodel.score(X_test,y_test),2))\nprint(\"Random Forest's train score: \",round(RFC.score(X_train,y_train),2),     \"   Random Forest test score: \",round(RFC.score(X_test,y_test),2))\nprint(\"LGBM train score:            \",round(lgb.score(X_train,y_train),2),     \"   LGB Model test score:     \",round(lgb.score(X_test,y_test),2))","metadata":{"_uuid":"da4b376fe7c3446cae9e9625430b8961fd66db07","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"y_valid_xgb = XGB.predict(X_test)\ny_valid_log = logmodel.predict(X_test)\ny_valid_rfc = RFC.predict(X_test)\ny_valid_lgb = lgb.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROC","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\n\nfpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_test, y_valid_xgb)\nroc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n\nfpr_log, tpr_log, thresholds_log = roc_curve(y_test, y_valid_log)\nroc_auc_log = auc(fpr_log, tpr_log)\n\nfpr_rfc, tpr_rfc, thresholds_rfc = roc_curve(y_test, y_valid_rfc)\nroc_auc_rfc = auc(fpr_rfc, tpr_rfc)\n\nfpr_lgb, tpr_lgb, thresholds_lgb = roc_curve(y_test, y_valid_lgb)\nroc_auc_lgb = auc(fpr_lgb, tpr_lgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrices for 4 models","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_valid_xgb), annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix for XGB'); \nax.xaxis.set_ticklabels(['Dead', 'Survived']); ax.yaxis.set_ticklabels(['Dead', 'Survived']);\nplt.show()\n\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_valid_log), annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix for Log Reg'); \nax.xaxis.set_ticklabels(['Dead', 'Survived']); ax.yaxis.set_ticklabels(['Dead', 'Survived']);\nplt.show()\n\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_valid_rfc), annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix for Random Forest'); \nax.xaxis.set_ticklabels(['Dead', 'Survived']); ax.yaxis.set_ticklabels(['Dead', 'Survived']);\nplt.show()\n\nax= plt.subplot()\nsns.heatmap(confusion_matrix(y_test, y_valid_lgb), annot=True, ax = ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix for LGBM'); \nax.xaxis.set_ticklabels(['Dead', 'Survived']); ax.yaxis.set_ticklabels(['Dead', 'Survived']);\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set('talk', 'whitegrid', 'dark', font_scale=1.2,rc={\"lines.linewidth\": 2, 'grid.linestyle': '--'})\nlw = 3\nplt.figure(figsize=(12, 8))\n\nsns.despine()\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n\nplt.plot(fpr_xgb, tpr_xgb, lw=lw, label='XGB   ROC curve (AUC = %0.2f)' % roc_auc_xgb);\nplt.plot(fpr_log, tpr_log, lw=lw, label='LR      ROC curve (AUC = %0.2f)' % roc_auc_log);\nplt.plot(fpr_rfc, tpr_rfc, lw=lw, label='RF      ROC curve (AUC = %0.2f)' % roc_auc_rfc);\nplt.plot(fpr_lgb, tpr_lgb, lw=lw, label='LGBM ROC curve (AUC = %0.2f)' % roc_auc_lgb);\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([-0.1, 1.1])\nplt.ylim([-0.1, 1.1])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('All Models ROC')\nplt.legend(loc=\"lower right\");\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blend","metadata":{"_uuid":"9ae15d114b5ae32cfb8edf8aafa7637b537d70c4"}},{"cell_type":"code","source":"y_pred_final = y_pred\ny_pred_final['Survived'] = round(  0.25 * y_pred_lgb['Survived'] \n                                 + 0.25 * y_pred_rf['Survived'] \n                                 + 0.25 * y_pred_xgb['Survived'] \n                                 + 0.25 * y_pred_lr['Survived'] )\n\ny_pred_final['PassengerId'] = df_test['PassengerId']\ny_pred_final['Survived'] = y_pred_final['Survived'].astype(int)\ny_pred_final.to_csv('titanic_pred_final.csv',index=False)","metadata":{"_uuid":"e992e5bf722f7df0d432ee7a97c49770f30c267f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_final['Survived'].value_counts()","metadata":{"_uuid":"194e4463bfbec23be2bbaa38612ea76c4429aa27","trusted":true},"execution_count":null,"outputs":[]}]}