{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic Tutorial for Beginners[Accuracy: 0.789]-\n\n\n* This is my first tutorial. Do point out my mistakes in comment section.\n* Do upvote if you find this notebook interesting.\n* I have uploaded my second tutorial on this problem statement with better accuracy(https://www.kaggle.com/rishabhdhyani4/titanic-tutorial2). Do check it."},{"metadata":{},"cell_type":"markdown","source":" This is default first cell in any kaggle kernel. They import **NumPy** and **Pandas** libraries and it also lists the available Kernel files.** NumPy** is the fundamental package for scientific computing with Python. **Pandas** is the most popular python library that is used for data analysis."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Data Loading\n\n\nOur first step is to extract train and test data. We will be extracting data using pandas function read_csv. Specify the location to the dataset and import them."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading data\ndf_train=pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test=pd.read_csv('/kaggle/input/titanic/test.csv')\ndf_test_copy=df_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Have a first look at train data\nprint(df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By using df_train.shape we get to know that train data has 891 rows and 12 columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, lets explore first five data from training set.\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got 12 features in our training data. From https://www.kaggle.com/c/titanic/data, we have:\n\n* Survival = Survival\n* Pclass = Ticket class\n* Sex = Sex\n* Age = Age in years\n* Sibsp = # of siblings / spouses aboard the Titanic\n* Parch = # of parents / children aboard the Titanic\n* Ticket = Ticket number\n* Fare = Passenger fare\n* Cabin = Cabin number\n* Embarked = Port of Embarkation\n\nQualitative Features (Categorical) : PassengerId , Pclass , Survived , Sex , Ticket , Cabin , Embarked.\n\nQuantitative Features (Numerical) : SibSp , Parch , Age , Fare.\n\nIt is obvious from the problem statement that we have to predict **Survival** feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use describe function to calculate count,mean,max and other for numerical feature.\ndf_train.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The feature survived contain binary data which can also be seen from its max(1) and min(0) value.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Our next step is to examine NULL values.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Have a look for possible missing values\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We see that Age, Cabin and Embarked feature have NULL values.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Have a first look at test data\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Have a look at train and test columns\nprint('Train columns:', df_train.columns.tolist())\nprint('Test columns:', df_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks OK, the only additional column in train is 'Survived', which is our target variable, i.e. the one we want to actually predict in the test dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's look at the figures and Understand the Survival Ratio\ndf_train.Survived.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We observe that less people survived.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To get better understanding of count of people who survived, we will plot it.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load our plotting libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Survived',data=df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, out of 891 examples only 342 (38%) survived and rest all died."},{"metadata":{},"cell_type":"markdown","source":"# Feature Examining-"},{"metadata":{},"cell_type":"markdown","source":"## ** Pclass**\n Come, let's examine Survival based on Pclass."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Pclass',data=df_train,hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**On examining the chart above, wer can clearly say that people belonging to third class died in large numbers.**"},{"metadata":{},"cell_type":"markdown","source":"##  **Sex**\n\nCome, let's examine Survival based on gender."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Sex',data=df_train,hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Sex' , y='Age' , data=df_train , hue='Survived' , kind='violin' , palette=['r','g'] , split=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**On examining the chart above, we can clearly say that male are more likely to die in comparision to female.**"},{"metadata":{},"cell_type":"markdown","source":"## **Age**\n\nCome, let's examine Survival based on gender."},{"metadata":{},"cell_type":"markdown","source":"**We have noticed earlier that column Age has some null values. So. first we will complete the Age column and then we will analyze it.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(df_train.Age , shade=True , color='r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fill the Age with it's Median, and that is because, for a dataset with great Outliers, it is advisable to fill the Null values with median.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To fill the missing values, we will calculate median of age with respect to Pclass.\ndf_train.groupby('Pclass').median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we will create a function to fill missing age values. This function is used to fill the age according to Pclass.\ndef fill_age(cols):\n    \n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass == 1:\n            return 37\n        \n        elif Pclass == 2:\n            return 29\n        \n        else:\n            return 24\n        \n    else:\n        \n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Age'] = df_train[['Age','Pclass']].apply(fill_age,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.Age.count())  # Null values filled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x='Sex',y='Age' , col='Pclass', data=df_train , hue='Survived' , kind = 'box', palette=['r','g'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Understanding Box Plot :\n\n# The bottom line indicates the min value of Age.\n# The upper line indicates the max value.\n# The middle line of the box is the median or the 50% percentile.\n# The side lines of the box are the 25 and 75 percentiles respectively.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Fare**\n\nCome, let's examine Survival based on Fare."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,30))\nsns.factorplot(x='Embarked' , y ='Fare' , kind='bar', data=df_train , hue='Survived' , palette=['r','g'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.boxplot(x='Embarked',y='Fare',data=df_train,hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We observe that people who paid more are more likely to survive.**"},{"metadata":{},"cell_type":"markdown","source":"## **Embarked**\n\nCome, let's examine Survival based on Embarked."},{"metadata":{},"cell_type":"markdown","source":"**We have noticed earlier that column Embarked has some null values. So. first we will complete this column and then we will analyze it.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The best way to fill it would be by most occured value\ndf_train['Embarked'].fillna(df_train['Embarked'].mode()[0] ,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.Embarked.count() # filled the values with Mode.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Cabin**\n\nCome, let's examine Survival based on Embarked."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Since Cabin has so many missing value, we will remove that column.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop('Cabin',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x='Embarked' , y='Pclass' , data=df_train , hue='Survived' , palette=['r','g'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that those who embarked at C with First Class ticket had a good chance of Survival. Whereas for S, it seems that all classes had nearly equal probability of Survival. And for Q, third Class seems to have Survived and Died with similar probabilities.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# None of the columns are empty.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **SibSp**\n\nNow lets analyze SibSp column."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=df_train,x='SibSp',hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[['SibSp','Survived']].groupby('SibSp').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It seems that there individuals having 1 or 2 siblings/spouses had the highest Probability of Survival, followed by individuals who were Alone.**"},{"metadata":{},"cell_type":"markdown","source":"## **Parch**\n\nNow lets analyze Parch column."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[['Parch','Survived']].groupby('Parch').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It seems that individuals with 1,2 or 3 family members had a greater Probability of Survival, followed by individuals who were Alone.**"},{"metadata":{},"cell_type":"markdown","source":"**Now let us perform some feature engineering to get informative and valuable attributes.**"},{"metadata":{},"cell_type":"markdown","source":"# **Feature Engineering:**"},{"metadata":{},"cell_type":"markdown","source":"**Now let us create an attribute 'Alone' so that we could know whether the passenger is travelling alone or not.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Alone'] = 0\ndf_train.loc[(df_train['SibSp']==0) & (df_train['Parch']==0) , 'Alone'] = 1\n\ndf_test['Alone'] = 0\ndf_test.loc[(df_test['SibSp']==0) & (df_test['Parch']==0) , 'Alone'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*  Now we are going to drop features which are not contributing much.\n* Names, PassengerId and Ticket Number doesn't help in finding Probability of Survival.\n* We have created Alone feature and therefore I'll be Dropping SibSp and Parch."},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_features = ['PassengerId' , 'Name' , 'SibSp' , 'Parch' , 'Ticket' ]\n\ndf_train.drop(drop_features , axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have a few Null values in Test (Age , Fare) , let's fill it up.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['Fare'].fillna(df_test['Fare'].median() , inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.groupby('Pclass').median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_ages(cols):\n    \n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass == 1:\n            return 42\n        \n        elif Pclass == 2:\n            return 26.5\n        \n        else:\n            return 24\n        \n    else:\n        \n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['Age'] = df_test[['Age','Pclass']].apply(fill_ages,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_featuress = ['PassengerId' , 'Name' , 'SibSp' , 'Parch' , 'Ticket','Cabin' ]\n\ndf_test.drop(drop_featuress , axis=1 , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets convert categorical feature into numerical value.\n\n* Sex Attribute has (Male/Female) , which will be mapped to 0/1.\n* Divide Age into 5 categories and Map them with 0/1/2/3/4.\n* Divide Fare into 4 categories and Map them to 0/1/2/3.\n* Embarked Attribute has (S/C/Q) , which will be mapped to 0/1/2."},{"metadata":{"trusted":true},"cell_type":"code","source":"def mapping(frame):\n    \n    frame['Sex'] = frame.Sex.map({'female': 0 ,  'male': 1}).astype(int)\n    \n    \n    frame['Embarked'] = frame.Embarked.map({'S' : 0 , 'C': 1 , 'Q':2}).astype(int)\n    \n    \n    \n    frame.loc[frame.Age <= 16 , 'Age'] = 0\n    frame.loc[(frame.Age >16) & (frame.Age<=32) , 'Age'] = 1\n    frame.loc[(frame.Age >32) & (frame.Age<=48) , 'Age'] = 2\n    frame.loc[(frame.Age >48) & (frame.Age<=64) , 'Age'] = 3\n    frame.loc[(frame.Age >64) & (frame.Age<=80) , 'Age'] = 4\n    \n    \n    frame.loc[(frame.Fare <= 7.91) , 'Fare'] = 0\n    frame.loc[(frame.Fare > 7.91) & (frame.Fare <= 14.454) , 'Fare'] = 1\n    frame.loc[(frame.Fare > 14.454) & (frame.Fare <= 31) , 'Fare'] = 2\n    frame.loc[(frame.Fare > 31) , 'Fare'] = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping(df_train)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping(df_test)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Now, it's right time to choose best model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing some algorithms from sklearn.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into test and train set.\nx_train,x_test,y_train,y_test=train_test_split(df_train.drop('Survived',axis=1),df_train.Survived,test_size=0.20,random_state=66)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [LogisticRegression(),RandomForestClassifier(),\n        DecisionTreeClassifier()]\n\nmodel_names=['LogisticRegression','RandomForestClassifier','DecisionTree']\n\naccuracy = []\n\nfor model in range(len(models)):\n    clf = models[model]\n    clf.fit(x_train,y_train)\n    pred = clf.predict(x_test)\n    accuracy.append(accuracy_score(pred , y_test))\n    \ncompare = pd.DataFrame({'Algorithm' : model_names , 'Accuracy' : accuracy})\ncompare","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We get highest accuracy for DecisionTreeClassifier**"},{"metadata":{},"cell_type":"markdown","source":"**Well, DecisionTree did a great job there, with the highest accuracy[82.6%]**\n"},{"metadata":{},"cell_type":"markdown","source":"**Now lets try to tune parameter**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"params_dict={'criterion':['gini','entropy'],'max_depth':[5.21,5.22,5.23,5.24,5.25,5.26,5.27,5.28,5.29,5.3]}\nclf_dt=GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=params_dict,scoring='accuracy', cv=5)\nclf_dt.fit(x_train,y_train)\npred=clf_dt.predict(x_test)\nprint(accuracy_score(pred,y_test))\nprint(clf_dt.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predio = clf_dt.predict(df_test)\n\nd = {'PassengerId' : df_test_copy.PassengerId , 'Survived' : predio}\nanswer = pd.DataFrame(d)\n# Generate CSV file based on DecisionTree Classifier\nanswer.to_csv('predio.csv' , index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thank you\n\nGuys,do put your query in comment section and if you like the implementation method, do upvote it. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}