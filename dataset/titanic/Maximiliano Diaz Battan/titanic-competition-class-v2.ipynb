{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> - | Notebook resume</div>\n\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nHello Kagglers, I just wanted to share with you another implementation of a trainer class like the one I did in my other Titanic notebook <a href=\"https://www.kaggle.com/code/maxdiazbattan/titanic-top-5-competition-class-v1-blending\">[link]</a>, It came to me when I was studying Pytorch and using Tez (Pytorch trainer), I wanted to do something similar. For this update I modified how the trainer class takes the models, for which I created a nested class with all the different models. I really like the final result. Greetings to all! </p>\n","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> - | Table of contents</div>\n\n* [1-Libraries](#section-one)\n* [2-Data loading](#section-two)\n* [3-Folds creation](#section-three)\n* [4-Exploratory data analysis (EDA)](#section-four)\n* [5-Feature engineering](#section-five)\n* [6-Feature selecion](#section-six)\n* [7-Modeling](#section-seven)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> 1 | Libraries</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn import model_selection, preprocessing, pipeline, metrics, impute, compose\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-20T11:19:27.274135Z","iopub.execute_input":"2022-02-20T11:19:27.274804Z","iopub.status.idle":"2022-02-20T11:19:28.608722Z","shell.execute_reply.started":"2022-02-20T11:19:27.274696Z","shell.execute_reply":"2022-02-20T11:19:28.607756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.610485Z","iopub.execute_input":"2022-02-20T11:19:28.610897Z","iopub.status.idle":"2022-02-20T11:19:28.615187Z","shell.execute_reply.started":"2022-02-20T11:19:28.610856Z","shell.execute_reply":"2022-02-20T11:19:28.614203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> 2 | Data loading</div>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\nsubmission = pd.read_csv('../input/titanic/gender_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.617036Z","iopub.execute_input":"2022-02-20T11:19:28.617326Z","iopub.status.idle":"2022-02-20T11:19:28.654479Z","shell.execute_reply.started":"2022-02-20T11:19:28.617298Z","shell.execute_reply":"2022-02-20T11:19:28.653734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> 3 | Folds creation</div>\n\n<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nUsually always it's recommended split the data in folds first </p>\n","metadata":{}},{"cell_type":"code","source":"train.Survived.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.655983Z","iopub.execute_input":"2022-02-20T11:19:28.656459Z","iopub.status.idle":"2022-02-20T11:19:28.674771Z","shell.execute_reply.started":"2022-02-20T11:19:28.656426Z","shell.execute_reply":"2022-02-20T11:19:28.67401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nBecause it's an imbalance problem I'm going to use stratified k fold</p>","metadata":{}},{"cell_type":"code","source":"kf = model_selection.StratifiedKFold(n_splits=5) \ntrain['kfold'] = -1\ntest['kfold'] = -1\ndef kfold (df):\n    df = df.copy()\n    # Shuffling the data\n    df = df.sample(frac=1.0, random_state=0).reset_index(drop=True)\n    for fold, (train_idx, test_idx) in enumerate(kf.split(X = df, y=df.Survived)):\n        df.loc[test_idx, 'kfold'] = fold\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.676176Z","iopub.execute_input":"2022-02-20T11:19:28.676467Z","iopub.status.idle":"2022-02-20T11:19:28.68535Z","shell.execute_reply.started":"2022-02-20T11:19:28.676439Z","shell.execute_reply":"2022-02-20T11:19:28.684232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = kfold(train)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.686726Z","iopub.execute_input":"2022-02-20T11:19:28.687013Z","iopub.status.idle":"2022-02-20T11:19:28.708204Z","shell.execute_reply.started":"2022-02-20T11:19:28.686985Z","shell.execute_reply":"2022-02-20T11:19:28.707234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nFor a better analysis I'm going to concat the 2 dataframes</p>","metadata":{}},{"cell_type":"code","source":"combined_df = pd.concat([train,test], axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.709288Z","iopub.execute_input":"2022-02-20T11:19:28.709706Z","iopub.status.idle":"2022-02-20T11:19:28.71925Z","shell.execute_reply.started":"2022-02-20T11:19:28.709676Z","shell.execute_reply":"2022-02-20T11:19:28.718483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> 4 | Exploratory data analysis (EDA)</div>","metadata":{}},{"cell_type":"code","source":"combined_df.describe().T.style.bar(subset=['mean'], color='#205ff2')\\\n                            .background_gradient(subset=['std'], cmap='Reds')\\\n                            .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.720441Z","iopub.execute_input":"2022-02-20T11:19:28.720933Z","iopub.status.idle":"2022-02-20T11:19:28.801419Z","shell.execute_reply.started":"2022-02-20T11:19:28.7209Z","shell.execute_reply":"2022-02-20T11:19:28.800405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categoric_features = [feature for feature in train.columns if train[feature].dtype =='O']\nnumeric_features = [feature for feature in train.columns if feature not in categoric_features+['kfold']]","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.804845Z","iopub.execute_input":"2022-02-20T11:19:28.805282Z","iopub.status.idle":"2022-02-20T11:19:28.812209Z","shell.execute_reply.started":"2022-02-20T11:19:28.805235Z","shell.execute_reply":"2022-02-20T11:19:28.810977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nChecking the categories length</p>","metadata":{}},{"cell_type":"code","source":"{feature: len(train[feature].unique()) for feature in train.select_dtypes('object')}","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.814352Z","iopub.execute_input":"2022-02-20T11:19:28.814714Z","iopub.status.idle":"2022-02-20T11:19:28.829827Z","shell.execute_reply.started":"2022-02-20T11:19:28.81468Z","shell.execute_reply":"2022-02-20T11:19:28.829028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nBesides of this categories, we have also Pclass</p>","metadata":{}},{"cell_type":"code","source":"sns.set_style ('darkgrid')\nsns.palplot(sns.color_palette('rainbow'))\nsns.set_palette('rainbow')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.830903Z","iopub.execute_input":"2022-02-20T11:19:28.831307Z","iopub.status.idle":"2022-02-20T11:19:28.936139Z","shell.execute_reply.started":"2022-02-20T11:19:28.831278Z","shell.execute_reply":"2022-02-20T11:19:28.93545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure (figsize = (20,15))\nfor i, feature in enumerate (numeric_features):\n    plt.subplot (4,2, i*1 + 1 )\n    sns.histplot (data = train, x = train[feature], hue='Survived')","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:28.937148Z","iopub.execute_input":"2022-02-20T11:19:28.937551Z","iopub.status.idle":"2022-02-20T11:19:32.1979Z","shell.execute_reply.started":"2022-02-20T11:19:28.937521Z","shell.execute_reply":"2022-02-20T11:19:32.196821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"border-radius:5px; font-size:15px; font-family:verdana; line-height: 1.7em\">\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px \">   \n<b> Insights: </b> We can see how almost half of the first class people survived, as opposed to the third class where less than a third did. Traveling alone gives almost a 50% chance of survival. Age is a bit right skew, and Fare much more, candidate for a log transformation.</p>","metadata":{}},{"cell_type":"code","source":"plt.figure (figsize = (20,15))\nfor i, feature in enumerate (numeric_features):\n    plt.subplot (4,2, i*1 + 1 )\n    sns.boxplot (data = train, x = train[feature])","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:32.199613Z","iopub.execute_input":"2022-02-20T11:19:32.200291Z","iopub.status.idle":"2022-02-20T11:19:33.484782Z","shell.execute_reply.started":"2022-02-20T11:19:32.200244Z","shell.execute_reply":"2022-02-20T11:19:33.483676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"border-radius:5px; font-size:15px; font-family:verdana; line-height: 1.7em\">\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \n<b> Insights: </b> There is some outliers in the data in the columns Age, Sibsp, Parch, and Fare.</p>","metadata":{}},{"cell_type":"code","source":"missing = (combined_df.isna().mean() * 100).round(2).sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:33.486227Z","iopub.execute_input":"2022-02-20T11:19:33.48658Z","iopub.status.idle":"2022-02-20T11:19:33.494927Z","shell.execute_reply.started":"2022-02-20T11:19:33.486547Z","shell.execute_reply":"2022-02-20T11:19:33.493903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:33.496217Z","iopub.execute_input":"2022-02-20T11:19:33.496501Z","iopub.status.idle":"2022-02-20T11:19:33.511556Z","shell.execute_reply.started":"2022-02-20T11:19:33.496473Z","shell.execute_reply":"2022-02-20T11:19:33.510565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.barplot(x = missing.index, y = missing.values, data=missing, edgecolor='black',linewidth=2)\nplt.ylabel('% of Missing' ,weight='bold', size=13)\nplt.title('Missing data',weight='bold', size=14);","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:33.512732Z","iopub.execute_input":"2022-02-20T11:19:33.513163Z","iopub.status.idle":"2022-02-20T11:19:33.788163Z","shell.execute_reply.started":"2022-02-20T11:19:33.51312Z","shell.execute_reply":"2022-02-20T11:19:33.787024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"border-radius:5px; font-size:15px; font-family:verdana; line-height: 1.7em\">\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; border: \">   \n<b> Insights: </b> Cabin it's the feature with most missing values, almost 78% of the data it's missing. </p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x = train[\"Survived\"], hue = \"Sex\", data=train, edgecolor='black',linewidth=2)\nplt.ylabel('Number of people' ,weight='bold', size=13)\nplt.xlabel('Survived' ,weight='bold', size=13)\nplt.title('Survival count by Gender',weight='bold', size=14);","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:33.78975Z","iopub.execute_input":"2022-02-20T11:19:33.790164Z","iopub.status.idle":"2022-02-20T11:19:33.989927Z","shell.execute_reply.started":"2022-02-20T11:19:33.790119Z","shell.execute_reply":"2022-02-20T11:19:33.988749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure (figsize = (12,6))\nsns.barplot(x = 'Sex', y ='Survived', data = train, edgecolor='black',linewidth=2);\nplt.ylabel('Survival Probability' ,weight='bold', size=13)\nplt.xlabel('Sex' ,weight='bold', size=13)\nplt.title('Survival Probability by Gender',weight='bold', size=14);","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:33.991155Z","iopub.execute_input":"2022-02-20T11:19:33.991434Z","iopub.status.idle":"2022-02-20T11:19:34.247197Z","shell.execute_reply.started":"2022-02-20T11:19:33.991407Z","shell.execute_reply":"2022-02-20T11:19:34.24612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"border-radius:5px; font-size:15px; font-family:verdana; line-height: 1.7em\">\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \n<b> Insights: </b> By far women are more likely to survive. </p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x = train[\"Survived\"], hue = \"Pclass\", data=train, edgecolor='black',linewidth=2)\nplt.ylabel('Number of people',weight='bold', size=13)\nplt.title('Survival count by Passenger class',weight='bold', size=14);","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:34.248507Z","iopub.execute_input":"2022-02-20T11:19:34.248849Z","iopub.status.idle":"2022-02-20T11:19:34.647116Z","shell.execute_reply.started":"2022-02-20T11:19:34.248818Z","shell.execute_reply":"2022-02-20T11:19:34.646171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"border-radius:5px; font-size:15px; font-family:verdana; line-height: 1.7em\">\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \n<b> Insights: </b> Rich people also has a greater opportunity to survive. </p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x = train[\"Survived\"], hue = \"SibSp\", data=train, edgecolor='black',linewidth=2)\nplt.ylabel('Number of people',weight='bold', size=13)\nplt.title('Survival count by sibiling and spouses',weight='bold', size=14);","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:34.648224Z","iopub.execute_input":"2022-02-20T11:19:34.648478Z","iopub.status.idle":"2022-02-20T11:19:34.940156Z","shell.execute_reply.started":"2022-02-20T11:19:34.648453Z","shell.execute_reply":"2022-02-20T11:19:34.939172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x = train[\"Survived\"], hue = \"Parch\", data=train, edgecolor='black',linewidth=2)\nplt.xlabel('Survived',weight='bold', size=13)\nplt.ylabel('Number of people',weight='bold', size=13)\nplt.title('Survival count by Parch',weight='bold', size=14);","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:34.941447Z","iopub.execute_input":"2022-02-20T11:19:34.941778Z","iopub.status.idle":"2022-02-20T11:19:35.212575Z","shell.execute_reply.started":"2022-02-20T11:19:34.941746Z","shell.execute_reply":"2022-02-20T11:19:35.211563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.swarmplot(data=train, x=(train['SibSp'] + train['Parch']), y=train['Fare'], hue=train['Pclass'])\nplt.xlabel('Family Size',weight='bold', size=13)\nplt.ylabel('Fare amount',weight='bold', size=13)\nplt.title('Survival by ',weight='bold', size=14);","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:35.213964Z","iopub.execute_input":"2022-02-20T11:19:35.214255Z","iopub.status.idle":"2022-02-20T11:19:41.550911Z","shell.execute_reply.started":"2022-02-20T11:19:35.214227Z","shell.execute_reply":"2022-02-20T11:19:41.549923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"border-radius:5px; font-size:15px; font-family:verdana; line-height: 1.7em\">\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \n<b> Insights: </b> Travel alone or just with one Sibsp or Patch gives the highest chance to survive. This may also be due to the fact that the smaller families are the ones with more first- or second-class people. </p>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.boxplot(x = combined_df[\"Pclass\"], y = combined_df[\"Age\"], data = combined_df)\nplt.xlabel('Pclass',weight='bold', size=13)\nplt.ylabel('Age',weight='bold', size=13)\nplt.title('Age by Passenger class',weight='bold', size=14);","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:41.552197Z","iopub.execute_input":"2022-02-20T11:19:41.552491Z","iopub.status.idle":"2022-02-20T11:19:41.787965Z","shell.execute_reply.started":"2022-02-20T11:19:41.552462Z","shell.execute_reply":"2022-02-20T11:19:41.78718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"border-radius:5px; font-size:15px; font-family:verdana; line-height: 1.7em\">\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \n<b> Insights: </b> The \"oldest\" people are the richest. </p>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> 5 | Feature engineering </div>","metadata":{}},{"cell_type":"code","source":"def preprocessing_inputs (df):\n    df = df.copy()\n    \n    # Feature Engineering:\n    \n    # Name\n    # Extracting the Name feature and creating a new feature just with the title \n    df['Title'] = df['Name'].apply(lambda x: x.split('.')[0]).apply(lambda x : x.split(',')[1])\n    \n    # Age\n    # Creating a flag if the Age value is null\n    df['AgeFlag'] = df['Age'].map(lambda x: 1 if pd.isnull(x) else 0)  \n    \n    # Filling the NA values\n    df['Age'].fillna(df['Age'].median(), inplace = True)\n    # Creating bins from the Age feature\n    df['AgeBin'] = pd.cut(df['Age'].astype(int), 5, labels=False)\n    \n    # SibSp & Parch\n    # Math transform on Sib and Parch\n    df['Family'] = df['SibSp'] + df['Parch']\n    \n    # Ticket\n    # Extracting the ticket number\n    df['TicketNumber'] = df['Ticket'].apply(lambda x: x.split(' ')).apply(lambda x : x[1] if len (x) > 1 else x[0]).apply(lambda x: x[0])\n    df['TicketNumber'].replace({'LINE': -1, 'SC/AH Basle 541': -1, 'L':-1, 'B':-1}, inplace=True)\n    df['TicketNumber'] = df['TicketNumber'].astype(int)\n    # Creating a flag if the Ticket value is null\n    df['TicketFlag'] = df['Ticket'].apply(lambda x: 1 if x.isnumeric() else 0)\n    # Extracting the first letter on the ticket feature\n    df['TicketCode'] = df['Ticket'].apply(lambda x: ''.join(x.split(' ')[:-1]).replace('.','').replace('/','') if len(x.split(' ')[:-1]) > 0 else 'None')\n    \n    # Fare\n    # Creating a feature by splitting the Fare in 3 different classes\n    df['SocialClassByFare'] = df['Fare'].apply(lambda x : 'Rich' if x > df['Fare'].quantile(0.75) else ( 'Poor' if x < df['Fare'].quantile(0.25) else 'Midd' ))\n    # Creating bins from the Age feature\n    df['FareBin'] = pd.qcut(df['Fare'], 4, labels=False)\n    \n    # Cabin\n    # Extracting the first letter on the Cabin feature\n    df['CabinCode'] = df['Cabin'].apply(lambda x : str(x)).apply(lambda x: 'U' if x == 'nan' else x[0])\n    # Extracting the length of the Cabin feature\n    df['CabinLen'] = df['Cabin'].apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))\n    # Creating a flag if the Cabin value is null\n    df['CabinFlag'] = df['Cabin'].map(lambda x: 1 if pd.isnull(x) else 0)\n    #df.drop('Cabin', inplace=True)\n    \n    # Embarked\n    # Replacing the null values on Embarked by U\n    df['Embarked'] = df['Embarked'].apply(lambda x : str(x)).apply(lambda x: 'U' if x == 'nan' else x)\n    \n    # Split the dataframe\n    train = df.query(\"kfold != -1\").copy()\n    train['Survived'] = train['Survived'].astype(int)\n    \n    test = df.query(\"kfold == -1\").copy()\n    test.drop(['Survived', 'kfold'], axis = 1, inplace=True)\n    \n    return train, test","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:41.789342Z","iopub.execute_input":"2022-02-20T11:19:41.789969Z","iopub.status.idle":"2022-02-20T11:19:41.809214Z","shell.execute_reply.started":"2022-02-20T11:19:41.789924Z","shell.execute_reply":"2022-02-20T11:19:41.808371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = preprocessing_inputs(combined_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:41.810527Z","iopub.execute_input":"2022-02-20T11:19:41.810893Z","iopub.status.idle":"2022-02-20T11:19:43.456782Z","shell.execute_reply.started":"2022-02-20T11:19:41.810859Z","shell.execute_reply":"2022-02-20T11:19:43.455743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-six\"></a>\n# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> 6 | Feature selection</div>\n\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \n It's a very small dataset, so this feature selection part it's not so important, but I think it's a good practice to apply it for educational purposes anyway. </p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">  \nMutual Information </p>","metadata":{}},{"cell_type":"code","source":"xm = train.copy()\nxm.dropna(inplace = True)\n\nym = xm.pop(\"Survived\").copy()\n\n# Label encoding for categoricals\nfor colname in xm.select_dtypes(\"object\"):\n    xm[colname], _ = xm[colname].factorize()\n\ndiscrete_features = xm.dtypes == int","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:43.45802Z","iopub.execute_input":"2022-02-20T11:19:43.458351Z","iopub.status.idle":"2022-02-20T11:19:43.472944Z","shell.execute_reply.started":"2022-02-20T11:19:43.458319Z","shell.execute_reply":"2022-02-20T11:19:43.471681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\n\ndef make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, n_neighbors = 5)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:43.478098Z","iopub.execute_input":"2022-02-20T11:19:43.478426Z","iopub.status.idle":"2022-02-20T11:19:43.496575Z","shell.execute_reply.started":"2022-02-20T11:19:43.478396Z","shell.execute_reply":"2022-02-20T11:19:43.495746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores = make_mi_scores(xm, ym, discrete_features)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:43.498032Z","iopub.execute_input":"2022-02-20T11:19:43.49844Z","iopub.status.idle":"2022-02-20T11:19:43.531652Z","shell.execute_reply.started":"2022-02-20T11:19:43.498409Z","shell.execute_reply":"2022-02-20T11:19:43.530766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n\n\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:43.532691Z","iopub.execute_input":"2022-02-20T11:19:43.53309Z","iopub.status.idle":"2022-02-20T11:19:43.823474Z","shell.execute_reply.started":"2022-02-20T11:19:43.533062Z","shell.execute_reply":"2022-02-20T11:19:43.822461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">  \nPermutation feature importance </p>","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nfeature_names = [i for i in train.columns if train[i].dtype in [np.int64]]\nX = train[feature_names]\ntrain_X, val_X, train_y, val_y = model_selection.train_test_split(xm, ym, random_state=1)\nmy_model = RandomForestClassifier(n_estimators=100,\n                                  random_state=0).fit(train_X, train_y)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:43.824993Z","iopub.execute_input":"2022-02-20T11:19:43.825587Z","iopub.status.idle":"2022-02-20T11:19:44.084633Z","shell.execute_reply.started":"2022-02-20T11:19:43.825537Z","shell.execute_reply":"2022-02-20T11:19:44.083585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\neli5.show_weights(perm, top=10, feature_names = val_X.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:44.085806Z","iopub.execute_input":"2022-02-20T11:19:44.086087Z","iopub.status.idle":"2022-02-20T11:19:52.175355Z","shell.execute_reply.started":"2022-02-20T11:19:44.086058Z","shell.execute_reply":"2022-02-20T11:19:52.174374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\" style=\"border-radius:5px; font-size:15px; font-family:verdana; line-height: 1.7em\">\n<p style=\"font-size:18px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \n<b> Insights: </b> For some reason mutual information and permutation feature importance takes PassengerId as relevant, most likely there is some leaking. We can see how Sex, Name (related with sex and social class), and Age are the top 3 most relevant features </p>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-seven\"></a>\n# <div style=\"color:#fff;display:fill;border-radius:10px;background-color:#000000;text-align:left;letter-spacing:0.1px;overflow:hidden;padding:20px;color:white;overflow:hidden;margin:0;font-size:100%\"> 7 | Modeling</div>","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nimport catboost as cb\nimport lightgbm as lgb\nfrom sklearn import linear_model","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:52.176598Z","iopub.execute_input":"2022-02-20T11:19:52.176898Z","iopub.status.idle":"2022-02-20T11:19:52.181358Z","shell.execute_reply.started":"2022-02-20T11:19:52.176871Z","shell.execute_reply":"2022-02-20T11:19:52.180183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['Pclass', 'Sex', 'Age', 'Ticket', 'Embarked', 'Title',\n            'AgeFlag', 'AgeBin', 'Family', 'TicketNumber', 'TicketFlag','TicketCode', \n            'SocialClassByFare', 'FareBin', 'CabinCode', 'CabinLen', 'CabinFlag']","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:52.182314Z","iopub.execute_input":"2022-02-20T11:19:52.182701Z","iopub.status.idle":"2022-02-20T11:19:52.195869Z","shell.execute_reply.started":"2022-02-20T11:19:52.182668Z","shell.execute_reply":"2022-02-20T11:19:52.194953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categoric_features = [feature for feature in train_df[features] if train_df[feature].dtype =='O']\nnumeric_features = [feature for feature in train_df[features] if feature not in categoric_features+['PassengerId','kfold','Survived']]  ","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:52.196974Z","iopub.execute_input":"2022-02-20T11:19:52.197385Z","iopub.status.idle":"2022-02-20T11:19:52.212853Z","shell.execute_reply.started":"2022-02-20T11:19:52.197355Z","shell.execute_reply":"2022-02-20T11:19:52.211728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ordinal_features = [feature for feature in train_df[categoric_features].columns if len(train_df[feature].unique()) <= 3 and feature not in ['Survived']]\nhigh_card_features = [feature for feature in train_df[categoric_features].columns if len(train_df[feature].unique()) > 3 and feature not in ['Survived','PassengerId']+ordinal_features]","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:52.214303Z","iopub.execute_input":"2022-02-20T11:19:52.214694Z","iopub.status.idle":"2022-02-20T11:19:52.226557Z","shell.execute_reply.started":"2022-02-20T11:19:52.214655Z","shell.execute_reply":"2022-02-20T11:19:52.225707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nTrainer class </p>","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    \n    \"\"\"\n    Args:\n        - model: Any ML model to train.\n        - model_name: The corresponding model name to be used to identify it in the training process.\n        - fold: Fold number.\n        - model_params: Hyperparameters of the respective model.\n        \n    \"\"\"\n    \n    def __init__(self, model, model_name, fold, model_params=None):\n     \n        self.model_ = model\n        self.model_name = model_name\n        self.fold = fold\n        self.model_params = model_params\n        \n        self.test_preds = []\n              \n    def fit(self, xtrain, ytrain, xvalid, yvalid):\n        \n        \"\"\"\n        Fits an instance of the model for a particular dataset.\n        Args:\n            - xtrain: Train data.\n            - ytrain: Train target.\n            - xvalid: Validation data.\n            - yvalid: Validation target.\n        \"\"\"\n        self.xtrain = xtrain\n        self.ytrain = ytrain\n        self.xvalid = xvalid\n        self.yvalid = yvalid\n        \n        self.model_.fit(self.xtrain, self.ytrain, self.xvalid, self.yvalid)\n        \n        return self.model_\n        \n    def pred_evaluate(self, xtest):\n        \n        \"\"\"\n        Makes predictions for each model on the test data provided.\n        Args:\n            - xtest: Test data.\n        \"\"\"\n        \n        self.xtest = xtest\n        \n        self.preds_valid = self.model_.predict(self.xvalid)\n        self.preds_test = self.model_.predict(self.xtest)\n        \n        pred = self.test_preds.append(self.preds_test) \n        score = metrics.accuracy_score(self.yvalid, self.preds_valid)      \n        \n        print(f'fold = {self.fold}, score = {score:.4f}')\n    \n    def blend(self, models):\n        \n        \"\"\"\n        Makes a blend of the trained models.\n        Args:\n            - models: Models to blend (dtype=list).\n        \"\"\"\n        \n        predictions = []\n        for m in models:\n            preds_test = m.predict(self.xtest)\n            predictions.append(preds_test)\n        \n        fin_preds = np.mean(np.column_stack (predictions), axis=1).astype(int)\n        return fin_preds","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:52.227837Z","iopub.execute_input":"2022-02-20T11:19:52.228356Z","iopub.status.idle":"2022-02-20T11:19:52.24051Z","shell.execute_reply.started":"2022-02-20T11:19:52.228305Z","shell.execute_reply":"2022-02-20T11:19:52.239098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nModels class</p>","metadata":{}},{"cell_type":"code","source":"class Models():\n    \n    \"\"\"\n    Nested class to wrapp all the models.\n    \"\"\"\n    \n    class XGBModel():\n        \"\"\"\n        XGboost model implementation.\n        \"\"\"\n        \n        def fit(self, X_train, y_train, X_valid, y_valid, params={}):\n            \"\"\"\n            Fits an instance of the model on the supplied data.\n            Args:\n                - X_train: Train data.\n                - y_train: Train target.\n                - X_valid: Validation data.\n                - y_valid: Validation target.\n            \"\"\"\n\n            self.model_ = xgb.XGBClassifier(objective=\"reg:squarederror\",\n                                            eval_metric='logloss',\n                                            use_label_encoder=False,\n                                            random_state=42,\n                                            **params\n                                        ) \n\n            self.model_.fit(X_train, \n                            y_train, \n                            early_stopping_rounds=20, \n                            eval_set=[(X_valid, y_valid)], \n                            verbose=False\n                            )\n\n            return self.model_\n\n        def predict(self, dataset):\n\n            if self.model_ is None:\n                return None\n\n            return self.model_.predict(dataset)\n    \n    class LGBMModel():\n        \"\"\"\n        LGBM model implementation.\n        \"\"\"\n        def fit(self, X_train, y_train, X_valid, y_valid, params={}):\n            \"\"\"\n            Fits an instance of the model on the supplied data.\n            Args:\n                - X_train: Train data.\n                - y_train: Train target.\n                - X_valid: Validation data.\n                - y_valid: Validation target.\n            \"\"\"\n                        \n            self.model_ = lgb.LGBMClassifier(objective='binary', \n                                             random_state=42,\n                                             **params\n                                             )\n\n            self.model_.fit(X_train, \n                            y_train, \n                            early_stopping_rounds=20, \n                            eval_set=[(X_valid, y_valid)], \n                            verbose=False\n                           )\n\n            return self.model_\n\n        def predict(self, dataset):\n\n            if self.model_ is None:\n                return None\n\n            return self.model_.predict(dataset)\n    \n    class CTBModel():\n        \"\"\"\n        Catboost model implementation.\n        \"\"\"\n        def fit(self, X_train, y_train, X_valid, y_valid, params={}):\n            \"\"\"\n            Fits an instance of the model on the supplied data.\n            Args:\n                - X_train: Train data.\n                - y_train: Train target.\n                - X_valid: Validation data.\n                - y_valid: Validation target.\n            \"\"\"\n            \n            self.model_ = cb.CatBoostClassifier(random_state=42, **params) \n\n            self.model_.fit(X_train, \n                            y_train, \n                            early_stopping_rounds=20, \n                            eval_set=[(X_valid, y_valid)], \n                            verbose=False\n                           )\n\n            return self.model_\n\n        def predict(self, dataset):\n\n            if self.model_ is None:\n                return None\n\n            return self.model_.predict(dataset)\n\n    @staticmethod\n    def __iter__():\n        \"\"\"\n        Iterate over the class atributes (Models) \n        \"\"\"\n        return iter([[getattr(Models, attr), attr] for attr in dir(Models) if not attr.startswith(\"__\")])","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:52.241985Z","iopub.execute_input":"2022-02-20T11:19:52.242514Z","iopub.status.idle":"2022-02-20T11:19:52.258445Z","shell.execute_reply.started":"2022-02-20T11:19:52.242479Z","shell.execute_reply":"2022-02-20T11:19:52.257346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_params = {\n                 ' CTBModel': {'iterations':1000},\n                 'LGBMModel': {'n_estimators':1000, 'max_depth':5},\n                 ' XGBModel': {'n_estimators':1000, 'max_depth':5},\n                }","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:52.259757Z","iopub.execute_input":"2022-02-20T11:19:52.260088Z","iopub.status.idle":"2022-02-20T11:19:52.275122Z","shell.execute_reply.started":"2022-02-20T11:19:52.260056Z","shell.execute_reply":"2022-02-20T11:19:52.274272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em; margin-left:20px\">   \nTraining loop </p>","metadata":{}},{"cell_type":"code","source":"models_trained = []\n\nfor mdls, params  in zip(Models().__iter__(), models_params.items()):\n    \n    # Instantiating the main class\n    models = mdls[0]()\n    name = mdls[1]\n    \n    # Splitting the models_params dict in name and values to feed the models\n    params_name = params[0]\n    params_vals = params[1]\n\n    print(f' Model {name}')\n    for fold in range(5):\n        \n        X_train = train_df[train_df.kfold != fold].reset_index(drop=True)\n        X_valid = train_df[train_df.kfold == fold].reset_index(drop=True)\n        \n        X_test = test_df.copy()\n\n        y_train = X_train['Survived']\n        y_valid = X_valid['Survived']\n        \n        # Scaling\n        scl = preprocessing.StandardScaler()\n        X_train[numeric_features] = scl.fit_transform(X_train[numeric_features])\n        X_valid[numeric_features] = scl.transform(X_valid[numeric_features])\n        X_test[numeric_features] = scl.transform(X_test[numeric_features])\n        \n        # Imputing\n        imp = impute.SimpleImputer(strategy='mean')\n        X_train[numeric_features] = imp.fit_transform(X_train[numeric_features])\n        X_valid[numeric_features] = imp.transform(X_valid[numeric_features])\n        X_test[numeric_features] = imp.transform(X_test[numeric_features])\n\n        # Encoding\n            # Ordinal\n        ord_enc = preprocessing.OrdinalEncoder()\n        X_train[ordinal_features] = ord_enc.fit_transform(X_train[ordinal_features])\n        X_valid[ordinal_features] = ord_enc.transform(X_valid[ordinal_features])\n        X_test[ordinal_features] = ord_enc.transform(X_test[ordinal_features])\n        \n            # OHE\n        ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown='ignore').fit(X_train[high_card_features])\n        encoded_cols = list(ohe.get_feature_names(high_card_features))\n    \n        X_train[encoded_cols] = ohe.transform(X_train[high_card_features])\n        X_valid[encoded_cols] = ohe.transform(X_valid[high_card_features])\n        X_test[encoded_cols] = ohe.transform(X_test[high_card_features])\n        \n        # Preprocessed's dfs\n        X_train = X_train[numeric_features+ordinal_features+encoded_cols]\n        X_valid = X_valid[numeric_features+ordinal_features+encoded_cols]\n        X_test = X_test[numeric_features+ordinal_features+encoded_cols]\n        \n        # Trainer class initialization\n        trainer = Trainer(model=models, model_name=name,fold=fold, model_params=params_vals)\n        \n        # Fit the trainer\n        model_trained = trainer.fit(X_train, y_train, X_valid, y_valid)\n        trainer.pred_evaluate(X_test)\n    print()\n        \n    models_trained.append(model_trained)\n    blend = trainer.blend(models_trained)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:19:52.276364Z","iopub.execute_input":"2022-02-20T11:19:52.276843Z","iopub.status.idle":"2022-02-20T11:20:09.065682Z","shell.execute_reply.started":"2022-02-20T11:19:52.276801Z","shell.execute_reply":"2022-02-20T11:20:09.064779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.Survived = blend","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:20:09.069745Z","iopub.execute_input":"2022-02-20T11:20:09.071774Z","iopub.status.idle":"2022-02-20T11:20:09.076565Z","shell.execute_reply.started":"2022-02-20T11:20:09.071725Z","shell.execute_reply":"2022-02-20T11:20:09.07574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T11:20:09.078747Z","iopub.execute_input":"2022-02-20T11:20:09.07918Z","iopub.status.idle":"2022-02-20T11:20:09.095081Z","shell.execute_reply.started":"2022-02-20T11:20:09.079135Z","shell.execute_reply":"2022-02-20T11:20:09.093832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:20px; font-family:verdana; line-height: 1.7em\">   \nFuture work try to add more features, thanks for read my notebook. Greetings! </p>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}