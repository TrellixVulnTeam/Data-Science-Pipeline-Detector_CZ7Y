{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Importing the relevant libraries","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:45:28.564014Z","iopub.execute_input":"2022-02-10T10:45:28.564486Z","iopub.status.idle":"2022-02-10T10:45:28.583883Z","shell.execute_reply.started":"2022-02-10T10:45:28.564403Z","shell.execute_reply":"2022-02-10T10:45:28.58332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For Faster run time of sklearn classes and modules\n!pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:45:28.585146Z","iopub.execute_input":"2022-02-10T10:45:28.58582Z","iopub.status.idle":"2022-02-10T10:46:18.024952Z","shell.execute_reply.started":"2022-02-10T10:45:28.585782Z","shell.execute_reply":"2022-02-10T10:46:18.024016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, \n                              GradientBoostingClassifier, VotingClassifier, \n                              AdaBoostClassifier)\nimport scipy.stats as sst\nimport math\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-10T10:46:18.026507Z","iopub.execute_input":"2022-02-10T10:46:18.026723Z","iopub.status.idle":"2022-02-10T10:46:23.162765Z","shell.execute_reply.started":"2022-02-10T10:46:18.026696Z","shell.execute_reply":"2022-02-10T10:46:23.161941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev = tf.config.list_physical_devices('GPU')\nif len(dev) > 0:\n    tf.config.experimental.set_memory_growth(dev[0], 'True')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:23.164111Z","iopub.execute_input":"2022-02-10T10:46:23.164338Z","iopub.status.idle":"2022-02-10T10:46:23.173072Z","shell.execute_reply.started":"2022-02-10T10:46:23.164311Z","shell.execute_reply":"2022-02-10T10:46:23.172534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:23.174325Z","iopub.execute_input":"2022-02-10T10:46:23.174802Z","iopub.status.idle":"2022-02-10T10:46:26.958375Z","shell.execute_reply.started":"2022-02-10T10:46:23.174774Z","shell.execute_reply":"2022-02-10T10:46:26.957298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\ncombine = [train, test]\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:26.960058Z","iopub.execute_input":"2022-02-10T10:46:26.960411Z","iopub.status.idle":"2022-02-10T10:46:27.034958Z","shell.execute_reply.started":"2022-02-10T10:46:26.960369Z","shell.execute_reply":"2022-02-10T10:46:27.034224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:27.035974Z","iopub.execute_input":"2022-02-10T10:46:27.036208Z","iopub.status.idle":"2022-02-10T10:46:27.049747Z","shell.execute_reply.started":"2022-02-10T10:46:27.036166Z","shell.execute_reply":"2022-02-10T10:46:27.04915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The below function has been directly taken from [this](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling) amazing notebook. Do check it out!","metadata":{}},{"cell_type":"code","source":"def detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \nout = detect_outliers(train, 2, ['Fare', 'SibSp', 'Parch', 'Age'])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:27.050832Z","iopub.execute_input":"2022-02-10T10:46:27.051362Z","iopub.status.idle":"2022-02-10T10:46:27.066614Z","shell.execute_reply.started":"2022-02-10T10:46:27.051328Z","shell.execute_reply":"2022-02-10T10:46:27.065695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(out, axis = 0, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:27.067844Z","iopub.execute_input":"2022-02-10T10:46:27.06823Z","iopub.status.idle":"2022-02-10T10:46:27.078162Z","shell.execute_reply.started":"2022-02-10T10:46:27.068188Z","shell.execute_reply":"2022-02-10T10:46:27.077449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:27.079224Z","iopub.execute_input":"2022-02-10T10:46:27.079853Z","iopub.status.idle":"2022-02-10T10:46:27.100723Z","shell.execute_reply.started":"2022-02-10T10:46:27.079823Z","shell.execute_reply":"2022-02-10T10:46:27.09994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test1 = test.copy()\ntest1['Survived'] = np.nan\ndata = pd.concat([train, test1]).reset_index(drop = True)\nlen(data)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:27.103035Z","iopub.execute_input":"2022-02-10T10:46:27.103276Z","iopub.status.idle":"2022-02-10T10:46:27.115674Z","shell.execute_reply.started":"2022-02-10T10:46:27.103249Z","shell.execute_reply":"2022-02-10T10:46:27.114927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:27.116742Z","iopub.execute_input":"2022-02-10T10:46:27.117107Z","iopub.status.idle":"2022-02-10T10:46:27.141956Z","shell.execute_reply.started":"2022-02-10T10:46:27.11708Z","shell.execute_reply":"2022-02-10T10:46:27.141246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:27.143136Z","iopub.execute_input":"2022-02-10T10:46:27.143379Z","iopub.status.idle":"2022-02-10T10:46:27.15383Z","shell.execute_reply.started":"2022-02-10T10:46:27.143348Z","shell.execute_reply":"2022-02-10T10:46:27.153241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the death frequency of the classes of different attributes","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = [20, 15])\nplt.subplot(3, 3, 1)\nsns.histplot(data = train, x = train['Sex'], hue = train['Survived'], multiple = 'dodge')\nplt.subplot(3, 3, 2)\nsns.histplot(data = train, x = train['Pclass'], hue = train['Survived'], multiple = 'dodge')\nplt.subplot(3, 3, 3)\nsns.histplot(data = train, x = train['Embarked'], hue = train['Survived'], multiple = 'dodge')\nplt.subplot(3, 3, 4)\nsns.histplot(data = train, x = train['Age'], hue = train['Survived'], multiple = 'dodge')\nplt.subplot(3, 3, 5)\nsns.histplot(data = train, x = train['SibSp'], hue = train['Survived'], multiple = 'dodge')\nplt.subplot(3, 3, 6)\nsns.histplot(data = train, x = train['Parch'], hue = train['Survived'], multiple = 'dodge')\nplt.plot();","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:27.154795Z","iopub.execute_input":"2022-02-10T10:46:27.155302Z","iopub.status.idle":"2022-02-10T10:46:28.64403Z","shell.execute_reply.started":"2022-02-10T10:46:27.155264Z","shell.execute_reply":"2022-02-10T10:46:28.643142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Adding Title attribute to the data","metadata":{}},{"cell_type":"markdown","source":"#### People with some titles were more likely to live than others","metadata":{}},{"cell_type":"code","source":"data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand = False)\npd.crosstab(data['Title'], data.Sex)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:28.645406Z","iopub.execute_input":"2022-02-10T10:46:28.645868Z","iopub.status.idle":"2022-02-10T10:46:28.676053Z","shell.execute_reply.started":"2022-02-10T10:46:28.645777Z","shell.execute_reply":"2022-02-10T10:46:28.675195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_rep = ['Capt', 'Col', 'Countess', 'Don', 'Dona', 'Dr', 'Jonkheer', 'Lady',\n           'Major', 'Rev', 'Sir']\n\ndata['Title'].replace(col_rep, 'Rare', inplace = True)\ndata['Title'].replace(['Mlle', 'Ms'], 'Miss', inplace = True)\ndata['Title'].replace(['Mme'], 'Mrs', inplace = True)\npd.crosstab(data['Title'], data['Sex'])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:28.677637Z","iopub.execute_input":"2022-02-10T10:46:28.677918Z","iopub.status.idle":"2022-02-10T10:46:28.702294Z","shell.execute_reply.started":"2022-02-10T10:46:28.677881Z","shell.execute_reply":"2022-02-10T10:46:28.70154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby('Title').mean()['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:28.703766Z","iopub.execute_input":"2022-02-10T10:46:28.704094Z","iopub.status.idle":"2022-02-10T10:46:28.716333Z","shell.execute_reply.started":"2022-02-10T10:46:28.704056Z","shell.execute_reply":"2022-02-10T10:46:28.715224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding the Sex attribute","metadata":{}},{"cell_type":"markdown","source":"#### Encoding the Sex attribute with 0 for Males, 1 for Females and 2 for Master, i.e, male children because they had higher chance of survival compared to adult males","metadata":{}},{"cell_type":"code","source":"data.loc[data['Sex'] == 'male', 'Sex'] = 0\ndata.loc[data['Sex'] == 'female', 'Sex'] = 1\ndata.loc[data['Title'] == 'Master', 'Sex'] = 2","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:28.717442Z","iopub.execute_input":"2022-02-10T10:46:28.718231Z","iopub.status.idle":"2022-02-10T10:46:28.724572Z","shell.execute_reply.started":"2022-02-10T10:46:28.718191Z","shell.execute_reply":"2022-02-10T10:46:28.723817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Replacing the null values in Age attribute with median values of the respective passenger classes","metadata":{}},{"cell_type":"markdown","source":"#### Different Passenger Classes had different median ages, so I account for that below. Also, I consider the Sex of a passenger as well as there were different median ages for different sexes as well.","metadata":{}},{"cell_type":"code","source":"index_NaN_age = list(data[\"Age\"][data[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_pred = np.nanmedian(data[\"Age\"][(data['Sex'] == data.iloc[i][\"Sex\"]) &  (data['Pclass'] == data.iloc[i][\"Pclass\"])])\n    data.loc[i, 'Age'] = age_pred\ndata.info() \n\n# There are better and optimized ways to implement what I did above. As you can see, on every loop the nanmedian function calculates the median\n# What we can do is store the medians of all the different possibilites in a matrix and access it in a constant time on every loop instead of calculating it everytime\n# At the end, you will be left with 9 different values based on 3 sexes and 3 passenger classes.","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:28.725659Z","iopub.execute_input":"2022-02-10T10:46:28.725893Z","iopub.status.idle":"2022-02-10T10:46:29.079848Z","shell.execute_reply.started":"2022-02-10T10:46:28.725867Z","shell.execute_reply":"2022-02-10T10:46:29.078924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Breaking the Age attribute into 5 different classes","metadata":{}},{"cell_type":"code","source":"data['Age_group'] = 0\ndata.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age_group'] = 1\ndata.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age_group'] = 2\ndata.loc[(data['Age'] > 48) & (data['Age'] <= 60), 'Age_group'] = 3\ndata.loc[(data['Age'] > 60), 'Age_group'] = 4\ndata.groupby('Age_group').mean()['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.081141Z","iopub.execute_input":"2022-02-10T10:46:29.081528Z","iopub.status.idle":"2022-02-10T10:46:29.097082Z","shell.execute_reply.started":"2022-02-10T10:46:29.081484Z","shell.execute_reply":"2022-02-10T10:46:29.09641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.value_counts(data['Age_group'])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.098601Z","iopub.execute_input":"2022-02-10T10:46:29.099258Z","iopub.status.idle":"2022-02-10T10:46:29.10583Z","shell.execute_reply.started":"2022-02-10T10:46:29.099219Z","shell.execute_reply":"2022-02-10T10:46:29.104782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding unknown value to the null values of the Cabin Attribute","metadata":{}},{"cell_type":"markdown","source":"#### Cabin can be considered a part of the Titanic. Like a Deck. Different parts of Titanic had different survival rates","metadata":{}},{"cell_type":"code","source":"f = data['Cabin'].str.extract('(^.{0,1})')\ndata['Cabin'] = f\ndata.loc[data['Cabin'].isnull(), 'Cabin'] = 'U' # U is unknown","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.106938Z","iopub.execute_input":"2022-02-10T10:46:29.1077Z","iopub.status.idle":"2022-02-10T10:46:29.116496Z","shell.execute_reply.started":"2022-02-10T10:46:29.107669Z","shell.execute_reply":"2022-02-10T10:46:29.115821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.value_counts(data['Cabin'])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.117422Z","iopub.execute_input":"2022-02-10T10:46:29.118045Z","iopub.status.idle":"2022-02-10T10:46:29.127771Z","shell.execute_reply.started":"2022-02-10T10:46:29.118008Z","shell.execute_reply":"2022-02-10T10:46:29.127016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[data['Cabin'] == 'T', 'Cabin'] = 'A'\nsns.histplot(data = data[:len(train)], x = data[:len(train)]['Cabin'], hue = 'Survived', multiple = 'stack');","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.128981Z","iopub.execute_input":"2022-02-10T10:46:29.129245Z","iopub.status.idle":"2022-02-10T10:46:29.403136Z","shell.execute_reply.started":"2022-02-10T10:46:29.12921Z","shell.execute_reply":"2022-02-10T10:46:29.402304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Deck'] = 'U'\ndata.loc[(data['Cabin'] == 'A') | (data['Cabin'] == 'B') | (data['Cabin'] == 'C'), 'Deck'] = 'ABC'\ndata.loc[(data['Cabin'] == 'D') | (data['Cabin'] == 'E'), 'Deck'] = 'DE'\ndata.loc[(data['Cabin'] == 'F') | (data['Cabin'] == 'G'), 'Deck'] = 'FG'\ndata.loc[(data['Cabin'] == np.nan), 'Deck'] = 'U'","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.404393Z","iopub.execute_input":"2022-02-10T10:46:29.404608Z","iopub.status.idle":"2022-02-10T10:46:29.415041Z","shell.execute_reply.started":"2022-02-10T10:46:29.404574Z","shell.execute_reply":"2022-02-10T10:46:29.414219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby('Deck').mean()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.416124Z","iopub.execute_input":"2022-02-10T10:46:29.416379Z","iopub.status.idle":"2022-02-10T10:46:29.43882Z","shell.execute_reply.started":"2022-02-10T10:46:29.416352Z","shell.execute_reply":"2022-02-10T10:46:29.438066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding Relatives attribute","metadata":{}},{"cell_type":"markdown","source":"#### Adding the number of Siblings/Spouse and number Parents and Children will give us the number of relatives that a passenger has","metadata":{}},{"cell_type":"code","source":"data['Relatives'] = data['SibSp'] + data['Parch'] + 1 # I add 1 to account for the passenger themself","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.440088Z","iopub.execute_input":"2022-02-10T10:46:29.44058Z","iopub.status.idle":"2022-02-10T10:46:29.44638Z","shell.execute_reply.started":"2022-02-10T10:46:29.440539Z","shell.execute_reply":"2022-02-10T10:46:29.445419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[data['Relatives'] == 1, 'Family_Size'] = 0\ndata.loc[(data['Relatives'] >= 2) & (data['Relatives'] < 5), 'Family_Size'] = 1\ndata.loc[(data['Relatives'] >= 5) & (data['Relatives'] <= 6), 'Family_Size'] = 2\ndata.loc[(data['Relatives'] >= 7), 'Family_Size'] = 3","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.447738Z","iopub.execute_input":"2022-02-10T10:46:29.448614Z","iopub.status.idle":"2022-02-10T10:46:29.459683Z","shell.execute_reply.started":"2022-02-10T10:46:29.44858Z","shell.execute_reply":"2022-02-10T10:46:29.458867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby('Family_Size').mean()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.465547Z","iopub.execute_input":"2022-02-10T10:46:29.466Z","iopub.status.idle":"2022-02-10T10:46:29.483102Z","shell.execute_reply.started":"2022-02-10T10:46:29.465966Z","shell.execute_reply":"2022-02-10T10:46:29.482445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ticket Frequency","metadata":{}},{"cell_type":"markdown","source":"#### This is number of people with the same ticket. Families and Friends bought tickets together and they got the same ticket number and id. This counts how many people held the same ticket","metadata":{}},{"cell_type":"code","source":"data['Ticket_Frequency'] = data.groupby('Ticket')['Ticket'].transform('count')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.484425Z","iopub.execute_input":"2022-02-10T10:46:29.484766Z","iopub.status.idle":"2022-02-10T10:46:29.492135Z","shell.execute_reply.started":"2022-02-10T10:46:29.484726Z","shell.execute_reply":"2022-02-10T10:46:29.491482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[data['Ticket_Frequency'] == 1, 'TF'] = 0\ndata.loc[(data['Ticket_Frequency'] >= 2) & (data['Ticket_Frequency'] <= 4), 'TF'] = 1\ndata.loc[data['Ticket_Frequency'] > 4, 'TF'] = 2","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.493284Z","iopub.execute_input":"2022-02-10T10:46:29.493965Z","iopub.status.idle":"2022-02-10T10:46:29.502908Z","shell.execute_reply.started":"2022-02-10T10:46:29.493924Z","shell.execute_reply":"2022-02-10T10:46:29.502359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding Surname Attribute","metadata":{}},{"cell_type":"markdown","source":"#### This adds the last name of all the people aboard the Titanic. This will helps us know how many members there are in a family","metadata":{}},{"cell_type":"code","source":"data['Surname'] = data['Name'].map(lambda i: i.split(',')[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.503852Z","iopub.execute_input":"2022-02-10T10:46:29.504761Z","iopub.status.idle":"2022-02-10T10:46:29.511734Z","shell.execute_reply.started":"2022-02-10T10:46:29.50472Z","shell.execute_reply":"2022-02-10T10:46:29.511064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculating the survival rate of families and people travelling in group","metadata":{}},{"cell_type":"markdown","source":"#### If someone travelled in a group or a family then they have a higher chance of survival, if people from that group/family also survived","metadata":{}},{"cell_type":"code","source":"# Below is the average survival rate of all the people aboard the Titanic. \n# If someone didn't have a group or a family then this is their survival rate\ndata['Family_Survival'] = 0.385\n\n'''\nWe check for all the people with families as to how many people survived from that family\nThis is their average survival rate..  sr = (survived / total family members)\n'''\nfor gid, gdf in data.groupby('Surname'):\n    if len(gdf) > 1:\n        for i, r in gdf.iterrows():\n            fam = gdf.drop(i)\n            sur = list(fam['Survived'])\n            ans = np.nanmean(sur)\n            if not math.isnan(ans):\n                data.loc[data['PassengerId'] == r['PassengerId'], 'Family_Survival'] = ans\n\n                \n# We do the same as above except in this case it is with ticket frequency, i.e, number of people having the same ticket  \ndata['Ticket_Survival'] = 0.385\n\nfor gid, gdf in data.groupby('Ticket'):\n    if len(gdf) > 1:\n        for i, r in gdf.iterrows():\n            fam = gdf.drop(i)\n            sur = list(fam['Survived'])\n            ans = np.nanmean(sur)\n            if not math.isnan(ans):\n                data.loc[data['PassengerId'] == r['PassengerId'], 'Ticket_Survival'] = ans\n\n'''\nHere I calculate the average survival rate of a particular person \nbased on their family survival rate and their ticket survival rate\n'''\nnum = (data['Family_Size'] * data['Family_Survival']) + (data['Ticket_Frequency'] * data['Ticket_Survival'])\nden = data['Family_Size'] + data['Ticket_Frequency']\ndata['Survival'] = num / den","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:29.512993Z","iopub.execute_input":"2022-02-10T10:46:29.513299Z","iopub.status.idle":"2022-02-10T10:46:30.81713Z","shell.execute_reply.started":"2022-02-10T10:46:29.513261Z","shell.execute_reply":"2022-02-10T10:46:30.816551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (8, 6))\nsns.histplot(data['Survival'], bins = 25);","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:30.819162Z","iopub.execute_input":"2022-02-10T10:46:30.820004Z","iopub.status.idle":"2022-02-10T10:46:31.07905Z","shell.execute_reply.started":"2022-02-10T10:46:30.819963Z","shell.execute_reply":"2022-02-10T10:46:31.078232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here I divide the Survival rate/probability into four classes","metadata":{}},{"cell_type":"code","source":"data.loc[(data['Survival'] <= 0.35), 'SP'] = 0\ndata.loc[(data['Survival'] > 0.35) & (data['Survival'] <= 0.5), 'SP'] = 1\ndata.loc[(data['Survival'] > 0.5) & (data['Survival'] <= 0.8), 'SP'] = 2\ndata.loc[(data['Survival'] > 0.8) & (data['Survival'] <= 1), 'SP'] = 3\ndata.groupby('SP').mean()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.080266Z","iopub.execute_input":"2022-02-10T10:46:31.080488Z","iopub.status.idle":"2022-02-10T10:46:31.106954Z","shell.execute_reply.started":"2022-02-10T10:46:31.080461Z","shell.execute_reply":"2022-02-10T10:46:31.106193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I tried dividing the group in such a way that all the classes had a decent number of data points. I experimented to find those classes above..","metadata":{}},{"cell_type":"code","source":"pd.value_counts(data['SP'])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.108105Z","iopub.execute_input":"2022-02-10T10:46:31.108434Z","iopub.status.idle":"2022-02-10T10:46:31.116703Z","shell.execute_reply.started":"2022-02-10T10:46:31.108402Z","shell.execute_reply":"2022-02-10T10:46:31.116113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Replacing null values in Embarked attribute with the most frequent value","metadata":{}},{"cell_type":"code","source":"data[data['Embarked'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.117872Z","iopub.execute_input":"2022-02-10T10:46:31.118349Z","iopub.status.idle":"2022-02-10T10:46:31.149379Z","shell.execute_reply.started":"2022-02-10T10:46:31.118316Z","shell.execute_reply":"2022-02-10T10:46:31.148575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 8))\nsns.boxplot(data = data, x = 'Embarked', y = 'Fare', hue = 'Pclass');\ndata.loc[data['Embarked'].isnull(), 'Embarked'] = 'C'","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.150653Z","iopub.execute_input":"2022-02-10T10:46:31.151066Z","iopub.status.idle":"2022-02-10T10:46:31.496032Z","shell.execute_reply.started":"2022-02-10T10:46:31.151036Z","shell.execute_reply":"2022-02-10T10:46:31.495265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Imputing missing values in Fare","metadata":{}},{"cell_type":"code","source":"data[data['Fare'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.497061Z","iopub.execute_input":"2022-02-10T10:46:31.497397Z","iopub.status.idle":"2022-02-10T10:46:31.522027Z","shell.execute_reply.started":"2022-02-10T10:46:31.497364Z","shell.execute_reply":"2022-02-10T10:46:31.521128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here I calculate the median value of Fare for the people for Passenger class 3 because the passenger with the missing value of Fare belonged to Pclass 3","metadata":{}},{"cell_type":"code","source":"np.nanmedian(data[data['Pclass']==3]['Fare'])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.523253Z","iopub.execute_input":"2022-02-10T10:46:31.523616Z","iopub.status.idle":"2022-02-10T10:46:31.531424Z","shell.execute_reply.started":"2022-02-10T10:46:31.523575Z","shell.execute_reply":"2022-02-10T10:46:31.530648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fm = np.nanmedian(data[(data['Pclass']==1)]['Fare'])\ndata.loc[data['Fare'].isnull(), 'Fare'] = fm","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.532659Z","iopub.execute_input":"2022-02-10T10:46:31.532879Z","iopub.status.idle":"2022-02-10T10:46:31.542057Z","shell.execute_reply.started":"2022-02-10T10:46:31.532846Z","shell.execute_reply":"2022-02-10T10:46:31.541311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transforming Fare attribute with log transformation","metadata":{}},{"cell_type":"markdown","source":"#### Since there are multiple people in a family, there are multiple tickets that are bought for the journey. The fare price is the total amount paid for the entire group/family. I calculate the amount spent per person in buying the tickets by dividing the fare price by the total number of people in a particular group","metadata":{}},{"cell_type":"code","source":"\ndata['Fare'] = data['Fare'] / data['Ticket_Frequency']","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.543258Z","iopub.execute_input":"2022-02-10T10:46:31.543449Z","iopub.status.idle":"2022-02-10T10:46:31.554054Z","shell.execute_reply.started":"2022-02-10T10:46:31.543425Z","shell.execute_reply":"2022-02-10T10:46:31.553417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(data['Fare'], kde = True);","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:31.555276Z","iopub.execute_input":"2022-02-10T10:46:31.555711Z","iopub.status.idle":"2022-02-10T10:46:32.16642Z","shell.execute_reply.started":"2022-02-10T10:46:31.555681Z","shell.execute_reply":"2022-02-10T10:46:32.165645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see, the above distribution is very skewed and this can create a significant bias in our models","metadata":{}},{"cell_type":"markdown","source":"#### So, in order to mitigate that problem, we transform the Fare data with log transformation","metadata":{}},{"cell_type":"code","source":"d = data[data['Fare'] != 0].index\ndata['Fare'] = data['Fare'].map(lambda i: np.log(i) if i>0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:32.167409Z","iopub.execute_input":"2022-02-10T10:46:32.167599Z","iopub.status.idle":"2022-02-10T10:46:32.175647Z","shell.execute_reply.started":"2022-02-10T10:46:32.167576Z","shell.execute_reply":"2022-02-10T10:46:32.17482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The below data looks much better than above but it can still create a lot of unnecessary bias","metadata":{}},{"cell_type":"code","source":"sns.histplot(data['Fare'], kde = True);","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:32.17664Z","iopub.execute_input":"2022-02-10T10:46:32.176829Z","iopub.status.idle":"2022-02-10T10:46:32.454474Z","shell.execute_reply.started":"2022-02-10T10:46:32.176806Z","shell.execute_reply":"2022-02-10T10:46:32.453629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(data = data, x = 'Fare', bins = 10);","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:32.456965Z","iopub.execute_input":"2022-02-10T10:46:32.45724Z","iopub.status.idle":"2022-02-10T10:46:32.668088Z","shell.execute_reply.started":"2022-02-10T10:46:32.457209Z","shell.execute_reply":"2022-02-10T10:46:32.667336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dividing the Fare into different categories based on the price of the ticket","metadata":{}},{"cell_type":"markdown","source":"#### I divide the Fare attribute to mitigate the bias problem and make sure that I include enough data points in every class. The only problem in this is that we lose a bit of information which it makes up for by reducing the bias","metadata":{}},{"cell_type":"code","source":"data.loc[(data['Fare'] >= 0) & (data['Fare'] <= 2.1), 'Cost'] = 0\ndata.loc[(data['Fare'] > 2.1) & (data['Fare'] <= 3), 'Cost'] = 1\ndata.loc[(data['Fare'] > 3), 'Cost'] = 2\ndata.groupby('Cost').mean()['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:32.669639Z","iopub.execute_input":"2022-02-10T10:46:32.669927Z","iopub.status.idle":"2022-02-10T10:46:32.688092Z","shell.execute_reply.started":"2022-02-10T10:46:32.669889Z","shell.execute_reply":"2022-02-10T10:46:32.687233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Below are the survival probability of the classes of the different attributes","metadata":{}},{"cell_type":"markdown","source":"#### Looking at this graph helps us know that which attribute has the highest influence on the survivability of a passenger","metadata":{}},{"cell_type":"code","source":"count = 1\ncol = ['Family_Size', 'Pclass', 'Embarked', 'Sex', 'Cost', 'Age_group', 'Deck', 'SP']\nplt.figure(figsize = (20, 8))\nfor i in range(len(col)):\n    plt.subplot(2, 4, count)\n    sns.barplot(data = data, x = col[i], y = 'Survived')\n    count += 1;","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:32.689249Z","iopub.execute_input":"2022-02-10T10:46:32.689513Z","iopub.status.idle":"2022-02-10T10:46:34.348253Z","shell.execute_reply.started":"2022-02-10T10:46:32.689485Z","shell.execute_reply":"2022-02-10T10:46:34.347621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.value_counts(data['Cost'])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:34.349268Z","iopub.execute_input":"2022-02-10T10:46:34.349899Z","iopub.status.idle":"2022-02-10T10:46:34.356809Z","shell.execute_reply.started":"2022-02-10T10:46:34.349829Z","shell.execute_reply":"2022-02-10T10:46:34.355862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling Numerical attributes","metadata":{}},{"cell_type":"code","source":"att = ['Fare', 'Parch', 'SibSp', 'Relatives', 'Age', 'Survival']\nss = StandardScaler()\ndata[att] = ss.fit_transform(data[att])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:34.35809Z","iopub.execute_input":"2022-02-10T10:46:34.358498Z","iopub.status.idle":"2022-02-10T10:46:34.376095Z","shell.execute_reply.started":"2022-02-10T10:46:34.358465Z","shell.execute_reply":"2022-02-10T10:46:34.375347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding categorical attributes","metadata":{}},{"cell_type":"code","source":"le = LabelEncoder()\ncat = ['Embarked', 'Deck']\nfor col in cat:\n    data[col] = le.fit_transform(data[col])","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:34.377297Z","iopub.execute_input":"2022-02-10T10:46:34.377499Z","iopub.status.idle":"2022-02-10T10:46:34.383669Z","shell.execute_reply.started":"2022-02-10T10:46:34.377476Z","shell.execute_reply":"2022-02-10T10:46:34.38313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Crammer's V for correlation of categorical attributes","metadata":{}},{"cell_type":"markdown","source":"##### Crammer's v is used to calculate correlation between 2 categorical attributes. We cannot use Pearson's R for this task as that can only be used for numerical attributes","metadata":{}},{"cell_type":"code","source":"def cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = sst.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))/(n-1))\n    rcorr = r-((r-1)**2)/(n-1)\n    kcorr = k-((k-1)**2)/(n-1)\n    return np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:34.384644Z","iopub.execute_input":"2022-02-10T10:46:34.385228Z","iopub.status.idle":"2022-02-10T10:46:34.392154Z","shell.execute_reply.started":"2022-02-10T10:46:34.385192Z","shell.execute_reply":"2022-02-10T10:46:34.39156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the correlation matrix of the categorical attributes","metadata":{}},{"cell_type":"code","source":"att = ['Pclass', 'Embarked', 'Family_Size', 'Age_group', 'SP', 'Sex', 'TF', 'Cost', 'Deck', 'Survived']\ncor = pd.DataFrame()\nfor i in att:\n    for j in att:\n        cor.loc[i, j] = cramers_v(data.loc[:len(train), i], data.loc[:len(train), j])\nfor i in att:\n    cor[i].astype(np.float)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:34.393304Z","iopub.execute_input":"2022-02-10T10:46:34.394019Z","iopub.status.idle":"2022-02-10T10:46:35.315964Z","shell.execute_reply.started":"2022-02-10T10:46:34.39399Z","shell.execute_reply":"2022-02-10T10:46:35.315138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 8))\nsns.heatmap(cor, annot = True);","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:35.317039Z","iopub.execute_input":"2022-02-10T10:46:35.317267Z","iopub.status.idle":"2022-02-10T10:46:36.084766Z","shell.execute_reply.started":"2022-02-10T10:46:35.31724Z","shell.execute_reply":"2022-02-10T10:46:36.084184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### [Pclass, SP, Sex, Cost, Deck] looks like promising attributes","metadata":{}},{"cell_type":"markdown","source":"#### The reason I didn't include TF in the above list even though it had a high enough correlation with survived is that it has a high correlation with SP attribute. And we should avoid including redudant attributes in our data. It can create bias which may reduce the perfomance of our models\n\n\n\n#### Also, there is a very high correlation between Cost and Pclass and you can choose to not include Cost attribute in your final dataset but including it yielded a little better accuracy on submission so I chose to include it in mine.","metadata":{}},{"cell_type":"markdown","source":"### Pearson's Correlation for Numerical Attributes","metadata":{}},{"cell_type":"code","source":"colls = ['Fare', 'Relatives', 'Survival', 'SibSp', 'Parch', 'Survived']\ncorr_mat_num = data.loc[:len(train), colls].corr()\ndat = data[:len(train)]\nfor i in range(len(colls) - 1):\n    corr_mat_num.loc['Survived', colls[i]] = sst.pointbiserialr(dat['Survived'], dat[colls[i]])[0]\n    corr_mat_num.loc[colls[i], 'Survived'] = sst.pointbiserialr(dat[colls[i]], dat['Survived'])[0]\nplt.figure(figsize = (10, 7))\nsns.heatmap(corr_mat_num, annot = True);","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.085794Z","iopub.execute_input":"2022-02-10T10:46:36.086109Z","iopub.status.idle":"2022-02-10T10:46:36.483179Z","shell.execute_reply.started":"2022-02-10T10:46:36.086082Z","shell.execute_reply":"2022-02-10T10:46:36.482244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There isn't any significant correlation of the given numerical attributes with the Survived attribute except for Fare and Survival, but they have already been accounted for by including Cost and SP attributes. So, I won't be including any numerical attribute in my dataset","metadata":{}},{"cell_type":"markdown","source":"### Selecting only those attributes with a high correlation coefficient","metadata":{}},{"cell_type":"code","source":"# Selecting the following attributes because they worked best in practice\ncoll = ['Survived', 'Pclass', 'Sex', 'Survival', 'Cost'] \n# I included Survival because it worked better than SP even though SP had a lower correlation\ndata = data[coll]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.484751Z","iopub.execute_input":"2022-02-10T10:46:36.485066Z","iopub.status.idle":"2022-02-10T10:46:36.492528Z","shell.execute_reply.started":"2022-02-10T10:46:36.485024Z","shell.execute_reply":"2022-02-10T10:46:36.491767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One-Hot Encoding non-ordinal categories","metadata":{}},{"cell_type":"markdown","source":"#### O-H Encoding 'Sex' because it is non-ordinal in nature","metadata":{}},{"cell_type":"code","source":"col = ['Sex']\ndata = pd.get_dummies(data, columns = col, drop_first = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.49425Z","iopub.execute_input":"2022-02-10T10:46:36.494806Z","iopub.status.idle":"2022-02-10T10:46:36.504638Z","shell.execute_reply.started":"2022-02-10T10:46:36.494766Z","shell.execute_reply":"2022-02-10T10:46:36.503927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.505914Z","iopub.execute_input":"2022-02-10T10:46:36.506352Z","iopub.status.idle":"2022-02-10T10:46:36.521494Z","shell.execute_reply.started":"2022-02-10T10:46:36.506322Z","shell.execute_reply":"2022-02-10T10:46:36.520486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Separating the training and testing data","metadata":{}},{"cell_type":"code","source":"train, test = data[:len(train)], data[len(train):]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.522718Z","iopub.execute_input":"2022-02-10T10:46:36.52307Z","iopub.status.idle":"2022-02-10T10:46:36.531038Z","shell.execute_reply.started":"2022-02-10T10:46:36.523037Z","shell.execute_reply":"2022-02-10T10:46:36.530439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Shuffling the training set","metadata":{}},{"cell_type":"code","source":"train = train.sample(frac = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.532274Z","iopub.execute_input":"2022-02-10T10:46:36.532721Z","iopub.status.idle":"2022-02-10T10:46:36.545753Z","shell.execute_reply.started":"2022-02-10T10:46:36.532692Z","shell.execute_reply":"2022-02-10T10:46:36.544872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train, X_test = train.drop(['Survived'], axis = 1), train['Survived'], test.drop(['Survived'], axis = 1)\nX_train.shape, y_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.547205Z","iopub.execute_input":"2022-02-10T10:46:36.547689Z","iopub.status.idle":"2022-02-10T10:46:36.558711Z","shell.execute_reply.started":"2022-02-10T10:46:36.54765Z","shell.execute_reply":"2022-02-10T10:46:36.558041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.56009Z","iopub.execute_input":"2022-02-10T10:46:36.560551Z","iopub.status.idle":"2022-02-10T10:46:36.573276Z","shell.execute_reply.started":"2022-02-10T10:46:36.560521Z","shell.execute_reply":"2022-02-10T10:46:36.572366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.574561Z","iopub.execute_input":"2022-02-10T10:46:36.574955Z","iopub.status.idle":"2022-02-10T10:46:36.585902Z","shell.execute_reply.started":"2022-02-10T10:46:36.574926Z","shell.execute_reply":"2022-02-10T10:46:36.585337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid, y_valid = X_train[800:], y_train[800:]\nX_valid.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.58706Z","iopub.execute_input":"2022-02-10T10:46:36.587424Z","iopub.status.idle":"2022-02-10T10:46:36.598999Z","shell.execute_reply.started":"2022-02-10T10:46:36.587385Z","shell.execute_reply":"2022-02-10T10:46:36.598096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importance of the features we have selected","metadata":{}},{"cell_type":"code","source":"et = ExtraTreesClassifier(n_estimators = 39)\net.fit(X_train, y_train)\net.score(X_valid, y_valid), et.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.600103Z","iopub.execute_input":"2022-02-10T10:46:36.60057Z","iopub.status.idle":"2022-02-10T10:46:36.673492Z","shell.execute_reply.started":"2022-02-10T10:46:36.600531Z","shell.execute_reply":"2022-02-10T10:46:36.672938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(et.feature_importances_, \n             index = X_train.columns)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.674708Z","iopub.execute_input":"2022-02-10T10:46:36.675457Z","iopub.status.idle":"2022-02-10T10:46:36.685021Z","shell.execute_reply.started":"2022-02-10T10:46:36.675421Z","shell.execute_reply":"2022-02-10T10:46:36.684243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see, the Survival attribute has a high importance which confirms the thinking that people survived in groups. If significant number of people from someone's group died then it is highly likely that they died as well","metadata":{}},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"param = [\n    {\n        'kernel': ['rbf'], 'C': [0.1, 0.3, 1, 2, 3, 4], \n        'gamma': [0.3, 1, 3, 10, 12, 15, 25, 28]\n    }, \n]\n\nsvc = SVC(probability = True)\ngs_svc = GridSearchCV(svc, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_svc.fit(X_train, y_train)\nsvc_best = gs_svc.best_estimator_\ngs_svc.best_estimator_, gs_svc.score(X_valid, y_valid), gs_svc.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:46:36.685992Z","iopub.execute_input":"2022-02-10T10:46:36.686755Z","iopub.status.idle":"2022-02-10T10:46:56.623047Z","shell.execute_reply.started":"2022-02-10T10:46:36.686711Z","shell.execute_reply":"2022-02-10T10:46:56.622131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"param_grid={\n    'max_depth': range(2, 10, 2),\n    'n_estimators': range(26, 46, 2),\n    'learning_rate': [0.2, 0.1, 0.03, 0.01]\n}\n\nxg = XGBClassifier(eval_metric='logloss', n_jobs = -1, use_label_encoder = False)\ngs_xg = GridSearchCV(xg, param_grid, cv = 5, n_jobs = -1, verbose = 1)\ngs_xg.fit(X_train, y_train)\n\nxg_best = gs_xg.best_estimator_\ngs_xg.best_params_, gs_xg.score(X_valid, y_valid), gs_xg.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:47:18.666749Z","iopub.execute_input":"2022-02-10T10:47:18.667467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"param = [\n    {'n_estimators': [100, 200, 300, 400, 450, 500], \n     'max_depth': [3, 4, 6, 8, 10, 12], \n     'max_leaf_nodes': [15, 20, 25]}, \n]\n\nrf = RandomForestClassifier()\ngs_rf = GridSearchCV(rf, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_rf.fit(X_train, y_train)\n\nrf_best = gs_rf.best_estimator_\ngs_rf.best_estimator_, gs_rf.score(X_valid, y_valid), gs_rf.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(rf_best.feature_importances_, index = X_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adaptive Boosting","metadata":{}},{"cell_type":"code","source":"param = [\n    {'n_estimators': [50, 100, 150, 200, 300, 400]}\n]\nada = AdaBoostClassifier()\ngs_ada = GridSearchCV(ada, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_ada.fit(X_train, y_train)\n\nada_best = gs_ada.best_estimator_\ngs_ada.best_estimator_, gs_ada.score(X_valid, y_valid), gs_ada.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extra Trees Classifier","metadata":{}},{"cell_type":"code","source":"param = [\n    {'n_estimators': range(8, 28, 4), \n     'max_depth': range(24, 48, 4),\n     'max_leaf_nodes': range(20, 48, 4),\n    }\n]\n\net = ExtraTreesClassifier()\ngs_et = GridSearchCV(et, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_et.fit(X_train, y_train)\n\net_best = gs_et.best_estimator_\ngs_et.best_estimator_, gs_et.score(X_valid, y_valid), gs_et.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"et_best.fit(X_train, y_train)\npd.Series(et_best.feature_importances_, index = X_train.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN","metadata":{}},{"cell_type":"code","source":"param = [\n    {'n_neighbors': range(2, 14, 1)}\n]\n\nknn = KNeighborsClassifier()\ngs_knn = GridSearchCV(knn, param, cv = 5, n_jobs = -1)\ngs_knn.fit(X_train, y_train)\n\nknn_best = gs_knn.best_estimator_\ngs_knn.best_estimator_, gs_knn.score(X_valid, y_valid), gs_knn.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"param = [\n    {\n        'criterion': ['gini', 'entropy'],\n        'max_depth': range(4, 20, 2),\n        'max_leaf_nodes': range(4, 28, 2),\n    }\n]\n\ndt = DecisionTreeClassifier()\ngs_dt = GridSearchCV(dt, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_dt.fit(X_train, y_train)\n\ndt_best = gs_dt.best_estimator_\ngs_dt.best_estimator_, gs_dt.score(X_valid, y_valid), gs_dt.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting ","metadata":{}},{"cell_type":"code","source":"param = [\n    {'n_estimators': range(12, 36, 4), \n     'max_depth': range(8, 24, 4),\n     'max_leaf_nodes': range(8, 28, 4),\n    }\n]\n\ngb = GradientBoostingClassifier()\ngs_gb = GridSearchCV(et, param, cv = 5, n_jobs = -1, verbose = 1)\ngs_gb.fit(X_train, y_train)\n\n\ngb_best = gs_gb.best_estimator_\ngs_gb.best_estimator_, gs_gb.score(X_valid, y_valid), gs_gb.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Voting Classifier","metadata":{}},{"cell_type":"markdown","source":"#### Here I use the best models found by the hyperparameter search of all the models above for voting","metadata":{}},{"cell_type":"code","source":"vc_lr = LogisticRegression(solver = 'sag')\nvc_mlp = MLPClassifier()\n\nvc = VotingClassifier(estimators = [('rf', rf_best), ('svc', svc_best), ('lr', vc_lr), \n                                    ('mlp', vc_mlp), ('xgc', xg_best), ('knn', knn_best),\n                                    ('ada', ada_best), ('ET', et_best), ('dt', dt_best),\n                                    ('gb', gb_best)], \n                                    voting = 'soft', n_jobs = -1, verbose = 1)\nvc.fit(X_train, y_train)\nvc.score(X_valid, y_valid), vc.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing Models","metadata":{}},{"cell_type":"code","source":"m = [gs_svc, gs_xg, gs_rf, gs_et, gs_ada, gs_dt, gs_gb, gs_knn, vc]\nn = ['SVC', 'XGBoost', 'Random Forest', 'Extra Trees', 'Adaboost', 'Decision Tree', 'Gradient Boosting', 'K-Nearest Neighbors', 'Voting Classifier']\np = dict()\nfor i in range(len(m)):\n    pred = m[i].score(X_train, y_train)\n    p[n[i]] = pred\n\np = dict(sorted(p.items(), key = lambda x: x[1], reverse = True))\nplt.figure(figsize = (8, 6))\nplt.xlabel('Accuracy')\nsns.barplot(x = list(p.values()), y = list(p.keys()), orient = 'h');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions!!","metadata":{}},{"cell_type":"markdown","source":"##### After a lot of experimentation, Gradient Boosting gave me the best results in practice, so I will be using GB for making the predictions. Also, I had to re-submit multiple times to reach the best accuracy. You'll get different accuracies every time you submit because the training set is shuffled differently and that affects the way the models are trained","metadata":{}},{"cell_type":"code","source":"predictions = gs_gb.predict(X_test).astype(np.uint8)\nsub = pd.read_csv('../input/titanic/gender_submission.csv')\nsub['Survived'] = predictions\nsub.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}