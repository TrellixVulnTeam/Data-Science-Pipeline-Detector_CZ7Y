{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Basic Packages\nimport pandas as pd\nimport numpy as numpy\n\n#H2O\nimport h2o\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\n\n#Evaluation Packages\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialize H2O\nh2o.init()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import train and test Datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Treat Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"all = pd.concat([train, test], sort = False)\nall.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill Missing numbers with median for Age and Fare\nall['Age'] = all['Age'].fillna(value=all['Age'].median())\nall['Fare'] = all['Fare'].fillna(value=all['Fare'].median())\n\n#Treat Embarked\nall['Embarked'] = all['Embarked'].fillna(value=all['Embarked'].mode()[0])\n\n#Bin Age\nall.loc[ all['Age'] <= 16, 'Age'] = 0\nall.loc[(all['Age'] > 16) & (all['Age'] <= 32), 'Age'] = 1\nall.loc[(all['Age'] > 32) & (all['Age'] <= 48), 'Age'] = 2\nall.loc[(all['Age'] > 48) & (all['Age'] <= 64), 'Age'] = 3\nall.loc[ all['Age'] > 64, 'Age'] = 4 \n\n#Cabin\nall['Cabin'] = all['Cabin'].fillna('Missing')\nall['Cabin'] = all['Cabin'].str[0]\n\n#Family Size & Alone \nall['Family_Size'] = all['SibSp'] + all['Parch'] + 1\nall['IsAlone'] = 0\nall.loc[all['Family_Size']==1, 'IsAlone'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extra Features: Title"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract Title from Name\nall['Title'] = all['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will combine a few categories, since few of them are unique \nall['Title'] = all['Title'].replace(['Capt', 'Dr', 'Major', 'Rev'], 'Officer')\nall['Title'] = all['Title'].replace(['Lady', 'Countess', 'Don', 'Sir', 'Jonkheer', 'Dona'], 'Royal')\nall['Title'] = all['Title'].replace(['Mlle', 'Ms'], 'Miss')\nall['Title'] = all['Title'].replace(['Mme'], 'Mrs')\nall['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop unwanted variables\nall = all.drop(['Name', 'Ticket'], axis = 1)\nall.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Dummy Values\nWe will drop one of them using drop_first = True"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_dummies = pd.get_dummies(all, drop_first = True)\nall_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Covert Pandas Dataframe to H2O Frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_train = h2o.H2OFrame(all_dummies[all_dummies['Survived'].notna()])\nall_test = h2o.H2OFrame(all_dummies[all_dummies['Survived'].isna()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train/Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get columns names for Building H2O Models\ntarget = 'Survived'\npredictors = [f for f in all_train.columns if f not in ['Survived','PassengerId']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Diving the dataset into Train, Validation and Test\n- **Train:** will be used to build model\n- **Validation** is used to help improve the evaluation metric (We will not use this in this kernel)\n- **Test** is used to help us evaluate the model we built"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, valid_df, test_df = all_train.split_frame(ratios=[0.7, 0.15], seed=2018)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Covert dtype to factor as per H2O implementation\ntrain_df[target] = train_df[target].asfactor()\nvalid_df[target] = valid_df[target].asfactor()\ntest_df[target] = test_df[target].asfactor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check X Variables\npredictors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize the H2O GBM \ngbm = H2OGradientBoostingEstimator()\n\n# train with the initialized model\ngbm.train(x=predictors, y=target, training_frame=train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict on Test Frame to evaluate how well our model performed\n#as_data_frame() converts the data to Pandas DataFrame\npred_val = gbm.predict(test_df[predictors])[0].as_data_frame()\npred_val","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"true_val = (test_df[target]).as_data_frame()\nprediction_auc = roc_auc_score(pred_val, true_val)\nprediction_auc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Predictions for Competition"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get X Variables from Competition Test Dataset\nTestForPred = all_test.drop(['PassengerId', 'Survived'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict\nfin_pred = gbm.predict(TestForPred[predictors])[0].as_data_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get Competition Test Ids\nPassengerId = all_test['PassengerId'].as_data_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make Submission File\nh2o_Sub = pd.DataFrame({'PassengerId': PassengerId['PassengerId'].tolist(), 'Survived':fin_pred['predict'].tolist() })\nh2o_Sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Export Submission File\nh2o_Sub.to_csv(\"1_h2o_Submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}