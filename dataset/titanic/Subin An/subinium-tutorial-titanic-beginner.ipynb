{"cells":[{"metadata":{"_uuid":"0659906ea0865d1333efd2d9d0d4a876841d8d46"},"cell_type":"markdown","source":"# [수비니움의 캐글 따라하기] 타이타닉 : Beginner Ver."},{"metadata":{"_uuid":"0b04cd5a0949d5c1525af6ee291008768b86e6d6"},"cell_type":"markdown","source":"본 커널은 다음 참고자료를 통해 재구성한 자료입니다.\n\n- [A Journey throgh Titanic](https://www.kaggle.com/omarelgabry/a-journey-through-titanic)\n- [캐글 코리아 블로그 - 타이타닉 분석하기](https://kaggle-kr.tistory.com/17#2_6)\n\n저는 캐글을 시작하는 초보자이며, 초보자에게 더 적합하게 쉬운 튜토리얼을 제작하는 것을 목표로 하고 있습니다.\n본 튜토리얼은 다음과 같은 목표 하에 제작되었습니다.\n\n**Beginner** \n- 데이터에 대한 정보를 최소한으로 살피며 분석을 진행합니다.\n- 어려운 메소드나 복잡한 함수의 사용을 최소화합니다.\n- 본 문제를 해결하기 위해 필수적인 요소와 순서를 서술하는 단계입니다.\n- 초심자가 접근하기에 거부감이 적어야합니다.\n- 다음 단계로 갈수록 내용이 심화됩니다.\n\n\n더 많은 정보는 다음을 참고해주세요.\n\n- **블로그** : [안수빈의 블로그](https://subinium.github.io)\n- **페이스북** : [어썸너드 수비니움](https://www.facebook.com/ANsubinium)\n- **유튜브** : [수비니움의 코딩일지](https://www.youtube.com/channel/UC8cvg1_oB-IDtWT2bfBC2OQ)"},{"metadata":{"_uuid":"fc56451de7f56d39f4834c31ecc409771c125db6"},"cell_type":"markdown","source":"## 1. 라이브러리 불러오기\n\n우선 코드를 작성하기에 앞서 기초적으로 필요한 라이브러리를 불러옵니다."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 필요한 라이브러리를 우선 불러옵니다.\n\n## 데이터 분석 관련\nimport pandas as pd\nfrom pandas import Series, DataFrame\nimport numpy as np\n\n## 데이터 시각화 관련\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid') # matplotlib의 스타일에 관련한 함\n## 그래프 출력에 필요한 IPython 명령어\n%matplotlib inline \n\n## Scikit-Learn의 다양한 머신러닝 모듈을 불러옵니다.\n## 분류 알고리즘 중에서 선형회귀, 서포트벡터머신, 랜덤포레스트, K-최근접이웃 알고리즘을 사용해보려고 합니다.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dde8699d37b6690b1a87c6b08d2210c43987daf4"},"cell_type":"markdown","source":"## 2. 데이터 읽기\n\nkaggle 또는 데이터 분석에서 가장 많이 사용되는 파일 형식은 `csv` 파일입니다.\n\n코드로 데이터를 읽는 방법은 다양한 방법이 있지만, 그 중에서도 가장 유용한 것은 `pd.read_csv`로 읽는 방법입니다."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# 데이터를 우선 가져와야합니다.\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\n\n# 데이터 미리보기\ntrain_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41670d3bacf7d4060ee12e5483dec00f9d9ebdca"},"cell_type":"markdown","source":"위의 정보로 볼때 번호는 큰 의미를 가지지 않고, 이름과 티켓의 경우에는 불규칙성이 많아 처리하기 어려울 것 같습니다.\n데이터의 정보는 `info` 메서드로 확인할 수 있습니다. 훈련 데이터와 테스트 데이터를 확인해보도록 하겠습니다."},{"metadata":{"trusted":true,"_uuid":"d5b7b4c72fe4bbbcc42b96a8a82a65cfc63dbf7c"},"cell_type":"code","source":"train_df.info()\nprint('-'*20)\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c67599a18283fcbaeeabdbeec25749eb1861423"},"cell_type":"markdown","source":"위 결과에서 각각의 데이터 개수는 891개. 418개인 것을 확인할 수 있습니다.\n특성은 각각 12개 11개입니다. 그 이유는 훈련 데이터는 생존 여부를 알고 있기 때문입니다.\n\n여기서 주의깊게 봐야할 부분은 다음과 같습니다.\n\n- 각 데이터는 빈 부분이 있는가?\n    -  빈 부분이 있다면, drop할 것인가 아니면 default값으로 채워넣을 것인가\n    - cabin, Age, Embarked 세 항목에 주의\n- 데이터는 float64로 변환할 수 있는가\n    - 아니라면 범주형 데이터로 만들 수 있는가\n    \n필요없는 부분이라고 생각되는 부분을 지웁니다. 여기서는 PassengerID와 이름, 티켓을 지웁니다.\n이름과 티켓에서 가져올 수 있는 데이터는 없기 때문입니다. 하지만 이 문제에서 결과물은 `'PassengerId', 'Survived'` 요소가 필요하므로 훈련데이터에서만 삭제합니다.\n"},{"metadata":{"trusted":true,"_uuid":"7ddb70d8e07bd2a47fd42d7393491803117f9dcb"},"cell_type":"code","source":"train_df = train_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\ntest_df = test_df.drop(['Name','Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e0c3e02ee3bbd31f1abaa40b0f15c952e3a9c13"},"cell_type":"markdown","source":"## 3. 데이터 하나하나 처리하기\n\n이제 남은 데이터 종류는 다음과 같습니다.\n\n1. Pclass\n2. Sex\n3. Age\n4. SibSp\n5. Parch\n6. Fare\n7. Cabin\n8. Embarked \n\n이제 순서대로 보도록 하겠습니다."},{"metadata":{"_uuid":"5b12a180ae20f4d04a96c0d92d7298cdf8ddcae3"},"cell_type":"markdown","source":"### 3.1 Pclass\n\nPclass는 서수형 데이터입니다. 1등석, 2등석, 3등석과 같은 정보입니다.\n처음에 확인시에 데이터가 비어있지 않은 것을 확인할 수 있었습니다.\n\n데이터에 대한 확인과 데이터를 변환해보도록 하겠습니다.\n우선 각 unique한 value에 대한 카운팅은 `value_counts()` 메서드로 확인할 수 있습니다."},{"metadata":{"trusted":true,"_uuid":"9c8faa33bca2dda8c8ea3f64c4dec6a646de14f2"},"cell_type":"code","source":"train_df['Pclass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ebd72342f8e017f02018e7649d5c016fc7541d6"},"cell_type":"markdown","source":"1,2,3은 정수이니 정수이니, 그냥 실수로만 바꾸면 되지않을까 생각할 수 있습니다.\n하지만 1, 2, 3 등급은 경우에 따라 다를 수 있지만 연속적인 정보가 아니며, 각 차이 또한 균등하지 않습니다.\n그렇기에 범주형(카테고리) 데이터로 인식하고 인코딩해야합니다. (비슷한 예시로 영화 별점 등이 있습니다.)\n\n이 데이터는 범주형 데이터이므로 one-hot-encoding을 `pd.get_dummies()` 메서드로 인코딩합시다."},{"metadata":{"trusted":true,"_uuid":"50a1f56071929f7191f352414f01b7c8b2170112"},"cell_type":"code","source":"pclass_train_dummies = pd.get_dummies(train_df['Pclass'])\npclass_test_dummies = pd.get_dummies(test_df['Pclass'])\n\ntrain_df.drop(['Pclass'], axis=1, inplace=True)\ntest_df.drop(['Pclass'], axis=1, inplace=True)\n\ntrain_df = train_df.join(pclass_train_dummies)\ntest_df = test_df.join(pclass_test_dummies)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"559a6d38cdecaba65334da3b60581739f61c8e53"},"cell_type":"markdown","source":"이렇게 Pclass의 원본을 없애고, 범주형으로 개별로 데이터가 변환되었습니다.\n\n> 여기서 살짝 실수한게  columns의 이름을 설정하고, 넣어줘야하는데 안그래서 1,2,3 이라는 컬럼으로 데이터가 들어갔습니다. 다른 데이터에는 이런 적용을 피하도록 합시다.\n\n### 3.2 Sex\n\nSex는 성별입니다. 남과 여로 나뉘므로 이 또한 one-hot-encoding을 진행해봅시다."},{"metadata":{"trusted":true,"_uuid":"62d180992f349ac7cd97080d138d7f8c98d63d8e"},"cell_type":"code","source":"sex_train_dummies = pd.get_dummies(train_df['Sex'])\nsex_test_dummies = pd.get_dummies(test_df['Sex'])\n\nsex_train_dummies.columns = ['Female', 'Male']\nsex_test_dummies.columns = ['Female', 'Male']\n\ntrain_df.drop(['Sex'], axis=1, inplace=True)\ntest_df.drop(['Sex'], axis=1, inplace=True)\n\ntrain_df = train_df.join(sex_train_dummies)\ntest_df = test_df.join(sex_test_dummies)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61f95317bd6c97be304ad3cc020b49b6a1b113c5"},"cell_type":"markdown","source":"### 3.3 Age\n\n나이는 연속형 데이터이므로, 큰 처리가 필요없습니다. (카테고리화를 하여 일부 알고리즘에 더 유용한 결과를 만들 수 있습니다.)\n하지만 일부 NaN 데이터가 있으니 이를 채울 수 있는 방법에 대해서 생각해봅시다.\n\n1. 랜덤\n2. 평균값\n3. 중간값\n4. 데이터 버리기\n\n저는 일단은 평균값으로 채우도록 하겠습니다. 데이터의 통일성을 가지기 위해 train 데이터셋의 평균값으로 훈련, 테스트 데이터셋을 채우겠습니다."},{"metadata":{"_uuid":"177eaf44e1ef36e36322439963acef572a3770b2","trusted":true},"cell_type":"code","source":"train_df[\"Age\"].fillna(train_df[\"Age\"].mean() , inplace=True)\ntest_df[\"Age\"].fillna(train_df[\"Age\"].mean() , inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"382a94a1d97f402f00655c192ceddd4e38eaa1d8"},"cell_type":"markdown","source":"### 3.4 SibSp & Panch\n\n형제 자매와 부모님은 가족으로 함께 처리할 수 있습니다. 하지만 마찬가지로 바꿀 필요는 없습니다."},{"metadata":{"_uuid":"a7ef95c5dafc65f86a4488616c95ba6cdd8ee143"},"cell_type":"markdown","source":"### 3.5 Fare\n\nFare은 탑승료입니다. 신기하게 test 데이터셋에 1개의 데이터가 비어있습니다. 아마 디카프리오인듯 합니다. :-)\n우선 빈 부분을 `fillna` 메서드로 채우겠습니다. \n\n저는 데이터 누락이 아닌 무단 탑승이라 생각하고 0으로 입력하겠습니다."},{"metadata":{"trusted":true,"_uuid":"5671df22cef771e443bb2db05e8f9f0954d8f162"},"cell_type":"code","source":"test_df[\"Fare\"].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"388ab1633a29e1f91f6e22308259126422b1a3b8"},"cell_type":"markdown","source":"### 3.6 Cabin\n\nCabin은 객실입니다. NaN이 대부분인 데이터이므로 버립시다. 이 데이터를 살리는 것은 너무 어려운 일입니다."},{"metadata":{"trusted":true,"_uuid":"8373c9fa4a1561e05522e1a34cce7826d8ec0fef"},"cell_type":"code","source":"train_df = train_df.drop(['Cabin'], axis=1)\ntest_df = test_df.drop(['Cabin'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b02ab600142c62b1eaf9763c759244067a2eee5"},"cell_type":"markdown","source":"### 3.7 Embarked\n\nEmbarked는 탑승 항구를 의미합니다. 우선 데이터를 확인해보겠습니다."},{"metadata":{"trusted":true,"_uuid":"6313d17e5ccd575eeae70e533aaab97a5a337c5f"},"cell_type":"code","source":"train_df['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4254be29e771b0413978abcc8cdafeec20cc35e3"},"cell_type":"code","source":"test_df['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"054cdaee29785a75609439cc78312b3b55106d33"},"cell_type":"markdown","source":"S가 대다수이고 일부 데이터가 비어있는 것을 알 수 있습니다. 빈 부분은 S로 우선 채우고 시작합시다. "},{"metadata":{"trusted":true,"_uuid":"e2d8aa39ae741dd6132e2c98723c050a10f4e141"},"cell_type":"code","source":"train_df[\"Embarked\"].fillna('S', inplace=True)\ntest_df[\"Embarked\"].fillna('S', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c4402497994b4a1f29d9edf232465dc297ddb17"},"cell_type":"code","source":"embarked_train_dummies = pd.get_dummies(train_df['Embarked'])\nembarked_test_dummies = pd.get_dummies(test_df['Embarked'])\n\nembarked_train_dummies.columns = ['S', 'C', 'Q']\nembarked_test_dummies.columns = ['S', 'C', 'Q']\n\ntrain_df.drop(['Embarked'], axis=1, inplace=True)\ntest_df.drop(['Embarked'], axis=1, inplace=True)\n\ntrain_df = train_df.join(embarked_train_dummies)\ntest_df = test_df.join(embarked_test_dummies)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1924bbce927cf28896c86ae69c13ee82ee00e460"},"cell_type":"markdown","source":"## 4. 데이터 나누기\n\n이제 학습용 데이터를 위해 데이터를 나누어야합니다.\n\n`(정보, 생존 여부)`와 같은 형태를 위하여 다음과 같이 데이터를 나눕니다."},{"metadata":{"trusted":true,"_uuid":"df41573c670bc723042fd9362aa3a5df05e32aa1"},"cell_type":"code","source":"X_train = train_df.drop(\"Survived\",axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\",axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"acf4d5b6878dabb19e85e1aedf6e140dca0600c7"},"cell_type":"markdown","source":"## 5. 머신러닝 알고리즘 적용하기\n\n이제 로지스틱 회귀, SVC, 랜덤 포레스트, K-최근접 이웃 알고리즘을 각각 적용해봅시다."},{"metadata":{"trusted":true,"_uuid":"a977aca6a34a38708cde208e612addd0bb7b5daa"},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nlogreg.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccbac06aad9737b9dfab2ee359e9a1026c16794b"},"cell_type":"code","source":"# Support Vector Machines\n\nsvc = SVC()\n\nsvc.fit(X_train, Y_train)\n\nY_pred = svc.predict(X_test)\n\nsvc.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f614ca4ca731f7b695beef3661ba188b6ebf926"},"cell_type":"code","source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05ed56b30af981677346c1c2b47d7b07f1c54480"},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\n\nknn.fit(X_train, Y_train)\n\nY_pred = knn.predict(X_test)\n\nknn.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff1eb3d090d1faca2b4842fb4830f48fb8e1e828"},"cell_type":"markdown","source":"## 6. 제출용 파일 만들기\n\n랜덤 포레스트가 가장 좋은 결과를 내는 것을 알 수 있습니다. 그 결과로 submission 파일을 만들어 제출해봅시다."},{"metadata":{"trusted":true,"_uuid":"6c4eec0c99f3e62e11fef78f43a62d309a838051"},"cell_type":"code","source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('titanic.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ebd1f64edee8e4f21bcad2bca68debd085c468d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}