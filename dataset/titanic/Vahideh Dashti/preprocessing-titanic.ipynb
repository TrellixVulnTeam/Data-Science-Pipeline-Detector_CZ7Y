{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  Preprocessing  \n\n**Detect and remove outliers in numerical variables**\n\n**One month from now it will be complete.**\n","metadata":{}},{"cell_type":"markdown","source":"# Contents\n\n1-Import Necessary Libraries\n\n2-Read In and Explore the Data(Numerical variables in our dataset are **SibSp, Parch, Age and Fare**)\n\n3-Data Visualization\n\n4-Data preprocessing\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"markdown","source":"# 1) Import Necessary Libraries","metadata":{}},{"cell_type":"markdown","source":"**1-1: Data Analysis Libraries(Data wrangling)**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport missingno\nfrom collections import Counter","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1-2: Visualization Libraries**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1-3: Machine Learning Models**","metadata":{}},{"cell_type":"markdown","source":"They will be used ","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1-4: Model evaluation**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1-5: Hyperparameter tuning**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1-5: Remove warnings**","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2-Read our training and testing data\n\n**Importing our CSV files**","metadata":{}},{"cell_type":"code","source":"my_train_data = pd.read_csv(\"../input/titanic/train.csv\")\nmy_test_data = pd.read_csv(\"../input/titanic/test.csv\")\nmy_submission=pd.read_csv(\"../input/titanic/gender_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's have a look at the datasets:**\n\nLooking training data by describe() and info()","metadata":{}},{"cell_type":"markdown","source":"# Nacessary Information:\n\n\n**Survival: Survival (0 = No; 1 = Yes)**\n\n**Pclass: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)**\n\n**Name : Name**\n\n**Sex : Male or female**\n\n**Age : Age in years, fractional if less than 1**\n\n**Sibsp : Number of siblings or spouses aboard the titanic**\n\n**Parch : Number of parents or children aboard the titanic**\n\n**Ticket : Passenger ticket number**\n\n**Fare : Passenger Fare**\n\n**Cabin : Cabin Number**\n\n**Embarked : Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)**","metadata":{}},{"cell_type":"code","source":"my_train_data.describe(include=\"all\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_train_data.describe(include=\"all\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3-Data Analysis\n\n# Exploratory Data Analysis (EDA)\n\n\n**whats up in our dataset?**\n\nExploratory data analysis is the process of visualising and analysing data to extract insights. In other words, we want to summarise important characteristics and trends in our data in order to gain a better understanding of our dataset.\n\nget a list of the features within the titanic dataset","metadata":{}},{"cell_type":"code","source":"my_train_data.info()\nprint('-'*40)\nmy_test_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('my_train_data is :', my_train_data.shape)\nprint(' '*27)\nprint('my_test_data is :', my_test_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing data in training set\n\nmissingno.matrix(my_train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing data in test set \n\nmissingno.matrix(my_test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* Note that the test set has one column less than training set, the Survived column.\n\n* This is because Survived is our response variable, or sometimes called a target variable. \n\n* Our job is to analyse the data in the training set and predict the survival of the passengers in the test set.","metadata":{}},{"cell_type":"code","source":"my_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our final dataframe that is to be submitted should look something like this: **418 rows and 2 columns, one for PassengerId and one for Survived.**","metadata":{}},{"cell_type":"markdown","source":"# Numerical variables\n\nNumerical variables in our dataset are: **SibSp, Parch, Age and Fare**\n\n\n**Detect and remove outliers in numerical variables:**\n\n* Outliers are data points that have extreme values and they do not conform with the majority of the data.\n* It is important to address this because outliers tend to skew our data towards extremes and can cause inaccurate model predictions.\n* I will use the Tukey method to remove these outliers.","metadata":{}},{"cell_type":"markdown","source":"\n **This function will loop through a list of features and detect outliers in each one of those features**\n    \n1- In each loop, a data point is deemed an outlier if it is less than the first quartile minus the outlier step or exceeds\n    \n2- third quartile plus the outlier step. The outlier step is defined as 1.5 times the interquartile range. \n\n3- Once the outliers have been determined for one feature, their indices will be stored in a list before proceeding to the next feature and the process repeats until the very last feature is completed. \n  \n4- Finally, using the list with outlier indices, we will count the frequencies of the index numbers and return them if their frequency exceeds n times.    \n","metadata":{}},{"cell_type":"code","source":"def detect_outliers(df, n, features):\n   \n    outlier_indices = [] \n    for col in features: \n        Q1 = np.percentile(df[col], 25)\n        Q3 = np.percentile(df[col], 75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR \n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step)].index\n        outlier_indices.extend(outlier_list_col) \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(key for key, value in outlier_indices.items() if value > n) \n    return multiple_outliers\n\noutliers_to_drop = detect_outliers(my_train_data, 2, ['Age', 'SibSp', 'Parch', 'Fare'])\nprint(\"We will drop these {} indices: \".format(len(outliers_to_drop)), outliers_to_drop)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_train_data.loc[outliers_to_drop, :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Before: {} rows\".format(len(my_train_data)))\nmy_train_data = my_train_data.drop(outliers_to_drop, axis = 0).reset_index(drop = True)\nprint(\"After: {} rows\".format(len(my_train_data)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4-Data Visualization\n**Numerical variables correlation with survival**","metadata":{}},{"cell_type":"code","source":"sns.heatmap(my_train_data[['Survived', 'SibSp', 'Parch', 'Age', 'Fare']].corr(), annot = True, fmt = '.2f', cmap = 'coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numerical variable: SibSp","metadata":{}},{"cell_type":"code","source":"# Value counts of the SibSp column \n\nmy_train_data['SibSp'].value_counts(dropna = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean of survival by SibSp\n\nmy_train_data[['SibSp', 'Survived']].groupby('SibSp', as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x = 'SibSp', y ='Survived', data = my_train_data)\nplt.ylabel('Survival Probability')\nplt.title('Survival Probability by SibSp')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numerical variable: Parch","metadata":{"trusted":true}},{"cell_type":"code","source":"# Value counts of the Parch column \n\nmy_train_data['Parch'].value_counts(dropna = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean of survival by Parch\n\nmy_train_data[['Parch', 'Survived']].groupby('Parch', as_index = False).mean().sort_values(by = 'Survived', ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x = 'Parch', y ='Survived', data = my_train_data)\nplt.ylabel('Survival Probability')\nplt.title('Survival Probability by Parch')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numerical variable: Age","metadata":{}},{"cell_type":"code","source":"# Null values in Age column \n\nmy_train_data['Age'].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Passenger age distribution\n\nsns.distplot(my_train_data['Age'], label = 'Skewness: %.3f'%(my_train_data['Age'].skew()))\nplt.legend(loc = 'best')\nplt.title('Passenger Age Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Age distribution by survival\n\ng = sns.FacetGrid(my_train_data, col = 'Survived')\ng.map(sns.distplot, 'Age')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numerical variable: Fare","metadata":{}},{"cell_type":"code","source":"# Null values of Fare column \n\nmy_train_data['Fare'].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Passenger fare distribution\n\nsns.distplot(my_train_data['Fare'], label = 'Skewness: %.2f'%(my_train_data['Fare'].skew()))\nplt.legend(loc = 'best')\nplt.ylabel('Passenger Fare Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  4. Data preprocessing\n\n**Data preprocessing is the process of getting our dataset ready for model training. In this section, we will perform the following preprocessing steps:**\n\n- **Drop and fill missing values**\n- **Data trasformation (log transformation)**\n- **Feature engineering**\n- **Feature encoding**","metadata":{}},{"cell_type":"markdown","source":"# 4.1 Drop and fill missing values","metadata":{}},{"cell_type":"code","source":"# Drop ticket and cabin features from training and test set\n\nmy_train_data = my_train_data.drop(['Ticket', 'Cabin'], axis = 1)\nmy_test_data = my_test_data.drop(['Ticket', 'Cabin'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nI have decided to drop both ticket and cabin for simplicity of this tutorial but if you have the time, I would recommend going through them and see if they can help improve your model.","metadata":{}},{"cell_type":"code","source":"# Missing values in training set \n\nmy_train_data.isnull().sum().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the most frequent value of Embarked in training set\n\nmode = my_train_data['Embarked'].dropna().mode()[0]\nmode","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing value in Embarked with mode\n\nmy_train_data['Embarked'].fillna(mode, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values in test set\n\nmy_test_data.isnull().sum().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute median of Fare in test set \n\nmedian = my_test_data['Fare'].dropna().median()\nmedian","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing value in Fare with median\n\nmy_test_data['Fare'].fillna(median, inplace = True)\n\n# Combine training set and test set\n\ncombine = pd.concat([my_train_data, my_test_data], axis = 0).reset_index(drop = True)\ncombine.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert Sex into numerical values where 0 = male and 1 = female\n\ncombine['Sex'] = combine['Sex'].map({'male': 0, 'female': 1})\n\nsns.factorplot(y = 'Age', x = 'Sex', hue = 'Pclass', kind = 'box', data = combine)\nsns.factorplot(y = 'Age', x = 'Parch', kind = 'box', data = combine)\nsns.factorplot(y = 'Age', x = 'SibSp', kind = 'box', data = combine)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(combine.drop(['Survived', 'Name', 'PassengerId', 'Fare'], axis = 1).corr(), annot = True, cmap = 'coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}