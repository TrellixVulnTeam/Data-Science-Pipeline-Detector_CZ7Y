{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"For this project we will be exploring publicly available data from **LendingClub.com.** \n\nLending Club connects people who need money (borrowers) with people who have money (investors). Hopefully, as an investor you would want to invest in people who showed a profile of having a high probability of paying you back.\n\n**We will try to create a model that will help predict this.**\n\nWe will use lending data from 2007-2010 and be trying to classify and predict whether or not the borrower paid back their loan in full.","metadata":{}},{"cell_type":"markdown","source":"# Here are what the columns represent:\n\n* **credit.policy:** 1= if the customer meets the credit underwriting criteria of LendingClub.com, and 0= otherwise.\n \n* **purpose:** The purpose of the loan (takes values \"credit_card\", \"debt_consolidation\", \"educational\", \"major_purchase\", \"small_business\", and \"all_other\").\n \n* **int.rate:** The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n \n* **installment:** The monthly installments owed by the borrower if the loan is funded.\n \n* **log.annual.inc:** The natural log of the self-reported annual income of the borrower.\n \n* **dti:** The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n \n* **fico:** The FICO credit score of the borrower.\n \n* **days.with.cr.line:** The number of days the borrower has had a credit line.\n \n* **revol.bal:** The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n \n* **revol.util:** The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n\n* **inq.last.6mths:** The borrower's number of inquiries by creditors in the last 6 months.\n\n* **delinq.2yrs:** The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n\n* **pub.rec:** The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries\nImport the usual libraries for pandas and plotting. You can import sklearn later on.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get the Data\n\n**Use pandas to read loan_data.csv as a dataframe called loans.**","metadata":{}},{"cell_type":"code","source":"loans = pd.read_csv('../input/lending-club-loan-data-imbalance-dataset/loan_data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Check out \n**info(), head(), and describe() methods on loans.**","metadata":{}},{"cell_type":"code","source":"loans.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loans.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loans.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis\n\n* **Let's do some data visualization!**\n\n* **We'll use seaborn and pandas built-in plotting capabilities, but feel free to use whatever library you want.** \n\n\n* **Create a histogram of two FICO distributions on top of each other, one for each credit.policy outcome.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\nloans[loans['credit.policy']==1]['fico'].hist(alpha=0.5,color='blue',\n                                              bins=30,label='Credit.Policy=1')\n\nloans[loans['credit.policy']==0]['fico'].hist(alpha=0.5,color='red',\n                                              bins=30,label='Credit.Policy=0')\nplt.legend()\n\nplt.xlabel('FICO')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**Create a similar figure, except this time select by the not.fully.paid column.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nloans[loans['not.fully.paid']==1]['fico'].hist(alpha=0.5,color='blue',\n                                              bins=30,label='not.fully.paid=1')\nloans[loans['not.fully.paid']==0]['fico'].hist(alpha=0.5,color='red',\n                                              bins=30,label='not.fully.paid=0')\nplt.legend()\nplt.xlabel('FICO')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create a countplot using seaborn showing the counts of loans by purpose, with the color hue defined by not.fully.paid.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(11,7))\nsns.countplot(x='purpose',hue='not.fully.paid',data=loans,palette='Set1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Let's see the trend between FICO score and interest rate.** \n* **Recreate the following jointplot.**","metadata":{}},{"cell_type":"code","source":"sns.jointplot(x='fico',y='int.rate',data=loans,color='purple')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **Create the following lmplots to see if the trend differed between not.fully.paid and credit.policy.** ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(11,7))\nsns.lmplot(y='int.rate',x='fico',data=loans,hue='credit.policy',\n           col='not.fully.paid',palette='Set1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting up the Data\n\n**Let's get ready to set up our data for our Random Forest Classification Model!**\n\n**Check loans.info() again.**","metadata":{}},{"cell_type":"code","source":"loans.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Categorical Features\n\n* Notice that the purpose column as categorical\n\n* That means we need to transform them using dummy variables so sklearn will be able to understand them. Let's do this in one clean step using pd.get_dummies.\n\n* Let's show you a way of dealing with these columns that can be expanded to multiple categorical features if necessary.\n\n* Create a list of 1 element containing the string 'purpose'. Call this list cat_feats.","metadata":{}},{"cell_type":"code","source":"cat_feats = ['purpose']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now use pd.get_dummies(loans,columns=cat_feats,drop_first=True) to create a fixed larger dataframe that has new feature columns with dummy variables.**\n\n**Set this dataframe as final_data.**","metadata":{}},{"cell_type":"code","source":"final_data = pd.get_dummies(loans,columns=cat_feats,drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Split\n\n**Now its time to split our data into a training set and a testing set!**\n\n **Use sklearn to split your data into a training set and a testing set as we've done in the past.**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = final_data.drop('not.fully.paid',axis=1)\ny = final_data['not.fully.paid']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training a Decision Tree Model\n\n**Let's start by training a single decision tree first!**\n\n **Import DecisionTreeClassifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.**","metadata":{}},{"cell_type":"code","source":"dtree = DecisionTreeClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtree.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predictions and Evaluation of Decision Tree**\n\nCreate predictions from the test set and create a classification report and a confusion matrix.","metadata":{}},{"cell_type":"code","source":"predictions = dtree.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training the Random Forest model**\n\n**Now its time to train our model!**\n\n\nCreate an instance of the RandomForestClassifier class and fit it to our training data from the previous step.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predictions and Evaluation\n**\n\n**Let's predict off the y_test values and evaluate our model.\n\n****Predict the class of not.fully.paid for the X_test data.**","metadata":{}},{"cell_type":"code","source":"predictions = rfc.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now create a classification report from the results.**\n\n****Do you get anything strange or some sort of warning?**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Show the Confusion Matrix for the predictions.**","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What performed better the random forest or the decision tree?**\n\n* Depends what metric you are trying to optimize for. \n* Notice the recall for each class for the models. Neither did very well, more feature engineering is needed.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}