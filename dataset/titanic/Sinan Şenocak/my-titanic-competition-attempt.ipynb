{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n    \n    Content:\n    \n1.  [Loading Data](#1)\n\n1.  [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        * [Categorical Variable Analysis](#4)\n        * [Numerical Variable Analysis](#5)\n\n1.  [Basic Data Analysis](#6)\n\n1.  [Outlier Detection](#7)\n\n1.  [Missing Values](#8)\n    * [Finding Missing Values](#9)\n    * [Filling Missing Values In](#10)\n\n1.  [Visualization](#11)\n    * [Correlation](#12)\n    * [\"SibSp\" and \"Survived\"](#13)\n    * [\"ParCh\" and \"Survived\"](#14)\n    * [\"PClass\" and \"Survived\"](#15)\n    * [\"Age\" and \"Survived\"](#16)\n    * [\"PClass\", \"Age\" and \"Survived\"](#17)\n    * [\"Embarked\", \"PClass\" and \"Survived\"](#18)\n    * [\"Embarked\", \"Sex\", \"Fare\" and \"Survived\"](#19)\n1.  [Filling Missing Age Values](#20)\n1.  [Feature Engineering](#21)\n    *  [Name and Title](#22)\n    *  [Family Size](#23)\n    *  [Embarked](#24)\n    *  [Ticket](#25)\n    *  [Pclass](#26)\n    *  [Sex](#27)\n    * [Dropping Passenger ID & Cabin](#28)\n1. [Modelling](29)\n    *  [Train Test Split](#30)\n    *  [Simple Logistic Regression](#31)\n    *  [Hyperparameter Tuning, Grid Search & Cross Validation](#32)\n    *  [Ensemble Modelling](#33)\n1. [Prediction & Submission](#34)","metadata":{}},{"cell_type":"markdown","source":"<a id = \"1\"></a>\n\n# 1. Loading Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport os\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"] # for future purposes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"2\"></a>\n\n## 2. Variable Descriptions\n\n1. PassengerId: unique ID # of each passenger\n1. Survived: passenger survived (1) or did not (0)\n1. Pclass: class of each passenger\n1. Name\n1. Sex\n1. Age\n1. SibSp: # of Siblings or Spouses\n1. Parch: # of Parents or children\n1. Ticket: assigned ticket number\n1. Fare: price paid for a ticket\n1. Cabin: cabin category\n1. Embarked: which port passenger embarked from (C: Cherbourg, Q: Queenstown, S: Southampton)","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Every data type:\n\n* float64(2): Fare | Age\n* int64(5): Pclass | SibSp | Parch | passengerid | survived\n* object(5): Cabin | Embarked | Ticket | Name | Sex","metadata":{}},{"cell_type":"markdown","source":"<a id = \"3\"></a>\n# Univariate Variable Analysis\n* Categorical Variable: Survived | Sex | Pclass | Embarked | Cabin | Name | Ticket | SibSp | Parch\n* Numerical Variable: PassengerId | Age | Fare","metadata":{}},{"cell_type":"markdown","source":"<a id = \"4\"></a>\n## Categorical Variables","metadata":{}},{"cell_type":"code","source":"def bar_plot(variable):\n    \"\"\"\n    input: variable, example: \"Sex\"\n    output: bar plot & value count\n    \n    \"\"\"\n    # getting the feature\n    \n    var=train_df[variable]\n    \n    # counting the number of categorical variables (value or sample)\n    \n    varValue=var.value_counts()\n    \n    # visualizing\n    \n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category1 = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\nfor c in category1:\n    bar_plot(c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# moving on to remaining categorical variables\n# unlike the ones so far,\n# these can be confusing when visualized\n\ncategory2=[\"Cabin\",\"Name\",\"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"5\"></a>\n\n## Numerical Variables","metadata":{}},{"cell_type":"code","source":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins =  80)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numericVar = [\"Fare\", \"Age\", \"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"6\"></a>\n\n## 3. Basic Data Analysis\n\nIn this part, I will analyse the relationship between certain features vs 'Survived' to see what are the chances of survival for passengers with different features in our data.","metadata":{}},{"cell_type":"code","source":"# correlation between features\n\ntrain_df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# heatmap of correlation\n\nf,ax = plt.subplots(figsize=(18,18))\nsns.heatmap(train_df.corr(), annot=True, linewidths =.5, fmt ='.1f',ax=ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pclass vs Survived\n\ntrain_df[[\"Pclass\",\"Survived\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pclass vs Survived\n\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sex vs Survived\n\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SibSp vs Survived\n\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parch vs Survived\n\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the chances of females who had SibSp amounts of siblings or spouses surviving\n\ntrain_df[[\"SibSp\", \"Sex\",\"Survived\"]].groupby([\"SibSp\", \"Sex\"], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"7\"></a>\n# 4. Outlier Detection\n\nIn this part, I will demonstrate how to detect and eliminate outliers in our data.","metadata":{}},{"cell_type":"code","source":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        \n        # 1st quartile:\n        \n        Q1 = np.percentile(df[c],25)\n        \n        # 3rd quartile:\n        \n        Q3 = np.percentile(df[c],75)\n        \n        # IQR:\n        \n        IQR = Q3 - Q1\n        \n        # Outlier step:\n        \n        outlier_step = IQR * 1.5\n        \n        # detect outlier and their indices:\n        \n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        \n        # store indices:\n        \n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[detect_outliers(train_df,[\"Age\", \"SibSp\",\"Parch\",\"Fare\"])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping outliers\n\ntrain_df = train_df.drop(detect_outliers(train_df,[\"Age\", \"SibSp\",\"Parch\",\"Fare\"]), axis = 0).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"8\"></a>\n\n## 5.Missing Values","metadata":{}},{"cell_type":"code","source":"train_df_len = len(train_df)\n\ntrain_df = pd.concat([train_df, test_df], axis = 0).reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"9\"></a>\n## Finding Missing Values","metadata":{}},{"cell_type":"code","source":"train_df.columns[train_df.isnull().any()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# these values are normal because of the concatenation\n\ntrain_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"10\"></a>\n## Filling Missing Values In","metadata":{}},{"cell_type":"code","source":"train_df[\"Embarked\"].isnull()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"Embarked\"].isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.boxplot(column=\"Fare\",by = \"Embarked\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"Embarked\"].isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"Fare\"].isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# how much these passengers have paid\n\nthird_class_price = train_df[train_df[\"Pclass\"] ==3][\"Fare\"]\nthird_class_price","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"Fare\"].isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"11\"></a>\n# 6. Visualization\n\nStarting with correlation, we will visualize the data.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"12\"></a>\n# Correlation","metadata":{}},{"cell_type":"code","source":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot=True, fmt = \".2f\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The highest values in this correlation matrix are 0.41 and 0.26, which indicate that:\n\nParent&Children <---> Sibling&Spouse\n\nFare <---> Survived\n\nboth have a correlation","metadata":{}},{"cell_type":"markdown","source":"<a id = \"13\"></a>\n# \"SibSp\" and \"Survived\"","metadata":{}},{"cell_type":"code","source":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Probability of Surviving\")\ng.set_xlabels(\"Total # of Siblings and Spouses\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"More siblings and/or spouses mean less chance of surviving.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"14\"></a>\n# \"ParCh\" and \"Survived\"","metadata":{}},{"cell_type":"code","source":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", kind = \"bar\", data = train_df, size = 6)\ng.set_ylabels(\"Probability of Surviving\")\ng.set_xlabels(\"Total # of Parents and Children\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"15\"></a>\n# \"PClass\" and \"Survived\"","metadata":{}},{"cell_type":"code","source":"g = sns.factorplot(x=\"Pclass\", y =\"Survived\", data = train_df, kind = \"bar\", size = 5)\ng.set_ylabels(\"Probability of SUrviving\")\ng.set_xlabels(\"Class no.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"16\"></a>\n# \"Age\" and \"Survived\"","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"17\"></a>\n# \"PClass\", \"Age\" and \"Survived\"","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\")\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The reverse relationship between being a higher class passenger and having a chance of survival is apparent","metadata":{}},{"cell_type":"markdown","source":"<a id = \"18\"></a>\n# \"Embarked\", \"PClass\" and \"Survived\"","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 5)\ng.map(sns.pointplot, \"Pclass\", \"Survived\", \"Sex\")\nplt.show()\ng.add_legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"19\"></a>\n# \"Embarked\", \"Sex\", \"Fare\" and \"Survived\"","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.5)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that higher fare means higher chance of survival.","metadata":{}},{"cell_type":"markdown","source":"<a id = \"20\"></a>\n# 7.Filling Missing Age Values","metadata":{}},{"cell_type":"code","source":"train_df[train_df[\"Age\"].isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can deduce that sex is not informative in filling missing age values, since the medians are very close for each sex.","metadata":{}},{"cell_type":"code","source":"sns.factorplot(x = \"Pclass\", y = \"Age\", data = train_df, kind = \"box\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ages of passengers are higher as classes of passengers go from 3 to 2 to 1.","metadata":{}},{"cell_type":"code","source":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train_df[[\"Age\", \"Sex\", \"SibSp\", \"Parch\", \"Pclass\"]].corr(), annot = True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No \"Sex\" feature in this heatmap since its categorical, we want to correct that.","metadata":{}},{"cell_type":"code","source":"train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train_df[[\"Age\", \"Sex\", \"SibSp\", \"Parch\", \"Pclass\"]].corr(), annot = True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df[\"Age\"].isnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"21\"></a>\n# 8.Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"<a id = \"22\"></a>\n## Name and Title","metadata":{}},{"cell_type":"code","source":"train_df[\"Name\"].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]\ntrain_df[\"Title\"].head(10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"Title\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to categorical\n\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Dr\",'Don','Rev','Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess', 'Jonkheer', 'Dona'], \"Other\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Mrs\" or i == \"Mme\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\", \"Mrs\", \"Mr\", \"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns=[\"Title\"])\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"23\"></a>\n## Family Size","metadata":{}},{"cell_type":"code","source":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\ntrain_df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# therefore, big families have less chance of survival","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns = [\"family_size\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"24\"></a>\n## Embarked","metadata":{}},{"cell_type":"code","source":"train_df[\"Embarked\"].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = \"Embarked\", data = train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns = [\"Embarked\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"25\"></a>\n## Ticket","metadata":{}},{"cell_type":"code","source":"train_df[\"Ticket\"].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(\" \")[0])\n    else:\n         tickets.append(\"X\")\ntrain_df[\"Ticket\"] = tickets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making tickets categorical\n\ntrain_df = pd.get_dummies(train_df, columns = [\"Ticket\"], prefix = \"T\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"26\"></a>\n## Pclass","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Pclass\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"27\"></a>\n## Sex","metadata":{}},{"cell_type":"code","source":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Sex\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"28\"></a>\n## Dropping Passenger ID & Cabin ","metadata":{}},{"cell_type":"code","source":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"29\"></a>\n# 9.Modelling","metadata":{}},{"cell_type":"code","source":"train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"30\"></a>\n## Train Test Split","metadata":{}},{"cell_type":"code","source":"train_df_len","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_train\", len(X_train))\nprint(\"X_test\", len(X_test))\nprint(\"y_train\", len(y_train))\nprint(\"y_test\", len(y_test))\nprint(\"test\", len(test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"31\"></a>\n## Simple Logistic Regression","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2)\nacc_log_test = round(logreg.score(X_test, y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"32\"></a>\n## Hyperparameter Tuning, Grid Search & Cross Validation\n\nWe will compare 5 classifier methods & evaluate them\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","metadata":{}},{"cell_type":"code","source":"random_state = 40\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grid search\n\ncv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a seaborn to visualize results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"33\"></a>\n## Ensemble Modelling","metadata":{}},{"cell_type":"code","source":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"34\"></a>\n# 10.Prediction & Submission","metadata":{}},{"cell_type":"code","source":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Citation:\nDATAI Team's tutorial has been helpful in helping me create this. ","metadata":{}}]}