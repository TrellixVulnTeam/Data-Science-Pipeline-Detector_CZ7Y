{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"text-align:center\"> <span style=\"color:Orange; font-size:3.4em;\"> ‚úÖ Beginners - Solving Tiranic using 12 Algorithms ü§© and Comparison ü§Ø <span></div>","metadata":{}},{"cell_type":"markdown","source":"![Alt Text](https://media.giphy.com/media/uaB5o9l6Wungk/giphy.gif)","metadata":{}},{"cell_type":"code","source":"from IPython.core.display import display, HTML, Javascript\n\ntable_of_contents =\"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n    <style>\n    .toc h2{\n        color: #3f4d63;\n        font-weight: 600;\n        font-family: 'Times New Roman', serif;\n        font-size: 28px;\n        margin-bottom: 4px;\n    }\n    \n    .toc ol li{\n        list-style:none;\n        line-height:normal;\n        }\n     \n    .toc li{\n        color: #080808;\n        font-weight: 600;\n        font-family: 'Times New Roman', serif;\n        font-size: 17px;\n        margin-bottom: 2px;\n    }\n\n    .toc ol ol li{\n        color: #4d4d4d;\n        font-weight: 400;\n        font-size: 15px;\n        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n        margin-top: 0px;\n        margin-bottom: 0px;\n    } \n    \n    .section_title{\n        background-color: #c22d2d;\n        color: white;\n        font-family: Helvetica;\n        font-size: 25px;\n        padding: 6px 12px;\n        margin-bottom: 5px;\n    }\n    .subsection_title{\n        background: #0f0f0f;\n        color: white;\n        font-family: Helvetica;\n        font-size: 21px;\n        padding: 6px 12px;\n        margin-bottom: 0px;\n    }\n    .subsubsection_title{\n        background: #609c8d;\n        color: white;\n        font-family: Helvetica;\n        font-size: 17px;\n        padding: 6px 12px;\n        margin-bottom: 0px;\n    }\n    .subsubsubsection_title{\n        background: #235f83;\n        color: white;\n        font-family: Helvetica;\n        font-size: 15px;\n        padding: 6px 12px;\n        margin-bottom: 0px;\n    }\n    </style>\n    </head>\n    <body>\n    </body>\n</html>\n\"\"\"\n\nHTML(table_of_contents)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:19.082864Z","iopub.execute_input":"2021-06-09T21:55:19.083286Z","iopub.status.idle":"2021-06-09T21:55:19.095512Z","shell.execute_reply.started":"2021-06-09T21:55:19.083254Z","shell.execute_reply":"2021-06-09T21:55:19.094433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"\n## <span style=\"color:orange\">üòäüôèüèª Credits/ Mentions \n### Before starting this i would like to give credits to Mr.Manav Sehgal and his absolutely beautiful explanatory notebook that inspired me to make a my own new, shorter and simplar notebook. Kaggle Team's Alexis Cook's Titanic Tutorial for making me understand concepts in simplest way possible.\n   \n","metadata":{}},{"cell_type":"markdown","source":"#  <span style=\"color:orange\">üö© ReadMe\n### This notebook is a tutorial for beginners who just want to dive into how everything is done, how various models are used to solve this problem and NOT made for increasing public scoring.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:red\">ü§î How is this Notebook different than others? \n    \n### We will **acquire**, **analyze**, make clear **Assumations** and **vizualize** for **each algorithm together** and avoid making a huge notebook of each and every algorithm seperately.\n    \n    \n","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-success\">Thank you all for viewing this, I understand you are here looking at the Title of the notebook which focuses on comparison of 12 algorithms, so let's get right to it!\n</div>\n    \n","metadata":{}},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"# <div class=\"section_title\">ü§© Algorithm's Used \n    \n* [KNN- K-nearest-neighbours](#q1)\n* [Suport Vector Machines](#q2)\n* [Logistic Regression](#q3)\n* [Naive Bayes](#q5)\n* [Perceptron](#q5)    \n* [Linear SVC](#q6)\n* [Stochastic Gradient Descent](#q7)\n* [Decision Tree](#q8)\n* [Random Forest](#9)\n* [XG boost](#q10)\n* [Ada Boosting](#q11)    \n* [Gradient Boosting](#q12) \n    \nAlso dont worry if it seems too much at this stage, \nfirst we will explore and analyze our data and then use the above mentioned alogorithms to predict our answers.","metadata":{}},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"## ‚ö°Ô∏è STEP 1:\n### ‚úÖ Import the neccessary libraries for data analysis\n### ‚úÖ Import library for Visualization\n### ‚úÖ Import Libraries for ML algorithms","metadata":{}},{"cell_type":"code","source":"# for data analysis\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# for viz\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# usual ML algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n##xgBoost\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n#adaBoost\nfrom sklearn.datasets import make_regression\nfrom sklearn.ensemble import AdaBoostClassifier\n\n#gradientBoosting\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:19.097358Z","iopub.execute_input":"2021-06-09T21:55:19.09777Z","iopub.status.idle":"2021-06-09T21:55:21.49123Z","shell.execute_reply.started":"2021-06-09T21:55:19.097742Z","shell.execute_reply":"2021-06-09T21:55:21.490437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"## ‚ö°Ô∏è Step 2:\n### ‚úÖ Get the data (Literally! or we can say \"to acquire\" the data and load it into our DataFrame(pandas).\n### ‚úÖ Analyze what is present in the dataset.\n  * **Categorize** features (weather they are categorical,numerical etc).\n  * **Indentify** if certain features are mixed (numerical with text for example)\n  * **Typos** (we are dealing with names here, we dont know who uses which title and if they name includes nicknames within etc, we  focus on finding errors and typos whenever dealing with names to avoid problems later in the model)\n<br> \n\n### ‚úÖ Preview the present data.\n","metadata":{}},{"cell_type":"markdown","source":"### üè≥Ô∏è Getting the Data ","metadata":{}},{"cell_type":"code","source":"# getting/acquiring our data\ntrain_df = pd.read_csv(\"../input/titanic/train.csv\")\ntest_df = pd.read_csv('../input/titanic/test.csv')\n# we are using combine for operations to run on both train and test which will be used later.\ncombine = [train_df, test_df]\n\n\n# we print values of columns which gives us nothing but our features\nprint(train_df.columns.values)\n\n\n# preview the data\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:21.492197Z","iopub.execute_input":"2021-06-09T21:55:21.492582Z","iopub.status.idle":"2021-06-09T21:55:21.548278Z","shell.execute_reply.started":"2021-06-09T21:55:21.492553Z","shell.execute_reply":"2021-06-09T21:55:21.547418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### üè≥Ô∏è Analyzing Data and Previewing Data\n\n**This will be done in a single step ahead, do read.**\n\nTo get better understanding of various categories in the dataset, read [here](https://www.kaggle.com/c/titanic/data).\n\n\n<br>\n\n\n\n### ü§î Categorical values\nThese are types of data which can be divided into group.\n* In our dataset we have -> Survived, Sex and Embarked.\n\n**Note** We have a value Pclass. Which is also categorical but it has a certain order fixed to it so we call it as **Ordinal**.\n\n### ü§î Numerical Values\nThese are values (numeric ofcourse!), but have an abosolute value to it, a specific measure of some amount.\nHere it would be -> Fare,Age.\n\n**Note** Here too we have another special value called Discrete Data which means it can have only certain values.\nBest example would be roling of 2 dice and the only values we have have is 2,3,4,5,6,7,8,9,10,11 and 12.\n\n<br>\n\n### ‚úÖ Summary\n* Categorical: Survived, Sex, and Embarked.\n* Ordinal: Pclass.\n* Continous: Age, Fare.\n* Discrete: SibSp, Parch.\n\n","metadata":{}},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"# <div class=\"section_title\">üì¢ Attention ‚¨áÔ∏è\n    \n### Now wait, this is getting too long and we have to analyze all of this by ourselfes and there is so so much left! üò∞ \n\n\n### What if i told you one line of code and give you all the EDA you need to figure out everything üò≤ Literally! I mean plots, Values, Correlation everything! Look at the magic below.\n\n","metadata":{}},{"cell_type":"code","source":"# our magic library\nimport pandas_profiling \ntrain_df.profile_report()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:21.549424Z","iopub.execute_input":"2021-06-09T21:55:21.549695Z","iopub.status.idle":"2021-06-09T21:55:37.260843Z","shell.execute_reply.started":"2021-06-09T21:55:21.54967Z","shell.execute_reply":"2021-06-09T21:55:37.259307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ‚ö†Ô∏è Wait! Did you say Interactive plots? CHECK ‚úÖ","metadata":{}},{"cell_type":"code","source":"## lets not mix our train csv so we create another variable\ntitanic_df = pd.read_csv('/kaggle/input/titanic/train.csv')\n\n\nfrom IPython.core.interactiveshell import InteractiveShell \nInteractiveShell.ast_node_interactivity = \"all\"\n\n#importing plotly and cufflinks in offline mode\nimport cufflinks as cf\nimport plotly.offline\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:37.262629Z","iopub.execute_input":"2021-06-09T21:55:37.263254Z","iopub.status.idle":"2021-06-09T21:55:38.673381Z","shell.execute_reply.started":"2021-06-09T21:55:37.263198Z","shell.execute_reply":"2021-06-09T21:55:38.672641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().iplot(kind='bar')\ntitanic_df[['Sex','Survived']].groupby(['Sex']).mean().iplot(kind='barh')\ntitanic_df.iplot()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:38.678582Z","iopub.execute_input":"2021-06-09T21:55:38.678992Z","iopub.status.idle":"2021-06-09T21:55:40.017764Z","shell.execute_reply.started":"2021-06-09T21:55:38.678958Z","shell.execute_reply":"2021-06-09T21:55:40.016703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"## ‚ö°Ô∏è Step 3:\n\n### ‚úÖ Wrangle Data \n\n**Okay, This is one of the most crucial steps but here, the main aim of this NoteBook was not to explain step by step on how to wrangle our data , there are lot of books existing for that same, but to compare all the Algorithms in short.\nI would suggest you to follow this [link](https://www.kaggle.com/startupsci/titanic-data-science-solutions#Wrangle-data) (just click the link and and give it a few seconds, it will take you directly to that particular section of the of the page), how the data was wrangled and what changes we made**.\n\nThe complete code for Data wrangling is hidden, cause i've used above link for the reference. I suggest you to follow that link if you want to get the details of that part.\n","metadata":{}},{"cell_type":"code","source":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:40.021323Z","iopub.execute_input":"2021-06-09T21:55:40.021969Z","iopub.status.idle":"2021-06-09T21:55:40.036832Z","shell.execute_reply.started":"2021-06-09T21:55:40.021921Z","shell.execute_reply":"2021-06-09T21:55:40.03574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:40.038313Z","iopub.execute_input":"2021-06-09T21:55:40.038641Z","iopub.status.idle":"2021-06-09T21:55:40.072639Z","shell.execute_reply.started":"2021-06-09T21:55:40.038611Z","shell.execute_reply":"2021-06-09T21:55:40.071747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:40.074486Z","iopub.execute_input":"2021-06-09T21:55:40.075017Z","iopub.status.idle":"2021-06-09T21:55:40.09843Z","shell.execute_reply.started":"2021-06-09T21:55:40.074977Z","shell.execute_reply":"2021-06-09T21:55:40.097437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:40.099568Z","iopub.execute_input":"2021-06-09T21:55:40.099959Z","iopub.status.idle":"2021-06-09T21:55:40.120416Z","shell.execute_reply.started":"2021-06-09T21:55:40.09992Z","shell.execute_reply":"2021-06-09T21:55:40.119494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:40.121667Z","iopub.execute_input":"2021-06-09T21:55:40.12221Z","iopub.status.idle":"2021-06-09T21:55:40.139188Z","shell.execute_reply.started":"2021-06-09T21:55:40.122158Z","shell.execute_reply":"2021-06-09T21:55:40.138019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:40.141303Z","iopub.execute_input":"2021-06-09T21:55:40.14169Z","iopub.status.idle":"2021-06-09T21:55:40.160506Z","shell.execute_reply.started":"2021-06-09T21:55:40.141645Z","shell.execute_reply":"2021-06-09T21:55:40.159767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')\ngrid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:40.161876Z","iopub.execute_input":"2021-06-09T21:55:40.162406Z","iopub.status.idle":"2021-06-09T21:55:42.268089Z","shell.execute_reply.started":"2021-06-09T21:55:40.162366Z","shell.execute_reply":"2021-06-09T21:55:42.267357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"guess_ages = np.zeros((2,3))\nguess_ages","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.26917Z","iopub.execute_input":"2021-06-09T21:55:42.269594Z","iopub.status.idle":"2021-06-09T21:55:42.274952Z","shell.execute_reply.started":"2021-06-09T21:55:42.269562Z","shell.execute_reply":"2021-06-09T21:55:42.274104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.276049Z","iopub.execute_input":"2021-06-09T21:55:42.276341Z","iopub.status.idle":"2021-06-09T21:55:42.324731Z","shell.execute_reply.started":"2021-06-09T21:55:42.276315Z","shell.execute_reply":"2021-06-09T21:55:42.323737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.326209Z","iopub.execute_input":"2021-06-09T21:55:42.326601Z","iopub.status.idle":"2021-06-09T21:55:42.351566Z","shell.execute_reply.started":"2021-06-09T21:55:42.326559Z","shell.execute_reply":"2021-06-09T21:55:42.350413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.353082Z","iopub.execute_input":"2021-06-09T21:55:42.353483Z","iopub.status.idle":"2021-06-09T21:55:42.388001Z","shell.execute_reply.started":"2021-06-09T21:55:42.353415Z","shell.execute_reply":"2021-06-09T21:55:42.387033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.389394Z","iopub.execute_input":"2021-06-09T21:55:42.389962Z","iopub.status.idle":"2021-06-09T21:55:42.404228Z","shell.execute_reply.started":"2021-06-09T21:55:42.389921Z","shell.execute_reply":"2021-06-09T21:55:42.402918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.405526Z","iopub.execute_input":"2021-06-09T21:55:42.405792Z","iopub.status.idle":"2021-06-09T21:55:42.428551Z","shell.execute_reply.started":"2021-06-09T21:55:42.405766Z","shell.execute_reply":"2021-06-09T21:55:42.427803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.42959Z","iopub.execute_input":"2021-06-09T21:55:42.42993Z","iopub.status.idle":"2021-06-09T21:55:42.447636Z","shell.execute_reply.started":"2021-06-09T21:55:42.429905Z","shell.execute_reply":"2021-06-09T21:55:42.446556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.449055Z","iopub.execute_input":"2021-06-09T21:55:42.449356Z","iopub.status.idle":"2021-06-09T21:55:42.469529Z","shell.execute_reply.started":"2021-06-09T21:55:42.449326Z","shell.execute_reply":"2021-06-09T21:55:42.468716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.471481Z","iopub.execute_input":"2021-06-09T21:55:42.471871Z","iopub.status.idle":"2021-06-09T21:55:42.49995Z","shell.execute_reply.started":"2021-06-09T21:55:42.471832Z","shell.execute_reply":"2021-06-09T21:55:42.49892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.501308Z","iopub.execute_input":"2021-06-09T21:55:42.501617Z","iopub.status.idle":"2021-06-09T21:55:42.519293Z","shell.execute_reply.started":"2021-06-09T21:55:42.501588Z","shell.execute_reply":"2021-06-09T21:55:42.518196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.520854Z","iopub.execute_input":"2021-06-09T21:55:42.521417Z","iopub.status.idle":"2021-06-09T21:55:42.546539Z","shell.execute_reply.started":"2021-06-09T21:55:42.52137Z","shell.execute_reply":"2021-06-09T21:55:42.5456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.548116Z","iopub.execute_input":"2021-06-09T21:55:42.548507Z","iopub.status.idle":"2021-06-09T21:55:42.563822Z","shell.execute_reply.started":"2021-06-09T21:55:42.548467Z","shell.execute_reply":"2021-06-09T21:55:42.562639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.565599Z","iopub.execute_input":"2021-06-09T21:55:42.566001Z","iopub.status.idle":"2021-06-09T21:55:42.591558Z","shell.execute_reply.started":"2021-06-09T21:55:42.565962Z","shell.execute_reply":"2021-06-09T21:55:42.590477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.593065Z","iopub.execute_input":"2021-06-09T21:55:42.593462Z","iopub.status.idle":"2021-06-09T21:55:42.625199Z","shell.execute_reply.started":"2021-06-09T21:55:42.593402Z","shell.execute_reply":"2021-06-09T21:55:42.624112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.626566Z","iopub.execute_input":"2021-06-09T21:55:42.627092Z","iopub.status.idle":"2021-06-09T21:55:42.65161Z","shell.execute_reply.started":"2021-06-09T21:55:42.627052Z","shell.execute_reply":"2021-06-09T21:55:42.650578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"## üèÅ Finally! ‚úÖ Models.....\n\n\n","metadata":{}},{"cell_type":"code","source":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.652783Z","iopub.execute_input":"2021-06-09T21:55:42.653304Z","iopub.status.idle":"2021-06-09T21:55:42.663347Z","shell.execute_reply.started":"2021-06-09T21:55:42.653262Z","shell.execute_reply":"2021-06-09T21:55:42.662436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q1\"></a>\n## üíé KNN - K-nearest-neighbours","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-06-09T21:55:42.664698Z","iopub.execute_input":"2021-06-09T21:55:42.665233Z","iopub.status.idle":"2021-06-09T21:55:42.734581Z","shell.execute_reply.started":"2021-06-09T21:55:42.665194Z","shell.execute_reply":"2021-06-09T21:55:42.73339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q2\"></a>\n## üíé Support Vector Machines ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.735738Z","iopub.execute_input":"2021-06-09T21:55:42.735998Z","iopub.status.idle":"2021-06-09T21:55:42.804356Z","shell.execute_reply.started":"2021-06-09T21:55:42.735974Z","shell.execute_reply":"2021-06-09T21:55:42.803226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q3\"></a>\n## üíé Logistic Regression","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.805714Z","iopub.execute_input":"2021-06-09T21:55:42.805989Z","iopub.status.idle":"2021-06-09T21:55:42.84518Z","shell.execute_reply.started":"2021-06-09T21:55:42.805962Z","shell.execute_reply":"2021-06-09T21:55:42.844376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q4\"></a>\n## üíé Naive Bayes","metadata":{}},{"cell_type":"code","source":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.846397Z","iopub.execute_input":"2021-06-09T21:55:42.846872Z","iopub.status.idle":"2021-06-09T21:55:42.86565Z","shell.execute_reply.started":"2021-06-09T21:55:42.846834Z","shell.execute_reply":"2021-06-09T21:55:42.864832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q5\"></a>\n## üíé Perceptron","metadata":{}},{"cell_type":"code","source":"perceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.866899Z","iopub.execute_input":"2021-06-09T21:55:42.867389Z","iopub.status.idle":"2021-06-09T21:55:42.888488Z","shell.execute_reply.started":"2021-06-09T21:55:42.867351Z","shell.execute_reply":"2021-06-09T21:55:42.88766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q6\"></a>\n## üíé Linear SVC","metadata":{}},{"cell_type":"code","source":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.889741Z","iopub.execute_input":"2021-06-09T21:55:42.890207Z","iopub.status.idle":"2021-06-09T21:55:42.953119Z","shell.execute_reply.started":"2021-06-09T21:55:42.890171Z","shell.execute_reply":"2021-06-09T21:55:42.952302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q7\"></a>\n## üíé Stochastic Gradient Descent","metadata":{}},{"cell_type":"code","source":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.954301Z","iopub.execute_input":"2021-06-09T21:55:42.95477Z","iopub.status.idle":"2021-06-09T21:55:42.973073Z","shell.execute_reply.started":"2021-06-09T21:55:42.954734Z","shell.execute_reply":"2021-06-09T21:55:42.97197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q8\"></a>\n## üíé Decision Tree","metadata":{}},{"cell_type":"code","source":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.974571Z","iopub.execute_input":"2021-06-09T21:55:42.974914Z","iopub.status.idle":"2021-06-09T21:55:42.997747Z","shell.execute_reply.started":"2021-06-09T21:55:42.974881Z","shell.execute_reply":"2021-06-09T21:55:42.996815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q9\"></a>\n## üíé Random Forest","metadata":{}},{"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:42.999039Z","iopub.execute_input":"2021-06-09T21:55:42.999373Z","iopub.status.idle":"2021-06-09T21:55:43.243996Z","shell.execute_reply.started":"2021-06-09T21:55:42.999341Z","shell.execute_reply":"2021-06-09T21:55:43.242678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q10\"></a>\n## üíé XG Boost","metadata":{}},{"cell_type":"code","source":"xg_boost = XGBClassifier()\nxg_boost.fit(X_train, Y_train)\nY_pred = xg_boost.predict(X_test)\nxg_boost.score(X_train, Y_train)\nacc_xg_boost = round(xg_boost.score(X_train, Y_train) * 100, 2)\nacc_xg_boost","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:43.246301Z","iopub.execute_input":"2021-06-09T21:55:43.246723Z","iopub.status.idle":"2021-06-09T21:55:43.336948Z","shell.execute_reply.started":"2021-06-09T21:55:43.246682Z","shell.execute_reply":"2021-06-09T21:55:43.336152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q11\"></a>\n## üíé Ada Boosting ","metadata":{}},{"cell_type":"code","source":"ada_boost = AdaBoostClassifier()\nada_boost.fit(X_train, Y_train)\nY_pred = ada_boost.predict(X_test)\nacc_ada_boost = round(ada_boost.score(X_train, Y_train) * 100, 2)\nacc_ada_boost","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:43.338247Z","iopub.execute_input":"2021-06-09T21:55:43.338773Z","iopub.status.idle":"2021-06-09T21:55:43.503929Z","shell.execute_reply.started":"2021-06-09T21:55:43.338736Z","shell.execute_reply":"2021-06-09T21:55:43.503105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = \"q11\"></a>\n## üíé Gradient Boosting","metadata":{}},{"cell_type":"markdown","source":"gr_boost = GradientBoostingClassifier()\ngr_boost.fit(X_train, Y_train)\nY_pred = ada_boost.predict(X_test)\nacc_gr_boost = round(gr_boost.score(X_train, Y_train) * 100, 2)\nacc_gr_boost","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:43.505361Z","iopub.execute_input":"2021-06-09T21:55:43.505933Z","iopub.status.idle":"2021-06-09T21:55:43.629703Z","shell.execute_reply.started":"2021-06-09T21:55:43.505896Z","shell.execute_reply":"2021-06-09T21:55:43.628999Z"}}},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:orange\">ü§© Model Comparison ","metadata":{}},{"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Gradient Boosting','Ada Boosting','XGBoost','Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_gr_boost,acc_ada_boost,acc_xg_boost,acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:43.633042Z","iopub.execute_input":"2021-06-09T21:55:43.633324Z","iopub.status.idle":"2021-06-09T21:55:43.646031Z","shell.execute_reply.started":"2021-06-09T21:55:43.633299Z","shell.execute_reply":"2021-06-09T21:55:43.645057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"\n\n## ü§î We clearly see the Random forest and Decision tree perform quite the same, but still we still will go with random forest. ‚úÖ\n\n### ü§Ø Remove \"#\" you want to use this ‚¨áÔ∏è  for submission.\n\n","metadata":{}},{"cell_type":"code","source":"#random_forest = RandomForestClassifier(n_estimators=100)\n#random_forest.fit(X_train, Y_train)\n#Y_pred = random_forest.predict(X_test)\n#random_forest.score(X_train, Y_train)\n#acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n#acc_random_forest\n#Y_pred = random_forest.predict(X_test)\n\n#output = pd.DataFrame({\n #       \"PassengerId\": test_df[\"PassengerId\"],\n #       \"Survived\": Y_pred\n #   })\n\n#output.to_csv('my_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2021-06-09T21:55:43.647912Z","iopub.execute_input":"2021-06-09T21:55:43.648297Z","iopub.status.idle":"2021-06-09T21:55:43.656512Z","shell.execute_reply.started":"2021-06-09T21:55:43.648257Z","shell.execute_reply":"2021-06-09T21:55:43.655717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<div class=\"alert alert-block alert-success\">\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:orange\"> ‚ö°Ô∏è Thank you for reading this far üôèüèªüòä. Dont forget to upvote if it helped you in any way. ","metadata":{}}]}