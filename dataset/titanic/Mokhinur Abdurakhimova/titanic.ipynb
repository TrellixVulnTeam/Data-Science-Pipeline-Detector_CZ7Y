{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Hey! Thank you for choosing my notebook ðŸ“‘\n> <center>ðŸ˜Ž It is bunch of fun, read it and fell free to comment. Your upvotes makes me work harder in myself ðŸš€ðŸ”¥","metadata":{}},{"cell_type":"markdown","source":"**Workflow:**\n\n* Exploratory Data Analysis.\n* Surviving rate\n* Pclass\n* Name\n* Sex\n* Age\n* SibSp, Parch\n* Ticket\n* Fare\n* Cabin\n* Embarked\n\n**Feature Engineering:**\n* Imputation on Embarked and Age columns\n* Title extraction\n* Ticket first letters\n* Cabin first letters\n* Encoding sex column\n* Family size\n* One Hot Encoding for all categorical variables\n\n**Machine Learning:**\n* Split data into train and test sets\n* Initialize a Random Forest Classifier\n* Hyperparameter Tuning with Grid Search\n* Prediction\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\n\n# I will keep the resulting plots\n%matplotlib inline\n\n# Enable Jupyter Notebook's intellisense\n%config IPCompleter.greedy=True\n\n# We want to see whole content (non-truncated)\npd.set_option('display.max_colwidth', None)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:34:47.861182Z","iopub.execute_input":"2022-05-25T01:34:47.861551Z","iopub.status.idle":"2022-05-25T01:34:48.95565Z","shell.execute_reply.started":"2022-05-25T01:34:47.861462Z","shell.execute_reply":"2022-05-25T01:34:48.954882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/titanic/train.csv\")\n\ndisplay(train.head())\n\nprint(train.info())\nprint(train.info())\nprint(train.describe())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:34:48.957097Z","iopub.execute_input":"2022-05-25T01:34:48.957329Z","iopub.status.idle":"2022-05-25T01:34:49.049265Z","shell.execute_reply.started":"2022-05-25T01:34:48.957301Z","shell.execute_reply":"2022-05-25T01:34:49.048347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Notes:**\n\n* There are some missing values in Age, Embarked and Cabin columns.\n* We do not need PassengerId column\n* The surviving rate is 38.3% in our dataset\n\n**Survived**\nLet's start with Survived column. It contains integer 1 or 0 which correspond to surviving ( 1 = Survived, 0 = Not Survived)","metadata":{}},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:37:13.665237Z","iopub.execute_input":"2022-05-25T01:37:13.665892Z","iopub.status.idle":"2022-05-25T01:37:13.669326Z","shell.execute_reply.started":"2022-05-25T01:37:13.665857Z","shell.execute_reply":"2022-05-25T01:37:13.668401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize with a countplot\nsns.countplot(x=\"Survived\", data=train)\nplt.show()\n\n# Print the proportions\nprint(train[\"Survived\"].value_counts(normalize=True))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:36:05.58067Z","iopub.execute_input":"2022-05-25T01:36:05.581795Z","iopub.status.idle":"2022-05-25T01:36:05.624509Z","shell.execute_reply.started":"2022-05-25T01:36:05.581748Z","shell.execute_reply":"2022-05-25T01:36:05.623595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Pclass**\nPclass column contains the socioeconomic status of the passengers. It might be predictive for our model\n\n*  1 = Upper\n*  2 = Middle\n*  3 = Lower","metadata":{}},{"cell_type":"code","source":"# Visualize with a countplot\nsns.countplot(x=\"Pclass\", hue=\"Survived\", data=train)\nplt.show()\n\n# Proportion of people survived for each class\nprint(train[\"Survived\"].groupby(train[\"Pclass\"]).mean())\n\n# How many people we have in each class?\nprint(train[\"Pclass\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:38:07.316451Z","iopub.execute_input":"2022-05-25T01:38:07.31671Z","iopub.status.idle":"2022-05-25T01:38:07.33538Z","shell.execute_reply.started":"2022-05-25T01:38:07.316681Z","shell.execute_reply":"2022-05-25T01:38:07.334309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As I expected, first class passengers have higher surviving rate. We will use this information in our training data.\n\n**Name**\n\nAt a first glance, I thought that I would use the titles.","metadata":{}},{"cell_type":"code","source":"# Display first five rows of the Name column\ndisplay(train[[\"Name\"]].head())","metadata":{"execution":{"iopub.status.busy":"2022-05-25T01:38:12.897841Z","iopub.execute_input":"2022-05-25T01:38:12.898504Z","iopub.status.idle":"2022-05-25T01:38:12.914158Z","shell.execute_reply.started":"2022-05-25T01:38:12.898465Z","shell.execute_reply":"2022-05-25T01:38:12.913232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can extract the titles from names.","metadata":{}},{"cell_type":"code","source":"# Get titles\ntrain[\"Title\"] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n\n# Print title counts\nprint(train[\"Title\"].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:13.985247Z","iopub.execute_input":"2022-05-24T10:01:13.98584Z","iopub.status.idle":"2022-05-24T10:01:14.000606Z","shell.execute_reply.started":"2022-05-24T10:01:13.985805Z","shell.execute_reply":"2022-05-24T10:01:13.999451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Is there any relationship between titles and surviving","metadata":{}},{"cell_type":"code","source":"# Print the Surviving rates by title\nprint(train[\"Survived\"].groupby(train[\"Title\"]).mean().sort_values(ascending=False))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:15.681778Z","iopub.execute_input":"2022-05-24T10:01:15.682519Z","iopub.status.idle":"2022-05-24T10:01:15.690405Z","shell.execute_reply.started":"2022-05-24T10:01:15.682469Z","shell.execute_reply":"2022-05-24T10:01:15.689451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apparently, there is relationship between titles and surviving rate. In feature engineering part, I will group title by their surviving rates like following\n\n* higher = the Countess, Mlle, Lady, Ms , Sir, Mme, Mrs, Miss, Master\n* neutral = Major, Col, Dr\n* lower = Mr, Rev, Jonkheer, Don, Capt\n\n# Age","metadata":{}},{"cell_type":"code","source":"# Print the missing values in Age column\nprint(train[\"Age\"].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:17.445105Z","iopub.execute_input":"2022-05-24T10:01:17.445674Z","iopub.status.idle":"2022-05-24T10:01:17.451477Z","shell.execute_reply.started":"2022-05-24T10:01:17.445638Z","shell.execute_reply":"2022-05-24T10:01:17.450553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 177 missing values in Age column, we will impute them in Feature engineering part. \nNow, let's look at the distribution of ages by surviving","metadata":{}},{"cell_type":"code","source":"# Survived by age\nsns.distplot(train[train.Survived==1][\"Age\"],color=\"y\", bins=7, label=\"1\")\n\n# Death by age\nsns.distplot(train[train.Survived==0][\"Age\"], bins=7, label=\"0\")\nplt.legend()\nplt.title(\"Age Distribution\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:18.989581Z","iopub.execute_input":"2022-05-24T10:01:18.989903Z","iopub.status.idle":"2022-05-24T10:01:19.28998Z","shell.execute_reply.started":"2022-05-24T10:01:18.989869Z","shell.execute_reply":"2022-05-24T10:01:19.289358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Sex**\n\nIs sex important for surviving?","metadata":{}},{"cell_type":"code","source":"# Visualize with a countplot\nsns.countplot(x=\"Sex\", hue=\"Survived\", data=train)\nplt.show()\n\n# Proportion of people survived for each class\nprint(train[\"Survived\"].groupby(train[\"Sex\"]).mean())\n\n# How many people we have in each class?\nprint(train[\"Sex\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:21.137958Z","iopub.execute_input":"2022-05-24T10:01:21.13848Z","iopub.status.idle":"2022-05-24T10:01:21.330451Z","shell.execute_reply.started":"2022-05-24T10:01:21.138435Z","shell.execute_reply":"2022-05-24T10:01:21.329719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obviously, there is a relationship between sex and surviving.\n\n* SibSp & Parch\n* SibSp = Sibling or Spouse number\n* Parch = Parent or Children number\n\nI decided to make a new feature called family size by summing the SibSp and Parch columns","metadata":{}},{"cell_type":"code","source":"print(train[\"SibSp\"].value_counts())\n\nprint(train[\"Parch\"].value_counts())\n\ntrain[\"family_size\"] = train[\"SibSp\"] + train[\"Parch\"]\n\nprint(train[\"family_size\"].value_counts())\n\n# Proportion of people survived for each class\nprint(train[\"Survived\"].groupby(train[\"family_size\"]).mean().sort_values(ascending=False))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:22.958428Z","iopub.execute_input":"2022-05-24T10:01:22.958701Z","iopub.status.idle":"2022-05-24T10:01:22.972877Z","shell.execute_reply.started":"2022-05-24T10:01:22.958672Z","shell.execute_reply":"2022-05-24T10:01:22.971982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apparently, family size is important to survive. I am going to group them in feature engineering step like following\n\n* **big family** = if family size > 3\n* **small family** = if family size > 0 and family size < =3\n* **alone** = family size == 0\n\nTicket\n\nAt first, I thought that I would drop this column but after exploration I found useful features.","metadata":{}},{"cell_type":"code","source":"# Print the first five rows of the Ticket column\nprint(train[\"Ticket\"].head(15))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:26.385999Z","iopub.execute_input":"2022-05-24T10:01:26.386471Z","iopub.status.idle":"2022-05-24T10:01:26.391883Z","shell.execute_reply.started":"2022-05-24T10:01:26.386437Z","shell.execute_reply":"2022-05-24T10:01:26.391141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I extracted only first letters of the tickets because I thought that they would indicate the ticket type.\n\n","metadata":{}},{"cell_type":"code","source":"# Get first letters of the tickets\ntrain[\"Ticket_first\"] = train[\"Ticket\"].apply(lambda x: str(x)[0])\n\n# Print value counts\nprint(train[\"Ticket_first\"].value_counts())\n\n# Surviving rates of first letters\nprint(train.groupby(\"Ticket_first\")[\"Survived\"].mean().sort_values(ascending=False))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:27.848238Z","iopub.execute_input":"2022-05-24T10:01:27.848819Z","iopub.status.idle":"2022-05-24T10:01:27.859881Z","shell.execute_reply.started":"2022-05-24T10:01:27.848777Z","shell.execute_reply":"2022-05-24T10:01:27.85911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first letters of the tickets are correlated with surviving rate somehow. I am going to group them like following\n\n* higher surviving rate = F, 1, P , 9\n* neutral = S, C, 2\n* lower surviving rate = else\n\nFare\nWe can plot a histogram to see Fare distribution","metadata":{}},{"cell_type":"code","source":"# Print 3 bins of Fare column\nprint(pd.cut(train['Fare'], 3).value_counts())\n\n# Plot the histogram\nsns.distplot(train[\"Fare\"])\nplt.show()\n\n# Print binned Fares by surviving rate\nprint(train['Survived'].groupby(pd.cut(train['Fare'], 3)).mean())","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:29.587831Z","iopub.execute_input":"2022-05-24T10:01:29.588542Z","iopub.status.idle":"2022-05-24T10:01:30.059961Z","shell.execute_reply.started":"2022-05-24T10:01:29.588506Z","shell.execute_reply":"2022-05-24T10:01:30.059051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is also a correlation between ticket fares and surviving\n\nCabin\n\n![https://raw.githubusercontent.com/Bhasfe/titanic/ae0e2f00f9945227a26005447626f3f6a703c60b/images/titanic.png](http://)\n\nI found this figure wikiwand.com. The figure shows us the most affacted parts of the Titanic and the Cabin locations. Although there are many missing value in Cabin column, I decided to extract the Cabin information to try whether it works or not.","metadata":{}},{"cell_type":"code","source":"# Print the unique values in the Cabin column\nprint(train[\"Cabin\"].unique())\n\n# Get the first letters of Cabins\ntrain[\"Cabin_first\"] = train[\"Cabin\"].apply(lambda x: str(x)[0])\n\n# Print value counts of first letters\nprint(train[\"Cabin_first\"].value_counts())\n\n# Surviving rate of Cabin first letters\nprint(train.groupby(\"Cabin_first\")[\"Survived\"].mean().sort_values(ascending=False))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:31.428564Z","iopub.execute_input":"2022-05-24T10:01:31.429277Z","iopub.status.idle":"2022-05-24T10:01:31.445008Z","shell.execute_reply.started":"2022-05-24T10:01:31.429241Z","shell.execute_reply":"2022-05-24T10:01:31.443917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to surviving rates. I will group the Cabins like following\n\n* higher surviving rate = D, E, B, F, C\n* neutral = G, A\n* lower surviving rate else\n\n**Embarked**\n\nEmbarked is a categorical features which shows us the port of embarkation.\n\n* C = Cherbourg\n* Q = Queenstown\n* S = Southampton","metadata":{}},{"cell_type":"code","source":"# Make a countplot\nsns.countplot(x=\"Embarked\", hue=\"Survived\", data=train)\nplt.show()\n\n# Print the value counts\nprint(train[\"Embarked\"].value_counts())\n\n# Surviving rates of Embarked\nprint(train[\"Survived\"].groupby(train[\"Embarked\"]).mean())","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:31.842495Z","iopub.execute_input":"2022-05-24T10:01:31.843234Z","iopub.status.idle":"2022-05-24T10:01:32.058564Z","shell.execute_reply.started":"2022-05-24T10:01:31.843192Z","shell.execute_reply":"2022-05-24T10:01:32.05772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No doubt, C has the higher surviving rate. \nWe will definetely use this information.\n\n# 2. Feature Engineering\nWe have learned a lot from exploratory data analysis. Now we can start feature engineering. Firstly, let's load the train and the test sets.","metadata":{}},{"cell_type":"code","source":"# Load the train and the test datasets\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\n\nprint(test.info())","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:32.232378Z","iopub.execute_input":"2022-05-24T10:01:32.23514Z","iopub.status.idle":"2022-05-24T10:01:32.261159Z","shell.execute_reply.started":"2022-05-24T10:01:32.235079Z","shell.execute_reply":"2022-05-24T10:01:32.260433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is one missing value in the Fare column of the test set. I imputed it by using mean.","metadata":{}},{"cell_type":"code","source":"# Put the mean into the missing value\ntest['Fare'].fillna(train['Fare'].mean(), inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:32.574415Z","iopub.execute_input":"2022-05-24T10:01:32.574941Z","iopub.status.idle":"2022-05-24T10:01:32.579969Z","shell.execute_reply.started":"2022-05-24T10:01:32.574905Z","shell.execute_reply":"2022-05-24T10:01:32.578838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have used two types of Imputer from sklearn. Iterative imputer for age imputation, and Simple imputer ( with most frequent strategy) for Embarked","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# Imputers\nimp_embarked = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\nimp_age = IterativeImputer(max_iter=100, random_state=34, n_nearest_features=2)\n\n# Impute Embarked\ntrain[\"Embarked\"] = imp_embarked.fit_transform(train[[\"Embarked\"]])\ntest[\"Embarked\"] = imp_embarked.transform(test[[\"Embarked\"]])\n\n# Impute Age\ntrain[\"Age\"] = np.round(imp_age.fit_transform(train[[\"Age\"]]))\ntest[\"Age\"] = np.round(imp_age.transform(test[[\"Age\"]]))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:33.78401Z","iopub.execute_input":"2022-05-24T10:01:33.784401Z","iopub.status.idle":"2022-05-24T10:01:33.879308Z","shell.execute_reply.started":"2022-05-24T10:01:33.784356Z","shell.execute_reply":"2022-05-24T10:01:33.878591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also encode the sex column.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Initialize a Label Encoder\nle = LabelEncoder()\n\n# Encode Sex\ntrain[\"Sex\"] = le.fit_transform(train[[\"Sex\"]].values.ravel())\ntest[\"Sex\"] = le.fit_transform(test[[\"Sex\"]].values.ravel())","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:34.216356Z","iopub.execute_input":"2022-05-24T10:01:34.216662Z","iopub.status.idle":"2022-05-24T10:01:34.228671Z","shell.execute_reply.started":"2022-05-24T10:01:34.21663Z","shell.execute_reply":"2022-05-24T10:01:34.227463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In EDA, we decided to use family size feature","metadata":{}},{"cell_type":"code","source":"# Family Size\ntrain[\"Fsize\"] = train[\"SibSp\"] + train[\"Parch\"]\ntest[\"Fsize\"] = test[\"SibSp\"] + test[\"Parch\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:34.602615Z","iopub.execute_input":"2022-05-24T10:01:34.603378Z","iopub.status.idle":"2022-05-24T10:01:34.609966Z","shell.execute_reply.started":"2022-05-24T10:01:34.603332Z","shell.execute_reply":"2022-05-24T10:01:34.609097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ticket first letters and Cabin first letters are also needed","metadata":{}},{"cell_type":"code","source":"# Ticket first letters\ntrain[\"Ticket\"] = train[\"Ticket\"].apply(lambda x: str(x)[0])\ntest[\"Ticket\"] = test[\"Ticket\"].apply(lambda x: str(x)[0])\n\n# Cabin first letters\ntrain[\"Cabin\"] = train[\"Cabin\"].apply(lambda x: str(x)[0])\ntest[\"Cabin\"] = test[\"Cabin\"].apply(lambda x: str(x)[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:35.927229Z","iopub.execute_input":"2022-05-24T10:01:35.928019Z","iopub.status.idle":"2022-05-24T10:01:35.939313Z","shell.execute_reply.started":"2022-05-24T10:01:35.927967Z","shell.execute_reply":"2022-05-24T10:01:35.938207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extract the titles from the names","metadata":{}},{"cell_type":"code","source":"# Titles\ntrain[\"Title\"] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\ntest[\"Title\"] = test['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:36.259053Z","iopub.execute_input":"2022-05-24T10:01:36.25932Z","iopub.status.idle":"2022-05-24T10:01:36.275561Z","shell.execute_reply.started":"2022-05-24T10:01:36.259291Z","shell.execute_reply":"2022-05-24T10:01:36.274756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we need some helper functions to group our categories","metadata":{}},{"cell_type":"code","source":"# Group the family_size column\ndef assign_passenger_label(family_size):\n    if family_size == 0:\n        return \"Alone\"\n    elif family_size <=3:\n        return \"Small_family\"\n    else:\n        return \"Big_family\"\n    \n# Group the Ticket column\ndef assign_label_ticket(first):\n    if first in [\"F\", \"1\", \"P\", \"9\"]:\n        return \"Ticket_high\"\n    elif first in [\"S\", \"C\", \"2\"]:\n        return \"Ticket_middle\"\n    else:\n        return \"Ticket_low\"\n    \n# Group the Title column    \ndef assign_label_title(title):\n    if title in [\"the Countess\", \"Mlle\", \"Lady\", \"Ms\", \"Sir\", \"Mme\", \"Mrs\", \"Miss\", \"Master\"]:\n        return \"Title_high\"\n    elif title in [\"Major\", \"Col\", \"Dr\"]:\n        return \"Title_middle\"\n    else:\n        return \"Title_low\"\n    \n# Group the Cabin column  \ndef assign_label_cabin(cabin):\n    if cabin in [\"D\", \"E\", \"B\", \"F\", \"C\"]:\n        return \"Cabin_high\"\n    elif cabin in [\"G\", \"A\"]:\n        return \"Cabin_middle\"\n    else:\n        return \"Cabin_low\"","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:37.238134Z","iopub.execute_input":"2022-05-24T10:01:37.238408Z","iopub.status.idle":"2022-05-24T10:01:37.246521Z","shell.execute_reply.started":"2022-05-24T10:01:37.238361Z","shell.execute_reply":"2022-05-24T10:01:37.245576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apply the functions.","metadata":{}},{"cell_type":"code","source":"# Family size\ntrain[\"Fsize\"] = train[\"Fsize\"].apply(assign_passenger_label)\ntest[\"Fsize\"] = test[\"Fsize\"].apply(assign_passenger_label)\n\n# Ticket\ntrain[\"Ticket\"] = train[\"Ticket\"].apply(assign_label_ticket)\ntest[\"Ticket\"] = test[\"Ticket\"].apply(assign_label_ticket)\n\n# Title\ntrain[\"Title\"] = train[\"Title\"].apply(assign_label_title)\ntest[\"Title\"] = test[\"Title\"].apply(assign_label_title)\n\n# Cabin\ntrain[\"Cabin\"] = train[\"Cabin\"].apply(assign_label_cabin)\ntest[\"Cabin\"] = test[\"Cabin\"].apply(assign_label_cabin)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:37.617703Z","iopub.execute_input":"2022-05-24T10:01:37.618165Z","iopub.status.idle":"2022-05-24T10:01:37.630942Z","shell.execute_reply.started":"2022-05-24T10:01:37.618127Z","shell.execute_reply":"2022-05-24T10:01:37.629884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's time to use One Hot Encoding","metadata":{}},{"cell_type":"code","source":"train = pd.get_dummies(columns=[\"Pclass\", \"Embarked\", \"Ticket\", \"Cabin\",\"Title\", \"Fsize\"], data=train, drop_first=True)\ntest = pd.get_dummies(columns=[\"Pclass\", \"Embarked\", \"Ticket\", \"Cabin\", \"Title\", \"Fsize\"], data=test, drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:38.604861Z","iopub.execute_input":"2022-05-24T10:01:38.605112Z","iopub.status.idle":"2022-05-24T10:01:38.62813Z","shell.execute_reply.started":"2022-05-24T10:01:38.605084Z","shell.execute_reply":"2022-05-24T10:01:38.627321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Drop the colums that are no longer needed","metadata":{}},{"cell_type":"code","source":"target = train[\"Survived\"]\ntrain.drop([\"Survived\", \"SibSp\", \"Parch\", \"Name\", \"PassengerId\"], axis=1, inplace=True)\ntest.drop([\"SibSp\", \"Parch\", \"Name\",\"PassengerId\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:40.26795Z","iopub.execute_input":"2022-05-24T10:01:40.268225Z","iopub.status.idle":"2022-05-24T10:01:40.278011Z","shell.execute_reply.started":"2022-05-24T10:01:40.268196Z","shell.execute_reply":"2022-05-24T10:01:40.277034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Final look","metadata":{}},{"cell_type":"code","source":"display(train.head())\ndisplay(test.head())\n\nprint(train.info())\nprint(test.info())","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:41.872197Z","iopub.execute_input":"2022-05-24T10:01:41.872457Z","iopub.status.idle":"2022-05-24T10:01:41.918819Z","shell.execute_reply.started":"2022-05-24T10:01:41.87243Z","shell.execute_reply":"2022-05-24T10:01:41.918168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Machine Learning\n\nTo evaluate our model's performance, we need to split our train data into training and test sets.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Select the features and the target\nX = train.values\ny = target.values\n\n# Split the data info training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:45.264166Z","iopub.execute_input":"2022-05-24T10:01:45.264449Z","iopub.status.idle":"2022-05-24T10:01:45.273018Z","shell.execute_reply.started":"2022-05-24T10:01:45.264418Z","shell.execute_reply":"2022-05-24T10:01:45.272152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have used GridSearchCV for tuning my Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"# Import Necessary libraries\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n\n# Initialize a RandomForestClassifier\nrf = RandomForestClassifier(random_state=34)\n\nparams = {'n_estimators': [50, 100, 200, 300, 350],\n          'max_depth': [3,4,5,7, 10,15,20],\n          'criterion':['entropy', 'gini'],\n          'min_samples_leaf' : [1, 2, 3, 4, 5, 10],\n          'max_features':['auto'],\n          'min_samples_split': [3, 5, 10, 15, 20],\n          'max_leaf_nodes':[2,3,4,5],\n          }\n\nclf = GridSearchCV(estimator=rf,param_grid=params,cv=10, n_jobs=-1)\n\nclf.fit(X_train, y_train.ravel())\n\nprint(clf.best_estimator_)\nprint(clf.best_score_)\n\nrf_best = clf.best_estimator_\n\n# Predict from the test set\ny_pred = clf.predict(X_test)\n\n# Print the accuracy with accuracy_score function\nprint(\"Accuracy: \", accuracy_score(y_test, y_pred))\n\n# Print the confusion matrix\nprint(\"\\nConfusion Matrix\\n\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T10:01:48.206376Z","iopub.execute_input":"2022-05-24T10:01:48.207077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save the model\n\n","metadata":{}},{"cell_type":"code","source":"pickle.dump(rf_best, open(\"model.pkl\", 'wb'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can look at the feature importances.","metadata":{}},{"cell_type":"code","source":"# Create a pandas series with feature importances\nimportance = pd.Series(rf_best.feature_importances_,index=train.columns).sort_values(ascending=False)\n\nsns.barplot(x=importance, y=importance.index)\n# Add labels to your graph\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.title(\"Important Features\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:59:25.818082Z","iopub.status.idle":"2022-05-24T09:59:25.818782Z","shell.execute_reply.started":"2022-05-24T09:59:25.818507Z","shell.execute_reply":"2022-05-24T09:59:25.818532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train the model again with entire train data.\n\n","metadata":{}},{"cell_type":"code","source":"last_clf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=4, max_features='auto',\n                       max_leaf_nodes=5, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=15,\n                       min_weight_fraction_leaf=0.0, n_estimators=350,\n                       n_jobs=None, oob_score=True, random_state=34, verbose=0,\n                       warm_start=False)\n\nlast_clf.fit(train, target)\nprint(\"%.4f\" % last_clf.oob_score_)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:59:25.82008Z","iopub.status.idle":"2022-05-24T09:59:25.820759Z","shell.execute_reply.started":"2022-05-24T09:59:25.820502Z","shell.execute_reply":"2022-05-24T09:59:25.820528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare the submission file\n\n","metadata":{}},{"cell_type":"code","source":"# Store passenger ids\nids = pd.read_csv(\"test.csv\")[[\"PassengerId\"]].values\n\n# Make predictions\npredictions = last_clf.predict(test.values)\n\n# Print the predictions\nprint(predictions)\n\n# Create a dictionary with passenger ids and predictions\ndf = {'PassengerId': ids.ravel(), 'Survived':predictions}\n\n# Create a DataFrame named submission\nsubmission = pd.DataFrame(df)\n\n# Display the first five rows of submission\ndisplay(submission.head())\n\n# Save the file\nsubmission.to_csv(\"submission_last.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T09:59:25.822029Z","iopub.status.idle":"2022-05-24T09:59:25.822719Z","shell.execute_reply.started":"2022-05-24T09:59:25.822436Z","shell.execute_reply":"2022-05-24T09:59:25.82246Z"},"trusted":true},"execution_count":null,"outputs":[]}]}