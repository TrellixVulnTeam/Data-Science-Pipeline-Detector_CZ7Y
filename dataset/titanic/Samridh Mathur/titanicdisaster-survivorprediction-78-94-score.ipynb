{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle - Titanic: Machine Learning from Disaster\n\nThe competition details as below\n\n### The Challenge\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc). \n\n### Predicting the survival on the Titanic","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Prediction Results : 0.78947**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Load Helpful Packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the Data ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/titanic/train.csv')\ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/titanic/test.csv')\ntest_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check Missing Values ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Missing values in train_data\ntrain_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Missing values in test_data\ntest_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\ntest_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = 'Embarked', kind = 'count', data = train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Embarked'] = train_data['Embarked'].fillna(\"S\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Cabin'] = train_data['Cabin'].fillna(\"Missing\")\ntest_data['Cabin'] = test_data['Cabin'].fillna(\"Missing\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Fare'] = test_data['Fare'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### No missing values left so we can proceed further","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## get dummy variables for Column sex and embarked since they are categorical value.\ntrain_data = pd.get_dummies(train_data, columns=[\"Sex\"], drop_first=True)\ntrain_data = pd.get_dummies(train_data, columns=[\"Embarked\"],drop_first=True)\n\n\n#Mapping the data.\ntrain_data['Fare'] = train_data['Fare'].astype(int)\ntrain_data.loc[train_data.Fare<=7.91,'Fare']=0\ntrain_data.loc[(train_data.Fare>7.91) &(train_data.Fare<=14.454),'Fare']=1\ntrain_data.loc[(train_data.Fare>14.454)&(train_data.Fare<=31),'Fare']=2\ntrain_data.loc[(train_data.Fare>31),'Fare']=3\n\ntrain_data['Age']=train_data['Age'].astype(int)\ntrain_data.loc[ train_data['Age'] <= 16, 'Age']= 0\ntrain_data.loc[(train_data['Age'] > 16) & (train_data['Age'] <= 32), 'Age'] = 1\ntrain_data.loc[(train_data['Age'] > 32) & (train_data['Age'] <= 48), 'Age'] = 2\ntrain_data.loc[(train_data['Age'] > 48) & (train_data['Age'] <= 64), 'Age'] = 3\ntrain_data.loc[train_data['Age'] > 64, 'Age'] = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## get dummy variables for Column sex and embarked since they are categorical value.\ntest_data = pd.get_dummies(test_data, columns=[\"Sex\"], drop_first=True)\ntest_data = pd.get_dummies(test_data, columns=[\"Embarked\"],drop_first=True)\n\n\n#Mapping the data.\ntest_data['Fare'] = test_data['Fare'].astype(int)\ntest_data.loc[test_data.Fare<=7.91,'Fare']=0\ntest_data.loc[(test_data.Fare>7.91) &(test_data.Fare<=14.454),'Fare']=1\ntest_data.loc[(test_data.Fare>14.454)&(test_data.Fare<=31),'Fare']=2\ntest_data.loc[(test_data.Fare>31),'Fare']=3\n\ntest_data['Age']=test_data['Age'].astype(int)\ntest_data.loc[ test_data['Age'] <= 16, 'Age']= 0\ntest_data.loc[(test_data['Age'] > 16) & (test_data['Age'] <= 32), 'Age'] = 1\ntest_data.loc[(test_data['Age'] > 32) & (test_data['Age'] <= 48), 'Age'] = 2\ntest_data.loc[(test_data['Age'] > 48) & (test_data['Age'] <= 64), 'Age'] = 3\ntest_data.loc[test_data['Age'] > 64, 'Age'] = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In our data the Ticket and Cabin,Name are the base less,leds to the false prediction so Drop both of them.\ntrain_data.drop(['Ticket','Cabin','Name'],axis=1,inplace=True)\ntest_data.drop(['Ticket','Cabin','Name'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.Survived.value_counts()/len(train_data)*100\n#This signifies almost 61% people in the ship died and 38% survived.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.groupby(\"Survived\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.groupby(\"Sex_male\").mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" #### The points to know from the analysis\n #### 1. 38% of people survived\n #### 2. 74% of Females survived and ~19% of Males survived ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Correlation between Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Heatmap\nplt.subplots(figsize=(10,8))\nsns.heatmap(train_data.corr(),annot=True,cmap='Blues_r')\nplt.title(\"Correlation Among Variables\", fontsize = 20);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Survived has positive correlation of 0.3 with Fare\n- Sex and survived have negative correlation of -0.54\n- Pclass and Survived have negative correlation of -0.34**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"Sex_male\",y=\"Survived\",data=train_data)\nplt.title(\"Gender Distribution - Survived\", fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Female passengers have survived more than male passengers i.e Females and Children would have been the priority","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Pclass',y='Survived',data=train_data)\nplt.title(\"Passenger Class Distribution - Survived\", fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Survival as per classes\n- 63% of Passenger Class 1\n- 48% of Passenger Class 2\n- Only 25% of Passenger Class 3 survived","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Modeling Data \n###### I will be modelling the data with the below models:\n- Logistic Regression\n- Support Vector Machine\n- Decision Tree Classifier\n- Random Forest Classifier\n- K-Nearest Neighbour Classifier\n- Gradient Boosting\n- Grid SearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data.drop(['Survived'], axis=1)\ny = train_data[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.22, random_state = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X_train),len(X_test),len(y_train),len(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\nlogReg = LogisticRegression()\nlogReg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logReg_predict = logReg.predict(X_test)\nlogReg_score = logReg.score(X_test,y_test)\n# print(\"Logistic Regression Prediction :\",logReg_predict)\nprint(\"Logistic Regression Score :\",logReg_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score of Logistic Regression Model:\")\nprint(metrics.accuracy_score(y_test,logReg_predict))\nprint(\"\\n\",\"Classification Report:\")\nprint(metrics.classification_report(y_test,logReg_predict),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SVC_model = SVC(probability=True)\nSVC_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVC_predict = SVC_model.predict(X_test)\nSVC_score = SVC_model.score(X_test,y_test)\n#print(\"Support Vector Classifier Prediction :\",SVC_predict)\nprint(\"Support Vector Classifier Score :\",SVC_score)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score of Support Vector Classifier SVC Model:\")\nprint(metrics.accuracy_score(y_test,SVC_predict))\nprint(\"\\n\",\"Classification Report:\")\nprint(metrics.classification_report(y_test,SVC_predict),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"decisionTreeModel = DecisionTreeClassifier(max_leaf_nodes=17, random_state=0)\ndecisionTreeModel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decisionTree_predict = decisionTreeModel.predict(X_test)\ndecisionTree_score = decisionTreeModel.score(X_test,y_test)\n#print(\"Decision Tree Classifier Prediction :\",len(decisionTree_predict))\nprint(\"Decision Tree Classifier Score :\",decisionTree_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score of Decision Tree Classifier Model:\")\nprint(metrics.accuracy_score(y_test,decisionTree_predict))\nprint(\"\\n\",\"Classification Report:\")\nprint(metrics.classification_report(y_test,decisionTree_predict),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Random_forest = RandomForestClassifier(n_estimators=17)\nRandom_forest.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"randomForest_predict = Random_forest.predict(X_test)\nrandomForest_score = Random_forest.score(X_test,y_test)\n# print(\"Random Forest Prediction :\",RF_predict)\nprint(\"Random Forest Score :\",randomForest_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score of Random Forest Classifier Model:\")\nprint(metrics.accuracy_score(y_test,randomForest_predict))\nprint(\"\\n\",\"Classification Report:\")\nprint(metrics.classification_report(y_test,randomForest_predict),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-Nearest Neighbours","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN_model = KNeighborsClassifier(n_neighbors=37)\nKNN_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN_predict = KNN_model.predict(X_test)\nKNN_score = KNN_model.score(X_test,y_test)\n#print(\"KNN Classifier Prediction :\",KNN_predict)\nprint(\"KNN Classifier Score :\",KNN_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score of KNN Model:\")\nprint(metrics.accuracy_score(y_test,KNN_predict))\nprint(\"\\n\",\"Classification Report:\")\nprint(metrics.classification_report(y_test,KNN_predict),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier(random_state=101, n_estimators=150,min_samples_split=100, max_depth=6)\ngbk.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbk_predict = gbk.predict(X_test)\ngbk_score = gbk.score(X_test,y_test)\n#print(\"Gradient Boosting Prediction :\",gbk_predict)\nprint(\"Gradient Boosting Score :\",gbk_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score of Gradient Boosting Model:\")\nprint(metrics.accuracy_score(y_test,gbk_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid SearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GridList =[ {'n_estimators' : [10, 15, 20, 25, 30, 35, 40], 'max_depth' : [5,10,15, 20]},]\nrandomForest_ensemble = ensemble.RandomForestClassifier(random_state=31, max_features= 3)\ngridSearchCV = GridSearchCV(randomForest_ensemble,GridList, cv = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gridSearchCV.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gridSearchCV_predict = gridSearchCV.predict(X_test)\ngridSearchCV_score = gridSearchCV.score(X_test,y_test)\n#print(\"Grid SearchCV Prediction :\",gridSearchCV_predict)\nprint(\"Grid SearchCV Score :\",gridSearchCV_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tabulate import tabulate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tabulate([['K-Nearest Neighbour', KNN_score],['Logistic Regression',logReg_score ],['Decision Tree',decisionTree_score ],['Random Forest',randomForest_score ],['SVC', SVC_score],['Gradient Boosting', gbk_score],['Grid SearchCV',gridSearchCV_score]], headers=['Model Algorithm', 'Score']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From the above table, we can clearly see that the accuracy of the Grid SearchCV is Better\n\n#### Lets apply this to our test data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Prediction\n\n#### Let's use the Gradient Boosting Classifier to predict our data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set ids as PassengerId and predict survival \nids = test_data['PassengerId']\nprint(len(ids))\npredictions = gridSearchCV.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.head(10) # Output preview","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv('submission.csv', index=False) # Submission csv file","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will keep updating the notebook with updates\n\n**If you have any recommendations and suggestions, please share in the comments below !!**\n\nLooking forward to know your views and suggestions :)\n\n**If you feel the notebook is worth it, UPVOTE !!**\n\n**Thanks for reading :)**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**In Case you fork the Notebook, Don't forget to Mention the Author's name and Link below as well**\nhttps://www.kaggle.com/samridhmathur/titanicdisaster-survivorprediction-78-94-score/","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}