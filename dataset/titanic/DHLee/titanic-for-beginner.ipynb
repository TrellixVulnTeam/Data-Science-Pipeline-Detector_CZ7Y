{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\nsns.set(style='ticks', context='talk')\nplt.style.use('dark_background')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATADIR = '../input/titanic/'\n\ntrain  = pd.read_csv('{0}train.csv'.format(DATADIR))\ntest   = pd.read_csv('{0}test.csv'.format(DATADIR))\n\ntrain_len = len(train)\nIDtest = test['PassengerId'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"First, check the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features\n> ##  1. Age\n> ##  2. Sex, SibSp+Parch, Name\n> ##  3. Embarked\n> ##  4. Fare\n> ##  5. Pclass, Cabin\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.concat( objs=[train, test], axis=0 ).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## 1. Age\n \n > ### 1.1 Check Null "},{"metadata":{},"cell_type":"markdown","source":"> ### 1.2 Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(10,6))\n\nsns.distplot(dataset['Age'][(dataset['Age'].notnull())&(dataset['Survived']==0)] ,color='r', ax=ax )\nsns.distplot(dataset['Age'][(dataset['Age'].notnull())&(dataset['Survived']==1)] ,color='b', ax=ax )\n\nplt.legend(['Not Survived', 'Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def age_classify(x):\n    return int(x//10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Before handling 'Age' null data, I'm gonna separate few class with 10 years."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Age'] = dataset['Age'][dataset['Age'].notnull()].apply(age_classify)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Age'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As saw you above, there's different number of people <br>\n> So I thought that I need to fill NaN data with staying this distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"m = len(dataset['n_Age'].value_counts())\ntotal = dataset['n_Age'].value_counts().sum()\ntotal_null = dataset['n_Age'].isnull().sum()\n\nage_percent = [0]*m\nage_dist    = [0]*m\n\nfor i in range(m):\n    age_percent[i]=round((dataset['n_Age'].value_counts()[i]/total),3)\n    age_dist[i] = int(round(age_percent[i]*total_null))\n\nage_dist[3]-=1\nprint('percentage[%] : ',np.multiply(age_percent,100))\nprint('counts for n_Age :',age_dist)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> This finds percentage of 'n_Age' class.\n\n> 0~9   years: 7.8%<br>\n> 10~19 years: 13.7%<br>\n> ...<br>\n> 80~   years: 0.1%<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntotal_null = dataset['n_Age'].isnull().sum()\n\nfor i in dataset['n_Age'].index[dataset['n_Age'].isnull()]:\n    if age_dist[0] != 0: \n        dataset['n_Age'][i]=0.0\n        age_dist[0]-=1\n    elif age_dist[1] != 0: \n        dataset['n_Age'][i]=1.0\n        age_dist[1]-=1\n    elif age_dist[2] != 0:\n        dataset['n_Age'][i]=2.0\n        age_dist[2]-=1\n    elif age_dist[3] != 0: \n        dataset['n_Age'][i]=3.0\n        age_dist[3]-=1\n    elif age_dist[4] != 0: \n        dataset['n_Age'][i]=4.0\n        age_dist[4]-=1\n    elif age_dist[5] != 0:\n        dataset['n_Age'][i]=5.0\n        age_dist[5]-=1\n    elif age_dist[6] != 0: \n        dataset['n_Age'][i]=6.0\n        age_dist[6]-=1            \n    elif age_dist[7] != 0: \n        dataset['n_Age'][i]=7.0\n        age_dist[7]-=1\n    elif age_dist[8] != 0: \n        dataset['n_Age'][i]=8.0\n        age_dist[8]-=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(14, 6))\n\ng1 = sns.countplot( x='n_Age', hue='Survived',data=dataset, palette='YlGnBu_r', ax=ax[0])\ng2 = sns.factorplot(x='n_Age', y='Survived',  data=dataset, palette='YlGnBu_r', ax=ax[1], kind = 'bar')\n\nplt.close(g2.fig)\nplt.subplots_adjust(wspace = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax= plt.subplots(1,2,figsize=(18,6))\n\ng1 = sns.factorplot(x='n_Age',hue='Survived', data=dataset, kind='count', palette='YlGnBu_r', ax=ax[0])\ng2 = sns.factorplot(x='n_Age',  y='Survived', data=dataset, kind='bar',   palette='YlGnBu_r', ax=ax[1])\n\nax[0].legend(['Not Survived', 'Survived'],loc='best')\nax[1].set_ylabel('Survived Probability')\n\nplt.subplots_adjust(wspace=1)\nplt.close(g1.fig)\nplt.close(g2.fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(labels=['Age'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Sex / SibSp+Parch / Name\n___\n\n\n ### 2.1 Sex<br>\n>  2.1.1 Cleaning<br>\n>  2.1.2 Correlation with Age, Pclass, Embarked \n\n ### 2.2 FamSize = SibSp + Parch + 1\n> 2.2.1 Cleaning<br>\n> 2.2.2 Engineering<br>\n> 2.2.3 Check Survival Rate.\n\n ### 2.3 Name\n> 2.3.1 Cleaning <br>\n> 2.3.2 Engineering<br>\n> 2.3.3 Check Survival Rate.\n___"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Sex\n> ### 2.1.1 Cleaning Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As you can see above, there's no NaN value so that I don't have to replace them."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(12,6))\n\ng = sns.factorplot( x='Sex', y='Survived', data=dataset, palette='Blues_r', kind='bar' ,ax=ax[0] )\nplt.close(g.fig)\n\ng2 = sns.countplot( x='Sex', data=dataset, palette='Blues_r', ax=ax[1] )\nplt.subplots_adjust(wspace=0.5)\n\nax[0].set_xticklabels(['Female', 'Male']);\nax[1].set_xticklabels(['Female', 'Male']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### 2.1.2 Engineering\n> Make string value ('female', 'male) to integer( 0 / 1 )"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Sex'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1.3 Correlation with Age, Pclass, Embarked\n> Make the plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,2, figsize=(15,15))\n\ng1 = sns.countplot(x='n_Age',                  hue='Sex', data=dataset, palette='Blues_r',     ax=ax[0,0])\ng2 = sns.barplot(  x='n_Age',    y='Survived', hue='Sex', data=dataset, palette='Greens_r',    ax=ax[0,1])\ng3 = sns.barplot(  x='Pclass',   y='Survived', hue='Sex', data=dataset, palette='Oranges_r',   ax=ax[1,0])\ng4 = sns.barplot(  x='Embarked', y='Survived', hue='Sex', data=dataset, palette='Reds_r',      ax=ax[1,1])\n\ng1.set_ylabel('Counts')\ng2.set_ylabel('survived Probability')\ng3.set_ylabel('survived Probability')\ng4.set_ylabel('survived Probability')\n\nax[0,0].legend(['Female','Male'])\n\nplt.subplots_adjust(wspace=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> You can see \"Lady, Kids, Elderly First\""},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 2.2 FamilySize = SibSp + Parch\n> ### 2.2.1. Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['SibSp'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Parch'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's nothing to clean up for NaN value."},{"metadata":{},"cell_type":"markdown","source":"> ### 2.2.2 Engineering Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['FamSize']=dataset['SibSp']+dataset['Parch']+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['FamSize'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['FamSize'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### 2.2.3 Check Survival Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1, figsize=(12,10))\n\ng1 = sns.countplot(x='FamSize', data=dataset, palette='RdBu', ax=ax[0])\ng2 = sns.factorplot(x='FamSize', y='Survived',kind='bar', data=dataset, palette='RdBu', ax=ax[1])\nax[1].set(ylabel='survived probability')\n\nplt.close(g2.fig)\nplt.subplots_adjust(hspace=0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(labels=['SibSp','Parch'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 2.3 Name\n> ### 2.3.1 Cleaning\n> ### 2.3.2 Engineering\n> ### 2.3.3 Check Survival Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Name'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Name'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> There's no NaN value.<br>\nHowever, 'Name' data is not usefull by itself.<br>\nI thought that I need to refine this data.<br><br>\n\n>Then, how can I refine it?<br>\nLet's think about that emergency situation that so many people need to escape.<br>\n\n>As there're so many people, we can't call their total name.<br>\nMaybe we should not do that for rescue much more people rapidly.<br>\n\n>\nSo, I thought maybe I only need the title of their Name's<br>\n\n\n"},{"metadata":{},"cell_type":"markdown","source":" ### 2.3.2 Engineering Feature\n\n> 1) Sperate Title from Name <br>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Title'] = [0]*dataset['Name'].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num=0\nfor x in dataset['Name']:\n    title = x.split(',')[1].split(',')[0].split('.')[0]\n    title = title.split(' ')[1]\n    dataset['Title'][num]=title\n    num+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> 2) Replacing Rare value with one of clear titles('Miss', 'Mr', 'Mrs', 'Master') <br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Title'].replace(['Rev','Dr','Col','Major','Jonkheer','Ms','Mlle','Mme','Lady','Dona','the Countess','Sir','Capt','Don'],'Rare', inplace=True)\ndataset['Title'] = dataset['Title'].replace(['Ms','Mlle','Mme','Lady','Dona','the'],'Miss')\ndataset['Title'] = dataset['Title'].replace(['Sir','Capt','Don'],'Mr')\n\ndataset['Title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(15, 6))\n\ng1 = sns.countplot(x='Title', data=dataset, palette='YlGnBu_r', ax=ax[0] )\ng2 = sns.factorplot(x='Title', y='Survived', data=dataset, palette='YlGnBu_r',kind='bar', ax=ax[1])\nplt.close(g2.fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As you can see above, even though there's so many men, Most of them could not survived.<br>\n> Again, They behave **<u>'Lady, elderly First'</u>** even if they were in desperate situation."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(labels=['Name'], axis=1, inplace=True)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Embarked\n\n> ### 3.1 Cleaning<br>\n: Replaceing NaN data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Embarked'].fillna(method='ffill', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Embarked'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### 3.2 Engineering\n> Nothing special but make string value to integer."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(18,6))\n\ng = sns.factorplot(x='Embarked', y='Survived',data=dataset, kind='bar', palette='binary', ax=ax[0])\nax[0].set(ylabel='survived probability')\n\ng2 = sns.countplot(x='Embarked', hue='Survived',data=dataset, palette='binary',ax=ax[1])\ng2.set(ylabel='survived counts')\ng2.legend(['Not Survived', 'Survived'])\n\nplt.close(g.fig)\nplt.subplots_adjust(wspace=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Fare"},{"metadata":{},"cell_type":"markdown","source":"> ### 4.1 Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Fare'].fillna(method='ffill',inplace=True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Fare'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> There's no NaN value to clean"},{"metadata":{},"cell_type":"markdown","source":"> ### 4.2 Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Fare'] = (dataset['Fare']//1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Fare'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Fare'] = pd.qcut(dataset['n_Fare'], 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mapping(x):\n    x= str(x)\n    left= (x.split(', ')[0].split('(')[1])\n    if   left =='-0.001': return 1\n    elif left =='7.0'   : return 2\n    elif left =='8.0'   : return 3\n    elif left =='12.0'  : return 4\n    elif left =='19.0'  : return 5\n    elif left =='27.0'  : return 6\n    elif left =='59.0'  : return 7    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Fare'] = dataset['n_Fare'].map(mapping)\ndataset['n_Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Fare'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize=(15, 6))\ng=sns.factorplot(x='n_Fare', y='Survived', data=dataset, kind='bar', palette='YlGnBu_r', ax=ax)\nplt.close(g.fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### 4.3 Checking Survival rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2,figsize=(17, 6))\n\ng  = sns.countplot( x='n_Fare', hue='Survived', data=dataset, palette='Greens_r', ax=ax[0])\ng2 = sns.factorplot(x='n_Fare', y='Survived',   data=dataset, palette='Blues_r',  ax=ax[1], kind='bar')\nax[0].set(ylabel='Survived counts')\nax[1].set(ylabel='Survived probability')\n\nplt.close(g2.fig)\nplt.subplots_adjust(wspace=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(labels=['Fare', 'PassengerId'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 5. Pclass, Cabin"},{"metadata":{},"cell_type":"markdown","source":"> ### 5.1 Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Pclass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Pclass'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> There's nothing to clean up.\n\n> ### 5.2 Engineering\n> Actually, no need to refine. "},{"metadata":{},"cell_type":"markdown","source":"### 5.3 Check the Survival Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(18, 6))\n\ng = sns.factorplot( x='Pclass', y='Survived', data=dataset, palette='Greens_r', kind='bar', ax=ax[0] )\nplt.close(g.fig)\n\ng = sns.countplot( x='Pclass', hue='Survived',data=dataset, palette='bone_r', ax=ax[1] )\ng.legend(['Not Survived', 'Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"> 1st Class has highest survival rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Cabin'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def refine(x):\n    if type(x)==float: return 'X'\n    else:\n        if len(x)>4: return x.split(' ')[0][0]\n        else: return x[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Cabin'] = dataset['Cabin'].apply(refine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Cabin'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(15, 6))\ng1 = sns.countplot( x='n_Cabin', data=dataset, palette='rainbow' ,ax=ax[0] )\ng2 = sns.factorplot( x='n_Cabin', y='Survived', data=dataset, palette='rainbow', kind='bar', ax=ax[1] )\n\nplt.subplots_adjust(wspace=1.0)\nplt.close(g2.fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['n_Cabin']=dataset['n_Cabin'].map({'A':2,'B':1,'C':3,'D':1,'E':1,'F':3,'G':2,'T':1,'X':4})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x='n_Cabin',y='Survived', data=dataset, kind='bar', palette='YlGnBu_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop(labels=['Cabin'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Ticket\n> ## 6.1 Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Ticket'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Ticket_Frequency'] = dataset.groupby('Ticket')['Ticket'].transform('count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(15, 6))\n\ng1 = sns.countplot(x='Ticket_Frequency',              hue='Sex', data=dataset, palette='Oranges_r', ax=ax[0]  )\ng2 = sns.barplot(  x='Ticket_Frequency', y='Survived',hue='Sex', data=dataset, palette='Oranges_r', ax=ax[1]  )\ng1.legend(['Female', 'Male'])\nplt.subplots_adjust(wspace=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can check the correlation between Ticket number length and Sex\n\n> If Ticket length is 3 and female, She would be survived.\n> And also legnth 5 and female.\n\n> So, I'm gonna use this data."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop(labels=['Ticket'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One-Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset.profile_report()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Emabarked unique() :' , dataset['Embarked'].unique())\nprint('Title.    unique() :' , dataset['Title'   ].unique())\nprint('Sex       unique() :' , dataset['Sex'     ].unique())\nprint('Pclass    unique() :' , dataset['Pclass'  ].unique())\nprint('n_Age     unique() :' , dataset['n_Age'   ].unique())\nprint('FamSize   unique() :' , dataset['FamSize' ].unique())\nprint('n_Cabin   unique() :' , dataset['n_Cabin' ].unique())\nprint('n_Fare    unique() :' , dataset['n_Fare'  ].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encoding for non integer values\ndataset = pd.get_dummies(dataset, columns=[ 'Sex'     ], prefix='Sx')\ndataset = pd.get_dummies(dataset, columns=[ 'Embarked'], prefix='Em')\ndataset = pd.get_dummies(dataset, columns=[ 'Title'   ], prefix='Tt')\ndataset = pd.get_dummies(dataset, columns=[ 'n_Fare'  ], prefix='nF')\n\n# dataset = pd.get_dummies(dataset, columns=[ 'n_Age'   ], prefix='nA')\n# dataset = pd.get_dummies(dataset, columns=[ 'Pclass'  ], prefix='Pc')\n# dataset = pd.get_dummies(dataset, columns=[ 'FamSize' ], prefix='FS')\n# dataset = pd.get_dummies(dataset, columns=[ 'Ticket_Frequency'], prefix='nT')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This part is for removing low feature_importance_values.\n# However that doesn't mean that we don't need these values.\n\n# So to check this, I erased values which has low importance values, But the result doesn't changed.\n\n# dataset.drop(['nA_1','nA_4','nA_5','nA_6','nA_7','nA_8'],axis=1, inplace=True)\n# dataset.drop(['Tt_1','Tt_2','Tt_3','Tt_4'],axis=1,inplace=True)\n# dataset.drop(['Em_1','Em_2'],              axis=1,inplace=True)\n# dataset.drop(['Pc_1','Pc_2'],              axis=1,inplace=True)\n# dataset.drop(['nT_5','nT_8','nT_7','nT_11','nF_2','nF_3','nF_7'],       axis=1,inplace=True)\n# dataset.drop(['FS_1','FS_2','FS_4','FS_5','FS_6','FS_7','FS_8','FS_11'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"### 1. Seperate dataset to train/test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = dataset[:train_len]\ntest  = dataset[train_len:]\ntest.drop(labels=['Survived'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Survived'] = train['Survived'].astype(int)\nY_train = train['Survived']\nX_train = train.drop(labels=['Survived'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Cross validate models. "},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = StratifiedKFold(n_splits=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nrandom_state=3\nclassifiers = []\n\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state), random_state=random_state, learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state=random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\nclassifiers.append(XGBClassifier(random_state=random_state))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = []\n\nfor classifier in classifiers:\n    cv_results.append(cross_val_score(classifier, X_train, y=Y_train, scoring='accuracy', cv=kfold, n_jobs=4))\n\ncv_means = []\ncv_std   = []\nfor cv_result in cv_results:\n    cv_means.append( cv_result.mean() )\n    cv_std.append(   cv_result.std()  )\n    \ncv_res = pd.DataFrame({'CrossValMeans':cv_means, 'CorssValerrors':cv_std,\n                       'Algorithm':['SVC','DecisionTree','AdaBoost','RandomForest','ExtraTrees',\n                                    'GradientBoosting','MultipleLayerPerceptron','KNeighbors','LogisticRegression','LinearDiscriminantAnalysis','XGBoost']})\n\ng = sns.barplot('CrossValMeans','Algorithm', data=cv_res, palette='YlGnBu', orient='h', **{'xerr':cv_std})\ng = g.set(title='Cross Validation scores',xlabel='Mean Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB = XGBClassifier(random_state=0)\n\nxgb_param_grid={'colsample_bylevel':[0.9],\n                'colsample_bytree' :[0.8],\n                'gamma'            :[0.99],\n                'max_depth'        :[4],\n                'min_child_weight' :[1],\n                'n_estimators'     :[10],\n                'nthread'          :[4],\n                'silent'           :[True]}\n\ngsXGB = GridSearchCV(XGB, param_grid=xgb_param_grid, cv=kfold, scoring='accuracy', n_jobs=4, verbose=1)\ngsXGB.fit(X_train, Y_train)\nXGBC_best = gsXGB.best_estimator_\n\ngsXGB.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DTC = DecisionTreeClassifier(max_depth=1)\n\nadaDTC = AdaBoostClassifier(DTC, random_state=0)\n\nada_param_grid = {'base_estimator__criterion':['gini', 'entropy'],\n                  'base_estimator__splitter' :['best', 'random'],\n                  'algorithm'                :['SAMME', 'SAMME.R'],\n                  'n_estimators'             :[100],\n                  'learning_rate'            :[0.0001, 0.001, 0.01, 0.1, 1, 5, 10]}\n\ngsadaDTC = GridSearchCV( adaDTC, param_grid=ada_param_grid, cv=kfold, scoring='accuracy', n_jobs=4, verbose=1 )\ngsadaDTC.fit(X_train,Y_train)\nada_best = gsadaDTC.best_estimator_\n\ngsadaDTC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ExtC = ExtraTreesClassifier(random_state=0)\n\nex_param_grid = {'max_depth'        :[4],\n                 'max_features'     :[7],\n                 'min_samples_split':[8],\n                 'min_samples_leaf' :[4],\n                 'bootstrap'        :[False],\n                 'n_estimators'     :[100],\n                 'criterion'        :['gini']}\n\ngsExtC = GridSearchCV(ExtC, param_grid=ex_param_grid, cv=kfold, scoring='accuracy', n_jobs=4, verbose=1)\ngsExtC.fit(X_train, Y_train)\n\nExtC_best = gsExtC.best_estimator_\n\ngsExtC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC = RandomForestClassifier(random_state=0)\n\nrf_param_grid = {'max_depth'        :[6],\n                 'max_features'     :[10],\n                 'min_samples_split':[10],\n                 'bootstrap'        :[False],\n                 'n_estimators'     :[100],\n                 'criterion'        :['gini']}\n\ngsRFC = GridSearchCV(RFC, param_grid=rf_param_grid, cv=kfold, scoring='accuracy', n_jobs=4, verbose=1)\ngsRFC.fit(X_train, Y_train)\nRFC_best = gsRFC.best_estimator_\n\ngsRFC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GBC = GradientBoostingClassifier(random_state=0)\n\ngb_param_grid = {'loss'            :['deviance'],\n                 'n_estimators'    :[10],\n                 'learning_rate'   :[0.001, 0.01, 0.1, 1, 10, 100],\n                 'max_depth'       :[4],\n                 'min_samples_leaf':[8],\n                 'max_features'    :[0.3, 0.1]\n                }\n\ngsGBC = GridSearchCV( GBC, param_grid=gb_param_grid, cv=kfold, scoring='accuracy',n_jobs=4, verbose=1 )\n\ngsGBC.fit(X_train, Y_train)\nGBC_best = gsGBC.best_estimator_\n\ngsGBC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVMC = SVC(probability=True)\nsvc_param_grid = {'kernel':['rbf'],\n                  'gamma' :[0.01,0.1,1,10,100],\n                  'C'     :[0.01,0.1,1,10,100]}\n\ngsSVMC = GridSearchCV(SVMC, param_grid=svc_param_grid, cv=kfold, scoring='accuracy', n_jobs=4, verbose=1)\n\ngsSVMC.fit(X_train, Y_train)\nSVMC_best = gsSVMC.best_estimator_\n\ngsSVMC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'solver':['adam'], 'max_iter':[800], 'alpha':10.0**-np.arange(1,10), 'hidden_layer_sizes':[40,20,10], 'random_state':[0,1] }\ngsMLPC=GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n\ngsMLPC.fit(X_train, Y_train)\nMLPC_best = gsMLPC.best_estimator_\n\ngsMLPC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel('Training examples')\n    plt.ylabel('Score')\n    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean( train_scores, axis=1 )\n    train_scores_std  = np.std(  train_scores, axis=1 )\n    test_scores_mean  = np.mean( test_scores, axis=1  )\n    test_scores_std   = np.std(  test_scores, axis=1  )\n    \n    plt.fill_between( train_sizes, train_scores_mean-train_scores_std, train_scores_mean+train_scores_std, alpha=0.1, color='r' )\n    plt.fill_between( train_sizes, test_scores_mean-train_scores_std,  test_scores_mean+train_scores_std,  alpha=0.1, color='g' )\n    \n    plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n    plt.plot(train_sizes, test_scores_mean,  'o-', color='g', label='Cross-validation score')\n    plt.legend(loc='best')\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g1 = plot_learning_curve( gsGBC.best_estimator_,    'Gradient Boosting Learning Curve', X_train, Y_train, cv=kfold )\ng2 = plot_learning_curve( gsExtC.best_estimator_,   'ExtraTrees learning curves',       X_train, Y_train, cv=kfold )\ng3 = plot_learning_curve( gsSVMC.best_estimator_,   'SVC learning curves',              X_train, Y_train, cv=kfold )\ng4 = plot_learning_curve( gsadaDTC.best_estimator_, 'AdaBoost learning curves',         X_train, Y_train, cv=kfold )\ng5 = plot_learning_curve( gsRFC.best_estimator_,    'RF learning curves',               X_train, Y_train, cv=kfold )\ng6 = plot_learning_curve( gsMLPC.best_estimator_,   'MLP learning curves',              X_train, Y_train, cv=kfold )\ng6 = plot_learning_curve( gsXGB.best_estimator_,    'XGB learning curves',              X_train, Y_train, cv=kfold )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nrows = 2\nncols = 2\nfig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex='all', figsize=(15,15))\n\nnames_classifiers = [('AdaBoosting', ada_best),('ExtraTrees',ExtC_best),('RandomForest',RFC_best),\n                     ('GradientBoosting',GBC_best)]\n\nnclassifier = 0\nfor row in range(nrows):\n    for col in range(ncols):\n        name = names_classifiers[nclassifier][0]\n        classifier = names_classifiers[nclassifier][1]\n        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n        g = sns.barplot(y=X_train.columns[indices][:40],x=classifier.feature_importances_[indices][:40], orient='h', ax=axes[row][col])\n        g.set_xlabel('Relative importance', fontsize=12)\n        g.set_ylabel('Features', fontsize=12)\n        g.tick_params(labelsize=9)\n        g.set_title(name+' feature importance')\n        nclassifier +=1\n        \nplt.subplots_adjust(wspace=0.4, hspace=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Survived_RFC  = pd.Series( RFC_best.predict(test), name='RFC' )\ntest_Survived_ExtC = pd.Series(ExtC_best.predict(test), name='ExtC')\ntest_Survived_SVMC = pd.Series(SVMC_best.predict(test), name='SVC' )\ntest_Survived_AdaC = pd.Series( ada_best.predict(test), name='Ada' )\ntest_Survived_GBC  = pd.Series( GBC_best.predict(test), name='GBC' )\ntest_Survived_MLP  = pd.Series(MLPC_best.predict(test), name='MLP' )\ntest_Survived_XGB  = pd.Series(XGBC_best.predict(test), name='XGB' )\n\nensemble_results = pd.concat( [test_Survived_RFC, test_Survived_ExtC, test_Survived_SVMC, \n                               test_Survived_AdaC, test_Survived_GBC, test_Survived_MLP, test_Survived_XGB], axis=1 )\ng = sns.heatmap(ensemble_results.corr(), annot=True, annot_kws={'size':12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# votingC = VotingClassifier(estimators = [('rfc',RFC_best),('extc',ExtC_best),('svc',SVMC_best),('adac',ada_best),('gbc',GBC_best),('mlp',MLPC_best)],voting='soft',n_jobs=4)\n# print(votingC)\n# votingC = votingC.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_Survived = pd.Series(votingC.predict(test), name='Survived')\n\n# results = pd.concat([IDtest, test_Survived],axis=1)\n\n# results.to_csv('51th_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Survived = gsExtC.predict(test)\n\nsubmission = pd.DataFrame({\n    'PassengerId' : IDtest,\n    'Survived' : test_Survived\n})\n\nsubmission.to_csv('ExtC_55th.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Survived = gsXGB.predict(test)\n\nsubmission = pd.DataFrame({\n    'PassengerId' : IDtest,\n    'Survived' : test_Survived\n})\n\nsubmission.to_csv('XGB_55th.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Survived = gsGBC.predict(test)\n\nsubmission = pd.DataFrame({\n    'PassengerId' : IDtest,\n    'Survived' : test_Survived\n})\n\nsubmission.to_csv('GBC_55th.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_Survived = gsSVMC.predict(test)\n\nsubmission = pd.DataFrame({\n    'PassengerId' : IDtest,\n    'Survived' : test_Survived\n})\n\nsubmission.to_csv('SVMC_55th.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_Survived = mlp.predict(test)\n\n# submission = pd.DataFrame({\n#     'PassengerId' : IDtest,\n#     'Survived' : test_Survived\n# })\n\n# submission.to_csv('my_NN_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}