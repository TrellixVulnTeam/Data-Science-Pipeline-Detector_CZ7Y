{"cells":[{"metadata":{},"cell_type":"markdown","source":"In the [last lesson](https://www.kaggle.com/prashantkikani/introduction-to-basic-python-libraries-for-ml), we saw basics of Python libraris which we use in Machine Learning.<br>\nToday in this lesson, we are going to solve one of the most famous & interesting problem. **Titanic survival problem** üõ≥Ô∏è\n\n![titanic](https://upload.wikimedia.org/wikipedia/commons/6/6e/St%C3%B6wer_Titanic.jpg)\n\n<br>\nIn this problem, we have some data about each passenger that were into that ship.<br>\n**Our problem is to predict or forecast, whether this person will survive the ship sinking or not**.<br><br>\n\nWe will try to solve this problem in a standard way.<br>\nWe can solve any machine learning problem this way.<br>\n\n## Goal of this lesson is to learn a standard way to solve / approch any machine learning problem.\n\nWe will keep this lesson as simple as possible so that everyone can grasp the idea & learn to solve any basic problem in ML.\n\nHere are the steps we tentatively follow.<br>\n1. Open the data files.\n2. Understand the data. What each column in the table means.\n3. Preprocess data\n    * Remove the outliers.\n    * Fill `NaN` or `null` values. Sometimes, we also remove all the rows with `NaN` values.\n    * Feature engineering - Create new columns out of existing columns using our understanding.\n    * Converting data into numeric form if it's not.\n4. Train a machine learning model.\n5. Validate the trained model i.e. checking it's performance on unseen data.\n6. If it performs good in validation, use model to predict future real world data.\n\n<br>\nAbove steps are generally followed to solve a ML problem.<br>\nSo, let's start.."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import necessary libraries first\n\n# pandas to open data files & processing it.\nimport pandas as pd\n\n# numpy for numeric data processing\nimport numpy as np\n\n# sklearn to do preprocessing & ML models\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Matplotlob & seaborn to plot graphs & visulisation\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# to fix random seeds\nimport random, os\n\n# ignore warnings\nimport warnings\nwarnings.simplefilter(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Open the data files."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"titanic_data = pd.read_csv(\"../input/titanic/train.csv\")\ntitanic_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have total of 891 rows & 12 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Understand the data. What each column in the table means.\n\n**Each row in above table contains data of a passenger.<br>**\nThose details include following columns.<br>\n\nHere is all the columns of above table mean.<br>\n\n`PassengerId` : Unique ID for each passenger.<br><br>\n`Survived` : Whether that passenger survived or not. (0 = No, 1 = Yes)<br><br>\n`Pclass` : Ticket class of passenger. (1 = Upper, 2 = Middle, 3 = Lower)<br><br>\n`Name` : Name of passenger<br><br>\n`Sex` : Gender of passenger<br><br>\n`Age` : Age of passenger<br><br>\n`SibSp` : # of siblings / spouses aboard the Titanic of passenger<br><br>\n`Parch` : # of parents / children aboard the Titanic of passenger<br><br>\n`Ticket` : Ticket number of passenger<br><br>\n`Fare` : Ticket amount / passenger fare.<br><br>\n`Cabin` : Cabin number of passenger<br><br>\n`Embarked` : Port of Embarkation of passenger. (C = Cherbourg, Q = Queenstown, S = Southampton)<br><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check unique values for each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Survival\ntitanic_data['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, total 335 people have survived & 547 people have died in the Titanic."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ticket class\ntitanic_data['Pclass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This tells `3` value occurs 491 times, `1` value occurs 207 times etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gender\ntitanic_data['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Siblings\ntitanic_data['SibSp'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parent or Childs\ntitanic_data['Parch'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Embarked station\ntitanic_data['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the passengers have embarked from \"Cherbourg\" & \"Southampton\""},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(titanic_data['Sex']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(titanic_data['Survived'], titanic_data['Sex']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow !<br>\n~75% of females have survived.<br>\nEven if total number of females are less than males.<br><br>\n\nMay be because, females were given more priority in lifeboats than males. May be."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(titanic_data['Survived'], titanic_data['Fare'], titanic_data['Pclass']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People with higher class have higher chances of survival !"},{"metadata":{},"cell_type":"markdown","source":"# 3. Preprocess data\n\nIn preprocessing step, we detect outliers & remove them from our data.\n\n## 3.1\n\n## What is an outlier in data? Why does it occur?\nOutliers are as the name suggests, very different from general / normal trend.<br>\nThey occur in data because of some faults in data collection pipeline.<br><br>\n\n## Why we generally remove outliers?\nBecause one big outlier can mess up whole model's performance.<br>\nEven if all other contributions might be of a low value, one high outlier value already shifts the entire gradient towards higher values as well.<br>\n\nMost of the time, we remove outliers so that, we can train our model only from general trends.<br>\nLet's see some examples using our titanic data.<br>\n\n### One common practice followed to detect outliers is BoxPlot."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=titanic_data[\"Fare\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see, for majority of passengers, `Fare` price is less than 250.<br>\nSo, let's only keep the rows with `Fare` < 250."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only take rows which have \"Fare\" value less than 250.\ntitanic_data = titanic_data[titanic_data['Fare'] < 250]\ntitanic_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have removed 9 rows.<br>Originally, there were 891 rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=titanic_data[\"Age\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see there are some outliers in `Age`, but they are not much far. So, we will keep as of now."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 3.2 Fill NaN or null values in data\n\n### Why NaN (not a number) values occur in data?\nSometimes, while collecting data, if some information is missing for some rows, it's filled as NaN.<br>\nIt means nothing is there.<br>\nIt's empty.<br>\n\n### How NaN values can be handled?\nThere are several methods.\n* Fill a specified value like \"EMPTY\" or -1 for all the NaN values.\n    * This option is good for categorical type columns / features.\n* If column is numeric in nature, fill with mean or median of that specific column.\n    * This option is good for numerical type columns / features.\n* Remove all the raws who have atleast 1 NaN value in any column.\n    * If total number of raws with NaN values is less, we can just remove those rows from our data.\n\nLet's look if there are any missing values in our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 177 NaN values in Age & 686 NaN values in Cabin column.<br>\nIn Cabin more than 75% values are empty.<br>\nSo, we will just remove that column."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.drop(\"Cabin\", axis=1, inplace=True)\ntitanic_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see `Cabin` column is removed from our data.<br><br>\nNow, `Age` is a numeric column.<br>\nSo, let's fill NaN values by mean of all the other non-NaN values."},{"metadata":{"trusted":true},"cell_type":"code","source":"age_mean = titanic_data['Age'].mean()\nprint(age_mean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can fill all the NaN values using `fillna` "},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data['Age'].fillna(age_mean, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are just 2 NaN values in `Embarked` column.<br>\nWe handle NaN values in `Embarked` column by filling most occuring value in that column."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data['Embarked'].fillna(\"S\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can see, no NaN values are there in our whole data."},{"metadata":{},"cell_type":"markdown","source":"Next step is **Feature Engineering**\n\n## 3.3\n\n### What is Feature Engineering?\n> Feature Engineering is creating more meaningful data out of existing data using our domain knowledge & comman sense.<br>\n\nIn other words, we try to create more relevant information for our ML models. <br>\nSo, that our model can capture patterns in faster & better ways.\n\n### Now, this is a creative step. We need to use brain to create relevant features in the data.\n\nLet's think."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's once again look at what we have at hand.<br><br><br>\n`PassengerId` : Unique ID for each passenger.<br><br>\n`Survived` : Whether that passenger survived or not. (0 = No, 1 = Yes)<br><br>\n`Pclass` : Ticket class of passenger. (1 = Upper, 2 = Middle, 3 = Lower)<br><br>\n`Name` : Name of passenger<br><br>\n`Sex` : Gender of passenger<br><br>\n`Age` : Age of passenger<br><br>\n`SibSp` : # of siblings / spouses aboard the Titanic of passenger<br><br>\n`Parch` : # of parents / children aboard the Titanic of passenger<br><br>\n`Ticket` : Ticket number of passenger<br><br>\n`Fare` : Ticket amount / passenger fare.<br><br>\n`Embarked` : Port of Embarkation of passenger. (C = Cherbourg, Q = Queenstown, S = Southampton)<br><br>\n\n### How can we use these columns to create more relevant information?\n\nLet's use `SibSp` & `Parch` to create a `total_family_members` feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data['total_family_members'] = titanic_data['Parch'] + titanic_data['SibSp'] + 1\n\n# if total family size is 1, person is alone.\ntitanic_data['is_alone'] = titanic_data['total_family_members'].apply(lambda x: 0 if x > 1 else 1)\n\ntitanic_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(titanic_data['total_family_members'], titanic_data['Survived'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interesting.<br>\nPeople with total_family_members = 4 have more than 70% chances of survival !<br><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(titanic_data['is_alone'], titanic_data['Survived'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People with family have 20% higher chance of survival than people travelling alone !!\n\n`Age` column also can be used to create partitions.<br>\nWe can use `apply` function to `Age` column to create new column `age_group`<br>\nLike.."},{"metadata":{"trusted":true},"cell_type":"code","source":"def age_to_group(age):\n    if 0 < age < 12:\n        # children\n        return 0\n    elif 12 <= age < 50:\n        # adult\n        return 1\n    elif age >= 50:\n        # elderly people\n        return 2\n    \ntitanic_data['age_group'] = titanic_data['Age'].apply(age_to_group)\ntitanic_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Why this age_group feature is useful ?\nLet's see.."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(titanic_data['age_group'], titanic_data['Survived']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`0` i.e. children have higher survival rate compared to adults & elderly people.<br>\nThis data may become useful to our model.<br>\n\n### Can you think of any way we can use `name` column ?\nWe can capture name title like Mr. Ms. Miss. etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data['name_title'] = titanic_data['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\ntitanic_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data['name_title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_name_title(val):\n    if val in ['Rev', 'Col', 'Mlle', 'Mme', 'Ms', 'Sir', 'Lady', 'Don', 'Jonkheer', 'Countess', 'Capt']:\n        return 'RARE'\n    else:\n        return val\n\ntitanic_data['name_title'] = titanic_data['name_title'].apply(clean_name_title)\ntitanic_data['name_title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(titanic_data['name_title'], titanic_data['Survived']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People with `Mrs` & `Miss` titles i.e. females have high chances of survival.<br>\nBut in males, with `Master` title, you have higher chances of survival !<br><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's drop columns which are not useful to us as of now.<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# save the target column \ntarget = titanic_data['Survived'].tolist()\n\ntitanic_data.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.4 Convert all the data into numeric form\n\nWe can see, `Sex`, `Embarked` & `name_title` are not in numeric form.<br>\nLet's convert them via LabelEncoder from sci-kit learn."},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ntitanic_data['Sex'] = le.fit_transform(titanic_data['Sex'])\ntitanic_data['Embarked'] = le.fit_transform(titanic_data['Embarked'])\ntitanic_data['name_title'] = le.fit_transform(titanic_data['name_title'])\ntitanic_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we have everything in numbers !!"},{"metadata":{},"cell_type":"markdown","source":"# 4. Train a machine learning model.\n\nIn this step, we choose a ML model & train it one the data we have.<br>\nFor this lesson, we will use basic `LogisticRegression` model.<br>\n\nBut first of all, let's split our data into training & validation part.<br>\nThere's `train_test_split` from sci-kit learn."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, val_data, train_target, val_target = train_test_split(titanic_data, target, test_size=0.2)\ntrain_data.shape, val_data.shape, len(train_target), len(val_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have our training data & validation data.<br>\nWe have randomly choosen 20% of the all the rows on which we will check our model's performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n# We fix all the random seed so that, we can reproduce the results.\nseed_everything(2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the LogisticRegression model.\n\nmodel = LogisticRegression()\nmodel.fit(train_data, train_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training is done.<br>\nWe have trainied our Logistic Regression model.<br><br>\n\n# 5. Validate the trained model i.e. checking it's performance on unseen data.\n\nIt's called \"unseen\" because our ML model have never seen this data.<br>\nIt's kind of a test for it.<br>\nWhere it's performance will be checked on data which it have never seen or train."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict labels on Validation data which model have never seen before.\n\nval_predictions = model.predict(val_data)\nlen(val_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first 10 values of validation_predictions\nval_predictions[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the accuracy score on validation data.\n# We already have correct target information for them.\n\naccuracy = accuracy_score(val_target, val_predictions)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Voila !!<br>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"We got %.3f percent accuracy on our validation unseen data !!\"%(accuracy*100))\nprint(\"We are %.3f correct in predicting whether a person will survice in Titanic crash !!\"%(accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How cool is that..!!\n\nThere's a lot can be done to improve performance.<br>\nBut we will not do that as of now to keep things simple as of now.<br>"},{"metadata":{},"cell_type":"markdown","source":"# 6. If it performs good in validation, use model to predict future real world data.\n\n### Now, we can use this model to other people & predict if they were on Titanic ship in 1912 !! "},{"metadata":{},"cell_type":"markdown","source":"# Summary\n\nSo, in this lesson, we saw, what a typical pipeline looks like in solving a machine learning(ML) problem.\n\n1. Open the data files.\n2. Understand the data. What each column in the table means.\n3. Preprocess data\n    * Remove the outliers.\n    * Fill `NaN` or `null` values. Sometimes, we also remove all the rows with `NaN` values.\n    * Feature engineering - Create new columns out of existing columns using our understanding.\n    * Converting data into numeric form if it's not.\n4. Train a machine learning model.\n5. Validate the trained model i.e. checking it's performance on unseen data.\n6. If it performs good in validation, use model to predict future real world data.\n\n\n## Upvote this kernel if you have learned something from it.\n## Tell me if you have any kind of doubts / questions in comment section below.\n\n## In next lesson we will solve this same problem with deep learning.\n## See you in the [next lesson](https://www.kaggle.com/prashantkikani/solving-the-titanic-problem-deep-learning-way) üëã"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}