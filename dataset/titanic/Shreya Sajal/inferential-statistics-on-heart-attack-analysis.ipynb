{"cells":[{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install chart_studio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt  # Matlab-style plotting\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\nfrom plotly import tools\nimport chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom IPython.display import HTML, Image\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/heart-attack-analysis-prediction-dataset/heart.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['output'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**List of continuous and categorical features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features=[i for i in df.columns if df[i].nunique()>5]\ncat_features=[i for i in df.columns if df[i].nunique()<=5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normality Check- Continuous Features:"},{"metadata":{},"cell_type":"markdown","source":"Test for Normality Of Features(A pre requirement for parametric hypothesis tests):\nWe check whether our continuous features are normal/not through:\n* Boxplots(to check for outliers causing non normality)\n* Distplots\n* Q-Q PLOTS\n* SHAPIRO WILK TEST(tests against the null hypothesis that the distribution is normal)\n"},{"metadata":{},"cell_type":"markdown","source":"**AGE**"},{"metadata":{},"cell_type":"markdown","source":"Boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot10=sns.boxplot(df['age'],orient='v')\nplt.title('Numerical Summary',fontdict={'fontsize':8})\nplt.xlabel('Age',fontdict={'fontsize':7})\nplt.ylabel(r'Five Point Summary(BP)',fontdict={'fontsize':7})\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distplot and Q-Q plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot([df.age],['age'],bin_size=5)\niplot(fig, filename='Basic Distplot')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(df['age'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shapiro Wilk Test "},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import shapiro\nimport scipy.stats as stats\nshapiro(df['age'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the p value<0.05(significance level),the null hypothesis is rejected and we conclude that the distribution is non normal."},{"metadata":{},"cell_type":"markdown","source":"**TRTBPS**\n\ntrtbps : resting blood pressure (in mm Hg)"},{"metadata":{},"cell_type":"markdown","source":"Boxplot and outliers removal"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot10=sns.boxplot(df['trtbps'],orient='v')\nplt.title('Numerical Summary',fontdict={'fontsize':8})\nplt.xlabel('trtbps',fontdict={'fontsize':7})\nplt.ylabel(r'Five Point Summary(BP)',fontdict={'fontsize':7})\nplt.tight_layout()\nQ1 = df['trtbps'].quantile(0.25)\nQ3 = df['trtbps'].quantile(0.75)\n\nIQR = Q3 - Q1    #IQR is interquartile range. \n\nfilter = (df['trtbps'] >= Q1 - 1.5 * IQR) & (df['trtbps'] <= Q3 + 1.5 *IQR)\ndf1=df.loc[filter]  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distplot and Q-Q plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot([df.trtbps],['trtbps'],bin_size=5)\niplot(fig, filename='Basic Distplot')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(df1['trtbps'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shapiro Wilk Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import shapiro\nimport scipy.stats as stats\nntA = shapiro(df1['trtbps'])\nntA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the p value<0.05(significance level),the null hypothesis is rejected and we conclude that the distribution is non normal."},{"metadata":{},"cell_type":"markdown","source":"**Thalachh**\n\nmax heart rate achieved\n"},{"metadata":{},"cell_type":"markdown","source":"Boxplot and Outliers Removal"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot10=sns.boxplot(df['thalachh'],orient='v')\nplt.title('Numerical Summary',fontdict={'fontsize':8})\nplt.xlabel('thalachh',fontdict={'fontsize':7})\nplt.ylabel(r'Five Point Summary(BP)',fontdict={'fontsize':7})\nplt.tight_layout()\nQ1 = df['thalachh'].quantile(0.25)\nQ3 = df['thalachh'].quantile(0.75)\n\nIQR = Q3 - Q1    #IQR is interquartile range. \n\nfilter = (df['thalachh'] >= Q1 - 1.5 * IQR) & (df['thalachh'] <= Q3 + 1.5 *IQR)\ndf1=df.loc[filter]  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distplot and Q-Q plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot([df.thalachh],['thalachh'],bin_size=5)\niplot(fig, filename='Basic Distplot')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(df1['thalachh'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shapiro Wilk Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import shapiro\nimport scipy.stats as stats\nshapiro(df1['thalachh'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the p value<0.05(significance level),the null hypothesis is rejected and we conclude that the distribution is non normal."},{"metadata":{},"cell_type":"markdown","source":"**Chol**\n\nCholesterol in mg/dl fetched via BMI sensor"},{"metadata":{},"cell_type":"markdown","source":"Boxplot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nplot10=sns.boxplot(df['chol'],orient='v')\nplt.title('Numerical Summary',fontdict={'fontsize':8})\nplt.xlabel('chol',fontdict={'fontsize':7})\nplt.ylabel(r'Five Point Summary(BP)',fontdict={'fontsize':7})\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = df['chol'].quantile(0.25)\nQ3 = df['chol'].quantile(0.75)\nIQR = Q3 - Q1    #IQR is interquartile range. \n\nfilter = (df['chol'] >= Q1 - 1.5 * IQR) & (df['chol'] <= Q3 + 1.5 *IQR)\ndf1=df.loc[filter]  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distplot and Q-Q plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot([df.chol],['chol'],bin_size=5)\niplot(fig, filename='Basic Distplot')\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(df1['chol'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shapiro Wilk Test for normality"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import shapiro\nfrom scipy.stats import anderson\nimport scipy.stats as stats\nshapiro(df1['chol'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the p value>0.05(significance level),we fail to reject the null hypothesis and conclude that the distribution is normal."},{"metadata":{},"cell_type":"markdown","source":"Anderson-Darling Test for Normality"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = anderson(df['chol'])\nprint('Statistic: %.3f' % result.statistic)\np = 0\nfor i in range(len(result.critical_values)):\n    sl, cv = result.significance_level[i], result.critical_values[i]\n    if result.statistic < result.critical_values[i]:\n        print('%.3f: %.3f, data looks normal (fail to reject H0)' % (sl, cv))\n    else:\n        print('%.3f: %.3f, data does not look normal (reject H0)' % (sl, cv))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So,our data is normal"},{"metadata":{},"cell_type":"markdown","source":"**OLD PEAK**"},{"metadata":{},"cell_type":"markdown","source":"Distplot and Q-Q plot"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = ff.create_distplot([df.oldpeak],['oldpeak'],bin_size=5)\niplot(fig, filename='Basic Distplot')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(df['oldpeak'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shapiro test for normality"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import shapiro\nimport scipy.stats as stats\nshapiro(df['oldpeak'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the p value<0.05(significance level),the null hypothesis is rejected and we conclude that the distribution is non normal."},{"metadata":{},"cell_type":"markdown","source":"* Out of the 5 continuous features,only **chol**(cholestoral in mg/dl fetched via BMI sensor) has an overall normal distribution.Rest of them show deviations from normality in their distributions as we saw above.So,we will be performing the parametric statistical tests on the chol feature only.\n* For the non normal features, we can perform some non parametric statistical test that we will see further."},{"metadata":{},"cell_type":"markdown","source":"# **Confidence Intervals**"},{"metadata":{},"cell_type":"markdown","source":"1.**What proportion of the population has a higher chance of having a heart attack?**\n\nThe answer to this question about the entire population has to be given from our data that is a random sample of our population.\n* **OUR TASK**:Obtain a 95% confidence interval for the population proportion of people that have higher chances of heart attack.\n* What we mean by 95% confidence interval is that “we are confident that in 95% of the samplings, the samples will have the **proportion of people having higher chances of heart attack** that can create the interval which covers the **population proportion of people that have higher chances of heart attack**”"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df1\ndf.output.replace({0:'Less chance',1:'More chance'},inplace=True)\n\nprint(df.output.value_counts())\nn = df.shape[0]\nMore_chance = df.output.value_counts().loc['More chance']\n\nprint(\"\\nTotal Observation ==>\",n,\"\\t\",\"Number of people in our sample data having more chances of heart attack==> \",More_chance,\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nprint(\"\\n95% Confidence interval with statsmodels library ==>\",sm.stats.proportion_confint(More_chance, n),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation of the result**:\n* With 95% confidence, the population proportion of people having more chances of heart attack is estimated to be between 48.70% - 60.01%.\n"},{"metadata":{},"cell_type":"markdown","source":"**2.What is the average cholesterol level for people with more chance of heart attack?**\n*  This question has to be answered for the population,so we need to obtain a confidence interval as in the previous question.What is different is the population metric,it was proportion in the previous question and it is mean in this question.The population is also different as now it just contains the people with more chance of heart attack.\n* The population:people having more chance of heart attack\n* The population metric:average cholesterol level of people having more chance of heart attack\n\n* Our task:To obtain a 95% confidence interval around the **sample average cholesterol level** that will contain the **population average cholesterol level** in 95% of the samplings."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_more_chance=df[df['output']=='More chance']\nprint(\"\\n95% C.I. with statsmodels library ==>\",sm.stats.DescrStatsW(df_more_chance['chol']).zconfint_mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation of the result**:\n* With 95% confidence, the population average cholestrol level of people having more chances of heart attack is estimated to be between 231.46 and 244.99."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(dpi=120,figsize=(5,3))\nsns.distplot(df_more_chance['chol'],color='green')\nplt.axvline(x=231.46447712295694,color = 'black',ls=':')\nplt.axvline(x=244.99231300049988,color = 'black',ls=':')\nplt.axvline(x=df_more_chance['chol'].mean(),color='red',ls='--')\nplt.xticks([231.46447712295694,244.99231300049988],['lcb','ucb'],rotation=90)\nplt.xlabel('Cholestrol level for people with more chance of Heart attack',fontdict={'fontsize':8})\nplt.ylabel('Count/Distribution',fontdict={'fontsize':8})\nplt.title('Cholestrol level distribution for people with more chance of heart attack',fontdict={'fontsize':8}) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here \n* LCB =Lower confidence Bound\n* UCB =Upper Confidence Bound\n* and, the red line denotes the sample average or the **Best Point Estimate**"},{"metadata":{},"cell_type":"markdown","source":"**3.What is the average cholestrol level for people with less chance of heart attack?**\n* The population:people having less chance of heart attack\n* The population metric:average cholestrol level of people having less chance of heart attack\n* Our task:To obtain a 95% confidence interval around the **sample average cholestrol level** that will contain the **population average cholestrol level** in 95% of the samplings.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_less_chance=df[df['output']=='Less chance']\nprint(\"\\n95% C.I. with statsmodels library ==>\",sm.stats.DescrStatsW(df_less_chance['chol']).zconfint_mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation of the result**:\n* With 95% confidence, the population average cholestrol level of people having less chances of heart attack is estimated to be between 241.05 and 256.50"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(dpi=120,figsize=(5,3))\nsns.distplot(df_less_chance['chol'],color='green')\nplt.axvline(x=241.05598752555554,color = 'black',ls=':')\nplt.axvline(x=256.5028360038562,color = 'black',ls=':')\nplt.axvline(x=df_less_chance['chol'].mean(),color='red',ls='--')\nplt.xticks([241.05598752555554,256.5028360038562],['lcb','ucb'],rotation=90)\nplt.xlabel('Cholestrol level for people with less chance of Heart attack',fontdict={'fontsize':8})\nplt.ylabel('Count/Distribution',fontdict={'fontsize':8})\nplt.title('Cholestrol level distribution for people with less chance of heart attack',fontdict={'fontsize':8}) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PARAMETRIC STATISTICAL TEST"},{"metadata":{},"cell_type":"markdown","source":"**4.Taking the entire population,do people with more chance and less chance of heart attack differ significantly in average cholestrol level?**\n* Population:People with more chance of heart attack+people with less chance of heart attack\n* Parameter:(μ1 − μ2 ):average cholesterol level difference\n* μ1:avg. cholesterol level of people with more chance of heart attack\n* μ2:avg. cholesterol level of people with less chance of heart attack\n\nTo answer our question,we define a null and an alternate hypothesis,then try to reject the null hypothesis through the statistical test.\n* Null:There is no difference in the average cholesterol levels of the two groups\n* Alternate:There is a significant difference in the average cholesterol levels of the two group\nSignificance Level = 5%\n\nSince the group chol feature was normally distributed as we saw earlier ,we can proceed with a parametric statistical test.\nWe will use the **Independent samples t-test** in this case.\nAgain,we need to determine which type of **Independent samples t-test** to use:\n1. Pooled variance T test:Assumes equal variance of sample groups\n2. Welch T test:Takes no assumption of equal variance of sample groups but has higher margin of error than pooled variance hence,should be preferred only when variances aren't equal."},{"metadata":{},"cell_type":"markdown","source":"**SO FIRST WE NEED TO CHECK FOR EQUALITY OF VARIANCES TO DECIDE THE TYPE OF T TEST TO USE**\n"},{"metadata":{},"cell_type":"markdown","source":"**PLOT**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,axes = plt.subplots(nrows=1,ncols=2,dpi=100,figsize = (9,5))\n\nplot0 = sns.boxplot(df_more_chance['chol'],ax=axes[0],orient='v',color = 'red')\naxes[0].set_title('Cholesterol',fontdict={'fontsize':8})\naxes[0].set_xlabel('More chance of Heart attack',fontdict={'fontsize':7})\naxes[0].set_ylabel('Five Point Summary',fontdict={'fontsize':7})\nplt.tight_layout()\n\nplot1 = sns.boxplot(df_less_chance['chol'],ax=axes[1],orient='v',color='green')\naxes[1].set_title('Cholesterol',fontdict={'fontsize':8})\naxes[1].set_xlabel('Less chance of Heart Attack',fontdict={'fontsize':7})\naxes[1].set_ylabel('Five Point Summary',fontdict={'fontsize':7})\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Variance of both groups are nearly similar or IQR is also almost same. Thus we can proceed with Pooled approach."},{"metadata":{},"cell_type":"markdown","source":"**STATISTICAL TEST**"},{"metadata":{},"cell_type":"markdown","source":"# Levene Test for Equality of Variances"},{"metadata":{},"cell_type":"markdown","source":"In Levene test,we test the null hypothesis that the population variances are equal/homogenous."},{"metadata":{"trusted":true},"cell_type":"code","source":"leveneTest = stats.levene(df_more_chance['chol'], df_less_chance['chol'])\nleveneTest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nHere,Levene test gives a p-value>0.05.Hence, we fail to reject the null hypothesis.This implies that the groups show equal variances.\n**SO WE CAN PROCEED WITH THE POOLED VARIANCE T-TEST**,that assumes the equal variances of sample groups\n"},{"metadata":{},"cell_type":"markdown","source":"# POOLED T TEST"},{"metadata":{"trusted":true},"cell_type":"code","source":"ttest = stats.ttest_ind(df_more_chance['chol'], df_less_chance['chol'], equal_var=True)\nttest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here,T test gives a p-value<0.05(significance level)implying strong evidence against the null hypothesis.Hence, we reject the null hypothesis.\n* We infer that there is a significant difference in the average cholestrol levels of people with more and less chance of heart attack."},{"metadata":{},"cell_type":"markdown","source":"To know which group has a higher average cholestrol level,we can obtain a 95% confidence interval around the sample difference in average cholestrol levels(x1-x2) ,such that the confidence interval would contain (μ1 − μ2 ),ie,the population metric in 95% of the samples."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class diffMean:\n    import numpy as np\n    def __init__(self,x1,x2,std1,std2,n1,n2,t):\n        '''t multiplier comes from t distribution with appropriate degree of freedom'''        \n        self.best_estimate1 = x1\n        self.best_estimate2 = x2\n        self.std1 = std1\n        self.std2 = std2\n        self.n1 = n1\n        self.n2 = n2\n        self.t = t\n        self.pooled_estimated_se = np.sqrt((np.sqrt(((self.n1-1)*(self.std1**2) + (self.n2-1)*(self.std2**2)) / ((self.n1+self.n2)-2))) * (np.sqrt((1/self.n1)+(1/self.n2))))\n        self.unpooled_estimated_se = np.sqrt(((self.std1**2)/self.n1) + ((self.std2**2)/self.n2))\n        \n    def pooledMoe(self):\n        return (self.t)*(self.pooled_estimated_se)\n    \n    def pooledMean(self):\n        lcb = (self.best_estimate1 - self.best_estimate2) - self.pooledMoe()\n        ucb = (self.best_estimate1 - self.best_estimate2) + self.pooledMoe()\n        return (lcb,ucb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = df_more_chance.chol.mean()\nx2 = df_less_chance.chol.mean()\nstd1 = df_more_chance.chol.std()\nstd2 = df_less_chance.chol.std()\nn1 = df_more_chance.shape[0]\nn2 = df_less_chance.shape[0]\nmean_diff_chol = diffMean(x1,x2,std1,std2,n1,n2,1.98)\nprint(\"\\n95% Confidence Interval for (μ1 − μ2 ): Average cholestrol level difference ==> \",mean_diff_chol.pooledMean(),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we get a negative LOWER CONFIDENCE and UPPER CONFIDENCE bound,implying μ1< μ2,i.e.,avg. cholestrol level of people with more chance of heart attack is less than avg. cholestrol level of people with less chance of heart attack."},{"metadata":{},"cell_type":"markdown","source":"# NON-PARAMETRIC STATISTICAL TEST"},{"metadata":{},"cell_type":"markdown","source":"5.**Taking the entire population,do people with more chance and less chance of heart attack differ significantly in average age?**\n* Population:People with more chance of heart attack+people with less chance of heart attack\n* Parameter:(μ1 − μ2 ):average age difference\n* μ1:avg. age of people with more chance of heart attack\n* μ2:avg. age of people with less chance of heart attack\n\nTo answer our question,we define a null and an alternate hypothesis,then try to reject the null hypothesis through the statistical test.\n* Null:There is no difference in the average age of the two groups\n* Alternate:There is a significant difference in the average age of the two group\n* Significance Level = 5%\n* The type of statistical test we use depends on the normality of the continuous feature being discussed,here Age. Since the Age feature was not normally distributed as we saw earlier ,we cannot proceed with a parametric statistical test.We will use a non-parametric test:**The Wilcoxon rank-sum test (also known as the Mann-Whitney U test)**.It is considered as the non-parametric alternative to the 2 sample t test ,the parametric test used to compare population means .\n"},{"metadata":{},"cell_type":"markdown","source":"# Mann-Whitney U test"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.mannwhitneyu(df_more_chance['age'], df_less_chance['age'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here,Mann-Whitney U test gives a p-value<0.05(significance level)implying strong evidence against the null hypothesis.Hence, we reject the null hypothesis.\n* We infer that there is a significant difference in the average age of people with more and less chance of heart attack."},{"metadata":{},"cell_type":"markdown","source":"Thanks for reading this far!Do consider upvoting my notebook if you found it useful,this being my first on Inferential statistics."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}