{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **The Challenge in Python**","metadata":{}},{"cell_type":"markdown","source":"# Background\n\nThe [RMS Titanic](https://www.britannica.com/topic/Titanic) was a luxury streamship that sank on the 15th of April 1912, off the coast of Newfoundland in the North Atlanic. After a collision with an iceberg while en route to New York City from Southampton, England. There were a recorded 2,240 passengers and crew on board for the voyage and a total of 1504 lost their lives.  \n  \nThis project was initially written as a submission for the \"[Titanic: Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)\" Competition. This challenge called for participants to predict whether a passenger on the titanic would survive based on passenger data from the event. The Titanic dataset provided a diverse amount of information about passengers such as socio-economic status, gender, age, survival and more.  \n\n  This project will display a full walkthrough of the procress of creating a machine learning model, data exploration, data cleaning and analysis through various classification methods.\n  \n  **Classification methods used**\n* Logistics Regression\n* Random Forest\n* Decision Tree\n* K Nearest Neighbor","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\n\n#packages for Algorithms\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.011933Z","iopub.execute_input":"2022-04-27T20:52:53.012254Z","iopub.status.idle":"2022-04-27T20:52:53.021946Z","shell.execute_reply.started":"2022-04-27T20:52:53.012222Z","shell.execute_reply":"2022-04-27T20:52:53.021108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Data \n  \n  The data referenced below and used throughout this project is sources directly from [\"*Titanic: Machine Learning from Disaster*\"](https://www.kaggle.com/competitions/titanic/data)","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/titanic/train.csv')\ntest_df = pd.read_csv('../input/titanic/test.csv')\ncombine = [train_df, test_df]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.047376Z","iopub.execute_input":"2022-04-27T20:52:53.047882Z","iopub.status.idle":"2022-04-27T20:52:53.06646Z","shell.execute_reply.started":"2022-04-27T20:52:53.047831Z","shell.execute_reply":"2022-04-27T20:52:53.065678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration \n  \nI started the data exploration process by trying to answer the following questions to become more familiar with the data types and quantity of data.\n1. Which features are listed in the dataset?\n2. Which features are categorical or numerical?\n3. Which features include mixed data types?\n4. Which features may contain errors, typos or missing data?\n5. Which features could contribute to a high survival rate?","metadata":{}},{"cell_type":"markdown","source":"### The Features  \n  \n  1. **Which features are listed in the data set?**  \n    \n    PassengerID, Survived, Pclass, Name, Sex, Age, Sibsp, Parch, Ticket, Fare, Cabin and Embarked. This was discovered through the process below.","metadata":{}},{"cell_type":"code","source":"print(train_df.columns.values)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.11714Z","iopub.execute_input":"2022-04-27T20:52:53.117447Z","iopub.status.idle":"2022-04-27T20:52:53.12194Z","shell.execute_reply.started":"2022-04-27T20:52:53.117415Z","shell.execute_reply":"2022-04-27T20:52:53.121326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. **Which features are categorical or numerical?**  \n  \n  Previewing the data found a few different data types in each feature. The data types included are defined as follows. [Catergorical data](http://www.stat.yale.edu/Courses/1997-98/101/catdat.htm) is defined as a variable that can take one of a limited, usually fixed, number of possible values. [Ordinal data](https://www.scribbr.com/statistics/ordinal-data/) is a type of categorical data but it refers to a type of data that can be ranked in a natural order . [Continuous data](https://www.isixsigma.com/dictionary/continuous-data/) is a type of numerical data that be measured on an infinate scale. [Discrete data](https://www.thedrum.com/profile/whatagraph/news/discrete-vs-continuous-data-whats-the-difference) is a data type that involves integers and a limited number of values possible.  \n    \n    * Categorical: Survived, Sex and Embarked\n    * Ordinal: Pclass\n    *Continous: Age, Fare\n    *Discrete: SibSp, Parch","metadata":{}},{"cell_type":"code","source":"#Previewing the data to determine data types and column headers.\n#The head command is used to output the first part of the file.\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.178792Z","iopub.execute_input":"2022-04-27T20:52:53.179536Z","iopub.status.idle":"2022-04-27T20:52:53.195261Z","shell.execute_reply.started":"2022-04-27T20:52:53.179493Z","shell.execute_reply":"2022-04-27T20:52:53.194354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. **Which features include mixed data types?**  \n  \n  Ticket and Cabin have mixed data types  \n    \n4. **Which features may contain errors, typos or missing data?**  \n  \n  This will be determined throughout the data cleaning and exploration process as it is more difficult to determine during prelimiary looks. ","metadata":{}},{"cell_type":"code","source":"#Previewing data continued\n#The tail command will output of last part of the file.\ntrain_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.242405Z","iopub.execute_input":"2022-04-27T20:52:53.243227Z","iopub.status.idle":"2022-04-27T20:52:53.259734Z","shell.execute_reply.started":"2022-04-27T20:52:53.243185Z","shell.execute_reply":"2022-04-27T20:52:53.259059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#display nulls in data within range\ntrain_df.info()\nprint('_'*10)\ntest_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.32502Z","iopub.execute_input":"2022-04-27T20:52:53.325832Z","iopub.status.idle":"2022-04-27T20:52:53.3467Z","shell.execute_reply.started":"2022-04-27T20:52:53.32579Z","shell.execute_reply":"2022-04-27T20:52:53.345825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# determine the number of null or missing values in each column for train set\ntrain_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.382532Z","iopub.execute_input":"2022-04-27T20:52:53.382813Z","iopub.status.idle":"2022-04-27T20:52:53.392151Z","shell.execute_reply.started":"2022-04-27T20:52:53.382784Z","shell.execute_reply":"2022-04-27T20:52:53.391249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#determine the number of null or missing value in each column for test set\ntest_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.446765Z","iopub.execute_input":"2022-04-27T20:52:53.447681Z","iopub.status.idle":"2022-04-27T20:52:53.457348Z","shell.execute_reply.started":"2022-04-27T20:52:53.447609Z","shell.execute_reply":"2022-04-27T20:52:53.456706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. **Which features could contribute to a high survival rate?**  \n\n  Based on observations and assumptions of preliminary data exploration the features I will focus on correlationg are Pclass(socio-econimic status), Sex and Age.  \n    Displayed below are results of the Pclass and Sex analysis. The survival rate based on age will be determined after the data cleaning process as there are missing features within the data.\n* **Pclass** it was observed that there is a signficant correlation amoung 1st class passengers/pclass 1. This correltation decreases with the Pclass, meaning those on the second and 3rd class decks had a poor survival rate.\n* **Sex** it was observed that there is a significant correlation between Sex and Survival as the Sex=Female had about a 74% survival rate. Compared to Sex=Male with a survival rate of about 19%","metadata":{}},{"cell_type":"code","source":"#survival rate of pclass\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.505799Z","iopub.execute_input":"2022-04-27T20:52:53.506244Z","iopub.status.idle":"2022-04-27T20:52:53.521373Z","shell.execute_reply.started":"2022-04-27T20:52:53.506212Z","shell.execute_reply":"2022-04-27T20:52:53.520672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visual representation of survival rate per Pclass\nsns.barplot(x='Pclass',y='Survived',data=train_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.555918Z","iopub.execute_input":"2022-04-27T20:52:53.556337Z","iopub.status.idle":"2022-04-27T20:52:53.821487Z","shell.execute_reply.started":"2022-04-27T20:52:53.556307Z","shell.execute_reply":"2022-04-27T20:52:53.820628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#survival rate based on sex 1=Female, 0=Male\ntrain_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.825358Z","iopub.execute_input":"2022-04-27T20:52:53.825671Z","iopub.status.idle":"2022-04-27T20:52:53.84327Z","shell.execute_reply.started":"2022-04-27T20:52:53.825626Z","shell.execute_reply":"2022-04-27T20:52:53.842342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visual representation of survival rate\nsns.barplot(x='Sex',y='Survived',data=train_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:53.844774Z","iopub.execute_input":"2022-04-27T20:52:53.845164Z","iopub.status.idle":"2022-04-27T20:52:54.107779Z","shell.execute_reply.started":"2022-04-27T20:52:53.845119Z","shell.execute_reply":"2022-04-27T20:52:54.107175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning Data\nNow that I have an idea of what types of data are in the set and have an idea of what data is missing the process of cleaning or wrangling data begins. The focus of this process is to transform and unify the data for easy access and analysis. I will do this by dropping and adding features, converting data types and completing numerical continuous features. \n","metadata":{}},{"cell_type":"markdown","source":"## Unifying Categorical Features\nIn order to unify certain aspects of the data I converted features that contain strings to numerical values. Numerical values are favored by most models and will create consistancy through the features.  \n  \n  The feature Sex will be converted to a discrete data type where female = 1 and male = 0.","metadata":{}},{"cell_type":"code","source":"for dataset in combine:\n        dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n        \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:54.109405Z","iopub.execute_input":"2022-04-27T20:52:54.109741Z","iopub.status.idle":"2022-04-27T20:52:54.128491Z","shell.execute_reply.started":"2022-04-27T20:52:54.109713Z","shell.execute_reply":"2022-04-27T20:52:54.12772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Completing Continuous Feature\nThrough the exploration of the data and its features above it was found that 177 data points for age were missing. In order to correct this use the randomized age data will be generated using the mean age and standard deviation of the data set to account for the missing values.","metadata":{}},{"cell_type":"code","source":"#compute mean and standard dev of Age\nage_mean = train_df['Age'].mean()\nage_std = train_df['Age'].std()\n\n#number of NaN values (non number values)\nnum_na = train_df['Age'].isna().sum()\n\n#generate random ages from mean and standard dev\nrandom_vals = age_mean + age_std * np.random.randn(num_na)\n\n#replace missing values with random_vals\ntrain_df.loc[train_df['Age'].isna(), 'Age'] = random_vals\n\n# convert to whole numbers\ntrain_df['Age'] = train_df['Age'].astype(np.int64)\n\n#view data to check work\ntrain_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:54.129583Z","iopub.execute_input":"2022-04-27T20:52:54.129815Z","iopub.status.idle":"2022-04-27T20:52:54.150859Z","shell.execute_reply.started":"2022-04-27T20:52:54.129788Z","shell.execute_reply":"2022-04-27T20:52:54.150121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verify that missing values for age have been replaced.\ntrain_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:54.152186Z","iopub.execute_input":"2022-04-27T20:52:54.152398Z","iopub.status.idle":"2022-04-27T20:52:54.160829Z","shell.execute_reply.started":"2022-04-27T20:52:54.152373Z","shell.execute_reply":"2022-04-27T20:52:54.160042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compute mean and standard dev of Age\nage_mean = test_df['Age'].mean()\nage_std = test_df['Age'].std()\n\n#number of NaN values (non number values)\nnum_na = test_df['Age'].isna().sum()\n\n#generate random ages from mean and standard dev\nrandom_vals = age_mean + age_std * np.random.randn(num_na)\n\n#replace missing values with random_vals\ntest_df.loc[test_df['Age'].isna(), 'Age'] = random_vals\n\n# convert to whole numbers\ntest_df['Age'] = test_df['Age'].astype(np.int64)\n\n#view data to check work\ntrain_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:54.162335Z","iopub.execute_input":"2022-04-27T20:52:54.162796Z","iopub.status.idle":"2022-04-27T20:52:54.186624Z","shell.execute_reply.started":"2022-04-27T20:52:54.162754Z","shell.execute_reply":"2022-04-27T20:52:54.185998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row= 'Pclass', col= 'Sex', size = 2.2, aspect = 2.6)\ngrid.map(plt.hist, 'Age', alpha= .5, bins=10, color= 'orange')\nplt.ylim((0,80))\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:54.18757Z","iopub.execute_input":"2022-04-27T20:52:54.188413Z","iopub.status.idle":"2022-04-27T20:52:55.532404Z","shell.execute_reply.started":"2022-04-27T20:52:54.188367Z","shell.execute_reply":"2022-04-27T20:52:55.531529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()\nprint('_'*10)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-27T20:52:55.533475Z","iopub.execute_input":"2022-04-27T20:52:55.533684Z","iopub.status.idle":"2022-04-27T20:52:55.547619Z","shell.execute_reply.started":"2022-04-27T20:52:55.533648Z","shell.execute_reply":"2022-04-27T20:52:55.546767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Completing a Categorical Feature\nThroughout the process of data exploration it was found that data points in the feature embarked were missing. In order to correct this I will fill those spaces with the most common occurance before converting the categorical feature to numeric.","metadata":{}},{"cell_type":"code","source":"#discover the most frequently used port\nport = train_df.Embarked.dropna().mode()[0]\nport","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:55.550824Z","iopub.execute_input":"2022-04-27T20:52:55.55106Z","iopub.status.idle":"2022-04-27T20:52:55.55793Z","shell.execute_reply.started":"2022-04-27T20:52:55.551031Z","shell.execute_reply":"2022-04-27T20:52:55.557306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], \n                                as_index=False).mean().sort_values(by='Survived', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:55.559248Z","iopub.execute_input":"2022-04-27T20:52:55.559688Z","iopub.status.idle":"2022-04-27T20:52:55.581224Z","shell.execute_reply.started":"2022-04-27T20:52:55.559637Z","shell.execute_reply":"2022-04-27T20:52:55.5804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:55.582588Z","iopub.execute_input":"2022-04-27T20:52:55.584287Z","iopub.status.idle":"2022-04-27T20:52:55.593694Z","shell.execute_reply.started":"2022-04-27T20:52:55.584241Z","shell.execute_reply":"2022-04-27T20:52:55.592732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert categorical embarked feature to numeric\n#this creates a unifying data type for analysis\n\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:55.594779Z","iopub.execute_input":"2022-04-27T20:52:55.596832Z","iopub.status.idle":"2022-04-27T20:52:55.616162Z","shell.execute_reply.started":"2022-04-27T20:52:55.596784Z","shell.execute_reply":"2022-04-27T20:52:55.615175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert Fare from float to int64\ndata = [train_df,test_df]\nfor dataset in data:\n    dataset['Fare'] = dataset['Fare'].fillna(0)\n    dataset['Fare'] = dataset['Fare'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:55.617552Z","iopub.execute_input":"2022-04-27T20:52:55.618036Z","iopub.status.idle":"2022-04-27T20:52:55.62702Z","shell.execute_reply.started":"2022-04-27T20:52:55.617991Z","shell.execute_reply":"2022-04-27T20:52:55.626051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correction by dropping features\nAnother tool used in data cleaning is dropping data or features in order to increase overall quality and efficency of the data. In this season of the data cleaning process I dropped the features PassengerID, Ticket, Cabin and Name as I do not intend to use them in this analysis. ","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop(['PassengerId'], axis=1)\ntrain_df = train_df.drop(['Ticket', 'Cabin', 'Name',], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin', 'Name',], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape,test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:55.628582Z","iopub.execute_input":"2022-04-27T20:52:55.629089Z","iopub.status.idle":"2022-04-27T20:52:55.643097Z","shell.execute_reply.started":"2022-04-27T20:52:55.629046Z","shell.execute_reply":"2022-04-27T20:52:55.642205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization\nData visualization is a useful tool for data cleaning as it can assist with detecting outliers, missing values, implicit boundaries and much more. In this case I will be using it to check the effectiveness of my data cleaning methods as well as correlating various related features. ","metadata":{}},{"cell_type":"markdown","source":"### Age vs Survival\n \nThroughout the cleaning process I noticed a few relationships between age and survival. Most passangers in this data set are in the age range 15-35 years old. The oldest surviving passanger was 80 years old and children under the age of 4 had a high survival rate.","metadata":{}},{"cell_type":"code","source":"age_hist = sns.FacetGrid(train_df, col= 'Survived')\nage_hist.map(plt.hist, 'Age', bins = 20, color = \"Orange\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:55.644333Z","iopub.execute_input":"2022-04-27T20:52:55.644818Z","iopub.status.idle":"2022-04-27T20:52:56.136322Z","shell.execute_reply.started":"2022-04-27T20:52:55.644775Z","shell.execute_reply":"2022-04-27T20:52:56.13553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Survival Classified by Age and Passenger Class\n","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass', size = 2.2, aspect = 1.6)\ngrid.map(plt.hist, 'Age', alpha = .5, bins = 20, color = \"Orange\")\ngrid.add_legend();","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:56.137759Z","iopub.execute_input":"2022-04-27T20:52:56.138057Z","iopub.status.idle":"2022-04-27T20:52:57.792464Z","shell.execute_reply.started":"2022-04-27T20:52:56.138019Z","shell.execute_reply":"2022-04-27T20:52:57.791397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Survival by Sex, Passenger Class and Embarking Port\n\nNext I explored the correlation between sex,passenger class, embarking port and survival.  \n  I found that Female passengers had a higher survival rate across all aspects. However, males that embarked at port C were more likely to survive then males that embarked at ports S and Q.\n  ","metadata":{}},{"cell_type":"code","source":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:57.794194Z","iopub.execute_input":"2022-04-27T20:52:57.794589Z","iopub.status.idle":"2022-04-27T20:52:59.156571Z","shell.execute_reply.started":"2022-04-27T20:52:57.794542Z","shell.execute_reply":"2022-04-27T20:52:59.155734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicitive Modeling \n\n[Predicitive modeling](https://www.gartner.com/en/information-technology/glossary/predictive-modeling) is a commonly used statistical techinque to predict future behavior by analyzing historical and current data and generation a model to help predict outcomes.  \n  The challenge asks to identify relationships between surviral and other variables so I chose a selection of classication and regression models to best answer this question.\n* Logistic Regression\n* Random Forest\n* k-Nearest Neighbors\n* Decision Tree","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:59.157785Z","iopub.execute_input":"2022-04-27T20:52:59.158014Z","iopub.status.idle":"2022-04-27T20:52:59.169489Z","shell.execute_reply.started":"2022-04-27T20:52:59.157986Z","shell.execute_reply":"2022-04-27T20:52:59.168445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:59.170508Z","iopub.execute_input":"2022-04-27T20:52:59.170733Z","iopub.status.idle":"2022-04-27T20:52:59.182324Z","shell.execute_reply.started":"2022-04-27T20:52:59.170705Z","shell.execute_reply":"2022-04-27T20:52:59.18153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:59.183471Z","iopub.execute_input":"2022-04-27T20:52:59.18371Z","iopub.status.idle":"2022-04-27T20:52:59.195705Z","shell.execute_reply.started":"2022-04-27T20:52:59.183677Z","shell.execute_reply":"2022-04-27T20:52:59.194732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression\nLogistic regression is a statisical model used to handle classification problems. [Logistic regression](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc) is a process of modeling the probablity of a discrete outcome given an input variable. In other words it measures the realatoinship between the categorical depedent feature and one of more independent features.","metadata":{}},{"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:59.196786Z","iopub.execute_input":"2022-04-27T20:52:59.197603Z","iopub.status.idle":"2022-04-27T20:52:59.248003Z","shell.execute_reply.started":"2022-04-27T20:52:59.197569Z","shell.execute_reply":"2022-04-27T20:52:59.247429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree\n[Decision Trees](https://scikit-learn.org/stable/modules/tree.html) are a non-parametric surpervised learning method used for classifications and regression.The goal is to use a tree like model to evaluate decisions and their possible outcomes including things such as probablity, cost, and other relavent features. Decision tree models ","metadata":{}},{"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:59.24914Z","iopub.execute_input":"2022-04-27T20:52:59.249526Z","iopub.status.idle":"2022-04-27T20:52:59.264241Z","shell.execute_reply.started":"2022-04-27T20:52:59.249481Z","shell.execute_reply":"2022-04-27T20:52:59.263456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest\n","metadata":{}},{"cell_type":"markdown","source":"The [random forest](https://towardsdatascience.com/understanding-random-forest-58381e0602d2) analysis is a classification algorithm consisting of many decision trees. However is utilizes a bagging method and randomness features.","metadata":{}},{"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:59.265634Z","iopub.execute_input":"2022-04-27T20:52:59.266105Z","iopub.status.idle":"2022-04-27T20:52:59.561762Z","shell.execute_reply.started":"2022-04-27T20:52:59.266066Z","shell.execute_reply":"2022-04-27T20:52:59.560837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-Nearest Neighbor","metadata":{}},{"cell_type":"markdown","source":"The [K-nearest Neighbor algorithm](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761) is a data classification method for estimating the likelihood of the data point will beocome a member of one group or another based on what the group data points nearest to is belong to.","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:59.562976Z","iopub.execute_input":"2022-04-27T20:52:59.563218Z","iopub.status.idle":"2022-04-27T20:52:59.629448Z","shell.execute_reply.started":"2022-04-27T20:52:59.56319Z","shell.execute_reply":"2022-04-27T20:52:59.628554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation\nThe chart below shows the confidence scores from the analysis preformed above. \n","metadata":{}},{"cell_type":"code","source":"models = pd.DataFrame({\n   'Model': ['KNN', 'Logistic Regression', 'Random Forest',  'Decision Tree'],\n    'Score': [ acc_knn, acc_log, acc_random_forest, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T20:52:59.630835Z","iopub.execute_input":"2022-04-27T20:52:59.63108Z","iopub.status.idle":"2022-04-27T20:52:59.646042Z","shell.execute_reply.started":"2022-04-27T20:52:59.63105Z","shell.execute_reply":"2022-04-27T20:52:59.64517Z"},"trusted":true},"execution_count":null,"outputs":[]}]}