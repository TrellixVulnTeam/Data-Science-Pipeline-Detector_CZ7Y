{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Necessary Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy.stats import chi2_contingency\nimport category_encoders as ce\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Train and Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/titanic/train.csv')\ntest=pd.read_csv('../input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing number of columns and rows in the dataset\nprint(\"There are {} number of rows and {} number of columns in training data\".format(train.shape[0],train.shape[1]))\nprint(\"There are {} number of rows and {} number of columns in testing data\".format(test.shape[0],test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for data imbalanceness if any\nsns.countplot(y=train[\"Survived\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From the above statistics, it appears that the dataset is partially imbalanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the type of columns in dataset\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describing columns statistics\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"# Handling Missing Values\nWe will first check which all columns have the missing values with the help of Visualization."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,9))\nplt.subplot(1,2,1)\nplt.title(\"Training Data\")\nsns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap=\"viridis\")\n\nplt.subplot(1,2,2)\nplt.title(\"Testing Data\")\nsns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap=\"viridis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above visualization, it appears that the Age,Cabin and Embarked columns contain null values in training data while Age,Cabin and Fare columns contain null values in testing data. The Cabin column contains maximum null values in both the dataset.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Null features\nnull_features = [feature for feature in train.columns if train[feature].isnull().sum()>=1]\nfor features in null_features:\n    print(features,np.round(train[features].isnull().mean(),4),'%missing values')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Numerical Variables\nnumerical_features = [feature for feature in train.columns if train[feature].dtypes!='O']\nprint(\"The number of numerical features in the dataset are {}.\".format(len(numerical_features)))\ntrain[numerical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Discrete variables in data\ndiscrete_features = [feature for feature in numerical_features if len(train[feature].unique())<25 and feature not in ['PassengerId','Survived']]\nprint(\"The number of discrete variables is: {}\".format(len(discrete_features)))\ntrain[discrete_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Understanding the relationship between discrete and target variables\nfor feature in discrete_features:\n    data = train.copy()\n    data.groupby(feature)['Survived'].mean().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('Survived')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Continuous Distribution \ncontinuous_features = [feature for feature in numerical_features if feature not in discrete_features and feature not in ['PassengerId','Survived']]\nprint(\"The number of continuous features are : {}\".format(len(continuous_features)))\ntrain[continuous_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relationship between continous and target variable\nfor feature in continuous_features:\n    data = train.copy()\n    data[feature].hist(bins=50)\n    plt.xlabel(feature)\n    plt.ylabel('Survived')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detecting Outliers\n\nfor feature in numerical_features:\n    data = train.copy()\n    data.boxplot(column=feature)\n    plt.xlabel(feature)\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in numerical_features:\n    data = train.copy()\n    sns.scatterplot(x=data[feature],y=data['Survived'])\n    plt.xlabel(feature)\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From box plot and scatterplot, it appears that some of the columns contains outliers but we will leave them as it is since they are acceptable**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing the correlation of variables\nplt.figure(figsize=(20,12))\nsns.heatmap(train[numerical_features].corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From above correlation graph, it seems like there is no correlation amongst and with the target variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical Features\ncategorical_feature = [feature for feature in train.columns if feature not in numerical_features]\nprint(\"There are {} number of categorical features\".format(len(categorical_feature)))\ntrain[categorical_feature].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Determining the cadinality of categorical data\nfor feature in categorical_feature:\n    print(\"The feature is {} and its cardinality is {}\".format(feature,len(train[feature].unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It appears like columns Name,Ticket and Cabin has higher cardinality**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing relationsip between categorical and target values\nfor feature in ['Sex','Embarked']:\n    data = train.copy()\n    data.groupby(feature)['Survived'].mean().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('Survived')\n    plt.title(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations from above Graphs:**\n**1. Sex: It appears that on an average number of females survived > no. of males.**\n**2. Embarked: It appears the number of person belonging to category 'C' survived the most while in 'S' survived the least.** "},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy = train.copy()\nplt.figure(figsize=(12,7))\nsns.boxplot(x=dummy[\"Pclass\"],y=dummy[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It appears that the median age of people in class 1 is around 37. While it is 29 for class 2 and it is 22 for class 3. We can consider this info. while imputing the missing values in Age Feature**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspecting Name feature\ntrain[\"Name\"].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndummy_train = train.copy()\ndummy_test = test.copy()\ndummy_train[\"Title\"] = dummy_train.Name.apply(lambda x:re.search(' ([A-Z][a-z]+)\\. ',x).group(1))\ndummy_test[\"Title\"] = dummy_test.Name.apply(lambda x:re.search(' ([A-Z][a-z]+)\\. ',x).group(1))\nplt.figure(figsize=(10,9))\nplt.subplot(1,2,1)\nsns.countplot(x=\"Title\",data = dummy_train)\nplt.xticks(rotation=45) \n\nplt.subplot(1,2,2)\nsns.countplot(x=\"Title\",data = dummy_test)\nplt.xticks(rotation=45)                                              ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_train['Title'] = dummy_train['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\ndummy_train['Title'] = dummy_train['Title'].replace(['Don', 'Dona', 'Rev', 'Dr',\n                                            'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Special')\n\ndummy_test['Title'] = dummy_test['Title'].replace({'Ms':'Miss'})\ndummy_test['Title'] = dummy_test['Title'].replace(['Dona', 'Rev', 'Dr',\n                                            'Col'],'Special')\nplt.subplot(1,2,1)\nsns.countplot(x='Title', data=dummy_train);\nplt.xticks(rotation=45);\n\nplt.subplot(1,2,2)\nsns.countplot(x='Title', data=dummy_test);\nplt.xticks(rotation=45);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Listing Null values in Numerical data\nnumerical_with_nan = [feature for feature in train.columns if train[feature].isnull().sum()>=1 and train[feature].dtypes!='O' ]\nfor feature in numerical_with_nan:\n    print(feature,np.round(train[feature].isnull().mean(),4),'%missing values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling the missing values with median\ndef impute_numerical(n_feature):\n    \n        median_value_train = train[n_feature].median()\n        median_value_test = test[n_feature].median()\n        train[feature+'_nan'] = np.where(train[n_feature].isnull(),1,0)\n        train[feature] = train[n_feature].fillna(median_value_train)\n        test[feature+'_nan'] = np.where(test[n_feature].isnull(),1,0)\n        test[feature] = test[n_feature].fillna(median_value_test)\n        return train,test\n    \ntrain,test = impute_numerical(numerical_with_nan)\ntrain[numerical_with_nan].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Listing Null values in Categorical data\ncategorical_with_nan = [feature for feature in train.columns if train[feature].isnull().sum()>=1 and train[feature].dtypes=='O' ]\nfor feature in categorical_with_nan:\n    print(feature,np.round(train[feature].isnull().mean(),4),'%missing values')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will only handle missing values in Embarked column not the Cabin columns since, it contains lots of missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling the embarked column with mode count.\ndef replace_cat_feature(train,test,feature):\n    train_data = train.copy()\n    test_data = test.copy()\n    train_data[feature] = np.where(train_data[feature].isnull(),train_data[feature].mode(),train_data[feature])\n    test_data[feature] =  np.where(test_data[feature].isnull(),test_data[feature].mode(),test_data[feature])\n    return train_data,test_data\n\ntrain,test = replace_cat_feature(train,test,['Embarked'])\ntrain[categorical_with_nan].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling missing values in Fare column in test data\ntest['Fare'] = test['Fare'].fillna(test['Fare'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Performing Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering numerical variables: [Pclass\tAge\tSibSp\tParch\tFare]\n\ndef eng_age(train_data,testing_data):\n    train_data['Age_cat'] = pd.qcut(train_data.Age,  q=4, labels=False)\n    testing_data['Age_cat'] = pd.qcut(testing_data.Age, q=4, labels=False)\n    return train_data,testing_data\n\n\ndef eng_fare(train_data,testing_data):\n    train_data[\"Fare_cat\"] = pd.qcut(train_data[\"Fare\"], q=4, labels=False)\n    testing_data[\"Fare_cat\"] = pd.qcut(testing_data[\"Fare\"], q=4, labels=False)\n    return train_data,testing_data\n\ndef eng_family(train_data,testing_data):\n    train_data[\"Family_size\"] = train_data[\"Parch\"] + train_data[\"SibSp\"]\n    testing_data[\"Family_size\"] = testing_data[\"Parch\"] + testing_data[\"SibSp\"]\n    return train_data,testing_data\n\n\ndef feature_eng_numerical(train,test_data):\n    train_data = train.copy()\n    testing_data = test_data.copy()\n    \n    train_data,testing_data = eng_family(train_data,testing_data)\n    \n    train_data,testing_data = eng_age(train_data,testing_data)\n    \n    train_data,testing_data = eng_fare(train_data,testing_data)\n    \n    return train_data,testing_data\n\ntrain,test_data = feature_eng_numerical(train,test_data) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping columns which contribute less.['PassengerId','Cabin','Ticket']\n\ntrain = train.drop(columns=['PassengerId','Ticket','Cabin'],axis=1)\ntest_data = test_data.drop(columns=['PassengerId','Ticket','Cabin'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering Categorical Variable: 'Embarked'\nimport re\n\ndef eng_categorical(train,test_data):\n    train_data = train.copy()\n    testing_data = test_data.copy()\n    \n    \n    train_data['Embarked_min'] = np.where(train['Embarked']=='Q',1,0)\n    train_data['Embarked_max'] = np.where(train['Embarked']=='S',1,0)\n    testing_data['Embarked_min'] = np.where(testing_data['Embarked']=='Q',1,0)\n    testing_data['Embarked_max'] = np.where(testing_data['Embarked']=='S',1,0)\n    \n    train_data[\"Title\"] = train_data.Name.apply(lambda x:re.search(' ([A-Z][a-z]+)\\. ',x).group(1))\n    testing_data[\"Title\"] = testing_data.Name.apply(lambda x:re.search(' ([A-Z][a-z]+)\\. ',x).group(1))\n    train_data['Title'] = train_data['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\n    train_data['Title'] = train_data['Title'].replace(['Don', 'Dona', 'Rev', 'Dr',\n                                            'Major', 'Lady', 'Sir', 'Col', 'Capt', 'Countess', 'Jonkheer'],'Special')\n    testing_data['Title'] = testing_data['Title'].replace({'Ms':'Miss'})\n    testing_data['Title'] = testing_data['Title'].replace(['Dona', 'Rev', 'Dr',\n                                                'Col'],'Special')\n    return train_data,testing_data\n\ntrain,test_data = eng_categorical(train,test_data)\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns=[\"Name\",\"Age\",\"Fare\"],axis=1)\ntest_data = test_data.drop(columns=[\"Name\",\"Age\",\"Fare\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding Columns with category\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n#cols = ['Cabin']\ncols = ['Sex','Embarked','Title']\n\ndef encoding_columns(train,test_data,cols):\n    encoded_train = train.copy()\n    encoded_test =  test_data.copy()\n    for feature in cols:\n        encoded_train[feature] = le.fit_transform(train[feature])\n        encoded_test[feature] =  le.fit_transform(test_data[feature])\n    return encoded_train,encoded_test\n\n\ntrain_encoded,test_encoded = encoding_columns(train,test_data,cols)\ntrain_encoded.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spitting the independent and dependent variables\ny_train_splitted = train_encoded[[\"Survived\"]]\nx_train = train_encoded.drop(columns=[\"Survived\"],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardizing the variables\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\nX_train_norm = pd.DataFrame(sc.fit_transform(x_train))\nX_train_norm.columns = x_train.columns\n\n\nX_test_norm = pd.DataFrame(sc.fit_transform(test_encoded))\nX_test_norm.columns = test_encoded.columns\n\nX_train_norm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_norm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_norm.to_csv(\"training.csv\",index=False)\nX_test_norm.to_csv(\"testing.csv\",index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_normed = pd.read_csv(\"training.csv\")\nX_test_normed = pd.read_csv(\"testing.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will perform feature selection using SHAP Values\n# Using Extra Tree Classifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nmodel=ExtraTreesClassifier()\nmodel.fit(X_train_normed,y_train_splitted.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances=pd.Series(model.feature_importances_,index=X_train_normed.columns)\nfeat_importances.nlargest(23).plot(kind=\"barh\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n'''\nX_train_norm_select = X_train_normed\nX_train_norm = X_train_norm_select[['Sex','Fare_cat','Age_cat',\"Title\",'Pclass',\n                                    \"Family_size\",\"SibSp\",\"Parch\",\"Age_nan\",\"Embarked_max\"\n                                ]]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nX_test_normed = X_test_normed[['Sex_female','Fare','Age',\"Title_Mr\",'Pclass',\"Sex_male\",\"Ticket_Freq_Count\",\n                                    \"Has_Cabin\",\"Family_size\",\"Title_Mrs\",\"Title_Miss\",\"SibSp\",\"Parch\"\n                                ]]\n                               #'SibSp','Agenan','Embarked','Embarked_max','Parch']]\n                               #,'Parch','Mean_Fare',\n                                  # 'Age>18','Agenan','Embarked','Embarked_max','Embarked_min']]\n                                  '''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spitting the data\nfrom sklearn.model_selection import train_test_split\nX_train,x_test,Y_train,y_test = train_test_split(X_train_normed,y_train_splitted,test_size=0.1,stratify=y_train_splitted,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_valid,y_train,y_valid = train_test_split(X_train,Y_train,test_size=0.1,stratify=Y_train,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling\nNow, we will perform training of data using various Classification Models."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score,f1_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1=LogisticRegression(max_iter=500,random_state=0)\nmodel_1.fit(x_train,y_train.values.ravel())\npred = model_1.predict(x_valid)\nscore_1 = accuracy_score(y_valid,pred)\nscore_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_1 = model_1.predict(x_test)\nscore_1 = accuracy_score(y_test,predictions_1)\nscore_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predictions_1,target_names=['0','1']))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2 = KNeighborsClassifier()\nmodel_2.fit(x_train,y_train.values.ravel())\npred = model_2.predict(x_valid)\nscore_2 = accuracy_score(y_valid,pred)\nscore_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_2 = model_2.predict(x_test)\nprint(classification_report(y_test,predictions_2,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_3=SVC(random_state=0)\nmodel_3.fit(x_train,y_train.values.ravel())\npred = model_3.predict(x_valid)\nscore_3 = accuracy_score(y_valid,pred)\nscore_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_3 = model_3.predict(x_test)\nprint(classification_report(y_test,predictions_3,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive-Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_4=GaussianNB()\nmodel_4.fit(x_train,y_train.values.ravel())\npred = model_4.predict(x_valid)\nscore_4 = accuracy_score(y_valid,pred)\nscore_4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_4 = model_4.predict(x_test)\nprint(classification_report(y_test,predictions_4,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_5=DecisionTreeClassifier(random_state=0)\nmodel_5.fit(x_train,y_train.values.ravel())\npred = model_5.predict(x_valid)\nscore_5 = accuracy_score(y_valid,pred)\nscore_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_5 = model_5.predict(x_test)\nprint(classification_report(y_test,predictions_5,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest (Untuned)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_6=RandomForestClassifier(random_state=0)\nmodel_6.fit(x_train,y_train.values.ravel())\npred = model_6.predict(x_valid)\nscore_6 = accuracy_score(y_valid,pred)\nscore_6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_6 = model_6.predict(x_test)\nprint(classification_report(y_test,predictions_6,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBOOST (Untuned)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel_7 = XGBClassifier()\nmodel_7.fit(x_train,y_train.values.ravel())\npred = model_7.predict(x_valid)\nscore_7 = accuracy_score(y_valid,pred)\nscore_7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_7 = model_7.predict(x_test)\nprint(classification_report(y_test,predictions_7,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CatBoost (Untuned)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\ncat_model = CatBoostClassifier(verbose=2,iterations=500,od_type='Iter')\ncat_model.fit(x_train,y_train,eval_set=(x_valid,y_valid))\nprint(cat_model.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_8 = cat_model.predict(x_test)\nprint(classification_report(y_test,predictions_8,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyper-parameter Tuning Random Forest Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nparam_grid={'max_depth':range(3,6),'n_estimators':range(400,700,100),\"max_features\": range(3,6)}\ngrid_search = RandomizedSearchCV(RandomForestClassifier(),param_grid,verbose=1,cv=10,n_jobs=-1)\ngrid_search.fit(x_train,y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_pred = grid_search.predict(x_valid)\nscore = accuracy_score(y_valid,grid_search_pred)\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_predictions = grid_search.predict(x_test)\nprint(classification_report(y_test,grid_search_predictions,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyper-parameter Tuning SVM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid={'C': [100],\n              'gamma': [0.01,0.001,0.0001],\n              'kernel': ['rbf','poly']}\ngrid_search_1 = GridSearchCV(SVC(),param_grid,verbose=1,cv=10,n_jobs=-1)\ngrid_search_1.fit(x_train,y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_1.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_pred_1 = grid_search_1.predict(x_valid)\nscore = accuracy_score(y_valid,grid_search_pred_1)\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_predictions_1 = grid_search_1.predict(x_test)\nprint(classification_report(y_test,grid_search_predictions_1,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyper-Parameter Tuning XGBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nparam_grid_xg={\"learning_rate\" : [0.05] ,\n \"max_depth\"        : [ 1],\n \"min_child_weight\" : [ 1],\n \"gamma\"            : [ 0.0],\n \"colsample_bytree\" : [ 0.1,0.3],\n \"n_estimators\"     : [300,400]}\ngrid_search_xg = RandomizedSearchCV(XGBClassifier(),param_grid_xg,verbose=1,cv=10,n_jobs=-1)\ngrid_search_xg.fit(x_train,y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_xg.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_pred_xg = grid_search_xg.predict(x_valid)\nscore = accuracy_score(y_valid,grid_search_pred_xg)\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_predictions_xg = grid_search_xg.predict(x_test)\nprint(classification_report(y_test,grid_search_predictions_xg,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyper-tuning CatBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid_cat = {'iterations': range(10,100,40),\n                 'depth': range(1, 8),\n                 'learning_rate': [0.03,0.001,0.01,0.1,0.2,0.3],\n                 \n                 'bagging_temperature': [0.0,0.2,0.4,0.6,0.8,1.0],\n                 'border_count': range(1, 255),\n                 'l2_leaf_reg': range(2, 30),\n                 'scale_pos_weight': [0.01,0.1,0.3,0.5,0.7,0.9,1.0]}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_cat = RandomizedSearchCV(CatBoostClassifier(verbose=2,od_type='Iter'),param_grid_cat,verbose=1,cv=10,n_jobs=-1)\ngrid_search_cat.fit(x_train,y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_predictions_cat = grid_search_cat.predict(x_test)\nprint(classification_report(y_test,grid_search_predictions_cat,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using Neural Networks"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\n\nmodel_neural = Sequential()\n\nmodel_neural.add(Dense(100, activation='relu', input_shape=(12,),kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n\nmodel_neural.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))\n\nmodel_neural.add(Dense(1, activation='sigmoid'))\n\nmodel_neural.compile(loss='binary_crossentropy',\n              optimizer=Adam(lr=0.00001),\n              metrics=['accuracy'])\n                   \nmodel_neural.fit(x_train, y_train,epochs=150, batch_size=1, verbose=1,validation_data=(x_valid,y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making predictions using test data\npredict_neural = model_neural.predict_classes(x_test)\nprint(classification_report(y_test,predict_neural,target_names=['0','1']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **Final Model:** Although, most of the models implemented above output accuracy > 80% , but Neural Network is chosen as the final model since, it performed less overfitting on test data."},{"metadata":{},"cell_type":"markdown","source":"# Predictions on Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions =  pd.DataFrame(model_neural.predict_classes(X_test_normed))\nfinal_predictions.columns = [\"Survived\"]\nfinal_predictions = pd.concat([test[\"PassengerId\"],final_predictions],axis=1)\nfinal_predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}