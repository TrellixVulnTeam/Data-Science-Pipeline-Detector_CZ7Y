{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport itertools\nimport random \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nrandom.seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:25:17.085931Z","iopub.execute_input":"2021-08-16T09:25:17.086297Z","iopub.status.idle":"2021-08-16T09:25:17.091749Z","shell.execute_reply.started":"2021-08-16T09:25:17.086268Z","shell.execute_reply":"2021-08-16T09:25:17.090578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_df =  pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# Join the train and test dataframes so the data preprocessing \n# will be done simultaneously in both datasets \nfull_df = train_df.append(test_df, ignore_index=True)\nprint(f'There are {full_df.shape[0]} rows and {full_df.shape[1]} columns in the full dataframe.')","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:25:17.093097Z","iopub.execute_input":"2021-08-16T09:25:17.093379Z","iopub.status.idle":"2021-08-16T09:25:17.131085Z","shell.execute_reply.started":"2021-08-16T09:25:17.093352Z","shell.execute_reply":"2021-08-16T09:25:17.129993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_preprocessing(df):\n  \n  # Label-encode the sex of a passenger \n  df['Sex'] = df['Sex'].replace(['male'],0)\n  df['Sex'] = df['Sex'].replace(['female'],1)\n\n  # Initialize new columns \n  df['title'] = np.NaN\n  df['alone'] = np.NaN\n  df['cabin_class'] = np.NaN\n\n  # Identify if a passenger is alone in the ship \n  for i,_ in enumerate(df['alone']):\n    if df['SibSp'][i] + df['Parch'][i] == 0:\n      df['alone'][i] = 1\n    else:\n      df['alone'][i] = 0 \n\n  # Handle missing values\n  cols = ['SibSp','Parch','Fare','Age']\n  for col in cols:\n    df[col].fillna(df[col].median(), inplace = True)\n    \n  # Feature-engineer the cabin-class \n  for i,row in enumerate(df['Cabin']):\n    # Get cabin class \n    df['cabin_class'][i] =  str(row)[:1]\n\n  # Count the cabin distribution per class (if available) \n  cabin_distribution = {}\n  count = 0 \n  for row in df['cabin_class']:\n    if row != 'n':\n      count += 1 \n      if row not in cabin_distribution:\n        cabin_distribution[row] = 1 \n      else:\n        cabin_distribution[row] +=1 \n\n  # Calculate the probability of being in a sepcific cabin-class  \n  cabin_pdf = {k:v / count for k, v in cabin_distribution.items()}\n\n  # Calculate the cumulative probability of being in a specific cabin-class \n  keys, vals = cabin_pdf.keys(), cabin_pdf.values()\n  cabin_cdf = dict(zip(keys, itertools.accumulate(vals)))\n  cabin_cdf = sorted(cabin_cdf.items(), key=lambda x: x[1])    \n\n  # Randomly assign cabin-classes to passengers that are missing the cabin \n  # field, based on the probabilities calculated above \n  for i,row in enumerate(df['cabin_class']):\n    random_num = random.random()\n    if row == 'n':\n      if random_num < cabin_cdf[0][1]:\n        df['cabin_class'][i] =  cabin_cdf[0][0]\n      elif cabin_cdf[0][1] <= random_num < cabin_cdf[1][1]:\n        df['cabin_class'][i] =  cabin_cdf[1][0]\n\n      elif cabin_cdf[1][1] <= random_num < cabin_cdf[2][1]:\n        df['cabin_class'][i] =  cabin_cdf[2][0]\n      \n      elif cabin_cdf[2][1] <= random_num < cabin_cdf[3][1]:\n        df['cabin_class'][i] =  cabin_cdf[2][0]\n\n      elif cabin_cdf[3][1] <= random_num < cabin_cdf[4][1]:\n        df['cabin_class'][i] =  cabin_cdf[3][0]\n\n      elif cabin_cdf[3][1] <= random_num < cabin_cdf[4][1]:\n        df['cabin_class'][i] =  cabin_cdf[4][0]\n\n      elif cabin_cdf[4][1] <= random_num < cabin_cdf[5][1]:\n        df['cabin_class'][i] =  cabin_cdf[4][0]\n      \n      elif cabin_cdf[5][1] <= random_num < cabin_cdf[6][1]:\n        df['cabin_class'][i] =  cabin_cdf[5][0]\n\n      elif cabin_cdf[6][1] <= random_num < cabin_cdf[7][1]:\n        df['cabin_class'][i] =  cabin_cdf[6][0]\n      else:\n        df['cabin_class'][i] = cabin_cdf[7][0]\n\n  # Perform feature engineering to obtain additional title-info \n  for i,row in enumerate(df['Name']):\n    # Get person's title \n    df['title'][i] = row.split(',')[1].split('.')[0]\n\n  # Embarked one-hot encoding \n  embarked_dummies = pd.get_dummies(df.Embarked, prefix='Embarked')\n  df = pd.concat([df, embarked_dummies], axis=1)\n\n  # Person's title one-hot encoding \n  title_dummies = pd.get_dummies(df.title, prefix='title')\n  df = pd.concat([df, title_dummies], axis=1)\n\n  # Cabin class one-hot encoding \n  cabin_class_dummies = pd.get_dummies(df.cabin_class, prefix = 'cabin_class')\n  df = pd.concat([df, cabin_class_dummies], axis = 1)\n\n  #Remove unecessary columns \n  del df['Name']\n  del df['PassengerId']\n  del df['title']\n  del df['Embarked']\n  del df['Cabin']\n  del df['Ticket']\n  del df['cabin_class']\n\n  return df ","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:25:17.132821Z","iopub.execute_input":"2021-08-16T09:25:17.133121Z","iopub.status.idle":"2021-08-16T09:25:17.158869Z","shell.execute_reply.started":"2021-08-16T09:25:17.133093Z","shell.execute_reply":"2021-08-16T09:25:17.157781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the data and create the train / test sets \nfull_df = data_preprocessing(full_df)\nX_train = full_df[:891]\ny_train = full_df['Survived'][:891]\nX_test = full_df[891:]\ndel X_train['Survived']\ndel X_test['Survived']\n\n\nprint(f'There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the training data.\\n')\nprint(f'There are {X_test.shape[0]} rows and {X_test.shape[1]} columns in the test data.')","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:25:17.160067Z","iopub.execute_input":"2021-08-16T09:25:17.160341Z","iopub.status.idle":"2021-08-16T09:25:19.683564Z","shell.execute_reply.started":"2021-08-16T09:25:17.160314Z","shell.execute_reply":"2021-08-16T09:25:19.682591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model \nfrom sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression(max_iter=1000,C=0.175,random_state=42)\nLR.fit(X_train, y_train)\ntraining_accuracy = LR.score(X_train, y_train)\npredictions = LR.predict(X_test)\nprint(\"Training accuracy: %.2f%%\" % (training_accuracy * 100.0))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:25:19.684706Z","iopub.execute_input":"2021-08-16T09:25:19.684991Z","iopub.status.idle":"2021-08-16T09:25:19.920458Z","shell.execute_reply.started":"2021-08-16T09:25:19.684964Z","shell.execute_reply":"2021-08-16T09:25:19.919447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [int(x) for x in predictions]\nsubmission = pd.DataFrame({'PassengerId':test_df['PassengerId'],'Survived':predictions})\nsubmission.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T09:25:19.922053Z","iopub.execute_input":"2021-08-16T09:25:19.922754Z","iopub.status.idle":"2021-08-16T09:25:19.933671Z","shell.execute_reply.started":"2021-08-16T09:25:19.922711Z","shell.execute_reply":"2021-08-16T09:25:19.932485Z"},"trusted":true},"execution_count":null,"outputs":[]}]}