{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport itertools\nimport random \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nrandom.seed(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-11T12:09:29.158177Z","iopub.execute_input":"2021-09-11T12:09:29.158559Z","iopub.status.idle":"2021-09-11T12:09:29.163462Z","shell.execute_reply.started":"2021-09-11T12:09:29.158528Z","shell.execute_reply":"2021-09-11T12:09:29.162682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_df =  pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# Join the train and test dataframes so the data preprocessing \n# will be done simultaneously in both datasets \nfull_df = train_df.append(test_df, ignore_index=True)\nprint(f'There are {full_df.shape[0]} rows and {full_df.shape[1]} columns in the full dataframe.')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:09:29.164803Z","iopub.execute_input":"2021-09-11T12:09:29.165308Z","iopub.status.idle":"2021-09-11T12:09:29.196287Z","shell.execute_reply.started":"2021-09-11T12:09:29.165275Z","shell.execute_reply":"2021-09-11T12:09:29.195115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_preprocessing(df):\n  \n  # Label-encode the sex of a passenger \n  df['Sex'] = df['Sex'].replace(['male'],0)\n  df['Sex'] = df['Sex'].replace(['female'],1)\n\n  # Initialize new columns \n  df['title'] = np.NaN\n  df['alone'] = np.NaN\n  df['cabin_class'] = np.NaN\n\n  # Identify if a passenger is alone in the ship \n  for i,_ in enumerate(df['alone']):\n    if df['SibSp'][i] + df['Parch'][i] == 0:\n      df['alone'][i] = 1\n    else:\n      df['alone'][i] = 0 \n\n  # Handle missing values\n  cols = ['SibSp','Parch','Fare','Age']\n  for col in cols:\n    df[col].fillna(df[col].median(), inplace = True)\n    \n  # Feature-engineer the cabin-class \n  for i,row in enumerate(df['Cabin']):\n    # Get cabin class \n    df['cabin_class'][i] =  str(row)[:1]\n\n  # Count the cabin distribution per class (if available) \n  cabin_distribution = {}\n  count = 0 \n  for row in df['cabin_class']:\n    if row != 'n':\n      count += 1 \n      if row not in cabin_distribution:\n        cabin_distribution[row] = 1 \n      else:\n        cabin_distribution[row] +=1 \n\n  # Calculate the probability of being in a sepcific cabin-class  \n  cabin_pdf = {k:v / count for k, v in cabin_distribution.items()}\n\n  # Calculate the cumulative probability of being in a specific cabin-class \n  keys, vals = cabin_pdf.keys(), cabin_pdf.values()\n  cabin_cdf = dict(zip(keys, itertools.accumulate(vals)))\n  cabin_cdf = sorted(cabin_cdf.items(), key=lambda x: x[1])    \n\n  # Randomly assign cabin-classes to passengers that are missing the cabin \n  # field, based on the probabilities calculated above \n  for i,row in enumerate(df['cabin_class']):\n    random_num = random.random()\n    if row == 'n':\n      if random_num < cabin_cdf[0][1]:\n        df['cabin_class'][i] =  cabin_cdf[0][0]\n      elif cabin_cdf[0][1] <= random_num < cabin_cdf[1][1]:\n        df['cabin_class'][i] =  cabin_cdf[1][0]\n\n      elif cabin_cdf[1][1] <= random_num < cabin_cdf[2][1]:\n        df['cabin_class'][i] =  cabin_cdf[2][0]\n      \n      elif cabin_cdf[2][1] <= random_num < cabin_cdf[3][1]:\n        df['cabin_class'][i] =  cabin_cdf[2][0]\n\n      elif cabin_cdf[3][1] <= random_num < cabin_cdf[4][1]:\n        df['cabin_class'][i] =  cabin_cdf[3][0]\n\n      elif cabin_cdf[3][1] <= random_num < cabin_cdf[4][1]:\n        df['cabin_class'][i] =  cabin_cdf[4][0]\n\n      elif cabin_cdf[4][1] <= random_num < cabin_cdf[5][1]:\n        df['cabin_class'][i] =  cabin_cdf[4][0]\n      \n      elif cabin_cdf[5][1] <= random_num < cabin_cdf[6][1]:\n        df['cabin_class'][i] =  cabin_cdf[5][0]\n\n      elif cabin_cdf[6][1] <= random_num < cabin_cdf[7][1]:\n        df['cabin_class'][i] =  cabin_cdf[6][0]\n      else:\n        df['cabin_class'][i] = cabin_cdf[7][0]\n\n  # Perform feature engineering to obtain additional title-info \n  for i,row in enumerate(df['Name']):\n    # Get person's title \n    df['title'][i] = row.split(',')[1].split('.')[0]\n\n  # Embarked one-hot encoding \n  embarked_dummies = pd.get_dummies(df.Embarked, prefix='Embarked')\n  df = pd.concat([df, embarked_dummies], axis=1)\n\n  # Person's title one-hot encoding \n  title_dummies = pd.get_dummies(df.title, prefix='title')\n  df = pd.concat([df, title_dummies], axis=1)\n\n  # Cabin class one-hot encoding \n  cabin_class_dummies = pd.get_dummies(df.cabin_class, prefix = 'cabin_class')\n  df = pd.concat([df, cabin_class_dummies], axis = 1)\n\n  #Remove unecessary columns \n  del df['Name']\n  del df['PassengerId']\n  del df['title']\n  del df['Embarked']\n  del df['Cabin']\n  del df['Ticket']\n  del df['cabin_class']\n\n  return df ","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:09:29.197824Z","iopub.execute_input":"2021-09-11T12:09:29.19811Z","iopub.status.idle":"2021-09-11T12:09:29.223912Z","shell.execute_reply.started":"2021-09-11T12:09:29.198083Z","shell.execute_reply":"2021-09-11T12:09:29.22275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the data and create the train / test sets \nfull_df = data_preprocessing(full_df)\nX_train = full_df[:891]\ny_train = full_df['Survived'][:891]\nX_test = full_df[891:]\ndel X_train['Survived']\ndel X_test['Survived']\n\n\nprint(f'There are {X_train.shape[0]} rows and {X_train.shape[1]} columns in the training data.\\n')\nprint(f'There are {X_test.shape[0]} rows and {X_test.shape[1]} columns in the test data.')","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:09:29.225489Z","iopub.execute_input":"2021-09-11T12:09:29.225937Z","iopub.status.idle":"2021-09-11T12:09:31.602981Z","shell.execute_reply.started":"2021-09-11T12:09:29.225904Z","shell.execute_reply":"2021-09-11T12:09:31.601909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stack two models for higher accuracy  \nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm \n\nLR = LogisticRegression(max_iter=1000,C=0.175,random_state=42)\nLR.fit(X_train, y_train)\nlr_training_accuracy = LR.score(X_train, y_train)\nlr_predictions = LR.predict(X_test)\nlr_predictions = [int(x) for x in lr_predictions]\n\nxgboost = XGBRegressor(learning_rate=0.005,\n                       n_estimators=6000,\n                       max_depth=4,\n                       min_child_weight=0,\n                       gamma=0.6,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:squarederror',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=42)\n\nxgb = xgboost.fit(X_train,y_train)\nxgb_training_accuracy = xgb.score(X_train,y_train)\nxgb_predictions = xgb.predict(X_test)\nxgb_predictions = [round(x) for x in xgb_predictions]\n\nprint(\"Logistic Regression training accuracy: %.2f%%\" % (lr_training_accuracy * 100.0))\nprint(\"\\nXGB training accuracy: %.2f%%\" % (xgb_training_accuracy * 100.0))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:09:31.604328Z","iopub.execute_input":"2021-09-11T12:09:31.604919Z","iopub.status.idle":"2021-09-11T12:09:37.443678Z","shell.execute_reply.started":"2021-09-11T12:09:31.604873Z","shell.execute_reply":"2021-09-11T12:09:37.442845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine the results from both models  \npredictions = [round((lr_pred + xgb_pred) / 2) for lr_pred,xgb_pred in zip(lr_predictions,xgb_predictions)]\n# Create submission file \nsubmission = pd.DataFrame({'PassengerId':test_df['PassengerId'],'Survived':predictions})\nsubmission.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:09:37.444927Z","iopub.execute_input":"2021-09-11T12:09:37.445439Z","iopub.status.idle":"2021-09-11T12:09:37.454448Z","shell.execute_reply.started":"2021-09-11T12:09:37.445399Z","shell.execute_reply":"2021-09-11T12:09:37.453399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### My original notebook: https://www.kaggle.com/christodoulos/titanic-top-3-w-simple-feature-engineering","metadata":{}}]}