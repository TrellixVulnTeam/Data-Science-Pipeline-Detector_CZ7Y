{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Baseline Models**","metadata":{}},{"cell_type":"markdown","source":"![High Jump](https://media.aws.iaaf.org/media/Original/827ec70e-b460-4b2d-bf97-7d9c6be10c5a.jpg)\n\n[Source](https://www.worldathletics.org/disciplines/jumps/high-jump)","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pycaret[full]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction\n\nHey, thanks for viewing my Kernel!\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! ðŸ˜Š","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntitanic_train = pd.read_csv('../input/titanic/train.csv')\ndisplay(titanic_train.head())","metadata":{"execution":{"iopub.status.busy":"2022-01-22T08:45:52.075758Z","iopub.execute_input":"2022-01-22T08:45:52.076058Z","iopub.status.idle":"2022-01-22T08:45:52.117496Z","shell.execute_reply.started":"2022-01-22T08:45:52.076028Z","shell.execute_reply":"2022-01-22T08:45:52.116788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(titanic_train.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T12:11:55.026653Z","iopub.execute_input":"2022-01-21T12:11:55.026979Z","iopub.status.idle":"2022-01-21T12:11:55.033151Z","shell.execute_reply.started":"2022-01-21T12:11:55.026952Z","shell.execute_reply":"2022-01-21T12:11:55.032318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T12:11:55.035611Z","iopub.execute_input":"2022-01-21T12:11:55.036464Z","iopub.status.idle":"2022-01-21T12:11:55.05047Z","shell.execute_reply.started":"2022-01-21T12:11:55.036416Z","shell.execute_reply":"2022-01-21T12:11:55.049851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Baseline Models\nIn the real world, data can not always be predictable.  In these such problems, the best baseline model is a dummy classifier or dummy regressor. That baseline model shows you to your ml model is actually learning or not. You can see how to use random baseline models below.","metadata":{}},{"cell_type":"code","source":"np.random.seed(0)\nrandom_dim = (1000,3)\nrandom_X = np.random.random(random_dim)\nrandom_reg_y = np.random.random(random_dim[0])\nrandom_clf_y = np.random.randint(random_dim[1], size=random_dim[0])\n\n#train_reg = np.concatenate((random_X, random_reg_y.reshape(random_dim[0], 1)), axis=1)\n#col_list = [str(i +1) for i in range(random_dim[1])]\n#col_list.append('target')\n#train_reg = pd.DataFrame(train_reg, columns=col_list)\n\ntrain_clf = np.concatenate((random_X, random_clf_y.reshape(random_dim[0], 1)), axis=1)\ncol_list = [str(i +1) for i in range(random_dim[1])]\ncol_list.append('target')\ntrain_clf = pd.DataFrame(train_clf, columns=col_list)\n\ntrain_clf['target'] = train_clf['target'].astype('str')\ntrain_clf","metadata":{"execution":{"iopub.status.busy":"2022-01-13T07:15:43.392898Z","iopub.execute_input":"2022-01-13T07:15:43.393197Z","iopub.status.idle":"2022-01-13T07:15:43.419686Z","shell.execute_reply.started":"2022-01-13T07:15:43.393165Z","shell.execute_reply":"2022-01-13T07:15:43.418543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pycaret.classification import *\n\nclf = setup(data=train_clf, \n            target='target', \n            silent=True,\n            session_id=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T08:45:58.443741Z","iopub.execute_input":"2022-01-22T08:45:58.444011Z","iopub.status.idle":"2022-01-22T08:46:01.041283Z","shell.execute_reply.started":"2022-01-22T08:45:58.443985Z","shell.execute_reply":"2022-01-22T08:46:01.040164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_models(sort='Accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T09:18:21.380964Z","iopub.execute_input":"2022-01-12T09:18:21.381501Z","iopub.status.idle":"2022-01-12T09:25:45.898452Z","shell.execute_reply.started":"2022-01-12T09:18:21.381448Z","shell.execute_reply":"2022-01-12T09:25:45.897356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning Baseline Models\nIf data is predictable, the second step is to create an ml baseline model. This baseline model shows us which feature is important for prediction and which is not. Generally, ml baseline models use with feature engineering.","metadata":{}},{"cell_type":"code","source":"from pycaret.classification import *\n\nCAT_FEATURES = ['Sex', 'Embarked']\nNUM_FEATURES = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\nIGN_FEATURES = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n\nclf = setup(data=titanic_train, \n            target='Survived',\n            normalize = True, #normalisation helps some algorithms\n            normalize_method = 'robust', #resilient to outliers\n            transformation = True, #applies transformation to target column\n            transformation_method = 'quantile',\n            data_split_shuffle = False, #so that we do not use \"future\" observations to predict \"past\" observations\n            create_clusters = True,\n            feature_interaction = True,\n            categorical_features = CAT_FEATURES,\n            numeric_features = NUM_FEATURES,\n            ignore_features = IGN_FEATURES,\n            session_id = 42,\n            use_gpu = False,\n            silent = True,\n            fold = 10,\n            n_jobs = -1)","metadata":{"execution":{"iopub.status.busy":"2022-01-14T06:25:26.961456Z","iopub.execute_input":"2022-01-14T06:25:26.962558Z","iopub.status.idle":"2022-01-14T06:25:37.392161Z","shell.execute_reply.started":"2022-01-14T06:25:26.962472Z","shell.execute_reply":"2022-01-14T06:25:37.391527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_models(sort='Accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-01-13T09:20:29.57445Z","iopub.status.idle":"2022-01-13T09:20:29.575049Z","shell.execute_reply.started":"2022-01-13T09:20:29.574787Z","shell.execute_reply":"2022-01-13T09:20:29.574814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_model = create_model('rf')\n\nbaseline_preds = predict_model(baseline_model, raw_score=True)\nbaseline_preds","metadata":{"execution":{"iopub.status.busy":"2022-01-14T06:43:58.220883Z","iopub.execute_input":"2022-01-14T06:43:58.221147Z","iopub.status.idle":"2022-01-14T06:44:02.749878Z","shell.execute_reply.started":"2022-01-14T06:43:58.22112Z","shell.execute_reply":"2022-01-14T06:44:02.749204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_scores = pull()\nbaseline_scores","metadata":{"execution":{"iopub.status.busy":"2022-01-14T06:44:55.95922Z","iopub.execute_input":"2022-01-14T06:44:55.959822Z","iopub.status.idle":"2022-01-14T06:44:55.973877Z","shell.execute_reply.started":"2022-01-14T06:44:55.959785Z","shell.execute_reply":"2022-01-14T06:44:55.973325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"import re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\n# Name\ntitanic_train_FeaEng = titanic_train.copy()\nname_last = titanic_train_FeaEng['Name'].str.split(' ', n=1, expand=True)[1]\ntitle = name_last.str.split(' ', n=1, expand=True)[0]\ntitanic_train_FeaEng['Title'] = title\n\nname_len = titanic_train_FeaEng['Name'].str.len()\ntitanic_train_FeaEng['Name_len'] = name_len\n\ntfidf_vec = TfidfVectorizer(max_features=15, token_pattern=\"\\w+\")\nsvd = TruncatedSVD(n_components=10)\ntfidf_array = svd.fit_transform(tfidf_vec.fit_transform(titanic_train_FeaEng[\"Name\"]))\nfor i in range(tfidf_array.shape[1]):\n    titanic_train_FeaEng['Name_' + str(i)] = tfidf_array [:,i]\n\n# Cabin\ncabin_first = []\ncabin_last = []\ncabin_len = []\n\nfor cabin in titanic_train_FeaEng['Cabin']:\n    try:\n        re_list = re.split('(\\d+)',cabin)\n        if len(re_list) > 1:\n            cabin_first.append(re_list[0])\n            cabin_last.append(int(re_list[-2]))\n            cabin_len.append(len(re_list))\n        else:\n            cabin_first.append('None')\n            cabin_last.append(0)\n            cabin_len.append(0)\n    except:\n        cabin_first.append('None')\n        cabin_last.append(0)\n        cabin_len.append(0)\n\ntitanic_train_FeaEng['Cabin_First'] = cabin_first\ntitanic_train_FeaEng['Cabin_Last'] = cabin_last\ntitanic_train_FeaEng['Cabin_Len'] = cabin_len\n\n# Ticket\ntfidf_vec = TfidfVectorizer(max_features=5, analyzer=\"char\")\nsvd = TruncatedSVD(n_components=3)\ntfidf_array = svd.fit_transform(tfidf_vec.fit_transform(titanic_train_FeaEng[\"Ticket\"]))\nfor i in range(tfidf_array.shape[1]):\n    titanic_train_FeaEng['Ticket_' + str(i)] = tfidf_array [:,i]\n\nnew_features = ['Title', 'Name_len','Name_0', 'Name_1', 'Name_2', 'Name_3', 'Name_4', \n                'Name_5', 'Name_6', 'Name_7', 'Name_8', 'Name_9', 'Cabin_First', \n                'Cabin_Last', 'Cabin_Len', 'Ticket_0', 'Ticket_1', 'Ticket_2']\nold_features = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp',\n                'Parch', 'Fare', 'Embarked']","metadata":{"execution":{"iopub.status.busy":"2022-01-14T07:01:04.393365Z","iopub.execute_input":"2022-01-14T07:01:04.393956Z","iopub.status.idle":"2022-01-14T07:01:04.480575Z","shell.execute_reply.started":"2022-01-14T07:01:04.393912Z","shell.execute_reply":"2022-01-14T07:01:04.47974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features Importance","metadata":{}},{"cell_type":"code","source":"feature_score_dict = {}\n\nfor index, feature in enumerate(new_features):\n    old_features_temp = old_features.copy()\n    old_features_temp.append(feature)\n    titanic_train_FeaEng_temp = titanic_train_FeaEng[old_features_temp].copy()\n    \n    clf = setup(data=titanic_train_FeaEng_temp, \n            target='Survived',\n            normalize = True, #normalisation helps some algorithms\n            normalize_method = 'robust', #resilient to outliers\n            transformation = True, #applies transformation to target column\n            transformation_method = 'quantile',\n            data_split_shuffle = False, #so that we do not use \"future\" observations to predict \"past\" observations\n            create_clusters = True,\n            feature_interaction = True,\n            session_id = 42,\n            use_gpu = False,\n            silent = True,\n            fold = 10,\n            n_jobs = -1)\n    \n    baseline_model = create_model('rf')\n    scores = pull()\n    feature_score_dict[feature] = scores","metadata":{"execution":{"iopub.status.busy":"2022-01-14T07:49:52.569291Z","iopub.execute_input":"2022-01-14T07:49:52.569608Z","iopub.status.idle":"2022-01-14T08:32:46.299274Z","shell.execute_reply.started":"2022-01-14T07:49:52.569572Z","shell.execute_reply":"2022-01-14T08:32:46.298235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric_list = []\nfeature_list = []\nscore_list = []\n\nfor key in feature_score_dict.keys():\n    metric_list.extend(list(feature_score_dict[key].columns))\n    score_list.extend(list(feature_score_dict[key].loc['Mean', :]))\n    feature_list.extend([key for i in range(len(feature_score_dict[key].columns))])\n\nall_scores_pd = pd.DataFrame()\nall_scores_pd['Metric'] = metric_list\nall_scores_pd['Feature'] = feature_list\nall_scores_pd['Score'] = score_list","metadata":{"execution":{"iopub.status.busy":"2022-01-14T08:36:07.833214Z","iopub.execute_input":"2022-01-14T08:36:07.83352Z","iopub.status.idle":"2022-01-14T08:36:07.847395Z","shell.execute_reply.started":"2022-01-14T08:36:07.833487Z","shell.execute_reply":"2022-01-14T08:36:07.846482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncol_list = ['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1', 'Kappa']\nscore_color = {'Accuracy':'C0', 'AUC':'C1', 'Recall':'C2', 'Prec.':'C3', 'F1':'C4', 'Kappa':'C5'}\nfig, ax = plt.subplots(figsize=(24, 8))\nall_scores_pd = all_scores_pd.loc[all_scores_pd['Metric'] != 'MCC', :]\nsns.lineplot(data=all_scores_pd, x='Feature', y='Score', hue='Metric', ax=ax, palette=score_color)\nax.legend(loc=\"lower left\")\nfor base_col in col_list:\n    base_score = baseline_scores.loc[:, base_col].values[0]\n    ax.plot([0, len(all_scores_pd['Feature'].unique())], [base_score, base_score], color=score_color[base_col])\n    ax.text(len(all_scores_pd['Feature'].unique()), base_score, 'Base ' + base_col);","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:32:34.233168Z","iopub.execute_input":"2022-01-22T09:32:34.233792Z","iopub.status.idle":"2022-01-22T09:32:34.587126Z","shell.execute_reply.started":"2022-01-22T09:32:34.233736Z","shell.execute_reply":"2022-01-22T09:32:34.585371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Automated Machine Learning Baseline Models\nThe final baseline model is the automated ml baseline model. It is a very good model for benchmarking your ml model. If your ml model is better than the automated baseline model, it is a very strong sign that the model can become a product.","metadata":{}},{"cell_type":"markdown","source":"## LightAutoML","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install -U lightautoml","metadata":{"execution":{"iopub.status.busy":"2022-01-22T08:46:15.13262Z","iopub.execute_input":"2022-01-22T08:46:15.133355Z","iopub.status.idle":"2022-01-22T08:48:15.438442Z","shell.execute_reply.started":"2022-01-22T08:46:15.133313Z","shell.execute_reply":"2022-01-22T08:48:15.437316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\n\nimport torch","metadata":{"execution":{"iopub.status.busy":"2022-01-22T08:49:31.579156Z","iopub.execute_input":"2022-01-22T08:49:31.580336Z","iopub.status.idle":"2022-01-22T08:49:33.06834Z","shell.execute_reply.started":"2022-01-22T08:49:31.580292Z","shell.execute_reply":"2022-01-22T08:49:33.067608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nN_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 5 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 300 # Time in seconds for automl run\n\nnp.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)\n\ndef acc_score(y_true, y_pred, **kwargs):\n    return accuracy_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\ndef f1_metric(y_true, y_pred, **kwargs):\n    return f1_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\ntask = Task('binary', metric = acc_score)\n\nroles = {\n    'target': 'Survived',\n    'drop': ['Passengerid', 'Name', 'Ticket'],\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-22T08:49:39.16737Z","iopub.execute_input":"2022-01-22T08:49:39.168214Z","iopub.status.idle":"2022-01-22T08:49:39.179742Z","shell.execute_reply.started":"2022-01-22T08:49:39.168166Z","shell.execute_reply":"2022-01-22T08:49:39.179085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \nfrom sklearn.model_selection import StratifiedKFold\n\nn_fold = 3\nskf = StratifiedKFold(n_splits=n_fold)\nskf.get_n_splits(titanic_train)\n\nacc_list = []\nfor train_index, test_index in skf.split(titanic_train, titanic_train['Survived']):\n    X_train, X_test = titanic_train.loc[train_index, :], titanic_train.loc[test_index, :]\n    y = X_test['Survived']\n    X_test.drop(['Survived'], axis=1, inplace=True)\n    \n    automl = TabularUtilizedAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS})\n    automl.fit_predict(X_train, roles = roles)\n    \n    test_pred = automl.predict(X_test)\n    test_pred = (test_pred.data[:, 0] > 0.5).astype(int)\n    acc_list.append(acc_score(y, test_pred))\nlightautoml_acc_score = sum(acc_list) / n_fold\nprint('lightautoml_acc_score: ', lightautoml_acc_score)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-22T09:09:54.192612Z","iopub.execute_input":"2022-01-22T09:09:54.192963Z","iopub.status.idle":"2022-01-22T09:24:12.336032Z","shell.execute_reply.started":"2022-01-22T09:09:54.192932Z","shell.execute_reply":"2022-01-22T09:24:12.335071Z"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('lightautoml_acc_score: ', lightautoml_acc_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## H2O AutoML","metadata":{}},{"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:24:12.337707Z","iopub.execute_input":"2022-01-22T09:24:12.33861Z","iopub.status.idle":"2022-01-22T09:24:12.343279Z","shell.execute_reply.started":"2022-01-22T09:24:12.338544Z","shell.execute_reply":"2022-01-22T09:24:12.342288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2o.init()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:24:12.344536Z","iopub.execute_input":"2022-01-22T09:24:12.344762Z","iopub.status.idle":"2022-01-22T09:24:12.444413Z","shell.execute_reply.started":"2022-01-22T09:24:12.344737Z","shell.execute_reply":"2022-01-22T09:24:12.443655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nacc_list = []\nfor train_index, test_index in skf.split(titanic_train, titanic_train['Survived']):\n    X_train, X_test = titanic_train.loc[train_index, :], titanic_train.loc[test_index, :]\n    y = X_test['Survived'].astype(int)\n    X_test.drop(['Survived'], axis=1, inplace=True)\n    \n    train_hf = h2o.H2OFrame(X_train.copy())\n    test_hf = h2o.H2OFrame(X_test.copy())\n    feature_columns = X_train.drop(['Survived', 'PassengerId'], axis=1).columns\n    \n    aml = H2OAutoML(\n        seed=2022, \n        max_runtime_secs=100,\n        nfolds = 3,\n        exclude_algos = [\"DeepLearning\"]\n    )\n    \n    aml.train(\n        x=list(feature_columns), \n        y='Survived', \n        training_frame=train_hf\n    )\n    \n    test_pred = aml.predict(test_hf)\n    test_pred = test_pred.as_data_frame()\n    test_pred['test_pred_int'] = (test_pred[['predict']] > 0.5)\n    y_pred = test_pred['test_pred_int'].astype(int)\n    h2o_acc_score = accuracy_score(y, y_pred)\n    acc_list.append(h2o_acc_score)\nh2o_tautoml_acc_score = sum(acc_list) / n_fold\nprint('h2o_tautoml_acc_score: ', h2o_tautoml_acc_score)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-22T09:24:12.447471Z","iopub.execute_input":"2022-01-22T09:24:12.448636Z","iopub.status.idle":"2022-01-22T09:28:49.022472Z","shell.execute_reply.started":"2022-01-22T09:24:12.448585Z","shell.execute_reply":"2022-01-22T09:28:49.021789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('h2o_tautoml_acc_score: ', h2o_tautoml_acc_score)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:28:49.023766Z","iopub.execute_input":"2022-01-22T09:28:49.024332Z","iopub.status.idle":"2022-01-22T09:28:49.03007Z","shell.execute_reply.started":"2022-01-22T09:28:49.024286Z","shell.execute_reply":"2022-01-22T09:28:49.028975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  AutoML Scores","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(24, 8))\nax.plot([0, 10], [h2o_tautoml_acc_score, h2o_tautoml_acc_score], color='r')\nax.text(10, h2o_tautoml_acc_score, 'Base_H2O')\nax.plot([0, 10], [lightautoml_acc_score, lightautoml_acc_score], color='r')\nax.text(10, lightautoml_acc_score, 'Base_LightAutoMl');","metadata":{"execution":{"iopub.status.busy":"2022-01-22T09:40:15.850361Z","iopub.execute_input":"2022-01-22T09:40:15.850742Z","iopub.status.idle":"2022-01-22T09:40:16.100414Z","shell.execute_reply.started":"2022-01-22T09:40:15.850702Z","shell.execute_reply":"2022-01-22T09:40:16.09956Z"},"trusted":true},"execution_count":null,"outputs":[]}]}