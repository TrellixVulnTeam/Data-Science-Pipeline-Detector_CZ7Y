{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First of all, we import to the train data as \"train\" and \"train_orig\". \"train_orig\" same as \"train\" for if we do something wrong, we can access the original train data.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_orig = pd.read_csv(\"/kaggle/input/titanic/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are looking at the first five lines in our data. This way we can recognize features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are looking at correlations. The important thing for us is the \"Survived\" column that we will predict.\n\nThe correlation increases as it approaches 1. This shows that there is a linear link between the two variables. (It doesn't matter if it is negative, only the direction of linearity is changing.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order for our model to work and perform better, we have to deal with missing data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 3 missing features. Let's use the \"pandas_profilling\" library for a closer look. (It didn't work on my personal computer due to version problems, but I will share the file with you.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas_profiling import ProfileReport\nprof = ProfileReport(train)\nprof.to_file(output_file='output.html')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train[\"Age\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.distplot(train[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Age\"].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Age\"].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We fill the Age's missing values with median. But otherway we can fill with mean. It is a matter of distribution, but below you can see that the distribution does not matter much when changed either way.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Age\"].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_orig[\"Age\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_orig[\"Age\"] = train_orig[\"Age\"].fillna(train[\"Age\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_orig[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We fill  the Embarked's missing values with \"S\" I prefer it because it is the most frequently used.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train[\"Embarked\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Embarked\"][train[\"Embarked\"].isnull()] =\"S\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We're deleting the Cabin column because there are too many minus values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(\"Cabin\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(\"Name\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We do the same for test data as we do on train data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_orig = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(test[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(test[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test[\"Fare\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Fare\"][test[\"Pclass\"]==3].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Fare\"][test[\"Fare\"].isnull()]=test[\"Fare\"][test[\"Pclass\"]==3].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test= test.drop(\"Cabin\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test= test.drop(\"Name\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Sex\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Sex\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want to give numerical values to our model, we convert the object type values to numeric values.\nWe use one_hot for those with lesser values.\nWe use one_hot for those with many different values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_onehot = [\"Sex\", \"Embarked\"]\ncolumns_to_label=[\"Ticket\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Ticket\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.get_dummies(train, columns=columns_to_onehot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.get_dummies(test, columns=columns_to_onehot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle= LabelEncoder()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Ticket\"]=le.fit_transform(train[\"Ticket\"])\ntest[\"Ticket\"]=le.fit_transform(test[\"Ticket\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pi = test[\"PassengerId\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will keep Passenger_Id separate and use it for Submission.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(\"PassengerId\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(\"PassengerId\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(\"Survived\", axis=1)\ny_train = train[\"Survived\"]\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We build our neural network model. Going from high neuron count to low usually increases our performance.\n\nWe use droput because we try to avoid overfitting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential(name='titanic_model')\n\nmodel.add(L.InputLayer(input_shape=(11,))) # necessary to use model.summary()\n\nmodel.add(L.Dense(2048, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(1024, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(512, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(128, activation='relu'))\nmodel.add(L.Dropout(0.4))\nmodel.add(L.Dense(64, activation='relu'))\n\nmodel.add(L.Dense(32, activation='relu'))\nmodel.add(L.Dense(1, activation='sigmoid')) # output layer, use sigmoid for binary\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0001), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train,\n                    batch_size=16, \n                    epochs=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['loss'])\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'acc'], loc='upper left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/titanic/gender_submission.csv\")\nsubmission['Survived'] = [0 if pred < 0.5 else 1 for pred in preds]\nsubmission.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\n\n\nsubmission.to_csv('submission.csv',index=False)\nFileLink(r'submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}