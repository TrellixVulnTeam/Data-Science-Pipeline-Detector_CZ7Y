{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# **Stacked Classifier : Top 10 % on LB** \n\n\n\n## **Introduction**\n\n\nPrashant Banerjee\n\n\nApril 2020\n\n\nThis notebook gives a very simple and basic introduction to an ensemble learning technique known as **stacking**. The objective of this notebook is to provide an intuitive understanding and implement **stacking**. We have used the famous titanic dataset for the illustration purposes.\n\n\nThere is an excellent notebook on titanic survival. It is -\n\n\n[Titanic Survival Prediction End to End ML Pipeline](https://www.kaggle.com/poonaml/titanic-survival-prediction-end-to-end-ml-pipeline) by **Poonam Ligade**. Nice data exploration.\n\n\nI have adapted several lines of code from the above notebook.\n\n\nNow let's begin our journey to understand stacking. So, let's dive in.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**I hope you find this kernel useful and your <font color=\"red\"><b>UPVOTES</b></font> keep me motivated.**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n# **Notebook Contents**\n\n- [Part 1 - Introduction to Stacking](#1)\n- [Part 2 - Stacking is prone to Overfitting](#2)\n- [Part 3 - Basic Set Up](#3)\n   - [3.1 Import libraries](#3.1)\n   - [3.2 Load data](#3.2)\n- [Part 4 - Data Exploration](#4)\n- [Part 5 - Data Visualization](#5)\n- [Part 6 - Data Preprocessing](#6)\n- [Part 7 - Feature Engineering](#7)\n- [Part 8 - Categorical Encoding](#8)\n- [Part 9 - Feature Scaling](#9)\n- [Part 10 - Declare feature vector and target variable](#10)\n- [Part 11 - Individual Classifier](#11)\n- [Part 12 - Stacked Classifier](#12)\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **1. Introduction to Stacking** <a class=\"anchor\" id=\"1\"></a>\n\n[Notebook Contents](#0.1)\n\n\n- [Stacking](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/) is an ensemble machine learning technique to combine multiple individual classification models via a meta-classifier. \n\n- But, wait what is a meta-classifier?\n\n- Let's visualize the schematic representation of meta classifier below.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Stacked Classifier](https://www.researchgate.net/profile/David_Powers2/publication/264125265/figure/fig1/AS:295914087436290@1447562824204/Fusion-system-based-on-stacking.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"From the above diagram, we can conclude that stacking can be thought of as a two step process.\n\n### **Step 1** : In the first step, the individual classification models are trained based on the complete training set and their individual outputs are stored. These individual classification models are referred to as **Level One or Base Classifiers**.\n\n\n### **Step 2** : In the second step, the predictions of individual classifiers (referred to as **Level One or Base Classifiers**) are used as new features to train a new classifier. This new classifier is called **Meta Classifier**. The meta-classifier can be any classifier of our choice. \n\n\nThe meta-classifier is fitted based on the outputs -- **meta-features** -- of the individual classification models in the ensemble. The meta-classifier can either be trained on the predicted class labels or probabilities from the ensemble.\n\nThe figure below shows how three different classifiers get trained. Their predictions get stacked and are used as features to train the meta-classifier which makes the final prediction.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Stacked Classifier](https://miro.medium.com/max/2044/1*5O5_Men2op_sZsK6TTjD9g.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **2. Stacking is prone to overfitting** <a class=\"anchor\" id=\"2\"></a>\n\n[Notebook Contents](#0.1)\n\n\n- This type of Stacking is prone to overfitting due to information leakage.\n\n- To prevent information leakage into the training set from the target set, the level one predictions should come from a subset of the training data that was not used to train the level one classifiers.\n\n- This can be applied by applying k-fold cross validation technique. In this technique, the training data is split into k-folds. Then the first k-1 folds are used to train the level one classifiers. The validation fold is then used to generate a subset of the level one predictions. The process is repeated for each unique group to generate the level one predictions.\n\n- The figure below illustrates this process -","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![k-fold Cross Validation Techniques](https://miro.medium.com/max/2972/1*RP0pkQEOSrw9_EjFu4w3gg.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Now, let's get to implementation of stacking or stacked classifier.\n\n- The first step is to import the libraries and dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **3. Basic Set Up** <a class=\"anchor\" id=\"3\"></a>\n\n[Notebook Contents](#0.1)\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **3.1 Import Libraries** <a class=\"anchor\" id=\"3.1\"></a>\n\n[Notebook Contents](#0.1)\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## Ignore warning\nimport warnings \nwarnings.filterwarnings('ignore') \n\n\n# Data processing and analysis libraries\nimport numpy as np\nimport pandas as pd\nimport re\n\n\n# Data visualisation libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\n\n# Configure visualisations\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\n\n\n# Classification algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import NuSVC, SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n\n# Data preprocessing :\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n\n\n# Modeling helper functions\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n\n\n# Classification metrices\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **3.2 Load data** <a class=\"anchor\" id=\"3.2\"></a>\n\n[Notebook Contents](#0.1)\n\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load train and Test set\n\n%time\n\ntrain_df = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_df = pd.read_csv('/kaggle/input/titanic/test.csv')\nsubmission_df = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\nIDtest = test_df['PassengerId']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. Data Exploration** <a class=\"anchor\" id=\"4\"></a>\n\n[Notebook Contents](#0.1)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **Check the shape of the datasets**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'The shape of the training set : ', (train_df.shape))\nprint(f'The shape of the test set : ', (test_df.shape))\nprint(f'The shape of the submission set : ', (submission_df.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Preview training set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Preview test set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **View concise summary of training set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We suspect missing values in `Age`,`Cabin` and `Embarked` in training set. We will explore it later.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **View concise summary of test set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, missing values occur in `Age`,`Fare` and `Cabin`. We will see it later.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **Check for missing values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values in training set\n\nvar1 = [col for col in train_df.columns if train_df[col].isnull().sum() != 0]\n\nprint(train_df[var1].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we are right that `Age`, `Cabin` and `Embarked` contain missing values in training set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values in test set\n\nvar2 = [col for col in test_df.columns if test_df[col].isnull().sum() != 0]\n\nprint(test_df[var2].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Age`, `Fare` and `Cabin` contain missing values in test set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **View statistical properties**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Types of Variables**\n\n\nNow, we will classify the variables into categorical and numerical variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# find categorical variables in training set\n\ncategorical1 = [var for var in train_df.columns if train_df[var].dtype =='O']\n\nprint('There are {} categorical variables in training set.\\n'.format(len(categorical1)))\n\nprint('The categorical variables are :', categorical1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find numerical variables in training set\n\nnumerical1 = [var for var in train_df.columns if train_df[var].dtype !='O']\n\nprint('There are {} numerical variables in training set.\\n'.format(len(numerical1)))\n\nprint('The numerical variables are :', numerical1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find categorical variables in test set\n\ncategorical2 = [var for var in test_df.columns if test_df[var].dtype =='O']\n\nprint('There are {} categorical variables in test set.\\n'.format(len(categorical2)))\n\nprint('The categorical variables are :', categorical2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find numerical variables in test set\n\nnumerical2 = [var for var in test_df.columns if test_df[var].dtype !='O']\n\nprint('There are {} numerical variables in test set.\\n'.format(len(numerical2)))\n\nprint('The numerical variables are :', numerical2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **5. Data Visualization** <a class=\"anchor\" id=\"5\"></a>\n\n[Notebook Contents](#0.1)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **5.1 Missing values** <a class=\"anchor\" id=\"5.1\"></a>\n\n[Notebook Contents](#0.1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# view missing values in training set\n\nmsno.matrix(train_df, figsize = (30,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view missing values in test set\n\nmsno.matrix(test_df, figsize = (30,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **5.2 Survived**  <a class=\"anchor\" id=\"5.2\"></a>\n\n[Notebook Contents](#0.1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here 0 stands for not survived and 1 stands for survived.\n\nSo, 549 people survived and 342 people did not survive.\n\nLet's visualize it by plotting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6,6))\ngraph = sns.countplot(ax=ax,x=train_df['Survived'], data = train_df, palette = 'PuBuGn_d')\ngraph.set_title('Distribution of people who survived', fontsize = 12)\ngraph.set_xticklabels(graph.get_xticklabels(),rotation=30)\nfor p in graph.patches:\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now females have higher probability of survival than males.\n\nLet' check it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby('Survived')['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6,6))\ngraph = sns.countplot(ax=ax,x=train_df['Survived'], data = train_df, hue='Sex', palette = 'PuBuGn_d')\ngraph.set_title('Distribution of people who survived', fontsize = 12)\ngraph.set_xticklabels(graph.get_xticklabels(),rotation=30)\nfor p in graph.patches:\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the percentage of survival for males and females separately.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"females = train_df[train_df['Sex'] == 'female']\nfemales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"females['Survived'].value_counts()/len(females)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"males = train_df[train_df['Sex'] == 'male']\nmales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"males['Survived'].value_counts()/len(males)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected females have higher probability of survival (value 1) 74.20% than males 18.89%.\n\nLet's visualize it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the first of two pie-charts and set current axis\nplt.figure(figsize=(8,6))\nplt.subplot(1, 2, 1)   # (rows, columns, panel number)\nlabels1 = females['Survived'].value_counts().index\nsize1 = females['Survived'].value_counts()\ncolors1=['cyan','pink']\nplt.pie(size1, labels = labels1, colors = colors1, shadow = True, autopct='%1.1f%%',startangle = 90)\nplt.title('Percentage of females who survived', fontsize = 20)\nplt.legend(['1:Survived', '0:Not Survived'], loc=0)\nplt.show()\n\n# create the second of two pie-charts and set current axis\nplt.figure(figsize=(8,6))\nplt.subplot(1, 2, 2)   # (rows, columns, panel number)\nlabels2 = males['Survived'].value_counts().index\nsize2 = males['Survived'].value_counts()\ncolors2=['pink','cyan']\nplt.pie(size2, labels = labels2, colors = colors2, shadow = True, autopct='%1.1f%%',startangle = 90)\nplt.title('Percentage of males who survived', fontsize = 20)\nplt.legend(['0:Not Survived','1:Survived'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **5.3 Sex** <a class=\"anchor\" id=\"5.3\"></a>\n\n[Table of Contents](#0.1)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6,6))\ngraph = sns.countplot(ax=ax,x=train_df['Sex'], data=train_df, palette = 'bone')\ngraph.set_title('Distribution of sex among passengers', fontsize = 12)\ngraph.set_xticklabels(graph.get_xticklabels(),rotation=30)\nfor p in graph.patches:\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Sex'].value_counts()/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nlabels = train_df['Sex'].value_counts().index\nsize = train_df['Sex'].value_counts()\ncolors=['cyan','pink']\nplt.pie(size, labels = labels, shadow = True, colors=colors, autopct='%1.1f%%',startangle = 90)\nplt.title('Percentage distribution of sex among passengers', fontsize = 20)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **5.4 Pclass** <a class=\"anchor\" id=\"5.4\"></a>\n\n[Table of Contents](#0.1)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby('Pclass')['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8,6))\ngraph = sns.countplot(ax=ax,x=train_df['Pclass'], data=train_df, palette = 'bone')\ngraph.set_title('Number of people in different classes', fontsize = 12)\ngraph.set_xticklabels(graph.get_xticklabels(),rotation=30)\nfor p in graph.patches:\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8,6))\ngraph = sns.countplot(ax=ax,x=train_df['Pclass'], data=train_df, hue='Survived', palette = 'bone')\ngraph.set_title('Distribution of people segregated by survival', fontsize = 12)\ngraph.set_xticklabels(graph.get_xticklabels(),rotation=30)\nfor p in graph.patches:\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here 0 stands for not survived and 1 stands for survived.\n\nSo, we can see that Pclass plays a major role in survival.\n\nMajority of people survived in Pclass 1 while a large number of people do not survive in Pclass 3.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# percentage of survivors per class\nsns.factorplot('Pclass', 'Survived', data = train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **5.5 Embarked** <a class=\"anchor\" id=\"5.5\"></a>\n\n[Table of Contents](#0.1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8,6))\ngraph = sns.countplot(ax=ax,x=train_df['Embarked'], data=train_df, palette = 'bone')\ngraph.set_title('Number of people across different embarkment', fontsize = 12)\ngraph.set_xticklabels(graph.get_xticklabels(),rotation=30)\nfor p in graph.patches:\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8,6))\ngraph = sns.countplot(ax=ax,x=train_df['Embarked'], data=train_df, hue='Survived', palette = 'bone')\ngraph.set_title('Number of people who survived across different embarkment', fontsize = 12)\ngraph.set_xticklabels(graph.get_xticklabels(),rotation=30)\nfor p in graph.patches:\n    height = p.get_height()\n    graph.text(p.get_x()+p.get_width()/2., height + 0.1,height ,ha=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that port of embarkment plays a major role in survival probability.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **5.6 Age** <a class=\"anchor\" id=\"5.6\"></a>\n\n[Table of Contents](#0.1) ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_df['Age']\nplt.figure(figsize=(8,6))\nplt.hist(x, bins=25, color='g')\nplt.xlabel('Age')\nplt.ylabel('Number of passengers')\nplt.title('Age distribution of passengers', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that majority of passengers are aged between 20 and 40.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\ntrain_df.Age[train_df.Pclass == 1].plot(kind='kde')    \ntrain_df.Age[train_df.Pclass == 2].plot(kind='kde')\ntrain_df.Age[train_df.Pclass == 3].plot(kind='kde')\n # plots an axis lable\nplt.xlabel(\"Age\")    \nplt.title(\"Age Distribution within classes\")\n# sets our legend for our graph.\nplt.legend(('1st Class', '2nd Class','3rd Class'),loc='best') ;","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **5.7 Visualizations about training set** <a class=\"anchor\" id=\"5.7\"></a>\n\n[Table of Contents](#0.1) ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.hist(bins=10,figsize=(12,8),grid=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that `Age` and `Fare` are measured on very different scaling. So we need to do feature scaling before predictions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(train_df, col=\"Sex\", row=\"Survived\", margin_titles=True)\ng.map(plt.hist, \"Age\", color=\"green\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **5.8 Correlation Heatmap** <a class=\"anchor\" id=\"5.8\"></a>\n\n[Table of Contents](#0.1) ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_df.corr()#[\"Survived\"]\nplt.figure(figsize=(10, 10))\nsns.heatmap(corr, vmax=.8, linewidths=0.01, square=True,annot=True,cmap='YlGnBu',linecolor=\"white\")\nplt.title('Correlation between features');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation of features with target variable\ntrain_df.corr()[\"Survived\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, `Pclass` has got highest negative correlation with `Survived` and `Fare` has got highest positive correlation with `Survived`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(x=\"Age\", y=\"Embarked\",\n                    hue=\"Sex\", row=\"Pclass\",\n                    data=train_df[train_df.Embarked.notnull()],\n                    orient=\"h\", size=2, aspect=3.5, \n                   palette={'male':\"purple\", 'female':\"blue\"},\n                    kind=\"violin\", split=True, cut=0, bw=.2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **6. Data Preprocessing** <a class=\"anchor\" id=\"6\"></a>\n\n[Table of Contents](#0.1)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **6.1 Missing Values Imputation** <a class=\"anchor\" id=\"6.1\"></a>\n\n[Table of Contents](#0.1)\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It is important to fill missing values, because some machine learning algorithms can't accept them eg SVM.\n\n\nBut filling missing values with mean/median/mode is also a prediction which may not be 100% accurate, instead we can use models like Decision Trees and Random Forest which handle missing values very well.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **Embarked Column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check which rows have null Embarked column\ntrain_df[train_df['Embarked'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PassengerId** **62** and **830** have missing embarked values. Both have **Passenger class 1** and **fare $80**.\n\n\nNow, lets plot a graph to visualize and try to guess from where they embarked.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=train_df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that for 1st class median line is coming around fare $80 for embarked value 'C'. So we can replace NA values in Embarked column with 'C'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna('C')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there is an empty fare column in test set\ntest_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Fare Column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[test_df['Fare'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we can replace missing value in fare by taking median of all fares of those passengers \n#who share 3rd Passenger class and Embarked from 'S' \ndef fill_missing_fare(df):\n    median_fare=df[(df['Pclass'] == 3) & (df['Embarked'] == 'S')]['Fare'].median()\n#'S'\n       #print(median_fare)\n    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n    return df\n\ntest_df=fill_missing_fare(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **7. Feature Engineering** <a class=\"anchor\" id=\"7\"></a>\n\n[Table of Contents](#0.1)\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **Deck- Where exactly were passenger on the ship?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Deck\"]=train_df.Cabin.str[0]\ntest_df[\"Deck\"]=test_df.Cabin.str[0]\ntrain_df[\"Deck\"].unique() # 0 is for null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.factorplot(\"Survived\", col=\"Deck\", col_wrap=4,\n                    data=train_df[train_df.Deck.notnull()],\n                    kind=\"count\", size=2.5, aspect=.8);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.assign(Deck=train_df.Deck.astype(object)).sort_values(\"Deck\")\ng = sns.FacetGrid(train_df, col=\"Pclass\", sharex=False,\n                  gridspec_kws={\"width_ratios\": [5, 3, 3]})\ng.map(sns.boxplot, \"Deck\", \"Age\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Deck.fillna('Z', inplace=True)\ntest_df.Deck.fillna('Z', inplace=True)\ntrain_df[\"Deck\"].unique() # Z is for null values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How Big is your family?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a family size variable including the passenger themselves\ntrain_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"]+1\ntest_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"]+1\nprint(train_df[\"FamilySize\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Discretize family size\ntrain_df.loc[train_df[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntrain_df.loc[(train_df[\"FamilySize\"] > 1)  &  (train_df[\"FamilySize\"] < 5) , \"FsizeD\"] = 'small'\ntrain_df.loc[train_df[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\n\ntest_df.loc[test_df[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntest_df.loc[(test_df[\"FamilySize\"] >1) & (test_df[\"FamilySize\"] <5) , \"FsizeD\"] = 'small'\ntest_df.loc[test_df[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df[\"FsizeD\"].unique())\nprint(train_df[\"FsizeD\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x=\"FsizeD\", y=\"Survived\", data=train_df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Do you have longer names?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create feature for length of name \n# The apply method generates a new series\n\ntrain_df[\"NameLength\"] = train_df[\"Name\"].apply(lambda x: len(x))\ntest_df[\"NameLength\"] = test_df[\"Name\"].apply(lambda x: len(x))\nbins = [0, 20, 40, 57, 85]\ngroup_names = ['short', 'okay', 'good', 'long']\ntrain_df['NlengthD'] = pd.cut(train_df['NameLength'], bins, labels=group_names)\ntest_df['NlengthD'] = pd.cut(test_df['NameLength'], bins, labels=group_names)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x=\"NlengthD\", y=\"Survived\", data=train_df)\nprint(train_df[\"NlengthD\"].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **What's in the name?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\n#A function to get the title from a name.\ndef get_title(name):\n    \"\"\"Use a regular expression to search for a title.  \n       Titles always consist of capital and lowercase letters, and end with a period\"\"\"\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    #If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get all the titles and print how often each one occurs.\ntitles = train_df[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add in the title column.\ntrain_df[\"Title\"] = titles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Also reassign mlle, ms, and mme accordingly\ntrain_df.loc[train_df[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntrain_df.loc[train_df[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntrain_df.loc[train_df[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntrain_df.loc[train_df[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntrain_df.loc[train_df[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Do the same with test set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"titles = test_df[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add in the title column.\ntest_df[\"Title\"] = titles\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Also reassign mlle, ms, and mme accordingly\ntest_df.loc[test_df[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntest_df.loc[test_df[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntest_df.loc[test_df[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntest_df.loc[test_df[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntest_df.loc[test_df[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"Title\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Ticket column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"Ticket\"].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"TicketNumber\"] = train_df[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntrain_df[\"TicketNumber\"] = train_df[\"TicketNumber\"].apply(pd.to_numeric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"TicketNumber\"] = test_df[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntest_df[\"TicketNumber\"] = test_df[\"TicketNumber\"].apply(pd.to_numeric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#some rows in ticket column dont have numeric value so we got NaN there\ntrain_df[train_df[\"TicketNumber\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.TicketNumber.fillna(train_df[\"TicketNumber\"].median(), inplace=True)\ntest_df.TicketNumber.fillna(test_df[\"TicketNumber\"].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **8. Categorical Encoding** <a class=\"anchor\" id=\"8\"></a>\n\n[Table of Contents](#0.1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labelenc=LabelEncoder()\n\ncat_vars=['Embarked','Sex',\"Title\",\"FsizeD\",\"NlengthD\",'Deck']\nfor col in cat_vars:\n    train_df[col]=labelenc.fit_transform(train_df[col])\n    test_df[col]=labelenc.fit_transform(test_df[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Age Column**\n\nAge seems to be promising feature. So it doesnt make sense to simply fill null values out with median/mean/mode.\n\nWe will use Random Forest algorithm to predict ages.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(train_df[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"red\")\n    plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n#predicting missing values in age using Random Forest\ndef fill_missing_age(df):\n    \n    #Feature set\n    age_df = df[['Age','Embarked','Fare', 'Parch', 'SibSp',\n                 'TicketNumber', 'Title','Pclass','FamilySize',\n                 'FsizeD','NameLength',\"NlengthD\",'Deck']]\n    # Split sets into train and test\n    train  = age_df.loc[ (df.Age.notnull()) ]# known Age values\n    test = age_df.loc[ (df.Age.isnull()) ]# null Ages\n    \n    # All age values are stored in a target array\n    y = train.values[:, 0]\n    \n    # All the other values are stored in the feature array\n    X = train.values[:, 1::]\n    \n    # Create and fit a model\n    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n    rtr.fit(X, y)\n    \n    # Use the fitted model to predict the missing values\n    predictedAges = rtr.predict(test.values[:, 1::])\n    \n    # Assign those predictions to the full data set\n    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=fill_missing_age(train_df)\ntest_df=fill_missing_age(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **9. Feature Scaling** <a class=\"anchor\" id=\"9\"></a>\n\n[Table of Contents](#0.1)\n\n\nWe can see that Age, Fare are measured on different scales, so we need to do Feature Scaling first before we proceed with making predictions with **stacked classifier**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nstd_scale = preprocessing.StandardScaler().fit(train_df[['Age', 'Fare']])\ntrain_df[['Age', 'Fare']] = std_scale.transform(train_df[['Age', 'Fare']])\n\n\nstd_scale = preprocessing.StandardScaler().fit(test_df[['Age', 'Fare']])\ntest_df[['Age', 'Fare']] = std_scale.transform(test_df[['Age', 'Fare']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Correlation of features with target**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.corr()[\"Survived\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **10. Declare feature vector and target label** <a class=\"anchor\" id=\"10\"></a>\n\n[Table of Contents](#0.1)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Declare feature vector and target variable\nX_train = train_df.drop(labels = ['Survived'],axis = 1)\ny_train = train_df['Survived']\nX_test = test_df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **11. Individual Classifiers** <a class=\"anchor\" id=\"11\"></a>\n\n[Table of Contents](#0.1)\n\n\nFor the purpose of illustration, we will train a **Support Vector Classifier (SVC)**, **Multi-layer Perceptron (MLP) classifier**, **Nu-Support Vector classifier (NuSVC)** and a **Random Forest (RF) classifier** — classifiers available in Scikit-learn. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing Support Vector classifier\nclf_svc = SVC(C = 50, degree = 1, gamma = \"auto\", kernel = \"rbf\", probability = True)\n\n# Initializing Multi-layer perceptron  classifier\nclf_mlp = MLPClassifier(activation = \"relu\", alpha = 0.1, hidden_layer_sizes = (10,10,10),\n                            learning_rate = \"constant\", max_iter = 2000, random_state = 1000)\n\n# Initialing Nu Support Vector classifier\nclf_nusvc = NuSVC(degree = 1, kernel = \"rbf\", nu = 0.25, probability = True)\n\n# Initializing Random Forest classifier\nclf_rfc = RandomForestClassifier(n_estimators = 500, criterion = \"gini\", max_depth = 10,\n                                     max_features = \"auto\", min_samples_leaf = 0.005,\n                                     min_samples_split = 0.005, n_jobs = -1, random_state = 1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **12. Stacked Classifier** <a class=\"anchor\" id=\"12\"></a>\n\n[Table of Contents](#0.1)\n\n\nTo stack the above classifiers, we will use the [StackingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) from scikit-learn library.\n\n\nWe can also use the [StackingCVClassifier](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/) from MLXTEND for the same purpose. We can take a look at the [official documentation](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/) since it goes in detail over useful examples of how to implement the StackingCVClassifier.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [('svc', clf_svc),\n               ('mlp', clf_mlp),                             \n               ('nusvc', clf_nusvc),\n               ('rfc', clf_rfc)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = StackingClassifier(estimators=classifiers, \n                         final_estimator=LogisticRegression(),\n                         stack_method='auto',\n                         n_jobs=-1,\n                         passthrough=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors=[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"NameLength\",\"TicketNumber\"]\n\nclf.fit(X_train[predictors],y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions=clf.predict(X_test[predictors])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions=test_predictions.astype(int)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": test_predictions\n    })\n\nsubmission.to_csv(\"titanic_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this notebook, we have demonstrated the stacked classifier.\n\nNow we will come to the end of this kernel. I hope you find this kernel useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\nThank you\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Go to Top](#0)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}