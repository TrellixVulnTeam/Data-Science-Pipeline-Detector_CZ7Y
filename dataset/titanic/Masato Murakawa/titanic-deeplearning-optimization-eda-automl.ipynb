{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n# [Titanic - Machine Learning from Disaster][1]\n\n**Goal:** To predict if a passenger survived the sinking of the Titanic or not.\n\n---\n### **The aim of this notebook is to**\n- **1. Conduct Exploratory Data Analysis (EDA) and Feature Engineering.**\n- **2. Create and train a Deep Learning model with TensorFlow.**\n- **3. Optimize the neural network architecture with Optuna.**\n- **4. Learn how to use TPU.**\n- **5. Learn how to use AutoML (H2O AutoML).**\n---\n#### **Note:** \n- You can run this notebook on CPU, GPU, and TPU without changing codes.\n- In this notebook, training model on TPU takes more time than on GPU or CPU, because of the small batch size, small datasets, ect. Please understand that I didn't optimize the experiment parameters for TPU.\n- It would take much time to run optimization codes with many trials on TPU, so it is recommended to run on CPU or GPU.\n\n---\n#### **References:**\n Thanks to previous great codes, blogs, and notebooks.\n- [How to Use Kaggle: Tensor Processing Units (TPUs)][2]\n- [AutoML: Automatic Machine Learning][5]\n- [H2O AutoML Tutorial][6]\n- [Automated Machine Learning with H2O][7]\n\n---\n#### **My Previous Notebooks:**\n- This competition is a basic classification task. If you are also interested in basic regression task, **[my notebook of House Prices competition][3]** would be useful.\n- If you would like to know more about other deep learning models for tabular data, you can find it in **[my notebook of Spaceship Titanic competition][4]**.\n\n---\n### **If you find this notebook useful, or when you copy&edit this notebook, please do give me an upvote. It helps me keep up my motivation.**\n\n---\n[1]: https://www.kaggle.com/competitions/titanic\n[2]: https://www.kaggle.com/docs/tpu\n[3]: https://www.kaggle.com/code/masatomurakawamm/houseprices-deeplearning-eda-automl-pycaret\n[4]: https://www.kaggle.com/code/masatomurakawamm/spaceshiptitanic-eda-tabtransformer-tensorflow\n[5]: https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n[6]: https://github.com/h2oai/h2o-tutorials/tree/master/h2o-world-2017/automl\n[7]: https://towardsdatascience.com/automated-machine-learning-with-h2o-258a2f3a203f","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>0. TABLE OF CONTENTS</center></h1>\n\n<ul class=\"list-group\" style=\"list-style-type:none;\">\n    <li><a href=\"#1\" class=\"list-group-item list-group-item-action\">1. Settings</a></li>\n    <li><a href=\"#2\" class=\"list-group-item list-group-item-action\">2. Data Loading</a></li>\n    <li><a href=\"#3\" class=\"list-group-item list-group-item-action\">3. EDA and Feature Engineering</a>\n        <ul class=\"list-group\" style=\"list-style-type:none;\">\n            <li><a href=\"#3.1\" class=\"list-group-item list-group-item-action\">3.1 AutoEDA with Sweetviz</a></li>\n            <li><a href=\"#3.2\" class=\"list-group-item list-group-item-action\">3.2 Feature Selection</a></li>\n            <li><a href=\"#3.3\" class=\"list-group-item list-group-item-action\">3.3 Target Distribution</a></li>\n            <li><a href=\"#3.4\" class=\"list-group-item list-group-item-action\">3.4 Numerical Features</a></li>\n            <li><a href=\"#3.5\" class=\"list-group-item list-group-item-action\">3.5 Categorical Features</a></li>\n            <li><a href=\"#3.6\" class=\"list-group-item list-group-item-action\">3.6 Validation Split</a></li>\n        </ul>\n    </li>\n    <li><a href=\"#4\" class=\"list-group-item list-group-item-action\">4. Deep Learning</a>\n        <ul class=\"list-group\" style=\"list-style-type:none;\">\n            <li><a href=\"#4.1\" class=\"list-group-item list-group-item-action\">4.1 Creating Dataset</a></li>\n            <li><a href=\"#4.2\" class=\"list-group-item list-group-item-action\">4.2 Creating Model</a></li>\n            <li><a href=\"#4.3\" class=\"list-group-item list-group-item-action\">4.3 Training Model</a></li>\n            <li><a href=\"#4.4\" class=\"list-group-item list-group-item-action\">4.4 Inference</a></li>\n        </ul>\n    </li>\n    <li><a href=\"#5\" class=\"list-group-item list-group-item-action\">5. Optimization</a></li>\n    <li><a href=\"#6\" class=\"list-group-item list-group-item-action\">6. Cross Validation and Ensebmling</a></li>\n    <li><a href=\"#7\" class=\"list-group-item list-group-item-action\">7. AutoML</a>\n        <ul class=\"list-group\" style=\"list-style-type:none;\">\n            <li><a href=\"#7.1\" class=\"list-group-item list-group-item-action\">7.1 Set up</a></li>\n            <li><a href=\"#7.2\" class=\"list-group-item list-group-item-action\">7.2 Create Training Data</a></li>\n            <li><a href=\"#7.3\" class=\"list-group-item list-group-item-action\">7.3 Run AutoML</a></li>\n            <li><a href=\"#7.4\" class=\"list-group-item list-group-item-action\">7.4 Explainability</a></li>\n        </ul>\n    </li>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"<a id =\"1\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>1. Settings</center></h1>","metadata":{}},{"cell_type":"code","source":"## Parameters\ndata_config = {'train.csv': '../input/titanic/train.csv',\n               'test.csv': '../input/titanic/test.csv',\n               'gender_submission.csv': '../input/titanic/gender_submission.csv',\n              }\n\nexp_config = {'competition_name': 'titanic',\n              'n_splits': 5,\n              'normalization': 'Robust',\n              'encoding': 'one_hot',\n              'n_sample_per_TPU_core': 16,\n              'batch_size': 128,\n              'learning_rate': 5e-4,\n              'label_smoothing': 0.01,\n              'train_epochs': 100,\n              'checkpoint_filepath': './tmp/model/exp.ckpt',\n              'cross_validation': True,\n             }\n\nmodel_config = {'model_input_shape': (57, ),\n                'model_units': [64, 48, 32],\n                'dropout_rates': [0., 0.1, 0.1],\n               }\n\nopt_config = {'opt_flg': True,\n              'opt_trials': 30,\n              'opt_epochs': 60,\n              'opt_batch_size': 256}\n\nprint('Parameters setted!')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-06-22T02:52:59.412992Z","iopub.execute_input":"2022-06-22T02:52:59.413445Z","iopub.status.idle":"2022-06-22T02:52:59.448861Z","shell.execute_reply.started":"2022-06-22T02:52:59.413357Z","shell.execute_reply":"2022-06-22T02:52:59.447568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Import dependencies \nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport sklearn\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\nimport os\nimport pathlib\nimport gc\nimport sys\nimport re\nimport math \nimport random\nimport time \nimport datetime as dt\nimport pprint\nfrom tqdm import tqdm \n\nprint('Import done!')","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-06-22T02:52:59.451344Z","iopub.execute_input":"2022-06-22T02:52:59.452223Z","iopub.status.idle":"2022-06-22T02:53:10.125681Z","shell.execute_reply.started":"2022-06-22T02:52:59.452162Z","shell.execute_reply":"2022-06-22T02:53:10.124205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## For reproducible results    \ndef seed_all(s):\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(s) \n    print('Seeds setted!')\n    \nglobal_seed = 42\nseed_all(global_seed)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:10.127967Z","iopub.execute_input":"2022-06-22T02:53:10.128749Z","iopub.status.idle":"2022-06-22T02:53:10.13562Z","shell.execute_reply.started":"2022-06-22T02:53:10.128713Z","shell.execute_reply":"2022-06-22T02:53:10.134689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# [TPU] Distribution Strategy #\n\nA TPU has eight different *cores* and each of these cores acts as its own accelerator. (A TPU is sort of like having eight GPUs in one machine.) We tell TensorFlow how to make use of all these cores at once through a **distribution strategy**. Run the following cell to create the distribution strategy that we'll later apply to our model. We'll use the distribution strategy when we create our neural network model. Then, TensorFlow will distribute the training among the eight TPU cores by creating eight different replicas of the model, one for each core.","metadata":{}},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:10.137756Z","iopub.execute_input":"2022-06-22T02:53:10.139479Z","iopub.status.idle":"2022-06-22T02:53:10.176114Z","shell.execute_reply.started":"2022-06-22T02:53:10.139241Z","shell.execute_reply":"2022-06-22T02:53:10.174814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<a id =\"2\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>2. Data Loading</center></h1>","metadata":{}},{"cell_type":"markdown","source":"---\n## [TPU] Loading the Competition Data ##\n\nWhen used with TPUs, datasets need to be stored in a [Google Cloud Storage bucket](https://cloud.google.com/storage/). You can use data from any public GCS bucket by giving its path just like you would data from `'/kaggle/input'`. The following will retrieve the GCS path for this competition's dataset.","metadata":{}},{"cell_type":"code","source":"competition_name = exp_config['competition_name']\n\n## Get GCS Path\nfrom kaggle_datasets import KaggleDatasets\n\nif tpu:\n    DATA_DIR = KaggleDatasets().get_gcs_path(competition_name) \n    \n    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n    load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n    \n    for file_path in tf.io.gfile.glob(os.path.join(DATA_DIR, \"*\")):\n        file_name = file_path.split('/')[-1]\n        data_config[file_name] = file_path\n    \nelse:\n    DATA_DIR = '/kaggle/input/' + competition_name\n    save_locally = None\n    load_locally = None\n\nprint(f\"Data Directory Path: {DATA_DIR}\\n\")\nprint(\"Contents of Data Directory:\")\nfor file in tf.io.gfile.glob(os.path.join(DATA_DIR, \"*\")):\n    print(f\"\\t{file}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:10.178972Z","iopub.execute_input":"2022-06-22T02:53:10.179791Z","iopub.status.idle":"2022-06-22T02:53:10.196741Z","shell.execute_reply.started":"2022-06-22T02:53:10.179622Z","shell.execute_reply":"2022-06-22T02:53:10.195884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After Loading data, we can conduct EDA or Feature Engineering just as like on CPU/GPU.\n\n---","metadata":{}},{"cell_type":"markdown","source":"### [File and Data Field Descriptions](https://www.kaggle.com/competitions/titanic/data)\n\n- **train.csv** - the training set\n- **test.csv** - the test set\n- **gender_submission.csv** - a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like\n\n\n---\n### [Submission & Evaluation](https://www.kaggle.com/competitions/titanic/overview/evaluation)\n\n-  For each in the test set, you must predict a 0 or 1 value for the variable. Your score is the percentage of passengers you correctly predict. This is known as accuracy.","metadata":{}},{"cell_type":"code","source":"## Data Loading\ntrain_df = pd.read_csv(data_config['train.csv'])\ntest_df = pd.read_csv(data_config['test.csv'])\nsubmission_df = pd.read_csv(data_config['gender_submission.csv'])\n\nprint(f'train_length: {len(train_df)}')\nprint(f'test_lenght: {len(test_df)}')\nprint(f'submission_length: {len(submission_df)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:10.198064Z","iopub.execute_input":"2022-06-22T02:53:10.198617Z","iopub.status.idle":"2022-06-22T02:53:10.246143Z","shell.execute_reply.started":"2022-06-22T02:53:10.198581Z","shell.execute_reply":"2022-06-22T02:53:10.244944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Null Value Check\nprint('train_df.info()'); print(train_df.info(), '\\n')\nprint('test_df.info()'); print(test_df.info(), '\\n')\n\n## train_df Check\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:10.24758Z","iopub.execute_input":"2022-06-22T02:53:10.248297Z","iopub.status.idle":"2022-06-22T02:53:10.304155Z","shell.execute_reply.started":"2022-06-22T02:53:10.248239Z","shell.execute_reply":"2022-06-22T02:53:10.303356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"3\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>3. EDA and Feature Engineering</center></h1>","metadata":{}},{"cell_type":"markdown","source":"<a id =\"3.1\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>3.1 AutoEDA with Sweetviz</center></h2>","metadata":{}},{"cell_type":"code","source":"## Import dependencies\n!pip install -U -q sweetviz \nimport sweetviz\nprint('import done!')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:53:10.305569Z","iopub.execute_input":"2022-06-22T02:53:10.306148Z","iopub.status.idle":"2022-06-22T02:53:25.22947Z","shell.execute_reply.started":"2022-06-22T02:53:10.306116Z","shell.execute_reply":"2022-06-22T02:53:25.22802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#my_report = sweetviz.analyze(train_df, \"Survived\")\nmy_report = sweetviz.compare([train_df, \"Train\"], [test_df, \"Test\"], \"Survived\")\nmy_report.show_notebook()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:25.23115Z","iopub.execute_input":"2022-06-22T02:53:25.231509Z","iopub.status.idle":"2022-06-22T02:53:31.848926Z","shell.execute_reply.started":"2022-06-22T02:53:25.231476Z","shell.execute_reply":"2022-06-22T02:53:31.847762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"3.2\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>3.2 Feature Selection</center></h2>","metadata":{}},{"cell_type":"code","source":"for column in train_df.columns:\n    print(f\"# of unique values in {column}: {train_df[column].nunique()}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:31.849879Z","iopub.execute_input":"2022-06-22T02:53:31.850187Z","iopub.status.idle":"2022-06-22T02:53:31.860972Z","shell.execute_reply.started":"2022-06-22T02:53:31.850159Z","shell.execute_reply":"2022-06-22T02:53:31.859912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = 'Survived'\ncategorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked']\nnumerical_features = ['Age', 'Fare']","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:31.86511Z","iopub.execute_input":"2022-06-22T02:53:31.86616Z","iopub.status.idle":"2022-06-22T02:53:31.874619Z","shell.execute_reply.started":"2022-06-22T02:53:31.866098Z","shell.execute_reply":"2022-06-22T02:53:31.873809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"3.3\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>3.3 Target Distribution</center></h2>","metadata":{}},{"cell_type":"code","source":"## Interactive Target Distribution Plot with plotly\ntarget_count = train_df.groupby(target)['PassengerId'].count()\ntarget_percent = target_count / target_count.sum()\n\n## 1. Make Figure object\nfig = go.Figure()\n\n## 2. Make trace (graph object)\ndata = go.Bar(x=target_count.index.astype(str).values,\n              y=target_count.values)\n\n## 3. Add the trace to the Figure\nfig.add_trace(data)\n\n## 4. Setting layouts\nfig.update_layout(title=dict(text='Target distribution'),\n                  xaxis=dict(title='Survived values'),\n                  yaxis=dict(title='counts'))\n\n## 5. Show the Figure\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:31.876178Z","iopub.execute_input":"2022-06-22T02:53:31.876783Z","iopub.status.idle":"2022-06-22T02:53:32.021221Z","shell.execute_reply.started":"2022-06-22T02:53:31.876747Z","shell.execute_reply":"2022-06-22T02:53:32.020412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"3.4\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>3.4 Numerical Features</center></h2>","metadata":{}},{"cell_type":"code","source":"## Statistics of training data\ntrain_df[numerical_features].describe().T.style.bar(subset=['mean'],)\\\n                        .background_gradient(subset=['std'], cmap='coolwarm')\\\n                        .background_gradient(subset=['50%'], cmap='coolwarm')\\\n                        .background_gradient(subset=['max'], cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:32.022568Z","iopub.execute_input":"2022-06-22T02:53:32.023204Z","iopub.status.idle":"2022-06-22T02:53:32.119377Z","shell.execute_reply.started":"2022-06-22T02:53:32.023162Z","shell.execute_reply":"2022-06-22T02:53:32.118399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Statistics of test data\ntest_df[numerical_features].describe().T.style.bar(subset=['mean'],)\\\n                        .background_gradient(subset=['std'], cmap='coolwarm')\\\n                        .background_gradient(subset=['50%'], cmap='coolwarm')\\\n                        .background_gradient(subset=['max'], cmap='coolwarm')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:32.120744Z","iopub.execute_input":"2022-06-22T02:53:32.121069Z","iopub.status.idle":"2022-06-22T02:53:32.1542Z","shell.execute_reply.started":"2022-06-22T02:53:32.12104Z","shell.execute_reply":"2022-06-22T02:53:32.15288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Interactive Heatmap of Correlation Matrix with plotly\ntrain_numerical = train_df[numerical_features + ['Survived']]\n\nfig = px.imshow(train_numerical.corr(),\n                color_continuous_scale='RdBu_r',\n                color_continuous_midpoint=0, \n                aspect='auto')\nfig.update_layout(height=300, \n                  width=300,\n                  title = \"Heatmap\",                  \n                  showlegend=False)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:32.155788Z","iopub.execute_input":"2022-06-22T02:53:32.156283Z","iopub.status.idle":"2022-06-22T02:53:33.108448Z","shell.execute_reply.started":"2022-06-22T02:53:32.156229Z","shell.execute_reply":"2022-06-22T02:53:33.106995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plotting distribution of numerical features with seaborn\nbins = 20\nfig = plt.figure(figsize=(10, 5))\nfor i, nf in enumerate(numerical_features):\n    ax = fig.add_subplot(1, 2, i+1)\n    sns.histplot(data=train_df,\n                 x=nf,\n                 bins=bins,\n                 kde=True,\n                 hue=target,\n                 ax=ax)\n    plt.title(nf)\n    plt.xlabel(None)\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:33.110202Z","iopub.execute_input":"2022-06-22T02:53:33.110608Z","iopub.status.idle":"2022-06-22T02:53:33.851592Z","shell.execute_reply.started":"2022-06-22T02:53:33.110575Z","shell.execute_reply":"2022-06-22T02:53:33.850686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Fill NaN in numerical columns with its median\ntrain_df[numerical_features] = train_df[numerical_features].fillna(train_df[numerical_features].median()) \ntest_df[numerical_features] = test_df[numerical_features].fillna(train_df[numerical_features].median()) ","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:33.852866Z","iopub.execute_input":"2022-06-22T02:53:33.853193Z","iopub.status.idle":"2022-06-22T02:53:33.866841Z","shell.execute_reply.started":"2022-06-22T02:53:33.853163Z","shell.execute_reply":"2022-06-22T02:53:33.865518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Binning for Numerical Features","metadata":{}},{"cell_type":"code","source":"## Binning for \"Age\"\nage_bins = np.array([i*5 for i in range(18)])\nage_bins","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:53:33.868279Z","iopub.execute_input":"2022-06-22T02:53:33.869409Z","iopub.status.idle":"2022-06-22T02:53:33.87991Z","shell.execute_reply.started":"2022-06-22T02:53:33.869341Z","shell.execute_reply":"2022-06-22T02:53:33.878681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Binning for \"Fare\"\nfare_mean = train_df['Fare'].mean()\nprint(f'fare mean: {fare_mean}\\n')\n\nfare_quantiles = train_df['Fare'].quantile([0, 0.05, 0.1, 0.5, 0.8, 0.9, 0.95, 0.99, 1])\nprint(f'fare quantiles: {fare_quantiles}\\n')\n\nfare_uniques = train_df['Fare'].unique()\nfare_uniques.sort()\nprint(f'fare uniques: {fare_uniques}\\n')\n\nfare_bins = np.array([0, 10, 20, 30, 40, 50, 75, 100, 200, 500, 1_000])\nprint(f'fare_bins: {fare_bins}\\n')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:53:33.881469Z","iopub.execute_input":"2022-06-22T02:53:33.881966Z","iopub.status.idle":"2022-06-22T02:53:33.905337Z","shell.execute_reply.started":"2022-06-22T02:53:33.88193Z","shell.execute_reply":"2022-06-22T02:53:33.904416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def binning(dataframe, column, bins):\n    df = dataframe.copy()\n    splits = pd.cut(df[column], \n                    bins=bins, \n                    labels=False, ## For return of integer index.\n                    right=False)\n    df[column] = splits\n    return df\n\n## Binning for numerical features\ntrain = binning(train_df, 'Age', age_bins)\ntrain = binning(train, 'Fare', fare_bins)\n\ntest = binning(test_df, 'Age', age_bins)\ntest = binning(test, 'Fare', fare_bins)\n\n## After binning, 'Age' and 'Fare' become categorical features.\ncategorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked', 'Age', 'Fare']","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:33.906582Z","iopub.execute_input":"2022-06-22T02:53:33.907544Z","iopub.status.idle":"2022-06-22T02:53:33.92073Z","shell.execute_reply.started":"2022-06-22T02:53:33.907507Z","shell.execute_reply":"2022-06-22T02:53:33.91975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"3.5\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>3.5 Categorical Features</center></h2>","metadata":{}},{"cell_type":"code","source":"## Plotting distribution of categorical features with seaborn\nfig = plt.figure(figsize=(10, 20))\nfor i, cf in enumerate(categorical_features):\n    ax = fig.add_subplot(4, 2, i+1)\n    sns.histplot(data=train_df,\n                 x=cf,\n                 hue=target,\n                 kde=False,\n                 ax=ax)\n    plt.title(cf)\n    plt.xlabel(None)\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:33.922178Z","iopub.execute_input":"2022-06-22T02:53:33.922963Z","iopub.status.idle":"2022-06-22T02:53:38.395614Z","shell.execute_reply.started":"2022-06-22T02:53:33.922926Z","shell.execute_reply":"2022-06-22T02:53:38.394355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering on 'Cabin'","metadata":{}},{"cell_type":"code","source":"train_df['Cabin'].unique()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:53:38.396862Z","iopub.execute_input":"2022-06-22T02:53:38.397192Z","iopub.status.idle":"2022-06-22T02:53:38.405101Z","shell.execute_reply.started":"2022-06-22T02:53:38.397162Z","shell.execute_reply":"2022-06-22T02:53:38.403994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cabin_alphabet(cabin):\n    if cabin is np.NaN:\n        return 'NA'\n    else:\n        return cabin[0]\n    \ntrain['Cabin_alphabet'] = train['Cabin'].map(get_cabin_alphabet)\ntest['Cabin_alphabet'] = test['Cabin'].map(get_cabin_alphabet)\n\ntrain = train.drop('Cabin', axis=1)\ntest = test.drop('Cabin', axis=1)\n\ncategorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin_alphabet', 'Embarked', 'Age', 'Fare']","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:38.406401Z","iopub.execute_input":"2022-06-22T02:53:38.406793Z","iopub.status.idle":"2022-06-22T02:53:38.421481Z","shell.execute_reply.started":"2022-06-22T02:53:38.40676Z","shell.execute_reply":"2022-06-22T02:53:38.420738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plotting distribution of 'Cabin_alphabet' with seaborn\nsns.histplot(data=train,\n             x='Cabin_alphabet',\n             hue=target,\n             kde=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:38.42383Z","iopub.execute_input":"2022-06-22T02:53:38.424782Z","iopub.status.idle":"2022-06-22T02:53:38.694117Z","shell.execute_reply.started":"2022-06-22T02:53:38.424734Z","shell.execute_reply":"2022-06-22T02:53:38.69308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Encoding","metadata":{}},{"cell_type":"code","source":"## Fill NaN in categorical columns with its mode\ntrain[categorical_features] = train[categorical_features].fillna(train[categorical_features].mode().iloc[0])  \ntest[categorical_features] = test[categorical_features].fillna(train[categorical_features].mode().iloc[0])  ","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:38.695378Z","iopub.execute_input":"2022-06-22T02:53:38.695739Z","iopub.status.idle":"2022-06-22T02:53:38.720325Z","shell.execute_reply.started":"2022-06-22T02:53:38.695708Z","shell.execute_reply":"2022-06-22T02:53:38.71952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_encode(categorical_features,\n              train,\n              test,\n              valid=None,\n              encoding='one_hot',\n              encoder=None,\n              return_encoder=False):\n    \n    if encoder is not None:\n        enc = encoder\n    else:\n        if encoding == 'one_hot':\n            enc = preprocessing.OneHotEncoder(handle_unknown='ignore',\n                                              sparse=False,\n                                              dtype=np.int32)\n        elif encoding == 'label':\n            enc = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',\n                                               unknown_value=-1,\n                                               dtype=np.int32)\n        enc.fit(train[categorical_features])\n        \n    train_categorical = pd.DataFrame(enc.transform(train[categorical_features]),\n                                     columns=enc.get_feature_names())\n    test_categorical = pd.DataFrame(enc.transform(test[categorical_features]),\n                                    columns=enc.get_feature_names())\n    \n    if valid is not None:\n        valid_categorical = pd.DataFrame(enc.transform(valid[categorical_features]),\n                                         columns=enc.get_feature_names())\n        if return_encoder:\n            return train_categorical, valid_categorical, test_categorical, enc\n        else:\n            return train_categorical, valid_categorical, test_categorical\n        \n    else:\n        if return_encoder:\n            return train_categorical, test_categorical, enc\n        else:\n            return train_categorical, test_categorical","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:38.721452Z","iopub.execute_input":"2022-06-22T02:53:38.722421Z","iopub.status.idle":"2022-06-22T02:53:38.734557Z","shell.execute_reply.started":"2022-06-22T02:53:38.722387Z","shell.execute_reply":"2022-06-22T02:53:38.733503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## One-Hot Encoding\nencoding = exp_config['encoding']\n\n_, _, enc = df_encode(categorical_features,\n                      train,\n                      test,\n                      encoding=encoding,\n                      return_encoder=True)\n\ntrain, test = df_encode(categorical_features,\n                        train,\n                        test,\n                        encoding=encoding,\n                        encoder=enc)\n\ntrain[target] = train_df[target]\nprint(train.columns)\nprint(train.shape, test.shape)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:53:38.735777Z","iopub.execute_input":"2022-06-22T02:53:38.7362Z","iopub.status.idle":"2022-06-22T02:53:38.784774Z","shell.execute_reply.started":"2022-06-22T02:53:38.73617Z","shell.execute_reply":"2022-06-22T02:53:38.783439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"3.6\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>3.6 Validation Split</center></h2>","metadata":{}},{"cell_type":"code","source":"## K-Fold validation split\nn_splits = exp_config['n_splits']\n\n#kf = KFold(n_splits=n_splits)\nskf = StratifiedKFold(n_splits=n_splits)\n\ntrain['k_folds'] = -1\n\n#for fold, (train_idx, valid_idx) in enumerate(kf.split(train)):\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(X=train,\n                                                        y=train[target])):\n    train['k_folds'][valid_idx] = fold\n        \nfor i in range(n_splits):\n    print(f\"fold {i}: {len(train.query('k_folds==@i'))} samples\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:53:38.786355Z","iopub.execute_input":"2022-06-22T02:53:38.787671Z","iopub.status.idle":"2022-06-22T02:53:38.837055Z","shell.execute_reply.started":"2022-06-22T02:53:38.787602Z","shell.execute_reply":"2022-06-22T02:53:38.835986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Hold-out validation split\nvalid_fold = train.query('k_folds == 0').reset_index(drop=True)\ntrain_fold = train.query('k_folds != 0').reset_index(drop=True)\n\ntrain_fold = train_fold.drop(['k_folds'], axis=1)\nvalid_fold = valid_fold.drop(['k_folds'], axis=1)\n\nprint(len(train_fold), len(valid_fold))","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:38.841828Z","iopub.execute_input":"2022-06-22T02:53:38.842265Z","iopub.status.idle":"2022-06-22T02:53:38.864321Z","shell.execute_reply.started":"2022-06-22T02:53:38.842221Z","shell.execute_reply":"2022-06-22T02:53:38.862869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"4\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>4. Deep Learning</center></h1>","metadata":{}},{"cell_type":"markdown","source":"<a id =\"4.1\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>4.1 Creating Dataset</center></h2>","metadata":{}},{"cell_type":"markdown","source":"---\n## [TPU] Batch size ##\n\nTo go fast on a TPU, increase the batch size. The rule of thumb is to use batches of 128 elements per core (ex: batch size of 128*8=1024 for a TPU with 8 cores). At this size, the 128x128 hardware matrix multipliers of the TPU (see hardware section below) are most likely to be kept busy. You start seeing interesting speedups from a batch size of 8 per core though. In the sample above, the batch size is scaled with the core count through this line of code:","metadata":{}},{"cell_type":"code","source":"if tpu:\n    n_sample_per_TPU_core = exp_config['n_sample_per_TPU_core']\n    batch_size = n_sample_per_TPU_core * strategy.num_replicas_in_sync\nelse:\n    batch_size = exp_config['batch_size']","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:38.865733Z","iopub.execute_input":"2022-06-22T02:53:38.866786Z","iopub.status.idle":"2022-06-22T02:53:38.876243Z","shell.execute_reply.started":"2022-06-22T02:53:38.866749Z","shell.execute_reply":"2022-06-22T02:53:38.87511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"def df_to_dataset(data_frame,\n                  target_column=None,\n                  shuffle=False, repeat=False,\n                  batch_size=5, drop_remainder=False):\n    \n    df = data_frame.copy()\n    \n    if target_column is not None:\n        target = df.pop(target_column) ##PandasArray\n        data = df.values\n        ds = tf.data.Dataset.from_tensor_slices((data, target))\n    else:\n        data = df.values\n        ds = tf.data.Dataset.from_tensor_slices(data)\n        \n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(df))\n    if repeat:\n        ds = ds.repeat()\n    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n    ds = ds.prefetch(batch_size)\n    \n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:38.877729Z","iopub.execute_input":"2022-06-22T02:53:38.878302Z","iopub.status.idle":"2022-06-22T02:53:38.897025Z","shell.execute_reply.started":"2022-06-22T02:53:38.878264Z","shell.execute_reply":"2022-06-22T02:53:38.895772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Create datasets\nbatch_size = exp_config['batch_size']\n\ntrain_ds = df_to_dataset(train_fold,\n                         target_column=target,\n                         shuffle=True,\n                         repeat=False,\n                         batch_size=batch_size,\n                         drop_remainder=False,)\n    \nvalid_ds = df_to_dataset(valid_fold,\n                         target_column=target,\n                         shuffle=False,\n                         repeat=False,\n                         batch_size=batch_size,\n                         drop_remainder=False,)\n\nf, t = next(iter(train_ds))\nprint(f.shape, t.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:38.898672Z","iopub.execute_input":"2022-06-22T02:53:38.899094Z","iopub.status.idle":"2022-06-22T02:53:39.047879Z","shell.execute_reply.started":"2022-06-22T02:53:38.899058Z","shell.execute_reply":"2022-06-22T02:53:39.047152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"4.2\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>4.2 Creating Model</center></h2>","metadata":{}},{"cell_type":"code","source":"def create_training_model(input_shape, model_units=[128,], dropout_rates=[0.2]):\n    \n    model_inputs = layers.Input(shape=input_shape)\n    x = model_inputs\n    \n    for units, dropout_rate in zip(model_units, dropout_rates):\n        feedforward = keras.Sequential([\n            layers.Dense(units, use_bias=False),\n            layers.BatchNormalization(),\n            layers.ReLU(),\n            layers.Dropout(dropout_rate),\n        ])\n        x = feedforward(x)\n        \n    final_layer = layers.Dense(units=1, activation=None)\n    model_outputs = final_layer(x)\n    \n    training_model = tf.keras.Model(inputs=model_inputs,\n                                    outputs=model_outputs)\n    return training_model","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:39.048904Z","iopub.execute_input":"2022-06-22T02:53:39.049553Z","iopub.status.idle":"2022-06-22T02:53:39.05752Z","shell.execute_reply.started":"2022-06-22T02:53:39.049521Z","shell.execute_reply":"2022-06-22T02:53:39.056633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"--- \n## [TPU] Model on TPUs ##\n\nThe strategy scope instructs Tensorflow to instantiate all the variables of the model in the memory of the TPU. The TPUClusterResolver.connect() call automatically enters the TPU device scope which instructs Tensorflow to run Tensorflow operations on the TPU. ","metadata":{}},{"cell_type":"code","source":"## Create training model\ninput_shape = model_config['model_input_shape']\nmodel_units = model_config['model_units']\ndropout_rates = model_config['dropout_rates']\n\nif tpu:\n    with strategy.scope():\n        training_model = create_training_model(input_shape=input_shape,\n                                               model_units=model_units, \n                                               dropout_rates=dropout_rates)\nelse:\n    training_model = create_training_model(input_shape=input_shape,\n                                           model_units=model_units, \n                                           dropout_rates=dropout_rates)\n\n## Model compile and build\nlr = exp_config['learning_rate']\nlabel_smoothing = exp_config['label_smoothing']\noptimizer = keras.optimizers.Adam(learning_rate=lr)\nloss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n                                             label_smoothing=label_smoothing)\n\ntraining_model.compile(optimizer=optimizer,\n                       loss=loss_fn,\n                       metrics=['acc'])\n\ntraining_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:39.058831Z","iopub.execute_input":"2022-06-22T02:53:39.060008Z","iopub.status.idle":"2022-06-22T02:53:39.624539Z","shell.execute_reply.started":"2022-06-22T02:53:39.059969Z","shell.execute_reply":"2022-06-22T02:53:39.623032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"<a id =\"4.3\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>4.3 Training Model</center></h2>","metadata":{}},{"cell_type":"markdown","source":"---\n## [TPU] Model saving/loading on TPUs ##\nWhen loading and saving models TPU models from/to the local disk, the `experimental_io_device `option must be used. It can be omitted if writing to GCS because TPUs have direct access to GCS. This option does nothing on GPUs.\n\nTPU users will remember that in order to train a model on TPU, you have to instantiate the model in a TPUStrategy scope. The strategy scope instructs Tensorflow to instantiate all the variables of the model in the memory of the TPU. The TPUClusterResolver.connect() call automatically enters the TPU device scope which instructs Tensorflow to run Tensorflow operations on the TPU. Now if you call model.save('./model') when you are connected to a TPU, Tensorflow will try to run the save operations on the TPU and since the TPU is a network-connected accelerator that has no access to your local disk, the operation will fail. Notice that saving to GCS will work though. The TPU does have access to GCS. If you want to save a TPU model to your local disk, you need to run the saving operation on your local machine and that is what the `experimental_io_device='/job:localhost'` flag does.","metadata":{}},{"cell_type":"code","source":"def model_training(training_model,\n                   train_ds,\n                   vali_ds,\n                   epochs,\n                   batch_size,\n                   steps_per_epoch,\n                   verbose=1,\n                   fold=None,\n                   model_save=True):\n    \n    ## For saving the best model\n    checkpoint_filepath = exp_config['checkpoint_filepath'] ## './tmp/model/exp.ckpt'\n    if fold is not None:\n        l = checkpoint_filepath.split('/')  ## ['.', 'tmp', 'model', 'exp.ckpt']\n        l[2] = l[2] + '_' + str(fold)\n        checkpoint_filepath = '/'.join(l) ## f'./tmp/model_{fold}/exp.ckpt'\n        \n    if tpu:\n        save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n            filepath=checkpoint_filepath, \n            save_weights_only=False, \n            monitor='val_loss', \n            mode='min', \n            save_best_only=True,\n            options=save_locally)  \n    else:\n        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n            filepath=checkpoint_filepath, \n            save_weights_only=True, \n            monitor='val_loss', \n            mode='min', \n            save_best_only=True)\n        \n    ## For the adjustment of learning rate\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=3,\n        cooldown=10,\n        min_lr=1e-5,\n        verbose=verbose)\n    \n    if model_save:\n        callbacks = [model_checkpoint_callback, reduce_lr]\n    else:\n        callbacks = [reduce_lr]\n    \n    ## Model training\n    history = training_model.fit(train_ds,\n                                 epochs=epochs,\n                                 shuffle=True,\n                                 validation_data=valid_ds,\n                                 callbacks=callbacks,\n                                 verbose=verbose,\n                                 )\n    \n    ## Load the best parameters\n    if model_save:\n        if tpu:\n            with strategy.scope():\n                load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n                training_model = tf.keras.models.load_model(checkpoint_filepath,\n                                                            options=load_locally)\n        else:\n            training_model.load_weights(checkpoint_filepath)\n        \n    return history","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:39.626245Z","iopub.execute_input":"2022-06-22T02:53:39.626726Z","iopub.status.idle":"2022-06-22T02:53:39.642086Z","shell.execute_reply.started":"2022-06-22T02:53:39.626681Z","shell.execute_reply":"2022-06-22T02:53:39.640914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"## Settings for Training\nepochs = exp_config['train_epochs']\nbatch_size = exp_config['batch_size']\nsteps_per_epoch = len(train_ds)//batch_size \n\nhistory = model_training(training_model,\n                         train_ds,\n                         valid_ds,\n                         epochs,\n                         batch_size,\n                         steps_per_epoch,\n                         verbose=1,\n                         fold=None)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:53:39.643606Z","iopub.execute_input":"2022-06-22T02:53:39.644011Z","iopub.status.idle":"2022-06-22T02:53:48.144151Z","shell.execute_reply.started":"2022-06-22T02:53:39.643977Z","shell.execute_reply":"2022-06-22T02:53:48.14278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot the train and valid losses\ndef plot_history(hist, title=None, valid=True):\n    plt.figure(figsize=(7, 5))\n    plt.plot(np.array(hist.index), hist['loss'], label='Train Loss')\n    if valid:\n        plt.plot(np.array(hist.index), hist['val_loss'], label='Valid Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title(title)\n    plt.show()\n    \nhist = pd.DataFrame(history.history)\nplot_history(hist)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:48.145975Z","iopub.execute_input":"2022-06-22T02:53:48.146954Z","iopub.status.idle":"2022-06-22T02:53:48.361736Z","shell.execute_reply.started":"2022-06-22T02:53:48.146905Z","shell.execute_reply":"2022-06-22T02:53:48.361015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"4.4\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>4.4 Inference</center></h2>","metadata":{}},{"cell_type":"code","source":"## Create test dataset\ntest_ds = df_to_dataset(test,\n                        target_column=None,\n                        shuffle=False,\n                        repeat=False,\n                        batch_size=batch_size,\n                        drop_remainder=False,)\n\nf = next(iter(test_ds))\nprint(f.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:48.362711Z","iopub.execute_input":"2022-06-22T02:53:48.3634Z","iopub.status.idle":"2022-06-22T02:53:48.376775Z","shell.execute_reply.started":"2022-06-22T02:53:48.363367Z","shell.execute_reply":"2022-06-22T02:53:48.37527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = training_model.predict(test_ds)\nprobs = tf.math.sigmoid(logits)\nprobs = np.squeeze(probs)\npreds = np.where(probs < 0.5, 0, 1)\n\nsubmission_df[target] = preds\n\nsubmission_df.to_csv('submission_dnn.csv', index=False)\nsubmission_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:48.378715Z","iopub.execute_input":"2022-06-22T02:53:48.37962Z","iopub.status.idle":"2022-06-22T02:53:48.563856Z","shell.execute_reply.started":"2022-06-22T02:53:48.379564Z","shell.execute_reply":"2022-06-22T02:53:48.562552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"5\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>5. Optimization</center></h1>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://www.preferred.jp/wp-content/themes/preferred/assets/img/projects/optuna/pict01.jpg\" width=\"200\"/>\n\n[Optuna™](https://www.preferred.jp/en/projects/optuna/) is an open-source automatic hyperparameter optimization framework. It automatically finds optimal hyperparameter values based on an optimization target.","metadata":{}},{"cell_type":"code","source":"def create_trial_model(trial):\n    model = keras.Sequential()\n    model.add(layers.Input(shape=model_config['model_input_shape']))\n    \n    activation = trial.suggest_categorical('activation', ['relu', 'gelu', 'selu'])\n    n_layers = trial.suggest_int('n_layers', 1, 3)\n    for i in range(n_layers):\n        n_units = trial.suggest_discrete_uniform(f'units_{i}', 24, 256, 12)\n        dropout_rate = trial.suggest_uniform(f'dropout_{i}', 0, 0.5)\n        model.add(layers.Dense(n_units, use_bias=True, activation=activation))\n        model.add(layers.BatchNormalization())\n        model.add(layers.Dropout(dropout_rate))\n    model.add(layers.Dense(units=1, activation=None))\n    \n    lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n    label_smoothing = trial.suggest_uniform('label_smoothing', 0, 0.2)\n    optimizer = keras.optimizers.Adam(learning_rate=lr)\n    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n                                                 label_smoothing=label_smoothing)\n    model.compile(optimizer=optimizer,\n                  loss=loss_fn,\n                  metrics=['acc'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:48.565211Z","iopub.execute_input":"2022-06-22T02:53:48.56554Z","iopub.status.idle":"2022-06-22T02:53:48.577849Z","shell.execute_reply.started":"2022-06-22T02:53:48.565511Z","shell.execute_reply":"2022-06-22T02:53:48.576724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    if tpu:\n        with strategy.scope():\n            compiled_model = create_trial_model(trial)\n    else:\n        compiled_model = create_trial_model(trial)\n        \n    epochs = opt_config['opt_epochs']\n    batch_size = opt_config['opt_batch_size']\n    steps_per_epoch = len(train_ds)//batch_size \n        \n    history = model_training(compiled_model,\n                             train_ds,\n                             valid_ds,\n                             epochs,\n                             batch_size,\n                             steps_per_epoch,\n                             verbose=0,\n                             fold=None,\n                             model_save=False)\n    \n    return min(history.history['val_loss'])","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:53:48.579109Z","iopub.execute_input":"2022-06-22T02:53:48.579448Z","iopub.status.idle":"2022-06-22T02:53:48.59627Z","shell.execute_reply.started":"2022-06-22T02:53:48.579419Z","shell.execute_reply":"2022-06-22T02:53:48.59541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if opt_config['opt_flg']:\n    import optuna\n    n_trials = opt_config['opt_trials']\n    study = optuna.create_study(direction='minimize')\n    study.optimize(objective, n_trials=n_trials)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:53:48.598112Z","iopub.execute_input":"2022-06-22T02:53:48.599028Z","iopub.status.idle":"2022-06-22T02:56:06.693471Z","shell.execute_reply.started":"2022-06-22T02:53:48.598979Z","shell.execute_reply":"2022-06-22T02:56:06.692718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if opt_config['opt_flg']:\n    best_params = study.best_params\n    pprint.pprint(best_params)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:56:06.69457Z","iopub.execute_input":"2022-06-22T02:56:06.695034Z","iopub.status.idle":"2022-06-22T02:56:06.702129Z","shell.execute_reply.started":"2022-06-22T02:56:06.695002Z","shell.execute_reply":"2022-06-22T02:56:06.700836Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:56:23.898126Z","iopub.execute_input":"2022-06-22T02:56:23.89859Z","iopub.status.idle":"2022-06-22T02:56:23.922399Z","shell.execute_reply.started":"2022-06-22T02:56:23.898556Z","shell.execute_reply":"2022-06-22T02:56:23.921747Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_slice(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:57:31.391557Z","iopub.execute_input":"2022-06-22T02:57:31.392135Z","iopub.status.idle":"2022-06-22T02:57:31.635464Z","shell.execute_reply.started":"2022-06-22T02:57:31.392081Z","shell.execute_reply":"2022-06-22T02:57:31.633914Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"6\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>6. Cross Validation and Ensebmling</center></h1>","metadata":{}},{"cell_type":"code","source":"if exp_config['cross_validation']:\n    ## Settings for Training\n    batch_size = exp_config['batch_size']\n    \n    cv_results = submission_df.drop('Survived', axis=1)\n    cv_results['probs_mean'] = 0.\n    \n    ## Create test dataset\n    test_ds = df_to_dataset(test,\n                            target_column=None,\n                            shuffle=False,\n                            repeat=False,\n                            batch_size=batch_size,\n                            drop_remainder=False,)\n    \n    ## Create cross validation samples\n    for fold in range(exp_config['n_splits']):\n        valid_fold = train.query(f'k_folds == {fold}').reset_index(drop=True)\n        train_fold = train.query(f'k_folds != {fold}').reset_index(drop=True)\n        \n        train_fold = train_fold.drop(['k_folds'], axis=1)\n        valid_fold = valid_fold.drop(['k_folds'], axis=1)\n        \n        ## Create datasets\n        train_ds = df_to_dataset(train_fold,\n                                 target_column=target,\n                                 shuffle=True,\n                                 repeat=False,\n                                 batch_size=batch_size,\n                                 drop_remainder=False,)\n        \n        valid_ds = df_to_dataset(valid_fold,\n                                 target_column=target,\n                                 shuffle=False,\n                                 repeat=False,\n                                 batch_size=batch_size,\n                                 drop_remainder=False,)\n        \n        ## Create training model\n        input_shape = model_config['model_input_shape']\n        model_units = model_config['model_units']\n        dropout_rates = model_config['dropout_rates']\n        \n        if tpu:\n            with strategy.scope():\n                training_model = create_training_model(input_shape=input_shape,\n                                                       model_units=model_units, \n                                                       dropout_rates=dropout_rates)\n        else:\n            training_model = create_training_model(input_shape=input_shape,\n                                                   model_units=model_units, \n                                                   dropout_rates=dropout_rates)\n            \n        ## Model compile and build\n        lr = exp_config['learning_rate']\n        label_smoothing = exp_config['label_smoothing']\n        optimizer = keras.optimizers.Adam(learning_rate=lr)\n        loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n                                                     label_smoothing=label_smoothing)\n        training_model.compile(optimizer=optimizer,\n                               loss=loss_fn,\n                               metrics=['acc'])\n        \n        ## Model training\n        epochs = exp_config['train_epochs']\n        batch_size = exp_config['batch_size']\n        steps_per_epoch = len(train_ds)//batch_size \n        \n        history = model_training(training_model,\n                                 train_ds,\n                                 valid_ds,\n                                 epochs,\n                                 batch_size,\n                                 steps_per_epoch,\n                                 verbose=0,\n                                 fold=fold)\n        \n        ## Plot the train and valid losses\n        hist = pd.DataFrame(history.history)\n        plot_history(hist, title=f'fold: {fold}')\n        \n        ## Inference\n        logits = training_model.predict(test_ds)\n        probs = tf.math.sigmoid(logits)\n        probs = np.squeeze(probs)\n        cv_results[f'prods_{fold}'] = probs\n        cv_results['probs_mean'] += probs\n        \n    ## Ensebmle the inferences of cross-validations\n    cv_results['probs_mean'] /= exp_config['n_splits']\n    probs_mean = cv_results['probs_mean'].values\n    preds = np.where(probs_mean > 0.5, 1, 0)\n    submission_df[target] = preds\n    \n    submission_df.to_csv('submission_cv.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:56:07.005059Z","iopub.execute_input":"2022-06-22T02:56:07.005716Z","iopub.status.idle":"2022-06-22T02:56:16.159598Z","shell.execute_reply.started":"2022-06-22T02:56:07.005667Z","shell.execute_reply":"2022-06-22T02:56:16.157972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if exp_config['cross_validation']:\n    submission_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:56:16.160746Z","iopub.status.idle":"2022-06-22T02:56:16.161198Z","shell.execute_reply.started":"2022-06-22T02:56:16.160949Z","shell.execute_reply":"2022-06-22T02:56:16.160967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if exp_config['cross_validation']:\n    cv_results.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:56:16.16264Z","iopub.status.idle":"2022-06-22T02:56:16.163001Z","shell.execute_reply.started":"2022-06-22T02:56:16.162839Z","shell.execute_reply":"2022-06-22T02:56:16.162855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"7\"></a><h1 style=\"background:#05445E; border:0; border-radius: 12px; color:#D3D3D3\"><center>7. AutoML</center></h1>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://docs.h2o.ai/h2o/latest-stable/h2o-docs/_images/h2o-automl-logo.jpg\" width=\"200\"/>\n\nAutoML (Automatic Machine Learning) is the process of automating algorithm selection, feature generation, hyperparameter tuning, iterative modeling, and model assessment. [H2O AutoML](https://h2o.ai/platform/h2o-automl/) can be used for automating the machine learning workflow with a simple interface in R, Python, or a web GUI.","metadata":{}},{"cell_type":"markdown","source":"<a id =\"7.1\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>7.1 Set up</center></h2>","metadata":{}},{"cell_type":"code","source":"## Install and Import dependencies\n#!pip install h2o -q\nimport h2o\nfrom h2o.automl import H2OAutoML\n\n## Initialize the H2O cluster\nh2o.init()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.164384Z","iopub.status.idle":"2022-06-22T02:56:16.16479Z","shell.execute_reply.started":"2022-06-22T02:56:16.16458Z","shell.execute_reply":"2022-06-22T02:56:16.164597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"7.2\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>7.2 Create Training Data</center></h2>","metadata":{}},{"cell_type":"code","source":"## Load the dataset as a H2OFrame\ntrain_h2o_df = h2o.import_file(data_config['train.csv'])\ntest_h2o_df = h2o.import_file(data_config['test.csv'])\n\n## How to make a H2OFrame from Pandas DataFrame\n#train_h2o_df = h2o.H2OFrame(train)\n#test_h2o_df = h2o.H2OFrame(test)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.166311Z","iopub.status.idle":"2022-06-22T02:56:16.166861Z","shell.execute_reply.started":"2022-06-22T02:56:16.166545Z","shell.execute_reply":"2022-06-22T02:56:16.166563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Describe the dataset\ntrain_h2o_df.describe(chunk_summary=False)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.167818Z","iopub.status.idle":"2022-06-22T02:56:16.168324Z","shell.execute_reply.started":"2022-06-22T02:56:16.168071Z","shell.execute_reply":"2022-06-22T02:56:16.168099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For classification, target should be encoded as categorical (aka. \"factor\" or \"enum\"). As described, `Survived` column is encoded as a 0/1 \"int\", thus we have to convert the column as follows:","metadata":{}},{"cell_type":"code","source":"## Convert the column into categorical\ntrain_h2o_df['Survived'] = train_h2o_df['Survived'].asfactor()\ntrain_h2o_df.describe()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.170212Z","iopub.status.idle":"2022-06-22T02:56:16.170915Z","shell.execute_reply.started":"2022-06-22T02:56:16.170578Z","shell.execute_reply":"2022-06-22T02:56:16.170609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"7.3\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>7.3 Run AutoML</center></h2>","metadata":{}},{"cell_type":"code","source":"## Create AutoML Models\naml = H2OAutoML(max_models=10,\n                exclude_algos=['GBM'],\n                max_runtime_secs=120,\n                balance_classes=True, ## This option is only applicable for classification.\n                seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:56:16.172817Z","iopub.status.idle":"2022-06-22T02:56:16.173427Z","shell.execute_reply.started":"2022-06-22T02:56:16.173121Z","shell.execute_reply":"2022-06-22T02:56:16.173148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `max_models` argument specifies the number of individual (or \"base\") models, and does not include the two ensemble models that are trained at the end. The current version of H2O AutoML trains and cross-validates the models in the following order:\n\n1. three pre-specified XGBoost GBM (Gradient Boosting Machine) models,\n2. a fixed grid of GLMs,\n3. a default Random Forest (DRF),\n4. five pre-specified H2O GBMs,\n5. a near-default Deep Neural Net,\n6. an Extremely Randomized Forest (XRT),\n7. a random grid of XGBoost GBMs,\n8. a random grid of H2O GBMs,\n9. and a random grid of Deep Neural Nets.\n\nIn addition, it also trains the two ensemble models:\n\n1. a stacked ensemble of all the models trained above\n2. a “Best of Family” Stacked Ensemble that contains the best performing model for each algorithm class\n\n**Nonte:** Particular algorithms (or groups of algorithms) can be switched on/off using the `include_algos` and`exclude_algos` argument.\n\nIn some cases, there will not be enough time to complete all the algorithms, so some may be missing from the leaderboard.","metadata":{}},{"cell_type":"code","source":"## Feature Selection\nx = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Age', 'Fare']\ny = 'Survived'\n\naml.train(training_frame=train_h2o_df,\n          x=x, y=y)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.175204Z","iopub.status.idle":"2022-06-22T02:56:16.175816Z","shell.execute_reply.started":"2022-06-22T02:56:16.17552Z","shell.execute_reply":"2022-06-22T02:56:16.175547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By default and when `nfolds` > 1, models will be evaluated using k-fold cross validation. Thus, when you would like to specify validation_frame for holdout validation, run the following codes:","metadata":{}},{"cell_type":"code","source":"#train_h2o, valid_h2o = train_h2o_df.split_frame(ratios=[0.8], seed=42)  ## Validation split\n#aml = H2OAutoML(max_models=10,\n#                exclude_algos=['GBM'],\n#                max_runtime_secs=120,\n#                balance_classes=True,\n#                nfolds=0,\n#                seed=42)\n#aml.train(training_frame=train_h2o,\n#          validation_frame=valid_h2o,\n#          leaderboard_frame=valid_h2o,\n#          x=x,　y=y,)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T02:56:16.177591Z","iopub.status.idle":"2022-06-22T02:56:16.178159Z","shell.execute_reply.started":"2022-06-22T02:56:16.177889Z","shell.execute_reply":"2022-06-22T02:56:16.177916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After the models are trained, we can compare the model performance using the leaderboard. When we did not specify a `leaderboard_frame` in the `H2OAutoML.train()` method, the AutoML leaderboard uses cross-validation metrics to score and rank the models.","metadata":{}},{"cell_type":"code","source":"lb = aml.leaderboard\nlb.head(rows=lb.nrows)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.179519Z","iopub.status.idle":"2022-06-22T02:56:16.180069Z","shell.execute_reply.started":"2022-06-22T02:56:16.179801Z","shell.execute_reply":"2022-06-22T02:56:16.179827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the case of binary classification, the default ranking metric is Area Under the ROC Curve (AUC).","metadata":{}},{"cell_type":"code","source":"## Get the top model of leaderboard\nbest_model = aml.leader\n#best_model = aml.get_best_model() ## same result\n\nprint(best_model)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.181551Z","iopub.status.idle":"2022-06-22T02:56:16.182126Z","shell.execute_reply.started":"2022-06-22T02:56:16.18184Z","shell.execute_reply":"2022-06-22T02:56:16.181865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Save and load the model\nmodel_path = h2o.save_model(model=best_model,\n                            path='./automl_model', \n                            force=True)\nprint(model_path)\nloaded_model = h2o.load_model(path=model_path)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.183984Z","iopub.status.idle":"2022-06-22T02:56:16.18461Z","shell.execute_reply.started":"2022-06-22T02:56:16.18436Z","shell.execute_reply":"2022-06-22T02:56:16.184387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Inference\nprobs = aml.predict(test_h2o_df)\n#probs = best_model.predict(test_h2o_df) ## same result\n\nprobs = h2o.as_list(probs) ## Convert to pandas DataFrame\npreds = probs['predict'].values\nsubmission_df[target] = preds\n\nsubmission_df.to_csv('submission_automl.csv', index=False)\nsubmission_df.head(20)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.186208Z","iopub.status.idle":"2022-06-22T02:56:16.18662Z","shell.execute_reply.started":"2022-06-22T02:56:16.186437Z","shell.execute_reply":"2022-06-22T02:56:16.186456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id =\"7.4\"></a><h2 style=\"background:#75E6DA; border:0; border-radius: 12px; color:black\"><center>7.4 Explainability</center></h2>","metadata":{}},{"cell_type":"markdown","source":"H2O AutoML provides insights into model’s global explainability (such as variable importance, partial dependence plot, SHAP values, and model correlation) and local explainability for individual records.","metadata":{}},{"cell_type":"code","source":"## Global explainability for models\nexplain_model = aml.explain(frame=train_h2o_df, figsize=(8, 6))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.18843Z","iopub.status.idle":"2022-06-22T02:56:16.188862Z","shell.execute_reply.started":"2022-06-22T02:56:16.188648Z","shell.execute_reply":"2022-06-22T02:56:16.188695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Local explainability for individual records\nrow_index = 1\naml.explain_row(frame=train_h2o_df, row_index=row_index, figsize=(8, 6))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-22T02:56:16.191778Z","iopub.status.idle":"2022-06-22T02:56:16.192194Z","shell.execute_reply.started":"2022-06-22T02:56:16.192014Z","shell.execute_reply":"2022-06-22T02:56:16.192033Z"},"trusted":true},"execution_count":null,"outputs":[]}]}