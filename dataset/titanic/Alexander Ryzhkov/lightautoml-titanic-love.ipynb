{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 0.0. Install LightAutoML","metadata":{}},{"cell_type":"code","source":"pip install -U lightautoml","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.1. Import necessary libraries ","metadata":{}},{"cell_type":"code","source":"# Standard python libraries\nimport os\nimport time\nimport re\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nimport torch\n\n# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\nfrom lightautoml.utils.profiler import Profiler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.2. Parameters ","metadata":{}},{"cell_type":"code","source":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 5 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 600 # Time in seconds for automl run","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.3. Fix torch number of threads and numpy seed ","metadata":{}},{"cell_type":"code","source":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.4. Data load ","metadata":{}},{"cell_type":"code","source":"%%time\n\ntrain_data = pd.read_csv('../input/titanic/train.csv')\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('../input/titanic/test.csv')\ntest_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/titanic/gender_submission.csv')\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.5. Add new features","metadata":{}},{"cell_type":"code","source":"def get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\ndef create_extra_features(data):\n    data['Ticket_type'] = data['Ticket'].map(lambda x: x[0:3])\n    data['Name_Words_Count'] = data['Name'].map(lambda x: len(x.split()))\n    data['Has_Cabin'] = data[\"Cabin\"].map(lambda x: 1 - int(type(x) == float))\n    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n    \n    data['CategoricalFare'] = pd.qcut(data['Fare'], 5).astype(str)\n    data['CategoricalAge'] = pd.cut(data['Age'], 5).astype(str)\n    \n    data['Title'] = data['Name'].apply(get_title).replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n    data['Title'] = data['Title'].replace('Ms', 'Miss')\n    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n    data['Title'] = data['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}).fillna(0)\n    return data\n\ntrain_data = create_extra_features(train_data)\ntest_data = create_extra_features(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 0.6. Data splitting for train-test ","metadata":{}},{"cell_type":"code","source":"tr_data, te_data = train_test_split(train_data, \n                                     test_size=TEST_SIZE, \n                                     stratify=train_data['Survived'], \n                                     random_state=RANDOM_STATE)\nprint('Data splitted. Parts sizes: tr_data = {}, te_data = {}'.format(tr_data.shape, te_data.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ========= AutoML preset usage =========\n\n\n## Step 1. Create Task","metadata":{}},{"cell_type":"code","source":"%%time\ndef acc_score(y_true, y_pred, **kwargs):\n    return accuracy_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\ndef f1_metric(y_true, y_pred, **kwargs):\n    return f1_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\ntask = Task('binary', metric = f1_metric)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2. Setup columns roles","metadata":{}},{"cell_type":"code","source":"%%time\n\nroles = {\n    'target': 'Survived',\n    'drop': ['PassengerId', 'Name','Ticket'],\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3. Create AutoML from preset and train on 80% of data","metadata":{}},{"cell_type":"code","source":"%%time \n\nautoml = TabularAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS})\noof_pred = automl.fit_predict(tr_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4. Predict to validation data and check scores","metadata":{}},{"cell_type":"code","source":"%%time\n\ntest_pred = automl.predict(te_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(acc_score(tr_data['Survived'].values, oof_pred.data[:, 0])))\nprint('TEST score: {}'.format(acc_score(te_data['Survived'].values, test_pred.data[:, 0])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    Score for `TabularAutoML` is 83.8% accuracy for OOF preds and 82.1% accuracy for validation preds in 2 minutes time. \n\n## Step 5. Create AutoML with time utilization ","metadata":{}},{"cell_type":"markdown","source":"Below we are going to create specific AutoML preset for TIMEOUT utilization (try to spend it as much as possible):","metadata":{}},{"cell_type":"code","source":"%%time \n\nautoml = TabularUtilizedAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS})\noof_pred = automl.fit_predict(tr_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","metadata":{"scrolled":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 6. Predict to validation data and check scores for utilized automl","metadata":{}},{"cell_type":"code","source":"%%time\n\ntest_pred = automl.predict(te_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(acc_score(tr_data['Survived'].values, oof_pred.data[:, 0])))\nprint('TEST score: {}'.format(acc_score(te_data['Survived'].values, test_pred.data[:, 0])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Score for `TabularUtilizedAutoML` is 85.5% accuracy for OOF preds and 82.7% accuracy for validation preds in 10 minutes. As the validation score is better for `TabularUtilizedAutoML` for this case, we choose it for final model retrain on full train dataset.\n\n## Step 7. Train on full data ","metadata":{}},{"cell_type":"code","source":"%%time \n\nautoml = TabularUtilizedAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS})\noof_pred = automl.fit_predict(train_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 8. Predict for test data and check OOF score","metadata":{}},{"cell_type":"code","source":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(acc_score(train_data['Survived'].values, oof_pred.data[:, 0])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 9. Prepare submission","metadata":{}},{"cell_type":"code","source":"submission['Survived'] = (test_pred.data[:, 0] > 0.5).astype(int)\nsubmission.to_csv('automl_utilized_600_f1_score.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission above scores 79.665% accuracy on public LB.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}