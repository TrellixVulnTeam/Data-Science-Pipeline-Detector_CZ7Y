{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# 50 Tips for Data Science for tabular data for beginners\n## Frequently used useful code for:\n* Import libraries\n* Data download\n* Data cleaning\n* FE\n* Modeling\n* Analysing, and visualization of modeling results\n* Prediction and submitting of modeling results\netc.\n\n### With BONUS - the short solution for Competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) with LB=0.80382 (Top 4%)\n\n### Part of tips from the first versions of the notebook see in a new notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)\n\nLater I will publish another notebook for EDA.","metadata":{"papermill":{"duration":0.030237,"end_time":"2020-11-15T02:05:17.81389","exception":false,"start_time":"2020-11-15T02:05:17.783653","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## It's done 50 tips: 1.1-1.5, 2.1-2.8, 3.1-3.3, 4.1-4.9, 5.1-5.7, 6.1-6.16, 7.1, 8\n### I improved \"Tip 2.7. Download json-data via API in Kaggle\"\n### I added: \n* \"Tip 4.8. EDA\"\n* \"Tip 4.9. Create a spreadsheet-style pivot table as a DataFrame\"\n*  Limited output in the \"Tip 3.1. Pandas option for output data\"\n*  new \"Tip 5.1. Get numeric features from the DataFrame\"\n*  new \"Tip 5.2. Get categorical features from the DataFrame\"","metadata":{}},{"cell_type":"markdown","source":"## Acknowledgements\n\n### Datasets:\n* for Classification task solutions - competition's dataset [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic)\n* for Classification task solutions - [Heart Disease UCI](https://www.kaggle.com/ronitf/heart-disease-uci)\n* for Regression task solutions - my dataset [Ammonium prediction in river water](https://www.kaggle.com/vbmokin/ammonium-prediction-in-river-water)\n* from API for Regression task solutions - official data of COVID-19 in Ukraine (https://covid19.rnbo.gov.ua/)\n* for NLP task - [NLP : Reports & News Classification](https://www.kaggle.com/vbmokin/nlp-reports-news-classification)\n\n### Notebooks:\n* [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)\n* [Data Science for tabular data: Advanced Techniques](https://www.kaggle.com/vbmokin/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https://www.kaggle.com/vbmokin/eda-for-tabular-data-advanced-techniques)\n* [Heart Disease - Automatic AdvEDA & FE & 20 models](https://www.kaggle.com/vbmokin/heart-disease-automatic-adveda-fe-20-models)\n* [COVID in UA: Prophet with 4, Nd seasonality](https://www.kaggle.com/vbmokin/covid-in-ua-prophet-with-4-nd-seasonality)\n* [Top score : one line of the prediction](https://www.kaggle.com/vbmokin/titanic-top-score-one-line-of-the-prediction)\n* [AI-ML-DS Training. L3AT: NH4 - NN models](https://www.kaggle.com/vbmokin/ai-ml-ds-training-l3at-nh4-nn-models)\n* https://www.dataschool.io/python-pandas-tips-and-tricks/\n* https://github.com/rougier/numpy-100","metadata":{"papermill":{"duration":0.028785,"end_time":"2020-11-15T02:05:18.049591","exception":false,"start_time":"2020-11-15T02:05:18.020806","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n## Table of Contents\n\n1. [Import main libraries](#1)\n    - [Tip 1.1. Import the most popular and useful main Python libraries](#1.1)\n    - [Tip 1.2. Warnings - ignore all](#1.2)\n    - [Tip 1.3. Ignore all warnings about later execution](#1.3)    \n    - [Tip 1.4. Install new libraries or packages with the given version](#1.4)\n    - [Tip 1.5. Import module or subpackage](#1.5)\n1. [Data download](#2)\n    - [Tip 2.1. Download typical csv-file to DataFrame](#2.1)\n    - [Tip 2.2. Download csv-file saved from MS Excel-file to DataFrame](#2.2)\n    - [Tip 2.3. Download csv-file with Cyrillic text to DataFrame](#2.3)\n    - [Tip 2.4. Download csv-file with given data types and NAN values](#2.4)\n    - [Tip 2.5. Download 1% data with random rows from big csv-file](#2.5)\n    - [Tip 2.6. Internally process the file in chunks (low_memory)](#2.6)    \n    - [Tip 2.7. Download json-data via API in Kaggle](#2.7)\n    - [Tip 2.8. Selection data from DataFrame (Pandas Tips)](#2.8)\n1. [Auxiliary functions](#3)\n    - [Tip 3.1. Pandas option for output data](#3.1)\n    - [Tip 3.2. The garbage collector](#3.2)\n    - [Tip 3.3. Time execution of a Python code in the cell](#3.3)\n1. [EDA & Data cleaning](#4)\n    - [Tip 4.1. Count of rows that match a condition](#4.1)\n    - [Tip 4.2. Combine the small categories into a single category named \"Other\"](#4.2)\n    - [Tip 4.3. Count the missing values](#4.3)\n    - [Tip 4.4. Convert one type of values to others](#4.4)\n    - [Tip 4.5. Replaced inf, -inf, nan to given value](#4.5)\n    - [Tip 4.6. Filtering the missing data in DataFrame](#4.6)\n    - [Tip 4.7. Generate descriptive statistics](#4.7)\n    - [Tip 4.8. EDA](#4.8)\n    - [Tip 4.9. Create a spreadsheet-style pivot table as a DataFrame](#4.9)    \n1. [FE](#5)\n    - [Tip 5.1. Get numeric features from the DataFrame](#5.1)\n    - [Tip 5.2. Get categorical features from the DataFrame](#5.2)\n    - [Tip 5.3. Search and encoding categorical columns](#5.3)\n    - [Tip 5.4. Difference or rolling of values in DataFrame](#5.4)\n    - [Tip 5.5. Data dropping (rows or columns removing) in DataFrame](#5.5)\n    - [Tip 5.6. Date in str format to date in datetime format in DataFrame](#5.6)\n    - [Tip 5.7. MinMaxScaling data in DataFrame](#5.7)\n1. [Modeling](#6)\n    - [Tip 6.1. Data preparation with standardization for modeling](#6.1)\n    - [Tip 6.2. Splitting data with train_test_split](#6.2)\n    - [Tip 6.3. Accuracy score for train and test prediction](#6.3)\n    - [Tip 6.4. Classification report](#6.4)\n    - [Tip 6.5. Linear Regression](#6.5)\n    - [Tip 6.6. Support Vector Machines](#6.6)\n    - [Tip 6.7. Linear SVC](#6.7)\n    - [Tip 6.8. Decision Tree Classifier & Regressor](#6.8)\n    - [Tip 6.9. Random Forest Classifier & Regressor](#6.9)\n    - [Tip 6.10. XGB Classifier](#6.10)\n    - [Tip 6.11. LGBM Classifier](#6.11)\n    - [Tip 6.12. Logistic Regression](#6.12)\n    - [Tip 6.13. k-Nearest Neighbors (KNN)](#6.13)\n    - [Tip 6.14. MLP Classifier](#6.14)\n    - [Tip 6.15. Voting Classifier](#6.15)\n    - [Tip 6.16. Feature importance diagram](#6.16)\n1. [Analysis and visualization of modeling results](#7)\n    - [Tip 7.1. Drawing plot data with modeling results](#7.1)\n    - [Tip 7.2. Drawing plot data of DataFrame (Pandas)](#7.2)\n1. [BONUS](#8)\n    - [Tip 8.1. Submission data from DataFrame to Kaggle competition](#8.1)","metadata":{"papermill":{"duration":0.029848,"end_time":"2020-11-15T02:05:18.108536","exception":false,"start_time":"2020-11-15T02:05:18.078688","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 1. Import main libraries<a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.028871,"end_time":"2020-11-15T02:05:18.166715","exception":false,"start_time":"2020-11-15T02:05:18.137844","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Tip 1.1. Import the most popular and useful main Python libraries<a class=\"anchor\" id=\"1.1\"></a>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.285751,"end_time":"2020-11-15T02:05:18.481628","exception":false,"start_time":"2020-11-15T02:05:18.195877","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-16T20:45:10.28Z","iopub.execute_input":"2021-10-16T20:45:10.280792Z","iopub.status.idle":"2021-10-16T20:45:11.085822Z","shell.execute_reply.started":"2021-10-16T20:45:10.280662Z","shell.execute_reply":"2021-10-16T20:45:11.084645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 1.2. Warnings - ignore all<a class=\"anchor\" id=\"1.2\"></a>","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:11.087925Z","iopub.execute_input":"2021-10-16T20:45:11.088334Z","iopub.status.idle":"2021-10-16T20:45:11.093778Z","shell.execute_reply.started":"2021-10-16T20:45:11.088289Z","shell.execute_reply":"2021-10-16T20:45:11.092654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 1.3. Ignore all warnings about later execution <a class=\"anchor\" id=\"1.3\"></a>\n","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:11.09504Z","iopub.execute_input":"2021-10-16T20:45:11.095321Z","iopub.status.idle":"2021-10-16T20:45:11.106136Z","shell.execute_reply.started":"2021-10-16T20:45:11.095292Z","shell.execute_reply":"2021-10-16T20:45:11.105139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 1.4. Install new libraries or packages with the given version<a class=\"anchor\" id=\"1.4\"></a>","metadata":{}},{"cell_type":"code","source":"!pip install pandas-profiling==2.11.0","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-16T20:45:11.107734Z","iopub.execute_input":"2021-10-16T20:45:11.108065Z","iopub.status.idle":"2021-10-16T20:45:20.076921Z","shell.execute_reply.started":"2021-10-16T20:45:11.108034Z","shell.execute_reply":"2021-10-16T20:45:20.075493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 1.5. Import module or subpackage <a class=\"anchor\" id=\"1.5\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.080642Z","iopub.execute_input":"2021-10-16T20:45:20.081126Z","iopub.status.idle":"2021-10-16T20:45:20.274128Z","shell.execute_reply.started":"2021-10-16T20:45:20.081084Z","shell.execute_reply":"2021-10-16T20:45:20.273016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data download<a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.028564,"end_time":"2020-11-15T02:05:18.539412","exception":false,"start_time":"2020-11-15T02:05:18.510848","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Tip 2.1. Download typical csv-file to DataFrame <a class=\"anchor\" id=\"2.1\"></a>","metadata":{}},{"cell_type":"code","source":"data_titanic = pd.read_csv('../input/titanic/train.csv')\ndata_titanic.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.275812Z","iopub.execute_input":"2021-10-16T20:45:20.276128Z","iopub.status.idle":"2021-10-16T20:45:20.324029Z","shell.execute_reply.started":"2021-10-16T20:45:20.276098Z","shell.execute_reply":"2021-10-16T20:45:20.323022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_health = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\ndata_health.tail(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.325268Z","iopub.execute_input":"2021-10-16T20:45:20.325554Z","iopub.status.idle":"2021-10-16T20:45:20.35274Z","shell.execute_reply.started":"2021-10-16T20:45:20.325526Z","shell.execute_reply":"2021-10-16T20:45:20.351783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 2.2. Download csv-file saved from MS Excel-file to DataFrame <a class=\"anchor\" id=\"2.2\"></a>\nMS Excel with saves csv-files with the default settings with the delimiter \";\"","metadata":{}},{"cell_type":"code","source":"data_water = pd.read_csv('../input/ammonium-prediction-in-river-water/PB_1996_2019_NH4.csv', sep=';')\ndata_water.tail(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.35423Z","iopub.execute_input":"2021-10-16T20:45:20.35464Z","iopub.status.idle":"2021-10-16T20:45:20.378389Z","shell.execute_reply.started":"2021-10-16T20:45:20.354597Z","shell.execute_reply":"2021-10-16T20:45:20.377097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_water['date'] = pd.to_datetime(data_water['Date'], format='%d.%m.%Y', errors='coerce').dt.to_period('m')\ndata_water = data_water[['ID_Station','date','NH4']]\ndisplay(data_water)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.379844Z","iopub.execute_input":"2021-10-16T20:45:20.380228Z","iopub.status.idle":"2021-10-16T20:45:20.413392Z","shell.execute_reply.started":"2021-10-16T20:45:20.380193Z","shell.execute_reply":"2021-10-16T20:45:20.412208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 2.3. Download csv-file with Cyrillic text to DataFrame <a class=\"anchor\" id=\"2.3\"></a>","metadata":{}},{"cell_type":"code","source":"data_nlp = pd.read_csv('../input/nlp-reports-news-classification/water_problem_nlp_ua_for_Kaggle_100.csv', delimiter=';', \n                 header=0, encoding='cp1251')\ndata_nlp.tail(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.414947Z","iopub.execute_input":"2021-10-16T20:45:20.415356Z","iopub.status.idle":"2021-10-16T20:45:20.44133Z","shell.execute_reply.started":"2021-10-16T20:45:20.415308Z","shell.execute_reply":"2021-10-16T20:45:20.440248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 2.4. Download csv-file with given data types and NAN values<a class=\"anchor\" id=\"2.4\"></a>\nThe data type \"Int64\" allows the presence of NAN values during import, in contrast to the data type \"int\"","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/nlp-reports-news-classification/water_problem_nlp_ua_for_Kaggle_100.csv', delimiter=';', \n                 header=0, encoding='cp1251', \n                 dtype = {'text': str, \n                          'env_problems': 'Int64',\n                          'pollution': 'Int64', \n                          'treatment': 'Int64',\n                          'climate': 'Int64',\n                          'biomonitoring': 'Int64'})\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.442942Z","iopub.execute_input":"2021-10-16T20:45:20.443356Z","iopub.status.idle":"2021-10-16T20:45:20.467438Z","shell.execute_reply.started":"2021-10-16T20:45:20.443309Z","shell.execute_reply":"2021-10-16T20:45:20.466342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 2.5. Download 1% data with random rows from big csv-file<a class=\"anchor\" id=\"2.5\"></a>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/ammonium-prediction-in-river-water/PB_1996_2019_NH4.csv', sep=';', \n                 skiprows = lambda x: x>0 and np.random.rand() > 0.01)\nprint(\"The shape of the df is {}. It has been reduced 100 times!\".format(df.shape))\n\n\n'''\nHow it works:\nskiprows accepts a function that is evaluated against the integer index.\nx > 0 makes sure that the headers is not skipped\nnp.random.rand() > 0.01 returns True 99% of the tie, thus skipping 99% of the time.\nNote that we are using skiprows\n'''\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.469139Z","iopub.execute_input":"2021-10-16T20:45:20.469624Z","iopub.status.idle":"2021-10-16T20:45:20.491787Z","shell.execute_reply.started":"2021-10-16T20:45:20.469561Z","shell.execute_reply":"2021-10-16T20:45:20.49095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 2.6. Internally process the file in chunks (low_memory)<a class=\"anchor\" id=\"2.6\"></a>\nInternally process the file in chunks, resulting in lower memory use while parsing, but possibly mixed type inference. To ensure no mixed types specify the type with the dtype parameter.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/nlp-reports-news-classification/water_problem_nlp_ua_for_Kaggle_100.csv', delimiter=';', \n                 header=0, encoding='cp1251', low_memory=True,\n                 dtype = {'text': str, \n                          'env_problems': 'Int64',\n                          'pollution': 'Int64', \n                          'treatment': 'Int64',\n                          'climate': 'Int64',\n                          'biomonitoring': 'Int64'})\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.49311Z","iopub.execute_input":"2021-10-16T20:45:20.493595Z","iopub.status.idle":"2021-10-16T20:45:20.511071Z","shell.execute_reply.started":"2021-10-16T20:45:20.493564Z","shell.execute_reply":"2021-10-16T20:45:20.510288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 2.7. Download json-data via API in Kaggle<a class=\"anchor\" id=\"2.7\"></a>","metadata":{}},{"cell_type":"code","source":"# Download one file\nimport requests\nprint(f'Download confirmed daily data from RNBO of Ukraine')\nmyfile = requests.get('https://api-covid19.rnbo.gov.ua/charts/main-data?mode=ukraine')\nopen('filename', 'wb').write(myfile.content)\ndata_covid = pd.read_json('filename')\ndata_covid.tail(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T20:45:20.512202Z","iopub.execute_input":"2021-10-16T20:45:20.512662Z","iopub.status.idle":"2021-10-16T20:45:22.27781Z","shell.execute_reply.started":"2021-10-16T20:45:20.512629Z","shell.execute_reply":"2021-10-16T20:45:22.276723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download some files\nprint('Download daily data for some regions of Ukraine (Kyiv - 4909, Lviv.reg. - 4895, Vinn.reg - 4907)')\nfor filename in ['country=4909', 'country=4895', 'country=4907']:\n    myfile = requests.get(f'https://api-covid19.rnbo.gov.ua/charts/main-data?mode=ukraine&{filename}')\n    open('filename', 'wb').write(myfile.content)\n    data_covid_region = pd.read_json('filename')\n    display(data_covid_region.tail(3))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:24.327621Z","iopub.execute_input":"2021-06-03T09:34:24.327891Z","iopub.status.idle":"2021-06-03T09:34:29.445148Z","shell.execute_reply.started":"2021-06-03T09:34:24.327864Z","shell.execute_reply":"2021-06-03T09:34:29.444144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 2.8. Selection data from DataFrame (Pandas Tips)<a class=\"anchor\" id=\"2.8\"></a>","metadata":{}},{"cell_type":"code","source":"df = data_titanic.copy()\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.170273Z","iopub.execute_input":"2021-06-03T09:34:31.170694Z","iopub.status.idle":"2021-06-03T09:34:31.186289Z","shell.execute_reply.started":"2021-06-03T09:34:31.170651Z","shell.execute_reply":"2021-06-03T09:34:31.185173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.loc[], df.iloc\ndf.iloc[2:5, :].loc[:, \"Name\":\"Fare\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.187491Z","iopub.execute_input":"2021-06-03T09:34:31.187792Z","iopub.status.idle":"2021-06-03T09:34:31.203301Z","shell.execute_reply.started":"2021-06-03T09:34:31.187763Z","shell.execute_reply":"2021-06-03T09:34:31.20253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.204484Z","iopub.execute_input":"2021-06-03T09:34:31.20476Z","iopub.status.idle":"2021-06-03T09:34:31.221041Z","shell.execute_reply.started":"2021-06-03T09:34:31.204733Z","shell.execute_reply":"2021-06-03T09:34:31.220255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[2, 5]","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.221961Z","iopub.execute_input":"2021-06-03T09:34:31.222293Z","iopub.status.idle":"2021-06-03T09:34:31.234871Z","shell.execute_reply.started":"2021-06-03T09:34:31.222265Z","shell.execute_reply":"2021-06-03T09:34:31.233914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[2, 'Age']","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.236079Z","iopub.execute_input":"2021-06-03T09:34:31.236332Z","iopub.status.idle":"2021-06-03T09:34:31.248996Z","shell.execute_reply.started":"2021-06-03T09:34:31.236307Z","shell.execute_reply":"2021-06-03T09:34:31.248167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data.at\npd.set_option('max_colwidth', 1000)\ndf_all = pd.DataFrame(columns=['data'], index=[0, 1])\ndf_all.at[0,'data'] = data_titanic.copy()\ndf_all.at[1,'data'] = data_covid.copy()\ndf_all.at[2,'data'] = df.Name.tolist()\ndf_all.at[3,'data'] = df.Age.values\ndf_all","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.250595Z","iopub.execute_input":"2021-06-03T09:34:31.250866Z","iopub.status.idle":"2021-06-03T09:34:31.295526Z","shell.execute_reply.started":"2021-06-03T09:34:31.25084Z","shell.execute_reply":"2021-06-03T09:34:31.294586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all.at[0, 'data'].head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.296583Z","iopub.execute_input":"2021-06-03T09:34:31.296838Z","iopub.status.idle":"2021-06-03T09:34:31.313779Z","shell.execute_reply.started":"2021-06-03T09:34:31.296812Z","shell.execute_reply":"2021-06-03T09:34:31.312546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select multiple slices of columns from a df\ncols_str = list(map(str, list(df.columns))) # so that we can do df[\"0\"] as string for the example\ndf.columns = cols_str\n\n# Using pandas concatenation\n# if you are ever confused about axis = 1 or axis = 0, just put axis = \"columns\" or axis = \"rows\"\ndisplay(pd.concat([df.loc[:, \"PassengerId\":\"Pclass\"], df.loc[:, \"Sex\":\"SibSp\"]], axis = \"columns\").head(3))\n\n# Using lists\n# please ntoe that df.columns is a series with index, so we are using index to filter #\ndisplay(df[list(df.columns[0:3]) + list(df.columns[4:7])].head(3))\n\n# Using numpy\ndisplay(df.iloc[:, np.r_[0:3, 4:7]].head(3)) # probably the most beautiful solution","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.315121Z","iopub.execute_input":"2021-06-03T09:34:31.315412Z","iopub.status.idle":"2021-06-03T09:34:31.35087Z","shell.execute_reply.started":"2021-06-03T09:34:31.315386Z","shell.execute_reply":"2021-06-03T09:34:31.350089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)","metadata":{}},{"cell_type":"markdown","source":"## 3. Auxiliary functions<a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"### Tip 3.1. Pandas option for output data<a class=\"anchor\" id=\"3.1\"></a>","metadata":{}},{"cell_type":"code","source":"# Sets the value of the specified option.\npd.set_option('max_columns',100)\npd.set_option('max_rows',900)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-03T09:34:31.352065Z","iopub.execute_input":"2021-06-03T09:34:31.352373Z","iopub.status.idle":"2021-06-03T09:34:31.356865Z","shell.execute_reply.started":"2021-06-03T09:34:31.352343Z","shell.execute_reply":"2021-06-03T09:34:31.355913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic.head(8)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.357894Z","iopub.execute_input":"2021-06-03T09:34:31.358191Z","iopub.status.idle":"2021-06-03T09:34:31.385131Z","shell.execute_reply.started":"2021-06-03T09:34:31.358164Z","shell.execute_reply":"2021-06-03T09:34:31.384159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Available options:\n> display.[chop_threshold, colheader_justify, column_space, date_dayfirst,\n>          date_yearfirst, encoding, expand_frame_repr, float_format, height,\n>          line_width, max_columns, max_colwidth, max_info_columns, max_info_rows,\n>          max_rows, max_seq_items, mpl_style, multi_sparse, notebook_repr_html,\n>          pprint_nest_depth, precision, width]","metadata":{}},{"cell_type":"code","source":"pd.set_option('max_colwidth',200)\ndata_nlp.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.386478Z","iopub.execute_input":"2021-06-03T09:34:31.386823Z","iopub.status.idle":"2021-06-03T09:34:31.406037Z","shell.execute_reply.started":"2021-06-03T09:34:31.386793Z","shell.execute_reply":"2021-06-03T09:34:31.404876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reset all of them options to default\npd.reset_option('all')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.407634Z","iopub.execute_input":"2021-06-03T09:34:31.40808Z","iopub.status.idle":"2021-06-03T09:34:31.41853Z","shell.execute_reply.started":"2021-06-03T09:34:31.408038Z","shell.execute_reply":"2021-06-03T09:34:31.417645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 3.2. The garbage collector<a class=\"anchor\" id=\"3.2\"></a>","metadata":{}},{"cell_type":"code","source":"del df_all","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.419814Z","iopub.execute_input":"2021-06-03T09:34:31.42017Z","iopub.status.idle":"2021-06-03T09:34:31.428792Z","shell.execute_reply.started":"2021-06-03T09:34:31.420138Z","shell.execute_reply":"2021-06-03T09:34:31.427977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.429854Z","iopub.execute_input":"2021-06-03T09:34:31.430573Z","iopub.status.idle":"2021-06-03T09:34:31.560128Z","shell.execute_reply.started":"2021-06-03T09:34:31.430543Z","shell.execute_reply":"2021-06-03T09:34:31.559089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)","metadata":{}},{"cell_type":"markdown","source":"### Tip 3.3. Time execution of a Python code in the cell<a class=\"anchor\" id=\"3.3\"></a>","metadata":{}},{"cell_type":"code","source":"%%time\n# Time execution of a Python statement or expression in the cell","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.562123Z","iopub.execute_input":"2021-06-03T09:34:31.562485Z","iopub.status.idle":"2021-06-03T09:34:31.569897Z","shell.execute_reply.started":"2021-06-03T09:34:31.562454Z","shell.execute_reply":"2021-06-03T09:34:31.568873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. EDA & Data cleaning<a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.029974,"end_time":"2020-11-15T02:05:20.229181","exception":false,"start_time":"2020-11-15T02:05:20.199207","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Tip 4.1. Count of rows that match a condition <a class=\"anchor\" id=\"4.1\"></a>","metadata":{}},{"cell_type":"code","source":"df = data_titanic.copy()\ndf.head()\ndf.shape\n\n# absolute values\n(df[\"Age\"] < 18).sum()\nprint(\"In the columns Age we have {} of rows that are below 18\".format((df[\"Age\"] < 18).sum()))\n\n# mean value\n(df[\"Age\"] < 18).mean()\nprint(\"In the columns Age the values that are below 18 represent {}%\".format((df[\"Age\"] < 18).mean()))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.571213Z","iopub.execute_input":"2021-06-03T09:34:31.571586Z","iopub.status.idle":"2021-06-03T09:34:31.587256Z","shell.execute_reply.started":"2021-06-03T09:34:31.571557Z","shell.execute_reply":"2021-06-03T09:34:31.586016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 4.2. Combine the small categories into a single category named \"Other\" <a class=\"anchor\" id=\"4.2\"></a>","metadata":{}},{"cell_type":"code","source":"d = {\"class\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Step 1: count the frequencies\nfrequencies = df[\"class\"].value_counts(normalize = True)\nprint(frequencies)\n\n# Step 2: establish your threshold and filter the smaller categories\nthreshold = 0.1\nsmall_categories = frequencies[frequencies < threshold].index\nprint(small_categories)\n\n# Step 3: replace the values\ndf[\"class\"] = df[\"class\"].replace(small_categories, \"Other\")\ndf[\"class\"].value_counts(normalize = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.588779Z","iopub.execute_input":"2021-06-03T09:34:31.58913Z","iopub.status.idle":"2021-06-03T09:34:31.611054Z","shell.execute_reply.started":"2021-06-03T09:34:31.589098Z","shell.execute_reply":"2021-06-03T09:34:31.609702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 4.3. Count the missing values <a class=\"anchor\" id=\"4.3\"></a>","metadata":{}},{"cell_type":"markdown","source":"\"\\n\" in \"print\" - line skip in the text output ","metadata":{}},{"cell_type":"code","source":"df = data_titanic.copy()\n# Solution 1\nprint('df.isnull().sum().sum()')\nprint(df.isnull().sum().sum(), \"\\n\\n\")\n\n# Solution 2\nprint('df.isna().sum()\\n')\nprint(df.isna().sum(), \"\\n\\n\")\n\n# Solution 3\nprint('df.isna().any()\\n')\nprint(df.isna().any(), \"\\n\\n\")\n\n# Solution 4:\ndf.isna().any(axis = None)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.612196Z","iopub.execute_input":"2021-06-03T09:34:31.612459Z","iopub.status.idle":"2021-06-03T09:34:31.630391Z","shell.execute_reply.started":"2021-06-03T09:34:31.612433Z","shell.execute_reply":"2021-06-03T09:34:31.629463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 4.4. Convert one type of values to others <a class=\"anchor\" id=\"4.4\"></a>","metadata":{}},{"cell_type":"code","source":"# Do some fast feature eng on the DF\nd = {\"gender\":[\"male\", \"female\", \"male\"], \"color\":[\"red\", \"green\", \"blue\"], \"age\":[25, 30, 15]}\ndf = pd.DataFrame(d)\ndf\n\n# Solution\ndf[\"gender_mapped\"] = df[\"gender\"].map({\"male\":\"M\", \"female\":\"F\"}) # using dictionaries to map values\ndf[\"gender_mapped\"] = df[\"gender\"].map({\"female\":0, \"male\":1}) # using dictionaries to map values\ndf[\"color_factorized\"] = df[\"color\"].factorize()[0] # using factorize: returns a tuple of arrays (array([0, 1, 2]), Index(['red', 'green', 'blue'], dtype='object')) that's why we select [0]\ndf[\"age_compared_boolean\"] = df[\"age\"] < 18 # return a True False boolean value\ndf[\"age_str\"] = df[\"age\"].astype('str')\n\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.639085Z","iopub.execute_input":"2021-06-03T09:34:31.639405Z","iopub.status.idle":"2021-06-03T09:34:31.661245Z","shell.execute_reply.started":"2021-06-03T09:34:31.639376Z","shell.execute_reply":"2021-06-03T09:34:31.660291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataFrame with types as in other\n#df2 = df2.astype(df1.dtypes.to_dict())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic_num = data_titanic[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare','Embarked']].copy()\ndata_titanic_num[\"Sex\"] = data_titanic_num[\"Sex\"].map({\"female\":0, \"male\":1})\ndata_titanic_num[\"Embarked\"] = data_titanic_num[\"Embarked\"].map({\"S\":0, \"C\":1, \"Q\": 2})\ndata_titanic_num = data_titanic_num.dropna()  # without NAN \ndata_titanic_num","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.662704Z","iopub.execute_input":"2021-06-03T09:34:31.663015Z","iopub.status.idle":"2021-06-03T09:34:31.69621Z","shell.execute_reply.started":"2021-06-03T09:34:31.662983Z","shell.execute_reply":"2021-06-03T09:34:31.695399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 4.5. Replaced inf, -inf, nan to given value <a class=\"anchor\" id=\"4.5\"></a>","metadata":{}},{"cell_type":"code","source":"data_titanic['Age'].replace([np.inf, -np.inf], np.nan).fillna(-1)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.699889Z","iopub.execute_input":"2021-06-03T09:34:31.700198Z","iopub.status.idle":"2021-06-03T09:34:31.710059Z","shell.execute_reply.started":"2021-06-03T09:34:31.70017Z","shell.execute_reply":"2021-06-03T09:34:31.709245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 4.6. Filtering the missing data in DataFrame<a class=\"anchor\" id=\"4.6\"></a>","metadata":{}},{"cell_type":"code","source":"data_titanic.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.711148Z","iopub.execute_input":"2021-06-03T09:34:31.71153Z","iopub.status.idle":"2021-06-03T09:34:31.720814Z","shell.execute_reply.started":"2021-06-03T09:34:31.711425Z","shell.execute_reply":"2021-06-03T09:34:31.719837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic.dropna().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.721964Z","iopub.execute_input":"2021-06-03T09:34:31.722327Z","iopub.status.idle":"2021-06-03T09:34:31.756272Z","shell.execute_reply.started":"2021-06-03T09:34:31.722294Z","shell.execute_reply":"2021-06-03T09:34:31.755382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic[['Name', 'Age']].dropna().reset_index(drop=True)","metadata":{"papermill":{"duration":0.054558,"end_time":"2020-11-15T02:05:20.385518","exception":false,"start_time":"2020-11-15T02:05:20.33096","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-03T09:34:31.758336Z","iopub.execute_input":"2021-06-03T09:34:31.759126Z","iopub.status.idle":"2021-06-03T09:34:31.778835Z","shell.execute_reply.started":"2021-06-03T09:34:31.759081Z","shell.execute_reply":"2021-06-03T09:34:31.777433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic.dropna(subset = ['Name', 'Age']).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.780492Z","iopub.execute_input":"2021-06-03T09:34:31.781015Z","iopub.status.idle":"2021-06-03T09:34:31.813736Z","shell.execute_reply.started":"2021-06-03T09:34:31.780968Z","shell.execute_reply":"2021-06-03T09:34:31.812724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 4.7. Generate descriptive statistics<a class=\"anchor\" id=\"4.7\"></a>","metadata":{}},{"cell_type":"code","source":"data_health.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.815255Z","iopub.execute_input":"2021-06-03T09:34:31.815657Z","iopub.status.idle":"2021-06-03T09:34:31.869198Z","shell.execute_reply.started":"2021-06-03T09:34:31.815616Z","shell.execute_reply":"2021-06-03T09:34:31.868297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 4.8. EDA<a class=\"anchor\" id=\"4.8\"></a>","metadata":{}},{"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nscatter_matrix(data_titanic, alpha=0.4, figsize=(10, 10), diagonal=\"kde\");","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:31.870629Z","iopub.execute_input":"2021-06-03T09:34:31.871031Z","iopub.status.idle":"2021-06-03T09:34:34.918075Z","shell.execute_reply.started":"2021-06-03T09:34:31.87099Z","shell.execute_reply":"2021-06-03T09:34:34.917133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas.plotting import andrews_curves\nplt.figure(figsize=(10, 10));\ndata_titanic_num_cleaning = data_titanic[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch']].fillna(-1)\ndata_titanic_num_cleaning['Age10'] = data_titanic_num_cleaning['Age'] // 10\nandrews_curves(data_titanic_num_cleaning, 'Age10');","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:34.91964Z","iopub.execute_input":"2021-06-03T09:34:34.920027Z","iopub.status.idle":"2021-06-03T09:34:36.974025Z","shell.execute_reply.started":"2021-06-03T09:34:34.919981Z","shell.execute_reply":"2021-06-03T09:34:36.972949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 4.9. Create a spreadsheet-style pivot table as a DataFrame<a class=\"anchor\" id=\"4.9\"></a>","metadata":{}},{"cell_type":"code","source":"data_water","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:36.975545Z","iopub.execute_input":"2021-06-03T09:34:36.975917Z","iopub.status.idle":"2021-06-03T09:34:36.992628Z","shell.execute_reply.started":"2021-06-03T09:34:36.975878Z","shell.execute_reply":"2021-06-03T09:34:36.99163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_water = pd.pivot_table(data_water, values='NH4', index=['date'], columns='ID_Station')\ndata_water","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:36.993728Z","iopub.execute_input":"2021-06-03T09:34:36.994067Z","iopub.status.idle":"2021-06-03T09:34:37.050654Z","shell.execute_reply.started":"2021-06-03T09:34:36.994037Z","shell.execute_reply":"2021-06-03T09:34:37.0497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_water = data_water[[27, 28, 29]]\ndata_water.columns = ['target', 'Kl', \"Khm\"]\ndata_water = data_water.dropna().reset_index(drop=False)\ndata_water","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.051858Z","iopub.execute_input":"2021-06-03T09:34:37.052135Z","iopub.status.idle":"2021-06-03T09:34:37.073929Z","shell.execute_reply.started":"2021-06-03T09:34:37.052109Z","shell.execute_reply":"2021-06-03T09:34:37.072882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)","metadata":{}},{"cell_type":"markdown","source":"## 5. FE<a class=\"anchor\" id=\"5\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.036817,"end_time":"2020-11-15T02:05:21.573582","exception":false,"start_time":"2020-11-15T02:05:21.536765","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Tip 5.1. Get numeric features from the DataFrame<a class=\"anchor\" id=\"5.1\"></a>","metadata":{}},{"cell_type":"code","source":"data_titanic.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.075226Z","iopub.execute_input":"2021-06-03T09:34:37.075638Z","iopub.status.idle":"2021-06-03T09:34:37.093547Z","shell.execute_reply.started":"2021-06-03T09:34:37.075606Z","shell.execute_reply":"2021-06-03T09:34:37.092497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_numeric_features(df):\n    # Get numeric features from df\n    return df.select_dtypes(include=np.number).columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.095443Z","iopub.execute_input":"2021-06-03T09:34:37.096114Z","iopub.status.idle":"2021-06-03T09:34:37.103686Z","shell.execute_reply.started":"2021-06-03T09:34:37.096063Z","shell.execute_reply":"2021-06-03T09:34:37.1029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_numeric_features(data_titanic)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.104613Z","iopub.execute_input":"2021-06-03T09:34:37.104865Z","iopub.status.idle":"2021-06-03T09:34:37.119745Z","shell.execute_reply.started":"2021-06-03T09:34:37.10484Z","shell.execute_reply":"2021-06-03T09:34:37.118685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 5.2. Get categorical features from the DataFrame<a class=\"anchor\" id=\"5.2\"></a>","metadata":{}},{"cell_type":"code","source":"def get_categorical_features(df):\n    # Get categorical features from df\n    # see get_numeric_features in Tip 5.1\n    return list(set(df.columns.tolist()) - set(get_numeric_features(df)))","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.121344Z","iopub.execute_input":"2021-06-03T09:34:37.121762Z","iopub.status.idle":"2021-06-03T09:34:37.128661Z","shell.execute_reply.started":"2021-06-03T09:34:37.121722Z","shell.execute_reply":"2021-06-03T09:34:37.127767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_categorical_features(data_titanic)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.130391Z","iopub.execute_input":"2021-06-03T09:34:37.130736Z","iopub.status.idle":"2021-06-03T09:34:37.143921Z","shell.execute_reply.started":"2021-06-03T09:34:37.130706Z","shell.execute_reply":"2021-06-03T09:34:37.143108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 5.3. Search and encoding categorical columns <a class=\"anchor\" id=\"5.3\"></a>","metadata":{}},{"cell_type":"code","source":"data_titanic.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.145623Z","iopub.execute_input":"2021-06-03T09:34:37.146009Z","iopub.status.idle":"2021-06-03T09:34:37.167417Z","shell.execute_reply.started":"2021-06-03T09:34:37.145979Z","shell.execute_reply":"2021-06-03T09:34:37.166353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ndef df_encoding(df):\n    #  Search and encoding categorical columns\n    categorical_columns = get_categorical_features(df) # see Tip 5.2\n    \n    for col in categorical_columns:\n        if col in df.columns:\n            le = LabelEncoder()\n            le.fit(list(df[col].astype(str).values))\n            df[col] = le.transform(list(df[col].astype(str).values))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.168809Z","iopub.execute_input":"2021-06-03T09:34:37.169159Z","iopub.status.idle":"2021-06-03T09:34:37.176725Z","shell.execute_reply.started":"2021-06-03T09:34:37.169116Z","shell.execute_reply":"2021-06-03T09:34:37.17596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic = df_encoding(data_titanic)\ndata_titanic","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.17792Z","iopub.execute_input":"2021-06-03T09:34:37.178344Z","iopub.status.idle":"2021-06-03T09:34:37.215957Z","shell.execute_reply.started":"2021-06-03T09:34:37.178286Z","shell.execute_reply":"2021-06-03T09:34:37.215231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 5.4. Difference and rolling of values in DataFrame<a class=\"anchor\" id=\"5.4\"></a>","metadata":{}},{"cell_type":"code","source":"data_covid['confirmed'].plot()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.216963Z","iopub.execute_input":"2021-06-03T09:34:37.217352Z","iopub.status.idle":"2021-06-03T09:34:37.366257Z","shell.execute_reply.started":"2021-06-03T09:34:37.217314Z","shell.execute_reply":"2021-06-03T09:34:37.365127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Daily gain\ndata_covid['n_confirmed'] = data_covid['confirmed'].diff()\ndata_covid","metadata":{"papermill":{"duration":0.041056,"end_time":"2020-11-15T02:05:20.300251","exception":false,"start_time":"2020-11-15T02:05:20.259195","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-03T09:34:37.367652Z","iopub.execute_input":"2021-06-03T09:34:37.367994Z","iopub.status.idle":"2021-06-03T09:34:37.389631Z","shell.execute_reply.started":"2021-06-03T09:34:37.367923Z","shell.execute_reply":"2021-06-03T09:34:37.388485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_covid['n_confirmed'].plot()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.391188Z","iopub.execute_input":"2021-06-03T09:34:37.3916Z","iopub.status.idle":"2021-06-03T09:34:37.552758Z","shell.execute_reply.started":"2021-06-03T09:34:37.39156Z","shell.execute_reply":"2021-06-03T09:34:37.55183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sliding total for a week\ndata_covid['n_confirmed_week'] = data_covid['n_confirmed'].rolling(7).sum()\ndata_covid['n_confirmed_week']","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.55401Z","iopub.execute_input":"2021-06-03T09:34:37.554269Z","iopub.status.idle":"2021-06-03T09:34:37.564221Z","shell.execute_reply.started":"2021-06-03T09:34:37.554243Z","shell.execute_reply":"2021-06-03T09:34:37.563119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_covid['n_confirmed_week'].plot()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.565373Z","iopub.execute_input":"2021-06-03T09:34:37.565652Z","iopub.status.idle":"2021-06-03T09:34:37.714982Z","shell.execute_reply.started":"2021-06-03T09:34:37.565625Z","shell.execute_reply":"2021-06-03T09:34:37.713922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot with all these features\n(data_covid['confirmed']/data_covid['confirmed'].max()).plot()\n(data_covid['n_confirmed']/data_covid['n_confirmed'].max()).plot()\n(data_covid['n_confirmed_week']/data_covid['n_confirmed_week'].max()).plot()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.716121Z","iopub.execute_input":"2021-06-03T09:34:37.716379Z","iopub.status.idle":"2021-06-03T09:34:37.883168Z","shell.execute_reply.started":"2021-06-03T09:34:37.716353Z","shell.execute_reply":"2021-06-03T09:34:37.882125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 5.5. Data dropping (rows or columns removing) in DataFrame<a class=\"anchor\" id=\"5.5\"></a>","metadata":{}},{"cell_type":"code","source":"data_titanic.drop(columns = ['Ticket', 'Cabin'])","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.884484Z","iopub.execute_input":"2021-06-03T09:34:37.885068Z","iopub.status.idle":"2021-06-03T09:34:37.907738Z","shell.execute_reply.started":"2021-06-03T09:34:37.885032Z","shell.execute_reply":"2021-06-03T09:34:37.906632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dublicates removing\nprint(data_health.shape)\ndisplay(data_health.drop_duplicates())","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.909704Z","iopub.execute_input":"2021-06-03T09:34:37.910201Z","iopub.status.idle":"2021-06-03T09:34:37.941237Z","shell.execute_reply.started":"2021-06-03T09:34:37.910125Z","shell.execute_reply":"2021-06-03T09:34:37.940168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 5.6. Date in str format to date in datetime format in DataFrame<a class=\"anchor\" id=\"5.6\"></a>","metadata":{}},{"cell_type":"code","source":"data_covid['date'] = pd.to_datetime(data_covid['dates'])\n# Forced conversion\npd.to_datetime(data_covid[\"dates\"], format = '%Y-%m-%d', errors='coerce')\ndata_covid.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.942615Z","iopub.execute_input":"2021-06-03T09:34:37.943045Z","iopub.status.idle":"2021-06-03T09:34:37.962683Z","shell.execute_reply.started":"2021-06-03T09:34:37.942992Z","shell.execute_reply":"2021-06-03T09:34:37.96188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_covid.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.963798Z","iopub.execute_input":"2021-06-03T09:34:37.964307Z","iopub.status.idle":"2021-06-03T09:34:37.978494Z","shell.execute_reply.started":"2021-06-03T09:34:37.964275Z","shell.execute_reply":"2021-06-03T09:34:37.977246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 5.7. MinMaxScaling data in DataFrame<a class=\"anchor\" id=\"5.7\"></a>","metadata":{}},{"cell_type":"code","source":"# MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef df_minmax_scaler(df):\n    # Data Scalling\n    scaler = MinMaxScaler().fit(df)\n    df = pd.DataFrame(scaler.transform(df), columns = df.columns)\n    return scaler, df","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.979766Z","iopub.execute_input":"2021-06-03T09:34:37.980127Z","iopub.status.idle":"2021-06-03T09:34:37.991196Z","shell.execute_reply.started":"2021-06-03T09:34:37.980096Z","shell.execute_reply":"2021-06-03T09:34:37.989906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler, df = df_minmax_scaler(data_health.copy())\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:37.993048Z","iopub.execute_input":"2021-06-03T09:34:37.993778Z","iopub.status.idle":"2021-06-03T09:34:38.032822Z","shell.execute_reply.started":"2021-06-03T09:34:37.99373Z","shell.execute_reply":"2021-06-03T09:34:38.031757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)","metadata":{}},{"cell_type":"markdown","source":"## 6. Modeling<a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.038107,"end_time":"2020-11-15T02:05:24.595869","exception":false,"start_time":"2020-11-15T02:05:24.557762","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Thanks to [Heart Disease - Automatic AdvEDA & FE & 20 models](https://www.kaggle.com/vbmokin/heart-disease-automatic-adveda-fe-20-models)\n\nThere are 60+ predictive modeling algorithms to choose from. Consider the classification problem with the next models (with hyperparameters tuning by GridSearchCV):\n\n- Linear Regression, Logistic Regression\n- Naive Bayes \n- k-Nearest Neighbors algorithm\n- Neural network with Keras\n- Support Vector Machines and Linear SVC\n- Stochastic Gradient Descent, Gradient Boosting Classifier, RidgeCV, Bagging Classifier\n- Decision Tree Classifier, Random Forest Classifier, AdaBoost Classifier, XGB Classifier, LGBM Classifier, ExtraTrees Classifier \n- Gaussian Process Classification\n- MLP Classifier (Deep Learning)\n- Voting Classifier\n\nApplication and tuning of these models using cross-validation with [learning_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html?highlight=learning_curve#sklearn.model_selection.learning_curve) see in the notebook [Heart Disease - Automatic AdvEDA & FE & 20 models](https://www.kaggle.com/vbmokin/heart-disease-automatic-adveda-fe-20-models).","metadata":{}},{"cell_type":"markdown","source":"### Tip 6.1. Data preparation with standardization for modeling<a class=\"anchor\" id=\"6.1\"></a>","metadata":{}},{"cell_type":"code","source":"data_health.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:38.034175Z","iopub.execute_input":"2021-06-03T09:34:38.03476Z","iopub.status.idle":"2021-06-03T09:34:38.049678Z","shell.execute_reply.started":"2021-06-03T09:34:38.034717Z","shell.execute_reply":"2021-06-03T09:34:38.048527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data preparation for data_health (very simple)\ndata_h = data_health.copy()\ntarget_data_h = data_h.pop('target')\ndisplay(data_h.head(3))\ndata_h.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:38.051139Z","iopub.execute_input":"2021-06-03T09:34:38.051767Z","iopub.status.idle":"2021-06-03T09:34:38.083859Z","shell.execute_reply.started":"2021-06-03T09:34:38.051723Z","shell.execute_reply":"2021-06-03T09:34:38.082592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_titanic.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:38.085294Z","iopub.execute_input":"2021-06-03T09:34:38.085667Z","iopub.status.idle":"2021-06-03T09:34:38.100854Z","shell.execute_reply.started":"2021-06-03T09:34:38.085634Z","shell.execute_reply":"2021-06-03T09:34:38.099915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data preparation for data_titanic (real - classification task)\nfrom sklearn.preprocessing import StandardScaler\n\ndata = data_titanic.copy()\ndata.index = data['PassengerId']  # it's need removed all id-features with unique values\ndata = data.drop(columns=['PassengerId'])\ndata = data.dropna()  # it's very simple but not good approach\ntarget_data = data.pop('Survived')\nscaler = StandardScaler()\ndata = pd.DataFrame(scaler.fit_transform(data), columns = data.columns)\ndisplay(data.head(3))\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:34:38.102213Z","iopub.execute_input":"2021-06-03T09:34:38.102486Z","iopub.status.idle":"2021-06-03T09:34:38.14221Z","shell.execute_reply.started":"2021-06-03T09:34:38.10246Z","shell.execute_reply":"2021-06-03T09:34:38.141332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_water.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:28.734435Z","iopub.execute_input":"2021-06-03T09:23:28.734827Z","iopub.status.idle":"2021-06-03T09:23:28.747896Z","shell.execute_reply.started":"2021-06-03T09:23:28.734787Z","shell.execute_reply":"2021-06-03T09:23:28.746676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data preparation for data_water (real - regression task)\ndata_w = data_water.copy()\ndata_w = data_w.drop(columns=['date'])\ntarget_data_w = data_w.pop('target')\nscaler_w = StandardScaler()\ndata_w = pd.DataFrame(scaler_w.fit_transform(data_w), columns = data_w.columns)\ndisplay(data_w.head(3))\ndata_w.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:28.749435Z","iopub.execute_input":"2021-06-03T09:23:28.749835Z","iopub.status.idle":"2021-06-03T09:23:28.777467Z","shell.execute_reply.started":"2021-06-03T09:23:28.749793Z","shell.execute_reply":"2021-06-03T09:23:28.776549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.2. Splitting data with train_test_split<a class=\"anchor\" id=\"6.2\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# For data_health\ntrain, test, target, target_test = train_test_split(data, target_data, test_size=0.2, random_state=0)\nprint(train.shape, test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:28.778402Z","iopub.execute_input":"2021-06-03T09:23:28.778687Z","iopub.status.idle":"2021-06-03T09:23:28.806715Z","shell.execute_reply.started":"2021-06-03T09:23:28.778659Z","shell.execute_reply":"2021-06-03T09:23:28.805991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For data_water\ntrain_w, test_w, target_w, target_test_w = train_test_split(data_w, target_data_w, test_size=0.2, random_state=0)\nprint(train_w.shape, test_w.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:28.80767Z","iopub.execute_input":"2021-06-03T09:23:28.808075Z","iopub.status.idle":"2021-06-03T09:23:28.815008Z","shell.execute_reply.started":"2021-06-03T09:23:28.808047Z","shell.execute_reply":"2021-06-03T09:23:28.814188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.3. Accuracy score for train and test prediction<a class=\"anchor\" id=\"6.3\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score, accuracy_score\n\ndef acc(model, train, test, target, target_test, is_round=True):\n    # Calculation accuracy score for train and test prediction\n    # is_round=True - for classification task only, for regression task is_round=False\n    \n    if is_round:\n        # Classification task\n        ytrain = model.predict(train).astype(int)\n        ytest = model.predict(test).astype(int)\n        acc_train = round(accuracy_score(target, ytrain), 2)\n        acc_test = round(accuracy_score(target_test, ytest), 2)\n    else:\n        # Regression task\n        ytrain = model.predict(train)\n        ytest = model.predict(test)\n        acc_train = round(r2_score(target, ytrain), 2)\n        acc_test = round(r2_score(target_test, ytest), 2)\n        \n    print('Accuracy for train prediction =', acc_train)\n    print('Accuracy for test prediction =', acc_test,'\\n')\n    \n    return ytrain, ytest\n\n# See examples below","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:28.816008Z","iopub.execute_input":"2021-06-03T09:23:28.816449Z","iopub.status.idle":"2021-06-03T09:23:28.824932Z","shell.execute_reply.started":"2021-06-03T09:23:28.816421Z","shell.execute_reply":"2021-06-03T09:23:28.824185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.4. Classification report<a class=\"anchor\" id=\"6.4\"></a>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ndef classification_report_print(y_true, y_pred, title, target_names=['0', '1']):\n    print(f'Classification report {title}:')\n    print(classification_report(y_true, y_pred, target_names=target_names))\n\n# See examples below","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:28.825976Z","iopub.execute_input":"2021-06-03T09:23:28.826349Z","iopub.status.idle":"2021-06-03T09:23:28.840965Z","shell.execute_reply.started":"2021-06-03T09:23:28.826322Z","shell.execute_reply":"2021-06-03T09:23:28.840008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.5. Linear Regression <a class=\"anchor\" id=\"6.5\"></a>","metadata":{}},{"cell_type":"markdown","source":"**Linear Regression** is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression. Reference [Wikipedia](https://en.wikipedia.org/wiki/Linear_regression).\n\nNote the confidence score generated by the model based on our training dataset.","metadata":{}},{"cell_type":"code","source":"# Linear Regression\nfrom sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nlinreg.fit(train, target)\n\nytrain, ytest = acc(linreg, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:28.842001Z","iopub.execute_input":"2021-06-03T09:23:28.842518Z","iopub.status.idle":"2021-06-03T09:23:28.962108Z","shell.execute_reply.started":"2021-06-03T09:23:28.84248Z","shell.execute_reply":"2021-06-03T09:23:28.961236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.6. Support Vector Machines <a class=\"anchor\" id=\"6.6\"></a>","metadata":{}},{"cell_type":"markdown","source":"**Support Vector Machines** are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine).","metadata":{}},{"cell_type":"code","source":"%%time\n# Support Vector Machines\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nsvr = SVC()\nsvr_CV = GridSearchCV(svr, param_grid={'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n                                       'tol': [1e-3]}, verbose=False)\nsvr_CV.fit(train, target)\nprint(svr_CV.best_params_,'\\n')\n\nytrain, ytest = acc(svr_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:28.963193Z","iopub.execute_input":"2021-06-03T09:23:28.963446Z","iopub.status.idle":"2021-06-03T09:23:29.252551Z","shell.execute_reply.started":"2021-06-03T09:23:28.963421Z","shell.execute_reply":"2021-06-03T09:23:29.251674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.7. Linear SVC <a class=\"anchor\" id=\"6.7\"></a>","metadata":{}},{"cell_type":"code","source":"# Linear SVR\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import GridSearchCV\n\nlinear_svc = LinearSVC()\nparam_grid = {'dual':[False],\n              'C': np.linspace(1, 15, 15)}\nlinear_svc_CV = GridSearchCV(linear_svc, param_grid=param_grid, verbose=False)\nlinear_svc_CV.fit(train, target)\nprint(linear_svc_CV.best_params_,'\\n')\n\nytrain, ytest = acc(linear_svc_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:29.253512Z","iopub.execute_input":"2021-06-03T09:23:29.253765Z","iopub.status.idle":"2021-06-03T09:23:29.677502Z","shell.execute_reply.started":"2021-06-03T09:23:29.25374Z","shell.execute_reply":"2021-06-03T09:23:29.676351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.8. Decision Tree Classifier & Regressor<a class=\"anchor\" id=\"6.8\"></a>","metadata":{}},{"cell_type":"markdown","source":"This model uses a **Decision Tree** as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning).","metadata":{}},{"cell_type":"code","source":"# Decision Tree Classifier for data_health\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ndecision_tree = DecisionTreeClassifier()\nparam_grid = {'min_samples_leaf': [i for i in range(2,10)]}\ndecision_tree_CV = GridSearchCV(decision_tree, param_grid=param_grid, verbose=False)\ndecision_tree_CV.fit(train, target)\nprint(decision_tree_CV.best_params_, '\\n')\n\nytrain, ytest = acc(decision_tree_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:29.678742Z","iopub.execute_input":"2021-06-03T09:23:29.679082Z","iopub.status.idle":"2021-06-03T09:23:30.02886Z","shell.execute_reply.started":"2021-06-03T09:23:29.679038Z","shell.execute_reply":"2021-06-03T09:23:30.027766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DecisionTreeRegressor for data_water\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# Parameters of model (param_grid) taken from the notebook https://www.kaggle.com/vbmokin/ai-ml-ds-training-l2t-nh4-tree-regress-models\ndecision_tree = DecisionTreeRegressor()\nparam_grid = {'min_samples_leaf': [i for i in range(2,10)]}\ndecision_tree_CV_w = GridSearchCV(decision_tree, param_grid=param_grid, verbose=False)\ndecision_tree_CV_w.fit(train_w, target_w)\nprint(decision_tree_CV_w.best_params_, '\\n')\n\nytrain_dt_w, ytest_dt_w = acc(decision_tree_CV_w, train_w, test_w, target_w, target_test_w, is_round=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:30.030203Z","iopub.execute_input":"2021-06-03T09:23:30.030578Z","iopub.status.idle":"2021-06-03T09:23:30.238772Z","shell.execute_reply.started":"2021-06-03T09:23:30.030546Z","shell.execute_reply":"2021-06-03T09:23:30.237814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.9. Random Forest Classifier & Regressor <a class=\"anchor\" id=\"6.9\"></a>","metadata":{}},{"cell_type":"markdown","source":"**Random Forest** is one of the most popular model. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators= [100, 300]) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Random_forest).","metadata":{}},{"cell_type":"code","source":"%%time\n# Random Forest for data_health\n# Parameters of model (param_grid) taken from the notebook https://www.kaggle.com/morenovanton/titanic-random-forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nrandom_forest = RandomForestClassifier()\nparam_grid = {'n_estimators': [40, 50, 60], 'min_samples_split': [40, 50, 60, 70], 'min_samples_leaf': [12, 13, 14, 15, 16, 17], \n              'max_features': ['auto'], 'max_depth': [3, 4, 5, 6], 'criterion': ['gini'], 'bootstrap': [False]}\nrandom_forest_CV = GridSearchCV(estimator=random_forest, param_grid=param_grid, verbose=False)\nrandom_forest_CV.fit(train, target)\nprint(random_forest_CV.best_params_, '\\n')\n\nytrain, ytest = acc(random_forest_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:23:30.240522Z","iopub.execute_input":"2021-06-03T09:23:30.240927Z","iopub.status.idle":"2021-06-03T09:25:29.462341Z","shell.execute_reply.started":"2021-06-03T09:23:30.240884Z","shell.execute_reply":"2021-06-03T09:25:29.461265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Random Forest for data_water\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# Parameters of model (param_grid) taken from the notebook https://www.kaggle.com/vbmokin/ai-ml-ds-training-l2t-nh4-tree-regress-models\nrandom_forest = RandomForestRegressor()\nparam_grid = {'n_estimators': [10, 100, 500], 'min_samples_leaf': [i for i in range(5,10)], \n              'max_features': ['auto'], 'max_depth': [i for i in range(4,6)], \n              'criterion': ['mse'], 'bootstrap': [False]}\nrandom_forest_CV_w = GridSearchCV(estimator=random_forest, param_grid=param_grid, verbose=False)\nrandom_forest_CV_w.fit(train_w, target_w)\nprint(random_forest_CV_w.best_params_, '\\n')\n\nytrain_rf_w, ytest_rf_w = acc(random_forest_CV_w, train_w, test_w, target_w, target_test_w, is_round=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:25:29.463528Z","iopub.execute_input":"2021-06-03T09:25:29.463857Z","iopub.status.idle":"2021-06-03T09:26:07.844735Z","shell.execute_reply.started":"2021-06-03T09:25:29.463827Z","shell.execute_reply":"2021-06-03T09:26:07.84362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.10. XGB Classifier <a class=\"anchor\" id=\"6.10\"></a>","metadata":{}},{"cell_type":"markdown","source":"**XGBoost** is an ensemble tree method that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. XGBoost improves upon the base Gradient Boosting Machines (GBM) framework through systems optimization and algorithmic enhancements. Reference [Towards Data Science.](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)","metadata":{}},{"cell_type":"code","source":"%%time\n# XGBoost Classifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nxgb_clf = xgb.XGBClassifier(objective='reg:logistic') \nparameters = {'n_estimators': [50, 60, 70, 80, 90], \n              'learning_rate': [0.09, 0.1, 0.15, 0.2],\n              'max_depth': [3, 4, 5]}\nxgb_reg = GridSearchCV(estimator=xgb_clf, param_grid=parameters).fit(train, target)\nprint(\"Best score: %0.3f\" % xgb_reg.best_score_)\nprint(\"Best parameters set:\", xgb_reg.best_params_, '\\n')\n\nytrain, ytest = acc(xgb_reg, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:07.846291Z","iopub.execute_input":"2021-06-03T09:26:07.846708Z","iopub.status.idle":"2021-06-03T09:26:21.656609Z","shell.execute_reply.started":"2021-06-03T09:26:07.846665Z","shell.execute_reply":"2021-06-03T09:26:21.655557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.11. LGBM Classifier <a class=\"anchor\" id=\"6.11\"></a>","metadata":{}},{"cell_type":"markdown","source":"**Light GBM** is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithms. It splits the tree leaf wise with the best fit whereas other boosting algorithms split the tree depth wise or level wise rather than leaf-wise. So when growing on the same leaf in Light GBM, the leaf-wise algorithm can reduce more loss than the level-wise algorithm and hence results in much better accuracy which can rarely be achieved by any of the existing boosting algorithms. Also, it is surprisingly very fast, hence the word ‘Light’. Reference [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/).","metadata":{}},{"cell_type":"code","source":"%%time\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.2, random_state=0)\nmodelL = lgb.LGBMClassifier(n_estimators=1000, num_leaves=40)\nmodelL.fit(Xtrain, Ztrain, eval_set=[(Xval, Zval)], early_stopping_rounds=50, verbose=True)\n\nytrain, ytest = acc(modelL, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:21.657853Z","iopub.execute_input":"2021-06-03T09:26:21.658425Z","iopub.status.idle":"2021-06-03T09:26:21.909063Z","shell.execute_reply.started":"2021-06-03T09:26:21.65838Z","shell.execute_reply":"2021-06-03T09:26:21.908232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.12. Logistic Regression <a class=\"anchor\" id=\"6.12\"></a>","metadata":{}},{"cell_type":"markdown","source":"**Logistic Regression** is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Reference [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression).","metadata":{}},{"cell_type":"code","source":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nlogreg = LogisticRegression()\nlogreg_CV = GridSearchCV(estimator=logreg, param_grid={'C' : [.2, .3, .4]}, verbose=False)\nlogreg_CV.fit(train, target)\nprint(logreg_CV.best_params_, '\\n')\n\nytrain, ytest = acc(logreg_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:21.910809Z","iopub.execute_input":"2021-06-03T09:26:21.911147Z","iopub.status.idle":"2021-06-03T09:26:22.066308Z","shell.execute_reply.started":"2021-06-03T09:26:21.911118Z","shell.execute_reply":"2021-06-03T09:26:22.065283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.13. k-Nearest Neighbors (KNN) <a class=\"anchor\" id=\"6.13\"></a>","metadata":{}},{"cell_type":"markdown","source":"In pattern recognition, the **k-Nearest Neighbors algorithm** (or k-NN for short) is a non-parametric method used for classification and regression. A sample is classified by a majority vote of its neighbors, with the sample being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). Reference [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).","metadata":{}},{"cell_type":"code","source":"# KNN - k-Nearest Neighbors algorithm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nknn = KNeighborsClassifier()\nknn_CV = GridSearchCV(estimator=knn, param_grid={'n_neighbors': range(2, 7)}, \n                      verbose=False).fit(train, target)\nprint(knn_CV.best_params_, '\\n')\n\nytrain, ytest = acc(knn_CV, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:22.067402Z","iopub.execute_input":"2021-06-03T09:26:22.067671Z","iopub.status.idle":"2021-06-03T09:26:22.417736Z","shell.execute_reply.started":"2021-06-03T09:26:22.067646Z","shell.execute_reply":"2021-06-03T09:26:22.416751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.14. MLP Classifier <a class=\"anchor\" id=\"6.14\"></a>","metadata":{}},{"cell_type":"markdown","source":"The **MLPClassifier** optimizes the squared-loss using LBFGS or stochastic gradient descent by the Multi-layer Perceptron regressor. Reference [Sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor).","metadata":{}},{"cell_type":"code","source":"%%time\n# MLPClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nmlp = MLPClassifier()\nparam_grid = {'hidden_layer_sizes': [i for i in range(2,5)],\n              'solver': ['sgd'],\n              'learning_rate': ['adaptive'],\n              'max_iter': [1000]\n              }\nmlp_GS = GridSearchCV(mlp, param_grid=param_grid, verbose=False)\nmlp_GS.fit(train, target)\nprint(mlp_GS.best_params_, '\\n')\n\nytrain, ytest = acc(mlp_GS, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:22.419226Z","iopub.execute_input":"2021-06-03T09:26:22.419634Z","iopub.status.idle":"2021-06-03T09:26:36.927946Z","shell.execute_reply.started":"2021-06-03T09:26:22.41959Z","shell.execute_reply":"2021-06-03T09:26:36.926784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.15. Voting Classifier <a class=\"anchor\" id=\"6.15\"></a>","metadata":{}},{"cell_type":"markdown","source":"There is **VotingClassifier**. The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses. Reference [sklearn documentation](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier).","metadata":{}},{"cell_type":"code","source":"# See start at \"Tip 6.12. Logistic Regression\" (logreg_CV), \n# \"Tip 6.14. MLP Classifier\" (mlp_GS) and \"Tip 6.7. Linear SVC\" (linear_svc_CV)\n# Voting Classifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nVoting_ens = VotingClassifier(estimators=[('log', logreg_CV), ('mlp', mlp_GS ), ('svc', linear_svc_CV)])\nVoting_ens.fit(train, target)\n\nytrain, ytest = acc(Voting_ens, train, test, target, target_test, is_round=True)\nclassification_report_print(target, ytrain, 'for training data')\nclassification_report_print(target_test, ytest, 'for test data')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:36.929438Z","iopub.execute_input":"2021-06-03T09:26:36.929839Z","iopub.status.idle":"2021-06-03T09:26:50.397999Z","shell.execute_reply.started":"2021-06-03T09:26:36.929796Z","shell.execute_reply":"2021-06-03T09:26:50.397001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 6.16. Feature importance diagram <a class=\"anchor\" id=\"6.16\"></a>","metadata":{}},{"cell_type":"code","source":"# See start at \"Tip 6.11. LGBM Classifier\"\n# Feature importance diagram\nfig =  plt.figure(figsize = (10,10))\naxes = fig.add_subplot(111)\nlgb.plot_importance(modelL,ax = axes,height = 0.5)\nplt.show();\nplt.close()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:50.399075Z","iopub.execute_input":"2021-06-03T09:26:50.399335Z","iopub.status.idle":"2021-06-03T09:26:50.614874Z","shell.execute_reply.started":"2021-06-03T09:26:50.399309Z","shell.execute_reply":"2021-06-03T09:26:50.613947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In progress...","metadata":{}},{"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)","metadata":{}},{"cell_type":"markdown","source":"## 7. Analysis and visualization of modeling results<a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"### Tip 7.1. Drawing plot data with modeling results<a class=\"anchor\" id=\"7.1\"></a>","metadata":{}},{"cell_type":"code","source":"def plot_prediction(target, y_list, label_list, data_name, MAV=0.5):\n    # Thanks to https://www.kaggle.com/vbmokin/ai-ml-ds-training-l3at-nh4-nn-models\n    # Building plot with target, Maximum allowable value (MAV) and \n    # prediction for the data_name (training, validation or test) data by 3 models\n    \n    x = np.arange(len(y_list[0]))\n    plt.figure(figsize=(16,10))\n    if target is not None:\n        plt.scatter(x, target, label = \"Target data\")\n    for i in range(len(y_list)):\n        plt.scatter(x, y_list[i], label = label_list[i])\n    plt.plot(x, np.full(len(y_list[0]), MAV), label = \"Maximum allowable value\", color = 'r')\n    plt.title(f'Prediction for the {data_name} data')\n    plt.legend(loc='best')\n    plt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:50.616019Z","iopub.execute_input":"2021-06-03T09:26:50.616278Z","iopub.status.idle":"2021-06-03T09:26:50.62373Z","shell.execute_reply.started":"2021-06-03T09:26:50.616252Z","shell.execute_reply":"2021-06-03T09:26:50.622455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_name = ['Decision Tree prediction', 'Random Forest prediction']\nplot_prediction(target_w, [ytrain_dt_w, ytrain_rf_w], models_name, 'training', MAV=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:50.624975Z","iopub.execute_input":"2021-06-03T09:26:50.625325Z","iopub.status.idle":"2021-06-03T09:26:50.931895Z","shell.execute_reply.started":"2021-06-03T09:26:50.625297Z","shell.execute_reply":"2021-06-03T09:26:50.930884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tip 7.2. Drawing plot data of DataFrame (Pandas)<a class=\"anchor\" id=\"7.2\"></a>","metadata":{}},{"cell_type":"code","source":"# In progress...\n#df.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:50.933084Z","iopub.execute_input":"2021-06-03T09:26:50.933348Z","iopub.status.idle":"2021-06-03T09:26:50.936744Z","shell.execute_reply.started":"2021-06-03T09:26:50.933322Z","shell.execute_reply":"2021-06-03T09:26:50.935921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In progress...\n# Interactive plots out of the box in pandas\n# run !pip install hvplot\n#pd.options.plotting.backend = \"hvplot\"\n#df.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\", c = \"continent\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-03T09:26:50.937973Z","iopub.execute_input":"2021-06-03T09:26:50.93824Z","iopub.status.idle":"2021-06-03T09:26:50.947477Z","shell.execute_reply.started":"2021-06-03T09:26:50.938214Z","shell.execute_reply":"2021-06-03T09:26:50.946612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### See more in the notebook [50 Advanced Tips: Data Science for tabular data](https://www.kaggle.com/vbmokin/50-advanced-tips-data-science-for-tabular-data)","metadata":{}},{"cell_type":"markdown","source":"In progress...","metadata":{}},{"cell_type":"markdown","source":"## 8. BONUS<a class=\"anchor\" id=\"8\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"### Tip 8.1. Submission data from DataFrame to Kaggle competition<a class=\"anchor\" id=\"8.1\"></a>","metadata":{}},{"cell_type":"markdown","source":"### Competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)","metadata":{}},{"cell_type":"code","source":"# From https://www.kaggle.com/vbmokin/titanic-top-score-one-line-of-the-prediction\ntraindf = pd.read_csv('../input/titanic/train.csv').set_index('PassengerId')\ntestdf = pd.read_csv('../input/titanic/test.csv').set_index('PassengerId')\ndf = pd.concat([traindf, testdf], axis=0, sort=False)\ndf['Title'] = df.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ndf['IsWomanOrBoy'] = ((df.Title == 'Master') | (df.Sex == 'female'))\ndf['LastName'] = df.Name.str.split(',').str[0]\nfamily = df.groupby(df.LastName).Survived\ndf['WomanOrBoyCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).count())\ndf['WomanOrBoyCount'] = df.mask(df.IsWomanOrBoy, df.WomanOrBoyCount - 1, axis=0)\ndf['FamilySurvivedCount'] = family.transform(lambda s: s[df.IsWomanOrBoy].fillna(0).sum())\ndf['FamilySurvivedCount'] = df.mask(df.IsWomanOrBoy, df.FamilySurvivedCount - df.Survived.fillna(0), axis=0)\ndf['WomanOrBoySurvived'] = df.FamilySurvivedCount / df.WomanOrBoyCount.replace(0, np.nan)\ndf['Alone'] = (df.WomanOrBoyCount == 0)\ndf = pd.concat([df.WomanOrBoySurvived.fillna(0), df.Alone, df.Sex.replace({'male': 0, 'female': 1})], axis=1)\ntest_x = df.loc[testdf.index]\ntest_x['Survived'] = (((test_x.WomanOrBoySurvived <= 0.238) & (test_x.Sex > 0.5) & (test_x.Alone > 0.5)) | \\\n          ((test_x.WomanOrBoySurvived > 0.238) & \\\n           ~((test_x.WomanOrBoySurvived > 0.55) & (test_x.WomanOrBoySurvived <= 0.633))))\npd.DataFrame({'Survived': test_x['Survived'].astype(int)}, \\\n             index=testdf.index).reset_index().to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T09:26:50.949787Z","iopub.execute_input":"2021-06-03T09:26:50.950187Z","iopub.status.idle":"2021-06-03T09:26:52.168588Z","shell.execute_reply.started":"2021-06-03T09:26:50.950141Z","shell.execute_reply":"2021-06-03T09:26:52.167771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Result: the file \"submission.csv\" gives LB = 0.80382 (Top 4%)","metadata":{}},{"cell_type":"markdown","source":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","metadata":{"papermill":{"duration":0.043475,"end_time":"2020-11-15T02:05:28.535056","exception":false,"start_time":"2020-11-15T02:05:28.491581","status":"completed"},"tags":[]}}]}