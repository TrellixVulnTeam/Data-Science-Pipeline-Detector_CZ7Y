{"cells":[{"metadata":{},"cell_type":"markdown","source":"# A Beginner's Guide to Predictive Modelling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Find here data analysis, exploratory data analysis and several predictive modelling approaches implemented on the ever-famous titanic dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*P.S: This Notebook is designed to help people break into ML competitions involving predictive modelling and expose beginners to concepts such as feature extraction, binning, simple to intermediate visualizations and ensembling techniques, all through the most user friendly and insightful dataset*","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(url= \"https://media.nationalgeographic.org/assets/photos/000/273/27302.jpg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Contents of this notebook","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* [Initial review and preprocessing](#prepro)\n\n    - [Reading the dataset](#reading)\n    - [Understanding the structure](#structure)\n    - [Data Dictionary](#datadict)\n    - [Identifying Nans or Nulls](#nulls)\n    \n    \n* [Data Visualization and Exploratory Data Analysis](#dv)\n\n    - [Bar charts](#bar)\n    - [Correlation Maps](#corr)\n    \n    \n* [Feature Extraction and Feature Engineering](#fe)\n    \n    - [Title Mapping](#tit)\n    - [Gender Mapping](#gend)\n    - [Age Mapping & Binning](#age)\n    - [Pclass Mapping](#pclass)\n    - [Embarked Mapping](#emb)\n    - [Fare and Pclass Mapping](#fare)\n    - [Cabin Mapping](#cabin)\n    - [Family Size Mapping and Binning](#fam)\n    - [Dropping Unnecessary features](#drop)\n    \n    \n* [Predictive Modelling](#models)\n\n    - [Introducing K-Fold Cross Validation](#kfold)\n    - [Ensembling with 20 ML algorithms](#ensemble)\n    - [K- Nearest Neighbour Classifier](#knn)\n    - [Support Vector Machine Classifier](#svc)\n    \n    \n* [Submission of final predictions](#submit)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Initial Review and Preprocessing<a id=\"prepro\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1.1 Reading the dataset<a id=\"reading\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Shape:\",train.shape)\nprint(\"Test Shape:\",test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Understanding the structure<a id=\"structure\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3 Data Dictionary<a id=\"datadict\"></a>\n\n* Survived: 0 = No, 1 = Yes\n* pclass: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n* sibsp: # of siblings / spouses aboard the Titanic\n* parch: # of parents / children aboard the Titanic\n* ticket: Ticket number\n* cabin: Cabin number\n* embarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n\n**Total rows and columns**\n\nWe can see that there are 891 rows and 12 columns in our training dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4 Identifying the NaNs or Nulls<a id=\"nulls\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()\ntest[\"Survived\"] = \"\"\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Visualizations and Exploratory Data Analysis<a id=\"dv\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt # Plot the graphs\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Bar Chart for Categorical Features <a id=\"bar\"></a>\n\n* Pclass\n* Sex\n* SibSp ( # of siblings and spouse)\n* Parch ( # of parents and children)\n* Embarked\n* Cabin","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Sex')\nprint(\"Survived :\\n\",train[train['Survived']==1]['Sex'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['Sex'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Chart confirms **Women more likely survivied than Men**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Pclass')\nprint(\"Survived :\\n\",train[train['Survived']==1]['Pclass'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['Pclass'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Chart confirms **1st class** more likely survivied than **other classes**.  \nThe Chart confirms **3rd class** more likely dead than **other classes**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('SibSp')\nprint(\"Survived :\\n\",train[train['Survived']==1]['SibSp'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['SibSp'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Chart confirms a **person aboarded with more than 2 siblings or spouse** more likely survived.  \nThe Chart confirms a **person aboarded without siblings or spouse** more likely dead","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Parch')\nprint(\"Survived :\\n\",train[train['Survived']==1]['Parch'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['Parch'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Chart confirms a **person aboarded with more than 2 parents or children more likely survived.**  \nThe Chart confirms a **person aboarded alone more likely dead**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Embarked')\nprint(\"Survived :\\n\",train[train['Survived']==1]['Embarked'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['Embarked'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Chart confirms a **person aboarded from C** slightly more likely survived.  \nThe Chart confirms a **person aboarded from Q** more likely dead.  \nThe Chart confirms a **person aboarded from S** more likely dead.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Correlation charts and heatmaps <a id=\"corr\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\ng = sns.heatmap(corr,  vmax=.3, center=0,\n            square=True, linewidths=1, cbar_kws={\"shrink\": .5}, annot=True, fmt='.2f', cmap='coolwarm')\nsns.despine()\ng.figure.set_size_inches(12,8)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=train.corr()#[\"Survived\"]\nplt.figure(figsize=(10, 10))\n\nsns.heatmap(corr, vmax=.8, linewidths=0.01,\n            square=True,annot=True,cmap='YlGnBu',linecolor=\"white\")\nplt.title('Correlation between features');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Feature extraction & Feature Engineering <a id=\"fe\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Feature engineering is the process of using domain knowledge of the data\nto create features (**feature vectors**) that make machine learning algorithms work.  \n\nfeature vector is an n-dimensional vector of numerical features that represent some object.\nMany algorithms in machine learning require a numerical representation of objects,\nsince such representations facilitate processing and statistical analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Title Mapping <a id=\"tit\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_data = [train,test] # combine dataset\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Title Map\n\nMr : 0   \nMiss : 1  \nMrs: 2  \nOthers: 3  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset[\"Title\"].map(title_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Title')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete unnecessary feature from dataset\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Gender mapping <a id=\"gend\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_chart('Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Age mapping & Binning <a id=\"age\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace= True)\ntest[\"Age\"].fillna(test.groupby('Title')['Age'].transform(\"median\"), inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(30)\n#train.groupby(\"Title\")[\"Age\"].transform(\"median\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend() \nplt.show()\n\nfacet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend() \nplt.xlim(10,50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those who were **20 to 30 years old** were **more dead and more survived.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Binning**\n\nBinning/Converting Numerical Age to Categorical Variable\n\nfeature vector map:\n* child: 0\n* young: 1\n* adult: 2\n* mid-age: 3\n* senior: 4","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4\n# for dataset in train_test_data:\n#     dataset.loc[]\n#train[train['Age'].isin([23])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\nbar_chart('Age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4 Pclass Mappping <a id=\"pclass\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Pclass1 = train[train['Pclass'] == 1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass'] == 2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass'] == 3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1,Pclass2,Pclass3])\ndf.index = ['1st Class','2nd Class','3rd Class']\ndf.plot(kind = 'bar', stacked =  True, figsize=(10,5))\nplt.show()\nprint(\"Pclass1:\\n\",Pclass1)\nprint(\"Pclass2:\\n\",Pclass2)\nprint(\"Pclass3:\\n\",Pclass3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"more than 50 % of 1st class are from S embark.  \nmore than 50 % of 2st class are from S embark.   \nmore than 50 % of 3st class are from S embark.  \n\n**fill out missing embark with S embark**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.5 Embarked mapping <a id=\"emb\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test_data:\n    dataset['Embarked'] =  dataset['Embarked'].fillna('S')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embarked_mapping = {'S':0,'C':1,'Q':2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.6 Fare and Pclass mapping with binning<a id=\"fare\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"])\n# train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace = True)\n# test[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace = True)\n# train.head(50)\n\n\n# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4 )\nfacet.map(sns.kdeplot, 'Fare', shade = True)\nfacet.set(xlim = (0, train['Fare'].max()))\nfacet.add_legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test_data:\n    dataset.loc[dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[dataset['Fare'] >= 100, 'Fare'] = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.7 Cabin mapping <a id=\"cabin\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Cabin.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in train_test_data:\n    dataset['Cabin'] =  dataset['Cabin'].str[:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.8 Family Size mapping <a id=\"fam\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.8 Dropping unnecessary features <a id=\"drop\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features_drop = ['Ticket','SibSp','Parch']\ntrain = train.drop(features_drop, axis = 1)\ntest = test.drop(features_drop,axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train.drop('Survived', axis = 1)\ntarget = train['Survived']\ntrain_data.shape, target.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Predictive Modelling with several ML Algorithms and techniques <a id=\"models\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Introducing Cross Validation(k-fold) <a id=\"kfold\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data.copy()\nY = target.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Ensembling techniques <a id=\"ensemble\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Find here an Ensemble of 20 Benchmark ML models including tree classifiers, GBDTs, SVCs, Naive Bayes and LDA Classifiers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Ensembling ##\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process,model_selection\nimport xgboost\nfrom xgboost import XGBClassifier\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    #gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n    #xgboost\n    XGBClassifier()    \n    ]\n\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\nMLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\nMLA_predict = Y\nrow_index = 0\nX1 = X.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for alg in MLA:\n    X = train_data.copy()\n    Y = target.copy()\n    MLA_name = alg.__class__.__name__\n    print(\"Evaluating \",MLA_name)\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    cv_results = model_selection.cross_validate(alg, X, Y, cv  = cv_split)\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3\n    alg.fit(X, Y)\n    MLA_predict[MLA_name] = alg.predict(X)\n    row_index+=1\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MLA_compare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#barplot using https://seaborn.pydata.org/generated/seaborn.barplot.html\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *We next choose the 2 best classifiers in terms of preformance on validation set and use one of them to generate our test predictions*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.3 K-NN Classifier <a id=\"knn\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\nclf = [KNeighborsClassifier(n_neighbors = 13),DecisionTreeClassifier(),\n       RandomForestClassifier(n_estimators=13),GaussianNB(),SVC(),ExtraTreeClassifier(),\n      GradientBoostingClassifier(n_estimators=10, learning_rate=1,max_features=3, max_depth =3, random_state = 10),AdaBoostClassifier(),ExtraTreesClassifier()]\ndef model_fit():\n    scoring = 'accuracy'\n    for i in range(len(clf)):\n        score = cross_val_score(clf[i], train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n        print(\"Score of Model\",i,\":\",round(np.mean(score)*100,2))\n#     round(np.mean(score)*100,2)\n#     print(\"Score of :\\n\",score)\nmodel_fit()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.4 SVC Classifer <a id=\"svc\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = SVC()\nclf1.fit(train_data, target)\ntest\ntest_data = test.drop(['Survived','PassengerId'], axis=1)\nprediction = clf1.predict(test_data)\n# test_data\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Making Submission files ready<a id=\"submit\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Survived'] = prediction\nsubmission = pd.DataFrame(pd.concat([test['PassengerId'],test_data['Survived']],axis=1))\nsubmission.set_index('PassengerId',inplace = True)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"Submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### That's it!\n### Hope this notebook helped you navigate your way through predictive modelling techniques and EDA methods!\n\n### If this notebook piqued your interest in ML or helped you out in whatever way, kindly upvote :-) !","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}