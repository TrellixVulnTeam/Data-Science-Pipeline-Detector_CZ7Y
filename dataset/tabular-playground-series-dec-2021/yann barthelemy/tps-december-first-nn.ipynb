{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-08T16:51:27.281839Z","iopub.execute_input":"2021-12-08T16:51:27.282218Z","iopub.status.idle":"2021-12-08T16:51:27.310996Z","shell.execute_reply.started":"2021-12-08T16:51:27.282129Z","shell.execute_reply":"2021-12-08T16:51:27.310313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import modules :","metadata":{}},{"cell_type":"code","source":"import time\nimport datatable as dt\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport catboost\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.cluster import KMeans\nimport optuna\n# import imblearn\n#from imblearn.pipeline import make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.metrics import geometric_mean_score\nfrom imblearn.metrics import make_index_balanced_accuracy\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:51:31.641822Z","iopub.execute_input":"2021-12-08T16:51:31.642328Z","iopub.status.idle":"2021-12-08T16:51:33.449844Z","shell.execute_reply.started":"2021-12-08T16:51:31.64229Z","shell.execute_reply":"2021-12-08T16:51:33.449025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_STATE = 42\nN_SPLITS = 20\nCLIP_FEATURES = False\nCLUSTER_DISTANCE = False","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:19:21.265273Z","iopub.execute_input":"2021-12-08T17:19:21.266057Z","iopub.status.idle":"2021-12-08T17:19:21.270734Z","shell.execute_reply.started":"2021-12-08T17:19:21.266017Z","shell.execute_reply":"2021-12-08T17:19:21.269664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import data :","metadata":{}},{"cell_type":"code","source":"%%time\ntrain_file_name = \"/kaggle/input/tabular-playground-series-dec-2021/train.csv\"\ntest_file_name = \"/kaggle/input/tabular-playground-series-dec-2021/test.csv\"\nsubmission_file_name = \"/kaggle/input/tabular-playground-series-dec-2021/sample_submission.csv\"\ntrain_dt = dt.fread(train_file_name)\ntest_dt = dt.fread(test_file_name)\nsubmission = pd.read_csv(submission_file_name)    ","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:12:47.983648Z","iopub.execute_input":"2021-12-08T17:12:47.984369Z","iopub.status.idle":"2021-12-08T17:12:51.0091Z","shell.execute_reply.started":"2021-12-08T17:12:47.984313Z","shell.execute_reply":"2021-12-08T17:12:51.008237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize():\n    train_file_name = \"/kaggle/input/tabular-playground-series-dec-2021/train.csv\"\n    test_file_name = \"/kaggle/input/tabular-playground-series-dec-2021/test.csv\"\n    submission_file_name = \"/kaggle/input/tabular-playground-series-dec-2021/sample_submission.csv\"\n    train_dt = dt.fread(train_file_name)\n    test_dt = dt.fread(test_file_name)\n    submission = pd.read_csv(submission_file_name)\n    \n    X = train_dt.to_pandas()\n    X_test = test_dt.to_pandas()\n    \n    X = reduce_mem_usage(X)\n    X_test = reduce_mem_usage(X_test)\n    return X, X_test","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:12:55.299379Z","iopub.execute_input":"2021-12-08T17:12:55.300054Z","iopub.status.idle":"2021-12-08T17:12:55.305459Z","shell.execute_reply.started":"2021-12-08T17:12:55.300017Z","shell.execute_reply":"2021-12-08T17:12:55.304503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DATA FIELDS :  \n\n(from https://www.kaggle.com/c/forest-cover-type-prediction/overview)\n\nElevation - Elevation in meters\n\nAspect - Aspect in degrees azimuth\n\nSlope - Slope in degrees\n\nHorizontal_Distance_To_Hydrology - Horz Dist to nearest surface water features\n\nVertical_Distance_To_Hydrology - Vert Dist to nearest surface water features\n\nHorizontal_Distance_To_Roadways - Horz Dist to nearest roadway\n\nHillshade_9am (0 to 255 index) - Hillshade index at 9am, summer solstice\n\nHillshade_Noon (0 to 255 index) - Hillshade index at noon, summer solstice\n\nHillshade_3pm (0 to 255 index) - Hillshade index at 3pm, summer solstice\n\nHorizontal_Distance_To_Fire_Points - Horz Dist to nearest wildfire ignition points\n\nWilderness_Area (4 binary columns, 0 = absence or 1 = presence) - Wilderness area\ndesignation\n\nSoil_Type (40 binary columns, 0 = absence or 1 = presence) - Soil Type designation\n\nCover_Type (7 types, integers 1 to 7) - Forest Cover Type designation\n\n\n\nThe wilderness areas are:\n\n1 - Rawah Wilderness Area\n\n2 - Neota Wilderness Area\n\n3 - Comanche Peak Wilderness Area\n\n4 - Cache la Poudre Wilderness Area\n\n\n\nThe soil types are:\n\n1 Cathedral family - Rock outcrop complex, extremely stony.\n\n2 Vanet - Ratake families complex, very stony.\n\n3 Haploborolis - Rock outcrop complex, rubbly.\n\n4 Ratake family - Rock outcrop complex, rubbly.\n\n5 Vanet family - Rock outcrop complex complex, rubbly.\n\n6 Vanet - Wetmore families - Rock outcrop complex, stony.\n\n7 Gothic family.\n\n8 Supervisor - Limber families complex.\n\n9 Troutville family, very stony.\n\n10 Bullwark - Catamount families - Rock outcrop complex, rubbly.\n\n11 Bullwark - Catamount families - Rock land complex, rubbly.\n\n12 Legault family - Rock land complex, stony.\n\n13 Catamount family - Rock land - Bullwark family complex, rubbly.\n\n14 Pachic Argiborolis - Aquolis complex.\n\n15 unspecified in the USFS Soil and ELU Survey.\n\n16 Cryaquolis - Cryoborolis complex.\n\n17 Gateview family - Cryaquolis complex.\n\n18 Rogert family, very stony.\n\n19 Typic Cryaquolis - Borohemists complex.\n\n20 Typic Cryaquepts - Typic Cryaquolls complex.\n\n21 Typic Cryaquolls - Leighcan family, till substratum complex.\n\n22 Leighcan family, till substratum, extremely bouldery.\n\n23 Leighcan family, till substratum - Typic Cryaquolls complex.\n\n24 Leighcan family, extremely stony.\n\n25 Leighcan family, warm, extremely stony.\n\n26 Granile - Catamount families complex, very stony.\n\n27 Leighcan family, warm - Rock outcrop complex, extremely stony.\n\n28 Leighcan family - Rock outcrop complex, extremely stony.\n\n29 Como - Legault families complex, extremely stony.\n\n30 Como family - Rock land - Legault family complex, extremely stony.\n\n31 Leighcan - Catamount families complex, extremely stony.\n\n32 Catamount family - Rock outcrop - Leighcan family complex, extremely stony.\n\n33 Leighcan - Catamount families - Rock outcrop complex, extremely stony.\n\n34 Cryorthents - Rock land complex, extremely stony.\n\n35 Cryumbrepts - Rock outcrop - Cryaquepts complex.\n\n36 Bross family - Rock land - Cryumbrepts complex, extremely stony.\n\n37 Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.\n\n38 Leighcan - Moran families - Cryaquolls complex, extremely stony.\n\n39 Moran family - Cryorthents - Leighcan family complex, extremely stony.\n\n40 Moran family - Cryorthents - Rock land complex, extremely stony.","metadata":{}},{"cell_type":"code","source":"#Setting up options\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\npd.options.display.float_format = \"{:,.3f}\".format","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:51:51.469369Z","iopub.execute_input":"2021-12-08T16:51:51.469679Z","iopub.status.idle":"2021-12-08T16:51:51.475217Z","shell.execute_reply.started":"2021-12-08T16:51:51.46964Z","shell.execute_reply":"2021-12-08T16:51:51.474488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_dt.to_pandas()\nX = train_dt.to_pandas()\nX_test = test_dt.to_pandas()\ntarget = 'Cover_Type'\n\nX_id = X.Id\nX_test_id = X_test.Id","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:58:13.275647Z","iopub.execute_input":"2021-12-08T16:58:13.276241Z","iopub.status.idle":"2021-12-08T16:58:13.738196Z","shell.execute_reply.started":"2021-12-08T16:58:13.276182Z","shell.execute_reply":"2021-12-08T16:58:13.737342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features = [col for col in X.columns if X[col].dtype in ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']]\ncat_features = [col for col in X.columns if X[col].dtype in ['bool']]","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:51:52.000748Z","iopub.execute_input":"2021-12-08T16:51:52.001022Z","iopub.status.idle":"2021-12-08T16:51:52.010062Z","shell.execute_reply.started":"2021-12-08T16:51:52.000983Z","shell.execute_reply":"2021-12-08T16:51:52.009259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reduce memory","metadata":{}},{"cell_type":"code","source":"# will do 83.9% reduction im memory usage\ndef reduce_mem_usage(df, verbose=True):#from santander ml comp\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    for col in df.columns :\n        if df[col].dtype=='bool' :\n            df[col] = df[col].astype(int)\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n                    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:51:52.011165Z","iopub.execute_input":"2021-12-08T16:51:52.011855Z","iopub.status.idle":"2021-12-08T16:51:52.027638Z","shell.execute_reply.started":"2021-12-08T16:51:52.011815Z","shell.execute_reply":"2021-12-08T16:51:52.026462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = reduce_mem_usage(X)\nX_test = reduce_mem_usage(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:58:16.519998Z","iopub.execute_input":"2021-12-08T16:58:16.520685Z","iopub.status.idle":"2021-12-08T16:58:19.23521Z","shell.execute_reply.started":"2021-12-08T16:58:16.520644Z","shell.execute_reply":"2021-12-08T16:58:19.234334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature engineering :","metadata":{}},{"cell_type":"code","source":"%%time\nX, X_test = initialize()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:19:29.423239Z","iopub.execute_input":"2021-12-08T17:19:29.423784Z","iopub.status.idle":"2021-12-08T17:19:34.777363Z","shell.execute_reply.started":"2021-12-08T17:19:29.423743Z","shell.execute_reply":"2021-12-08T17:19:34.776576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineering(X, X_test, clip_features=CLIP_FEATURES, cluster_distance=CLUSTER_DISTANCE):\n    \"\"\"\n    X : train data set\n    X_test : test data set\n    clip_features : bool : clip features to naturale scale or handel them by other way : abs or rescaling\n    cluster_distance : bool : True if you want to add cluster_distance features else false\n    (do not improuve the score on kaggle comp with catboost. See with other models...)\n    return : X (modified, target droped), y : target, X_test (modified)\n    \n    \"\"\"\n    \n    # drop the only one sample with Cover_Type == 5 :\n    outlier=X[X.Cover_Type==5].index\n    X.drop(index=outlier, axis=1, inplace=True)\n    X.reset_index(inplace=True, drop=True)\n    print('Cover_Type 5 droped : just one sample')\n    \n    y = X.Cover_Type.astype(int)\n    X_test.drop(['Id'], axis=1, inplace=True)\n    X.drop(['Cover_Type', 'Id'], axis=1, inplace=True)\n    print('Target feature y created')\n    print('Features \"Id\" droped in train and test set. \"Cover_type\" droped in train set')\n    \n    \n    \n    # drop 'Soil_Type7' and 'Soil_Type15' : no sample\n    X.drop(['Soil_Type7', 'Soil_Type15'], axis=1, inplace=True)\n    X_test.drop(['Soil_Type7', 'Soil_Type15'], axis=1, inplace=True)\n    print('\"Soil_Type7\" and \"Soil_Type15\" features droped in train and test set : no samples')\n    \n    \n    # sum of soil type\n    soil_features=[f'Soil_Type{i}' for i in range(1,41) if not i in (7, 15) ]\n    X['sum_soil']=X[soil_features].sum(axis=1)\n    X_test['sum_soil']=X_test[soil_features].sum(axis=1)\n    print('feature \"sum_soil\" added')\n    \n    # Handle distance features, Aspect and Hillshade_features, wich are out of natural range : clip or else\n    # Aspect is supposed to be between 0 and 360\n    # Hillshade is supposed to be between 0 and 255 \n    # --> http://www.geography.hunter.cuny.edu/~jochen/gtech361/lectures/lecture11/concepts/hillshade.htm\n    # distance features are supposed to be positive\n    \n    distance_features = ['Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', \n                             'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points']\n    Hillshade_features = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n    \n    if clip_features:\n        # clip values for \"Aspect\" between 0° and 360°\n        X['Aspect'].clip(0, 360, inplace=True)\n        X_test['Aspect'].clip(0, 360, inplace=True)\n        print('Feature \"Aspect\" cliped between 0 and 360 in train and test set')\n    \n        # clip values for \"Hillshade_features\" between 0 and 255\n        for feature in Hillshade_features:\n            X[feature].clip(0, 255, inplace=True)\n            X_test[feature].clip(0, 255, inplace=True)\n        print('Features \"Hillshade\" cliped positive in train and test set')\n            \n        # clip values for distances >0\n        for feature in distance_features:\n            X[feature].clip(0, inplace=True)\n            X_test[feature].clip(0, inplace=True)\n        print('Distance features cliped positive in train and test set')\n        \n        X['Slope'].clip(0, inplace=True)\n        X_test['Slope'].clip(0, inplace=True)\n        print('\"Slope\" features cliped positive in train and test set')\n        \n    else :\n        \n        #X[\"Aspect\"][X[\"Aspect\"] < 0] += 360\n        #X[\"Aspect\"][X[\"Aspect\"] > 359] -= 360\n        X[\"Aspect\"] = X[\"Aspect\"].map(lambda x : x + 360 if x < 0 else (x- 360 if x> 359 else x))\n        \n        #X_test[\"Aspect\"][X_test[\"Aspect\"] < 0] += 360\n        #X_test[\"Aspect\"][X_test[\"Aspect\"] > 359] -= 360\n        X_test[\"Aspect\"] = X_test[\"Aspect\"].map(lambda x : x + 360 if x < 0 else (x- 360 if x> 359 else x))\n        print('Features \"Aspect\" rescaled between 0 and 360 in train and test set')\n        \n        for feature in distance_features:\n            X[feature] = np.abs(X[feature])\n            X_test[feature] = np.abs(X_test[feature])\n        print('Distance features rescaled positive in train and test set')\n        \n        X[\"Slope\"] = np.abs(X[\"Slope\"])\n        X_test[\"Slope\"] = np.abs(X_test[\"Slope\"])\n        print('\"Slope\" feature rescaled positive in train and test set')\n        \n        for feature in Hillshade_features:\n            X[feature] = X[feature].map(lambda x : -x if x < 0 else (x - (x - 255) if x> 255 else x))\n            X_test[feature] = X_test[feature].map(lambda x : -x if x < 0 else (x - (x - 255) if x> 255 else x))\n            \n        print('Features \"Hillshade\" rescaled in [0, 255] in train and test set')\n        \n    \n    # sum of Wilderness_Area features :\n    Wilderness_Area_features = [f'Wilderness_Area{i}' for i in range(1,5)]\n    X['sum_W_A']=X[Wilderness_Area_features].sum(axis=1)\n    X_test['sum_W_A']=X_test[Wilderness_Area_features].sum(axis=1)\n    print('feature \"sum_W_A\" added in train and test set')\n    \n    # Hillshade_features : mean and amplitude :\n    X['mean_Hillshade']=X[Hillshade_features].mean(axis=1)\n    X_test['mean_Hillshade']=X_test[Hillshade_features].mean(axis=1)\n    X['amp_Hillshade']=X[Hillshade_features].max(axis=1)-X[Hillshade_features].min(axis=1)\n    X_test['amp_Hillshade']=X_test[Hillshade_features].max(axis=1) - X_test[Hillshade_features].min(axis=1)\n    print('feature \"amp_Hillshade\" added in train and test set')\n    \n    # Euclidean distance to hydrology\n    X['dist_water']=np.sqrt(\n        np.square(X['Horizontal_Distance_To_Hydrology'].astype('int64')) + np.square(X['Vertical_Distance_To_Hydrology'].astype('int64'))\n            )\n    X_test['dist_water']=np.sqrt(\n        np.square(X_test['Horizontal_Distance_To_Hydrology'].astype('int64')) + np.square(X_test['Vertical_Distance_To_Hydrology'].astype('int64'))\n            )\n    print('feature \"dist_water\" added in train and test set')\n    \n    # Add cluster distances features : n_cluster =3 (best results after optuna tuning)\n    if cluster_distance :\n        # Add \"cluster distance to centroids\" features\n        n_clusters = 3\n        kmeans=KMeans(n_clusters=n_clusters)\n    \n        cluster_features = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n           'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n           'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n           'Horizontal_Distance_To_Fire_Points', 'mean_Hillshade', 'amp_Hillshade', 'dist_water']\n        X_test_scaled = X_test.loc[:, cluster_features]\n        X_test_scaled = (X_test_scaled - X_test_scaled.mean(axis=0)) / X_test_scaled.std(axis=0)\n        X_scaled = X.loc[:, cluster_features]\n        X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n        X_cd = kmeans.fit_transform(X_scaled)\n        X_test_cd = kmeans.transform(X_test_scaled)\n\n        X_cd = pd.DataFrame(X_cd, index =X.index,  columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])])\n        X = X.join(X_cd)\n        X_test_cd = pd.DataFrame(X_test_cd, index =X_test.index, columns=[f\"Centroid_{i}\" for i in range(X_test_cd.shape[1])])\n        X_test = X_test.join(X_test_cd)\n        print('Feature cluster distance added in train and test set')\n    print('Feature engineering done')\n    \n    return X, y, X_test","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:19:34.779209Z","iopub.execute_input":"2021-12-08T17:19:34.779634Z","iopub.status.idle":"2021-12-08T17:19:34.809266Z","shell.execute_reply.started":"2021-12-08T17:19:34.779582Z","shell.execute_reply":"2021-12-08T17:19:34.808494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y, X_test = feature_engineering(X, X_test, clip_features=CLIP_FEATURES, cluster_distance=CLUSTER_DISTANCE)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:19:34.810488Z","iopub.execute_input":"2021-12-08T17:19:34.811068Z","iopub.status.idle":"2021-12-08T17:19:46.830546Z","shell.execute_reply.started":"2021-12-08T17:19:34.811028Z","shell.execute_reply":"2021-12-08T17:19:46.829654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:18:59.177321Z","iopub.execute_input":"2021-12-08T17:18:59.177578Z","iopub.status.idle":"2021-12-08T17:18:59.205099Z","shell.execute_reply.started":"2021-12-08T17:18:59.177548Z","shell.execute_reply":"2021-12-08T17:18:59.204454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:14:24.960223Z","iopub.execute_input":"2021-12-08T17:14:24.96092Z","iopub.status.idle":"2021-12-08T17:14:28.356972Z","shell.execute_reply.started":"2021-12-08T17:14:24.960874Z","shell.execute_reply":"2021-12-08T17:14:28.355614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature='Horizontal_Distance_To_Roadways'\n# Horizontal_Distance_To_Fire_Points\nsns.displot(X[feature], kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:36:35.729864Z","iopub.execute_input":"2021-12-08T16:36:35.730537Z","iopub.status.idle":"2021-12-08T16:36:55.056914Z","shell.execute_reply.started":"2021-12-08T16:36:35.7305Z","shell.execute_reply":"2021-12-08T16:36:55.056078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature='Horizontal_Distance_To_Fire_Points'\nsns.displot(X[feature], kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:36:55.058453Z","iopub.execute_input":"2021-12-08T16:36:55.058864Z","iopub.status.idle":"2021-12-08T16:37:14.949618Z","shell.execute_reply.started":"2021-12-08T16:36:55.058824Z","shell.execute_reply":"2021-12-08T16:37:14.948921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature='Slope'\n# Horizontal_Distance_To_Fire_Points\nsns.displot(X[feature], kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-08T16:37:14.950903Z","iopub.execute_input":"2021-12-08T16:37:14.951309Z","iopub.status.idle":"2021-12-08T16:37:34.436911Z","shell.execute_reply.started":"2021-12-08T16:37:14.951272Z","shell.execute_reply":"2021-12-08T16:37:34.436141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\ntableW_A = pd.crosstab(X['sum_W_A'], y)\ntestW_A=chi2_contingency(tableW_A)\ntestW_A","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:37:23.508746Z","iopub.execute_input":"2021-12-06T07:37:23.509275Z","iopub.status.idle":"2021-12-06T07:37:23.860622Z","shell.execute_reply.started":"2021-12-06T07:37:23.509234Z","shell.execute_reply":"2021-12-06T07:37:23.859853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tableSoil = pd.crosstab(X['sum_soil'], y)\ntestSoil=chi2_contingency(tableSoil)\ntestSoil","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:37:23.862024Z","iopub.execute_input":"2021-12-06T07:37:23.862402Z","iopub.status.idle":"2021-12-06T07:37:24.194321Z","shell.execute_reply.started":"2021-12-06T07:37:23.862357Z","shell.execute_reply":"2021-12-06T07:37:24.193576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_mi_scores(X, y, discrete_features):\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:37:24.19555Z","iopub.execute_input":"2021-12-06T07:37:24.195794Z","iopub.status.idle":"2021-12-06T07:37:24.203345Z","shell.execute_reply.started":"2021-12-06T07:37:24.19576Z","shell.execute_reply":"2021-12-06T07:37:24.202566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discrete_features = [col for col in X.columns if X.loc(axis=1)[col].dtypes != 'float64']\ndiscrete_features = [col in discrete_features for col in X.columns]","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:37:24.20458Z","iopub.execute_input":"2021-12-06T07:37:24.204823Z","iopub.status.idle":"2021-12-06T07:37:24.215006Z","shell.execute_reply.started":"2021-12-06T07:37:24.204794Z","shell.execute_reply":"2021-12-06T07:37:24.214236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# discrete_features","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:37:24.216131Z","iopub.execute_input":"2021-12-06T07:37:24.216834Z","iopub.status.idle":"2021-12-06T07:37:24.22487Z","shell.execute_reply.started":"2021-12-06T07:37:24.21679Z","shell.execute_reply":"2021-12-06T07:37:24.22394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mi_scores = make_mi_scores(X, y, discrete_features)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T07:37:24.226218Z","iopub.execute_input":"2021-12-06T07:37:24.226916Z","iopub.status.idle":"2021-12-06T07:37:24.234231Z","shell.execute_reply.started":"2021-12-06T07:37:24.226868Z","shell.execute_reply":"2021-12-06T07:37:24.233441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### MI Scores : \nElevation                            0.618  \nWilderness_Area4                     0.066  \nHorizontal_Distance_To_Roadways      0.033  \nHorizontal_Distance_To_Fire_Points   0.022  \nWilderness_Area1                     0.019  \nsum_soil                             0.013  \nsum_W_A                              0.011  \nWilderness_Area3                     0.011  \nSoil_Type39                          0.006  \nSoil_Type10                          0.006  \nSoil_Type38                          0.004  \nVertical_Distance_To_Hydrology       0.004  \nSoil_Type6                           0.004  \nSoil_Type3                           0.003  \nSoil_Type40                          0.003  \nWilderness_Area2                     0.003  \nSoil_Type2                           0.003  \nSoil_Type23                          0.002  \ndist_water                           0.002  \nSoil_Type32                          0.002  \nmean_Hillshade                       0.002  \nHorizontal_Distance_To_Hydrology     0.002  \nSoil_Type33                          0.002  \nSoil_Type22                          0.001  \nSoil_Type29                          0.001  \nSlope                                0.001  \nSoil_Type30                          0.001  \nSoil_Type35                          0.001  \nSoil_Type4                           0.001  \nSoil_Type31                          0.001  \nSoil_Type13                          0.001  \nSoil_Type24                          0.001  \nSoil_Type37                          0.001  \nSoil_Type11                          0.000  \nSoil_Type17                          0.000  \nHillshade_3pm                        0.000  \nSoil_Type36                          0.000  \namp_Hillshade                        0.000  \nAspect                               0.000  \nSoil_Type12                          0.000  \nSoil_Type1                           0.000  \nHillshade_9am                        0.000  \nHillshade_Noon                       0.000  \nSoil_Type20                          0.000  \nSoil_Type19                          0.000  \nSoil_Type34                          0.000  \nSoil_Type14                          0.000  \nSoil_Type18                          0.000  \nSoil_Type16                          0.000  \nSoil_Type26                          0.000  \nSoil_Type21                          0.000  \nSoil_Type27                          0.000  \nSoil_Type28                          0.000  \nSoil_Type9                           0.000  \nSoil_Type25                          0.000  \nSoil_Type5                           0.000  \nSoil_Type8                           0.000","metadata":{}},{"cell_type":"code","source":"# mi_scores  \n# show a few features with their MI scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wilderness_Area_features :\nfor i in range(1,5) :\n    tableWilderness = pd.crosstab(X[f'Wilderness_Area{i}'], y)\n    print(f'Wilderness_Area{i} :\\n')\n    display(tableWilderness)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T13:20:32.262137Z","iopub.execute_input":"2021-12-05T13:20:32.263108Z","iopub.status.idle":"2021-12-05T13:20:33.72074Z","shell.execute_reply.started":"2021-12-05T13:20:32.263054Z","shell.execute_reply":"2021-12-05T13:20:33.719567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T13:20:33.726089Z","iopub.execute_input":"2021-12-05T13:20:33.726535Z","iopub.status.idle":"2021-12-05T13:20:33.770042Z","shell.execute_reply.started":"2021-12-05T13:20:33.726496Z","shell.execute_reply":"2021-12-05T13:20:33.768941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Can't be done : too long\n#%%time\n#sm = SMOTE(random_state=RANDOM_STATE, n_jobs=-1)\n#X, y = sm.fit_resample(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T13:21:58.283817Z","iopub.execute_input":"2021-12-05T13:21:58.28414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.to_pickle('../input/tabular-playground-series-dec-2021/X_resample.pkl')\ny.to_pickle('../input/tabular-playground-series-dec-2021/y_resample.pkl')\n# df = pd.read_pickle(file_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds=[]\ncount=0   \n\nalpha = 0.1\ngeo_mean = make_index_balanced_accuracy(alpha=alpha, squared=True)(geometric_mean_score)\n\ndef objective(trial):\n    \n    kf = StratifiedShuffleSplit(n_splits=N_SPLITS, test_size=0.2, random_state=RANDOM_STATE)\n    score=[]\n    score_geo=[]\n    global X_test\n    global count\n    idx=0\n    \n    \n    n_clusters = trial.suggest_int('n_clusters', 2, 10)\n    kmeans=KMeans(n_clusters=n_clusters)\n    \n    cluster_features = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n           'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n           'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n           'Horizontal_Distance_To_Fire_Points', 'mean_Hillshade', 'amp_Hillshade', 'dist_water']\n        \n    \n    idx=0\n    \n    for train_index, test_index in kf.split(X, y) :\n        \n        start = time.time()\n        \n        \n        X_train,  y_train = X.iloc[train_index], y.iloc[train_index]\n        X_valid, y_valid = X.iloc[test_index], y.iloc[test_index]\n        print(\"smote done\")       \n       \n        # Standardize\n        X_test_in = X_test.copy()\n        X_train_scaled = X_train.loc[:, cluster_features]\n        X_train_scaled = (X_train_scaled - X_train_scaled.mean(axis=0)) / X_train_scaled.std(axis=0)\n        X_valid_scaled = X_valid.loc[:, cluster_features]\n        X_valid_scaled = (X_valid_scaled - X_valid_scaled.mean(axis=0)) / X_valid_scaled.std(axis=0)\n        X_test_scaled = X_test_in.loc[:, cluster_features]\n        X_test_scaled = (X_test_scaled - X_test_scaled.mean(axis=0)) / X_test_scaled.std(axis=0)\n        #X_test_scaled = X_test_in.loc[:, cluster_features]\n        #X_test_scaled = (X_test_scaled - X_test_scaled.mean(axis=0)) / X_test_scaled.std(axis=0)\n        \n        \n        X_train_cd = kmeans.fit_transform(X_train_scaled)\n        X_valid_cd = kmeans.transform(X_valid_scaled)\n        # X_test_cd = kmeans.transform(X_test_scaled)\n        \n        # Label features and join to dataset\n        X_train_cd = pd.DataFrame(X_train_cd, index =X_train.index,  columns=[f\"Centroid_{i}\" for i in range(X_train_cd.shape[1])])\n        X_train = X_train.join(X_train_cd)\n        X_valid_cd = pd.DataFrame(X_valid_cd, index =X_valid.index, columns=[f\"Centroid_{i}\" for i in range(X_valid_cd.shape[1])])\n        X_valid = X_valid.join(X_valid_cd)\n        X_test_cd = kmeans.transform(X_test_scaled)\n        X_test_cd = pd.DataFrame(X_test_cd, index =X_test_in.index, columns=[f\"Centroid_{i}\" for i in range(X_test_cd.shape[1])])\n        X_test_in = X_test_in.join(X_test_cd)\n        \n        # cat_clf = make_pipeline(SMOTE(random_state=RANDOM_STATE), \n        #                            CatBoostClassifier(iterations=1000, task_type=\"GPU\")) \n        cat_clf = catboost.CatBoostClassifier(iterations=2000, task_type=\"GPU\")\n        cat_clf.fit(X_train, y_train, verbose=0) #eval_set=[X_valid, y_valid]\n        cat_preds = cat_clf.predict(X_valid)\n        cat_test_preds = cat_clf.predict(X_test_in)\n        test_preds.append(cat_test_preds)\n        score.append(accuracy_score(cat_preds, y_valid))\n        score_geo.append(geo_mean(cat_preds, y_valid))\n        end = time.time()\n        idx+=1\n        print(f'Finished round{count}, fold {idx} done in {end-start} with accuracy {accuracy_score(cat_preds, y_valid)} and geo_score {geo_mean(cat_preds, y_valid)}  ')\n    count+=1    \n    print(f'Round {count} finished with score {np.mean(score)} and geo_score {np.mean(score_geo)}')\n    return np.mean(score_geo)\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-12-06T08:00:51.265584Z","iopub.execute_input":"2021-12-06T08:00:51.265843Z","iopub.status.idle":"2021-12-06T08:00:51.283788Z","shell.execute_reply.started":"2021-12-06T08:00:51.265812Z","shell.execute_reply":"2021-12-06T08:00:51.283024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=20)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T08:00:52.354283Z","iopub.execute_input":"2021-12-06T08:00:52.354542Z","iopub.status.idle":"2021-12-06T12:52:50.674865Z","shell.execute_reply.started":"2021-12-06T08:00:52.354512Z","shell.execute_reply":"2021-12-06T12:52:50.674116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add \"cluster distance to centroids\" features\nn_clusters = 3\nkmeans=KMeans(n_clusters=n_clusters)\n    \ncluster_features = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n           'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n           'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n           'Horizontal_Distance_To_Fire_Points', 'mean_Hillshade', 'amp_Hillshade', 'dist_water']\nX_test_scaled = X_test.loc[:, cluster_features]\nX_test_scaled = (X_test_scaled - X_test_scaled.mean(axis=0)) / X_test_scaled.std(axis=0)\nX_scaled = X.loc[:, cluster_features]\nX_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\nX_cd = kmeans.fit_transform(X_scaled)\nX_test_cd = kmeans.transform(X_test_scaled)\n\nX_cd = pd.DataFrame(X_cd, index =X.index,  columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])])\nX = X.join(X_cd)\nX_test_cd = pd.DataFrame(X_test_cd, index =X_test.index, columns=[f\"Centroid_{i}\" for i in range(X_test_cd.shape[1])])\nX_test = X_test.join(X_test_cd)\n\n    \n ","metadata":{"execution":{"iopub.status.busy":"2021-12-05T19:59:37.373234Z","iopub.execute_input":"2021-12-05T19:59:37.373819Z","iopub.status.idle":"2021-12-05T20:00:32.303726Z","shell.execute_reply.started":"2021-12-05T19:59:37.373779Z","shell.execute_reply":"2021-12-05T20:00:32.302964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T20:00:32.305338Z","iopub.execute_input":"2021-12-05T20:00:32.305586Z","iopub.status.idle":"2021-12-05T20:00:32.336972Z","shell.execute_reply.started":"2021-12-05T20:00:32.305553Z","shell.execute_reply":"2021-12-05T20:00:32.336352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T20:00:32.338279Z","iopub.execute_input":"2021-12-05T20:00:32.338537Z","iopub.status.idle":"2021-12-05T20:00:32.368823Z","shell.execute_reply.started":"2021-12-05T20:00:32.338502Z","shell.execute_reply":"2021-12-05T20:00:32.368101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(study.best_trial)\nprint(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T22:48:04.700976Z","iopub.status.idle":"2021-12-05T22:48:04.701747Z","shell.execute_reply.started":"2021-12-05T22:48:04.701498Z","shell.execute_reply":"2021-12-05T22:48:04.701524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"FrozenTrial(number=1, values=[0.9606684999999999], datetime_start=datetime.datetime(2021, 12, 5, 10, 39, 14, 808230), datetime_complete=datetime.datetime(2021, 12, 5, 10, 46, 21, 260684), params={'n_clusters': 3}, distributions={'n_clusters': IntUniformDistribution(high=10, low=2, step=1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1, state=TrialState.COMPLETE, value=None)\n{'n_clusters': 3}","metadata":{}},{"cell_type":"code","source":"'''\nkf = StratifiedShuffleSplit(n_splits=N_SPLITS, test_size=0.2, random_state=RANDOM_STATE)\nX1 = pd.concat([X, X.iloc[y[y==5].index]], axis=0)\ny1 = pd.concat([y, y[y==5]], axis=0)\nfor train_index, test_index in kf.split(X1, y1.astype(int)) :\n    X_train = X1.iloc[train_index]\n    y_train = y1.iloc[train_index]\n    X_valid = X1.iloc[test_index]\n    y_valid = y1.iloc[test_index]\n    \n    n_clusters = 4\n        \n    cluster_features = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n           'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n           'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n           'Horizontal_Distance_To_Fire_Points', 'mean_Hillshade', 'amp_Hillshade', 'dist_water']\n        \n    kmeans=KMeans(n_clusters=n_clusters)\n    # Standardize\n    X_train_scaled = X_train.loc[:, cluster_features]\n    X_train_scaled = (X_train_scaled - X_train_scaled.mean(axis=0)) / X_train_scaled.std(axis=0)\n    X_valid_scaled = X_valid.loc[:, cluster_features]\n    X_valid_scaled = (X_valid_scaled - X_valid_scaled.mean(axis=0)) / X_valid_scaled.std(axis=0)\n    \n    X_train_cd = kmeans.fit_transform(X_train_scaled)\n    X_valid_cd = kmeans.transform(X_valid_scaled)\n    print('X_train_cd :')\n    display(X_train_cd[:5])\n    print('X_train_cd.shape :', X_train_cd.shape)\n    \n    print('----------------')\n    print('X_valid_cd :')\n    display(X_valid_cd[:5])\n    print('X_valid_cd.shape :', X_valid_cd.shape)\n    \n    # Label features and join to dataset\n    X_train_cd = pd.DataFrame(X_train_cd, index =X_train.index,  columns=[f\"Centroid_{i}\" for i in range(X_train_cd.shape[1])])\n    X_train = X_train.join(X_train_cd)\n    X_valid_cd = pd.DataFrame(X_valid_cd, index =X_valid.index, columns=[f\"Centroid_{i}\" for i in range(X_valid_cd.shape[1])])\n    display(X_valid_cd.head(5))\n    X_valid = X_valid.join(X_valid_cd)\n    print('--------------------------')\n    print('X_train :')\n    display(X_train.head(5))\n    print('--------------------------')\n    print('X_valid :')\n    display(X_valid.head(5))\n'''","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:07:08.409341Z","iopub.execute_input":"2021-12-04T16:07:08.409694Z","iopub.status.idle":"2021-12-04T16:11:41.300339Z","shell.execute_reply.started":"2021-12-04T16:07:08.409659Z","shell.execute_reply":"2021-12-04T16:11:41.299303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T15:32:20.643423Z","iopub.execute_input":"2021-12-04T15:32:20.644513Z","iopub.status.idle":"2021-12-04T15:32:20.972844Z","shell.execute_reply.started":"2021-12-04T15:32:20.644465Z","shell.execute_reply":"2021-12-04T15:32:20.971891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling :","metadata":{}},{"cell_type":"code","source":"cat_clf = catboost.CatBoostClassifier(iterations=2000, task_type=\"GPU\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:19:56.393327Z","iopub.execute_input":"2021-12-08T17:19:56.393609Z","iopub.status.idle":"2021-12-08T17:19:56.40241Z","shell.execute_reply.started":"2021-12-08T17:19:56.393562Z","shell.execute_reply":"2021-12-08T17:19:56.401471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_predictions = [] # list of predictions for X_test on every split\nfinal_valid_predictions = {} # key : index of validation set, values : predictions for X_valid on every split (probabilities)\nscores = []\nscore_geo=[]\n\nkf = StratifiedShuffleSplit(n_splits=N_SPLITS, test_size=0.2, random_state=RANDOM_STATE)\nalpha = 0.1\ngeo_mean = make_index_balanced_accuracy(alpha=alpha, squared=True)(geometric_mean_score)\n\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X = X, y = y)):\n    start = time.time()\n    print(10*\"=\", f\"Fold={fold}\", 10*\"=\")\n\n    x_train = X.loc[train_idx, :]\n    x_valid = X.loc[valid_idx, :]\n    y_train = y[train_idx]\n    y_valid = y[valid_idx]\n    cat_clf = catboost.CatBoostClassifier(iterations=2000, task_type=\"GPU\")\n    \n    cat_clf.fit(x_train, y_train, verbose=0)\n\n    preds_valid = cat_clf.predict(x_valid)\n    final_valid_predictions.update(dict(zip(valid_idx, preds_valid)))\n    \n    accur = accuracy_score(y_valid, preds_valid)\n    geo_score = geo_mean(y_valid, preds_valid)\n    scores.append(accur)\n    score_geo.append(geo_score)\n    #loss = log_loss(y_valid, preds_valid)\n    print('accuracy: ', accur)\n    print('geo_score', geo_score)\n    \n    \n    \n    test_preds = cat_clf.predict(X_test)\n    final_test_predictions.append(test_preds)\n    end = time.time()\n    print(f\"Finished fold {fold} in {end - start}\")\n ","metadata":{"execution":{"iopub.status.busy":"2021-12-08T17:26:08.060198Z","iopub.execute_input":"2021-12-08T17:26:08.060936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"scores -> mean: {np.mean(scores)}, std: {np.std(scores)}\")\nprint(f\"scores_geo -> mean: {np.mean(score_geo)}, std: {np.std(score_geo)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dict values : rows of the df\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"train_pred_1.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(np.column_stack(final_test_predictions))\n\ndf.head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mod = df.mode(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T22:24:13.154872Z","iopub.execute_input":"2021-12-05T22:24:13.155389Z","iopub.status.idle":"2021-12-05T22:30:04.343523Z","shell.execute_reply.started":"2021-12-05T22:24:13.155351Z","shell.execute_reply":"2021-12-05T22:30:04.342672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mod2 = mod.loc[:,0].astype(int) ","metadata":{"execution":{"iopub.status.busy":"2021-12-05T22:30:04.345314Z","iopub.execute_input":"2021-12-05T22:30:04.345605Z","iopub.status.idle":"2021-12-05T22:30:04.353312Z","shell.execute_reply.started":"2021-12-05T22:30:04.345565Z","shell.execute_reply":"2021-12-05T22:30:04.352372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mod2.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T21:22:38.612161Z","iopub.execute_input":"2021-12-05T21:22:38.612659Z","iopub.status.idle":"2021-12-05T21:22:38.619279Z","shell.execute_reply.started":"2021-12-05T21:22:38.612622Z","shell.execute_reply":"2021-12-05T21:22:38.618456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#col=mod.loc[:5,0].astype(int)\n#col","metadata":{"execution":{"iopub.status.busy":"2021-12-05T21:21:19.376697Z","iopub.execute_input":"2021-12-05T21:21:19.376953Z","iopub.status.idle":"2021-12-05T21:21:19.383697Z","shell.execute_reply.started":"2021-12-05T21:21:19.376924Z","shell.execute_reply":"2021-12-05T21:21:19.382909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df['mode']=mod","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_test=df.loc[70:80]\n#df_test","metadata":{"execution":{"iopub.status.busy":"2021-12-05T20:51:44.992016Z","iopub.execute_input":"2021-12-05T20:51:44.992292Z","iopub.status.idle":"2021-12-05T20:51:45.001703Z","shell.execute_reply.started":"2021-12-05T20:51:44.99226Z","shell.execute_reply":"2021-12-05T20:51:45.00103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mod2=df_test.mode(axis=1)\ndf_test['mode']=mod2\ndf_test.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Cover_Type'] = mod2\n\nsubmission.to_csv(\"test_pred_1.csv\",index=None)\nsubmission.to_csv(\"catboost_cv_FE.csv\",index=None)\nsubmission[70:79]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[70:79]","metadata":{"execution":{"iopub.status.busy":"2021-12-05T22:30:07.749726Z","iopub.execute_input":"2021-12-05T22:30:07.750135Z","iopub.status.idle":"2021-12-05T22:30:07.758244Z","shell.execute_reply.started":"2021-12-05T22:30:07.750098Z","shell.execute_reply":"2021-12-05T22:30:07.757548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('done')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T20:09:11.083545Z","iopub.execute_input":"2021-12-05T20:09:11.083747Z","iopub.status.idle":"2021-12-05T20:09:11.090038Z","shell.execute_reply.started":"2021-12-05T20:09:11.083722Z","shell.execute_reply":"2021-12-05T20:09:11.089113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nfrom catboost import *\nexplainer = shap.TreeExplainer(cat_clf)\nshap_values = explainer.shap_values(X)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T19:17:11.125935Z","iopub.execute_input":"2021-12-05T19:17:11.12629Z","iopub.status.idle":"2021-12-05T19:17:12.226986Z","shell.execute_reply.started":"2021-12-05T19:17:11.126228Z","shell.execute_reply":"2021-12-05T19:17:12.226064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize the first prediction's explanation\nshap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize the effects of all the features\nshap.summary_plot(shap_values, X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_preds = cat_clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T19:18:07.334389Z","iopub.execute_input":"2021-12-02T19:18:07.334967Z","iopub.status.idle":"2021-12-02T19:18:10.443748Z","shell.execute_reply.started":"2021-12-02T19:18:07.334923Z","shell.execute_reply":"2021-12-02T19:18:10.442996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Cover_Type'] = cat_preds\nsubmission.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T19:18:10.444719Z","iopub.execute_input":"2021-12-02T19:18:10.444917Z","iopub.status.idle":"2021-12-02T19:18:10.459006Z","shell.execute_reply.started":"2021-12-02T19:18:10.444893Z","shell.execute_reply":"2021-12-02T19:18:10.458291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T19:18:10.46027Z","iopub.execute_input":"2021-12-02T19:18:10.46046Z","iopub.status.idle":"2021-12-02T19:18:11.675985Z","shell.execute_reply.started":"2021-12-02T19:18:10.460436Z","shell.execute_reply":"2021-12-02T19:18:11.675153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"V1 : without FE:\nKaggle score : 0.95310\n\nV2 : with FE : \nKaggle score : 0.95460\n\nV3 : with cv, FE and cluster distance : 0.95466\n\nV4 : with cv, FE without cluster distance : 0.95484\n\nV5 : with cv no FE : 0.95397\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}