{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## To  do: \n\n#### 1. Ensemble \n- create a model with Cross Val (find best)\n- Create model with Neural Network (seperate kernel)\n- Add probabilities together and argmax\n\n#### 2. DART Cross val\n- Run outside Kaggle as takes too long \n\n#### 3. Check Clipped values feature importance -- maybe remove\n\n#### 4. Fold Additional Data into Cross Val ","metadata":{}},{"cell_type":"markdown","source":"# Project Description and goals \nIn this months Tabular Playground we have a synthetic [forest cover dataset ](https://www.kaggle.com/c/forest-cover-type-prediction/data). \n\n## Process:\n### 1. Feature engineering \n* feature extraction - as per notebooks and competition discussions \n* feature processing - duplicates, nulls etc \n\n### 2. Data Augmentation \n* Sampling  - over / under sampling \n* Additional data - external / synthetic(oversampling) \\   \n* Feature Selection  - PCA \n\n### 3. Model Build  / Transfer learning \n* Model type  **Note** will only use LIGHTGBM\n* Loss / error type - multilogloss\n* Model build - classifier, train, cross-val\n\n### 4. Training Schedule and Optimization\n* Optimize LIGHTGBM  ---needed for multiple experiments \n* Parameter Tuning - Optuna \n\n### 5. Post processing \n* Improve post predicted values - calibration\n\nScoring metric = accuracy","metadata":{}},{"cell_type":"markdown","source":"## Experiments \nI ran multiple experiments using different parameters, the main experiments and submission scores are below:\n\n<style type=\"text/css\">\n.tg  {border-collapse:collapse;border-spacing:0;}\n.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n.tg .tg-vfn0{background-color:#efefef;border-color:#000000;text-align:left;vertical-align:top}\n.tg .tg-cjtp{background-color:#ecf4ff;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-l0ny{background-color:#FFCE93;border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-pwrz{background-color:#FD6864;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-jio7{background-color:#FD6864;border-color:#000000;text-align:left;vertical-align:top}\n.tg .tg-tcpe{background-color:#ecf4ff;border-color:inherit;color:#333333;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-l6ss{background-color:#3531ff;border-color:#6200c9;color:#ffffff;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-mylm{background-color:#ecf4ff;border-color:#000000;color:#333333;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-zv36{background-color:#ffffff;border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-7od5{background-color:#9aff99;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-jxgv{background-color:#FFF;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-dvid{background-color:#efefef;border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-pdeq{background-color:#FFF;border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-y698{background-color:#efefef;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-pidv{background-color:#ffce93;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-fymr{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-73oq{border-color:#000000;text-align:left;vertical-align:top}\n.tg .tg-112g{background-color:#67FD9A;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-q32f{background-color:#9AFF99;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-smvl{background-color:#fd6864;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-kbue{background-color:#9aff99;border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n.tg .tg-c6of{background-color:#ffffff;border-color:inherit;text-align:left;vertical-align:top}\n.tg .tg-fgdu{background-color:#ecf4ff;border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n</style>\n<table class=\"tg\">\n<thead>\n  <tr>\n    <th class=\"tg-l6ss\">No.</th>\n    <th class=\"tg-l6ss\">Name</th>\n    <th class=\"tg-l6ss\">Version</th>\n    <th class=\"tg-l6ss\">Model Type</th>\n    <th class=\"tg-l6ss\">Optuna</th>\n    <th class=\"tg-l6ss\">Additional Data</th>\n    <th class=\"tg-l6ss\">Boosting Type</th>\n    <th class=\"tg-l6ss\">Scaler</th>\n    <th class=\"tg-l6ss\">Score</th>\n    <th class=\"tg-l6ss\">To Rerun</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <td class=\"tg-0pky\">1</td>\n    <td class=\"tg-tcpe\" rowspan=\"4\">Scaler</td>\n    <td class=\"tg-0pky\">117</td>\n    <td class=\"tg-0pky\">Cross Val</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Robust</td>\n    <td class=\"tg-0pky\">0.95562</td>\n    <td class=\"tg-pdeq\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\">2</td>\n    <td class=\"tg-0pky\">212</td>\n    <td class=\"tg-0pky\">Cross Val</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">MinMax </td>\n    <td class=\"tg-0pky\">0.95570</td>\n    <td class=\"tg-pdeq\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\">3</td>\n    <td class=\"tg-0pky\">213</td>\n    <td class=\"tg-0pky\">Cross Val</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Standard</td>\n    <td class=\"tg-0pky\">0.95570</td>\n    <td class=\"tg-pdeq\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\">4</td>\n    <td class=\"tg-0pky\">251</td>\n    <td class=\"tg-0pky\">Cross Val</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">None</td>\n    <td class=\"tg-7od5\">0.95571</td>\n    <td class=\"tg-zv36\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\">5</td>\n    <td class=\"tg-tcpe\" rowspan=\"2\">Optuna </td>\n    <td class=\"tg-y698\">173</td>\n    <td class=\"tg-pidv\">Train</td>\n    <td class=\"tg-pidv\">Yes</td>\n    <td class=\"tg-pidv\">PSEUDO 2<br>Original Data (Complete)</td>\n    <td class=\"tg-pidv\">GBDT</td>\n    <td class=\"tg-pidv\">None</td>\n    <td class=\"tg-pidv\">0.95496</td>\n    <td class=\"tg-l0ny\">Rerunning</td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\">6</td>\n    <td class=\"tg-y698\">240</td>\n    <td class=\"tg-y698\">Train</td>\n    <td class=\"tg-y698\">Yes</td>\n    <td class=\"tg-y698\">PSEUDO 2</td>\n    <td class=\"tg-y698\">GBDT</td>\n    <td class=\"tg-dvid\">MinMax</td>\n    <td class=\"tg-7od5\">BASELINE</td>\n    <td class=\"tg-zv36\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\">9</td>\n    <td class=\"tg-tcpe\" rowspan=\"3\">Model Type</td>\n    <td class=\"tg-0pky\">86</td>\n    <td class=\"tg-0pky\">Train</td>\n    <td class=\"tg-0pky\">Yes</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Robust</td>\n    <td class=\"tg-7od5\">0.95491</td>\n    <td class=\"tg-0pky\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\">10</td>\n    <td class=\"tg-0pky\">112</td>\n    <td class=\"tg-0pky\">Classifier</td>\n    <td class=\"tg-0pky\">Yes</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Robust</td>\n    <td class=\"tg-7od5\">0.95510</td>\n    <td class=\"tg-0pky\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\">11</td>\n    <td class=\"tg-0pky\">107</td>\n    <td class=\"tg-0pky\">Cross Val</td>\n    <td class=\"tg-0pky\">Yes</td>\n    <td class=\"tg-0pky\">NO</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Robust</td>\n    <td class=\"tg-7od5\">0.95556</td>\n    <td class=\"tg-fymr\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-73oq\">12</td>\n    <td class=\"tg-mylm\">DART</td>\n    <td class=\"tg-vfn0\">238</td>\n    <td class=\"tg-vfn0\">Train</td>\n    <td class=\"tg-vfn0\">No</td>\n    <td class=\"tg-vfn0\">PSEUDO 2</td>\n    <td class=\"tg-vfn0\">DART</td>\n    <td class=\"tg-vfn0\">Robust</td>\n    <td class=\"tg-vfn0\">0.95532</td>\n    <td class=\"tg-jio7\">RE-RUNNING HOME</td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-cjtp\" rowspan=\"11\"><span style=\"font-weight:bold\">CROSS VAL</span></td>\n    <td class=\"tg-fymr\">259</td>\n    <td class=\"tg-fymr\">Train </td>\n    <td class=\"tg-fymr\">No</td>\n    <td class=\"tg-fymr\">PSEUDO 2</td>\n    <td class=\"tg-fymr\">GBDT</td>\n    <td class=\"tg-fymr\">MinMax</td>\n    <td class=\"tg-112g\">0.95692</td>\n    <td class=\"tg-jxgv\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">260</td>\n    <td class=\"tg-0pky\">Train </td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">PSEUDO 2<br>Original Data (4,5,6)</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">MinMax</td>\n    <td class=\"tg-7od5\">0.95692</td>\n    <td class=\"tg-jxgv\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">267</td>\n    <td class=\"tg-0pky\">Train </td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">PSEUDO 2<br>Original Data (Complete)</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">MinMax</td>\n    <td class=\"tg-7od5\">0.95692</td>\n    <td class=\"tg-jxgv\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">220</td>\n    <td class=\"tg-0pky\">Train </td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">PSEUDO 2</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Robust</td>\n    <td class=\"tg-q32f\">0.95688</td>\n    <td class=\"tg-smvl\">RE-RUNNING 261</td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">228</td>\n    <td class=\"tg-0pky\">Train </td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">PSEUDO 2<br>Original Data (4,5,6)</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Robust</td>\n    <td class=\"tg-q32f\">0.95689</td>\n    <td class=\"tg-jxgv\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-pidv\">234</td>\n    <td class=\"tg-pidv\">Train </td>\n    <td class=\"tg-pidv\">No</td>\n    <td class=\"tg-pidv\">PSEUDO 2<br>Original Data (Complete)</td>\n    <td class=\"tg-pidv\">GBDT</td>\n    <td class=\"tg-pidv\">Robust</td>\n    <td class=\"tg-112g\">0.95690</td>\n    <td class=\"tg-pwrz\">RE-RUNNING 266</td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">Train </td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">PSEUDO 2</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Standard</td>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-pwrz\">RUNNING 262</td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">264</td>\n    <td class=\"tg-0pky\">Train </td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">PSEUDO 2<br>Original Data (Complete)</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">Standard</td>\n    <td class=\"tg-7od5\">0.95684</td>\n    <td class=\"tg-jxgv\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">258</td>\n    <td class=\"tg-0pky\">Train </td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">PSEUDO 2</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">None</td>\n    <td class=\"tg-7od5\">0.95691</td>\n    <td class=\"tg-jxgv\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-fymr\">252</td>\n    <td class=\"tg-fymr\">Train </td>\n    <td class=\"tg-fymr\">No</td>\n    <td class=\"tg-fymr\">PSEUDO 2<br>Original Data (Complete)</td>\n    <td class=\"tg-fymr\">GBDT</td>\n    <td class=\"tg-fymr\">None</td>\n    <td class=\"tg-kbue\">0.95701</td>\n    <td class=\"tg-jxgv\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">253</td>\n    <td class=\"tg-0pky\">Train - unbalanced false</td>\n    <td class=\"tg-0pky\">No</td>\n    <td class=\"tg-0pky\">PSEUDO 2<br>Original Data (Complete)</td>\n    <td class=\"tg-0pky\">GBDT</td>\n    <td class=\"tg-0pky\">None</td>\n    <td class=\"tg-7od5\">NO Change</td>\n    <td class=\"tg-c6of\"></td>\n  </tr>\n  <tr>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-fgdu\">Ensemble</td>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\">Train, Class, Cross_val</td>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\"></td>\n    <td class=\"tg-0pky\"></td>\n  </tr>\n</tbody>\n</table>\n\n**BEST Run** CROSS VAL v252 - No Scaling PSEUDO 2 +ADD DATA(Complete) **BEST**  ==0.95691 ","metadata":{}},{"cell_type":"markdown","source":"#### Over Sampling techniques \nTo check \n\n#### PCA\nTo check\n\n#### Summary \n* Hyperparameters tuning              ---- using Optuna \n* Oversampling                        ---- duplicated class5 increases accuracy -- checking SMOTEENN and SMOTEtomek\n* clustering                          ---- Kmeans reduces accuracy                  ---- CHECKING DBSCAN\n* Calibration                         ---- sigmoid reduces accuracy-- \"isotonic\" seems to improve accuracy\n* Cross Validation                    ---- Checking \n* pseudo labelling                    ---- CHECKING \n* Scaling                             ---- Unsure - need to confirm with standardised params","metadata":{}},{"cell_type":"markdown","source":"# Libraries ","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nfrom sklearn.calibration import CalibratedClassifierCV\n\n#scaling \nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n\nfrom scipy.stats import mode\n\n#model\nimport lightgbm as lgb\n\n# parameter tuning\nimport optuna\n\n# over and under sampling\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.combine import SMOTETomek\nfrom imblearn.under_sampling import CondensedNearestNeighbour\n\n# analysis and files\nfrom collections import Counter\nimport time\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-12-31T14:08:03.337446Z","iopub.execute_input":"2021-12-31T14:08:03.338109Z","iopub.status.idle":"2021-12-31T14:08:06.653551Z","shell.execute_reply.started":"2021-12-31T14:08:03.33803Z","shell.execute_reply":"2021-12-31T14:08:06.652429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Experiments","metadata":{}},{"cell_type":"code","source":"#Boosting\n#dart has dropout and should stop overfitting , -- very long to run\n#gdbt is default with good accuracy but tends to overfit\n# goss is fast to converge \n\n#Scaling \n#Robust is good with outliers \nSCALER_NAME = \"None\"   #None\nSCALER = MinMaxScaler() # RobustScaler() MinMaxScaler() StandardScaler()\n\n## additional data and sampling\nPSEUDOLABEL =2\nADD_DATA = False\nCLUSTERING = False \nsample_technique = \"class5\" #'class5' \"none\" \"SMOTEENN\" \"SMOTETomek\"  \"PCA\"   ----SMOTEEN and SMOTETomek needs Add Data to run \n\n#Training Type and Tuning \nOPTUNA = False\nNUM_TRIALS  = 200\n\n#Training Params\nMODEL_TYPE = \"Cross_validation\" #\"train\" \"classifier\" \"classifier_cal\" \"Cross_validation\"\nFull_Train = False # retrain model on full dataset\n\nFOLDS = 20\nBOOSTING = 'gbdt'  # \"goss\" 'dart'  'gbdt'\nEARLY_STOPPING_ROUNDS = 30 #20\nEPOCHS = 1000 #1000\n\n# Post processing \nCALIBRATION_METHOD = 'isotonic' #'sigmoid'","metadata":{"execution":{"iopub.status.busy":"2021-12-31T14:08:06.655433Z","iopub.execute_input":"2021-12-31T14:08:06.655798Z","iopub.status.idle":"2021-12-31T14:08:06.662529Z","shell.execute_reply.started":"2021-12-31T14:08:06.655762Z","shell.execute_reply":"2021-12-31T14:08:06.661664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Params \nDOWNCASTING = True\n\nDEVICE = \"cpu\" #\"gpu\" cpu\n\n# multi classification method - weightings \nUNBALANCED = True\n\nMETRIC = \"multi_logloss\"","metadata":{"execution":{"iopub.status.busy":"2021-12-31T14:08:06.663777Z","iopub.execute_input":"2021-12-31T14:08:06.663997Z","iopub.status.idle":"2021-12-31T14:08:06.67678Z","shell.execute_reply.started":"2021-12-31T14:08:06.663968Z","shell.execute_reply":"2021-12-31T14:08:06.675995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title = \"CROSS - Best Params -no scaling- PSEUDO 2+ADD DATA (Complete)\"\nversion = 1\nminor = 0\n\nf= open(f\"log_file_{version}_{minor}.txt\",\"a\")\nf.write(f\"########################### {title} ########################### \")\nf.write(f\"\\n Boosting type: {BOOSTING}\")\nf.write(f\"\\n Sampling technique: {sample_technique}\")\nf.write(f\"\\n Scaler: {SCALER_NAME}\")\nf.write(f\"\\n Hyper Parameter Tuning: {OPTUNA}\")\nf.write(f\"\\n Model Type: {MODEL_TYPE}\")\nf.write(f\"\\n Pseudo labelling : {PSEUDOLABEL}\")\nf.close()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:25.569681Z","iopub.execute_input":"2021-12-29T06:29:25.57019Z","iopub.status.idle":"2021-12-29T06:29:25.581682Z","shell.execute_reply.started":"2021-12-29T06:29:25.570143Z","shell.execute_reply":"2021-12-29T06:29:25.580886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Enable LightGBM GPU","metadata":{}},{"cell_type":"code","source":"\"\"\"!pip uninstall -y lightgbm\n!apt-get install -y libboost-all-dev\n!git clone --recursive https://github.com/Microsoft/LightGBM\"\"\"","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-29T06:29:25.584251Z","iopub.execute_input":"2021-12-29T06:29:25.584744Z","iopub.status.idle":"2021-12-29T06:29:25.601626Z","shell.execute_reply.started":"2021-12-29T06:29:25.584689Z","shell.execute_reply":"2021-12-29T06:29:25.600752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)\"\"\"","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-29T06:29:25.603135Z","iopub.execute_input":"2021-12-29T06:29:25.603627Z","iopub.status.idle":"2021-12-29T06:29:25.615799Z","shell.execute_reply.started":"2021-12-29T06:29:25.603583Z","shell.execute_reply":"2021-12-29T06:29:25.614865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"!cd LightGBM/python-package/;python setup.py install --precompile\n!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n!rm -r LightGBM\"\"\"","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-29T06:29:25.616976Z","iopub.execute_input":"2021-12-29T06:29:25.617245Z","iopub.status.idle":"2021-12-29T06:29:25.629511Z","shell.execute_reply.started":"2021-12-29T06:29:25.617215Z","shell.execute_reply":"2021-12-29T06:29:25.628502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/tabular-playground-series-dec-2021/test.csv\", index_col=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:25.630742Z","iopub.execute_input":"2021-12-29T06:29:25.630979Z","iopub.status.idle":"2021-12-29T06:29:49.695486Z","shell.execute_reply.started":"2021-12-29T06:29:25.63095Z","shell.execute_reply":"2021-12-29T06:29:49.694623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:49.696675Z","iopub.execute_input":"2021-12-29T06:29:49.696934Z","iopub.status.idle":"2021-12-29T06:29:49.703276Z","shell.execute_reply.started":"2021-12-29T06:29:49.696905Z","shell.execute_reply":"2021-12-29T06:29:49.702277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Additional & Pseudo data \n* Load original [forest Cover Data ](https://www.kaggle.com/uciml/forest-cover-type-dataset) \\\n   From previous experiments we noted classes 4,5, and 6 have the worst accuracy \\\n   We will add these classes only\n","metadata":{}},{"cell_type":"code","source":"def additional_data():\n    original_data = pd.read_csv(\"../input/forest-cover-type-dataset/covtype.csv\")\n    #only class 4, 5, 6\n    #original_data = original_data [ (original_data[\"Cover_Type\"] ==4) | (original_data[\"Cover_Type\"] ==5)  | (original_data[\"Cover_Type\"] ==6) ]\n    original_data[\"Cover_Type\"].value_counts()\n    return original_data\n\noriginal_data =additional_data() \ndisplay(original_data.head())","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:49.704404Z","iopub.execute_input":"2021-12-29T06:29:49.704631Z","iopub.status.idle":"2021-12-29T06:29:52.061427Z","shell.execute_reply.started":"2021-12-29T06:29:49.704605Z","shell.execute_reply":"2021-12-29T06:29:52.060223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pseudo_labelling_1():\n    # obtain submissions\n    sub_files = pd.DataFrame()\n    for file in os.listdir(\"../input/submission-files-tps-dec-2021\"):\n        sub_files = pd.concat([sub_files,pd.read_csv(\"../input/submission-files-tps-dec-2021/\"+file,index_col=0)],axis=1)    \n        \n    # get all rows where the values are the same for each column - num files =10\n    filter_vals =  sub_files.sum(axis =1 )/ 10 == sub_files.iloc[:,0]\n    \n    # filter test and sub_files from above results & join \n    pseudo_df = test.copy(deep=True)[ filter_vals ] \n    pseudo_df[\"Cover_Type\"] = sub_files[ filter_vals ].iloc[:,0]\n    \n    return pseudo_df","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:52.062666Z","iopub.execute_input":"2021-12-29T06:29:52.062895Z","iopub.status.idle":"2021-12-29T06:29:52.070652Z","shell.execute_reply.started":"2021-12-29T06:29:52.062867Z","shell.execute_reply":"2021-12-29T06:29:52.06956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PSEUDOLABEL ==1:\n    print(\"Pseudo 1 loaded\")\n    pseudo_df =  pseudo_labelling_1()\n    print(\"Pseudo shape: \",pseudo_df.shape)\n    \nif PSEUDOLABEL ==2 or PSEUDOLABEL ==0:\n    print(\"Pseudo 2 loaded\")\n    pseudo_df = pd.read_csv('../input/tps12-pseudolabels/tps12-pseudolabels_v2.csv', index_col=0, dtype=train.dtypes.to_dict())\n    print(\"Pseudo shape: \",pseudo_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:52.071858Z","iopub.execute_input":"2021-12-29T06:29:52.072135Z","iopub.status.idle":"2021-12-29T06:29:56.563651Z","shell.execute_reply.started":"2021-12-29T06:29:52.0721Z","shell.execute_reply":"2021-12-29T06:29:56.562749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Cover_Type\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:56.565113Z","iopub.execute_input":"2021-12-29T06:29:56.565435Z","iopub.status.idle":"2021-12-29T06:29:56.594869Z","shell.execute_reply.started":"2021-12-29T06:29:56.565392Z","shell.execute_reply":"2021-12-29T06:29:56.594102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,7))\nsns.countplot(x = train[\"Cover_Type\"])\nplt.title(\"Count of Target (Cover_Type)\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:56.59829Z","iopub.execute_input":"2021-12-29T06:29:56.598608Z","iopub.status.idle":"2021-12-29T06:29:57.117824Z","shell.execute_reply.started":"2021-12-29T06:29:56.598568Z","shell.execute_reply":"2021-12-29T06:29:57.11698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation analaysis \nWe will exclude soil types as these are boolean values ","metadata":{}},{"cell_type":"code","source":"cols = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4', 'Cover_Type']","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:57.119482Z","iopub.execute_input":"2021-12-29T06:29:57.11999Z","iopub.status.idle":"2021-12-29T06:29:57.126183Z","shell.execute_reply.started":"2021-12-29T06:29:57.119944Z","shell.execute_reply":"2021-12-29T06:29:57.125246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,10))\nsns.heatmap(train[cols].corr(), vmin = -1, vmax=1, annot = True, cmap=\"Spectral\") ","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:29:57.127375Z","iopub.execute_input":"2021-12-29T06:29:57.127602Z","iopub.status.idle":"2021-12-29T06:30:01.946695Z","shell.execute_reply.started":"2021-12-29T06:29:57.127575Z","shell.execute_reply":"2021-12-29T06:30:01.945732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note**: Elevation seems to have the highest negative correlation to Cover_type although relativelty weak correlation ","metadata":{}},{"cell_type":"markdown","source":"# Downcasting \nWe note from train.info above that all columns are int64 \\\nWe should look at the min and max of the columns to check if they need full 64bit to store the integers ","metadata":{}},{"cell_type":"markdown","source":"![image.png](attachment:97f75336-b8a0-4e8b-a220-719f126bac38.png)","metadata":{},"attachments":{"97f75336-b8a0-4e8b-a220-719f126bac38.png":{"image/png":"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"}}},{"cell_type":"code","source":"def memory_usage_mb(df, *args, **kwargs):\n    \"\"\"Dataframe memory usage in MB. \"\"\"\n    return df.memory_usage(*args, **kwargs).sum() / 1024**2\n\ndef reduce_memory_usage(df, deep=True, verbose=True, categories=True):\n    # All types that we want to change for \"lighter\" ones.\n    # int8 and float16 are not include because we cannot reduce\n    # those data types.\n    # float32 is not include because float16 has too low precision.\n    numeric2reduce = [\"int16\", \"int32\", \"int64\", \"float64\"]\n    start_mem = 0\n    if verbose:\n        start_mem = memory_usage_mb(df, deep=deep)\n\n    for col, col_type in df.dtypes.iteritems():\n        best_type = None\n        if col_type == \"object\":\n            df[col] = df[col].astype(\"category\")\n            best_type = \"category\"\n        elif col_type in numeric2reduce:\n            downcast = \"integer\" if \"int\" in str(col_type) else \"float\"\n            df[col] = pd.to_numeric(df[col], downcast=downcast)\n            best_type = df[col].dtype.name\n        # Log the conversion performed.\n        #if verbose and best_type is not None and best_type != str(col_type):\n         #   print(f\"Column '{col}' converted from {col_type} to {best_type}\")\n\n    if verbose:\n        end_mem = memory_usage_mb(df, deep=deep)\n        diff_mem = start_mem - end_mem\n        percent_mem = 100 * diff_mem / start_mem\n        print(f\"Memory usage decreased from\"\n              f\" {start_mem:.2f}MB to {end_mem:.2f}MB\"\n              f\" ({diff_mem:.2f}MB, {percent_mem:.2f}% reduction)\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:01.948693Z","iopub.execute_input":"2021-12-29T06:30:01.949282Z","iopub.status.idle":"2021-12-29T06:30:01.961615Z","shell.execute_reply.started":"2021-12-29T06:30:01.949238Z","shell.execute_reply":"2021-12-29T06:30:01.960943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DOWNCASTING:\n    reduce_memory_usage(train)\n    reduce_memory_usage(test)\n    reduce_memory_usage(original_data)\n    reduce_memory_usage(pseudo_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:01.963327Z","iopub.execute_input":"2021-12-29T06:30:01.964131Z","iopub.status.idle":"2021-12-29T06:30:26.238386Z","shell.execute_reply.started":"2021-12-29T06:30:01.964057Z","shell.execute_reply":"2021-12-29T06:30:26.237331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering and splitting \nAll credit to their respecitve notebooks and discussion topics ","metadata":{}},{"cell_type":"code","source":"all_df = pd.concat([train.assign(ds=0), test.assign(ds=1),original_data.assign(ds=2),pseudo_df.assign(ds=3)]).reset_index(drop=True).drop(columns=['Soil_Type7', 'Soil_Type15'] )\n\ndef start_at_eps(series, eps=1e-10): return series - series.min() + eps\n\npos_h_hydrology = start_at_eps(all_df.Horizontal_Distance_To_Hydrology)\npos_v_hydrology = start_at_eps(all_df.Vertical_Distance_To_Hydrology)\n\nwilderness = all_df.columns[all_df.columns.str.startswith('Wilderness')]\nsoil_type = all_df.columns[all_df.columns.str.startswith('Soil_Type')]\nhillshade = all_df.columns[all_df.columns.str.startswith('Hillshade')]\n\nall_df = pd.concat([\n    all_df,\n\n    all_df[wilderness].sum(axis=1).rename('Wilderness_Sum').astype(np.float32),\n    all_df[soil_type].sum(axis=1).rename('Soil_Type_Sum').astype(np.float32),\n\n    (all_df.Aspect % 360).rename('Aspect_mod_360'),\n    (all_df.Aspect * np.pi / 180).apply(np.sin).rename('Aspect_sin').astype(np.float32),\n    (all_df.Aspect - 180).where(all_df.Aspect + 180 > 360, all_df.Aspect + 180).rename('Aspect2'),\n\n    (all_df.Elevation - all_df.Vertical_Distance_To_Hydrology).rename('Hydrology_Elevation'),\n    all_df.Vertical_Distance_To_Hydrology.apply(np.sign).rename('Water_Vertical_Direction'),\n\n    (pos_h_hydrology + pos_v_hydrology).rename('Manhatten_positive_hydrology').astype(np.float32),\n    (all_df.Horizontal_Distance_To_Hydrology.abs() + all_df.Vertical_Distance_To_Hydrology.abs()).rename('Manhattan_abs_hydrology'),\n    (pos_h_hydrology ** 2 + pos_v_hydrology ** 2).apply(np.sqrt).rename('Euclidean_positive_hydrology').astype(np.float32),\n    (all_df.Horizontal_Distance_To_Hydrology ** 2 + all_df.Vertical_Distance_To_Hydrology ** 2).apply(np.sqrt).rename('Euclidean_hydrology'),\n\n    all_df[hillshade].clip(lower=0, upper=255).add_suffix('_clipped'),\n    all_df[hillshade].sum(axis=1).rename('Hillshade_sum'),\n\n    (all_df.Horizontal_Distance_To_Roadways * all_df.Elevation).rename('road_m_elev'),\n    (all_df.Vertical_Distance_To_Hydrology * all_df.Elevation).rename('vhydro_elevation'),\n    (all_df.Elevation - all_df.Horizontal_Distance_To_Hydrology * .2).rename('elev_sub_.2_h_hydro').astype(np.float32),\n\n    (all_df.Horizontal_Distance_To_Hydrology + all_df.Horizontal_Distance_To_Fire_Points).rename('h_hydro_p_fire'),\n    (start_at_eps(all_df.Horizontal_Distance_To_Hydrology) + start_at_eps(all_df.Horizontal_Distance_To_Fire_Points)).rename('h_hydro_eps_p_fire').astype(np.float32),\n    (all_df.Horizontal_Distance_To_Hydrology - all_df.Horizontal_Distance_To_Fire_Points).rename('h_hydro_s_fire'),\n    (all_df.Horizontal_Distance_To_Hydrology + all_df.Horizontal_Distance_To_Roadways).abs().rename('abs_h_hydro_road'),\n    (start_at_eps(all_df.Horizontal_Distance_To_Hydrology) + start_at_eps(all_df.Horizontal_Distance_To_Roadways)).rename('h_hydro_eps_p_road').astype(np.float32),\n\n    (all_df.Horizontal_Distance_To_Fire_Points + all_df.Horizontal_Distance_To_Roadways).abs().rename('abs_h_fire_p_road'),\n    (all_df.Horizontal_Distance_To_Fire_Points - all_df.Horizontal_Distance_To_Roadways).abs().rename('abs_h_fire_s_road'),\n], axis=1)\n\ntypes = {'Cover_Type': np.int8}\ntrain = all_df.loc[all_df.ds == 0].astype(types).drop(columns=['ds'])\ntest = all_df.loc[all_df.ds == 1].drop(columns=['Cover_Type', 'ds'])\noriginal_data = all_df.loc[all_df.ds == 2].astype(types).drop(columns=['ds'])\npseudo_df = all_df.loc[all_df.ds == 3].astype(types).drop(columns=['ds'])\n\ndel all_df\ndel pos_h_hydrology\ndel pos_v_hydrology\ndel wilderness\ndel soil_type\ndel hillshade\n\nif not ADD_DATA:\n    del original_data\nif PSEUDOLABEL==0:\n    del pseudo_df","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:26.239933Z","iopub.execute_input":"2021-12-29T06:30:26.240355Z","iopub.status.idle":"2021-12-29T06:30:32.176491Z","shell.execute_reply.started":"2021-12-29T06:30:26.240309Z","shell.execute_reply":"2021-12-29T06:30:32.17558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:32.178056Z","iopub.execute_input":"2021-12-29T06:30:32.178308Z","iopub.status.idle":"2021-12-29T06:30:32.202149Z","shell.execute_reply.started":"2021-12-29T06:30:32.178279Z","shell.execute_reply":"2021-12-29T06:30:32.20114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encode the Target\nSeems like a weird interaction in lighgbm.train \\\nNeed to specify the num_classes for the model and it only works if the target class starts from 0 (for classification) ","metadata":{}},{"cell_type":"code","source":"#start from 0 --> 6\ntrain[\"Cover_Type\"] = train[\"Cover_Type\"]-1\n\nif ADD_DATA:\n    original_data[\"Cover_Type\"] = original_data[\"Cover_Type\"]-1\n    \nif PSEUDOLABEL>0:\n    pseudo_df[\"Cover_Type\"] = pseudo_df[\"Cover_Type\"]-1","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:32.203585Z","iopub.execute_input":"2021-12-29T06:30:32.203839Z","iopub.status.idle":"2021-12-29T06:30:32.220974Z","shell.execute_reply.started":"2021-12-29T06:30:32.203797Z","shell.execute_reply":"2021-12-29T06:30:32.220105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sampling techniques\n\nSampling used:\n* none\n* Class 5 duplication \n* SMOTEEEN   --- due to memory issues we have to run pca \n* SMOTETomek --- due to memory issues we have to run pca ","metadata":{}},{"cell_type":"code","source":"kfold = StratifiedKFold(n_splits= FOLDS, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:32.222123Z","iopub.execute_input":"2021-12-29T06:30:32.222554Z","iopub.status.idle":"2021-12-29T06:30:32.231724Z","shell.execute_reply.started":"2021-12-29T06:30:32.222516Z","shell.execute_reply":"2021-12-29T06:30:32.231012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class oversample_techniques():\n    \n    def __init__ (self, df ,num):\n        self.df = df \n        self.num = num\n        \n    def sample_class5(self):\n        \n        #note that due to encoding class 5 = 4\n        class5 = self.df[self.df[\"Cover_Type\"]==4]\n        #append class 5 for each fold -1 \n        for i in range(self.num):\n            self.df = self.df.append(class5, ignore_index=True)\n            \n        f= open(f\"log_file_{version}_{minor}.txt\",\"a\")\n        f.write(\"\\n ##############################\")\n        f.write(\"\\n Oversampling Technique: oversample class 5\")\n        f.write(\"\\n ##############################\")\n        f.close()\n        \n        return self.df\n    \n    def no_change(self):\n        f= open(f\"log_file_{version}_{minor}.txt\",\"a\")\n        f.write(\"\\n ##############################\")\n        f.write(\"\\n Oversampling Technique: no sampling\")\n        f.write(\"\\n ##############################\")\n        f.close()\n        \n        \n    def over_under_SMOTEENN(self):\n        \n        smote_enn = SMOTEENN(random_state=42, n_jobs = -1)\n        X_resampled, y_resampled = smote_enn.fit_resample(self.df.drop(\"Cover_Type\",axis =1),\n                                                          self.df[\"Cover_Type\"])\n        X_resampled[\"Cover_Type\"] = y_resampled\n        \n        f= open(f\"log_file_{version}_{minor}.txt\",\"a\")\n        f.write(\"\\n ##############################\")\n        f.write(\"\\n Oversampling Technique: SMOTEENN\")\n        f.write(\"\\n ##############################\")\n        f.close()\n        \n        return X_resampled\n    \n    def over_under_SMOTETomek(self):\n\n        smote_tomek = SMOTETomek(random_state=42, n_jobs = -1)\n        X_resampled, y_resampled = smote_tomek.fit_resample(self.df.drop(\"Cover_Type\",axis =1),\n                                                            self.df[\"Cover_Type\"])\n        X_resampled[\"Cover_Type\"] = y_resampled\n        \n        f= open(f\"log_file_{version}_{minor}.txt\",\"a\")\n        f.write(\"\\n ##############################\")\n        f.write(\"\\n Oversampling Technique: SMOTETomek\")\n        f.write(\"\\n ##############################\")\n        f.close()\n        \n        return X_resampled","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:32.232848Z","iopub.execute_input":"2021-12-29T06:30:32.233461Z","iopub.status.idle":"2021-12-29T06:30:32.249077Z","shell.execute_reply.started":"2021-12-29T06:30:32.233421Z","shell.execute_reply":"2021-12-29T06:30:32.248114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run class 5 sample here as we are duplicatign the training data not the split data \nif sample_technique == \"class5\":\n    train = oversample_techniques(train,5).sample_class5()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:32.250307Z","iopub.execute_input":"2021-12-29T06:30:32.250529Z","iopub.status.idle":"2021-12-29T06:30:33.163036Z","shell.execute_reply.started":"2021-12-29T06:30:32.250502Z","shell.execute_reply":"2021-12-29T06:30:33.162276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Cover_Type\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:33.164006Z","iopub.execute_input":"2021-12-29T06:30:33.164514Z","iopub.status.idle":"2021-12-29T06:30:33.193001Z","shell.execute_reply.started":"2021-12-29T06:30:33.164476Z","shell.execute_reply":"2021-12-29T06:30:33.191691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation \n\n1. Adding original data \n1. adding Pseudo labels\n1. Over/ under sample data \n\n**Note**: Im adverse to drop data so we shall keep class 5 and either append new data, over/undersample or duplicate class 5","metadata":{}},{"cell_type":"markdown","source":"# Split ","metadata":{}},{"cell_type":"code","source":"X = train.drop(\"Cover_Type\",axis =1)\ny = train[\"Cover_Type\"]\n\nprint(\"X shape:\",X.shape)\n\nif MODEL_TYPE != \"Cross_validation\":\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    print(\"X_train shape:\",X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:33.19449Z","iopub.execute_input":"2021-12-29T06:30:33.194759Z","iopub.status.idle":"2021-12-29T06:30:36.747872Z","shell.execute_reply.started":"2021-12-29T06:30:33.194721Z","shell.execute_reply":"2021-12-29T06:30:36.746949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Additional Data \nWe will use the [original data](https://www.kaggle.com/uciml/forest-cover-type-dataset) and concatenate so our training data - to as to keep validation data clean","metadata":{}},{"cell_type":"code","source":"if ADD_DATA:\n    print(\"Adding Original Data\")\n    \n    ## Cross val uses training data so add it to train\n    if MODEL_TYPE ==\"Cross_validation\":\n        print(\"X shape prior: \",X.shape)\n        train = pd.concat([X,original_data.drop(\"Cover_Type\",axis =1)])\n        print(\"X shape after: \",train.shape)\n    else:\n        print(\"X_train shape prior: \",X_train.shape)\n        X_train = pd.concat([X_train,original_data.drop(\"Cover_Type\",axis =1)])\n        y_train = pd.concat([y_train,original_data[\"Cover_Type\"]])\n        print(\"X_Train shape after: \",X_train.shape)\ndel train","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:36.749346Z","iopub.execute_input":"2021-12-29T06:30:36.749672Z","iopub.status.idle":"2021-12-29T06:30:36.758902Z","shell.execute_reply.started":"2021-12-29T06:30:36.749631Z","shell.execute_reply":"2021-12-29T06:30:36.757599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pseudo Labelling \nTwo ways we can do this: \\\n**Process 1** \\\nWe can use historical submissions (10 submissions) and identify where all submissions predicted the same class \\\nWe can then append these rows to our training data \n   \n**Process 2** \\\nRun our a training model over the training data - where probability > threshold (i.e. 90%) then we add this data to training data and retrain model ","metadata":{}},{"cell_type":"code","source":"# we concat here if not a cross validation session as cross validation concat will occur in fold\nif PSEUDOLABEL >0 and MODEL_TYPE!=\"Cross_validation\" :\n    print(\"Pseudo shape: \",pseudo_df.shape)\n    print(\"XTrain shape prior: \",X_train.shape)\n    \n    X_train = pd.concat([X_train,pseudo_df.drop(\"Cover_Type\",axis =1)])\n    y_train = pd.concat([y_train,pseudo_df[\"Cover_Type\"]])\n    \n    print(\"XTrain shape after: \",X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:36.76082Z","iopub.execute_input":"2021-12-29T06:30:36.761287Z","iopub.status.idle":"2021-12-29T06:30:37.281088Z","shell.execute_reply.started":"2021-12-29T06:30:36.761242Z","shell.execute_reply":"2021-12-29T06:30:37.280073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SPlit & Scale\nSplit and scaling for **Train** and **Classifier** done here\n**Cross Val ** is done in fold ","metadata":{}},{"cell_type":"code","source":"def scale_data(X_train, X_test, test):\n    scaler= SCALER\n    scaler.fit(X_train)\n    X_train = scaler.transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    test_scaled = scaler.transform(test)\n    \n    return X_train, X_test, test_scaled","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:37.282392Z","iopub.execute_input":"2021-12-29T06:30:37.282594Z","iopub.status.idle":"2021-12-29T06:30:37.289003Z","shell.execute_reply.started":"2021-12-29T06:30:37.28257Z","shell.execute_reply":"2021-12-29T06:30:37.288163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if SCALER_NAME != \"None\" and MODEL_TYPE !=\"Cross_validation\":\n    \n    print(f\"Scaling with {SCALER_NAME}\")\n    X_train, X_test, test_scaled = scale_data(X_train, X_test, test)\n    \n    display(test_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:37.290678Z","iopub.execute_input":"2021-12-29T06:30:37.290999Z","iopub.status.idle":"2021-12-29T06:30:43.303753Z","shell.execute_reply.started":"2021-12-29T06:30:37.290957Z","shell.execute_reply":"2021-12-29T06:30:43.30268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PCA \n* There are a certain features which may have low to no impact on the Target - PCA should have limit this impact and remove noise\n* Oversampling Techniques - Due to memory issues for sampling we need to run PCA prior to Sampling","metadata":{}},{"cell_type":"code","source":"if sample_technique in [\"SMOTETEENN\", \"SMOTETomek\", \"PCA\"]:\n    \n    pca = PCA(n_components=10)\n    X_train = pca.fit_transform(X_train)\n    X_test = pca.transform(X_test)\n\n    test = pca.transform(test)\n\n    pca_cols = []\n    for i in range(10):\n        pca_cols.append(\"pca_\"+f\"{i}\")\n\n    X_train = pd.DataFrame(X_train, columns = pca_cols)\n    X_test = pd.DataFrame(X_test, columns = pca_cols)\n\n    test = pd.DataFrame(test, columns = pca_cols)\n    \n    #Boxplot & df \n    plt.figure(figsize= (15,7))\n    sns.boxplot(data = X_train)\n    \n    display(X_train.head())","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.304867Z","iopub.execute_input":"2021-12-29T06:30:43.305124Z","iopub.status.idle":"2021-12-29T06:30:43.313316Z","shell.execute_reply.started":"2021-12-29T06:30:43.305084Z","shell.execute_reply":"2021-12-29T06:30:43.312332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Applying Oversampling Technique: {sample_technique}\")\n\nif sample_technique == \"none\":\n    oversample  = oversample_techniques(train,kfold.n_splits)\n    train = oversample.no_change()\n    \nelif sample_technique ==\"SMOTEENN\":\n    X_train = oversample_techniques(X_train,kfold.n_splits).over_under_SMOTEENN()\n    X_test = oversample_techniques(X_test,kfold.n_splits).over_under_SMOTEENN()\n    \nelif sample_technique ==\"SMOTETomek\":\n    X_train = oversample_techniques(X_train,kfold.n_splits).over_under_SMOTETomek()\n    X_test = oversample_techniques(X_test,kfold.n_splits).over_under_SMOTETomek()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.314772Z","iopub.execute_input":"2021-12-29T06:30:43.314993Z","iopub.status.idle":"2021-12-29T06:30:43.328643Z","shell.execute_reply.started":"2021-12-29T06:30:43.314966Z","shell.execute_reply":"2021-12-29T06:30:43.327518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cluster  - Check ","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans, DBSCAN\nfrom scipy.cluster.hierarchy import dendrogram, linkage","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.329632Z","iopub.execute_input":"2021-12-29T06:30:43.330435Z","iopub.status.idle":"2021-12-29T06:30:43.344553Z","shell.execute_reply.started":"2021-12-29T06:30:43.330392Z","shell.execute_reply":"2021-12-29T06:30:43.343539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CLUSTERING:\n    cluster = KMeans(n_clusters= 7)\n    y_cluster =cluster.fit_predict(train.drop(\"Cover_Type\",axis =1))\n    train[\"cluster\"] = y_cluster\n\n    y_cluster_test = cluster.predict(test)\n    test[\"cluster\"] = y_cluster_test\n    test[\"cluster\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.346127Z","iopub.execute_input":"2021-12-29T06:30:43.346706Z","iopub.status.idle":"2021-12-29T06:30:43.361817Z","shell.execute_reply.started":"2021-12-29T06:30:43.346661Z","shell.execute_reply":"2021-12-29T06:30:43.360651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna hyperparameter tuning \nOptuna + cross val takes too long - will exclude any experiments with both enabled","metadata":{}},{"cell_type":"code","source":"# 1. Define an objective function to be maximized.\ndef objective(trial):\n    # 2. Suggest values of the hyperparameters using a trial object.\n    lgb_params = {\n        \"is_unbalance\": UNBALANCED,\n        'objective': 'multiclass',\n        \"num_class\": 7,\n        'metric': \"multi_logloss\",\n        'verbosity': -1,\n        'num_iterations': EPOCHS,\n        \"num_threads\": -1,\n        #\"force_col_wise\": True\n        \"learning_rate\": trial.suggest_float('learning_rate',0.01,0.2),\n        'boosting_type': trial.suggest_categorical('boosting',[BOOSTING]),\n        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        #'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1000, 10000),\n        'max_depth': trial.suggest_int('max_depth', 2,15),\n        #'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n        #'bagging_freq': trial.suggest_int('bagging_freq', 1, 7)\n    }\n    \n    if BOOSTING == \"dart\":\n        lgb_params[\"drop_seed\"]= 42\n        \n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"multi_logloss\")\n    \n    model = lgb.train(params=lgb_params,train_set= train_data, \n                      valid_sets= [test_data], \n                      early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n                      callbacks=[pruning_callback]\n                     )\n    \n    \n    y_pred = model.predict(X_test)\n    test_preds = [np.argmax(x) for x in y_pred]\n    accuracy_s = accuracy_score(y_test,test_preds)\n    print(f\"Accuracy score of {accuracy_s}\")\n    print(classification_report(y_test,test_preds))\n    \n    return 1-accuracy_s","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.363365Z","iopub.execute_input":"2021-12-29T06:30:43.36371Z","iopub.status.idle":"2021-12-29T06:30:43.378748Z","shell.execute_reply.started":"2021-12-29T06:30:43.363665Z","shell.execute_reply":"2021-12-29T06:30:43.377666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note \nWe are looking at the inverse accuracy (1-accuracy) which we want to minimize \\\nwe are doing this to keep the prunning callback in line with the objective metric","metadata":{}},{"cell_type":"code","source":"%%time\nif OPTUNA:\n            \n    train_data = lgb.Dataset(X_train, label=y_train)\n    test_data = lgb.Dataset(X_test, label=y_test)\n    \n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=NUM_TRIALS)\n    trial = study.best_trial\n    \n    \n    #Print our results\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n    print(\"Best trial:\")\n    print(\" Accuracy Value: {}\".format(1- trial.value))\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))\n\n    #write to log file\n    f= open(f\"log_file_{version}_{minor}.txt\",\"a\")\n    f.write(\"\\n ##################  Hyper paramter tuning ###############\")\n    f.write(\"\\n Number of finished trials: {}\".format(len(study.trials)))\n    f.write(f\"\\n Best trial accuracy score: {1-trial.value}\")\n    f.write(f\"\\n Best params: {trial.params}\")\n    f.close()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.38028Z","iopub.execute_input":"2021-12-29T06:30:43.381027Z","iopub.status.idle":"2021-12-29T06:30:43.400692Z","shell.execute_reply.started":"2021-12-29T06:30:43.380977Z","shell.execute_reply":"2021-12-29T06:30:43.399797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if OPTUNA:\n    lgb_params = trial.params\n    lgb_params[\"is_unbalance\"]= UNBALANCED\n    lgb_params[\"objective\"]= \"multiclass\"\n    lgb_params[\"metric\"]= \"multi_logloss\"\n    lgb_params[\"num_class\"]= 7\n    lgb_params[\"device_type\"]= DEVICE\n    lgb_params[\"num_iterations\"]= EPOCHS\n    \nelse: #set to best params - see 'TEST DELETE notebook'\n    lgb_params = {\n    \"is_unbalance\": UNBALANCED,\n    \"objective\" : \"multiclass\",\n    \"metric\": \"multi_logloss\",\n    \"num_class\": 7,\n    #\"num_threads\": -1,\n    #\"force_col_wise\": True\n    \"device_type\": DEVICE,\n    'boosting': BOOSTING,  \n    'num_iterations': EPOCHS,\n    \"learning_rate\": 0.16704206649880823,\n    #\"lambda_l1\": 0.03469015403439412,\n    \"lambda_l2\": 9.993162304351474,\n    \"num_leaves\": 243,\n    \"max_depth\": 12\n                   }\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T14:08:11.885989Z","iopub.execute_input":"2021-12-31T14:08:11.886571Z","iopub.status.idle":"2021-12-31T14:08:11.894434Z","shell.execute_reply.started":"2021-12-31T14:08:11.886521Z","shell.execute_reply":"2021-12-31T14:08:11.893384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation ","metadata":{}},{"cell_type":"code","source":"def cross_val(X,y, test):\n    \n    test_predictions = []\n    lgb_scores = []\n\n    for idx, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n\n        print(10*\"=\", f\"Fold={idx+1}\", 10*\"=\")\n        start_time = time.time()\n\n        x_train, y_train = X.iloc[train_idx,:], y.iloc[train_idx,]\n        x_valid, y_val = X.iloc[val_idx,:], y.iloc[val_idx,]\n\n        if PSEUDOLABEL >0:\n            #add pseduo data to each fold\n            x_train = np.concatenate([x_train, pseudo_df.drop(\"Cover_Type\", axis =1)], axis=0)\n            y_train = np.concatenate([y_train, pseudo_df[\"Cover_Type\"]], axis=0)\n        \n        if SCALER_NAME !=\"None\":\n            print(f\"Scaling with {SCALER_NAME}\")\n            x_train,x_valid, test_scaled = scale_data(x_train,x_valid, test)\n        else:\n            test_scaled = test\n        \n        train_dat = lgb.Dataset(x_train, label=y_train)\n        val_dat = lgb.Dataset(x_valid, label=y_val)\n        \n        del x_train\n        del y_train\n\n        model = lgb.train(params=lgb_params,\n                          train_set= train_dat, \n                          valid_sets= [val_dat], \n                          early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n                          verbose_eval = -1\n                     )\n\n        preds_valid = model.predict(x_valid)\n        preds_valid = [np.argmax(x) for x in preds_valid]\n        accuracy_val = accuracy_score(y_val,  preds_valid)\n        lgb_scores.append(accuracy_val)\n        \n        del x_valid\n        del y_val\n        \n        run_time = time.time() - start_time\n        print(f\"Fold={idx+1}, accuracy: {accuracy_val}, Run Time: {run_time:.2f}\")\n        f.write(f\"Fold={idx+1}, accuracy: {accuracy_val}, Run Time: {run_time:.2f}\")\n\n        test_preds = model.predict(test_scaled)\n        test_preds = [np.argmax(x) for x in test_preds]\n        test_predictions.append(test_preds)\n\n    print(\"Mean Validation Accuracy :\", np.mean(lgb_scores))\n    return test_predictions","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.42304Z","iopub.execute_input":"2021-12-29T06:30:43.42375Z","iopub.status.idle":"2021-12-29T06:30:43.438804Z","shell.execute_reply.started":"2021-12-29T06:30:43.423714Z","shell.execute_reply":"2021-12-29T06:30:43.43749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if MODEL_TYPE == \"Cross_validation\":\n    \n    ##open log file\n    f= open(f\"log_file_{version}_{minor}.txt\",\"a\")\n    f.write(f\"########################### CROSSVAL SCORES ########################### \")\n    \n    test_predictions = cross_val(X,y, test)\n    y_pred_test = np.squeeze(mode(np.column_stack(test_predictions),axis = 1)[0]).astype('int')\n    \n    #Close logs\n    f.close()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-29T06:30:43.440308Z","iopub.execute_input":"2021-12-29T06:30:43.440739Z","iopub.status.idle":"2021-12-29T06:30:43.458006Z","shell.execute_reply.started":"2021-12-29T06:30:43.440698Z","shell.execute_reply":"2021-12-29T06:30:43.457262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model - with best parms\n\nIf using Calibration - need to use LGBMClassifier as this is compatible with probability calibration - although much slower","metadata":{}},{"cell_type":"markdown","source":"## lgb.Train model ","metadata":{}},{"cell_type":"code","source":"def scoring(model ):\n    # train score \n    metric_score = model.best_score[\"valid_0\"][METRIC]\n    print(f\"{METRIC} score of {metric_score}\")\n    \n    train_probs = model.predict(X_train)\n    train_preds = [np.argmax(x) for x in train_probs]\n    accuracy_train = accuracy_score(y_train,train_preds)\n    print(f\"train accuracy score of {accuracy_train}\")\n    print(\"\\n Train Classification Report:\")\n    print(classification_report(y_train,train_preds))\n    \n    #test score\n    test_probs = model.predict(X_test)\n    test_preds = [np.argmax(x) for x in test_probs]\n    accuracy_s = accuracy_score(y_test,test_preds)\n    print(f\"Test accuracy score of {accuracy_s}\")\n    print(\"\\n Test Classification Report:\")\n    print(classification_report(y_test,test_preds))\n   \n    #Write log\n    f= open(f\"log_file_{version}_{minor}.txt\",\"a\")\n    f.write(\"\\n ##################  SCORE ###############\")\n    f.write(f\"\\n {METRIC} score: {metric_score}\")\n    f.write(f\"\\n accuracy score: {accuracy_s}\")\n    f.close()\n    return test_probs","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.45945Z","iopub.execute_input":"2021-12-29T06:30:43.460472Z","iopub.status.idle":"2021-12-29T06:30:43.478633Z","shell.execute_reply.started":"2021-12-29T06:30:43.460419Z","shell.execute_reply":"2021-12-29T06:30:43.477803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef train_model():   \n    \n    train_data = lgb.Dataset(X_train, label=y_train)\n    test_data = lgb.Dataset(X_test, label=y_test)\n    \n    model = lgb.train(params=lgb_params,\n                  train_set= train_data, \n                  valid_sets= [test_data], \n                  early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n                  verbose_eval = -1\n                 )\n    \n    y_val_probs = scoring(model)\n    \n    #predict Test data\n    y_test_probs = model.predict(test_scaled)\n    \n    return model , y_test_probs,y_val_probs\n    \nif MODEL_TYPE == \"train\":\n    model, y_test_probs, y_val_probs = train_model()\n    y_pred_test = [np.argmax(x) for x in y_test_probs]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-29T06:30:43.483927Z","iopub.execute_input":"2021-12-29T06:30:43.485105Z","iopub.status.idle":"2021-12-29T06:30:43.499211Z","shell.execute_reply.started":"2021-12-29T06:30:43.485024Z","shell.execute_reply":"2021-12-29T06:30:43.498076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if MODEL_TYPE == \"train\":\n    lgb.plot_importance(booster= model, figsize=(20,10))\n    y_val = [np.argmax(x) for x in y_val_probs]\n    \n    #Confusion Matrix\n    cm = confusion_matrix(y_test, y_val)\n    ix = np.arange(cm.shape[0])\n    cm[ix, ix] = 0\n    col_names = [1,2,3,4,5,6,7]\n    cm = pd.DataFrame(cm, columns=col_names, index=col_names)\n    display(cm)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.500731Z","iopub.execute_input":"2021-12-29T06:30:43.501379Z","iopub.status.idle":"2021-12-29T06:30:43.519813Z","shell.execute_reply.started":"2021-12-29T06:30:43.501346Z","shell.execute_reply":"2021-12-29T06:30:43.518933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## lgb.LGBMClassifier model","metadata":{}},{"cell_type":"code","source":"def scoring_model (model_i):\n    y_pred_train = model_i.predict(X_train)\n    accuracy_train = accuracy_score(y_train,y_pred_train)\n\n    print(f\"Train accuracy score of {accuracy_train}\")\n    print(\"\\n Train classification report:\")\n    print(classification_report(y_train,y_pred_train))\n\n    y_pred = model_i.predict(X_test)\n    accuracy_test = accuracy_score(y_test,y_pred)\n\n    print(f\"Test accuracy score of {accuracy_test}\")\n    print(\"\\n Test classification report:\")\n    print(classification_report(y_test,y_pred))\n    \n    f= open(f\"log_file_{version}_{minor}.txt\",\"a\")\n    f.write(\"\\n ##################  Final Scoring ###############\")\n    f.write(f\"\\n Train accuracy score of {accuracy_train}\")\n    f.write(f\"\\n Test accuracy score of {accuracy_test}\")\n    f.write(f\"\\n Test Classification report: {classification_report(y_test,y_pred)}\")\n    f.close()\n    \n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:30:43.521499Z","iopub.execute_input":"2021-12-29T06:30:43.522083Z","iopub.status.idle":"2021-12-29T06:30:43.538Z","shell.execute_reply.started":"2021-12-29T06:30:43.522021Z","shell.execute_reply":"2021-12-29T06:30:43.53662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nif MODEL_TYPE == \"classifier\" or MODEL_TYPE == \"classifier_cal\":\n        \n    lgb_clf = lgb.LGBMClassifier(**lgb_params)\n    lgb_clf.fit(\n        X_train,\n        y_train,\n        eval_set=(X_test,y_test),\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n        eval_metric= METRIC\n    )\n    y_pred = scoring_model(lgb_clf)\n    \n    y_pred_test = lgb_clf.predict(test_scaled)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-29T06:30:43.539397Z","iopub.execute_input":"2021-12-29T06:30:43.539652Z","iopub.status.idle":"2021-12-29T06:31:15.534877Z","shell.execute_reply.started":"2021-12-29T06:30:43.539618Z","shell.execute_reply":"2021-12-29T06:31:15.533858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if MODEL_TYPE == \"classifier\" or MODEL_TYPE == \"classifier_cal\":\n    plt.figure(figsize=(20,7))\n    plt.bar(X.columns, lgb_clf.feature_importances_)\n    plt.xticks(rotation = 90)\n    plt.title(\"Feature Importance\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:15.536332Z","iopub.execute_input":"2021-12-29T06:31:15.536687Z","iopub.status.idle":"2021-12-29T06:31:16.948674Z","shell.execute_reply.started":"2021-12-29T06:31:15.536639Z","shell.execute_reply":"2021-12-29T06:31:16.947733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Post Processing - Probability Calibration \n\nsklearn calibration only works with LGBMClassifier","metadata":{}},{"cell_type":"code","source":"if MODEL_TYPE == \"classifier_cal\":\n    model = CalibratedClassifierCV(base_estimator = lgb_clf,  method = CALIBRATION_METHOD, cv=\"prefit\") \n    model.fit(X_test, y_test) \n\n    y_pred = scoring_model(model)\n    \n    #predict Test data\n    y_pred_test = model.predict(test_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:16.95005Z","iopub.execute_input":"2021-12-29T06:31:16.950333Z","iopub.status.idle":"2021-12-29T06:31:37.098591Z","shell.execute_reply.started":"2021-12-29T06:31:16.9503Z","shell.execute_reply":"2021-12-29T06:31:37.0974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Post Processing - Pseudo Labelling 3\nThis creates pseudo data 2:\nFind the highest probabilities, set a threshold. If probabilities are > threshold \\\nKeep rows as ground truth and retrain model (import data into Kaggle and rerun)","metadata":{}},{"cell_type":"code","source":"if PSEUDOLABEL == 3:\n    max_probabilities = []\n    for val in y_test_probs:\n        max_probabilities.append(max(val))\n        \n    new_train = test.copy(deep = True)\n    new_train[\"Cover_Type\"] = y_pred_test\n    new_train[\"Cover_Type\"] = new_train[\"Cover_Type\"].astype(\"int32\") +1\n    new_train[\"Max_Proba\"] = max_probabilities\n    \n    # Return only predictions > 0.99 \n    new_train = new_train[new_train[\"Max_Proba\"] >0.99]\n    new_train.drop(\"Max_Proba\", axis = 1)\n    \n    train = pd.concat([train,new_train])\n    new_train.to_csv(\"psedo_labels_2.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:37.100371Z","iopub.execute_input":"2021-12-29T06:31:37.100624Z","iopub.status.idle":"2021-12-29T06:31:37.111343Z","shell.execute_reply.started":"2021-12-29T06:31:37.100596Z","shell.execute_reply":"2021-12-29T06:31:37.109947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# POST Full Training \nAs we are trying to get the most out of the model, we will do one final training on the full training data (no splitting)","metadata":{}},{"cell_type":"code","source":"if Full_Train:\n    \n    X = np.concatenate((np.array(X),test),axis =0)\n    y = np.concatenate((np.array(y),y_pred_test),axis =0)\n    \n    train_data = lgb.Dataset(X, label=y)\n    \n    model = lgb.train(params=lgb_params,\n                  train_set= train_data, \n                  verbose_eval = -1\n                 )\n    \n    y_probs = model.predict(X)\n    y_pred = [np.argmax(x) for x in y_probs]\n    print(\"accuracy check\", accuracy_score(y,y_pred))\n    print(classification_report(y,y_pred))\n    \n    #predict Test data\n    y_test_probs = model.predict(test_scaled)\n    y_pred_test = [np.argmax(x) for x in y_test_probs]","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:37.113259Z","iopub.execute_input":"2021-12-29T06:31:37.113591Z","iopub.status.idle":"2021-12-29T06:31:37.126376Z","shell.execute_reply.started":"2021-12-29T06:31:37.113558Z","shell.execute_reply":"2021-12-29T06:31:37.125222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission ","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(\"../input/tabular-playground-series-dec-2021/sample_submission.csv\", index_col=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:37.128207Z","iopub.execute_input":"2021-12-29T06:31:37.12869Z","iopub.status.idle":"2021-12-29T06:31:37.553155Z","shell.execute_reply.started":"2021-12-29T06:31:37.128654Z","shell.execute_reply":"2021-12-29T06:31:37.552114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[\"Cover_Type\"] = y_pred_test \n\n# Ensure interger column \nsub[\"Cover_Type\"] = sub[\"Cover_Type\"].astype(\"int32\")\n\n# reverse encoding on Target \nsub[\"Cover_Type\"] = sub[\"Cover_Type\"]+1","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:37.554793Z","iopub.execute_input":"2021-12-29T06:31:37.555122Z","iopub.status.idle":"2021-12-29T06:31:37.568473Z","shell.execute_reply.started":"2021-12-29T06:31:37.555077Z","shell.execute_reply":"2021-12-29T06:31:37.567629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:37.569931Z","iopub.execute_input":"2021-12-29T06:31:37.570388Z","iopub.status.idle":"2021-12-29T06:31:39.856228Z","shell.execute_reply.started":"2021-12-29T06:31:37.570348Z","shell.execute_reply":"2021-12-29T06:31:39.855289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[\"Cover_Type\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:39.857476Z","iopub.execute_input":"2021-12-29T06:31:39.857702Z","iopub.status.idle":"2021-12-29T06:31:39.869992Z","shell.execute_reply.started":"2021-12-29T06:31:39.857675Z","shell.execute_reply":"2021-12-29T06:31:39.868904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T06:31:39.871775Z","iopub.execute_input":"2021-12-29T06:31:39.872029Z","iopub.status.idle":"2021-12-29T06:31:39.887606Z","shell.execute_reply.started":"2021-12-29T06:31:39.871999Z","shell.execute_reply":"2021-12-29T06:31:39.886752Z"},"trusted":true},"execution_count":null,"outputs":[]}]}