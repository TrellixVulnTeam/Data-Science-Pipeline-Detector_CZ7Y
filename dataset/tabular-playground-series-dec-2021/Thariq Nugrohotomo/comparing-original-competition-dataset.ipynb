{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, I would like to compare the (synthetic) dataset from [Tabular Playground Series - Dec 2021](https://www.kaggle.com/c/tabular-playground-series-dec-2021) against the  original competition (non-synthetic) dataset [Forest Cover Type Prediction](https://www.kaggle.com/c/forest-cover-type-prediction).","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-13T00:23:57.976375Z","iopub.execute_input":"2021-12-13T00:23:57.97693Z","iopub.status.idle":"2021-12-13T00:23:59.362194Z","shell.execute_reply.started":"2021-12-13T00:23:57.976839Z","shell.execute_reply":"2021-12-13T00:23:59.361111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original = pd.read_csv('../input/forest-cover-type-prediction/train.csv')\nsynthetic = pd.read_csv('../input/tabular-playground-series-dec-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:23:59.364174Z","iopub.execute_input":"2021-12-13T00:23:59.364558Z","iopub.status.idle":"2021-12-13T00:24:18.293104Z","shell.execute_reply.started":"2021-12-13T00:23:59.364502Z","shell.execute_reply":"2021-12-13T00:24:18.292195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Shape","metadata":{}},{"cell_type":"code","source":"print('original', original.shape)\nprint('synthetic', synthetic.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:18.294536Z","iopub.execute_input":"2021-12-13T00:24:18.294784Z","iopub.status.idle":"2021-12-13T00:24:18.301073Z","shell.execute_reply.started":"2021-12-13T00:24:18.294754Z","shell.execute_reply":"2021-12-13T00:24:18.300112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Columns Names and Data-Types","metadata":{}},{"cell_type":"code","source":"(original.columns == synthetic.columns).all()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:18.302686Z","iopub.execute_input":"2021-12-13T00:24:18.303061Z","iopub.status.idle":"2021-12-13T00:24:18.316325Z","shell.execute_reply.started":"2021-12-13T00:24:18.30303Z","shell.execute_reply":"2021-12-13T00:24:18.315482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(original.dtypes == synthetic.dtypes).all()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:18.318954Z","iopub.execute_input":"2021-12-13T00:24:18.319513Z","iopub.status.idle":"2021-12-13T00:24:18.330523Z","shell.execute_reply.started":"2021-12-13T00:24:18.319477Z","shell.execute_reply":"2021-12-13T00:24:18.32957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown above, the column's names and data-types are similar.","metadata":{}},{"cell_type":"markdown","source":"# Target Label/Class Distribution","metadata":{}},{"cell_type":"code","source":"target = 'Cover_Type'\ndef plot(df, name):\n    count = df[target].value_counts().sort_index()\n    plt.ticklabel_format(useOffset=False, style='plain')\n    plt.bar(count.index, count)\n    plt.xlabel('label/class')\n    plt.title(name)\n    plt.show()\nplot(synthetic, 'synthetic')\nplot(original, 'original')","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:18.33181Z","iopub.execute_input":"2021-12-13T00:24:18.332114Z","iopub.status.idle":"2021-12-13T00:24:18.771624Z","shell.execute_reply.started":"2021-12-13T00:24:18.332072Z","shell.execute_reply":"2021-12-13T00:24:18.770786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of synthetic dataset is imbalanced, but the distribution of original dataset is balanced.","metadata":{}},{"cell_type":"markdown","source":"### Leaked Test-Label on Original-Competition","metadata":{}},{"cell_type":"markdown","source":"In the original-competition, the **leaked test-label** has imbalance distribution (almost half of them are class 2, which resembles the train-set in the synthethic-dataset).\n\nIn the original-competition, a classifier normally would have no access to the information about class imbalance in the test-set, hence can't utilize the imbalance distribution of the label when doing prediction.\n\nContrary, synthetic's training-set contains information about the class imbalance. The classifier should be able to gain benefit from the class imbalance ***under assumption*** that the imbalance in the synthetic's test-set will be similar.","metadata":{}},{"cell_type":"markdown","source":"# Aspect","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(dict(\n    synthetic = synthetic.Aspect.describe(),\n    original = original.Aspect.describe()\n)).round(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:18.772791Z","iopub.execute_input":"2021-12-13T00:24:18.772999Z","iopub.status.idle":"2021-12-13T00:24:18.924674Z","shell.execute_reply.started":"2021-12-13T00:24:18.772974Z","shell.execute_reply":"2021-12-13T00:24:18.923936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The original Aspect range is [0,360] angle-degree, but the synthethic range is [-33,407].","metadata":{}},{"cell_type":"code","source":"def plot(df, name):\n    df.Aspect.value_counts().sort_index().plot(figsize=(11,5))\n    plt.title(name)\n    plt.xlabel('Aspect')\n    plt.show()\nplot(original, 'original')\nplot(synthetic, 'synthetic')","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:18.925713Z","iopub.execute_input":"2021-12-13T00:24:18.925944Z","iopub.status.idle":"2021-12-13T00:24:19.417772Z","shell.execute_reply.started":"2021-12-13T00:24:18.925916Z","shell.execute_reply":"2021-12-13T00:24:19.416713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Please note that the original one looks shaky, but the synthetic one looks smoother, this is simply because the synthetic one has large number of sample.\n\nIf we smooth-out the shakiness, both of them has similar movement which resembles a trigonometric's [sinusoid](https://en.wikipedia.org/wiki/Sine_wave) curve. I would say that the original one definitely forming a sine wave, but not sure about the synthethic one.\n\nI also would like to mention about the sharp spike on `Aspect=0` on the synthethic one that seems pretty strange.","metadata":{}},{"cell_type":"markdown","source":"## Periodicity of Aspect","metadata":{}},{"cell_type":"markdown","source":"I would like to do a experiment to prove the following:\n1. Aspect of 1 degree-angle would closely resemble 359 degree.\n2. Aspect of 90 degree-angle would be very different from 270 degree.\n\nA classifier should have difficulty to separate the 1st case (because of similiarity), but not the 2nd case.","metadata":{}},{"cell_type":"code","source":"x = synthetic.copy()\nfor cname in ['Elevation', 'Aspect', 'Slope',\n       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']:\n    before = len(x)\n    x = x[x[cname].between(\n        original[cname].min(),\n        original[cname].max(),\n    )]\n    after = len(x)\n    print(cname, after-before, before, after, sep='\\t')\ndef clean_one_hot(cnames, x=x):\n    cnt = x[cnames].sum(axis=1)\n    before = len(x)\n    x = x[cnt==1]\n    after = len(x)\n    print(after-before, before, after, sep='\\t')\n    return x\nx = clean_one_hot([\n    'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4'\n])\nx = clean_one_hot([\n    'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n    'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n    'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n    'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n    'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n    'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n    'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n    'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n    'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n    'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40',\n])\nsynthetic = x\ndel x","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:19.419234Z","iopub.execute_input":"2021-12-13T00:24:19.419664Z","iopub.status.idle":"2021-12-13T00:24:29.142477Z","shell.execute_reply.started":"2021-12-13T00:24:19.419617Z","shell.execute_reply":"2021-12-13T00:24:29.141494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ? Aspect of 1 degree-angle would closely resemble 359 degree ?","metadata":{}},{"cell_type":"markdown","source":"A classifier should have difficulty to separate samples of 1 degree from 359 degree (due to similarity)","metadata":{}},{"cell_type":"markdown","source":"#### Original Dataset","metadata":{}},{"cell_type":"code","source":"high = original.Aspect.between(340,359)\nlow = original.Aspect.between(1,20)\nhigh = original[high].copy()\nhigh['isHigh'] = 1\nlow = original[low].copy()\nlow['isHigh'] = 0\nx = pd.concat([high, low])\ny = x.pop('isHigh')\nprint('total sample', len(x))\nprint('target class balance', y.mean())\nx.pop('Aspect') # important, it's too easy if the classifier can see the Aspect directly\nx.pop('Id')\nx = x.drop(columns=['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']) # explained later\nx = x.to_numpy()\ny = y.to_numpy()\ntrain, val = train_test_split(np.arange(len(x)), stratify=y, random_state=0)\nest = RandomForestClassifier(random_state=0)\nest.fit(x[train], y[train])\nprint('train score', accuracy_score(y[train], est.predict(x[train])))\nprint('val score', accuracy_score(y[val], est.predict(x[val])))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:29.143733Z","iopub.execute_input":"2021-12-13T00:24:29.143942Z","iopub.status.idle":"2021-12-13T00:24:29.615874Z","shell.execute_reply.started":"2021-12-13T00:24:29.143916Z","shell.execute_reply":"2021-12-13T00:24:29.6151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With validation-accuracy only 57% it seems the classifier is having hard time separating `Aspect<20` from `Aspect>340`, because those Aspect values are close/similar.","metadata":{}},{"cell_type":"markdown","source":"**Why I drop `Hillshade` columns?**\n\nI believe Hillshade have a strong correlation with Aspect. E.g. if your house is facing East (`Aspect=90`), then your house will be brighter at morning, compared to other houses facing West that will be darker at morning (`Aspect=270`). Large Hillshade value means brighter, and vice-versa, small Hillshade value means darker.\n\nLet's feed the Hillshade columns back into our classifier to prove the correlation.","metadata":{}},{"cell_type":"code","source":"high = original.Aspect.between(340,359)\nlow = original.Aspect.between(1,20)\nhigh = original[high].copy()\nhigh['isHigh'] = 1\nlow = original[low].copy()\nlow['isHigh'] = 0\nx = pd.concat([high, low])\ny = x.pop('isHigh')\nprint('total sample', len(x))\nprint('target class balance', y.mean())\nx.pop('Aspect') # important, it's too easy if the classifier can see the Aspect directly\nx.pop('Id')\n# Hillshade data are not dropped this time\nx = x.to_numpy()\ny = y.to_numpy()\ntrain, val = train_test_split(np.arange(len(x)), stratify=y, random_state=0)\nest = RandomForestClassifier(random_state=0)\nest.fit(x[train], y[train])\nprint('train score', accuracy_score(y[train], est.predict(x[train])))\nprint('val score', accuracy_score(y[val], est.predict(x[val])))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:29.617484Z","iopub.execute_input":"2021-12-13T00:24:29.617801Z","iopub.status.idle":"2021-12-13T00:24:29.99093Z","shell.execute_reply.started":"2021-12-13T00:24:29.617761Z","shell.execute_reply":"2021-12-13T00:24:29.990075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The validation-accuracy improves from 57% to 98%, hence Hillshade have strong correlation with Aspect ... ***at least in the original dataset***.","metadata":{}},{"cell_type":"markdown","source":"#### Synthetic Dataset","metadata":{}},{"cell_type":"code","source":"high = synthetic.Aspect.between(340,359)\nlow = synthetic.Aspect.between(1,20)\nhigh = synthetic[high].sample(999, random_state=0).copy()\nhigh['isHigh'] = 1\nlow = synthetic[low].sample(999, random_state=0).copy()\nlow['isHigh'] = 0\nx = pd.concat([high, low])\ny = x.pop('isHigh')\nx.pop('Aspect') # important, it's too easy if the classifier can see the Aspect directly\nx.pop('Id')\nx = x.drop(columns=['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']) # explained above\nx = x.to_numpy()\ny = y.to_numpy()\nprint('total sample', len(x))\nprint('target class balance', y.mean())\ntrain, val = train_test_split(np.arange(len(x)), stratify=y, random_state=0)\nest = RandomForestClassifier(random_state=0)\nest.fit(x[train], y[train])\nprint('train score', accuracy_score(y[train], est.predict(x[train])))\nprint('val score', accuracy_score(y[val], est.predict(x[val])))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:29.992496Z","iopub.execute_input":"2021-12-13T00:24:29.992788Z","iopub.status.idle":"2021-12-13T00:24:30.634891Z","shell.execute_reply.started":"2021-12-13T00:24:29.992748Z","shell.execute_reply":"2021-12-13T00:24:30.633991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only 52% accuracy, pretty similar with our finding on original data, the classifier is having hard time distinguishing similar Aspect (`Aspect<20` versus `Aspect>340`) ... **but let's try to use the Hillshade data now**.","metadata":{}},{"cell_type":"code","source":"high = synthetic.Aspect.between(340,359)\nlow = synthetic.Aspect.between(1,20)\nhigh = synthetic[high].sample(999, random_state=0).copy()\nhigh['isHigh'] = 1\nlow = synthetic[low].sample(999, random_state=0).copy()\nlow['isHigh'] = 0\nx = pd.concat([high, low])\ny = x.pop('isHigh')\nx.pop('Aspect') # important, it's too easy if the classifier can see the Aspect directly\nx.pop('Id')\n# Hillshade data are not dropped this time\nx = x.to_numpy()\ny = y.to_numpy()\nprint('total sample', len(x))\nprint('target class balance', y.mean())\ntrain, val = train_test_split(np.arange(len(x)), stratify=y, random_state=0)\nest = RandomForestClassifier(random_state=0)\nest.fit(x[train], y[train])\nprint('train score', accuracy_score(y[train], est.predict(x[train])))\nprint('val score', accuracy_score(y[val], est.predict(x[val])))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:30.636227Z","iopub.execute_input":"2021-12-13T00:24:30.637152Z","iopub.status.idle":"2021-12-13T00:24:31.267311Z","shell.execute_reply.started":"2021-12-13T00:24:30.637106Z","shell.execute_reply":"2021-12-13T00:24:31.266501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now this is funny. The validation-accuracy staying around 52%, while in the original-dataset the validation-accuracy improves drastically from 57% to 98%. Hence my conclusion is:\n\n**In the original dataset, Aspect is strongly-correlated with Hillshade. But this doesn't hold true for the synthetic dataset.**","metadata":{}},{"cell_type":"markdown","source":"### ? Aspect of 90 degree-angle would be very different from 270 degree ?","metadata":{}},{"cell_type":"markdown","source":"A classifier should be able to easily distinguish samples of 90 degree from 270 degree, since facing East would bring a lot of difference compared to facing West.","metadata":{}},{"cell_type":"markdown","source":"#### Original Dataset","metadata":{}},{"cell_type":"code","source":"east = original.Aspect.between(70,110)\nwest = original.Aspect.between(260,280)\neast = original[east].sample(500, random_state=0).copy()\neast['isEast'] = 1\nwest = original[west].copy()\nwest['isEast'] = 0\nx = pd.concat([east, west])\ny = x.pop('isEast')\nprint('total sample', len(x))\nprint('target class balance', y.mean())\nx.pop('Aspect') # important, it's too easy if the classifier can see the Aspect directly\nx.pop('Id')\nx = x.drop(columns=['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']) # explained above\nx = x.to_numpy()\ny = y.to_numpy()\ntrain, val = train_test_split(np.arange(len(x)), stratify=y, random_state=0)\nest = RandomForestClassifier(random_state=0)\nest.fit(x[train], y[train])\nprint('train score', accuracy_score(y[train], est.predict(x[train])))\nprint('val score', accuracy_score(y[val], est.predict(x[val])))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:31.271037Z","iopub.execute_input":"2021-12-13T00:24:31.271557Z","iopub.status.idle":"2021-12-13T00:24:31.589641Z","shell.execute_reply.started":"2021-12-13T00:24:31.271518Z","shell.execute_reply":"2021-12-13T00:24:31.588736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I would say that validation-score 85% is pretty good. The classifier can easily separate the sample that facing East from the one that facing West.","metadata":{}},{"cell_type":"markdown","source":"#### Synthetic Dataset","metadata":{}},{"cell_type":"code","source":"east = synthetic.Aspect.between(70,110)\nwest = synthetic.Aspect.between(260,280)\neast = synthetic[east].sample(500, random_state=0).copy()\neast['isEast'] = 1\nwest = synthetic[west].sample(500, random_state=0).copy()\nwest['isEast'] = 0\nx = pd.concat([east, west])\ny = x.pop('isEast')\nprint('total sample', len(x))\nprint('target class balance', y.mean())\nx.pop('Aspect') # important, it's too easy if the classifier can see the Aspect directly\nx.pop('Id')\nx = x.drop(columns=['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']) # explained above\nx = x.to_numpy()\ny = y.to_numpy()\ntrain, val = train_test_split(np.arange(len(x)), stratify=y, random_state=0)\nest = RandomForestClassifier(random_state=0)\nest.fit(x[train], y[train])\nprint('train score', accuracy_score(y[train], est.predict(x[train])))\nprint('val score', accuracy_score(y[val], est.predict(x[val])))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T00:24:31.590977Z","iopub.execute_input":"2021-12-13T00:24:31.591232Z","iopub.status.idle":"2021-12-13T00:24:32.064037Z","shell.execute_reply.started":"2021-12-13T00:24:31.591205Z","shell.execute_reply":"2021-12-13T00:24:32.063092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now this is funny. Only 48% accuracy is indication that the classifier is having difficulty separating the sample that facing East from the one that facing West.\n\nWe can get 85% accuracy on the original dataset, but only able to get 48% accuracy on the synthetic dataset.","metadata":{}},{"cell_type":"markdown","source":"## Take Away","metadata":{}},{"cell_type":"markdown","source":"`Aspect` column in the synthetic-dataset is quite different from what the real-data (original-dataset) should be. Seems like the generation of synthethic data wasn't able to properly generate the periodicity of a feature, and it's also failing to generate the same correlation between features.","metadata":{}}]}