{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:10.561401Z","iopub.execute_input":"2022-01-02T13:50:10.561839Z","iopub.status.idle":"2022-01-02T13:50:10.599454Z","shell.execute_reply.started":"2022-01-02T13:50:10.561728Z","shell.execute_reply":"2022-01-02T13:50:10.598708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Загрузка данных","metadata":{}},{"cell_type":"code","source":"input_dir = \"/kaggle/input/tabular-playground-series-dec-2021/\"\ntrain = pd.read_csv(input_dir+\"train.csv\", index_col='Id')\ntest = pd.read_csv(input_dir+\"test.csv\", index_col='Id')\nsub = pd.read_csv(input_dir+\"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:10.603486Z","iopub.execute_input":"2022-01-02T13:50:10.603964Z","iopub.status.idle":"2022-01-02T13:50:30.90662Z","shell.execute_reply.started":"2022-01-02T13:50:10.603927Z","shell.execute_reply":"2022-01-02T13:50:30.90591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Выделили непрерывные колонки, бинарные и целевую","metadata":{}},{"cell_type":"code","source":"cont_cols = [\"Elevation\",\"Aspect\",\"Slope\",\"Horizontal_Distance_To_Hydrology\", \\\n                   \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\\\n                   \"Horizontal_Distance_To_Fire_Points\",\\\n                  \"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\"]\n\nbinary_cols = [f\"Wilderness_Area{i}\" for i in range(1,5)]+[f\"Soli_Type{i}\" for i in range(1,41)]\ntarget_col = \"Cover_Type\"","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:30.908004Z","iopub.execute_input":"2022-01-02T13:50:30.908244Z","iopub.status.idle":"2022-01-02T13:50:30.913355Z","shell.execute_reply.started":"2022-01-02T13:50:30.908211Z","shell.execute_reply":"2022-01-02T13:50:30.912407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[target_col].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:30.914576Z","iopub.execute_input":"2022-01-02T13:50:30.915024Z","iopub.status.idle":"2022-01-02T13:50:30.947139Z","shell.execute_reply.started":"2022-01-02T13:50:30.914967Z","shell.execute_reply":"2022-01-02T13:50:30.94633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Искусственно добавили 20 строчек класса 5","metadata":{}},{"cell_type":"code","source":"row_5 = train[train[target_col]==5] \nfor i in range(20):\n    train = train.append( row_5, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:30.94945Z","iopub.execute_input":"2022-01-02T13:50:30.950571Z","iopub.status.idle":"2022-01-02T13:50:43.723966Z","shell.execute_reply.started":"2022-01-02T13:50:30.950506Z","shell.execute_reply":"2022-01-02T13:50:43.722973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[target_col].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:43.728454Z","iopub.execute_input":"2022-01-02T13:50:43.728739Z","iopub.status.idle":"2022-01-02T13:50:43.777734Z","shell.execute_reply.started":"2022-01-02T13:50:43.728704Z","shell.execute_reply":"2022-01-02T13:50:43.77685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[target_col] = train[target_col]-1","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:43.781625Z","iopub.execute_input":"2022-01-02T13:50:43.783653Z","iopub.status.idle":"2022-01-02T13:50:43.811626Z","shell.execute_reply.started":"2022-01-02T13:50:43.783617Z","shell.execute_reply":"2022-01-02T13:50:43.810938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Поделили train/val 0.9/0.1","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, val, _, _ = train_test_split(train, train[target_col], test_size=0.1, stratify = train[target_col])","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:43.815898Z","iopub.execute_input":"2022-01-02T13:50:43.817937Z","iopub.status.idle":"2022-01-02T13:50:50.066616Z","shell.execute_reply.started":"2022-01-02T13:50:43.817901Z","shell.execute_reply":"2022-01-02T13:50:50.06587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Нормируем непрерывные колонки","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ntrain[cont_cols] = scaler.fit_transform(train[cont_cols])\nval[cont_cols] = scaler.transform(val[cont_cols])\ntest[cont_cols] = scaler.transform(test[cont_cols])","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:50.06782Z","iopub.execute_input":"2022-01-02T13:50:50.068081Z","iopub.status.idle":"2022-01-02T13:50:55.86846Z","shell.execute_reply.started":"2022-01-02T13:50:50.068048Z","shell.execute_reply":"2022-01-02T13:50:55.86774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_cols = cont_cols+binary_cols\nn_classes = len(train[target_col].unique())","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:55.869549Z","iopub.execute_input":"2022-01-02T13:50:55.869807Z","iopub.status.idle":"2022-01-02T13:50:55.894441Z","shell.execute_reply.started":"2022-01-02T13:50:55.869775Z","shell.execute_reply":"2022-01-02T13:50:55.893838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Класс Dataset (особенность pytorch - нужно переопределять класс dataset)","metadata":{}},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import optim\n\nclass ForestDataset(Dataset):\n    def __init__(self, csv):\n        if target_col in csv.columns:\n            self.X = csv.drop(columns=[target_col]).values\n            self.y = csv[target_col].values\n        else:\n            self.X = csv.values\n            csv[target_col] = 0\n            self.y = csv[target_col].values\n    def __len__(self):\n        return len(self.y)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n    \ntrain_dataset = ForestDataset(train)\nval_dataset = ForestDataset(val)\n#test_dataset = ForestDataset(test)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:55.895449Z","iopub.execute_input":"2022-01-02T13:50:55.895787Z","iopub.status.idle":"2022-01-02T13:50:58.130579Z","shell.execute_reply.started":"2022-01-02T13:50:55.89575Z","shell.execute_reply":"2022-01-02T13:50:58.129793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Класс модели (полносвязная сеть)","metadata":{}},{"cell_type":"code","source":"class MultiLayerPerceptron(nn.Module):\n    def __init__(self, len_fc1, len_fc2):\n        super().__init__()\n        self.fc1 = nn.Linear(len(all_cols), len_fc1)\n        self.act1 = nn.Tanh()\n        self.fc2 = nn.Linear(len_fc1, len_fc2)\n        self.act2 = nn.Tanh()\n        self.fc3 = nn.Linear(len_fc2, n_classes)\n        \n    def forward(self, x):\n        x = self.act1( self.fc1(x) )\n        x = self.act2( self.fc2(x) )\n        return self.fc3(x)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:58.131797Z","iopub.execute_input":"2022-01-02T13:50:58.132035Z","iopub.status.idle":"2022-01-02T13:50:58.139402Z","shell.execute_reply.started":"2022-01-02T13:50:58.132003Z","shell.execute_reply":"2022-01-02T13:50:58.138733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Модель, лосс, оптимизатор","metadata":{}},{"cell_type":"code","source":"mlp_model = MultiLayerPerceptron(3*len(test.columns), 3*len(test.columns)).to('cuda')\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(mlp_model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:50:58.140866Z","iopub.execute_input":"2022-01-02T13:50:58.141313Z","iopub.status.idle":"2022-01-02T13:51:00.520543Z","shell.execute_reply.started":"2022-01-02T13:50:58.14128Z","shell.execute_reply":"2022-01-02T13:51:00.519826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# функция, которая выполняет 1 эпоху train","metadata":{}},{"cell_type":"code","source":"def train_epoch(model,criterion,optimizer,dataset,epoch):\n    train_dataset=dataset\n    data_loader=DataLoader(dataset,batch_size=32,shuffle=True,num_workers=4)\n    dataset_size=len(dataset)\n    print(f\"Epoch#{epoch}. Train\")\n    start_time=time.time()\n    model.train()\n    running_loss=0.0 #накопление лосса\n    running_acc=0.0\n    epoch_loss=0.0\n    \n    for inputs,labels in tqdm( data_loader):\n        inputs=inputs.to('cuda').type(torch.float)\n        labels=labels.to('cuda')#.type(torch.float) #передаем батч на GPU(cuda)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss=criterion(outputs,labels)\n        loss.backward() # обратное распостранение градиента\n        optimizer.step() # шаг оптимизатора\n        running_loss+=loss.item()*inputs.size(0)\n        \n        _,preds=torch.max(outputs,dim=1)\n        running_acc+= (torch.sum(preds == labels.data))\n    epoch_loss = running_loss / dataset_size\n    epoch_acc = running_acc / dataset_size\n    print(f'Loss (cross-entropy): { epoch_loss }')\n    print(f\"Accuracy (multiclass): { epoch_acc }\")\n    print(f\"Epoch#{epoch} (Train) completed. {round(time.time()-start_time,3)}s \")\n    return model, epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:51:00.52358Z","iopub.execute_input":"2022-01-02T13:51:00.523864Z","iopub.status.idle":"2022-01-02T13:51:00.532657Z","shell.execute_reply.started":"2022-01-02T13:51:00.523826Z","shell.execute_reply":"2022-01-02T13:51:00.531806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# функция, которая считает 1 эпоху валидации","metadata":{}},{"cell_type":"code","source":"def valid_epoch(model,criterion,optimizer,dataset,epoch):\n    val_dataset=dataset\n    data_loader=DataLoader(dataset,batch_size=32,shuffle=True,num_workers=4)\n    dataset_size=len(val_dataset)\n    print(f\"Epoch#{epoch}. Validation\")\n    start_time=time.time()\n    model.eval()\n    running_loss=0.0 # накопление лосc\n    running_acc=0.0\n    epoch_loss=0.0\n    with torch.no_grad():\n        for inputs,labels in tqdm( data_loader):\n            inputs=inputs.to('cuda').type(torch.float)\n            labels=labels.to('cuda')#.type(torch.float) #передаем батч на GPU(cuda)\n            outputs = model(inputs)\n            loss=criterion(outputs,labels)\n            running_loss+=loss.item()*inputs.size(0)\n            _,preds=torch.max(outputs,dim=1)\n            running_acc+= (torch.sum(preds == labels.data))\n            \n    epoch_loss = running_loss / dataset_size\n    epoch_acc = running_acc / dataset_size\n    print(f'Loss (cross-entropy): { epoch_loss } ')\n    print(f\"Accuracy (multiclass): { epoch_acc }\")\n    print(f\"Epoch#{epoch} (Validation) completed. {round(time.time()-start_time,3)}s \")\n    return model, epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:51:00.533784Z","iopub.execute_input":"2022-01-02T13:51:00.534647Z","iopub.status.idle":"2022-01-02T13:51:00.545888Z","shell.execute_reply.started":"2022-01-02T13:51:00.534611Z","shell.execute_reply":"2022-01-02T13:51:00.54526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train-loop модели (выбор лучшей за n эпох - по accuracy на валидации)","metadata":{}},{"cell_type":"code","source":"best_model = mlp_model\nbest_epoch = 1\nbest_loss = 1000000\nbest_acc = 0\n#num_epochs=len(keys)*2\nnum_epochs = 10\n\ntrain_loss_history = []\nval_loss_history = []\n\ntrain_acc_history = []\nval_acc_history = []\n\nfor epoch in range(1,num_epochs+1):\n    #тренировка\n    mlp_model, train_loss, train_acc = train_epoch(mlp_model,criterion,optimizer,train_dataset,epoch)\n    train_loss_history.append(train_loss)\n    train_acc_history.append(train_acc)\n    \n    mlp_model, val_loss, val_acc = valid_epoch(mlp_model,criterion,optimizer,val_dataset,epoch)\n    val_loss_history.append(val_loss)\n    val_acc_history.append(val_acc)\n    \n    #if(val_loss<best_loss):\n    if(val_acc>best_acc):\n        best_model = mlp_model\n        best_epoch = epoch","metadata":{"execution":{"iopub.status.busy":"2022-01-02T13:51:00.547091Z","iopub.execute_input":"2022-01-02T13:51:00.547697Z","iopub.status.idle":"2022-01-02T14:59:09.883555Z","shell.execute_reply.started":"2022-01-02T13:51:00.547643Z","shell.execute_reply":"2022-01-02T14:59:09.882755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Сохранили модель в файл","metadata":{}},{"cell_type":"code","source":"#saving\noutput_model_file = 'best_model.bin'\ntorch.save(best_model, output_model_file)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T14:59:09.885566Z","iopub.execute_input":"2022-01-02T14:59:09.886144Z","iopub.status.idle":"2022-01-02T14:59:09.896423Z","shell.execute_reply.started":"2022-01-02T14:59:09.886098Z","shell.execute_reply":"2022-01-02T14:59:09.895777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference - для kaggle соревнования, вывод на test-выборке","metadata":{}},{"cell_type":"code","source":"test_dataset = ForestDataset(test)\ntest_dataset","metadata":{"execution":{"iopub.status.busy":"2022-01-02T14:59:09.897931Z","iopub.execute_input":"2022-01-02T14:59:09.8982Z","iopub.status.idle":"2022-01-02T14:59:10.115742Z","shell.execute_reply.started":"2022-01-02T14:59:09.898165Z","shell.execute_reply":"2022-01-02T14:59:10.115031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_loader=DataLoader(test_dataset,batch_size=32,shuffle=False,num_workers=4)\ndataset_size=len(test_dataset)\nbest_model.eval()\n\npreds_list = []\nwith torch.no_grad():\n    for inputs,labels in tqdm( data_loader):\n        inputs=inputs.to('cuda').type(torch.float)\n        labels=labels.to('cuda')\n        outputs = best_model(inputs)\n        _,preds=torch.max(outputs,dim=1)\n        preds_list.append(preds)\ntorch.cat(preds_list)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T14:59:10.117031Z","iopub.execute_input":"2022-01-02T14:59:10.117435Z","iopub.status.idle":"2022-01-02T15:00:13.720498Z","shell.execute_reply.started":"2022-01-02T14:59:10.117398Z","shell.execute_reply":"2022-01-02T15:00:13.719633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub[\"Cover_Type\"] = torch.cat(preds_list).cpu().detach().numpy()\nsub[\"Cover_Type\"] = sub[\"Cover_Type\"]+1 #вернули обратно номера классов, потому что в начале делали -1","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:00:13.722177Z","iopub.execute_input":"2022-01-02T15:00:13.722476Z","iopub.status.idle":"2022-01-02T15:00:13.760616Z","shell.execute_reply.started":"2022-01-02T15:00:13.722437Z","shell.execute_reply":"2022-01-02T15:00:13.75991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission_mlp.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:00:13.762007Z","iopub.execute_input":"2022-01-02T15:00:13.762276Z","iopub.status.idle":"2022-01-02T15:00:15.368854Z","shell.execute_reply.started":"2022-01-02T15:00:13.762237Z","shell.execute_reply":"2022-01-02T15:00:15.368137Z"},"trusted":true},"execution_count":null,"outputs":[]}]}