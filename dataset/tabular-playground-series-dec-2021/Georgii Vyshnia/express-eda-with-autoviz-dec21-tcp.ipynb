{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"color:white;background-color:#1d1545;padding:3%;border-radius:50px 50px;font-size:1em;text-align:center\">Introduction</div>\n\nThis notebook is intended to extract useful insights for the datasets of ‘Tabular Playground Series - Dec 2021’ competition in Kaggle. \n\nFor this competition, you will be predicting a categorical target based on a number of feature columns given in the data. \n\nThe data is synthetically generated by a GAN that was trained on a the data from the [Forest Cover Type Prediction](https://www.kaggle.com/c/forest-cover-type-prediction/overview). This dataset is (a) much larger, and (b) may or may not have the same relationship to the target as the original data.\n\n**Note:** Please refer to this [data page](https://www.kaggle.com/c/forest-cover-type-prediction/data) for a detailed explanation of the features.\n\nWe are going to perform the complete and comprehensive EDA as follows\n-\tAutomate the generic aspects of EDA with AutoViz, one of the leading freeware Rapid EDA tools in Pythonic Data Science world\n-\tDeep into the problem-specific advanced analytical questions/discoveries with the custom manual EDA routines programmed on top of standard capabilities of conventional Python visualization libraries","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:white;background-color:#1d1545;padding:3%;border-radius:50px 50px;font-size:1em;text-align:center\">EDA Findings in Training Set</div>\n\nThis section will be focused on the discoveries and insights we obtained from the *AutoViz*-automated EDA for the contest dataset.\n\n**Note:** The diagrams used in the subsecctions have been automatically generated by running the code in the next chapter. The charts were generated in a matter of minutes thus exposing you to spend time on more thinking-intensive activities and drawing insights from your data.","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"font-size:20px;text-align:center;color:black;border-bottom:5px #0026d6 solid;padding-bottom:3%\">Target Class Label Distribution</div>\n\nOne of the plots auto-generated by *AutoViz* displays the bar chats to visualize the distribution of the class labels of target variable.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/gvyshnya/tab-dec-21/main/AutoViz_Plots/Cover_Type/Dist_Plots_target.png\">","metadata":{}},{"cell_type":"markdown","source":"Based on the charts above, we find that \n- the target class labels are seriously imbalanced, with labels *4* and *5* to be neglactibely small relative to other class labels (it may justify exclusing the observations with such class labels from the training set, to improve the ML model accuracy)\n- it will be required to use one of the industrial techniques to handle inbalanced target class problem iin ML modelling experiments down the road (see below)","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"font-size:20px;text-align:center;color:black;border-bottom:5px #0026d6 solid;padding-bottom:3%\">Relations Between Numeric Feature and Target</div>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/gvyshnya/tab-dec-21/main/AutoViz_Plots/Cover_Type/Box_Plots.png\">","metadata":{}},{"cell_type":"markdown","source":"Reviewing the box plots above reveals a lot of interesting insights\n- There are certain numeric features that have strong association with the target variable (*Cover_Type*) and thus they are going to be quite good predictors (for instance, *Elevation*, *Horizontal_Distance_to_Hydrology*, *Vertical_Distance_to_Hydrology*, *Hillshade_9am*, *'Horizontal_Distance_to_Fire_Points'*)\n- Other features seem to be less strong predictors in terms of their association with the target class labels (howerver, it  does not equally justify excluding such features from the model training in ML Experiments)","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/gvyshnya/tab-dec-21/main/AutoViz_Plots/Cover_Type/Scatter_Plots.png\">","metadata":{}},{"cell_type":"markdown","source":"The pair scatter plots above further detail the insights on the feature variables-to-target class label relations.","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"font-size:20px;text-align:center;color:black;border-bottom:5px #0026d6 solid;padding-bottom:3%\">Pair Associations Between Features by Target</div>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/gvyshnya/tab-dec-21/main/AutoViz_Plots/Cover_Type/Pair_Scatter_Plots.png\">","metadata":{}},{"cell_type":"markdown","source":"When we review the associations between the feature variables (factored by the distribution of the target class labels in the training set observations), we see *Elevation* to separate the target class labels quite solidly, in the interactions with other feature variables.","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"font-size:20px;text-align:center;color:black;border-bottom:5px #0026d6 solid;padding-bottom:3%\">Pair Correlations Between Features</div>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/gvyshnya/tab-dec-21/main/AutoViz_Plots/Cover_Type/Heat_Maps.png\">","metadata":{}},{"cell_type":"markdown","source":"Although many numeric features in this dataset are often categories with numeric discrete values, looking at the Pearson correlation between such variables can still bring some more insights on highly associated/'correlated' features. From that standpoint, we observe that\n\n- *'Wilderness_Area1'* and *'Wilderness_Area3'* are highgly correlated, and one of such features can be removed from the training set withough compromising the model accuracy","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:white;background-color:#1d1545;padding:3%;border-radius:50px 50px;font-size:1em;text-align:center\">Call for Action: Let's get the hands dirty</div>\n\nThe sections below demonstrate the source code of the express EDA experiment that lead to the insights collected above.\n\nExecuting the source code in the sections below will lead to generating the charts used as images in the previous chapter.","metadata":{}},{"cell_type":"code","source":"!pip install AutoViz","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-11T18:25:52.663671Z","iopub.execute_input":"2021-12-11T18:25:52.664404Z","iopub.status.idle":"2021-12-11T18:26:03.29819Z","shell.execute_reply.started":"2021-12-11T18:25:52.664265Z","shell.execute_reply":"2021-12-11T18:26:03.297158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"font-size:20px;text-align:center;color:black;border-bottom:5px #0026d6 solid;padding-bottom:3%\">Initial Preparations</div>\n\nWe are going to start with the essential pre-requisites as follows\n\n- installing *AutoViz* into this notebook\n- importing the standard Python packages we need to use down the road\n- programming the useful automation routines for repeatable data visualizations we are going to draw in the Advance Analytical EDA trials down the road","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as dt\nfrom typing import Tuple, List, Dict\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.offline\n\n\n# read data\nin_kaggle = True\n\ndef get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n    train_path = ''\n    test_path = ''\n    sample_submission_path = ''\n\n    if is_in_kaggle:\n        # running in Kaggle, inside the competition\n        train_path = '../input/tabular-playground-series-dec-2021/train.csv'\n        test_path = '../input/tabular-playground-series-dec-2021/test.csv'\n        sample_submission_path = '../input/tabular-playground-series-dec-2021/sample_submission.csv'\n    else:\n        # running locally\n        train_path = 'data/train.csv'\n        test_path = 'data/test.csv'\n        sample_submission_path = 'data/sample_submission.csv'\n\n    return train_path, test_path, sample_submission_path","metadata":{"execution":{"iopub.status.busy":"2021-12-11T18:26:03.300083Z","iopub.execute_input":"2021-12-11T18:26:03.300324Z","iopub.status.idle":"2021-12-11T18:26:05.303005Z","shell.execute_reply.started":"2021-12-11T18:26:03.300297Z","shell.execute_reply":"2021-12-11T18:26:05.302113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# main flow\nstart_time = dt.datetime.now()\nprint(\"Started at \", start_time)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T18:26:05.30456Z","iopub.execute_input":"2021-12-11T18:26:05.304819Z","iopub.status.idle":"2021-12-11T18:26:05.309562Z","shell.execute_reply.started":"2021-12-11T18:26:05.304763Z","shell.execute_reply":"2021-12-11T18:26:05.30872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# get the training set and labels\ntrain_set_path, test_set_path, sample_subm_path = get_data_file_path(in_kaggle)\n\ndf_train = pd.read_csv(train_set_path)\ndf_test = pd.read_csv(test_set_path)\n\nsubm = pd.read_csv(sample_subm_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T18:26:05.311961Z","iopub.execute_input":"2021-12-11T18:26:05.312281Z","iopub.status.idle":"2021-12-11T18:26:24.046968Z","shell.execute_reply.started":"2021-12-11T18:26:05.312238Z","shell.execute_reply":"2021-12-11T18:26:24.045688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"font-size:20px;text-align:center;color:black;border-bottom:5px #0026d6 solid;padding-bottom:3%\">Training Set Overview</div>","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T18:26:24.048559Z","iopub.execute_input":"2021-12-11T18:26:24.048901Z","iopub.status.idle":"2021-12-11T18:26:24.078088Z","shell.execute_reply.started":"2021-12-11T18:26:24.048856Z","shell.execute_reply":"2021-12-11T18:26:24.076976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"font-size:20px;text-align:center;color:black;border-bottom:5px #0026d6 solid;padding-bottom:3%\">Detecting Cardinality of the Variables in Training Set</div>","metadata":{}},{"cell_type":"code","source":"cols = df_train.columns\nfor f in cols:\n    dist_value = df_train[f].value_counts().shape[0]\n    print('Variable {:>40} has {} distinct values'.format(f, dist_value))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T18:26:24.080685Z","iopub.execute_input":"2021-12-11T18:26:24.081368Z","iopub.status.idle":"2021-12-11T18:26:25.980932Z","shell.execute_reply.started":"2021-12-11T18:26:24.081315Z","shell.execute_reply":"2021-12-11T18:26:25.979744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result, we see that *'Soil_Type15'*, and *'Soil_Type7'* have just one value in every training records. Therefore it won't make any sense to use such features in the model training down the road.\n\n'Id' feature is also a nominal identifier, and therefore it should be excluded from the training set in the model training time down the road. ","metadata":{}},{"cell_type":"code","source":"features_to_drop = ['Soil_Type15', 'Soil_Type7']\ndf_train = df_train.drop(features_to_drop, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T18:26:25.982559Z","iopub.execute_input":"2021-12-11T18:26:25.983001Z","iopub.status.idle":"2021-12-11T18:26:26.974216Z","shell.execute_reply.started":"2021-12-11T18:26:25.982951Z","shell.execute_reply":"2021-12-11T18:26:26.973002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <div style=\"font-size:20px;text-align:center;color:black;border-bottom:5px #0026d6 solid;padding-bottom:3%\">Express EDA Analysis with AutoViz</div>\n\nWe are going to invoke *AutoViz*, one of the prominent freeware Pythonic Rapid EDA tools, to quickly draw the basic insights about the data","metadata":{}},{"cell_type":"code","source":"# uncomment the block below to run it on your premise\n'''from autoviz.AutoViz_Class import AutoViz_Class\n\nAV = AutoViz_Class()\ndftc = AV.AutoViz(\n    filename='', \n    sep='' , \n    depVar='Cover_Type', \n    dfte=df_train, \n    header=0, \n    verbose=1, \n    lowess=False, \n    chart_format='png', \n    max_rows_analyzed=400000, \n    max_cols_analyzed=55\n)'''\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T18:26:26.976052Z","iopub.execute_input":"2021-12-11T18:26:26.976377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****# <div style=\"color:white;background-color:#1d1545;padding:3%;border-radius:50px 50px;font-size:1em;text-align:center\">Tackling Imbalanced Target Class Labels</div>\n\nSince we detected extremely imbanalced target class labels, we should take it into account when building ML models down the road. We can choose from one of the conventional methods below\n\n- undersampling\n- oversampling (like using SMOTE etc.)\n- assigning the differnt class label weights in the ML model training\n- Etc.\n\n**Note:** In a nice discussion thread per [Imbalanced classes vs. imbalanced cost](https://www.kaggle.com/c/tabular-playground-series-dec-2021/discussion/294305) it is presented with the arguments on why resampling methods are not likely to work in a less efficient manner vs. class weightening and other model-level tweaks.","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:white;background-color:#1d1545;padding:3%;border-radius:50px 50px;font-size:1em;text-align:center\">Benefits</div>\n\nThis notebook provides a real-world example of how **AutoViz**, one of the best freeware Rapid EDA tools, can save your time on routinous steps in EDA while allowing you to spend more time on drawing the real insights from your data, using the auto-generated charts producted by **AutoViz**.\n\nThe contribution in this notebook expands on the research to prove **AutoViz** to be a good automation tool for Data Analysts/Data Scientists. Previous EDA experiments with **AutoViz** could be reviewed below\n\n- [Using AutoViz to Build a Comprehensive EDA](https://www.kaggle.com/gvyshnya/using-autoviz-to-build-a-comprehensive-eda)\n- [Express EDA with AutoViz](https://www.kaggle.com/gvyshnya/mar-21-tpc-express-eda-with-autoviz)\n- [EDA and Feature Importance Findings](https://www.kaggle.com/c/lish-moa/discussion/190647#1047649)","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:white;background-color:#1d1545;padding:3%;border-radius:50px 50px;font-size:1em;text-align:center\">References</div>\n\n- https://www.kaggle.com/damagejun/tps-dec-2021-eda\n- https://towardsdatascience.com/heres-what-i-ve-learnt-about-sklearn-resample-ab735ae1abc4\n- https://towardsdatascience.com/how-to-handle-imbalance-data-and-small-training-sets-in-ml-989f8053531d\n","metadata":{}},{"cell_type":"code","source":"print('We are done. That is all, folks!')\nfinish_time = dt.datetime.now()\nprint(\"Finished at \", finish_time)\nelapsed = finish_time - start_time\nprint(\"Elapsed time: \", elapsed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}