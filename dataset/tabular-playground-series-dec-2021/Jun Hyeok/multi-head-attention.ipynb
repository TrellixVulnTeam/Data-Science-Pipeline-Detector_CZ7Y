{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **TPS Dec - Multi Head Attention**\n\n* This notebook is based on [tensorflow homepage](https://www.tensorflow.org/)","metadata":{}},{"cell_type":"markdown","source":"[](https://data-science-blog.com/wp-content/uploads/2022/01/mha_visualization-930x1030.png)","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport gc\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:51:54.985006Z","iopub.execute_input":"2021-12-11T20:51:54.985362Z","iopub.status.idle":"2021-12-11T20:52:01.224761Z","shell.execute_reply.started":"2021-12-11T20:51:54.985264Z","shell.execute_reply":"2021-12-11T20:52:01.223895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Memory Reduce Func**\n\n* **If you don't use some memory reducing strategy, you can face some OOM**","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:52:01.226704Z","iopub.execute_input":"2021-12-11T20:52:01.227028Z","iopub.status.idle":"2021-12-11T20:52:01.241505Z","shell.execute_reply.started":"2021-12-11T20:52:01.226988Z","shell.execute_reply":"2021-12-11T20:52:01.240696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-dec-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv')\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:06.539073Z","iopub.execute_input":"2021-12-11T20:53:06.539789Z","iopub.status.idle":"2021-12-11T20:53:06.84026Z","shell.execute_reply.started":"2021-12-11T20:53:06.539757Z","shell.execute_reply":"2021-12-11T20:53:06.839662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature Engineering**\n\n* **Check Missing Values**\n* **Check Target Column**","metadata":{}},{"cell_type":"markdown","source":"* **Soil_Type7 & Soil_Type15 â†’ useless**","metadata":{}},{"cell_type":"code","source":"train = train.drop(columns = ['Id', 'Soil_Type7', 'Soil_Type15'])\ntest = test.drop(columns = ['Id', 'Soil_Type7', 'Soil_Type15'])","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:11.393988Z","iopub.execute_input":"2021-12-11T20:53:11.394802Z","iopub.status.idle":"2021-12-11T20:53:11.996868Z","shell.execute_reply.started":"2021-12-11T20:53:11.394752Z","shell.execute_reply":"2021-12-11T20:53:11.995994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Check Missing Values**\n\n* **Looking good!**","metadata":{}},{"cell_type":"code","source":"print('<----------Value Count of Missing Values in Train Data---------->\\n', train.isna().sum())\nprint('<----------Value Count of Missing Values in Test Data---------->\\n', test.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:12.660165Z","iopub.execute_input":"2021-12-11T20:53:12.660759Z","iopub.status.idle":"2021-12-11T20:53:12.984072Z","shell.execute_reply.started":"2021-12-11T20:53:12.660729Z","shell.execute_reply":"2021-12-11T20:53:12.983225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Check Target Column**\n\n* **There is only one row of class5! We need to drop this**","metadata":{}},{"cell_type":"code","source":"train['Cover_Type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:13.960752Z","iopub.execute_input":"2021-12-11T20:53:13.961449Z","iopub.status.idle":"2021-12-11T20:53:13.992606Z","shell.execute_reply.started":"2021-12-11T20:53:13.96141Z","shell.execute_reply":"2021-12-11T20:53:13.991975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(index = train[train['Cover_Type'] == 5].index).reset_index(drop = True)\ntrain['Cover_Type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:18.783431Z","iopub.execute_input":"2021-12-11T20:53:18.784097Z","iopub.status.idle":"2021-12-11T20:53:20.580414Z","shell.execute_reply.started":"2021-12-11T20:53:18.784054Z","shell.execute_reply":"2021-12-11T20:53:20.57964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Aspect**\n\n* **Aspect means angle. Good for rescaling**\n* **Hillshade needs to rescale to 0 ~ 255**\n\nFrom [gulshanmishra Kernel](https://www.kaggle.com/gulshanmishra/tps-dec-21-tensorflow-nn-feature-engineering)\n\nThank you for sharing nice notebook :)","metadata":{}},{"cell_type":"code","source":"train[\"Aspect\"][train[\"Aspect\"] < 0] += 360\ntrain[\"Aspect\"][train[\"Aspect\"] > 359] -= 360\n\ntest[\"Aspect\"][test[\"Aspect\"] < 0] += 360\ntest[\"Aspect\"][test[\"Aspect\"] > 359] -= 360","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:20.58192Z","iopub.execute_input":"2021-12-11T20:53:20.582174Z","iopub.status.idle":"2021-12-11T20:53:20.758639Z","shell.execute_reply.started":"2021-12-11T20:53:20.582147Z","shell.execute_reply":"2021-12-11T20:53:20.757886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[train[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\ntest.loc[test[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n\ntrain.loc[train[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\ntest.loc[test[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n\ntrain.loc[train[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\ntest.loc[test[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n\ntrain.loc[train[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\ntest.loc[test[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n\ntrain.loc[train[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\ntest.loc[test[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n\ntrain.loc[train[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\ntest.loc[test[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:21.281388Z","iopub.execute_input":"2021-12-11T20:53:21.281651Z","iopub.status.idle":"2021-12-11T20:53:21.325772Z","shell.execute_reply.started":"2021-12-11T20:53:21.281624Z","shell.execute_reply":"2021-12-11T20:53:21.325051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Interaction Features**\n\n* **Sum of Hydrology**\n* **Subtraction of Hydrology**","metadata":{}},{"cell_type":"code","source":"train['Sum_Hydrology'] = np.abs(train['Horizontal_Distance_To_Hydrology']) + np.abs(train['Vertical_Distance_To_Hydrology'])\ntrain['Sub_Hydrology'] = np.abs(train['Horizontal_Distance_To_Hydrology']) - np.abs(train['Vertical_Distance_To_Hydrology'])\n\ntest['Sum_Hydrology'] = np.abs(test['Horizontal_Distance_To_Hydrology']) + np.abs(test['Vertical_Distance_To_Hydrology'])\ntest['Sub_Hydrology'] = np.abs(test['Horizontal_Distance_To_Hydrology']) - np.abs(test['Vertical_Distance_To_Hydrology'])","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:23.394653Z","iopub.execute_input":"2021-12-11T20:53:23.395215Z","iopub.status.idle":"2021-12-11T20:53:23.46578Z","shell.execute_reply.started":"2021-12-11T20:53:23.395178Z","shell.execute_reply":"2021-12-11T20:53:23.464992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Target Encoding**\n\n### **Need to use inverse_transform at the end for submission**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n\nle = LabelEncoder()\ny = le.fit_transform(train['Cover_Type'])\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:24.932241Z","iopub.execute_input":"2021-12-11T20:53:24.932662Z","iopub.status.idle":"2021-12-11T20:53:25.312465Z","shell.execute_reply.started":"2021-12-11T20:53:24.932629Z","shell.execute_reply":"2021-12-11T20:53:25.311609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Scaling**\n\n* **Robust Scaling**","metadata":{}},{"cell_type":"code","source":"train = train.drop(columns = ['Cover_Type'])\n\ncols = train.columns\n\n# Scaling\nrb = RobustScaler()\n\ntrain[cols] = rb.fit_transform(train[cols].values)\ntest[cols] = rb.transform(test[cols].values)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:28.718558Z","iopub.execute_input":"2021-12-11T20:53:28.719061Z","iopub.status.idle":"2021-12-11T20:53:54.670683Z","shell.execute_reply.started":"2021-12-11T20:53:28.719029Z","shell.execute_reply":"2021-12-11T20:53:54.67006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\n\ntrain = train.values\ntest = test.values\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:53:58.306235Z","iopub.execute_input":"2021-12-11T20:53:58.306839Z","iopub.status.idle":"2021-12-11T20:54:00.455875Z","shell.execute_reply.started":"2021-12-11T20:53:58.306799Z","shell.execute_reply":"2021-12-11T20:54:00.45511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\ntarget = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:54:04.899052Z","iopub.execute_input":"2021-12-11T20:54:04.89934Z","iopub.status.idle":"2021-12-11T20:54:04.96554Z","shell.execute_reply.started":"2021-12-11T20:54:04.899309Z","shell.execute_reply":"2021-12-11T20:54:04.964538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modeling**","metadata":{}},{"cell_type":"markdown","source":"## **Multi-Head Attention**\n\n* **Removed Batch Size (No Time Step here)**","metadata":{}},{"cell_type":"code","source":"def scaled_dot_product_attention(q, k, v, mask):\n  matmul_qk = tf.matmul(q, k, transpose_b=True)\n\n  # scale matmul_qk\n  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n    \n  if mask is not None:\n    scaled_attention_logits += (mask * -1e9)\n\n  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n\n  output = tf.matmul(attention_weights, v)\n\n  return output, attention_weights","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:54:09.207153Z","iopub.execute_input":"2021-12-11T20:54:09.207406Z","iopub.status.idle":"2021-12-11T20:54:09.213747Z","shell.execute_reply.started":"2021-12-11T20:54:09.20738Z","shell.execute_reply":"2021-12-11T20:54:09.213179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n  def __init__(self, d_model, num_heads):\n    super(MultiHeadAttention, self).__init__()\n    self.num_heads = num_heads\n    self.d_model = d_model\n\n    assert d_model % self.num_heads == 0\n\n    self.depth = d_model // self.num_heads\n\n    self.wq = tf.keras.layers.Dense(d_model)\n    self.wk = tf.keras.layers.Dense(d_model)\n    self.wv = tf.keras.layers.Dense(d_model)\n\n    self.dense = tf.keras.layers.Dense(d_model)\n\n  def split_heads(self, x):\n    \"\"\"Split the last dimension into (num_heads, depth).\n    Transpose the result such that the shape is (num_heads, seq_len, depth)\n    \"\"\"\n    x = tf.reshape(x, (-1, self.num_heads, self.depth))\n    return tf.transpose(x, perm=[0, 2, 1])\n\n  def call(self, v, k, q, mask):\n    batch_size = tf.shape(q)[0]\n\n    q = self.wq(q)\n    k = self.wk(k)\n    v = self.wv(v)\n\n    q = self.split_heads(q) \n    k = self.split_heads(k) \n    v = self.split_heads(v) \n\n    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n\n    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1]) \n\n    concat_attention = tf.reshape(scaled_attention,\n                                  (-1, self.d_model))\n\n    output = self.dense(concat_attention)\n\n    return output, attention_weights","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:54:20.472478Z","iopub.execute_input":"2021-12-11T20:54:20.472776Z","iopub.status.idle":"2021-12-11T20:54:20.486176Z","shell.execute_reply.started":"2021-12-11T20:54:20.472744Z","shell.execute_reply":"2021-12-11T20:54:20.485243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Feed Forward Net**","metadata":{}},{"cell_type":"code","source":"def point_wise_feed_forward_network(d_model, dff):\n  return tf.keras.Sequential([\n      tf.keras.layers.Dense(dff, activation='relu'),\n      tf.keras.layers.Dense(d_model)\n  ])","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:54:59.870748Z","iopub.execute_input":"2021-12-11T20:54:59.87167Z","iopub.status.idle":"2021-12-11T20:54:59.876829Z","shell.execute_reply.started":"2021-12-11T20:54:59.871633Z","shell.execute_reply":"2021-12-11T20:54:59.875919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Encoder Block**","metadata":{}},{"cell_type":"code","source":"class EncoderLayer(tf.keras.layers.Layer):\n  def __init__(self, d_model, num_heads, dff, rate=0.1):\n    super(EncoderLayer, self).__init__()\n\n    self.mha = MultiHeadAttention(d_model, num_heads)\n    self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n    self.dropout1 = tf.keras.layers.Dropout(rate)\n    self.dropout2 = tf.keras.layers.Dropout(rate)\n\n  def call(self, x, training, mask = None):\n\n    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n    attn_output = self.dropout1(attn_output, training=training)\n    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n\n    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n    ffn_output = self.dropout2(ffn_output, training=training)\n    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n\n    return out2","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:55:08.974362Z","iopub.execute_input":"2021-12-11T20:55:08.975125Z","iopub.status.idle":"2021-12-11T20:55:08.98484Z","shell.execute_reply.started":"2021-12-11T20:55:08.975078Z","shell.execute_reply":"2021-12-11T20:55:08.983992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_model = 54 # Embedding Dimension of our data\ndropout_rate = 0.1","metadata":{"execution":{"iopub.status.busy":"2021-12-11T20:55:11.889052Z","iopub.execute_input":"2021-12-11T20:55:11.889345Z","iopub.status.idle":"2021-12-11T20:55:11.893576Z","shell.execute_reply.started":"2021-12-11T20:55:11.889296Z","shell.execute_reply":"2021-12-11T20:55:11.892546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model Builder**","metadata":{}},{"cell_type":"code","source":"def get_model():\n    inputs = tf.keras.layers.Input(shape = (54))\n\n    x = EncoderLayer(d_model, 6, 512, dropout_rate)(inputs)\n    x = EncoderLayer(d_model, 6, 256, dropout_rate)(x)\n    x = EncoderLayer(d_model, 6, 128, dropout_rate)(x)\n    x = EncoderLayer(d_model, 6, 32, dropout_rate)(x)\n    \n    outputs = tf.keras.layers.Dense(6, activation = 'softmax')(x)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"encoder\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-11T21:00:09.319509Z","iopub.execute_input":"2021-12-11T21:00:09.320216Z","iopub.status.idle":"2021-12-11T21:00:09.329143Z","shell.execute_reply.started":"2021-12-11T21:00:09.32017Z","shell.execute_reply":"2021-12-11T21:00:09.328082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\ntf.keras.utils.plot_model(model, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T21:00:11.421899Z","iopub.execute_input":"2021-12-11T21:00:11.422314Z","iopub.status.idle":"2021-12-11T21:00:12.07105Z","shell.execute_reply.started":"2021-12-11T21:00:11.422284Z","shell.execute_reply":"2021-12-11T21:00:12.070074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**\n\n### **Pseudolabeling using [public data](https://www.kaggle.com/remekkinas/tps12-pseudolabels?select=tps12-pseudolabels_v1.csv)**\n#### **Thanks for sharing Remek Kinas!**\n\n#### **You can increase the EPOCH for better result**","metadata":{}},{"cell_type":"code","source":"EPOCH = 20\nBATCH_SIZE = 1024\nNUM_FOLDS = 5\n\nkf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state=2021)\ntest_preds = []\n\nfor fold, (train_idx, test_idx) in enumerate(kf.split(train, y)):\n    print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n\n    checkpoint_filepath = f\"folds{fold}.hdf5\"\n    X_train, X_valid = train[train_idx], train[test_idx]\n    y_train, y_valid = target[train_idx], target[test_idx]\n\n    model = get_model()\n    model.compile(optimizer = \"adam\",\n                  loss = \"categorical_crossentropy\",\n                  metrics = ['accuracy'])\n\n    lr = ReduceLROnPlateau(monitor = \"val_loss\",\n                           factor = 0.5,\n                           patience = 1,\n                           verbose = 1)\n\n    es = EarlyStopping(monitor = \"val_loss\",\n                       patience = 2,\n                       verbose = 1,\n                       restore_best_weights = True)\n\n    sv = ModelCheckpoint(checkpoint_filepath,\n                         monitor = 'val_loss',\n                         verbose = 1,\n                         save_best_only = True,\n                         save_weights_only = True,\n                         mode = 'auto',\n                         save_freq = 'epoch',\n                         options = None)\n\n    model.fit(X_train,\n              y_train,\n              validation_data = (X_valid, y_valid),\n              epochs = EPOCH,\n              batch_size = BATCH_SIZE,\n              callbacks = [lr, es, sv])\n\n    test_preds.append(model.predict(test))\n\n    del X_train, X_valid, y_train, y_valid, model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T21:00:12.948019Z","iopub.execute_input":"2021-12-11T21:00:12.948304Z","iopub.status.idle":"2021-12-11T21:01:23.564096Z","shell.execute_reply.started":"2021-12-11T21:00:12.948273Z","shell.execute_reply":"2021-12-11T21:01:23.562921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/tabular-playground-series-dec-2021/sample_submission.csv')\nsub['Cover_Type'] = le.inverse_transform(np.argmax(np.array(test_preds).sum(axis = 0), axis = 1))\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('sub.csv', index = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}