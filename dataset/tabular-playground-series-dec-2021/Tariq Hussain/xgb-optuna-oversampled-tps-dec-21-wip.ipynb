{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-09T12:03:32.510692Z","iopub.execute_input":"2021-12-09T12:03:32.511057Z","iopub.status.idle":"2021-12-09T12:03:32.544167Z","shell.execute_reply.started":"2021-12-09T12:03:32.510976Z","shell.execute_reply":"2021-12-09T12:03:32.543046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:03:32.546392Z","iopub.execute_input":"2021-12-09T12:03:32.54703Z","iopub.status.idle":"2021-12-09T12:03:33.380788Z","shell.execute_reply.started":"2021-12-09T12:03:32.546991Z","shell.execute_reply":"2021-12-09T12:03:33.38011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    #iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\n    \n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    #create a dataframe and optimize its memory usage\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-09T12:03:33.382207Z","iopub.execute_input":"2021-12-09T12:03:33.38272Z","iopub.status.idle":"2021-12-09T12:03:33.397148Z","shell.execute_reply.started":"2021-12-09T12:03:33.382682Z","shell.execute_reply":"2021-12-09T12:03:33.396404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = import_data('../input/tabular-playground-series-dec-2021/train.csv')\ntest_df = import_data('../input/tabular-playground-series-dec-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:03:33.399001Z","iopub.execute_input":"2021-12-09T12:03:33.399317Z","iopub.status.idle":"2021-12-09T12:04:13.510818Z","shell.execute_reply.started":"2021-12-09T12:03:33.399281Z","shell.execute_reply":"2021-12-09T12:04:13.51009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:13.511963Z","iopub.execute_input":"2021-12-09T12:04:13.512792Z","iopub.status.idle":"2021-12-09T12:04:13.539531Z","shell.execute_reply.started":"2021-12-09T12:04:13.512753Z","shell.execute_reply":"2021-12-09T12:04:13.53888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()\nprint(\" \")\ntrain_df.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:13.540771Z","iopub.execute_input":"2021-12-09T12:04:13.541004Z","iopub.status.idle":"2021-12-09T12:04:13.8065Z","shell.execute_reply.started":"2021-12-09T12:04:13.540971Z","shell.execute_reply":"2021-12-09T12:04:13.805706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:13.80796Z","iopub.execute_input":"2021-12-09T12:04:13.80823Z","iopub.status.idle":"2021-12-09T12:04:13.830345Z","shell.execute_reply.started":"2021-12-09T12:04:13.808194Z","shell.execute_reply":"2021-12-09T12:04:13.829759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()\nprint(\" \")\ntest_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:13.831412Z","iopub.execute_input":"2021-12-09T12:04:13.831715Z","iopub.status.idle":"2021-12-09T12:04:13.992249Z","shell.execute_reply.started":"2021-12-09T12:04:13.831672Z","shell.execute_reply":"2021-12-09T12:04:13.991565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.drop(['Id', 'Cover_Type'], axis=1)\ny = train_df.Cover_Type","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:13.993395Z","iopub.execute_input":"2021-12-09T12:04:13.994196Z","iopub.status.idle":"2021-12-09T12:04:14.221096Z","shell.execute_reply.started":"2021-12-09T12:04:13.99415Z","shell.execute_reply":"2021-12-09T12:04:14.220383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(y)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:14.223698Z","iopub.execute_input":"2021-12-09T12:04:14.223955Z","iopub.status.idle":"2021-12-09T12:04:14.230429Z","shell.execute_reply.started":"2021-12-09T12:04:14.22392Z","shell.execute_reply":"2021-12-09T12:04:14.229711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imblearn\nprint(imblearn.__version__)\nfrom imblearn.over_sampling import RandomOverSampler\n\noversample = RandomOverSampler()\nX_over, y_over = oversample.fit_resample(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:14.231776Z","iopub.execute_input":"2021-12-09T12:04:14.232289Z","iopub.status.idle":"2021-12-09T12:04:32.348478Z","shell.execute_reply.started":"2021-12-09T12:04:14.232254Z","shell.execute_reply":"2021-12-09T12:04:32.347681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_over","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:32.349778Z","iopub.execute_input":"2021-12-09T12:04:32.35003Z","iopub.status.idle":"2021-12-09T12:04:34.217127Z","shell.execute_reply.started":"2021-12-09T12:04:32.349996Z","shell.execute_reply":"2021-12-09T12:04:34.21643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_over_2 = y_over - 1 ","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:34.218403Z","iopub.execute_input":"2021-12-09T12:04:34.218802Z","iopub.status.idle":"2021-12-09T12:04:34.227119Z","shell.execute_reply.started":"2021-12-09T12:04:34.218765Z","shell.execute_reply":"2021-12-09T12:04:34.226436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_over_2","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:34.228323Z","iopub.execute_input":"2021-12-09T12:04:34.228967Z","iopub.status.idle":"2021-12-09T12:04:34.236999Z","shell.execute_reply.started":"2021-12-09T12:04:34.228927Z","shell.execute_reply":"2021-12-09T12:04:34.236124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n\nxtrain,xvalid,ytrain,yvalid = train_test_split(X_over,y_over_2,test_size=0.2,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T12:04:34.238803Z","iopub.execute_input":"2021-12-09T12:04:34.23916Z","iopub.status.idle":"2021-12-09T12:04:41.619909Z","shell.execute_reply.started":"2021-12-09T12:04:34.23912Z","shell.execute_reply":"2021-12-09T12:04:41.61906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nfrom optuna.samplers import TPESampler\nfrom hyperopt import STATUS_OK,Trials,fmin,hp,tpe\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom sklearn.metrics import log_loss, accuracy_score, mean_absolute_error, r2_score, roc_auc_score\nfrom optuna.integration import XGBoostPruningCallback\n\ndef objective(trial):\n    \n    params = {\n        \"objective\": trial.suggest_categorical('objective', [\"binary:logistic\"]),\n        \"eval_metric\": trial.suggest_categorical('eval_metric', [\"auc\"]),\n        \"use_label_encoder\": trial.suggest_categorical('use_label_encoder', [False]),\n        \"n_estimators\": trial.suggest_categorical('n_estimators', [40000]),\n        \"learning_rate\": trial.suggest_loguniform('learning_rate', 0.15, 1.0),\n        \"subsample\": trial.suggest_float('subsample', 0.1, 1, step=0.01),\n        \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.05, 1, step=0.01),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 8),\n        \"booster\": trial.suggest_categorical('booster', [\"gbtree\"]),\n        \"gamma\": trial.suggest_float('gamma', 0, 100, step=0.1),\n        \"tree_method\": trial.suggest_categorical('tree_method', [\"gpu_hist\"]),\n        \"reg_lambda\": trial.suggest_loguniform('reg_lambda', 0.1, 100),\n        \"reg_alpha\": trial.suggest_loguniform('reg_alpha', 0.1, 100),\n        \"random_state\": trial.suggest_categorical('random_state', [42]),\n        \"n_jobs\": trial.suggest_categorical('n_jobs', [4]),\n        \"min_child_weight\": trial.suggest_categorical(\"min_child_weight\", [256]),\n            }\n    \n    #opt_params = params\n    #opt_params['n_estimators'] = 80000\n    \n    model = XGBClassifier(**params)\n\n    model.fit(\n        xtrain, \n        ytrain,\n        early_stopping_rounds=100,\n        eval_set=[(xvalid, yvalid)],\n        #eval_metric='auc',\n        verbose=False\n    )\n\n    preds = model.predict_proba(np.float32(xvalid))\n    yhat = preds#[:, 1]\n    return roc_auc_score(yvalid, yhat, multi_class='ovr')\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=100)\nprint(study.best_params)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-09T12:04:41.62208Z","iopub.execute_input":"2021-12-09T12:04:41.622526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best value (RMSE): {:.5f}\".format(study.best_value))\nprint(\"Best params:\")\n\nfor key, value in study.best_params.items():\n    print(\"{}: {}\".format(key, value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}