{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-01T22:02:57.210486Z","iopub.execute_input":"2022-01-01T22:02:57.211415Z","iopub.status.idle":"2022-01-01T22:02:57.24237Z","shell.execute_reply.started":"2022-01-01T22:02:57.211297Z","shell.execute_reply":"2022-01-01T22:02:57.241445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imports\n \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer\nfrom sklearn.metrics import balanced_accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier\n \nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline as pipe_with_sampling\nfrom imblearn.pipeline import make_pipeline\n\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:02:57.244298Z","iopub.execute_input":"2022-01-01T22:02:57.245057Z","iopub.status.idle":"2022-01-01T22:02:58.593301Z","shell.execute_reply.started":"2022-01-01T22:02:57.24502Z","shell.execute_reply":"2022-01-01T22:02:58.592353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# downcasting\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\ntrain = pd.read_csv('../input/tabular-playground-series-dec-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv')\n\ntrain, test = reduce_mem_usage(train), reduce_mem_usage(test)\n\n# drop zero-variance features and id\ntrain.drop(columns=['Id', 'Soil_Type7', 'Soil_Type15'], inplace=True)\ntest.drop(columns=['Id', 'Soil_Type7', 'Soil_Type15'], inplace=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:02:58.594655Z","iopub.execute_input":"2022-01-01T22:02:58.594898Z","iopub.status.idle":"2022-01-01T22:03:41.189473Z","shell.execute_reply.started":"2022-01-01T22:02:58.594867Z","shell.execute_reply":"2022-01-01T22:03:41.18864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Aspect_ind'] = train['Aspect'].apply(lambda x: int(x < 0))\ntrain['Aspect'] = np.abs(train['Aspect'])\ntrain['Slope_ind'] = train['Slope'].apply(lambda x: int(x < 0))\ntrain['Aspect'] = np.abs(train['Aspect'])\n\ntrain['Hillshade_9am_ind'] = train['Hillshade_9am'].apply(lambda x: int(x < 0))\ntrain['Aspect'] = np.abs(train['Aspect'])\n\ntrain['Hillshade_Noon_ind'] = train['Hillshade_Noon'].apply(lambda x: int(x < 0))\ntrain['Aspect'] = np.abs(train['Aspect'])\n\ntrain['Hillshade_3pm_ind'] = train['Hillshade_3pm'].apply(lambda x: int(x < 0))\ntrain['Aspect'] = np.abs(train['Aspect'])\n\n\ntest['Aspect_ind'] = test['Aspect'].apply(lambda x: int(x < 0))\ntest['Aspect'] = np.abs(test['Aspect'])\ntest['Slope_ind'] = test['Slope'].apply(lambda x: int(x < 0))\ntest['Aspect'] = np.abs(test['Aspect'])\n\ntest['Hillshade_9am_ind'] = test['Hillshade_9am'].apply(lambda x: int(x < 0))\ntest['Aspect'] = np.abs(test['Aspect'])\n\ntest['Hillshade_Noon_ind'] = test['Hillshade_Noon'].apply(lambda x: int(x < 0))\ntest['Aspect'] = np.abs(test['Aspect'])\n\ntest['Hillshade_3pm_ind'] = test['Hillshade_3pm'].apply(lambda x: int(x < 0))\ntest['Aspect'] = np.abs(test['Aspect'])\n\n\ntrain['dist_to_hydro'] = np.abs(train['Horizontal_Distance_To_Hydrology']) + np.abs(train['Vertical_Distance_To_Hydrology'])\ntest['dist_to_hydro'] = np.abs(test['Horizontal_Distance_To_Hydrology']) + np.abs(test['Vertical_Distance_To_Hydrology'])","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:03:41.191406Z","iopub.execute_input":"2022-01-01T22:03:41.191655Z","iopub.status.idle":"2022-01-01T22:03:58.877654Z","shell.execute_reply.started":"2022-01-01T22:03:41.191624Z","shell.execute_reply":"2022-01-01T22:03:58.876729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sum_soil_types(df):\n    soil_cols = [col for col in df.columns if col.startswith('Soil_T')] \n    df['sum_soil_type'] = df.loc[:, soil_cols].sum(axis=1)\n    return df\n\ndef summary_stats_features(df):\n    df[\"mean\"] = df.loc[:, df.columns].mean(axis = 1)\n    df[\"min\"] = df.loc[:, df.columns].min(axis = 1)\n    df[\"max\"] = df.loc[:, df.columns].max(axis = 1)\n    \n    return df\n    \nss_types = FunctionTransformer(sum_soil_types)\nss_features = FunctionTransformer(summary_stats_features)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:03:58.87908Z","iopub.execute_input":"2022-01-01T22:03:58.8793Z","iopub.status.idle":"2022-01-01T22:03:58.88721Z","shell.execute_reply.started":"2022-01-01T22:03:58.879273Z","shell.execute_reply":"2022-01-01T22:03:58.886246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = train.loc[:, train.columns != 'Cover_Type'], train.Cover_Type\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3) ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:03:58.88856Z","iopub.execute_input":"2022-01-01T22:03:58.888771Z","iopub.status.idle":"2022-01-01T22:04:01.024058Z","shell.execute_reply.started":"2022-01-01T22:03:58.888745Z","shell.execute_reply":"2022-01-01T22:04:01.023217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n\nclf = make_pipeline(ss_types, ss_features, StandardScaler(), RandomOverSampler(), RandomUnderSampler(), classifier)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:04:01.025427Z","iopub.execute_input":"2022-01-01T22:04:01.026324Z","iopub.status.idle":"2022-01-01T22:04:01.032278Z","shell.execute_reply.started":"2022-01-01T22:04:01.026265Z","shell.execute_reply":"2022-01-01T22:04:01.031425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(x_train, y_train)\ny_pred = clf.predict(x_test)\nacc = balanced_accuracy_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred, average='weighted')\n\nprint(f'Acc: {acc :.3f}\\nF1 : {f1: .3f}')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:04:01.035307Z","iopub.execute_input":"2022-01-01T22:04:01.036019Z","iopub.status.idle":"2022-01-01T22:38:39.296319Z","shell.execute_reply.started":"2022-01-01T22:04:01.035979Z","shell.execute_reply":"2022-01-01T22:38:39.294775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submit(model):\n    y_hat = clf.predict(test)\n    sub = pd.read_csv('../input/tabular-playground-series-dec-2021/sample_submission.csv')\n    sub['Cover_Type'] = y_hat\n    sub.to_csv('submission.csv', index=False)\n    \nsubmit(clf)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T22:38:39.299029Z","iopub.execute_input":"2022-01-01T22:38:39.299414Z","iopub.status.idle":"2022-01-01T22:39:01.171488Z","shell.execute_reply.started":"2022-01-01T22:38:39.299382Z","shell.execute_reply":"2022-01-01T22:39:01.170622Z"},"trusted":true},"execution_count":null,"outputs":[]}]}