{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import plot_model\nfrom warnings import filterwarnings\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.preprocessing import QuantileTransformer, LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfilterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:27:56.220895Z","iopub.execute_input":"2021-12-26T23:27:56.221375Z","iopub.status.idle":"2021-12-26T23:28:01.838944Z","shell.execute_reply.started":"2021-12-26T23:27:56.221347Z","shell.execute_reply":"2021-12-26T23:28:01.837973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Flatten, Input, Concatenate, Dropout\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:01.842246Z","iopub.execute_input":"2021-12-26T23:28:01.843409Z","iopub.status.idle":"2021-12-26T23:28:02.122884Z","shell.execute_reply.started":"2021-12-26T23:28:01.84337Z","shell.execute_reply":"2021-12-26T23:28:02.122158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_keras_history(history, measures):\n    \"\"\"\n    history: Keras training history\n    measures = list of names of measures\n    \"\"\"\n    rows = len(measures) // 2 + len(measures) % 2\n    fig, panels = plt.subplots(rows, 2, figsize=(15, 5))\n    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.4, wspace=0.2)\n    try:\n        panels = [item for sublist in panels for item in sublist]\n    except:\n        pass\n    for k, measure in enumerate(measures):\n        panel = panels[k]\n        panel.set_title(measure + ' history')\n        panel.plot(history.epoch, history.history[measure], label=\"Train \"+measure)\n        panel.plot(history.epoch, history.history[\"val_\"+measure], label=\"Validation \"+measure)\n        panel.set(xlabel='epochs', ylabel=measure)\n        panel.legend()\n        \n    plt.show(fig)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:02.124037Z","iopub.execute_input":"2021-12-26T23:28:02.124306Z","iopub.status.idle":"2021-12-26T23:28:02.132717Z","shell.execute_reply.started":"2021-12-26T23:28:02.124252Z","shell.execute_reply":"2021-12-26T23:28:02.131813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:02.135135Z","iopub.execute_input":"2021-12-26T23:28:02.135659Z","iopub.status.idle":"2021-12-26T23:28:02.148699Z","shell.execute_reply.started":"2021-12-26T23:28:02.135623Z","shell.execute_reply":"2021-12-26T23:28:02.148007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-dec-2021/test.csv\")\nsubmission = pd.read_csv(\"../input/tabular-playground-series-dec-2021/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:02.14989Z","iopub.execute_input":"2021-12-26T23:28:02.150663Z","iopub.status.idle":"2021-12-26T23:28:22.186312Z","shell.execute_reply.started":"2021-12-26T23:28:02.150626Z","shell.execute_reply":"2021-12-26T23:28:22.185559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source: https://www.kaggle.com/remekkinas/tps-12-nn-tpu-pseudolabeling-0-95661\npseudolabels = pd.read_csv(\"../input/tps12-pseudolabels/tps12-pseudolabels_v2.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:22.187456Z","iopub.execute_input":"2021-12-26T23:28:22.187713Z","iopub.status.idle":"2021-12-26T23:28:26.528706Z","shell.execute_reply.started":"2021-12-26T23:28:22.187679Z","shell.execute_reply":"2021-12-26T23:28:26.527977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The target class distribution:\")\nprint((train.groupby('Cover_Type').Id.nunique() / len(train)).apply(lambda p: f\"{p:.3%}\"))","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:26.529983Z","iopub.execute_input":"2021-12-26T23:28:26.530238Z","iopub.status.idle":"2021-12-26T23:28:26.988234Z","shell.execute_reply.started":"2021-12-26T23:28:26.530205Z","shell.execute_reply":"2021-12-26T23:28:26.987503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Droping Cover_Type 5 label, since there is only one instance of it\ntrain = train[train.Cover_Type != 5]","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:26.989624Z","iopub.execute_input":"2021-12-26T23:28:26.989883Z","iopub.status.idle":"2021-12-26T23:28:27.710137Z","shell.execute_reply.started":"2021-12-26T23:28:26.989838Z","shell.execute_reply":"2021-12-26T23:28:27.709412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove unuseful features\ntrain = train.drop([ 'Soil_Type7', 'Soil_Type15'], axis=1)\npseudolabels = pseudolabels.drop([ 'Soil_Type7', 'Soil_Type15'], axis=1)\ntest = test.drop(['Soil_Type7', 'Soil_Type15'], axis=1)\n\n# extra feature engineering\ndef r(x):\n    if x+180>360:\n        return x-180\n    else:\n        return x+180\n    \n\ndef fe(df):\n    df['EHiElv'] = df['Horizontal_Distance_To_Roadways'] * df['Elevation']\n    df['EViElv'] = df['Vertical_Distance_To_Hydrology'] * df['Elevation']\n    df['Aspect2'] = df.Aspect.map(r)\n    ### source: https://www.kaggle.com/c/tabular-playground-series-dec-2021/discussion/293373\n    df[\"Aspect\"][df[\"Aspect\"] < 0] += 360\n    df[\"Aspect\"][df[\"Aspect\"] > 359] -= 360\n    df.loc[df[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n    df.loc[df[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n    df.loc[df[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n    df.loc[df[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n    df.loc[df[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n    df.loc[df[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\n    ########\n    df['Highwater'] = (df.Vertical_Distance_To_Hydrology < 0).astype(int)\n    df['EVDtH'] = df.Elevation - df.Vertical_Distance_To_Hydrology\n    df['EHDtH'] = df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2\n    df['Euclidean_Distance_to_Hydrolody'] = (df['Horizontal_Distance_To_Hydrology']**2 + df['Vertical_Distance_To_Hydrology']**2)**0.5\n    df['Manhattan_Distance_to_Hydrolody'] = df['Horizontal_Distance_To_Hydrology'] + df['Vertical_Distance_To_Hydrology']\n    df['Hydro_Fire_1'] = df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points']\n    df['Hydro_Fire_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\n    df['Hydro_Road_1'] = abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\n    df['Hydro_Road_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\n    df['Fire_Road_1'] = abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\n    df['Fire_Road_2'] = abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])\n    df['Hillshade_3pm_is_zero'] = (df.Hillshade_3pm == 0).astype(int)\n    return df\n\ntrain = fe(train)\ntest = fe(test)\npseudolabels = fe(pseudolabels)\n\n# Summed features pointed out by @craigmthomas (https://www.kaggle.com/c/tabular-playground-series-dec-2021/discussion/292823)\nsoil_features = [x for x in train.columns if x.startswith(\"Soil_Type\")]\nwilderness_features = [x for x in train.columns if x.startswith(\"Wilderness_Area\")]\n\ntrain[\"soil_type_count\"] = train[soil_features].sum(axis=1)\npseudolabels[\"soil_type_count\"] = pseudolabels[soil_features].sum(axis=1)\ntest[\"soil_type_count\"] = test[soil_features].sum(axis=1)\n\ntrain[\"wilderness_area_count\"] = train[wilderness_features].sum(axis=1)\npseudolabels[\"wilderness_area_count\"] = pseudolabels[wilderness_features].sum(axis=1)\ntest[\"wilderness_area_count\"] = test[wilderness_features].sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:27.712382Z","iopub.execute_input":"2021-12-26T23:28:27.712878Z","iopub.status.idle":"2021-12-26T23:28:38.793544Z","shell.execute_reply.started":"2021-12-26T23:28:27.712838Z","shell.execute_reply":"2021-12-26T23:28:38.792817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = reduce_mem_usage(train)\npseudolabels = reduce_mem_usage(pseudolabels)\noriginal_len = len(train)\ntrain = pd.concat([train, pseudolabels], axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:28:38.795824Z","iopub.execute_input":"2021-12-26T23:28:38.796091Z","iopub.status.idle":"2021-12-26T23:29:11.109082Z","shell.execute_reply.started":"2021-12-26T23:28:38.796056Z","shell.execute_reply":"2021-12-26T23:29:11.107463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train.Cover_Type.values - 1\nX = train.drop(\"Cover_Type\", axis=1).set_index(\"Id\").values.astype(np.float32)\nXt = test.set_index(\"Id\").values.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:29:11.110487Z","iopub.execute_input":"2021-12-26T23:29:11.110737Z","iopub.status.idle":"2021-12-26T23:29:14.229051Z","shell.execute_reply.started":"2021-12-26T23:29:11.110704Z","shell.execute_reply":"2021-12-26T23:29:14.228313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel([train, test, pseudolabels])\n_ = [gc.collect() for i in range(5)]","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:29:14.230408Z","iopub.execute_input":"2021-12-26T23:29:14.231096Z","iopub.status.idle":"2021-12-26T23:29:14.888616Z","shell.execute_reply.started":"2021-12-26T23:29:14.231056Z","shell.execute_reply":"2021-12-26T23:29:14.887873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\ntarget = le.fit_transform(y)\n\n_, classes_num = np.unique(target, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:29:14.889696Z","iopub.execute_input":"2021-12-26T23:29:14.889945Z","iopub.status.idle":"2021-12-26T23:29:15.18079Z","shell.execute_reply.started":"2021-12-26T23:29:14.889912Z","shell.execute_reply":"2021-12-26T23:29:15.18006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"public_poteriors = {0:1.05, 1:0.91, 2:1.60, 3:3.61, 4:0.00, 5:2.45, 6:1.04}\nclass_weight = {k:public_poteriors[j] for k, j in enumerate(le.classes_)}","metadata":{"execution":{"iopub.status.busy":"2021-12-26T23:29:15.1819Z","iopub.execute_input":"2021-12-26T23:29:15.182216Z","iopub.status.idle":"2021-12-26T23:29:15.188299Z","shell.execute_reply.started":"2021-12-26T23:29:15.182172Z","shell.execute_reply":"2021-12-26T23:29:15.18747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### create baseline-model\ndef get_model(layers=[8], targets=7, dropout_rate=0.0, skip_layers=True, \n              batchnorm=True, activation='selu', kernel_initializer=\"lecun_normal\"):\n    \n    if activation=='selu':\n        dropout_function = tf.keras.layers.AlphaDropout\n        kernel_initializer = \"lecun_normal\"\n    else:\n        dropout_function = Dropout\n    \n    inputs_sequence = Input(shape=(X.shape[1]))\n    x = Flatten()(inputs_sequence)\n\n    skips = list()\n    for layer, nodes in enumerate(layers):\n        x = Dense(nodes, kernel_initializer=kernel_initializer, activation=activation)(x)\n        if batchnorm is True:\n            x = BatchNormalization()(x)\n        if layer != (len(layers) - 1):\n            if dropout_rate > 0:\n                x = dropout_function(rate=dropout_rate)(x)\n            skips.append(x)\n    \n    if skip_layers is True:\n        x = Concatenate(axis=1)([x, inputs_sequence] + skips)\n    else:\n        del(skips)\n        \n    output_class = Dense(targets, activation='softmax', \n                         kernel_regularizer=tf.keras.regularizers.l2(l2=0.03))(x)\n\n    model = Model(inputs=inputs_sequence, outputs=output_class)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:51:11.748328Z","iopub.execute_input":"2021-12-16T16:51:11.749283Z","iopub.status.idle":"2021-12-16T16:51:11.759976Z","shell.execute_reply.started":"2021-12-16T16:51:11.749225Z","shell.execute_reply":"2021-12-16T16:51:11.759181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dnn_params = {'layers': [256, 128, 64, 32],\n              'batchnorm': False, \n              'skip_layers': True, \n              'dropout_rate': 0.0,\n              'activation': 'selu',\n              'targets': len(le.classes_)}\n\nmodel = get_model(**dnn_params)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:51:11.761396Z","iopub.execute_input":"2021-12-16T16:51:11.761952Z","iopub.status.idle":"2021-12-16T16:51:13.977546Z","shell.execute_reply.started":"2021-12-16T16:51:11.761913Z","shell.execute_reply":"2021-12-16T16:51:13.976834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(\n    model, \n    to_file='baseline.png', \n    show_shapes=True,\n    show_layer_names=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:51:13.97901Z","iopub.execute_input":"2021-12-16T16:51:13.979545Z","iopub.status.idle":"2021-12-16T16:51:14.884447Z","shell.execute_reply.started":"2021-12-16T16:51:13.979506Z","shell.execute_reply":"2021-12-16T16:51:14.883573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # detect and init the TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    # instantiate a distribution strategy\n    tf_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print(\"Running on TPU:\", tpu.master())\nexcept:\n    tf_strategy = tf.distribute.get_strategy()\n    print(f\"Running on {tf_strategy.num_replicas_in_sync} replicas\")\n    print(\"Number of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:51:14.885731Z","iopub.execute_input":"2021-12-16T16:51:14.886641Z","iopub.status.idle":"2021-12-16T16:51:14.896971Z","shell.execute_reply.started":"2021-12-16T16:51:14.886602Z","shell.execute_reply":"2021-12-16T16:51:14.896289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n### define callbacks\nearly_stopping = EarlyStopping(\n    monitor='val_acc', \n    min_delta=0, \n    patience=10, \n    verbose=0,\n    mode='max', \n    baseline=None, \n    restore_best_weights=True\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_acc', \n    factor=0.5,\n    patience=5,\n    mode='max'\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:51:14.898028Z","iopub.execute_input":"2021-12-16T16:51:14.898275Z","iopub.status.idle":"2021-12-16T16:51:14.910823Z","shell.execute_reply.started":"2021-12-16T16:51:14.898241Z","shell.execute_reply":"2021-12-16T16:51:14.910086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_FOLDS = 20\n\n### cross-validation \ncv = KFold(n_splits=N_FOLDS, shuffle=True, random_state=1)\n\npredictions = np.zeros((len(Xt), len(le.classes_)))\noof = np.zeros((original_len, len(le.classes_)))\nscores = list()\n\nwith tf_strategy.scope():\n    for fold, (idx_train, idx_valid) in enumerate(cv.split(X, y)):\n        \n        idx_valid = idx_valid[idx_valid<original_len]\n        X_train, y_train = X[idx_train, :], target[idx_train]\n        X_valid, y_valid = X[idx_valid, :], target[idx_valid]\n        \n        ss = RobustScaler()\n        X_train = ss.fit_transform(X_train)\n        X_valid = ss.transform(X_valid)\n\n        model = get_model(**dnn_params)\n        \n        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)    \n    \n        model.compile(\n            optimizer=optimizer,\n            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n            metrics=['acc']\n        )\n\n        print('**'*20)\n        print(f\"Fold {fold+1} || Training\")\n        print('**'*20)\n\n        history = model.fit(\n            X_train, y_train,\n            validation_data=(X_valid, y_valid),\n            batch_size=1024*2,\n            epochs=150,\n            verbose=1,\n            shuffle=True,\n            class_weight=class_weight,\n            callbacks=[\n                early_stopping,\n                reduce_lr\n            ]\n        )\n        \n        plot_keras_history(history, ['loss', 'acc'])\n        \n        print(f\"Best training accuracy: {np.max(history.history['acc']):0.5f}\")\n        print(f\"Best validation accuracy: {np.max(history.history['val_acc']):0.5f}\")\n        scores.append(np.max(history.history['val_acc']))\n\n        oof[idx_valid] = model.predict(X_valid, batch_size=4096) \n\n        predictions += model.predict(ss.transform(Xt), batch_size=4096)\n        \n        del([X_train, y_train, X_valid, y_valid])\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T16:51:14.912496Z","iopub.execute_input":"2021-12-16T16:51:14.912793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Average cv accuracy: {np.mean(scores):0.5f} (std={np.std(scores):0.5f})\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.Cover_Type = le.inverse_transform(np.argmax(predictions, axis=1)) + 1\nsubmission.Cover_Type[submission.Cover_Type == 4] = 3\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = pd.DataFrame(oof, columns=[f\"prob_{i}\" for i in le.classes_])\noof.insert(loc=0, column='Id', value=range(len(oof)))\noof.to_csv(\"oof.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}