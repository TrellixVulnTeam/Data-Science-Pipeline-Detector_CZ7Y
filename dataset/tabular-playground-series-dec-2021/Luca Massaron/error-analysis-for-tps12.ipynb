{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Let's compare how pseudo-labelling augments the performances of the a DNN model by using error analysis. By comparing errors on out-of-fold predictions you can have a clearer idea of what happens.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-12T15:59:17.440082Z","iopub.execute_input":"2021-12-12T15:59:17.44042Z","iopub.status.idle":"2021-12-12T15:59:18.612201Z","shell.execute_reply.started":"2021-12-12T15:59:17.440332Z","shell.execute_reply":"2021-12-12T15:59:18.611242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\")\noof_woda = pd.read_csv(\"../input/tfkeras-dnn-without-augmentation/oof.csv\")\noof_wda = pd.read_csv(\"../input/tfkeras-dnn-with-augmentation/oof.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T15:59:55.283755Z","iopub.execute_input":"2021-12-12T15:59:55.284406Z","iopub.status.idle":"2021-12-12T16:00:34.01562Z","shell.execute_reply.started":"2021-12-12T15:59:55.284365Z","shell.execute_reply":"2021-12-12T16:00:34.01444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[train.Cover_Type != 5]","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:00:34.017313Z","iopub.execute_input":"2021-12-12T16:00:34.017663Z","iopub.status.idle":"2021-12-12T16:00:34.95Z","shell.execute_reply.started":"2021-12-12T16:00:34.017627Z","shell.execute_reply":"2021-12-12T16:00:34.948998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = {0:0, 1:1, 2:2, 3:4, 4:5, 5:6}\noof_woda = np.array([mapping[i] for i in np.argmax(oof_woda[['prob_0', 'prob_1', 'prob_2', 'prob_3', 'prob_5', 'prob_6']].values, axis=1)])\noof_woda = oof_woda + 1\noof_wda = np.array([mapping[i] for i in np.argmax(oof_wda[['prob_0', 'prob_1', 'prob_2', 'prob_3', 'prob_5', 'prob_6']].values, axis=1)])\noof_wda = oof_wda + 1","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:00:34.951425Z","iopub.execute_input":"2021-12-12T16:00:34.951768Z","iopub.status.idle":"2021-12-12T16:00:42.764264Z","shell.execute_reply.started":"2021-12-12T16:00:34.951724Z","shell.execute_reply":"2021-12-12T16:00:42.76336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(train.Cover_Type, oof_woda, labels=np.unique(train.Cover_Type))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=np.unique(train.Cover_Type))\n\nfig, ax = plt.subplots(figsize=(13, 13))\n\ndisp.plot(ax=ax, values_format='d')\n\nfor labels in disp.text_.ravel():\n    labels.set_fontsize(12)\n    \nplt.show()\n\naccuracy = np.sum(train.Cover_Type == oof_woda) / len(oof_woda)\nprint(f\"oof accuracy without pseudo-labelling: {accuracy:0.5f}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:00:42.766277Z","iopub.execute_input":"2021-12-12T16:00:42.766762Z","iopub.status.idle":"2021-12-12T16:00:48.805012Z","shell.execute_reply.started":"2021-12-12T16:00:42.766718Z","shell.execute_reply":"2021-12-12T16:00:48.803932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(train.Cover_Type, oof_wda, labels=np.unique(train.Cover_Type))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=np.unique(train.Cover_Type))\n\nfig, ax = plt.subplots(figsize=(13, 13))\n\ndisp.plot(ax=ax, values_format='d')\n\nfor labels in disp.text_.ravel():\n    labels.set_fontsize(12)\n    \nplt.show()\n\naccuracy = np.sum(train.Cover_Type == oof_wda) / len(oof_wda)\nprint(f\"oof accuracy with pseudo-labelling: {accuracy:0.5f}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:00:48.806361Z","iopub.execute_input":"2021-12-12T16:00:48.806601Z","iopub.status.idle":"2021-12-12T16:00:54.814386Z","shell.execute_reply.started":"2021-12-12T16:00:48.806574Z","shell.execute_reply":"2021-12-12T16:00:54.813483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using pseudo-labels seems to improve performances at oof level. How are these extra performances achieved? ","metadata":{}},{"cell_type":"code","source":"cm_wda = confusion_matrix(train.Cover_Type, oof_wda, labels=np.unique(train.Cover_Type))\ncm_woda = confusion_matrix(train.Cover_Type, oof_woda, labels=np.unique(train.Cover_Type))\n\ncm = cm_wda - cm_woda\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=np.unique(train.Cover_Type))\n\nfig, ax = plt.subplots(figsize=(13, 13))\n\ndisp.plot(ax=ax, values_format='d')\n\nfor labels in disp.text_.ravel():\n    labels.set_fontsize(12)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:00:54.81562Z","iopub.execute_input":"2021-12-12T16:00:54.815825Z","iopub.status.idle":"2021-12-12T16:01:06.50566Z","shell.execute_reply.started":"2021-12-12T16:00:54.815799Z","shell.execute_reply":"2021-12-12T16:01:06.504789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}