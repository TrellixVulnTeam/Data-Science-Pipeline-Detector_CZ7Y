{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-31T18:06:05.886681Z","iopub.execute_input":"2021-12-31T18:06:05.887595Z","iopub.status.idle":"2021-12-31T18:06:05.920218Z","shell.execute_reply.started":"2021-12-31T18:06:05.88747Z","shell.execute_reply":"2021-12-31T18:06:05.919558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read datasets to pandas dataframe\ndf_train = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/test.csv')\ndf_sample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:06:12.727833Z","iopub.execute_input":"2021-12-31T18:06:12.728439Z","iopub.status.idle":"2021-12-31T18:06:36.034865Z","shell.execute_reply.started":"2021-12-31T18:06:12.728313Z","shell.execute_reply":"2021-12-31T18:06:36.03403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking out df_train\ndf_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:06:46.927121Z","iopub.execute_input":"2021-12-31T18:06:46.92744Z","iopub.status.idle":"2021-12-31T18:06:52.179195Z","shell.execute_reply.started":"2021-12-31T18:06:46.927408Z","shell.execute_reply":"2021-12-31T18:06:52.178318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets see if we have any missing values\nmissing_values_train = df_train.isna().any().sum()\nmissing_values_test = df_test.isna().any().sum()\nprint(f'There are {missing_values_train} missing values in the train dataset')\nprint(f'There are {missing_values_test} missing values in the test dataset')","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:06:52.180741Z","iopub.execute_input":"2021-12-31T18:06:52.181215Z","iopub.status.idle":"2021-12-31T18:06:52.252073Z","shell.execute_reply.started":"2021-12-31T18:06:52.181178Z","shell.execute_reply":"2021-12-31T18:06:52.251195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets see which features are the most correlated with target\ndf_train.corr()['Cover_Type'].sort_values()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:06:52.253131Z","iopub.execute_input":"2021-12-31T18:06:52.253368Z","iopub.status.idle":"2021-12-31T18:07:28.538774Z","shell.execute_reply.started":"2021-12-31T18:06:52.253338Z","shell.execute_reply":"2021-12-31T18:07:28.538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets establish a baseline if we just always predict the target's most common class\n# AKA: null accuracy\ndf_train['Cover_Type'].value_counts(normalize=True).head(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:07:28.540859Z","iopub.execute_input":"2021-12-31T18:07:28.541444Z","iopub.status.idle":"2021-12-31T18:07:28.570767Z","shell.execute_reply.started":"2021-12-31T18:07:28.541401Z","shell.execute_reply":"2021-12-31T18:07:28.569949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# How imbalanced are the class distrubutions in our target variable?\ndf_train.groupby('Cover_Type').size()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:07:28.572177Z","iopub.execute_input":"2021-12-31T18:07:28.572483Z","iopub.status.idle":"2021-12-31T18:07:28.646935Z","shell.execute_reply.started":"2021-12-31T18:07:28.572444Z","shell.execute_reply":"2021-12-31T18:07:28.646135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train[df_train['Cover_Type']!=5]","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:07:28.648132Z","iopub.execute_input":"2021-12-31T18:07:28.648572Z","iopub.status.idle":"2021-12-31T18:07:29.438856Z","shell.execute_reply.started":"2021-12-31T18:07:28.648537Z","shell.execute_reply":"2021-12-31T18:07:29.437895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"train=df_train\ntest=df_test","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:07:55.560351Z","iopub.execute_input":"2021-12-31T18:07:55.560671Z","iopub.status.idle":"2021-12-31T18:07:55.565841Z","shell.execute_reply.started":"2021-12-31T18:07:55.560637Z","shell.execute_reply":"2021-12-31T18:07:55.564921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get train data without the target and ids\nX = train.iloc[:, 1:-1].copy()\n# Get the target\ny = train.Cover_Type.copy()\n\n# Create test X, drop ids.\ntest_X = test.iloc[:, 1:].copy()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:08:02.04296Z","iopub.execute_input":"2021-12-31T18:08:02.04353Z","iopub.status.idle":"2021-12-31T18:08:03.046603Z","shell.execute_reply.started":"2021-12-31T18:08:02.043491Z","shell.execute_reply":"2021-12-31T18:08:03.045573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_validate, Y_train, Y_validate = train_test_split( X, y, test_size=0.2, random_state=2)\nprint ('Train set:', X_train.shape,  Y_train.shape)\nprint ('Validation set:', X_validate.shape,  Y_validate.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:08:09.296305Z","iopub.execute_input":"2021-12-31T18:08:09.296609Z","iopub.status.idle":"2021-12-31T18:08:14.14047Z","shell.execute_reply.started":"2021-12-31T18:08:09.296573Z","shell.execute_reply":"2021-12-31T18:08:14.139665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2021-12-31T18:08:15.855252Z","iopub.execute_input":"2021-12-31T18:08:15.855823Z","iopub.status.idle":"2021-12-31T18:08:16.218641Z","shell.execute_reply.started":"2021-12-31T18:08:15.855775Z","shell.execute_reply":"2021-12-31T18:08:16.217623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"## LGBM","metadata":{}},{"cell_type":"code","source":"# Create LightGBM model\nfrom lightgbm import LGBMClassifier\n\nlgb_params = {\n    'objective' : 'multiclass',\n    'metric' : 'multi_logloss',\n    'device' : 'gpu',\n}\n\nlgbmmodel = LGBMClassifier(**lgb_params) \n\nlgbmmodel.fit(X_train,Y_train,\n               early_stopping_rounds=200,\n               eval_set=[(X_validate,Y_validate)],\n               verbose=True)\n\n# R^2 for training data\nlgbmmodel.score(X_train,Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View sample submission\ndf_sample_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename df and replace the cover type column with our predictions\ndf_lgbm_submission = df_sample_submission\ndf_lgbm_submission['Cover_Type'] = lgbmmodel.predict(test_X).astype('int')\ndf_lgbm_submission.to_csv(\"submission.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]}]}