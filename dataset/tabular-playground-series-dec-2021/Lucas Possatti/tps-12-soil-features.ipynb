{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction","metadata":{}},{"cell_type":"markdown","source":"As I was browsing the data description of the Forest Cover Type Competition (https://www.kaggle.com/c/forest-cover-type-prediction/data), I noticed it had some details on the characteristics and families of the soil types. And doing [my EDA](https://www.kaggle.com/possatti/tps-12-eda) I wondered if those details could be used as features to improve model performance.\n\nOn this notebook I give it a try. I coded how these features can be generated, and experimented with a Random Forest model.","metadata":{}},{"cell_type":"markdown","source":"## Description of soil properties\n\nFrom https://www.kaggle.com/c/forest-cover-type-prediction/data: \n\n> - 1 Cathedral family - Rock outcrop complex, extremely stony.\n> - 2 Vanet - Ratake families complex, very stony.\n> - 3 Haploborolis - Rock outcrop complex, rubbly.\n> - 4 Ratake family - Rock outcrop complex, rubbly.\n> - 5 Vanet family - Rock outcrop complex complex, rubbly.\n> - 6 Vanet - Wetmore families - Rock outcrop complex, stony.\n> - 7 Gothic family.\n> - 8 Supervisor - Limber families complex.\n> - 9 Troutville family, very stony.\n> - 10 Bullwark - Catamount families - Rock outcrop complex, rubbly.\n> - 11 Bullwark - Catamount families - Rock land complex, rubbly.\n> - 12 Legault family - Rock land complex, stony.\n> - 13 Catamount family - Rock land - Bullwark family complex, rubbly.\n> - 14 Pachic Argiborolis - Aquolis complex.\n> - 15 unspecified in the USFS Soil and ELU Survey.\n> - 16 Cryaquolis - Cryoborolis complex.\n> - 17 Gateview family - Cryaquolis complex.\n> - 18 Rogert family, very stony.\n> - 19 Typic Cryaquolis - Borohemists complex.\n> - 20 Typic Cryaquepts - Typic Cryaquolls complex.\n> - 21 Typic Cryaquolls - Leighcan family, till substratum complex.\n> - 22 Leighcan family, till substratum, extremely bouldery.\n> - 23 Leighcan family, till substratum - Typic Cryaquolls complex.\n> - 24 Leighcan family, extremely stony.\n> - 25 Leighcan family, warm, extremely stony.\n> - 26 Granile - Catamount families complex, very stony.\n> - 27 Leighcan family, warm - Rock outcrop complex, extremely stony.\n> - 28 Leighcan family - Rock outcrop complex, extremely stony.\n> - 29 Como - Legault families complex, extremely stony.\n> - 30 Como family - Rock land - Legault family complex, extremely stony.\n> - 31 Leighcan - Catamount families complex, extremely stony.\n> - 32 Catamount family - Rock outcrop - Leighcan family complex, extremely stony.\n> - 33 Leighcan - Catamount families - Rock outcrop complex, extremely stony.\n> - 34 Cryorthents - Rock land complex, extremely stony.\n> - 35 Cryumbrepts - Rock outcrop - Cryaquepts complex.\n> - 36 Bross family - Rock land - Cryumbrepts complex, extremely stony.\n> - 37 Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.\n> - 38 Leighcan - Moran families - Cryaquolls complex, extremely stony.\n> - 39 Moran family - Cryorthents - Leighcan family complex, extremely stony.\n> - 40 Moran family - Cryorthents - Rock land complex, extremely stony.","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:47:04.601827Z","iopub.execute_input":"2021-12-15T01:47:04.602198Z","iopub.status.idle":"2021-12-15T01:47:04.642317Z","shell.execute_reply.started":"2021-12-15T01:47:04.602107Z","shell.execute_reply":"2021-12-15T01:47:04.641338Z"}}},{"cell_type":"markdown","source":"## Preparation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nfrom scipy.stats import uniform, randint, mode\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nsns.set()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-15T01:49:18.072808Z","iopub.execute_input":"2021-12-15T01:49:18.073089Z","iopub.status.idle":"2021-12-15T01:49:19.576597Z","shell.execute_reply.started":"2021-12-15T01:49:18.073059Z","shell.execute_reply":"2021-12-15T01:49:19.575617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (16, 4)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:49:19.57891Z","iopub.execute_input":"2021-12-15T01:49:19.57923Z","iopub.status.idle":"2021-12-15T01:49:19.584871Z","shell.execute_reply.started":"2021-12-15T01:49:19.579187Z","shell.execute_reply":"2021-12-15T01:49:19.583907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data","metadata":{}},{"cell_type":"code","source":"soil_type_vars = [f'Soil_Type{i}' for i in range(1, 41)]\nwilderness_area_vars = [f'Wilderness_Area{i}' for i in range(1, 5)]\nbinary_vars = soil_type_vars + wilderness_area_vars\nnumerical_vars = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\nfeatures = numerical_vars + binary_vars\ntarget = 'Cover_Type'","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:49:19.586747Z","iopub.execute_input":"2021-12-15T01:49:19.587057Z","iopub.status.idle":"2021-12-15T01:49:19.601515Z","shell.execute_reply.started":"2021-12-15T01:49:19.587018Z","shell.execute_reply":"2021-12-15T01:49:19.600215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtypes = {\n    'Id': np.int32,\n    'Elevation': np.int16,\n    'Aspect': np.int16,\n    'Slope': np.int8,\n    'Horizontal_Distance_To_Hydrology': np.int16,\n    'Vertical_Distance_To_Hydrology': np.int16,\n    'Horizontal_Distance_To_Roadways': np.int16,\n    'Hillshade_9am': np.int16,\n    'Hillshade_Noon': np.int16,\n    'Hillshade_3pm': np.int16,\n    'Horizontal_Distance_To_Fire_Points': np.int16,\n    'Cover_Type': np.int8,\n}\nbinary_vars_dtypes = {c: np.int8 for c in binary_vars}\ndtypes.update(binary_vars_dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:49:19.916268Z","iopub.execute_input":"2021-12-15T01:49:19.916776Z","iopub.status.idle":"2021-12-15T01:49:19.92489Z","shell.execute_reply.started":"2021-12-15T01:49:19.916722Z","shell.execute_reply":"2021-12-15T01:49:19.923834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/train.csv', dtype=dtypes)\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/test.csv', dtype=dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:49:20.312453Z","iopub.execute_input":"2021-12-15T01:49:20.313017Z","iopub.status.idle":"2021-12-15T01:49:41.851636Z","shell.execute_reply.started":"2021-12-15T01:49:20.312975Z","shell.execute_reply":"2021-12-15T01:49:41.8506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only for some quick tests.\ntrain_50k = train.sample(n=50_000, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:49:41.853342Z","iopub.execute_input":"2021-12-15T01:49:41.853757Z","iopub.status.idle":"2021-12-15T01:49:42.086688Z","shell.execute_reply.started":"2021-12-15T01:49:41.853718Z","shell.execute_reply":"2021-12-15T01:49:42.085814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soil_Type7 and Soil_Type15 are all zeros. So it's safe to drop.\nfeatures.remove('Soil_Type7')\nfeatures.remove('Soil_Type15')\n# There is only one observation for Cover Type 5, so I dropped it too.\ntrain = train.query('Cover_Type != 5')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:49:42.088034Z","iopub.execute_input":"2021-12-15T01:49:42.08833Z","iopub.status.idle":"2021-12-15T01:49:42.646709Z","shell.execute_reply.started":"2021-12-15T01:49:42.088292Z","shell.execute_reply":"2021-12-15T01:49:42.645809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Parsing interesting soil properties","metadata":{}},{"cell_type":"code","source":"soil_descriptions = '''\n1;  Cathedral family - Rock outcrop complex, extremely stony.\n2;  Vanet - Ratake families complex, very stony.\n3;  Haploborolis - Rock outcrop complex, rubbly.\n4;  Ratake family - Rock outcrop complex, rubbly.\n5;  Vanet family - Rock outcrop complex complex, rubbly.\n6;  Vanet - Wetmore families - Rock outcrop complex, stony.\n7;  Gothic family.\n8;  Supervisor - Limber families complex.\n9;  Troutville family, very stony.\n10; Bullwark - Catamount families - Rock outcrop complex, rubbly.\n11; Bullwark - Catamount families - Rock land complex, rubbly.\n12; Legault family - Rock land complex, stony.\n13; Catamount family - Rock land - Bullwark family complex, rubbly.\n14; Pachic Argiborolis - Aquolis complex.\n15; unspecified in the USFS Soil and ELU Survey.\n16; Cryaquolis - Cryoborolis complex.\n17; Gateview family - Cryaquolis complex.\n18; Rogert family, very stony.\n19; Typic Cryaquolis - Borohemists complex.\n20; Typic Cryaquepts - Typic Cryaquolls complex.\n21; Typic Cryaquolls - Leighcan family, till substratum complex.\n22; Leighcan family, till substratum, extremely bouldery.\n23; Leighcan family, till substratum - Typic Cryaquolls complex.\n24; Leighcan family, extremely stony.\n25; Leighcan family, warm, extremely stony.\n26; Granile - Catamount families complex, very stony.\n27; Leighcan family, warm - Rock outcrop complex, extremely stony.\n28; Leighcan family - Rock outcrop complex, extremely stony.\n29; Como - Legault families complex, extremely stony.\n30; Como family - Rock land - Legault family complex, extremely stony.\n31; Leighcan - Catamount families complex, extremely stony.\n32; Catamount family - Rock outcrop - Leighcan family complex, extremely stony.\n33; Leighcan - Catamount families - Rock outcrop complex, extremely stony.\n34; Cryorthents - Rock land complex, extremely stony.\n35; Cryumbrepts - Rock outcrop - Cryaquepts complex.\n36; Bross family - Rock land - Cryumbrepts complex, extremely stony.\n37; Rock outcrop - Cryumbrepts - Cryorthents complex, extremely stony.\n38; Leighcan - Moran families - Cryaquolls complex, extremely stony.\n39; Moran family - Cryorthents - Leighcan family complex, extremely stony.\n40; Moran family - Cryorthents - Rock land complex, extremely stony.\n'''","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:49:42.648758Z","iopub.execute_input":"2021-12-15T01:49:42.649052Z","iopub.status.idle":"2021-12-15T01:49:42.656407Z","shell.execute_reply.started":"2021-12-15T01:49:42.649018Z","shell.execute_reply":"2021-12-15T01:49:42.655222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from io import StringIO\nsoil_desc_df = pd.read_csv(StringIO(soil_descriptions.lower()), sep=';', header=None, names=['soil_id', 'description'])\nsoil_desc_df.info()\nsoil_desc_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:49:42.657742Z","iopub.execute_input":"2021-12-15T01:49:42.658038Z","iopub.status.idle":"2021-12-15T01:49:42.705816Z","shell.execute_reply.started":"2021-12-15T01:49:42.658005Z","shell.execute_reply":"2021-12-15T01:49:42.705196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below, I manually selected keywords from the description that could have potential. Using pandas I created columns for each of these keywords, where it's values (boolean) mark if that keyword shows up in the soil description or not.","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:50:56.784878Z","iopub.execute_input":"2021-12-15T01:50:56.786645Z","iopub.status.idle":"2021-12-15T01:50:56.795231Z","shell.execute_reply.started":"2021-12-15T01:50:56.786562Z","shell.execute_reply":"2021-12-15T01:50:56.793808Z"}}},{"cell_type":"code","source":"soil_keywords = [\n    'cathedral',\n    'vanet',\n    'ratake',\n    'haploborolis',\n    'wetmore',\n    'troutville',\n    'bullwark',\n    'rogert',\n    'cryaquolis',\n    'cryaquepts',\n    'cryaquolls',\n    'granile',\n    'como',\n    'catamount',\n    'cryorthents',\n    'cryumbrepts',\n    'bross',\n    'rock outcrop',\n    'rock land',\n    'aquolis',\n    'pachic argiborolis',\n    'rogert',\n    'till substratum',\n    'leighcan',\n    'moran',\n    'gothic',\n    'legault',\n    'limber',\n    'supervisor',\n    'cryoborolis',\n    'gateview',\n    'borohemists',\n    'warm',\n    'rubbly',\n    'very stony',\n    'extremely stony',\n    'extremely bouldery',\n    # Stony has to be the last keyword in this list, otherwise it eats up the word \"stony\"\n    'stony',\n]","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:53:09.166243Z","iopub.execute_input":"2021-12-15T01:53:09.166612Z","iopub.status.idle":"2021-12-15T01:53:09.174797Z","shell.execute_reply.started":"2021-12-15T01:53:09.166576Z","shell.execute_reply":"2021-12-15T01:53:09.174074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"soil_desc_df['empty_description'] = soil_desc_df['description']\nfor keyword in soil_keywords:\n    soil_desc_df[keyword] = soil_desc_df['empty_description'].str.find(keyword) >= 0\n    soil_desc_df['empty_description'] = soil_desc_df['empty_description'].str.replace(keyword, '', regex=False)\n    \nfor meaningless_word in ['family', 'families', 'complex', ',', '.', '-']:\n    soil_desc_df['empty_description'] = soil_desc_df['empty_description'].str.replace(meaningless_word, '', regex=False)\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:53:09.418678Z","iopub.execute_input":"2021-12-15T01:53:09.419085Z","iopub.status.idle":"2021-12-15T01:53:09.489308Z","shell.execute_reply.started":"2021-12-15T01:53:09.419054Z","shell.execute_reply":"2021-12-15T01:53:09.488619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now I check if I missed any important keywords. The pandas series below shows all words that remained after I processed it as a keyword (or blatantly ignored it).","metadata":{}},{"cell_type":"code","source":"soil_desc_df['empty_description']","metadata":{"execution":{"iopub.status.busy":"2021-12-15T02:27:03.178259Z","iopub.execute_input":"2021-12-15T02:27:03.178891Z","iopub.status.idle":"2021-12-15T02:27:03.187063Z","shell.execute_reply.started":"2021-12-15T02:27:03.178833Z","shell.execute_reply":"2021-12-15T02:27:03.186127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"typic\" is an adjective that appears before some keywords. I don't think it's important. E.g., is there a difference between \"Typic Cryaquolis\" and \"Cryaquolis\"? My guess is that they just supressed the word \"typic\" in some instance, that's why I'm ignoring it. I could be wrong though.\n\nNext, I tried to infer which of these features could be relevant or not. I do so, by filtering only those keywords which show in more than one soil description. If only one soil type has a certain keyword, than it brings no value at all, since this new feature would be identical to the respective `Soil_TypeX` feature.","metadata":{}},{"cell_type":"code","source":"important_keywords = soil_desc_df[soil_keywords].sum().to_frame('count')\nimportant_keywords = important_keywords.query('count > 1')\nimportant_keywords.sort_values('count', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T01:56:49.155455Z","iopub.execute_input":"2021-12-15T01:56:49.156114Z","iopub.status.idle":"2021-12-15T01:56:49.184229Z","shell.execute_reply.started":"2021-12-15T01:56:49.156051Z","shell.execute_reply":"2021-12-15T01:56:49.183381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I think how stony the soil is could be an ordinal feature. So, I created the feature `how_stony` below. Since I am working with a tree-based model (Random Forest), I don't use it. But the idea is here, in case it's useful for anyone. I display the dataframe below with some coloring, to more easily check the logic of the feature.","metadata":{}},{"cell_type":"code","source":"stony_binary_features = ['rubbly', 'stony', 'very stony', 'extremely stony', 'extremely bouldery']\nsoil_desc_df['how_stony'] = (\n    soil_desc_df['rubbly'] * 1 +\n    soil_desc_df['stony'] * 2 +\n    soil_desc_df['very stony'] * 3 +\n    soil_desc_df['extremely stony'] * 4 +\n    soil_desc_df['extremely bouldery'] * 5\n)\nsoil_desc_df[stony_binary_features + ['how_stony']].sort_values('how_stony') \\\n    .style.highlight_max(subset=stony_binary_features).background_gradient('YlGn', subset='how_stony')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T02:02:36.514507Z","iopub.execute_input":"2021-12-15T02:02:36.514847Z","iopub.status.idle":"2021-12-15T02:02:36.638428Z","shell.execute_reply.started":"2021-12-15T02:02:36.51481Z","shell.execute_reply":"2021-12-15T02:02:36.637322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Joining with train and test datasets","metadata":{}},{"cell_type":"code","source":"soil_important_features = important_keywords.index.tolist()\nsoil_important_features","metadata":{"execution":{"iopub.status.busy":"2021-12-15T02:04:12.22527Z","iopub.execute_input":"2021-12-15T02:04:12.225618Z","iopub.status.idle":"2021-12-15T02:04:12.233143Z","shell.execute_reply.started":"2021-12-15T02:04:12.225575Z","shell.execute_reply":"2021-12-15T02:04:12.232325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ok, here is when I noticed joining these soil features with the main dataset would not be so straightforward as I thought. Some observations in the training and testing sets have multiple soil types! I totally forgot about this. On the original dataset, each observation had only one soil type...","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=train[soil_type_vars].sum(axis=1).rename('number_of_soil_types'));","metadata":{"execution":{"iopub.status.busy":"2021-12-15T02:09:11.599791Z","iopub.execute_input":"2021-12-15T02:09:11.600111Z","iopub.status.idle":"2021-12-15T02:09:12.526955Z","shell.execute_reply.started":"2021-12-15T02:09:11.600079Z","shell.execute_reply":"2021-12-15T02:09:12.525865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the observations which have two or more soil types, with which row of soil features should we join it with? We could merge/blend the soil features of the multiple soil types... Here, I went with the simplest approach, I only join those observations that have one soil type. Those which have two or more soil types will not get any soil features.","metadata":{}},{"cell_type":"code","source":"def insert_soil_features(df, skip_soil_ids=[]):\n    soil_id = sum([df[f'Soil_Type{i}'] * i for i in range(1, 41) if i not in skip_soil_ids])\n    soil_id[df[soil_type_vars].sum(axis=1) != 1] = 0\n    df['soil_id'] = soil_id\n    df_with_soil_features = df.join(soil_desc_df.set_index('soil_id')[soil_important_features], on='soil_id')\n    df_with_soil_features[soil_important_features] = df_with_soil_features[soil_important_features].fillna(False)\n    return df_with_soil_features","metadata":{"execution":{"iopub.status.busy":"2021-12-15T02:18:24.049591Z","iopub.execute_input":"2021-12-15T02:18:24.049937Z","iopub.status.idle":"2021-12-15T02:18:24.058306Z","shell.execute_reply.started":"2021-12-15T02:18:24.049904Z","shell.execute_reply":"2021-12-15T02:18:24.057601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"soil_id = sum([train[f'Soil_Type{i}'] * i for i in range(1, 41)])\nsoil_id[train[soil_type_vars].sum(axis=1) != 1] = 0\ntrain['soil_id'] = soil_id\ntrain_with_soil_features = train.join(soil_desc_df.set_index('soil_id')[soil_important_features], on='soil_id')\ntrain_with_soil_features[soil_important_features] = train_with_soil_features[soil_important_features].fillna(False)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T02:18:24.403681Z","iopub.execute_input":"2021-12-15T02:18:24.403979Z","iopub.status.idle":"2021-12-15T02:18:52.708118Z","shell.execute_reply.started":"2021-12-15T02:18:24.403941Z","shell.execute_reply":"2021-12-15T02:18:52.706986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_with_soil_features = insert_soil_features(train, skip_soil_ids=[7, 15])\ntest_with_soil_features = insert_soil_features(test, skip_soil_ids=[7, 15])","metadata":{"execution":{"iopub.status.busy":"2021-12-15T02:18:52.710134Z","iopub.execute_input":"2021-12-15T02:18:52.710439Z","iopub.status.idle":"2021-12-15T02:19:28.428056Z","shell.execute_reply.started":"2021-12-15T02:18:52.710397Z","shell.execute_reply":"2021-12-15T02:19:28.427194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Just checking if I'm getting what I expected.\nwith pd.option_context('display.max_columns', None):\n    display(test_with_soil_features.drop_duplicates(subset=['soil_id']).set_index('soil_id').sort_index()[soil_type_vars + soil_important_features])","metadata":{"execution":{"iopub.status.busy":"2021-12-15T02:25:59.226829Z","iopub.execute_input":"2021-12-15T02:25:59.227152Z","iopub.status.idle":"2021-12-15T02:25:59.346649Z","shell.execute_reply.started":"2021-12-15T02:25:59.227119Z","shell.execute_reply":"2021-12-15T02:25:59.345587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest (without soil features)","metadata":{}},{"cell_type":"code","source":"%%time\nn_folds = 10\nX = train[features]\ny = train[target]\nX_test = test[features]\nn_labels = y.nunique()\n\nkf = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\nfold_accuracies = np.empty(shape=(n_folds), dtype=np.float)\nfold_preds_test = np.empty(shape=(n_folds, len(X_test)), dtype=np.int)\nfold_proba_test = np.empty(shape=(n_folds, len(X_test), n_labels), dtype=np.int)\nfor fold_i, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n    X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n\n    model = RandomForestClassifier(n_jobs=6)\n    model.fit(X_train, y_train)\n\n    preds_val = model.predict(X_val)\n    fold_accuracies[fold_i] = accuracy_score(y_val, preds_val)\n    print(f'Fold: {fold_i}, accuracy: {fold_accuracies[fold_i]:.4f}')\n\n    # Prediction on test set.\n    fold_proba_test[fold_i] = model.predict_proba(X_test)\n    fold_preds_test[fold_i] = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T03:10:34.016194Z","iopub.execute_input":"2021-12-09T03:10:34.017013Z","iopub.status.idle":"2021-12-09T03:10:38.981611Z","shell.execute_reply.started":"2021-12-09T03:10:34.016949Z","shell.execute_reply":"2021-12-09T03:10:38.980978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'CV accuracy: {fold_accuracies.mean()} +- {fold_accuracies.std()}')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T03:10:38.982535Z","iopub.execute_input":"2021-12-09T03:10:38.983373Z","iopub.status.idle":"2021-12-09T03:10:38.988111Z","shell.execute_reply.started":"2021-12-09T03:10:38.983333Z","shell.execute_reply":"2021-12-09T03:10:38.987177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode_result = mode(fold_preds_test, axis=0)\nmode_submission = test[['Id']].copy()\nmode_submission[target] = mode_result.mode.ravel()\nmode_submission.to_csv('submission_without_soil_features.csv', index=False)\nmode_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T03:10:38.989584Z","iopub.execute_input":"2021-12-09T03:10:38.990009Z","iopub.status.idle":"2021-12-09T03:11:14.096594Z","shell.execute_reply.started":"2021-12-09T03:10:38.989972Z","shell.execute_reply":"2021-12-09T03:11:14.095883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature importance","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(model.feature_importances_, columns=['importance'], index=features) \\\n    .sort_values('importance', ascending=False).style.bar()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T03:11:14.097745Z","iopub.execute_input":"2021-12-09T03:11:14.098087Z","iopub.status.idle":"2021-12-09T03:11:14.220671Z","shell.execute_reply.started":"2021-12-09T03:11:14.098055Z","shell.execute_reply":"2021-12-09T03:11:14.218396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest (using soil features)","metadata":{}},{"cell_type":"code","source":"%%time\nn_folds = 10\nX = train_with_soil_features[features + soil_important_features]\ny = train_with_soil_features[target]\nX_test = test_with_soil_features[features + soil_important_features]\nn_labels = y.nunique()\n\nkf = StratifiedKFold(n_splits=n_folds, random_state=42, shuffle=True)\nfold_accuracies = np.empty(shape=(n_folds), dtype=np.float)\nfold_preds_test = np.empty(shape=(n_folds, len(X_test)), dtype=np.int)\nfold_proba_test = np.empty(shape=(n_folds, len(X_test), n_labels), dtype=np.int)\nfor fold_i, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n    X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n\n    model = RandomForestClassifier(n_jobs=6)\n    model.fit(X_train, y_train)\n\n    preds_val = model.predict(X_val)\n    fold_accuracies[fold_i] = accuracy_score(y_val, preds_val)\n    print(f'Fold: {fold_i}, accuracy: {fold_accuracies[fold_i]:.4f}')\n\n    # Prediction on test set.\n    fold_proba_test[fold_i] = model.predict_proba(X_test)\n    fold_preds_test[fold_i] = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T03:11:14.222036Z","iopub.execute_input":"2021-12-09T03:11:14.222436Z","iopub.status.idle":"2021-12-09T03:16:38.430419Z","shell.execute_reply.started":"2021-12-09T03:11:14.222389Z","shell.execute_reply":"2021-12-09T03:16:38.427155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'CV accuracy: {fold_accuracies.mean()} +- {fold_accuracies.std()}')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T03:16:38.437346Z","iopub.execute_input":"2021-12-09T03:16:38.439227Z","iopub.status.idle":"2021-12-09T03:16:38.451527Z","shell.execute_reply.started":"2021-12-09T03:16:38.438971Z","shell.execute_reply":"2021-12-09T03:16:38.449716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode_result = mode(fold_preds_test, axis=0)\nmode_submission = test[['Id']].copy()\nmode_submission[target] = mode_result.mode.ravel()\nmode_submission.to_csv('submission_with_soil_features.csv', index=False)\nmode_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T03:16:38.454068Z","iopub.execute_input":"2021-12-09T03:16:38.455807Z","iopub.status.idle":"2021-12-09T03:17:14.694037Z","shell.execute_reply.started":"2021-12-09T03:16:38.45572Z","shell.execute_reply":"2021-12-09T03:17:14.69295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature importance","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(model.feature_importances_, columns=['importance'], index=features + soil_important_features) \\\n    .sort_values('importance', ascending=False).style.bar()","metadata":{"execution":{"iopub.status.busy":"2021-12-09T03:17:14.69554Z","iopub.execute_input":"2021-12-09T03:17:14.695789Z","iopub.status.idle":"2021-12-09T03:17:14.821511Z","shell.execute_reply.started":"2021-12-09T03:17:14.695761Z","shell.execute_reply":"2021-12-09T03:17:14.820575Z"},"trusted":true},"execution_count":null,"outputs":[]}]}