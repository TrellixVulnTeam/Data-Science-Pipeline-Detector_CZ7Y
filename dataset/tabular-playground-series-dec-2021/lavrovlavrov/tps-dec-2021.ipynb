{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-28T23:46:57.986887Z","iopub.execute_input":"2021-12-28T23:46:57.987218Z","iopub.status.idle":"2021-12-28T23:46:58.003534Z","shell.execute_reply.started":"2021-12-28T23:46:57.987174Z","shell.execute_reply":"2021-12-28T23:46:58.002627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-dec-2021/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:46:58.581789Z","iopub.execute_input":"2021-12-28T23:46:58.58425Z","iopub.status.idle":"2021-12-28T23:47:19.82277Z","shell.execute_reply.started":"2021-12-28T23:46:58.584205Z","shell.execute_reply":"2021-12-28T23:47:19.822028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Cover_Type'].value_counts() ","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:47:19.824432Z","iopub.execute_input":"2021-12-28T23:47:19.824674Z","iopub.status.idle":"2021-12-28T23:47:19.858449Z","shell.execute_reply.started":"2021-12-28T23:47:19.824641Z","shell.execute_reply":"2021-12-28T23:47:19.857667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=train[train['Cover_Type']!=5]","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:47:19.860245Z","iopub.execute_input":"2021-12-28T23:47:19.860644Z","iopub.status.idle":"2021-12-28T23:47:20.603705Z","shell.execute_reply.started":"2021-12-28T23:47:19.860606Z","shell.execute_reply":"2021-12-28T23:47:20.602963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:37:03.6498Z","iopub.execute_input":"2021-12-28T23:37:03.650041Z","iopub.status.idle":"2021-12-28T23:37:03.67092Z","shell.execute_reply.started":"2021-12-28T23:37:03.650008Z","shell.execute_reply":"2021-12-28T23:37:03.670256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get train data without the target and ids\nX = train.iloc[:, 1:-1].copy()\n# Get the target\ny = train.Cover_Type.copy()\n\n# Create test X, drop ids.\ntest_X = test.iloc[:, 1:].copy()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:47:20.605554Z","iopub.execute_input":"2021-12-28T23:47:20.605818Z","iopub.status.idle":"2021-12-28T23:47:21.421733Z","shell.execute_reply.started":"2021-12-28T23:47:20.605783Z","shell.execute_reply":"2021-12-28T23:47:21.421047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:37:04.479941Z","iopub.execute_input":"2021-12-28T23:37:04.480457Z","iopub.status.idle":"2021-12-28T23:37:04.508705Z","shell.execute_reply.started":"2021-12-28T23:37:04.480415Z","shell.execute_reply":"2021-12-28T23:37:04.508047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some features are constant, let's remove them\ndrop_cols = [col for col in X.columns if X[col].nunique() == 1]\nX = X.drop(columns=drop_cols)\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:47:26.726221Z","iopub.execute_input":"2021-12-28T23:47:26.726464Z","iopub.status.idle":"2021-12-28T23:47:28.418274Z","shell.execute_reply.started":"2021-12-28T23:47:26.726435Z","shell.execute_reply":"2021-12-28T23:47:28.417614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport gc\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom skopt.space import Real, Categorical, Integer\nfrom skopt import BayesSearchCV\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:47:29.617909Z","iopub.execute_input":"2021-12-28T23:47:29.618162Z","iopub.status.idle":"2021-12-28T23:47:30.852392Z","shell.execute_reply.started":"2021-12-28T23:47:29.618133Z","shell.execute_reply":"2021-12-28T23:47:30.851674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=5)\n\ndel X\ngc.collect()\n\nX_train","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:48:07.27644Z","iopub.execute_input":"2021-12-28T23:48:07.276706Z","iopub.status.idle":"2021-12-28T23:48:13.2522Z","shell.execute_reply.started":"2021-12-28T23:48:07.276674Z","shell.execute_reply":"2021-12-28T23:48:13.251452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's make two lists, one with only one-hot-encoded features, the other with the rest\noh_cols = [col for col in X_train.columns if X_train[col].nunique()==2]\nn_oh_cols = [col for col in X_train.columns if X_train[col].nunique()>2]\n\n# this should be zero\nlen(n_oh_cols)+len(oh_cols)-len(X_train.columns) ","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:48:17.82395Z","iopub.execute_input":"2021-12-28T23:48:17.824202Z","iopub.status.idle":"2021-12-28T23:48:19.263414Z","shell.execute_reply.started":"2021-12-28T23:48:17.824174Z","shell.execute_reply":"2021-12-28T23:48:19.262661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalising the non-enconded features\nsc = StandardScaler()\nprep = ColumnTransformer([('sc', sc, n_oh_cols)], remainder='passthrough')\n\n# Define model\nmodel = XGBClassifier(tree_method='gpu_hist', use_label_encoder=False, eval_metric='merror', random_state=7)\n\n# Define pipeline\npipe = Pipeline(steps=[('preprocessing', prep),('model', model)])","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:48:22.69131Z","iopub.execute_input":"2021-12-28T23:48:22.691563Z","iopub.status.idle":"2021-12-28T23:48:22.69739Z","shell.execute_reply.started":"2021-12-28T23:48:22.691532Z","shell.execute_reply":"2021-12-28T23:48:22.696574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The target needs to be properly enconded, i.e. give 0, 1, 2,...\nle = LabelEncoder()\ny_train = pd.Series(le.fit_transform(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:48:26.195485Z","iopub.execute_input":"2021-12-28T23:48:26.195743Z","iopub.status.idle":"2021-12-28T23:48:26.323913Z","shell.execute_reply.started":"2021-12-28T23:48:26.195713Z","shell.execute_reply":"2021-12-28T23:48:26.323137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now, we fit using the role train data and the best parameters in the scan\nmodel_opt = XGBClassifier(80, eval_metric='error', use_label_encoder=False, tree_method='gpu_hist')\n\n# Defining the pipeline with the same preprocessing as before, but with the tuned model\npipe_opt = Pipeline(steps=[('preprocessing', prep), ('model', model_opt)])\n\n#transform y_val according to the encoding applied to y_train\ny_test = pd.Series(le.transform(y_test))\n# Fitting the whole dataset\npipe_opt.fit(X_test, y_test)\n\ndel X_test\ndel y_test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:48:29.841505Z","iopub.execute_input":"2021-12-28T23:48:29.841821Z","iopub.status.idle":"2021-12-28T23:48:41.132405Z","shell.execute_reply.started":"2021-12-28T23:48:29.841788Z","shell.execute_reply":"2021-12-28T23:48:41.131633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### We calculate and store the probability of the positive prediction\nX_test = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv', index_col='Id')\n\n# drop the columns dropped in the train set\nX_test = X_test.drop(columns=drop_cols)\n\npred_test = pipe_opt.predict(X_test)\n# inverse transform the results to the original enconding and submit\npred_test = pd.Series(le.inverse_transform(pred_test))\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'Cover_Type': pred_test})\noutput","metadata":{"execution":{"iopub.status.busy":"2021-12-28T23:48:51.958575Z","iopub.execute_input":"2021-12-28T23:48:51.958844Z","iopub.status.idle":"2021-12-28T23:49:06.702323Z","shell.execute_reply.started":"2021-12-28T23:48:51.958813Z","shell.execute_reply":"2021-12-28T23:49:06.701612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}