{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-28T15:13:48.847841Z","iopub.execute_input":"2022-01-28T15:13:48.848575Z","iopub.status.idle":"2022-01-28T15:13:48.885079Z","shell.execute_reply.started":"2022-01-28T15:13:48.848429Z","shell.execute_reply":"2022-01-28T15:13:48.88437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Read The Data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/train.csv')\ntest_data = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:13:48.887936Z","iopub.execute_input":"2022-01-28T15:13:48.888144Z","iopub.status.idle":"2022-01-28T15:14:10.400953Z","shell.execute_reply.started":"2022-01-28T15:13:48.888118Z","shell.execute_reply":"2022-01-28T15:14:10.40015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. EDA","metadata":{}},{"cell_type":"code","source":"print('The number of categorical target :', len(train_data['Cover_Type'].unique()))","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:10.40315Z","iopub.execute_input":"2022-01-28T15:14:10.403671Z","iopub.status.idle":"2022-01-28T15:14:10.436346Z","shell.execute_reply.started":"2022-01-28T15:14:10.403632Z","shell.execute_reply":"2022-01-28T15:14:10.435165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:10.44026Z","iopub.execute_input":"2022-01-28T15:14:10.440446Z","iopub.status.idle":"2022-01-28T15:14:10.463688Z","shell.execute_reply.started":"2022-01-28T15:14:10.440423Z","shell.execute_reply":"2022-01-28T15:14:10.463008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-1. The count of each Cover_Type","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ntrain_data['Count'] = 1\ntrain_data_cover_type = train_data.groupby('Cover_Type').sum()\nsns.set()\nsns.barplot(x = train_data_cover_type.index, y = train_data_cover_type.Count)\nplt.title('The relation between Cover_Type and Count')","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:10.465166Z","iopub.execute_input":"2022-01-28T15:14:10.465432Z","iopub.status.idle":"2022-01-28T15:14:15.017506Z","shell.execute_reply.started":"2022-01-28T15:14:10.465397Z","shell.execute_reply":"2022-01-28T15:14:15.016802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-2. Elevation features","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\nfig, axes = plt.subplots(1, 7, figsize=(50, 10))\nfig.suptitle('The features : Elevation', fontsize=30)\nfor i in range(7):\n    Cover_type_cate = train_data[train_data['Cover_Type'] == (i+1)]\n    sns.histplot(x =  Cover_type_cate.Elevation, ax = axes[i])\n    axes[i].set_title(f'Cover_Type : {i+1}', fontsize=30)\n    axes[i].set_xlabel('Elevation', fontsize=30)\n    axes[i].set_ylabel('Count', fontsize=30)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:15.018734Z","iopub.execute_input":"2022-01-28T15:14:15.01901Z","iopub.status.idle":"2022-01-28T15:14:21.960486Z","shell.execute_reply.started":"2022-01-28T15:14:15.018972Z","shell.execute_reply":"2022-01-28T15:14:21.959791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-3. Aspect Feature","metadata":{}},{"cell_type":"code","source":"sns.set()\nfig, axes = plt.subplots(1, 7, figsize=(40, 10))\nfig.suptitle('The features : Aspect', fontsize=30)\nfor i in range(7):\n    Cover_type_cate = train_data[train_data['Cover_Type'] == (i+1)]\n    sns.histplot(x =  Cover_type_cate.Aspect, ax = axes[i])\n    axes[i].set_title(f'Cover_Type : {i+1}', fontsize=30)\n    axes[i].set_xlabel('Aspect', fontsize=30)\n    axes[i].set_ylabel('Count', fontsize=30)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:21.961515Z","iopub.execute_input":"2022-01-28T15:14:21.961744Z","iopub.status.idle":"2022-01-28T15:14:26.227726Z","shell.execute_reply.started":"2022-01-28T15:14:21.96171Z","shell.execute_reply":"2022-01-28T15:14:26.226965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-4. Slope Feature","metadata":{}},{"cell_type":"code","source":"sns.set()\nfig, axes = plt.subplots(1, 7, figsize=(40, 10))\nfig.suptitle('The features : Slope', fontsize=30)\nfor i in range(7):\n    Cover_type_cate = train_data[train_data['Cover_Type'] == (i+1)]\n    sns.histplot(x =  Cover_type_cate.Slope, ax = axes[i])\n    axes[i].set_title(f'Cover_Type : {i+1}', fontsize=30)\n    axes[i].set_xlabel('Slope', fontsize=30)\n    axes[i].set_ylabel('Count', fontsize=30)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:26.23215Z","iopub.execute_input":"2022-01-28T15:14:26.234543Z","iopub.status.idle":"2022-01-28T15:14:32.024018Z","shell.execute_reply.started":"2022-01-28T15:14:26.234494Z","shell.execute_reply":"2022-01-28T15:14:32.023169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-5. Horizontal_Distance_To_Hydrology Feature","metadata":{}},{"cell_type":"code","source":"sns.set()\nfig, axes = plt.subplots(1, 7, figsize=(40, 10))\nfig.suptitle('The features : Horizontal_Distance_To_Hydrology', fontsize=30)\nfor i in range(7):\n    Cover_type_cate = train_data[train_data['Cover_Type'] == (i+1)]\n    sns.histplot(x =  Cover_type_cate.Horizontal_Distance_To_Hydrology, ax = axes[i])\n    axes[i].set_title(f'Cover_Type : {i+1}', fontsize=30)\n    axes[i].set_xlabel('Horizontal_Distance_To_Hydrology', fontsize=15)\n    axes[i].set_ylabel('Count', fontsize=30)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:32.025316Z","iopub.execute_input":"2022-01-28T15:14:32.026236Z","iopub.status.idle":"2022-01-28T15:14:37.678162Z","shell.execute_reply.started":"2022-01-28T15:14:32.02619Z","shell.execute_reply":"2022-01-28T15:14:37.677442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-6. Vertical_Distance_To_Hydrology Feature","metadata":{}},{"cell_type":"code","source":"\nsns.set()\nfig, axes = plt.subplots(1, 7, figsize=(40, 10))\nfig.suptitle('The features : Vertical_Distance_To_Hydrology ', fontsize=30)\nfor i in range(7):\n    Cover_type_cate = train_data[train_data['Cover_Type'] == (i+1)]\n    sns.histplot(x =  Cover_type_cate.Vertical_Distance_To_Hydrology, ax = axes[i])\n    axes[i].set_title(f'Cover_Type : {i+1}', fontsize=30)\n    axes[i].set_xlabel('Vertical_Distance_To_Hydrology', fontsize=15)\n    axes[i].set_ylabel('Count', fontsize=30)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:37.68103Z","iopub.execute_input":"2022-01-28T15:14:37.681778Z","iopub.status.idle":"2022-01-28T15:14:45.363577Z","shell.execute_reply.started":"2022-01-28T15:14:37.681735Z","shell.execute_reply":"2022-01-28T15:14:45.362935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-7. Horizontal_Distance_To_Roadways Feature","metadata":{}},{"cell_type":"code","source":"sns.set()\nfig, axes = plt.subplots(1, 7, figsize=(40, 10))\nfig.suptitle('The features : Horizontal_Distance_To_Roadways ', fontsize=30)\nfor i in range(7):\n    Cover_type_cate = train_data[train_data['Cover_Type'] == (i+1)]\n    sns.histplot(x =  Cover_type_cate.Horizontal_Distance_To_Roadways, ax = axes[i])\n    axes[i].set_title(f'Cover_Type : {i+1}', fontsize=30)\n    axes[i].set_xlabel('Horizontal_Distance_To_Roadways', fontsize=15)\n    axes[i].set_ylabel('Count', fontsize=30)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:45.364846Z","iopub.execute_input":"2022-01-28T15:14:45.365391Z","iopub.status.idle":"2022-01-28T15:14:51.087886Z","shell.execute_reply.started":"2022-01-28T15:14:45.365346Z","shell.execute_reply":"2022-01-28T15:14:51.087165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Deep Learning Model","metadata":{}},{"cell_type":"code","source":"train_data = train_data.drop(columns = ['Count', 'Id'])\ntest_data = test_data.drop(columns = ['Id'])","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:51.089135Z","iopub.execute_input":"2022-01-28T15:14:51.09004Z","iopub.status.idle":"2022-01-28T15:14:51.872721Z","shell.execute_reply.started":"2022-01-28T15:14:51.089997Z","shell.execute_reply":"2022-01-28T15:14:51.871637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\ndata = train_data.drop(columns = 'Cover_Type')\ntarget = train_data['Cover_Type']\n\nScale = MinMaxScaler()\ndata = Scale.fit_transform(data)\ntest_data = Scale.transform(test_data)\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import plot_model, to_categorical\nx_train, x_test, y_train, y_test = train_test_split(data, target, train_size = 0.8, random_state = 10)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:14:51.874016Z","iopub.execute_input":"2022-01-28T15:14:51.874355Z","iopub.status.idle":"2022-01-28T15:15:02.615565Z","shell.execute_reply.started":"2022-01-28T15:14:51.874303Z","shell.execute_reply":"2022-01-28T15:15:02.614514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.utils import plot_model, to_categorical\nmodel = Sequential()\nmodel.add(Dense(128, activation = 'relu', input_shape = (x_train.shape[1],)))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dense(8, activation = 'softmax'))\nmodel.compile(optimizer= 'adam', \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])\n\nhistory = model.fit(x_train, y_train, epochs = 30, validation_split = 0.2, batch_size = 512, verbose = 0)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:15:02.628906Z","iopub.execute_input":"2022-01-28T15:15:02.629273Z","iopub.status.idle":"2022-01-28T15:18:28.498826Z","shell.execute_reply.started":"2022-01-28T15:15:02.629213Z","shell.execute_reply":"2022-01-28T15:18:28.497922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-1. Model's Training Process","metadata":{}},{"cell_type":"code","source":"df_DL = pd.DataFrame(history.history)\ndf_DL.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:18:28.500848Z","iopub.execute_input":"2022-01-28T15:18:28.501155Z","iopub.status.idle":"2022-01-28T15:18:28.515891Z","shell.execute_reply.started":"2022-01-28T15:18:28.501116Z","shell.execute_reply":"2022-01-28T15:18:28.515226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(df_DL.index, df_DL['loss'], label = 'loss')\nplt.plot(df_DL.index, df_DL['val_loss'], label = 'Val_loss')\nplt.xlabel( 'Epochs')\nplt.ylabel('Binary_crossentropy')\nplt.title('DL loss function')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:18:28.518071Z","iopub.execute_input":"2022-01-28T15:18:28.518546Z","iopub.status.idle":"2022-01-28T15:18:28.800763Z","shell.execute_reply.started":"2022-01-28T15:18:28.518508Z","shell.execute_reply":"2022-01-28T15:18:28.799948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:18:28.802064Z","iopub.execute_input":"2022-01-28T15:18:28.802403Z","iopub.status.idle":"2022-01-28T15:18:49.12784Z","shell.execute_reply.started":"2022-01-28T15:18:28.80236Z","shell.execute_reply":"2022-01-28T15:18:49.126947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = np.argmax(y_test, axis = 1)\ny_pred = np.argmax(y_pred, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:18:49.14871Z","iopub.execute_input":"2022-01-28T15:18:49.149061Z","iopub.status.idle":"2022-01-28T15:18:49.17948Z","shell.execute_reply.started":"2022-01-28T15:18:49.14902Z","shell.execute_reply":"2022-01-28T15:18:49.178777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-2. Comparsion between Reality and Prediction -> Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nplt.figure(figsize = (15, 15))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:18:49.18089Z","iopub.execute_input":"2022-01-28T15:18:49.181164Z","iopub.status.idle":"2022-01-28T15:18:50.679747Z","shell.execute_reply.started":"2022-01-28T15:18:49.181129Z","shell.execute_reply":"2022-01-28T15:18:50.67897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/sample_submission.csv')\nsubmission['Cover_Type'] = np.argmax(model.predict(test_data), axis = 1)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T15:18:50.958075Z","iopub.execute_input":"2022-01-28T15:18:50.958853Z","iopub.status.idle":"2022-01-28T15:19:18.803904Z","shell.execute_reply.started":"2022-01-28T15:18:50.958776Z","shell.execute_reply":"2022-01-28T15:19:18.802977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['Cover_Type'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T16:05:12.135728Z","iopub.execute_input":"2022-01-28T16:05:12.1365Z","iopub.status.idle":"2022-01-28T16:05:12.217405Z","shell.execute_reply.started":"2022-01-28T16:05:12.136397Z","shell.execute_reply":"2022-01-28T16:05:12.216251Z"},"trusted":true},"execution_count":null,"outputs":[]}]}