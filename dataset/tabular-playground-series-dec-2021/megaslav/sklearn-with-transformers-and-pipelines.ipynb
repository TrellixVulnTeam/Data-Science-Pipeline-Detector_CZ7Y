{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-15T12:57:33.232856Z","iopub.execute_input":"2021-12-15T12:57:33.233263Z","iopub.status.idle":"2021-12-15T12:57:33.27285Z","shell.execute_reply.started":"2021-12-15T12:57:33.233147Z","shell.execute_reply":"2021-12-15T12:57:33.271753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is an example of using tranfromers and pipelines in Sklearn. Feature engineering transformer is based on this research: https://www.kaggle.com/balamurugan1603/tps-dec-21-nn-feature-engg-tf","metadata":{}},{"cell_type":"code","source":"train_ds = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/train.csv', index_col='Id')\ntrain_ds.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:57:33.274703Z","iopub.execute_input":"2021-12-15T12:57:33.274944Z","iopub.status.idle":"2021-12-15T12:57:51.656404Z","shell.execute_reply.started":"2021-12-15T12:57:33.274913Z","shell.execute_reply":"2021-12-15T12:57:51.655415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing empty columns and NaN rows","metadata":{}},{"cell_type":"code","source":"train_ds.drop([\"Soil_Type7\", \"Soil_Type15\"], axis=1, inplace=True)\ntrain_ds = train_ds.where(train_ds['Cover_Type'] != 5)\nprint('Before removing null: ', train_ds.isnull().sum().sum())\ntrain_ds.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:57:51.657618Z","iopub.execute_input":"2021-12-15T12:57:51.657853Z","iopub.status.idle":"2021-12-15T12:58:14.123978Z","shell.execute_reply.started":"2021-12-15T12:57:51.657821Z","shell.execute_reply":"2021-12-15T12:58:14.123058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = train_ds['Cover_Type'].copy()\ntrain_ds = train_ds.drop('Cover_Type', axis=1) ","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:58:14.125997Z","iopub.execute_input":"2021-12-15T12:58:14.126231Z","iopub.status.idle":"2021-12-15T12:58:14.745432Z","shell.execute_reply.started":"2021-12-15T12:58:14.126202Z","shell.execute_reply":"2021-12-15T12:58:14.744487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we define a feature engineering tranformer, it will addjust and add features.","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline, FeatureUnion\n\n\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, hill_feat, soil_feat, wild_feat):\n        self.hill_feat = hill_feat\n        self.soil_feat = soil_feat\n        self.wild_feat = wild_feat\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):        \n        X['Aspect'][X['Aspect'] < 0] += 360\n        X[\"Aspect\"][X[\"Aspect\"] > 359] -= 360\n\n        X[\"Mnhttn_Dist_Hydrlgy\"] = np.abs(X[\"Horizontal_Distance_To_Hydrology\"]) + np.abs(X[\"Vertical_Distance_To_Hydrology\"])\n        X[\"Ecldn_Dist_Hydrlgy\"] = (X[\"Horizontal_Distance_To_Hydrology\"]**2 + X[\"Vertical_Distance_To_Hydrology\"]**2)**0.5\n        \n        for hill in self.hill_feat:\n            X.loc[X[hill] < 0, hill] = 0\n            X.loc[X[hill] > 255, hill] = 255\n\n        X[\"Soil_Count\"] = X[self.soil_feat].apply(sum, axis=1)\n        X[\"Wild_Area_Count\"] = X[self.wild_feat].apply(sum, axis=1)\n        X[\"Hillshade_Mean\"] = X[self.hill_feat].mean(axis=1)\n        X['Amp_Hillshade'] = X[self.hill_feat].max(axis=1) - X[self.hill_feat].min(axis=1)\n\n        return X\n","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:58:14.746743Z","iopub.execute_input":"2021-12-15T12:58:14.746969Z","iopub.status.idle":"2021-12-15T12:58:15.724236Z","shell.execute_reply.started":"2021-12-15T12:58:14.74694Z","shell.execute_reply":"2021-12-15T12:58:15.72322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hill_feat = [x for x in train_ds.columns if x.startswith(\"Hillshade\")]\nsoil_feat = [x for x in train_ds.columns if x.startswith(\"Soil_Type\")]\nwild_feat = [x for x in train_ds.columns if x.startswith(\"Wilderness_Area\")]\n\nfeature_engineer = FeatureEngineer(hill_feat=hill_feat, soil_feat=soil_feat, wild_feat=wild_feat)\ntrain_ds = feature_engineer.fit_transform(train_ds)\ntrain_ds.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T12:58:15.725618Z","iopub.execute_input":"2021-12-15T12:58:15.726371Z","iopub.status.idle":"2021-12-15T13:00:16.044105Z","shell.execute_reply.started":"2021-12-15T12:58:15.726323Z","shell.execute_reply":"2021-12-15T13:00:16.043095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we add data selector. It will seperate dataset based on column types. Also we define pipelines to preprocess dataset.","metadata":{}},{"cell_type":"code","source":"class DataSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attributes):\n        self.attributes = attributes\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        return X[self.attributes].values.astype(np.float16)\n\n\nbool_cols = [i for i in train_ds.columns if i.startswith('Soil_Type') or i.startswith('Wilderness')]\nnum_cols = [i for i in train_ds.columns if not i.startswith('Soil_Type') and not i.startswith('Wilderness')]\n\nnum_pipeline = Pipeline([\n    ('num_selector', DataSelector(num_cols)),\n    ('scaler', StandardScaler())\n])\n\nint_pipeline = Pipeline([\n    ('int_selector', DataSelector(bool_cols))\n])\n\npreprocessor = FeatureUnion([\n    ('num_pipeline', num_pipeline),\n    ('int_pipeline', int_pipeline)\n])","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:00:16.045816Z","iopub.execute_input":"2021-12-15T13:00:16.047464Z","iopub.status.idle":"2021-12-15T13:00:16.056508Z","shell.execute_reply.started":"2021-12-15T13:00:16.047411Z","shell.execute_reply":"2021-12-15T13:00:16.055714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare dataset with pipelines","metadata":{}},{"cell_type":"code","source":"train_ds = preprocessor.fit_transform(train_ds)\nlabels = labels.values","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:00:16.057731Z","iopub.execute_input":"2021-12-15T13:00:16.058664Z","iopub.status.idle":"2021-12-15T13:00:24.45909Z","shell.execute_reply.started":"2021-12-15T13:00:16.058614Z","shell.execute_reply":"2021-12-15T13:00:24.458052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I didn't reduce memory usage for this task, so *n_estimators=25*. Sorry) This is all for demonstrational purpose.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=25, random_state=42, verbose=2, n_jobs=-1).fit(train_ds, labels)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:00:24.460951Z","iopub.execute_input":"2021-12-15T13:00:24.461531Z","iopub.status.idle":"2021-12-15T13:04:25.882477Z","shell.execute_reply.started":"2021-12-15T13:00:24.461481Z","shell.execute_reply":"2021-12-15T13:04:25.881754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our pipeline in action for test dataset.","metadata":{}},{"cell_type":"code","source":"test_ds = pd.read_csv('/kaggle/input/tabular-playground-series-dec-2021/test.csv', index_col='Id')\n\nadded_features = FeatureEngineer(hill_feat=hill_feat, soil_feat=soil_feat, wild_feat=wild_feat).fit_transform(test_ds)\ntest_data = preprocessor.transform(added_features)\ntest_labels = clf.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:04:25.884653Z","iopub.execute_input":"2021-12-15T13:04:25.885477Z","iopub.status.idle":"2021-12-15T13:05:11.047045Z","shell.execute_reply.started":"2021-12-15T13:04:25.88544Z","shell.execute_reply":"2021-12-15T13:05:11.045759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = test_labels.astype(np.uint8)\n\nsub_df = pd.DataFrame({'Id': test_ds.index, 'Cover_Type': predictions})\n\nsub_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:05:11.048382Z","iopub.execute_input":"2021-12-15T13:05:11.048635Z","iopub.status.idle":"2021-12-15T13:05:12.869419Z","shell.execute_reply.started":"2021-12-15T13:05:11.048601Z","shell.execute_reply":"2021-12-15T13:05:12.868503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you found it useful - plz UV ;)","metadata":{}}]}