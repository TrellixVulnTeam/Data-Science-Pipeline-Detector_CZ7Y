{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np              # linear algebra\nimport pandas as pd             # data processing, CSV file I/O (e.g. pd.read_csv)\n                                \nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns           # data visualization","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation\n\n---\n\n## Data Extraction","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/tabular-playground-series-dec-2021/sample_submission.csv\")\ntrain = pd.read_csv(\"/kaggle/input/tabular-playground-series-dec-2021/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tabular-playground-series-dec-2021/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Concatenation","metadata":{}},{"cell_type":"code","source":"data = pd.concat([train, test], sort = False)\ndata.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Null Check","metadata":{}},{"cell_type":"code","source":"null_cols = [col for col in data.iloc[: , : -1].columns if data[col].isnull().sum() != 0]\nnull_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET = 'Cover_Type'\nFEATURES = [col for col in train.columns if col not in ['id', TARGET]]\n\ncat_features = [col for col in FEATURES if data[col].nunique() < 25]\ncont_features = [col for col in FEATURES if data[col].nunique() >= 25]\n\ndel data\nprint(f'Total number of features: {len(FEATURES)}')\nprint(f'Number of categorical features: {len(cat_features)}')\nprint(f'Number of continuos features: {len(cont_features)}')\n\nplt.pie([len(cat_features), len(cont_features)], \n        labels=['Categorical', 'Continuos'],\n        colors=['#76D7C4', '#F5B7B1'],\n        textprops={'fontsize': 13},\n        autopct='%1.1f%%')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='GnBu')\\\n                     .bar(subset=[\"max\"], color='#BB0000')\\\n                     .bar(subset=[\"mean\",], color='green')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.countplot(x='Cover_Type', data=train, palette='icefire');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# predictor\nX = train.drop(columns=['Id','Cover_Type','Soil_Type7','Soil_Type15'])\n\n# target\ny = train['Cover_Type']\n\ndel train\n\n# test data \ntest_df = test.drop(columns=['Id','Soil_Type7','Soil_Type15'])\ndel test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train-test split\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nimport optuna\n\ndef objective(trial):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, random_state = 123, shuffle = True)\n\n    param = {\n        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3]),\n        'n_estimators': 1000,\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n        'random_state': trial.suggest_categorical('random_state', [0, 24, 48,2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n    }\n    \n    model = XGBClassifier(**param)  \n    \n    model.fit(X_train, y_train, eval_set=[(X_val,y_val)], early_stopping_rounds = 20, verbose = False)\n    \n    y_pred = model.predict(X_val)\n    \n    result = accuracy_score(y_val, y_pred)\n    \n    return result\n\n\nstudy = optuna.create_study(direction = 'maximize', sampler = optuna.samplers.RandomSampler(seed = 0))\n\nstudy.optimize(objective, n_trials = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param = {\n        'tree_method': 'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n        'lambda': study.best_params['lambda'],\n        'alpha': study.best_params['alpha'],\n        'colsample_bytree': study.best_params['colsample_bytree'],\n        'subsample': study.best_params['subsample'],\n        'learning_rate': study.best_params['learning_rate'],\n        'n_estimators': 500,\n        'max_depth': study.best_params['max_depth'],\n        'random_state': study.best_params['random_state'],\n        'min_child_weight': study.best_params['min_child_weight'],\n    }\n\n\nmodel = XGBClassifier(**param)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, random_state = 123, shuffle = True)\ndel X, y\n\nmodel.fit(X_train, y_train, eval_set=[(X_val,y_val)], early_stopping_rounds = 20, verbose = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation prediction\ny_pred = model.predict(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation accuracy\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy Score : ',accuracy_score(y_val, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test prediction\ny_pred = model.predict(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission\nsubmission = pd.read_csv('../input/tabular-playground-series-dec-2021/sample_submission.csv')\nsubmission['Cover_Type'] = y_pred\nsubmission.to_csv(\"submission.csv\",index=False)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}