{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-02T12:12:15.259328Z","iopub.execute_input":"2021-12-02T12:12:15.260068Z","iopub.status.idle":"2021-12-02T12:12:15.288275Z","shell.execute_reply.started":"2021-12-02T12:12:15.259961Z","shell.execute_reply":"2021-12-02T12:12:15.287557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport gc\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom skopt.space import Real, Categorical, Integer\nfrom skopt import BayesSearchCV\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:15.289933Z","iopub.execute_input":"2021-12-02T12:12:15.290411Z","iopub.status.idle":"2021-12-02T12:12:16.362286Z","shell.execute_reply.started":"2021-12-02T12:12:15.290375Z","shell.execute_reply":"2021-12-02T12:12:16.361556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the train data set\ntrain = pd.read_csv('../input/tabular-playground-series-dec-2021/train.csv', index_col='Id')\n# Load the test data set only when needed, to avoid using up too much memory\n#test = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv', index_col='Id')","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:16.365452Z","iopub.execute_input":"2021-12-02T12:12:16.365652Z","iopub.status.idle":"2021-12-02T12:12:33.485034Z","shell.execute_reply.started":"2021-12-02T12:12:16.365627Z","shell.execute_reply":"2021-12-02T12:12:33.484309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns='Cover_Type')\ny = train['Cover_Type']\n\ndel train\ngc.collect()\n\nX","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:33.48701Z","iopub.execute_input":"2021-12-02T12:12:33.487276Z","iopub.status.idle":"2021-12-02T12:12:34.503192Z","shell.execute_reply.started":"2021-12-02T12:12:33.487242Z","shell.execute_reply":"2021-12-02T12:12:34.502484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finding how many classes in the target and how often they appear\nb = []\nfor i in y.unique():\n    a = y==i\n    b.append(a.sum())\n    \ny.unique(),b","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:34.504459Z","iopub.execute_input":"2021-12-02T12:12:34.504867Z","iopub.status.idle":"2021-12-02T12:12:34.603609Z","shell.execute_reply.started":"2021-12-02T12:12:34.50483Z","shell.execute_reply":"2021-12-02T12:12:34.602939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# So the entry 5 appears only once in y, let's remove it.\nr_ind = y[y==5].index[0]\ny=y.drop(labels=r_ind)\nX=X.drop(labels=r_ind)\n\ny.unique(),X.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:34.604863Z","iopub.execute_input":"2021-12-02T12:12:34.605114Z","iopub.status.idle":"2021-12-02T12:12:35.726257Z","shell.execute_reply.started":"2021-12-02T12:12:34.605072Z","shell.execute_reply":"2021-12-02T12:12:35.725394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.isnull().sum(), X.dtypes, X.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:35.727746Z","iopub.execute_input":"2021-12-02T12:12:35.728009Z","iopub.status.idle":"2021-12-02T12:12:37.014089Z","shell.execute_reply.started":"2021-12-02T12:12:35.727975Z","shell.execute_reply":"2021-12-02T12:12:37.013037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some features are constant, let's remove them\ndrop_cols = [col for col in X.columns if X[col].nunique() == 1]\nX = X.drop(columns=drop_cols)\nX","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:37.015444Z","iopub.execute_input":"2021-12-02T12:12:37.015721Z","iopub.status.idle":"2021-12-02T12:12:38.94479Z","shell.execute_reply.started":"2021-12-02T12:12:37.015686Z","shell.execute_reply":"2021-12-02T12:12:38.944027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data set\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.4, test_size=0.6, stratify=y, random_state=7)\n\ndel X\ngc.collect()\n\nX_train","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:38.946288Z","iopub.execute_input":"2021-12-02T12:12:38.946565Z","iopub.status.idle":"2021-12-02T12:12:40.494588Z","shell.execute_reply.started":"2021-12-02T12:12:38.946527Z","shell.execute_reply":"2021-12-02T12:12:40.493905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val.unique(), y_train.unique()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:40.497334Z","iopub.execute_input":"2021-12-02T12:12:40.497845Z","iopub.status.idle":"2021-12-02T12:12:40.508722Z","shell.execute_reply.started":"2021-12-02T12:12:40.497805Z","shell.execute_reply":"2021-12-02T12:12:40.507837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's make two lists, one with only one-hot-encoded features, the other with the rest\noh_cols = [col for col in X_train.columns if X_train[col].nunique()==2]\nn_oh_cols = [col for col in X_train.columns if X_train[col].nunique()>2]\n\n# this should be zero\nlen(n_oh_cols)+len(oh_cols)-len(X_train.columns) ","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:40.510071Z","iopub.execute_input":"2021-12-02T12:12:40.510334Z","iopub.status.idle":"2021-12-02T12:12:40.731883Z","shell.execute_reply.started":"2021-12-02T12:12:40.510301Z","shell.execute_reply":"2021-12-02T12:12:40.731071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalising the non-enconded features\nsc = StandardScaler()\nprep = ColumnTransformer([('sc', sc, n_oh_cols)], remainder='passthrough')\n\n# Define model\nmodel = XGBClassifier(tree_method='gpu_hist', use_label_encoder=False, eval_metric='merror', random_state=7)\n\n# Define pipeline\npipe = Pipeline(steps=[('preprocessing', prep),('model', model)])","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:40.733324Z","iopub.execute_input":"2021-12-02T12:12:40.73359Z","iopub.status.idle":"2021-12-02T12:12:40.738927Z","shell.execute_reply.started":"2021-12-02T12:12:40.733548Z","shell.execute_reply":"2021-12-02T12:12:40.738002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The target needs to be properly enconded, i.e. give 0, 1, 2,...\nle = LabelEncoder()\ny_train = pd.Series(le.fit_transform(y_train))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:40.740431Z","iopub.execute_input":"2021-12-02T12:12:40.740731Z","iopub.status.idle":"2021-12-02T12:12:40.762503Z","shell.execute_reply.started":"2021-12-02T12:12:40.740692Z","shell.execute_reply":"2021-12-02T12:12:40.761882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's scan through different sets of hyperparameters using BayesSearchScan\nsearch_spaces = {'model__n_estimators': Integer(400, 1200),'model__learning_rate': Real(0.006, 0.21, 'log-uniform'), 'model__max_depth': Integer(3, 12), \n                 'model__subsample': Real(0.1, 1, 'log-uniform')}\n\n# for cross validation with 5 splits, using StratifiedKFold to keep the same percentage of sample per each class\n# skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n\n# defining a Bayes scan, n_iter=50 (picks 50 scenarios), using 'accuracy' and the scoring method\nsearch_bay = BayesSearchCV(pipe, search_spaces, n_iter=20, scoring='accuracy', cv=5, random_state=7)\nsearch_bay.total_iterations","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:40.763748Z","iopub.execute_input":"2021-12-02T12:12:40.763994Z","iopub.status.idle":"2021-12-02T12:12:40.776107Z","shell.execute_reply.started":"2021-12-02T12:12:40.763962Z","shell.execute_reply":"2021-12-02T12:12:40.775082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# start counting how long the fitting takes\nstart = time.time()\n\n# fit with the whole dataset\nresult_bay = search_bay.fit(X_train, y_train)\n\ndel X_train\ndel y_train\ngc.collect()\n\n\n# print the best score and parameters found during the scan\nprint(\"(Bayes) Best: %f using %s\" % (result_bay.best_score_, result_bay.best_params_))\nelapsed = time.time() - start\nprint(\"Time to run the scan: %f\" % (elapsed))","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:12:40.77754Z","iopub.execute_input":"2021-12-02T12:12:40.777977Z","iopub.status.idle":"2021-12-02T12:21:37.019887Z","shell.execute_reply.started":"2021-12-02T12:12:40.777936Z","shell.execute_reply":"2021-12-02T12:21:37.018163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In order to use b_result.best_params_ in the next model, we need to remove \"model__\" from the keys\nbest_parameters_bay = dict(result_bay.best_params_.copy())\n\nfor k in best_parameters_bay.keys():\n    best_parameters_bay[k.replace(\"model__\",\"\")] = best_parameters_bay.pop(k)\n\n# for some reason, the loop is not replacing two model__ instances, so we do it one by one\nbest_parameters_bay['n_estimators'] = best_parameters_bay.pop('model__n_estimators')\nbest_parameters_bay['subsample'] = best_parameters_bay.pop('model__subsample')\n\nbest_parameters_bay","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:21:37.021264Z","iopub.execute_input":"2021-12-02T12:21:37.021585Z","iopub.status.idle":"2021-12-02T12:21:37.029192Z","shell.execute_reply.started":"2021-12-02T12:21:37.021547Z","shell.execute_reply":"2021-12-02T12:21:37.028484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now, we fit using the role train data and the best parameters in the scan\nmodel_opt = XGBClassifier(**best_parameters_bay, eval_metric='error', use_label_encoder=False, tree_method='gpu_hist')\n\n# Defining the pipeline with the same preprocessing as before, but with the tuned model\npipe_opt = Pipeline(steps=[('preprocessing', prep), ('model', model_opt)])\n\n#transform y_val according to the encoding applied to y_train\ny_val = pd.Series(le.transform(y_val))\n# Fitting the whole dataset\npipe_opt.fit(X_val, y_val)\n\ndel X_val\ndel y_val\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:21:37.030277Z","iopub.execute_input":"2021-12-02T12:21:37.03072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### We calculate and store the probability of the positive prediction\nX_test = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv', index_col='Id')\n\n# drop the columns dropped in the train set\nX_test = X_test.drop(columns=drop_cols)\n\npred_test = pipe_opt.predict(X_test)\n# inverse transform the results to the original enconding and submit\npred_test = pd.Series(le.inverse_transform(pred_test))\n\noutput = pd.DataFrame({'Id': X_test.index,\n                       'Cover_Type': pred_test})\noutput.to_csv('submission_TPS-21-21.csv', index=False)\n\noutput","metadata":{"execution":{"iopub.status.idle":"2021-12-02T12:27:17.885948Z","shell.execute_reply.started":"2021-12-02T12:23:36.410517Z","shell.execute_reply":"2021-12-02T12:27:17.885263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # fit and predict\n# pipe.fit(X_train, y_train)\n\n# pred = pipe.predict(X_val)\n\n# # to compare we need to transform y_val according to the label enconding on y_train\n# y_val = pd.Series(le.transform(y_val))\n\n# score =  accuracy_score(y_val,pred)\n# score","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:27:17.887386Z","iopub.execute_input":"2021-12-02T12:27:17.887615Z","iopub.status.idle":"2021-12-02T12:27:17.891841Z","shell.execute_reply.started":"2021-12-02T12:27:17.887582Z","shell.execute_reply":"2021-12-02T12:27:17.89102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # competition score, 1st model, 0.95224 with train_size=0.8\n\n# # load the test set\n# X_test = pd.read_csv('../input/tabular-playground-series-dec-2021/test.csv', index_col='Id')\n\n# # drop the columns dropped in the train set\n# X_test = X_test.drop(columns=drop_cols)\n# # predict results\n# pred_test = pipe.predict(X_test)\n\n# # inverse transform the results to the original enconding and submit\n# pred_test = pd.Series(le.inverse_transform(pred_test))\n\n# output = pd.DataFrame({'Id': X_test.index,\n#                        'Cover_Type': pred_test})\n# output.to_csv('submission_TPS-12-21.csv', index=False)\n\n\n# output","metadata":{"execution":{"iopub.status.busy":"2021-12-02T12:27:17.893243Z","iopub.execute_input":"2021-12-02T12:27:17.893459Z","iopub.status.idle":"2021-12-02T12:27:17.903877Z","shell.execute_reply.started":"2021-12-02T12:27:17.893432Z","shell.execute_reply":"2021-12-02T12:27:17.903124Z"},"trusted":true},"execution_count":null,"outputs":[]}]}