{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pyarrow\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option(\"display.max_columns\",100)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport random\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.feature_selection import f_classif, chi2, mutual_info_classif\nfrom sklearn.preprocessing import StandardScaler, QuantileTransformer, RobustScaler, PowerTransformer, MinMaxScaler\n\n#plt.rcParams['figure.dpi'] = 600\nsns.set(rc={'figure.figsize':(6,6)})\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-28T21:35:48.462802Z","iopub.execute_input":"2022-01-28T21:35:48.464737Z","iopub.status.idle":"2022-01-28T21:35:49.933444Z","shell.execute_reply.started":"2022-01-28T21:35:48.464601Z","shell.execute_reply":"2022-01-28T21:35:49.932485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.layers import Dense, Dropout,BatchNormalization, AlphaDropout\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import backend as K\nimport keras_tuner as kt\nfrom kerastuner import BayesianOptimization\nimport os\nfrom kaggle_datasets import KaggleDatasets","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:35:49.93602Z","iopub.execute_input":"2022-01-28T21:35:49.936343Z","iopub.status.idle":"2022-01-28T21:35:56.02117Z","shell.execute_reply.started":"2022-01-28T21:35:49.936299Z","shell.execute_reply":"2022-01-28T21:35:56.020219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:35:56.023107Z","iopub.execute_input":"2022-01-28T21:35:56.023422Z","iopub.status.idle":"2022-01-28T21:35:56.032807Z","shell.execute_reply.started":"2022-01-28T21:35:56.02338Z","shell.execute_reply":"2022-01-28T21:35:56.031216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_all_seeds(seed):\n    random.seed(seed) #python\n    np.random.seed(seed) #numpy\n    tf.random.set_seed(seed) # tf global seed\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Seed set to: {seed}\")\nseed = set_all_seeds(42)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:35:56.037298Z","iopub.execute_input":"2022-01-28T21:35:56.038276Z","iopub.status.idle":"2022-01-28T21:35:56.05393Z","shell.execute_reply.started":"2022-01-28T21:35:56.038221Z","shell.execute_reply":"2022-01-28T21:35:56.052673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-dec-2021/train.csv\", index_col=\"Id\")\ntest = pd.read_csv(\"../input/tabular-playground-series-dec-2021/test.csv\", index_col=\"Id\")\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:35:56.056026Z","iopub.execute_input":"2022-01-28T21:35:56.05648Z","iopub.status.idle":"2022-01-28T21:36:21.025356Z","shell.execute_reply.started":"2022-01-28T21:35:56.056416Z","shell.execute_reply":"2022-01-28T21:36:21.024361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train.Cover_Type.value_counts()/ train.shape[0])*100","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:21.026866Z","iopub.execute_input":"2022-01-28T21:36:21.027192Z","iopub.status.idle":"2022-01-28T21:36:21.066993Z","shell.execute_reply.started":"2022-01-28T21:36:21.027145Z","shell.execute_reply":"2022-01-28T21:36:21.066029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[(train.Cover_Type != 4) & (train.Cover_Type != 5)].reset_index()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:21.069157Z","iopub.execute_input":"2022-01-28T21:36:21.069529Z","iopub.status.idle":"2022-01-28T21:36:22.829418Z","shell.execute_reply.started":"2022-01-28T21:36:21.069452Z","shell.execute_reply":"2022-01-28T21:36:22.828455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = [col for col in train.columns if (str(col).startswith(\"W\") | str(col).startswith(\"Soil\"))]\nnum_cols = [col for col in train.columns if (col not in cat_cols + [\"Cover_Type\"])]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:22.831097Z","iopub.execute_input":"2022-01-28T21:36:22.831405Z","iopub.status.idle":"2022-01-28T21:36:23.019985Z","shell.execute_reply.started":"2022-01-28T21:36:22.831366Z","shell.execute_reply":"2022-01-28T21:36:23.018601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Manhhattan distance to Hydrology\ntrain[\"mnhttn_dist_hydrlgy\"] = np.abs(train[\"Horizontal_Distance_To_Hydrology\"]) + np.abs(train[\"Vertical_Distance_To_Hydrology\"])\ntest[\"mnhttn_dist_hydrlgy\"] = np.abs(test[\"Horizontal_Distance_To_Hydrology\"]) + np.abs(test[\"Vertical_Distance_To_Hydrology\"])\n\n# Euclidean distance to Hydrology\ntrain[\"ecldn_dist_hydrlgy\"] = (train[\"Horizontal_Distance_To_Hydrology\"]**2 + train[\"Vertical_Distance_To_Hydrology\"]**2)**0.5\ntest[\"ecldn_dist_hydrlgy\"] = (test[\"Horizontal_Distance_To_Hydrology\"]**2 + test[\"Vertical_Distance_To_Hydrology\"]**2)**0.5","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:23.021804Z","iopub.execute_input":"2022-01-28T21:36:23.022433Z","iopub.status.idle":"2022-01-28T21:36:23.228801Z","shell.execute_reply.started":"2022-01-28T21:36:23.022376Z","shell.execute_reply":"2022-01-28T21:36:23.227838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hillshades = [col for col in train.columns if col.startswith('Hillshade')]\ntrain[hillshades] = train[hillshades].clip(0, 255)\ntest[hillshades] = test[hillshades].clip(0, 255)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:23.233569Z","iopub.execute_input":"2022-01-28T21:36:23.233831Z","iopub.status.idle":"2022-01-28T21:36:25.805755Z","shell.execute_reply.started":"2022-01-28T21:36:23.233797Z","shell.execute_reply":"2022-01-28T21:36:25.804567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Aspect\"][train[\"Aspect\"] < 0] = 360 - train[\"Aspect\"]\ntrain[\"Aspect\"][train[\"Aspect\"] > 359] = train[\"Aspect\"] - 360\n\ntest[\"Aspect\"][test[\"Aspect\"] < 0] = 360 - test[\"Aspect\"]\ntest[\"Aspect\"][test[\"Aspect\"] > 359] = test[\"Aspect\"] - 360\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:25.810718Z","iopub.execute_input":"2022-01-28T21:36:25.811041Z","iopub.status.idle":"2022-01-28T21:36:26.144435Z","shell.execute_reply.started":"2022-01-28T21:36:25.810996Z","shell.execute_reply":"2022-01-28T21:36:26.143524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_Hillshade = ['Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n\ntrain[\"Hillshade_mean\"] = train[features_Hillshade].mean(axis=1)\ntrain['amp_Hillshade'] = train[features_Hillshade].max(axis=1) - train[features_Hillshade].min(axis=1)\n\ntest[\"Hillshade_mean\"] = test[features_Hillshade].mean(axis=1)\ntest['amp_Hillshade'] = test[features_Hillshade].max(axis=1) - test[features_Hillshade].min(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:26.145908Z","iopub.execute_input":"2022-01-28T21:36:26.146259Z","iopub.status.idle":"2022-01-28T21:36:26.433022Z","shell.execute_reply.started":"2022-01-28T21:36:26.146215Z","shell.execute_reply":"2022-01-28T21:36:26.431955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Soil type count\nsoil_features = [col for col in train.columns if col.startswith(\"Soil\")]\ntrain[\"soil_type_count\"] = train[soil_features].sum(axis=1)\ntest[\"soil_type_count\"] = test[soil_features].sum(axis=1)\n\n# Wilderness area count\nwilderness_features = [col for col in train.columns if col.startswith(\"Wild\")]\ntrain[\"wilderness_area_count\"] = train[wilderness_features].sum(axis=1)\ntest[\"wilderness_area_count\"] = test[wilderness_features].sum(axis=1)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:26.434666Z","iopub.execute_input":"2022-01-28T21:36:26.435014Z","iopub.status.idle":"2022-01-28T21:36:31.126511Z","shell.execute_reply.started":"2022-01-28T21:36:26.434954Z","shell.execute_reply":"2022-01-28T21:36:31.12541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(\"Id\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:31.128047Z","iopub.execute_input":"2022-01-28T21:36:31.128496Z","iopub.status.idle":"2022-01-28T21:36:33.274475Z","shell.execute_reply.started":"2022-01-28T21:36:31.128425Z","shell.execute_reply":"2022-01-28T21:36:33.273532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_cols = num_cols + [\"soil_type_count\", \"wilderness_area_count\", \"Hillshade_mean\",\"amp_Hillshade\", \n                       \"mnhttn_dist_hydrlgy\", \"ecldn_dist_hydrlgy\"]\nnum_cols.remove(\"Id\")\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:33.276096Z","iopub.execute_input":"2022-01-28T21:36:33.276401Z","iopub.status.idle":"2022-01-28T21:36:33.47002Z","shell.execute_reply.started":"2022-01-28T21:36:33.276353Z","shell.execute_reply":"2022-01-28T21:36:33.46896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ny=train[\"Cover_Type\"].copy()\nencoder = LabelEncoder()\ny = encoder.fit_transform(y)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:33.471695Z","iopub.execute_input":"2022-01-28T21:36:33.472769Z","iopub.status.idle":"2022-01-28T21:36:33.8998Z","shell.execute_reply.started":"2022-01-28T21:36:33.47272Z","shell.execute_reply":"2022-01-28T21:36:33.89867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop([\"Soil_Type7\", \"Soil_Type15\"], axis=1, inplace=True)\ntest.drop([\"Soil_Type7\", \"Soil_Type15\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:33.901512Z","iopub.execute_input":"2022-01-28T21:36:33.901947Z","iopub.status.idle":"2022-01-28T21:36:34.977196Z","shell.execute_reply.started":"2022-01-28T21:36:33.901898Z","shell.execute_reply":"2022-01-28T21:36:34.974901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(\"Cover_Type\", axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.978749Z","iopub.status.idle":"2022-01-28T21:36:34.979529Z","shell.execute_reply.started":"2022-01-28T21:36:34.979187Z","shell.execute_reply":"2022-01-28T21:36:34.979224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.981894Z","iopub.status.idle":"2022-01-28T21:36:34.982665Z","shell.execute_reply.started":"2022-01-28T21:36:34.982323Z","shell.execute_reply":"2022-01-28T21:36:34.982359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.984114Z","iopub.status.idle":"2022-01-28T21:36:34.984903Z","shell.execute_reply.started":"2022-01-28T21:36:34.984593Z","shell.execute_reply":"2022-01-28T21:36:34.984628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n \n    return df","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-01-28T21:36:34.986367Z","iopub.status.idle":"2022-01-28T21:36:34.987143Z","shell.execute_reply.started":"2022-01-28T21:36:34.986822Z","shell.execute_reply":"2022-01-28T21:36:34.986859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = reduce_mem_usage(X, verbose=True)\ntest = reduce_mem_usage(test, verbose=True)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.988611Z","iopub.status.idle":"2022-01-28T21:36:34.989369Z","shell.execute_reply.started":"2022-01-28T21:36:34.989025Z","shell.execute_reply":"2022-01-28T21:36:34.989061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.1, random_state=42, shuffle=True, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.990882Z","iopub.status.idle":"2022-01-28T21:36:34.991699Z","shell.execute_reply.started":"2022-01-28T21:36:34.991325Z","shell.execute_reply":"2022-01-28T21:36:34.991362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = RobustScaler()\nX_train[num_cols] = scaler.fit_transform(X_train[num_cols])\nX_valid[num_cols] = scaler.transform(X_valid[num_cols])\n#test[num_cols] = scaler.transform(test[num_cols])","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.993175Z","iopub.status.idle":"2022-01-28T21:36:34.993944Z","shell.execute_reply.started":"2022-01-28T21:36:34.993633Z","shell.execute_reply":"2022-01-28T21:36:34.993671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.995423Z","iopub.status.idle":"2022-01-28T21:36:34.996199Z","shell.execute_reply.started":"2022-01-28T21:36:34.995883Z","shell.execute_reply":"2022-01-28T21:36:34.99592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.5, patience=4,mode='max', verbose=0)\nes = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=10, restore_best_weights=True) \n\ndef my_model(X):   \n    model = Sequential()\n    model.add(Dense(256, activation= \"relu\",input_dim=X.shape[1]))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.082208))\n\n    model.add(Dense(128, activation= \"relu\"))\n    model.add(BatchNormalization())   \n\n    model.add(Dense(64, activation= \"relu\"))\n    model.add(BatchNormalization())\n\n    model.add(Dense(32, activation= \"relu\"))\n    model.add(BatchNormalization())    \n\n    model.add(Dense(len(encoder.classes_), activation= \"softmax\"))\n\n    model.compile(optimizer=Adam(lr= 0.026257),\n                  loss=\"sparse_categorical_crossentropy\",\n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.997733Z","iopub.status.idle":"2022-01-28T21:36:34.998491Z","shell.execute_reply.started":"2022-01-28T21:36:34.998157Z","shell.execute_reply":"2022-01-28T21:36:34.998193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nmodel= my_model(X_train)\nhistory = model.fit(X_train, y_train,\n                    validation_data = (X_valid, y_valid),callbacks=[es,reduce_lr ],\n                    validation_batch_size=len(X_valid),                   \n                    epochs=60, batch_size=2048, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:34.99996Z","iopub.status.idle":"2022-01-28T21:36:35.000726Z","shell.execute_reply.started":"2022-01-28T21:36:35.00038Z","shell.execute_reply":"2022-01-28T21:36:35.000417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss,acc = model.evaluate(X_valid, y_valid)\nprint(\"Accuracy\",(acc*100), \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.002178Z","iopub.status.idle":"2022-01-28T21:36:35.002951Z","shell.execute_reply.started":"2022-01-28T21:36:35.002636Z","shell.execute_reply":"2022-01-28T21:36:35.002673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_eval = pd.DataFrame({'train_loss': history.history['loss'], 'val_loss': history.history['val_loss'],\n                       'train_accuracy': history.history['accuracy'], 'val_accuracy': history.history['val_accuracy']})\n\nplt.plot(df_eval[[\"train_loss\", \"val_loss\"]], label=[\"Train\",\"Valid\"])\nplt.legend()\nplt.title(\"Loss\")","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.004422Z","iopub.status.idle":"2022-01-28T21:36:35.005195Z","shell.execute_reply.started":"2022-01-28T21:36:35.004878Z","shell.execute_reply":"2022-01-28T21:36:35.004914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nplt.plot(df_eval[[\"train_accuracy\", \"val_accuracy\"]], label=[\"Train\",\"Valid\"])\nplt.title(\"Accuracy\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.006695Z","iopub.status.idle":"2022-01-28T21:36:35.007432Z","shell.execute_reply.started":"2022-01-28T21:36:35.007118Z","shell.execute_reply":"2022-01-28T21:36:35.007156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\npred_valid = np.argmax(model.predict(X_valid, batch_size=1024), axis=1)\ncm=confusion_matrix(y_valid, np.argmax(model.predict(X_valid, batch_size=1024), axis=1))\ncm = pd.DataFrame(cm, columns=encoder.classes_, index=encoder.classes_)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.008928Z","iopub.status.idle":"2022-01-28T21:36:35.009699Z","shell.execute_reply.started":"2022-01-28T21:36:35.009353Z","shell.execute_reply":"2022-01-28T21:36:35.00939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nplt.figure(figsize=(10,5))\nsns.heatmap(cm, annot=True,fmt='.0f' ,cbar = False)\nplt.title('Confusion Matrix')\nplt.ylabel('Actual Values')\nplt.xlabel('Predicted Values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.011164Z","iopub.status.idle":"2022-01-28T21:36:35.011922Z","shell.execute_reply.started":"2022-01-28T21:36:35.011616Z","shell.execute_reply":"2022-01-28T21:36:35.011652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del model\nK.clear_session()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.013408Z","iopub.status.idle":"2022-01-28T21:36:35.014175Z","shell.execute_reply.started":"2022-01-28T21:36:35.013867Z","shell.execute_reply":"2022-01-28T21:36:35.013904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\ngc.collect()\ngc.collect()\ngc.collect()\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\nscores = {fold:None for fold in range(cv.n_splits)}\ntest_preds = []\n\n\nfor fold, (idx_train, idx_valid) in enumerate(cv.split(X, y)):\n    \n    X_train, X_valid = X.iloc[idx_train], X.iloc[idx_valid]\n    y_train, y_valid = y[idx_train], y[idx_valid]\n    \n    scaler = RobustScaler()\n    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n    X_valid[num_cols] = scaler.transform(X_valid[num_cols])\n    test_sc = test.copy()\n    test_sc[num_cols] = scaler.transform(test_sc[num_cols])\n    \n    model = my_model(X_train)   \n    history = model.fit(X_train, y_train,\n                        validation_data = (X_valid, y_valid),\n                        validation_batch_size=len(X_valid),\n                        epochs=60, batch_size=2048,\n                        callbacks=[es,reduce_lr],\n                        shuffle=True,\n                        verbose=0     )\n    gc.collect()\n    \n    scores[fold] = (history.history)\n    \n    print(f\"Fold {fold} -- Max Training AUC: {np.max(scores[fold]['accuracy']):.5f} -- Max Validation AUC: {np.max(scores[fold]['val_accuracy']):.5f}\")\n    \n    test_preds.append(model.predict(test_sc, batch_size=2048))\n    \nprint('**'*20)\ngc.collect()\n\noverall_train_auc = [np.max(scores[fold]['accuracy']) for fold in range(cv.n_splits)]\noverall_valid_auc = [np.max(scores[fold]['val_accuracy']) for fold in range(cv.n_splits)]\nprint(f\"Overall Mean Train AUC: {np.mean(overall_train_auc)} -- Overall Mean Validation AUC: {np.mean(overall_valid_auc)}\")\n\ndel model\nK.clear_session()\ngc.collect()\ngc.collect()\ngc.collect()\ngc.collect()\ngc.collect()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.015671Z","iopub.status.idle":"2022-01-28T21:36:35.016411Z","shell.execute_reply.started":"2022-01-28T21:36:35.016098Z","shell.execute_reply":"2022-01-28T21:36:35.016135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\n\nfor fold in range(10):\n    df_eval = pd.DataFrame({'train_loss': scores[fold]['loss'], 'val_loss': scores[fold]['val_loss'],\n                       'train_auc': scores[fold]['accuracy'], 'val_auc': scores[fold]['val_accuracy']})\n    \n    fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(10,4))\n    fig.suptitle('Fold : '+str(fold), fontsize=14)\n    \n    plt.subplot(1,2,1)\n    plt.plot(df_eval[[\"train_loss\", \"val_loss\"]], label=[\"Train\",\"Valid\"])\n    plt.legend()\n    plt.title(\"Loss\")\n    \n    plt.subplot(1,2,2)\n    plt.plot(df_eval[[\"train_auc\", \"val_auc\"]], label=[\"Train\",\"Valid\"])\n    plt.title(\"Accuracy\")\n    plt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.017905Z","iopub.status.idle":"2022-01-28T21:36:35.018674Z","shell.execute_reply.started":"2022-01-28T21:36:35.018325Z","shell.execute_reply":"2022-01-28T21:36:35.018361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nsample_submission=pd.read_csv(\"../input/tabular-playground-series-dec-2021/sample_submission.csv\")\nsample_submission['Cover_Type'] = encoder.inverse_transform(np.argmax(sum(test_preds), axis=1)) \nsample_submission.to_csv('./nn_model_not_normalized_robust_10fold.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.020119Z","iopub.status.idle":"2022-01-28T21:36:35.02088Z","shell.execute_reply.started":"2022-01-28T21:36:35.020569Z","shell.execute_reply":"2022-01-28T21:36:35.020603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nplt.figure(figsize=(10,5))\nax = sns.countplot(x=sample_submission.Cover_Type)\nplt.title(\"Predictions\")\nplt.xlabel(\"Cover Type\")\nax.bar_label(ax.containers[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.02237Z","iopub.status.idle":"2022-01-28T21:36:35.023141Z","shell.execute_reply.started":"2022-01-28T21:36:35.022827Z","shell.execute_reply":"2022-01-28T21:36:35.022864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nsample_submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-28T21:36:35.024622Z","iopub.status.idle":"2022-01-28T21:36:35.02539Z","shell.execute_reply.started":"2022-01-28T21:36:35.025069Z","shell.execute_reply":"2022-01-28T21:36:35.025118Z"},"trusted":true},"execution_count":null,"outputs":[]}]}