{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-13T21:16:43.285716Z","iopub.execute_input":"2022-04-13T21:16:43.28647Z","iopub.status.idle":"2022-04-13T21:16:43.319019Z","shell.execute_reply.started":"2022-04-13T21:16:43.286325Z","shell.execute_reply":"2022-04-13T21:16:43.318106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"# for data visualization\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('bmh')\nimport seaborn as sns\nimport missingno as msno\n\n# for pre-processing\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer, make_column_selector\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# for machine learning modelling\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\n\n\n# for ignoring warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:16:43.621657Z","iopub.execute_input":"2022-04-13T21:16:43.622317Z","iopub.status.idle":"2022-04-13T21:16:46.326019Z","shell.execute_reply.started":"2022-04-13T21:16:43.622269Z","shell.execute_reply":"2022-04-13T21:16:46.32481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Datasets","metadata":{}},{"cell_type":"markdown","source":"- After a careful study and consideration of all given files and the goal of the problem, we can notice that most files contain info about the `previous loans`, which means if we depend on these info, our model will `struggle in generalization` with new clients with `no previous loans experience or info`, so we will try to make the best use of `only application info` to make a model can generalize well.","metadata":{}},{"cell_type":"code","source":"# training dataset\ntrain_df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv', index_col='SK_ID_CURR')\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:16:46.327846Z","iopub.execute_input":"2022-04-13T21:16:46.328134Z","iopub.status.idle":"2022-04-13T21:16:52.443566Z","shell.execute_reply.started":"2022-04-13T21:16:46.328103Z","shell.execute_reply":"2022-04-13T21:16:52.442531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing dataset\ntest_df = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv', index_col='SK_ID_CURR')\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:16:52.445056Z","iopub.execute_input":"2022-04-13T21:16:52.445637Z","iopub.status.idle":"2022-04-13T21:16:53.371551Z","shell.execute_reply.started":"2022-04-13T21:16:52.445592Z","shell.execute_reply":"2022-04-13T21:16:53.370646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets sizes\nprint(f'Training dataset contains {train_df.shape[0]} records and {train_df.shape[1]} columns.')\nprint(f'Testing dataset contains {test_df.shape[0]} records and {test_df.shape[1]} columns.')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:16:53.373321Z","iopub.execute_input":"2022-04-13T21:16:53.373565Z","iopub.status.idle":"2022-04-13T21:16:53.379628Z","shell.execute_reply.started":"2022-04-13T21:16:53.373525Z","shell.execute_reply":"2022-04-13T21:16:53.378629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"#### Check Missing Values (NaNs) ","metadata":{}},{"cell_type":"code","source":"# all NaNs\nprint(f'Total training NaNs = {train_df.isnull().sum().sum()}')\nprint(f'Total Testing NaNs = {test_df.isnull().sum().sum()}')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:16:53.380715Z","iopub.execute_input":"2022-04-13T21:16:53.380936Z","iopub.status.idle":"2022-04-13T21:16:53.691345Z","shell.execute_reply.started":"2022-04-13T21:16:53.38091Z","shell.execute_reply":"2022-04-13T21:16:53.690424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only columns with NaNs count and percentage\ncolumns = train_df.isnull().sum()[train_df.isnull().sum() != 0].keys()\nnans_count = train_df.isnull().sum()[train_df.isnull().sum() != 0].values\nnans_percentage = train_df.isnull().sum()[train_df.isnull().sum() != 0].values/train_df.shape[0]\n\n# create a dataframe from the extracted info. \nnans_df = pd.DataFrame({'Column':columns, 'No. of NaNs':nans_count, '% of NaNs in Column':nans_percentage*100})\nnans_df = nans_df.sort_values(by='% of NaNs in Column', ascending=False)\nnans_df","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:16:53.692836Z","iopub.execute_input":"2022-04-13T21:16:53.693318Z","iopub.status.idle":"2022-04-13T21:16:55.243751Z","shell.execute_reply.started":"2022-04-13T21:16:53.693271Z","shell.execute_reply":"2022-04-13T21:16:55.24302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize columns with NaNs distribution over target\nmsno.matrix(train_df[list(columns)+['TARGET']].sort_values(by='TARGET'))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:16:55.244856Z","iopub.execute_input":"2022-04-13T21:16:55.245194Z","iopub.status.idle":"2022-04-13T21:17:02.431454Z","shell.execute_reply.started":"2022-04-13T21:16:55.245167Z","shell.execute_reply":"2022-04-13T21:17:02.430586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- NaNs distribution is random, so imputations won't be biased towards certain target class.\n- Columns with large percentage of NaNs (> 40%) will be dropped.\n- Other columns will be imputed according the column dtype.","metadata":{}},{"cell_type":"markdown","source":"#### Check Duplicates","metadata":{}},{"cell_type":"code","source":"# sum of all duplicated records in data\ntrain_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:02.433098Z","iopub.execute_input":"2022-04-13T21:17:02.433614Z","iopub.status.idle":"2022-04-13T21:17:03.950726Z","shell.execute_reply.started":"2022-04-13T21:17:02.433568Z","shell.execute_reply":"2022-04-13T21:17:03.949722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- No duplicates in our dataset","metadata":{}},{"cell_type":"markdown","source":"#### Check Target Column","metadata":{}},{"cell_type":"code","source":"# target value counts per each class\nprint('Count of Each Class\\n' + '-'*20)\nprint(train_df['TARGET'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:03.952434Z","iopub.execute_input":"2022-04-13T21:17:03.95306Z","iopub.status.idle":"2022-04-13T21:17:03.963401Z","shell.execute_reply.started":"2022-04-13T21:17:03.953007Z","shell.execute_reply":"2022-04-13T21:17:03.962719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize TARGET value counts\ntrain_df['TARGET'].value_counts().plot(kind='bar');\nplt.title('Target Classes Value Counts')\nplt.xlabel('Target')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:03.965939Z","iopub.execute_input":"2022-04-13T21:17:03.966789Z","iopub.status.idle":"2022-04-13T21:17:04.169363Z","shell.execute_reply.started":"2022-04-13T21:17:03.966732Z","shell.execute_reply":"2022-04-13T21:17:04.168414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Most of clients can repay their loans, and a few are with difficulties, so data is `imbalanced`. In this case we must keep in mind 2 things:\n    - data should `be balanced`\n    - `accuracy is not a proper` evaluation metric, it will be misleading,but `F1-score or ROC AUC scores is proper` in this case.","metadata":{}},{"cell_type":"markdown","source":"#### Check Columns dtypes","metadata":{}},{"cell_type":"code","source":"# all columns dtypes\ntrain_df.dtypes.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:04.170945Z","iopub.execute_input":"2022-04-13T21:17:04.171274Z","iopub.status.idle":"2022-04-13T21:17:04.179994Z","shell.execute_reply.started":"2022-04-13T21:17:04.17123Z","shell.execute_reply":"2022-04-13T21:17:04.178949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# go deeper with object columns and extract the unique classes in each column\n## create a dataframe with object dtype columns\nunique_df = pd.DataFrame(train_df.select_dtypes('object').nunique()).reset_index()\nunique_df.columns = ['Column','No. of Unique Values']\n\n## extract the unique classes in each column\nunique_df['Unique Values'] = unique_df['Column'].apply(lambda x: train_df[x].unique())\nunique_df.sort_values(by='No. of Unique Values')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:04.181392Z","iopub.execute_input":"2022-04-13T21:17:04.18167Z","iopub.status.idle":"2022-04-13T21:17:04.823742Z","shell.execute_reply.started":"2022-04-13T21:17:04.181637Z","shell.execute_reply":"2022-04-13T21:17:04.822782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check CODE_GENDER column in training and testing datasets\nprint('Train Dataset')\nprint(train_df['CODE_GENDER'].value_counts())\n\nprint('\\nTest Dataset')\nprint(test_df['CODE_GENDER'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:04.825401Z","iopub.execute_input":"2022-04-13T21:17:04.825776Z","iopub.status.idle":"2022-04-13T21:17:04.854714Z","shell.execute_reply.started":"2022-04-13T21:17:04.825729Z","shell.execute_reply":"2022-04-13T21:17:04.853913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- CODE_GENDER with `XNA will be dropped` as it's only exists in 4 records and not exists in testing dataset.\n- All columns are `catagorical and nominal`, so the best encoding technique is `OneHotEncoding`, but it will increase our dimensions, so we will `drop first column` or may `use LabelEnconding`","metadata":{}},{"cell_type":"markdown","source":"### Columns Correlation","metadata":{}},{"cell_type":"code","source":"# Top 5 Columns with Positive Correlation with our TARGET \nprint('Top 5 Columns with Positive Correlation with TARGET\\n', '-'*50)\nprint(train_df.corr()['TARGET'].sort_values().tail(5))\n\n# Negative ones\nprint('\\nTop 5 Columns with Negative Correlation with TARGET\\n', '-'*50)\nprint(train_df.corr()['TARGET'].sort_values().head(5))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:04.856065Z","iopub.execute_input":"2022-04-13T21:17:04.856998Z","iopub.status.idle":"2022-04-13T21:17:26.878912Z","shell.execute_reply.started":"2022-04-13T21:17:04.856959Z","shell.execute_reply":"2022-04-13T21:17:26.877997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There's no high correlation between our target and any feature.\n- External data sources is so important with our target.","metadata":{}},{"cell_type":"markdown","source":"#### Detect Outliers","metadata":{}},{"cell_type":"code","source":"# extract continuous columns\nall_numerical_cols = list(train_df.select_dtypes(exclude='object').columns)\n\n# continuous  columns are all columns excluding target and flags columns\ncont_cols = [col for col in all_numerical_cols if col!=\"TARGET\" and col[:5]!='FLAG_']\nprint(f'No. of continuous features = {len(cont_cols)}')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:26.880148Z","iopub.execute_input":"2022-04-13T21:17:26.880399Z","iopub.status.idle":"2022-04-13T21:17:26.972485Z","shell.execute_reply.started":"2022-04-13T21:17:26.880368Z","shell.execute_reply":"2022-04-13T21:17:26.971416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# draw boxplots for each continuous column\nplt.figure(figsize=(25, 25))\nfor i, col in enumerate(cont_cols):\n    plt.subplot(16, 5, i+1)\n    sns.boxplot(data=train_df, x=col)\n    plt.title(col)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:26.974319Z","iopub.execute_input":"2022-04-13T21:17:26.974865Z","iopub.status.idle":"2022-04-13T21:17:40.236114Z","shell.execute_reply.started":"2022-04-13T21:17:26.974814Z","shell.execute_reply":"2022-04-13T21:17:40.234923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's go deeper in these columns\n## show only 20 columns at a time\nfor i in np.linspace(0,60,4, dtype=int):\n    if i == 60:\n        display(train_df[cont_cols[i:78]].describe())\n    else:\n        display(train_df[cont_cols[i:i+20]].describe())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:40.237761Z","iopub.execute_input":"2022-04-13T21:17:40.238255Z","iopub.status.idle":"2022-04-13T21:17:41.497136Z","shell.execute_reply.started":"2022-04-13T21:17:40.238216Z","shell.execute_reply":"2022-04-13T21:17:41.496283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Suspicious data:\n  - Tha maximum income of a the clients is about 30 times the maximum amount of the loans\n  - All days features are in negative values\n  - The maximum age of a client is 69 year\n  - The maximum value in days employed is positive not negative, a typo! <br> + it's about 1000 years, how come! + the minimum value is about 49 years! client work in the same job for 49 years!\n  - A clients own car with 91 age! was manufactured in 1927! \"with respect to the competition year 2018\"\n  - The minimum days before application did a client change phone is zero!\n\n\n- As shown almost all continous features have outliers, so we will either `normalize these features` if we use models sensitive to the outliers like Logestic Regression Model or use models that is not sensitive, less impacted and robust to outliers like `Tree-Based Models` or `deep neural network`.\n\n- Features with suspicious data will be analyzed well to clean the wrong data.","metadata":{}},{"cell_type":"markdown","source":"#### Going Deeper with Suspicious data\n- some points will need to create a new dataframe to analyze data better, so `susp_df` is a helpful dataframe for this purpose.","metadata":{}},{"cell_type":"code","source":"# 1- Tha maximum income of a the clients is about 30 times the maximum amount of the loans\n\n## create dataframe with total income > 1M\nsusp_df1 = train_df[train_df['AMT_INCOME_TOTAL']>1e+6][['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','CNT_CHILDREN', 'TARGET']].sort_values(by='AMT_INCOME_TOTAL', ascending=False)\n\n## create Credit/Income and Annuity/Income percentages\nsusp_df1['Credit/Income'] = susp_df1['AMT_CREDIT']/susp_df1['AMT_INCOME_TOTAL']\nsusp_df1['Annuity/Income'] = susp_df1['AMT_ANNUITY']/susp_df1['AMT_INCOME_TOTAL']\n\n## show only clients with difficuties\nsusp_df1[susp_df1['TARGET']==1].sort_values(by='Credit/Income', ascending=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:41.498576Z","iopub.execute_input":"2022-04-13T21:17:41.499061Z","iopub.status.idle":"2022-04-13T21:17:41.524507Z","shell.execute_reply.started":"2022-04-13T21:17:41.499029Z","shell.execute_reply":"2022-04-13T21:17:41.523841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 1st record with Credit/Income < 0.005 and income over 117 million is not logical. It must be wrong.\n- Other records still suspicious, but almostly the other features plays a vital role in the prediction. ","metadata":{}},{"cell_type":"code","source":"# 2- All days features are in negative values\n## we will just take the absolute value for these features or keep it, it won't affect our models performance","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:41.525406Z","iopub.execute_input":"2022-04-13T21:17:41.525652Z","iopub.status.idle":"2022-04-13T21:17:41.52973Z","shell.execute_reply.started":"2022-04-13T21:17:41.525623Z","shell.execute_reply":"2022-04-13T21:17:41.529059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3- The maximum age of a client is 69 year\n\n## extract dataframe with DAYS_BIRTH and TARGET only\nsusp_df2 = train_df[['DAYS_BIRTH','TARGET']]\n\n## create column represnts the age in years\nsusp_df2['YEARS_BIRTH'] = np.abs(susp_df2['DAYS_BIRTH']) / 365.25\n\n## show datafame\ndisplay(susp_df2.sort_values(by='YEARS_BIRTH', ascending=False))\n\n## show the value counts of those who are aged > 65 with respect to target\ndisplay(susp_df2[(susp_df2['YEARS_BIRTH']>65)]['TARGET'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:41.530631Z","iopub.execute_input":"2022-04-13T21:17:41.530871Z","iopub.status.idle":"2022-04-13T21:17:41.617606Z","shell.execute_reply.started":"2022-04-13T21:17:41.530833Z","shell.execute_reply":"2022-04-13T21:17:41.616646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There's many clients with these age and the most can repay, so it's not a wrong data.","metadata":{}},{"cell_type":"code","source":"# 4- The maximum value in days employed is positive not negative + it's about 100 years\n\n## visualize the clients days of employment >=0\ntrain_df[train_df['DAYS_EMPLOYED']>=0]['DAYS_EMPLOYED'].value_counts().plot(kind='bar');\nplt.title('Specific Days of Employment Value Counts')\nplt.xlabel('Days')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:41.618822Z","iopub.execute_input":"2022-04-13T21:17:41.619129Z","iopub.status.idle":"2022-04-13T21:17:41.84075Z","shell.execute_reply.started":"2022-04-13T21:17:41.619084Z","shell.execute_reply":"2022-04-13T21:17:41.840094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the percentage of this value in our dataset\nvalue_perctage = len(train_df[train_df['DAYS_EMPLOYED']==365243])/len(train_df) * 100\nprint('Records with this value represent {:.2f}% of all data.'.format(value_perctage))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:41.841798Z","iopub.execute_input":"2022-04-13T21:17:41.842472Z","iopub.status.idle":"2022-04-13T21:17:41.893452Z","shell.execute_reply.started":"2022-04-13T21:17:41.842434Z","shell.execute_reply":"2022-04-13T21:17:41.89251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 18% of our dataset with this value, it may be an error and it must be `replaced with the mean or median value`.","metadata":{}},{"cell_type":"code","source":"# 5- A clients own car with 91 age! was manufactured in 1927!\n\n## show the value counts of those who own cars aged > 60 with respect to target\ndisplay(train_df[train_df['OWN_CAR_AGE']>60][['OWN_CAR_AGE','TARGET']]['TARGET'].value_counts())\n\n## show who owns car aged > 70 and its target class\ndisplay(train_df[train_df['OWN_CAR_AGE']>70][['OWN_CAR_AGE','TARGET']])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:41.894998Z","iopub.execute_input":"2022-04-13T21:17:41.895326Z","iopub.status.idle":"2022-04-13T21:17:41.92901Z","shell.execute_reply.started":"2022-04-13T21:17:41.895283Z","shell.execute_reply":"2022-04-13T21:17:41.928319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Not a typo and doesn't affect in out target column","metadata":{}},{"cell_type":"code","source":"# 6- The minimum days before application did a client change phone is zero!\n\n## extract dataframe with DAYS_LAST_PHONE_CHANGE = 0\nsusp_df3 = train_df[train_df['DAYS_LAST_PHONE_CHANGE']==0]\nprint('There\\'re {} records with 0 value in DAYS_LAST_PHONE_CHANGE column'.format(len(susp_df3)))\nprint('These records represent {:.2f}% of all data.'.format(len(susp_df3)/len(train_df) * 100))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:41.930617Z","iopub.execute_input":"2022-04-13T21:17:41.931584Z","iopub.status.idle":"2022-04-13T21:17:41.980752Z","shell.execute_reply.started":"2022-04-13T21:17:41.931514Z","shell.execute_reply":"2022-04-13T21:17:41.979272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- These records may refer for clients with high age so they didn't have phones or work before, so we will check these features distribution.","metadata":{}},{"cell_type":"code","source":"# go deeper with the distributions\n\n## convert birth and employment days into years\nsusp_df3['YEARS_BIRTH'] = susp_df3['DAYS_BIRTH']/-365.25\nsusp_df3['YEARS_EMPLOYED'] = susp_df3['DAYS_EMPLOYED']/-365.25\n\nplt.figure(figsize=(12,5))\n## age histogram for clients with DAYS_LAST_PHONE_CHANGE = 0\nplt.subplot(1, 2, 1)\nsusp_df3['YEARS_BIRTH'].hist(bins=25)\nplt.title('Distribution of Clients\\' Age')\nplt.xlabel('Age in Years')\nplt.ylabel('Frequency')\n\n## employment histogram for clients with DAYS_LAST_PHONE_CHANGE = 0 without the wrong value '365243'\nplt.subplot(1, 2, 2)\nsusp_df3[susp_df3['YEARS_EMPLOYED']!=(365243/-365.25)]['YEARS_EMPLOYED'].hist(bins=25)\nplt.title('Distribution of Clients\\' Employment Years')\nplt.xlabel('Employment Years')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:41.982061Z","iopub.execute_input":"2022-04-13T21:17:41.98241Z","iopub.status.idle":"2022-04-13T21:17:42.395951Z","shell.execute_reply.started":"2022-04-13T21:17:41.982359Z","shell.execute_reply":"2022-04-13T21:17:42.395066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- As shown in figures, 12% of our dataset with this value, it's an error as the most of clients have from 27:65 years and already most of them work and can earn money to have a phone, so it must be replaced with the mean or median value.","metadata":{}},{"cell_type":"markdown","source":"#### Continuous Columns Distribution","metadata":{}},{"cell_type":"code","source":"# create a distribution plot for each continuous feature\nplt.figure(figsize=(25, 50))\nfor i, col in enumerate(cont_cols):\n    plt.subplot(16, 5, i+1)\n    sns.distplot(train_df[col])\n    sns.distplot(test_df[col])","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:17:42.397216Z","iopub.execute_input":"2022-04-13T21:17:42.39749Z","iopub.status.idle":"2022-04-13T21:19:24.162689Z","shell.execute_reply.started":"2022-04-13T21:17:42.397457Z","shell.execute_reply":"2022-04-13T21:19:24.161493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Great! train and test dataset have the same distributions, so the trained model will mostly generalize and predict well.","metadata":{}},{"cell_type":"markdown","source":"#### Insights\n- Although the best stage to analyze the data and extract insights is after the cleaning stage,<br> but in our case without having dtype errors or errors hard to be handled, we can do it now.\n- some points will need to create a clean dataframe withour wrong data, so `proper_df` is a helpful dataframe for this purpose.","metadata":{}},{"cell_type":"code","source":"# Which gender applys more for loans?\n# Is there relation between the gender and the ability to repay?\n\nplt.figure(figsize=(12,5))\nplt.subplot(1, 2, 1)\ntrain_df[train_df['CODE_GENDER']!='XNA']['CODE_GENDER'].value_counts().plot(kind='bar', title='Males VS Females Apply for Loans');\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\n\nplt.subplot(1, 2, 2)\nsns.countplot(data=train_df[train_df['CODE_GENDER']!='XNA'], x='CODE_GENDER', hue='TARGET');\nplt.title('Males VS Females with Respect to Target')\nplt.xlabel('Gender')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:19:24.164245Z","iopub.execute_input":"2022-04-13T21:19:24.164907Z","iopub.status.idle":"2022-04-13T21:19:25.10311Z","shell.execute_reply.started":"2022-04-13T21:19:24.164854Z","shell.execute_reply":"2022-04-13T21:19:25.101991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Females applys for loans more than Males\n- Gender not affect in our Target","metadata":{}},{"cell_type":"code","source":"# Which type of loan contract clients applys more for?\n\nplt.figure(figsize=(12,5))\nplt.subplot(1, 2, 1)\ntrain_df['NAME_CONTRACT_TYPE'].value_counts().plot(kind='bar', title='Cash VS Revolving Loans');\nplt.xlabel('Contract Type')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\n\nplt.subplot(1, 2, 2)\nsns.countplot(data=train_df, x='NAME_CONTRACT_TYPE', hue='TARGET')\nplt.title('Cash VS Revolving Loans with Respect to Target')\nplt.xlabel('Contract Type')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:19:25.108157Z","iopub.execute_input":"2022-04-13T21:19:25.108448Z","iopub.status.idle":"2022-04-13T21:19:25.656131Z","shell.execute_reply.started":"2022-04-13T21:19:25.108415Z","shell.execute_reply":"2022-04-13T21:19:25.655095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Most clients tend to take cash loans rather than revolving loans\n- This feature won't affect our target","metadata":{}},{"cell_type":"code","source":"# Is there relation between the age and the ability to repay?\n\nplt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\n(train_df['DAYS_BIRTH']/-365.25).plot(kind='hist', bins=50, title='Distribution of Clients\\' Age');\nplt.xlabel('Age')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nproper_day_birth_df = train_df[['DAYS_BIRTH', 'TARGET']]\nproper_day_birth_df['DAYS_BIRTH'] = proper_day_birth_df['DAYS_BIRTH']/-365.25\nsns.distplot(proper_day_birth_df[proper_day_birth_df['TARGET']==0]['DAYS_BIRTH'], hist=False, label='Can Repay');\nsns.distplot(proper_day_birth_df[proper_day_birth_df['TARGET']==1]['DAYS_BIRTH'], hist=False, label='Can\\'t Repay');\nplt.title('Distribution of Clients\\' Age with Respect to Target')\nplt.xlabel('Age')\nplt.legend();\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:19:25.657502Z","iopub.execute_input":"2022-04-13T21:19:25.657794Z","iopub.status.idle":"2022-04-13T21:19:28.463586Z","shell.execute_reply.started":"2022-04-13T21:19:25.657759Z","shell.execute_reply":"2022-04-13T21:19:28.462604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Clients aged about 30 years are more likely to have difficulties with repay, where those aged about 40 can repay well.\n- This feature will be important for the model.","metadata":{}},{"cell_type":"code","source":"# Does the client's No. of children affect the ability to repay?\n\nplt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\ntrain_df['CNT_CHILDREN'].plot(kind='hist', bins=19, title='Distribution of Clients\\' No. of Children');\nplt.xlabel('No. of Children')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nsns.distplot(train_df[train_df['TARGET']==0]['CNT_CHILDREN'], hist=False, label='Can Repay');\nsns.distplot(train_df[train_df['TARGET']==1]['CNT_CHILDREN'], hist=False, label='Can\\'t Repay');\nplt.title('Clients\\' No. of Children with Respect to Target')\nplt.xlabel('No. of Children')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:19:28.465078Z","iopub.execute_input":"2022-04-13T21:19:28.46602Z","iopub.status.idle":"2022-04-13T21:19:30.221818Z","shell.execute_reply.started":"2022-04-13T21:19:28.46596Z","shell.execute_reply":"2022-04-13T21:19:30.22059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Client's without any children applys for loans more than others, and with increasing No. of children, client's don't tend to loan.","metadata":{}},{"cell_type":"code","source":"# Is there a relation between client income ant the amount of loan apply for?\n# Does income and credit affect in the ability to repay?\n\nplt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\nproper_income_df = train_df[train_df['AMT_INCOME_TOTAL']!=117000000.0]\nproper_income_df['AMT_INCOME_TOTAL'] = proper_income_df['AMT_INCOME_TOTAL']/10000\nproper_income_df['AMT_INCOME_TOTAL'].plot(kind='hist', bins=1000, title='Distribution of Clients\\' Income');\nplt.xlabel('Total Income')\nplt.xlim([0,100])\n\nplt.subplot(1, 2, 2)\nsns.distplot(proper_income_df[proper_income_df['TARGET']==0]['AMT_INCOME_TOTAL'], hist=False, bins=1000, label='Can Repay');\nsns.distplot(proper_income_df[proper_income_df['TARGET']==1]['AMT_INCOME_TOTAL'], hist=False, bins=1000, label='Can\\'t Repay');\nplt.title('Distribution of Clients\\' Income with Respect to Target')\nplt.xlabel('Total Income')\nplt.xlim([0,100])\nplt.legend();\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:19:30.223279Z","iopub.execute_input":"2022-04-13T21:19:30.224066Z","iopub.status.idle":"2022-04-13T21:19:33.862394Z","shell.execute_reply.started":"2022-04-13T21:19:30.224023Z","shell.execute_reply":"2022-04-13T21:19:33.861448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's normalize to see the plot properly\nproper_income_df['log_AMT_INCOME_TOTAL'] = np.log10(proper_income_df['AMT_INCOME_TOTAL']*10000)\nproper_income_df['log_AMT_CREDIT'] = np.log10(proper_income_df['AMT_CREDIT'])\n\nplt.figure(figsize=(8,8))\nsns.lmplot(x='log_AMT_INCOME_TOTAL', y='log_AMT_CREDIT', data=proper_income_df, hue='TARGET');\nplt.title('Relation Between Total Income & Loan Credit')\nplt.xlabel('Total Income')\nplt.ylabel('Loan Credit')\nplt.show()\n\nsns.distplot(proper_income_df[proper_income_df['TARGET']==0]['log_AMT_CREDIT'], hist=False, label='Can Repay');\nsns.distplot(proper_income_df[proper_income_df['TARGET']==1]['log_AMT_CREDIT'], hist=False, label='Can\\'t Repay');\nplt.title('Distribution of Loan Credit with Respect to Target');\nplt.xlabel('Loan Credit')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:19:33.863803Z","iopub.execute_input":"2022-04-13T21:19:33.864041Z","iopub.status.idle":"2022-04-13T21:20:26.339495Z","shell.execute_reply.started":"2022-04-13T21:19:33.864013Z","shell.execute_reply":"2022-04-13T21:20:26.338456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Client's with low income tends to apply for loans more than others with high income.\n- The more client's income is, the larger loan amount apply for.\n- Client't with income more than 3M tends always to repay, so this feature may help in our target\n- Clients with income between 10 and 18 are less likely to repay, vice versa.\n","metadata":{}},{"cell_type":"code","source":"# what's most income type of clients?\n\nax = sns.countplot(data=train_df, x='NAME_INCOME_TYPE', hue='TARGET');\nax.set_xticklabels(ax.get_xticklabels(),rotation = 90);\nplt.title('Clients\\' Income Type Value Counts with Respect to Target')\nplt.xlabel('Income Type')\nplt.show()\n\nprint('\\n'*2)\ntrain_df.groupby('NAME_INCOME_TYPE')['TARGET'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:26.341061Z","iopub.execute_input":"2022-04-13T21:20:26.341634Z","iopub.status.idle":"2022-04-13T21:20:26.906744Z","shell.execute_reply.started":"2022-04-13T21:20:26.341595Z","shell.execute_reply":"2022-04-13T21:20:26.9055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Working clients are more willing to apply for loans more than others.\n- Altought a few businessmen and students apply for loans, but they always repay.","metadata":{}},{"cell_type":"code","source":"# what's most high education degree for clients?\n\nax = sns.countplot(data=train_df, x='NAME_EDUCATION_TYPE', hue='TARGET');\nax.set_xticklabels(ax.get_xticklabels(),rotation = 90);\nplt.title('Clients\\' High Education Level Value Counts with Respect to Target')\nplt.xlabel('High Education Level')\nplt.show()\n\nprint('\\n'*2)\ntrain_df.groupby('NAME_EDUCATION_TYPE')['TARGET'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:26.908231Z","iopub.execute_input":"2022-04-13T21:20:26.908479Z","iopub.status.idle":"2022-04-13T21:20:27.473719Z","shell.execute_reply.started":"2022-04-13T21:20:26.90845Z","shell.execute_reply":"2022-04-13T21:20:27.472988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Clients with Secondary high education level are more willing to apply for loans more than others.\n- Almost 98% of clients with Academic degree high education level can repay their loans.\n","metadata":{}},{"cell_type":"code","source":"# Is this relation between owning car or realty on applying for loans or repay ability?\n\nplt.figure(figsize=(13,5))\nplt.subplot(1, 2, 1)\nsns.countplot(data=train_df, x='FLAG_OWN_CAR', hue='TARGET')\nplt.title('No. of Clients Owning Cars with Resect to Target')\nplt.xlabel('Owns Car?')\n\nplt.subplot(1, 2, 2)\nsns.countplot(data=train_df, x='FLAG_OWN_REALTY', hue='TARGET')\nplt.title('No. of Clients Owning Realty with Resect to Target')\nplt.xlabel('Owns Realty?')\nplt.show()\n\n\nplt.figure(figsize=(8,6))\ntrain_df[train_df['TARGET']==0].groupby(['FLAG_OWN_CAR', 'FLAG_OWN_REALTY']).count()['TARGET'].plot(kind='bar', color='#4984B8', width=0.3,  position=1, label='TARGET 0')\ntrain_df[train_df['TARGET']==1].groupby(['FLAG_OWN_CAR', 'FLAG_OWN_REALTY']).count()['TARGET'].plot(kind='bar', color='#9F1D35', width=0.3,  position=0, label='TARGET 1')\nplt.title('Count of Clients Owning Car and Realty with Respect to Target');\nplt.ylabel('Count')\nplt.xlabel('Owns Car? Owns Realty?')\nplt.xticks(rotation=0)\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:27.474959Z","iopub.execute_input":"2022-04-13T21:20:27.476062Z","iopub.status.idle":"2022-04-13T21:20:29.236251Z","shell.execute_reply.started":"2022-04-13T21:20:27.476012Z","shell.execute_reply":"2022-04-13T21:20:29.235569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Client's who doesn't own car but owns realty tend to apply for loans more than others, vice versa.\n- Most of both can repay well, but who owns both can repay more than who doesn't.","metadata":{}},{"cell_type":"code","source":"# IS rhere relation between employment year and the ability to repay\n\nproper_days_empolyed_df = train_df[train_df['DAYS_EMPLOYED']!=365243]\nproper_days_empolyed_df['YEARS_EMPLOYED'] = proper_days_empolyed_df['DAYS_EMPLOYED']/-365.25\n\nplt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\nsns.distplot(proper_days_empolyed_df['YEARS_EMPLOYED'])\nplt.title('Distribution of Clients\\' Employment Years')\nplt.xlabel('Employment Years')\n\nplt.subplot(1, 2, 2)\nsns.distplot(proper_days_empolyed_df[proper_days_empolyed_df['TARGET']==0]['YEARS_EMPLOYED'], hist=False, label='Can Repay');\nsns.distplot(proper_days_empolyed_df[proper_days_empolyed_df['TARGET']==1]['YEARS_EMPLOYED'], hist=False, label='Can\\'t Repay');\nplt.title('Distribution of Clients\\' Employment Years with Respect to Target');\nplt.xlim([-5,20])\nplt.xlabel('Employment Years')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:29.237442Z","iopub.execute_input":"2022-04-13T21:20:29.238108Z","iopub.status.idle":"2022-04-13T21:20:32.278947Z","shell.execute_reply.started":"2022-04-13T21:20:29.23806Z","shell.execute_reply":"2022-04-13T21:20:32.277872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Clients with employment years less than 5 years tend to apply for loans more than others, and they are less likely to repay, especially less than 2 years, vice versa.","metadata":{}},{"cell_type":"markdown","source":"### Data Cleaning & Preprocessing","metadata":{}},{"cell_type":"code","source":"# before start cleaning, we keep copy of datasets\ntrain_copy = train_df.copy()\ntest_copy = test_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:32.280714Z","iopub.execute_input":"2022-04-13T21:20:32.281263Z","iopub.status.idle":"2022-04-13T21:20:32.476682Z","shell.execute_reply.started":"2022-04-13T21:20:32.281212Z","shell.execute_reply":"2022-04-13T21:20:32.47564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Drop Columns with >40% NaNs","metadata":{}},{"cell_type":"code","source":"# extract these columns from nans_df\ndrop_cols = nans_df[nans_df['% of NaNs in Column']>40]['Column'].tolist()\nkeep_cols = [col for col in train_df.columns if col not in drop_cols]\n\n# extract the new train dataframe\ntrain_df = train_df[keep_cols]\n\n# remove Target from keep_cols and create the new test dataframe\nkeep_cols.remove('TARGET')\ntest_df = test_df[keep_cols]","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:32.478058Z","iopub.execute_input":"2022-04-13T21:20:32.478339Z","iopub.status.idle":"2022-04-13T21:20:32.601603Z","shell.execute_reply.started":"2022-04-13T21:20:32.478305Z","shell.execute_reply":"2022-04-13T21:20:32.600622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the new datasets shapes\nprint(train_df.shape)\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:32.602938Z","iopub.execute_input":"2022-04-13T21:20:32.603205Z","iopub.status.idle":"2022-04-13T21:20:32.608598Z","shell.execute_reply.started":"2022-04-13T21:20:32.603173Z","shell.execute_reply":"2022-04-13T21:20:32.607959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Drop XNA records from CODE_GENDER column","metadata":{}},{"cell_type":"code","source":"# extract all records doesn't have XNA value in CODE_GENDER column\ntrain_df = train_df[train_df['CODE_GENDER']!='XNA']\n\n# check\ntrain_df['CODE_GENDER'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:32.609922Z","iopub.execute_input":"2022-04-13T21:20:32.610428Z","iopub.status.idle":"2022-04-13T21:20:32.788949Z","shell.execute_reply.started":"2022-04-13T21:20:32.61039Z","shell.execute_reply":"2022-04-13T21:20:32.787952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Drop the wrong value in AMT_INCOME_TOTAL column","metadata":{}},{"cell_type":"code","source":"train_df = train_df[train_df['AMT_INCOME_TOTAL'] != 117000000.0]","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:32.790276Z","iopub.execute_input":"2022-04-13T21:20:32.790583Z","iopub.status.idle":"2022-04-13T21:20:32.901181Z","shell.execute_reply.started":"2022-04-13T21:20:32.790531Z","shell.execute_reply":"2022-04-13T21:20:32.900077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Change the wrong value in DAYS_EMPLOYED and DAYS_LAST_PHONE_CHANGE columns","metadata":{}},{"cell_type":"code","source":"# DAYS_EMPLOYED column\ntrain_df['DAYS_EMPLOYED'] = train_df['DAYS_EMPLOYED'].apply(lambda x: np.nan if x==365243 else x)\ntest_df['DAYS_EMPLOYED'] = test_df['DAYS_EMPLOYED'].apply(lambda x: np.nan if x==365243 else x)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:32.903052Z","iopub.execute_input":"2022-04-13T21:20:32.903403Z","iopub.status.idle":"2022-04-13T21:20:33.071668Z","shell.execute_reply.started":"2022-04-13T21:20:32.903356Z","shell.execute_reply":"2022-04-13T21:20:33.070169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check\nprint(train_df['DAYS_EMPLOYED'].max())\nprint(test_df['DAYS_EMPLOYED'].max())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.073118Z","iopub.execute_input":"2022-04-13T21:20:33.073387Z","iopub.status.idle":"2022-04-13T21:20:33.080339Z","shell.execute_reply.started":"2022-04-13T21:20:33.073357Z","shell.execute_reply":"2022-04-13T21:20:33.078887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DAYS_LAST_PHONE_CHANGE column\ntrain_df['DAYS_LAST_PHONE_CHANGE'] = train_df['DAYS_LAST_PHONE_CHANGE'].apply(lambda x: np.nan if x==0.0 else x)\ntest_df['DAYS_LAST_PHONE_CHANGE'] = test_df['DAYS_LAST_PHONE_CHANGE'].apply(lambda x: np.nan if x==0.0 else x)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.081643Z","iopub.execute_input":"2022-04-13T21:20:33.081957Z","iopub.status.idle":"2022-04-13T21:20:33.178441Z","shell.execute_reply.started":"2022-04-13T21:20:33.081926Z","shell.execute_reply":"2022-04-13T21:20:33.177678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check\nprint(train_df['DAYS_LAST_PHONE_CHANGE'].max())\nprint(test_df['DAYS_LAST_PHONE_CHANGE'].max())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.179955Z","iopub.execute_input":"2022-04-13T21:20:33.180332Z","iopub.status.idle":"2022-04-13T21:20:33.187606Z","shell.execute_reply.started":"2022-04-13T21:20:33.180287Z","shell.execute_reply":"2022-04-13T21:20:33.186649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### NaNs Imputation \n### Catagorical Features Encoding\n- Istead of doing both label encoding for features with 2 unique catagories and one hot encoding for the rest, we can do one hot encoding for all features with and drop the first outcome column, as:\n    - it will do it for us in one step\n    - decrease the No. of features to prevent increasing dimensions and prevent overfitting\n\n### MinMax Scaling\n- get rid of the outliers\n\n#### create one pipeline that impute NaNs with respect to columns dtype and then do One-Hot Encoding and Normalization\n#### we will use this pipeline in `modelling stage`","metadata":{}},{"cell_type":"code","source":"# create a pipeline to deal with numerical features\n## 1- impute with median as most of features cotain outliers\n## 2- apply Min-Max Scaler get rid of the outliers\nnumeric_transformer = Pipeline(\n    steps=[(\"num_imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", MinMaxScaler())]\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.188746Z","iopub.execute_input":"2022-04-13T21:20:33.189742Z","iopub.status.idle":"2022-04-13T21:20:33.19998Z","shell.execute_reply.started":"2022-04-13T21:20:33.1897Z","shell.execute_reply":"2022-04-13T21:20:33.19893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a pipeline to deal with catagorical features\n## 1- impute with the most frequent class \"mode\" \n## 2- apply One-Hot Encoding\ncategorical_transformer = Pipeline(\n    steps=[(\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"encoder\", OneHotEncoder(handle_unknown='ignore', drop='first'))]\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.201465Z","iopub.execute_input":"2022-04-13T21:20:33.202606Z","iopub.status.idle":"2022-04-13T21:20:33.214787Z","shell.execute_reply.started":"2022-04-13T21:20:33.20253Z","shell.execute_reply":"2022-04-13T21:20:33.213592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a column transformer instant\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, make_column_selector(dtype_exclude=\"object\")),\n        (\"cat\", categorical_transformer, make_column_selector(dtype_include=\"object\")),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.216889Z","iopub.execute_input":"2022-04-13T21:20:33.217518Z","iopub.status.idle":"2022-04-13T21:20:33.229025Z","shell.execute_reply.started":"2022-04-13T21:20:33.217462Z","shell.execute_reply":"2022-04-13T21:20:33.227786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Splitting\n","metadata":{}},{"cell_type":"code","source":"# separate target out of features \"predictors\"\nX = train_df.drop('TARGET', axis=1)\ny = train_df['TARGET']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.230751Z","iopub.execute_input":"2022-04-13T21:20:33.231567Z","iopub.status.idle":"2022-04-13T21:20:33.379329Z","shell.execute_reply.started":"2022-04-13T21:20:33.231504Z","shell.execute_reply":"2022-04-13T21:20:33.378402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data splitting\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.380714Z","iopub.execute_input":"2022-04-13T21:20:33.380964Z","iopub.status.idle":"2022-04-13T21:20:33.826269Z","shell.execute_reply.started":"2022-04-13T21:20:33.380934Z","shell.execute_reply":"2022-04-13T21:20:33.825171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling","metadata":{}},{"cell_type":"code","source":"# create a function for trained models evaluation\ndef evaluate_model(model_pipeline):\n    # prediction\n    train_pred = model_pipeline.predict(X_train)\n    test_pred = model_pipeline.predict(X_val)\n    \n    train_pred_proba = model_pipeline.predict_proba(X_train)\n    test_pred_proba = model_pipeline.predict_proba(X_val)\n    \n    # evaluations\n    print('Training & Validation ROC AUC Scores:\\n', '-'*40)\n    print('Training   roc auc score= {:.4f}'.format(roc_auc_score(y_train, train_pred_proba[:, 1])))\n    print('Validation roc auc score= {:.4f}'.format(roc_auc_score(y_val, test_pred_proba[:, 1])))\n    print('')\n    print('Training & Validation Confusion Metrices:')\n    print('Training   confusion matrix:\\n', confusion_matrix(y_train, train_pred))\n    print('Validation confusion matrix:\\n', confusion_matrix(y_val, test_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.8275Z","iopub.execute_input":"2022-04-13T21:20:33.828121Z","iopub.status.idle":"2022-04-13T21:20:33.834877Z","shell.execute_reply.started":"2022-04-13T21:20:33.828078Z","shell.execute_reply":"2022-04-13T21:20:33.833763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Without Target Classes Balancing ","metadata":{}},{"cell_type":"markdown","source":"- Random Forest","metadata":{}},{"cell_type":"code","source":"# create model instant and pipeline\nrf = RandomForestClassifier(n_estimators=100, max_depth=25, random_state=42)\nrf_pipe1 = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", rf)])\n\n# train model\nrf_pipe1.fit(X_train, y_train)\n\n# evaluate model\nevaluate_model(rf_pipe1)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:20:33.836595Z","iopub.execute_input":"2022-04-13T21:20:33.836935Z","iopub.status.idle":"2022-04-13T21:22:26.059868Z","shell.execute_reply.started":"2022-04-13T21:20:33.83689Z","shell.execute_reply":"2022-04-13T21:22:26.058887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Ada Boosting","metadata":{}},{"cell_type":"code","source":"# create model instant and pipeline\nadaboost = AdaBoostClassifier(n_estimators=200, random_state=42)\nada_pipe1 = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", adaboost)])\n\n# train model\nada_pipe1.fit(X_train, y_train)\n\n# evaluate model\nevaluate_model(ada_pipe1)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:22:26.061245Z","iopub.execute_input":"2022-04-13T21:22:26.061492Z","iopub.status.idle":"2022-04-13T21:28:02.181798Z","shell.execute_reply.started":"2022-04-13T21:22:26.061461Z","shell.execute_reply":"2022-04-13T21:28:02.180481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Light Gradient Boosting","metadata":{}},{"cell_type":"code","source":"# create model instant and pipeline \nlgbm = LGBMClassifier(n_estimators=1000, num_leaves=36, random_state=42)\nlgbm_pipe1 = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", lgbm)])\n\n# train model\nlgbm_pipe1.fit(X_train, y_train)\n\n# evaluate model\nevaluate_model(lgbm_pipe1)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:28:02.183316Z","iopub.execute_input":"2022-04-13T21:28:02.183588Z","iopub.status.idle":"2022-04-13T21:28:42.561003Z","shell.execute_reply.started":"2022-04-13T21:28:02.183541Z","shell.execute_reply":"2022-04-13T21:28:42.559924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Models performance is very bad, it almost can't predict the minor target class even in training or in testing.","metadata":{}},{"cell_type":"markdown","source":"#### Target Classes Balancing\n- As in our target major is 91% and minor is 9%, we `can't use either oversampling only` as the minor is very small or `downsampling only` as we will lose alot of our data, so we will `apply both oversample on minor class firstly, then downsample the major one`.","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:27:01.396215Z","iopub.execute_input":"2022-04-11T22:27:01.396563Z","iopub.status.idle":"2022-04-11T22:27:01.487264Z","shell.execute_reply.started":"2022-04-11T22:27:01.396529Z","shell.execute_reply":"2022-04-11T22:27:01.486152Z"}}},{"cell_type":"code","source":"# create oversampler, downsampler instants\noversampler = SMOTE(sampling_strategy=0.25)                     # minor/major = 1/4\nundersampler = RandomUnderSampler(sampling_strategy=0.75)       # minor/major = 3/4","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:28:42.562494Z","iopub.execute_input":"2022-04-13T21:28:42.56314Z","iopub.status.idle":"2022-04-13T21:28:42.56845Z","shell.execute_reply.started":"2022-04-13T21:28:42.563099Z","shell.execute_reply":"2022-04-13T21:28:42.567589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Random Forest","metadata":{}},{"cell_type":"code","source":"# create pipeline\nrf = RandomForestClassifier(n_estimators=100, max_depth=25, random_state=42)\nsteps = [('preprocessor', preprocessor), ('oversampler', oversampler), ('undersampler', undersampler), ('model', rf)]\nrf_pipeline2 = Pipeline(steps=steps)\n\n# train \nrf_pipeline2.fit(X_train, y_train)\n\n# evaluate\nevaluate_model(rf_pipeline2)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:28:42.569869Z","iopub.execute_input":"2022-04-13T21:28:42.570104Z","iopub.status.idle":"2022-04-13T21:30:04.071327Z","shell.execute_reply.started":"2022-04-13T21:28:42.570077Z","shell.execute_reply":"2022-04-13T21:30:04.070303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Ada Boosting","metadata":{}},{"cell_type":"code","source":"# create pipeline\nadaboost = AdaBoostClassifier(n_estimators=200, random_state=42)\nsteps = [('preprocessor', preprocessor), ('oversampler', oversampler), ('undersampler', undersampler), ('model', adaboost)]\nada_pipeline2 = Pipeline(steps=steps)\n\n# train \nada_pipeline2.fit(X_train, y_train)\n\n# evaluate\nevaluate_model(ada_pipeline2)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:30:04.072931Z","iopub.execute_input":"2022-04-13T21:30:04.073172Z","iopub.status.idle":"2022-04-13T21:34:04.080967Z","shell.execute_reply.started":"2022-04-13T21:30:04.073144Z","shell.execute_reply":"2022-04-13T21:34:04.080088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Light Gradient Boosting","metadata":{}},{"cell_type":"code","source":"# create pipeline\nlgbm = LGBMClassifier(n_estimators=500,num_leaves=36, random_state=42)\nsteps = [('preprocessor', preprocessor), ('oversampler', oversampler), ('undersampler', undersampler), ('model', lgbm)]\nlgbm_pipeline2 = Pipeline(steps=steps)\n\n# train \nlgbm_pipeline2.fit(X_train, y_train)\n\n# evaluate\nevaluate_model(lgbm_pipeline2)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:04.082794Z","iopub.execute_input":"2022-04-13T21:34:04.083436Z","iopub.status.idle":"2022-04-13T21:34:41.04842Z","shell.execute_reply.started":"2022-04-13T21:34:04.083385Z","shell.execute_reply":"2022-04-13T21:34:41.047436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- With target balancing, models `prediction become better` especially Ada Boost and Light GBM.\n- Models is underfitting, so we will try to enhance our dataset with `doing feature engineering` to create new features that models can rely on.","metadata":{}},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:13:14.386084Z","iopub.status.idle":"2022-04-12T19:13:14.38687Z","shell.execute_reply.started":"2022-04-12T19:13:14.386573Z","shell.execute_reply":"2022-04-12T19:13:14.386604Z"}}},{"cell_type":"code","source":"# column represent the credit/income percentage\nX_train['Credit/Income'] = X_train['AMT_CREDIT']/X_train['AMT_INCOME_TOTAL']\nX_val['Credit/Income'] = X_val['AMT_CREDIT']/X_val['AMT_INCOME_TOTAL']\ntest_df['Credit/Income'] = test_df['AMT_CREDIT']/test_df['AMT_INCOME_TOTAL']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:41.050726Z","iopub.execute_input":"2022-04-13T21:34:41.053865Z","iopub.status.idle":"2022-04-13T21:34:41.0634Z","shell.execute_reply.started":"2022-04-13T21:34:41.053776Z","shell.execute_reply":"2022-04-13T21:34:41.062719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column represent the annuity/income percentage\nX_train['Annuity/Income'] = X_train['AMT_ANNUITY']/X_train['AMT_INCOME_TOTAL']\nX_val['Annuity/Income'] = X_val['AMT_ANNUITY']/X_val['AMT_INCOME_TOTAL']\ntest_df['Annuity/Income'] = test_df['AMT_ANNUITY']/test_df['AMT_INCOME_TOTAL']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:41.064673Z","iopub.execute_input":"2022-04-13T21:34:41.064938Z","iopub.status.idle":"2022-04-13T21:34:41.079514Z","shell.execute_reply.started":"2022-04-13T21:34:41.064908Z","shell.execute_reply":"2022-04-13T21:34:41.078517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column represent days employed percentage\nX_train['Employed/Birth'] = X_train['DAYS_EMPLOYED']/X_train['DAYS_BIRTH']\nX_val['Employed/Birth'] = X_val['DAYS_EMPLOYED']/X_val['DAYS_BIRTH']\ntest_df['Employed/Birth'] = test_df['DAYS_EMPLOYED']/test_df['DAYS_BIRTH']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:41.080767Z","iopub.execute_input":"2022-04-13T21:34:41.081709Z","iopub.status.idle":"2022-04-13T21:34:41.096078Z","shell.execute_reply.started":"2022-04-13T21:34:41.081638Z","shell.execute_reply":"2022-04-13T21:34:41.094988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flag represents if he's greater than 32 or not\nX_train['Flag_Greater_32'] = (X_train['DAYS_BIRTH']/-365.25).apply(lambda x: 1 if x > 32 else 0)\nX_val['Flag_Greater_32'] = (X_val['DAYS_BIRTH']/-365.25).apply(lambda x: 1 if x > 32 else 0)\ntest_df['Flag_Greater_32'] = (test_df['DAYS_BIRTH']/-365.25).apply(lambda x: 1 if x > 32 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:41.097513Z","iopub.execute_input":"2022-04-13T21:34:41.098033Z","iopub.status.idle":"2022-04-13T21:34:41.241934Z","shell.execute_reply.started":"2022-04-13T21:34:41.09799Z","shell.execute_reply":"2022-04-13T21:34:41.240859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flag represents if his employmeny years is greater than 5 or not\nX_train['Flag_Employment_Greater_5'] = (X_train['DAYS_EMPLOYED']/-365.25).apply(lambda x: 1 if x > 5 else 0)\nX_val['Flag_Employment_Greater_5'] = (X_val['DAYS_EMPLOYED']/-365.25).apply(lambda x: 1 if x > 5 else 0)\ntest_df['Flag_Employment_Greater_5'] = (test_df['DAYS_EMPLOYED']/-365.25).apply(lambda x: 1 if x > 5 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:41.243475Z","iopub.execute_input":"2022-04-13T21:34:41.243813Z","iopub.status.idle":"2022-04-13T21:34:41.389905Z","shell.execute_reply.started":"2022-04-13T21:34:41.24376Z","shell.execute_reply":"2022-04-13T21:34:41.388882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flag represents if his income is greater than the loan or not\nX_train['Flag_Income_Greater_Credit'] = X_train['AMT_INCOME_TOTAL'] > X_train['AMT_CREDIT'] \nX_val['Flag_Income_Greater_Credit'] = X_val['AMT_INCOME_TOTAL'] > X_val['AMT_CREDIT'] \ntest_df['Flag_Income_Greater_Credit'] = test_df['AMT_INCOME_TOTAL'] > test_df['AMT_CREDIT'] ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:41.391541Z","iopub.execute_input":"2022-04-13T21:34:41.391883Z","iopub.status.idle":"2022-04-13T21:34:41.400535Z","shell.execute_reply.started":"2022-04-13T21:34:41.39185Z","shell.execute_reply":"2022-04-13T21:34:41.399594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create polynomial features of the top 3 pos & neg features with target\ncols = ['DAYS_BIRTH', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT',\n       'EXT_SOURCE_3', 'EXT_SOURCE_2', 'DAYS_EMPLOYED']\n\nfor col in cols:\n    for i in [2,3]:\n        X_train[f'{col}_power_{i}'] = X_train[col] ** i\n        X_val[f'{col}_power_{i}'] = X_val[col] ** i\n        test_df[f'{col}_power_{i}'] = test_df[col] ** i","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:41.40234Z","iopub.execute_input":"2022-04-13T21:34:41.40261Z","iopub.status.idle":"2022-04-13T21:34:41.486943Z","shell.execute_reply.started":"2022-04-13T21:34:41.402569Z","shell.execute_reply":"2022-04-13T21:34:41.485968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling 2","metadata":{}},{"cell_type":"markdown","source":"- Random Forest","metadata":{}},{"cell_type":"code","source":"# create pipeline\nrf = RandomForestClassifier(n_estimators=100, max_depth=25, random_state=42)\nsteps = [('preprocessor', preprocessor), ('oversampler', oversampler), ('undersampler', undersampler), ('model', rf)]\nrf_pipeline3 = Pipeline(steps=steps)\n\n# train \nrf_pipeline3.fit(X_train, y_train)\n\n# evaluate\nevaluate_model(rf_pipeline3)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:34:41.488273Z","iopub.execute_input":"2022-04-13T21:34:41.488521Z","iopub.status.idle":"2022-04-13T21:36:25.944357Z","shell.execute_reply.started":"2022-04-13T21:34:41.488493Z","shell.execute_reply":"2022-04-13T21:36:25.943306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Ada Boosting","metadata":{}},{"cell_type":"code","source":"# create pipeline\nadaboost = AdaBoostClassifier(n_estimators=200, random_state=42)\nsteps = [('preprocessor', preprocessor), ('oversampler', oversampler), ('undersampler', undersampler), ('model', adaboost)]\nada_pipeline3 = Pipeline(steps=steps)\n\n# train \nada_pipeline3.fit(X_train, y_train)\n\n# evaluate\nevaluate_model(ada_pipeline3)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:36:25.945677Z","iopub.execute_input":"2022-04-13T21:36:25.945943Z","iopub.status.idle":"2022-04-13T21:41:28.053987Z","shell.execute_reply.started":"2022-04-13T21:36:25.945914Z","shell.execute_reply":"2022-04-13T21:41:28.052844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Light GBM","metadata":{}},{"cell_type":"code","source":"# create model instant and pipeline \nlgbm = LGBMClassifier(n_estimators=500, num_leaves=36, random_state=42)\nlgbm_pipe3 = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", lgbm)])\n\n# train model\nlgbm_pipe3.fit(X_train, y_train)\n\n# evaluate model\nevaluate_model(lgbm_pipe3)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:41:28.056195Z","iopub.execute_input":"2022-04-13T21:41:28.057257Z","iopub.status.idle":"2022-04-13T21:42:03.493057Z","shell.execute_reply.started":"2022-04-13T21:41:28.057203Z","shell.execute_reply":"2022-04-13T21:42:03.492094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- models predictions become slightly better, but LightGBM become worse\n- let's try to `keep all the original features` and train the models again","metadata":{}},{"cell_type":"markdown","source":"### Keep All + Feature Engineering","metadata":{}},{"cell_type":"code","source":"# return the train_df and test_df from their copies\ntrain_df = train_copy.copy()\ntest_df = test_copy.copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:03.494698Z","iopub.execute_input":"2022-04-13T21:42:03.495697Z","iopub.status.idle":"2022-04-13T21:42:03.748027Z","shell.execute_reply.started":"2022-04-13T21:42:03.495653Z","shell.execute_reply":"2022-04-13T21:42:03.746845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Same cleanning as before","metadata":{}},{"cell_type":"code","source":"# doing the same cleaning as before\n\ntrain_df = train_df[train_df['CODE_GENDER']!='XNA']\n\ntrain_df = train_df[train_df['AMT_INCOME_TOTAL'] != 117000000.0]\n\ntrain_df['DAYS_EMPLOYED'] = train_df['DAYS_EMPLOYED'].apply(lambda x: np.nan if x==365243 else x)\ntest_df['DAYS_EMPLOYED'] = test_df['DAYS_EMPLOYED'].apply(lambda x: np.nan if x==365243 else x)\n\ntrain_df['DAYS_LAST_PHONE_CHANGE'] = train_df['DAYS_LAST_PHONE_CHANGE'].apply(lambda x: np.nan if x==0.0 else x)\ntest_df['DAYS_LAST_PHONE_CHANGE'] = test_df['DAYS_LAST_PHONE_CHANGE'].apply(lambda x: np.nan if x==0.0 else x)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:03.749504Z","iopub.execute_input":"2022-04-13T21:42:03.749899Z","iopub.status.idle":"2022-04-13T21:42:04.336466Z","shell.execute_reply.started":"2022-04-13T21:42:03.749859Z","shell.execute_reply":"2022-04-13T21:42:04.335318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data splitting\nX = train_df.drop('TARGET', axis=1)\ny = train_df['TARGET']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, stratify=y, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:04.338027Z","iopub.execute_input":"2022-04-13T21:42:04.338371Z","iopub.status.idle":"2022-04-13T21:42:05.209306Z","shell.execute_reply.started":"2022-04-13T21:42:04.338328Z","shell.execute_reply":"2022-04-13T21:42:05.208231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Same feature engineering as before","metadata":{}},{"cell_type":"code","source":"# column represent the credit/income percentage\nX_train['Credit/Income'] = X_train['AMT_CREDIT']/X_train['AMT_INCOME_TOTAL']\nX_val['Credit/Income'] = X_val['AMT_CREDIT']/X_val['AMT_INCOME_TOTAL']\ntest_df['Credit/Income'] = test_df['AMT_CREDIT']/test_df['AMT_INCOME_TOTAL']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:05.210836Z","iopub.execute_input":"2022-04-13T21:42:05.211106Z","iopub.status.idle":"2022-04-13T21:42:05.221768Z","shell.execute_reply.started":"2022-04-13T21:42:05.211077Z","shell.execute_reply":"2022-04-13T21:42:05.220918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column represent the annuity/income percentage\nX_train['Annuity/Income'] = X_train['AMT_ANNUITY']/X_train['AMT_INCOME_TOTAL']\nX_val['Annuity/Income'] = X_val['AMT_ANNUITY']/X_val['AMT_INCOME_TOTAL']\ntest_df['Annuity/Income'] = test_df['AMT_ANNUITY']/test_df['AMT_INCOME_TOTAL']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:05.223319Z","iopub.execute_input":"2022-04-13T21:42:05.223599Z","iopub.status.idle":"2022-04-13T21:42:05.238762Z","shell.execute_reply.started":"2022-04-13T21:42:05.223534Z","shell.execute_reply":"2022-04-13T21:42:05.237823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column represent days employed percentage\nX_train['Employed/Birth'] = X_train['DAYS_EMPLOYED']/X_train['DAYS_BIRTH']\nX_val['Employed/Birth'] = X_val['DAYS_EMPLOYED']/X_val['DAYS_BIRTH']\ntest_df['Employed/Birth'] = test_df['DAYS_EMPLOYED']/test_df['DAYS_BIRTH']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:05.240524Z","iopub.execute_input":"2022-04-13T21:42:05.24084Z","iopub.status.idle":"2022-04-13T21:42:05.253177Z","shell.execute_reply.started":"2022-04-13T21:42:05.240808Z","shell.execute_reply":"2022-04-13T21:42:05.252203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flag represents if he's greater than 32 or not\nX_train['Flag_Greater_32'] = (X_train['DAYS_BIRTH']/-365.25).apply(lambda x: 1 if x > 32 else 0)\nX_val['Flag_Greater_32'] = (X_val['DAYS_BIRTH']/-365.25).apply(lambda x: 1 if x > 32 else 0)\ntest_df['Flag_Greater_32'] = (test_df['DAYS_BIRTH']/-365.25).apply(lambda x: 1 if x > 32 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:05.254719Z","iopub.execute_input":"2022-04-13T21:42:05.255601Z","iopub.status.idle":"2022-04-13T21:42:05.402925Z","shell.execute_reply.started":"2022-04-13T21:42:05.255543Z","shell.execute_reply":"2022-04-13T21:42:05.402189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flag represents if his employmeny years is greater than 5 or not\nX_train['Flag_Employment_Greater_5'] = (X_train['DAYS_EMPLOYED']/-365.25).apply(lambda x: 1 if x > 5 else 0)\nX_val['Flag_Employment_Greater_5'] = (X_val['DAYS_EMPLOYED']/-365.25).apply(lambda x: 1 if x > 5 else 0)\ntest_df['Flag_Employment_Greater_5'] = (test_df['DAYS_EMPLOYED']/-365.25).apply(lambda x: 1 if x > 5 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:05.40471Z","iopub.execute_input":"2022-04-13T21:42:05.405007Z","iopub.status.idle":"2022-04-13T21:42:05.557333Z","shell.execute_reply.started":"2022-04-13T21:42:05.404974Z","shell.execute_reply":"2022-04-13T21:42:05.556631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flag represents if his income is greater than the loan or not\nX_train['Flag_Income_Greater_Credit'] = X_train['AMT_INCOME_TOTAL'] > X_train['AMT_CREDIT'] \nX_val['Flag_Income_Greater_Credit'] = X_val['AMT_INCOME_TOTAL'] > X_val['AMT_CREDIT'] \ntest_df['Flag_Income_Greater_Credit'] = test_df['AMT_INCOME_TOTAL'] > test_df['AMT_CREDIT'] ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:05.558844Z","iopub.execute_input":"2022-04-13T21:42:05.559287Z","iopub.status.idle":"2022-04-13T21:42:05.567542Z","shell.execute_reply.started":"2022-04-13T21:42:05.559235Z","shell.execute_reply":"2022-04-13T21:42:05.566188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create polynomial features of the top 3 pos & neg features with target\ncols = ['DAYS_BIRTH', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT',\n       'EXT_SOURCE_3', 'EXT_SOURCE_2', 'EXT_SOURCE_1']\n\nfor col in cols:\n    for i in [2,3]:\n        X_train[f'{col}_power_{i}'] = X_train[col] ** i\n        X_val[f'{col}_power_{i}'] = X_val[col] ** i\n        test_df[f'{col}_power_{i}'] = test_df[col] ** i","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:05.56931Z","iopub.execute_input":"2022-04-13T21:42:05.569597Z","iopub.status.idle":"2022-04-13T21:42:05.64587Z","shell.execute_reply.started":"2022-04-13T21:42:05.569538Z","shell.execute_reply":"2022-04-13T21:42:05.644792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling 3","metadata":{}},{"cell_type":"markdown","source":"- Random Forest","metadata":{}},{"cell_type":"code","source":"# create pipeline\nrf = RandomForestClassifier(n_estimators=100, max_depth=25, random_state=42)\nsteps = [('preprocessor', preprocessor), ('oversampler', oversampler), ('undersampler', undersampler), ('model', rf)]\nrf_pipeline4 = Pipeline(steps=steps)\n\n# train \nrf_pipeline4.fit(X_train, y_train)\n\n# evaluate\nevaluate_model(rf_pipeline4)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:42:05.647333Z","iopub.execute_input":"2022-04-13T21:42:05.647632Z","iopub.status.idle":"2022-04-13T21:44:18.996352Z","shell.execute_reply.started":"2022-04-13T21:42:05.647598Z","shell.execute_reply":"2022-04-13T21:44:18.995457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Ada Boosting","metadata":{}},{"cell_type":"code","source":"# create pipeline\nadaboost = AdaBoostClassifier(n_estimators=200, random_state=42)\nsteps = [('preprocessor', preprocessor), ('oversampler', oversampler), ('undersampler', undersampler), ('model', adaboost)]\nada_pipeline4 = Pipeline(steps=steps)\n\n# train \nada_pipeline4.fit(X_train, y_train)\n\n# evaluate\nevaluate_model(ada_pipeline4)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:44:18.997977Z","iopub.execute_input":"2022-04-13T21:44:18.998222Z","iopub.status.idle":"2022-04-13T21:51:12.35232Z","shell.execute_reply.started":"2022-04-13T21:44:18.998191Z","shell.execute_reply":"2022-04-13T21:51:12.349623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Light GBM","metadata":{}},{"cell_type":"code","source":"# create pipeline\nlgbm = LGBMClassifier(n_estimators=500, num_leaves=36, random_state=42)\nsteps = [('preprocessor', preprocessor), ('oversampler', oversampler), ('undersampler', undersampler), ('model', lgbm)]\nlgbm_pipeline4 = Pipeline(steps=steps)\n\n# train \nlgbm_pipeline4.fit(X_train, y_train)\n\n# evaluate\nevaluate_model(lgbm_pipeline4)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:51:12.354992Z","iopub.execute_input":"2022-04-13T21:51:12.355257Z","iopub.status.idle":"2022-04-13T21:52:21.89074Z","shell.execute_reply.started":"2022-04-13T21:51:12.355226Z","shell.execute_reply":"2022-04-13T21:52:21.889642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"# predict and export a submission file\npd.DataFrame({'SK_ID_CURR': test_df.index,'TARGET': lgbm_pipeline4.predict_proba(test_df)[:,1]}).to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:52:21.903538Z","iopub.execute_input":"2022-04-13T21:52:21.903869Z","iopub.status.idle":"2022-04-13T21:52:23.72007Z","shell.execute_reply.started":"2022-04-13T21:52:21.903837Z","shell.execute_reply":"2022-04-13T21:52:23.718941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Done!","metadata":{}}]}