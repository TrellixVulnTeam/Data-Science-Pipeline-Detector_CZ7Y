{"cells":[{"metadata":{},"cell_type":"markdown","source":"* [1.Split out categorical columns and numerical columns](#1)\n* [Data Cleaning](#2)\n    * Deal with cat-columns\n    * Dheck missing values\n* [Find the impact factors](#3)\n* [Deep look impact factors](#4)\n* [Deal with outliers]\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns \nsns.set(style = 'whitegrid',palette = 'Set3',context = 'talk')\n        \n        \nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#load data\ndf = pd.read_csv('../input/application_train.csv')\n#POS_CASH_balance = pd.read_csv('../input/POS_CASH_balance.csv')\n#bureau_balance = pd.read_csv('../input/bureau_balance.csv')\n#previous_application = pd.read_csv('../input/previous_application.csv')\n#installments_payments = pd.read_csv('../input/installments_payments.csv')\n#credit_card_balance = pd.read_csv('../input/credit_card_balance.csv')\n#bureau = pd.read_csv('../input/bureau.csv')\n#application_test = pd.read_csv('../input/application_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.Split out categorical columns and numerical columns"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# check column dtypes\nprint(df.dtypes.value_counts())\n\n# Number of unique classes in each object column\ndf.select_dtypes('object').apply(pd.Series.nunique, axis = 0)\n# they are category columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"### Deal with cat-columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# manually number the cat-columns (just in case )\n# of course we could also use (le) Lable Encoding or one-hot encoding \n# we will do this in next kernel : feature engineering\n\ndf['NAME_CONTRACT_TYPE'] = df['NAME_CONTRACT_TYPE'].replace({'Cash loans':0,\n                                                         'Revolving loans':1})\ndf['CODE_GENDER'] = df['CODE_GENDER'].replace({'M':1,'F':0})\ndf['CODE_GENDER'] = df[df['CODE_GENDER'] != 'XNA']  # just 4 rows, and we remove them\ndf['FLAG_OWN_CAR'] = df['FLAG_OWN_CAR'].replace({'Y':1,'N':0})\ndf['FLAG_OWN_REALTY'] = df['FLAG_OWN_REALTY'].replace({'Y':1,'N':0})                                                         \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing value check\ndef mis_check(x):\n    total = x.isnull().sum().sort_values(ascending = False)\n    percentage = (x.isnull().sum()/x.isnull().count()*100).sort_values(ascending = False)\n    tb = pd.concat([total, percentage], axis=1, keys=['Total', 'Percentage'])\n    \n    display(tb.head(20)) # just show the top 20 rows\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mis_check(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.Have a look on our data"},{"metadata":{},"cell_type":"markdown","source":"**Shortcut**\n* 90% loans are Revolving loans and the others are cash loans;\n* Most of users are in rules, 8.1% users have problem in repaying loan;\n* 30% loan applications are for car, the others are for realty;\n* Most of users have no kid,only a few have more than 2 kids"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tmp = df['NAME_CONTRACT_TYPE'].value_counts()\ntmp1 = df['TARGET'].value_counts()\nplt.subplots(1,2,figsize = (12,6))\nplt.subplots_adjust(left = 0.1,wspace = 0.4)\ncolors = ['lightcoral', 'lightskyblue']\n\nplt.subplot(121)\ntmp.plot.pie(autopct='%1.1f%%', shadow=True, startangle=45,explode = (0.2,0),colors = colors)\nplt.title('Gender Distribution')\nplt.subplot(122)\ntmp1.plot.pie(autopct='%1.1f%%', shadow=True, startangle=45,explode = (0.2,0),colors = colors)\nplt.title('Default Distribution')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\ncols = ['FLAG_OWN_CAR','FLAG_OWN_REALTY','CNT_CHILDREN']\nplt.figure(2 , figsize = ( 24, 6))\nn = 0\nfor c in cols:\n    n += 1\n    plt.subplot(1 , 3 , n)\n    plt.subplots_adjust(wspace =0.4)\n    sns.countplot(df[c] )\n    plt.title('Countplot of {}'.format(c))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shortcut:**\n* Most of AMT_Income_total is under 1 million, let's assume and define outilers,which are more than 1 million;\n* AMT_CREDIT outliers: value more than 2000K;\n* AMT_ANNUITY outliers: value more than 80k;\n* GOODS_PRICE outliers: value more than 2000k;\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cols = ['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE']\nplt.figure(4 , figsize = ( 24, 12))\nn = 0\nfor c in cols:\n    n += 1\n    plt.subplot(2 , 2 , n)\n    plt.subplots_adjust(wspace =0.2, hspace =0.4,)\n    sns.boxenplot(df[c] )\n    plt.title('boxplot of {}'.format(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cols =['NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE']\nplt.figure(4 , figsize = ( 24, 16))\nn = 0\nfor c in cols:\n    n += 1\n    plt.subplot(3 , 2 , n)\n    plt.subplots_adjust(wspace =0.5, hspace =0.4,)\n    sns.countplot(y = df[c], )\n    plt.title('countplot of {}'.format(c))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.Find the impact factors"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()['TARGET'].sort_values()\n# Display correlations\nprint('Top 10 strong Positive Correlations:\\n', corr.tail(10))\nprint('\\nTop 10 strong Negative Correlations:\\n', corr.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.Look Deeper"},{"metadata":{},"cell_type":"markdown","source":"**We can see expect 'target' itself, the most strong factor is DAY_BIRTH. **\n\nGenerally young people have more possibility to default,it might due to the less income and stability.\n\n**Except the EXT_SOURCE factors, the most strong negtive factor is DAYS_EMPLOYED**\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df['AGE'] = round(abs(df['DAYS_BIRTH'])/365,0)\n\nplt.subplots(2,1,figsize = (20,12))\nplt.subplot(211)\ndf['AGE'].plot(kind= 'hist',bins = 10, figsize = (12,6),color = 'lightblue')\nplt.title('Distribution of Age')\nplt.subplot(212)\nsns.kdeplot(df.loc[df['TARGET'] == 0, 'AGE'], label = 'Not-Default')\nsns.kdeplot(df.loc[df['TARGET'] == 1, 'AGE'], label = 'Default')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['EMPLOYED_YEAR'] = round(abs(df['DAYS_EMPLOYED'])/365,1)\ndf['EMPLOYED_YEAR'].corr(df['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.subplots(2,1,figsize = (20,12))\nplt.subplot(211)\ndf['EMPLOYED_YEAR'].plot(kind= 'hist',bins = 10, figsize = (12,6),color = 'lightcoral')\nplt.subplot(212)\nsns.kdeplot(df.loc[df['TARGET'] == 0, 'EMPLOYED_YEAR'], label = 'Not-Default')\nsns.kdeplot(df.loc[df['TARGET'] == 1, 'EMPLOYED_YEAR'], label = 'Default')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Employed year more than 1000 is total insane, after all it is not easy to stay alive 100 years.**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df0 = df[df['EMPLOYED_YEAR'] < 50]\n\nplt.subplots(2,1,figsize = (20,12))\nplt.subplot(211)\ndf0['EMPLOYED_YEAR'].plot(kind= 'hist',bins = 10, figsize = (12,6),color = 'lightcoral')\nplt.title('Distribution of working year')\nplt.subplot(212)\nsns.kdeplot(df0.loc[df0['TARGET'] == 0, 'EMPLOYED_YEAR'], label = 'Not-Default')\nsns.kdeplot(df0.loc[df0['TARGET'] == 1, 'EMPLOYED_YEAR'], label = 'Default')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shortcut:**\n* Users ages are between 20 -70\n* Most of uers' working year is under 10 years\n* Most of the default happens the first couple of working years.\n"},{"metadata":{},"cell_type":"markdown","source":"## Next Chapter: Feature Engineering\n* Imputing missing data\n* Remove outliers\n* Deal with extremely skewed data\n* Find features and create more features\n* Modeling and Predicting\n* Optimise results\n\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://i.redd.it/22uasph7vxvy.png)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}