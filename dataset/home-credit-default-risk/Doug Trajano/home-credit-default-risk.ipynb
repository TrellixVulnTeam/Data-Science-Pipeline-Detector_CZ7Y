{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Home Credit Default Risk\n\nThis is part of my capstone project on [Data Scientist nanodegree](https://www.udacity.com/course/data-scientist-nanodegree--nd025) at [Udacity](www.udacity.com)! \\o/\n\nAuthor: Douglas Trajano\n> [LinkedIn](https://www.linkedin.com/in/douglas-trajano/) | [GitHub](https://github.com/DougTrajano)\n\n---\n\n# // objective\n\n> Can you predict how capable each applicant is of repaying a loan?\n\nWell, it's a binary classification between `0` and `1`. Customer can repay or not his loan?\n\n---\n\n# // dataset\n\nThe dataset has 7 files. All these files can be downloaded [here](https://www.kaggle.com/c/home-credit-default-risk/data)\n\n![](https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png)\n\n### application_{train|test}.csv\n> Size (train): 308k x 122\n>\n> Size (test): 48.7k x 121\n\n- This is the main table, broken into two files for Train (with TARGET) and Test (without TARGET).\n- Static data for all applications. One row represents one loan in our data sample.\n\n\n### bureau.csv\n> Size: 1.72m x 17\n\n- All client's previous credits provided by other financial institutions that were reported to Credit Bureau (for clients who have a loan in our sample).\n- For every loan in our sample, there are as many rows as number of credits the client had in Credit Bureau before the application date.\n\n### bureau_balance.csv\n> Size: 27.3m x 3\n\n- Monthly balances of previous credits in Credit Bureau.\n- This table has one row for each month of history of every previous credit reported to Credit Bureau – i.e the table has (#loans in sample * # of relative previous credits * # of months where we have some history observable for the previous credits) rows.\n\n### POS_CASH_balance.csv\n> Size: 10.0m x 8\n\n- Monthly balance snapshots of previous POS (point of sales) and cash loans that the applicant had with Home Credit.\n- This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credits * # of months in which we have some history observable for the previous credits) rows.\n\n### credit_card_balance.csv\n> Size: 3.84m x 23\n\n- Monthly balance snapshots of previous credit cards that the applicant has with Home Credit.\n- This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credit cards * # of months where we have some history observable for the previous credit card) rows.\n\n### previous_application.csv\n> Size: 1.67m x 37\n\n- All previous applications for Home Credit loans of clients who have loans in our sample.\n- There is one row for each previous application related to loans in our data sample.\n\n### installments_payments.csv\n> Size: 13.6m x 8\n\n- Repayment history for the previously disbursed credits in Home Credit related to the loans in our sample.\n- There is a) one row for every payment that was made plus b) one row each for missed payment.\n- One row is equivalent to one payment of one installment OR one installment corresponding to one payment of one previous Home Credit credit related to loans in our sample.\n\n### HomeCredit_columns_description.csv\n> Size: 219 x 5\n\n- This file contains descriptions for the columns in the various data files."},{"metadata":{},"cell_type":"markdown","source":"---\n\n# // metric's definition\n\nAs metric to evaluate models I'll use [F1-Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). See below a little description about this metric.\n\n> The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n>\n> `F1 = 2 * (precision * recall) / (precision + recall)`\n\nAnother metric that we will use is the Kaggle's Score. We have a csv file called `application_test.csv` that can be used to predict and submit to Kaggle. Kaggle will provide a score for us."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Graphics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.offline as offline\npy.init_notebook_mode(connected=True)\ninit_notebook_mode(connected=True)\noffline.init_notebook_mode()\n%matplotlib inline\n\n# Sklearn and TensorFlow\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.testing import all_estimators\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\",category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n# // load datasets\n\nWe'll working only with `df_application_train.csv` in this study."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_application_train = pd.read_csv(\"/kaggle/input/home-credit-default-risk/application_train.csv\")\nprint(\"Shape:\", df_application_train.shape)\ndf_application_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n# // exploratory analysis\n\nIn this part of the notebook we will explore the dataset.\n\nWe will work with `application_train.csv` because this dataset has 122 characteristics for the loans, we have 307511 loans (one loan for row).\n\nWe also has a TARGET that we will use to fit the model."},{"metadata":{},"cell_type":"markdown","source":"## // pandas profiling\n\nI like to run [pandas_profiling](https://pandas-profiling.github.io/pandas-profiling/docs/) in the dataset. It's provide a lot of information about a dataset and we can do a quick analysis with it.\n\nBecause of the dataset size it could not be run on Kaggle Notebook.\n\nI ran this on [AWS SageMaker](https://aws.amazon.com/sagemaker/) (ml.m5.24xlarge, vCPU: 96, Mem (GiB): 384GB). ¯\\\\_(ツ)_/¯\n\n[dataset.overview.html](https://dougtrajano.github.io/udacity_capstone_project/dataset_overview.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = df_application_train[\"TARGET\"].value_counts()\n\ntrace = go.Pie(\n    labels = df_temp.index,\n    values = df_temp.values,\n)\n\ndata = [trace]\n\nlayout = go.Layout(\n    title = \"Loan Repayed or not\",\n    xaxis=dict(\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n    ),\n    yaxis=dict(\n        titlefont=dict(\n            size=16,\n            color='rgb(107, 107, 107)'\n        ),\n        tickfont=dict(\n            size=14,\n            color='rgb(107, 107, 107)'\n        )\n)\n)\n\nfig = go.Figure(data=data, layout=layout)\nfig.update_layout(template=\"seaborn\")\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can see that we have an imbalanced classes. We will need to work with before fit the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = df_application_train[\"NAME_CONTRACT_TYPE\"].value_counts()\n\nfig = {\n  \"data\": [\n    {\n      \"values\": df_temp.values,\n      \"labels\": df_temp.index,\n      \"domain\": {\"x\": [0, .48]},\n      \"hole\": .7,\n      \"type\": \"pie\"\n    },\n    \n    ],\n  \"layout\": {\n        \"title\":\"Contract type\",\n    }\n}\n\nfig = go.Figure(fig)\nfig.update_layout(template=\"seaborn\")\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = df_application_train[\"NAME_FAMILY_STATUS\"].value_counts()\n\nfig = {\n  \"data\": [\n    {\n      \"y\": df_temp.values,\n      \"x\": df_temp.index,\n      \"type\": \"bar\"\n    },\n    \n    ],\n  \"layout\": {\n        \"title\":\"Family Status\",\n    }\n}\n\nfig = go.Figure(fig)\nfig.update_layout(template=\"seaborn\")\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 63,88% applicants are married."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = df_application_train[\"OCCUPATION_TYPE\"].value_counts()\n\nfig = {\n  \"data\": [\n    {\n        \"x\": df_temp.index,\n        \"y\": df_temp.values,\n        \"type\": \"bar\"\n    },\n    \n    ],\n  \"layout\": {\n        \"title\":\"Occupation of applicant\\'s\"\n    }\n}\n\nfig = go.Figure(fig)\nfig.update_layout(template=\"seaborn\")\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Top occupations and it's percentage.\n> \n> - Laborers: 17,95%\n> - Sales staff: 10,44%\n> - Core staff: 8,97%\n> - Managers: 6,95%\n> - Drivers: 6,05%"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_temp = pd.DataFrame(df_application_train.isnull().sum().sort_values(ascending=False)/len(df_application_train), columns=[\"MISSING_VALUES\"])\ndf_temp = df_temp[df_temp[\"MISSING_VALUES\"] > 0]\n\nfig = {\n  \"data\": [\n    {\n        \"x\": df_temp.index,\n        \"y\": df_temp.MISSING_VALUES.values,\n        \"type\": \"bar\"\n    },\n    \n    ],\n  \"layout\": {\n        \"title\":\"Columns with missing values (%)\"\n    }\n}\n\nfig = go.Figure(fig)\nfig.update_layout(template=\"seaborn\")\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a lot of features with missing values. We need to handle with it before create our model."},{"metadata":{},"cell_type":"markdown","source":"---\n# // prepare dataset\n\n\nIn this section I'll check the best features and prepare the dataset to be used as **X** and **Y** in the modeling.\n\nWe will convert categorical features to numeric features using [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n\nWe will remove some features that aren't important or are inappropriate for the model as well. As example, it's inappropriate to use the gender for predict if a person can pay or not the loan."},{"metadata":{},"cell_type":"markdown","source":"## // missing values\n\nThe strategy to handle with missing values is divided by low, medium and high quantity of missing values. For each of these we will apply a different technique to solve it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values\n## For low number of missing values we'll apply the mean for float64 objects and \"Other\" for string columns.\n\nlow_missing_values_col = [\"DAYS_LAST_PHONE_CHANGE\", \"CNT_FAM_MEMBERS\", \"AMT_ANNUITY\", \"AMT_GOODS_PRICE\", \"EXT_SOURCE_2\",\n                          \"DEF_30_CNT_SOCIAL_CIRCLE\", \"DEF_60_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\",\n                          \"OBS_30_CNT_SOCIAL_CIRCLE\", \"NAME_TYPE_SUITE\"]\n\nfor col in low_missing_values_col:\n    if df_application_train[col].dtype == \"object\":\n        df_application_train[col].fillna(\"Other\", inplace=True)\n    elif df_application_train[col].dtype == \"float64\":\n        df_application_train[col].fillna(df_application_train[col].mean(), inplace=True)\n    else:\n        print(\"{} has a different dtype.\".format(col))\n    print(\"{}:\".format(col), df_application_train[col].dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Medium quantity\n## The strategy for medium quantity of missing values will be remove rows with np.nan.\n\nmedium_missing_values_col = [\"AMT_REQ_CREDIT_BUREAU_HOUR\", \"AMT_REQ_CREDIT_BUREAU_MON\", \"AMT_REQ_CREDIT_BUREAU_WEEK\",\n                             \"AMT_REQ_CREDIT_BUREAU_DAY\", \"AMT_REQ_CREDIT_BUREAU_YEAR\", \"AMT_REQ_CREDIT_BUREAU_QRT\",\n                            \"EXT_SOURCE_3\"]\n\nprint(\"df_application_train shape before remove missing rows:\", df_application_train.shape)\n    \nfor col in medium_missing_values_col:\n    print(col, df_application_train[col].dtype)\n    if col == \"EXT_SOURCE_3\":\n        print(\"Mean:\", df_application_train[col].mean(), \"\\n\")\n    else:\n        print(df_application_train[col].unique(), \"\\n\")\n\ndf_application_train.dropna(subset=medium_missing_values_col, inplace=True)\nprint(\"df_application_train shape after remove missing rows:\", df_application_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For high quantity of missing values, we'll drop these columns\ndf_application_train.dropna(axis=\"columns\", how=\"any\", inplace=True)\ndf_application_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check missing values\nmissing_values = df_application_train.isnull().sum().sum()\nprint(\"Quantiy of missing values:\", missing_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical features\ndf_application_train_dtypes = pd.DataFrame(df_application_train.dtypes, columns=[\"dtypes\"])\ncat_features = df_application_train_dtypes[(df_application_train_dtypes[\"dtypes\"] == \"object\") | (df_application_train_dtypes[\"dtypes\"] == \"category\")].index.tolist()\nprint(\"Categorical features ({}):\".format(len(cat_features)), cat_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# instantiate labelencoder object\nle = LabelEncoder()\n\n# apply le on categorical feature columns\ndf_application_train[cat_features] = df_application_train[cat_features].apply(lambda col: le.fit_transform(col))\ndf_application_train.loc[:][cat_features].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = df_application_train.corr()\nsns.heatmap(cor, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with TARGET variable\ncor_target = abs(cor[\"TARGET\"])\n\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.05].sort_values(ascending=False)\nrelevant_features[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pairplot only for relevant_features\nsns.pairplot(df_application_train, hue=\"TARGET\", vars=relevant_features.index.tolist())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split in X and Y and apply MinMaxScaler (0, 1)\n\nX = df_application_train.drop(columns=[\"SK_ID_CURR\", \"TARGET\"])\ny = df_application_train[\"TARGET\"].values\n\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X.values)\n\nprint(\"X shape:\", X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n# // PCA\n\nNow we have 70 features in the X. Can we apply a dimensionality reduction technique?\n\nYes! PCA (Principal Component Analysis) can discovery it for us what importance each feature has in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_pca(n_components, data):\n    '''\n    Transforms data using PCA to create n_components, and provides back the results of the\n    transformation.\n\n    INPUT: n_components - int - the number of principal components to create\n           data - the data you would like to transform\n\n    OUTPUT: pca - the pca object created after fitting the data\n            X_pca - the transformed X matrix with new number of components\n    '''\n    X = StandardScaler().fit_transform(data)\n    pca = PCA(n_components)\n    X_pca = pca.fit_transform(X)\n    return pca, X_pca\n\ndef scree_plot(pca):\n    '''\n    Creates a scree plot associated with the principal components \n    \n    INPUT: pca - the result of instantian of PCA in scikit learn\n            \n    OUTPUT:\n            None\n    '''\n    num_components=len(pca.explained_variance_ratio_)\n    ind = np.arange(num_components)\n    vals = pca.explained_variance_ratio_\n \n    plt.figure(figsize=(10, 6))\n    ax = plt.subplot(111)\n    cumvals = np.cumsum(vals)\n    ax.bar(ind, vals)\n    ax.plot(ind, cumvals)\n    #for i in range(num_components):\n    #    ax.annotate(r\"%s%%\" % ((str(vals[i]*100)[:4])), (ind[i]+0.2, vals[i]), va=\"bottom\", ha=\"center\", fontsize=12)\n \n    ax.xaxis.set_tick_params(width=0)\n    ax.yaxis.set_tick_params(width=2, length=12)\n \n    ax.set_xlabel(\"Principal Component\")\n    ax.set_ylabel(\"Variance Explained (%)\")\n    plt.title('Explained Variance Per Principal Component')\n    \npca, X_pca = do_pca(X.shape[1], X)\nX_pca = None #just cleaning memory\nscree_plot(pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_components = 40\npca, X_pca = do_pca(n_components, X)\n\nprint(\"Explained variance for {} components: {:.2f}%\".format(n_components, sum(pca.explained_variance_ratio_)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"PCA: Top 10 Explained variance\", \"\\n\")\nfor i in range(len(pca.explained_variance_ratio_[:10])):\n    print(\"component {}: {:.2f}%\".format(i+1, pca.explained_variance_ratio_[i]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n# // modeling\n\nI tried build model with commum machine learning algorithms (LogisticRegression, RandomForestClassifier, etc.) and neural networks with TensorFlow/Keras.\n\nSee below the best results for this dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataset in train and test.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nprint(\"train size:\", len(X_train))\nprint(\"test size:\", len(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Handling unbalanced classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n\nclass_weights = {\n    0: class_weights[0],\n    1: class_weights[1]\n}\n\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> What sklearn algorithms has **class_weight** as attribute?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Sklearn's classifier algorithms with class_weight attribute:\", \"\\n\")\nestimators = all_estimators(type_filter='classifier')\nfor name, class_ in estimators:\n    try:\n        if hasattr(class_(), 'class_weight'): \n            print(name)\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nclf_log = LogisticRegression(solver=\"liblinear\", class_weight=class_weights)\nclf_log.fit(X_train, y_train)\n\ny_pred = clf_log.predict(X_test)\n\nprint(classification_report(y_test, y_pred, digits=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nclf_rf = RandomForestClassifier(n_estimators=50, class_weight=class_weights, n_jobs=-1, min_samples_leaf=200, max_depth=30)\nclf_rf.fit(X_train, y_train)\n\ny_pred = clf_rf.predict(X_test)\n\nprint(classification_report(y_test, y_pred, digits=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# GridSearch for RandomForestClassifier\nmodel = RandomForestClassifier(class_weight=class_weights)\n\nparameters = {\n    \"n_estimators\": [10, 30, 50, 100],\n    \"criterion\": [\"gini\", \"entropy\"],\n    \"max_depth\": [10, 20, 30],\n    \"min_samples_leaf\": [50, 100, 200]    \n}\n\nclf_rf = GridSearchCV(model, parameters, cv=5, n_jobs=-1, verbose=1)\nclf_rf.fit(X_train, y_train)\n\ny_pred = clf_rf.predict(X_test)\nprint(clf_rf.best_estimator_)\nprint(\"\\n\")\nprint(classification_report(y_test, y_pred, digits=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[LGBMClassifier](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom lightgbm import LGBMClassifier\nclf_lgbmc = LGBMClassifier(objective='binary', metric='auc', class_weight=class_weights, n_estimators=1000, max_depth=20)\n\nclf_lgbmc.fit(X_train, y_train,\n              eval_set = [(X_test, y_test)],\n              early_stopping_rounds=50,\n              verbose=0)\n\ny_pred = clf_lgbmc.predict(X_test, num_iteration=clf_lgbmc.best_iteration_)\n\nprint(classification_report(y_test, y_pred, digits=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# GridSearch for LGBMClassifier\nmodel = LGBMClassifier(class_weight=class_weights, objective='binary', metric='auc')\n    \nparameters = {\n    \"n_estimators\": [100, 300, 500, 1000],\n    \"boosting_type\": [\"gbdt\", \"dart\", \"goss\"],\n    \"max_depth\": [10, 20, 30] \n}\n\nclf_lgbmc = GridSearchCV(model, parameters, cv=5, n_jobs=-1, verbose=1)\nclf_lgbmc.fit(X_train, y_train)\n\ny_pred = clf_lgbmc.predict(X_test)\n\nprint(classification_report(y_test, y_pred, digits=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[TensorFlow](https://www.tensorflow.org)/[Keras](http://keras.io)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport keras.backend as K\n\nX_train_k = X_train\ny_train_k = np.array(y_train)\n\nX_test_k = X_test\ny_test_k = np.array(y_test)\n\ndef f1_keras(y_true, y_pred):\n    y_pred = K.round(y_pred)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    precision = tp / (tp + fp + K.epsilon())\n    recall = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*precision*recall / (precision+recall+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\n# TensorFlow/Keras\nclf_keras = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(512, input_dim=X_train_k.shape[1], activation=\"relu\"),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(256, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(64, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n    \nclf_keras.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\", f1_keras])\n\nclf_keras.fit(X_train_k, y_train_k, epochs=50, class_weight=class_weights, use_multiprocessing=True, batch_size=128)\n\nmodel_evals = clf_keras.evaluate(X_test_k, y_test_k)\n\nprint(\"\\n\")\nprint(\"Evaluate Model\")\nprint(\"Loss: {}\".format(model_evals[0]))\nprint(\"Accuracy: {}\".format(model_evals[1]))\nprint(\"F1-Score: {}\".format(model_evals[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_keras.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shame_function(y_pred):\n    \"\"\"\n    This function update y_pred for 1 or 0.\n    \n    I think that have a better solution for that, but I don't find anything at this time.\n    \"\"\"\n    result = []\n    for n in y_pred:\n        if n[0] >= 0.5:\n            result.append(1)\n        else:\n            result.append(0)\n    return result\n\ny_pred = shame_function(clf_keras.predict(X_test))\n\nprint(\"y_test\")\nprint(\"% of target == 1: {:.2f}%\".format((len(y_test.tolist())/sum(y_test.tolist()))))\nprint(y_test.tolist()[:10])\nprint(\"\\n\")\nprint(\"y_pred\")\nprint(\"% of target == 1: {:.2f}%\".format((len(y_pred)/sum(y_pred))))\nprint(y_pred[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n# // submission\n\nIn this section I'll create a submission.csv file to send to the Leaderboard."},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(df, n_components=None, return_pca=False):\n    # Missing values\n    low_missing_values_col = [\"DAYS_LAST_PHONE_CHANGE\", \"CNT_FAM_MEMBERS\", \"AMT_ANNUITY\", \"AMT_GOODS_PRICE\", \"EXT_SOURCE_2\",\n                              \"DEF_30_CNT_SOCIAL_CIRCLE\", \"DEF_60_CNT_SOCIAL_CIRCLE\", \"OBS_60_CNT_SOCIAL_CIRCLE\",\n                              \"OBS_30_CNT_SOCIAL_CIRCLE\", \"NAME_TYPE_SUITE\"]\n\n    for col in low_missing_values_col:\n        if df[col].dtype == \"object\":\n            df[col].fillna(\"Other\", inplace=True)\n        elif df[col].dtype == \"float64\":\n            df[col].fillna(df[col].mean(), inplace=True)\n\n\n    medium_missing_values_col = [\"AMT_REQ_CREDIT_BUREAU_HOUR\", \"AMT_REQ_CREDIT_BUREAU_MON\", \"AMT_REQ_CREDIT_BUREAU_WEEK\",\n                                 \"AMT_REQ_CREDIT_BUREAU_DAY\", \"AMT_REQ_CREDIT_BUREAU_YEAR\", \"AMT_REQ_CREDIT_BUREAU_QRT\",\n                                \"EXT_SOURCE_3\"]\n\n    for col in medium_missing_values_col:\n        if df[col].dtype == \"object\":\n            df[col].fillna(\"Other\", inplace=True)\n        elif df[col].dtype == \"float64\":\n            df[col].fillna(df[col].mean(), inplace=True)\n            \n    df.dropna(axis=\"columns\", how=\"any\", inplace=True)\n    \n    # Split in X and Y\n    X = df.dropna(axis=\"columns\", how=\"any\")\n    X.drop(columns=[\"SK_ID_CURR\", \"TARGET\"], inplace=True, errors=\"ignore\")\n\n    try:\n        y = df[\"TARGET\"].values\n    except:\n        y = None\n        print(\"TARGET column not found.\")\n    \n    X_dtypes = pd.DataFrame(X.dtypes, columns=[\"dtypes\"])\n    cat_features = X_dtypes[(X_dtypes[\"dtypes\"] == \"object\") | (X_dtypes[\"dtypes\"] == \"category\")].index.tolist()\n    \n    # instantiate labelencoder object\n    le = LabelEncoder()\n    # apply le on categorical feature columns\n    X[cat_features] = X[cat_features].apply(lambda col: le.fit_transform(col))\n    X.loc[:][cat_features].head(10)\n\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X.values)\n\n    if n_components == None:\n        n_components = X.shape[1]\n        \n    pca, X_pca = do_pca(n_components, X)\n    \n    if y != None and return_pca != False:\n        return X_pca, y\n    elif y != None and return_pca == True:\n        return X_pca, y, pca\n    elif y == None and return_pca == True:\n        return X_pca, pca\n    else:\n        return X_pca\n\ndef submission_file(model, keras_model=False, n_components=70, filename=\"submission.csv\"):\n    \"\"\"\n    Args\n    \n    model: Model to predict\n    keras_model: True/False if we are using Keras Model or not.\n    n_components: To preprocessing PCA.\n    \n    Return\n    Link to submission file download.\n    \"\"\"\n    from IPython.display import FileLink\n    \n    df_application_test = pd.read_csv(\"/kaggle/input/home-credit-default-risk/application_test.csv\")\n    submission = preprocessing(df_application_test, n_components=n_components)\n\n    if keras_model:\n        predicts = shame_function(model.predict(submission))\n    else:\n        predicts = model.predict(submission)\n\n    df_sample_submission = pd.read_csv(\"/kaggle/input/home-credit-default-risk/sample_submission.csv\")\n    df_sample_submission[\"TARGET\"] = predicts\n\n    df_sample_submission.to_csv(filename, index=False)\n    print(\"{} salved.\".format(filename))\n    return FileLink(r'{}'.format(filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LogisticRegression\nsubmission_file(clf_log, n_components=70,\n                filename=\"submission_LogisticRegression.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForest\nsubmission_file(clf_rf, n_components=70,\n                filename=\"submission_RandomForest.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LGBMClassifier\nsubmission_file(clf_lgbmc, n_components=70,\n                filename=\"submission_LGBMClassifier.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TensorFlow/Keras\nsubmission_file(clf_keras, keras_model=True, n_components=70,\n                filename=\"submission_TensorFlow-Keras.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n# // results\n\nYou can see the complete result in the [medium post](https://medium.com/@dougtrajano/ia-applied-in-credit-risk-home-credit-b70412ef8f02)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}