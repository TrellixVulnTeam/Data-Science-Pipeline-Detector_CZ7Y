{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"working_dir = \"/kaggle/input/home-credit-default-risk/\"\n\nprint('Importing data...')\ndata = pd.read_csv(working_dir + 'application_train.csv')\ntest = pd.read_csv(working_dir + 'application_test.csv')\nprev = pd.read_csv(working_dir + 'previous_application.csv')\nbureau = pd.read_csv(working_dir + 'bureau.csv')\nbureau_balance = pd.read_csv(working_dir + 'bureau_balance.csv')\ncredit_card  = pd.read_csv(working_dir + 'credit_card_balance.csv')\nPOS_CASH  = pd.read_csv(working_dir + 'POS_CASH_balance.csv')\npayments = pd.read_csv(working_dir + 'installments_payments.csv')\nlgbm_submission = pd.read_csv(working_dir + 'sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the target column\ntarget = data['TARGET']\ndel data['TARGET']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1. Data Preprocessing**\n\nThe provided dataset contains lots of details about the customer. And all the data are segregated into multiple tables. We will dive into all tables seperately.\n\nDataset has a relation table that shows the which table related with which table via which column. For example previous_application table is related with POS_CASH_balance via sk_id_prev. We will group this tables according to id variables such as sk_id_prev. We have three id variables:  \n1. SK_ID_CURR   -> id for current loan; \n2. SK_ID_BUREAU -> ids for the bureau loans\n3. SK_ID_PREV   -> id for previous loans\n\nAfter preprocess operation for all tables seperately we will combine all data into one final dataframe.\n\nThere are categorical data in tables. We have several options for dealing with categorical data. Such as replacing the meanings of the all categories, label encoding and one hot encoding. In this dataset we have two part of categorical data. The first part has binary features like female/male or yes/no but the other part has Cash loans/Revolving loans. We will use label encoding for the first part and one hot encoding for the second part.\n\nAnd the null values will be considered after combine operation.","metadata":{}},{"cell_type":"code","source":"# Preprocess application_train.csv and application_test.csv\ndef preprocess_application_files(data, test):\n    '''\n    negative_day_features = ['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE']\n    for negative_feature in negative_day_features:\n        data[negative_feature] = data[negative_feature].apply(lambda day : day*(-1/365))\n        \n    \n    data = data.append(test).reset_index()\n    #print(data['CODE_GENDER'].value_counts())\n    data = data[data['CODE_GENDER'] != 'XNA']\n\n    negative_day_features = ['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE']\n    for negative_feature in negative_day_features:\n        data[negative_feature] = data[negative_feature].apply(lambda day : day*(-1/365))\n    \n    binary_features = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n    for binary_feature in binary_features:\n            data[binary_feature], uniques = pd.factorize(data[binary_feature])\n    \n    non_binary_features = [col for col in data.columns if data[col].dtype == 'object' and (col not in binary_features)]\n    one_hot_df = pd.get_dummies(data, columns=non_binary_features)\n    \n    categorical_features = [col for col in data.columns if data[col].dtype == 'object']\n    one_hot_df = pd.concat([data,test])\n    one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)\n    '''\n    #One-hot encoding of categorical features in data and test sets\n    categorical_features = [col for col in data.columns if data[col].dtype == 'object']\n\n    one_hot_df = pd.concat([data,test])\n    one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)\n    return one_hot_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess bureau.csv and bureau_balance.csv\ndef preprocess_bureau_files(bureau, bureau_balance):\n    # One row is for one month history so we will group this rows according to id\n    bureau_grouped_size = bureau_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].size()\n    bureau_grouped_max = bureau_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].max()\n    bureau_grouped_min = bureau_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].min()\n\n    bureau_counts = bureau_balance.groupby('SK_ID_BUREAU')['STATUS'].value_counts(normalize = False)\n    bureau_counts_unstacked = bureau_counts.unstack('STATUS')\n    bureau_counts_unstacked.columns = ['STATUS_0', 'STATUS_1','STATUS_2','STATUS_3','STATUS_4','STATUS_5','STATUS_C','STATUS_X',]\n    bureau_counts_unstacked['MONTHS_COUNT'] = bureau_grouped_size\n    bureau_counts_unstacked['MONTHS_MAX'] = bureau_grouped_max\n    bureau_counts_unstacked['MONTHS_MIN'] = bureau_grouped_min\n\n    bureau = bureau.join(bureau_counts_unstacked, how='left', on='SK_ID_BUREAU')\n    '''\n    negative_day_features = ['DAYS_CREDIT', 'DAYS_CREDIT_UPDATE', 'DAYS_ENDDATE_FACT']\n    for negative_feature in negative_day_features:\n        bureau[negative_feature] = bureau[negative_feature].apply(lambda day : day*(-1/365))\n    \n    bureau['CREDIT_ACTIVE'], uniques = pd.factorize(bureau['CREDIT_ACTIVE'])\n    non_binary_features = [col for col in bureau.columns if bureau[col].dtype == 'object' and col != 'CREDIT_ACTIVE']\n    bureau = pd.get_dummies(bureau, columns=non_binary_features)\n    \n    avg_bureau = bureau.groupby('SK_ID_CURR').mean()\n    avg_bureau['buro_count'] = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].groupby('SK_ID_CURR').count()['SK_ID_BUREAU']\n    del avg_bureau['SK_ID_BUREAU']\n    return avg_bureau\n    '''\n    \n    buro_cat_features = [bcol for bcol in bureau.columns if bureau[bcol].dtype == 'object']\n    bureau = pd.get_dummies(bureau, columns=buro_cat_features)\n    avg_bureau = bureau.groupby('SK_ID_CURR').mean()\n    avg_bureau['buro_count'] = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].groupby('SK_ID_CURR').count()['SK_ID_BUREAU']\n    del avg_bureau['SK_ID_BUREAU']\n    return avg_bureau","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing previous_application\ndef preprocess_previous_application(prev):\n    prev_cat_features = [pcol for pcol in prev.columns if prev[pcol].dtype == 'object']\n    prev = pd.get_dummies(prev, columns=prev_cat_features)\n    avg_prev = prev.groupby('SK_ID_CURR').mean()\n    cnt_prev = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    avg_prev['nb_app'] = cnt_prev['SK_ID_PREV']\n    del avg_prev['SK_ID_PREV']\n    return avg_prev\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess POS_CASH_balance.csv\ndef preprocess_pos_cash(POS_CASH):\n    le = LabelEncoder()\n    POS_CASH['NAME_CONTRACT_STATUS'] = le.fit_transform(POS_CASH['NAME_CONTRACT_STATUS'].astype(str))\n    nunique_status = POS_CASH[['SK_ID_CURR', 'NAME_CONTRACT_STATUS']].groupby('SK_ID_CURR').nunique()\n    nunique_status2 = POS_CASH[['SK_ID_CURR', 'NAME_CONTRACT_STATUS']].groupby('SK_ID_CURR').max()\n    POS_CASH['NUNIQUE_STATUS'] = nunique_status['NAME_CONTRACT_STATUS']\n    POS_CASH['NUNIQUE_STATUS2'] = nunique_status2['NAME_CONTRACT_STATUS']\n    POS_CASH.drop(['SK_ID_PREV', 'NAME_CONTRACT_STATUS'], axis=1, inplace=True)\n    return POS_CASH","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess credit_card_balance.csv\ndef preprocess_credit_card_balance(credit_card):\n    le = LabelEncoder()\n    credit_card['NAME_CONTRACT_STATUS'] = le.fit_transform(credit_card['NAME_CONTRACT_STATUS'].astype(str))\n    nunique_status = credit_card[['SK_ID_CURR', 'NAME_CONTRACT_STATUS']].groupby('SK_ID_CURR').nunique()\n    nunique_status2 = credit_card[['SK_ID_CURR', 'NAME_CONTRACT_STATUS']].groupby('SK_ID_CURR').max()\n    credit_card['NUNIQUE_STATUS'] = nunique_status['NAME_CONTRACT_STATUS']\n    credit_card['NUNIQUE_STATUS2'] = nunique_status2['NAME_CONTRACT_STATUS']\n    credit_card.drop(['SK_ID_PREV', 'NAME_CONTRACT_STATUS'], axis=1, inplace=True)\n    \n    return credit_card ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing payments\ndef preprocess_payments(payments):\n    '''\n    negative_day_features = ['DAYS_INSTALMENT', 'DAYS_ENTRY_PAYMENT']\n    for negative_feature in negative_day_features:\n        payments[negative_feature] = payments[negative_feature].apply(lambda day : day*(-1/365))\n    '''\n    payments_mean = payments.groupby('SK_ID_CURR').mean()\n    payments_max = payments.groupby('SK_ID_CURR').max()\n    payments_min = payments.groupby('SK_ID_CURR').min()\n\n    del payments_mean['SK_ID_PREV']\n    return payments_mean, payments_max, payments_min","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_all(data, test, bureau, bureau_balance, prev, POS_CASH, credit_card, payments):\n    bureau = preprocess_bureau_files(bureau, bureau_balance)\n    prev = preprocess_previous_application(prev)\n    POS_CASH = preprocess_pos_cash(POS_CASH)\n    credit_card = preprocess_credit_card_balance(credit_card)\n    payments_mean, payments_max, payments_min = preprocess_payments(payments)\n    \n    data = data.merge(right=prev.reset_index(), how='left', on='SK_ID_CURR')\n    data = data.merge(right=bureau.reset_index(), how='left', on='SK_ID_CURR')\n    data = data.merge(POS_CASH.groupby('SK_ID_CURR').mean().reset_index(), how='left', on='SK_ID_CURR')\n    data = data.merge(credit_card.groupby('SK_ID_CURR').mean().reset_index(), how='left', on='SK_ID_CURR')\n    data = data.merge(right=payments_mean.reset_index(), how='left', on='SK_ID_CURR')\n    data = data.merge(right=payments_max.reset_index(), how='left', on='SK_ID_CURR')\n    data = data.merge(right=payments_min.reset_index(), how='left', on='SK_ID_CURR')\n    \n    test = test.merge(right=prev.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=bureau.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(POS_CASH.groupby('SK_ID_CURR').mean().reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(credit_card.groupby('SK_ID_CURR').mean().reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=payments_mean.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=payments_max.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=payments_min.reset_index(), how='left', on='SK_ID_CURR')\n    return data, test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data = preprocess_application_files(data, test)\ndata = application_data.iloc[:data.shape[0],:]\ntest = application_data.iloc[data.shape[0]:,]\n\nprint('Combining all tables...')\ndata, test  = combine_all(data, test, bureau, bureau_balance, prev, POS_CASH, credit_card, payments)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.value_counts().plot(kind='bar');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Model Operations\n\nWe have a classification problem and we will start with LightGBM. Splitting data to the parts as train, validation and test is helpful for evaluation. But the result might be belongs to a particular split. This brings on the overfitting problem. We can use cross validation to solve this problem. We will consider K-Folds and Stratified K-Folds as a cross validator.   \n\nWhile selecting the right model validation method we will consider the dataset. As we can see in the above graphic, we have inbalance dataset. In this bar chart, 0 stands for customer will repay on time and 1 is opposite. Stratified K-Folds will enforce the class distribution in each split of the data to match the distribution in the complete training dataset.([source](https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/)) So, it means that we should prefer StratifiedKFold over KFold when dealing with classifications tasks with imbalanced class distributions.","metadata":{}},{"cell_type":"code","source":"import re\ndata = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\ntest = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LightGBM parameters based on this study -> https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code","metadata":{}},{"cell_type":"code","source":"def get_model():\n    clf = LGBMClassifier(\n            nthread=4,\n            n_estimators=10000,\n            learning_rate=0.03,\n            num_leaves=34,\n            colsample_bytree=0.9497036,\n            subsample=0.8715623,\n            max_depth=8,\n            reg_alpha=0.041545473,\n            reg_lambda=0.0735294,\n            min_split_gain=0.0222415,\n            min_child_weight=39.3259775,\n            silent=-1,\n            verbose=-1, )\n\n    return clf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\noof_preds = np.zeros(data.shape[0])\nsub_preds = np.zeros(test.shape[0])\n\nfeature_importance_df = pd.DataFrame()\n\nfeats = [f for f in data.columns if f not in ['SK_ID_CURR']]\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(data, target)):\n    trn_x, trn_y = data[feats].iloc[trn_idx], target.iloc[trn_idx]\n    val_x, val_y = data[feats].iloc[val_idx], target.iloc[val_idx]\n    \n    clf = get_model()\n    \n    clf.fit(trn_x, trn_y, \n            eval_set= [(trn_x, trn_y), (val_x, val_y)], \n            eval_metric='auc', verbose=100, early_stopping_rounds=100  #30\n           )\n    \n    oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n    sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = feats\n    fold_importance_df[\"importance\"] = clf.feature_importances_\n    fold_importance_df[\"fold\"] = n_fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n    del clf, trn_x, trn_y, val_x, val_y\n    gc.collect()\n\nprint('Full AUC score %.6f' % roc_auc_score(target, oof_preds)) \n\ntest['TARGET'] = sub_preds\n\ntest[['SK_ID_CURR', 'TARGET']].to_csv('1submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install lofo-importance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection\nWe have 504 features after all these preprocessing operations. More features might seem like a useful thing but indeed they can be harmful in some case. Sometimes irrelevant features, highly correlated features and also null values decrease the generalization of the model. After all features extracted we must perform feature selection to keep only the most useful variables. Feature selection is for calculating the importance of the features based on given metric and given model. Our model is LightGBM and the selected metric is roc. We will [LOFO-importance](https://github.com/aerdem4/lofo-importance) for this aim.\n","metadata":{}},{"cell_type":"code","source":"from lofo import LOFOImportance, Dataset, plot_importance\ndata['TARGET'] = target\ndataset = Dataset(df=data, target=\"TARGET\", features=[data.columns[i] for i in range(len(data.columns))])\nlofo_imp = LOFOImportance(dataset, cv=folds, model=get_model(), scoring='roc_auc')\nimportance_df = lofo_imp.get_importance()\nimportance_df\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nplot_importance(importance_df, figsize=(12, 12))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimisation\nHyperparameter optimization(known as tuning) is the way of choosing a set of optimal hyperparameters for choosed learning algorithm, LightGBM for our case. [Optuna](https://optuna.readthedocs.io/en/stable/#) is automated hyperparameter optimization framework for this aim. ","metadata":{}},{"cell_type":"code","source":"# Lets see how to change our study to use Optuna\n# Change the model for getting parameters from outside\ndef get_model(nthread, n_estimators, learning_rate, num_leaves, max_depth, min_split_gain, min_child_samples, reg_alpha, reg_lambda):\n    clf = LGBMClassifier(\n            nthread=nthread, #4,\n            n_estimators=n_estimators, #10000,\n            learning_rate=learning_rate, #0.03,\n            num_leaves=num_leaves, #34,\n            max_depth=max_depth, #8,\n            reg_alpha=reg_alpha, #0.041545473,\n            reg_lambda=reg_lambda, #0.0735294,\n            min_split_gain=min_split_gain, #0.0222415,\n            min_child_samples=min_child_samples,\n            silent=-1,\n            verbose=-1, )\n\n    return clf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an objection function for optuna\n# \nimport gc\ndef objective(data, test, trial):\n\n    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\n    oof_preds = np.zeros(data.shape[0])\n    sub_preds = np.zeros(test.shape[0])\n\n    feature_importance_df = pd.DataFrame()\n\n    feats = [f for f in data.columns if f not in ['SK_ID_CURR']]\n\n    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(data, target)):\n        trn_x, trn_y = data[feats].iloc[trn_idx], target.iloc[trn_idx]\n        val_x, val_y = data[feats].iloc[val_idx], target.iloc[val_idx]\n        \n        \n        nthread = trial.suggest_int('nthread',1,10)\n        n_estimators = trial.suggest_int('n_estimators',100,20000)\n        learning_rate = trial.suggest_loguniform('learning_rate',0.001,0.1)\n        num_leaves = trial.suggest_int('num_leaves',2,70)\n        max_depth = trial.suggest_int('max_depth',1,20)\n        min_split_gain = trial.suggest_discrete_uniform('min_split_gain', 0.1, 5, 0.01)\n        min_child_samples = trial.suggest_int('min_child_samples', 5, 100)\n        reg_alpha =  trial.suggest_loguniform('reg_alpha', 1e-8, 10.0)\n        reg_lambda = trial.suggest_loguniform('reg_lambda', 1e-8, 10.0)\n            \n        clf = get_model(nthread, n_estimators, learning_rate, num_leaves, max_depth, min_split_gain, min_child_samples, reg_alpha, reg_lambda)\n\n        clf.fit(trn_x, trn_y, \n                eval_set= [(trn_x, trn_y), (val_x, val_y)], \n                eval_metric='auc', verbose=100, early_stopping_rounds=100  #30\n               )\n\n        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n        sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n        del clf, trn_x, trn_y, val_x, val_y\n        gc.collect()\n\n        print('Full AUC score %.6f' % roc_auc_score(target, oof_preds)) \n        test['TARGET'] = sub_preds\n\n        return roc_auc_score(target, oof_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(lambda trial: objective(data, test, trial), n_trials=100)\n \nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}