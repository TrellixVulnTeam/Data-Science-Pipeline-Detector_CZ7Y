{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Kutuphanelerin yuklenmesi\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport gc\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Previous application\nimport pandas as pd\nprevious_application = pd.read_csv(\"../input/home-credit-default-risk/previous_application.csv\")\n\n#Verideki ilk 5 gözlem\npd.set_option('display.max_columns', None) \nprevious_application.head(2) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verideki tekil gözlemlerin sayısı\nprevious_application.nunique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verinin boyutu\nprevious_application.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verinin hakkında bilgiler\nprevious_application.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Previous application tablosundaki kategorik değişkenlerin tutulması\ncat_cols = [col for col in previous_application.columns if previous_application[col].nunique() < 30]\nprint(\"kategorik degisken sayısı : \" , len(cat_cols))\n\n#Verinin kategorik değişkenlerinin hedef değişkene gore durumları\ndef cat_summary(dataframe,target, noc=30):\n    print(\"CATEGORICAL FEATURE ANALYSIS\",end=\"\\n\\n\")\n    var_count = 0\n    vars_more_classes = []\n    for var in cat_cols:\n        if dataframe[var].nunique() <= noc:  # sınıf sayısına göre seç\n            print(var, \": has\",dataframe[var].nunique(), \"unique category\",\"\\t-\",str(dataframe[var].dtypes),end=\"\\n\\n\")\n            print(pd.DataFrame({var: dataframe[var].value_counts(),\n                                \"Count\": len(dataframe[var]),\n                                \"Ratio\": 100 * dataframe[var].value_counts() / len(dataframe),\n                                \"TARGET_MEAN\": dataframe.groupby(var)[target].mean()}),end=\"\\n\\n\\n\")\n            var_count += 1\n            \n            print(\"\\n\\n\")\n        else:\n            vars_more_classes.append(dataframe[var].name)\n    print('%d categorical variables have been described' % var_count, end=\"\\n\\n\")\n    print('There are', len(vars_more_classes), \"variables have more than\", noc, \"classes\", end=\"\\n\\n\")\n    print('Variable names have more than %d classes:' % noc, end=\"\\n\\n\")\n    print(vars_more_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Histogram cizdirilmesi icin sayısal degiskenlerin secilmesi\n\nnum_cols = [col for col in previous_application.columns if previous_application[col].dtypes != 'O' and col not in \"Id\"\n           and previous_application[col].nunique() > 30]\nprint('Sayısal değişken sayısı: ', len(num_cols))\n\n\n#Sayısal degiskenlerin histogramına bakılmasını sağlayan fonksiyon.\ndef hist_for_nums(data, numeric_cols):\n    col_counter = 0\n    data = data.copy()\n    for col in numeric_cols:\n        data[col].hist(bins=20)\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n        col_counter += 1\n    print(col_counter, \"variables have been plotted\")\n\n\nhist_for_nums(previous_application, num_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encoding for categorical columns with get_dummies\ndef one_hot_encoder(df, nan_as_category = False):\n    original_columns = list(df.columns)\n    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n    new_columns = [c for c in df.columns if c not in original_columns]\n    return df, new_columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Preprocess application_train.csv and application_test.csv\ndef application_train_test(num_rows = None, nan_as_category = False):\n    # Read data and merge\n    df = pd.read_csv('../input/home-credit-default-risk/application_train.csv', nrows= num_rows)\n    test_df = pd.read_csv('../input/home-credit-default-risk/application_test.csv', nrows= num_rows)\n    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n    df = df.append(test_df).reset_index()\n    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n    df = df[df['CODE_GENDER'] != 'XNA']\n    \n    # Categorical features with Binary encode (0 or 1; two categories)\n    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n    # Categorical features with One-Hot encode\n    df, cat_cols = one_hot_encoder(df, nan_as_category)\n    \n    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n    \n\n    # Some simple new features (percentages)\n    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n    \n    #yeniler\n    \n    df[\"app_1\"] = df[\"EXT_SOURCE_1\"] * df[\"OBS_30_CNT_SOCIAL_CIRCLE\"]\n    df[\"app_2\"] = df[\"EXT_SOURCE_1\"] * df[\"AMT_INCOME_TOTAL\"]\n    df[\"app_3\"] = df[\"NONLIVINGAPARTMENTS_AVG\"] * df[\"OWN_CAR_AGE\"]\n    df[\"app_4\"] = df[\"EXT_SOURCE_2\"] * df[\"OBS_30_CNT_SOCIAL_CIRCLE\"]\n    df[\"app_5\"] = df[\"EXT_SOURCE_3\"] * df[\"OBS_30_CNT_SOCIAL_CIRCLE\"]\n    df[\"app_6\"] = (df[\"AMT_CREDIT\"] * df[\"AMT_ANNUITY\"]) * (df[\"AMT_INCOME_TOTAL\"])\n    \n    del test_df\n    gc.collect()\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef previous_applications(num_rows = None, nan_as_category = False):\n    prev = pd.read_csv('../input/home-credit-default-risk/previous_application.csv', nrows = num_rows)\n    prev, cat_cols = one_hot_encoder(prev, nan_as_category= False)\n    # Days 365.243 values -> nan\n    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n    # Add feature: value ask / value received percentage\n    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n    \n    prev[\"new_1\"] = (prev.AMT_DOWN_PAYMENT * prev.RATE_DOWN_PAYMENT)\n    prev[\"new_2\"] = (prev.AMT_DOWN_PAYMENT * prev.AMT_CREDIT)\n    prev[\"new_3\"] = (prev.AMT_APPLICATION *  prev.AMT_GOODS_PRICE)\n    prev[\"new_4\"] = (prev.AMT_DOWN_PAYMENT * prev.AMT_APPLICATION)\n    prev[\"new_5\"] = (prev.AMT_DOWN_PAYMENT * prev.AMT_ANNUITY)\n   \n    # Previous applications numeric features\n    num_aggregations = {\n        'AMT_ANNUITY': ['mean'],\n        'AMT_APPLICATION': ['mean'],\n        'AMT_CREDIT': ['mean'],\n        'APP_CREDIT_PERC': ['mean'],\n        'AMT_DOWN_PAYMENT': ['mean'],\n        'AMT_GOODS_PRICE': ['mean'],\n        'HOUR_APPR_PROCESS_START': ['mean'],\n        'RATE_DOWN_PAYMENT': ['mean'],\n        'DAYS_DECISION': ['max'],\n        'CNT_PAYMENT': ['mean'],\n\n    }\n    # Previous applications categorical features\n    cat_aggregations = {}\n    for cat in cat_cols:\n        cat_aggregations[cat] = ['mean']\n    \n    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n    # Previous Applications: Approved Applications - only numerical features\n    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n    # Previous Applications: Refused Applications - only numerical features\n    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n    del refused, refused_agg, approved, approved_agg, prev\n    gc.collect()\n    return prev_agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tabloların birlestirilmesi\n\ndf = application_train_test()\nprev = previous_applications()\nprint(\"Previous applications df shape:\", prev.shape)\ndf = df.join(prev, how='left', on='SK_ID_CURR')\n#del prev\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kategorik değiskenlerin sınıfları\nprev_orj = pd.read_csv(\"../input/home-credit-default-risk/previous_application.csv\")\nprev_cat_cols = [col for col in prev_orj.columns if prev_orj[col].nunique() < 30]\n\n\nfor i in prev_cat_cols:\n    print(\"*\" * 100)\n    print(i)\n    print(prev_orj[i].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#application_train ve previous_application tablolarının özetleri(iki tablodaki sayısal degiskenlerin \"TARGET\"e gore durumları)\ndef target_summary_with_nums(data, target):\n    num_names = [col for col in data.columns if len(data[col].unique()) > 30\n                 and data[col].dtypes != 'O']\n\n    for var in num_names:\n        print(data.groupby(target).agg({var: np.median}), end=\"\\n\\n\\n\")\n    \ntarget_summary_with_nums(df , \"TARGET\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Numerik ve kategorik degiskenlerin tespiti ve tutulması\ndef get_categorical_and_numeric_columns(dataframe, exit_columns, number_of_unique_classes=10):\n    \"\"\"\n    -> Kategorik ve sayısal değişkenleri belirler.\n\n    :param dataframe: İşlem yapılacak dataframe\n    :param exit_columns: Dikkate alınmayacak değişken ismi\n    :param number_of_unique_classes: Değişkenlerin sınıflarının frekans sınırı\n    :return: İlk değer olarak kategorik sınıfların adını, ikinci değer olarak sayısal değişkenlerin adını döndürür.\n\n    \"\"\"\n\n    categorical_columns = [col for col in dataframe.columns\n                           if len(dataframe[col].unique()) <= number_of_unique_classes]\n\n    numeric_columns = [col for col in dataframe.columns if len(dataframe[col].unique()) > number_of_unique_classes\n                       and dataframe[col].dtype != \"O\"\n                       and col not in exit_columns]\n\n    return categorical_columns, numeric_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kategorik değişken analizi(previous_applcation - TARGET)\nprev_target = pd.concat([prev , df.TARGET] , axis = 1)\nprev_target.shape\n\n#Kategorik değişken analizi\ncat_cols = [col for col in prev_target.columns if prev_target[col].nunique() < 10]\nprint(\"kategorik degisken sayısı : \" , len(cat_cols))\n\n#get_categorical_and_numeric_columns(prev_target , \"TARGET\" )\n\ncat_summary(prev_target , \"TARGET\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Nadirlik durumunun incelenmesi\ndef rare_analyser(dataframe, categorical_columns, target, rare_perc):\n    \"\"\"\n     Data frame değişkenlerinin herhangi bir sınıfı, verilen eşik değerden düşük frekansa sahipse bu değişkenleri gösterir.\n    :param dataframe: İşlem yapılacak dataframe\n    :param categorical_columns: Rare analizi yapılacak kategorik değişken adları\n    :param target: Analizi yapılacak hedef değişken adı\n    :param rare_perc: Rare için sınır değer. Altında olanlar rare kategorisine girer.\n    :return:\n    \"\"\"\n    rare_columns = [col for col in categorical_columns\n                    if (dataframe[col].value_counts() / len(dataframe) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        print(var, \" : \", len(dataframe[var].value_counts()))\n\n        print(pd.DataFrame({\"COUNT\": dataframe[var].value_counts(),\n                            \"RATIO\": dataframe[var].value_counts() / len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(var)[target].mean(),\n                            \"TARGET_MEDIAN\": dataframe.groupby(var)[target].median()}),\n              end=\"\\n\\n\\n\")\n\n    print(len(rare_columns), \" adet rare sınıfa sahip değişken var.\")\n    \nrare_analyser(prev_target ,cat_cols , \"TARGET\" , 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Aykırı degerlerin sınırlarının belirlenmesi\ndef outlier_thresholds(dataframe, variable, low_quantile=0.05, up_quantile=0.95):\n    \"\"\"\n    -> Verilen değerin alt ve üst aykırı değerlerini hesaplar ve döndürür.\n    :param dataframe: İşlem yapılacak dataframe\n    :param variable: Aykırı değeri yakalanacak değişkenin adı\n    :param low_quantile: Alt eşik değerin hesaplanması için bakılan quantile değeri\n    :param up_quantile: Üst eşik değerin hesaplanması için bakılan quantile değeri\n    :return: İlk değer olarak verilen değişkenin alt sınır değerini, ikinci değer olarak üst sınır değerini döndürür\n    \"\"\"\n    quantile_one = dataframe[variable].quantile(low_quantile)\n\n    quantile_three = dataframe[variable].quantile(up_quantile)\n\n    interquantile_range = quantile_three - quantile_one\n\n    up_limit = quantile_three + 1.5 * interquantile_range\n\n    low_limit = quantile_one - 1.5 * interquantile_range\n\n    return low_limit, up_limit\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Aykırı degerlerin baskılanması\ndef replace_with_thresholds(dataframe, numeric_columns):\n    \"\"\"\n    Baskılama yöntemi\n    Silmemenin en iyi alternatifidir.\n    Loc kullanıldığından dataframe içinde işlemi uygular.\n    :param dataframe: İşlem yapılacak dataframe\n    :param numeric_columns: Aykırı değerleri baskılanacak sayısal değişkenlerin adları\n    \"\"\"\n    for variable in numeric_columns:\n        low_limit, up_limit = outlier_thresholds(dataframe, variable)\n\n        dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n\n        dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Baskılama işlemi için numerik degişkenlerin tespiti\nnum_cols = [col for col in prev_target.columns if len(prev_target[col].unique()) > 30\n                 and prev_target[col].dtypes != 'O']\n#Baskılama isleminin gerçeklestirilmesi\nreplace_with_thresholds(prev_target, num_cols )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sayısal degiskenlerin(previous_application) TARGET'e gore durumları \ndef target_summary_with_nums(data, target):\n    num_names = [col for col in data.columns if len(data[col].unique()) > 30\n                 and data[col].dtypes != 'O']\n\n    for var in num_names:\n        print(data.groupby(target).agg({var: np.mean}), end=\"\\n\\n\\n\")\n    \ntarget_summary_with_nums(prev_target , \"TARGET\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NUMERİK DEGİSKENLERİN TARGET DEGİSKENİNE GORE DURUMLARI (previous_application )\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nnum_cols_prev = [col for col in prev_target.columns if prev_target[col].nunique() > 30 ]\n\nlen(num_cols_prev)\n\n#Tum degiskenlerin target degiskenine gore gorsellestirilmesi\nimport seaborn as sns\n\nfor i in num_cols_prev:\n    \n    sns.catplot(x = \"TARGET\"  , y= i ,data = prev_target , kind=\"violin\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None) \nprev_target.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NEW_DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}