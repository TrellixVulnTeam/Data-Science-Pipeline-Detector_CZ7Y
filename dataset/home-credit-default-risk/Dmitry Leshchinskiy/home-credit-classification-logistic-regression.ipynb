{"cells":[{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/homecredit/home_credit.png\")","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"-"},"trusted":true},"cell_type":"code","source":"%config IPCompleter.greedy=True\nimport pandas as pd\nimport numpy as nm\nimport matplotlib.pyplot as plt\nimport warnings\nimport random\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"-"},"trusted":true},"cell_type":"code","source":"def chooseColor():\n    colors=['b', 'g', 'r','c','m','y']\n    return colors[random.randint(0,5)]","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"-"},"trusted":true},"cell_type":"code","source":"def NanTooMany(dataq):\n    mis_val_percent = pd.DataFrame(100 * dataq.isnull().sum() / len(dataq))\n    mis_val_percent= mis_val_percent[mis_val_percent[0]>=50]\n    print(\"Missing values in percentage, columns to drop\")\n    print(mis_val_percent.sort_values(by=0,ascending=False))\n    mis_val_percent.index.name=\"name\"\n    for index in mis_val_percent.iterrows(): \n        dataq=dataq.drop(index[0],axis=1)\n    return dataq","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"-"},"trusted":true},"cell_type":"code","source":"def checkMatches(data,dat):\n    sat=set(data['SK_ID_CURR']) & set(dat['SK_ID_CURR'])\n    match=len(sat)/len(data['SK_ID_CURR'])\n    print(\"percent of matching records: \"+ str(match))\n    if match>0.70:\n        dataq=pd.merge(data, dat, how='left', on='SK_ID_CURR')\n    return dataq","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Data Selection\n## Three datafiles are selected to meet the project needs\n- application_train includes data for current credit application and binary TARGET variable \n- bureau includes data on previous credits issued for a specific application available in application_train\n- previous_application includes data on previous applications submited to the same institution\n\n### Keeping columns that include less than 50% of missing values\n_output provides list of the droped columns and missing values percent per data file_"},{"metadata":{"scrolled":true,"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"\napplication = pd.read_csv(\"../input/homecredit-labeled/application_train.csv\")\nbureau = pd.read_csv(\"../input/home-credit-default-risk/bureau.csv\")\nprevious_app = pd.read_csv(\"../input/home-credit-default-risk/previous_application.csv\")\napplication=NanTooMany(application)\nbureau=NanTooMany(bureau)\nprevious_app=NanTooMany(previous_app)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Target Variable Distribution\n\n### Supervised learning is based on labeled data\n### The dataset inludes target variable\n\n* 1 Defaulted applications\n* 0 Repaid applications\n\n_data set is unbalanced which is important for model accuracy method selection_"},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"\nd= application['TARGET'].value_counts()\nplt.figure(figsize=(10,1))\nplt.title(\"TARGET\")\ny_pos = nm.arange(len(d.index))\n        # Create horizontal bars\nplt.barh( d.index, d.values,color= chooseColor())\n \n        # Create names on the y-axis\nplt.yticks(y_pos, ['Repaid','Defaulted'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"<h1><u>Feature engineering</u></h1>\n\nThe dataset includes raw data. The following part includes engineering of various features that could help us to explain why certain customers are defaulted in reapying their credits. \n\nFor every new fetuare we control the percentage of corresponding records if coming from different datatables\n\n### 1. Binary Overdue\n#### if current applicant has a credit overdue on any other credit registered at the authorities ( 1 if overdue, 0 his credit histrory has no negative records)"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"##adding overdue column 1 if overdue for a app exists\nbureau_overdue= bureau[['SK_ID_CURR','AMT_CREDIT_SUM_OVERDUE']]\nbureau_overdue= bureau_overdue.groupby(by='SK_ID_CURR').max().reset_index()\nbureau_overdue['overdue']=bureau_overdue['AMT_CREDIT_SUM_OVERDUE'].apply(lambda x: 1 if x >0 else 0)\nbureau_overdue=bureau_overdue.drop('AMT_CREDIT_SUM_OVERDUE', axis=1)\napplication1= checkMatches(application,bureau_overdue)\nd=application1['overdue'].value_counts()\nd","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,1))\nplt.barh(d.index,d.values,color= chooseColor())\nplt.title(\"Overdue\")\ny_pos = nm.arange(len(d.index))\nplt.yticks(y_pos, ['Repaid on time','Overdue payment'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### 2. Binary New Customer\n#### We like to investigate if the current aplicant has already applied to credit at this institution ( 1 if new customer otherwise 0)"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"##adding new customer column 1 if new customer\nhas_previous_application=set(previous_app['SK_ID_CURR']) & set(application['SK_ID_CURR'])\ndt={'SK_ID_CURR':list(has_previous_application)}\nnewCustomers=pd.DataFrame(dt)\nnewCustomers['new_customer']=0\napplication1=checkMatches(application1,newCustomers)\napplication1['new_customer']=application1['new_customer'].apply(lambda x: 1 if x!=0 else 0)\nd=application1['new_customer'].value_counts()\nd","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,1))\n\nplt.barh(d.index,d.values,color= chooseColor())\nplt.title(\"New customer\")\ny_pos = nm.arange(len(d.index))\n        # Create names on the y-axis\nplt.yticks(y_pos, ['Already has credit','Does not have credits'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### 3.Binary Last contract status\n#### To investigate if the last application/offer was approved , rejected, unused, canceled ( 1 if positive: approved, unused. 0 if negative)"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"##adding column last contract status 1 is positive ( approved and unused offer) othrwise 0\nhello=previous_app[['SK_ID_CURR','SK_ID_PREV', 'NAME_CONTRACT_STATUS']].groupby(by='SK_ID_CURR').max().reset_index()\nhello['lastContractStatus']= hello['NAME_CONTRACT_STATUS'].apply(lambda x: 1 if x=='Approved'or x=='Unused offer' else 0)\nnew_pv_app=hello[['SK_ID_CURR','lastContractStatus']]\napplication1=checkMatches(application1,new_pv_app)\nd=application1['lastContractStatus'].value_counts()\nd","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,1))\nplt.barh(d.index,d.values,color= chooseColor())\nplt.title(\"Status of the last application\")\ny_pos = nm.arange(len(d.index))\n \n        # Create names on the y-axis\nplt.yticks(y_pos, ['Negative','Positive'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### 4.Converting days from birth to years from birth\n\nOur dataset includes days from birth which is probably should be converted into years to see if there is a relationship between age of a person and payment default"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"application1['DAYS_BIRTH']= pd.to_numeric(application1['DAYS_BIRTH'].abs()/365, downcast=\"signed\")\napplication1['YEARS_BIRTH']=application1['DAYS_BIRTH']\napplication1=application1.drop('DAYS_BIRTH',axis=1)\napplication1['YEARS_BIRTH'].describe()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"application1['YEARS_BIRTH'].plot(kind='density',figsize=(5,3), title=\"Applicants Age\")","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## 5.Converting days since started new job to months\n\nSimilary to the above, we like to invesigate the number of months person spent on the last place of work. We choose months over years because we cannot expect from an employee staying significant number of years with the same employee."},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"application1['DAYS_EMPLOYED']= pd.to_numeric(application1['DAYS_EMPLOYED'].abs(), downcast=\"signed\")\napplication1['MONTHS_EMPLOYED']=application1['DAYS_EMPLOYED']/30\napplication1=application1.drop('DAYS_EMPLOYED',axis=1)\nmed=application1['MONTHS_EMPLOYED'].median()\napplication1['MONTHS_EMPLOYED']=application1['MONTHS_EMPLOYED'].apply(lambda x :med if x>4800 else x)\napplication1['MONTHS_EMPLOYED'].describe()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"application1['MONTHS_EMPLOYED'].plot(kind='density',figsize=(5,3), title=\"Employee Seniority\")","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## 6.Number of documents provided by a customer\n\nProbably number of provided documents has relationship with payment default. Additional documents might have some prove of applicants financial stability."},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"coro=application1.filter(regex=('FLAG_DOCUMENT_') )\ncoro['SK_ID_CURR']=application1['SK_ID_CURR']\ncoro['TARGET']=application1['TARGET']\ncoro['totalDocuments']=coro[['FLAG_DOCUMENT_2','FLAG_DOCUMENT_3','FLAG_DOCUMENT_4',\n                    'FLAG_DOCUMENT_5','FLAG_DOCUMENT_6','FLAG_DOCUMENT_7','FLAG_DOCUMENT_8','FLAG_DOCUMENT_9','FLAG_DOCUMENT_10',\n                    'FLAG_DOCUMENT_11','FLAG_DOCUMENT_12','FLAG_DOCUMENT_13','FLAG_DOCUMENT_14','FLAG_DOCUMENT_15','FLAG_DOCUMENT_16',\n                    'FLAG_DOCUMENT_17','FLAG_DOCUMENT_18','FLAG_DOCUMENT_19','FLAG_DOCUMENT_20','FLAG_DOCUMENT_21']].sum(axis=1)\nd=coro['totalDocuments'].value_counts()\nd","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"#### Investigate if the totalDocuments and Target are independent\n\nWe want to investigate if defaults can be explained by low number of provided documents \n\n_method cross-tabulation, chi square_\nAssumptions:\n* independence\n* cell number should be higher than 5\n\nNull hypotesis:target variable is independent of number of documents provided."},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"hu=pd.crosstab(coro['TARGET'],coro['totalDocuments'])\nhu.head()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"##checking is there is association : H0=variables are independent\nfrom scipy import stats\nchi2, p, dof, ex=stats.chi2_contingency(hu)\nprint(str(p)+\" p < 0.05 reject H0. Variables are not independent and \\n there is a relationship between number of provided documents and default\")","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"#### Binary if customer provided documents\nDerivating fetuare to see if those customers who have provided documents have not defalted\n\n##### 1 at least document was provided"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"coro['document_provided']=coro['totalDocuments'].apply(lambda x: 1 if x > 0  else 0)\nd=coro['document_provided'].value_counts()\nd","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,1))\nplt.barh(d.index,d.values,color=chooseColor())\nplt.title(\"Documents provided by customer\")\ny_pos = nm.arange(len(d.index))\n\n        # Create names on the y-axis\nplt.yticks(y_pos, ['Not provided','Provided'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"-"},"trusted":true},"cell_type":"code","source":"application1=application1[application1.columns.drop(list(application1.filter(regex='FLAG_DOCUMENT_')))]\napplication1['document_provided']=coro['document_provided']\napplication1['totalDocuments']=coro['totalDocuments']\n","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## 7.Sum current credit (quantitative)\n\nInvestigate if there is a relationship between sum of current credits and credit default\n"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"##current credit volume\nbureau['AMT_CREDIT_SUM_DEBT']=bureau['AMT_CREDIT_SUM_DEBT'].fillna(0).abs()\ncredit=pd.DataFrame({'SK_ID_CURR':bureau['SK_ID_CURR'], 'debt':bureau['AMT_CREDIT_SUM_DEBT']})\ncredit=credit.groupby(by='SK_ID_CURR').sum().reset_index()\napplication3=checkMatches(application1,credit)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\napplication3['debt'].describe()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"plt.title(\"Existing debt no extreme values\")\napplication3.boxplot(column='debt',showfliers=False, figsize=(5,5))","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## 8.Binary Repaid all credits\n\nInvestigate if all previously taken credits have been repaid.\n\n#### 1 if all the taken credit have been repaid"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"##if al credit talen by customer have been repaid\nbureau['CREDIT_SCORE']=bureau['CREDIT_ACTIVE'].apply(lambda x :1 if x==\"Closed\" else -200)\nnn={'SK_ID_CURR':bureau['SK_ID_CURR'],'repaidCredit':bureau['CREDIT_SCORE']}\ngooCustomer=pd.DataFrame(nn)\ngooCustomer=gooCustomer.groupby(by='SK_ID_CURR').sum().reset_index()\ngooCustomer['repaidCredit']=gooCustomer['repaidCredit'].apply(lambda x:1 if x>0 else 0)\napplication4= checkMatches(application3, gooCustomer)\nd= application4['repaidCredit'].value_counts()\nd","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,1))\nplt.barh(d.index,d.values,color=chooseColor())\nplt.title(\"All credits been repaid\")\ny_pos = nm.arange(len(d.index))\n \n\n \n        # Create names on the y-axis\nplt.yticks(y_pos, ['No details provided','All been repaid'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## 9.Binary Repaid Last Credit\n #### 1 if repaid\n \n The number of defaulted customers is low so we will only study not defaulted customers\n \n "},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"##bureau1 = pd.read_csv(\"bureau.csv\")\n##if the last credit has been repaid\nlastCredit=pd.DataFrame({\"dateClosed\":bureau['DAYS_CREDIT_ENDDATE'],'SK_ID_CURR':bureau['SK_ID_CURR'],'status':bureau['CREDIT_ACTIVE']})\nlastCredit['dateClosed']=lastCredit['dateClosed'].apply(lambda x :x if x<=0 else 1)\nlastCredit['status']=lastCredit['status'].apply(lambda x :1 if x==\"Closed\" else 0)\nlastCredit=lastCredit[lastCredit['dateClosed']<=0]\nlastCredit=lastCredit.groupby(by='SK_ID_CURR').max().reset_index()\nlastCreditPaid=pd.DataFrame(lastCredit[lastCredit['status']==1])\nlastCreditFail=pd.DataFrame(lastCredit[lastCredit['status']==0])\nprint(\"repaid customers: \"+str(len(lastCreditPaid))+ \" defauled customers: \"+ str(len(lastCreditFail)))\nlastCreditPaid.drop('status',axis=1)\nlastCreditFail.drop('status',axis=1)\napplication5= checkMatches(application4,lastCreditPaid)\napplication5['repaidLastCredit']= application5['dateClosed'].apply(lambda x:1 if x<=0 else 0)\napplication5=application5.drop('dateClosed',axis=1)\napplication5=application5.drop('status', axis=1)\nd= application5['repaidLastCredit'].value_counts()\nd","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,1))\nplt.barh(d.index,d.values,color=chooseColor())\nplt.title(\"The customers who repaid the last credit\")\ny_pos = nm.arange(len(d.index))\n \n        # Create horizontal bars\nplt.barh( d.index, d.values)\n \n        # Create names on the y-axis\nplt.yticks(y_pos, ['No details','Repaid'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"<h1> <u>AVAILABLE VARIABLES AFTER FEATURE ENGINEERING</u></h1>"},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"application5.columns","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"<h1><u> QUANTITATIVE DATA REVIEW </u></h1>\n\nStart with studing correlation between target and available variables we will follow to review the relationship on the pairplot. \n"},{"metadata":{"slideshow":{"slide_type":"-"},"trusted":true},"cell_type":"code","source":"quant= application5[['TARGET','CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',  'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH',  'CNT_FAM_MEMBERS', \n          'HOUR_APPR_PROCESS_START', 'EXT_SOURCE_2','REGION_POPULATION_RELATIVE', 'EXT_SOURCE_3','YEARS_BEGINEXPLUATATION_AVG', 'FLOORSMAX_AVG',\n        'YEARS_BEGINEXPLUATATION_MODE', 'FLOORSMAX_MODE', 'YEARS_BEGINEXPLUATATION_MEDI', 'FLOORSMAX_MEDI', 'TOTALAREA_MODE',\n 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', \n        'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR',\n'YEARS_BIRTH', 'MONTHS_EMPLOYED',  'totalDocuments', 'debt']]\n","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Correlation with target variable\n\nUsing Spearman correlation to investigate if there is any relationship between target variable and other quantitative fetuares\n\nSpearman correlation assumptions:\n- same level of measurement\n- related pairs\n- absence of outliers\n- normality of variables\n- linearity\n- homoscedasticity"},{"metadata":{"scrolled":true,"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler \nscaler = MinMaxScaler()\nscaler.fit(quant)\nqnt=pd.DataFrame(scaler.transform(quant), columns= quant.columns)\nquant.corr('spearman')['TARGET'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"The correlation resultis are rather poor so to continue with our analysis we wlll keep only features with at least 4% correlation.\nData visualisation will help us to see if data distribution, linearity, absence of outliers. The purpose of the data visualisation analysis is to investigate what variables should be chosen for model built with help of logistic regression and how they need to be preprocessed."},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Data Visulaization and Outliers Identification"},{"metadata":{"scrolled":true,"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"import seaborn as s\nvisual=quant[['TARGET','AMT_INCOME_TOTAL','DAYS_LAST_PHONE_CHANGE','DAYS_ID_PUBLISH','debt',\n'DAYS_REGISTRATION','DEF_30_CNT_SOCIAL_CIRCLE','FLOORSMAX_AVG','MONTHS_EMPLOYED','YEARS_BIRTH','EXT_SOURCE_2','EXT_SOURCE_3']]\ns.pairplot(visual)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"We can identify outliers in debt, default 30 days count in the social circle as well as the income columns.\nthe distribution of variables is not normal.\n"},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"<h1><u> Preparing and cleaning the data </u></h1>\n\n## Processing missing values\n\nThe dataset still includes some missing values\nThe following is the methods to replace them:\n\n- quantitative variable replaced with the variable median\n- categorical variables replaced with the variable frequency\n- binary depending on case: 0 or add 3 option\n\nExtreme values are removed(1% of top observations )\nY,N columns are refactored to 1,0\nData is normalized to fit with previously normilized data\n"},{"metadata":{"slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Spliting labeled data into test and train. ratio 0,3/0,7\nFurther analysis require data splitting into test and train data.\n* Train data in to be used for mode training\n* Test data is used to evaluate the model\n\nTraining data shape and available columns:"},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"def flagReplace(list,data):\n    for i in list:\n        data[i]=data[i].apply(lambda x:1 if x==\"Y\" else 0)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"def removeOutliers(array,data):\n    for i in array:\n        quant=data[i].quantile(0.99)\n        med=data[i].median()\n        ##data[i]=data[i][data[i]<quant]\n        data[i]=data[i].apply(lambda x:med if x >quant else x)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"def replaceColumn(list,train1, train):\n    for i in list:\n        train[i]=train1[i]\n    return train\n\ndef fillNaNumber(list,train, number):\n    for i in list:\n        if number==\"median\":\n            train[i]=train[i].fillna(train[i].median())\n           \n        elif number== \"freq\":\n            train[i] = train[i].fillna(train[i].value_counts().index[0])\n        else:\n            train[i]=train[i].fillna(number)\n    return train","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"prp= application5[['SK_ID_CURR','TARGET','EXT_SOURCE_2','EXT_SOURCE_3','debt','CNT_CHILDREN','new_customer','totalDocuments','overdue','lastContractStatus','document_provided','repaidCredit','repaidLastCredit','AMT_INCOME_TOTAL','DAYS_LAST_PHONE_CHANGE','DAYS_ID_PUBLISH','DAYS_REGISTRATION',\n                    'DEF_30_CNT_SOCIAL_CIRCLE','FLOORSMAX_AVG','MONTHS_EMPLOYED','YEARS_BIRTH','CNT_FAM_MEMBERS', 'CODE_GENDER','FLAG_OWN_CAR', 'FLAG_OWN_REALTY']]\nprp=fillNaNumber(['EXT_SOURCE_2','EXT_SOURCE_3','debt','CNT_CHILDREN','new_customer','totalDocuments','document_provided','repaidLastCredit'],prp,0)\nprp=fillNaNumber(['repaidCredit','overdue','lastContractStatus'],prp,2)\nprp=fillNaNumber(['AMT_INCOME_TOTAL','DAYS_LAST_PHONE_CHANGE','DAYS_ID_PUBLISH','DAYS_REGISTRATION',\n                    'DEF_30_CNT_SOCIAL_CIRCLE','FLOORSMAX_AVG','MONTHS_EMPLOYED','YEARS_BIRTH','CNT_CHILDREN'],prp,\"median\")\nprp=fillNaNumber(['CNT_FAM_MEMBERS', 'CODE_GENDER','FLAG_OWN_CAR', 'FLAG_OWN_REALTY'],prp,\"freq\")\nprp=flagReplace(['FLAG_OWN_CAR','FLAG_OWN_REALTY'],prp)\nprp['CODE_GENDER']=prp['CODE_GENDER'].apply(lambda x :1 if x==\"M\" else 2)\nprp=removeOutliers(['AMT_INCOME_TOTAL','debt','DEF_30_CNT_SOCIAL_CIRCLE'],prp)\nfrom sklearn.preprocessing import MinMaxScaler \nscaler = MinMaxScaler()\narr=['debt','AMT_INCOME_TOTAL','DAYS_LAST_PHONE_CHANGE','DAYS_ID_PUBLISH','DAYS_REGISTRATION','DEF_30_CNT_SOCIAL_CIRCLE','FLOORSMAX_AVG','MONTHS_EMPLOYED','YEARS_BIRTH']\nnorm = pd.DataFrame(prp[arr], columns=arr)\nscaler.fit(norm)\ntrainN=pd.DataFrame(scaler.transform(norm), columns=arr)\nt=replaceColumn(arr,trainN,prp)\nfinal= t","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport statsmodels.formula.api as smf\ntrain, test = train_test_split(final, test_size=0.3, random_state=1)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"Our dataset is inbalanced so accuracy is not good measure here, it only takes into account only number of correct assesments( TP and TN). \n\nFor the further analysis AUC is better measure it takes both TP and FP"},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Logistic regression: selecting model parameters \n_using rsquare to identify most beneficial linear and polynomial models_\n\nLooping thought all available combinations of variables we add new variable to our formula is Rsquared is increased and pvalues of the cooficientis not higher than 0,05\n\nWe conduct optimal model parameter search for linear model first after for polynomial squared component degree.In the latter case we compare if adding polynomial component is more beneficial than adding linear.\n\n\n"},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"def findlinear(prepare,train):\n    results={}\n    formul=\"TARGET~\"\n    for cl in prepare:\n        formul1=formul\n        formul+=cl\n        res = smf.logit(formul, data = train).fit()\n        check=False\n        for p in res.pvalues.values:\n            if p>=0.05:\n                check=True\n                formul=formul1\n        if check == False:\n            results[formul]=res.prsquared\n            formul+=\"+\"\n    return pd.Series(results)\n\ndef findPolyn(prepare, power,train):\n    results={}\n    formul=\"TARGET~\"\n    for cl in prepare:\n        formul1=formul\n        if cl[0:2]!=\"C(\":\n            formulL=formul+cl\n            formulP=formul+\"nm.power( \"+cl+\" ,\"+str(power)+\" )\"\n            resL = smf.logit(formulL, data = train).fit()\n            resP= smf.logit(formulP, data = train).fit()\n            checkL=False\n            checkP=False\n            for p in resL.pvalues.values:\n                if p>=0.05:\n                    checkL=True\n                \n            for p in resP.pvalues.values:\n                if p>=0.05:\n                    checkP=True\n            final=\"\"\n            if  checkL==True and checkP==False:\n                formul= formulP\n                results[formul]=resP.prsquared\n                formul+=\"+\"\n            elif checkP==True and checkL==False:\n                formul= formulL\n                results[formul]=resL.prsquared\n                formul+=\"+\"\n            elif  checkL==False and checkP==False and resL.prsquared > resP.prsquared:\n                formul= formulL\n                results[formul]=resL.prsquared\n                formul+=\"+\"\n            elif  checkL==False and checkP==False and resL.prsquared < resP.prsquared:\n                formul= formulP\n                results[formul]=resP.prsquared\n                formul+=\"+\"\n            elif checkL==True and checkP==True:\n                formul=formul1\n        else:\n            formul+=cl\n            \n            res = smf.logit(formul, data = train).fit()\n            check=False\n            for p in res.pvalues.values:\n                if p>=0.05:\n                    check=True\n                    formul=formul1\n            if check == False:\n                results[formul]=res.prsquared\n                formul+=\"+\"\n        \n    return pd.Series(results)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"#### Formulae for linear model\n\npayment default is dependent on the following factors:\n\nRSquared score is 0.079\n\nTARGET~EXT_SOURCE_2+EXT_SOURCE_3+debt+CNT_CHILDREN+totalDocuments+DAYS_LAST_PHONE_CHANGE+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+FLOORSMAX_AVG+MONTHS_EMPLOYED+CNT_FAM_MEMBERS+C(new_customer)+C(FLAG_OWN_CAR)+C(overdue)+C(document_provided)+C(repaidLastCredit)\n"},{"metadata":{"scrolled":true,"slideshow":{"slide_type":"-"},"trusted":true},"cell_type":"code","source":"'''\nprepare= ['EXT_SOURCE_2', 'EXT_SOURCE_3','totalDocuments','DAYS_LAST_PHONE_CHANGE','debt','FLOORSMAX_AVG', 'MONTHS_EMPLOYED', 'YEARS_BIRTH', 'CNT_FAM_MEMBERS',\n       'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'DEF_30_CNT_SOCIAL_CIRCLE',\n          'C(FLAG_OWN_CAR)', 'C(FLAG_OWN_REALTY)','C(new_customer)', 'C(overdue)',\n         'C(repaidCredit)','C(repaidLastCredit)']\n\n'''\nprepare= ['EXT_SOURCE_2', 'EXT_SOURCE_3', 'debt',\n       'CNT_CHILDREN', 'totalDocuments',\n        'AMT_INCOME_TOTAL', 'DAYS_LAST_PHONE_CHANGE',\n       'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'DEF_30_CNT_SOCIAL_CIRCLE',\n       'FLOORSMAX_AVG', 'MONTHS_EMPLOYED', 'YEARS_BIRTH', 'CNT_FAM_MEMBERS','C(document_provided)', 'C(repaidCredit)',\n       'C(FLAG_OWN_CAR)', 'C(FLAG_OWN_REALTY)', 'C(overdue)',\n       'C(repaidLastCredit)','C(lastContractStatus)']\n\nlinear=findlinear(prepare,train)\nprint(linear.sort_values(ascending=False).head(3))\n","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Formulas for polymonial model\n\nRsquare measure for the best model: 0.81\n\nEXT_SOURCE_2+ EXT_SOURCE_3^2+debt+CNT_CHILDREN+totalDocuments+AMT_INCOME_TOTAL^2+DAYS_LAST_PHONE_CHANGE^2+DAYS_ID_PUBLISH^2 + DAYS_REGISTRATION^2+DEF_30_CNT_SOCIAL_CIRCLE+MONTHS_EMPLOYED+CNT_FAM_MEMBERS^2+overdue+document_provided+repaidLastCredit+lastContractStatus\n\na less performant polynomial models:\n\nEXT_SOURCE_2+ EXT_SOURCE_3^2+debt+CNT_CHILDREN+totalDocuments+AMT_INCOME_TOTAL^2+DAYS_LAST_PHONE_CHANGE^2+DAYS_ID_PUBLISH^2 + DAYS_REGISTRATION^2+DEF_30_CNT_SOCIAL_CIRCLE+MONTHS_EMPLOYED+CNT_FAM_MEMBERS^2+overdue+document_provided+repaidLastCredit\n\nEXT_SOURCE_2+ EXT_SOURCE_3^2+debt+CNT_CHILDREN+totalDocuments+AMT_INCOME_TOTAL^2+DAYS_LAST_PHONE_CHANGE^2+DAYS_ID_PUBLISH^2 + DAYS_REGISTRATION^2+DEF_30_CNT_SOCIAL_CIRCLE+MONTHS_EMPLOYED+CNT_FAM_MEMBERS^2+overdue+document_provided"},{"metadata":{"slideshow":{"slide_type":"-"},"trusted":true},"cell_type":"code","source":"polynomial=findPolyn(prepare,2,train)\nprint(polynomial.sort_values(ascending=False).head(3))","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Compare models based on 6 selected formulas\n\n\n3 best performant linear models and 3 best performant polynomial\n\nAssessing with McFadden's pseudo R2 and RMSE\n\nR-squared is used to calculate the goodness of fit of a model. Regression R-squared has higher values between 0 and 1 for pseudo R squred the values are somehow smaller. Good fit according to McFadden is around 0.2 -0.4\nR squared is Explained variation / Total variation\nPseudo R squared is the ratio of explained log likelihood and  intercept log likelihood\n\nRoot Mean Square Error is the measure that shows deviation of residuals from the model\n\nWe like to maximze Pseudo Rsquared but minimize RMSE"},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"\nformulas=['TARGET~EXT_SOURCE_2+EXT_SOURCE_3+debt+CNT_CHILDREN+totalDocuments+DAYS_LAST_PHONE_CHANGE+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+FLOORSMAX_AVG+MONTHS_EMPLOYED+CNT_FAM_MEMBERS+C(new_customer)+C(FLAG_OWN_CAR)+C(overdue)+C(document_provided)+C(repaidLastCredit)',\n'TARGET~EXT_SOURCE_2+EXT_SOURCE_3+debt+CNT_CHILDREN+totalDocuments+DAYS_LAST_PHONE_CHANGE+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+FLOORSMAX_AVG+MONTHS_EMPLOYED+CNT_FAM_MEMBERS+C(new_customer)+C(FLAG_OWN_CAR)+C(overdue)+C(document_provided)',\n'TARGET~EXT_SOURCE_2+EXT_SOURCE_3+debt+CNT_CHILDREN+totalDocuments+DAYS_LAST_PHONE_CHANGE+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+FLOORSMAX_AVG+MONTHS_EMPLOYED+CNT_FAM_MEMBERS+C(new_customer)+C(FLAG_OWN_CAR)+C(overdue) ']\n    \nsqrtFormulas=['TARGET~EXT_SOURCE_2+nm.power( EXT_SOURCE_3 ,2 )+debt+CNT_CHILDREN+totalDocuments+nm.power( AMT_INCOME_TOTAL ,2 )+DAYS_LAST_PHONE_CHANGE+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+FLOORSMAX_AVG+MONTHS_EMPLOYED+CNT_FAM_MEMBERS+C(new_customer)+C(overdue)+C(document_provided)+C(repaidCredit)+C(repaidLastCredit)',\n'TARGET~EXT_SOURCE_2+nm.power( EXT_SOURCE_3 ,2 )+debt+CNT_CHILDREN+totalDocuments+nm.power( AMT_INCOME_TOTAL ,2 )+DAYS_LAST_PHONE_CHANGE+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+FLOORSMAX_AVG+MONTHS_EMPLOYED+CNT_FAM_MEMBERS+C(new_customer)+C(overdue)+C(document_provided)+C(repaidCredit)',\n'TARGET~EXT_SOURCE_2+nm.power( EXT_SOURCE_3 ,2 )+debt+CNT_CHILDREN+totalDocuments+nm.power( AMT_INCOME_TOTAL ,2 )+DAYS_LAST_PHONE_CHANGE+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+FLOORSMAX_AVG+MONTHS_EMPLOYED+CNT_FAM_MEMBERS+C(new_customer)+C(overdue)+C(document_provided)']\ndef compareMods(formulas,train):\n    for f in formulas:\n        res = smf.logit(f, data = train).fit()\n        print(\"R^2: \"+str(res.prsquared)+\" RMSE: \"+ str(nm.sqrt(nm.square(res.resid_response).sum()) / len(res.resid_response)))\nprint(\"----------------Linear Models-----------------\")  \ncompareMods(formulas,train)\nprint(\"----------------Polynomial Models-----------------\")\ncompareMods(sqrtFormulas,train)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"For further analysis we keep polynomial model as it has the most optimal performance:\n0.0810594509415421 RMSE: 0.0005712690111769795"},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### One- hot  encoding of categorical variables to proceed with cross validation\n\nTo proceed with cross validation a different library is used that requires categorical variables encoding\nThe following variables are encoded: \n* repaidCredit\n* overdue\n* lastContractStatus\n\nAvailable columns after one-hot encoding"},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"dummies= pd.get_dummies(prp[['repaidCredit','overdue','lastContractStatus']], columns=['repaidCredit','overdue','lastContractStatus'])\ntrainDummy=final\ntrainDummy=trainDummy.drop(['repaidCredit','overdue','lastContractStatus'],axis=1)\ntrainDummy=trainDummy.join(dummies)\ntrainDummy.columns","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Cross validation of linear and polynomial models\n\nIn the former approach we have created the model using 70% of the data. We now will investigate if the linear is less performant than the polynomial model with a help of cross validation:\n\n- the whole dataset is split in 5 folds\n- each group is hold as a test data\n- other 4 groups are used to train model\n- the process is conducted for all 5 groups\n- the final score is avarage score of each group score"},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"def CV(data,target):\n    clf = LogisticRegressionCV(cv=5, random_state=0, scoring=\"roc_auc\").fit(data, target)\n    print(\"AUC :\"+str(clf.score(data,target)))","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\n\ntarget= trainDummy['TARGET']\ndata= trainDummy[['EXT_SOURCE_2','EXT_SOURCE_3','debt','CNT_CHILDREN','new_customer','totalDocuments','DAYS_LAST_PHONE_CHANGE','DAYS_ID_PUBLISH','DAYS_REGISTRATION','DEF_30_CNT_SOCIAL_CIRCLE','FLOORSMAX_AVG','MONTHS_EMPLOYED','CNT_FAM_MEMBERS','FLAG_OWN_CAR','repaidCredit_0.0',\n       'repaidCredit_1.0', 'repaidCredit_2.0', 'overdue_0.0', 'overdue_1.0',\n       'overdue_2.0','lastContractStatus_0.0', 'lastContractStatus_1.0',\n       'lastContractStatus_2.0']]\n\nCV(data,target)\n","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"trainDummySqrt=trainDummy\ntrainDummySqrt['EXT_SOURCE_3']=trainDummySqrt['EXT_SOURCE_3']**2\n#trainDummySqrt['YEARS_BIRTH']=trainDummySqrt['YEARS_BIRTH']**2\ntrainDummySqrt['AMT_INCOME_TOTAL']=trainDummySqrt['AMT_INCOME_TOTAL']**2\ndata=trainDummySqrt[['EXT_SOURCE_2','EXT_SOURCE_3','debt','CNT_CHILDREN','new_customer','totalDocuments','AMT_INCOME_TOTAL','DAYS_LAST_PHONE_CHANGE','DAYS_ID_PUBLISH','DAYS_REGISTRATION','DEF_30_CNT_SOCIAL_CIRCLE','FLOORSMAX_AVG','MONTHS_EMPLOYED','CNT_FAM_MEMBERS','repaidCredit_0.0',\n       'repaidCredit_1.0', 'repaidCredit_2.0', 'overdue_0.0', 'overdue_1.0',\n       'overdue_2.0', 'document_provided', 'repaidLastCredit']]\n#data1=trainDummySqrt[['EXT_SOURCE_2','EXT_SOURCE_3','totalDocuments','DAYS_LAST_PHONE_CHANGE','debt','FLOORSMAX_AVG','MONTHS_EMPLOYED','YEARS_BIRTH','AMT_INCOME_TOTAL','DAYS_ID_PUBLISH','DAYS_REGISTRATION','DEF_30_CNT_SOCIAL_CIRCLE','new_customer_1','overdue_0.0', 'overdue_1.0', 'overdue_2.0']]\n#data2=trainDummySqrt[['EXT_SOURCE_2','EXT_SOURCE_3','totalDocuments','DAYS_LAST_PHONE_CHANGE','debt','FLOORSMAX_AVG','MONTHS_EMPLOYED','YEARS_BIRTH','AMT_INCOME_TOTAL','DAYS_ID_PUBLISH','DAYS_REGISTRATION','DEF_30_CNT_SOCIAL_CIRCLE','new_customer_1']]\nCV(data,target)\n#CV(data1,target)\n#CV(data2,target)\n","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"### ROC-AUC measure\nROC plots performance of a classification model at all classification thresholds (0,...1 )\nIt takes into account for both correctly predicted and uncorrectly predicted results\nOn x axis it plots True Positive Rate per threshold\nTP/(TP+FN)\nOn y axis it plots False Positive rate per threshold\nFP/(FP+TN)\n\nThe curve is ploted over the diagonal that corresponds to a model with random prediction which is 50% of chance for banary classification. The area over the curve is what corresponding to AUC measure.\n\nWe can see that polynomial model explains payment default by 71,6% whereas linear by 71,3%\n\n\n\n"},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Hyperparameters tunning\n\nAfter the model has been selected we need to proceed with fine tunning of its parameters to maximize its performance.\n\n#### Grid Search\nGrid search, or a parameter sweep is an exhaustive searching through specified subset of the hyperparameter space of a learning algorithm.\n\nFor more accurate result we combine hyperparameters search with cross validation to use all the available data for hyper parameter tunning\n\nThe folliwng hyperparameters are to be tuned: 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \"penalty\":[\"l1\",\"l2\"]"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\ngrid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \"penalty\":[\"l1\",\"l2\"]}\nlogit=LogisticRegression()\ncv=GridSearchCV(logit,grid,cv=5,scoring=\"roc_auc\")\ncv.fit(data,target)\n\nprint(\"Tuned parameters:\",cv.best_params_)\nprint(\"AUC score for the best parametrized model:\",cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Testing fine tunned model on available test set"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25)\nlog=LogisticRegression(C= 10, penalty='l1',solver='liblinear').fit(X_train,y_train)\nres=log.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\nprint(\"-----------CONFUSION MATRIX----------\")\nprint(confusion_matrix(y_test, res, labels=[0,1]))\n","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"}},"cell_type":"markdown","source":"The confusion martix shows that model predicted  70609 true positive ( correctly predicted non defaulted applications) and 3 true negative ( correctly predicted defaulted applications) \n\n6265 was incorrectly predicted as false negative ( repaid applicats predicted as defalted) and 1 incorrectly predicted as true positive ( someone who defaulted by predicted as repaid his/her credit)"},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"### Final model and variables importance\n\n#### Formula: \n_EXT_SOURCE_2+ EXT_SOURCE_3^2+totalDocuments+DAYS_LAST_PHONE_CHANGE+debt+FLOORSMAX_AVG+YEARS_BIRTH^2+AMT_INCOME_TOTAL^2+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+new_customer+overdue+repaidLastCredit_\n\nVariables are normalized so to be able to explain differences in dependant variable by changes in independent we would need to scale them back to original scales\n\nHowever we can see that EXT_SOURCE_2 and squared EXT_SOURCE_3 as well as month_employed has the most influence in model"},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"start='TARGET~EXT_SOURCE_2+nm.power( EXT_SOURCE_3 ,2 )+debt+CNT_CHILDREN+C(new_customer)+totalDocuments+nm.power( AMT_INCOME_TOTAL ,2 )+DAYS_LAST_PHONE_CHANGE+DAYS_ID_PUBLISH+DAYS_REGISTRATION+DEF_30_CNT_SOCIAL_CIRCLE+FLOORSMAX_AVG+MONTHS_EMPLOYED+CNT_FAM_MEMBERS+C(overdue)+C(document_provided)+C(repaidCredit)+C(repaidLastCredit)'\n\nres = smf.logit(start, data = train).fit()\nprint(res.summary())\n\nss={\"Feature\":res.params.index, \"Coef\":res.params.values}\nss=pd.DataFrame(ss)\nss.plot.bar(x='Feature', y='Coef', rot=90,title=\"Feature importance\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plm\nfrom sklearn.metrics import roc_curve, auc\nyhat= res.predict(test)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(test['TARGET'], yhat)\nfalse_positive_rate_fake, true_positive_rate_fake, thresholds2 = roc_curve(test['TARGET'], test['TARGET'])\nplm.rcParams[\"figure.figsize\"] = (10,10)\nplm.title(\"ROC-AUC\")\n#plt.xlabel('False Positive')\n#plm.ylabel('True Positive')\nplm.plot(false_positive_rate, true_positive_rate, label=\"The model's ROC\")\nplm.plot(false_positive_rate_fake, true_positive_rate_fake,color=\"green\",linestyle=\"--\", label=\"Ideal ROC\")\nplm.plot([0,1],[0,1], color=\"red\", label=\"Predicts at chance model\")\nplm.legend()","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"subslide"},"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint( \"Models AUC score : \"+ str(roc_auc_score(test['TARGET'], yhat)))","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"## Cross Validation and AUC calculation of alternative classification models"},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nclf = DecisionTreeClassifier(random_state=0)\nprint(\"Decision tree AUC score \"+str(cross_val_score(clf, data, target, cv=5, scoring=\"roc_auc\").mean()))","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"fragment"},"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nprint(\"K-Neighbors classifier AUC score \"+str(cross_val_score(neigh, data, target, cv=5, scoring=\"roc_auc\").mean()))","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"skip"},"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nHTML('''<script>\ncode_show=true; \nfunction code_toggle() {\n if (code_show){\n $('div.input').hide();\n } else {\n $('div.input').show();\n }\n code_show = !code_show\n} \n$( document ).ready(code_toggle);\n</script>\nThe raw code for this IPython notebook is by default hidden for easier reading.\nTo toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')","execution_count":null,"outputs":[]}],"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":false,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"542.4px","left":"2022.77px","top":"0px","width":"261.188px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}