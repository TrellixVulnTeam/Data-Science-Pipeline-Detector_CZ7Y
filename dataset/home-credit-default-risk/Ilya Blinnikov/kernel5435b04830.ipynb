{"cells":[{"metadata":{"_uuid":"896d935f5719fc812a48861b79df536300a28dd3"},"cell_type":"markdown","source":"# Машинное обучение, ФКН ВШЭ\n\n## Практическое задание 7. Градиентный бустинг ~~своими руками~~\n\n### Общая информация\nДата выдачи: 07.12.2018\n\nМягкий дедлайн: 05:59MSK 18.12.2018\n\nЖесткий дедлайн: 05:59MSK 19.12.2018\n\n### Оценивание и штрафы\nКаждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n\nСдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n\nЗадание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n\nНеэффективная реализация кода может негативно отразиться на оценке.\n\n### Формат сдачи\nЗадания сдаются через систему anytask. Посылка должна содержать:\n* Ноутбук homework-practice-07-Username.ipynb\n\nUsername — ваша фамилия и имя на латинице именно в таком порядке"},{"metadata":{"trusted":true,"_uuid":"70d556e9e749b95d955877ee3ba8ccfe2996b4c6"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport catboost as cb\nimport lightgbm as lgb\nimport time\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import average_precision_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fad3ce16c1832f2cce08be01f68e9b61b05317a"},"cell_type":"markdown","source":"__Задание 1. (0.5 балла)__\n\nМы будем использовать данные соревнования [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk/data). \n* Загрузите таблицу application_train.csv;\n* Запишите в Y столбец с целевой переменной;\n* Удалите ненужные столбцы (для этого воспользуйтесь описанием);\n* Определите тип столбцов и заполните пропуски - стратегия произвольная;\n* Разбейте выборку в соотношении 70:30 с random_state=0.\n\nТак как в данных значительный дисбаланс классов, в качестве метрики качества везде будем использовать площадь под precision-recall кривой."},{"metadata":{"trusted":true,"_uuid":"71a774b511ebc87824fb716acda2e10729cbe16b"},"cell_type":"code","source":"X = pd.read_csv('../input/application_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cdca4f9bdc4e4d0abdb7720e79a8c7a890b3988"},"cell_type":"code","source":"y = X['TARGET']\nX = X.drop(['TARGET'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07fe0b5c8d38c9ae52a5446f2ada4a0a39f9f38f"},"cell_type":"code","source":"print(X.columns)\nX = X.fillna(0)\ncategorical_features = []\nnumerical_features = []\nfor column in X.columns:\n    if (X[column].dtype == 'O'):\n        categorical_features = categorical_features + [column]\n    else:\n        numerical_features = numerical_features + [column]\nprint(len(categorical_features))        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3b7fd697e3caaf26fd4a79e815307c299923c2d"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2208ffa594488bd688fc435c9e83aa79300c0193"},"cell_type":"markdown","source":"__Задание 2. (1.5 балла)__\n\nОбучите реализации градиентного бустинга LightGBM и Catboost на вещественных признаках без подбора параметров. \nПочему получилась заметная разница в качестве? \n\nВ этом и последующих экспериментах необходимо измерять время обучения моделей."},{"metadata":{"trusted":true,"_uuid":"c8a4a49568e18c6be6248e504a17a9303c961b56"},"cell_type":"code","source":"st_time = time.time()\nmodel = cb.CatBoostClassifier(task_type = \"GPU\")\nmodel.fit(X_train[numerical_features], y_train)\nprint('CatBoost:')\nprint('time:', time.time() - st_time)\nprint(average_precision_score(y_test, model.predict_proba(X_test[numerical_features])[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ed2a6fe5e37b6c7056ac58528798acfed06ee7c"},"cell_type":"code","source":"st_time = time.time()\nmodel = lgb.LGBMClassifier()\nmodel.fit(X_train[numerical_features], y_train)\nprint('Lgb:')\nprint('time:', time.time() - st_time)\nprint(average_precision_score(y_test, model.predict_proba(X_test[numerical_features])[:, 1]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b96bcdb89904c6c3aae84ae2a27a0bf02bf8febe"},"cell_type":"markdown","source":"Ответ: Разница в качестве тут, поскольку CB дольше обучается в этой ситуации, и позволяет лучше обучиться и показать лучший результат"},{"metadata":{"_uuid":"76a170c9f6f0061d15e95ad3e50596dacb198f5c"},"cell_type":"markdown","source":"__Задание 3. (2 балла)__\n\nПодберите с CV=3 оптимальные параметры алгоритмов, изменяя:\n\n* глубину деревьев;\n* количество деревьев;\n* темп обучения;\n* оптимизируемый функционал.\n\nПроанализируйте соотношения глубины и количества деревьев в зависимости от алгоритма."},{"metadata":{"trusted":true,"_uuid":"19e5a6c0f524a282e21f01fbb11e74f2409a75e4"},"cell_type":"code","source":"#st_time = time.time()\n#cat_boost_params = {\n#    'depth': [2,5,8],\n#    'n_estimators':[200, 500, 1000],\n#    'learning_rate': [0.03, 0.05, 0.1],\n#    'loss_function': ['Logloss', 'CrossEntropy']\n#}\n#mod_cb = GridSearchCV(cb.CatBoostClassifier(task_type=\"GPU\"), cv=3, param_grid=cat_boost_params, scoring='average_precision')\n#mod_cb.fit(X_train[numerical_features], y_train)\n#print('CbGridSearch')\n#print('time:', time.time() - st_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"969e63d940bcbe605cb2c173f8cda2415e4e9ff1"},"cell_type":"code","source":"#print(mod_cb.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"190b0fd78eb4d16c02117ac0a8e794c3abc8aaa1"},"cell_type":"code","source":"st_time = time.time()\nlgbm_params = {\n    'max_depth': [2,5,8],\n    'n_estimators':[200, 500, 1000],\n    'learning_rate': [0.03, 0.05, 0.1],\n    'metric': ['binary', 'regression']\n}\nmod_lgbm = GridSearchCV(lgb.LGBMClassifier(), cv=3, param_grid=lgbm_params, scoring='average_precision')\nmod_lgbm.fit(X_train[numerical_features], y_train)\nprint('CbGridSearch')\nprint('time:', time.time() - st_time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc4aa095c46f00ba2f6e94f1e03552320cbc12c9"},"cell_type":"code","source":"print(mod_lgbm.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c63fac3ca64f4cf059b626b751ee21b01acf4f15"},"cell_type":"markdown","source":"__Задание 4. (3.5 балла)__\n\nДобавьте категориальные признаки к вещественным следующими способами:\n\n* как OHE признаки;\n* как счетчики со сглаживанием.\n\nПри подсчете счетчиков запрещается использование циклов. \n\nНа получившихся датасетах подберите параметры у каждого из алгоритмов. Как меняется время, необходимое для обучения модели в зависимости от способа кодирования? Сравните полученные результаты с встроенными методами обработки категориальных признаков. "},{"metadata":{"trusted":false,"_uuid":"0ddcee6b7ae7374056e1491d1b6699b554561173"},"cell_type":"code","source":"### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c616d48e2219032e03763a0bd3a04afa042cdd5"},"cell_type":"markdown","source":"__Задание 5. (1 балл)__\n\nРеализуйте блендинг подобранных в предыдущем задании моделей и сравните качество."},{"metadata":{"trusted":false,"_uuid":"904b7178789f506f58fb23b0e6df0ef4b95e549d"},"cell_type":"code","source":"### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d85d1ebe9c2f27f6e9b8bb2dcb215bd12653280"},"cell_type":"markdown","source":"__Задание 6. (1.5 балла)__\n\nВ задании 3 вы подобрали гиперпараметры для LightGBM и CatBoost на вещественных признаках. Визуализируйте важности признаков, посчитанные этими алгоритмами, в виде горизонтального bar-plot (отсортируйте признаки по убыванию важности, подпишите названия признаков по оси y).\n\nДля каждого из двух алгоритмов удалите неважные признаки (обычно по bar-plot хорошо видно порог на важность, с которого начинается хвост неважных признаков) и обучите ту же модель на получившихся данных. Сильно ли упало качество при удалении признаков, которые модель считает неважными?"},{"metadata":{"trusted":false,"_uuid":"abd59074a7c0c47e91a5be077dd7751e87f6b269"},"cell_type":"code","source":"### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}