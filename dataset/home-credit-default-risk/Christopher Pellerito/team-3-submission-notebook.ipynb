{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model Submission Notebook - Home Credit Default Risk","metadata":{}},{"cell_type":"markdown","source":"### initialization - load packages and data\nThe Data Generation notebook already created the test set of features and performed all the cleansing, data engineering, table merging, etc. All we need to do is load that set into the model, feed it into the pipeline and apply our final model.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport joblib\nimport numpy as np\nimport gc\n\npd.options.display.max_columns = None\ntest = pd.read_pickle('../input/ensemblemodelstuff/test1205.pkl')\nprint(test.shape)\ntest.head(5)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-06T06:25:58.32591Z","iopub.execute_input":"2021-12-06T06:25:58.326449Z","iopub.status.idle":"2021-12-06T06:26:00.224377Z","shell.execute_reply.started":"2021-12-06T06:25:58.326411Z","shell.execute_reply":"2021-12-06T06:26:00.223416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Model(s)\nThe default_processor and default_model files were dumped to joblib in the final step of the model notebook. Since we are attempting an ensemble model, we need to load three different models: logistic regression, light gradient boost and random forest.","metadata":{}},{"cell_type":"code","source":"preprocessor = joblib.load('../input/ensemblemodelstuff/default_preprocessor_final.joblib')\nmodel1 = joblib.load('../input/ensemblemodelstuff/default_model_final_LR.joblib')                   # this is the logistic regression\nmodel2 = joblib.load('../input/ensemblemodelstuff/default_model_final_LGB.joblib')                  # this is the LightGBM\nmodel3 = joblib.load('../input/ensemblemodelstuff/default_model_final_RF.joblib')                   # this is the random forest\n\nprint(type(model1))\nprint(type(model2))\nprint(type(model3))","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:26:02.293202Z","iopub.execute_input":"2021-12-06T06:26:02.293644Z","iopub.status.idle":"2021-12-06T06:26:04.936679Z","shell.execute_reply.started":"2021-12-06T06:26:02.293602Z","shell.execute_reply":"2021-12-06T06:26:04.93594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing\nWe still need to run our data set through the pipeline to perform imputation and scaling on the numeric features, and one-hot encoding on the categorical features.","metadata":{}},{"cell_type":"code","source":"X_test = preprocessor.transform(test)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:26:06.168561Z","iopub.execute_input":"2021-12-06T06:26:06.169791Z","iopub.status.idle":"2021-12-06T06:26:11.640696Z","shell.execute_reply.started":"2021-12-06T06:26:06.169739Z","shell.execute_reply":"2021-12-06T06:26:11.639687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Predictions\nFor each model, we need to generate predictions on the test data, then we will take the weighted average, using the weights (80% LGBM, 15% LR, 5% RF) that we identified as a candidate ensemble model. This ensemble combination did outscore the pure LGBM model on the validation data, although the difference was in the hundred-thousandths place.","metadata":{}},{"cell_type":"code","source":"test_pred_1 = model1.predict_proba(X_test)           # predictions for logistic regression\ntest_pred_2 = model2.predict_proba(X_test)           # predictions for light GBM\ntest_pred_3 = model3.predict_proba(X_test)           # predictions for random forest\n\n# in the previous notebook, we identified an ensemble of 80% LGBM, 15% LR, 5% RF as a good candidate. So we need the weighted average of the three sets of predictions:\nensemble = (0.15 * test_pred_1) + (0.8 * test_pred_2) + (0.05 * test_pred_3) \n\n# the predictions that we need are in column 1 (the right hand column) of this array.\nprint(ensemble.shape)\nprint(ensemble[:5])","metadata":{"execution":{"iopub.status.busy":"2021-12-06T06:26:11.64208Z","iopub.execute_input":"2021-12-06T06:26:11.64246Z","iopub.status.idle":"2021-12-06T06:26:16.18558Z","shell.execute_reply.started":"2021-12-06T06:26:11.642425Z","shell.execute_reply":"2021-12-06T06:26:16.1847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission\nPrepare CSV file full of our probabilistic predictions for final Kaggle submission.","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/home-credit-default-risk/sample_submission.csv')\nsubmission.TARGET = ensemble[:,1]                   # replace the default values with our predictions\nsubmission.head(10)\nsubmission.to_csv('default_submission_17.csv', index=False, header = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T20:17:36.979756Z","iopub.status.idle":"2021-12-05T20:17:36.980718Z","shell.execute_reply.started":"2021-12-05T20:17:36.980347Z","shell.execute_reply":"2021-12-05T20:17:36.98038Z"},"trusted":true},"execution_count":null,"outputs":[]}]}