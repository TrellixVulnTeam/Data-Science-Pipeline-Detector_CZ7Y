{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport gc\nimport warnings\nimport time\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\napp_test = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train.shape[0] + app_test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating combined dataframe from train and test file\n- Purpuse of combining train and test file is to handle data modification at same time on both file\n- Once data pre-processing is done we can easily split it again with below logic\n- if TARGET=NaN meaning its test file else its train file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = app_train.append(app_test).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del app_train\ndel app_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Considering basic numeric features"},{"metadata":{"trusted":true},"cell_type":"code","source":"app_num_basic_col = [\n'SK_ID_CURR',\n'TARGET',\n'CNT_CHILDREN',\n'AMT_INCOME_TOTAL',\n'AMT_CREDIT',\n'AMT_ANNUITY',\n'AMT_GOODS_PRICE',\n'REGION_POPULATION_RELATIVE',\n'DAYS_BIRTH',\n'DAYS_EMPLOYED',\n'DAYS_REGISTRATION',\n'DAYS_ID_PUBLISH',\n'CNT_FAM_MEMBERS',\n'REGION_RATING_CLIENT',\n'REGION_RATING_CLIENT_W_CITY',\n'REG_REGION_NOT_LIVE_REGION',\n'REG_REGION_NOT_WORK_REGION',\n'LIVE_REGION_NOT_WORK_REGION',\n'REG_CITY_NOT_LIVE_CITY',\n'REG_CITY_NOT_WORK_CITY',\n'LIVE_CITY_NOT_WORK_CITY']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_cat_basic_col = ['NAME_CONTRACT_TYPE',\n'FLAG_OWN_CAR',\n'FLAG_OWN_REALTY',\n'CODE_GENDER',\n'NAME_TYPE_SUITE',\n'NAME_INCOME_TYPE',\n'NAME_EDUCATION_TYPE',\n'NAME_FAMILY_STATUS',\n'NAME_HOUSING_TYPE',\n'OCCUPATION_TYPE',\n'ORGANIZATION_TYPE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(app_num_basic_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(app_cat_basic_col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Creating dataframe with required columns only"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[app_num_basic_col + app_cat_basic_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_missing(data):\n    ## Number of missing values\n    missing_cnt = data.isnull().sum().values\n    ## Total\n    total = data.shape[0]\n    ##Percentage of Missing values\n    percentage = missing_cnt/total * 100\n    missing_df = pd.DataFrame(data={'Total': total, 'Missing Count' : missing_cnt,'Percentage' : percentage}, \n                              index=data.columns.values)\n    missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n    return missing_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(df[app_num_basic_col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['AMT_GOODS_PRICE']=df['AMT_GOODS_PRICE'].fillna(df['AMT_GOODS_PRICE'].median())\ndf['AMT_ANNUITY']=df['AMT_ANNUITY'].fillna(df['AMT_ANNUITY'].median())\ndf['CNT_FAM_MEMBERS']=df['CNT_FAM_MEMBERS'].fillna(df['CNT_FAM_MEMBERS'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(df[app_num_basic_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(df[app_cat_basic_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap\nplt.subplots(figsize=(20,12))\nsns.heatmap(df[app_cat_basic_col].isnull(), yticklabels = False, cbar = False,cmap = 'tab20c_r')\nplt.title('Missing Data: Training Set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Name Type Suite and Occupation type has missing values\n- Occupation type has lots of missing value so for now droping this column\n- Name Type suite will create some dummy NTS_XNA category for now"},{"metadata":{"trusted":true},"cell_type":"code","source":"app_cat_basic_col.remove('OCCUPATION_TYPE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('OCCUPATION_TYPE',inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NAME_TYPE_SUITE']=df['NAME_TYPE_SUITE'].fillna('NTS_XNA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categorical_bar(data, column):    \n    plotdata = data[column].value_counts();\n\n    fig = go.Figure(data=[\n        go.Bar(x=plotdata.index, y=plotdata.values)\n    ])\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categorical_pie(data, column, title, hole=.3):\n    plotdata = data[column].value_counts();\n    \n    fig = go.Figure(data=[go.Pie(labels=plotdata.index, values=plotdata.values, hole=hole)])\n    fig.update_layout(title_text=title)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical_pie(df, 'TARGET', 'Label Target ', .6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical_pie(df, 'NAME_INCOME_TYPE', 'House Type', .3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical_bar(df, 'NAME_HOUSING_TYPE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Draw distribution of numeric features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distributions(data, title, figsize, num_cols):\n    \n    column_names = list(data.columns.values)\n    number_of_features = len(column_names)\n    num_cols = num_cols\n    num_rows = int(np.ceil(number_of_features*1./num_cols))\n    fig = plt.figure(dpi=300, figsize = figsize)\n\n    for i, feature in enumerate(column_names):\n        feature_data = data[feature]\n        filtered_feature_data = feature_data[~np.isnan(feature_data)]\n        ax = fig.add_subplot(num_rows, num_cols, i+1)\n        ax.hist(filtered_feature_data, bins = 25)\n        ax.set_title(\"'%s' Distribution\"%(feature), fontsize = 12)\n        ax.set_xlabel(\"Value\")\n        ax.set_ylabel(\"Number of Borrowers\")\n\n    fig.suptitle(title, fontsize = 16, y = 1.03)\n\n    fig.tight_layout()\n    fig.show()\n\n    fig.savefig('{}.png'.format(title))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_column = ['CNT_CHILDREN',\n'AMT_INCOME_TOTAL',\n'AMT_CREDIT',\n'AMT_ANNUITY',\n'AMT_GOODS_PRICE',\n'REGION_POPULATION_RELATIVE',\n'DAYS_BIRTH',\n'DAYS_EMPLOYED',\n'DAYS_REGISTRATION',\n'DAYS_ID_PUBLISH',\n'CNT_FAM_MEMBERS',\n'REGION_RATING_CLIENT',\n'REGION_RATING_CLIENT_W_CITY',\n'REG_REGION_NOT_LIVE_REGION',\n'REG_REGION_NOT_WORK_REGION',\n'LIVE_REGION_NOT_WORK_REGION',\n'REG_CITY_NOT_LIVE_CITY',\n'REG_CITY_NOT_WORK_CITY',\n'LIVE_CITY_NOT_WORK_CITY']\nplot_distributions(df[num_column], title='Distributions of Main Data Table\\'s Normalized Features', figsize=(14,60), num_cols=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Handling Outlier"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df['DAYS_EMPLOYED'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\nplt.xlabel('Days Employment');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(df[df['DAYS_EMPLOYED'] == 365243]['DAYS_EMPLOYED'].count() / len(df) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(df[df['DAYS_EMPLOYED'] != 365243]['DAYS_EMPLOYED'].count() / len(df) * 100 ,2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- found that DAYS_EMPLOYED has some anomalies\n- Around 18% of data amongs all data has some '365243' value in this fields\n- as its not make sence to current data so we need to handle it somehow\n- so i am replacing this value with np.nan\n- creating new column called DAYS_EMPLOYED_ANOM Anomalous flag which will have True or False value based on this field"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Create an anomalous flag column\ndf['DAYS_EMPLOYED_ANOM'] = df[\"DAYS_EMPLOYED\"] == 365243\n\n# Replace the anomalous values with nan\ndf['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n\ndf['DAYS_EMPLOYED']=df['DAYS_EMPLOYED'].fillna(df['DAYS_EMPLOYED'].median())\n\n(df['DAYS_EMPLOYED']/365).plot.hist(title = 'Days Employment Histogram');\nplt.xlabel('Days Employment');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing anomalies we can see above histogram that DAYS_EMPLOYED has maximum as 49 years and minimum is 0 year as discribe below"},{"metadata":{},"cell_type":"markdown","source":"- Now add newly added column DAYS_EMPLOYED_ANOM to basic features list"},{"metadata":{},"cell_type":"markdown","source":"### creating combined basic features from numerical and categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"basic_features = app_num_basic_col + app_cat_basic_col ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(df[basic_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basic_features.append('DAYS_EMPLOYED_ANOM')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['DAYS_EMPLOYED'] / -365 > 8]['DAYS_EMPLOYED'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df['DAYS_BIRTH'] / -365).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['CODE_GENDER'] == 'XNA']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['CODE_GENDER'] != 'XNA']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lable encoding for categorical features whose values are binary like Y/N, Yes/No, True/False, M/F etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['SK_ID_CURR','CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'DAYS_EMPLOYED_ANOM']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical features with Binary encode (0 or 1; two categories)\nfor bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'DAYS_EMPLOYED_ANOM']:\n    df[bin_feature], uniques = pd.factorize(df[bin_feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['SK_ID_CURR','CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'DAYS_EMPLOYED_ANOM']].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"out of above basic categorical features we already encoded binary \n- FLAG_OWN_CAR\n- FLAG_OWN_REALITY\n- CODE_GENDER\n- DAYS_EMPLYED_ANOM\n\nNow doing one hot encoding for remaining features\n- NAME_CONTRACT_TYPE\n- NAME_TYPE_SUITE\n- NAME_INCOME_TYPE\n- NAME_EDUCATION_TYPE\n- NAME_FAMILY_STATUS\n- NAME_HOUSING_TYPE\n- ORGANIZATION_TYPE"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encode_col = ['NAME_CONTRACT_TYPE',\n'NAME_TYPE_SUITE',\n'NAME_INCOME_TYPE',\n'NAME_EDUCATION_TYPE',\n'NAME_FAMILY_STATUS',\n'NAME_HOUSING_TYPE',\n'ORGANIZATION_TYPE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_df = pd.get_dummies(df[one_hot_encode_col], dummy_na=False, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dummy_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(one_hot_encode_col, axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in one_hot_encode_col:\n    basic_features.remove(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### creating final dataframe with required features"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df[basic_features].columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dummy_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df[basic_features], dummy_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del dummy_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating baseline model using LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Make the model with the specified regularization parameter\nlog_reg = LogisticRegression(C = 0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.TARGET.isnull()].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.TARGET.notnull()].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df.loc[df.TARGET.notnull()].drop('TARGET',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train =  df.loc[df.TARGET.notnull()]['TARGET']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = df.loc[df.TARGET.isnull()].drop('TARGET', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train on the training data\nlog_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions\n# Make sure to select the second column only\nlog_reg_pred = log_reg.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(log_reg_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = X_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.to_csv('logistic_regression_baseline.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_features_list = df.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_features_list.remove('TARGET')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest.fit(X_train, y_train)\n\nfeature_importance_values = random_forest.feature_importances_\nfeature_importances = pd.DataFrame({'feature': final_features_list, 'importance': feature_importance_values})\n\nradon_forest_pred = random_forest.predict_proba(X_test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_importances(df):\n    \n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    \n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    plt.xlabel('Importance'); plt.title('Feature Importances')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importances(feature_importances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit1 = X_test[['SK_ID_CURR']]\nsubmit1['TARGET'] = radon_forest_pred\n\nsubmit1.to_csv('random_forest_baseline.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}