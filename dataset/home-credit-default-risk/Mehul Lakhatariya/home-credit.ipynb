{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport gc\nimport warnings\nimport time\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train = pd.read_csv('/kaggle/input/home-credit-default-risk/application_train.csv')\napp_test = pd.read_csv('/kaggle/input/home-credit-default-risk/application_test.csv')\n\nbureau = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau.csv')\nbureau_bal = pd.read_csv('/kaggle/input/home-credit-default-risk/bureau_balance.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train.shape[0] + app_test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating combined dataframe from train and test file\n- Purpuse of combining train and test file is to handle data modification at same time on both file\n- Once data pre-processing is done we can easily split it again with below logic\n- if TARGET=NaN meaning its test file else its train file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = app_train.append(app_test).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del app_train\ndel app_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Considering basic numeric features"},{"metadata":{"trusted":true},"cell_type":"code","source":"app_num_basic_col = [\n'SK_ID_CURR',\n'TARGET',\n'CNT_CHILDREN',\n'AMT_INCOME_TOTAL',\n'AMT_CREDIT',\n'AMT_ANNUITY',\n'AMT_GOODS_PRICE',\n'REGION_POPULATION_RELATIVE',\n'DAYS_BIRTH',\n'DAYS_EMPLOYED',\n'DAYS_REGISTRATION',\n'DAYS_ID_PUBLISH',\n'CNT_FAM_MEMBERS',\n'EXT_SOURCE_1',\n'EXT_SOURCE_2',\n'EXT_SOURCE_3',]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_cat_basic_col = ['NAME_CONTRACT_TYPE',\n'FLAG_OWN_CAR',\n'FLAG_OWN_REALTY',\n'CODE_GENDER',\n'NAME_TYPE_SUITE',\n'NAME_INCOME_TYPE',\n'NAME_EDUCATION_TYPE',\n'NAME_FAMILY_STATUS',\n'NAME_HOUSING_TYPE',\n'OCCUPATION_TYPE',\n'ORGANIZATION_TYPE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(app_num_basic_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(app_cat_basic_col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Creating dataframe with required columns only"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[app_num_basic_col + app_cat_basic_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA And Pre-Processing "},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_missing(data):\n    ## Number of missing values\n    missing_cnt = data.isnull().sum().values\n    ## Total\n    total = data.shape[0]\n    ##Percentage of Missing values\n    percentage = missing_cnt/total * 100\n    missing_df = pd.DataFrame(data={'Total': total, 'Missing Count' : missing_cnt,'Percentage' : percentage}, \n                              index=data.columns.values)\n    missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n    return missing_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(df[app_num_basic_col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[app_num_basic_col].describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[app_cat_basic_col].describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def describe_df(columns):\n    for column in columns:\n        print('{column} mean value={mean}, median value={median}'.format(column=column, mean=df[column].mean(), median=df[column].median()))\ndescribe_df(['AMT_GOODS_PRICE', 'AMT_ANNUITY', 'CNT_FAM_MEMBERS', 'EXT_SOURCE_1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['AMT_ANNUITY'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NAME_INCOME_TYPE'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['DAYS_EMPLOYED'] == 365243][['DAYS_EMPLOYED', 'NAME_INCOME_TYPE']].groupby('NAME_INCOME_TYPE').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['AMT_GOODS_PRICE']=df['AMT_GOODS_PRICE'].fillna(df['AMT_GOODS_PRICE'].median())\ndf['AMT_ANNUITY']=df['AMT_ANNUITY'].fillna(df['AMT_ANNUITY'].median())\ndf['CNT_FAM_MEMBERS']=df['CNT_FAM_MEMBERS'].fillna(df['CNT_FAM_MEMBERS'].median())\ndf['EXT_SOURCE_1']=df['EXT_SOURCE_1'].fillna(df['EXT_SOURCE_1'].median())\ndf['EXT_SOURCE_2']=df['EXT_SOURCE_2'].fillna(df['EXT_SOURCE_2'].median())\ndf['EXT_SOURCE_3']=df['EXT_SOURCE_3'].fillna(df['EXT_SOURCE_3'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(df[app_num_basic_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(df[app_cat_basic_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap\nplt.subplots(figsize=(20,12))\nsns.heatmap(df[app_cat_basic_col].isnull(), yticklabels = False, cbar = False,cmap = 'tab20c_r')\nplt.title('Missing Data: Training Set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Name Type Suite and Occupation type has missing values\n- Occupation type has lots of missing value so for now droping this column\n- Name Type suite will create some dummy NTS_XNA category for now"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_cat_basic_col.remove('OCCUPATION_TYPE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('OCCUPATION_TYPE',inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NAME_TYPE_SUITE']=df['NAME_TYPE_SUITE'].fillna('NTS_XNA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categorical_pie(data, column, title, hole=.3):\n    plotdata = data[column].value_counts();\n    \n    fig = go.Figure(data=[go.Pie(labels=plotdata.index, values=plotdata.values, hole=hole)])\n    fig.update_layout(title_text=title)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categorical(data, column, size=[8,4], xlabel_angle=0, title=''):\n    plotdata = data[column].value_counts();\n    plt.figure(figsize=size)\n    sns.barplot(x=plotdata.index, y=plotdata.values)\n    plt.title(title)\n    plt.xticks(rotation = xlabel_angle)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical_pie(df, 'TARGET', 'Label Target ', .6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['NAME_INCOME_TYPE'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical_pie(df, 'NAME_INCOME_TYPE', 'Income Type', .7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical(df,'NAME_EDUCATION_TYPE', size=[10,6], xlabel_angle=70,title='Education Type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_categorical_pie(df, 'NAME_FAMILY_STATUS', 'Income Type', .4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(20,12))\nsns.heatmap(corr_matrix, cmap = plt.cm.RdYlBu_r, annot = True, vmin = -0.25, vmax=0.6)\nplt.title('Correlation Heatmap');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Draw distribution of numeric features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CNT_FAM_MEMBERS'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CNT_FAM_MEMBERS'].plot.hist(title = 'Count of Family members Histogram');\nplt.xlabel('Count of family members');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df['DAYS_BIRTH']/365).plot.hist(title = 'Days Birth Histogram');\nplt.xlabel('Days Birth');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age information into a separate dataframe\nage_data = df[['TARGET', 'DAYS_BIRTH']]\nage_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / -365\n\n# Bin the age data\nage_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\nage_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_groups  = age_data.groupby('YEARS_BINNED').mean()\nage_groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8, 8))\n\n# Graph the age bins and the average of the target as a bar plot\nplt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'])\n\n# Plot labeling\nplt.xticks(rotation = 75); plt.xlabel('Age Group (years)'); plt.ylabel('Failure to Repay (%)')\nplt.title('Failure to Repay by Age Group');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Handling Outlier"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=df['DAYS_EMPLOYED'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\nplt.xlabel('Days Employment');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(df[df['DAYS_EMPLOYED'] == 365243]['DAYS_EMPLOYED'].count() / len(df) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(df[df['DAYS_EMPLOYED'] != 365243]['DAYS_EMPLOYED'].count() / len(df) * 100 ,2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- found that DAYS_EMPLOYED has some anomalies\n- Around 18% of data amongs all data has some '365243' value in this fields\n- as its not make sence to current data so we need to handle it somehow\n- so i am replacing this value with np.nan\n- creating new column called DAYS_EMPLOYED_ANOM Anomalous flag which will have True or False value based on this field"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Create an anomalous flag column\ndf['DAYS_EMPLOYED_ANOM'] = df[\"DAYS_EMPLOYED\"] == 365243\n\n# Replace the anomalous values with nan\ndf['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n\ndf['DAYS_EMPLOYED']=df['DAYS_EMPLOYED'].fillna(df['DAYS_EMPLOYED'].median())\n\n(df['DAYS_EMPLOYED']/365).plot.hist(title = 'Days Employment Histogram');\nplt.xlabel('Days Employment');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing anomalies we can see above histogram that DAYS_EMPLOYED has maximum as 49 years and minimum is 0 year as discribe below"},{"metadata":{},"cell_type":"markdown","source":"### creating combined basic features from numerical and categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"basic_features = app_num_basic_col + app_cat_basic_col ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(df[basic_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basic_features.append('DAYS_EMPLOYED_ANOM')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['DAYS_EMPLOYED'] / -365 > 8]['DAYS_EMPLOYED'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df['DAYS_BIRTH'] / -365).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['CODE_GENDER'] == 'XNA']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['CODE_GENDER'] != 'XNA']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lable encoding for categorical features whose values are binary like Y/N, Yes/No, True/False, M/F etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['SK_ID_CURR','CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'DAYS_EMPLOYED_ANOM']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical features with Binary encode (0 or 1; two categories)\nfor bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'DAYS_EMPLOYED_ANOM']:\n    df[bin_feature], uniques = pd.factorize(df[bin_feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['SK_ID_CURR','CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'DAYS_EMPLOYED_ANOM']].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"out of above basic categorical features we already encoded binary \n- FLAG_OWN_CAR\n- FLAG_OWN_REALITY\n- CODE_GENDER\n- DAYS_EMPLYED_ANOM\n\nNow doing one hot encoding for remaining features\n- NAME_CONTRACT_TYPE\n- NAME_TYPE_SUITE\n- NAME_INCOME_TYPE\n- NAME_EDUCATION_TYPE\n- NAME_FAMILY_STATUS\n- NAME_HOUSING_TYPE\n- ORGANIZATION_TYPE"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encode_col = ['NAME_CONTRACT_TYPE',\n'NAME_TYPE_SUITE',\n'NAME_INCOME_TYPE',\n'NAME_EDUCATION_TYPE',\n'NAME_FAMILY_STATUS',\n'NAME_HOUSING_TYPE',\n'ORGANIZATION_TYPE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_df = pd.get_dummies(df[one_hot_encode_col], dummy_na=False, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dummy_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(one_hot_encode_col, axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in one_hot_encode_col:\n    basic_features.remove(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(basic_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### creating final dataframe with required features"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df[basic_features].columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(dummy_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df[basic_features], dummy_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del dummy_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 1 : Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Make the model with the specified regularization parameter\nlog_reg = LogisticRegression(C = 0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.TARGET.isnull()].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.TARGET.notnull()].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df.loc[df.TARGET.notnull()].drop('TARGET',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_missing(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train =  df.loc[df.TARGET.notnull()]['TARGET']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = df.loc[df.TARGET.isnull()].drop('TARGET', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train on the training data\nlog_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions\n# Make sure to select the second column only\nlog_reg_pred = log_reg.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(log_reg_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = X_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.to_csv('logistic_regression.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dealing with Imbalance Data using SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smt = SMOTE()\nX_train, y_train = smt.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = X_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.to_csv('logistic_regression_with_smote.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}