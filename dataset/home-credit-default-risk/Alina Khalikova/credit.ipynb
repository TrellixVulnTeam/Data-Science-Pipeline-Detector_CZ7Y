{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-15T14:15:17.765858Z","iopub.execute_input":"2021-12-15T14:15:17.766206Z","iopub.status.idle":"2021-12-15T14:15:18.264853Z","shell.execute_reply.started":"2021-12-15T14:15:17.766117Z","shell.execute_reply":"2021-12-15T14:15:18.26404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\napp_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:18.26631Z","iopub.execute_input":"2021-12-15T14:15:18.266522Z","iopub.status.idle":"2021-12-15T14:15:22.771143Z","shell.execute_reply.started":"2021-12-15T14:15:18.266497Z","shell.execute_reply":"2021-12-15T14:15:22.769688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_test = pd.read_csv('../input/home-credit-default-risk/application_test.csv')\napp_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:22.772784Z","iopub.execute_input":"2021-12-15T14:15:22.773113Z","iopub.status.idle":"2021-12-15T14:15:23.464537Z","shell.execute_reply.started":"2021-12-15T14:15:22.773067Z","shell.execute_reply":"2021-12-15T14:15:23.463641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"app_train['TARGET'].astype(int).plot.hist();","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:23.465901Z","iopub.execute_input":"2021-12-15T14:15:23.466137Z","iopub.status.idle":"2021-12-15T14:15:23.68797Z","shell.execute_reply.started":"2021-12-15T14:15:23.466106Z","shell.execute_reply":"2021-12-15T14:15:23.68711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Из этой информации мы видим, что гораздо больше кредитов было погашено вовремя, чем кредитов, которые не были погашены. Далее мы можем взвесить классы, чтобы отразить этот дисбаланс.","metadata":{}},{"cell_type":"markdown","source":"# Пропущенные данные","metadata":{}},{"cell_type":"code","source":"def missing_values_table(df):\n        mis_val = df.isnull().sum()\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        print (\"The dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        return mis_val_table_ren_columns\nmissing_values = missing_values_table(app_train)\nmissing_values.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:23.689891Z","iopub.execute_input":"2021-12-15T14:15:23.690142Z","iopub.status.idle":"2021-12-15T14:15:24.808501Z","shell.execute_reply.started":"2021-12-15T14:15:23.690112Z","shell.execute_reply":"2021-12-15T14:15:24.807433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train.dtypes.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:24.810092Z","iopub.execute_input":"2021-12-15T14:15:24.810602Z","iopub.status.idle":"2021-12-15T14:15:24.819927Z","shell.execute_reply.started":"2021-12-15T14:15:24.810541Z","shell.execute_reply":"2021-12-15T14:15:24.818978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:24.821122Z","iopub.execute_input":"2021-12-15T14:15:24.821359Z","iopub.status.idle":"2021-12-15T14:15:25.319994Z","shell.execute_reply.started":"2021-12-15T14:15:24.821333Z","shell.execute_reply":"2021-12-15T14:15:25.319239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Кодирование категориальных переменных","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:25.321141Z","iopub.execute_input":"2021-12-15T14:15:25.321342Z","iopub.status.idle":"2021-12-15T14:15:25.324855Z","shell.execute_reply.started":"2021-12-15T14:15:25.321317Z","shell.execute_reply":"2021-12-15T14:15:25.323877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nle_count = 0\nfor col in app_train:\n    if app_train[col].dtype == 'object':\n        if len(list(app_train[col].unique())) <= 2:\n            le.fit(app_train[col])\n            app_train[col] = le.transform(app_train[col])\n            app_test[col] = le.transform(app_test[col])\n            le_count += 1\n            \nprint('%d columns were label encoded.' % le_count)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:25.325963Z","iopub.execute_input":"2021-12-15T14:15:25.326195Z","iopub.status.idle":"2021-12-15T14:15:26.217013Z","shell.execute_reply.started":"2021-12-15T14:15:25.326158Z","shell.execute_reply":"2021-12-15T14:15:26.216333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\n\nprint('Training Features shape: ', app_train.shape)\nprint('Testing Features shape: ', app_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:26.218084Z","iopub.execute_input":"2021-12-15T14:15:26.218396Z","iopub.status.idle":"2021-12-15T14:15:27.176996Z","shell.execute_reply.started":"2021-12-15T14:15:26.218368Z","shell.execute_reply":"2021-12-15T14:15:27.176361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = app_train['TARGET']\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\napp_train['TARGET'] = train_labels\n\nprint('Training Features shape: ', app_train.shape)\nprint('Testing Features shape: ', app_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:27.17804Z","iopub.execute_input":"2021-12-15T14:15:27.178353Z","iopub.status.idle":"2021-12-15T14:15:27.547588Z","shell.execute_reply.started":"2021-12-15T14:15:27.178326Z","shell.execute_reply":"2021-12-15T14:15:27.546552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(app_train['DAYS_BIRTH'] / -365).describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:27.548741Z","iopub.execute_input":"2021-12-15T14:15:27.548958Z","iopub.status.idle":"2021-12-15T14:15:27.56997Z","shell.execute_reply.started":"2021-12-15T14:15:27.54893Z","shell.execute_reply":"2021-12-15T14:15:27.569162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train['DAYS_EMPLOYED'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:27.571151Z","iopub.execute_input":"2021-12-15T14:15:27.571543Z","iopub.status.idle":"2021-12-15T14:15:27.589793Z","shell.execute_reply.started":"2021-12-15T14:15:27.571513Z","shell.execute_reply":"2021-12-15T14:15:27.588977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_train['DAYS_EMPLOYED'].plot.hist()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:27.593006Z","iopub.execute_input":"2021-12-15T14:15:27.59321Z","iopub.status.idle":"2021-12-15T14:15:27.824118Z","shell.execute_reply.started":"2021-12-15T14:15:27.593184Z","shell.execute_reply":"2021-12-15T14:15:27.822974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Есть выбросы.","metadata":{}},{"cell_type":"code","source":"app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\napp_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\napp_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:27.825628Z","iopub.execute_input":"2021-12-15T14:15:27.825925Z","iopub.status.idle":"2021-12-15T14:15:28.138709Z","shell.execute_reply.started":"2021-12-15T14:15:27.825883Z","shell.execute_reply":"2021-12-15T14:15:28.137787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\napp_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n\nprint('%d anomalies in the test data out of %d' % (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:28.140259Z","iopub.execute_input":"2021-12-15T14:15:28.140488Z","iopub.status.idle":"2021-12-15T14:15:28.152884Z","shell.execute_reply.started":"2021-12-15T14:15:28.14046Z","shell.execute_reply":"2021-12-15T14:15:28.151999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Корреляции","metadata":{}},{"cell_type":"code","source":"correlations = app_train.corr()['TARGET'].sort_values()\nprint('Most Positive Correlations:\\n', correlations.tail(15))\nprint('\\nMost Negative Correlations:\\n', correlations.head(15))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:15:28.154498Z","iopub.execute_input":"2021-12-15T14:15:28.155365Z","iopub.status.idle":"2021-12-15T14:16:20.115155Z","shell.execute_reply.started":"2021-12-15T14:15:28.155315Z","shell.execute_reply":"2021-12-15T14:16:20.114294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Смотрим на самые значимые показатели корреляции между таргетом и другим переменными. Наибольшая положительная корреляция с датой рождения, периодом занятости и рейтингом региона клиента. Наибольшие негативные корреляции с Normalized score from external data source и типом образования.","metadata":{}},{"cell_type":"code","source":"ext_data = app_train[['TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'REGION_RATING_CLIENT_W_CITY']]\next_data_corrs = ext_data.corr()\nplt.figure(figsize = (8, 6))\nsns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap');","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:20.116315Z","iopub.execute_input":"2021-12-15T14:16:20.116541Z","iopub.status.idle":"2021-12-15T14:16:20.975675Z","shell.execute_reply.started":"2021-12-15T14:16:20.116512Z","shell.execute_reply":"2021-12-15T14:16:20.974792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 12))\nfor i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']):\n    plt.subplot(3, 1, i + 1)\n    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0')\n    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1')\n    plt.title('Distribution of %s by Target Value' % source)\n    plt.xlabel('%s' % source); plt.ylabel('Density');\nplt.tight_layout(h_pad = 2.5)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:20.976774Z","iopub.execute_input":"2021-12-15T14:16:20.976988Z","iopub.status.idle":"2021-12-15T14:16:24.281453Z","shell.execute_reply.started":"2021-12-15T14:16:20.976961Z","shell.execute_reply":"2021-12-15T14:16:24.280594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'TARGET']]\npoly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']]\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = 'median')\npoly_target = poly_features['TARGET']\npoly_features = poly_features.drop(columns = ['TARGET'])\npoly_features = imputer.fit_transform(poly_features)\npoly_features_test = imputer.transform(poly_features_test)\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_transformer = PolynomialFeatures(degree = 3)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:24.28265Z","iopub.execute_input":"2021-12-15T14:16:24.282953Z","iopub.status.idle":"2021-12-15T14:16:24.630587Z","shell.execute_reply.started":"2021-12-15T14:16:24.282924Z","shell.execute_reply":"2021-12-15T14:16:24.629664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly_transformer.fit(poly_features)\npoly_features = poly_transformer.transform(poly_features)\npoly_features_test = poly_transformer.transform(poly_features_test)\nprint(poly_features.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:24.631902Z","iopub.execute_input":"2021-12-15T14:16:24.632638Z","iopub.status.idle":"2021-12-15T14:16:24.712194Z","shell.execute_reply.started":"2021-12-15T14:16:24.632551Z","shell.execute_reply":"2021-12-15T14:16:24.711301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])[:15]","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:24.713716Z","iopub.execute_input":"2021-12-15T14:16:24.714325Z","iopub.status.idle":"2021-12-15T14:16:24.721088Z","shell.execute_reply.started":"2021-12-15T14:16:24.714277Z","shell.execute_reply":"2021-12-15T14:16:24.720541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Объединение двух переменных вместе в одну переменную может показать более значимый результат влияния на целевую переменную.","metadata":{}},{"cell_type":"code","source":"poly_features = pd.DataFrame(poly_features, \n                             columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                           'EXT_SOURCE_3']))\npoly_features['TARGET'] = poly_target\npoly_corrs = poly_features.corr()['TARGET'].sort_values()\nprint(poly_corrs.head(10))\nprint(poly_corrs.tail(5))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:24.722105Z","iopub.execute_input":"2021-12-15T14:16:24.72274Z","iopub.status.idle":"2021-12-15T14:16:25.185946Z","shell.execute_reply.started":"2021-12-15T14:16:24.722705Z","shell.execute_reply":"2021-12-15T14:16:25.184829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poly_features_test = pd.DataFrame(poly_features_test, \n                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                                'EXT_SOURCE_3']))\npoly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\napp_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\npoly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\napp_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\napp_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:25.187236Z","iopub.execute_input":"2021-12-15T14:16:25.187453Z","iopub.status.idle":"2021-12-15T14:16:26.703786Z","shell.execute_reply.started":"2021-12-15T14:16:25.187424Z","shell.execute_reply":"2021-12-15T14:16:26.70277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Некоторые из новых переменных имеют более значимую корреляцию с таргетом, чем исходные.","metadata":{}},{"cell_type":"code","source":"app_train_domain = app_train.copy()\napp_test_domain = app_test.copy()\n\napp_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\napp_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\napp_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\napp_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:26.705249Z","iopub.execute_input":"2021-12-15T14:16:26.705503Z","iopub.status.idle":"2021-12-15T14:16:26.841621Z","shell.execute_reply.started":"2021-12-15T14:16:26.705473Z","shell.execute_reply":"2021-12-15T14:16:26.84096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\napp_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\napp_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\napp_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:26.842524Z","iopub.execute_input":"2021-12-15T14:16:26.843072Z","iopub.status.idle":"2021-12-15T14:16:26.852046Z","shell.execute_reply.started":"2021-12-15T14:16:26.843042Z","shell.execute_reply":"2021-12-15T14:16:26.851288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 20))\nfor i, feature in enumerate(['CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']):\n    plt.subplot(4, 1, i + 1)\n    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 0, feature], label = 'target == 0')\n    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 1, feature], label = 'target == 1')\n    plt.title('Distribution of %s by Target Value' % feature)\n    plt.xlabel('%s' % feature); plt.ylabel('Density');\n    \nplt.tight_layout(h_pad = 2.5)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:26.85328Z","iopub.execute_input":"2021-12-15T14:16:26.853495Z","iopub.status.idle":"2021-12-15T14:16:32.406517Z","shell.execute_reply.started":"2021-12-15T14:16:26.853468Z","shell.execute_reply":"2021-12-15T14:16:32.405646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Логистическая регрессия","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nif 'TARGET' in app_train:\n    train = app_train.drop(columns = ['TARGET'])\nelse:\n    train = app_train.copy()\nfeatures = list(train.columns)\ntest = app_test.copy()\nimputer = SimpleImputer(strategy = 'median')\nscaler = MinMaxScaler(feature_range = (0, 1))\nimputer.fit(train)\ntrain = imputer.transform(train)\ntest = imputer.transform(app_test)\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:16:32.407865Z","iopub.execute_input":"2021-12-15T14:16:32.408114Z","iopub.status.idle":"2021-12-15T14:17:11.494703Z","shell.execute_reply.started":"2021-12-15T14:16:32.408084Z","shell.execute_reply":"2021-12-15T14:17:11.493793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression(C = 0.0001)\nlog_reg.fit(train, train_labels)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:17:11.496043Z","iopub.execute_input":"2021-12-15T14:17:11.49629Z","iopub.status.idle":"2021-12-15T14:17:14.385798Z","shell.execute_reply.started":"2021-12-15T14:17:11.49626Z","shell.execute_reply":"2021-12-15T14:17:14.384952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для прогнозирования вероятности невыплаты кредита используем метод predic.proba. Он возвращает массив mx2, где m - количество наблюдений. Первый столбец - вероятность того, что цель будет равна 0, а второй столбец - вероятность того, что таргет будет равен 1. Нам нужна вероятность невозврата, поэтому мы берем второй столбец.","metadata":{}},{"cell_type":"code","source":"log_reg_pred = log_reg.predict_proba(test)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:17:14.387191Z","iopub.execute_input":"2021-12-15T14:17:14.387724Z","iopub.status.idle":"2021-12-15T14:17:14.411503Z","shell.execute_reply.started":"2021-12-15T14:17:14.387679Z","shell.execute_reply":"2021-12-15T14:17:14.410507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\nsubmit.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:17:14.413075Z","iopub.execute_input":"2021-12-15T14:17:14.413642Z","iopub.status.idle":"2021-12-15T14:17:14.431856Z","shell.execute_reply.started":"2021-12-15T14:17:14.413598Z","shell.execute_reply":"2021-12-15T14:17:14.431042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('log_reg_baseline.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:17:14.433732Z","iopub.execute_input":"2021-12-15T14:17:14.434304Z","iopub.status.idle":"2021-12-15T14:17:14.669929Z","shell.execute_reply.started":"2021-12-15T14:17:14.434261Z","shell.execute_reply":"2021-12-15T14:17:14.669102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Random Forest**\nСлучайный лес - более продвинутая модель машинного обучения, так как в данном случае мы будем использовать 100 деревьев в случайном лесу.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:17:14.67142Z","iopub.execute_input":"2021-12-15T14:17:14.671961Z","iopub.status.idle":"2021-12-15T14:17:14.692512Z","shell.execute_reply.started":"2021-12-15T14:17:14.671918Z","shell.execute_reply":"2021-12-15T14:17:14.691824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest.fit(train, train_labels)\nfeature_importance_values = random_forest.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\npredictions = random_forest.predict_proba(test)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:17:14.694076Z","iopub.execute_input":"2021-12-15T14:17:14.694664Z","iopub.status.idle":"2021-12-15T14:18:30.766807Z","shell.execute_reply.started":"2021-12-15T14:17:14.694616Z","shell.execute_reply":"2021-12-15T14:18:30.765994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest.score(train, train_labels)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:32:02.55878Z","iopub.execute_input":"2021-12-15T14:32:02.559074Z","iopub.status.idle":"2021-12-15T14:32:08.891807Z","shell.execute_reply.started":"2021-12-15T14:32:02.559046Z","shell.execute_reply":"2021-12-15T14:32:08.890937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\nsubmit.to_csv('random_forest_baseline.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:18:30.767669Z","iopub.execute_input":"2021-12-15T14:18:30.767887Z","iopub.status.idle":"2021-12-15T14:18:30.909044Z","shell.execute_reply.started":"2021-12-15T14:18:30.767861Z","shell.execute_reply":"2021-12-15T14:18:30.908174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Чтобы посмотреть улучшилась ли модель с полиномиальными переменными это обучить модель тестированию на этих характеристиках.","metadata":{}},{"cell_type":"code","source":"poly_features_names = list(app_train_poly.columns)\nimputer = SimpleImputer(strategy = 'median')\npoly_features = imputer.fit_transform(app_train_poly)\npoly_features_test = imputer.transform(app_test_poly)\nscaler = MinMaxScaler(feature_range = (0, 1))\npoly_features = scaler.fit_transform(poly_features)\npoly_features_test = scaler.transform(poly_features_test)\nrandom_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:18:30.91238Z","iopub.execute_input":"2021-12-15T14:18:30.91291Z","iopub.status.idle":"2021-12-15T14:19:13.668714Z","shell.execute_reply.started":"2021-12-15T14:18:30.912864Z","shell.execute_reply":"2021-12-15T14:19:13.667862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest_poly.fit(poly_features, train_labels)\npredictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:19:13.670166Z","iopub.execute_input":"2021-12-15T14:19:13.670413Z","iopub.status.idle":"2021-12-15T14:20:52.142082Z","shell.execute_reply.started":"2021-12-15T14:19:13.670383Z","shell.execute_reply":"2021-12-15T14:20:52.141189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\nsubmit.to_csv('random_forest_baseline_engineered.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:20:52.14343Z","iopub.execute_input":"2021-12-15T14:20:52.143686Z","iopub.status.idle":"2021-12-15T14:20:52.283657Z","shell.execute_reply.started":"2021-12-15T14:20:52.143656Z","shell.execute_reply":"2021-12-15T14:20:52.282853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_feature_importances(df):\n    df = df.sort_values('importance', ascending = False).reset_index()\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:20:52.284756Z","iopub.execute_input":"2021-12-15T14:20:52.284979Z","iopub.status.idle":"2021-12-15T14:20:52.292969Z","shell.execute_reply.started":"2021-12-15T14:20:52.284951Z","shell.execute_reply":"2021-12-15T14:20:52.291918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importances_sorted = plot_feature_importances(feature_importances)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:20:52.294447Z","iopub.execute_input":"2021-12-15T14:20:52.29481Z","iopub.status.idle":"2021-12-15T14:20:52.519073Z","shell.execute_reply.started":"2021-12-15T14:20:52.29477Z","shell.execute_reply":"2021-12-15T14:20:52.518123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Как было выявлено еще на этапе рассмотрения корреляций, переменные EXT_SOURCE и DAYS_BIRTH остаются наиболее значимыми. Кроме того, как мы видим, существует лишь несколько переменных, имеющих высокую значимость для модели, что говорит о том, что мы можем убрать менее значимые, что не должно ухудшить показатели модели. ","metadata":{}},{"cell_type":"markdown","source":"Наконец посмотрим сколько всего результатов предсказано верно","metadata":{}},{"cell_type":"code","source":"#Точность предсказания логистической регрессии\n'{:.3%}'.format(round(log_reg.score(train, train_labels),5))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:58:32.697236Z","iopub.execute_input":"2021-12-15T14:58:32.697529Z","iopub.status.idle":"2021-12-15T14:58:32.826202Z","shell.execute_reply.started":"2021-12-15T14:58:32.697496Z","shell.execute_reply":"2021-12-15T14:58:32.825321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Точность предсказания случайного леса\n'{:.3%}'.format(round(random_forest.score(train, train_labels),5))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:57:06.823328Z","iopub.execute_input":"2021-12-15T14:57:06.823636Z","iopub.status.idle":"2021-12-15T14:57:13.058618Z","shell.execute_reply.started":"2021-12-15T14:57:06.823599Z","shell.execute_reply":"2021-12-15T14:57:13.057752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Точность предсказания случайного леса с полиномиальными переменными\n'{:.3%}'.format(round(random_forest_poly.score(poly_features, train_labels),5))","metadata":{"execution":{"iopub.status.busy":"2021-12-15T14:57:13.060279Z","iopub.execute_input":"2021-12-15T14:57:13.06061Z","iopub.status.idle":"2021-12-15T14:57:19.208586Z","shell.execute_reply.started":"2021-12-15T14:57:13.06054Z","shell.execute_reply":"2021-12-15T14:57:19.20588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Итог**\nВ данном проекте я проанализировала финансовые данные с помощью следующих методов: эксплораторный анализ данных, корреляционный анализ, методы предобработки данных, логистическая регрессия, случайный лес.\nСодержательно - я рассчитала вероятность невыплаты кредита для тестовой выборки и сравнила методы.","metadata":{"execution":{"iopub.status.busy":"2021-12-15T13:47:17.062875Z","iopub.execute_input":"2021-12-15T13:47:17.063378Z","iopub.status.idle":"2021-12-15T13:47:17.069527Z","shell.execute_reply.started":"2021-12-15T13:47:17.063341Z","shell.execute_reply":"2021-12-15T13:47:17.068467Z"}}}]}