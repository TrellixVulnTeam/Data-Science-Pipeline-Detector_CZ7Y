{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Model Tuning**","metadata":{"id":"cYuNOqYrmo9D"}},{"cell_type":"markdown","source":"# Mô hình: Gradient Boosting Machine \n","metadata":{"id":"gBb5vu7Pmo9Q"}},{"cell_type":"markdown","source":"Phần giới thiệu về mô hình này là do nhóm tự tìm hiểu và giải thích.","metadata":{"id":"elwf5YabiVHf"}},{"cell_type":"markdown","source":"## Ensemble Methods","metadata":{"id":"6__uKpkWmo9S"}},{"cell_type":"markdown","source":"**Ensemble Methods** (Học kết hợp) là phương pháp giải quyết bài toán bằng cách xây dựng nhiều mô hình \"yếu“ (weak learner), đơn giản và kết hợp chúng là với nhau để thu được một mô hình vượt trội, thay vì xây dựng một mô hình thật sự tốt ngay từ ban đầu.","metadata":{"id":"JbpZFeWDmo9U"}},{"cell_type":"markdown","source":"![Ensemble Methods](https://github.com/huuthang2509/Applied_DS/blob/main/Image/ensemble-method.png?raw=true)","metadata":{"id":"wEjm6dwUmo9W"}},{"cell_type":"markdown","source":"> Nguồn: https://www.educba.com/ensemble-methods-in-machine-learning/","metadata":{"id":"v_mox9qzmo9Y"}},{"cell_type":"markdown","source":"## Boosting","metadata":{"id":"tIEWO9Z7mo9Z"}},{"cell_type":"markdown","source":"Là một trong 3 nhóm của Ensemble Methods (bên cạnh Bagging và Stacking).\n\n**Boosting** là một phương pháp xây dựng một loạt các mô hình giống nhau, trong đó các mô hình sau sẽ cố gắng học để hạn chế lỗi của mô hình trước. Mỗi mô hình có thể xem là một **base model** hay weak learner.\n\nCó 2 loại Boosting là:\n- Adaptive Boosting (AdaBoost)\n- Gradient Boosting","metadata":{"id":"mJWWqW7lmo9h"}},{"cell_type":"markdown","source":"## Gradient Boosting","metadata":{"id":"8G2qJEHRmo9k"}},{"cell_type":"markdown","source":"**Gradient Boosting** là một phương pháp xây dựng một loạt các mô hình giống nhau, trong đó các mô hình sau sẽ cố gắng học để hạn chế lỗi của mô hình trước. Thuật toán dựa vào **Gradient Descent** và ở đây mỗi base model là thường một **cây quyết định**.\n\nCó 2 framework phổ biến nhất là **XGBoost** và **LightGBM**.","metadata":{"id":"UF1dOkIrmo9n"}},{"cell_type":"markdown","source":"![Simple Example Gradient Boosting](https://github.com/huuthang2509/Applied_DS/blob/main/Image/examble-gradient-boosting.png?raw=true)","metadata":{"id":"VE333eQ3jfHE"}},{"cell_type":"markdown","source":"### Lý do lựa chọn LightGBM","metadata":{"id":"uS6av1DAmo9p"}},{"cell_type":"markdown","source":"- Đây là một trong những thuật toán mạnh nhất hiện nay.\n- Có thể xử lý vấn đề missing value, có feature important để loại bớt các thuộc tính không cần thiết.\n- Nó có tốc độ xử lý nhanh hơn rất nhiều lần so với XGBoost. (Vì XGBoost chạy rất chậm với tập dữ liệu lớn).","metadata":{"id":"BSLG_FjMmo9q"}},{"cell_type":"markdown","source":"LightGBM sử dụng phương pháp leaf - wise (Lựa chọn những node có giá trị tốt hơn thay vì duyệt qua tất cả các node):","metadata":{"id":"2B66mzzRmo9t"}},{"cell_type":"markdown","source":"![XGBoost vs LightGBM](https://github.com/huuthang2509/Applied_DS/blob/main/Image/LGBM.png?raw=true)","metadata":{"id":"AGKix279mo9u"}},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{"id":"G4OWY86Smo9v"}},{"cell_type":"markdown","source":"Điều chỉnh siêu tham số (Hyperparameter Tuning) là quá trình điều chỉnh mô hình và tìm sự kết hợp của các giá trị siêu tham số cho một mô hình học máy để đạt được độ đo tốt nhất cho một vấn đề.\n\nCó một số cách thường thấy của việc điều chỉnh siêu tham số:\n\n1. __Thủ công__: lựa chọn siêu tham số dựa vào kinh nghiệm, suy đoán... và sau đó huấn luyện mô hình. Lặp lại các bước khi được kết quả phù hợp hoặc khi hết kiên nhẫn.\n2. __Grid Search__: tạo một lưới các giá trị siêu tham số và huấn luyện mô hình, tính số điểm trên tập validation với mỗi sự kết hợp.\n3. __Random search__: tạo một lưới các giá trị siêu tham số và lựa chọn ngẫu nhiên một số sự kết hợp để huấn luyện và tính điểm của mô hình. Số lần lặp lại dựa trên tài nguyên/thời gian.\n4. __Automated Hyperparameter Tuning__: sử dụng các phương pháp như gradient descent, Bayesian Optiomization hoặc các thuật toán cải tiến để tìm kiếm các siêu tham số tốt nhất.\n\n(Ta có thể xem chi tiết hơn [tại đây](https://en.wikipedia.org/wiki/Hyperparameter_optimization))","metadata":{"id":"geq4f6kjmo9w"}},{"cell_type":"markdown","source":"Tác giả của chuỗi Notebook sử dụng hướng tiếp cận 2, 3 và 4. Nhóm đã thực hiện lại và lựa chọn Automated Hyperparameter Tuning để áp dụng và cải tiến mô hình.\nChi tiết về cách thực thi của nhóm bằng những phương pháp trên:\n- [Manual Model Tuning](https://colab.research.google.com/github/huuthang2509/Applied_DS/blob/main/individual_notebooks/Manual_Model_Tuning.ipynb)\n- [Automated Model Tuning](https://colab.research.google.com/github/huuthang2509/Applied_DS/blob/main/individual_notebooks/Automated_Model_Tuning.ipynb)","metadata":{"id":"MOb8T77mmo9z"}},{"cell_type":"markdown","source":"# Automated Model Tuning","metadata":{"id":"4GOVTvjumo91"}},{"cell_type":"markdown","source":"Phần giải thích thuật toán tự động hoá điều chỉnh siêu tham số này nhóm dịch lại của tác giả, lược bỏ bớt và sử dụng theo ngôn ngữ của nhóm.","metadata":{"id":"1rbNzYn0svhu"}},{"cell_type":"markdown","source":"Tác giả sử dụng phương pháp Bayesian Optimization và thư viện Hyperopt để điều chỉnh siêu tham số của GBM một cách tự động nhằm cải tiến mô hình máy học.","metadata":{"_uuid":"b75991b6b827d4506af8e4c8528b8323053dad88","id":"MU_wldQCr0ez"}},{"cell_type":"markdown","source":"## Bayesian Optimization Primer\n\nVấn đề của grid và random search đó là chúng không phải phương pháp có sử dụng những kết quả cũ từ các giá trị khác nhau của những siêu tham số trong hàm mục tiêu. Tối ưu hóa Bayes là giới hạn các lệnh gọi đến hàm đánh giá bằng cách chọn các giá trị siêu tham số tiếp theo dựa trên các kết quả trước đó. Điều này cho phép thuật toán dành nhiều thời gian hơn để đánh giá các giá trị siêu tham số  và tốn ít thời gian hơn ở các vùng có điểm thấp của không gian siêu tham số. Ví dụ, hãy xem xét hình ảnh dưới đây:\n\n![](https://github.com/huuthang2509/Applied_DS/blob/main/Image/random_forest_hypothetical.png?raw=true)\n\nNhư hình trên thì ta nên tập trung vào khu vực có độ lỗi thấp. Tối ưu hóa Bayes hoạt động bằng cách xây dựng một hàm thay thế (dưới dạng mô hình xác suất: mô hình chứa các giá trị có thể của biến và xác suất xảy ra của biến này) của hàm mục tiêu $P(\\text{score} | \\text{hyperparameters})$. Hàm thay thế tốn ít chi phí hơn nhiều để đánh giá so với hàm mục tiêu, vì vậy thuật toán chọn các giá trị tiếp theo để thử trong mục tiêu dựa trên việc tối đa hóa một tiêu chí trên hàm thay thế (thường là cải tiến được mong đợi).\n\nHàm thay thế dựa trên kết quả đánh giá trong quá khứ. Bayesian optimization dựa trên lý luận Bayes: hình thành một mô hình và sau đó cập nhật nó với nhiều thông tin hơn. Ý tưởng ở đây là khi dữ liệu đủ nhiều, hàm thay thế ngày càng gần hàm mục tiêu, và các siêu tham số tốt nhất cho hàm thay thế cũng sẽ tốt với hàm mục tiêu. Một số lựa chọn phổ biến là Gaussian Process, Random Forest Regression và Tree Parzen Estimator.\n\n### 4 Phần của Bayesian Optimization\n\n1. __Objective Function__: hàm mục tiêu, nhận về các siêu tham số và trả về độ đo cần giảm thiểu hoặc tối ưu hoá.\n2. __Domain space__: miền giá trị của các siêu tham số để tính toán\n3. __Optimization Algorithm__: phương pháp sử dụng hàm thay thế và lựa chọn giá trị tiếp theo cho mô hình\n4. __Results__: độ đo và các cặp giá trị để thuật toán sử dụng cho việc xây dựng hàm thay thế\n\n## Hyperopt\n\nHyperopt là một thư viện Python mã nguồn mở triển khai Bayesian Optimization bằng cách sử dụng thuật toán Tree Parzen Estimator để xây dựng hàm thay thế và chọn các giá trị siêu tham số tiếp theo để đánh giá trong hàm mục tiêu.\n[Hyperopt Documentation](http://hyperopt.github.io/hyperopt/)\n\n\n## Tập dữ liệu và hướng tiếp cận\n\nBởi vì dữ liệu của cuộc thi rất lớn (~300.000 mẫu), nếu thực hiện hết ngay từ đầu sẽ rất tốn thời gian và tài nguyên. Nhóm sẽ thực hiện trước trên tập giới hạn với 20000 dữ liệu train, 10000 dữ liệu test. (Tác giả thực hiện trên tập 10000 train, 6000 test; nhóm quyết định nâng dữ liệu lên để tránh hiện tượng overfitting). Sau khi áp dụng Bayesian hyperparameter optimization trên tập giới hạn này và có được giá trị của bộ siêu tham số tối ưu. Nhóm sẽ thực hiện tiếp trên tập dữ liệu đã được tiền xử lý từ phần trước.\n\n\n## Cross Validation\n\nChia tập train thành các tập con nhỏ đến tiến hành huấn luyện và xác thực chéo lẫn nhau. Sử dụng KFold (KFold cross validation) với n_fold = 5. Tập train sẽ được chia làm 5 phần, sau đó tiến hành train 5 lần, với mỗi lần thì sẽ dùng 1 phần làm validation và 4 phần còn lại làm dữ liệu train. Kết quả đánh giá model sẽ là trung bình cộng của 5 lần train. Hiệu suất của mỗi bộ siêu tham số sẽ được tính bằng ROC AUC. \n\n\n### Early Stopping\n\nSiêu tham số number of estimators (số lượng cây quyết định được đào tạo tuần tự) là một trong những siêu tham số quan trọng nhất trong GBM. Phương pháp early stopping sẽ dừng quá trình train khi lỗi không giảm trong một số lần lặp nhất định. Trong bài này, tác giả áp dụng early stopping với 100 lần lặp. \n\nNếu ta cứ tiếp tục huấn luyện khi độ lỗi không giảm thì có thể sai số huấn luyện sẽ giảm nhưng sẽ dẫn đến việc overfitting do mô hình quá phụ thuộc vào dữ liệu train.\n\nNội dung các phần code là nhóm thực hiện lại theo tác giả và lược bớt những phần không cần thiết.","metadata":{"id":"jVpvVqKoBmtz"}},{"cell_type":"markdown","source":"## Thực hiện","metadata":{"id":"6_oX4YcZmo96"}},{"cell_type":"markdown","source":"### Import thư viện","metadata":{"_uuid":"1798704d5f149fb36233f30149560847d3483690","id":"G82GxvaBr0fE"}},{"cell_type":"code","source":"# Thư viện để thực hiện các thao tác trên dữ liệu\nimport pandas as pd\nimport numpy as np\n\n# Mô hình\nimport lightgbm as lgb\n\n# Đánh giá mô hình\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\n# Trực quan hoá\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['font.size'] = 18\n%matplotlib inline\n\n# Các hằng phục vụ cho việc lựa chọn tham số\nN_FOLDS = 5\nMAX_EVALS = 5","metadata":{"_uuid":"ad6e0966d342110e5306d6c74a63f682e164e6a4","execution":{"iopub.execute_input":"2021-12-26T10:28:47.233925Z","iopub.status.busy":"2021-12-26T10:28:47.233111Z","iopub.status.idle":"2021-12-26T10:28:47.261742Z","shell.execute_reply":"2021-12-26T10:28:47.26091Z","shell.execute_reply.started":"2021-12-26T10:28:47.233772Z"},"id":"TgxosbWer0fG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import Data","metadata":{"id":"cKeyKcWDr-G3"}},{"cell_type":"code","source":"# Nhập dữ liệu train\n# Nhóm có thử thực hiện sử dụng dữ liệu train là dữ liệu do nhóm tiền xử lý hoặc tăng số lượng mẫu, tuy nhiên không thành công\n# Chi tiết nhóm sẽ trình bày ở phần \"Một số cải tiến nhưng không thành công\"\nfeatures = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\n\n# Chọn ra 30000 mẫu\nfeatures = features.sample(n = 30000, random_state = 42)\n\n# Chọn ra các thuộc tính là number để tăng tốc độ tìm kiếm\nfeatures = features.select_dtypes('number')\n\n# Tách thuộc tính TARGET riêng khỏi tập train\nlabels = np.array(features['TARGET'].astype(np.int32)).reshape((-1, ))\nfeatures = features.drop(columns = ['TARGET', 'SK_ID_CURR'])\n\n# Chia tập dữ liệu thành 20000 mẫu để train và 10000 mẫu để test\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 10000, random_state = 42)\n\nprint('Train shape: ', train_features.shape)\nprint('Test shape: ', test_features.shape)\n\ntrain_features.head()","metadata":{"_uuid":"7d46f3c242a588fb69fd805188cbb262bf2b619e","execution":{"iopub.execute_input":"2021-12-26T10:28:47.263515Z","iopub.status.busy":"2021-12-26T10:28:47.262981Z","iopub.status.idle":"2021-12-26T10:28:54.709771Z","shell.execute_reply":"2021-12-26T10:28:54.708779Z","shell.execute_reply.started":"2021-12-26T10:28:47.26347Z"},"id":"-pgadfGur0fL","outputId":"dd626453-d57a-4939-986a-d210befc57ff"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baseline Model \n","metadata":{"id":"cg9ewGJhmo-G"}},{"cell_type":"markdown","source":"Ta tạo một baseline model với các siêu tham số mặc định và tính độ đo của nó.","metadata":{"id":"mpKIv07mmo-H"}},{"cell_type":"code","source":"model = lgb.LGBMClassifier(random_state=50)\n\n# Chia tập dữ liệu\ntrain_set = lgb.Dataset(train_features, label = train_labels)\ntest_set = lgb.Dataset(test_features, label = test_labels)\n\n# Chọn tham số mặc định\nhyperparameters = model.get_params()\n\n# Xoá bỏ tham số 'n_estimators' nếu có, vì ta sẽ sử dụng early stopping\ndel hyperparameters['n_estimators']\n\n# Thực hiện n_folds cross validation với 100 lần lặp early stopping\ncv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, metrics = 'auc', \n           early_stopping_rounds = 100, verbose_eval = False, seed = 42)\n\n# Trích xuất độ đo cv cao nhất\nbest = cv_results['auc-mean'][-1]\n\n# Độ lệch chuẩn của best score\nbest_std = cv_results['auc-stdv'][-1]\n\nprint('The maximium ROC AUC in cross validation was {:.5f} with std of {:.5f}.'.format(best, best_std))\nprint('The ideal number of iterations was {}.'.format(len(cv_results['auc-mean'])))","metadata":{"execution":{"iopub.execute_input":"2021-12-26T10:28:54.711472Z","iopub.status.busy":"2021-12-26T10:28:54.71099Z","iopub.status.idle":"2021-12-26T10:29:00.273105Z","shell.execute_reply":"2021-12-26T10:29:00.27219Z","shell.execute_reply.started":"2021-12-26T10:28:54.711323Z"},"id":"OSdFogZTmo-I","outputId":"251cda95-b4fe-40f4-bf44-6021c9637e6d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Đánh giá độ đo ROC AUC trước khi điều chỉnh siêu tham số.","metadata":{"id":"5sNW1gK7mo-K"}},{"cell_type":"code","source":"# Tối ưu hoá số lượng vòng lặp thực thi\nmodel.n_estimators = len(cv_results['auc-mean'])\n\n# Huấn luyện và dự đoán kết quả\nmodel.fit(train_features, train_labels)\npreds = model.predict_proba(test_features)[:, 1]\nbaseline_auc = roc_auc_score(test_labels, preds)\n\nprint('The baseline model scores {:.5f} ROC AUC on the test set.'.format(baseline_auc))","metadata":{"execution":{"iopub.execute_input":"2021-12-26T10:29:00.274597Z","iopub.status.busy":"2021-12-26T10:29:00.274361Z","iopub.status.idle":"2021-12-26T10:29:00.745225Z","shell.execute_reply":"2021-12-26T10:29:00.744529Z","shell.execute_reply.started":"2021-12-26T10:29:00.274563Z"},"id":"pHlCiKCjmo-L","outputId":"9f736d9d-ee9f-4dc2-f173-700b914bbe55"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Objective Function\n\nHàm tối ưu hoá thường trả về việc giảm thiếu các giá trị, còn ROC AUC tốt khi đạt giá trị cao. Cho nên hàm mục tiêu sẽ trả về $1 - \\text{ROC AUC Cross Validation}$. Kết quả trả về thấp, đồng nghĩa với ROC AUC cao.\n\nHàm sau khi thực thi sẽ lưu các giá trị vào file csv để theo dõi kết quả","metadata":{"_uuid":"b5a87e7da07f85f4829d3d6a5390d6cacf81200f","id":"qdAv7zOhr0fR"}},{"cell_type":"code","source":"import csv\n# Kiểm tra trạng thái và thời gian thực thi\nfrom hyperopt import STATUS_OK\nfrom timeit import default_timer as timer\n\n\"\"\"Objective function cho Gradient Boosting Machine Hyperparameter Optimization.\n        Hàm nhận vào các giá trị của các siêu tham số.\n        Hàm trả về bộ các thông tin của lần lặp: độ lỗi(loss), giá trị của các siêu tham số,\n        lần lặp, thời gian thực thi, trạng thái thực thi\n        Qua mỗi lần lặp sẽ viết một dòng mới vào 'outfile'\"\"\"\ndef objective(hyperparameters):\n      \n    # Biến đếm lần lặp\n    global ITERATION\n    \n    ITERATION += 1\n    \n    # Xoá bỏ tham số 'n_estimators' nếu có, vì ta sẽ sử dụng early stopping\n    if 'n_estimators' in hyperparameters:\n        del hyperparameters['n_estimators']\n         \n    # Lấy subsample, cài đặt boosting_type và subsample là khoá chính của từ điển\n    # Khi không có subsample thì mặc định sẽ được gán là 1.0\n    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n    hyperparameters['subsample'] = subsample\n    \n    # Đảm bảo các tham số là số nguyên\n    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n\n    start = timer()\n    \n    # Thực hiện n_folds cross validation với 100 lần lặp early stopping\n    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n\n    run_time = timer() - start\n    \n    # Trích xuất độ đo cv cao nhất\n    best_score = cv_results['auc-mean'][-1]\n    \n    # Tính toán giá trị loss\n    loss = 1 - best_score\n    \n    # Số lượng vòng lặp mà thuật toán thực hiện\n    n_estimators = len(cv_results['auc-mean'])\n    \n    # Thêm chỉ số lần lặp vào từ điển\n    hyperparameters['n_estimators'] = n_estimators\n\n    # Ghi kết quả vào file csv\n    of_connection = open(OUT_FILE, 'a')\n    writer = csv.writer(of_connection)\n    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n    of_connection.close()\n\n    \"\"\" Từ điển trả về bao gồm các thông tin của lần lặp: độ lỗi(loss), giá trị của các siêu tham số,\n        lần lặp, thời gian thực thi, trạng thái thực thi\"\"\"\n    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n            'train_time': run_time, 'status': STATUS_OK}","metadata":{"_uuid":"ba10be21a3938f6dda3c45a7872a9fcf97529983","execution":{"iopub.execute_input":"2021-12-26T10:29:00.747353Z","iopub.status.busy":"2021-12-26T10:29:00.746798Z","iopub.status.idle":"2021-12-26T10:29:00.83419Z","shell.execute_reply":"2021-12-26T10:29:00.83317Z","shell.execute_reply.started":"2021-12-26T10:29:00.747295Z"},"id":"XPC_sEuVr0fS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Miền giá trị (Domain)\n\nĐối với mỗi siêu tham số, miền giá trị biểu thị một phân phối xác suất chứ không được xác định tại mỗi điểm rời rạc. Sử dụng thư viện hyperopt để thể hiện điều này.","metadata":{"_uuid":"0f694f36815af159485cebae5e89f6c5c92db4a4","id":"EePXH3nrr0fT"}},{"cell_type":"markdown","source":"### Hyperparameters for GBM\n\nXem đầy đủ tại [LightGBM documentation](http://lightgbm.readthedocs.io/en/latest/Parameters.html).","metadata":{"id":"KtBfqNzWmo-Q"}},{"cell_type":"code","source":"from hyperopt import hp\nfrom hyperopt.pyll.stochastic import sample","metadata":{"_uuid":"de250ef92c2ecf63d73c3365bf004c456de55af8","execution":{"iopub.execute_input":"2021-12-26T10:29:00.835778Z","iopub.status.busy":"2021-12-26T10:29:00.835513Z","iopub.status.idle":"2021-12-26T10:29:00.85138Z","shell.execute_reply":"2021-12-26T10:29:00.850551Z","shell.execute_reply.started":"2021-12-26T10:29:00.835719Z"},"id":"Ro8TJGRjr0fT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Miền hoàn chỉnh của Bayesian\n\nTác giả thực hiện thuật toán nhiều lần và lựa chọn ra các miền giá trị phù hợp. Có 10 siêu tham số được chọn.","metadata":{"_uuid":"986503a57f0ce7e6181eea0e8aa776b6d438ff5e","id":"0OQwZ2m0r0fa"}},{"cell_type":"code","source":"space = {\n    'boosting_type': hp.choice('boosting_type', \n                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n}","metadata":{"_uuid":"3e64d5e64487d437faf17cfb349aa9cc03f5cb5a","execution":{"iopub.execute_input":"2021-12-26T10:29:00.853102Z","iopub.status.busy":"2021-12-26T10:29:00.852761Z","iopub.status.idle":"2021-12-26T10:29:00.871798Z","shell.execute_reply":"2021-12-26T10:29:00.870991Z","shell.execute_reply.started":"2021-12-26T10:29:00.853031Z"},"id":"lO7tyDvkr0fb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kiểm tra tính đúng của hàm mục tiêu với các miền.","metadata":{"id":"IxBrcF-rmo-W"}},{"cell_type":"code","source":"# Tạo file csv lưu kết quả\nOUT_FILE = 'bayes_test.csv'\nof_connection = open(OUT_FILE, 'w')\nwriter = csv.writer(of_connection)\n\nITERATION = 0\n\n# Tạo dòng tiêu đề\nheaders = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\nwriter.writerow(headers)\nof_connection.close()\n\n# Kiểm tra hàm mục tiêu\nresults = objective(sample(space))\nprint('The cross validation loss = {:.5f}.'.format(results['loss']))\nprint('The optimal number of estimators was {}.'.format(results['hyperparameters']['n_estimators']))","metadata":{"id":"R6_h8dzemo-X","outputId":"6ab93a3f-cb6e-4fbe-9f25-a846b09ba4f4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thuật toán tối ưu hoá\n\nThuật toán tối ưu hóa là phương pháp xây dựng hàm thay thế (mô hình xác suất) và chọn tập siêu tham số tiếp theo để đánh giá trong hàm mục tiêu. Hyperopt có hai lựa chọn: tìm kiếm ngẫu nhiên và Tree Parzen Estimator.\n\nChi tiết về TPE có thể xem [tại đây](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf) và [đây](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f).","metadata":{"_uuid":"ac777fc3c83709161d43e0d751844548966b7741","id":"7F3E48vAr0fd"}},{"cell_type":"markdown","source":"Sơ lược về TPE:\n- Tổng quan:\n    - TPE đưa ra lịch sử tìm kiếm và gợi ý bộ siêu tham số cho lần thử tiếp theo\n    - Áp dụng độc lập cho từng siêu tham số của miền giá trị\n- Input:\n    - Lịch sử tìm kiếm (bộ tham số, độ đo)\n    - Biểu thức tính toán\n- Output:\n    - Gợi ý giá trị của từng tham số cho bước tiếp theo","metadata":{"id":"SU5-VzXwmYGY"}},{"cell_type":"code","source":"from hyperopt import tpe\n\n# Khởi tạo thuật toán\ntpe_algorithm = tpe.suggest","metadata":{"_uuid":"5c33d18601fd7a9211e34351bf8cbf6b3ae0fbc5","execution":{"iopub.execute_input":"2021-12-26T10:29:00.87357Z","iopub.status.busy":"2021-12-26T10:29:00.873263Z","iopub.status.idle":"2021-12-26T10:29:00.889722Z","shell.execute_reply":"2021-12-26T10:29:00.888989Z","shell.execute_reply.started":"2021-12-26T10:29:00.873515Z"},"id":"D9jHSNb-r0fd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lịch sử các kết quả\nHyperopt có cơ chế lưu giữ lại kết quả của thuật toán, nếu ta muốn tự theo dõi thì có 2 phương pháp:\n\n1. Một đối tượng `Trials` lưu trữ từ điển được hàm mục tiêu trả về: cách này là của Hyperopt\n2. Thêm một dòng vào file csv ở mỗi lần lặp: cách này là để mình xuất ra file csv sau này import lại nếu cần","metadata":{"_uuid":"474f0f6308ecc63cba6e8f1c3f226e926af28e47","id":"xITRFy6mr0ff"}},{"cell_type":"code","source":"# Sử dụng Trials\nfrom hyperopt import Trials\ntrials = Trials()\n\n# Sử dụng file csv\nOUT_FILE = 'bayes_test.csv'\nof_connection = open(OUT_FILE, 'w')\nwriter = csv.writer(of_connection)\n\nITERATION = 0\n\nheaders = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\nwriter.writerow(headers)\nof_connection.close()","metadata":{"execution":{"iopub.execute_input":"2021-12-26T10:29:00.8911Z","iopub.status.busy":"2021-12-26T10:29:00.890865Z","iopub.status.idle":"2021-12-26T10:29:00.902663Z","shell.execute_reply":"2021-12-26T10:29:00.901882Z","shell.execute_reply.started":"2021-12-26T10:29:00.89106Z"},"id":"H-4382kVmo-a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Automated Hyperparameter Optimization trong thực tế\n\nTa sử dụng `fmin` để chạy Bayesian optimization.","metadata":{"_uuid":"262b8db537d8b9fdf292d8bd26a5437e4c1a817d","id":"Z_wUlm3wr0fh"}},{"cell_type":"code","source":"from hyperopt import fmin","metadata":{"_uuid":"da392f020f3a69c5b65719f0b2de5645dd917c23","execution":{"iopub.execute_input":"2021-12-26T10:29:00.904088Z","iopub.status.busy":"2021-12-26T10:29:00.90382Z","iopub.status.idle":"2021-12-26T10:29:00.91508Z","shell.execute_reply":"2021-12-26T10:29:00.914352Z","shell.execute_reply.started":"2021-12-26T10:29:00.904025Z"},"id":"_df0L-dkr0fh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`fmin` thực hiện toàn bộ 4 phần ở trên và với số lần lặp lại là `max_evals`. ","metadata":{"_uuid":"76bb8e045c5f49a0a18c469672f6f7a45b6daaa4","id":"uAq9XtE6r0fi"}},{"cell_type":"code","source":"# Biến đếm lần lặp\nglobal  ITERATION\n\nITERATION = 0\n\n# Thực hiện tối ưu hoá với hàm mục tiêu, miền giá trị, thuật toán tối ưu hoá, lịch sử. số lần lặp tối đa\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n            max_evals = MAX_EVALS)\n\nbest","metadata":{"_uuid":"61c1dff17f82f41f143070d10233eeb2f52212bc","execution":{"iopub.execute_input":"2021-12-26T10:29:00.9166Z","iopub.status.busy":"2021-12-26T10:29:00.916179Z","iopub.status.idle":"2021-12-26T10:29:19.226088Z","shell.execute_reply":"2021-12-26T10:29:19.225509Z","shell.execute_reply.started":"2021-12-26T10:29:00.916543Z"},"id":"p-YXZIMer0fi","outputId":"7706b240-e79e-4e4a-92e7-48e4997003a1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`best` sẽ lưu các siêu tham số cho ra giá trị thấp nhất ở hàm mục tiêu. Ta có thể xem lại cá bước thực thi thông qua `Trials` hoặc file `csv`.","metadata":{"_uuid":"1068012ebcbf781b4f48dddb0d73bd9c2d6c013c","id":"c4bIF_h2r0fi"}},{"cell_type":"code","source":"trials_dict = sorted(trials.results, key = lambda x: x['loss'])\ntrials_dict[:1]","metadata":{"execution":{"iopub.execute_input":"2021-12-26T10:29:19.227356Z","iopub.status.busy":"2021-12-26T10:29:19.226995Z","iopub.status.idle":"2021-12-26T10:29:19.234134Z","shell.execute_reply":"2021-12-26T10:29:19.233304Z","shell.execute_reply.started":"2021-12-26T10:29:19.227317Z"},"id":"4_-WRMSrmo-h","outputId":"208ba6bc-392b-4534-a41b-a766e9c45e3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.read_csv(OUT_FILE)","metadata":{"execution":{"iopub.execute_input":"2021-12-26T10:29:19.235673Z","iopub.status.busy":"2021-12-26T10:29:19.235423Z","iopub.status.idle":"2021-12-26T10:29:19.249906Z","shell.execute_reply":"2021-12-26T10:29:19.2492Z","shell.execute_reply.started":"2021-12-26T10:29:19.235626Z"},"id":"RKN8hUkqmo-i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Xây dựng hàm đánh giá, hàm này sẽ nhận kết quả, đào tạo một mô hình trên dữ liệu train và đánh giá trên dữ liệu tập test. Nó trả về một dataframes các siêu tham số.\n\nTa lưu kết quả vào file csv, ở file csv kết quả sẽ được lưu thành string do đó ta dùng `ast.literal_eval` để chuyển lại thành từ điển.","metadata":{"_uuid":"caf8239e0d550e8379900520a93567ef38084a91","id":"dNNFLp2sr0fj"}},{"cell_type":"code","source":"import ast\n\ndef evaluate(results, name):\n    \"\"\" Đánh giá mô hình trên dữ liệu test thông qua bộ siêu tham số của result\n        Hàm trả về dataframe của các bộ siêu tham số\"\"\"\n    \n    new_results = results.copy()\n    # Chuyển đổi kiểu string thành kiểu dictionary\n    new_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n    \n    # Sắp xếp lại dữ liệu với giá trị tốt nhất đứng đầu\n    new_results = new_results.sort_values('score', ascending = False).reset_index(drop = True)\n    \n    # In ra độ đo cv\n    print('The highest cross validation score from {} was {:.5f} found on iteration {}.'.format(name, new_results.loc[0, 'score'], new_results.loc[0, 'iteration']))\n    \n    # Trích xuất bộ siêu tham số tối ưu\n    hyperparameters = new_results.loc[0, 'hyperparameters']\n    model = lgb.LGBMClassifier(**hyperparameters)\n    \n    # Huấn luyện và dự đoán kết quả\n    model.fit(train_features, train_labels)\n    preds = model.predict_proba(test_features)[:, 1]\n    \n    print('ROC AUC from {} on test data = {:.5f}.'.format(name, roc_auc_score(test_labels, preds)))\n    \n    # Tạo dataframe lưu bộ siêu tham số\n    hyp_df = pd.DataFrame(columns = list(new_results.loc[0, 'hyperparameters'].keys()))\n\n    # Lưu các bộ giá trị còn lại\n    for i, hyp in enumerate(new_results['hyperparameters']):\n        hyp_df = hyp_df.append(pd.DataFrame(hyp, index = [0]), \n                               ignore_index = True)\n        \n    # Ghi giá trị iteration và score vào dataframe trả về\n    hyp_df['iteration'] = new_results['iteration']\n    hyp_df['score'] = new_results['score']\n    \n    return hyp_df","metadata":{"_uuid":"3718a29f6665b1966429adb0cb4387de44c10ef5","execution":{"iopub.execute_input":"2021-12-26T10:29:19.251519Z","iopub.status.busy":"2021-12-26T10:29:19.251074Z","iopub.status.idle":"2021-12-26T10:29:19.311618Z","shell.execute_reply":"2021-12-26T10:29:19.31078Z","shell.execute_reply.started":"2021-12-26T10:29:19.251478Z"},"id":"EsMGZi5vr0fj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bayes_results = evaluate(results, name = 'Bayesian')\nbayes_results","metadata":{"id":"IgkToJWjmo-l","outputId":"5cbe8b28-b778-4589-f98b-442c08604cec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Các phần ở trên là ví dụ các cách thực thi của việc Automated Model Tuning, được dùng trên một số mẫu nhỏ. Phần dưới đây ta sẽ tiến hành trên tập Limited Data thực tế.","metadata":{"id":"VN9F1_8Hd0rW"}},{"cell_type":"markdown","source":"## Thực hiện trên tập Limited Data\n","metadata":{"_uuid":"177c71a7774d8c4bde35d9373cbc8b936cfe9a00","id":"581Y9cyDr0fm"}},{"cell_type":"markdown","source":"Tác giả chạy 1000 lần tính toán trên tập dữ liệu giới hạn để so sánh. Nhóm đã thực hiện trước và lưu lại các file csv vào dataset \"[Home Credit Team8 Model Tuning](https://www.kaggle.com/chnhgr/home-credit-team8-model-tuning)\" nên đoạn code dưới này được comment lại.","metadata":{"id":"cLhaAQeOmo-o"}},{"cell_type":"code","source":"# # Thực hiện 1000 lần lặp\n# MAX_EVALS = 1000\n\n# # Tạo file để lưu kết quả\n# OUT_FILE = 'bayesian_trials_1000.csv'\n# of_connection = open(OUT_FILE, 'w')\n# writer = csv.writer(of_connection)\n\n# # Tạo header file\n# headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n# writer.writerow(headers)\n# of_connection.close()\n\n# # Sử dụng Trials để lưu các giá trị\n# trials = Trials()\n\n# global ITERATION\n\n# ITERATION = 0 \n\n# # Thực thi thuật toán\n# best = fmin(fn = objective, space = space, algo = tpe.suggest,\n#             trials = trials, max_evals = MAX_EVALS)\n\n# # Sắp xếp các kết quả với giá trị có loss thấp nhất (điểm AUC cao nhất) ở đầu\n# trials_dict = sorted(trials.results, key = lambda x: x['loss'])\n\n# print('Finished, best results')\n# print(trials_dict[:1])\n\n# # Ghi kết quả vào file\n# with open('trials.json', 'w') as f:\n#     f.write(json.dumps(trials_dict))","metadata":{"_uuid":"4e3f5f06fe20d5085f09b554db701ca642e38b40","execution":{"iopub.status.busy":"2021-12-26T10:29:19.456865Z","iopub.status.idle":"2021-12-26T10:29:19.457316Z"},"id":"sJ0pgs2cr0fm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Kết quả thực hiện","metadata":{"id":"lvRsw8Hvmo-r"}},{"cell_type":"markdown","source":"Kết quả thực hiện trên tập Limited Data với 1000 lần lặp. Sau bước này ta sẽ sử dụng giá trị của các siêu tham số tìm được để áp dụng cho toàn bộ dữ liệu của cuộc thi. Ở đa ta sẽ lấy dữ liệu của cả Random Search để so sánh.","metadata":{"id":"hoyjanYbmo-s"}},{"cell_type":"code","source":"# Lấy lại kết quả nhóm đã thực hiện trước đó, kết quả được sắp xếp lại với giá trị tốt nhất nằm đầu tiên\nbayes_results = pd.read_csv('../input/home-credit-team8-model-tuning/bayesian_trials_1000_30000.csv').sort_values('score', ascending = False).reset_index()\n\n# Đánh giá mô hình và chọn ra bộ siêu tham số tối ưu nhất\nbayes_params = evaluate(bayes_results, name = 'Bayesian')","metadata":{"execution":{"iopub.execute_input":"2021-12-26T10:29:49.821533Z","iopub.status.busy":"2021-12-26T10:29:49.821204Z","iopub.status.idle":"2021-12-26T10:29:56.986008Z","shell.execute_reply":"2021-12-26T10:29:56.985095Z","shell.execute_reply.started":"2021-12-26T10:29:49.821479Z"},"id":"aAFBtr7wmo-s","outputId":"7e5183ae-4f39-4bef-96e9-26aa65aa116f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizations","metadata":{"id":"nqBY_6_8mo-t"}},{"cell_type":"markdown","source":"### Độ đo ROC AUC qua mỗi lần lặp","metadata":{"id":"j-YVqLjQmo-u"}},{"cell_type":"code","source":"# Dataframe thể hiện độ đo\nscores = pd.DataFrame({'ROC AUC': bayes_params['score'], 'iteration': bayes_params['iteration'], 'search': 'Bayesian'})\n\nscores['ROC AUC'] = scores['ROC AUC'].astype(np.float32)\nscores['iteration'] = scores['iteration'].astype(np.int32)\n\n# Giá trị tốt nhất\nbest_bayes_params = bayes_params.iloc[bayes_params['score'].idxmax(), :].copy()\n\n# Vẽ biểu đồ giá trị ROC AUC của mỗi lần lặp\nsns.lmplot('iteration', 'ROC AUC', hue = 'search', data = scores, size = 8);\nplt.scatter(best_bayes_params['iteration'], best_bayes_params['score'], marker = '*', s = 400, c = 'orange', edgecolor = 'k')\nplt.xlabel('Iteration'); plt.ylabel('ROC AUC'); plt.title(\"Validation ROC AUC versus Iteration\");","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:29:19.458906Z","iopub.status.idle":"2021-12-26T10:29:19.459313Z"},"id":"6TNPdKHtmo-v","outputId":"b88fc238-9d4e-4230-b55d-f58e3415ac04"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Áp dụng trên toàn bộ tập dữ liệu\n\nSử dụng các siêu tham số tốt nhất được tìm ra từ random search để áp dụng cho toàn bộ tập dữ liệu sau khi đã tiền xử lý của nhóm.\n\nTổng hợp các dataset đã xử lý của nhóm: \"[Home Credit Team8 Dataset](https://www.kaggle.com/chnhgr/home-credit-team8-dataset)\"","metadata":{"id":"qW8WWF2tmo_k"}},{"cell_type":"code","source":"# Đọc dữ liệu\ntrain = pd.read_csv('../input/home-credit-team8-dataset/final_train_2.csv')\ntest = pd.read_csv('../input/home-credit-team8-dataset/final_test_2.csv')\n\n# Tách cột ID và Target\ntest_ids = test['SK_ID_CURR']\ntrain_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1, ))\n\ntrain = train.drop(columns = ['SK_ID_CURR', 'TARGET'])\ntest = test.drop(columns = ['SK_ID_CURR'])\n\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:29:19.459855Z","iopub.status.idle":"2021-12-26T10:29:19.460245Z"},"id":"XF6EkIV2mo_l","outputId":"fc80a2a6-b5a3-4279-aeca-e82323651c37"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bayes_results['hyperparameters'] = bayes_results['hyperparameters'].map(ast.literal_eval)\ntrain_set = lgb.Dataset(train, label = train_labels)\nhyperparameters = dict(**bayes_results.loc[0, 'hyperparameters'])\ndel hyperparameters['n_estimators']\n\n# Thực thi Cross validation\ncv_results = lgb.cv(hyperparameters, train_set,\n                    num_boost_round = 10000, early_stopping_rounds = 100, \n                    metrics = 'auc', nfold = N_FOLDS)\n\nprint('The cross validation score on the full dataset for Bayesian optimization = {:.5f} with std: {:.5f}.'.format(\n    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\nprint('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:29:19.460785Z","iopub.status.idle":"2021-12-26T10:29:19.461166Z"},"id":"Lr2qbzkGmo_m","outputId":"956a2f31-e4f3-4521-b71d-141851ff981c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dự đoán kết quả trên tập test\nmodel = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameters)\nmodel.fit(train, train_labels)\n\npreds = model.predict_proba(test)[:, 1]\n\nsubmission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': preds})\nsubmission.to_csv('submission_bayesian_optimization.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-26T10:29:19.461699Z","iopub.status.idle":"2021-12-26T10:29:19.462065Z"},"id":"CyZVW74emo_n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Kết quả","metadata":{"id":"aQRk2DjEmo_o"}},{"cell_type":"markdown","source":"**Kết quả của tác giả là:**\n- Thời gian thực thi trên Kaggle: __3750.5s__.\n- Public Leaderboard: __0.791__.","metadata":{"id":"bOU89Tg6mo_p"}},{"cell_type":"markdown","source":"**Kết quả của Solution Top1 là:**\n- Public Leaderboard: __0.80920__.\n- Private Leaderboard: __0.80570__.","metadata":{"id":"GvG81QWFmo_q"}},{"cell_type":"markdown","source":"**Kết quả của nhóm là:**\n\n|                            \t| <font size=\"3\"> Dataset 1 \t| <font size=\"3\"> Dataset 2 \t| <font size=\"3\"> Dataset 3 \t|\n|:--------------------------:\t|:---------:\t|:---------:\t|:---------:\t|\n| <font size=\"3\"> Thời gian chạy trên Kaggle \t|  <font size=\"3\"> 2531.2s  \t|  <font size=\"3\"> 2395.9s \t|  <font size=\"3\"> 4079.8s \t|\n|     <font size=\"3\"> Private Leaderboard    \t|  <font size=\"3\"> 0.78873  \t|  <font size=\"3\"> 0.79011 \t|  <font size=\"3\"> 0.79073  \t|\n|     <font size=\"3\"> Public Leaderboard     \t|  <font size=\"3\"> 0.79491  \t|  <font size=\"3\"> 0.79573  \t|  <font size=\"3\"> 0.79456  \t|\n","metadata":{"id":"HaqP-UWrmo_q"}},{"cell_type":"markdown","source":"## Một số cải tiến nhưng không thành công\n\nTác giả sử dụng việc điều chỉnh siêu tham dựa vào việc tìm kiếm trên file `application_train` của đề bài. Nhóm nhận thấy là nếu sử dụng tìm kiếm trên file data train sau khi tiền xử lý thì có thể cho ra kết quả tốt hơn. Tuy nhiên kích thước file data train quá lớn, thực hiện tìm kiếm trên đó bị quá thời gian của Kaggle (9 tiếng).\n\nCụ thể nhóm thực hiện tìm kiếm lần lượt với các cách chia: 20000 train - 10000 test, 15000 - 10000, 10000 - 6000, 10000 - 5000 với cả 3 dataset tuy nhiên đều bị quá 9 tiếng (nhóm cũng đã thử trên cả GPU).\n\nKhi hạ số lượng xuống dưới mức 10000 train - 6000 test thì thực hiện được, nhưng kết quả khi submit lại thấp hơn nhiều (cao nhất là 0.787 với private và 0.79 với public) nên nhóm không lựa chọn cách này nữa. Bởi vì tốn rất nhiều thời gian chạy và không có hiệu quả cao.\n\nNhóm cũng có thực hiện tìm kiếm trên file `application_train` với các cách chia lớn hơn 100000 train - 50000 test, 50000 - 30000 nhưng cũng vượt quá giới hạn của kaggle.\n","metadata":{"id":"_wtpFPxJY-nF"}}]}