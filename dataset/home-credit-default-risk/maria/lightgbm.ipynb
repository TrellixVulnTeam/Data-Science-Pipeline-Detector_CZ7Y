{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nimport time\nfrom scipy import interp\n\nfrom contextlib import contextmanager\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import roc_auc_score, roc_curve, average_precision_score,precision_recall_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport pandas as pd\nimport numpy as np\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nimport imblearn\nfrom mpl_toolkits.mplot3d import Axes3D\nnp.random.seed(5)\nfrom sklearn import decomposition, datasets \nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import auc\nfrom sklearn import metrics\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import shuffle\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/preprocessed-home-credit/local_data_final.csv')\ntest_df = pd.read_csv('../input/preprocessed-home-credit/kaggle_test_final.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = train_df.head(70000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(t, test_df):\n    train_dff = t.drop(columns = ['SK_ID_CURR',\"TARGET\"],axis = 1)\n    X_train = train_dff.values\n    print (X_train.shape)\n    Y_train = t['TARGET']\n    \n    test_dff = test_df.drop(columns = ['SK_ID_CURR',\"TARGET\"],axis = 1)\n    X_test = test_dff.values\n    print (X_test.shape)\n\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    print (scaler)\n    xtr = pd.DataFrame((scaler.transform(X_train)).tolist())\n#     xtr['TARGET'] = Y_train.values.tolist()\n\n    xte = pd.DataFrame((scaler.transform(X_test)).tolist())\n\n    # df_norm = shuffle(df_norm.values)\n    # df_norm = pd.DataFrame(df_norm.tolist())\n    return xtr, xte, Y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train = normalize (t, test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = train_df.drop('SK_ID_CURR', axis = 1)\ndfff = dff.drop('TARGET', axis = 1)\ntarget = dff['TARGET']\nX_train.columns = dfff.columns\nX_test.columns = dfff.columns\ntrain_dff = X_train\ntrain_dff['TARGET'] = Y_train.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dff = X_test\ntest_dff.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def learning_rate_010_decay_power_099(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_010_decay_power_0995(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_005_decay_power_099(current_iter):\n    base_learning_rate = 0.05\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\nimport lightgbm as lgb\nfit_params={\"early_stopping_rounds\":30, \n            \"eval_metric\" : 'auc', \n#             \"eval_set\" : [(X_test,Y_test)],\n            'eval_names': ['valid'],\n            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n            'verbose': 100,\n            'categorical_feature': 'auto'}\n\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nparam_test ={'num_leaves': sp_randint(6, 50), \n             'min_child_samples': sp_randint(100, 500), \n             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n             'subsample': sp_uniform(loc=0.2, scale=0.8), \n             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n\n\n#This parameter defines the number of HP points to be tested\nn_HP_points_to_test = 100\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\nclf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\ngs = RandomizedSearchCV(\n    estimator=clf, param_distributions=param_test, \n    n_iter=n_HP_points_to_test,\n    scoring='roc_auc',\n    cv=3,\n    refit=True,\n    random_state=314,\n    verbose=True)\n\n\nopt_parameters = {'colsample_bytree': 0.48263575356020577, 'min_child_samples': 311, \n                  'min_child_weight': 1, 'num_leaves': 7, 'reg_alpha': 7, 'reg_lambda': 0.1, \n                  'subsample': 0.3542761367404292} \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM GBDT with KFold or Stratified KFold\ndef kfold_lightgbm(train_df,test_df,Y_train,num_folds,stratified = False, debug= False):\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n    else:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n\n        # LightGBM parameters found by Bayesian optimization\n        clf = LGBMClassifier(boosting_type='gbdt', class_weight=None,\n        colsample_bytree=0.48263575356020577, importance_type='split',\n        learning_rate=0.1, max_depth=-1, metric='None',\n        min_child_samples=311, min_child_weight=1, min_split_gain=0.0,\n        n_estimators=10000, n_jobs=4, num_leaves=7, objective=None,\n        random_state=None, reg_alpha=7, reg_lambda=0.1, silent=True,\n        subsample=0.3542761367404292, subsample_for_bin=200000,\n        subsample_freq=0,scale_pos_weight = 2)\n\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n            eval_metric= 'auc', verbose= 100, early_stopping_rounds= 30,callbacks=[lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_0995)])\n\n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n        \n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        \n        del clf, train_x, train_y, valid_x, valid_y\n        gc.collect()\n        \n#     print (sub_preds)\n    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n    \n    folds_idx = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df[feats], train_df['TARGET'])]\n    display_roc_curve(y_=Y_train,oof_preds_=oof_preds,sub_preds_ = sub_preds, folds_idx_=folds_idx)\n    display_precision_recall(y_=Y_train, oof_preds_=oof_preds, folds_idx_=folds_idx)\n    \n    return feature_importance_df,sub_preds\n\ndef display_roc_curve(y_, oof_preds_,sub_preds_,folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6,6))\n    scores = [] \n    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = roc_auc_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n    \n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n    fpr, tpr, thresholds = roc_curve(y_, oof_preds_)\n    score = roc_auc_score(y_, oof_preds_)\n    plt.plot(fpr, tpr, color='b',\n             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n             lw=2, alpha=.8)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('LightGBM ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.tight_layout()\n    \n    plt.savefig('roc_curve.png')\n\ndef display_precision_recall(y_, oof_preds_, folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6,6))\n    \n    scores = [] \n    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = average_precision_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='AP fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n    \n    precision, recall, thresholds = precision_recall_curve(y_, oof_preds_)\n    score = average_precision_score(y_, oof_preds_)\n    plt.plot(precision, recall, color='b',\n             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n             lw=2, alpha=.8)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('LightGBM Recall / Precision')\n    plt.legend(loc=\"best\")\n    plt.tight_layout()\n    \n    \ndef compiler2(train_df,test_df,Y_train,debug = False):\n    num_rows = 10000 if debug else None\n    feat_importance,sub_preds = kfold_lightgbm(train_df,test_df,\n                                                Y_train, num_folds= 5, \n                                                stratified= True, debug= debug)\n    \n    return feat_importance,sub_preds\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importance,sub_preds = compiler2(train_dff,test_dff,Y_train,debug = False)\nresult = pd.DataFrame()\nresult['SK_ID_CURR'] = test_df['SK_ID_CURR'].values.tolist()\nresult['TARGET'] = sub_preds\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('submission_kernel_lightGBM.csv', index= False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coding: utf-8\n# pylint: disable = invalid-name, C0111\nimport lightgbm as lgb\nimport pandas as pd\n\nif lgb.compat.MATPLOTLIB_INSTALLED:\n    import matplotlib.pyplot as plt\nelse:\n    raise ImportError('You need to install matplotlib for plot_example.py.')\n\n# create dataset for lightgbm\n# X_train = X_train.drop('TARGET', axis = 1)\nX_train_, X_test_, Y_train_, Y_test_ = train_test_split(X_train, Y_train, test_size=0.1,random_state=42)\nlgb_train = lgb.Dataset(X_train_, Y_train_)\nlgb_test = lgb.Dataset(X_test_, Y_test_, reference=lgb_train)\n\n# specify your configurations as a dict\nparams = {'colsample_bytree': 0.48263575356020577, 'min_child_samples': 311, \n                  'min_child_weight': 1, 'num_leaves': 7, 'reg_alpha': 7, 'reg_lambda': 0.1, \n                  'subsample': 0.3542761367404292,  'metric': 'roc_auc'} \n\n\nprint('Starting training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=100,\n                valid_sets=[lgb_train, lgb_test],\n                feature_name=[X_train.columns.tolist()[i] for i in range(len(X_train.columns.tolist()))],\n                verbose_eval=10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = lgb.plot_tree(gbm, figsize=(30, 50))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}