{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import interp\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport math\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nimport imblearn\nfrom mpl_toolkits.mplot3d import Axes3D\nnp.random.seed(5)\nfrom sklearn import decomposition, datasets \nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import auc\nfrom sklearn import metrics\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import shuffle\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/preprocessed-home-credit/local_data_final.csv')\ntest_df = pd.read_csv('../input/preprocessed-home-credit/kaggle_test_final.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame()\nresult['SK_ID_CURR'] = test_df['SK_ID_CURR'].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = train_df.drop(columns = ['SK_ID_CURR', 'TARGET'], axis = 1)\nfeats = dff.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del train_df\n# del dff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1 = (train_df.drop('TARGET', axis = 1)).head(70000)\nY_train = train_df['TARGET'].head(70000)\nX_test1 = (test_df.drop('TARGET', axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del train_df\n# del test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Imputer\nimp = Imputer(strategy='mean').fit(X_train1)\nX_train = pd.DataFrame((imp.transform(X_train1)).tolist())\nX_test = pd.DataFrame((imp.transform(X_test1)).tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns = X_train1.columns\nX_test.columns = X_train1.columns\n\nX_train.shape\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del X_train1\n# del X_test1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(X_train, X_test):\n    X_train = X_train.drop('SK_ID_CURR',axis = 1)\n    X_test = X_test.drop('SK_ID_CURR', axis = 1)\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    print (scaler)\n    xtr = pd.DataFrame((scaler.transform(X_train)).tolist())\n#     xtr['TARGET'] = Y_train.values.tolist()\n\n    xte = pd.DataFrame((scaler.transform(X_test)).tolist())\n\n    # df_norm = shuffle(df_norm.values)\n    # df_norm = pd.DataFrame(df_norm.tolist())\n    return xtr, xte, ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_, X_test_ = normalize (X_train, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del X_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class count\ndf_train = X_train_\ndf_train['TARGET'] = Y_train.tolist()\ncount_class_0, count_class_1 = df_train.TARGET.value_counts()\n\n# Divide by class\ndf_class_0 = df_train[df_train['TARGET'] == 0]\ndf_class_1 = df_train[df_train['TARGET'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class_0_under = df_class_0.sample(count_class_1)\ndf_undersampled = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nprint('Random under-sampling:')\nprint(df_undersampled.TARGET.value_counts())\n\ndf_undersampled.TARGET.value_counts().plot(kind='bar', title='Count (target)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_undersampled_xtr = df_undersampled.drop('TARGET', axis = 1)\ndf_undersampled_ytr = df_undersampled['TARGET']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del df_undersampled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## feature selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cor_selector(X, y,ft):\n    cor_list = []\n    # calculate the correlation with y for each feature\n    for i in X.columns.tolist():\n        cor = np.corrcoef(X[i], y)[0, 1]\n        cor_list.append(abs(cor))\n#     print (len(cor_list))\n    # replace NaN with 0\n    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n#     print (cor_list)\n    # feature name\n    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[::-1][:ft]].columns.tolist()\n#     print(cor_feature)\n    # feature selection? 0 for not select, 1 for select\n    cor_support = [True if i in cor_feature else False for i in cor_feature]\n#     print (cor_support)\n    return cor_support, cor_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cross_validation(feats, df_undersampled_xtr, df_undersampled_ytr, X_test, ft, n, classifier):\n    print(__doc__)\n\n    x = df_undersampled_xtr\n    y = df_undersampled_ytr\n    cor_support, cor_feature = cor_selector(x,y,ft)\n#     print(cor_support, cor_feature)\n    n_samples, n_features = x[cor_feature].shape\n\n    # Classification and ROC analysis\n\n    # Run classifier with cross-validation and plot ROC curves\n    df_corr = df_undersampled_xtr[cor_feature]\n    df_corr['TARGET'] = df_undersampled_ytr.values.tolist()\n    \n    fts = []\n    for i in cor_feature:\n        fts.append(feats[i])\n        \n    X_tr = df_corr.drop('TARGET',axis = 1)\n    Y_tr = df_corr['TARGET']\n    \n#     print(cor_feature)\n#     print (X_tr.columns)\n#     print(fts)\n    \n    cv = StratifiedKFold(n_splits=n)\n    tprs = []\n    aucs = []\n    mean_fpr = np.linspace(0, 1, 100)\n    X_tr.columns = df_undersampled_xtr[cor_feature].columns\n    \n    \n    i = 0\n    feature_importance_df = pd.DataFrame()\n    for train, test in cv.split(X_tr, y):\n        probas_ = classifier.fit(X_tr.values[train], Y_tr.values[train]).predict_proba(X_tr.values[test])\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = fts\n        f1 = (classifier.coef_)[0].tolist()\n        f = [abs(f) for f in f1]\n        max_f = np.array(f).max()\n        fold_importance_df[\"importance\"] = [(100.0 * (x / max_f)) for x in f]\n        fold_importance_df[\"fold\"] = n + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n        # Compute ROC curve and area the curve\n        fpr, tpr, thresholds = roc_curve(Y_tr.values[test], probas_[:, 1])\n        tprs.append(interp(mean_fpr, fpr, tpr))\n        tprs[-1][0] = 0.0\n        roc_auc = auc(fpr, tpr)\n        aucs.append(roc_auc)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n        i += 1\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n             label='Chance', alpha=.8)\n\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    std_auc = np.std(aucs)\n\n    plt.plot(mean_fpr, mean_tpr, color='b',\n             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n             lw=2, alpha=.8)\n\n    std_tpr = np.std(tprs, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                     label=r'$\\pm$ 1 std. dev.')\n\n    Y_score = classifier.predict_proba(X_test[cor_feature].values)\n\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic curve')\n    plt.legend(loc=\"lower right\")\n    \n    plt.show()\n    \n    return cor_feature, feature_importance_df, Y_score[:,1].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cor_feature, feat_imp, pred  = cross_validation(feats, df_undersampled_xtr, df_undersampled_ytr, \n                                                                              X_test_, 301, 5, \n                                          classifier =  LogisticRegression(penalty='l2', dual=False, \n                                                                           tol=0.0001, C=1e40, fit_intercept=True, \n                                                                           intercept_scaling=1, class_weight='balanced', \n                                                                           random_state=None, solver='warn', \n                                                                           max_iter=100, multi_class='warn', \n                                                                           verbose=0, warm_start=False, \n                                                                           n_jobs=None))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['TARGET'] = pred\n# result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('submission_logistic_reg.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display/plot feature importance\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", \n                                                                                                   ascending=False)[:30].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 8))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('Logistic Rgression \\nFeatures (avg over folds)')\n    plt.tight_layout()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_importances(feat_imp)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}