{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import interp\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport math\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nimport imblearn\nfrom mpl_toolkits.mplot3d import Axes3D\nnp.random.seed(5)\nfrom sklearn import decomposition, datasets \nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import auc\nfrom sklearn import metrics\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import shuffle\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/preprocessed-home-credit/local_data_final.csv')\ntest_df = pd.read_csv('../input/preprocessed-home-credit/kaggle_test_final.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame()\nresult['SK_ID_CURR'] = test_df['SK_ID_CURR'].values.tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1 = (train_df.drop('TARGET', axis = 1)).head(100000)\nY_train = train_df['TARGET'].head(100000)\nX_test1 = (test_df.drop('TARGET', axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_df\ndel test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Imputer\nimp = Imputer(strategy='mean').fit(X_train1)\nX_train = pd.DataFrame((imp.transform(X_train1)).tolist())\nX_test = pd.DataFrame((imp.transform(X_test1)).tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns = X_train1.columns\nX_test.columns = X_train1.columns\n\nX_train.shape\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_train1\ndel X_test1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(X_train, X_test):\n    X_train = X_train.drop('SK_ID_CURR',axis = 1)\n    X_test = X_test.drop('SK_ID_CURR', axis = 1)\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    print (scaler)\n    xtr = pd.DataFrame((scaler.transform(X_train)).tolist())\n#     xtr['TARGET'] = Y_train.values.tolist()\n\n    xte = pd.DataFrame((scaler.transform(X_test)).tolist())\n\n    # df_norm = shuffle(df_norm.values)\n    # df_norm = pd.DataFrame(df_norm.tolist())\n    return xtr, xte, ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_, X_test_ = normalize (X_train, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del X_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class count\ndf_train = X_train_\ndf_train['TARGET'] = Y_train.tolist()\ncount_class_0, count_class_1 = df_train.TARGET.value_counts()\n\n# Divide by class\ndf_class_0 = df_train[df_train['TARGET'] == 0]\ndf_class_1 = df_train[df_train['TARGET'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class_0_under = df_class_0.sample(count_class_1)\ndf_undersampled = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nprint('Random under-sampling:')\nprint(df_undersampled.TARGET.value_counts())\n\ndf_undersampled.TARGET.value_counts().plot(kind='bar', title='Count (target)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_undersampled_xtr = df_undersampled.drop('TARGET', axis = 1)\ndf_undersampled_ytr = df_undersampled['TARGET']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_undersampled_xtr = df_undersampled.drop('TARGET', axis = 1)\ndf_undersampled_ytr = df_undersampled['TARGET']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_undersampled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cross_validation(df_undersampled_xtr, df_undersampled_ytr, X_test, n, classifier):\n    print(__doc__)\n\n    X_tr = df_undersampled_xtr\n    Y_tr = df_undersampled_ytr\n\n    cv = StratifiedKFold(n_splits=n)\n    tprs = []\n    aucs = []\n    mean_fpr = np.linspace(0, 1, 100)\n\n    i = 0\n    for train, test in cv.split(X_tr, Y_tr):\n        probas_ = classifier.fit(X_tr.values[train], Y_tr.values[train]).predict_proba(X_tr.values[test])\n        # Compute ROC curve and area the curve\n        fpr, tpr, thresholds = roc_curve(Y_tr.values[test], probas_[:, 1])\n        tprs.append(interp(mean_fpr, fpr, tpr))\n        tprs[-1][0] = 0.0\n        roc_auc = auc(fpr, tpr)\n        aucs.append(roc_auc)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n        i += 1\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n             label='Chance', alpha=.8)\n\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    std_auc = np.std(aucs)\n\n    plt.plot(mean_fpr, mean_tpr, color='b',\n             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n             lw=2, alpha=.8)\n\n    std_tpr = np.std(tprs, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                     label=r'$\\pm$ 1 std. dev.')\n\n    Y_score = classifier.predict_proba(X_test.values)\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic curve')\n    plt.legend(loc=\"lower right\")\n    \n    plt.show()\n\n    return Y_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lda = LDA(n_components=1)\nX_lda = lda.fit_transform(df_undersampled_xtr, df_undersampled_ytr)\nX_te = lda.transform(X_test_)\nY_score = cross_validation(pd.DataFrame(X_lda.tolist()), \n                                                           pd.DataFrame(df_undersampled_ytr.tolist()), \n                                                           pd.DataFrame(X_te.tolist()), 5, \n                                      LogisticRegression(penalty='l2', dual=False, \n                                                                       tol=0.0001, C=1.0, fit_intercept=True, \n                                                                       intercept_scaling=1, class_weight=None, \n                                                                       random_state=None, solver='sag', \n                                                                       max_iter=100, multi_class='auto', \n                                                                       verbose=0, warm_start=False, \n                                                                       n_jobs=None))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result['TARGET'] = Y_score[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('submission_logistic_reg_LDA.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}