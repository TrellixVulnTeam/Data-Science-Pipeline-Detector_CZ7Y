{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A faire :\n\n- afficher la matrice de confusion directement en sortie de pipeline ?\n\n- tester un SVM avec kernel linéaire puis gaussien('rbf')/!\\ celui par défaut est le rbf (SVC.decision_function)\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_colwidth', 200, 'display.max_rows', None, 'display.max_columns', None)\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import plot_confusion_matrix, fbeta_score, make_scorer, accuracy_score\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn import set_config\nset_config(display='diagram')\nprint('Imports terminés.')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:47:20.966597Z","iopub.execute_input":"2021-06-10T12:47:20.967235Z","iopub.status.idle":"2021-06-10T12:47:23.529347Z","shell.execute_reply.started":"2021-06-10T12:47:20.967105Z","shell.execute_reply":"2021-06-10T12:47:23.528472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PROJET 4 - CONSTRUISEZ UN MODELE DE SCORING","metadata":{}},{"cell_type":"markdown","source":"La société financière \"Prêt à dépenser\" souhaite pouvoir utiliser un modèle de scoring l'aidant à prédire le risque de défaut de paiement d'un client ayant peu ou pas d'historique de prêt.  \nLe modèle devra permettre aux conseillers qui l'utilisent de comprendre les motifs de l'acceptation ou du rejet de la demande de prêt.  ","metadata":{}},{"cell_type":"markdown","source":"## 1. Exploration des données","metadata":{}},{"cell_type":"markdown","source":"Les données sont réparties en plusieurs fichiers.","metadata":{}},{"cell_type":"markdown","source":"Le tableau HomeCredit_columns_description propose le descriptif de chaque colonne dans chaque fichier. Commençons par créer une fonction qui permet de consulter ce descriptif pour une table donnée, ainsi qu'une fonction qui permet d'avoir un aperçu général d'une table donnée.","metadata":{}},{"cell_type":"code","source":"dirpath = '../input/home-credit-default-risk/'\ncolumns_description = pd.read_csv(dirpath + 'HomeCredit_columns_description.csv')\n\ndef describe_sheet(sheet_name):\n    '''Display content of HomeCredit_columns_description for sheet_name table.'''\n    if 'application' in sheet_name:\n        sheet_name = dirpath + 'application_{train|test}'\n    description = columns_description[columns_description['Table'].str.contains(sheet_name)].iloc[:,2:]\n    description = description.set_index('Row')\n    return description\n        \n\ndef overview(df_name):\n    '''Display information, result of describe, shape and head for given df_name.'''\n    df = globals()[df_name]\n    print('\\n\\n' + '#'*60)\n    print(f'Table {df_name}')\n    print('#'*60)\n    print(f'\\n\\nLa table {df_name} a {df.shape[0]:,.0f} lignes et {df.shape[1]:.0f} colonnes.'.replace(',', ' '))\n    print(f'\\n\\nDescription de la table :\\n')\n    display(describe_sheet(df_name))\n    print('\\n\\nPrincipales statistiques :\\n')\n    display(df.describe(include='all'))\n    print(f'\\n\\nPremières lignes :\\n')\n    display(df.head())\n    ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:47:23.531127Z","iopub.execute_input":"2021-06-10T12:47:23.531736Z","iopub.status.idle":"2021-06-10T12:47:23.559765Z","shell.execute_reply.started":"2021-06-10T12:47:23.531698Z","shell.execute_reply":"2021-06-10T12:47:23.558413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Quel(s) fichier(s) utiliser ?","metadata":{}},{"cell_type":"markdown","source":"Sur les 9 fichiers fournis (hors celui détaillant les informations contenues dans les autres) :\n\n- **application_train.csv** contient des données relatives à l'emprunteur lui-même, et concernant son crédit, au sort de celui-ci (mis en défaut de paiement ou non). Puisque le modèle est destiné à évaluer le risque de défaut d'emprunteurs n'ayant pas d'historique de crédit, il est bien sûr à utiliser.\n\n- **application_test.csv** ne nous sera pas utile dans le présent cas, car il ne comporte pas d'étiquettes relatives au sort du prêt (défaut ou pas). On ne l'utilisera donc pas.\n\n- **POS_CASH_balance.csv** : ce fichier est relatif au prêt en cours et au prêt précédent. Les données ne seront donc pas disponibles pour un nouvel emprunteur : il n'est donc pas utile pour l'entraînement du modèle.\n\n- **bureau.csv** : contient des informations sur le prêt en cours, donc là encore, inutile vu notre objectif.\n\n- **bureau_balance.csv** : La description précise \"use this to join to CREDIT_BUREAU table\", qui n'apparaît pas dans la liste. On prendra donc l'hypothèse qu'il faut la joindre avec la table bureau. Cette dernière n'étant pas utilisée, la présente table ne sera pas non plus utile.\n\n- **credit_card_balance** : se réfère au prêt en cours et au prêt précédent, donc inutile\n\n- **installment_payments** : idem\n\n- **previous_application_csv**: idem \n\n- **sample_submission.csv** : la signification de ce ficher n'est pas évidente puisque toutes les valeurs TARGET sont à 0.5. Faute d'information sur son utilité, il ne sera pas utilisé.\n\nAu final, seules les données contenues dans application_train.csv seront utilisées pour l'entraînement du modèle.","metadata":{}},{"cell_type":"code","source":"application_train = pd.read_csv(dirpath + 'application_train.csv')\n\noverview('application_train')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:47:23.561352Z","iopub.execute_input":"2021-06-10T12:47:23.561967Z","iopub.status.idle":"2021-06-10T12:47:32.917654Z","shell.execute_reply.started":"2021-06-10T12:47:23.561927Z","shell.execute_reply":"2021-06-10T12:47:32.916744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Nettoyage des données","metadata":{}},{"cell_type":"markdown","source":"Afin d'optimiser le pipeline qui sera utilisé plus tard, les étapes successives de nettoyage des données vont être regroupées dans deux fonctions qui seront enrichies au fur et à mesure de l'avancement du traitement :\n\n- une fonction destinée à supprimer les variables éventuellement redondantes et à créer de nouvelles variables synthétiques\n\n- une fonction destinée à traiter les valeurs manquantes ou aberrantes.","metadata":{}},{"cell_type":"markdown","source":"En première approche, nous allons commencer par entraîner un modèle de classification simple de type arbre de décision, sur les données simplement nettoyées des valeurs vides ou aberrantes. On ne modifiera donc pas les variables elles-mêmes dans cette étape. Puis, après examen des premiers résulats, nous affinerons notre démarche en supprimant / créant des variables si nécessaire. C'est donc la fonction de traitement des valeurs manquantes / aberrantes qui va être créée en premier lieu.","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Recherche des anomalies de valeurs numériques","metadata":{}},{"cell_type":"markdown","source":"Etudions les distributions pour les variables numériques.","metadata":{}},{"cell_type":"code","source":"data = application_train.copy()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:47:32.918903Z","iopub.execute_input":"2021-06-10T12:47:32.919429Z","iopub.status.idle":"2021-06-10T12:47:33.034314Z","shell.execute_reply.started":"2021-06-10T12:47:32.919373Z","shell.execute_reply":"2021-06-10T12:47:33.033395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist_data(df):\n    num_cols = [col for col in df.columns if data[col].dtype != 'object'] \n        \n    height = int(np.ceil(len(num_cols)/6))\n    fig_height = 3 * height\n    fig = plt.figure(figsize=(20,fig_height))\n    \n    for feat_idx, col in enumerate(num_cols):\n        ax = fig.add_subplot(height, 6, feat_idx+1)\n        ax.hist(df[col], bins=50)\n        ax.set_title(col)\n    fig.tight_layout(pad=4)  ","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:47:33.037052Z","iopub.execute_input":"2021-06-10T12:47:33.037659Z","iopub.status.idle":"2021-06-10T12:47:33.044505Z","shell.execute_reply.started":"2021-06-10T12:47:33.037587Z","shell.execute_reply":"2021-06-10T12:47:33.043249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_box_data(df):\n    num_cols = [col for col in df.columns if data[col].dtype != 'object'] \n    \n    height = int(np.ceil(len(num_cols)/6))\n    fig_height = 3 * height\n    fig = plt.figure(figsize=(20,fig_height))\n    \n    for feat_idx, col in enumerate(num_cols):\n        ax = fig.add_subplot(height, 6, feat_idx+1)\n        ax.boxplot(df[col])\n        ax.set_title(col)\n    fig.tight_layout(pad=4)  ","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:47:33.048094Z","iopub.execute_input":"2021-06-10T12:47:33.048743Z","iopub.status.idle":"2021-06-10T12:47:33.061137Z","shell.execute_reply.started":"2021-06-10T12:47:33.048692Z","shell.execute_reply":"2021-06-10T12:47:33.060267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist_data(data)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:47:33.062835Z","iopub.execute_input":"2021-06-10T12:47:33.0636Z","iopub.status.idle":"2021-06-10T12:47:58.752517Z","shell.execute_reply.started":"2021-06-10T12:47:33.063551Z","shell.execute_reply":"2021-06-10T12:47:58.75091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_box_data(data)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:47:58.75435Z","iopub.execute_input":"2021-06-10T12:47:58.754789Z","iopub.status.idle":"2021-06-10T12:48:12.774036Z","shell.execute_reply.started":"2021-06-10T12:47:58.754742Z","shell.execute_reply":"2021-06-10T12:48:12.772617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### AMT_INCOME_TOTAL\nOn observe des valeurs irréalistes :","metadata":{}},{"cell_type":"code","source":"px.box(data['AMT_INCOME_TOTAL'])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:48:12.77565Z","iopub.execute_input":"2021-06-10T12:48:12.775985Z","iopub.status.idle":"2021-06-10T12:48:17.562233Z","shell.execute_reply.started":"2021-06-10T12:48:12.775951Z","shell.execute_reply":"2021-06-10T12:48:17.55937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pour écarter les valeurs aberrantes, on utilisera le Z-score, c'est-à-dire la distance à la moyenne divisée par l'écart-type.  \n\nSi Z-score > 3, la valeur peut être considérée comme un outlier puisqu'elle ne fait pas partie des 99,7% valeurs les plus proches de la moyenne.\n\nRemarquons toutefois qu'en valeur absolue, le nombre de cas potentiellement écartés n'est pas négligeable :","metadata":{}},{"cell_type":"code","source":"def z_score(array, threshold=3):\n    '''Return an array of boolean, True for each value in the array where Z-score >threshold.'''\n    mean = array.mean()\n    std = array.std()\n    return abs((array-mean))/std > threshold","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:17.564847Z","iopub.execute_input":"2021-06-10T12:48:17.565397Z","iopub.status.idle":"2021-06-10T12:48:17.577055Z","shell.execute_reply.started":"2021-06-10T12:48:17.565346Z","shell.execute_reply":"2021-06-10T12:48:17.575823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_outliers = data[z_score(data['AMT_INCOME_TOTAL'])].shape[0]\npc_outliers = nb_outliers / data.shape[0]\nprint(f'Concernant la variable AMT_INCOME_TOTAL, on retrouve {nb_outliers} outliers \\\nqui représentent {pc_outliers:.2%} des cas.')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:17.578529Z","iopub.execute_input":"2021-06-10T12:48:17.578857Z","iopub.status.idle":"2021-06-10T12:48:17.602952Z","shell.execute_reply.started":"2021-06-10T12:48:17.578825Z","shell.execute_reply":"2021-06-10T12:48:17.601542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On risque donc de se priver d'outliers qui ne sont pas forcément des valeurs aberrantes, mais simplement hors norme, et qui pourraient obérer l'efficacité du modèle pour les très hauts revenus. Examinons les 10 plus gros revenus de la liste des emprunteurs :","metadata":{}},{"cell_type":"code","source":"data.sort_values(by='AMT_INCOME_TOTAL', ascending=False).head(10).style.format({'AMT_INCOME_TOTAL':'{:,.0f}'})","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:48:17.605207Z","iopub.execute_input":"2021-06-10T12:48:17.605738Z","iopub.status.idle":"2021-06-10T12:48:18.1479Z","shell.execute_reply.started":"2021-06-10T12:48:17.605698Z","shell.execute_reply":"2021-06-10T12:48:18.146325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mais le modèle que nous devons concevoir est fait pour être généraliste et s'appliquer aux cas 'normaux', au sens propre du terme. C'est donc en connaissance de cause que nous écarterons les données avec un Z-score supérieur à 3.  \n\nIl faudra garder à l'esprit que le modèle risque donc de ne pas donner de bons résultats sur les cas extrêmes (très hauts revenus notamment), des cas qui nécessiteront sans doute une approche manuelle, ou un autre modèle.","metadata":{}},{"cell_type":"markdown","source":"Les autres variables étant susceptibles d'être supprimées ou modifiées par la suite, on appliquera un traitement global avec le même seuil de Z-score à 3.","metadata":{}},{"cell_type":"markdown","source":"#### Données en nombre de jours\nConvertissons-les temporairement en années écoulées (divison par -365) pour faciliter la vérification : ","metadata":{}},{"cell_type":"code","source":"day_cols = [col for col in data.columns if \"DAYS_\" in col]\n(data[day_cols].describe().loc[['min', 'max']].transpose()/-365).style.format({'min':'{:,.2f}', 'max':'{:,.2f}'})","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:48:18.149419Z","iopub.execute_input":"2021-06-10T12:48:18.14976Z","iopub.status.idle":"2021-06-10T12:48:18.241247Z","shell.execute_reply.started":"2021-06-10T12:48:18.149725Z","shell.execute_reply":"2021-06-10T12:48:18.239795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le max de 1000 ans pour DAYS_EMPLOYED est visible sur l'histogramme (sous la valeur -365 000 environ) et correspond à un nombre non négligeable de lignes (on affiche cette fois-ci les valeurs d'origine, sans la division par -365):","metadata":{}},{"cell_type":"code","source":"(data[day_cols])[data['DAYS_EMPLOYED']>0].describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:18.24531Z","iopub.execute_input":"2021-06-10T12:48:18.245637Z","iopub.status.idle":"2021-06-10T12:48:18.296411Z","shell.execute_reply.started":"2021-06-10T12:48:18.245608Z","shell.execute_reply":"2021-06-10T12:48:18.294581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les valeurs sont toutes indentiques à 365 243 jours. Cette valeur aberrante et constante suggère un parti pris dans la saisie ou l'encodage, par exemple dans le cas où la durée dans l'emploi n'est pas connue ou parce que la zone n'est pas remplie.","metadata":{}},{"cell_type":"code","source":"days_count_pos = data['DAYS_EMPLOYED'][data['DAYS_EMPLOYED']>0].count()\nprint(f\"Nombre de lignes avec des valeurs aberrantes pour DAYS_EMPLOYED : {days_count_pos} soit {days_count_pos/data.shape[0]:.2%} du total\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:18.300621Z","iopub.execute_input":"2021-06-10T12:48:18.301039Z","iopub.status.idle":"2021-06-10T12:48:18.31228Z","shell.execute_reply.started":"2021-06-10T12:48:18.300998Z","shell.execute_reply":"2021-06-10T12:48:18.311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le nombre de cas concernés est trop important pour supprimer purement et simplement les lignes correspondantes. Nous allons prendre le parti de transformer ces valeurs en la valeur réaliste la plus proche, soit 0. Aux yeux d'un banquier, ne pas avoir d'emploi est à peu près équivalent à démarrer dans un poste le jour même de la demande de prêt.","metadata":{}},{"cell_type":"markdown","source":"Par ailleurs, des durées supérieures à l'âge seraient également aberrantes, vérifions si c'est le cas :","metadata":{"tags":[]}},{"cell_type":"code","source":"for col  in day_cols:\n    idx = data[data[col]<data['DAYS_BIRTH']].index\n    idx_exist = len(idx)\n    if idx_exist:\n        print(col, 'présente des valeurs aberrantes aux lignes :', list(idx))\n        for i in idx:\n            print(data.loc[i,[col, 'DAYS_BIRTH']])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:18.314338Z","iopub.execute_input":"2021-06-10T12:48:18.314745Z","iopub.status.idle":"2021-06-10T12:48:18.335597Z","shell.execute_reply.started":"2021-06-10T12:48:18.314713Z","shell.execute_reply":"2021-06-10T12:48:18.333478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mis à part cette erreur liée à un simple arrondi, les autres valeurs ne semblent pas aberrantes à cet égard.","metadata":{}},{"cell_type":"markdown","source":"On établit donc comme critères de valeur aberrantes :\n- les valeurs > 0 qui seront ramenées à 0\n- pour toutes les valeurs sauf DAYS_BIRTH, des valeurs inférieures à celle-ci (autrement dit des durées supérieures à l'âge), qui seront ramenées à la valeur de DAYS_BIRTH.\n\nOn pourrait aussi fixer des limites hautes et basse à DAYS_BIRTH, mais il est possible que la législation bancaire américaine permette les emprunts par des mineurs ou des personnes de plus de 70 ans : faute d'information, et les données présentes ne montrant pas d'aberration, on ne modifiera donc pas cette variable.","metadata":{}},{"cell_type":"code","source":"data[data['DAYS_EMPLOYED']>0].head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:18.339082Z","iopub.execute_input":"2021-06-10T12:48:18.34009Z","iopub.status.idle":"2021-06-10T12:48:18.51237Z","shell.execute_reply.started":"2021-06-10T12:48:18.340003Z","shell.execute_reply":"2021-06-10T12:48:18.510422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in day_cols:\n    data.loc[data[col]< data['DAYS_BIRTH'], col] = data['DAYS_BIRTH']\n    data.loc[data[col]>0, col] = 0","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:18.513818Z","iopub.execute_input":"2021-06-10T12:48:18.514118Z","iopub.status.idle":"2021-06-10T12:48:18.549868Z","shell.execute_reply.started":"2021-06-10T12:48:18.514089Z","shell.execute_reply":"2021-06-10T12:48:18.548155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[[8, 11, 23, 266366],day_cols]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:18.551248Z","iopub.execute_input":"2021-06-10T12:48:18.551584Z","iopub.status.idle":"2021-06-10T12:48:18.572428Z","shell.execute_reply.started":"2021-06-10T12:48:18.551553Z","shell.execute_reply":"2021-06-10T12:48:18.571189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Valeurs quantitatives ou qualitatives nulles ou manquantes","metadata":{}},{"cell_type":"markdown","source":"Examinons les valeurs pour les variables qualitatives :","metadata":{}},{"cell_type":"code","source":"for col in [col for col in data.columns if data[col].dtype == 'object']:\n    print(col,\":\", list(application_train[col].unique()))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:48:18.573873Z","iopub.execute_input":"2021-06-10T12:48:18.57431Z","iopub.status.idle":"2021-06-10T12:48:19.032946Z","shell.execute_reply.started":"2021-06-10T12:48:18.574246Z","shell.execute_reply":"2021-06-10T12:48:19.031003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les données correspondent à des historiques de prêt réellement accordés. Les éventuelles valeurs nulles constatées sont donc en principe \"réelles\" : soit parce qu'il s'agit de valeurs binaires (FLAGS), soit parce que l'information est effectivement égale à zéro (ex : montant du salaire) ou indisponible (valeur 'nan') dans le dossier. \n\nIl ne nous paraît pas possible dans ce dataset de procéder à une imputation, chaque dossier étant unique. Mais les modèles n'acceptant pas la valeur NaN, si une donnée n'est pas connue, elle sera considérée comme nulle ou vide (selon sa nature) lors de la normalisation.\n\nPrécisons que le choix de remplacer les valeurs quantitatives NaN à zéro peut se discuter. D'un point de vue métier, il se justifie pour la plupart des colonnes : un revenu non déclaré est considéré par le banquier comme un revenu nul, une ancienneté nulle dans l'emploi est équivalente à ses yeux à une absence d'emploi à l'instant T.  \n\nEn revanche, concernant la variable d'ancienneté du véhicule par exemple, le choix de mettre la variable NaN à zéro met à égalité l'emprunteur qui ne possède pas de voiture, et celui qui fait sa demande de prêt justement le jour où il vient de prendre possession d'un nouveau véhicule : ce qui correspond à des situations patrimoniales différentes. Toutefois, cette information est complétée par le booléen \"OWN_CAR_FLAG\", qui permet de faire la différence.","metadata":{}},{"cell_type":"markdown","source":"On complète `clean_values()` :","metadata":{}},{"cell_type":"code","source":"def clean_values(df):\n    print('Nettoyage des lignes...')\n    \n    old_length = df.shape[0]\n    result = df.copy()\n    num_cols = [col for col in result.columns if result[col].dtype!='object']\n    cat_cols = [col for col in result.columns if col not in num_cols]\n    \n    high_z_score = result[num_cols].apply(z_score, axis=0, args=[80])\n    result.drop(high_z_score[high_z_score.any(axis=1)].index, inplace=True)\n    \n    days_cols = [col for col in result.columns if \"DAYS_\" in col]\n    for col in day_cols:\n        result.loc[result[col]< result['DAYS_BIRTH'], col] = result['DAYS_BIRTH']\n        result.loc[result[col]>0, col] = 0\n        \n    result[num_cols]=result[num_cols].fillna(0)\n    result[cat_cols]=result[cat_cols].fillna('Not specified')\n    \n    new_length = result.shape[0]\n    deleted_rows = old_length - new_length\n    print(f'{deleted_rows} lignes ont été supprimées soit {deleted_rows/old_length:.2%} du total.')\n  \n    return result","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:19.034647Z","iopub.execute_input":"2021-06-10T12:48:19.03502Z","iopub.status.idle":"2021-06-10T12:48:19.046609Z","shell.execute_reply.started":"2021-06-10T12:48:19.034988Z","shell.execute_reply":"2021-06-10T12:48:19.04482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Premier essai d'entraînement","metadata":{}},{"cell_type":"markdown","source":"Dans un premier temps, on supprime les valeurs aberrantes, sans modifier les variables existantes :","metadata":{}},{"cell_type":"code","source":"data = clean_values(application_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:19.048182Z","iopub.execute_input":"2021-06-10T12:48:19.048649Z","iopub.status.idle":"2021-06-10T12:48:21.619669Z","shell.execute_reply.started":"2021-06-10T12:48:19.048605Z","shell.execute_reply":"2021-06-10T12:48:21.6176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Préalable : extraction des variables et des données cible","metadata":{}},{"cell_type":"code","source":"features_cols = [col for col in data.columns if col not in ['TARGET', 'SK_ID_CURR']]\nX = data[features_cols]\ny = data['TARGET']\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:21.621017Z","iopub.execute_input":"2021-06-10T12:48:21.621355Z","iopub.status.idle":"2021-06-10T12:48:21.746849Z","shell.execute_reply.started":"2021-06-10T12:48:21.621306Z","shell.execute_reply":"2021-06-10T12:48:21.745543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1 Choix de la métrique","metadata":{}},{"cell_type":"markdown","source":"Nous cherchons à établir un modèle de classification binaire. Le résultat peut donc être positif (cas du client qui est en défaut de paiement) ou négatif (le client rembourse normalement).\n\nUn faux positif est un emprunteur qui serait à tort estimé comme présentant un risque de défaut.  \nUn faux négatif est un emprunteur qui serait estimé à tort comme ne présentant pas de risque de défaut.\n\nL'objectif de l'établissement bancaire est de détecter le plus possible des cas positifs (sensibilité élevée), et aussi de minimiser le taux de faux négatifs : en effet, cela voudrait dire qu'elle accorde un prêt à un client qui ne le remboursera pas. \n\nPour autant, le taux de faux positifs n'est pas à négliger non plus car il représente pour un établissement une perte d'opportunité, en la personne d'un emprunteur qui aurait été solvable et auquel il aurait été possible de vendre d'autres produits et services.\n\nLe taux de faux positifs est estimé par la précision (nombre total de vrais positifs divisé par le nombre total de positifs prédits). Le taux de faux négatifs est estimé par 1 - recall (le recall, ou sensibilité, étant égal au nombre de vrais positifs rapporté au nombre total de cas positifs).\n\nL'optimisation entre la précision et le recall est donnée par la la maximisation du **F1-score**. Il s'agit de la moyenne harmonique de ces deux valeurs. Toutefois ce score attribue le même poids à ces derniers. Or nous souhaitons quant à nous privilégier la limitation des faux négatifs.\n\nOn utilisera donc le **F2-score** (c'est-à-dire un F-beta avec un Beta égal à 2), qui surpondère les faux négatifs ([source](https://machinelearningmastery.com/fbeta-measure-for-machine-learning/)).","metadata":{}},{"cell_type":"markdown","source":"### 3.2 Base de comparaison : classifieur naïf","metadata":{}},{"cell_type":"markdown","source":"On établit un dummy classifier qui servira de point de comparaison pour évaluer l'efficacité du modèle. Pour le choix du type de dummy classifier, vérifions la répartition des classes dans les données :","metadata":{"tags":[]}},{"cell_type":"code","source":"sum(y)/len(y)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:21.748602Z","iopub.execute_input":"2021-06-10T12:48:21.749218Z","iopub.status.idle":"2021-06-10T12:48:21.79575Z","shell.execute_reply.started":"2021-06-10T12:48:21.749171Z","shell.execute_reply":"2021-06-10T12:48:21.794725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comme on pouvait s'y attendre, les cas de défaut sont très minoritaires (8,6%). Un modèle qui prédirait systématiquement la classe négative (pas de défaut de paiement, l'emprunteur paie normalement) aura donc une accuracy de 91,4%.\n\nOn choisit un Dummy Classifier qui renvoie des prédictions avec la même distribution que le jeu d'entraînement, afin d'avoir la même sensibilité (taux de vrais positifs) et la même spécificité (taux de vrais négatifs).","metadata":{}},{"cell_type":"code","source":"dum = DummyClassifier(strategy='stratified')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:21.797278Z","iopub.execute_input":"2021-06-10T12:48:21.797636Z","iopub.status.idle":"2021-06-10T12:48:21.805619Z","shell.execute_reply.started":"2021-06-10T12:48:21.797604Z","shell.execute_reply":"2021-06-10T12:48:21.804434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = dum.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:21.806749Z","iopub.execute_input":"2021-06-10T12:48:21.807089Z","iopub.status.idle":"2021-06-10T12:48:21.830715Z","shell.execute_reply.started":"2021-06-10T12:48:21.807029Z","shell.execute_reply":"2021-06-10T12:48:21.828947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"L'accuracy de ce classifieur est de :","metadata":{}},{"cell_type":"code","source":"acc_dum = dum.score(X, y)\nacc_dum","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:21.832261Z","iopub.execute_input":"2021-06-10T12:48:21.832606Z","iopub.status.idle":"2021-06-10T12:48:21.873579Z","shell.execute_reply.started":"2021-06-10T12:48:21.832567Z","shell.execute_reply":"2021-06-10T12:48:21.872472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Et son F2 score est de :","metadata":{}},{"cell_type":"code","source":"y_pred_dum = dum.predict(X)\nf2_dum = fbeta_score(y, y_pred_dum, beta=2)\nf2_dum","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:21.875135Z","iopub.execute_input":"2021-06-10T12:48:21.875449Z","iopub.status.idle":"2021-06-10T12:48:21.993236Z","shell.execute_reply.started":"2021-06-10T12:48:21.875421Z","shell.execute_reply":"2021-06-10T12:48:21.99204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notre modèle doit donc surperformer ce classifieur naïf.","metadata":{}},{"cell_type":"markdown","source":"Construisons un tableau récapitulatif pour suivre l'évolution des scores selon les progrès de la modélisation.","metadata":{}},{"cell_type":"code","source":"recap = pd.DataFrame(columns=['accuracy', 'F2-score'])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:21.994572Z","iopub.execute_input":"2021-06-10T12:48:21.994871Z","iopub.status.idle":"2021-06-10T12:48:22.004969Z","shell.execute_reply.started":"2021-06-10T12:48:21.994843Z","shell.execute_reply":"2021-06-10T12:48:22.002701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_recap(index, acc, f2, recap=recap):\n    '''Add line to recap ith acuracy and f2 score.'''\n    if index not in recap.index:\n        recap.loc[index] = [acc, f2]\n    return recap.style.format('{:.2%}')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:22.006399Z","iopub.execute_input":"2021-06-10T12:48:22.006713Z","iopub.status.idle":"2021-06-10T12:48:22.020302Z","shell.execute_reply.started":"2021-06-10T12:48:22.006684Z","shell.execute_reply":"2021-06-10T12:48:22.01896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"update_recap('dummy', acc_dum, f2_dum)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:22.021759Z","iopub.execute_input":"2021-06-10T12:48:22.022074Z","iopub.status.idle":"2021-06-10T12:48:22.039717Z","shell.execute_reply.started":"2021-06-10T12:48:22.022044Z","shell.execute_reply":"2021-06-10T12:48:22.038371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Standardisation et encodage des valeurs","metadata":{}},{"cell_type":"markdown","source":"La transformation des données présente deux contraintes :  \n* d'une part, les données sont de nature différente (quantitative ou qualitative), et parmi les données quantitatives, certaines sont déjà normalisées ou binaires, elles nécessitent donc des traitements différents (standardisation - ou pas - ou encodage);  \n* d'autre part, la déséquilibre des classes rend d'autant plus nécessaire la séparation des jeux de test, et le recours à un stratified k-fold. Or, pour éviter toute fuite d'information, la séparation des jeux de données doit être effectuée avant la normalisation.\n    \nLe recours à un pipeline va permettre d'effectuer la normalisation après chaque stratification.","metadata":{}},{"cell_type":"markdown","source":"La standardisation sera réalisée avec StandardScaler, l'encodage par One Hot Encoder.","metadata":{}},{"cell_type":"code","source":"num_cols = [col for col in X.columns if data[col].dtype != 'object']\ncat_cols = [col for col in X.columns if col not in num_cols]\n\ntransformer = make_column_transformer(\n    (StandardScaler(), num_cols),\n    (OneHotEncoder(), cat_cols)\n    )","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:48:22.048348Z","iopub.execute_input":"2021-06-10T12:48:22.048699Z","iopub.status.idle":"2021-06-10T12:48:22.060697Z","shell.execute_reply.started":"2021-06-10T12:48:22.048671Z","shell.execute_reply":"2021-06-10T12:48:22.058927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On vérifie que le transformer produit le résultat attendu (sans modifier X) :","metadata":{}},{"cell_type":"code","source":"result = transformer.fit_transform(X)\ntransformed_cols = num_cols + list(transformer.named_transformers_['onehotencoder'].get_feature_names())\ndf_result = pd.DataFrame(result, columns=transformed_cols)\nprint(df_result.shape)\ndf_result.describe()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:48:22.062339Z","iopub.execute_input":"2021-06-10T12:48:22.062659Z","iopub.status.idle":"2021-06-10T12:48:37.847813Z","shell.execute_reply.started":"2021-06-10T12:48:22.062629Z","shell.execute_reply":"2021-06-10T12:48:37.84666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les données sont prêtes à être fournies au pipeline du modèle. ","metadata":{}},{"cell_type":"markdown","source":"### 3.4 Entraînement","metadata":{}},{"cell_type":"markdown","source":"Pour pouvoir utiliser une stratégie d'optimisation KStratifiedDFolds, on utilisera la fonction GridSearchCV de sckit-learn. Elle permet :\n-  d'éviter une fuite d'information entre jeux d'entraînement et de test, en les séparant avant normalisation\n- d'entraîner le modèle, pour pouvoir ensuite examiner les résultats (là où une simple cross_validation ne ferait que donner les scores pour chaque kfold).\n\nDe plus, elle sera également applicable pour la sélection des hyperparamètres (qui est sa fonction première). Enfin, elle permet la parallélisation.","metadata":{}},{"cell_type":"markdown","source":"Commençons avec un DecisionTreeClassifier avec les données simplement nettoyées des valeurs aberrantes, et avec les hypermaramètres par défaut :","metadata":{}},{"cell_type":"code","source":"pipeline = make_pipeline(transformer, DecisionTreeClassifier())\nparams = {'decisiontreeclassifier__max_depth': [None]}\n\nftwo_scorer = make_scorer(fbeta_score, beta=2)\naccuracy_scorer = make_scorer(accuracy_score)\n\ngrid_dtc = GridSearchCV(\n    pipeline, \n    param_grid=params, \n    cv=5, \n    scoring={'acc': accuracy_scorer, 'ftwo': ftwo_scorer},\n    refit='ftwo', \n    verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:48:37.849185Z","iopub.execute_input":"2021-06-10T12:48:37.84953Z","iopub.status.idle":"2021-06-10T12:48:37.857957Z","shell.execute_reply.started":"2021-06-10T12:48:37.8495Z","shell.execute_reply":"2021-06-10T12:48:37.85637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = grid_dtc.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:51:43.454149Z","iopub.execute_input":"2021-06-10T12:51:43.454796Z","iopub.status.idle":"2021-06-10T12:55:49.06513Z","shell.execute_reply.started":"2021-06-10T12:51:43.454712Z","shell.execute_reply":"2021-06-10T12:55:49.063602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimator = grid_dtc.best_estimator_\n_ = best_estimator.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:56:38.271212Z","iopub.execute_input":"2021-06-10T12:56:38.271611Z","iopub.status.idle":"2021-06-10T12:57:27.311248Z","shell.execute_reply.started":"2021-06-10T12:56:38.271578Z","shell.execute_reply":"2021-06-10T12:57:27.310311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,16)) \n_=plot_tree(best_estimator.named_steps['decisiontreeclassifier'], \n            max_depth=4, feature_names=transformed_cols, \n            proportion=True, filled=True, fontsize=8)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:55:49.094329Z","iopub.status.idle":"2021-06-10T12:55:49.094861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On remarque que ce sont les éléments 'EXT_SOURCE' qui semblent les plus significatifs. Mais les résultats, bien que meilleurs que ceux du classifieur naïf, ne sont pas bons pour autant.","metadata":{}},{"cell_type":"code","source":"update_recap('dtc basique', grid_dtc.cv_results_['mean_test_acc'][0], grid_dtc.cv_results_['mean_test_ftwo'][0])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:57:27.31334Z","iopub.execute_input":"2021-06-10T12:57:27.313775Z","iopub.status.idle":"2021-06-10T12:57:27.327171Z","shell.execute_reply.started":"2021-06-10T12:57:27.313731Z","shell.execute_reply":"2021-06-10T12:57:27.325574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Amélioration du modèle","metadata":{}},{"cell_type":"markdown","source":"- modification des variables\n- modification des hyperparamètres\n- changement de modèle","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Amélioration des variables","metadata":{}},{"cell_type":"markdown","source":"Quelques constats préliminaires :\n\n- le revenu ne peut être que d'une seule catégorie, alors qu'il est tout à fait possible d'avoir à la fois un salaire et des revenus immobiliers par exemple.\n- la variable FLAG_WORK_PHONE est indiquée comme correspondant à l'existence du numéro de téléphone du domicile dans le dossier, alors que le nom est plus évocateur d'un numéro professionnel, d'autant qu'il existe aussi la variable FLAG_PHONE pour le domicile.\n- il existe deux variables liées au numéro professionnel : FLAG_WORK_PHONE et FLAG_EMP_PHONE. Peut-être sont-elles différenciées pour traiter séparément les cas d'un entrepreneur indépendant / profession libérale et les cas de salariés, ou pour différencier la ligne directe professionnelle de celle de l'établissement, mais cela semble une lourdeur inutile.\n- la variable FLAG_MOBIL doublonne avec FLAG_CONT_MOBIL : l'important n'est pas d'avoir donné un numéro mais qu'il soit effectivement joignable.\n- Les variables EXT_SOURCE et FLAG_DOCUMENT ne permettent pas de vérifier que les sources et documents en question sont toujours fournis dans l'ordre attendu. Il conviendrait de vérifier ce point auprès de l'établissement bancaire. Si celui-ci n'est pas en mesure de certifier que c'est bien le cas, ces variables pourraient très certainement être regroupées.\n- bien que la magie de la Data Science soit justement de faire ressortir des corrélations cachées, on ne peut s'empêcher de se demander dans quelle mesure la nature des matériaux de construction, le nombre d'entrées ou d'étages du logement de l'emprunteur, pourraient conditionner sa capacité à rembourser le prêt.\n- les données relatives au cercle relationnel du client donnent à penser qu'il est licite et courant de demander ce type d'information aux USA, alors qu'en France cela constituerait une infraction à la fois au secret bancaire et au RGPD. Ce qui pose au passage la question de l'exportabilité d'un modèle de ML d'un pays à l'autre.","metadata":{}},{"cell_type":"markdown","source":"Examinons les corrélations entre les variables :","metadata":{}},{"cell_type":"code","source":"def show_correlation_matrix(corr):\n    '''display correlation matrix.'''\n    fig = px.imshow(corr, title = f\"Corrélation entre les variables\", \n                    labels={'color':\"Corrélation\"}, \n                    color_continuous_scale='RdBu',\n                    color_continuous_midpoint=0,\n                    width=1100, height=1100, )\n    fig.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:55:49.100492Z","iopub.status.idle":"2021-06-10T12:55:49.101495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:51:36.750491Z","iopub.status.idle":"2021-06-10T12:51:36.751003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = data.corr()\nshow_correlation_matrix(corr)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.752244Z","iopub.status.idle":"2021-06-10T12:51:36.75278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On remarque que certaines corrélations sont à NaN, ce qui correspond à des variables qui ont une seule valeur pour toutes les données (toutes ces variables sont binaires) :","metadata":{}},{"cell_type":"code","source":"data[list(corr[corr['AMT_INCOME_TOTAL'].isna()].index)].describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:51:36.753754Z","iopub.status.idle":"2021-06-10T12:51:36.754235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ceci est dû à la suppression des lignes présentant des outliers dans d'autres catégories. Ces variables ne sont donc d'aucune utilité pour entraîner le modèle et peuvent être supprimées.","metadata":{"tags":[]}},{"cell_type":"code","source":"constant_cols = corr[corr['AMT_INCOME_TOTAL'].isna()].index.to_list()\ndata.drop(constant_cols, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:51:36.755403Z","iopub.status.idle":"2021-06-10T12:51:36.755898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_correlation_matrix(data.corr())","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:51:36.756892Z","iopub.status.idle":"2021-06-10T12:51:36.757388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remarquons ensuite que le résultat (TARGET) ne semble nettement corrélé linéairement à aucune variable en particulier. Voici ci-après les corrélations, positives ou négatives, classées par ordre décroissant de valeur absolue :","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(corr['TARGET'].sort_values(ascending=False, key=lambda x: np.abs(x))).style.format('{:.2%}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.759104Z","iopub.status.idle":"2021-06-10T12:51:36.759672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les données relatives au logement sont fortement corrélées entre elles et il semble donc possible de les synthétiser. Dans un premier temps, on peut déjà supprimer le mode et la médiane pour ne conserver que la moyenne. Cette suppression sera intégrée à la fonction `clean_features()`.","metadata":{}},{"cell_type":"code","source":"columns_without_mode_and_medi = [col for col in data.columns if not (col.endswith('_MODE') or col.endswith('_MEDI'))]\ndata = data[columns_without_mode_and_medi]","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.760856Z","iopub.status.idle":"2021-06-10T12:51:36.761793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Revisualisons la matrice de corrélation après suppression de ces éléments :","metadata":{}},{"cell_type":"code","source":"show_correlation_matrix(data.corr())","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.763573Z","iopub.status.idle":"2021-06-10T12:51:36.764187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Maintenant que le nombre de variables a été sensiblement réduit, examinons les corrélations supérieures (en valeur absolue) à 0.7 :","metadata":{}},{"cell_type":"code","source":"def list_high_correlations(df, threshold):\n    '''Print pairs of correlated features in corr and their correlation score.'''\n    corr = df.corr()\n    limit = 0\n    list_of_corr = []\n    for row in corr.index:\n        for col in corr.columns[limit:]:\n            if threshold<np.abs(corr.loc[row, col])<1:\n                list_of_corr.append(((row, col), corr.loc[row, col]))\n        limit+=1\n        list_of_corr = sorted(list_of_corr, key= lambda x: np.abs(x[1]), reverse=True)\n    if not list_of_corr:\n        print(f'Aucune corrélation supérieure à {threshold}.')\n    else:\n        for element in list_of_corr:\n            print(element[0], \":\", f'{element[1]:.2%}')\n    ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.765367Z","iopub.status.idle":"2021-06-10T12:51:36.76608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_high_correlations(data, 0.7)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.7676Z","iopub.status.idle":"2021-06-10T12:51:36.768102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Décidons maintenant du traitement de ces variables. Le coefficient de corrélation est arrondi à 2 décimales.","metadata":{}},{"cell_type":"markdown","source":"**('DAYS_EMPLOYED', 'FLAG_EMP_PHONE') : -1**\n\nLa corrélation inverse, arrondie, est totale. Ce qui semble logique puisque dès lors que le demandeur de prêt a un employeur, il pourra fournir son numéro. Cette dernière information est donc en soi redondante (elle correspond peu ou prou à \"a un employeur\") et **la variable FLAG_EMP_PHONE peut être supprimée**, tandis que la variable concernant l'ancienneté dans l'emploi est beaucoup plus intéressante (c'est une variable attentivement étudiée par un banquier).","metadata":{}},{"cell_type":"code","source":"data.drop(['FLAG_EMP_PHONE'], axis=1, inplace=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.769158Z","iopub.status.idle":"2021-06-10T12:51:36.769648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**('OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE') : 1**  \n**('DEF_30_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE') : 0.86**","metadata":{}},{"cell_type":"markdown","source":"Traçons le nuage de points pour les retards de paiement (pour une meilleure lisibilité, on ignorera la valeur aberrante de 347, on reviendra sur cette valeur dans la 2ème partie du traitement des données).","metadata":{}},{"cell_type":"code","source":"px.scatter(data[data['OBS_30_CNT_SOCIAL_CIRCLE']<50], x='OBS_30_CNT_SOCIAL_CIRCLE', y='OBS_60_CNT_SOCIAL_CIRCLE')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.770587Z","iopub.status.idle":"2021-06-10T12:51:36.771053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La corrélation étant parfaite, on peut choisir d'ignorer une des deux variables. Reste à savoir laquelle. Etudions les variables relatives aux défaut de paiement :","metadata":{}},{"cell_type":"code","source":"px.scatter(data[data['DEF_30_CNT_SOCIAL_CIRCLE']<50], x='DEF_30_CNT_SOCIAL_CIRCLE', y='DEF_60_CNT_SOCIAL_CIRCLE')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.771985Z","iopub.status.idle":"2021-06-10T12:51:36.772461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reprenons les définitions de DEF_30 et DEF_60 : \"How many observation of client's social surroundings defaulted on [30]/[60] (days past due) DPD\". Cette variable recense le nombre de défauts de paiement dans l'entourage de l'emprunteur suite à un retard de paiement de 30 ou 60 jours. On constate sur le graphe que DEF60 n'est jamais supérieur à DEF 30, ce qui est logique : le nombre de personnes en défaut de paiement depuis plus d'un mois comprend celui en défaut de paiement depuis plus de deux mois (mais pas l'inverse).\n\nOn va donc choisir de retenir DEF_30, et par conséquent OBS_30 également. On supprimera donc les variables DEF_60 et OBS_60.","metadata":{}},{"cell_type":"code","source":"data.drop(['OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE'], axis=1, inplace=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.773327Z","iopub.status.idle":"2021-06-10T12:51:36.773772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**('AMT_CREDIT', 'AMT_ANNUITY') 0.77**\n\nLe montant de l'annuité croît linéairement dans le même sens que celui du crédit bien sûr, mais il dépend également de deux autres facteurs : le taux et la durée du prêt. Or ces deux facteurs pourraient aboutir à un paradoxe de Simpson. En effet, le taux du prêt est décidé par le banquier en fonction de plusieurs paramètres, dont la durée du prêt et la motivation de l'établissement bancaire à accorder le prêt. Le taux du prêt dépend donc de la qualité du dossier de l'emprunteur aux yeux de la banque. Or, pour une banque, un emprunteur de qualité, c'est un emprunteur qui ne fait pas défaut : c'est justement l'objectif du modèle que de le prédire ! \n\nQuant à la durée du prêt, elle impacte très fortement le montant de l'échéance et joue à ce titre un rôle majeur dans l'endettement. Il suffit parfois de la moduler pour que l'endettement passe d'excessif à acceptable.\n\nLes banques françaises utilisent couramment deux autres variables pour mesurer le risque client : le taux d'endettement (rapport entre le total des échéances à payer et les revenus) et le reste à vivre (différence entre les échéances à payer, majorées de charges fixe de type loyer, et les revenus). Mais cela nécessite de commencer par calculer le montant de l'échéance du prêt envisagé, donc à refaire tourner le modèle pour chaque durée considérée. \n\nUne variable plus pertinente dans ce cas est le **rapport entre le montant du crédit et le total des revenus** : il donne une idée, certes approximative, de la mesure dans laquelle le bien est dans les moyens de l'acquéreur. Par exemple, si on retient une limite d'endettement de 33%, cela signifie qu'un prêt remboursé sans encombre pendant 15 ans représentait environ 5 ans de salaire (hypothèse très simplifiée ici puisqu'on ne tient pas compte du taux du prêt). Acheter un bien qui vaut 5 ans de salaire est donc une opération raisonnablement envisageable. Par contre, acheter un bien représentant 25 ans de salaire impliquerait de devoir s'endetter à hauteur de 33% de ses revenus pendant plus de 75 ans.  \n\n**On créera donc la variable \"CREDIT_INCOME_RATIO\" et on supprimera la variable AMT_ANNUITY** qui est non seulement inutile mais dangereuse pour la fiabilité du modèle.","metadata":{}},{"cell_type":"code","source":"data['CREDIT_INCOME_RATIO'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\ndata.drop(['AMT_ANNUITY'], axis=1, inplace=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.77467Z","iopub.status.idle":"2021-06-10T12:51:36.775694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**('AMT_CREDIT', 'AMT_GOODS_PRICE') 0.99**  \n**('AMT_ANNUITY', 'AMT_GOODS_PRICE') : 0.78**\n\nLà encore, la corrélation parfaite observée  entre le montant du crédit et celui du bien est évidente et a beaucoup moins d'intérêt que le **ratio** entre le montant du crédit et celui de la valeur du bien. C'est le ratio d'apport personnel, également scruté de près par les banquiers, du moins en France. Couplé à CREDIT_INCOME_RATIO, il donne là aussi une bonne idée de la faisabilité du dossier. On créera donc la variable **'CREDIT_GOOD_RATIO' qui sera égale à AMT_CREDIT / AMT_GOODS_PRICE, et on supprimera la variable 'AMT_CREDIT'** puisqu'elle corrélée à la fois a CREDIT_GOOD_RATIO et à CREDIT_INCOME_RATIO.\n\nComme vu plus haut, la varable AMT_ANNUITY est supprimée, et on pourra également **supprimer la valeur d'achat du bien AMT_GOODS_PRICE**, puisqu'elle peut être reconstituée à partir de AMT_INCOME, CREDIT_INCOME_RATIO et CREDIT_GOOD_RATIO.","metadata":{"tags":[]}},{"cell_type":"code","source":"data['CREDIT_GOOD_RATIO'] = data['AMT_CREDIT']/(data['AMT_GOODS_PRICE']+1)\ndata.drop(['AMT_CREDIT', 'AMT_GOODS_PRICE'], axis=1, inplace=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.776961Z","iopub.status.idle":"2021-06-10T12:51:36.777496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**('REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY') 0.95**\n\nLa forte corrélation s'explique par le fait que l'opinion d'un établissement sur la région dont provient le client est influencée, notamment, par les villes qui en font partie. L'exclusion de la ville ne semble donc pas un choix significatif et la variable correspondante, **REGION_RATING_CLIENT_W_CITY, paraît pouvoir être omise dans le modèle**.","metadata":{}},{"cell_type":"code","source":"data.drop(['REGION_RATING_CLIENT_W_CITY'], axis=1, inplace=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.778379Z","iopub.status.idle":"2021-06-10T12:51:36.778827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**('APARTMENTS_AVG', 'ELEVATORS_AVG') 0.84  \n('APARTMENTS_AVG', 'LIVINGAPARTMENTS_AVG') 0.94  \n('APARTMENTS_AVG', 'LIVINGAREA_AVG') 0.91  \n('ELEVATORS_AVG', 'LIVINGAPARTMENTS_AVG') 0.81  \n('ELEVATORS_AVG', 'LIVINGAREA_AVG') 0.87**  \nOn constate que la variable APARTMENTS_AVG présente des corrélations élevées avec les variables ELEVATORS_AVG, LIVINGAPARTMENTS_AVG et LIVING_AREA_AVG : on peut donc supprimer ces dernières. En pratique, on peut d'ailleurs douter de la pertinence, voire de l'utilité de ces éléments dont on ne connaît pas le mode de détermination.","metadata":{}},{"cell_type":"code","source":"data = data.drop(['ELEVATORS_AVG', 'LIVINGAPARTMENTS_AVG','LIVINGAREA_AVG'], \n                       axis=1)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.780284Z","iopub.status.idle":"2021-06-10T12:51:36.781027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**('CNT_CHILDREN', 'CNT_FAM_MEMBERS') 0.88**\n\nLa corrélation entre le nombre d'enfants et le nombre de membres de la famille n'est pas surprenante, puisque les enfants forment un sous-ensemble des membres de la famille. Examinons-la :","metadata":{}},{"cell_type":"code","source":"px.scatter(data, x=data['CNT_CHILDREN'], y=data['CNT_FAM_MEMBERS'])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.782445Z","iopub.status.idle":"2021-06-10T12:51:36.78325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le nombre de membres de la famille correspond donc au(x) parent(s) du foyer, et c'est la statistique avec le nombre d'enfants qui est la plus pertinente. L'existence d'un lien de couple étant déjà traité par la donnée NAME_FAMILY_STATUS, la variable CNT_FAMILY_MEMBER peut être supprimée.","metadata":{}},{"cell_type":"code","source":"data.drop(['CNT_FAM_MEMBERS'], axis=1, inplace=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.785046Z","iopub.status.idle":"2021-06-10T12:51:36.785864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**('REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION') 0.86**  \n**('REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY') 0.83**\n\nIl s'agit ici de vérifier, au niveau de la région ou de la ville, si l'adresse de travail de l'emprunteur est différente de son adresse de résidence ou de son adresse de contact. Notons que les corrélations entre les variables croisées, par exemple entre REG_REGION_NOT_WORK_REGION et REG_CITY_NOT_WORK_CITY, sont inférieures à 0.7 puisqu'elles ne ressortent pas dans le détail ci-dessus. \nOn peut aussi relever là encore la différence entre un modèle américan et français puisque le premier accepte une troisième adresse en plus de celle du domicile et celle du travail : en France, l'adresse du domicile est obligatoirement l'adresse de contact, une autre adresse ne serait tout simplement pas prise en compte.\n\nOn retient ici les variables LIVE_ et on supprime les variables REG_.","metadata":{}},{"cell_type":"code","source":"data = data.drop(['REG_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_WORK_CITY'], axis=1)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.787153Z","iopub.status.idle":"2021-06-10T12:51:36.787647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**('FLOORSMAX_AVG', 'FLOORSMIN_AVG') : 0.74**  \nCes données manquent de clarté : le nombre maximum d'étages concerne-t-il le logement de l'emprunteur (auquel cas c'est tout simplement le nombre d'étages) ou le type de logement qu'il occupe ? Or dans ce cas il ne s'agit pas d'une donnée qui lui est personnelle et donc susceptible d'être utile au modèle. Pour diminuer le nombre de variables on retiendra la moyenne de ces deux valeurs. On sera par ailleurs attentif à la pertinence de la variable dans le modèle.","metadata":{}},{"cell_type":"code","source":"data['FLOORS_AVG'] = (data['FLOORSMAX_AVG'] + data['FLOORSMIN_AVG'])/2\ndata.drop(['FLOORSMAX_AVG','FLOORSMIN_AVG'], axis=1, inplace=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.788647Z","iopub.status.idle":"2021-06-10T12:51:36.789106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Affichons la matrice de corrélation actualisée :","metadata":{}},{"cell_type":"code","source":"show_correlation_matrix(data.corr())","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.790052Z","iopub.status.idle":"2021-06-10T12:51:36.790514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_high_correlations(data, 0.7)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.791468Z","iopub.status.idle":"2021-06-10T12:51:36.791902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"APARTMENTS_AVG est fortement corrélé à 3 variables : ENTRANCES_AVG, BASEMENTAREA_AVG et FLOORS_AVG, on supprime celles-ci.","metadata":{}},{"cell_type":"code","source":"data.drop(['ENTRANCES_AVG', 'BASEMENTAREA_AVG', 'FLOORS_AVG'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:51:36.792802Z","iopub.status.idle":"2021-06-10T12:51:36.793249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_high_correlations(data, 0.5)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-06-10T12:51:36.794146Z","iopub.status.idle":"2021-06-10T12:51:36.794627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les corrélations ne semblent pas suffisantes pour autoriser une modification des variables. ","metadata":{}},{"cell_type":"markdown","source":"Vérifions les données après nettoyage :","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:51:36.795687Z","iopub.status.idle":"2021-06-10T12:51:36.796378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On intègre les opérations réalisées ci-dessus à la fonction `clean_features()` :","metadata":{}},{"cell_type":"code","source":"def clean_features(df):\n    print('Nettoyage des colonnes...')\n    # Drop columns with a single value\n    \n    corr = df.corr()\n    constant_cols = corr[corr['AMT_INCOME_TOTAL'].isna()].index.to_list()\n    df.drop(constant_cols, axis=1, inplace=True)\n    \n    # Drop MODE and MEDI columns \n    \n    cols_without_mode_and_medi = [col for col in df.columns \n                                     if not (col.endswith('_MODE') or col.endswith('_MEDI'))]\n    df = df[cols_without_mode_and_medi]\n    \n    # Create new synthetic features\n    \n    df['CREDIT_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n    df['CREDIT_GOOD_RATIO'] = df['AMT_CREDIT']/(df['AMT_GOODS_PRICE']+1)\n    df['FLOORS_AVG'] = (df['FLOORSMAX_AVG'] + df['FLOORSMIN_AVG'])/2\n    \n    # Drop redundant columns\n    \n    cols_to_drop = ['FLAG_EMP_PHONE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE',\n                   'AMT_ANNUITY','AMT_CREDIT', 'AMT_GOODS_PRICE', 'REGION_RATING_CLIENT_W_CITY',\n                   'ELEVATORS_AVG', 'LIVINGAPARTMENTS_AVG','LIVINGAREA_AVG','CNT_FAM_MEMBERS',\n                    'REG_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_WORK_CITY',\n                   'FLOORSMAX_AVG','FLOORSMIN_AVG',\n                    'ENTRANCES_AVG', 'BASEMENTAREA_AVG', 'FLOORS_AVG']\n    \n    df = df.drop(cols_to_drop, axis=1)   \n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:59:11.847596Z","iopub.execute_input":"2021-06-10T12:59:11.84799Z","iopub.status.idle":"2021-06-10T12:59:11.858854Z","shell.execute_reply.started":"2021-06-10T12:59:11.847959Z","shell.execute_reply":"2021-06-10T12:59:11.857524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_values_data = clean_values(application_train)\ndata = clean_features(cleaned_values_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:59:18.87417Z","iopub.execute_input":"2021-06-10T12:59:18.874559Z","iopub.status.idle":"2021-06-10T12:59:31.216535Z","shell.execute_reply.started":"2021-06-10T12:59:18.874528Z","shell.execute_reply":"2021-06-10T12:59:31.215638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:51:36.80383Z","iopub.status.idle":"2021-06-10T12:51:36.804521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_cols = [col for col in data.columns if col not in ['TARGET', 'SK_ID_CURR']]\nX = data[features_cols]\ny = data['TARGET']\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:59:31.217868Z","iopub.execute_input":"2021-06-10T12:59:31.218325Z","iopub.status.idle":"2021-06-10T12:59:31.45861Z","shell.execute_reply.started":"2021-06-10T12:59:31.218268Z","shell.execute_reply":"2021-06-10T12:59:31.457651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Essai avec variables modifiées","metadata":{}},{"cell_type":"markdown","source":"On relance le modèle après avoir actualisé le transformer chargé d'encoder X puisque les variables ont changé : ","metadata":{}},{"cell_type":"code","source":"num_cols = [col for col in X.columns if data[col].dtype != 'object']\ncat_cols = [col for col in X.columns if col not in num_cols]\n\ntransformer = make_column_transformer(\n    (StandardScaler(), num_cols),\n    (OneHotEncoder(), cat_cols)\n    )\n\npipeline = make_pipeline(transformer, DecisionTreeClassifier())\nparams = {'decisiontreeclassifier__max_depth': [None]}\nftwo_scorer = make_scorer(fbeta_score, beta=2)\naccuracy_scorer = make_scorer(accuracy_score)\n\ngrid_dtc = GridSearchCV(\n    pipeline, \n    param_grid=params, \n    cv=5, \n    scoring={'acc': accuracy_scorer, 'ftwo': ftwo_scorer},\n    refit='ftwo', \n    verbose=2\n)\n_= grid_dtc.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:59:36.269361Z","iopub.execute_input":"2021-06-10T12:59:36.269769Z","iopub.status.idle":"2021-06-10T13:02:08.890364Z","shell.execute_reply.started":"2021-06-10T12:59:36.269738Z","shell.execute_reply":"2021-06-10T13:02:08.88943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"update_recap('dtc nouvelles variables', \n             grid_dtc.cv_results_['mean_test_acc'][0], \n             grid_dtc.cv_results_['mean_test_ftwo'][0])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T13:02:08.892393Z","iopub.execute_input":"2021-06-10T13:02:08.892727Z","iopub.status.idle":"2021-06-10T13:02:08.907269Z","shell.execute_reply.started":"2021-06-10T13:02:08.892696Z","shell.execute_reply":"2021-06-10T13:02:08.905544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le traitement des variables n'améliore pas la performance du modèle. En revanche il améliore sa rapidité (presque doublée).","metadata":{}},{"cell_type":"markdown","source":"### 4.3 Essai avec régression logistique","metadata":{}},{"cell_type":"markdown","source":"Essayons un autre modèle, la régression logistique :","metadata":{}},{"cell_type":"code","source":"pipeline = make_pipeline(transformer, LogisticRegression())\nparams = {'logisticregression__C': np.logspace(-1,1,3),\n         'logisticregression__max_iter': [1000],\n         'logisticregression__solver': ['saga']}\n\ngrid_lr = GridSearchCV(\n    pipeline, \n    param_grid=params, \n    cv=5, \n    scoring={'acc': accuracy_scorer, 'ftwo': ftwo_scorer},\n    refit='ftwo', \n    verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:55:49.113836Z","iopub.status.idle":"2021-06-10T12:55:49.114278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_= grid_lr.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:55:49.115445Z","iopub.status.idle":"2021-06-10T12:55:49.116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"update_recap('régression logistique',\n             grid_lr.cv_results_['mean_test_acc'][0], \n             grid_lr.cv_results_['mean_test_ftwo'][0])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:55:49.117165Z","iopub.status.idle":"2021-06-10T12:55:49.118019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_lr.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-06-10T12:55:49.119486Z","iopub.status.idle":"2021-06-10T12:55:49.120065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}