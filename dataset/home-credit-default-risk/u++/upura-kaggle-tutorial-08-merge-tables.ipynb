{"cells":[{"metadata":{},"cell_type":"markdown","source":"This Notebook is a kaggle tutorial for Japanese kaggle beginners writen in Japanese.\n\n# 8. Titanicの先へ行く①！ 複数テーブルを結合してみよう\n\nこの[Notebook](https://www.kaggle.com/sishihara/upura-kaggle-tutorial-08-merge-tables)では、複数のファイルを結合して機械学習アルゴリズムに入力するためのデータを用意する方法を扱います。\n\n題材にするのは「[Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk)」[^65]コンペです。このコンペでは、融資の申込に対して、それぞれが債務不履行になるか否かを予測します。application_{train/test}.csvに含まれる申込1件に対して、過去の申込履歴などの関連情報を含むcsvファイルが複数存在するデータ構造で、どのように有益な情報を取り出すかが問われるコンペとなりました。\n\nここでは、公開Notebook「[Introduction to Manual Feature Engineering](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering)」の冒頭の例を引用します。\n\nまずは主ファイルであるapplication_train.csvを読み込みます。各行が1つの融資の申込を表し、TAEGETが予測の対象です。","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\n\napplication_train = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\napplication_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"次いで、サブファイルに当たるbureau.csvを読み込みます。bureau.csvには、他の金融機関から提供された過去の申込履歴が記録されています。\n\n図に示された通り、SK_ID_CURRで紐づく関係性です。過去の履歴なので、application_trainの1行に対して、bureauの複数行が対応する可能性があります。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bureau = pd.read_csv('../input/home-credit-default-risk/bureau.csv')\nbureau.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"仮に1:1の関係ならば、純粋にデータを結合してしまえば良いです。ここでは1:Nの関係なので、N側のデータセットを何かしらの方法で集約して情報量を落とす必要があります。\n\n「何かしらの方法で集約」の部分は、「3. ここで差がつく！ 仮説に基づいて新しい特徴量を作ってみよう」で説明したような特徴量エンジニアリングの力が試されます。思考停止でさまざまな集約パターンを試す場合もありますが、今回のデータセットのようにある程度カラム数も多い場合には、意味のある仮説を立てるのが望ましいと思います。\n\nここでは「過去の申込回数」が有効な特徴量になるという仮説を得たとします。この特徴量は、次のようにbureauから作成可能です。SK_ID_CURRごとに、回数が集計されています。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"previous_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns={'SK_ID_BUREAU': 'previous_loan_counts'})\nprevious_loan_counts.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"あとは、application_trainにSK_ID_CURRをキーにして結合するだけです。\n\nこの際`how='left'`という引数が与えられている点に注目です。SQLを使ったことのある方はイメージしやすいかと思いますが、引数として与えられているデータセットのうち、左側のファイルを軸にデータセットを結合していくという意味合いです。右側のデータセットに該当する値が含まれていない場合は、欠損値になります。\n\n仮にこの引数を指定しないと、両者に含まれるSK_ID_CURRのデータセットのみが返ります。ここでprevious_loan_countsには申込が0回のSK_ID_CURRは含まれていないので、データセットの欠落が発生する可能性があります。\n\napplication_trainの行数が減るのは学習用データセットの量を保つ観点から望ましくありません。application_test.csvを扱う場合は、予測すべきデータセットが欠落する事態を招いてしまいます。\n\nこの欠損値は、意味合いを考えると0で補完するのが適切です。\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train = pd.merge(application_train, previous_loan_counts, on='SK_ID_CURR', how='left')\n\n# 欠損値の処理\napplication_train['previous_loan_counts'].fillna(0, inplace=True)\napplication_train.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}