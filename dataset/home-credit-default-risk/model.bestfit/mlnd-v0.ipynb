{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d08e128207059b0ef1fa58284345a9ab2266c18"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nimport re\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom xgboost import XGBClassifier\n\n#import lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set()\n\ntrain = pd.read_csv(\"../input/application_train.csv\")\n#train = pd.read_csv(\"data/application_test.csv\")\ntrain = train.drop(columns=[\"SK_ID_CURR\"])\ndf = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65efb8e6c534db299b948dec989bbd1e4836a858"},"cell_type":"markdown","source":"* The dataset provided has 307511 rows and 121 columns which makes it small to mid-size.  As such no GPU or big data techniques are required.\n* The column we try to predict is the column called TARGET - it is either 1 or 0, where 1 means loan was defaulted.  Looking at the distribution, it is a very imbalanced dataset.  This has resulted in the choice of using AUC-ROC as our metric, and also this implies we need to do some resampling.\n* Looking at the data types of the columns, we found that 65 are float, 39 are integers and 16 are objects.  However we noted that amongst the 40 integear variables, some of them are FLAGS hence they should be considered categorical\n* Missing value??\n* Outliers??"},{"metadata":{"trusted":true,"_uuid":"d86bad1d608f8edb2e06d96c13e2c8438eae413a"},"cell_type":"code","source":"def create_dummy(df, col_list):\n    '''\n    parameters : df - input dataframe, col_list - list of columns to be one-hot-encoded\n    returns : new df with those fields in col_list one-hot-encoded\n    '''\n    res = df.copy()\n    for col in col_list:\n        df[col] = df[col].apply(lambda s:col+\"_\"+str(s))\n        dummy = pd.get_dummies(df[col])\n        res = pd.concat([res, dummy], axis=1)\n        res = res.drop(columns = [col])\n    return res\n\ndef encode_data(org_df):\n    \n    df = org_df.copy()\n    df_types = df.dtypes\n    list_obj_var = df_types[df_types==np.object].index.tolist()\n    list_int_var = df_types[df_types==np.integer].index.tolist()\n    list_cat_var = [ele for ele in list_int_var if ele not in (\"TARGET\",\"CNT_CHILDREN\",\"DAYS_BIRTH\", \"DAYS_EMPLOYED\", \"DAYS_ID_PUBLISH\",\"HOUR_APPR_PROCESS_START\")]\n    list_cat_var = list_cat_var + list_obj_var\n    df = create_dummy(df, list_cat_var)\n    \n    return df\n\ndef normalize_data(org_df):\n    '''\n    parameter : org_df - dataframe\n    returns : a new dataframe where all float variables are normalize\n    '''\n    df = org_df.copy()\n    scaler = StandardScaler()\n    df_types = df.dtypes\n    list_float_var = df_types[df_types==np.float].index\n    df[list_float_var] = scaler.fit_transform(df[list_float_var])\n    \n    return df\n\ndef split_res_data(X, y):    \n    '''\n    parameters: df, dataframe consisting of all training data\n    returns : X_train, y_train, X_test, y_test\n    ''' \n    \n    # split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n    \n    \n    # oversampling with SMOTE\n    sm = SMOTE(random_state=12)\n    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n    X_train = pd.DataFrame(X_train_res)\n    X_train.columns = X_test.columns\n    y_train = pd.DataFrame(y_train_res)\n    y_train.columns = y_test.columns\n    \n    return X_train, y_train, X_test, y_test\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7c25939052b657f21c384b319fe17dbcb263441"},"cell_type":"code","source":"df = df.fillna(value=0)\ndf = encode_data(df)\ndf = normalize_data(df)\n\ny = df[[\"TARGET\"]]\nX = df.drop(columns = [\"TARGET\"])\n\nX_train, y_train, X_test, y_test = split_res_data(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6eeeb9792410c2b43ef46da1b326fe2c411383c2"},"cell_type":"code","source":"best_score = 0\nfor num_leaves in [15,63,255]:\n    for min_data_in_leaves in [10, 100, 1000]:\n        for max_depth in [-1, 5, 10]:\n            clf = LGBMClassifier(num_leaves=num_leaves, min_data_in_leaves=min_data_in_leaves, max_depth=max_depth)\n            clf.fit(X_train,y_train)\n            pred_test = clf.predict_proba(X_test)\n            score = roc_auc_score(y_test, pred_test[:,1])\n            print(num_leaves,min_data_in_leaves,max_depth,score)\n            if score > best_score:\n                best_score = score\n                params = [num_leaves, min_data_in_leaves, max_depth]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b03c89e190ae1d8f297d2b5982816b4898f9c7e8"},"cell_type":"code","source":"ratios = [0.1, 0.5, 0.9]\nclf = LGBMClassifier()\ntrain_score = []\ntest_score = []\nfor ratio in ratios:\n    X, _, y , _ = train_test_split(X_train,y_train,test_size=1.-ratio)\n    clf.fit(X,y)\n    pred_train = clf.predict_proba(X)\n    train_score.append(roc_auc_score(y, pred_train[:,1]))\n    pred_test = clf.predict_proba(X_test)\n    test_score.append(roc_auc_score(y_test, pred_test[:,1]))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ff6159ae668a7ae528730557114a91c47545d9b"},"cell_type":"code","source":"plt.plot(ratios, train_score, '--', color=\"#111111\",  label=\"Training score\")\n#plt.plot(ratios, test_score, color=\"#111111\", label=\"Cross-validation score\")\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d71dd2c8e222d63bf4a6127646e06c9a8ec4a37"},"cell_type":"code","source":"clf = cv_clf.best_estimator_\nclf.fit(X_train, y_train)\npred_test = clf.predict_proba(X_test)\nscore = roc_auc_score(y_test, pred_test[:,1])\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d461be1f27456a10c412196436b4b53f13591fae"},"cell_type":"code","source":"clf = LGBMClassifier(num_leaves=15)\nclf.fit(X_train, y_train)\npred_test = clf.predict_proba(X_test)\nscore = roc_auc_score(y_test, pred_test[:,1])\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c4d85ea9dcc39ef1b0f3fb4e2ca30abcbfc559e"},"cell_type":"code","source":"param_grid = { \n    'num_leaves': [15,31,63],\n    'min_data_in_leaves' : [10,100,1000]\n}\n\nclf = LGBMClassifier()\ncv_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 5)\ncv_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae54b03fcc2df252322c8a02a3ae712eb48bea2c"},"cell_type":"code","source":"train[\"TARGET\"].plot.hist(title=\"Distribution of TARGET variable\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6c51850c154120ef61fdcb0c22f08a574712d89"},"cell_type":"code","source":"train.drop([\"TARGET\"],axis=1).dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b202fa58a17a23c1bcd71b8d62a67be5521065f5"},"cell_type":"code","source":"list_float_var = train_types[train_types==np.float].index\ntrain_float = train[list_float_var]\ntrain_float.head()\nnull_perc = train_float.isnull().sum() / len(train_float)\nlen(null_perc[null_perc>0.5])\n#sns.boxplot(data = train[list_float_var[[5,58]]], orient=\"h\")\n#null_perc[null_perc>0.5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb27ba6ba843b1d1484c7bebb95cb7979ef00268"},"cell_type":"code","source":"list_int_var = train_types[train_types==np.int].index\ntrain_int = train[list_int_var]\ntrain_int.head()\nnull_perc = train_int.isnull().sum() / len(train_int)\ntrain_int.head()\ntrain_int.nunique()\n#len(null_perc[null_perc>0.1])\n#sns.boxplot(data = train[list_float_var[[5,58]]], orient=\"h\")\n#null_perc[null_perc>0.5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d05c9288308e0ee7d6e1d7bdac313b697c8bdb44"},"cell_type":"code","source":"list_obj_var = train_types[train_types==np.object].index\ntrain_obj = train[list_obj_var]\ntrain_obj.head()\nnull_perc = train_obj.isnull().sum() / len(train_int)\n#train_obj.head()\n#len(null_perc[null_perc>0.1])\n#sns.boxplot(data = train[list_float_var[[5,58]]], orient=\"h\")\nnull_perc[null_perc>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b122db9189270f3ae7ace699471586d24bd0dfe8"},"cell_type":"code","source":"df_types = df.dtypes\nlist_int_var = df_types[df_types==np.integer].index.tolist()\ndf[list_int_var].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0009bd07287c00b9e4473ab643e3d7c340d50cf6"},"cell_type":"code","source":"train_types = train.dtypes\nlist_float_var = train_types[train_types==np.integer].index\ntrain_unique_count=train[list_float_var].apply(lambda x: len(x.unique()))\ndata = train_unique_count.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f273f62f29cb71c6ce55b068605cf7b0f2cbd247"},"cell_type":"code","source":"#clf = RandomForestClassifier()\n#clf = XGBClassifier()\nclf = LGBMClassifier()\n\nclf.fit(X_train, y_train)\npred_test = clf.predict_proba(X_test)\nscore = roc_auc_score(y_test, pred_test[:,1])\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e7ec585a0857e0f1ee2fd51567133c72a934fc0"},"cell_type":"code","source":"df_types = df.dtypes\nlist_obj_var = df_types[df_types==np.object].index.tolist()\nlist_int_var = df_types[df_types==np.integer].index.tolist()\nlist_cat_var = [ele for ele in list_int_var if ele not in (\"CNT_CHILDREN\",\"DAYS_BIRTH\")]\nlist_cat_var = list_cat_var + list_obj_var\ndf[list_cat_var].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2e3184ffc32cb0c3eded9701333c31d835a1c2f"},"cell_type":"code","source":"from hyperopt import fmin, tpe, hp\n\ndef score_lgb(params):\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n    para = {\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': {'auc'},\n        'num_leaves': params[\"num_leaves\"],\n        'learning_rate': params[\"learning_rate\"],\n        'feature_fraction': 0.9, #0.8\n        'bagging_fraction': 0.8,\n        'bagging_freq': 5,\n        'verbose': 0\n    }\n    gbm = lgb.train(para,lgb_train)\n    pred_test = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n    score = roc_auc_score(y_test, pred_test)\n    return score\n\nspace_lgb = {\n        'num_leaves': hp.choice('num_leaves', range(8,256)),\n        'learning_rate' : hp.choice('learning_rate', [0.01, 0.3, 0.1])\n        }\n        \n\ndef objective(params):\n    print(params)\n    score = score_lgb(params)\n    return -score\n\nbest = fmin(fn=objective, space=space_lgb, algo=tpe.suggest, max_evals=50)\nprint(\"best:\", best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cebe0054916f86d5330aff1ab5a18120e4b9cdf","_kg_hide-input":false},"cell_type":"code","source":"from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\nspace_rf = {\n    'n_estimators': hp.choice('n_estimators', range(25,500)),\n    'max_depth': hp.choice('max_depth', range(1,30))\n}\n    \ndef objective(params):\n    print(params)\n    clf = RandomForestClassifier(**params)\n    clf.fit(X_train, y_train)\n    pred_test = clf.predict(X_test)\n    score = roc_auc_score(y_test, pred_test)\n    return -score\n    #return {\"loss\":-score, \"status\": STATUS_OK}\n\n\nbest = fmin(fn=objective, space=space_rf, algo=tpe.suggest, max_evals=3)\nprint(\"best:\", best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b6578a759614627131f9d3ec3752188ee8b723a"},"cell_type":"code","source":"from hyperopt import fmin, tpe, hp\n\ndef score_xgb(params):\n    clf = XGBClassifier(**params)\n    clf.fit(X_train, y_train)\n    pred_test = clf.predict(X_test)\n    score = roc_auc_score(y_test, pred_test)\n    return score\n\nspace_xgb = {\n        'max_depth': hp.choice('max_depth', [2,3,4,5]),\n        'learning_rate' : hp.choice('learning_rate', [0.01, 0.3, 0.1])\n        }\n        #'min_child_weight': hp.quniform ('min_child', 1, 20, 1),\n        #'subsample': hp.uniform ('subsample', 0.8, 1),\n        #'n_estimators' : hp.choice('n_estimators', np.arange(1000, 10000, 100, dtype=int)),\n        #'gamma' : hp.quniform('gamma', 0, 1, 5),\n        #'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05)\n        \n\ndef objective(params):\n    print(params)\n    score = score_xgb(params)\n    return -score\n\nbest = fmin(fn=objective, space=space_xgb, algo=tpe.suggest, max_evals=3)\n\nprint(\"best:\", best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f4fb633257765659b9c84e2c47215cdfa7b9694"},"cell_type":"code","source":"#from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nclf = XGBClassifier()\n\ngrid_param = {  \n    \"max_depth\": [2,3,4,5],\n    \"learning_rate\": [0.01, 0.3, 0.1 ]\n}\n\ngd_sr = GridSearchCV(estimator=clf,  \n                     param_grid=grid_param,\n                     scoring='roc_auc',\n                     cv=5,\n                     n_jobs=-1)\n\ngd_sr.fit(X_train, y_train)  \nbest_parameters = gd_sr.best_params_  \nprint(best_parameters) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"426327a296e53057676744b7aed53d7f41d3b74e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}