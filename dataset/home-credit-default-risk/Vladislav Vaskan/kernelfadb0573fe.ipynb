{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nPATH=\"../input/\"\nprint(os.listdir(PATH))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"app_train = pd.read_csv(PATH + 'application_train.csv',)\napp_test = pd.read_csv(PATH + 'application_test.csv',)\nprint (\"формат обучающей выборки:\", app_train.shape)\nprint (\"формат тестовой выборки:\", app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\n\nprint('Training Features shape: ', app_train.shape)\nprint('Testing Features shape: ', app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#сохраним лейблы, их же нет в тестовой выборке и при выравнивании они потеряются. \ntrain_labels = app_train['TARGET']\n\n# Выравнивание - сохранятся только столбцы. имеющиеся в обоих датафреймах\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n\nprint('Формат тренировочной выборки: ', app_train.shape)\nprint('Формат тестовой выборки: ', app_test.shape)\n\n# Add target back in to the data\napp_train['TARGET'] = train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# создадим новый датафрейм для полиномиальных признаков\npoly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\npoly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n\n# обработаем отуствующие данные\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = 'median')\n\npoly_target = poly_features['TARGET']\n\npoly_features = poly_features.drop('TARGET', axis=1)\n\npoly_features = imputer.fit_transform(poly_features)\npoly_features_test = imputer.transform(poly_features_test)\n\nfrom sklearn.preprocessing import PolynomialFeatures\n                                  \n# Создадим полиномиальный объект степени 3\npoly_transformer = PolynomialFeatures(degree = 3)\n\n# Тренировка полиномиальных признаков\npoly_transformer.fit(poly_features)\n\n# Трансформация признаков\npoly_features = poly_transformer.transform(poly_features)\npoly_features_test = poly_transformer.transform(poly_features_test)\nprint('Формат полиномиальных признаков: ', poly_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Датафрейм для новых фич \npoly_features = pd.DataFrame(poly_features, \n                             columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                           'EXT_SOURCE_3', 'DAYS_BIRTH']))\n\n# Добавим таргет\npoly_features['TARGET'] = poly_target\n\n# рассчитаем корреляцию\npoly_corrs = poly_features.corr()['TARGET'].sort_values()\n\n# Отобразим признаки с наивысшей корреляцией\nprint(poly_corrs.head(10))\nprint(poly_corrs.tail(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# загрузим тестовые признаки в датафрейм\npoly_features_test = pd.DataFrame(poly_features_test, \n                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n\n# объединим тренировочные датафреймы\npoly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\napp_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\n\n# объединим тестовые датафреймы\npoly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\napp_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n\n# Выровняем датафреймы\napp_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)\n\n# Посмотрим формат\nprint('Тренировочная выборка с полиномиальными признаками: ', app_train_poly.shape)\nprint('Тестовая выборка с полиномиальными признаками: ', app_test_poly.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Уберем таргет из тренировочных данных\nif 'TARGET' in app_train:\n    train = app_train.drop(labels = ['TARGET'], axis=1)\nelse:\n    train = app_train.copy()\nfeatures = list(train.columns)\n\n# копируем тестовые данные\ntest = app_test.copy()\n\n# заполним недостающее по медиане\nimputer = SimpleImputer(strategy = 'median')\n\n# Нормализация\nscaler = MinMaxScaler(feature_range = (0, 1))\n\n# заполнение тренировочной выборки\nimputer.fit(train)\n\n# Трансофрмация тренировочной и тестовой выборок\ntrain = imputer.transform(train)\ntest = imputer.transform(app_test)\n\n# то же самое с нормализацией\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\n\nprint('Формат тренировочной выборки: ', train.shape)\nprint('Формат тестовой выборки: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(train,train_labels,test_size=0.3,random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_values = np.logspace(-2, 3, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid1.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlog_reg1 = LogisticRegression(C = 0.0001,solver=\"lbfgs\",max_iter=2500)\n\nc_values1 = np.logspace(-2, 3, 30)\nparameters={'C':c_values1}\ngrid1 = GridSearchCV(log_reg1, parameters, scoring='roc_auc', cv=3)\ngrid1.fit(X_train, y_train)\nprint(grid1)\n# summarize the results of the grid search\nprint(grid1.best_score_)\nprint (grid1.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\nnow = datetime.now()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"now #время было 4.16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n\n# Создаем модель\nlog_reg = LogisticRegression(C = 0.99,solver=\"lbfgs\",max_iter=2500)\n\nparameters={'C':c_values}\ngrid = GridSearchCV(log_reg, parameters, cv=5)\ngrid.fit(X_train, y_train)\nprint(grid)\n# summarize the results of the grid search\nprint(grid.best_score_)\nprint (grid.best_params_)\n# Тренируем модель\n#log_reg.fit(X_train, y_train)\n\n\n#log_reg_pred_acc = log_reg.predict(X_test)\n#log_reg_pred = log_reg.predict_proba(X_test)[:, 1]\n#print (\"Доля правильных ответов: \",accuracy_score(y_test,log_reg_pred_acc))\n#print (\"ROC-AUC: \",roc_auc_score(y_test,log_reg_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Создаем модель\nlog_reg = LogisticRegression(C = 28.072,solver=\"lbfgs\", max_iter=2500)\n\n# Тренируем модель\nlog_reg.fit(train, train_labels)\n\n\nlog_reg_pred = log_reg.predict_proba(test)[:, 1]\n# Предсказание на тестовых данных\n#predictions = random_forest.predict_proba(test)[:, 1]\n\n# Создание датафрейма для загрузки\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\n# Сохранение\nsubmit.to_csv('up_linear_model.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV \nfrom sklearn.model_selection import cross_val_score, StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Создадим классификатор\nrandom_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)\n\n# Тренировка на тернировочных данных\nrandom_forest.fit(train, train_labels)\n\n# Предсказание на тестовых данных\npredictions = random_forest.predict_proba(test)[:, 1]\n\n# Создание датафрейма для загрузки\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\n# Сохранение\nsubmit.to_csv('random_forest_baseline.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_features_names = list(app_train_poly.columns)\n\n# Создание и тренировка объекта для заполнение недостающих данных\nimputer = SimpleImputer(strategy = 'median')\n\npoly_features = imputer.fit_transform(app_train_poly)\npoly_features_test = imputer.transform(app_test_poly)\n\n# Нормализация\nscaler = MinMaxScaler(feature_range = (0, 1))\n\npoly_features = scaler.fit_transform(poly_features)\npoly_features_test = scaler.transform(poly_features_test)\n\nrandom_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50)\n\n# Тренировка на полиномиальных данных\nrandom_forest_poly.fit(poly_features, train_labels)\n\n# Предсказания\npredictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]\n\n# Датафрейм для загрузки\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\n# Сохранение датафрейма\nsubmit.to_csv('random_forest_baseline_engineered.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nclf = LGBMClassifier()\nclf.fit(train, train_labels)\n\npredictions = clf.predict_proba(test)[:, 1]\n\n# Датафрейм для загрузки\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\n# Сохранение датафрейма\nsubmit.to_csv('lightgbm_baseline.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.head()"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('log_reg_baseline.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}