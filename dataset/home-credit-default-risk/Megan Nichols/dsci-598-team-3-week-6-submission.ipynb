{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport joblib\nimport gc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load test data, pipeline, and model","metadata":{}},{"cell_type":"code","source":"#import test data\ntest = pd.read_csv('../input/home-credit-default-risk/application_test.csv')\ntest.set_index(['SK_ID_CURR'], inplace=True)\ntest.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load saved pipeline and model\npreprocessor = joblib.load('../input/wk6-default/wk6default_preprocessor.joblib')\n\nLGBM_model = joblib.load('../input/wk6-default/wk6_LGBM_default_model.joblib')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing: Cleaning and Merging Datasets","metadata":{}},{"cell_type":"markdown","source":"#### Merge Bureau and Bureau_Balance with Test Data","metadata":{}},{"cell_type":"code","source":"#load bureau_balance and bureau into memory\nbureau_bal = pd.read_csv('../input/home-credit-default-risk/bureau_balance.csv')\nbureau = pd.read_csv('../input/home-credit-default-risk/bureau.csv')\n\nbb = pd.merge(bureau, bureau_bal, on = 'SK_ID_BUREAU', how = 'left')\n\n#feature engineering\nbb['REMAIN_CRED'] = bb['AMT_CREDIT_SUM'] - bb['AMT_CREDIT_SUM_DEBT'] - bb['AMT_CREDIT_SUM_LIMIT']\nbb['AC_RATIO'] = bb['AMT_ANNUITY'] / bb['AMT_CREDIT_SUM'] \n\n#add prefix to bureau columns\nbb.columns = ['BU_'+column if column != ('SK_ID_CURR') \n                       else column for column in bb.columns]\n\n#group categorical features in bureau\nbur_cat = pd.get_dummies(bb.select_dtypes('object'))\nbur_cat['SK_ID_CURR'] = bb['SK_ID_CURR']\nbur_cat = bur_cat.groupby(by = ['SK_ID_CURR']).agg(['mean'])\n  \n#group numerical features    \nbur_num = bb.groupby(by = ['SK_ID_CURR']).agg(['max', 'mean', 'sum']).astype('float32')\n\n# merge cat and num columns\nbureau_rev = bur_cat.merge(bur_num, on = ['SK_ID_CURR'], how = 'left')\n\n#merge bureau_rev and test\ntest = test.merge(bureau_rev, on = ['SK_ID_CURR'], how = 'left')\n\n#remove unneeded datasets from memory\ndel bur_cat\ndel bur_num\ndel bureau\ndel bureau_bal\n\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Merge Credit_Card_Balance with Test Dataset","metadata":{}},{"cell_type":"code","source":"#load data into memory\ncc_bal = pd.read_csv('../input/home-credit-default-risk/credit_card_balance.csv')\n\n#feature engineering\ncc_bal['DRAW_RATIO'] = cc_bal['AMT_DRAWINGS_CURRENT'] / cc_bal['CNT_DRAWINGS_CURRENT']\ncc_bal['RECEIVE_RATIO'] = cc_bal['AMT_RECIVABLE'] / cc_bal['AMT_RECEIVABLE_PRINCIPAL']\ncc_bal['RECEIVE_PER'] = cc_bal['AMT_RECIVABLE'] / cc_bal['AMT_TOTAL_RECEIVABLE']\n\n\n#create prefix for columns\ncc_bal.columns = ['CC_'+ column if column !='SK_ID_CURR' \n                  else column for column in cc_bal.columns]\n\n#group categorical features by SK_ID_CURR\ncc_cat = pd.get_dummies(cc_bal.select_dtypes('object'))\ncc_cat['SK_ID_CURR'] = cc_bal['SK_ID_CURR']\ncc_cat = cc_cat.groupby(by = ['SK_ID_CURR']).mean()\n\n#group numerical features in credit card balance by SK_ID_CURR\ncc_num = cc_bal.groupby(by = ['SK_ID_CURR']).agg(['max', 'mean', 'sum']).astype('float32')\n\ntest = test.merge(cc_cat, on = ['SK_ID_CURR'], how = 'left')\ntest = test.merge(cc_num, on = ['SK_ID_CURR'], how = 'left')\n\ndel cc_bal\ndel cc_cat\ndel cc_num\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Merge Installments_Payments with Test Dataset","metadata":{}},{"cell_type":"code","source":"#load installments_payments into memory\ninstall = pd.read_csv('../input/home-credit-default-risk/installments_payments.csv')\n\n#feature engineering\ninstall['PAY_PERCENT'] = install['AMT_INSTALMENT'] / install['AMT_PAYMENT']\ninstall['PAY_DIFF'] = install['AMT_INSTALMENT'] - install['AMT_PAYMENT']\n\ninstall['DPD'] = install['DAYS_ENTRY_PAYMENT'] - install['DAYS_INSTALMENT']\ninstall['DPD'] = install['DPD'].apply(lambda x: x if x>0 else 0)\n\ninstall['DBD'] = install['DAYS_INSTALMENT'] - install['DAYS_ENTRY_PAYMENT']\ninstall['DBD'] = install['DBD'].apply(lambda x: x if x>0 else 0)\n\n#create prefix\ninstall.columns = ['IP_'+ column if column !='SK_ID_CURR' \n                   else column for column in install.columns]  \n\n\n#group numeric features (no cat features in install)\ninst_num = install.groupby(by = ['SK_ID_CURR']).agg(['max', 'mean']).astype('float32')\n\n#merge install with prev\ntest = test.merge(inst_num, on = 'SK_ID_CURR', how='left')\n\ndel install\ndel inst_num\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Merge POS_CASH with test set","metadata":{}},{"cell_type":"code","source":"#load POS_CASH into memory\npos = pd.read_csv('../input/home-credit-default-risk/POS_CASH_balance.csv')\n\n#create prefix\npos.columns = ['PC_'+ column if column !='SK_ID_CURR' \n                   else column for column in pos.columns]\n\n#group numeric features (no cat features in install)\npos_num = pos.groupby(by = ['SK_ID_CURR']).agg(['max', 'mean', 'sum']).astype('float32')\n\ntest = test.merge(pos_num, on = ['SK_ID_CURR'], how = 'left')\n\ndel pos\ndel pos_num\ngc.collect()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Merge Previous_Application with Test Dataset","metadata":{}},{"cell_type":"code","source":"#load data\nprev = pd.read_csv('../input/home-credit-default-risk/previous_application.csv')\n\n#feature engineering\nprev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace = True)\nprev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace = True)\nprev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace = True)\nprev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace = True)\nprev['DAYS_TERMINATION'].replace(365243, np.nan, inplace = True)\n\nprev['AppCred_RATIO'] = prev['AMT_APPLICATION'] / (prev['AMT_CREDIT'] + 1)\nprev['AppGoods_RATIO'] = prev['AMT_APPLICATION'] / (prev['AMT_GOODS_PRICE'] + 1)\nprev['AnnCred_RATIO'] = prev['AMT_ANNUITY'] / (prev['AMT_CREDIT'] + 1)\nprev['CredGoods_RATIO'] = prev['AMT_CREDIT'] / (prev['AMT_GOODS_PRICE'] + 1)\n\n#calculate APR and add it as a feature\ndef calc_rate(row):\n    return np.rate(row['CNT_PAYMENT'], -row['AMT_ANNUITY'], row['AMT_CREDIT'], 0, guess = 0.05, maxiter = 10)\n\nprev['CALC_RATE'] = prev.apply(calc_rate, axis=1)\n\n\n#Remove unnecessary features\np_dels = ['RATE_INTEREST_PRIMARY','RATE_INTEREST_PRIVILEGED']\nprev = prev.drop(prev[p_dels], axis = 1)\n\n#create prefix\nprev.columns = ['PR_'+ column if column != 'SK_ID_CURR' \n                else column for column in prev.columns]\n\n#group categorical features in previous_application\nprev_cat = pd.get_dummies(prev.select_dtypes('object'))\nprev_cat['SK_ID_CURR'] = prev['SK_ID_CURR']\nprev_cat = prev_cat.groupby(by = ['SK_ID_CURR']).agg(['mean'])\n\n#group numeric features\nprev_num = prev.groupby(by = ['SK_ID_CURR']).agg(['max', 'mean', 'sum']).astype('float32')\n\n#combine previous_application categorical and numeric features\nprev_rev = prev_num.merge(prev_cat, on = ['SK_ID_CURR'], how = 'left')\n\n#merge revised previous_application features into test dataset\ntest = test.merge(prev_rev, on = ['SK_ID_CURR'], how = 'left')\n\ndel prev_rev\ndel prev_cat\ndel prev_num\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace 365243 in days employed with nan\ntest['DAYS_EMPLOYED'].replace(365243, np.nan, inplace = True)\n\n#convert age to years\ntest['AGE'] = test['DAYS_BIRTH'] / - 365\n\n#create avg of each row of EXIT_SOURCE values\ntest['AVG_EXT'] = test.iloc[:, 41:44].sum(axis=1)/(3- test.iloc[:,41:44].isnull().sum(axis=1))\ntest.EXT_SOURCE_1.fillna(test.AVG_EXT, inplace=True)\ntest.EXT_SOURCE_2.fillna(test.AVG_EXT, inplace=True)\ntest.EXT_SOURCE_3.fillna(test.AVG_EXT, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#percentage of days employed \ntest['EmpAge_RATIO'] = test['DAYS_EMPLOYED'] / test['AGE']\n\n#create credit/income ratio \ntest['CredInc_RATIO'] = test['AMT_CREDIT'] / test['AMT_INCOME_TOTAL']\n\n#create annuity to income ration\ntest['AnnInc_RATIO'] = test['AMT_ANNUITY'] / test['AMT_INCOME_TOTAL']\n\n#create credit/annuity ratio \ntest['AnnCred_RATIO'] = test['AMT_ANNUITY'] / (test['AMT_CREDIT'] + 1)\n\n#create credit/cost of goods ratio feature\ntest['CredGoods_RATIO'] = test['AMT_CREDIT'] / (test['AMT_GOODS_PRICE'] + 1)\n\n\ntest['AVG_EXT_INCOME'] = test['AMT_INCOME_TOTAL'] * test['AVG_EXT']\ntest['AVG_EXT_GOODS'] = test['AMT_GOODS_PRICE'] * test['AVG_EXT']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dels = ['APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', \n        'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', \n        'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', \n        'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', \n        'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', \n        'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI',\n        'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', \n        'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', \n        'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', \n        'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'FLAG_DOCUMENT_2', \n        'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5',\n        'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', \n        'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', \n        'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', \n        'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', \n        'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', \n        'FLAG_DOCUMENT_21', 'DAYS_BIRTH', 'LIVINGAPARTMENTS_AVG', \n        'LIVINGAREA_AVG', 'CNT_FAM_MEMBERS',  'OBS_30_CNT_SOCIAL_CIRCLE',\n        'OBS_60_CNT_SOCIAL_CIRCLE', 'ELEVATORS_AVG', 'AVG_EXT']\n\n\ntest = test.drop(test[dels], axis =1)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.replace([np.inf, -np.inf], np.nan)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = preprocessor.transform(test)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Predictions","metadata":{}},{"cell_type":"code","source":"test_pred = LGBM_model.predict_proba(X_test)\nprint(test_pred.shape)\nprint(test_pred[:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/home-credit-default-risk/sample_submission.csv')\nsubmission.head(10)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.TARGET = test_pred[:,1]   # replace the default values with our predictions\nsubmission.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('default_submission_wk06.csv', index=False, header = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}