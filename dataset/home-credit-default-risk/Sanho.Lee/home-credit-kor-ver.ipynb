{"cells":[{"metadata":{},"cell_type":"markdown","source":"* 본 커널은 다음 커널을 참조하여, 공부를 위한 목적으로 따라 쓴 커널임.\n* It is referenced by the kernel down below for study.\n\nhttps://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## 사용할 모듈 불러오기."},{"metadata":{"trusted":true},"cell_type":"code","source":"# numpy and pandas for data manipulation\nimport pandas as pd\nimport numpy as np\n\n# sklearn preprocessing for dealing with categorical variables\nfrom sklearn.preprocessing import LabelEncoder\n\n# File system management\nimport os\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 데이터 읽어들이기\n\n먼저, 사용가능한 모든 파일을 리스트 업 해본다. 9개의 파일이 있으며,각각 1개씩 훈련, 테스트 파일이 있다. 또한, 제출 예시 파일과 6개의 피쳐 내용이 들어있는 파일이 있음."},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of files available.\nprint(os.listdir('../input/home-credit-default-risk/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training data\napp_train = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\nprint('Training data shape : ', app_train.shape)\napp_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"훈련데이터에는 307511개의 각각 론을 한 사람에대해 데이터를 가지고 있으며, 122개의 피쳐 컬럼을 보여준다. 피쳐가 완전 많네."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing data features\napp_test = pd.read_csv('../input/home-credit-default-risk/application_test.csv')\nprint('Testing data shape : ', app_test.shape)\napp_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"테스트 파일은 훈련 파일에 비해 상당히 데이터 수는 작다. \n`Target`컬럼이 빠져있는 것이 특징. 컬럼수가 121인 것에 주목!"},{"metadata":{},"cell_type":"markdown","source":"## EDA(Exploratory Data Analysis)"},{"metadata":{},"cell_type":"markdown","source":"EDA를 통해서 데이터들의 통계적인 추이, 데이터 간의 관계 및 어떤 패턴들을 파악할 수 있다.\n목표는, 데이터들이 어떤 것들을 얘기하고 있는지 파악하는 것이며, 전체적인 추이를 먼저 확인하고, 점점 좁혀 나가는 순으로 하는것이 좋다.\n데이터들의 어떤 패턴을 파악하면, 모델을 선택하는데 도움을 줄 수 있고, 어떤 피쳐들을 사용할 지 결정할 수 있도록 해준다."},{"metadata":{},"cell_type":"markdown","source":"### Examine the Distribution of the Target Column"},{"metadata":{},"cell_type":"markdown","source":"타켓은 론에 대해서 대상자가 론을 모두 상환 할 것인지 아닌지를 바이너리 분류로 0 또는 1로 나타내고 있다.\n\n0이 모두 정해진 기간내에 정상 상환하는 경우\n\n1의 경우는 상환하지 못하는 경우를 나탐냄!\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train['TARGET'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"그래도 정상 상환 하는 경우(0이 나오는 숫자)가 훨씬 많네."},{"metadata":{},"cell_type":"markdown","source":"히스토그램으로 두 데이터를 시각화 해보자!"},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train['TARGET'].astype(int).plot.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> From this information, we see this is an imbalanced class problem. There are far more loans that were repaid on time than loans that were not repaid. Once we get into more sophisticated machine learning models, we can weight the classes by their representation in the data to reflect this imbalance."},{"metadata":{},"cell_type":"markdown","source":"### Examine Missing value\n\n이제 각 컬럼의 missing value의 수와 그 퍼센티지를 확인해보자."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total missing values\nmis_val = app_train.isnull().sum()\n\n# Percentage of missing values\nmis_val_percent = 100 * mis_val / len(app_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(app_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mis_val_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename the columns\nmis_val_table_ren_columns = mis_val_table.rename(\n    columns = {\n        0:'Missing Values',\n        1:'% of Total Values'\n    }\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort the table by percentage of missing descending\nmis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n'% of Total Values', ascending=False).round(1)\n\n# Print some summary information\nprint('Your selected dataframe has ' + str(app_train.shape[1]) + ' columns.\\n''There are '+str(mis_val_table_ren_columns.shape[0]) + ' columns that have missing values'\n     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위의 과정을 함수화 하여 다시 표현한다!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values_table(df):\n    \"\"\"\n    param : \n        df : pandas DataFrame data, processing target dataframe.\n    Return :\n        mis_val_table_ren_columns : pandas DataFrame , \n        column data extracted from df that has null data\n    \"\"\"\n    # Total missing values\n    mis_val = df.isnull().sum()\n    \n    # Percentage of missing values\n    mis_val_percent = 100 * mis_val / len(df)\n    \n    # Make a table with the results / concat은 지정 데이터를 합쳐준다.\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    \n    # Rename the columns\n    mis_val_table_ren_columns = mis_val_table.rename(columns={\n        0:'Missing Values',\n        1:'% of Total Values'\n    })\n    \n    # Sort the table by percentage of missing descending\n    mis_val_table_ren_columns=mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:,1]!=0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n    \n    # Print some summary information\n    print('You selected dataframe has '+str(df.shape[1])+' columns.\\n'\n    'There are '+str(mis_val_table_ren_columns.shape[0])+' columns that have missing values.')\n    \n    # Return the dataframe with missing information\n    return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values statistics\nmissing_values = missing_values_table(app_train)\nmissing_values.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> When it comes time to build our machine learning models, we will have to fill in these missing values (known as imputation). In later work, we will use models such as XGBoost that can handle missing values with no need for imputation. Another option would be to drop columns with a high percentage of missing values, although it is impossible to know ahead of time if these columns will be helpful to our model. Therefore, we will keep all of the columns for now."},{"metadata":{},"cell_type":"markdown","source":"머신러닝 모델을 만드는데 있어서, 이런 눌 데이터를 채워야 한다.(imputation?)\n나중에 우리는 XGBoost 같은 것을 사용해서 눌 데이터에 대한 imputation 할 필요가 없다?\n또 다른 하나의 옵션으로는 눌 데이터가 많은 컬럼을 아예 삭제(드랍) 해버리는 방법인데, 이런 컬럼이 중요하지 않다는 것을 확인하기 어렵기 때문에, 일단 여기서는 다 남겨 놓고 진행한다."},{"metadata":{},"cell_type":"markdown","source":"### Column Types\n\n각 데이터 타입에 따른 컬럼의 숫자를 확인한다. `int64`, `float64`는 수치적인 값을 나타낸다(연속적 또는 불연속적일 수 있음). 객체(object) 컬럼은 문자열 그리고 카테고리컬 피쳐 내용을 가지고 있음."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of each type of column\napp_train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"이제, 객체 내용을 가지는 특별한 컬럼의 데이터를 살표본다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of unique classes in each object column\napp_train.select_dtypes('object').apply(pd.Series.nunique, axis=0)\n# pd.Series.nunique 메소드는 각 카테고리 컬럼의 데이터를 분류하는 분류자 수를 반환함 // 아래 참조","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 실제 이렇게 데이터 타입을 선택해서 출력해보면, 각 컬럼별로 어떤 종류의 분류자로 분류 되는지 볼 수 있고, \n# nunique는 기본적으로 null데이터는 제외하고 분류자 갯수를 반환해준다.\napp_train.select_dtypes('object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"기관 분류인 `ORGANIZATION_TYPE` 이 가장 많은 분류자를 가지고 있다."},{"metadata":{},"cell_type":"markdown","source":"### Encoding Categorical Variables"},{"metadata":{},"cell_type":"markdown","source":"카테고리 변수들은 문자열 등으로 이루어 져 있기 때문에, 모델에 바로 적용 할 수 없다.\n\n그래서, 이런 변수들을 수치적으로 encoding 해줘야 하는데 다음 두가지 방법을 활용 할 수 있다.\n"},{"metadata":{},"cell_type":"markdown","source":"1. Label encoding :\n\n각 분류자 별로 정수값을 할당해서 분류한다. 즉, 새로운 컬럼을 만들 필요없이 해당 분류에 맞는 정수값을 할당해서 바꿔주면 됨\n![image.png](attachment:image.png)","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{},"cell_type":"markdown","source":"2. One-hot encoding : \n\n한 id 별로 분류장의 컬럼을 모두 생성해서, 해당되는 컬럼에 1을 할당하고,\n나머지 컬럼에는 0을 할당하는 방식, 이렇게 하면 컬럼은 많아 지기 때문에 엄청 데이터양이 커지는 것 같음.\n근데 구분하기에는 좋은거 같음\n![image.png](attachment:image.png)","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{},"cell_type":"markdown","source":"* 참고사항 : 라벨 인코딩 vs. 원-핫 인코딩에 대한 설명 \n\n\n>The problem with label encoding is that it gives the categories an arbitrary ordering. The value assigned to each of the categories is random and does not reflect any inherent aspect of the category. In the example above, programmer recieves a 4 and data scientist a 1, but if we did the same process again, the labels could be reversed or completely different. The actual assignment of the integers is arbitrary. Therefore, when we perform label encoding, the model might use the relative value of the feature (for example programmer = 4 and data scientist = 1) to assign weights which is not what we want. If we only have two unique values for a categorical variable (such as Male/Female), then label encoding is fine, but for more than 2 unique categories, one-hot encoding is the safe option.\n\n>There is some debate about the relative merits of these approaches, and some models can deal with label encoded categorical variables with no issues. Here is a good Stack Overflow discussion. I think (and this is just a personal opinion) for categorical variables with many classes, one-hot encoding is the safest approach because it does not impose arbitrary values to categories. The only downside to one-hot encoding is that the number of features (dimensions of the data) can explode with categorical variables with many categories. To deal with this, we can perform one-hot encoding followed by PCA or other dimensionality reduction methods to reduce the number of dimensions (while still trying to preserve information).\n\n>In this notebook, we will use Label Encoding for any categorical variables with only 2 categories and One-Hot Encoding for any categorical variables with more than 2 categories. This process may need to change as we get further into the project, but for now, we will see where this gets us. (We will also not use any dimensionality reduction in this notebook but will explore in future iterations).\n\n\n즉, 카테고리 분류에서 분류자가 2개 이상이면, 원-핫 인코딩을 쓰고, 2개일경우는 라벨인코딩으로 진행한다.\n\n2개일경우에만 라벨인코딩을 쓰는 이유는, 2개 이상일 때 라벨 인코딩을 쓰면 임의적인 순서를 부여하는 것이기 때문에 어떤 분류자에 대한 특정 가중치가 가해지는 효과? 가 생기는 것으로 생각되므로, 2개 이상의 분류자를 가질 때는 원-핫 인코딩을 쓰는게 좋다.\n\n하지만 안좋은 점은 분류자 수만큼 컬럼이 증가하기 때문에 엄청난 양의 데이터가 생성된다는 점만 빼면 원-핫 인코딩이 훨씬 좋다고 함."},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding and One-Hot Encoding"},{"metadata":{},"cell_type":"markdown","source":"그래서, 카테고리 데이터의 dtype==object 이면서 분류자가 2개이면 label encoding을 사용!\n\n분류자가 2개이상의 경우에는 one-hot encoding을 채용해서 사용함.\n\n라벨 인코딩에서는 Scikit-Learn `LabelEncoder`을 사용하고,\none-hot encoding 에서는 pandas 의  `get_dummies(df)` 함수를 사용한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a label encoder object.\nle = LabelEncoder()\nle_count = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterate through the columns\nfor col in app_train:\n    if app_train[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        if len(list(app_train[col].unique())) <= 2:\n            \n            # Train on the training data\n            le.fit(app_train[col])\n            # Transform both Training and Testing data\n            app_train[col] = le.transform(app_train[col])\n            app_test[col] = le.transform(app_test[col])\n            \n            print('%s is processed !' % col)\n            # Keep track of how many columns label encoded\n            le_count +=1            \n            \nprint('%d columns were label encoded' % le_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train[['FLAG_OWN_REALTY','FLAG_OWN_CAR','NAME_CONTRACT_TYPE']].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"라벨 인코딩 된걸 확인할 수 있다"},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot encoding of categorical variables\napp_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\n\nprint('Training Feature shape', app_train.shape)\nprint('Testing Feature shape', app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Aligning Training and Testing Data\n\n일단, 트레이닝/테스팅 컬럼 수 차이가 타겟 컬럼 하나만 나는게 정상인데, 현재 데이터를 보면 차이가 있다. "},{"metadata":{},"cell_type":"markdown","source":"> There need to be the same features (columns) in both the training and testing data. One-hot encoding has created more columns in the training data because there were some categorical variables with categories not represented in the testing data. To remove the columns in the training data that are not in the testing data, we need to align the dataframes. First we extract the target column from the training data (because this is not in the testing data but we need to keep this information). When we do the align, we must make sure to set axis = 1 to align the dataframes based on the columns and not on the rows!\n\n테스트 데이터에는 없는 컬럼데이터(카테고리 데이터)가 트레이닝 데이터에 있기 때문에 차이가 나는데, 그 컬럼들을 제거 해주는 게 좋다.\n\n즉, 트레이닝에만 있는 컬럼들을 삭제해서, 테스트 데이터와 align 해줘야 한다는 말!\n\n먼저, 트레이닝 데이터를 가공해야되는데, 타겟데이터를 살려두기 위해서 따로 저장해놓자!\n\n주의할 점은 axis=1의 컬럼데이터를 가공해야하는 점!, axis=0의 경우에는 row 데이터를 나타냄!"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels=app_train['TARGET']\n\n# Align the training and testing data, keep only columns present in both dataframes\napp_train, app_test = app_train.align(app_test, join='inner', axis=1)\n\n# Add the target back in\napp_train['TARGET'] = train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Feature shape', app_train.shape)\nprint('Testing Feature shape', app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"app_test 컬럼에 맞춰서 app_train 데이터의 컬럼수를 맞췄다!"},{"metadata":{},"cell_type":"markdown","source":"> The training and testing datasets now have the same features which is required for machine learning. The number of features has grown significantly due to one-hot encoding. At some point we probably will want to try dimensionality reduction (removing features that are not relevant) to reduce the size of the datasets.\n\n원래 app_train 데이터의 컬럼수가 122개 였는데, 엄청 늘었네. one-hot encoding으로 240개 까지 늘었다.\n\n영향이 적은 내용들에 대해서는 차원을 줄이기 위해서 골라낼 필요가 있다."},{"metadata":{},"cell_type":"markdown","source":"### Back to Exploratory Data Analysis\n\nAnomalies(변칙적인, 이례적인 내용들)"},{"metadata":{},"cell_type":"markdown","source":"> One problem we always want to be on the lookout for when doing EDA is anomalies within the data. These may be due to mis-typed numbers, errors in measuring equipment, or they could be valid but extreme measurements. One way to support anomalies quantitatively is by looking at the statistics of a column using the describe method. The numbers in the DAYS_BIRTH column are negative because they are recorded relative to the current loan application. To see these stats in years, we can mutliple by -1 and divide by the number of days in a year:\n\n\n데이터 값들 중에 이례적으로, 문제가 있는 값들을 찾아내야 한다. 타입이 잘못되거나, 측정이 잘못될수도 있고 여러가지 잘못된 경우가 있을 수 있다.\n\n그래서, 각 컬럼에 대해서 정량적으로 확인 해보는 것 이 좋은데, `describe` 메소드를 이용해서 정량적으로 데이터의 통계 데이터를 확인할 수 있다.\n\n`DAYS_BIRTH` 컬럼은 현재 론 대상자의 나이를 상대적으로 나타내기 때문에 음수로 표시되어 있다. 그러므로 -1을 곱해서 양수화 시키고 나이 값으로 변환해보자.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# original DAYS_BIRTH 데이터 값\napp_train[['DAYS_BIRTH']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(app_train['DAYS_BIRTH'] / (-365)).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"평균치랑 중간값(50%분위수)이 거의 근사한 수치를 가지며, 최대/최소값도 아웃라이어라고 판단되지는 않으며 크게 문제는 없는 것으로 판단된다!\n\n다음으로는, `DAYS_EMPLOYED` 수치를 확인해보자!"},{"metadata":{"trusted":true},"cell_type":"code","source":"(app_train['DAYS_EMPLOYED']).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"최소값이 일단, 음수이고, 최대값은 1000이며, 75% 분위수가 여전이 음수이다. 이상한 거 같다. \n\n그리고, 연(year) 수로 환산했는데, 1000년이 나왔으므로, 올바른 데이터는 아닌듯."},{"metadata":{"trusted":true},"cell_type":"code","source":"(app_train['DAYS_EMPLOYED']).plot.hist(title='Days Employment Histogram');\nplt.xlabel('Days Employment')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"전체 데이터 중에서 이례적인 데이터? 1000년이 넘는 고용기간으로 나오는 데이터?가 일반 데이터들의 통계 수치보다 높은지 낮은지 부분으로 떼어내서 살펴보자.\n즉, 정상인 데이터, 정상이 아닌 데이터!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DAYS_EMPLOYED 값이 최대값을 갖는 고객 데이터를 모두 가져와서 anom에 저장\nanom = app_train[app_train['DAYS_EMPLOYED']==365243]\n# DAYS_EMPLOYED 값이 최대값이 아닌 고객 데이터를 모두 가져옴!\nnon_anom = app_train[app_train['DAYS_EMPLOYED']!=365243]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The non-anomalies default on %0.2f%% of loans' % (100 * non_anom['TARGET'].mean()))\nprint('The anomalies default on %0.2f%% of loans' % (100 * anom['TARGET'].mean()))\nprint('There are %d anamalous days of employment' % len(anom))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Well that is extremely interesting! It turns out that the anomalies have a lower rate of default.\nHandling the anomalies depends on the exact situation, with no set rules. One of the safest approaches is just to set the anomalies to a missing value and then have them filled in (using Imputation) before machine learning. In this case, since all the anomalies have the exact same value, we want to fill them in with the same value in case all of these loans share something in common. The anomalous values seem to have some importance, so we want to tell the machine learning model if we did in fact fill in these values. As a solution, we will fill in the anomalous values with not a number (np.nan) and then create a new boolean column indicating whether or not the value was anomalous.\n\n\n디폴트 값, 즉 타겟값의 평균값이 이례적인 경우의 데이터가 더 작다. 즉 지정 시기에 돈을 모두 갚을 확률이 높다는 건데 음...여기서는 가장 안전화 데이터 가공 방법으로는, 이런 이례적인 데이터 들에 대해서\n\nmissing value 취급을 한다고 한다. 하지만 `np.nan`값으로 모두 채워준다고 한다. 그리고, boolean컬럼을 새로 만들어서 해당 고객 정보가 이례적인 데이터인지 아닌지를 알려주는 용도로 사용한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create anomalous flag column\n# 해당 데이터가 있는 곳엔 True를 반환해줌\napp_train['DAYS_EMPLOYED_ANOM'] = app_train['DAYS_EMPLOYED']==365243\n\n# Replace the anomalous values with nan\n# numpy의 nan을 사용, 사전형 형태로 데이터가 365243인 곳에 np.nan을 반환해줌!\napp_train['DAYS_EMPLOYED'].replace({365243:np.nan}, inplace=True)\n\n# 그럼 다시, 히스토그램을 그려서, 데이터의 가공 상태를 확인\napp_train['DAYS_EMPLOYED'].plot.hist(title='Days Employment Histogram after processing ANOM data');\nplt.xlabel('Days Employment');\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(app_train[['DAYS_EMPLOYED']] / (-365)).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"데이터를 가공하니 분포가 매끄럽게 자연스러워 졌다."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"테스트 데이터에도 똑같은 작업을 해줘야한다. 즉, 최대값을 먼저 같은지 확인해보고, 이례적인 데이터는 분류해서 nan값으로 채워준다."},{"metadata":{"trusted":true},"cell_type":"code","source":"app_test['DAYS_EMPLOYED'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"역시 트레이닝 데이터와 같게 이상치가 보인다."},{"metadata":{"trusted":true},"cell_type":"code","source":"app_test['DAYS_EMPLOYED_ANOM'] = app_test['DAYS_EMPLOYED'] == 365243\napp_test['DAYS_EMPLOYED'].replace({365243:np.nan}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are %d anomalies in the test data out of %d entries' % \n      (app_test['DAYS_EMPLOYED_ANOM'].sum(), len(app_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`DAYS_EMPLOYED_ANOM`의 TRUE값을 다 더하게 되면 9274개가 나옴을 확인할 수 있다."},{"metadata":{"trusted":true},"cell_type":"code","source":"app_test[app_test['DAYS_EMPLOYED']==365243]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`DAYS_EMPLOYED == 365243` 이 참인 곳은 위와 같이 데이터가 없음을 확인가능!"},{"metadata":{},"cell_type":"markdown","source":"### Correlations"},{"metadata":{},"cell_type":"markdown","source":">Now that we have dealt with the categorical variables and the outliers, let's continue with the EDA. One way to try and understand the data is by looking for correlations between the features and the target. We can calculate the Pearson correlation coefficient between every variable and the target using the .corr dataframe method.\nThe correlation coefficient is not the greatest method to represent \"relevance\" of a feature, but it does give us an idea of possible relationships within the data. Some general interpretations of the absolute value of the correlation coefficent are:\n\n* .00-.19 “very weak”\n* .20-.39 “weak”\n* .40-.59 “moderate”\n* .60-.79 “strong”\n* .80-1.0 “very strong”"},{"metadata":{},"cell_type":"markdown","source":"데이터 간의 상관관계를 피어슨계수를 통해서 확인 할 수 있으며, `corr` 메소드를 이용함.\n\n1에 가까운 수치는 Positive 상관관계 / -1에 가까운 수치는 Negative 상관관계를 가짐.\n\n0이 되면 상관관계가 없다고 판단하면 됨"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 먼저 전체적인 코릴레이션 계수를 이렇게 출력할 수 있다. 디폴트는 피어슨 방법으로 코릴레이션 함\ncorrmat = app_train.corr()\ncorrmat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위 수치들을 heatmap을 통해서 시각화 된 데이터를 확인한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(20,15))\nsns.heatmap(corrmat, vmax=1.0, square=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"컬럼 수가 너무 많아서 이건 못본다. 패스!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find correlations with the target and sort\ncorrmat = corrmat['TARGET'].sort_values()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display correlations\nprint('Most Positive Correlations : \\n', corrmat.tail(15))\nprint('\\n')\nprint('Most Negative Correlations : \\n', corrmat.head(15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let's take a look at some of more significant correlations: the DAYS_BIRTH is the most positive correlation. (except for TARGET because the correlation of a variable with itself is always 1!) Looking at the documentation, DAYS_BIRTH is the age in days of the client at the time of the loan in negative days (for whatever reason!). The correlation is positive, but the value of this feature is actually negative, meaning that as the client gets older, they are less likely to default on their loan (ie the target == 0). That's a little confusing, so we will take the absolute value of the feature and then the correlation will be negative.\n\n내가 이해하기론, 다음과 같다. 일단, 문서상 DAYS_BIRTH 는 대출 당시 고객의 연령을 의미한다.\n\nPositive 수치가 높다는 의미는 즉, 해당 feature 값이 증가함에 따라 타겟 값도 증가한다. 즉, feature값의 증가함에 따라 대출을 상환 하지 못할 것이다 라는 확률이 높아지는 경우다.\n\n근데, 여기서 Correlation한 결과 DAYS_BIRTH 항목이 Positive 수치가 가장 높은데, 사실 'DAYS_BIRTH'는 음수를 가지는 항목이며, 음수가 커질수록 대출 당시 고객 연령이 많은 사람 이라는 의미를 나타낸다.\n\n하지만 음수, 양수를 모두 고려하여 증가하는 방향으로 계산했다면 0에 가까운 수, 즉 절대값이 작은 수로 갈수록 TARGET 값이 1에 가까워진다는 것을 의미하므로, 대출 당시 고객의 연령이 어린 고객일수록 상환하지 못하는 확률이 높아진다는 판단을 할 수있다. \n\n이 내용을 절대치? 를 통해서 다시 확인해 보면, 음의 상관관계가 나올 수 있을 것이다~ 즉, 나이가 많은 고객일 수록 상환 가능한 확률이 높아질 것이다 라는 상관관계를 지금부터 확인하는듯!"},{"metadata":{},"cell_type":"markdown","source":"### Effect of Age on Repayment"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the correlation of the positive days since birth and target\napp_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\napp_train['DAYS_BIRTH'].corr(app_train['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"예상한 바와 같이, 음수의 상관관계가 나왔다.\n\n즉, 고객 나이가 많을 수록, 타겟은 0에 가까워 지는 선형관계를 가짐을 알 수 있다. 그리고, 그 말은 나이가 많을 수록 대출 상환을 제때 할 확률이 높아진다는 것을 의미한다.\n\n이제, 고객의 나이 분포에 대해 시각화 하여 히스토그램으로 플랏해보자."},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train['DAYS_BIRTH'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the style of plots\nplt.style.use('fivethirtyeight')\n\n# Plot the distribution of ages in years\nplt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins=25) # bins 옵션은 몇개의 막대로 표현할지 정해줌\nplt.title('Age of Client')\nplt.xlabel('Age (years)')\nplt.ylabel('Count')           \n           ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> By itself, the distribution of age does not tell us much other than that there are no outliers as all the ages are reasonable. To visualize the effect of the age on the target, we will next make a kernel density estimation plot (KDE) colored by the value of the target. A kernel density estimate plot shows the distribution of a single variable and can be thought of as a smoothed histogram (it is created by computing a kernel, usually a Gaussian, at each data point and then averaging all the individual kernels to develop a single smooth curve). We will use the seaborn kdeplot for this graph.\n\n이 자체로는, 아웃라이어가 없다는것 이상으로 무언가 말해줄수는 없으며, 그래프 분포는 이상적인거 같다.\n\n이제 고객 나이에 따른 타겟의 영향정도를 확인하기 위해, KDE를 사용해서 타겟의 영향도를 시각화 해본다.\n\n이 과정에서 seaborn의 `kdeplot` 메소드를 활용한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\n\n# KDE plot of loans that were repaid on time\nsns.kdeplot(app_train.loc[app_train['TARGET']==0, 'DAYS_BIRTH'] / 365, label='target == 0')\n\n# KDE plot of loans which were not repaid on time\nsns.kdeplot(app_train.loc[app_train['TARGET']==1, 'DAYS_BIRTH'] / 365, label='target == 1')\n\n# Labeling of plot\nplt.xlabel('Age (years)')\nplt.ylabel('Density')\nplt.title('Distribution of Ages')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The target == 1 curve skews towards the younger end of the range. Although this is not a significant correlation (-0.07 correlation coefficient), this variable is likely going to be useful in a machine learning model because it does affect the target. Let's look at this relationship in another way: average failure to repay loans by age bracket.\nTo make this graph, first we cut the age category into bins of 5 years each. Then, for each bin, we calculate the average value of the target, which tells us the ratio of loans that were not repaid in each age category.\n\ntarget == 1 그래프는 확실히 나이가 어린 쪽으로 더 뾰족한 부분이 쏠려있다.\n\n하지만 그렇게 큰 상관계수(-0.07)는 아니다. 그래도 머신러닝에 사용하기에는 유용하다고 생각 된다.\n\n조금 다른 방법으로 관계를 살펴볼려고 한다. average failure to repay loans by age bracket. 즉 나이를 버켓에 담아서 조각조각 나눠서 보겟다는 뜻.\n\n즉, 5살 단위로 나이 분포를 나눠서 각 버켓별로 타겟의 평균값을 살펴본다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age information into a separate dataframe\nage_data = app_train[['TARGET', 'DAYS_BIRTH']]\nage_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365\n\n# Bin the age data\nage_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins=np.linspace(20,70, num=11))\nage_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.linspace(20,70, num=11) # 처음 수, 끝 수, 총 숫자 수=11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group by the bin and calculate averages\nage_groups = age_data.groupby('YEARS_BINNED').mean()\nage_groups","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"확실히, 나이가 많은 그룹일수록 타겟 평균값이 점점 작아지는 것을 확인 할 수 있다.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"age_groups.index.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\n\n# Graph the age bins and the average of the target as a bar plot\nplt.bar(age_groups.index.astype(str), 100 * age_groups['TARGET'] )\n\n# Plot labeling\nplt.xticks(rotation = 75)\nplt.xlabel('Age Group (years)')\nplt.ylabel('Failure to Repay (%)')\nplt.title('Failure to Repay by Age Group');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">There is a clear trend: younger applicants are more likely to not repay the loan! The rate of failure to repay is above 10% for the youngest three age groups and beolow 5% for the oldest age group.\nThis is information that could be directly used by the bank: because younger clients are less likely to repay the loan, maybe they should be provided with more guidance or financial planning tips. This does not mean the bank should discriminate against younger clients, but it would be smart to take precautionary measures to help younger clients pay on time.\n\n"},{"metadata":{},"cell_type":"markdown","source":"어린 고객이 명백하게 상환하지 못할 확률이 크다는 것을 보여주고 있다.\n\n그래서 은행에서는 어린 고객에게 론에 대한 신청 등이 있으면, 주의사항이나 안내를 더 잘 해야 될 것이라고 말하고 있네. 맞는 듯."},{"metadata":{},"cell_type":"markdown","source":"### Exterior Sources\n"},{"metadata":{},"cell_type":"markdown","source":"타겟과 음의 관계를 갖는 항목중에 가장 높은 수치를 보이는 항목에 대해서 살펴본다.\n\nEXT_SOURCE_1, EXT_SOURCE_2, EXT_SOURCE_3 요렇게 세갠데 도큐먼트 설명에 의하면,\n\n이 항목들은 외부요인에 의해 일반화된 데이터 소스라고 함. 뭔지는 잘 모르겠지만 누적된 신용정보? 정도로 이해하면 될 것 같다.\n\n먼저, 이런 항목들과 타겟간의 상관관계를 찾아보자!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the EXT_SOURCE variables and show correlations\next_data = app_train[['TARGET', 'EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','DAYS_BIRTH']]\next_data_corrs = ext_data.corr()\next_data_corrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\n\n# Heatmap of correlations\nsns.heatmap(ext_data_corrs, cmap=plt.cm.RdYlBu_r, vmin=-0.25, annot=True, vmax=0.6)\nplt.title('Correlation Heatmap');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EXT 변수들은 타겟과 음의 상관관계를 갖는 것을 확인할 수 있으며, EXT 변수값이 증가하면, 고객들이 대출상환 할 확률이 높음을 의미한다.\n\n또한, EXT 1 변수와 DAYS_BIRTH가 양의 상관관계를 가지고 있는 것을 확인할 수 있다.\n이것은, EXT 1 변수가 나이를 나타내는 어떤 스코어 일 것으로 추정된다.\n\n이제 이 변수들과 타겟간의 분포를 시각화 해서 살펴 본다.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,12))\n\n# iterate through the sources\nfor i, source in enumerate(['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']):\n    \n    # create a new subplot for each source\n    plt.subplot(3,1,i+1) # 3 행 1열 모양으로 잡고, 각 순서대로 플랏 함\n    # plot repaid loans\n    sns.kdeplot(app_train.loc[app_train['TARGET']==0,source], label='target == 0')\n    # plot loans that were not repaid\n    sns.kdeplot(app_train.loc[app_train['TARGET']==1,source], label='target == 1')\n    \n    plt.title('Distribution of %s by Target Value' % source)\n    plt.xlabel('%s' % source)\n    plt.ylabel('Density');\n\nplt.tight_layout(h_pad = 2.5)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EXT_SOURCE_3은 타겟에 따른 분포가 현저하게 다른 것을 볼 수 있으며, 이런 항목들은 대출상환 가능성과의 상관관계를 가지고 있다고 확실히 판단할 수 있다.\n\n근데, 사실 이정도 수치는 상관관계 수치가 약한 거라고 한다.\n그래도 머신러닝에 사용하는데 있어서는 유용한 정보이기 때문에 사용할 수도 있을 것 같다."},{"metadata":{},"cell_type":"markdown","source":"### Pairs Plot"},{"metadata":{},"cell_type":"markdown","source":">As a final exploratory plot, we can make a pairs plot of the EXT_SOURCE variables and the DAYS_BIRTH variable. The Pairs Plot is a great exploration tool because it lets us see relationships between multiple pairs of variables as well as distributions of single variables. Here we are using the seaborn visualization library and the PairGrid function to create a Pairs Plot with scatterplots on the upper triangle, histograms on the diagonal, and 2D kernel density plots and correlation coefficients on the lower triangle.\nIf you don't understand this code, that's all right! Plotting in Python can be overly complex, and for anything beyond the simplest graphs, I usually find an existing implementation and adapt the code (don't repeat yourself)!"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"마지막 플랏 검토로, pairs plot 이란 것을 적용해볼거다. 즉, EXT_SOURCE - DAYS_BIRTH 변수간의 어떤 관계를 시각화 해서 보게 될 것이다. \n\nPairs Plot은 한가지 변수에 대한 분포 뿐만 아니라, 여러가지 멀티 variables 간의 관계를 확인하는 것도 가능하게 해준다.\n\nseaborn의 시각화 라이브러리와 `PairGrid` 함수를 이용해서 플랏 몇개를 그려볼 것이다.\n\n자세한 설명은 위의 원문 참조!\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy the ext_data for plotting\next_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data = ext_data.drop(columns=['DAYS_BIRTH']).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 데이터 컬럼 확인!\nplot_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add in the age of the client in years\nplot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']\n# Drop na values and limit to first 100000 rows\nplot_data = plot_data.dropna().loc[:100000, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data.shape\n# 전체 데이터 수 가 3분의 1로 줄었음.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate correlation coeffiecient between two columns\ndef corr_func(x,y, **kwargs):\n    r = np.corrcoef(x,y)[0][1]\n    ax = plt.gca()\n    ax.annotate('r = {:.2f}'.format(r),\n                xy=(.2, .8), xycoords=ax.transAxes,\n                size = 20\n               )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the pairgrid object\n# 플랏할 대상을 이 오브젝트에서 정의하고, 페어 플랏에서 대각선 , 대각선 위/아래 방향으로 원하는 플랏을 넣어줌\ngrid = sns.PairGrid(\n    data = plot_data,\n    size = 3,\n    diag_sharey=False,\n    hue='TARGET',\n    vars = [x for x in list(plot_data.columns) if x != 'TARGET']\n)\n# 여기 까지 하면 그래프를 그릴 수 있는 자리만 나옴!\n\n# Upper is a scatter plot\ngrid.map_upper(plt.scatter, alpha = 0.2)\n\n# Diagonal is a histogram\ngrid.map_diag(sns.kdeplot)\n\n# Bottom is density plot\ngrid.map_lower(sns.kdeplot, cmap=plt.cm.OrRd_r);\n\nplt.suptitle('Ext Source and Age Features Pairs Plot', size=32, y=1.05)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">In this plot, the red indicates loans that were not repaid and the blue are loans that are paid. We can see the different relationships within the data. There does appear to be a moderate positive linear relationship between the EXT_SOURCE_1 and the DAYS_BIRTH (or equivalently YEARS_BIRTH), indicating that this feature may take into account the age of the client.\n\n\n빨간색은 대출상환 x, 파란색은 대출상황 o을 의미한다.\n\nEXT_SOURCE_1 , YEARS_BIRTH는 선형적인 관계를 가진다고 볼 수 있으며, 역시나 나이가 많아짐에 따라 파란색 점이 많아지는 것을 알수 있다."},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":">Kaggle competitions are won by feature engineering: those win are those who can create the most useful features out of the data. (This is true for the most part as the winning models, at least for structured data, all tend to be variants on gradient boosting). This represents one of the patterns in machine learning: feature engineering has a greater return on investment than model building and hyperparameter tuning. This is a great article on the subject). As Andrew Ng is fond of saying: \"applied machine learning is basically feature engineering.\"\n\n모델 빌딩하고, 하이퍼파라미터 튜닝하는 것보다 결국은 feature engineering을 어떻게 하는지가 더 중요하고, 컴페티션 결과에 큰 영향을 미친다!\n\n>While choosing the right model and optimal settings are important, the model can only learn from the data it is given. Making sure this data is as relevant to the task as possible is the job of the data scientist (and maybe some automated tools to help us out).\n\n반면에 좋은모델을 잘 선택하고 셋팅을 최적화 하는것도 중요하다. 모델은 주어지는 데이터만 가지고 학습을 할 수 있기 때문.\n\n>Feature engineering refers to a geneal process and can involve both feature construction: adding new features from the existing data, and feature selection: choosing only the most important features or other methods of dimensionality reduction. There are many techniques we can use to both create features and select features.\n\nfeature engineering은 일반적인 과정이며, `feature construction`, `feature selection` 두가지 과정을 모두 포함한다.\n\n* feature construction: adding new features from the existing data\n* feature selection: choosing only the most important features or other methods of dimensionality reduction.\n\n\n많은 feature engineering 방법이 있지만 이 커널에서는 다음의 간단한 feature construction 과정만 해본다.\n* Polynomial features\n* Domain knowledge features\n\n\n\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Polynomial Features"},{"metadata":{},"cell_type":"markdown","source":"> One simple feature construction method is called polynomial features. In this method, we make features that are powers of existing features as well as interaction terms between existing features. For example, we can create variables EXT_SOURCE_1^2 and EXT_SOURCE_2^2 and also variables such as EXT_SOURCE_1 x EXT_SOURCE_2, EXT_SOURCE_1 x EXT_SOURCE_2^2, EXT_SOURCE_1^2 x EXT_SOURCE_2^2, and so on. These features that are a combination of multiple individual variables are called interaction terms because they capture the interactions between variables. In other words, while two variables by themselves may not have a strong influence on the target, combining them together into a single interaction variable might show a relationship with the target. Interaction terms are commonly used in statistical models to capture the effects of multiple variables, but I do not see them used as often in machine learning. Nonetheless, we can try out a few to see if they might help our model to predict whether or not a client will repay a loan.\nJake VanderPlas writes about polynomial features in his excellent book Python for Data Science for those who want more information.\nIn the following code, we create polynomial features using the EXT_SOURCE variables and the DAYS_BIRTH variable. Scikit-Learn has a useful class called PolynomialFeatures that creates the polynomials and the interaction terms up to a specified degree. We can use a degree of 3 to see the results (when we are creating polynomial features, we want to avoid using too high of a degree, both because the number of features scales exponentially with the degree, and because we can run into problems with overfitting).\n\n간단하게 말해서, 이건 기존의 존재한 변수에 대해서, 서로 곱하거나 제곱을 하거나, 제곱한것에 대해서 서로 곱하거나 해서 새로운 변수를 생성하는 방식이다.\n\n개개의 변수들이 타겟과의 관련이 없었더 하더라고 이런과정을 통해서 곱해진 새로운 변수가 타겟과의 관계성을 보여주는 경우가 있으므로, 이를 이용하려고 한다. Scikit-Learn의 클래스 PolynomialFeatures를 이용함!\n\n여기서 우리는 3차원 까지만 degree 정도? 를 부여하기로 한다. 차원수가 너무 높아지면 너무 복잡해질수도 있고, [오버피팅](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html#sphx-glr-auto-examples-model-selection-plot-underfitting-overfitting-py)이 되는 문제로 빠질수도 있기 때문이다.\n\n사용할 변수는, EXT_SOURCE 변수 3개와 DAYS_BIRTH 변수 이렇게 4개가 되겠다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a new dataframe for polynomial features\npoly_features = app_train[\n    ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','DAYS_BIRTH','TARGET']]\npoly_features_test = app_test[\n    ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','DAYS_BIRTH']]\n\n# imputer for handling missing values\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(strategy='median')\n\npoly_target = poly_features['TARGET']\npoly_features = poly_features.drop(columns=['TARGET'])\n\npoly_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Need to impute missing values\npoly_features = imputer.fit_transform(poly_features)\npoly_features_test = imputer.transform(poly_features_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"원래 NaN 이였던 데이터 들이 기존에 있는 데이터를 이용해서 채워 진 것을 확인 할 수 있다.\n\n훈련데이터와 테스트 데이터 둘다 데이터 프레임에서, ndarray 형태로 데이터 타입이 변했다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the polynomial object with specified degree\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly_transformer = PolynomialFeatures(degree=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the polynomial features\npoly_transformer.fit(poly_features)\n\n# Transform the features\npoly_features = poly_transformer.transform(poly_features)\npoly_features_test = poly_transformer.transform(poly_features_test)\nprint('Polynomial Features shape : ', poly_features.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"poly_features 컬럼 수는 원래 EXT 변수 3개와 DAYS_BIRTH 이렇게 4개 였는데 35개 까지 늘어났다.\n\n새로 생긴 polynomial 변수의 이름을 가져오기 위해 `get_feature_names`메소드를 이용한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 35개 변수 모두 출력함\npoly_transformer.get_feature_names(input_features=[\n    'EXT_SOURCE_1',\n    'EXT_SOURCE_2',\n    'EXT_SOURCE_3',\n    'DAYS_BIRTH'\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"최고 3승까지 제곱하여 변수를 만들고, 서로 곱하는 항까지 모두 만들어 냈다.\n\n이제, 이런 변수들이 타겟 변수와 어떤 관계가 있는지 확인한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe of the features\npoly_features = pd.DataFrame(poly_features, \n                             columns=poly_transformer.get_feature_names(input_features=[\n                                 'EXT_SOURCE_1',\n                                 'EXT_SOURCE_2',\n                                 'EXT_SOURCE_3',\n                                 'DAYS_BIRTH',\n                             ]))\n\n# Add in the target\n# 타겟값은 원래 이 데이터프레임에 있었는데, polynomial feature 만드느라고, 드랍시키고, 따로 새로운 변수에 저장중이였다.\n# 그 값을 다시 그대로 가져온다.\npoly_features['TARGET'] = poly_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the correlations with the target\npoly_corrs = poly_features.corr()['TARGET'].sort_values()\n\n# Display most negative and most positive\nprint(poly_corrs.head(10))\nprint(poly_corrs.tail(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"몇몇 새로운 변수들은 독립된 하나의 변수로써 상관관계보다 더 높은 수치를 보여주고 있다.\n\n우리는, 머신러닝 모델을 빌드할때 유용한지 여부에 따라 이런 변수들을 포함 또는 포함시키지 않을 수도 있다.\n\n이제, 모델을 평가할때 이런 feature를 포함 시킨 데이터와 그렇지 않은 데이터를 모델에 피드해서 결과가 어떤지 확인할 거다.\n\n머신러닝은 여러번 해봐야 함. Try!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Put test features into dataframe\nprint('Polynomial Features shape for test data : ', poly_features_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_features_test = pd.DataFrame(poly_features_test, \n                                  columns=poly_transformer.get_feature_names(input_features=[\n                                      'EXT_SOURCE_1',\n                                      'EXT_SOURCE_2',\n                                      'EXT_SOURCE_3',\n                                      'DAYS_BIRTH']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_features_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge polynomial featueres into training dataframe\npoly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\napp_train_poly = app_train.merge(poly_features, on='SK_ID_CURR', how='left')\n\n# Merge polynomial features into testing dataframe\npoly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\napp_test_poly = app_test.merge(poly_features_test, on='SK_ID_CURR', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Align the dataframes\napp_train_poly, app_test_poly = app_train_poly.align(\n    app_test_poly,\n    join='inner',\n    axis=1\n)\n\n# Print out the new shapes\nprint('Training data with polynomial features shape : ', app_train_poly.shape)\nprint('Testing data with polynomial features shape : ', app_test_poly.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"align 과정에서 join을 `inner`로 해서, 데이터 차원이 작은 방향으로 얼라인 되고,  app_train_poly의 TARGET 컬럼이 사라지지 않았을까 해서 아래와 같이 확인! , 머지 하면서 이름이 바뀐건지 안보인다. polynomial 변수들도 1차원 변수들의 이름이 바뀐건지 안보임"},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in app_train_poly.columns:\n    print(item)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DAYS_BIRTH_x,DAYS_BIRTH_y 로 변함.\n\nEXT_SOURCE_1_x\n\nEXT_SOURCE_2_x\n\nEXT_SOURCE_3_x\n\n나머지 것도 y항도 생겼음\n\n"},{"metadata":{},"cell_type":"markdown","source":"### Domain Knowledge Features\n"},{"metadata":{},"cell_type":"markdown","source":">Maybe it's not entirely correct to call this \"domain knowledge\" because I'm not a credit expert, but perhaps we could call this \"attempts at applying limited financial knowledge\". In this frame of mind, we can make a couple features that attempt to capture what we think may be important for telling whether a client will default on a loan. Here I'm going to use five features that were inspired by [this script](https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features) by Aguiar:\n>* CREDIT_INCOME_PERCENT: the percentage of the credit amount relative to a client's income\n* ANNUITY_INCOME_PERCENT: the percentage of the loan annuity relative to a client's income\n* CREDIT_TERM: the length of the payment in months (since the annuity is the monthly amount due\n* DAYS_EMPLOYED_PERCENT: the percentage of the days employed relative to the client's age\n\n>Again, thanks to Aguiar and [his great script](https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features) for exploring these features.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 새로운 컬럼을 만드는 과정, 기존에 있었던 컬럼들을 조합해서 유용한 정보를 가지는 텀들을 생성\n# annuity : 연금\napp_train_domain = app_train.copy()\napp_test_domain = app_test.copy()\n\napp_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\napp_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\napp_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\napp_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train_domain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\napp_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\napp_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\napp_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_test_domain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize New Variables\n\n시각화 해서 위에서 만든 domain knowledge변수들을 플랏해본다.\n\n모든 변수에 대해서, TARGET값을 [KDE(kernel density estimation plot) plot](https://en.wikipedia.org/wiki/Kernel_density_estimation)으로 표현할 거다."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,20))\n# iterate through the new features\nfor i, feature in enumerate(['CREDIT_INCOME_PERCENT','ANNUITY_INCOME_PERCENT','CREDIT_TERM','DAYS_EMPLOYED_PERCENT']):\n    \n    # create a new subplot for each source\n    plt.subplot(4,1,i+1)\n    # plot repaid loans\n    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 0, feature], label='target == 0')\n    # plot loans that were not repaid\n    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET'] == 1, feature], label='target == 1')\n    \n    # Label the plots\n    plt.title('Distribution of %s by Target Value' % feature)\n    plt.xlabel('%s' % feature); plt.ylabel('Density');\n\nplt.tight_layout(h_pad = 2.5)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"확실히 이 데이터가 유용한지는 말하기 어렵다고 함. 직접 모델에 사용해 봐야 알수 있는 듯."},{"metadata":{},"cell_type":"markdown","source":"## Baseline"},{"metadata":{},"cell_type":"markdown","source":">For a naive baseline, we could guess the same value for all examples on the testing set. We are asked to predict the probability of not repaying the loan, so if we are entirely unsure, we would guess 0.5 for all observations on the test set. This will get us a Reciever Operating Characteristic Area Under the Curve (AUC ROC) of 0.5 in the competition (random guessing on a classification task will score a 0.5).\nSince we already know what score we are going to get, we don't really need to make a naive baseline guess. Let's use a slightly more sophisticated model for our actual baseline: Logistic Regression."},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression Implementation"},{"metadata":{},"cell_type":"markdown","source":">Here I will focus on implementing the model rather than explaining the details, but for those who want to learn more about the theory of machine learning algorithms, I recommend both [An Introduction to Statistical Learning and Hands-On Machine Learning with Scikit-Learn and TensorFlow. Both of these books present the theory and also the code needed to make the models (in R and Python respectively). They both teach with the mindset that the best way to learn is by doing, and they are very effective!\nTo get a baseline, we will use all of the features after encoding the categorical variables. We will preprocess the data by filling in the missing values (imputation) and normalizing the range of the features (feature scaling). The following code performs both of these preprocessing steps.\n\n이제 모델 구성에 대해서 구체적으로 배워 볼 거고,\n\n데이터를 전처리하는 과정에 대해서도 해볼거다. 즉, missing value를 채우거나, 데이터를 정규화 하는 과정이 그에 포함된다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, Imputer\n\n# Drop the target from the training data\nif 'TARGET' in app_train:\n    train = app_train.drop(columns=['TARGET'])\nelse:\n    train = app_train.copy()\n\n# Feature names\nfeatures = list(train.columns)\n\n# Copy of the testing data\ntest = app_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Median imputation of missing values\nimputer = Imputer(strategy = 'median')\n\n# Scale each feature to 0-1\nscaler = MinMaxScaler(feature_range=(0,1))\n\n# Fit on the training data\n# fit 과정은 Imputer의 strategy를 `median`으로 했기 때문에, \n# 트레이닝 데이터를 기준으로 중간값? 을 찾아서 객체에 가지고 있을 것으로 유추할수? 있다.\nimputer.fit(train)\n\n# Transform both training and testing data\ntrain = imputer.transform(train)\ntest = imputer.transform(app_test)\n# 여기서 왠지모르겠지만 테스트 데이터는 원래 데이터를 그대로 사용? \n# 위에 먼저 만든 test 라는 값도 어차피 카피 한 것이기 때문에 값은 같겠지만, 튜토리얼에서 하는대로 일단 한다.\n# 이렇게 missing value를 채워준다.\n\n# Repeat with the scaler(0~1)\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\n\nprint('Training data shape : ', train.shape)\nprint('Testing data shape : ', test.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":">We will use LogisticRegressionfrom Scikit-Learn for our first model. The only change we will make from the default model settings is to lower the regularization parameter, C, which controls the amount of overfitting (a lower value should decrease overfitting). This will get us slightly better results than the default LogisticRegression, but it still will set a low bar for any future models.\nHere we use the familiar Scikit-Learn modeling syntax: we first create the model, then we train the model using .fit and then we make predictions on the testing data using .predict_proba (remember that we want probabilities and not a 0 or 1)."},{"metadata":{},"cell_type":"markdown","source":"데이터 정규화를 하게 되면 모델 예측시 오버피팅되는 것을 감소시킬수 있고, 현재 이 작업에서 데이터 셋의 차이점은 정규화 변수 C값이 작아진 것이라고 하는데, 잘 모르겠음.\n\n일단 모델을 만들어서 fit해보고, 예측 해본다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Make the model with the specified regularization parameter\nlog_reg = LogisticRegression(C=0.0001)\n\n# Train on the training data\n# train_labels값은 app_train['TARGET'] 을 할당한 변수임\nlog_reg.fit(train, train_labels)\n# (X, y) 형태로 데이터를 핏팅하고, 해당 모델이 이진 분류 문제로 적용되기 때문에, 예측되는 결과도 두가지 종류에 대해서 확률 값으로 반환된다.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">Now that the model has been trained, we can use it to make predictions. We want to predict the probabilities of not paying a loan, so we use the model predict.proba method. This returns an m x 2 array where m is the number of observations. The first column is the probability of the target being 0 and the second column is the probability of the target being 1 (so for a single row, the two columns must sum to 1). We want the probability the loan is not repaid, so we will select the second column.\n\n>The following code makes the predictions and selects the correct column.\n\n모델이 훈련이 되었고, 예측을 할거다.\n\n여기서 원하는 것은 대출을 상환하지 못하는 확률이다. \n\n예측을 진행하면, m x 2 형태로 어레이를 반환하게 되는데, m은 샘플 관찰수이며,\n\n첫번째 컬럼은 예측이 0이 될 확률, 두번째 컬럼은 예측이 1 이 될 활률.\n\n우리는, 상환하지 못할 확률을 알고 싶기 때문에 두번째 컬럼을 선택한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions\n# Make sure to select the second column only\n# input 은 테스트 데이터, 보고 싶은 데이터는 모든 행에 대하여 두번째 컬럼이다.\nlog_reg_pred = log_reg.predict_proba(test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"예측한 내용이, 제출포맷에 맞지 않기 때문에, 제출포맷에 맞게 설정한다. 그래서, 데이터프레임을 새로 생성!\n\n`sample_submission.csv`참고"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission dataframe\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET']=log_reg_pred\n\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">The predictions represent a probability between 0 and 1 that the loan will not be repaid. If we were using these predictions to classify applicants, we could set a probability threshold for determining that a loan is risky.\n\n여기서 확률은 대출을 상환하지못할 확률을 나타내고, 만약 대출대상에 대해서 이 예측결과를 사용한다고 했다면, 대출상환 여부에 대한 위험정도를 특정 임계치를 설정해서 판단할수 있었을 것이다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the submission to a csv file.\nsubmit.to_csv('log_reg_baseline.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">The submission has now been saved to the virtual environment in which our notebook is running. To access the submission, at the end of the notebook, we will hit the blue Commit & Run button at the upper right of the kernel. This runs the entire notebook and then lets us download any files that are created during the run.\nOnce we run the notebook, the files created are available in the Versions tab under the Output sub-tab. From here, the submission files can be submitted to the competition or downloaded. Since there are several models in this notebook, there will be multiple output files.\n\nThe logistic regression baseline should score around 0.671 when submitted."},{"metadata":{},"cell_type":"markdown","source":"일단 이렇게 커밋하면, 제출이 된다.\n\n참조한 커널에서는 0.671 점수를 받았다고 한다. 이제 직접 commit 해서 몇점이 나오는지 확인!\n\n* 실제로 public 점수로 0.67041이 나온다.\n\n모델을 개선해보자.\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Improved Model : Random Forest"},{"metadata":{},"cell_type":"markdown","source":">To try and beat the poor performance of our baseline, we can update the algorithm. Let's try using a Random Forest on the same training data to see how that affects performance. The Random Forest is a much more powerful model especially when we use hundreds of trees. We will use 100 trees in the random forest.\n\n기본셋팅(LogisticRegression)의 저조한 성능을 개선해보자, 알고리즘을 변경할 건데, Random Forest 알고리즘? 을 사용해서 성능에 어떤 영향이 있는지 동일한 데이터를 가지고 평가해보자.\n\nRandom Forest는 옵션중에 hundreds of trees를 사용할때 좋은 성능을 보여준다는데, 이건 모델 핏팅할때 옵션중에 하나 일 것 같다.\n\n[RandomForestClassifier 설명](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 대출상환 가능/불가능에 대한 분류 문제 이므로, classifier를 선택!\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Make random forest classifier\nrandom_forest = RandomForestClassifier(\n    n_estimators=100,\n    random_state=50,\n    verbose=1,\n    n_jobs=-1\n)\n# 일단 에스티메이터? 랜덤포레스트 알고리즘을 가지는 객체를 생성한거임","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train on the training data\nrandom_forest.fit(train,train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract feature importances\nfeature_importance_value = random_forest.feature_importances_ # np.ndarray 반환함\nfeature_importances = pd.DataFrame({'feature':features,'importance':feature_importance_value})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"feature별로 중요도가 어느 정도 되는지를, 트레이닝 데이터를 핏팅하면서 알아내줌"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions on test data\npredictions = random_forest.predict_proba(test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a submission dataframe\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the submission dataframe\nsubmit.to_csv('random_forest_baseline.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"참고 커널상의 예측 점수는 0.678이다.\n\n내 점수도 0.67877 이렇게 나왔다. 단지 랜덤포레스트로 예측 알고리즘? 을 바꾸서 모델성능을 개선하는데는 큰 효과는 없는 것 같다."},{"metadata":{},"cell_type":"markdown","source":"이제 가공한 데이터 셋을 대상으로 모델을 구성해서, 대출상환 가능여부를 예측해본다."},{"metadata":{},"cell_type":"markdown","source":"### Make Predictions using Engineered Features\n\n>The only way to see if the Polynomial Features and Domain knowledge improved the model is to train a test a model on these features! We can then compare the submission performance to that for the model without these features to gauge the effect of our feature engineering.\n\nPolynomial feature, Domain Knowledge feature를 직접 모델에 피딩해서 그 효과가 있는지 시험해보자.\n\n결과는, submission 점수를 보고 과연 이 feature들이 효과가 있는지 판단할 수 있을 것이다."},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_features_names = list(app_train_poly.columns)\n\n# Impute the polynomial features\nimputer = Imputer(strategy = 'median')\n\npoly_features = imputer.fit_transform(app_train_poly)\npoly_features_test = imputer.transform(app_test_poly)\n\n# Scale the polynomial features\nscaler = MinMaxScaler(feature_range=(0,1))\n\npoly_features = scaler.fit_transform(poly_features)\npoly_features_test = scaler.transform(poly_features_test)\n\nrandom_forest_poly = RandomForestClassifier(n_estimators=100, random_state=50, verbose=1, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train on the training data\n# 핏팅할때 훈련데이터의 타겟값, 즉 상환 여부에 대한 레이블 값은 어떤 피쳐를 사용하든, 알고리즘을 사용하든 같으므로,\n# 여기서도 train_labels을 사용함.\nrandom_forest_poly.fit(poly_features, train_labels)\n\n# Make predictions on the test data\npredictions = random_forest_poly.predict_proba(poly_features_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a submission dataframe\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\n# Save the submission datafrmae\nsubmit.to_csv('random_forest_baseline_engineered.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"참담한 결과다, public 점수는 0.60 대 까지 떨어졌다. 참고한 커널에서는0.678로 동등한 수준이 나왔다.\n\n내가 어딘가 틀린 조작을 했거나, 아무튼 polynomial feature는 큰 효과가 없다. 오히려 확률 정확도가 떨어진다."},{"metadata":{},"cell_type":"markdown","source":"### Testing Domain Feature\n\n이제 여러 변수를 조합해서 새로운 형태의 feature를 만들었던, domain feature에 대해서 테스트 해보자."},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train_domain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 입력데이터에서 타겟 컬럼을 분리한다.\napp_train_domain = app_train_domain.drop(columns='TARGET')\n\n# 도메인 피쳐 이름 생성, 리스트\ndomain_features_names = list(app_train_domain.columns)\n\n# Impute the domain nomial features\nimputer = Imputer(strategy = 'median')\n\ndomain_features = imputer.fit_transform(app_train_domain)\ndomain_features_test = imputer.transform(app_test_domain)\n\n# Scale the domainnomial features\nscaler = MinMaxScaler(feature_range=(0,1))\n\ndomain_features = scaler.fit_transform(domain_features)\ndomain_features_test = scaler.transform(domain_features_test)\n\n# Create Random Forest object for domain features data\nrandom_forest_domain = RandomForestClassifier(n_estimators=100, random_state=50, verbose=1, n_jobs=-1)\n\n# Train on the training data\nrandom_forest_domain.fit(domain_features, train_labels)\n\n# Extract feature importances, 후 작업을 위한 사전 작업\nfeature_importance_values_domain = random_forest_domain.feature_importances_\nfeature_importance_domain = pd.DataFrame({'feature':domain_features_names,'importance':feature_importance_values_domain})\n\n# Make prediction on the test data\npredictons = random_forest_domain.predict_proba(domain_features_test)[:,1]\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a submission dataframe\nsubmit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\n\n# Save the submission dataframe\nsubmit.to_csv('random_forest_baseline_domain.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"domain features를 사용했을때는 참고한 커널에서는 0.679가 나왔다.\n\n실제 커밋햇을때 성능의 변화는 거의 없다.(근데, 커널 끝에 나오는, the Gradient Boosting모델에는 효과가 있다고 함)\n\n나중에, feature engineering을 다른 데이터 소스(파일)에 대해서도 해볼 예정이다. 그러면 어느정도 점수가 올라갈 것으로 예상"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Model Interpretation: Feature Importances"},{"metadata":{},"cell_type":"markdown","source":"가장 영향력이 있는 변수가 어떤 것인지 확인하기 위해, feature importance 값을 살펴 보면된다.\n\nEDA를 통해서 가장 그 영향이 클 것으로 예상되는 것은, EXT_SOURCE변수과 DAYS_BIRTH이다.\n\n나중에 이런 변수들은 예측에 사용할 변수의 차원을 줄이기 위한 수단? 으로 사용할 수 있을 것 같다."},{"metadata":{"trusted":true},"cell_type":"code","source":"#영향계수? 를 플랏하는 함수를 작성!\ndef plot_feature_importances(df):\n    \"\"\"\n    Plot importances returned by a model. This can work with any measure of \n    feature importance provided that higher importance is better.\n    \n    Args:\n        df(dataframe): feature importances. Must have the features in a column\n        called 'features' and the importances in a column called 'importance'\n        \n    Reutrns:\n        shows a plot of the 15 most importance features\n        \n        df(dataframe): feature importances sorted by importance(hightest to lowest)\n        with a column for normalized importance\n    \"\"\"\n    \n    # Sort features according to importance\n    # reset_index()를 하면, sorting 후 내림차순이 된 데이터의 row에 대해서 다시 0부터 인덱스를 매겨준다!\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    # Normalize the feature importances to add up to one\n    # 전체 영향계수? 를 더하면 1이 되므로, 그 값으로 각각의 영향 계수를 나눠서 일반화 해줌.(0,1)사이의 값을 갖는다.\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    \n    # Make a horizontal bar chart of feature importances\n    plt.figure(figsize=(10,6))\n    ax = plt.subplot()\n    \n    # Need to reverse the index to plot most important on top\n    # 여기서 인덱스를 리버스 하면서 앞에 list를 겹처서 붙여주는 이유는, \n    # 상속되는 대상이 객체(object) 타입의? 데이터라서, 리스트 화 시켜주기 위함이다.\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align='center', \n            edgecolor='k')\n    \n    # Set the yticks and labels, y축 값 범위 정해주고, y축 데이터 라벨 이름 할당해주기\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    # Plot labeling\n    plt.xlabel('Normalized Importance')\n    plt.title('Feature Importances')\n    plt.show()\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the feature importances for the dafault features\nfeature_importances_sorted = plot_feature_importances(feature_importances)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"예상한 대로, `EXT_SOURCE`와 `DAYS_BIRTH`가 가장 중요한 feature 임을 그래프를 통해서 알수있다.\n\n모델을 표현하거나 차원을 줄이는 방법으로 feature importance가 가장 정교한 방법은 아니지만, 예측할 때 어떤 factor들이 중요할지를 알게 해주는 중요한 요소이다."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importances_domain_sorted = plot_feature_importances(feature_importance_domain)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"가공한 feature들에 대해서 탑 15개 안에 다 들어가 있는 것을 확인할 수 있다."},{"metadata":{},"cell_type":"markdown","source":"## 결론"},{"metadata":{},"cell_type":"markdown","source":"이 노트북을 통해서, 머신러닝을 어떻게 시작해야 되는지에 대해서 공부했다.\n\n데이터, 컴페티션의 목표, 어떤 모델을 쓸지에 대해서 먼저 이해한다.\\\n\n모델리에 도움을 줄, 간단한 EDA를 통해서 데이터의 관계, 트렌드, 데이터 이상점 들을 파악한다. // 과정으로, 데이터를 채우고, 카테고리컬 데이터를 인코딩하고, 데이터를 스케일링하는 등의 작업을 진행함\n\n그 다음에, baseline모델을 만들어서, 예측을 해보고, 다음으로 모델을 조금 더 복잡하게 개선시키거나, feature안에 또 다른 특성들을 추가 해 가면서 예측 점수를 올려간다.\n\n\n\n>We followed the general outline of a machine learning project:\n1. Understand the problem and the data\n2. Data cleaning and formatting (this was mostly done for us)\n3. Exploratory Data Analysis\n4. Baseline model\n5. Improved model\n6. Model interpretation (just a little)\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Just for Fun : Light Gradient Boosting Machine"},{"metadata":{},"cell_type":"markdown","source":"필자는, 진짜 머신러닝 모델이라고 한다.\n\nLightGBM 라이브러리의 the gradient boosting machine을 이용한다.\n\nGBM모델은 구조화 된 데이터셋에서 잘나가는 모델이란고 한다. 특히 캐글에서. 또 이 모델은 적용하기 위한 특별한 포맷이 필요하다.\n\n일단, 전체적인 모델을 구축하기 위한 코드를 적어놓는 것이기 때문에 겁먹을 필요는 없단다. 시작해보자."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 필요한 모듈 불러오기\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(features, test_features, encoding = 'ohe', n_folds = 5):\n    \"\"\"\n    Train and Test a light gradient boosting model using cross validation.\n    \n    Parameters:\n    -----------\n        features(pd.DataFrame):\n            dataframe of training feature to use\n            for training a model. Must include Target column.\n        test_features(pd.DataFrame):\n            dataframe of testing feature to use\n            for making predictions with the model.\n        encoding(str, default = 'ohe'):\n            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for interger label encoding\n        n_folds(int, default = 5): number of folds to use for cross validation\n        \n    Return:\n    -------\n        submission(pd.DataFrame):\n            dataframe with 'SK_ID_CURR' and 'TARGET' probabilities\n            predicted by the model.\n        feature_importances(pd.DataFrame):\n            dataframe with the feature importances from the model.\n        valid_metrics(pd.DataFrame):\n            dataframe with training and validation metrics(ROC AUC) for each fold and overall.\n    \"\"\"\n    \n    # Extract the ids\n    train_ids = features['SK_ID_CURR']\n    test_ids = test_features['SK_ID_CURR']\n    \n    # Extract the labels for training\n    labels = features['TARGET']\n    \n    # Remove the ids and target\n    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n    \n    \n    # One Hot Encoding\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        \n        # Align the dataframes by the columns\n        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n        \n        # No categorical indices to record\n        cat_indices = 'auto'\n    \n    # Integer label encoding\n    elif encoding == 'le':\n        \n        # Create a label encoder\n        label_encoder = LabelEncoder()\n        \n        # List for storing categorical indices\n        cat_indices = []\n        \n        # Iterate through each column\n        for i, col in enumerate(features):\n            if features[col].dtype == 'object':\n                # Map the categorical features to integers\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n\n                # Record the categorical indices\n                cat_indices.append(i)\n    \n    # Catch error if label encoding scheme is not valid\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n        \n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    \n    # Extract feature names\n    feature_names = list(features.columns)\n    \n    # Convert to np arrays\n    features = np.array(features)\n    test_features = np.array(test_features)\n    \n    # Create the kfold object\n    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n    \n    # Empty array for feature importances\n    feature_importance_values = np.zeros(len(feature_names))\n    \n    # Empty array for test predictions\n    test_predictions = np.zeros(test_features.shape[0])\n    \n    # Empty array for out of fold validation predictions\n    out_of_fold = np.zeros(features.shape[0])\n    \n    # Lists for recording validation and training scores\n    valid_scores = []\n    train_scores = []\n    \n    # Iterate through each fold\n    for train_indices, valid_indices in k_fold.split(features):\n        \n        # Training data for the fold\n        train_features, train_labels = features[train_indices], labels[train_indices]\n        # Validation data for the fold\n        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n        \n        # Create the model\n        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n                                   class_weight = 'balanced', learning_rate = 0.05, \n                                   reg_alpha = 0.1, reg_lambda = 0.1, \n                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n        \n        # Train the model\n        model.fit(train_features, train_labels, eval_metric = 'auc',\n                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n                  early_stopping_rounds = 100, verbose = 200)\n        \n        # Record the best iteration\n        best_iteration = model.best_iteration_\n        \n        # Record the feature importances\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        \n        # Make predictions\n        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n        \n        # Record the out of fold predictions\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n        \n        # Record the best score\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        \n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        \n        # Clean up memory\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n        \n    # Make the submission dataframe\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    \n    # Make the feature importance dataframe\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    \n    # Overall validation score\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    \n    # Add the overall scores to the metrics\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    \n    # Needed for creating dataframe of validation scores\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    \n    # Dataframe of validation scores\n    metrics = pd.DataFrame({'fold': fold_names,\n                            'train': train_scores,\n                            'valid': valid_scores}) \n    \n    return submission, feature_importances, metrics\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission, fi, metrics = model(app_train, app_test)\nprint('Baseline metrics')\nprint(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi_sorted = plot_feature_importances(fi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('baseline_lgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.733 까지 나왔다. 뭔지 모르겠지만 이게 효과가 있다. 나중에 자세한 부분은 차차 공부 하도록.."},{"metadata":{},"cell_type":"markdown","source":"이제, 하나더 해보는데, feature항목에 변수들을 조합해서 새로운 변수를 추가한, domain knowledge변수를 훈련데이터로 적용해서,\n\n예측을 해본다."},{"metadata":{"trusted":true},"cell_type":"code","source":"app_train_domain['TARGET'] = train_labels\n\n# Test the domain knowledge features\nsumission_domain, fi_domain, metrics_domain = model(\n    app_train_domain,\n    app_test_domain,\n)\n\nprint('Baseline with domain knowledge features metrics')\nprint(metrics_domain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi_sorted = plot_feature_importances(fi_domain)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"다시, 도메인 feature들을 포함시켜 중요도를 플랏해봤다.\n\nCREDIT_TERM 이라는 것이 월등하게 영향도가 큰것을 볼 수 있다. 하지만, 금융 적인 내용을 잘 모르기 때문에 여기까지만 한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"sumission_domain.to_csv('baseline_lgb_domain_features.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"핵심은 Feature Engineering!"},{"metadata":{},"cell_type":"markdown","source":"끝!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}