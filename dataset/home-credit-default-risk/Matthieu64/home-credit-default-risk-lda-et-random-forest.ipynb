{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Home Credit Default Risk LDA"},{"metadata":{},"cell_type":"markdown","source":"-------------------------------------------------------------------------\n        Matthieu64\n--------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"##  Charging the datasets and librairies"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import plotly \n#import plotly.plotly as py\n#import plotly.graph_objs as go\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n#Scikit learn librairies\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import scale\n\nimport pandas as pd\nimport numpy as np\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/home-credit-default-risk/application_train.csv')\ndf_bureau=pd.read_csv('../input/home-credit-default-risk/bureau.csv')\ndftmp= pd.read_csv('../input/home-credit-default-risk/application_train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploration des données"},{"metadata":{},"cell_type":"markdown","source":"On affiche les dimensions de la base 'application_train.csv'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On affiche les 10 premiers elements de la base de donnée."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regardons le nombre de colonne de chaque type."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On affiche maintenant un graphique de la répartition de la target (le defaut de paiement)."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig11=plt.figure()\nax11=plt.axes()\nthe_target = dftmp['TARGET']\nthe_target.replace(to_replace=[1,0], value= ['YES','NO'], inplace = True)\nplt.title('Target repartition')\nax11 = ax11.set(xlabel='Default proportion', ylabel='Number of people')\nthe_target.value_counts().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La répartition de la target n'est pas équilibrée. Il y a environ 8% des individus qui ont fait défaut. Cette distribution sera à prendre en compte lors de l'analyse de nos résultats."},{"metadata":{},"cell_type":"markdown","source":"Ce jeu de donnée est constitué de plusieurs bases de données. Nous allons donc joindre notre base de donnée à la base de donnée 'bureau.csv'. L'ID que nous utilisons pour joindre les bases est 'SK_ID_CURR' car c'est la seule colonne commune aux deux tables."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)\ndf=df.merge(right=df_bureau,how='inner', on='SK_ID_CURR')\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apres la fusion des bases, nous avons maintenant 138 colonnes et 1 465 325 lignes. Verifions qu'il n'y a pas d'invidus avec une target manquante:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.TARGET.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On affiche également le nombre de colonnes par types."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On vérifie que la nouvelle distribution de la target est consistante."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig11=plt.figure()\nax11=plt.axes()\nthe_target = dftmp['TARGET']\nthe_target.replace(to_replace=[1,0], value= ['YES','NO'], inplace = True)\nplt.title('Target repartition')\nax11 = ax11.set(xlabel='Default proportion', ylabel='Number of people')\nthe_target.value_counts().plot.pie(startangle=90, autopct='%1.1f%%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Afin d'avoir une meilleure visibilité de la data nous souhaitons crées des graphiques de nos données.\n\nNous avons écrit une fonction afin de d'afficher la valeur de chaque individu pour chaque catégorie."},{"metadata":{"trusted":true},"cell_type":"code","source":"#A function to print every graph with the ID as \ndef print_all_values():\n    df1=df.drop('SK_ID_CURR',axis=1)\n    cols=df1.columns\n    for col in cols:\n        if (df[col].dtypes !='object'):\n\n            fig1=plt.figure()\n            ax1=plt.axes()\n            plt.scatter(df[[col]],df.SK_ID_CURR,alpha=1,s=0.5)\n            plt.title(col)\n            ax1 = ax1.set(xlabel=col, ylabel='ID')\n            plt.show()\n            \n            \nprint_all_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remarque qu'il y a des valeurs aberantes, par exemple pour les salaires. Voici-ci dessous un graphique avec et sans la  valeur aberante. Ces valeurs réduisent grandement la precision des prédiction des algorithmes de machine learning, principalement la regression logistique."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the income of the people making default\ndf1=df[df.AMT_INCOME_TOTAL <1600000.0]\ndf1=df1[df.TARGET ==1 ]\ndf2=df[df.TARGET ==1 ]\n\n\nfig2=plt.figure()\nax2=plt.axes()\nplt.scatter(df2.SK_ID_CURR ,df2.AMT_INCOME_TOTAL ,alpha=1)\nplt.title('Repartition des salaires sans limite de maximum')\nax2 = ax2.set(xlabel='ID', ylabel='Salaire')\n\nfig1=plt.figure()\nax1=plt.axes()\nplt.scatter(df1.SK_ID_CURR ,df1.AMT_INCOME_TOTAL ,alpha=1)\nplt.title('Repartition des salaires avec une limite de maximum de 1600000$')\nax1 = ax1.set(xlabel='ID', ylabel='Salaire')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On peut donc supprimer cette valeur. On fait de meme pour les autres catégories où cela est le cas.\n\nNous ne pouvons malheuresement pas utiliser la fonction que l'on avait codé pour la précédente base de donnée car nos ordinateurs ne sont pas assez puissants pour effectuer les calculs dans un temps raisonnable. Nous nous contenterons donc d'une suppression manuelle."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)\ndf=df[df.AMT_INCOME_TOTAL <1750000.0]\ndf=df[df.CNT_FAM_MEMBERS <12]\ndf=df[df.OBS_30_CNT_SOCIAL_CIRCLE <50]\ndf=df[df.DEF_30_CNT_SOCIAL_CIRCLE <20]\ndf=df[df.OBS_60_CNT_SOCIAL_CIRCLE <55]\ndf=df[df.DEF_60_CNT_SOCIAL_CIRCLE <15]\ndf=df[df.AMT_REQ_CREDIT_BUREAU_HOUR <4]\ndf=df[df.AMT_REQ_CREDIT_BUREAU_QRT <55]\ndf=df[df.CNT_CREDIT_PROLONG <6.5]\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensuite, on remplace les valeurs manquantes lorsque cela est possible."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['OWN_CAR_AGE']=df['OWN_CAR_AGE'].fillna(0)\n\n\ncols=['APARTMENTS_AVG','BASEMENTAREA_AVG','COMMONAREA_AVG','ELEVATORS_AVG','ENTRANCES_AVG','FLOORSMAX_AVG','FLOORSMIN_AVG','LANDAREA_AVG','LIVINGAPARTMENTS_AVG','LIVINGAREA_AVG','NONLIVINGAPARTMENTS_AVG','NONLIVINGAREA_AVG','APARTMENTS_MODE','BASEMENTAREA_MODE','COMMONAREA_MODE','ELEVATORS_MODE','ENTRANCES_MODE','FLOORSMAX_MODE','FLOORSMIN_MODE','LANDAREA_MODE','LIVINGAPARTMENTS_MODE','LIVINGAREA_MODE','NONLIVINGAPARTMENTS_MODE','NONLIVINGAREA_MODE','APARTMENTS_MEDI','BASEMENTAREA_MEDI','COMMONAREA_MEDI','ELEVATORS_MEDI','ENTRANCES_MEDI','FLOORSMAX_MEDI','FLOORSMIN_MEDI','LANDAREA_MEDI','LIVINGAPARTMENTS_MEDI','LIVINGAREA_MEDI','NONLIVINGAPARTMENTS_MEDI','NONLIVINGAREA_MEDI']        \nfor i in df.index:\n    if (df.loc[i,'FLAG_OWN_REALTY'] =='N'):\n        for col in cols:\n            df.set_value(i,col,0)\n            \n\ndf['NAME_TYPE_SUITE']=df['NAME_TYPE_SUITE'].fillna('Unknown')\ndf['OCCUPATION_TYPE']=df['OCCUPATION_TYPE'].fillna('Unknown')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Par exemple, pour la variable 'OWN_CAR_AGE', lorsque la personne n'a pas de voiture (le drapeau 'OWN_CAR' est à zéro), l'age de sa voiture est remplie avec 'Nan'. On remarque que la solution optimale et de remplacer les valeurs d'age manquantes par 0 (cf. graph ci-dessous)."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1=plt.figure()\nax1=plt.axes()\nplt.scatter(df.OWN_CAR_AGE,df.FLAG_OWN_CAR,color='cyan')\nplt.title('Graphique de \"Own_Car\" et \"Own_Car_Age\"')\nax1 = ax1.set(xlabel='Own_Car_Age', ylabel='Own_Car')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On en profite aussi pour remplacer la variable 'DAYS_BIRTH' par l'age de la personne pour plus de lisibilité."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DAYS_BIRTH'] = df['DAYS_BIRTH']/(-365)\ndf=df.rename(columns={'DAYS_BIRTH':'AGE'})\ndf.AGE.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nous avons crée une fonction qui créer un dataframe avec le nom de la catégorie et le pourcentage de valeurs manquantes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dataset of missing values order by percentage\ndef nan_count_df(df_to_print):\n    \n    nan_count = df_to_print.isnull().sum()\n\n    nan_percentage = (nan_count / len(df))*100\n\n    nan_df=pd.concat([nan_percentage], axis=1)\n    nan_df=nan_df.rename(columns={0:'Percentage'})\n    nan_df=nan_df[nan_df.Percentage != 0]\n    nan_df = nan_df.sort_values(by='Percentage',ascending=False)\n    return nan_df\n\nnan_df=nan_count_df(df)\nnan_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Il y a des colonnes ou plus de 70% des valeurs sont manquantes. Nous ne pouvons pas remplacer ces valeurs par des moyennes ou des médiannes car elles ne seraient pas représentatives des données. Nous ne pouvons pas non plus supprimer les lignes avec des valeurs manquantes car nous supprimerions 70% des valeurs de notre base de donnée. La seule solution ici est de supprimer les colonnes avec trop de valeurs manquantes. Pour cela nous avons crée une fonction qui, à partir du dataframes précédent, supprime les colonnes avec un pourcentage de valeur manquantes supérieur à celui donné en paramètre."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)\ndef delete_columns(df_transformed,df_missing_values,max_value):\n        cols=df_missing_values[df_missing_values['Percentage']>=max_value].T.columns\n        for col in cols:\n            df_transformed=df_transformed.drop(col, axis=1)\n        \n        return df_transformed\ndf=delete_columns(df,nan_df,62)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nous avons donc à présent 132 colonnes au lieu de 138."},{"metadata":{},"cell_type":"markdown","source":"# Encodage des catégories"},{"metadata":{},"cell_type":"markdown","source":"Regardons le nombre de catégories pour chaque colonne de type 'objet'."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On supprime les colonnes qui ne se sont pas avérées utiles à la prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"#useless columns\ncolumns_to_drop = ['SK_ID_CURR','WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START','NAME_TYPE_SUITE','FLAG_MOBIL','FLAG_CONT_MOBILE']\ndf=df.drop(columns=columns_to_drop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Maintenant, nous allons encodé les colonnes des types 'object' de deux manières différentes:\n\n1. Pour les colonnes de 2 catégories, on les encode avec 1 et 0.\n2. Pour celles qui ont plus de 2 catégories, on les encode avec la methode des OneHotEncoding pour réduire le biais induit"},{"metadata":{},"cell_type":"markdown","source":"##### 1. Les colonnes à deux catégories"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encodage pour 2 catégories\ndef two_cat_encoding(df_to_transf):\n    le = LabelEncoder()\n\n    for cols in df_to_transf:\n        if df_to_transf[cols].dtype == 'object':\n            if len(list(df_to_transf[cols].unique())) == 2:\n                le.fit(df_to_transf[cols])\n                df_to_transf[cols] = le.transform(df_to_transf[cols])\n    return df_to_transf\ndf=two_cat_encoding(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 2. Les colonnes à plus de 2 catégories"},{"metadata":{},"cell_type":"markdown","source":"On utilise la methode get_dummies() pour faire le oneHotEncoding. Elle séparera donc les variables en utilisant des flags."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Les nouvelles dimensions du dataframes sont :\\n', df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---------------------------------------------------------------------------------------------\n#                  Algorithmes de Machine Learning\n----------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"On commence par supprimer les valeurs nulles que nous n'avons pas réussi à remplacer."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_columns=df.columns\ndf=df.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Spliting the data between training and testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"X =df.drop('TARGET',axis=1)\ny = df['TARGET']  \n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogisticRegr = LogisticRegression(fit_intercept=True,intercept_scaling=1,max_iter=200,tol=0.0001,random_state=None)\nlogisticRegr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Score et erreur"},{"metadata":{"trusted":true},"cell_type":"code","source":"#ERROR\nerror = (1 - logisticRegr.score(X_test, y_test))*100\nprint('Score  = ',logisticRegr.score(X_test, y_test)*100, '%','\\nErreur = %f' % error, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda=LinearDiscriminantAnalysis(n_components=None)\nlda.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Score et erreur"},{"metadata":{"trusted":true},"cell_type":"code","source":"#ERROR\nerror = (1 - lda.score(X_test, y_test))*100\nprint('Score  = ',lda.score(X_test, y_test)*100, '%','\\nErreur = %f' % error, '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=300, oob_score=True, random_state=0)\nrf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Score et erreur"},{"metadata":{"trusted":true},"cell_type":"code","source":"error = (1 - rf.score(X_test, y_test))*100\nprint('Score  = ',rf.score(X_test, y_test)*100, '%','\\nErreur = %f' % error, '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tree Decision Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Score et erreur"},{"metadata":{"trusted":true},"cell_type":"code","source":"error = (1 - clf.score(X_test, y_test))*100\nprint('Score  = ',clf.score(X_test, y_test)*100, '%','\\nErreur = %f' % error, '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation"},{"metadata":{},"cell_type":"markdown","source":"On fini par faire une cross-validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\npredictions = logisticRegr.predict(X_test)\n\nprint(classification_report(y_test,predictions))\nprint('\\n')\nprint(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(estimator = logisticRegr , \n                         X=X_train, \n                         y=y_train, \n                         cv=3)\nprint('Cross-validation scores de réussite: %s' %(scores))\nprint('CV précision: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Résultats"},{"metadata":{},"cell_type":"markdown","source":"Après entrainement de nos algorithmes, nous avons obtenu les résultats suivants sur le jeu de test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Taux de réussite par modèle:\\n\\nRégression Logistique:',logisticRegr.score(X_test, y_test)*100,'%','\\n\\nLDA:',lda.score(X_test, y_test)*100,'%','\\n\\nRandom Forest Classifier:',rf.score(X_test, y_test)*100,'%','\\n\\nDecision Tree Classifier:',clf.score(X_test, y_test)*100,'%')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}