{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# numpy and pandas for data manipulation\nimport numpy as np\nimport pandas as pd \n\n# sklearn preprocessing for dealing with categorical variables\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm_notebook as tqdm\n# File system manangement\nimport os\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nimport time\nfrom contextlib import contextmanager\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Display/plot feature importance\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(15, 20))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances01.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def application_train():\n\n    df = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\n    test_df = pd.read_csv('../input/home-credit-default-risk/application_test.csv')\n\n    df = df.append(test_df).reset_index()\n    df = df[df['CODE_GENDER'] != 'XNA']\n\n    lbe = LabelEncoder()\n\n    for col in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n            df[col] = lbe.fit_transform(df[col])\n\n    df = pd.get_dummies(df, dummy_na = True)\n\n    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace = True)\n    df['NEW_DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['NEW_INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n    df['NEW_INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n    df['NEW_ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n    df['NEW_PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n\n    df.drop(\"index\", axis = 1, inplace =  True)\n\n    df.columns = pd.Index([\"APP_\" + col for col in df.columns.tolist()])\n\n    df.rename(columns={\"APP_SK_ID_CURR\":\"SK_ID_CURR\"}, inplace = True)\n\n    df.rename(columns={\"APP_TARGET\":\"TARGET\"}, inplace = True)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def previous_application():\n\n\n    df_prev = pd.read_csv('../input/home-credit-default-risk/previous_application.csv')\n    \n    # Features that has outliers\n    feat_outlier = [\"AMT_ANNUITY\",\"AMT_APPLICATION\", \"AMT_CREDIT\", \"AMT_DOWN_PAYMENT\", \"AMT_GOODS_PRICE\", \"SELLERPLACE_AREA\"]\n    \n    # Replacing the outliers of the features with their own upper values\n    for var in feat_outlier:\n        \n        Q1 = df_prev[var].quantile(0.01)\n        Q3 = df_prev[var].quantile(0.99)\n        IQR = Q3-Q1\n        lower = Q1- 1.5*IQR\n        upper = Q3 + 1.5*IQR\n        \n        df_prev[var][(df_prev[var] > (upper))] = upper\n    \n    # 365243 value will be replaced by NaN in the following features\n    feature_replace = ['DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', 'DAYS_TERMINATION']\n    for var in feature_replace:\n        df_prev[var].replace(365243, np.nan, inplace= True)\n        \n        \n    # One hot encoding\n    categorical_columns = [col for col in df_prev.columns if df_prev[col].dtype == 'object']\n    df_prev = pd.get_dummies(df_prev, columns = categorical_columns, dummy_na = True)\n    \n    \n    # Creating new features\n    \n    df_prev['APP_CREDIT_PERC'] = df_prev['AMT_APPLICATION'] / df_prev['AMT_CREDIT']\n    df_prev['NEW_CREDIT_TO_ANNUITY_RATIO'] = df_prev['AMT_CREDIT']/df_prev['AMT_ANNUITY']\n    df_prev['NEW_DOWN_PAYMENT_TO_CREDIT'] = df_prev['AMT_DOWN_PAYMENT'] / df_prev['AMT_CREDIT']\n    df_prev['NEW_TOTAL_PAYMENT'] = df_prev['AMT_ANNUITY'] * df_prev['CNT_PAYMENT']\n    df_prev['NEW_TOTAL_PAYMENT_TO_AMT_CREDIT'] = df_prev['NEW_TOTAL_PAYMENT'] / df_prev['AMT_CREDIT']\n    # Innterest ratio previous application (simplified)\n\n    df_prev['SIMPLE_INTERESTS'] = (df_prev['NEW_TOTAL_PAYMENT']/df_prev['AMT_CREDIT'] - 1)/df_prev['CNT_PAYMENT']\n    \n    # Previous applications numeric features\n    num_aggregations = {}\n    num_cols = df_prev.select_dtypes(exclude=['object']) \n    num_cols.drop(['SK_ID_PREV', 'SK_ID_CURR'], axis= 1,inplace = True)\n    for num in num_cols:\n        num_aggregations[num] = ['min', 'max', 'mean', 'var','sum']\n\n    \n        # Previous applications categoric features\n    cat_aggregations = {}\n    for i in df_prev.columns: \n        if df_prev[i].dtypes == \"O\":\n            cat_aggregations[i] = ['mean']\n\n    \n    \n    prev_agg = df_prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n    \n    \n    \n    # Dropping features with small variance\n    features_with_small_variance = prev_agg.columns[(prev_agg.std(axis = 0) < .1).values]\n    prev_agg.drop(features_with_small_variance, axis = 1, inplace = True)\n    \n    \n    \n\n    \n    return prev_agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" def pre_processing_and_combine():\n    with timer(\"Process application train\"):\n        df = application_train()\n        print(\"application train & test shape:\", df.shape)\n    \n    with timer(\"previous_application\"):\n            df_prev = previous_application()\n            print(\"previous_application:\", df_prev.shape) \n            \n    # merging prev and train application table\n    df_prev_and_train = df.merge(df_prev, how = 'left',on = 'SK_ID_CURR')\n    \n    print(\"the shape of prev and train data:\", df_prev_and_train.shape) \n\n    \n    \n    return df_prev_and_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modeling(df_prev_and_train):\n    all_data = df_prev_and_train.copy()\n    all_data = all_data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n    \n    train_df = all_data[all_data['TARGET'].notnull()]\n    test_df = all_data[all_data['TARGET'].isnull()]\n\n    folds = KFold(n_splits = 10, shuffle = True, random_state = 1001)\n\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n\n    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR']]\n\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n\n        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n\n        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n\n        clf = LGBMClassifier(\n                n_jobs = -1,\n                n_estimators=10000,\n                learning_rate=0.02,\n                num_leaves=34,\n                colsample_bytree=0.9497036,\n                subsample=0.8715623,\n                max_depth=8,\n                reg_alpha=0.041545473,\n                reg_lambda=0.0735294,\n                min_split_gain=0.0222415,\n                min_child_weight=39.3259775,\n                silent=-1,\n                verbose=-1)\n\n        clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)], \n                eval_metric = 'auc', verbose = 200, early_stopping_rounds = 200)\n\n        #y_pred_valid\n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n\n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx]))) \n\n\n    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds)) #y_pred_valid   \n\n    test_df['TARGET'] = sub_preds\n    test_df[['SK_ID_CURR', 'TARGET']].to_csv(\"submission_lightgbm.csv\", index= False)\n\n    display_importances(feature_importance_df)\n    \n    return feature_importance_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def main():\n    \n    with timer(\"Preprocessing Time\"):\n        all_data = pre_processing_and_combine()\n    \n    with timer(\"Modeling\"):\n        feat_importance = modeling(all_data)\n    return feat_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == \"__main__\":\n    with timer(\"Full model run\"):\n        main()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}