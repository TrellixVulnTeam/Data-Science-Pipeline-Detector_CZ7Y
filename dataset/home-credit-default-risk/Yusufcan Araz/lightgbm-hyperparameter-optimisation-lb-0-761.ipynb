{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **LightGBM Model**\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \nplt.xkcd()\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nPATH = \"../input/\"\nprint(os.listdir(PATH))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-06-14T13:34:06.662246Z","iopub.execute_input":"2021-06-14T13:34:06.66279Z","iopub.status.idle":"2021-06-14T13:34:06.681714Z","shell.execute_reply.started":"2021-06-14T13:34:06.662745Z","shell.execute_reply":"2021-06-14T13:34:06.6809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read in the data reducing memory pattern for variables.\nThe implementation was copied over from [this kernel](https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)","metadata":{"_uuid":"0ed4d74b3e586cc5b1be41bf67756e370b86186a"}},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","metadata":{"_uuid":"259665371981ab1eeae11333963b96b6099fd9e0","execution":{"iopub.status.busy":"2021-06-14T13:34:10.640695Z","iopub.execute_input":"2021-06-14T13:34:10.641013Z","iopub.status.idle":"2021-06-14T13:34:10.768259Z","shell.execute_reply.started":"2021-06-14T13:34:10.640959Z","shell.execute_reply":"2021-06-14T13:34:10.767463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_train = import_data(PATH+'application_train.csv')\napplication_test = import_data(PATH+'application_test.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-06-14T13:34:16.294154Z","iopub.execute_input":"2021-06-14T13:34:16.294457Z","iopub.status.idle":"2021-06-14T13:34:29.48497Z","shell.execute_reply.started":"2021-06-14T13:34:16.294419Z","shell.execute_reply":"2021-06-14T13:34:29.484149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following 2 cells with cleaning criteria were inherited from [this kernel](https://www.kaggle.com/kingychiu/home-credit-eda-distributions-and-outliers)","metadata":{"_uuid":"83d85f866b03c50ff1962917db4dd9d149ef6243"}},{"cell_type":"code","source":"application_train = application_train[application_train['AMT_INCOME_TOTAL'] != 1.170000e+08]\napplication_train = application_train[application_train['AMT_REQ_CREDIT_BUREAU_QRT'] != 261]\napplication_train = application_train[application_train['OBS_30_CNT_SOCIAL_CIRCLE'] < 300]","metadata":{"_uuid":"a258ddefe97be5807054b3742fb8ab1f18ac62aa","execution":{"iopub.status.busy":"2021-06-14T13:34:29.485993Z","iopub.execute_input":"2021-06-14T13:34:29.486318Z","iopub.status.idle":"2021-06-14T13:34:29.753246Z","shell.execute_reply.started":"2021-06-14T13:34:29.486254Z","shell.execute_reply":"2021-06-14T13:34:29.75248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_train['DAYS_EMPLOYED'] = (application_train['DAYS_EMPLOYED'].apply(lambda x: x if x != 365243 else np.nan))","metadata":{"_uuid":"1a56b73ffe90bdab9015d385d68567cf03617bdf","execution":{"iopub.status.busy":"2021-06-14T13:34:29.754431Z","iopub.execute_input":"2021-06-14T13:34:29.754702Z","iopub.status.idle":"2021-06-14T13:34:30.044041Z","shell.execute_reply.started":"2021-06-14T13:34:29.754652Z","shell.execute_reply":"2021-06-14T13:34:30.04322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Additional numerical features\nThe credit length feature idea is due [@oskird](https://www.kaggle.com/sz8416) implemented [here in the corresponding kernel](https://www.kaggle.com/sz8416/eda-baseline-model-using-application)","metadata":{"_uuid":"5fb1ac77952823a894bede3dc852b942bf6ee4a7"}},{"cell_type":"code","source":"def feat_ext_source(df):\n    x1 = df['EXT_SOURCE_1'].fillna(-1) + 1e-1\n    x2 = df['EXT_SOURCE_2'].fillna(-1) + 1e-1\n    x3 = df['EXT_SOURCE_3'].fillna(-1) + 1e-1\n    \n    df['EXT_SOURCE_1over2_NAminus1_Add0.1'] = x1/x2\n    df['EXT_SOURCE_2over1_NAminus1_Add0.1'] = x2/x1\n    df['EXT_SOURCE_1over3_NAminus1_Add0.1'] = x1/x3\n    df['EXT_SOURCE_3over1_NAminus1_Add0.1'] = x3/x1\n    df['EXT_SOURCE_2over3_NAminus1_Add0.1'] = x2/x3\n    df['EXT_SOURCE_3over2_NAminus1_Add0.1'] = x3/x2\n    \n    df['EXT_SOURCE_na1_2'] = (df['EXT_SOURCE_1'].isnull()) * (df['EXT_SOURCE_2'].fillna(0))\n    df['EXT_SOURCE_na1_3'] = (df['EXT_SOURCE_1'].isnull()) * (df['EXT_SOURCE_3'].fillna(0))\n    df['EXT_SOURCE_na2_1'] = (df['EXT_SOURCE_2'].isnull()) * (df['EXT_SOURCE_1'].fillna(0))\n    df['EXT_SOURCE_na2_3'] = (df['EXT_SOURCE_2'].isnull()) * (df['EXT_SOURCE_3'].fillna(0))\n    df['EXT_SOURCE_na3_1'] = (df['EXT_SOURCE_3'].isnull()) * (df['EXT_SOURCE_1'].fillna(0))\n    df['EXT_SOURCE_na3_2'] = (df['EXT_SOURCE_3'].isnull()) * (df['EXT_SOURCE_2'].fillna(0))\n    \n    df['CREDIT_LENGTH'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n    \n    return df","metadata":{"_uuid":"3b5d60b0df693c67fbb18f68f9123e0b2b3ae7e0","execution":{"iopub.status.busy":"2021-06-14T13:34:30.045161Z","iopub.execute_input":"2021-06-14T13:34:30.045477Z","iopub.status.idle":"2021-06-14T13:34:30.087775Z","shell.execute_reply.started":"2021-06-14T13:34:30.045413Z","shell.execute_reply":"2021-06-14T13:34:30.086895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_train = feat_ext_source(application_train)\napplication_test  = feat_ext_source(application_test)","metadata":{"_uuid":"aa46a91e767414557d54b0fa9d79bfc013812289","execution":{"iopub.status.busy":"2021-06-14T13:34:30.089003Z","iopub.execute_input":"2021-06-14T13:34:30.08948Z","iopub.status.idle":"2021-06-14T13:34:30.323347Z","shell.execute_reply.started":"2021-06-14T13:34:30.089411Z","shell.execute_reply":"2021-06-14T13:34:30.322377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical encoding\nThe function was taken from [this kernel](https://www.kaggle.com/sz8416/simple-intro-eda-baseline-model-with-gridsearch). It allows to do OneHotEncoding (OHE) keeping only those columns that are common to train and test samples. OHE is performed using `pd.get_dummies`, which allows to convert categorical features, while keeping numerical untouched","metadata":{"_uuid":"87bce4fc7ddd06b3778cd5c0bcf99bcde57ce0ab"}},{"cell_type":"code","source":"# use this if you want to convert categorical features to dummies(default)\ndef cat_to_dummy(train, test):\n    train_d = pd.get_dummies(train, drop_first=False)\n    test_d = pd.get_dummies(test, drop_first=False)\n    # make sure that the number of features in train and test should be same\n    for i in train_d.columns:\n        if i not in test_d.columns:\n            if i!='TARGET':\n                train_d = train_d.drop(i, axis=1)\n    for j in test_d.columns:\n        if j not in train_d.columns:\n            if j!='TARGET':\n                test_d = test_d.drop(i, axis=1)\n    print('Memory usage of train increases from {:.2f} to {:.2f} MB'.format(train.memory_usage().sum() / 1024**2, \n                                                                            train_d.memory_usage().sum() / 1024**2))\n    print('Memory usage of test increases from {:.2f} to {:.2f} MB'.format(test.memory_usage().sum() / 1024**2, \n                                                                            test_d.memory_usage().sum() / 1024**2))\n    return train_d, test_d\n\napplication_train_ohe, application_test_ohe = cat_to_dummy(application_train, application_test)","metadata":{"_uuid":"f4114dfe218a34a532275add442cb92a0414b3a4","execution":{"iopub.status.busy":"2021-06-14T13:34:30.58674Z","iopub.execute_input":"2021-06-14T13:34:30.587085Z","iopub.status.idle":"2021-06-14T13:34:31.52323Z","shell.execute_reply.started":"2021-06-14T13:34:30.58703Z","shell.execute_reply":"2021-06-14T13:34:31.522454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use this if you want to convert categorical features to dummies(default)\ndef cat_to_int(train, test):\n    mem_orig_train = train.memory_usage().sum() / 1024**2\n    mem_orig_test  = test .memory_usage().sum() / 1024**2\n    categorical_feats = [ f for f in train.columns if train[f].dtype == 'object' or train[f].dtype.name == 'category' ]\n    print('---------------------')\n    print(categorical_feats)\n    for f_ in categorical_feats:\n        train[f_], indexer = pd.factorize(train[f_])\n        test[f_] = indexer.get_indexer(test[f_])\n    print('Memory usage of train increases from {:.2f} to {:.2f} MB'.format(mem_orig_train, \n                                                                            train.memory_usage().sum() / 1024**2))\n    print('Memory usage of test increases from {:.2f} to {:.2f} MB'.format(mem_orig_test, \n                                                                            test.memory_usage().sum() / 1024**2))\n    return categorical_feats, train, test\n\ncategorical_feats, application_train_ohe, application_test_ohe = cat_to_int(application_train, application_test)","metadata":{"_uuid":"4bf82dab5971e542c488ed1e96fc5f9fa75b6e87","execution":{"iopub.status.busy":"2021-06-14T13:34:34.309848Z","iopub.execute_input":"2021-06-14T13:34:34.310187Z","iopub.status.idle":"2021-06-14T13:34:34.886187Z","shell.execute_reply.started":"2021-06-14T13:34:34.310119Z","shell.execute_reply":"2021-06-14T13:34:34.885288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deal with category imbalance\nUse a standard library (`imblearn`) to to random undersampling on the dominating category. Use if if you want to repeat the HP optimisation","metadata":{"_uuid":"bfa35f60c92ae01d6de9c82ef52ffc1a0c00350d"}},{"cell_type":"code","source":"\nX_rus, y_rus = (application_train_ohe.drop(['SK_ID_CURR', 'TARGET'], axis=1),\n                application_train_ohe['TARGET'])","metadata":{"_uuid":"f62e64bf4e4d4329a0c4216651b287cea8f3100d","execution":{"iopub.status.busy":"2021-06-14T13:34:37.943254Z","iopub.execute_input":"2021-06-14T13:34:37.943633Z","iopub.status.idle":"2021-06-14T13:34:38.012526Z","shell.execute_reply.started":"2021-06-14T13:34:37.943557Z","shell.execute_reply":"2021-06-14T13:34:38.011551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntarget = application_train_ohe.loc[:,'TARGET']\ntarget.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T11:30:53.811309Z","iopub.execute_input":"2021-06-14T11:30:53.811638Z","iopub.status.idle":"2021-06-14T11:30:53.818202Z","shell.execute_reply.started":"2021-06-14T11:30:53.811583Z","shell.execute_reply":"2021-06-14T11:30:53.817204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total = 225359 + 19830\n\n\n# Import libraries\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n# Creating dataset\ncounts = ['1_count' , '0_count']\n\ndata = [19830 ,  225359]\n\n# Creating plot\nfig = plt.figure(figsize =(10, 7))\nplt.pie(data, labels = counts)\n\n# show plot\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:34:55.558156Z","iopub.execute_input":"2021-06-14T13:34:55.558661Z","iopub.status.idle":"2021-06-14T13:34:55.682583Z","shell.execute_reply.started":"2021-06-14T13:34:55.558614Z","shell.execute_reply":"2021-06-14T13:34:55.68163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Burda modeli train ve test set diye ayiriyoruz ayrica targeti da ayriyoruz.\n# In this part we are splitting the data set (Train and Test sets) beside we are creating target and features.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_rus, y_rus, test_size=0.20, random_state=314)","metadata":{"_uuid":"4c9053167195838284544e5d717c1c68b27b46fb","execution":{"iopub.status.busy":"2021-06-14T13:35:00.270073Z","iopub.execute_input":"2021-06-14T13:35:00.270372Z","iopub.status.idle":"2021-06-14T13:35:00.712116Z","shell.execute_reply.started":"2021-06-14T13:35:00.270315Z","shell.execute_reply":"2021-06-14T13:35:00.711255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ikinci asamada validation için Kfold mu stratifiedKfold mu kullanıcağımızı öğrenmek için Targettaki data dağılımına baktık ve dağılımda büyük bir eşitsizlik olduğundan dolayı startifiedKfold kullanmaya karar verdik.\n\n# In the second part, we are finding the correct validation algorithm between Kfold and stratifiedkfold. In order to decide it, we are looking the balance between target variable. We saw a huge difference between percentages. Therefore, we are deciding to use StratifiedKfold.","metadata":{}},{"cell_type":"code","source":"count1 = 0\ncount0 = 0\nprint(y_train.value_counts())\n\ntotal = 225359 + 19830\n\n\n# Import libraries\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n\n# Creating dataset\ncounts = ['1_count' , '0_count']\n\ndata = [19830 ,  225359]\n\n# Creating plot\nfig = plt.figure(figsize =(10, 7))\nplt.pie(data, labels = counts)\n\n# show plot\nplt.show()\n\n#comment: big difference between percentages. The strategy that i will use will be StratifiedKFold. This is because of the\n#huge difference in target values.","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:35:03.369722Z","iopub.execute_input":"2021-06-14T13:35:03.370067Z","iopub.status.idle":"2021-06-14T13:35:03.509294Z","shell.execute_reply.started":"2021-06-14T13:35:03.370006Z","shell.execute_reply":"2021-06-14T13:35:03.508389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom imblearn.datasets import make_imbalance","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:35:07.794075Z","iopub.execute_input":"2021-06-14T13:35:07.794708Z","iopub.status.idle":"2021-06-14T13:35:08.180259Z","shell.execute_reply.started":"2021-06-14T13:35:07.794534Z","shell.execute_reply":"2021-06-14T13:35:08.179529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts().plot(kind='bar')\nplt.title('label balance')\nplt.xlabel('label values')\nplt.ylabel('amount per label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:35:10.192327Z","iopub.execute_input":"2021-06-14T13:35:10.192662Z","iopub.status.idle":"2021-06-14T13:35:10.41412Z","shell.execute_reply.started":"2021-06-14T13:35:10.192615Z","shell.execute_reply":"2021-06-14T13:35:10.413533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:35:14.034703Z","iopub.execute_input":"2021-06-14T13:35:14.035215Z","iopub.status.idle":"2021-06-14T13:35:14.042672Z","shell.execute_reply.started":"2021-06-14T13:35:14.035164Z","shell.execute_reply":"2021-06-14T13:35:14.041997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filling the nan values with most frequent value.","metadata":{}},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='most_frequent')\nimputed_X_train = pd.DataFrame(imputer.fit_transform(X_train))\nimputed_X_train.columns = X_train.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:35:16.506937Z","iopub.execute_input":"2021-06-14T13:35:16.507619Z","iopub.status.idle":"2021-06-14T13:36:35.912894Z","shell.execute_reply.started":"2021-06-14T13:35:16.507542Z","shell.execute_reply":"2021-06-14T13:36:35.912063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='most_frequent')\nimputed_X_val = pd.DataFrame(imputer.fit_transform(X_val))\nimputed_X_val.columns = X_val.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:35.913936Z","iopub.execute_input":"2021-06-14T13:36:35.914192Z","iopub.status.idle":"2021-06-14T13:36:51.743301Z","shell.execute_reply.started":"2021-06-14T13:36:35.914145Z","shell.execute_reply":"2021-06-14T13:36:51.74255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# StratifiedKfold algoritmasi ile validation, bu asama da accuracy score yüzde 90 üzeri çıktığından dolayı burda overfitting yaptığımızı düşünüyoruz ama nedenini çözemedik.\n\n# We use stratifiedKfold. However we observe very high accuracy scores. We tought that we make a mistake which cause an overfitting.","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\ncross_val_score(model, imputed_X_val, y_val, cv=skf) #overfitting","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:52.120825Z","iopub.status.idle":"2021-06-14T13:36:52.121292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\ncross_val_score(model, X_val_B, y_val_B, cv=skf)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:52.122264Z","iopub.status.idle":"2021-06-14T13:36:52.122743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# We tried with other methodes but we could not find anything.","metadata":{}},{"cell_type":"code","source":"# fold_no = 1\n# for train_index, test_index in skf.split(application_train_ohe, target):\n#     train = application_train_ohe.loc[train_index,:]\n#     test = application_train_ohe.loc[test_index,:]\n#     #print(sum(test['TARGET']))\n#     print('Fold',str(fold_no),'Class Ratio:',(test['TARGET'].count()/len(application_train_ohe['TARGET'])))\n#     fold_no += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:14:48.297339Z","iopub.execute_input":"2021-06-14T12:14:48.29775Z","iopub.status.idle":"2021-06-14T12:14:49.500589Z","shell.execute_reply.started":"2021-06-14T12:14:48.297689Z","shell.execute_reply":"2021-06-14T12:14:49.499788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data = application_train_ohe.dropna(subset = [\"TARGET\"])\n# data[\"TARGET\"].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:14:52.534946Z","iopub.execute_input":"2021-06-14T12:14:52.535297Z","iopub.status.idle":"2021-06-14T12:14:52.680939Z","shell.execute_reply.started":"2021-06-14T12:14:52.535256Z","shell.execute_reply":"2021-06-14T12:14:52.680118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn import preprocessing\n# from sklearn import utils\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:26:57.608551Z","iopub.execute_input":"2021-06-01T01:26:57.608804Z","iopub.status.idle":"2021-06-01T01:26:57.612718Z","shell.execute_reply.started":"2021-06-01T01:26:57.60876Z","shell.execute_reply":"2021-06-01T01:26:57.611912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def train_model(train, test, fold_no):\n#     y_train = train['TARGET']\n#     X_train = train.drop([\"TARGET\" , \"SK_ID_CURR\"],axis=1)\n#     y_test = test['TARGET']\n#     X_test = test.drop([\"TARGET\" ,\"SK_ID_CURR\" ],axis=1)\n    \n    \n    \n#     lab_enc = preprocessing.LabelEncoder()\n#     y_train = lab_enc.fit_transform(y_train)\n#     print(y_train.shape , X_train.shape)\n    \n#     model.fit(X_train,y_train)\n#     predictions = model.predict(X_test)\n#     print('Fold',str(fold_no),'Accuracy:',accuracy_score(y_test,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:27:53.691297Z","iopub.execute_input":"2021-06-01T01:27:53.691613Z","iopub.status.idle":"2021-06-01T01:27:53.705234Z","shell.execute_reply.started":"2021-06-01T01:27:53.691535Z","shell.execute_reply":"2021-06-01T01:27:53.704371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold_no = 1\n# for train_index, test_index in skf.split(data, target):\n#     train = data.loc[train_index,:]\n#     test = data.loc[test_index,:]\n#     train_model(train,test,fold_no)\n#     fold_no += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:26:57.630989Z","iopub.execute_input":"2021-06-01T01:26:57.631318Z","iopub.status.idle":"2021-06-01T01:27:49.151944Z","shell.execute_reply.started":"2021-06-01T01:26:57.631266Z","shell.execute_reply":"2021-06-01T01:27:49.084232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:52.123608Z","iopub.status.idle":"2021-06-14T13:36:52.124049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold_no = 1\n# for train_index, test_index in skf.split(application_train_ohe, target):\n#     train = application_train_ohe.loc[train_index,:]\n#     test = application_train_ohe.loc[test_index,:]\n\n#     fold_no += 1 \n#     #in order to build folds and ","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:28:00.373356Z","iopub.execute_input":"2021-06-01T01:28:00.373639Z","iopub.status.idle":"2021-06-01T01:28:04.834036Z","shell.execute_reply.started":"2021-06-01T01:28:00.373581Z","shell.execute_reply":"2021-06-01T01:28:04.833309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Balance the data\nBizde stratified k-fold u uygulayamayinca benzerini ama daha simple versyonunu uygulamaya karar verdik ve datayi oranlarini esitledik.","metadata":{}},{"cell_type":"code","source":"X_train_B, y_train_B = make_imbalance(imputed_X_train, y_train, sampling_strategy={0: 19000, 1: 19000},random_state=14)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:35.989172Z","iopub.execute_input":"2021-06-14T13:37:35.989781Z","iopub.status.idle":"2021-06-14T13:37:36.664581Z","shell.execute_reply.started":"2021-06-14T13:37:35.989732Z","shell.execute_reply":"2021-06-14T13:37:36.663728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val_B, y_val_B = make_imbalance(imputed_X_val, y_val, sampling_strategy={0: 5010, 1: 5010},random_state=14)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:38.010825Z","iopub.execute_input":"2021-06-14T13:37:38.011528Z","iopub.status.idle":"2021-06-14T13:37:38.175484Z","shell.execute_reply.started":"2021-06-14T13:37:38.011456Z","shell.execute_reply":"2021-06-14T13:37:38.174691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeli default parametrelerle oluşturduk.\n\n# We create model with default parametres.","metadata":{}},{"cell_type":"code","source":"model = lgb.LGBMClassifier(max_depth=-1 ,n_estimators = 100 , n_jobs=4) #model with basic parametre\n#print(X_train.shape , y_train.shape)\nmodel.fit(X_train_B,y_train_B)\npredictions = model.predict(X_val_B)\nprint('Accuracy:',accuracy_score(y_val_B,predictions))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:53.710961Z","iopub.execute_input":"2021-06-14T13:37:53.711606Z","iopub.status.idle":"2021-06-14T13:37:55.628375Z","shell.execute_reply.started":"2021-06-14T13:37:53.711554Z","shell.execute_reply":"2021-06-14T13:37:55.627453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare learning rate shrinkage","metadata":{"_uuid":"08cb13d0caa3713665f843db8a83de6744210f83"}},{"cell_type":"code","source":"def learning_rate_010_decay_power_099(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_010_decay_power_0995(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_005_decay_power_099(current_iter):\n    base_learning_rate = 0.05\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3","metadata":{"_uuid":"a746df8c0f27948f76f476b7329bf11449d25f38","execution":{"iopub.status.busy":"2021-06-14T13:39:16.496656Z","iopub.execute_input":"2021-06-14T13:39:16.496956Z","iopub.status.idle":"2021-06-14T13:39:16.512519Z","shell.execute_reply.started":"2021-06-14T13:39:16.496918Z","shell.execute_reply":"2021-06-14T13:39:16.511412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use test subset for early stopping criterion \nThis allows us to avoid overtraining and we do not need to optimise the number of trees","metadata":{"_uuid":"b8af9e2ff9ca6f6bb59b7380bc65c99a5063f4c7"}},{"cell_type":"code","source":"import lightgbm as lgb\nfit_params={\"early_stopping_rounds\":30, \n            \"eval_metric\" : 'auc', \n            \"eval_set\" : [(X_val_B,y_val_B)],\n            'eval_names': ['valid'],\n            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n            'verbose': 100,\n            'categorical_feature': 'auto'}","metadata":{"_uuid":"f565eef3d14a6d8ade0602823dcd316ad2829117","execution":{"iopub.status.busy":"2021-06-14T13:39:19.760338Z","iopub.execute_input":"2021-06-14T13:39:19.760657Z","iopub.status.idle":"2021-06-14T13:39:19.766939Z","shell.execute_reply.started":"2021-06-14T13:39:19.760614Z","shell.execute_reply":"2021-06-14T13:39:19.766248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set up HyperParameter search\nWe use random search, which is more flexible and more efficient than a grid search","metadata":{"_uuid":"edcf7716984b1f0ed56d4d325d0ddee2efe7c017"}},{"cell_type":"code","source":"from scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nparam_test ={'num_leaves': sp_randint(6, 50), \n             'min_child_samples': sp_randint(100, 500), \n             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n             'subsample': sp_uniform(loc=0.2, scale=0.8), \n             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}","metadata":{"_uuid":"8a1c436c90043f3ade05d149f4714ccf5bbf15aa","execution":{"iopub.status.busy":"2021-06-14T13:39:22.830848Z","iopub.execute_input":"2021-06-14T13:39:22.831175Z","iopub.status.idle":"2021-06-14T13:39:22.843543Z","shell.execute_reply.started":"2021-06-14T13:39:22.831119Z","shell.execute_reply":"2021-06-14T13:39:22.842648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This parameter defines the number of HP points to be tested\nn_HP_points_to_test = 5\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\nclf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=200)\nclf.fit(X_train_B,y_train_B)\npredictions = clf.predict(X_val_B)\nprint('Accuracy:',accuracy_score(y_val_B,predictions))\n\ngs = RandomizedSearchCV(\n    estimator=clf, param_distributions=param_test, \n    n_iter=n_HP_points_to_test,\n    scoring='roc_auc',\n    cv=3,\n    refit=True,\n    random_state=314,\n    verbose=True)","metadata":{"_uuid":"5bb7998f3db77da6fc23737bbf8d80a260391f24","execution":{"iopub.status.busy":"2021-06-14T13:39:25.248875Z","iopub.execute_input":"2021-06-14T13:39:25.249154Z","iopub.status.idle":"2021-06-14T13:39:28.271632Z","shell.execute_reply.started":"2021-06-14T13:39:25.249111Z","shell.execute_reply":"2021-06-14T13:39:28.270838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs.fit(X_train_B, y_train_B, **fit_params)\nprint('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))","metadata":{"_uuid":"1d6c7e208287046714f376085cb3745da63ad7e1","execution":{"iopub.status.busy":"2021-06-14T13:39:29.558497Z","iopub.execute_input":"2021-06-14T13:39:29.558813Z","iopub.status.idle":"2021-06-14T13:39:56.122974Z","shell.execute_reply.started":"2021-06-14T13:39:29.558756Z","shell.execute_reply":"2021-06-14T13:39:56.12204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_parameters = {'colsample_bytree': 0.950, 'min_child_samples': 301, 'min_child_weight': 0.1, 'num_leaves': 28, 'reg_alpha': 0, 'reg_lambda': 100, 'subsample': 0.93264}","metadata":{"_uuid":"684c01b827d63be6cb3e8a97eb942f8ece5201e5","execution":{"iopub.status.busy":"2021-06-14T13:39:56.124397Z","iopub.execute_input":"2021-06-14T13:39:56.124826Z","iopub.status.idle":"2021-06-14T13:39:56.130297Z","shell.execute_reply.started":"2021-06-14T13:39:56.124687Z","shell.execute_reply":"2021-06-14T13:39:56.1295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:39:56.131617Z","iopub.execute_input":"2021-06-14T13:39:56.132132Z","iopub.status.idle":"2021-06-14T13:39:56.144492Z","shell.execute_reply.started":"2021-06-14T13:39:56.132089Z","shell.execute_reply":"2021-06-14T13:39:56.143845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lofo importance hyperparametreleri optimize etmek icin kullanmaya calistik ancak hata aldik.","metadata":{}},{"cell_type":"code","source":"# !pip install git+https://github.com/aerdem4/lofo-importance","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:04:23.198872Z","iopub.execute_input":"2021-06-14T13:04:23.199387Z","iopub.status.idle":"2021-06-14T13:05:09.711629Z","shell.execute_reply.started":"2021-06-14T13:04:23.199342Z","shell.execute_reply":"2021-06-14T13:05:09.710625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from lofo.lofo_importance import LOFOImportance, plot_importance","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:33:29.622671Z","iopub.execute_input":"2021-06-01T01:33:29.622956Z","iopub.status.idle":"2021-06-01T01:33:29.646548Z","shell.execute_reply.started":"2021-06-01T01:33:29.622916Z","shell.execute_reply":"2021-06-01T01:33:29.645371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lofo_imp = LOFOImportance(X_train, model = clf,scoring='neg_mean_squared_error')\n# importance_df = lofo_imp.get_importance()\n# plot_importance(importance_df, figsize=(12, 12))","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:33:45.277212Z","iopub.execute_input":"2021-06-01T01:33:45.277698Z","iopub.status.idle":"2021-06-01T01:33:45.293856Z","shell.execute_reply.started":"2021-06-01T01:33:45.277657Z","shell.execute_reply":"2021-06-01T01:33:45.292626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FINAL MODEL\nWe set best parametre.\n","metadata":{"_uuid":"7ec17e1e5fec8b04a1602f4524486848deda39a9"}},{"cell_type":"code","source":"#Configure from the HP optimisation\n#clf_final = lgb.LGBMClassifier(**gs.best_estimator_.get_params())\n\n#Configure locally from hardcoded values\nclf_final = lgb.LGBMClassifier(**clf.get_params())\n#set optimal parameters\nclf_final.set_params(**opt_parameters)\n\n#Train the final model with learning rate decay\nclf_final.fit(X_train_B, y_train_B, **fit_params, callbacks=[lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_0995)]  )","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:40:02.511522Z","iopub.execute_input":"2021-06-14T13:40:02.512066Z","iopub.status.idle":"2021-06-14T13:40:06.323536Z","shell.execute_reply.started":"2021-06-14T13:40:02.512018Z","shell.execute_reply":"2021-06-14T13:40:06.322764Z"},"trusted":true},"execution_count":null,"outputs":[]}]}