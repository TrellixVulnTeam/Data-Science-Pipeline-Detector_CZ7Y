{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ShuffleSplit, learning_curve\nfrom sklearn.metrics import roc_auc_score, make_scorer\nfrom sklearn.preprocessing import Imputer, MinMaxScaler, StandardScaler\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\n\nimport zipfile\n\nfrom IPython.display import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/home-credit-default-risk/'\n\nPOS_CASH_balance = pd.read_csv(path+'POS_CASH_balance.csv')\nbureau_balance = pd.read_csv(path+'bureau_balance.csv')\napplication_train = pd.read_csv(path+'application_train.csv')\nprevious_application = pd.read_csv(path+'previous_application.csv')\ninstallments_payments = pd.read_csv(path+'installments_payments.csv')\ncredit_card_balance = pd.read_csv(path+'credit_card_balance.csv')\napplication_test = pd.read_csv(path+'application_test.csv')\nbureau = pd.read_csv(path+'bureau.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выведем изображение с моделью данных\nImage(url = \"https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выведем shape'ы тренировочных и тестовых данных\nprint('application_train shape: {} rows, {} columns'.format(*application_train.shape))\nprint('application_test shape: {} rows, {} columns'.format(*application_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train.set_index('SK_ID_CURR', inplace=True)\napplication_test.set_index('SK_ID_CURR', inplace=True)\n\ny = application_train['TARGET']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим категориальные и вещественные признаки\ncategorical_features = [col for col in application_test.columns if application_test[col].dtype == 'object']\nnumerical_features = [col for col in application_test.columns if application_test[col].dtype != 'object']\n        \nprint('Data has {} categorical features, and {} numerical features'.format(\n    len(categorical_features), len(numerical_features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Запилим функцию для визуализации распределения вещественных признаков\ndef plot_features_hist(df, features, cols=3, bins=200, window_width=7.5, window_height=5):\n    cols = cols\n    rows = (len(features) + cols - 1) // cols\n    gs = gridspec.GridSpec(rows, cols)\n    fig = plt.figure(figsize=(cols * window_width, rows * window_height))\n    for feature, grd in zip(features,\n                            range(len(features))):\n        ax = plt.subplot(gs[grd // cols, grd % cols])\n        fig = plt.hist(df[feature].dropna(), bins=bins)\n        plt.title(str(feature)\n                  +' (min:'+str(round(min(df[feature].dropna())))\n                  +', mean:'+str(round(np.mean(df[feature].dropna())))\n                  +', max:'+str(round(max(df[feature].dropna())))+')')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_features_hist(application_train, numerical_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_features_hist(application_test, numerical_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('application_test \"DAYS_EMPLOYED\" anomalies {}, {}%'.format(\n    len(application_test[application_test['DAYS_EMPLOYED']==365243]),\n    len(application_test[application_test['DAYS_EMPLOYED']==365243]) / len(application_test) * 100))\nprint('')\nprint('application_train \"DAYS_EMPLOYED\" anomalies {}, {}%'.format(\n    len(application_train[application_train['DAYS_EMPLOYED']==365243]),\n    len(application_train[application_train['DAYS_EMPLOYED']==365243]) / len(application_train) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В признаке DAYS_EMPLOYED часто встречается значение 365243. Скорее всего, это какая-то опечатка или характерный баг CRM-ки, не может же сотрудник работать тысячу лет на одном месте. Создадим специальный признак, в котором будет метка о наличии такого явления, а само значение в признаке заменим пропуском."},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train['DAYS_EMPLOYED_ANOM'] = application_train[\"DAYS_EMPLOYED\"] == 365243\napplication_train[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\napplication_test['DAYS_EMPLOYED_ANOM'] = application_test[\"DAYS_EMPLOYED\"] == 365243\napplication_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Далее обработаем категориальные признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train = pd.get_dummies(data=application_train, columns=categorical_features, dummy_na=True)\napplication_test = pd.get_dummies(data=application_test, columns=categorical_features, dummy_na=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('application_train shape: {} rows {} columns'.format(*application_train.shape))\nprint('application_test shape: {} rows {} columns'.format(*application_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тренировочный и тестовый наборы теперь имеют разное число признаков. Приведём их к единому виду"},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train, application_test = application_train.align(application_test, join='inner', axis = 1)\n\nprint('application_train shape: ', application_train.shape)\nprint('application_test shape: ', application_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Далее разберёмся с пропусками"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df = (application_train.isna().sum() / len(application_train)).reset_index()\nmissing_df.sort_values(ascending=False, by=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_indicator(df, features=None, inplace=False):\n    if not features:\n        features = df.columns\n    if not inplace:\n        df = df.copy()\n    for feature in df[features].columns:\n        if df[feature].isna().sum() > 0:\n            df['missing_'+feature] = df[feature].isna().astype(int)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train = missing_indicator(application_train)\napplication_test = missing_indicator(application_test)\n\nprint('application_train shape: ', application_train.shape)\nprint('application_test shape: ', application_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"По всей видимости, в тренировочном и тестовом наборах разный характер пропусков, приведём к единому виду"},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train, application_test = application_train.align(application_test, join='inner', axis = 1)\n\nprint('application_train shape: ', application_train.shape)\nprint('application_test shape: ', application_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Далее мы заполним пропуски в вещественных признаках средними значениями. Однако среди вещественных принаков встречаются бинарные признаки, и пропуски в них мы будем заполнять строго нулями"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_features_train = application_train[numerical_features].nunique()\nbinary_features_train = binary_features_train[binary_features_train<=2]\nbinary_features_train = binary_features_train.index\n\nbinary_features_test = application_test[numerical_features].nunique()\nbinary_features_test = binary_features_test[binary_features_test<=2]\nbinary_features_test = binary_features_test.index\n\nmin(binary_features_train == binary_features_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_features_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train[binary_features_train] = application_train[binary_features_train].fillna(0)\napplication_test[binary_features_test] = application_test[binary_features_test].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_imputer = Imputer(missing_values='NaN', strategy='mean')\napplication_train[numerical_features] = mean_imputer.fit_transform(application_train[numerical_features])\napplication_test[numerical_features] = mean_imputer.transform(application_test[numerical_features])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь проверим, нет ли у нас признаков скореллированных с целевой переменной"},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train.corrwith(y).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"application_train.corrwith(y).sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n!git clone --recursive https://github.com/Microsoft/LightGBM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt-get install -y -qq libboost-all-dev","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd LightGBM/python-package/;python3 setup.py install --precompile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n!rm -r LightGBM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n        'num_leaves': 10,\n        'max_bin': 127,\n        'min_data_in_leaf': 11,\n        'learning_rate': 0.02,\n        'min_sum_hessian_in_leaf': 0.00245,\n        'bagging_fraction': 1.0, \n        'bagging_freq': 5, \n        'feature_fraction': 0.05,\n        'lambda_l1': 4.972,\n        'lambda_l2': 2.276,\n        'min_gain_to_split': 0.65,\n        'max_depth': 14,\n        'save_binary': True,\n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'binary',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'auc',\n        'is_unbalance': True,\n        'boost_from_average': False,\n        'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnfold = 2\n\ntarget = 'target'\npredictors = application_train.columns.values.tolist()\n\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(application_train))\npredictions = np.zeros(len(application_test))\n\ni = 1\nfor train_index, valid_index in skf.split(application_train, y.values):\n    print(\"\\nfold {}\".format(i))\n    xg_train = lgb.Dataset(application_train.iloc[train_index][predictors].values,\n                           label=y.iloc[train_index].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )\n    xg_valid = lgb.Dataset(application_train.iloc[valid_index][predictors].values,\n                           label=y.iloc[valid_index].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )   \n\n    \n    clf = lgb.train(param, xg_train, 5000, valid_sets = [xg_valid], verbose_eval=50, early_stopping_rounds = 50)\n    oof[valid_index] = clf.predict(application_train.iloc[valid_index][predictors].values, num_iteration=clf.best_iteration) \n    \n    predictions += clf.predict(application_test[predictors], num_iteration=clf.best_iteration) / nfold\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.2f}\".format(metrics.roc_auc_score(y.values, oof)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Модель показывает ROC_AUC 0.75 на тренировочных данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(path+'sample_submission.csv')\nsample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'SK_ID_CURR': application_test.index, 'TARGET': predictions})\nmy_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}