{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom numpy import mean\nfrom sklearn.linear_model import LogisticRegression, Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_rows\", 30)\nd_train = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\nd_test = pd.read_csv('../input/home-credit-default-risk/application_test.csv')\nd_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def missing_values_table(df):\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n            \" columns that have missing values.\")\n    return mis_val_table_ren_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_table(d_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_table(d_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_train.dtypes.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\ncorrelation= d_train.corr()['TARGET'].sort_values()\nprint(correlation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=[\n    'TARGET',\n    'EXT_SOURCE_3',\n    'EXT_SOURCE_2',\n    'EXT_SOURCE_1',\n    'DAYS_EMPLOYED',\n    'FLOORSMAX_AVG',\n    'FLOORSMAX_MEDI',\n    'FLOORSMAX_MODE',\n    'AMT_GOODS_PRICE',\n    'REGION_POPULATION_RELATIVE',\n    'DAYS_LAST_PHONE_CHANGE',\n    'REGION_RATING_CLIENT',\n    'REGION_RATING_CLIENT_W_CITY',\n    'DAYS_BIRTH',\n    'DAYS_ID_PUBLISH',\n    'REG_CITY_NOT_WORK_CITY'    \n]\nd_train=d_train[features]\nfeatures.remove(\"TARGET\")\nd_test=d_test[features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npd.set_option('display.max_rows', 10)\nd_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_table(d_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns=[\n    'EXT_SOURCE_3',\n    'EXT_SOURCE_2',\n    'EXT_SOURCE_1',\n    'FLOORSMAX_AVG',\n    'FLOORSMAX_MEDI',\n    'FLOORSMAX_MODE',\n    'AMT_GOODS_PRICE',\n    'DAYS_LAST_PHONE_CHANGE',   \n]\nfor col in columns:\n    d_train[col]=d_train[col].fillna(d_train[col].mean())\n    d_test[col]=d_test[col].fillna(d_test[col].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_table(d_train)\nd_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_test.dtypes.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = d_train['TARGET']\nd_train=d_train.drop('TARGET',1)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\ntrain_labels\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\ntrain = d_train.copy()\nfeatures = list(train.columns)\ntest = d_test.copy()\nimputer = SimpleImputer(strategy = 'median')\nscaler = MinMaxScaler(feature_range = (0, 1))\nimputer.fit(train)\ntrain = imputer.transform(train)\ntest = imputer.transform(d_test)\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nclf = LGBMClassifier()\nclf.fit(train, train_labels)\npredictions = clf.predict_proba(test)[:, 1]\nd_test = pd.read_csv('../input/home-credit-default-risk/application_test.csv')\nsubmit = d_test[['SK_ID_CURR']]\nsubmit['TARGET'] = predictions\nsubmit.to_csv('lightgbm_baseline.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimg = plt.imread('../input/img123/image.jpg')\nplt.imshow(img)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve \nfrom sklearn.metrics import roc_auc_score\ntrain_x, test_x, train_y, test_y = train_test_split(train, train_labels, test_size=0.2)\ntrain_preds = clf.predict(train_x)\nprint(f\"Train Accuracy: {accuracy_score(train_y, train_preds)}\")\ntest_preds = clf.predict(test_x)\nprint(f\"Test Accuracy: {accuracy_score(test_y, test_preds)}\")\ntest_preds = clf.predict_proba(test_x)\ntest_preds = test_preds[:, 1]\ntrain_preds = clf.predict_proba(train_x)\ntrain_preds = train_preds[:, 1]\nlr_auc = roc_auc_score(test_y, test_preds)\ntr_auc = roc_auc_score(train_y, train_preds)\nprint('train:ROC AUC=%.3f' % (tr_auc))\nprint('test:ROC AUC=%.3f' % (lr_auc))\ntr_fpr, tr_tpr, _ = roc_curve(train_y, train_preds)\n\nlr_fpr, lr_tpr, _ = roc_curve(test_y, test_preds)\nplt.plot(lr_fpr, lr_tpr, marker='.', label='test')\nplt.plot(tr_fpr, tr_tpr, marker='.', label='train')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}