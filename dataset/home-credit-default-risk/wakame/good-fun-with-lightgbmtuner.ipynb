{"cells":[{"metadata":{},"cell_type":"markdown","source":"This Notebook is a rewrite of [Kaggle - good-fun-with-ligthgbm](https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm) in Notebook."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install optuna==0.18.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna \noptuna.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%ls ../input/home-credit-default-risk/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pandas as pd\nimport numpy as np\n\nimport lightgbm as lgb_origin\nimport optuna.integration.lightgbm as lgb\n\nfrom pathlib import Path\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\nfrom sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path = Path(\"../input/home-credit-default-risk/\")\nbureau_path = input_path / \"bureau.csv\"\nbureau_balance_path = input_path / \"bureau_balance.csv\"\napplication_train_path = input_path / \"application_train.csv\"\napplication_test_path = input_path / \"application_test.csv\"\ncredit_card_balance_path = input_path / \"credit_card_balance.csv\"\ninstallments_payments_path = input_path / \"installments_payments.csv\"\nprevious_application_path = input_path / \"previous_application.csv\"\nPOS_CASH_balance_path = input_path / \"POS_CASH_balance.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_importances(feature_importance_df_):\n    # Plot feature importances\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n        by=\"importance\", ascending=False)[:50].index\n    \n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    \n    plt.figure(figsize=(8,10))\n    sns.barplot(x=\"importance\", y=\"feature\", \n                data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances.png')\n    \n\ndef display_roc_curve(y_, oof_preds_, folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6,6))\n    scores = [] \n    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = roc_auc_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n    \n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Luck', alpha=.8)\n    fpr, tpr, thresholds = roc_curve(y_, oof_preds_)\n    score = roc_auc_score(y_, oof_preds_)\n    plt.plot(fpr, tpr, color='b',\n             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n             lw=2, alpha=.8)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('LightGBM ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.tight_layout()\n    \n    plt.savefig('roc_curve.png')\n    \n\ndef display_precision_recall(y_, oof_preds_, folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6,6))\n    \n    scores = [] \n    for n_fold, (_, val_idx) in enumerate(folds_idx_):  \n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = average_precision_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='AP fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n    \n    precision, recall, thresholds = precision_recall_curve(y_, oof_preds_)\n    score = average_precision_score(y_, oof_preds_)\n    plt.plot(precision, recall, color='b',\n             label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n             lw=2, alpha=.8)\n    \n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('LightGBM Recall / Precision')\n    plt.legend(loc=\"best\")\n    plt.tight_layout()\n    \n    plt.savefig('recall_precision_curve.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" def train_model(data_, test_, y_, folds_):\n\n    oof_preds = np.zeros(data_.shape[0])\n    sub_preds = np.zeros(test_.shape[0])\n    \n    feats = [f for f in data_.columns if f not in ['SK_ID_CURR']]\n    \n    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n        trn_data = lgb.Dataset(trn_x, label=trn_y)\n        val_data = lgb.Dataset(val_x, label=val_y)\n        \n        # LightGBMTuner\n        # Reference: https://gist.github.com/smly/367c53e855cdaeea35736f32876b7416\n        best_params = {}\n        tuning_history = []\n        \n        params = {\n                'objective': 'binary',\n                'metric': 'auc',\n            }\n        \n        lgb.train(\n            params,\n            trn_data,\n            num_boost_round=10000,\n            valid_sets=[trn_data, val_data],\n            early_stopping_rounds=100,\n            verbose_eval=200,\n            best_params=best_params,\n            tuning_history=tuning_history\n        )\n        \n        pd.DataFrame(tuning_history).to_csv('./tuning_history_{}.csv'.format(n_fold + 1))\n    \n        best_params['learning_rate'] = 0.05\n\n        # origin LightGBM Model\n        model = lgb_origin.train(\n                best_params,\n                trn_data,\n                num_boost_round=20000,\n                valid_names=['train', 'valid'],\n                valid_sets=[trn_data, val_data],\n                early_stopping_rounds=1000,\n                verbose_eval=1000)\n        \n        oof_preds[val_idx] = model.predict(val_x, \n                                           num_iteration=model.best_iteration)\n        sub_preds += model.predict(test_[feats], num_iteration=model.best_iteration) / folds_.n_splits\n        \n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n        del model, trn_x, trn_y, val_x, val_y, trn_data, val_data\n        gc.collect()\n        \n    print('Full AUC score %.6f' % roc_auc_score(y, oof_preds)) \n    \n    test_['TARGET'] = sub_preds\n\n    return oof_preds, test_[['SK_ID_CURR', 'TARGET']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model_input():\n    buro_bal = pd.read_csv(bureau_balance_path)\n    print('Buro bal shape : ', buro_bal.shape)\n    \n    print('transform to dummies')\n    buro_bal = pd.concat([buro_bal, pd.get_dummies(buro_bal.STATUS, prefix='buro_bal_status')], axis=1).drop('STATUS', axis=1)\n    \n    print('Counting buros')\n    buro_counts = buro_bal[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()\n    buro_bal['buro_count'] = buro_bal['SK_ID_BUREAU'].map(buro_counts['MONTHS_BALANCE'])\n    \n    print('averaging buro bal')\n    avg_buro_bal = buro_bal.groupby('SK_ID_BUREAU').mean()\n    \n    avg_buro_bal.columns = ['avg_buro_' + f_ for f_ in avg_buro_bal.columns]\n    del buro_bal\n    gc.collect()\n    \n    print('Read Bureau')\n    buro = pd.read_csv(bureau_path)\n    \n    print('Go to dummies')\n    buro_credit_active_dum = pd.get_dummies(buro.CREDIT_ACTIVE, prefix='ca_')\n    buro_credit_currency_dum = pd.get_dummies(buro.CREDIT_CURRENCY, prefix='cu_')\n    buro_credit_type_dum = pd.get_dummies(buro.CREDIT_TYPE, prefix='ty_')\n    buro_full = pd.concat([buro, buro_credit_active_dum, buro_credit_currency_dum, buro_credit_type_dum], axis=1)\n    # buro_full.columns = ['buro_' + f_ for f_ in buro_full.columns]\n    \n    del buro_credit_active_dum, buro_credit_currency_dum, buro_credit_type_dum\n    gc.collect()\n    \n    print('Merge with buro avg')\n    buro_full = buro_full.merge(right=avg_buro_bal.reset_index(), how='left', on='SK_ID_BUREAU', suffixes=('', '_bur_bal'))\n    \n    print('Counting buro per SK_ID_CURR')\n    nb_bureau_per_curr = buro_full[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n    buro_full['SK_ID_BUREAU'] = buro_full['SK_ID_CURR'].map(nb_bureau_per_curr['SK_ID_BUREAU'])\n    \n    print('Averaging bureau')\n    avg_buro = buro_full.groupby('SK_ID_CURR').mean()\n    print(avg_buro.head())\n    \n    del buro, buro_full\n    gc.collect()\n    \n    print('Read prev')\n    prev = pd.read_csv(previous_application_path)\n    \n    prev_cat_features = [\n        f_ for f_ in prev.columns if prev[f_].dtype == 'object'\n    ]\n    \n    print('Go to dummies')\n    prev_dum = pd.DataFrame()\n    for f_ in prev_cat_features:\n        prev_dum = pd.concat([prev_dum, pd.get_dummies(prev[f_], prefix=f_).astype(np.uint8)], axis=1)\n    \n    prev = pd.concat([prev, prev_dum], axis=1)\n    \n    del prev_dum\n    gc.collect()\n    print('Counting number of Prevs')\n    nb_prev_per_curr = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    prev['SK_ID_PREV'] = prev['SK_ID_CURR'].map(nb_prev_per_curr['SK_ID_PREV'])\n    \n    print('Averaging prev')\n    avg_prev = prev.groupby('SK_ID_CURR').mean()\n    print(avg_prev.head())\n    del prev\n    gc.collect()\n    \n    print('Reading POS_CASH')\n    pos = pd.read_csv(POS_CASH_balance_path)\n    \n    print('Go to dummies')\n    pos = pd.concat([pos, pd.get_dummies(pos['NAME_CONTRACT_STATUS'])], axis=1)\n    \n    print('Compute nb of prevs per curr')\n    nb_prevs = pos[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    pos['SK_ID_PREV'] = pos['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n    \n    print('Go to averages')\n    avg_pos = pos.groupby('SK_ID_CURR').mean()\n    \n    del pos, nb_prevs\n    gc.collect()\n    \n    print('Reading CC balance')\n    cc_bal = pd.read_csv(credit_card_balance_path)\n    \n    print('Go to dummies')\n    cc_bal = pd.concat([cc_bal, pd.get_dummies(cc_bal['NAME_CONTRACT_STATUS'], prefix='cc_bal_status_')], axis=1)\n    \n    nb_prevs = cc_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    cc_bal['SK_ID_PREV'] = cc_bal['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n    print('Compute average')\n    avg_cc_bal = cc_bal.groupby('SK_ID_CURR').mean()\n    avg_cc_bal.columns = ['cc_bal_' + f_ for f_ in avg_cc_bal.columns]\n    \n    del cc_bal, nb_prevs\n    gc.collect()\n    \n    print('Reading Installments')\n    inst = pd.read_csv(installments_payments_path)\n    nb_prevs = inst[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    inst['SK_ID_PREV'] = inst['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n    \n    avg_inst = inst.groupby('SK_ID_CURR').mean()\n    avg_inst.columns = ['inst_' + f_ for f_ in avg_inst.columns]\n    \n    print('Read data and test')\n    data = pd.read_csv(application_train_path)\n    test = pd.read_csv(application_test_path)\n    print('Shapes : ', data.shape, test.shape)\n    \n    y = data['TARGET']\n    del data['TARGET']\n    \n    categorical_feats = [\n        f for f in data.columns if data[f].dtype == 'object'\n    ]\n    categorical_feats\n    for f_ in categorical_feats:\n        data[f_], indexer = pd.factorize(data[f_])\n        test[f_] = indexer.get_indexer(test[f_])\n        \n    data = data.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\n    \n    data = data.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n    \n    data = data.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n    \n    data = data.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n    \n    data = data.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n    \n    del avg_buro, avg_prev\n    gc.collect()\n\n    return data, test, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.enable()\n# Build model inputs\ndata, test, y = build_model_input()\n# Create Folds\nfolds = KFold(n_splits=5, shuffle=True, random_state=546789)\n# Train model and get oof and test predictions\noof_preds, test_preds = train_model(data, test, y, folds)\n# Save test predictions\ntest_preds.to_csv('first_submission.csv', index=False)\n# Display a few graphs\n# folds_idx = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(data)]\n# display_importances(feature_importance_df_=importances)\n# display_roc_curve(y_=y, oof_preds_=oof_preds, folds_idx_=folds_idx)\n# display_precision_recall(y_=y, oof_preds_=oof_preds, folds_idx_=folds_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}