{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/home-credit-default-risk/application_train.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clear value with missing value > 0\ndf = df.drop(columns=df.columns[df.isnull().sum() > 0])\n# Remove the FLAG_DOCUMENT_* columns and SK_ID_CURR (since its represent the ID No. only)\ncolumn_save = list(filter(lambda x: not x.startswith('FLAG_DOCUMENT'), df.columns))\ndf = df[column_save].drop(columns='SK_ID_CURR')\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the target proportion\ntg = df[\"TARGET\"].value_counts()\nplt.subplots(figsize=(12,8))\npie_target = tg.plot.pie(autopct=\"%.1f%%\")\npie_target.legend(loc=1, labels={'Client with payment difficulties': 0, 'All other cases': 1})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dummy_variable_all(df, sort_frequence=True, dropna=True, map_show=False, skip_column=[]):\n    for column_name in df:\n        if np.dtype(df[column_name]) == 'O' and column_name not in skip_column:\n            if sort_frequence:\n                unique_value = df[column_name].value_counts(dropna=dropna).sort_values().index\n            else:\n                unique_value = df[column_name].value_counts(dropna=dropna).sort_index().index\n            name_map = {}\n            for i, value in enumerate(unique_value):\n                name_map[value] = i\n            if map_show:\n                print('column_name :', column_name)\n                print('replace :', name_map)\n            df[column_name] = df[column_name].map(name_map)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = dummy_variable_all(df.copy(), dropna=False, map_show=True)\ndf2.fillna(df2.median(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndf2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.dtypes.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the correlation\ncorr = df2.corr()\n\nplt.subplots(figsize=(18, 12))\nsns.heatmap(corr, linewidth=0.1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_corr = abs(corr['TARGET'].copy().drop(index=['TARGET'])).sort_values(ascending=False)\ntarget_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the data\nX = df2[df2.columns.copy().drop('TARGET')].values\ny = df2['TARGET'].values\nprint(X.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_classif\nX_new = SelectKBest(f_classif, k=2).fit_transform(X, y)\nprint(X_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the name of selected features\nselected_features = []\nfor i in df2.columns:\n    if all(df2.loc[:, i] == X_new[:, 0]) or all(df2.loc[:, i] == X_new[:, 1]):\n        selected_features.append(i)\nprint(selected_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, train_size=0.75, test_size=0.25)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalized the data\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compare before and after scaled\nprint(X_train)\nprint(X_train_scaled)\nprint(X_test)\nprint(X_test_scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create function to calculate all scores/evaluations\nfrom sklearn.metrics import *\n\ndef evaluation(test, predict):\n    acc_score = accuracy_score(test, predict)\n    prec_score = precision_score(test, predict)\n    rec_score = recall_score(test, predict)\n    f_score = f1_score(test, predict)\n    conf_matrix = confusion_matrix(test, predict)\n    print('Accuracy : {:.3f}'.format(acc_score))\n    print('Precision: {:.3f}'.format(prec_score))\n    print('Recall   : {:.3f}'.format(rec_score))\n    print('F        : {:.3f}'.format(f_score))\n    print('Confusion matrix:\\n', conf_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nneigh5 = KNeighborsClassifier()\nneigh5.fit(X_train_scaled, y_train)\npredict_5 = neigh5.predict(X_test_scaled)\nevaluation(y_test, predict_5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train_scaled, y_train)\ndt_predict = dt.predict(X_test_scaled)\nevaluation(y_test, dt_predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(X_train_scaled, y_train)\nrf_predict = rf.predict(X_test_scaled)\nevaluation(y_test, rf_predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn5_prob = neigh5.predict_proba(X_test_scaled)\ndt_prob = dt.predict_proba(X_test_scaled)\nrf_prob = rf.predict_proba(X_test_scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_prob = (knn5_prob + dt_prob + rf_prob) / 3\naverage_prob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict with application_train.csv\ndf_test = pd.read_csv('../input/home-credit-default-risk/application_test.csv')\ndf_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_file = df_test[selected_features].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalized the data\nX_test_file_scaled = scaler.transform(X_test_file)\nX_test_file_scaled","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn5_prob = neigh5.predict_proba(X_test_file_scaled)\ndt_prob = dt.predict_proba(X_test_file_scaled)\nrf_prob = rf.predict_proba(X_test_file_scaled)\naverage_prob = (knn5_prob + dt_prob + rf_prob) / 3\npredict_res = 1 - average_prob[:, 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = pd.Series(predict_res, name='TARGET')\nfinal = pd.concat([df_test['SK_ID_CURR'], pred], axis=1)\nfinal.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfinal.to_csv(os.path.join('','oof_all_01.csv'), index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}