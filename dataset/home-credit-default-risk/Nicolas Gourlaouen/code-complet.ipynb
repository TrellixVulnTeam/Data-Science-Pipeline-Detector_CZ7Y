{"cells":[{"metadata":{"trusted":true,"_uuid":"afeac7b7af9b171aee27f9be3a49cc8a9179a59d","collapsed":true},"cell_type":"code","source":"#Data preprocessing - 7 mn\nfrom sklearn.model_selection import train_test_split\nimport time\nimport numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport collections\nimport gc\ndeb=time.time()\npath=\"../input\"\n\n#Dictionary which contains the keys of every table. {table:(PRIMARY_KEY,LIST_OF_KEYS)}\nlistfiles={\"application_train\":(\"SK_ID_CURR\",[\"SK_ID_CURR\"]),\"application_test\":(\"SK_ID_CURR\",[\"SK_ID_CURR\"]),\"bureau\":(\"SK_ID_CURR\",[\"SK_ID_CURR\",\"SK_ID_BUREAU\"]),\n           \"bureau_balance\":(\"SK_ID_BUREAU\",[\"SK_ID_BUREAU\"]),\"POS_CASH_balance\":(\"SK_ID_PREV\",[\"SK_ID_CURR\",\"SK_ID_PREV\"]),\"previous_application\":(\"SK_ID_CURR\",[\"SK_ID_CURR\",\"SK_ID_PREV\"]),\n           \"installments_payments\":(\"SK_ID_PREV\",[\"SK_ID_CURR\",\"SK_ID_PREV\"]),\"credit_card_balance\":(\"SK_ID_PREV\",[\"SK_ID_CURR\",\"SK_ID_PREV\"])}\n\n#Function which displays execution time\nftime=[(\"Start\",time.time(),0)]\ndef timer(title,showtime=True):\n    global ftime\n    newtime=(title,time.time(),time.time()-ftime[-1][1])\n    ftime.append(newtime)\n    if showtime==True:\n        print(newtime[0] + \" in \" + str(np.round(newtime[2],2)))\n    else:\n        print(newtime[0]) \n\n#Reading of the file; they are placed in a dictionary\ndata={x:(pd.read_csv(path +\"/\"+ x + '.csv')).sort_values(listfiles[x][0],ascending=True) for x in listfiles}\nfor i in listfiles:\n    data[i].index=list(range(data[i].shape[0]))\n\n#Concatenation of training and testing sets for preprocessing\ndata[\"full\"]=pd.concat([data[\"application_train\"],data[\"application_test\"]],axis=0,sort=True)\ndata[\"full\"].index=list(range(data[\"full\"].shape[0]))\ntrain_shape,test_shape=data[\"application_train\"].shape[0],data[\"application_test\"].shape[0]\ndel data[\"application_train\"],data[\"application_test\"]\ngc.collect()\ntimer(\"Files read and sorted by key\")\n\n#Function which distinguishes continuous, categorical and binary features\ndef set_groups(dataf):\n    num=dataf.columns[(dataf.dtypes!=\"object\").tolist()].tolist() #Numerical features\n    nom=dataf.columns[(dataf.dtypes==\"object\").tolist()].tolist() #Object features\n    continuous,discrete,dichot = [],nom,[]\n    for i in num:\n        notnull=dataf[i][pd.isnull(dataf[i])==False]\n        if len(set(notnull.loc[:200]))>2: continuous.append(i) \n        #Numerical features with more than 2 distinct values are considered continuous\n        #We first only look at the 200 first values in order to limit calculation time\n            \n        else:\n            setvar=set(notnull)\n            if len(setvar)>2: continuous.append(i)\n            elif setvar==set([0,1]): dichot.append(i)\n            #and dataf[i].count()==dataf.shape[0]\n            else: discrete.append(i)\n    timer(\"Groups set\")\n    return(continuous, discrete,dichot)\n\n\"\"\"Agreggation function, which takes as input the table to agreggate (which has to be sorted by key), aggregation key \nand the first 2 letters of the name of the table (to rename features).\nThe purpose of this function is to divide the table into 10 subparts which are agreggated individually and then concatenated \nto limit memory usage. This allows us to avoid memory issues.\"\"\"\ndef agregate(dataf,key,table): \n    continuous, discrete,dichot=set_groups(dataf)\n    if len(dichot) > 0 : dichot = dichot + [key]\n    vals=sorted(list(set(dataf[key]))) #sorted values of the features (in each subpart we will take 1/10 of these values)\n    nbint=10 #Number of subparts\n    pace=len(vals)//nbint+nbint #pace, number of distinct values in each subpart\n    indmin=dataf[key].index[0]\n    dicodf={}\n    for k,i in enumerate(list(range(pace,len(vals)+pace,pace-1))):\n        valmax=vals[i-pace:i-1][-1] #last value of the split\n        indmax=dataf[key][dataf[key]==valmax].index.tolist()[-1] #max index : index of the last line whose value is valmax \n        dicosets={}\n        if len(continuous) > 0 : dicosets[\"continuous\"]=dataf[continuous].loc[indmin:indmax,:].groupby(key).agg([\"sum\",\"max\",\"min\"]) #Agreggation of continuous features\n        if len(dichot) > 0 : dicosets[\"dichot\"]=dataf[dichot].loc[indmin:indmax,:].groupby(key).agg([\"sum\"]) #Agreggation of binary features\n        dicosets[\"count\"]=pd.DataFrame(dataf.loc[indmin:indmax,:].groupby(key)[key].agg(\"count\")) #Count of the number of rows per key\n        ind=pd.MultiIndex(levels=[[table],[\"count\"]],labels=[[0],[0]]) \n        dicosets[\"count\"].columns=ind\n        for x in list(dicosets): dicosets[x].columns=[x[0]+\"_\"+x[1] for x in dicosets[x].columns] #Renaming of the columns\n        dicodf[k]=pd.concat([dicosets[x] for x in list(dicosets)],axis=1) #Concatenation of binary features, continuous features and count\n        del dicosets\n        indmin=indmax+1 #max index for next subpart\n    dataf_tsf=pd.concat([dicodf[k] for k in list(dicodf)],axis=0) #Concatenation of the 10 subparts\n    timer(\"Agreggation done\")\n    return dataf_tsf\n\n#This function gets dummy features from a categorical feature \ndef binar(series,table):\n    setserie=set(series)\n    if len(setserie)==2:\n        var=pd.DataFrame(pd.get_dummies(series).iloc[:,0])\n    else: var=pd.get_dummies(series)\n    name=series.name\n    var.columns=[str(x) + \"_\"+ name for x in var.columns]\n    return var\n\n#This function preprocesses categorical features (filling missing values and getting dummy features)\ndef fill_values(dataf,table):\n        dataf=dataf.fillna('missing')\n        timer(\"Missing values filled for discrete vars\")\n        return pd.concat([binar(dataf[x],table) for x in list(dataf)],axis=1)\n\n#This function preprocesses a table: it defines features types, agreggates and renames the features\ndef process(dataf,keys,keyforagg,name):\n    liste=list(set(dataf)^set(keys)) #Features that are not a key\n    dataf=dataf[liste+[keyforagg]] #Features that are not a key + primary key\n    continuous, discrete,dichot =set_groups(dataf[liste])\n    if len (discrete)>0:\n        var=fill_values(dataf[discrete],name)\n        dataf=dataf.drop(columns=discrete)\n        dataf=pd.concat([dataf,var],axis=1)\n    liste=dataf.columns.tolist()\n    for i in range(len(liste)):\n        if liste[i] not in keys: liste[i]= str(liste[i]+\"_\" +name) #Renaming\n    dataf.columns=liste\n    dataf=agregate(dataf,keyforagg,name)\n    dataf[keyforagg]=dataf.index.tolist()\n    dataf.index=list(range(dataf.shape[0]))\n    return dataf\n\n#First letters of the tables to rename the features \ndiconame={\"bureau\":\"B\",\"bureau_balance\":\"BB\",\"POS_CASH_balance\":\"PCB\",\"previous_application\":\"PA\",\"installments_payments\":\"IP\",\"credit_card_balance\":\"CCB\"}\n\n#List of the successive merging between tables that will be made\nlinks=[('bureau_balance','bureau'),('installments_payments','previous_application'),('credit_card_balance','previous_application'),('POS_CASH_balance','previous_application'),\n      ('previous_application','full'),('bureau','full')]\nfor i in links:\n    timer(\"Processing \" + i[0],showtime=False)\n    data[i[0]]=process(data[i[0]],listfiles[i[0]][1],listfiles[i[0]][0],diconame[i[0]])\n    gc.collect()\n    timer(\"Merging \" + i[0] + \" with \" +i[1],showtime=False)\n    print(data[i[0]].shape)\n    data[i[1]]=data[i[1]].merge(right=data[i[0]],how='left',on=listfiles[i[0]][0]) #Merging\n    del data[i[0]]\n    timer(\"Merging completed\")\n    print(data[i[1]].shape)\n    gc.collect()\n\n#Processing of the final testing set\ncolumnswithoutkeys=list(set(data[\"full\"])^set([\"SK_ID_CURR\"]))\ncontinuous, discrete,dichot =set_groups(data[\"full\"][columnswithoutkeys])\nvar=fill_values(data[\"full\"][discrete],\"Main\") \ndata[\"full\"]=data[\"full\"].drop(columns=discrete)\ndata[\"full\"]=pd.concat([data[\"full\"],var],axis=1)\ngc.collect()\nprint('total preprocessing time : ' + str(time.time()-deb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"689beecaef21111ff6e038d04704465cde6a5a42"},"cell_type":"code","source":"#Feature Engineering, inspired by https://www.kaggle.com/ogrellier/lighgbm-with-selected-features\ndata[\"full\"][\"ANNUITY_INCOME_RATIO\"]=data[\"full\"][\"AMT_ANNUITY\"]/data[\"full\"][\"AMT_INCOME_TOTAL\"]\ndata[\"full\"]['CREDIT_ANNUITY_RATIO'] = data[\"full\"]['AMT_CREDIT'] / data[\"full\"]['AMT_ANNUITY']\ndata[\"full\"]['EXT_SOURCES_PRODUCT'] = data[\"full\"]['EXT_SOURCE_1'] * data[\"full\"]['EXT_SOURCE_2'] * data[\"full\"]['EXT_SOURCE_3']\ndata[\"full\"]['EXT_SOURCES_MEAN'] = data[\"full\"][['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\ndata[\"full\"]['CREDIT_GROODS_PRICE_RATIO'] = data[\"full\"]['AMT_CREDIT'] / data[\"full\"]['AMT_GOODS_PRICE']\ndata[\"full\"]['DAYS_EMPLOYED_DAYS_BIRTH_RATIO'] = data[\"full\"]['DAYS_EMPLOYED'] / data[\"full\"]['DAYS_BIRTH']\ndata[\"full\"]['DAYS_LAST_PHONE_CHANGE_DAYS_EMPLOYED_RATIO'] = data[\"full\"]['DAYS_LAST_PHONE_CHANGE'] / data[\"full\"]['DAYS_EMPLOYED']\ndata[\"full\"]['EXT_SOURCES_STD'] = data[\"full\"][['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\ndata[\"full\"][\"DOCUMENTS_SUM\"]=data[\"full\"][['FLAG_DOCUMENT_2','FLAG_DOCUMENT_3','FLAG_DOCUMENT_4','FLAG_DOCUMENT_5','FLAG_DOCUMENT_6',\n                                       'FLAG_DOCUMENT_7','FLAG_DOCUMENT_8','FLAG_DOCUMENT_9','FLAG_DOCUMENT_10','FLAG_DOCUMENT_11',\n                                       'FLAG_DOCUMENT_12','FLAG_DOCUMENT_13','FLAG_DOCUMENT_14','FLAG_DOCUMENT_15','FLAG_DOCUMENT_16',\n                                       'FLAG_DOCUMENT_17','FLAG_DOCUMENT_18','FLAG_DOCUMENT_19','FLAG_DOCUMENT_20','FLAG_DOCUMENT_21']].mean(axis=1)\ndata[\"full\"][\"REQ_CREDIT_BUREAU_DAY_SUM\"]=data[\"full\"][['AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK',\n                                            'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']].sum(axis=1)\ndata[\"full\"][\"AMT_INCOME_TOTAL_CNT_CHILDREN_RATIO\"]=data[\"full\"][\"AMT_INCOME_TOTAL\"]/data[\"full\"][\"CNT_CHILDREN\"]\ndata[\"full\"][\"CONTACT_FLAGS_MEAN\"]=data[\"full\"][['FLAG_MOBIL','FLAG_EMP_PHONE','FLAG_WORK_PHONE','FLAG_CONT_MOBILE','FLAG_PHONE','FLAG_EMAIL']].mean(axis=1)\ndata[\"full\"][\"LIVE_WORK_PLACE_MEAN\"]=data[\"full\"][[\"REG_CITY_NOT_LIVE_CITY\", \"REG_CITY_NOT_WORK_CITY\", \"LIVE_CITY_NOT_WORK_CITY\"]].mean(axis=1)\ndata[\"full\"][\"LIVE_WORK_REGION_MEAN\"]=data[\"full\"][['REG_REGION_NOT_LIVE_REGION','REG_REGION_NOT_WORK_REGION','LIVE_REGION_NOT_WORK_REGION']].mean(axis=1)\ndata[\"full\"][\"REGION_RATING_MEAN\"]=data[\"full\"][[\"REGION_RATING_CLIENT\",\"REGION_RATING_CLIENT_W_CITY\"]].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85dba3eedaf5385581b637210774222980bc5ff4","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#Validation split\nliste=list(filter(lambda x :x !=\"TARGET\",list(data[\"full\"]))) #List of features for training set\n\nX_train, X_val, y_train, y_val = train_test_split((data[\"full\"].iloc[: train_shape,:])[liste], data[\"full\"][\"TARGET\"].iloc[:train_shape], test_size=0.2, random_state=42)\ndel data[\"full\"]\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59f3d34d48a92df65bf61209bacc7b4df3c04047","scrolled":true,"collapsed":true},"cell_type":"code","source":"#Deletion of the features whose importance is < 5  \nlistetodel=['2_STATUS_BB_sum_B_min',\n '3_STATUS_BB_sum_B_max',\n '3_STATUS_BB_sum_B_min',\n '4_STATUS_BB_sum_B_max',\n '4_STATUS_BB_sum_B_min',\n 'AMT_BALANCE_CCB_sum_PA_sum',\n 'AMT_CREDIT_SUM_OVERDUE_B_min',\n 'AMT_DRAWINGS_ATM_CURRENT_CCB_min_PA_max',\n 'AMT_DRAWINGS_ATM_CURRENT_CCB_min_PA_min',\n 'AMT_DRAWINGS_CURRENT_CCB_min_PA_max',\n 'AMT_DRAWINGS_OTHER_CURRENT_CCB_min_PA_max',\n 'AMT_DRAWINGS_OTHER_CURRENT_CCB_min_PA_min',\n 'AMT_DRAWINGS_OTHER_CURRENT_CCB_min_PA_sum',\n 'AMT_DRAWINGS_OTHER_CURRENT_CCB_sum_PA_max',\n 'AMT_DRAWINGS_POS_CURRENT_CCB_min_PA_max',\n 'AMT_DRAWINGS_POS_CURRENT_CCB_min_PA_sum',\n 'AMT_INST_MIN_REGULARITY_CCB_min_PA_max',\n 'AMT_INST_MIN_REGULARITY_CCB_sum_PA_sum',\n 'AMT_RECIVABLE_CCB_min_PA_min',\n 'AMT_REQ_CREDIT_BUREAU_HOUR',\n 'AMT_TOTAL_RECEIVABLE_CCB_max_PA_sum',\n 'AMT_TOTAL_RECEIVABLE_CCB_min_PA_max',\n 'AMT_TOTAL_RECEIVABLE_CCB_sum_PA_sum',\n 'APARTMENTS_AVG',\n 'APARTMENTS_MEDI',\n 'APARTMENTS_MODE',\n 'Additional Service_NAME_GOODS_CATEGORY_PA_sum',\n 'Advertising_ORGANIZATION_TYPE',\n 'Agriculture_ORGANIZATION_TYPE',\n 'Amortized debt_NAME_CONTRACT_STATUS_PCB_sum_PA_max',\n 'Amortized debt_NAME_CONTRACT_STATUS_PCB_sum_PA_min',\n 'Amortized debt_NAME_CONTRACT_STATUS_PCB_sum_PA_sum',\n 'Animals_NAME_GOODS_CATEGORY_PA_sum',\n 'Another type of loan_CREDIT_TYPE_B_sum',\n 'Approved_NAME_CONTRACT_STATUS_CCB_sum_PA_max',\n 'Approved_NAME_CONTRACT_STATUS_CCB_sum_PA_min',\n 'Approved_NAME_CONTRACT_STATUS_CCB_sum_PA_sum',\n 'Approved_NAME_CONTRACT_STATUS_PCB_sum_PA_max',\n 'Approved_NAME_CONTRACT_STATUS_PCB_sum_PA_min',\n 'Approved_NAME_CONTRACT_STATUS_PCB_sum_PA_sum',\n 'BASEMENTAREA_AVG',\n 'BASEMENTAREA_MEDI',\n 'BASEMENTAREA_MODE',\n 'Bad debt_CREDIT_ACTIVE_B_sum',\n 'Building a house or an annex_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Business development_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Buying a garage_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Buying a holiday home / land_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Buying a home_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Buying a new car_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Buying a used car_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'CLIENT_CODE_REJECT_REASON_PA_sum',\n 'CNT_CREDIT_PROLONG_B_min',\n 'CNT_CREDIT_PROLONG_B_sum',\n 'CNT_DRAWINGS_ATM_CURRENT_CCB_min_PA_max',\n 'CNT_DRAWINGS_ATM_CURRENT_CCB_min_PA_min',\n 'CNT_DRAWINGS_ATM_CURRENT_CCB_min_PA_sum',\n 'CNT_DRAWINGS_CURRENT_CCB_min_PA_max',\n 'CNT_DRAWINGS_CURRENT_CCB_min_PA_min',\n 'CNT_DRAWINGS_CURRENT_CCB_min_PA_sum',\n 'CNT_DRAWINGS_OTHER_CURRENT_CCB_max_PA_max',\n 'CNT_DRAWINGS_OTHER_CURRENT_CCB_max_PA_min',\n 'CNT_DRAWINGS_OTHER_CURRENT_CCB_min_PA_max',\n 'CNT_DRAWINGS_OTHER_CURRENT_CCB_min_PA_min',\n 'CNT_DRAWINGS_OTHER_CURRENT_CCB_min_PA_sum',\n 'CNT_DRAWINGS_OTHER_CURRENT_CCB_sum_PA_max',\n 'CNT_DRAWINGS_OTHER_CURRENT_CCB_sum_PA_min',\n 'CNT_DRAWINGS_POS_CURRENT_CCB_min_PA_sum',\n 'CNT_INSTALMENT_MATURE_CUM_CCB_min_PA_max',\n 'CNT_INSTALMENT_MATURE_CUM_CCB_min_PA_min',\n 'CNT_INSTALMENT_MATURE_CUM_CCB_min_PA_sum',\n 'COMMONAREA_AVG',\n 'COMMONAREA_MEDI',\n 'COMMONAREA_MODE',\n 'CREDIT_DAY_OVERDUE_B_min',\n 'Canceled_NAME_CONTRACT_STATUS_PCB_sum_PA_max',\n 'Canceled_NAME_CONTRACT_STATUS_PCB_sum_PA_min',\n 'Canceled_NAME_CONTRACT_STATUS_PCB_sum_PA_sum',\n 'Car dealer_CHANNEL_TYPE_PA_sum',\n 'Car repairs_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Cars_NAME_PORTFOLIO_PA_sum',\n 'Cash loan (non-earmarked)_CREDIT_TYPE_B_sum',\n 'Cashless from the account of the employer_NAME_PAYMENT_TYPE_PA_sum',\n 'Cleaning_ORGANIZATION_TYPE',\n 'Cooking staff_OCCUPATION_TYPE',\n 'Culture_ORGANIZATION_TYPE',\n 'DAYS_FIRST_DRAWING_PA_max',\n 'Demand_NAME_CONTRACT_STATUS_CCB_sum_PA_max',\n 'Demand_NAME_CONTRACT_STATUS_CCB_sum_PA_min',\n 'Demand_NAME_CONTRACT_STATUS_CCB_sum_PA_sum',\n 'Demand_NAME_CONTRACT_STATUS_PCB_sum_PA_min',\n 'Demand_NAME_CONTRACT_STATUS_PCB_sum_PA_sum',\n 'Direct Sales_NAME_GOODS_CATEGORY_PA_sum',\n 'ELEVATORS_AVG',\n 'ELEVATORS_MEDI',\n 'ELEVATORS_MODE',\n 'ENTRANCES_AVG',\n 'ENTRANCES_MEDI',\n 'ENTRANCES_MODE',\n 'Education_NAME_GOODS_CATEGORY_PA_sum',\n 'Electricity_ORGANIZATION_TYPE',\n 'Emergency_ORGANIZATION_TYPE',\n 'Everyday expenses_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'FLAG_CONT_MOBILE',\n 'FLAG_DOCUMENT_15',\n 'FLAG_DOCUMENT_2',\n 'FLAG_DOCUMENT_5',\n 'FLAG_DOCUMENT_9',\n 'FLAG_EMP_PHONE',\n 'FLOORSMAX_AVG',\n 'FLOORSMAX_MEDI',\n 'FLOORSMAX_MODE',\n 'FLOORSMIN_AVG',\n 'FLOORSMIN_MEDI',\n 'FLOORSMIN_MODE',\n 'Fitness_NAME_GOODS_CATEGORY_PA_sum',\n 'Furniture_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Gardening_NAME_GOODS_CATEGORY_PA_sum',\n 'Gasification / water supply_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Group of people_NAME_TYPE_SUITE_PA_sum',\n 'Hobby_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'House Construction_NAME_GOODS_CATEGORY_PA_sum',\n 'Industry: type 10_ORGANIZATION_TYPE',\n 'Industry: type 11_ORGANIZATION_TYPE',\n 'Industry: type 13_ORGANIZATION_TYPE',\n 'Industry: type 2_ORGANIZATION_TYPE',\n 'Industry: type 6_ORGANIZATION_TYPE',\n 'Industry: type 7_ORGANIZATION_TYPE',\n 'Industry: type 8_ORGANIZATION_TYPE',\n 'Insurance_NAME_GOODS_CATEGORY_PA_sum',\n 'Insurance_ORGANIZATION_TYPE',\n 'Interbank credit_CREDIT_TYPE_B_sum',\n 'Journey_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'LANDAREA_AVG',\n 'LANDAREA_MEDI',\n 'LANDAREA_MODE',\n 'LIVE_CITY_NOT_WORK_CITY',\n 'LIVINGAPARTMENTS_AVG',\n 'LIVINGAPARTMENTS_MEDI',\n 'LIVINGAPARTMENTS_MODE',\n 'LIVINGAREA_AVG',\n 'LIVINGAREA_MEDI',\n 'LIVINGAREA_MODE',\n 'Legal Services_ORGANIZATION_TYPE',\n 'Loan for business development_CREDIT_TYPE_B_sum',\n 'Loan for purchase of shares (margin lending)_CREDIT_TYPE_B_sum',\n 'Loan for the purchase of equipment_CREDIT_TYPE_B_sum',\n 'Loan for working capital replenishment_CREDIT_TYPE_B_sum',\n 'MLM partners_NAME_SELLER_INDUSTRY_PA_sum',\n 'MONTHS_BALANCE_CCB_max_PA_min',\n 'MONTHS_BALANCE_CCB_sum_PA_sum',\n 'Maternity leave_NAME_INCOME_TYPE',\n 'Medical Supplies_NAME_GOODS_CATEGORY_PA_sum',\n 'Medicine_NAME_GOODS_CATEGORY_PA_sum',\n 'Medicine_ORGANIZATION_TYPE',\n 'Mobile operator loan_CREDIT_TYPE_B_sum',\n 'Mobile_ORGANIZATION_TYPE',\n 'Money for a third person_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Monolithic_WALLSMATERIAL_MODE',\n 'NONLIVINGAPARTMENTS_AVG',\n 'NONLIVINGAPARTMENTS_MEDI',\n 'NONLIVINGAPARTMENTS_MODE',\n 'NONLIVINGAREA_AVG',\n 'NONLIVINGAREA_MEDI',\n 'NONLIVINGAREA_MODE',\n 'NUM_INSTALMENT_NUMBER_IP_min_PA_max',\n 'NUM_INSTALMENT_VERSION_IP_min_PA_min',\n 'Office Appliances_NAME_GOODS_CATEGORY_PA_sum',\n 'Other_B_NAME_TYPE_SUITE',\n 'Other_NAME_GOODS_CATEGORY_PA_sum',\n 'POS others without interest_PRODUCT_COMBINATION_PA_sum',\n 'Payments on other loans_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Private service staff_OCCUPATION_TYPE',\n 'Purchase of electronic equipment_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Real estate loan_CREDIT_TYPE_B_sum',\n 'Refusal to name the goal_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'Refused_NAME_CONTRACT_STATUS_CCB_sum_PA_max',\n 'Refused_NAME_CONTRACT_STATUS_CCB_sum_PA_min',\n 'Refused_NAME_CONTRACT_STATUS_CCB_sum_PA_sum',\n 'Religion_ORGANIZATION_TYPE',\n 'Returned to the store_NAME_CONTRACT_STATUS_PCB_sum_PA_min',\n 'SK_DPD_CCB_max_PA_max',\n 'SK_DPD_CCB_sum_PA_sum',\n 'SK_DPD_DEF_CCB_max_PA_sum',\n 'SK_DPD_DEF_PCB_min_PA_max',\n 'SK_DPD_DEF_PCB_min_PA_sum',\n 'SK_DPD_PCB_min_PA_max',\n 'SK_DPD_PCB_min_PA_sum',\n 'SYSTEM_CODE_REJECT_REASON_PA_sum',\n 'Sent proposal_NAME_CONTRACT_STATUS_CCB_sum_PA_max',\n 'Sent proposal_NAME_CONTRACT_STATUS_CCB_sum_PA_min',\n 'Sent proposal_NAME_CONTRACT_STATUS_CCB_sum_PA_sum',\n 'Services_ORGANIZATION_TYPE',\n 'Signed_NAME_CONTRACT_STATUS_CCB_sum_PA_max',\n 'Signed_NAME_CONTRACT_STATUS_CCB_sum_PA_min',\n 'Signed_NAME_CONTRACT_STATUS_CCB_sum_PA_sum',\n 'TOTALAREA_MODE',\n 'Telecom_ORGANIZATION_TYPE',\n 'Tourism_NAME_GOODS_CATEGORY_PA_sum',\n 'Tourism_NAME_SELLER_INDUSTRY_PA_sum',\n 'Trade: type 1_ORGANIZATION_TYPE',\n 'Trade: type 4_ORGANIZATION_TYPE',\n 'Trade: type 5_ORGANIZATION_TYPE',\n 'Trade: type 6_ORGANIZATION_TYPE',\n 'Transport: type 1_ORGANIZATION_TYPE',\n 'Transport: type 2_ORGANIZATION_TYPE',\n 'Unemployed_NAME_INCOME_TYPE',\n 'University_ORGANIZATION_TYPE',\n 'Unknown type of loan_CREDIT_TYPE_B_sum',\n 'Vehicles_NAME_GOODS_CATEGORY_PA_sum',\n 'Weapon_NAME_GOODS_CATEGORY_PA_sum',\n 'XNA_NAME_CLIENT_TYPE_PA_sum',\n 'XNA_NAME_CONTRACT_STATUS_PCB_sum_PA_max',\n 'XNA_NAME_CONTRACT_STATUS_PCB_sum_PA_sum',\n 'XNA_NAME_CONTRACT_TYPE_PA_sum',\n 'YEARS_BEGINEXPLUATATION_AVG',\n 'YEARS_BEGINEXPLUATATION_MEDI',\n 'YEARS_BEGINEXPLUATATION_MODE',\n 'YEARS_BUILD_AVG',\n 'YEARS_BUILD_MEDI',\n 'YEARS_BUILD_MODE',\n 'currency 4_CREDIT_CURRENCY_B_sum',\n 'missing_NAME_TYPE_SUITE',\n 'missing_PRODUCT_COMBINATION_PA_sum',\n '4_STATUS_BB_sum_B_sum',\n 'Industry: type 5_ORGANIZATION_TYPE',\n 'N_FLAG_LAST_APPL_PER_CONTRACT_PA_sum',\n 'AMT_RECEIVABLE_PRINCIPAL_CCB_sum_PA_sum',\n 'Security_ORGANIZATION_TYPE',\n 'CNT_DRAWINGS_OTHER_CURRENT_CCB_sum_PA_sum',\n 'Jewelry_NAME_SELLER_INDUSTRY_PA_sum',\n 'Completed_NAME_CONTRACT_STATUS_CCB_sum_PA_max',\n 'Co-op apartment_NAME_HOUSING_TYPE',\n 'AMT_RECIVABLE_CCB_min_PA_sum',\n 'Education_NAME_CASH_LOAN_PURPOSE_PA_sum',\n 'IT staff_OCCUPATION_TYPE',\n 'Businessman_NAME_INCOME_TYPE',\n 'Group of people_NAME_TYPE_SUITE',\n 'FLAG_DOCUMENT_17',\n 'SK_DPD_CCB_min_PA_max',\n 'FLAG_DOCUMENT_7',\n 'FLAG_DOCUMENT_19',\n 'NUM_INSTALMENT_NUMBER_IP_min_PA_min',\n 'SK_DPD_DEF_PCB_min_PA_min',\n 'SK_DPD_DEF_CCB_min_PA_min',\n 'FLAG_DOCUMENT_21',\n 'FLAG_DOCUMENT_12',\n 'FLAG_DOCUMENT_4',\n 'XNA_NAME_CONTRACT_STATUS_PCB_sum_PA_min',\n 'FLAG_MOBIL',\n 'SK_DPD_CCB_min_PA_min',\n 'Other_A_NAME_TYPE_SUITE',\n 'SK_DPD_PCB_min_PA_min',\n 'SK_DPD_DEF_CCB_min_PA_sum',\n 'SK_DPD_CCB_min_PA_sum',\n 'HR staff_OCCUPATION_TYPE',\n 'Realty agents_OCCUPATION_TYPE',\n 'SK_DPD_DEF_CCB_min_PA_max',\n 'Secretaries_OCCUPATION_TYPE',\n 'Student_NAME_INCOME_TYPE',\n 'Unknown_NAME_FAMILY_STATUS',\n 'XNA_CODE_GENDER',\n 'FLAG_DOCUMENT_20',\n 'FLAG_DOCUMENT_10']\nlistfin=list((set(listetodel)^set(X_train))&set(X_train))\nX_train=X_train[listfin]\nX_val=X_val[listfin]\ngc.collect()\ntimer(\"Features selected\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57a032e54d97e4c7c822d6555cee10e99a227e5d","collapsed":true},"cell_type":"code","source":"#LGBM model\nfrom contextlib import contextmanager\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n#vect=np.copy(y_train)\n#vect[vect==1]=X_train[y_train==0].shape[0]/X_train[y_train==1].shape[0]\n#vect[vect==0]=1\n\nclf = LGBMClassifier(learning_rate =0.1, num_boost_round=1500,  nthread=8, seed=27,colsample_bytree=1, max_depth=3,\n                     min_child_weight=92.5116,min_split_gain=0.0420,num_leaves=13,reg_alpha=0.0407,reg_lambda=0.0305,subsample=0.6408)\nclf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric= 'auc', verbose= 100, early_stopping_rounds= 50)\n#AUC score is measured on both training and validation sets. It is displayed every 100 iterations \n#Training is stopped if there has not been any improvement of AUC score on validation set in 50 iterations\n\nscore=np.round(roc_auc_score(y_val, clf.predict_proba(X_val)[:,1]),4) \nprint(\"Final score on validation set: \" + str(np.round(score,3)))\ntimer(\"Model created.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65b4d867de1043267d1ea438f10460db19cc9813","collapsed":true},"cell_type":"code","source":"\"\"\"#Inspired by https://github.com/fmfn/BayesianOptimization/blob/master/examples/xgboost_example.py\nfrom bayes_opt import BayesianOptimization\nfrom contextlib import contextmanager\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport lightgbm\n\ndef lgbm_evaluate(min_child_weight, colsample_bytree, max_depth, subsample, reg_alpha, min_split_gain, num_leaves, reg_lambda):\n    params['min_child_weight'] = int(min_child_weight)\n    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n    params['max_depth'] = int(max_depth)\n    params['subsample'] = max(min(subsample, 1), 0)\n    params['reg_alpha'] = max(reg_alpha, 0)\n    params['reg_lambda'] = max(reg_lambda, 0)\n    params['num_leaves'] = int(num_leaves)\n    params['min_split_gain'] = max(min(min_split_gain, 1), 0)\n    cv_result = lightgbm.cv(params, dset, num_boost_round=num_rounds, nfold=5,\n             seed=seed,early_stopping_rounds=50,metrics=params[\"eval_metric\"])\n    return cv_result['auc-mean'][-1]\n\ndset=lightgbm.Dataset(X_train,y_train)\nnum_rounds = 3000\nseed=27\nnum_iter = 25\ninit_points = 5\nparams = {'eta': 0.1,'eval_metric': 'auc','verbose_eval': True,'seed': seed,'learning_rate':0.1}\n\nxgbBO = BayesianOptimization(lgbm_evaluate, {'min_child_weight': (1, 100),\n                                            'colsample_bytree': (0.1, 1),\n                                            'max_depth': (3, 10),\n                                            'subsample': (0.5, 1),\n                                            'reg_alpha':(0.001,0.1),\n                                             'num_leaves':(5,30),\n                                             'reg_lambda':(0.001,0.1),\n                                             'min_split_gain':(0.001,0.1)})\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    xgbBO.maximize(init_points=init_points, n_iter=num_iter)\n\n#Results after 5 init points + 25 iterations (LR 0.1)\n#Value   |   colsample_bytree |   max_depth |   min_child_weight |   min_split_gain |   num_leaves |   reg_alpha |   reg_lambda |   subsample \n#0.78363 |             0.9938 |      3.1352 |            92.5116 |           0.0420 |      12.7615 |      0.0407 |       0.0305 |      0.6408 \n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d5647a2b6ddb63f0d08a676bb7d684ebc01ad2e","collapsed":true},"cell_type":"code","source":"\"\"\"#Submission \nsub=pd.Series(reg.predict(test_filled),name=\"TARGET\")\nsub.loc[sub<0]=0\nsub.loc[sub>1]=1\nsub.index=test.index\nsubmission=pd.concat([test[\"SK_ID_CURR\"],sub],axis=1)\nsubmission.to_csv('submission.csv', index=False)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22f57294c240273dad604546367dc43ff267df1a","collapsed":true},"cell_type":"code","source":"#Exploration\n#Reading of the file; they are placed in a dictionary\ndata={x:(pd.read_csv(path +\"/\"+ x + '.csv')).sort_values(listfiles[x][0],ascending=True) for x in listfiles}\nfor i in listfiles:\n    data[i].index=list(range(data[i].shape[0]))\n\n#Concatenation of training and testing sets for preprocessing\ndata[\"full\"]=pd.concat([data[\"application_train\"],data[\"application_test\"]],axis=0,sort=True)\ndata[\"full\"].index=list(range(data[\"full\"].shape[0]))\ntrain_shape,test_shape=data[\"application_train\"].shape[0],data[\"application_test\"].shape[0]\n\n#Table with missing values\ndfstat=pd.DataFrame(index=list(data),columns=[\"NAN < 20 %\", \"< 20 % NAN < 60 %\",\"NAN > 60 %\",\"% missing keys\",\"Nb by key\"])\ndico={'bureau_balance':'bureau','installments_payments':'previous_application','credit_card_balance':'previous_application','POS_CASH_balance':'previous_application',\n      'previous_application':'full','bureau':'full'}\n\nfor file in list(data):\n    print(file)\n    size=data[file].shape[0]\n    nbvar=data[file].shape[1]\n    nb20=0 \n    nb2060=0\n    nb60=0\n    try:\n        dfstat[\"Nb by key\"].loc[file]=data[file].shape[0]/len(set(data[file][listfiles[file][0]]))\n    except KeyError:\n        pass\n    try:\n        setf=set(data[file][listfiles[file][0]])\n        setref=set(data[dico[file]][listfiles[file][0]])\n        ratio = len(setf & setref)/len(setref)\n        dfstat[\"% missing keys\"].loc[file]=1-ratio\n    except KeyError:\n        pass\n    for var in list(data[file]):\n        ratio=data[file][var].count()/size\n        if ratio > 0.8:\n            nb20 +=1\n        elif ratio > 0.4:\n            nb2060 +=1\n        else:\n            nb60 +=1\n    dfstat[\"NAN < 20 %\"].loc[file]=nb20/nbvar\n    dfstat[\"< 20 % NAN < 60 %\"].loc[file]=nb2060/nbvar\n    dfstat[\"NAN > 60 %\"].loc[file]=nb60/nbvar\ndfstat[\"% missing keys\"].loc[\"application_train\",\"application_test\"]=0\ndfstat=dfstat.astype(float).round(2)\ndfstat=dfstat.drop([\"full\"])\ndfstat[\"Nb by key\"]=dfstat[\"Nb by key\"].astype(int)\ndfstat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4400a9c6526af5753fc9805e62ac6ac0228d46a0"},"cell_type":"code","source":"#Proportion d'id du jeu d'entraînement/de test avec au moins un enregistrement dans CCB\nlen(set(data[\"credit_card_balance\"][\"SK_ID_CURR\"])&set(data[\"full\"][\"SK_ID_CURR\"]))/len(set(data[\"full\"][\"SK_ID_CURR\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e15247cd0c89920c1aef6b1797cc523348c88e33"},"cell_type":"code","source":"#Variables avec peu de NAN par table\nimport matplotlib.pyplot as plt\nplt.xticks(rotation=90)\nplt.bar(dfstat.index,dfstat[\"NAN < 20 %\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"44d38fe0898645e94d2b85d8a39e35949c5bed9f"},"cell_type":"code","source":"#Effet voiture/pas de voiture sur la variable cible\ndata[\"application_train\"][\"TARGET\"][data[\"application_train\"][\"FLAG_OWN_CAR\"]==\"Y\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"75065d13252cf8562af88bca84c56452ea6c5023"},"cell_type":"code","source":"#Effet du score extérieur 1 sur la variable cible\ndfvar=data[\"application_train\"][pd.isnull(data[\"application_train\"][\"EXT_SOURCE_1\"])==False]\ndfvar[\"cat\"]=pd.qcut(dfvar[\"EXT_SOURCE_1\"],10,labels=range(10))\ndfvar2=dfvar.groupby(\"cat\",as_index=False)[\"TARGET\"].mean()\ndfvar2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"de18619b49a8ee2ce13645a50a320c49750d8d51"},"cell_type":"code","source":"#Etude sur la mémoire\nimport sys\n\ndicov={\"data[\"+x+\"]\" : data[x] for x in list(data)}\ndicov2={**dicov,**globals()}\na=0\ndicov={\"data[\"+x+\"]\" : data[x] for x in list(data)}\nfor var, obj in dicov2.items():\n    try:\n        a=int(sys.getsizeof(obj)/1e6)\n    except TypeError:\n        print(\"error with \",obj,type(obj),var)\ngc.collect()\nimport sys\ndfmem=pd.DataFrame({x:[\"chat\"] for x in [\"Object\",\"Type\",\"Size\"]},index=list(range(len(dicov2))))\ndico={}\nind=0\ndfmem[\"Size\"]=0\ndfmem[\"Size\"]=dfmem[\"Size\"].astype(int)\nfor var, obj in dicov2.items():\n    try:\n        dfmem[\"Object\"].iat[ind]=var\n        dfmem[\"Type\"].iat[ind]=str(type(obj))\n        dfmem[\"Size\"].iat[ind]=int(sys.getsizeof(obj)/1e6)\n    except TypeError: pass\n    ind+=1\ndfmem=dfmem.sort_values([\"Size\"],ascending=False)\ndfmem","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bae676b59925f5ddf6b20cd857b7e7f3197af1e7"},"cell_type":"code","source":"#Courbe ROC\nfrom sklearn.metrics import roc_curve\na, b, _ = roc_curve(y_val, clf.predict_proba(X_val)[:,1])\nplt.figure(figsize=(5,5))\nplt.xlabel(\"False positive rate\")\nplt.ylabel(\"True positive rate\")\nplt.plot(a,b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"af0b7170bb821295c91be1ad5bfd2931b53211c4"},"cell_type":"code","source":"#Feature Importance\nimport matplotlib.pyplot as plt\nser=pd.concat([pd.Series(list(X_train),name=\"var\"),pd.Series(clf.feature_importances_.tolist(), name=\"Importance\")],axis=1).sort_values(\"Importance\",ascending=False)\nser","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}