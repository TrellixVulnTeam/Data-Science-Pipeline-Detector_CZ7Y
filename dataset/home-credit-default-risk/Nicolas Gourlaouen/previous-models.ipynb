{"cells":[{"metadata":{"trusted":true,"_uuid":"b17e32d88e190c9f86b184e2301d3b9fedc2a40e"},"cell_type":"code","source":"#Imports\nimport time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport collections\n\n#Chargement fichiers\nt=time.time()\n\"\"\"for file in os.listdir(\"../input\"):\n    var=pd.read_csv(\"../input/\" + file)\n    print(\"../input/\" + file, var.shape)\n    print(\"time for loading \" + file + \" : \" + str(time.time()-t) + \" s\")\n    t=time.time() \"\"\"\ntrain=pd.read_csv(\"../input/application_train.csv\")\ntest=pd.read_csv(\"../input/application_test.csv\")\n\n#Distinction variables discrètes/continues\ntype_groups={}\nfor group in [\"float64\", \"int64\", \"object\"]:\n    type_groups[group]=train.dtypes[train.dtypes==group].index.tolist()\ntrain[type_groups[\"float64\"]]\n\nnunique_groups={}\nnunique_groups[\">=40\"]=[]\nnunique_groups[\"<40\"]=[]\nfor x in list(train):\n    if train[x].value_counts().shape[0]>=40:\n        nunique_groups[\">=40\"].append(x)\n    else:\n        nunique_groups[\"<40\"].append(x)\n\ntype_nunique_groups={}\nfor i in list(nunique_groups):\n    for j in list(type_groups):\n        type_nunique_groups[j + \" \" + i]=list(filter(lambda x : x in nunique_groups[i],type_groups[j]))\n        \ncontinuous = type_nunique_groups[\"int64 >=40\"] + type_nunique_groups[\"float64 >=40\"] + type_nunique_groups[\"float64 <40\"] + [\"CNT_CHILDREN\"]\ndiscrete=type_nunique_groups[\"object >=40\"] + type_nunique_groups[\"object <40\"] + list(filter(lambda x : x not in [\"CNT_CHILDREN\",\"TARGET\"], type_nunique_groups[\"int64 <40\"]))\n\n#Gestion des valeurs manquantes\ndef fill_values(dataf,mask=None):\n    t=time.time()\n    #Variables discrètes\n    var=pd.get_dummies(dataf[discrete[0]].fillna('missing'))\n    var.columns=[discrete[0] + '_'+x for x in var.columns]\n    mat=var\n\n    for i in discrete[1:]:\n        var=pd.get_dummies(dataf[i].fillna('missing'))\n        var.columns=[str(i)+ '_'+str(x) for x in var.columns]\n        mat=pd.concat([mat,var],axis=1)\n\n    #Variables continues avec peu de valeurs manquantes\n    missing=(dataf[continuous].count()/dataf.shape[0]).sort_values(ascending=False)\n    to_fill=list(missing[missing>=0.8].index)\n\n    mat2=dataf[to_fill[0]].fillna(dataf[to_fill[0]].median())\n    for i in to_fill[1:]:\n        var=dataf[i].fillna(dataf[i].median())\n        mat2=pd.concat([mat2,var],axis=1)\n\n    #Variables continues avec beaucoup de valeurs manquantes\n    left_to_fill=list(missing[missing<0.8].index)\n    name=left_to_fill[0]\n    var=pd.cut(dataf[name],3).astype('category').cat.add_categories(['missing'])\n    var=pd.get_dummies(var.fillna('missing'))\n    var.columns=[name + \"_\" + str(1),name + \"_\" + str(2),name + \"_\" + str(3),name + \"_\" +'missing']\n    mat3=var\n\n    for i in left_to_fill[1:]:\n        var=pd.cut(dataf[i],3).astype('category').cat.add_categories(['missing'])\n        var=pd.get_dummies(var.fillna('missing'))\n        var.columns=[i + \"_\" + str(1),i + \"_\" + str(2),i + \"_\" + str(3),i + \"_\" +'missing']\n        mat3=pd.concat([mat3,var],axis=1)\n    print(\"Temps pour nettoyage des données : \",time.time()-t,' s')\n    fusion=pd.concat([mat,mat2,mat3],axis=1)\n    #Ajout de colonnes le cas échéant\n    if mask!=None:\n        diff=list(filter(lambda x : x not in list(fusion),mask ))\n        for i in diff : \n            fusion[i]=0\n        diff=list(filter(lambda x : x not in mask,list(fusion) ))\n        for i in diff:\n            del fusion[i]\n    return fusion[sorted(list(fusion))]\ntrain_filled=fill_values(train)\ntest_filled=fill_values(test,list(train_filled))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76675d37ed7661f1df969d479971f3e6b3ded340"},"cell_type":"code","source":"\"\"\"#Modélisation\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nX_train, X_val, y_train, y_val = train_test_split(train_filled, train[\"TARGET\"], test_size=0.2, random_state=42)\nclf=LatentDirichletAllocation()\n#clf=LGBMClassifier(learning_rate =0.075, num_boost_round=1500,  nthread=8, seed=27,colsample_bytree=1, max_depth=3,\n#                     min_child_weight=87.5467,min_split_gain=0.0950,num_leaves=22,reg_alpha=0.0019,reg_lambda=0.0406,subsample=0.8709)\n#clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric= 'auc', verbose= 100, early_stopping_rounds= 50)\nclf.fit(X_train,y_train)\n#score=np.round(roc_auc_score(y_val, clf.predict_proba(X_val)[:,1]),4) \nscore=np.round(roc_auc_score(y_val, clf.predict(X_val)),4) \nscore  \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"#Modélisation\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.linear_model import LinearRegression\n\n#Modèles\n\"\"\"reg=RandomForestRegressor()\nreg.fit(train_filled,train[\"TARGET\"])\n\"\"\"\nclf=LGBMClassifier(learning_rate =0.075, num_boost_round=1500,  nthread=8, seed=27,colsample_bytree=1, max_depth=3,\n                     min_child_weight=87.5467,min_split_gain=0.0950,num_leaves=22,reg_alpha=0.0019,reg_lambda=0.0406,subsample=0.8709)\nclf.fit(train_filled, train[\"TARGET\"], eval_metric= 'auc', verbose= 100)\n\nsub=pd.Series(clf.predict_proba(test_filled)[:,1],name=\"TARGET\")\n#sub=pd.Series(reg.predict(test_filled),name=\"TARGET\")\nsub.loc[sub<0]=0\nsub.loc[sub>1]=1\nsub.index=test.index\nsubmission=pd.concat([test[\"SK_ID_CURR\"],sub],axis=1)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"063527d980faa6a35b8dda11fc74790cac4303ef"},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e2be40bdcbe2affcddb085890e892ee8f87c52bf"},"cell_type":"code","source":"\"\"\"#Target encoding\ndef fill_values(dataf,target,continuous, discrete,nint):\n    a=0\n    #Variables discrètes\n    dataf_tsf=pd.DataFrame(dataf[target])\n    dataf_tsf.index=dataf.index\n    if len(discrete) >0:\n        #dataf[discrete]=dataf[discrete].fillna('missing')\n        for i in discrete:\n            print(a,i)\n            a+=1\n            dataf_tsf[i]=0\n            groups=dataf.groupby(i)[\"TARGET\"].mean()\n            dicogroups={x:groups[x] for x in groups.index}\n            meannull=dataf[\"TARGET\"][pd.isnull(dataf[i])==True].mean() #Calcul de la valeur moyenne de la variable cible par modalité\n            dicogroups[np.nan]=meannull\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}