{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nimport time\nfrom contextlib import contextmanager\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot_encoder(df, nan_as_category = True):\n    original_columns = list(df.columns) # col names as string in a list \n    categorical_columns = [col for col in df.columns if df[col].dtype == 'object'] #categorical col names\n    df = pd.get_dummies(df, columns = categorical_columns, dummy_na = nan_as_category) #creating dummies\n    new_columns = [c for c in df.columns if c not in original_columns] #new col names\n    return df, new_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_encoder(df):\n    # Create a label encoder object\n    le = LabelEncoder()\n    le_count = 0\n\n    # Iterate through the columns\n    for col in df:\n        if df[col].dtype == 'object':\n            # If 2 or fewer unique categories\n            if len(list(df[col].unique())) <= 2:\n                # Train on the training data\n                le.fit(df[col])\n                # Transform both training and testing data\n                df[col] = le.transform(df[col])\n\n                # Keep track of how many columns were label encoded\n                le_count += 1\n\n    print('%d columns were label encoded.' % le_count)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Preprocess application_train.csv and application_test.csv\ndef application_train_test():\n    \n    df = pd.read_csv(\"../input/home-credit-default-risk/application_train.csv\")\n    test_df = pd.read_csv(\"../input/home-credit-default-risk/application_test.csv\")\n\n    df = df.append(test_df).reset_index()\n    del df[\"index\"]\n    \n    df = df[df['CODE_GENDER'] != 'XNA']\n    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n\n    df['APP_NEW_AGE'] = df['DAYS_BIRTH'] / (- 365.25)\n    \n    APP_NEW_AGE_CAT = pd.Series([\"Young\", \"Adult 1\",\"Adult 2\",\"Adult 3\", \"Adult 4\"], dtype = \"object\")\n    df[\"APP_NEW_AGE_CAT\"] = APP_NEW_AGE_CAT\n    df.loc[(df[\"APP_NEW_AGE\"] > 20.0) & (df[\"APP_NEW_AGE\"] <= 30.0), \"APP_NEW_AGE_CAT\"] = APP_NEW_AGE_CAT[0]\n    df.loc[(df[\"APP_NEW_AGE\"] > 30.0) & (df[\"APP_NEW_AGE\"] <= 40.0), \"APP_NEW_AGE_CAT\"] = APP_NEW_AGE_CAT[1]\n    df.loc[(df[\"APP_NEW_AGE\"] > 40.0) & (df[\"APP_NEW_AGE\"] <= 50.0), \"APP_NEW_AGE_CAT\"] = APP_NEW_AGE_CAT[2]\n    df.loc[(df[\"APP_NEW_AGE\"] > 50.0) & (df[\"APP_NEW_AGE\"] <= 60.0), \"APP_NEW_AGE_CAT\"] = APP_NEW_AGE_CAT[3]\n    df.loc[df[\"APP_NEW_AGE\"] > 60 ,\"APP_NEW_AGE_CAT\"] = APP_NEW_AGE_CAT[4]\n    \n    df[\"APP_NEW_AGE_DAYS_EMP\"] = df[\"DAYS_EMPLOYED\"] / (- 365.25)\n    df[\"APP_NEW_AGE_WORK_PERCENT\"] = (df[\"APP_NEW_AGE_DAYS_EMP\"] / df['APP_NEW_AGE']) * 100\n    df['APP_NEW_CREDIT_INCOME_PERCENT'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n    df['APP_NEW_ANNUITY_INCOME_PERCENT'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n    df['APP_NEW_DAYS_EMPLOYED_PERCENT'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['APP_NEW_INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n    df['APP_NEW_INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n    df['APP_NEW_PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n    df['APP_NEW_AMT_PAY_YEAR'] = df['AMT_CREDIT'] / df['AMT_ANNUITY'] \n    df['APP_NEW_AGE_PAYOFF'] = df['APP_NEW_AGE'] + df['APP_NEW_AMT_PAY_YEAR']\n    df['APP_NEW_AMT_DIFF_CREDIT_GOODS'] = df['AMT_CREDIT'] - df['AMT_GOODS_PRICE'] \n    df['APP_NEW_AMT_CREDIT_GOODS_PERC'] = ((df['AMT_GOODS_PRICE'] / df['AMT_CREDIT']) * 100)\n    df['APP_NEW_CNT_ADULT'] = df['CNT_FAM_MEMBERS'] - df['CNT_CHILDREN']\n    df['APP_NEW_EXT_SOURCES_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n\n    df = label_encoder(df)\n    \n    df, cat_cols = one_hot_encoder(df)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess bureau.csv and bureau_balance.csv\ndef bureau_and_balance(num_rows = None, nan_as_category = True):\n    bureau = pd.read_csv('../input/home-credit-default-risk/bureau.csv', nrows = num_rows)\n    bureau_balance = pd.read_csv('../input/home-credit-default-risk/bureau_balance.csv', nrows = num_rows)\n    \n    \n    # Bureau balance: Perform aggregations and merge with bureau.csv\n    def _status_to_int(status):\n        if status in ['X', 'C']:\n            return 0\n        if pd.isnull(status):\n            return np.nan\n        return int(status)\n\n    bureau_balance['NEW_BUREAU_BALANCE_DPD_LEVEL'] = bureau_balance['STATUS'].apply(_status_to_int)\n    bureau_balance['NEW_BUREAU_BALANCE_STATUS_UNKNOW'] = (bureau_balance['STATUS'] == 'X').astype(int)  \n    bureau_balance[\"MONTHS_BALANCE\"] = (-1*bureau_balance[\"MONTHS_BALANCE\"])+1\n    bb_aggregations = {'MONTHS_BALANCE': [\"max\"],\n                    'NEW_BUREAU_BALANCE_DPD_LEVEL':['sum', 'mean', 'max', 'std', 'skew'],\n                    'NEW_BUREAU_BALANCE_STATUS_UNKNOW':['sum', 'mean']}\n    bb_agg = bureau_balance.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n    del bureau_balance, bb_agg\n    gc.collect()\n    \n     # Bureau new features\n    bureau.drop([\"AMT_CREDIT_SUM_LIMIT\",\"AMT_CREDIT_SUM_OVERDUE\",\"CREDIT_DAY_OVERDUE\",\"AMT_CREDIT_SUM_OVERDUE\"],axis=1,inplace=True)\n    bureau['BUREAU_CREDIT_TYPE_CONSUMER'] = (bureau['CREDIT_TYPE'] == 'Consumer credit').astype(int)\n    bureau['BUREAU_CREDIT_TYPE_CAR'] = (bureau['CREDIT_TYPE'] == 'Car loan').astype(int)\n    bureau['BUREAU_CREDIT_TYPE_MORTGAGE'] = (bureau['CREDIT_TYPE'] == 'Mortgage').astype(int)\n    bureau['BUREAU_CREDIT_TYPE_CREDIT_CARD'] = (bureau['CREDIT_TYPE'] == 'Credit card').astype(int)\n    bureau['BUREAU_CREDIT_TYPE_OTHER'] = (~(bureau['CREDIT_TYPE'].isin(['Consumer credit',\n                                                        'Car loan', 'Mortgage', 'Credit card']))).astype(int)\n    bureau['BUREAU_UNUSUAL_CURRENCY'] = (~(bureau['CREDIT_CURRENCY'] == 'currency 1')).astype(int)\n    bureau['NEW_PAYMENT_RATE_SUM'] = bureau['AMT_ANNUITY'] / bureau['AMT_CREDIT_SUM']\n    bureau['NEW_PAYMENT_RATE_SUM_DEBT'] = bureau['AMT_ANNUITY'] / bureau['AMT_CREDIT_SUM_DEBT']\n    bureau['NEW_PAYMENT_RATE_AMT_CREDIT_MAX_OVERDUE'] = bureau['AMT_ANNUITY'] / bureau['AMT_CREDIT_MAX_OVERDUE']\n    \n    bureau.drop([\"CREDIT_TYPE\",\"CREDIT_CURRENCY\"],axis=1,inplace=True)\n     # Bureau and bureau_balance numeric features\n    num_aggregations = {\n        \"DAYS_CREDIT\": ['min', 'max', 'mean', 'var', 'sum'],\n        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n        'DAYS_CREDIT_UPDATE': ['mean'],\n        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n        'DAYS_ENDDATE_FACT': ['mean', 'sum'],\n        'AMT_ANNUITY': ['max', 'mean'],\n        'CNT_CREDIT_PROLONG': ['sum','std'],\n        'MONTHS_BALANCE_MAX': ['max'],\n        \"NEW_BUREAU_BALANCE_DPD_LEVEL_SUM\" :['max',\"sum\"],\n        \"NEW_BUREAU_BALANCE_DPD_LEVEL_MEAN\" :['max',\"sum\",\"mean\"],\n        \"NEW_BUREAU_BALANCE_DPD_LEVEL_MAX\" :['max',\"sum\"],\n        \"NEW_BUREAU_BALANCE_DPD_LEVEL_STD\" :['max',\"sum\",\"std\"],\n        \"NEW_BUREAU_BALANCE_DPD_LEVEL_SKEW\" :['max',\"sum\",\"skew\"],\n        \"NEW_BUREAU_BALANCE_STATUS_UNKNOW_SUM\" :['max',\"sum\"],\n        \"NEW_BUREAU_BALANCE_STATUS_UNKNOW_MEAN\" :['max',\"sum\",\"mean\"],\n        'BUREAU_CREDIT_TYPE_CONSUMER': ['mean', 'sum'],\n        'BUREAU_CREDIT_TYPE_CAR': ['mean', 'sum'],\n        'BUREAU_CREDIT_TYPE_MORTGAGE': ['mean', 'sum'],\n        'BUREAU_CREDIT_TYPE_CREDIT_CARD': ['mean', 'sum'],\n        'BUREAU_CREDIT_TYPE_OTHER': ['mean', 'sum'],\n        'BUREAU_UNUSUAL_CURRENCY': ['mean', 'sum'],\n        'NEW_PAYMENT_RATE_SUM':['max',\"mean\",\"sum\"],\n        'NEW_PAYMENT_RATE_SUM_DEBT':['max',\"mean\",\"sum\"],\n        'NEW_PAYMENT_RATE_AMT_CREDIT_MAX_OVERDUE':['max',\"mean\",\"sum\"]\n    }\n    # Bureau and bureau_balance categorical features\n    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n    cat_aggregations = {}\n    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n    \n    \n    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n    # Bureau: Active credits - using only numerical aggregations\n    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n    del active, active_agg\n    gc.collect()\n    # Bureau: Closed credits - using only numerical aggregations\n    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n    del closed, closed_agg, bureau\n    gc.collect()\n    return bureau_agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Preprocess previous_applications.csv\ndef previous_applications(num_rows = None, nan_as_category = True):\n    \n    df = pd.read_csv(\"../input/home-credit-default-risk/previous_application.csv\")\n    \n    df.replace(365243,np.nan,inplace = True)\n    df.replace(\"XNA\",np.nan,inplace = True)\n\n    df['NEW_RETURN_DAY'] = df['DAYS_DECISION'] + df['CNT_PAYMENT'] * 30\n\n    df['NEW_DAYS_TERMINATION_diff'] = df['DAYS_TERMINATION'] - df['NEW_RETURN_DAY']\n\n    df['NEW_AMT_DOWN_PAYMENT_rate'] = df['AMT_DOWN_PAYMENT'] / (df['AMT_CREDIT'] + 0.01)\n\n    df['NEW_AMT_SPEND_TO_PRODUCT'] = df['AMT_GOODS_PRICE'] / df['AMT_CREDIT']\n    \n    df['NEW_DAYS_DUE']=df['DAYS_FIRST_DUE'] - df['DAYS_LAST_DUE_1ST_VERSION'] \n    \n    df['NEW_APP_CREDIT_PERC'] = df['AMT_APPLICATION'] / df['AMT_CREDIT']\n    \n    df[\"NAME_PAYMENT_TYPE\"].replace([\"Non-cash from your account\",\"Cashless from the account of the employer\"],np.nan,inplace=True)\n\n    a = [\"Channel of corporate sales\",\"Car dealer\"]\n    df[\"CHANNEL_TYPE\"].replace(a,\"Others_Type\",inplace=True)\n\n    b = ['Family', 'Spouse, partner', 'Children', 'Other_B', 'Other_A', 'Group of people'] \n    df[\"NAME_TYPE_SUITE\"] = df[\"NAME_TYPE_SUITE\"].replace(b, 'not_alone')\n\n    df[\"WEEKDAY_APPR_PROCESS_START\"] = df[\"WEEKDAY_APPR_PROCESS_START\"].replace(['MONDAY','TUESDAY', 'WEDNESDAY','THURSDAY','FRIDAY'], 'WEEK_DAY') \n    df[\"WEEKDAY_APPR_PROCESS_START\"] = df[\"WEEKDAY_APPR_PROCESS_START\"].replace(['SATURDAY', 'SUNDAY'], 'WEEKEND')\n\n    a = ['Auto technology', 'Jewelry', 'MLM partners', 'Tourism'] \n    df[\"NAME_SELLER_INDUSTRY\"] = df[\"NAME_SELLER_INDUSTRY\"].replace(a, 'Other_Ind')\n\n    a = ['Auto Accessories', 'Jewelry', 'Homewares', 'Medical Supplies', 'Vehicles', 'Sport and Leisure','Gardening', 'Other', 'Office Appliances', 'Tourism', 'Medicine', 'Direct Sales', 'Fitness', 'Additional Service','Education', 'Weapon', 'Insurance', 'House Construction', 'Animals']  \n    df[\"NAME_GOODS_CATEGORY\"] = df[\"NAME_GOODS_CATEGORY\"].replace(a, 'Other_Cat')\n\n    a = ['Buying a used car','Building a house or an annex','Everyday expenses','Medicine','Payments on other loans','Education','Journey', 'Purchase of electronic equipment','Buying a new car','Wedding / gift / holiday','Buying a home','Car repairs','Furniture','Buying a holiday home / land', 'Business development','Gasification / water supply','Buying a garage','Hobby','Money for a third person','Refusal to name the goal','Urgent needs','Other']\n    df['NAME_CASH_LOAN_PURPOSE']= df['NAME_CASH_LOAN_PURPOSE'].replace(a,'Others')\n\n    df[\"NAME_PORTFOLIO\"].replace(\"cars\",np.nan,inplace=True)\n    \n    a = [8,9,10,11,12,13,14,15,16,17]\n    df[\"HOUR_APPR_PROCESS_START\"] = df[\"HOUR_APPR_PROCESS_START\"].replace(a, 'Working_Hours')\n\n    b = [18,19,20,21,22,23,0,1,2,3,4,5,6,7]\n    df[\"HOUR_APPR_PROCESS_START\"] = df[\"HOUR_APPR_PROCESS_START\"].replace(b, 'Off_Hours')\n    \n    drops = [\"RATE_INTEREST_PRIMARY\",\"RATE_INTEREST_PRIVILEGED\",\"FLAG_LAST_APPL_PER_CONTRACT\",\"NFLAG_LAST_APPL_IN_DAY\",\"NAME_PRODUCT_TYPE\",\"SELLERPLACE_AREA\"]\n    df.drop(drops,inplace=True,axis=1)\n    \n    df[\"NFLAG_INSURED_ON_APPROVAL\"] = df[\"NFLAG_INSURED_ON_APPROVAL\"].astype(\"object\")\n    cat_features = list(df.select_dtypes(['object']).columns)\n    df = pd.get_dummies(df, columns= cat_features, dummy_na= True,drop_first=True)\n    \n    agg1 = {'SK_ID_CURR': ['size'],\n    'AMT_ANNUITY': ['max', 'min', 'mean','std', 'sum'], \n    'AMT_APPLICATION':['max', 'min', 'mean','std', 'sum'],\n    'AMT_CREDIT':['max', 'min', 'mean','std', 'sum'],\n    'AMT_DOWN_PAYMENT': ['max', 'min', 'mean','std', 'sum'],\n    'AMT_GOODS_PRICE': ['max', 'min', 'mean','std', 'sum'],\n    'RATE_DOWN_PAYMENT': ['max', 'min', 'mean','std'],\n    'DAYS_DECISION': ['max', 'min', 'mean', 'sum'],\n    'CNT_PAYMENT': ['max', 'min', 'mean','std', 'sum'],\n    'DAYS_FIRST_DRAWING': ['max', 'min', 'mean', 'sum'],\n    'DAYS_FIRST_DUE': ['max', 'min', 'mean', 'sum'],\n    'DAYS_LAST_DUE_1ST_VERSION': ['max', 'min', 'mean', 'sum'],\n    'DAYS_LAST_DUE': ['max', 'min', 'mean', 'sum'],\n    'DAYS_TERMINATION': ['max', 'min', 'mean','std', 'sum'],\n    'NEW_RETURN_DAY': ['max', 'min', 'mean','std', 'sum'],\n    'NEW_DAYS_TERMINATION_diff': ['max', 'min', 'mean','std', 'sum'],\n    'NEW_AMT_DOWN_PAYMENT_rate': ['max', 'min', 'mean','std'],\n    'NEW_AMT_SPEND_TO_PRODUCT': ['max', 'min', 'mean','std', 'sum'],\n    'NEW_APP_CREDIT_PERC': ['max', 'min', 'mean'],\n    'NAME_CONTRACT_TYPE_Consumer loans': ['max', 'min','sum'],\n    'NAME_CONTRACT_TYPE_Revolving loans': ['max', 'min','sum'],\n    'NAME_CONTRACT_TYPE_nan': ['max', 'min','sum'],\n    'WEEKDAY_APPR_PROCESS_START_WEEK_DAY': ['max', 'min', 'sum'],\n    'WEEKDAY_APPR_PROCESS_START_nan': ['max', 'min', 'sum'],\n    'HOUR_APPR_PROCESS_START_Working_Hours': ['max', 'min', 'sum'],\n    'HOUR_APPR_PROCESS_START_nan': ['max', 'min', 'sum'],\n    'NAME_CASH_LOAN_PURPOSE_Repairs': ['max', 'min', 'sum'],\n    'NAME_CASH_LOAN_PURPOSE_XAP': ['max', 'min', 'sum'],\n    'NAME_CASH_LOAN_PURPOSE_nan': ['max', 'min',  'sum'],\n    'NAME_CONTRACT_STATUS_Canceled': ['max', 'min', 'sum'],\n    'NAME_CONTRACT_STATUS_Refused': ['max', 'min', 'sum'],\n    'NAME_CONTRACT_STATUS_Unused offer': ['max', 'min', 'sum'],\n    'NAME_CONTRACT_STATUS_nan': ['max', 'min', 'sum'],\n    'NAME_PAYMENT_TYPE_nan': ['max', 'min', 'sum'],\n    'CODE_REJECT_REASON_HC': ['max', 'min','sum'],\n    'CODE_REJECT_REASON_LIMIT': ['max', 'min','sum'],\n    'CODE_REJECT_REASON_SCO': ['max', 'min','sum'],\n    'CODE_REJECT_REASON_SCOFR': ['max', 'min', 'sum'],\n    'CODE_REJECT_REASON_SYSTEM': ['max', 'min', 'sum'],\n    'CODE_REJECT_REASON_VERIF': ['max', 'min', 'sum'],\n    'CODE_REJECT_REASON_XAP': ['max', 'min', 'sum'],\n    'CODE_REJECT_REASON_nan': ['max', 'min','sum'],\n    'NAME_TYPE_SUITE_not_alone': ['max', 'min','sum'],\n    'NAME_TYPE_SUITE_nan': ['max', 'min', 'sum'],\n    'NAME_CLIENT_TYPE_Refreshed': ['max', 'min','sum'],\n    'NAME_CLIENT_TYPE_Repeater': ['max', 'min', 'sum'],\n    'NAME_CLIENT_TYPE_nan': ['max', 'min','sum'],\n    'NAME_GOODS_CATEGORY_Clothing and Accessories': ['max', 'min', 'sum'],\n    'NAME_GOODS_CATEGORY_Computers': ['max', 'min','sum'],\n    'NAME_GOODS_CATEGORY_Construction Materials': ['max', 'min', 'sum'],\n    'NAME_GOODS_CATEGORY_Consumer Electronics': ['max', 'min', 'sum'],\n    'NAME_GOODS_CATEGORY_Furniture': ['max', 'min', 'sum'],\n    'NAME_GOODS_CATEGORY_Mobile': ['max', 'min', 'sum'],\n    'NAME_GOODS_CATEGORY_Other_Cat': ['max', 'min', 'sum'],\n    'NAME_GOODS_CATEGORY_Photo / Cinema Equipment': ['max', 'min', 'sum'],\n    'NAME_GOODS_CATEGORY_nan': ['max', 'min', 'sum'],\n    'NAME_PORTFOLIO_Cars': ['max', 'min', 'sum'],\n    'NAME_PORTFOLIO_Cash': ['max', 'min', 'sum'],\n    'NAME_PORTFOLIO_POS': ['max', 'min','sum'],\n    'NAME_PORTFOLIO_nan': ['max', 'min', 'sum'],\n    'CHANNEL_TYPE_Contact center': ['max', 'min', 'sum'],\n    'CHANNEL_TYPE_Country-wide': ['max', 'min', 'sum'],\n    'CHANNEL_TYPE_Credit and cash offices': ['max', 'min', 'sum'],\n    'CHANNEL_TYPE_Others_Type': ['max', 'min', 'sum'],\n    'CHANNEL_TYPE_Regional / Local': ['max', 'min','sum'],\n    'CHANNEL_TYPE_Stone': ['max', 'min','sum'],\n    'CHANNEL_TYPE_nan': ['max', 'min', 'sum'],\n    'NAME_SELLER_INDUSTRY_Connectivity': ['max', 'min','sum'],\n    'NAME_SELLER_INDUSTRY_Construction': ['max', 'min', 'sum'],\n    'NAME_SELLER_INDUSTRY_Consumer electronics': ['max', 'min',  'sum'],\n    'NAME_SELLER_INDUSTRY_Furniture': ['max', 'min', 'sum'],\n    'NAME_SELLER_INDUSTRY_Industry': ['max', 'min', 'sum'],\n    'NAME_SELLER_INDUSTRY_Other_Ind': ['max', 'min','sum'],\n    'NAME_SELLER_INDUSTRY_nan': ['max', 'min','sum'],\n    'NAME_YIELD_GROUP_low_action': ['max', 'min', 'sum'],\n    'NAME_YIELD_GROUP_low_normal': ['max', 'min', 'sum'],\n    'NAME_YIELD_GROUP_middle': ['max', 'min','sum'],\n    'NAME_YIELD_GROUP_nan': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_Card X-Sell': ['max', 'min', 'sum'],\n    'PRODUCT_COMBINATION_Cash': ['max', 'min', 'sum'],\n    'PRODUCT_COMBINATION_Cash Street: high': ['max', 'min', 'sum'],\n    'PRODUCT_COMBINATION_Cash Street: low': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_Cash Street: middle': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_Cash X-Sell: high': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_Cash X-Sell: low': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_Cash X-Sell: middle': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_POS household with interest': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_POS household without interest': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_POS industry with interest': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_POS industry without interest': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_POS mobile with interest': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_POS mobile without interest': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_POS other with interest': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_POS others without interest': ['max', 'min','sum'],\n    'PRODUCT_COMBINATION_nan': ['max', 'min','sum'],\n    'NFLAG_INSURED_ON_APPROVAL_1.0': ['max', 'min','sum'],\n    'NFLAG_INSURED_ON_APPROVAL_nan': ['max', 'min','sum']}\n    \n    df = df.groupby(['SK_ID_CURR']).agg(agg1)\n    \n    df.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in df.columns.tolist()])\n\n    return (df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess installments_payments.csv\ndef installments_payments(num_rows=None, nan_as_category = True):\n    pd.options.mode.chained_assignment = None\n    df = pd.read_csv(\"../input/home-credit-default-risk/installments_payments.csv\")\n    df[\"NEW_DELAY\"] = df[\"DAYS_INSTALMENT\"] - df[\"DAYS_ENTRY_PAYMENT\"] \n    \n    df['NEW_FLAG_DELAY'] = df['NEW_DELAY'].apply(lambda x : 1 if x < 0 else 0)\n    df['NEW_RATIO_DELAY'] = df[['SK_ID_PREV','NEW_FLAG_DELAY']].groupby('SK_ID_PREV')['NEW_FLAG_DELAY'].transform(lambda x : x.sum() / x.count())\n    \n    df[\"NEW_PAYMENT_DIFF\"] = df[\"AMT_INSTALMENT\"] - df[\"AMT_PAYMENT\"]\n    \n    \n    df[\"NUM_INSTALMENT_VERSION\"] = df[\"NUM_INSTALMENT_VERSION\"].astype(\"object\")\n    df[(df[\"NUM_INSTALMENT_VERSION\"] != 1) & (df[\"NUM_INSTALMENT_VERSION\"] != 0) & (df[\"NUM_INSTALMENT_VERSION\"] != 2) & (df[\"NUM_INSTALMENT_VERSION\"] != 3)]['NUM_INSTALMENT_VERSION'] = 4\n    \n    cat_features = list(df.select_dtypes(['object']).columns)\n    df = pd.get_dummies(df, columns= cat_features,drop_first=True)\n    \n    \n    agg1 = {'SK_ID_CURR': ['count','max'],\n           'NEW_DELAY': ['max', 'min', 'mean','std', 'sum'],\n           'NUM_INSTALMENT_NUMBER':['min','max'], \n           'DAYS_INSTALMENT':['max','min','std'], \n           'NEW_PAYMENT_DIFF': ['max', 'mean', 'std', 'min','sum'],\n           'AMT_INSTALMENT': ['max', 'mean', 'sum', 'min', 'std'],\n           'AMT_PAYMENT': ['min', 'max', 'mean', 'sum', 'std'],\n           'DAYS_ENTRY_PAYMENT': ['max', 'min', 'std'],\n           \"NUM_INSTALMENT_VERSION_1.0\":[\"sum\"],\n           \"NUM_INSTALMENT_VERSION_2.0\":[\"sum\"],\n           \"NUM_INSTALMENT_VERSION_3.0\":[\"sum\"],\n           \"NUM_INSTALMENT_VERSION_4.0\":[\"sum\"]\n            }\n    \n    \n    \n    Installments_agg = df.groupby(['SK_ID_PREV']).agg(agg1)\n    \n    Installments_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in Installments_agg.columns.tolist()])\n    \n    Installments_agg['NEW_DAYS_INSTALMENT_NUMBER']=Installments_agg['DAYS_INSTALMENT_MAX']-Installments_agg['DAYS_INSTALMENT_MIN'] \n    \n    Installments_agg['NEW_AMT_INSTALMENT_DIFF']=Installments_agg['AMT_INSTALMENT_MAX']-Installments_agg['AMT_INSTALMENT_MIN']\n    \n    \n    \n    agg2= {'SK_ID_CURR_COUNT':['min', 'max'],\n           'SK_ID_CURR_MAX':['min', 'max'],\n           'NEW_DELAY_MAX':['min', 'max', 'mean'],\n           'NEW_DELAY_MIN':['min', 'max', 'mean'],\n           'NEW_DELAY_MEAN':['min', 'max', 'mean'],\n           'NEW_DELAY_STD':['min', 'max', 'mean'],\n           'NEW_DELAY_SUM':['min', 'max', 'mean', 'sum', 'std'],\n           'NUM_INSTALMENT_NUMBER_MIN':['min','max','mean'], \n           'NUM_INSTALMENT_NUMBER_MAX':['min','max','mean','sum'],\n           'NEW_DAYS_INSTALMENT_NUMBER':['min','max','std'], \n           'DAYS_INSTALMENT_STD':['min','max','std'], \n           'DAYS_INSTALMENT_MIN':['std','min','max'],\n           'DAYS_INSTALMENT_MAX':['std','min','max'],\n           'NEW_PAYMENT_DIFF_MAX':['min', 'max', 'mean',\"std\"],\n           'NEW_PAYMENT_DIFF_MEAN':['min', 'max', 'mean',\"std\"],\n           'NEW_PAYMENT_DIFF_SUM':['min', 'max', 'mean',\"std\"],\n           'NEW_PAYMENT_DIFF_STD':['min', 'max', 'mean',\"std\"],\n           'NEW_PAYMENT_DIFF_MIN':['min', 'max', 'mean',\"std\"],\n           'AMT_INSTALMENT_MAX':['min', 'max', 'mean',\"sum\"],\n           'AMT_INSTALMENT_MEAN':['min', 'max', 'mean',\"sum\"],\n           'AMT_INSTALMENT_SUM':['min', 'max', 'mean',\"sum\"],\n           'AMT_INSTALMENT_STD':['min', 'max', 'mean',\"sum\"],\n           'AMT_INSTALMENT_MIN':['min', 'max', 'mean',\"sum\"],\n           'NEW_AMT_INSTALMENT_DIFF':['min','max','mean',\"sum\"],\n           'AMT_PAYMENT_MIN':['min', 'max', 'mean',\"std\",\"sum\"],\n           'AMT_PAYMENT_MAX':['min', 'max', 'mean',\"std\",\"sum\"],\n           'AMT_PAYMENT_MEAN':['min', 'max', 'mean',\"std\",\"sum\"],\n           'AMT_PAYMENT_STD':['min', 'max', 'mean',\"std\",\"sum\"],\n           'AMT_PAYMENT_SUM':['min', 'max', 'mean',\"std\",\"sum\"],\n           'DAYS_ENTRY_PAYMENT_MIN':['min', 'max', 'mean'],\n           'DAYS_ENTRY_PAYMENT_STD':['min', 'max', 'mean'],\n           'DAYS_ENTRY_PAYMENT_MAX':['min', 'max', 'mean'],\n           'NUM_INSTALMENT_VERSION_1.0_SUM':['sum'],\n           'NUM_INSTALMENT_VERSION_2.0_SUM':['sum'],\n           'NUM_INSTALMENT_VERSION_3.0_SUM':['sum'],\n           'NUM_INSTALMENT_VERSION_4.0_SUM':['sum']\n    }\n    \n    Installments_agg2=Installments_agg.groupby('SK_ID_CURR_MAX').agg(agg2)\n    Installments_agg2.index.names = ['SK_ID_CURR']\n    \n    \n    Installments_agg2.columns = pd.Index(\"INSTAL_\" + e[0] + \"_\" + e[1].upper() for e in Installments_agg2.columns.tolist())\n    return(Installments_agg2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess POS_CASH_balance.csv\ndef pos_cash(num_rows = None, nan_as_category = True):\n    df=pd.read_csv('../input/home-credit-default-risk/POS_CASH_balance.csv')\n    \n    df['NEW_ADJOURNMENT']=df['SK_DPD']-df['SK_DPD_DEF']\n    \n    \n    b = [\"Demand\",\"Returned to the store\",\"Approved\",\"Amortized debt\",\"Canceled\",\"XNA\"]\n    df[\"NAME_CONTRACT_STATUS\"].replace(b, 'Others',inplace=True)\n    \n    \n    cat_features = list(df.select_dtypes(['object']).columns)\n    df = pd.get_dummies(df, columns= cat_features, dummy_na= True)\n    \n    \n    agg={\n    'MONTHS_BALANCE': ['max',\"min\"],\n    'SK_DPD': ['max', 'mean',\"std\"],\n    'SK_DPD_DEF': ['max', 'mean',\"std\"],\n    'CNT_INSTALMENT':['min','mean','max'],\n    'CNT_INSTALMENT_FUTURE':['mean','min','max'],\n    'SK_ID_CURR':['max','size'],\n    'NEW_ADJOURNMENT':['max','mean',\"std\"],\n    'NAME_CONTRACT_STATUS_Active':['sum'],\n    'NAME_CONTRACT_STATUS_Completed':['sum'],\n    'NAME_CONTRACT_STATUS_Signed':['sum'],\n    'NAME_CONTRACT_STATUS_Others':['sum']\n    \n    }\n    \n    \n    pos_agg = df.groupby(['SK_ID_PREV']).agg(agg)\n    \n    \n    pos_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n    \n    pos_agg[\"NEW_PAID_MONTH\"] = pos_agg[\"CNT_INSTALMENT_MAX\"] - pos_agg[\"CNT_INSTALMENT_FUTURE_MIN\"]\n    \n    agg2={\n        \"MONTHS_BALANCE_MAX\":[\"min\",\"max\",\"mean\"],\n        \"MONTHS_BALANCE_MIN\":[\"min\",\"max\",\"mean\"],\n        \"SK_DPD_MAX\":[\"max\",\"mean\",\"min\"],\n        \"SK_DPD_MEAN\":[\"max\",\"mean\",\"min\"],\n        \"SK_DPD_STD\":[\"max\",\"mean\",\"min\",\"std\"],\n        \"SK_DPD_DEF_MAX\":[\"max\",\"mean\",\"min\"],\n        \"SK_DPD_DEF_MEAN\":[\"max\",\"mean\",\"min\"],\n        \"SK_DPD_DEF_STD\":[\"max\",\"mean\",\"min\"],\n        \"CNT_INSTALMENT_MIN\":[\"max\",\"mean\",\"min\"],\n        \"CNT_INSTALMENT_MEAN\":[\"max\",\"mean\",\"min\"],\n        \"CNT_INSTALMENT_MAX\":[\"max\",\"mean\",\"min\"],\n        \"CNT_INSTALMENT_FUTURE_MEAN\":[\"max\",\"mean\",\"min\"],\n        \"CNT_INSTALMENT_FUTURE_MIN\":[\"max\",\"mean\",\"min\"],\n        \"CNT_INSTALMENT_FUTURE_MAX\":[\"max\",\"mean\",\"min\"],\n        \"SK_ID_CURR_MAX\":[\"max\",\"min\"],\n        \"SK_ID_CURR_SIZE\":[\"max\",\"min\"],\n        \"NEW_ADJOURNMENT_MAX\":[\"max\",\"mean\",\"min\"],\n        \"NEW_ADJOURNMENT_MEAN\":[\"max\",\"mean\",\"min\"],\n        \"NEW_ADJOURNMENT_STD\":[\"max\",\"mean\",\"min\"],\n        \"NAME_CONTRACT_STATUS_Active_SUM\":[\"max\",\"min\",\"sum\"],\n        'NAME_CONTRACT_STATUS_Signed_SUM':[\"max\",\"min\",\"sum\"],\n        'NAME_CONTRACT_STATUS_Completed_SUM':[\"max\",\"min\",\"sum\"],\n        'NAME_CONTRACT_STATUS_Others_SUM':[\"max\",\"min\",\"sum\"]\n        \n    }\n    \n    pos_agg2 = pos_agg.groupby([\"SK_ID_CURR_MAX\"]).agg(agg2)\n    pos_agg2.index.names = ['SK_ID_CURR']\n    \n    pos_agg2.columns = pd.Index([\"POS\" + \"_\" + e[0] + \"_\" + e[1].upper() for e in pos_agg2.columns.tolist()])\n    \n    return (pos_agg2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess credit_card_balance.csv\ndef credit_card_balance(num_rows = None, nan_as_category = True):\n    cc = pd.read_csv('../input/home-credit-default-risk/credit_card_balance.csv', nrows = num_rows)\n    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n    # General aggregations\n    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n    cc['number_of_instalments'] = cc.groupby(\n    by=['SK_ID_CURR'])['CNT_INSTALMENT_MATURE_CUM'].agg('max').reset_index()[\n    'CNT_INSTALMENT_MATURE_CUM']\n    cc['AMT_DRAWINGS_ATM_CURRENT'][cc['AMT_DRAWINGS_ATM_CURRENT'] < 0] = np.nan\n    cc['AMT_DRAWINGS_CURRENT'][cc['AMT_DRAWINGS_CURRENT'] < 0] = np.nan\n    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n    # Count credit card lines\n    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n    del cc\n    gc.collect()\n    return cc_agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM GBDT with KFold or Stratified KFold\n# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\ndef kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n    import re\n    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n    # Divide in training/validation and test data\n    train_df = df[df['TARGET'].notnull()]\n    test_df = df[df['TARGET'].isnull()]\n    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n    del df\n    gc.collect()\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n    else:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n\n        # LightGBM parameters found by Bayesian optimization\n        clf = LGBMClassifier(\n            njobs = -1,\n            n_estimators=10000,\n            learning_rate=0.02,\n            num_leaves=34,\n            colsample_bytree=0.9497036,\n            subsample=0.8715623,\n            max_depth=8,\n            reg_alpha=0.041545473,\n            reg_lambda=0.0735294,\n            min_split_gain=0.0222415,\n            min_child_weight=39.3259775,\n            silent=-1,\n            verbose=-1, )\n\n        clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)], \n            eval_metric = 'auc', verbose = 300, early_stopping_rounds = 200)\n\n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        del clf, train_x, train_y, valid_x, valid_y\n        gc.collect()\n\n    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n    # Write submission file and plot feature importance\n    if not debug:\n        test_df['TARGET'] = sub_preds\n        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n    display_importances(feature_importance_df)\n    return feature_importance_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def main(debug = False):\n    num_rows = 10000 if debug else None\n    df = application_train_test()\n    with timer(\"Process bureau and bureau_balance\"):\n        bureau = bureau_and_balance(num_rows)\n        print(\"Bureau df shape:\", bureau.shape)\n        df = df.join(bureau, how='left', on='SK_ID_CURR')\n        del bureau\n        gc.collect()\n    with timer(\"Process previous_applications\"):\n        prev = previous_applications(num_rows)\n        print(\"Previous applications df shape:\", prev.shape)\n        df = df.join(prev, how='left', on='SK_ID_CURR')\n        del prev\n        gc.collect()\n    with timer(\"Process POS-CASH balance\"):\n        pos = pos_cash(num_rows)\n        print(\"Pos-cash balance df shape:\", pos.shape)\n        df = df.join(pos, how='left', on='SK_ID_CURR')\n        del pos\n        gc.collect()\n    with timer(\"Process installments payments\"):\n        ins = installments_payments(num_rows)\n        print(\"Installments payments df shape:\", ins.shape)\n        df = df.join(ins, how='left', on='SK_ID_CURR')\n        del ins\n        gc.collect()\n    with timer(\"Process credit card balance\"):\n        cc = credit_card_balance(num_rows)\n        print(\"Credit card balance df shape:\", cc.shape)\n        df = df.join(cc, how='left', on='SK_ID_CURR')\n        del cc\n        gc.collect()\n    with timer(\"Run LightGBM with kfold\"):\n        feat_importance = kfold_lightgbm(df, num_folds= 10, stratified= False, debug= debug)\n\nif __name__ == \"__main__\":\n    submission_file_name = \"submission_kernel02.csv\"\n    with timer(\"Full model run\"):\n        main()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}