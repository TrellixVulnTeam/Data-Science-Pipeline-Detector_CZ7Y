{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Reference: https://www.kaggle.com/inversion/starter-kernel-yt8m-2019-sample-data (Thanks!)\n# How to save tfrecord into numpy for pytorch user (TOO SLOW!)\n# Please remove \"break\" in In[4] to experience how it is really slow.\n# Do you have any ideas? \n\nimport os\nimport numpy as np\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"frame_dir = '../input/validate-sample/validate/'\nout_dir = '../out/'\ntry:\n    os.stat(out_dir)\nexcept:\n    os.mkdir(out_dir)       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frame_lvl_record = frame_dir + 'validate00.tfrecord'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for example in tf.python_io.tf_record_iterator(frame_lvl_record):\n\n    dataset = dict()\n    \n    tf_example = tf.train.Example.FromString(example)\n    tf_seq_example = tf.train.SequenceExample.FromString(example)\n\n    n_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n\n    vid_id = tf_example.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\n    vid_labels = tf_example.features.feature['labels'].int64_list.value    \n\n    rgb_frame = []\n    audio_frame = []\n    \n    sess = tf.InteractiveSession()\n\n    for i in range(n_frames):\n        rgb_frame.append(tf.cast(tf.decode_raw(\n            tf_seq_example.feature_lists.feature_list['rgb']\n            .feature[i].bytes_list.value[0], tf.uint8)\n                                 , tf.float32).eval())\n        \n        audio_frame.append(tf.cast(tf.decode_raw(\n            tf_seq_example.feature_lists.feature_list['audio']\n            .feature[i].bytes_list.value[0], tf.uint8)\n                                   , tf.float32).eval())\n\n    sess.close()\n    \n    dataset['id'] = vid_id\n    dataset['labels'] = list(vid_labels)\n    dataset['rgb_frame'] = list(rgb_frame)\n    dataset['audio_frame'] = list(audio_frame)\n            \n    np.save(out_dir + vid_id + '.npy', np.array(dataset))\n    \n    break  # read only the 1st video","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(out_dir))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}