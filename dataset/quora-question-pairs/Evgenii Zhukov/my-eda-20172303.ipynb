{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"517a9969-a564-7410-693f-de6bcf795a6d"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8651a74d-4054-ff0c-bb42-c72efb9d6c1c"},"outputs":[],"source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ec35bc9-ddcd-0249-231b-880939f575db"},"outputs":[],"source":"train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59fc20a2-960b-5a65-5f3a-4b66dd23c125"},"outputs":[],"source":"test.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"9c08531f-edd8-48e3-e373-a65aab6df06d"},"source":"Now I'm gonna to print some queation pairs from duplicated subset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7c6c0d53-7e01-18f5-76c3-82fb05fa4736"},"outputs":[],"source":"# look at some diplicated question pairs\nfor i in train[train['is_duplicate'] == 1].index[:10]:\n    print('{}.'.format(i))\n    print('question1: {}'.format(train[train['is_duplicate'] == 1].loc[i, 'question1']))\n    print('question2: {}'.format(train[train['is_duplicate'] == 1].loc[i, 'question2']))\n    print('---------------------------------------------------')"},{"cell_type":"markdown","metadata":{"_cell_guid":"65385968-70cb-f282-be7b-894d93a8fb49"},"source":"Do the same but with non-duplicated"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05ade257-2c6f-9b62-d14a-e238a1871b9d"},"outputs":[],"source":"# look at some no-diplicated question pairs\nfor i in train[train['is_duplicate'] == 0].index[:30]:\n    print('{}.'.format(i))\n    print('question1: {}'.format(train[train['is_duplicate'] == 0].loc[i, 'question1']))\n    print('question2: {}'.format(train[train['is_duplicate'] == 0].loc[i, 'question2']))\n    print('---------------------------------------------------')"},{"cell_type":"markdown","metadata":{"_cell_guid":"a0ee9d74-0557-f77d-a38a-5c0158a1bb53"},"source":"One little note: I've noted there are some non-duplicated question pairs which can have one big common part and different little clarification"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7c32fc18-fe79-f87d-32e5-215c1e0d3b7b"},"outputs":[],"source":"train.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd9c1037-4f14-76b5-a5b6-7644d620b049"},"outputs":[],"source":"test.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"02de8230-04d3-edf0-b8ab-2383caf5d16b"},"outputs":[],"source":"train.fillna('xxxxx', inplace=True)\ntest.fillna('xxxxx', inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac805543-85cf-b983-c079-de3214c82a6c"},"outputs":[],"source":"# create columns with both question1 and question2\ntrain['question_pair'] = train['question1'] + '. ' + train['question2']\ntest['question_pair'] = test['question1'] + '. ' + test['question2']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1c3c43e-314f-0ba9-f9cf-78563f83195f"},"outputs":[],"source":"### Get a set of all Symbols in both train and text"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8d001a8-8800-8dba-a43e-9adb43833c96"},"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71f4338b-d21f-aad3-2bdd-7992b9c5a947"},"outputs":[],"source":"count_vectorizer = CountVectorizer(analyzer='char')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"28a6ab1b-a324-562e-ea89-673d7b810929"},"outputs":[],"source":"count_vectorizer.fit(pd.concat([train['question_pair'], test['question_pair']]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce9dad79-5cf1-91a2-0fdd-9e8a47d58d77"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}