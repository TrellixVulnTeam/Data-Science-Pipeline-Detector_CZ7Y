{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26c10c12-4b8d-92f5-9e2f-0b19fb94dbc4"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nimport xgboost as xgb\n\nfrom fuzzywuzzy import fuzz\n\ncolor = sns.color_palette()\n%matplotlib inline\n\neng_stopwords = set(nltk.corpus.stopwords.words('english'))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ffda97c7-63dd-853d-54ba-0177fa7149fa"},"outputs":[],"source":"raw_df = pd.read_csv(\"../input/train.csv\", encoding=\"utf8\")\ndf = raw_df.set_index(\"id\")\ndf = df.sample(n=100000, random_state=7)\nprint (df[df[\"is_duplicate\"]==1].shape)\nprint (df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd80faea-82d6-3ecb-9371-836b124e60df"},"outputs":[],"source":"# lower ==> tokenize ==> rm stop words\nfrom nltk.stem.lancaster import LancasterStemmer\nst = LancasterStemmer()\n\ndef nlp_preprocess(sent):\n    try:\n        #words = nltk.wordpunct_tokenize(sent.lower())\n        words = sent.lower().replace(\"?\", \"\").split()\n        #words = [st.stem(w) for w in words]\n    except:\n        words = []\n    words = [w for w in words if w not in eng_stopwords]\n    return words\n    \ndef preprocess(sent):\n    q = nlp_preprocess(sent) # q = [\"w1\", \"w2\", ..]\n    return q\n\ndf[\"q1\"] = df[\"question1\"].apply(preprocess)\ndf[\"q2\"] = df[\"question2\"].apply(preprocess)\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"172b6a16-7200-577a-c388-8c27fc66a831"},"outputs":[],"source":"# find same words\n\ndef find_same_words(x):\n    return list( set(x[\"q1\"]) & set(x[\"q2\"]) )\n\ndf[\"same_words\"] = df.apply(find_same_words, axis=1)\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c3d81e6-a464-6f3c-5498-099f3fbefedc"},"outputs":[],"source":"# feature 1: unigram\ndf[\"f_nSameWords\"] = df[\"same_words\"].apply(lambda x: len(x))\n\ndef prop_of_same_words_1(x):\n    return x[\"f_nSameWords\"]*1.0 / (len(x[1])+1.0)\ndef prop_of_same_words_2(x):\n    return x[\"f_nSameWords\"]*1.0 / max( (len(set(x[1])|set(x[2]))) , 1.0 )\n\ndf[\"f_ratioSameWords\"] = df[[\"f_nSameWords\", \"q1\", \"q2\"]].apply(prop_of_same_words_2, axis=1)\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa6bdb7a-910b-a89d-673b-f03bc90e232f"},"outputs":[],"source":"plt.figure(figsize=(12,6))\nsns.boxplot(x=\"is_duplicate\", y=\"f_nSameWords\", data=df)\nplt.xlabel('Is duplicate', fontsize=12)\nplt.ylabel('Common unigram ratio', fontsize=12)\nplt.show()\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x=\"is_duplicate\", y=\"f_ratioSameWords\", data=df)\nplt.xlabel('Is duplicate', fontsize=12)\nplt.ylabel('Common unigram ratio', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9675edd6-eb06-d045-222b-254ae02de108"},"outputs":[],"source":"# feature 2: 2-gram words\ndef get_twogram(que):\n    return [i for i in nltk.ngrams(que, 2)]\n\ndef get_same_twogram(row):\n    return list( set(row[\"twogram1\"]) & set(row[\"twogram2\"]) )\n\ndef prop_of_same_twogram(row):\n    return row[\"f_nSameTwoGram\"]*1.0 / max( (len(set(row[\"twogram1\"]) | set(row[\"twogram2\"]))), 1.0 )\n\ndf[\"twogram1\"] = df[\"q1\"].apply(get_twogram)\ndf[\"twogram2\"] = df[\"q2\"].apply(get_twogram)\ndf[\"same_twogram\"] = df.apply(get_same_twogram, axis=1)\n\ndf[\"f_nSameTwoGram\"] = df.apply(lambda x: len(x[\"same_twogram\"]), axis=1)\ndf[\"f_ratioSameTwogram\"] = df.apply(prop_of_same_twogram, axis=1)\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a2c6adc9-a6d2-a5bc-8ec1-8dbccd89fbe2"},"outputs":[],"source":"plt.figure(figsize=(12,6))\nsns.boxplot(x=\"is_duplicate\", y=\"f_nSameTwoGram\", data=df)\nplt.xlabel('Is duplicate', fontsize=12)\nplt.ylabel('Common twograms ratio', fontsize=12)\nplt.show()\n\nplt.figure(figsize=(12,6))\nsns.boxplot(x=\"is_duplicate\", y=\"f_ratioSameTwogram\", data=df)\nplt.xlabel('Is duplicate', fontsize=12)\nplt.ylabel('Common twograms ratio', fontsize=12)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea63e74e-5a56-dd45-ef26-6e56eaddf6b2"},"outputs":[],"source":"# reduce the # of positive samples in training data\ndef resample(df):\n    df_train_neg = df[df[\"is_duplicate\"]==0]\n    df_train_pos = df[df[\"is_duplicate\"]==1]\n    ratio_inc = (df_train_pos.shape[0]/0.17 - df.shape[0])*1.0 / df_train_neg.shape[0]\n    if ratio_inc > 1:\n        df_inc = df_train_neg.sample(frac=(ratio_inc-1.0))\n        df_train_neg_inc = pd.concat([df_train_neg, df_inc])\n    else:\n        df_train_neg_inc = df_train_neg.sample(frac=ratio_inc)\n    df = pd.concat([df_train_neg, df_train_neg_inc, df_train_pos]).sample(frac=1.0) # concat and shuffle\n    return df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6caf8555-a3b3-b6e3-c650-06407f6a4ccb"},"outputs":[],"source":"#=============================================#\n#               train a model                 #\n#=============================================#\n\nn_valid = 20000\nfeatures = [\"f_nSameWords\", \"f_ratioSameWords\"]\nfeatures.extend([\"f_nSameTwoGram\", \"f_ratioSameTwogram\"])\n\ndf_need = df[features+[\"is_duplicate\"]]\ndf_valid = df_need.iloc[0:n_valid, ]\ndf_train = df_need.iloc[n_valid:, ]\ndf_valid = resample(df_valid)\ndf_train = resample(df_train)\nprint (df_valid.shape)\nprint (df_train.shape)\n\nX_valid = df_valid[features].iloc[0:n_valid, ]\nX_train = df_train[features].iloc[n_valid:, ]\n\ny_valid = df_valid[\"is_duplicate\"].iloc[0:n_valid, ]\ny_train = df_train[\"is_duplicate\"].iloc[n_valid:, ]\n\ndtrain = xgb.DMatrix( X_train, label=y_train)\ndvalid = xgb.DMatrix( X_valid, label=y_valid)\n\nevallist  = [(dtrain,'train'), (dvalid,'test')]\n\nparam = {'max_depth':4, 'eta':0.05, 'silent':1, 'objective':'binary:logistic' }\nparam['nthread'] = 12\nparam['eval_metric'] = 'logloss'\n\nparam[\"min_child_weight\"] = 1\nparam[\"colsample_bytree\"] = 0.7\nparam[\"subsample\"] = 0.7\nparam[\"seed\"] = 71\n\nnum_round = 300\nbst = xgb.train( param.items(), dtrain, num_round, evallist, early_stopping_rounds=100, verbose_eval=10 )\n\nxgb.plot_importance(bst)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ddc2b81c-00f1-8ce1-f621-4bce5de657a5"},"outputs":[],"source":"# sampling from wrong predicted samples\npred = bst.predict(dvalid)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2ebe0aa-0753-a26b-1058-056d08516202"},"outputs":[],"source":"# do predict\n#df_test = pd.read_csv(\"../input/test.csv\", encoding=\"utf8\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"94a4268a-6509-82e3-2e5d-035ece85574f"},"outputs":[],"source":"#df_test[\"q1\"] = df_test[\"question1\"].apply(preprocess)\n#df_test[\"q2\"] = df_test[\"question2\"].apply(preprocess)\n#df_test[\"same_words\"] = df_test.apply(find_same_words, axis=1)\n#df_test[\"f_nSameWords\"] = df_test[\"same_words\"].apply(lambda x: len(x))\n#df_test[\"f_ratioSameWords\"] = df_test[[\"f_nSameWords\", \"q1\", \"q2\"]].apply(prop_of_same_words_2, axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"009b3f86-49f0-ac38-f6fa-e68163b21fe6"},"outputs":[],"source":"#df_test[\"twogram1\"] = df_test[\"q1\"].apply(get_twogram)\n#df_test[\"twogram2\"] = df_test[\"q2\"].apply(get_twogram)\n#df_test[\"same_twogram\"] = df_test.apply(get_same_twogram, axis=1)\n#df_test[\"f_nSameTwoGram\"] = df_test.apply(lambda x: len(x[\"same_twogram\"]), axis=1)\n#df_test[\"f_ratioSameTwogram\"] = df_test.apply(prop_of_same_twogram, axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6326d25-c234-049e-b1af-e391ce48f513"},"outputs":[],"source":"#=============================================#\n#                    predict                  #\n#=============================================#\n\n#X_test = df_test[features]\n#dtest = xgb.DMatrix( X_test )\n\n#ypred = bst.predict(dtest)\n\n#df_test[\"is_duplicate\"] = ypred\n#df_test[[\"test_id\", \"is_duplicate\"]].to_csv(\"xgb_starter.csv\", index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"090a15ae-0029-b062-21f7-03baab636b39"},"outputs":[],"source":"import random\n\nque1 = df[\"question1\"].iloc[0:n_valid, ]\nque2 = df[\"question2\"].iloc[0:n_valid, ]\nq1 = df[\"q1\"].iloc[0:n_valid, ]\nq2 = df[\"q2\"].iloc[0:n_valid, ]\n\nr = random.sample(range(n_valid), 100)\nfor i in r:\n    print (y_valid.iloc[i], pred[i], q1.iloc[i], q2.iloc[i], que1.iloc[i], que2.iloc[i])"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}